{"title": "Demima: A multilayered approach for design pattern identification\n", "abstract": " Design patterns are important in object-oriented programming because they offer design motifs, elegant solutions to recurrent design problems, which improve the quality of software systems. Design motifs facilitate system maintenance by helping to understand design and implementation. However, after implementation, design motifs are spread throughout the source code and are thus not directly available to maintainers. We present DeMIMA, an approach to identify semi-automatically micro-architectures that are similar to design motifs in source code and to ensure the traceability of these micro-architectures between implementation and design. DeMIMA consists of three layers: two layers to recover an abstract model of the source code, including binary class relationships, and a third layer to identify design patterns in the abstract model. We apply DeMIMA to five open-source systems and, on average, we\u00a0\u2026", "num_citations": "235\n", "authors": ["1128"]}
{"title": "Cerberus: Tracing requirements to source code using information retrieval, dynamic analysis, and program analysis\n", "abstract": " The concern location problem is to identify the source code within a program related to the features, requirements, or other concerns of the program. This problem is central to program development and maintenance. We present a new technique called prune dependency analysis that can be combined with existing techniques to dramatically improve the accuracy of concern location. We developed CERBERUS, a potent hybrid technique for concern location that combines information retrieval, execution tracing, and prune dependency analysis. We used CERBERUS to trace the 360 requirements of RHINO, a 32,134 line Java program that implements the ECMAScript international standard. In our experiment, prune dependency analysis boosted the recall of information retrieval by 155% and execution tracing by 104%. Moreover, we show that our combined technique outperformed the other techniques when run\u00a0\u2026", "num_citations": "203\n", "authors": ["1128"]}
{"title": "Aura: a hybrid approach to identify framework evolution\n", "abstract": " Software frameworks and libraries are indispensable to today's software systems. As they evolve, it is often time-consuming for developers to keep their code up-to-date, so approaches have been proposed to facilitate this. Usually, these approaches cannot automatically identify change rules for one-replaced-by-many and many-replaced-by-one methods, and they trade off recall for higher precision using one or more experimentally-evaluated thresholds. We introduce AURA, a novel hybrid approach that combines call dependency and text similarity analyses to overcome these limitations. We implement it in a Java system and compare it on five frameworks with three previous approaches by Dagenais and Robillard, M. Kim et al., and Sch\u00e4fer et al. The comparison shows that, on average, the recall of AURA is 53.07% higher while its precision is similar, eg, 0.10% lower.", "num_citations": "166\n", "authors": ["1128"]}
{"title": "Instantiating and detecting design patterns: Putting bits and pieces together\n", "abstract": " Design patterns ease the designing, understanding, and re-engineering of software. Achieving a well-designed piece of software requires a deep understanding and a good practice of design patterns. Understanding existing software relies on the ability to identify architectural forms resulting from the implementation of design patterns. Maintaining software involves spotting places that can be improved by using better design decisions, like those advocated by design patterns. Nevertheless, there is a lack of tools automatizing the use of design patterns to achieve well-designed pieces of software, to identify recurrent architectural forms, and to maintain software. We present a set of tools and techniques to help OO software practitioners design, understand, and re-engineer a piece of software using design-patterns. A first prototype tool, PATTERNS-BOX, provides assistance in designing the architecture of a new piece\u00a0\u2026", "num_citations": "148\n", "authors": ["1128"]}
{"title": "Recovering binary class relationships: Putting icing on the UML cake\n", "abstract": " A discontinuity exists between object-oriented modeling and programming languages. This discontinuity arises from ambiguous concepts in modeling languages and a lack of corresponding concepts in programming languages. It is particularly acute for binary class relationships---association, aggregation, and composition. It hinders the traceability between software implementation and design, thus hampering software analysis. We propose consensual definitions of the binary class relationships with four minimal properties---exclusivity, invocation site, lifetime, and multiplicity. We describe algorithms to detect automatically these properties in source code and apply these on several frameworks. Thus, we bridge the gap between implementation and design for the binary class relationships, easing software analysis.", "num_citations": "144\n", "authors": ["1128"]}
{"title": "Feature identification: An epidemiological metaphor\n", "abstract": " Feature identification is a technique to identify the source code constructs activated when exercising one of the features of a program. We propose new statistical analyses of static and dynamic data to accurately identify features in large multithreaded object-oriented programs. We draw inspiration from epidemiology to improve previous approaches to feature identification and develop an epidemiological metaphor. We build our metaphor on our previous approach to feature identification, in which we use processor emulation, knowledge-based filtering, probabilistic ranking, and metamodeling. We carry out three case studies to assess the usefulness of our metaphor, using the \"save a bookmark\" feature of Web browsers as an illustration. In the first case study, we compare our approach with three previous approaches (a naive approach, a concept analysis-based approach, and our previous probabilistic approach\u00a0\u2026", "num_citations": "128\n", "authors": ["1128"]}
{"title": "Trustrace: Mining software repositories to improve the accuracy of requirement traceability links\n", "abstract": " Traceability is the only means to ensure that the source code of a system is consistent with its requirements and that all and only the specified requirements have been implemented by developers. During software maintenance and evolution, requirement traceability links become obsolete because developers do not/cannot devote effort to updating them. Yet, recovering these traceability links later is a daunting and costly task for developers. Consequently, the literature has proposed methods, techniques, and tools to recover these traceability links semi-automatically or automatically. Among the proposed techniques, the literature showed that information retrieval (IR) techniques can automatically recover traceability links between free-text requirements and source code. However, IR techniques lack accuracy (precision and recall). In this paper, we show that mining software repositories and combining mined results\u00a0\u2026", "num_citations": "115\n", "authors": ["1128"]}
{"title": "Smurf: A svm-based incremental anti-pattern detection approach\n", "abstract": " In current, typical software development projects, hundreds of developers work asynchronously in space and time and may introduce anti-patterns in their software systems because of time pressure, lack of understanding, communication, and-or skills. Anti-patterns impede development and maintenance activities by making the source code more difficult to understand. Detecting anti-patterns incrementally and on subsets of a system could reduce costs, effort, and resources by allowing practitioners to identify and take into account occurrences of anti-patterns as they find them during their development and maintenance activities. Researchers have proposed approaches to detect occurrences of anti-patterns but these approaches have currently four limitations: (1) they require extensive knowledge of anti-patterns, (2) they have limited precision and recall, (3) they are not incremental, and (4) they cannot be applied\u00a0\u2026", "num_citations": "106\n", "authors": ["1128"]}
{"title": "Using design patterns and constraints to automate the detection and correction of inter-class design defects\n", "abstract": " Developing code free of defects is a major concern for the object oriented software community. The authors classify design defects as those within classes (intra-class), those among classes (inter-classes), and those of semantic nature (behavioral). Then, we introduce guidelines to automate the detection and correction of inter-class design defects. We assume that design patterns embody good architectural solutions and that a group of entities with organization similar, but not equal, to a design pattern represents an inter-class design defect. Thus, the transformation of such a group of entities, such that its organization complies exactly with a design pattern, corresponds to the correction of an inter-class design defect. We use a meta-model to describe design patterns and we exploit the descriptions to infer sets of detection and transformation rules. A constraint solver with explanations uses the descriptions and rules\u00a0\u2026", "num_citations": "97\n", "authors": ["1128"]}
{"title": "Meta-modeling design patterns: Application to pattern detection and code synthesis\n", "abstract": " Design Patterns have been quickly adopted by the object-oriented community, in particular since the publication of \u201cDesign Patterns: Elements of Reusable Object-Oriented Software\u201d. They offer elegant and reusable solutions to recurring problems of design. Their use increases productivity and development quality. However, these solutions, at the boundary of programming languages and design models, suffer from a lack of formalism. For this reason, their application remains empirical and manually performed. This position paper presents how a meta-model can be used to obtain a representation of design patterns and how this representation allows both automatic code generation and design patterns detection.", "num_citations": "95\n", "authors": ["1128"]}
{"title": "Automatic generation of detection algorithms for design defects\n", "abstract": " Maintenance is recognised as the most difficult and expansive activity of the software development process. Numerous techniques and processes have been proposed to ease the maintenance of software. In particular, several authors published design defects formalising \"bad\" solutions to recurring design problems (e.g., anti-patterns, code smells). We propose a language and a framework to express design defects synthetically and to generate detection algorithms automatically. We show that this language is sufficient to describe some design defects and to generate detection algorithms, which have a good precision. We validate the generated algorithms on several programs", "num_citations": "93\n", "authors": ["1128"]}
{"title": "Efficient identification of design patterns with bit-vector algorithm\n", "abstract": " Design patterns are important in software maintenance because they help in designing, in understanding, and in re-engineering programs. The identification of occurrences of a design pattern consists in identifying, in a program, classes which structure and organisation match - strictly or approximately - the structure and organisation of classes as suggested by the design pattern. We express the problem of design pattern identification with operations on finite sets of bit-vectors. We use the inherent parallelism of bit-wise operations to derive an efficient bit-vector algorithm that finds exact and approximate occurrences of design patterns in a program. We apply our algorithm on three small-to-medium size programs, JHotDraw, Juzzle, and QuickUML, with the Abstract Factory and Composite design patterns and compare its performance and results with two existing constraint-based approaches", "num_citations": "85\n", "authors": ["1128"]}
{"title": "Support vector machines for anti-pattern detection\n", "abstract": " Developers may introduce anti-patterns in their software systems because of time pressure, lack of understanding, communication, and--or skills. Anti-patterns impede development and maintenance activities by making the source code more difficult to understand. Detecting anti-patterns in a whole software system may be infeasible because of the required parsing time and of the subsequent needed manual validation. Detecting anti-patterns on subsets of a system could reduce costs, effort, and resources. Researchers have proposed approaches to detect occurrences of anti-patterns but these approaches have currently some limitations: they require extensive knowledge of anti-patterns, they have limited precision and recall, and they cannot be applied on subsets of systems. To overcome these limitations, we introduce SVMDetect, a novel approach to detect anti-patterns, based on a machine learning technique\u00a0\u2026", "num_citations": "82\n", "authors": ["1128"]}
{"title": "An empirical study on the efficiency of different design pattern representations in UML class diagrams\n", "abstract": " Design patterns are recognized in the software engineering community as useful solutions to recurring design problems that improve the quality of programs. They are more and more used by developers in the design and implementation of their programs. Therefore, the visualization of the design patterns used in a program could be useful to efficiently understand how it works. Currently, a common representation to visualize design patterns is the UML collaboration notation. Previous work noticed some limitations in the UML representation and proposed new representations to tackle these limitations. However, none of these pieces of work conducted empirical studies to compare their new representations with the UML representation. We designed and conducted an empirical study to collect data on the performance of developers on basic tasks related to design pattern comprehension (i.e., identifying\u00a0\u2026", "num_citations": "80\n", "authors": ["1128"]}
{"title": "A reverse engineering tool for precise class diagrams\n", "abstract": " Developers use class diagrams to describe the architecture of their programs intensively. Class diagrams represent the structure and global behaviour of programs. They show the programs classes and interfaces and their relationships of inheritance, instantiation, use, association, aggregation and composition. Class diagrams could provide useful data during programs maintenance. However, they often are obsolete and imprecise: They do not reflect the real implementation and behaviour of programs. We propose a reverse-engineering tool suite, Ptidej, to build precise class diagrams from Java programs, with respect to their implementation and behaviour. We describe static and dynamic models of Java programs and algorithms to analyse these models and to build class diagrams. In particular, we detail algorithms to infer use, association, aggregation, and composition relationships, because these relationships do not have precise definitions. We show that class diagrams obtained semi-automatically are similar to those obtained manually and more precise than those provided usually.", "num_citations": "80\n", "authors": ["1128"]}
{"title": "Instance generator and problem representation to improve object oriented code coverage\n", "abstract": " Search-based approaches have been extensively applied to solve the problem of software test-data generation. Yet, test-data generation for object-oriented programming (OOP) is challenging due to the features of OOP, e.g., abstraction, encapsulation, and visibility that prevent direct access to some parts of the source code. To address this problem we present a new automated search-based software test-data generation approach that achieves high code coverage for unit-class testing. We first describe how we structure the test-data generation problem for unit-class testing to generate relevant sequences of method calls. Through a static analysis, we consider only methods or constructors changing the state of the class-under-test or that may reach a test target. Then we introduce a generator of instances of classes that is based on a family of means-of-instantiation including subclasses and external factory methods\u00a0\u2026", "num_citations": "73\n", "authors": ["1128"]}
{"title": "P-mart: Pattern-like micro architecture repository\n", "abstract": " We introduce P-MARt, a repository of pattern-like micro-architetcures. The purpose of P-MARt is to serve as baseline to assess the precision and recall of pattern identification tools. Indeed, several approaches have been proposed to identify occurrences of design patterns, yet few have been independently validated for precision and recall for lack of known occurrences. We hope that P-MARt can be shared and enriched by researchers interested in design pattern identification.", "num_citations": "71\n", "authors": ["1128"]}
{"title": "Design evolution metrics for defect prediction in object oriented systems\n", "abstract": " Testing is the most widely adopted practice to ensure software quality. However, this activity is often a compromise between the available resources and software quality. In object-oriented development, testing effort should be focused on defective classes. Unfortunately, identifying those classes is a challenging and difficult activity on which many metrics, techniques, and models have been tried. In this paper, we investigate the usefulness of elementary design evolution metrics to identify defective classes. The metrics include the numbers of added, deleted, and modified attributes, methods, and relations. The metrics are used to recommend a ranked list of classes likely to contain defects for a system. They are compared to Chidamber and Kemerer\u2019s metrics on several versions of Rhino and of ArgoUML. Further comparison is conducted with the complexity metrics computed by Zimmermann et al. on several\u00a0\u2026", "num_citations": "70\n", "authors": ["1128"]}
{"title": "A quality model for design patterns\n", "abstract": " Design patterns are high level building blocks that are claimed to promote elegance in object-oriented programs by increasing flexibility, scalability, usability, reusability, and robustness. However, there is also some evidence that design patterns do not intrinsically promote quality. We believe that the problem of quality with design patterns comes both from the design patterns themselves and from their misuse. Unfortunately, little work has attempted so far to study the quality characteristics of design patterns rigorously. The objective of this technical report is to introduce a quality model and metrics that help in assessing the quality characteristics of design patterns and in concluding on design patterns quality. We begin with a summary of definitions on quality and related concepts and by introducing the most common and standard quality models. Then, we define characteristics of the models in details and present the metrics used to measure the characteristics. Some of the most common characteristics of quality models introduced are used to develop a quality model to assess and measure the quality characteristics that design patterns claim to possess.", "num_citations": "68\n", "authors": ["1128"]}
{"title": "TAUPE: towards understanding program comprehension\n", "abstract": " Program comprehension is a very important activity during the development and the maintenance of programs. This activity has been actively studied in the past decades to present software engineers with the most accurate and---hopefully---most useful pieces of information on the organisation, algorithms, executions, evolution, and documentation of a program. Yet, only few work tried to understand concretely how software engineers obtain and use this information. Software engineers mainly use sight to obtain information about a program, usually from source code or class diagrams. Therefore, we use eye-tracking to collect data about the use of class diagrams by software engineers during program comprehension. We introduce a new visualisation technique to aggregate and to present the collected data. We also report the results and surprising insights gained from two case studies.", "num_citations": "65\n", "authors": ["1128"]}
{"title": "Recommendation system for design patterns in software development: An dpr overview\n", "abstract": " Software maintenance can become monotonous and expensive due to ignorance and misapplication of appropriate design patterns during the early phases of design and development. To have a good and reusable system, designers and developers must be aware of large information set and many quality concerns, e.g., design patterns. Systems with correct design pattern may ensure easy maintenance and evolution. However, without assistance, designing and development of software systems following certain design patterns is difficult for engineers. Recommendation systems for software engineering can assist designers and developers with a wide range of activities including suggesting design patterns. With the help of pattern recommenders, designers can come up with a reusable design. We provide a Design Pattern Recommender (DPR) process overview for software design to suggest design patterns\u00a0\u2026", "num_citations": "63\n", "authors": ["1128"]}
{"title": "Ptidej: Promoting patterns with patterns\n", "abstract": " We introduce the Ptidej project and its tool suite to evaluate and to enhance software quality by promoting patterns. First, we summarise the components of the tool suite and describe its implementation in Java, which uses several architectural, design, and language patterns. Then, we take position on issues related to pattern claims, choices, uses, and limits from our experience with pattern definition, formalisation, use for reverse-engineering and for implementation.", "num_citations": "61\n", "authors": ["1128"]}
{"title": "Specification and detection of SOA antipatterns in web services\n", "abstract": " Service Based Systems, composed of Web Services (WSs), offer promising solutions to software development problems for companies. Like other software artefacts, WSs evolve due to the changed user requirements and execution contexts, which may introduce poor solutions-Antipatterns-may cause (1) degradation of design and quality of service (QoS) and (2) difficult maintenance and evolution. Thus, the automatic detection of antipatterns in WSs, which aims at evaluating their design and QoS requires attention. We propose SODA-W (Service Oriented Detection for Antipatterns in Web services), an approach supported by a framework for specifying and detecting antipatterns in WSs. Using SODA-W, we specify ten antipatterns, including God Object Web Service and Fine Grained Web Service, and perform their detection in two different corpora: (1) 13 weather-related and (2) 109 financial-related WSs\u00a0\u2026", "num_citations": "60\n", "authors": ["1128"]}
{"title": "Refactorings of design defects using relational concept analysis\n", "abstract": " Software engineers often need to identify and correct design defects, i.e., recurring design problems that hinder development and maintenance by making programs harder to comprehend and/or evolve. While detection of design defects is an actively researched area, their correction \u2014 mainly a manual and time-consuming activity \u2014 is yet to be extensively investigated for automation. In this paper, we propose an automated approach for suggesting defect-correcting refactorings using relational concept analysis (rca). The added value of rca consists in exploiting the links between formal objects which abound in a software re-engineering context. We validated our approach on instances of the Blob design defect taken from four different open-source programs.", "num_citations": "58\n", "authors": ["1128"]}
{"title": "Using explanations for design-patterns identification\n", "abstract": " Design patterns describe micro-architectures that solve recurrent architectural problems in objectoriented programming languages. It is important to identify these micro-architectures during the maintenance of object-oriented programs. But these micro-architectures often appear distorted in the source code. We present an application of explanation-based constraint programming for identifying these distorted micro-architectures.", "num_citations": "58\n", "authors": ["1128"]}
{"title": "No Java without caffeine: A tool for dynamic analysis of Java programs\n", "abstract": " To understand the behavior of a program, a maintainer reads some code, asks a question about this code, conjectures an answer, and searches the code and the documentation for confirmation of her conjecture. However, the confirmation of the conjecture can be error-prone and time-consuming because the maintainer has only static information at her disposal. She would benefit from dynamic information. In this paper, we present Caffeine, an assistant that helps the maintainer in checking her conjecture about the behavior of a Java program. Our assistant is a dynamic analysis tool that uses the Java platform debug architecture to generate a trace, i.e., an execution history, and a Prolog engine to perform queries over the trace. We present a usage scenario based on the n-queens problem, and two real-life examples based on the Singleton design pattern and on the composition relationship.", "num_citations": "56\n", "authors": ["1128"]}
{"title": "Detection of REST patterns and antipatterns: a heuristics-based approach\n", "abstract": " REST (REpresentational State Transfer), relying on resources as its architectural unit, is currently a popular architectural choice for building Web-based applications. It is shown that design patterns\u2014good solutions to recurring design problems\u2014improve the design quality and facilitate maintenance and evolution of software systems. Antipatterns, on the other hand, are poor and counter-productive solutions. Therefore, the detection of REST (anti)patterns is essential for improving the maintenance and evolution of RESTful systems. Until now, however, no approach has been proposed. In this paper, we propose SODA-R (Service Oriented Detection for Antipatterns in REST), a heuristics-based approach to detect (anti)patterns in RESTful systems. We define detection heuristics for eight REST antipatterns and five patterns, and perform their detection on a set of 12 widely-used REST APIs including BestBuy\u00a0\u2026", "num_citations": "47\n", "authors": ["1128"]}
{"title": "Trust-based requirements traceability\n", "abstract": " Information retrieval (IR) approaches have proven useful in recovering traceability links between free text documentation and source code. IR-based traceability recovery approaches produce ranked lists of traceability links between pieces of documentation and source code. These traceability links are then pruned using various strategies and, finally, validated by human experts. In this paper we propose two contributions to improve the precision and recall of traceability links and, thus, reduces the required human experts' manual validation effort. First, we propose a novel approach, Trustrace, inspired by Web trust models to improve the precision and recall of traceability links: Trustrace uses any traceability recovery approach to obtain a set of traceability links, which rankings are then re-evaluated using a set of other traceability recovery approaches. Second, we propose a novel traceability recovery approach\u00a0\u2026", "num_citations": "45\n", "authors": ["1128"]}
{"title": "Are restful apis well-designed? detection of their linguistic (anti) patterns\n", "abstract": " Identifier lexicon has a direct impact on software understandability and reusability and, thus, on the quality of the final software product. Understandability and reusability are two important characteristics of software quality. REST (REpresentational State Transfer) style is becoming a de facto standard adopted by many software organisations. The use of proper lexicon in RESTful APIs might make them easier to understand and reuse by client developers, and thus, would ease their adoption. Linguistic antipatterns represent poor practices in the naming, documentation, and choice of identifiers in the APIs as opposed to linguistic patterns that represent best practices. We present the DOLAR approach (Detection Of Linguistic Antipatterns in REST), which applies syntactic and semantic analyses for the detection of linguistic (anti)patterns in RESTful APIs. We provide detailed definitions of ten (anti)patterns and\u00a0\u2026", "num_citations": "44\n", "authors": ["1128"]}
{"title": "Identification of behavioural and creational design motifs through dynamic analysis\n", "abstract": " Design patterns offer design motifs, solutions to object\u2010oriented design problems. Design motifs lead to well\u2010structured designs and thus are believed to ease software maintenance. However, after use, they are often \u2018lost\u2019 and are consequently of little help during program comprehension and other maintenance activities. Therefore, several works proposed design pattern identification approaches to recover occurrences of the motifs. These approaches mainly used the structure and organization of classes as input. Consequently, they have a low precision when considering behavioural and creational motifs, which pertain to the assignment of responsibilities and the collaborations among objects at runtime. We propose MoDeC, an approach to describe behavioural and creational motifs as collaborations among objects in the form of scenario diagrams. We identify these motifs using dynamic analysis and constraint\u00a0\u2026", "num_citations": "43\n", "authors": ["1128"]}
{"title": "Are REST APIs for cloud computing well-designed? An exploratory study\n", "abstract": " Cloud computing is currently the most popular model to offer and access computational resources and services. Many cloud providers use the REST architectural style (Representational State Transfer) for offering such computational resources. However, these cloud providers face challenges when designing and exposing REST APIs that are easy to handle by end-users and/or developers. Yet, they benefit from best practices to help them design understandable and reusable REST\u00a0APIs.                 However, these best practices are scattered in the literature and they have not be studied systematically on real-world APIs. Consequently, we propose two contributions. In our first contribution, we survey the literature and compile a catalog of 73 best practices in the design of REST APIs making APIs more understandable and reusable. In our second contribution, we perform a study of three different and well\u00a0\u2026", "num_citations": "40\n", "authors": ["1128"]}
{"title": "A nursing virtual intervention: real-time support for managing antiretroviral therapy\n", "abstract": " Based on a philosophy of empowerment, we developed the HIV Treatment, Virtual Nursing Assistance and Education intervention to equip persons living with HIV for managing their daily antiretroviral therapies. In this article, we describe the project and the process of developing it, which was carried out in three phases:(1) development of the intervention's clinical content,(2) generation of a multimedia presentation, and (3) implementation of our Web application via computer interface. The HIV Treatment, Virtual Nursing Assistance and Education consists of four interactive sessions at the computer, animated by a virtual nurse that takes the individual through the learning process about the capabilities necessary for taking the treatment. This information and strategies provided by the virtual nurse are specifically adapted to the participant, according to the responses he/she supplies. The virtual intervention approach\u00a0\u2026", "num_citations": "40\n", "authors": ["1128"]}
{"title": "Concept location with genetic algorithms: A comparison of four distributed architectures\n", "abstract": " Genetic algorithms are attractive to solve many search-based software engineering problems because they allow the easy parallelization of computations, which improves scalability and reduces computation time. In this paper, we present our experience in applying different distributed architectures to parallelize a genetic algorithm used to solve the concept identification problem. We developed an approach to identify concepts in execution traces by finding cohesive and decoupled fragments of the traces. The approach relies on a genetic algorithm, on a textual analysis of source code using latent semantic indexing, and on trace compression techniques. The fitness function in our approach has a polynomial evaluation cost and is highly computationally intensive. A run of our approach on a trace of thousand methods may require several hours of computation on a standard PC. Consequently, we reduced\u00a0\u2026", "num_citations": "40\n", "authors": ["1128"]}
{"title": "A simple recommender system for design patterns\n", "abstract": " Since its introduction in computer science, the concept of pattern has flourished. Several conferences and workshops focus on writing and disseminating patterns. Consequently, a large number of patterns exist and it is sometimes difficult to find the right patterns and to choose among many candidate, when solving a given problem. In this paper, we introduce a simple recommender system to help user in choosing among the 23 design patterns from the GoF. We detail its implementation and discuss its application to other patterns.", "num_citations": "39\n", "authors": ["1128"]}
{"title": "On issues with software quality models\n", "abstract": " Software metrics and quality models play a pivotal role in measurement of software quality. A number of well-known quality models and software metrics are used to build quality software both in industry and in academia. However, during our research on measuring software quality using design patterns, we faced many issues related to existing software metrics and quality models. In this position paper, we discuss some of these issues and present our approach to software quality assessment", "num_citations": "39\n", "authors": ["1128"]}
{"title": "Virtual intervention to support self-management of antiretroviral therapy among people living with HIV\n", "abstract": " Background: Living with human immunodeficiency virus (HIV) necessitates long-term health care follow-up, particularly with respect to antiretroviral therapy (ART) management. Taking advantage of the enormous possibilities afforded by information and communication technologies (ICT), we developed a virtual nursing intervention (VIH-TAVIE) intended to empower HIV patients to manage their ART and their symptoms optimally. ICT interventions hold great promise across the entire continuum of HIV patient care but further research is needed to properly evaluate their effectiveness.Objective: The objective of the study was to compare the effectiveness of two types of follow-up\u2014traditional and virtual\u2014in terms of promoting ART adherence among HIV patients.Methods: A quasi-experimental study was conducted. Participants were 179 HIV patients on ART for at least 6 months, of which 99 were recruited at a site offering virtual follow-up and 80 at another site offering only traditional follow-up. The primary outcome was medication adherence and the secondary outcomes were the following cognitive and affective variables: self-efficacy, attitude toward medication intake, symptom-related discomfort, stress, and social support. These were evaluated by self-administered questionnaire at baseline (T0), and 3 (T3) and 6 months (T6) later.Results: On average, participants had been living with HIV for 14 years and had been on ART for 11 years. The groups were highly heterogeneous, differing on a number of sociodemographic dimensions: education, income, marital status, employment status, and living arrangements. Adherence at baseline was high\u00a0\u2026", "num_citations": "38\n", "authors": ["1128"]}
{"title": "An exploratory study of macro co-changes\n", "abstract": " The literature describes several approaches to identify the artefacts of programs that change together to reveal the (hidden) dependencies among these artefacts. These approaches analyse historical data, mined from version control systems, and report co-changing artefacts, which hint at the causes, consequences, and actors of the changes. We introduce the novel concepts of macro co-changes (MCC), i.e., of artefacts that co-change within a large time interval, and of dephase macro co-changes (DMCC), i.e., macro co-changes that always happen with the same shifts in time. We describe typical scenarios of MCC and DMCC and we use the Hamming distance to detect approximate occurrences of MCC and DMCC. We present our approach, Macocha, to identify these concepts in large programs. We apply Macocha and compare it in terms of precision and recall with UML Diff (file stability) and association rules\u00a0\u2026", "num_citations": "37\n", "authors": ["1128"]}
{"title": "Requirements traceability for object oriented systems by partitioning source code\n", "abstract": " Requirements trace ability ensures that source code is consistent with documentation and that all requirements have been implemented. During software evolution, features are added, removed, or modified, the code drifts away from its original requirements. Thus trace ability recovery approaches becomes necessary to re-establish the trace ability relations between requirements and source code. This paper presents an approach (Coparvo) complementary to existing trace ability recovery approaches for object-oriented programs. Coparvo reduces false positive links recovered by traditional trace ability recovery processes thus reducing the manual validation effort. Coparvo assumes that information extracted from different entities (i.e., class names, comments, class variables, or methods signatures) are different information sources, they may have different level of reliability in requirements trace ability and each\u00a0\u2026", "num_citations": "35\n", "authors": ["1128"]}
{"title": "A systematic study of UML class diagram constituents for their abstract and precise recovery\n", "abstract": " Existing reverse-engineering tools use algorithms based on vague and verbose definitions of UML constituents to recover class diagrams from source code. Thus, reverse-engineered class diagrams are neither abstract nor precise representations of source code and are of little interest for software engineers. We propose an exhaustive study of class diagram constituents with respect to their recovery from C++, Java, and Smalltalk source code. We exemplify our study with a tool suite, PTIDEJ, to reverse-engineer Java programs as UML class diagrams abstractly and precisely. The tool suite produces class diagrams that help software engineers in better understanding programs.", "num_citations": "34\n", "authors": ["1128"]}
{"title": "Are the old days gone? A survey on actual software engineering processes in video game industry\n", "abstract": " In the past 10 years, several researches studied video game development process who proposed approaches to improve the way how games are developed. These approaches usually adopt agile methodologies because of claims that traditional practices and the waterfall process are gone. However, are the\" old days\" really gone in the game industry?", "num_citations": "32\n", "authors": ["1128"]}
{"title": "Improving bug location using binary class relationships\n", "abstract": " Bug location assists developers in locating culprit source code that must be modified to fix a bug. Done manually, it requires intensive search activities with unpredictable costs of effort and time. Information retrieval (IR) techniques have been proven useful to speedup bug location in object-oriented programs. IR techniques compute the textual similarities between a bug report and the source code to provide a list of potential culprit classes to developers. They rank the list of classes in descending order of the likelihood of the classes to be related to the bug report. However, due to the low textual similarity between source code and bug reports, IR techniques may put a culprit class at the end of a ranked list, which forces developers to manually verify all non-culprit classes before finding the actual culprit class. Thus, even with IR techniques, developers are not saved from manual effort. In this paper, we conjecture that\u00a0\u2026", "num_citations": "32\n", "authors": ["1128"]}
{"title": "An Internet-based intervention (Condom-Him) to increase condom use among HIV-positive men who have sex with men: protocol for a randomized controlled trial\n", "abstract": " Background: In the recent years, the Internet has been used as a medium to find sexual partners and engage in risky sexual behavior. This has changed the way in which men having have sex with men (MSM) seek sexual partners and has increased the number of high-risk sexual encounters. Therefore, developers of human immunodeficiency virus (HIV)-prevention interventions have also started using the Internet as a viable medium to promote safe sexual behaviors. However, much of the efforts thus far have been aimed at HIV-negative rather than HIV-positive MSM. HIV-positive individuals continue to engage in risky sexual behaviors and thus constitute an important group in which HIV prevention strategies need to be addressed. Therefore, HIV prevention in HIV-positive MSM is a critical issue.Objective: Condom-Him, an Internet-based intervention tailored to increase condom use among HIV-positive MSM, was developed with the aim of improving condom use, self-efficacy, and intentions to use condoms among these individuals. The acceptability and feasibility of this Internet-based intervention will be examined in a pilot study.Methods: We will perform a randomized controlled parallel-group superiority trial. HIV-positive MSM who currently engage in unprotected anal sex will be recruited for the study. Participants will be randomly assigned using a one-to-one allocation ratio generated by the computer program. The researchers will be blinded to participant\u2019s group assignment. Participants will be assigned either to use the Condom-Him intervention (experimental arm) or to view a list of websites containing HIV/AIDS related information\u00a0\u2026", "num_citations": "28\n", "authors": ["1128"]}
{"title": "Prereqir: Recovering pre-requirements via cluster analysis\n", "abstract": " High-level software artifacts, such as requirements, domain-specific requirements, and so on, are an important source of information that is often neglected during the reverse- and re-engineering processes. We posit that domain specific pre-requirements information (PRI) can be obtained by eliciting the stakeholderspsila understanding of generic systems or domains. We discuss the semi-automatic recovery of domain-specific PRI that can then be used during reverse- and re-engineering, for example, to recover traceability links or to assess the degree of obsolescence of a system with respect to competing systems and the clientspsila expectations. We present a method using partition around medoids and agglomerative clustering for obtaining, structuring, analyzing, and labeling textual PRI from a group of diverse stakeholders. We validate our method using PRI for the development of a generic Web browser\u00a0\u2026", "num_citations": "28\n", "authors": ["1128"]}
{"title": "A systematic literature review on automated log abstraction techniques\n", "abstract": " Context: Logs are often the first and only information available to software engineers to understand and debug their systems. Automated log-analysis techniques help software engineers gain insights into large log data. These techniques have several steps, among which log abstraction is the most important because it transforms raw log-data into high-level information. Thus, log abstraction allows software engineers to perform further analyses. Existing log-abstraction techniques vary significantly in their designs and performances. To the best of our knowledge, there is no study that examines the performances of these techniques with respect to the following seven quality aspects concurrently: mode, coverage, delimiter independence, efficiency,scalability, system knowledge independence, and parameter tuning effort.Objectives: We want (1) to build a quality model for evaluating automated log-abstraction\u00a0\u2026", "num_citations": "27\n", "authors": ["1128"]}
{"title": "Un cadre pour la tra\u00e7abilit\u00e9 des motifs de conception\n", "abstract": " Un cadre pour la tra\u00e7abilit\u00e9 des motifs de conception Page 1 Un cadre pour la tra\u00e7abilit\u00e9 des motifs de conception Soutenance de th\u00e8se de doctorat Yann-Ga\u00ebl Gu\u00e9h\u00e9neuc \u00c9cole des Mines de Nantes, France Object Technology International, Inc., Canada Page 2 2/80 Plan \u220e Contexte \u2013 Identification des choix de conception \u220e Probl\u00e8mes \u2013 Obtention de l\u2019architecture d\u2019un programme \u2013 Identification des choix de conception \u220e Contributions \u220e \u00c9valuation, perspectives Page 3 3/80 Plan \u220e Contexte \u2013 Identification des choix de conception \u220e Probl\u00e8mes \u2013 Obtention de l\u2019architecture d\u2019un programme \u2013 Identification des choix de conception \u220e Contributions \u220e \u00c9valuation, perspectives Page 4 4/80 Contexte (1/2) \u220e Maintenance des programmes \u00e0 objets \u2013 R\u00e9tro-conception \u2013 Compr\u00e9hension \u2013 Tra\u00e7abilit\u00e9 \u2013 Modification \u220e Co\u00fbts humains, temporels, financiers pr\u00e9pond\u00e9rants [Sharon96, Takang96, Pressman01] Page 5 5/80 \u2026", "num_citations": "26\n", "authors": ["1128"]}
{"title": "Using FCA to suggest refactorings to correct design defects\n", "abstract": " Design defects are poor design choices resulting in a hard-to- maintain software, hence their detection and correction are key steps of a disciplined software process aimed at yielding high-quality software artifacts. While modern structure- and metric-based techniques enable precise detection of design defects, the correction of the discovered defects, e.g., by means of refactorings, remains a manual, hence error-prone, activity. As many of the refactorings amount to re-distributing class members over a (possibly extended) set of classes, formal concept analysis (FCA) has been successfully applied in the past as a formal framework for refactoring exploration. Here we propose a novel approach for defect removal in object-oriented programs that combines the effectiveness of metrics with the theoretical strength of FCA. A case study of a specific defect, the Blob, drawn from the Azureus project illustrates our\u00a0\u2026", "num_citations": "25\n", "authors": ["1128"]}
{"title": "On the automatic detection and correction of software architectural defects in object-oriented designs\n", "abstract": " On the Automatic Detection and Correction of Software Architectural Defects in Object-Oriented Designs Page 1 Naouel Moha and Yann-Ga\u00ebl Gu\u00e9h\u00e9neuc \u00a9 Moha and Gu\u00e9heneuc 2005 Ptidej Team \u2013 OO Programs Quality Evaluation and Enhancement using Patterns Group of Open, Distributed Systems, Experimental Software Engineering Department of Informatics and Operations Research University of Montreal GEODES On the Automatic Detection and Correction of Software Architectural Defects in Object-Oriented Designs 6th ECOOP workshop on Object-Oriented Reengineering Glasgow, Scotland 2005/07/26 Page 2 2/10 Outline \u220e Objective \u220e Terminology \u2013 Taxonomy, Classifications, Formalization \u220e Detection of Software Defects \u2013 Techniques, Tools \u220e Correction of Software Defects \u2013 Techniques, Tools \u220e Challenges Page 3 3/10 Objective \u220e Our Aim \u2013 \u201cFormalize SAD* including antipatterns and design \u2026", "num_citations": "25\n", "authors": ["1128"]}
{"title": "Evaluation of a real-time virtual intervention to empower persons living with HIV to use therapy self-management: study protocol for an online randomized controlled trial\n", "abstract": " Living with HIV makes considerable demands on a person in terms of self-management, especially as regards adherence to treatment and coping with adverse side-effects. The online HIV Treatment, Virtual Nursing Assistance and Education (Virus de I\u2019immunod\u00e9ficience Humaine\u2013Traitement Assistance Virtuelle Infirmi\u00e8re et Enseignement; VIH-TAVIE\u2122) intervention was developed to provide persons living with HIV (PLHIV) with personalized follow-up and real-time support in managing their medication intake on a daily basis. An online randomized controlled trial (RCT) will be conducted to evaluate the efficacy of this intervention primarily in optimizing adherence to combination anti-retroviral therapy (ART) among PLHIV. A convenience sample of 232 PLHIV will be split evenly and randomly between an experimental group that will use the web application, and a control group that will be handed a list of websites\u00a0\u2026", "num_citations": "24\n", "authors": ["1128"]}
{"title": "PTIDEJ and DECOR identification of design patterns and design defects\n", "abstract": " The PTIDEJ project started in 2001 to study code generation from and identification of patterns. Since then, it has evolved into a complete reverse-engineering tool suite that includes several identification algorithms. It is a flexible tool suite that attempts to ease as much as possible the development of new identification and analysis algorithms. Recently, the module D< scp> ECOR has been added to P< scp> TIDEJ and allows the detection of design defects, which are recurring design problems. In this demonstration, we particularly focus on the creation and use of identification algorithms for design patterns and defects.", "num_citations": "23\n", "authors": ["1128"]}
{"title": "Analyzing program dependencies in java ee applications\n", "abstract": " Program dependency artifacts such as call graphs help support a number of software engineering tasks such as software mining, program understanding, debugging, feature location, software maintenance and evolution. Java Enterprise Edition (JEE) applications represent a significant part of the recent legacy applications, and we are interested in modernizing them. This modernization involves, among other things, analyzing dependencies between their various components/tiers. JEE applications tend to be multilanguage, rely on JEE container services, and make extensive use of late binding techniques-all of which makes finding such dependencies difficult. In this paper, we describe some of these difficulties and how we addressed them to build a dependency call graph. We developed our tool called DeJEE (Dependencies in JEE) as an Eclipse plug-in. We applied DeJEE on two open-source JEE applications\u00a0\u2026", "num_citations": "20\n", "authors": ["1128"]}
{"title": "Detecting asynchrony and dephase change patterns by mining software repositories\n", "abstract": " Software maintenance accounts for the largest part of the costs of any program. During maintenance activities, developers implement changes (sometimes simultaneously) on artifacts in order to fix bugs and to implement new requirements. To reduce this part of the costs, previous work proposed approaches to identify the artifacts of programs that change together. These approaches analyze historical data, mined from version control systems, and report change patterns, which lead at the causes, consequences, and actors of the changes to source code files. They also introduce so\u2010called change patterns that describe some typical change dependencies among files. In this paper, we introduce two novel change patterns: the asynchrony change pattern, corresponding to macro co\u2010changes (MC), that is, of files that co\u2010change within a large time interval (change periods) and the dephase change pattern\u00a0\u2026", "num_citations": "20\n", "authors": ["1128"]}
{"title": "Boosting search based testing by using constraint based testing\n", "abstract": " Search-Based Testing (SBT) uses an evolutionary algorithm to generate test cases. Traditionally, a random selection is used to generate an initial population and also, less often, during the evolution process. Such selection is likely to achieve lower coverage than a guided selection. We define two novel concepts: (1) a constrained population generator (CPG) that generates a diversified initial population that satisfies some test target constraints; and (2) a constrained evolution operator (CEO) that evolves test candidates according to some constraints of the test target. Either the CPG or CEO may substantially increase the chance of reaching adequate coverage with less effort. In this paper, we propose an approach that models a relaxed version of the unit under test as a constraint satisfaction problem. Based on this model and the test target, a CPG generates an initial population. Then, an evolutionary\u00a0\u2026", "num_citations": "20\n", "authors": ["1128"]}
{"title": "Decor: a tool for the detection of design defects\n", "abstract": " Software engineers often need to identify design defects, recurring design problems that hinder the development process, to improve and assess the quality of their systems. However, this is di\u00b1cult because of the lack of specifications and tools. We propose Decor, a method to specify design defects systematically and to generate automatically detection algorithms. With this method, software engineers analyse and specify design defects at a high-level of abstraction using a unified vocabulary and dedicated language for generating detection algorithms", "num_citations": "20\n", "authors": ["1128"]}
{"title": "Identification of design motifs with pattern matching algorithms\n", "abstract": " Design patterns are important in software maintenance because they help in understanding and re-engineering systems. They propose design motifs, solutions to recurring design problems. The identification of occurrences of design motifs in large systems consists of identifying classes whose structure and organization match exactly or approximately the structure and organization of classes as suggested by the motif. We adapt two classical approximate string matching algorithms based on automata simulation and bit-vector processing to efficiently identify exact and approximate occurrences of motifs. We then carry out two case studies to show the performance, precision, and recall of our algorithms. In the first case study, we assess the performance of our algorithms on seven medium-to-large systems. In the second case study, we compare our approach with three existing approaches (an explanation-based\u00a0\u2026", "num_citations": "19\n", "authors": ["1128"]}
{"title": "Bridging the gap between modeling and programming languages\n", "abstract": " A discontinuity exists between modeling languages and object-oriented programming languages. This discontinuity is a consequence of ambiguous notions in modeling languages and lack of corresponding notions in objectoriented programming languages. It hinders the transition between a software design and its implementation, and vice versa. Thus, it hampers the implementation and the maintenance processes. This discontinuity is particularly acute for binary class relationships, which describe, at the design level, notions such as association, aggregation, and composition. From the current state of the art, we propose synthetic definitions for the binary class relationships at the design level and corresponding definitions at the implementation level. We express the latter definitions in terms of common properties. We present algorithms to synthesize code for these properties and to detect these properties in code. These algorithms allow us to generate and to detect binary class relationships. We verify the detection algorithms on several well-known frameworks. The definitions and algorithms bring continuity between modeling languages and objectoriented programming languages.", "num_citations": "18\n", "authors": ["1128"]}
{"title": "Unidosa: The unified specification and detection of service antipatterns\n", "abstract": " Service-based Systems (SBSs) are developed on top of diverse Service-Oriented Architecture (SOA) technologies or architectural styles. Like any other complex systems, SBSs face both functional and non-functional changes at the design or implementation-level. Such changes may degrade the design quality and quality of service (QoS) of the services in SBSs by introducing poor solutions-service antipatterns. The presence of service antipatterns in SBSs may hinder the future maintenance and evolution of SBSs. Assessing the quality of design and QoS of SBSs through the detection of service antipatterns may ease their maintenance and evolution. However, the current literature lacks a unified approach for modelling and evaluating the design of SBSs in term of design quality and QoS. To address this lack, this paper presents a meta-model unifying the three main service technologies: REST, SCA, and SOAP\u00a0\u2026", "num_citations": "16\n", "authors": ["1128"]}
{"title": "Semantic analysis of restful apis for the detection of linguistic patterns and antipatterns\n", "abstract": " Identifier lexicon may have a direct impact on software understandability and reusability and, thus, on the quality of the final software product. Understandability and reusability are two important characteristics of software quality. REpresentational State Transfer (REST) style is becoming a de facto standard adopted by software organizations to build their Web applications. Understandable and reusable Uniform Resource Identifers (URIs) are important to attract client developers of RESTful APIs because good URIs support the client developers to understand and reuse the APIs. Consequently, the use of proper lexicon in RESTful APIs has also a direct impact on the quality of Web applications that integrate these APIs. Linguistic antipatterns represent poor practices in the naming, documentation, and choice of identifiers in the APIs as opposed to linguistic patterns that represent the corresponding best practices. In\u00a0\u2026", "num_citations": "16\n", "authors": ["1128"]}
{"title": "Acceptability and feasibility of a virtual intervention to help people living with HIV manage their daily therapies\n", "abstract": " We conducted a study of the acceptability and feasibility of a web application which was designed to empower people living with HIV to manage their daily antiretroviral therapies. The application (VIH-TAVIE) consists of four interactive computer sessions with a virtual nurse who guides the user through a learning process aimed at enhancing treatment management capacities. The information furnished and the strategies proposed by the nurse are tailored, based on the responses provided by the user. The application was evaluated in a hospital setting as an adjunct to usual care. The participants (n = 71) had a mean age of 47 years (SD = 7.6). There were 59 men and 12 women. They had been diagnosed with HIV some 15 years earlier and had been on antiretroviral medication for a mean duration of 11 years. Data were collected by acceptability questionnaires, field notes and observations. Most participants\u00a0\u2026", "num_citations": "16\n", "authors": ["1128"]}
{"title": "Un m\u00e9tamod\u00e8le pour coupler application et d\u00e9tection des design patterns.\n", "abstract": " Une formes exacte= un design pattern tel que d\u00e9crit dans le GoF. Une forme exacte suit \u00e0 la fois la structure du design pattern et aussi son intention, ses collaborations,\u2026 telles que d\u00e9crites dans le GoF. En opposition avec une forme d\u00e9grad\u00e9e dans laquelle certaines caract\u00e9ristiques (r\u00f4les, relations,\u2026) ne sont pas v\u00e9rifi\u00e9es. Par exemple, dans le design pattern Composite, peut-\u00eatre la relation d\u2019h\u00e9ritage entre Component et Composite n\u2019est-elle pas vitale pour satisfaire l\u2019intention du design pattern.", "num_citations": "15\n", "authors": ["1128"]}
{"title": "The impact of imperfect change rules on framework api evolution identification: an empirical study\n", "abstract": " Software frameworks keep evolving. It is often time-consuming for developers to keep their client code up-to-date. Not all frameworks have documentation about the upgrading process. Many approaches have been proposed to ease the impact of non-documented framework evolution on developers by identifying change rules between two releases of a framework, but these change rules are imperfect, i.e., not 100 % correct. To the best of our knowledge, there is no empirical study to show the usefulness of these imperfect change rules. Therefore, we design and conduct an experiment to evaluate their impact. In the experiment, the subjects must find the replacements of 21 missing methods in the new releases of three open-source frameworks with the help of (1) all-correct, (2) imperfect, and (3) no change rules. The statistical analysis results show that the precision of the replacements found by the subjects\u00a0\u2026", "num_citations": "14\n", "authors": ["1128"]}
{"title": "Ptidej: A flexible reverse engineering tool suite\n", "abstract": " The Ptidej project started in 2001 to study code generation from and identification of design patterns. Since then, it has evolved into a complete reverse-engineering tool suite that includes several identification algorithms for idioms, micro-patterns, design patterns, and design defects. It is a flexible tool suite that attempts to ease as much as possible the development of new identification and analysis algorithms. In this demonstration, we first present the key features of the tool suite and several identification algorithms. We then discuss the architecture and design choices of the tool suite and lessons learned in developing the suite.", "num_citations": "14\n", "authors": ["1128"]}
{"title": "A taxonomy and a first study of design pattern defects\n", "abstract": " Design patterns propose \u201cgood\u201d solutions to recurring design problems in object-oriented architectures. Design patterns have been quickly adopted by the Software Engineering community and are now widely spread. We define design pattern defects as occurring errors in the design of a software that come from the absence or the bad use of design patterns. Design pattern defects are software defects at the architectural level that must be detected and corrected to improve software quality. Automatic detection and correction of these software architectural defects, which suffer of a lack of tools, are important to improve object-oriented architectures and, thus, to ease maintenance. We propose a first taxonomy of design pattern defects and presents techniques and tools to detect these defects in source code.", "num_citations": "14\n", "authors": ["1128"]}
{"title": "On the impact of aspect-oriented programming on object-oriented metrics\n", "abstract": " Aspect-oriented programming is a new paradigm designed to fulfill the limitations of object-oriented programming regarding separation of concerns. The advent of a new paradigm requires software engineers to define new metrics and quality models to measure the quality of programs in this paradigm. The close relationship of aspect-oriented programming and object-oriented languages drives us to wonder about the impact of this new paradigm over object-oriented languages, and especially over object metrics. In this position paper, we attempt to present an approach to study and to understand the impact of aspect-oriented programming on object-oriented metrics.", "num_citations": "14\n", "authors": ["1128"]}
{"title": "Acua: Api change and usage auditor\n", "abstract": " Modern software uses frameworks through their Application Programming Interfaces (APIs). Framework APIs may change while frameworks evolve. Client programs have to upgrade to new releases of frameworks if security vulnerabilities are discovered in the used releases. Patching security vulnerabilities can be delayed by non-security-related API changes when the frameworks used by client programs are not up to date. Keeping frameworks updated can reduce the reaction time to patch security leaks. Client program upgrades are not cost free, developers need to understand the API usages in client programs and API changes between framework releases before conduct upgrading tasks. In this paper, we propose a tool ACUA to generate reports containing detailed API change and usage information by analyzing the binary code of both frameworks and clients programs written in Java. Developers can use the\u00a0\u2026", "num_citations": "13\n", "authors": ["1128"]}
{"title": "Design patterns formalization\n", "abstract": " Design patterns contribution covers the definition, the design and the documentation of class libraries and frameworks, offering elegant and reusable solutions to design problems, and consequently increasing productivity and development quality. Each design pattern lets some aspects of the system structure vary independently of other aspects, thereby making the system more robust to a particular kind of change [GAM95]. The majority of publications in the pattern field focuses on micro-architectures; ie, intentionally abstract description of generic aspects of software systems. Despite this abstractness, the academic community recognizes that a better understanding of design patterns by means of systematic investigation is essential. Reflective tasks in this direction include comparative analyses of design patterns, proposals for precise means of specification, attempts for tools, analysis of relationships among patterns, and other discussions.However, few works offer methods of precise specification of design patterns, resulting in lack of formalism. In this sense, patterns remain empirical and manually applied. According to [BR\u00d600], manual application is tedious and error prone. Precise specification can improve the application of design patterns as well as the analysis of relationships among them and tools in support of their application. Very little progress has been made towards better understanding of the microarchitectures dictated by design patterns [EDE00]. This report tries to capture the \u2018\u2019essence\u2019\u2019of patterns, showing the importance of researches able to illuminate how design patterns are essentially structured.", "num_citations": "13\n", "authors": ["1128"]}
{"title": "State of the practice in service identification for soa migration in industry\n", "abstract": " The migration of legacy software systems to Service Oriented Architectures (SOA) has become a mainstream trend for modernizing enterprise software systems. A key step in SOA migration is the identification of services in the target application, but it is a challenging one to the extent that the potential services (1) embody reusable functionalities, (2) can be developed in a cost-effective manner, and (3) should be easy to maintain. In this paper, we report on state of the practice of SOA migration in industry. We surveyed 45 practitioners of legacy-to-SOA migration to understand how migration, in general, and service identification (SI), in particular are done. Key findings include: (1) reducing maintenance costs is a key driver in SOA migration, (2) domain knowledge and source code of legacy applications are most often used respectively in a hybrid top-down and bottom-up approach for SI, (3) industrial SI\u00a0\u2026", "num_citations": "12\n", "authors": ["1128"]}
{"title": "Sub-graph mining: identifying micro-architectures in evolving object-oriented software\n", "abstract": " Developers introduce novel and undocumented micro-architectures when performing evolution tasks on object-oriented applications. We are interested in understanding whether those organizations of classes and relations can bear, much like cataloged design and anti-patterns, potential harm or benefit to an object-oriented application. We present SGFinder, a sub-graph mining approach and tool based on an efficient enumeration technique to identify recurring micro-architectures in object-oriented class diagrams. Once SGFinder has detected instances of micro-architectures, we exploit these instances to identify their desirable properties, such as stability, or unwanted properties, such as change or fault proneness. We perform a feasibility study of our approach by applying SGFinder on the reverse-engineered class diagrams of several releases of two Java applications: ArgoUML and Rhino. We characterize and\u00a0\u2026", "num_citations": "12\n", "authors": ["1128"]}
{"title": "An observational study on the state of REST API uses in android mobile applications\n", "abstract": " REST is by far the most commonly-used style for designing APIs, especially for mobile platforms. Indeed, REST APIs are well suited for providing content to apps running on small devices, like smart-phones and tablets. Several research works studied REST APIs development practices for mobile apps. However, little is known about how Android apps use/consume these APIs in practice through HTTP client libraries. Consequently, we propose an observational study on the state of the practice of REST APIs use in Android mobile apps. We (1) build a catalogue of Android REST mobile clients practices; (2) define each of these practices through a number of heuristics based on their potential implementations in Android apps, and (3) propose an automatic approach to detect these practices. We analyze 1,595 REST mobile apps downloaded from the Google Play Store and mine thousands of StackOverflow posts to\u00a0\u2026", "num_citations": "11\n", "authors": ["1128"]}
{"title": "Soda: A Tool Support for the Detection of SOA Antipatterns\n", "abstract": " During their evolution, Service Based Systems (SBSs) need to fit new user requirements and execution contexts. The resulting changes from the evolution of SBSs may degrade their design and Quality of Service (QoS), and thus may cause the appearance of common poor solutions, called Antipatterns. Like other complex systems, antipatterns in SBSs may hinder the future maintenance and evolution. Therefore, the automatic detection of such antipatterns is an important task for assessing the design and QoS of SBSs, to facilitate their maintenance and evolution. However, despite of their importance, no tool support exists for the detection of antipatterns in SBSs. In this paper, we introduce a prototype tool, called Soda, for detecting SOA (Service Oriented Architecture) antipatterns in SBSs.", "num_citations": "11\n", "authors": ["1128"]}
{"title": "A theory of program comprehension: Joining vision science and program comprehension\n", "abstract": " There exists an extensive literature on vision science, on the one hand, and on program comprehension, on the other hand. However, these two domains of research have been so far rather disjoint. Indeed, several cognitive theories have been proposed to explain program comprehension. These theories explain the processes taking place in the software engineers\u2019 minds when they understand programs. They explain how software engineers process available information to perform their tasks but not how software engineers acquire this information. Vision science provides explanations on the processes used by people to acquire visual information from their environment. Joining vision science and program comprehension provides a more comprehensive theoretical framework to explain facts on program comprehension, to predict new facts, and to frame experiments. We join theories in vision science and in\u00a0\u2026", "num_citations": "11\n", "authors": ["1128"]}
{"title": "On the coherence of component protocols\n", "abstract": " Component-based programming promises to ease the construction of large-scale applications. The construction of applications using components relies on the notion of interfaces. However, the notion of interfaces provided by current component models is restricted: In particular, it does not include behavioral information to define the protocols of the components: Sequences of service requests. The lack of behavioral information limits our trust in components: Security, reuse, and quality relate directly on this missing information. In this paper, we consider the problem of verifying if a component implementation respects the protocol specified during its design. First, we define a notion of coherence between protocols and an algorithm to verify the coherence between two protocols. Then, we describe an algorithm to extract the protocol of a component from its source code. Finally, we present a tool that enables the static\u00a0\u2026", "num_citations": "11\n", "authors": ["1128"]}
{"title": "Towards a REST cloud computing lexicon\n", "abstract": " Cloud computing is a popular Internet-based computing paradigm that provides on-demand computational services and resources, generally offered by cloud providers' REpresentational State Transfer (REST) APIs. To the best of our knowledge, there has been no study on the analysis of the lexicon adopted by cloud providers, despite its importance for developers. In this paper, we studied three different and well-known REST APIs (Google Cloud Platform, OpenStack, and Open Cloud Computing Interface) to investigate and organise their lexicons. This study presents three main contributions: 1) a tooled approach, called CLOUDLEX, for extracting and analysing REST cloud computing lexicons, 2) a dataset of services, resources, and terms used in the three studied REST APIs, 3) our analysis of this dataset, which represents a first attempt to provide a common REST cloud computing lexicon. After analysing our dataset, we observe that although the three studied REST APIs to describe the same domain (cloud computing), contrary to what one might expect, they do not share a large number of common terms, and only 5% of terms (17/352) are shared by two providers. Thus, the three APIs are lexically heterogeneous, and there is not a consensus on which terms to use on cloud computing systems. We discuss new avenues for cloud computing API designers and researchers.", "num_citations": "10\n", "authors": ["1128"]}
{"title": "Constraint-based fitness function for search-based software testing\n", "abstract": " Search-based software testing is a powerful automated technique to generate test inputs for software. Its goal is to reach a branch or a statement in a program under test. One major limitation of this approach is an insufficiently informed fitness function to guide search toward a test target within nested predicates (constraints). To address this problem we propose fitness functions based on concepts well known to the constraint programming community, such as constrainedness and arity, to rank test candidates. Preliminary experiments promise efficiency and effectiveness for the new fitness functions.", "num_citations": "10\n", "authors": ["1128"]}
{"title": "Studying software evolution of large object\u2010oriented software systems using an ETGM algorithm\n", "abstract": " Analyzing and understanding the evolution of large object\u2010oriented software systems is an important but difficult task in which matching algorithms play a fundamental role. An error\u2010tolerant graph matching (ETGM) algorithm can identify evolving classes that maintain a stable structure of relations (associations, inheritances, and aggregations) with other classes and thus likely constitute the backbone of the system. Therefore, to study the evolution of class diagrams, we first develop a novel ETGM algorithm, which improves the performance of our previous algorithm. Second, we describe the process of building an oracle to validate the results of our approach to solve the class diagram evolution problem. Third, we report for the new algorithm the impact of its parameters on the F\u2010measure summarizing precision (quantifying the exactness of the solution) and recall (quantifying the completeness of the solution). Finally\u00a0\u2026", "num_citations": "10\n", "authors": ["1128"]}
{"title": "Factors impacting the inputs of traceability recovery approaches\n", "abstract": " In requirement engineering, researchers have proposed various tractability recovery approaches. To the best of our knowledge, all traceability recovery approaches have low precision and recall. Our main claim in this chapter is that there exist factors that impact the traceability approaches\u2019 inputs, in particular source document, target document, and experts\u2019 opinion, that cause low precision and recall. In this chapter, we pursue four objectives: first, to identify and document factors that impact traceability recovery approaches\u2019 inputs; second, to identify metrics/tools to measure/improve the quality of the inputs with respect to the identified factors, third, to provide precautions to control these factors, and, fourth, to empirically prove and quantify the effect of one of these factors\u2013expert\u2019s programming knowledge\u2013on the traceability recovery approaches\u2019 inputs. To achieve the first two objectives, we perform an\u00a0\u2026", "num_citations": "10\n", "authors": ["1128"]}
{"title": "Learning from the past: A process recommendation system for video game projects using postmortems experiences\n", "abstract": " Context: The video game industry is a billion dollar industry that faces problems in the way games are developed. One method to address these problems is using developer aid tools, such as Recommendation Systems. These tools assist developers by generating recommendations to help them perform their tasks.Objective: This article describes a systematic approach to recommend development processes for video game projects, using postmortem knowledge extraction and a model of the context of the new project, in which \u201cpostmortems\u201d are articles written by video game developers at the end of projects, summarizing the experience of their game development team. This approach aims to provide reflections about development processes used in the game industry as well as guidance to developers to choose the most adequate process according to the contexts they\u2019re in.Method: Our approach is divided in\u00a0\u2026", "num_citations": "9\n", "authors": ["1128"]}
{"title": "Do Not Trust Build Results at Face Value-An Empirical Study of 30 Million CPAN Builds\n", "abstract": " Continuous Integration (CI) is a cornerstone of modern quality assurance, providing on-demand builds (compilation and tests) of code changes or software releases. Despite the myriad of CI tools and frameworks, the basic activity of interpreting build results is not straightforward, due to not only the number of builds being performed but also, and especially, due to the phenomenon of build inflation, according to which one code change can be built on dozens of different operating systems, run-time environments and hardware architectures. As existing work mostly ignored this inflation, this paper performs a large-scale empirical study of the impact of OS and run-time environment on build failures on 30 million builds of the CPAN ecosystem's CI environment. We observe the evolution of build failures over time, and investigate the impact of OSes and environments on build failures. We show that distributions may fail\u00a0\u2026", "num_citations": "9\n", "authors": ["1128"]}
{"title": "Evaluation of a Web-based tailored intervention (TAVIE en sant\u00e9) to support people living with HIV in the adoption of health promoting behaviours: an online randomized\u00a0\u2026\n", "abstract": " Long-term use of antiretroviral therapy, normal aging, and presence of certain risk factors are associated with metabolic disorders that predispose persons living with HIV to diabetes and cardiovascular diseases. The emergence and progression of these disorders can be prevented by adopting healthy behaviours. Based on the theory of planned behaviour, the Web-based tailored intervention TAVIE en sant\u00e9 was developed. The aim of this study is to evaluate the effectiveness of TAVIE en sant\u00e9 in order to support people living with HIV in the adoption of health promoting behaviours. An online randomized controlled trial with parallel-groups will be conducted across Canada. To participate in this study, people living with HIV must be: \u2265 18\u00a0years, able to read/understand French or English, have access to the Internet. A convenience sample of 750 participants will be randomly assigned either to an experimental group\u00a0\u2026", "num_citations": "9\n", "authors": ["1128"]}
{"title": "Factors impacting the inputs of traceability recovery approaches\n", "abstract": " In requirement engineering, researchers have proposed various tractability recovery approaches. To the best of our knowledge, all traceability recovery approaches have low precision and recall. Our main claim in this chapter is that there exist factors that impact the traceability approaches\u2019 inputs, in particular source document, target document, and experts\u2019 opinion, that cause low precision and recall. In this chapter, we pursue four objectives: first, to identify and document factors that impact traceability recovery approaches\u2019 inputs; second, to identify metrics/tools to measure/improve the quality of the inputs with respect to the identified factors, third, to provide precautions to control these factors, and, fourth, to empirically prove and quantify the effect of one of these factors\u2014expert\u2019s programming knowledge\u2014on the traceability recovery approaches\u2019 inputs. To achieve the first two objectives, we perform an incremental literature review of traceability recovery approaches and identify and document three key inputs and the seven factors impacting these inputs, out of 12 identified factors. We analyse the reported results in literature for the identified factors to address our third objective. We conduct an empirical study to", "num_citations": "9\n", "authors": ["1128"]}
{"title": "Mendel: A model, metrics, and rules to understand class hierarchies\n", "abstract": " Inheritance is an important mechanism when developing object-oriented programs with class-based programming languages: it enables subtyping, polymorphism, and code reuse. Inheritance is also known as a difficult feature to grasp and to use correctly because of its many purposes. We propose a model of inheritance to help understand class hierarchies of class-based object-oriented programs. We define metrics and rules to highlight interesting classes and behaviours with respect to inheritance. Thus, we provide the programmer with insight on how inheritance is used in a program. We illustrate our approach on JHOTDraw and validate it further on three other programs: ArgoUML, Azureus, and Log4J. We also show that our model can describe existing rules, such as micro patterns.", "num_citations": "9\n", "authors": ["1128"]}
{"title": "Game industry problems: An extensive analysis of the gray literature\n", "abstract": " Context:Given its competitiveness, the video-game industry has a closed-source culture. Hence, little is known about the problems faced by game developers. However, game developers do share information about their game projects through postmortems, which describe informally what happened during the projects.Objective:The software-engineering research community and game developers would benefit from a state of the problems of the video game industry, in particular the problems faced by game developers, their evolution in time, and their root causes. This state of the practice would allow researchers and practitioners to work towards solving these problems.Method:We analyzed 200 postmortems from 1997 to 2019, resulting in 927 problems divided into 20 types. Through our analysis, we described the overall landscape of game industry problems in the past 23 years and how these problems evolved\u00a0\u2026", "num_citations": "8\n", "authors": ["1128"]}
{"title": "Are game engines software frameworks? A three-perspective study\n", "abstract": " Game engines help developers create video games and avoid duplication of code and effort, like frameworks for traditional software systems. In this paper, we explore open-source game engines along three perspectives: literature, code, and human. First, we explore and summarize the academic literature on game engines. Second, we compare the characteristics of the 282 most popular engines and the 282 most popular frameworks in GitHub. Finally, we survey 124 engine developers about their experience with the development of their engines. We report that: (1) Game engines are not well-studied in software-engineering research with few studies having engines as object of research. (2) Open-source game engines are slightly larger in terms of size and complexity and less popular and engaging than traditional frameworks. Their programming languages differ greatly from frameworks. Engine projects have\u00a0\u2026", "num_citations": "8\n", "authors": ["1128"]}
{"title": "Inherent characteristics of traceability artifacts less is more\n", "abstract": " This paper describes ongoing work to characterize the inherent ease or \u201ctraceability\u201d with which a textual artifact can be traced using an automated technique. Software traceability approaches use varied measures to build models that automatically recover links between pairs of natural language documents. Thus far, most of the approaches use a single-step model, such as logistic regression, to identify new trace links. However, such approaches require a large enough training set of both true and false trace links. Yet, the former are by far in the minority, which reduces the performance of such models. Therefore, this paper formulates the problem of identifying trace links as the problem of finding, for a given logistic regression model, the subsets of links in the training set giving the best accuracy (in terms of G-metric) on a test set. Using hill climbing with random restart for subset selection, we found that, for the\u00a0\u2026", "num_citations": "8\n", "authors": ["1128"]}
{"title": "Optimizing threads schedule alignments to expose the interference bug pattern\n", "abstract": " Managing and controlling interference conditions in multi-threaded programs has been an issue of worry for application developers for a long time. Typically, when write events from two concurrent threads to the same shared variable are not properly protected, an occurrence of the interference bug pattern could be exposed. We propose a mathematical formulation and its resolution to maximize the possibility of exposing occurrences of the interference bug pattern. We formulate and solve the issue as an optimization problem that gives us (1) the optimal position to inject a delay in the execution flow of a thread and (2) the optimal duration for this delay to align at least two different write events in a multi-threaded program. To run the injected threads and calculate the thread execution times for validating the results, we use a virtual platform modelling a perfectly parallel system. All the effects due to the\u00a0\u2026", "num_citations": "8\n", "authors": ["1128"]}
{"title": "Divide-by-zero exception raising via branch coverage\n", "abstract": " In this paper, we discuss how a search-based branch coverage approach can be used to design an effective test data generation approach, specifically targeting divide-by-zero exceptions. We first propose a novel testability transformation combining approach level and branch distance. We then use different search strategies, i.e. hill climbing, simulated annealing, and genetic algorithm, to evaluate the performance of the novel testability transformation on a small synthetic example as well as on methods known to throw divide-by-zero exceptions, extracted from real world systems, namely Eclipse and Android. Finally, we also describe how the test data generation for divide-by-zero exceptions can be formulated as a constraint programming problem and compare the resolution of this problem with a genetic algorithm in terms of execution time. We thus report evidence that genetic algorithm using our novel\u00a0\u2026", "num_citations": "8\n", "authors": ["1128"]}
{"title": "Design patterns: A round-trip\n", "abstract": " Design patterns are of major interest to increase software quality and abstraction level. However, design patterns are difficult to choose, to apply, and to recover. We propose a set of tools to use design patterns in a round-trip fashion. We define a meta-model to describe design patterns. This meta-model is specifically oriented towards design patterns instantiation and detection. We develop a source-to-source transformation engine to modify the source code to comply with design patterns descriptions. Meanwhile, we use an explanationbased constraint solver to detect design patterns in source code from their descriptions. With these tools, we hope to offer a mean to apply and to recover design patterns without overhead for the developers.", "num_citations": "8\n", "authors": ["1128"]}
{"title": "A taxonomy of service identification approaches for legacy software systems modernization\n", "abstract": " The success of modernizing legacy software systems to Service-Oriented Architecture (SOA) depends on Service Identification Approaches (SIAs), which identify reusable functionalities that could become services. The literature describes several SIAs. However, the selection of an identification approach that is suitable for a practitioner is difficult because it depends on several factors, including the goal of modernization, the available legacy artifacts, the organization\u2019s development process, the desired output, and the usability of the approach. Accordingly, to select a suitable service identification approach, a practitioner must have a comprehensive view of existing techniques.We report a systematic literature review (SLR) that covers 41 SIAs based on software-systems analyses. Based on this SLR, we create a taxonomy of SIAs and build a multi-layer classification of existing identification approaches. We start from a\u00a0\u2026", "num_citations": "7\n", "authors": ["1128"]}
{"title": "What skills do IT companies look for in new developers? a study with Stack Overflow Jobs\n", "abstract": " Context: There is a growing demand for information on how IT companies look for candidates to their open positions. Objective: This paper investigates which hard and soft skills are more required in IT companies by analyzing the description of 20,000 job opportunities. Method: We applied open card sorting to perform a high-level analysis on which types of hard skills are more requested. Further, we manually analyzed the most mentioned soft skills. Results: Programming languages are the most demanded hard skills. Communication, collaboration, and problem-solving are the most demanded soft skills. Conclusion: We recommend developers to organize their resum\u00e9 according to the positions they are applying. We also highlight the importance of soft skills, as they appear in many job opportunities.", "num_citations": "7\n", "authors": ["1128"]}