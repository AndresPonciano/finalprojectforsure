{"title": "Piranha: A scalable architecture based on single-chip multiprocessing\n", "abstract": " The microprocessor industry is currently struggling with higher development costs and longer design times that arise from exceedingly complex processors that are pushing the limits of instruction-level parallelism. Meanwhile, such designs are especially ill suited for important commercial applications, such as on-line transaction processing (OLTP), which suffer from large memory stall times and exhibit little instruction-level parallelism. Given that commercial applications constitute by far the most important market for high-performance servers, the above trends emphasize the need to consider alternative processor designs that specifically target such workloads. The abundance of explicit thread-level parallelism in commercial workloads, along with advances in semiconductor integration density, identify chip multiprocessing (CMP) as potentially the most promising approach for designing processors targeted at\u00a0\u2026", "num_citations": "763\n", "authors": ["1741"]}
{"title": "A type and effect system for atomicity\n", "abstract": " Ensuring the correctness of multithreaded programs is difficult, due to the potential for unexpected and nondeterministic interactions between threads. Previous work addressed this problem by devising tools for detecting race conditions, a situation where two threads simultaneously access the same data variable, and at least one of the accesses is a write. However, verifying the absence of such simultaneous-access race conditions is neither necessary nor sufficient to ensure the absence of errors due to unexpected thread interactions.We propose that a stronger non-interference property is required, namely atomicity. Atomic methods can be assumed to execute serially, without interleaved steps of other threads. Thus, atomic methods are amenable to sequential reasoning techniques, which significantly simplifies both formal and informal reasoning about program correctness.This paper presents a type system for\u00a0\u2026", "num_citations": "479\n", "authors": ["1741"]}
{"title": "Context-bounded model checking of concurrent software\n", "abstract": " The interaction among concurrently executing threads of a program results in insidious programming errors that are difficult to reproduce and fix. Unfortunately, the problem of verifying a concurrent boolean program is undecidable [24]. In this paper, we prove that the problem is decidable, even in the presence of unbounded parallelism, if the analysis is restricted to executions in which the number of context switches is bounded by an arbitrary constant. Restricting the analysis to executions with a bounded number of context switches is unsound. However, the analysis can still discover intricate bugs and is sound up to the bound since within each context, a thread is fully explored for unbounded stack depth. We present an analysis of a real concurrent system by the ZING model checker which demonstrates that the ability to model check with arbitrary but fixed context bound in the presence of unbounded\u00a0\u2026", "num_citations": "461\n", "authors": ["1741"]}
{"title": "Predicate abstraction for software verification\n", "abstract": " Software verification is an important and difficult problem. Many static checking techniques for software require annotations from the programmer in the form of method specifications and loop invariants. This annotation overhead, particularly of loop invariants, is a significant hurdle in the acceptance of static checking. We reduce the annotation burden by inferring loop invariants automatically. Our method is based on predicate abstraction, an abstract interpretation technique in which the abstract domain is constructed from a given set of predicates over program variables. A novel feature of our approach is that it infers universally-quantified loop invariants, which are crucial for verifying programs that manipulate unbounded data such as arrays. We present heuristics for generating appropriate predicates for each loop automatically; the programmer can specify additional predicates as well. We also present an efficient\u00a0\u2026", "num_citations": "376\n", "authors": ["1741"]}
{"title": "Goldilocks: a race and transaction-aware java runtime\n", "abstract": " Data races often result in unexpected and erroneous behavior. In addition to causing data corruption and leading programs to crash, the presence of data races complicates the semantics of an execution which might no longer be sequentially consistent. Motivated by these observations, we have designed and implemented a Java runtime system that monitors program executions and throws a DataRaceException when a data race is about to occur. Analogous to other runtime exceptions, the DataRaceException provides two key benefits. First, accesses causing race conditions are interruptedand handled before they cause errors that may be difficult to diagnose later. Second, if no DataRaceException is thrown in an execution, it is guaranteed to be sequentially consistent. This strong guarantee helps to rule out many concurrency-related possibilities as the cause of erroneous behavior. When a DataRaceException\u00a0\u2026", "num_citations": "286\n", "authors": ["1741"]}
{"title": "KISS: keep it simple and sequential\n", "abstract": " The design of concurrent programs is error-prone due to the interaction between concurrently executing threads. Traditional automated techniques for finding errors in concurrent programs, such as model checking, explore all possible thread interleavings. Since the number of thread interleavings increases exponentially with the number of threads, such analyses have high computational complexity. In this paper, we present a novel analysis technique for concurrent programs that avoids this exponential complexity. Our analysis transforms a concurrent program into a sequential program that simulates the execution of a large subset of the behaviors of the concurrent program. The sequential program is then analyzed by a tool that only needs to understand the semantics of sequential execution. Our technique never reports false errors but may miss errors. We have implemented the technique in KISS, an automated\u00a0\u2026", "num_citations": "272\n", "authors": ["1741"]}
{"title": "Thread-modular model checking\n", "abstract": " We present thread-modular model checking, a novel technique for verifying correctness properties of loosely-coupled multithreaded software systems. Thread-modular model checking verifies each thread separately using an automatically inferred environment assumption that abstracts the possible steps of other threads. Separate verification of each thread yields significant space and time savings. Suppose there are n threads, each with a local store of size L, where the threads communicate via a shared global store of size G. If each thread is finite-state (without a stack), the naive model checking algorithm requires O(G. L                                       n               ) space, whereas thread-modular model checking requires only O(n.G.(G + L)) space. If each thread has a stack, the general model checking problem is undecidable, but thread-modular model checking terminates in polynomial time.", "num_citations": "204\n", "authors": ["1741"]}
{"title": "GPUVerify: a verifier for GPU kernels\n", "abstract": " We present a technique for verifying race-and divergence-freedom of GPU kernels that are written in mainstream kernel programming languages such as OpenCL and CUDA. Our approach is founded on a novel formal operational semantics for GPU programming termed synchronous, delayed visibility (SDV) semantics. The SDV semantics provides a precise definition of barrier divergence in GPU kernels and allows kernel verification to be reduced to analysis of a sequential program, thereby completely avoiding the need to reason about thread interleavings, and allowing existing modular techniques for program verification to be leveraged. We describe an efficient encoding for data race detection and propose a method for automatically inferring loop invariants required for verification. We have implemented these techniques as a practical verification tool, GPUVerify, which can be applied directly to OpenCL and\u00a0\u2026", "num_citations": "176\n", "authors": ["1741"]}
{"title": "How to shop for free online--security analysis of cashier-as-a-service based web stores\n", "abstract": " Web applications increasingly integrate third-party services. The integration introduces new security challenges due to the complexity for an application to coordinate its internal states with those of the component services and the web client across the Internet. In this paper, we study the security implications of this problem to merchant websites that accept payments through third-party cashiers (e.g., PayPal, Amazon Payments and Google Checkout), which we refer to as Cashier-as-a-Service or CaaS. We found that leading merchant applications (e.g., NopCommerce and Interspire), popular online stores (e.g., Buy.com and JR.com) and a prestigious CaaS provider (Amazon Payments) all contain serious logic flaws that can be exploited to cause inconsistencies between the states of the CaaS and the merchant. As a result, a malicious shopper can purchase an item at an arbitrarily low price, shop for free after paying\u00a0\u2026", "num_citations": "152\n", "authors": ["1741"]}
{"title": "Types for atomicity\n", "abstract": " Ensuring the correctness of multithreaded programs is difficult, due to the potential for unexpected and nondeterministic interactions, between threads. Previous work addressed this problem by devising tools for detecting race conditions, a situation where two threads simultaneously access the same data variable, and at least one of the accesses is a write. Unfortunately, verifying the absence of such simultaneous-access race conditions is neither necessary nor sufficient to ensure the absence of errors due to unexpected thread interactions. We propose that a stronger non-interference property is required, namely the atomicity of code blocks, and we present a type system for specifying and verifying such atomicity properties. The type system allows statement blocks and functions to be annotated with the keyword atomic. If the program type checks, then the type system guarantees that for any arbitrarily-interleaved\u00a0\u2026", "num_citations": "150\n", "authors": ["1741"]}
{"title": "A calculus of atomic actions\n", "abstract": " We present a proof calculus and method for the static verification of assertions and procedure specifications in shared-memory concurrent programs. The key idea in our approach is to use atomicity as a proof tool and to simplify the verification of assertions by rewriting programs to consist of larger atomic actions. We propose a novel, iterative proof style in which alternating use of abstraction and reduction is exploited to compute larger atomic code blocks in a sound manner. This makes possible the verification of assertions in the transformed program by simple sequential reasoning within atomic blocks, or significantly simplified application of existing concurrent program verification techniques such as the Owicki-Gries or rely-guarantee methods. Our method facilitates a clean separation of concerns where at each phase of the proof, the user worries only about only either the sequential properties or the concurrency\u00a0\u2026", "num_citations": "118\n", "authors": ["1741"]}
{"title": "Thread-modular verification for shared-memory programs\n", "abstract": " Ensuring the reliability of multithreaded software systems is difficult due to the interaction between threads. This paper describes the design and implementation of a static checker for such systems. To avoid considering all possible thread interleavings, the checker uses assumeguarantee reasoning, and relies on the programmer to specify an environment assumption that constrains the interaction between threads. Using this environment assumption, the checker reduces the verification of the original multithreaded program to the verification of several sequential programs, one for each thread. These sequential programs are subsequently analyzed using extended static checking techniques (based on verification conditions and automatic theorem proving). Experience indicates that the checker is capable of handling a range of synchronization disciplines. In addition, the required environment assumptions\u00a0\u2026", "num_citations": "115\n", "authors": ["1741"]}
{"title": "Conflict exceptions: Simplifying concurrent language semantics with precise hardware exceptions for data-races\n", "abstract": " We argue in this paper that concurrency errors should be treated as exceptions, i.e., have fail-stop behavior and precise semantics. We propose an exception model based on conflict of synchronization free regions, which precisely detects a broad class of data-races. We show that our exceptions provide enough guarantees to simplify high-level programming language semantics and debugging, but are significantly cheaper to enforce than traditional data-race detection. To make the performance cost of enforcement negligible, we propose architecture support for accurately detecting and precisely delivering these exceptions. We evaluate the suitability of our model as well as the behavior of our architectural mechanisms using the PARSEC benchmark suite and commercial applications. Our results show that the exception model largely reflects how programmers are already writing code and that the main memory\u00a0\u2026", "num_citations": "112\n", "authors": ["1741"]}
{"title": "Explicating sdks: Uncovering assumptions underlying secure authentication and authorization\n", "abstract": " Most modern applications are empowered by online services, so application developers frequently implement authentication and authorization. Major online providers, such as Facebook and Microsoft, provide SDKs for incorporating authentication services. This paper considers whether those SDKs enable typical developers to build secure apps. Our work focuses on systematically explicating implicit assumptions that are necessary for secure use of an SDK. Understanding these assumptions depends critically on not just the SDK itself, but on the underlying runtime systems. We present a systematic process for identifying critical implicit assumptions by building semantic models that capture both the logic of the SDK and the essential aspects of underlying systems. These semantic models provide the explicit basis for reasoning about the security of an SDK. We use a formal analysis tool, along with the semantic models, to reason about all applications that can be built using the SDK. In particular, we formally check whether the SDK, along with the explicitly captured assumptions, is sufficient to imply the desired security properties. We applied our approach to three widely used authentication/authorization SDKs. Our approach led to the discovery of several implicit assumptions in each SDK, including issues deemed serious enough to receive Facebook bug bounties and change the OAuth 2.0 specification. We verified that many apps constructed with these SDKs (indeed, the majority of apps in our study) are vulnerable to serious exploits because of these implicit assumptions, and we built a prototype testing tool that can detect several of the\u00a0\u2026", "num_citations": "111\n", "authors": ["1741"]}
{"title": "Types for atomicity: Static checking and inference for Java\n", "abstract": " Atomicity is a fundamental correctness property in multithreaded programs. A method is atomic if, for every execution, there is an equivalent serial execution in which the actions of the method are not interleaved with actions of other threads. Atomic methods are amenable to sequential reasoning, which significantly facilitates subsequent analysis and verification. This article presents a type system for specifying and verifying the atomicity of methods in multithreaded Java programs using a synthesis of Lipton's theory of reduction and type systems for race detection. The type system supports guarded, write-guarded, and unguarded fields, as well as thread-local data, parameterized classes and methods, and protected locks. We also present an algorithm for verifying atomicity via type inference. We have applied our type checker and type inference tools to a number of commonly used Java library classes and programs\u00a0\u2026", "num_citations": "82\n", "authors": ["1741"]}
{"title": "Unifying type checking and property checking for low-level code\n", "abstract": " We present a unified approach to type checking and property checking for low-level code. Type checking for low-level code is challenging because type safety often depends on complex, program-specific invariants that are difficult for traditional type checkers to express. Conversely, property checking for low-level code is challenging because it is difficult to write concise specifications that distinguish between locations in an untyped program's heap. We address both problems simultaneously by implementing a type checker for low-level code as part of our property checker. We present a low-level formalization of a C program's heap and its types that can be checked with an SMT solver, and we provide a decision procedure for checking type safety. Our type system is flexible enough to support a combination of nominal and structural subtyping for C, on a per-structure basis. We discuss several case studies that\u00a0\u2026", "num_citations": "77\n", "authors": ["1741"]}
{"title": "Checking concise specifications for multithreaded software\n", "abstract": " Ensuring the reliability of multithreaded software systems is difficult due to the potential for subtle interactions between threads. We present a new modular verification technique to check concise specifications of large multithreaded programs. Our analysis scales to systems with large numbers of procedures and threads. We achieve thread-modular analysis by annotating each shared variable by an access predicate that summarizes the condition under which a thread may access that variable. We achieve procedure-modular analysis by annotating each procedure with a specification related to its implementation by an abstraction relation combining the notions of simulation and reduction. We have implemented our analysis in Calvin-R, a static checker for multithreaded Java programs.", "num_citations": "77\n", "authors": ["1741"]}
{"title": "Modular verification of multithreaded programs\n", "abstract": " Multithreaded software systems are prone to errors due to the difficulty of reasoning about multiple interleaved threads operating on shared data. Static checkers that analyze a program's behavior over all execution paths and all thread interleavings are a powerful approach to identifying bugs in such systems. In this paper, we present Calvin, a scalable and expressive static checker for multithreaded programs based on automatic theorem proving. To handle realistic programs, Calvin performs modular checking of each procedure called by a thread using specifications of other procedures and other threads. Our experience applying Calvin to several real-world programs indicates that Calvin has a moderate annotation overhead and can catch common defects in multithreaded programs, such as synchronization errors and violations of data invariants.", "num_citations": "76\n", "authors": ["1741"]}
{"title": "Drona: A framework for safe distributed mobile robotics\n", "abstract": " Distributed mobile robotics (DMR) involves teams of networked robots navigating in a physical space to achieve tasks in a coordinated fashion. A major challenge in DMR is to program the ensemble of robots with formal guarantees and high assurance of correct operation. To this end, we introduce Drona, a framework for building reliable DMR applications.", "num_citations": "75\n", "authors": ["1741"]}
{"title": "RADISH: Always-on sound and complete race detection in software and hardware\n", "abstract": " Data-race freedom is a valuable safety property for multithreaded programs that helps with catching bugs, simplifying memory consistency model semantics, and verifying and enforcing both atomicity and determinism. Unfortunately, existing software-only dynamic race detectors are precise but slow; proposals with hardware support offer higher performance but are imprecise. Both precision and performance are necessary to achieve the many advantages always-on dynamic race detection could provide.", "num_citations": "71\n", "authors": ["1741"]}
{"title": "Verifying sequential consistency on shared-memory multiprocessors by model checking\n", "abstract": " The memory model of a shared-memory multiprocessor is a contract between the designer and the programmer of the multiprocessor. A memory model is typically implemented by means of a cache-coherence protocol. The design of this protocol is one of the most complex aspects of multiprocessor design and is consequently quite error-prone. However, it is imperative to ensure that the cache-coherence protocol satisfies the shared-memory model. We present a novel technique based on model checking to tackle this difficult problem for the important and well-known shared-memory model of sequential consistency. Surprisingly, verifying sequential consistency is undecidable in general, even for finite-state cache-coherence protocols. In practice, cache-coherence protocols satisfy the properties of causality and data independence. Causality is the property that values of read events flow from values of write events\u00a0\u2026", "num_citations": "66\n", "authors": ["1741"]}
{"title": "Context-bounded analysis for concurrent programs with dynamic creation of threads\n", "abstract": " Context-bounded analysis has been shown to be both efficient and effective at finding bugs in concurrent programs. According to its original definition, context-bounded analysis explores all behaviors of a concurrent program up to some fixed number of context switches between threads. This definition is inadequate for programs that create threads dynamically because bounding the number of context switches in a computation also bounds the number of threads involved in the computation. In this paper, we propose a more general definition of context-bounded analysis useful for programs with dynamic thread creation. The idea is to bound the number of context switches for each thread instead of bounding the number of switches of all threads. We consider several variants based on this new definition, and we establish decidability and complexity results for the analysis induced by them.", "num_citations": "64\n", "authors": ["1741"]}
{"title": "Vyrd: verifying concurrent programs by runtime refinement-violation detection\n", "abstract": " We present a runtime technique for checking that a concurrently-accessed data structure implementation, such as a file system or the storage management module of a database, conforms to an executable specification that contains an atomic method per data structure operation. The specification can be provided separately or a non-concurrent, \"atomized\" interpretation of the implementation can serve as the specification. The technique consists of two phases. In the first phase, the implementation is instrumented in order to record information into a log during execution. In the second, a separate verification thread uses the logged information to drive an instance of the specification and to check whether the logged execution conforms to it. We paid special attention to the general applicability and scalability of the techniques and to minimizing their concurrency and performance impact. The result is a lightweight\u00a0\u2026", "num_citations": "62\n", "authors": ["1741"]}
{"title": "Automated and modular refinement reasoning for concurrent programs\n", "abstract": " We present civl, a language and verifier for concurrent programs based on automated and modular refinement reasoning. civl supports reasoning about a concurrent program at many levels of abstraction. Atomic actions in a high-level description are refined to fine-grain and optimized lower-level implementations. A novel combination of automata theoretic and logic-based checks is used to verify refinement. Modular specifications and proof annotations, such as location invariants and procedure pre- and post-conditions, are specified separately, independently at each level in terms of the variables visible at that level. We have implemented civl as an extension to the boogie language and verifier. We have used civl to refine a realistic concurrent garbage collection algorithm from a simple high-level specification down to a highly-concurrent implementation described in terms of individual memory accesses\u00a0\u2026", "num_citations": "58\n", "authors": ["1741"]}
{"title": "Induction in compositional model checking\n", "abstract": " This paper describes a technique of inductive proof based on model checking. It differs from previous techniques that combine induction and model checking in that the proof is fully mechanically checked and temporal variables (process identifiers, for example) may be natural numbers. To prove \u2200n.\u03d5(n) inductively, the predicate  must be proved for all values of the parameter n. Its proof for a fixed\u00a0n uses a conservative abstraction that partitions the natural numbers into a finite number of intervals. This renders the model finite. Further, the abstractions for different values of n fall into a finite number of isomorphism classes. Thus, an inductive proof of \u2200n.\u03d5(n) can be obtained by checking a finite number of formulas on finite models. The method is integrated with a compositional proof system based on the SMV model checker. It is illustrated by examples, including the N-process \u201cbakery\u201d mutual\u00a0\u2026", "num_citations": "55\n", "authors": ["1741"]}
{"title": "Simplifying linearizability proofs with reduction and abstraction\n", "abstract": " The typical proof of linearizability establishes an abstraction map from the concurrent program to a sequential specification, and identifies the commit points of operations. If the concurrent program uses fine-grained concurrency and complex synchronization, constructing such a proof is difficult. We propose a sound proof system that significantly simplifies the reasoning about linearizability. Linearizability is proved by transforming an implementation into its specification within this proof system. The proof system combines reduction and abstraction, which increase the granularity of atomic actions, with variable introduction and hiding, which syntactically relate the representation of the implementation to that of the specification. We construct the abstraction map incrementally, and eliminate the need to reason about the location of commit points in the implementation. We have implemented our method in the\u00a0\u2026", "num_citations": "53\n", "authors": ["1741"]}
{"title": "Context-bounded analysis of multithreaded programs with dynamic linked structures\n", "abstract": " Bounded context switch reachability analysis is a useful and efficient approach for detecting bugs in multithreaded programs. In this paper, we address the application of this approach to the analysis of multithreaded programs with procedure calls and dynamic linked structures. We define a program semantics based on concurrent pushdown systems with visible heaps as stack symbols. A visible heap is the part of the heap reachable from global and local variables. We use pushdown analysis techniques to define an algorithm that explores the entire configuration space reachable under given bounds on the number of context switches and the size of visible heaps.", "num_citations": "49\n", "authors": ["1741"]}
{"title": "Interleaving and lock-step semantics for analysis and verification of GPU kernels\n", "abstract": " We study semantics of GPU kernels \u2014 the parallel programs that run on Graphics Processing Units (GPUs). We provide a novel lock-step execution semantics for GPU kernels represented by arbitrary reducible control flow graphs and compare this semantics with a traditional interleaving semantics. We show for terminating kernels that either both semantics compute identical results or both behave erroneously.               The result induces a method that allows GPU kernels with arbitrary reducible control flow graphs to be verified via transformation to a sequential program that employs predicated execution. We implemented this method in the GPUVerify tool and experimentally evaluated it by comparing the tool with the previous version of the tool based on a similar method for structured programs, i.e., where control is organised using if and while statements. The evaluation was based on a set of 163 open\u00a0\u2026", "num_citations": "47\n", "authors": ["1741"]}
{"title": "Data race detection using sequential program analysis\n", "abstract": " A concurrent program is analyzed for the presence of data races by the creation of a sequential program from the concurrent program. The sequential program contains assertions which can be verified by a sequential program analysis tool, and which, when violated, indicate the presence of a data race. The sequential program emulates multiple executions of the concurrent program by nondeterministically scheduling asynchronous threads of the concurrent program on a single runtime stack and nondeterministically removing the currently-executing thread from the stack before instructions of the program. Checking functions are used to provide assertions for data races, along with a global access variable, which indicates if a variable being analyzed for data races is currently being accessed by any threads.", "num_citations": "47\n", "authors": ["1741"]}
{"title": "Exploiting purity for atomicity\n", "abstract": " Multithreaded programs often exhibit erroneous behavior because of unintended interactions between concurrent threads. This paper focuses on the noninterference property of atomicity. A procedure is atomic if, for every execution, there is an equivalent serial execution in which the actions of the atomic procedure are not interleaved with actions of other threads. This key property makes atomic procedures amenable to sequential reasoning techniques, which significantly facilitates subsequent validation activities such as code inspection and testing. Several existing tools verify atomicity by using commutativity of actions to show that every execution reduces to a corresponding serial execution. However, experiments with these tools have highlighted a number of interesting procedures that, while intuitively atomic, are not reducible. In this paper, we exploit the notion of pure code blocks to verify the atomicity of such\u00a0\u2026", "num_citations": "47\n", "authors": ["1741"]}
{"title": "The design and implementation of a verification technique for GPU kernels\n", "abstract": " We present a technique for the formal verification of GPU kernels, addressing two classes of correctness properties: data races and barrier divergence. Our approach is founded on a novel formal operational semantics for GPU kernels termed synchronous, delayed visibility (SDV) semantics, which captures the execution of a GPU kernel by multiple groups of threads. The SDV semantics provides operational definitions for barrier divergence and for both inter- and intra-group data races. We build on the semantics to develop a method for reducing the task of verifying a massively parallel GPU kernel to that of verifying a sequential program. This completely avoids the need to reason about thread interleavings, and allows existing techniques for sequential program verification to be leveraged. We describe an efficient encoding of data race detection and propose a method for automatically inferring the loop invariants\u00a0\u2026", "num_citations": "44\n", "authors": ["1741"]}
{"title": "Precise data-race detection using locksets\n", "abstract": " A data race detection system is described which precisely identifies data races in concurrent programs. The system and techniques described utilize locksets to maintain information while searching through executions of a concurrent program. The locksets are updated according to program statements in the concurrent program. The dynamic updating of the locksets, combined with a less conservative approach then used in existing lockset data race detection techniques, allows the technique to be precise; that is, the technique does not report false positives when searching a program.", "num_citations": "42\n", "authors": ["1741"]}
{"title": "A modular checker for multithreaded programs\n", "abstract": " Designing multithreaded software systems is prone to errors due to the difficulty of reasoning about multiple interleaved threads of control operating on shared data. Static checking, with the potential to analyze the program\u2019s behavior over all execution paths and for all thread interleavings, is a powerful debugging tool. We have built a scalable and expressive static checker called Calvin for multithreaded programs. To handle realistic programs, Calvin performs modular checking of each procedure called by a thread using specifications of other procedures and other threads. The checker leverages off existing sequential program verification techniques based on automatic theorem proving. To evaluate the checker, we have applied it to several real-world programs. Our experience indicates that Calvin has a moderate annotation overhead and can catch defects in multithreaded programs, including\u00a0\u2026", "num_citations": "41\n", "authors": ["1741"]}
{"title": "Powering the static driver verifier using corral\n", "abstract": " The application of software-verification technology towards building realistic bug-finding tools requires working through several precision-scalability tradeoffs. For instance, a critical aspect while dealing with C programs is to formally define the treatment of pointers and the heap. A machine-level modeling is often intractable, whereas one that leverages high-level information (such as types) can be inaccurate. Another tradeoff is modeling integer arithmetic. Ideally, all arithmetic should be performed over bitvector representations whereas the current practice in most tools is to use mathematical integers for scalability. A third tradeoff, in the context of bounded program exploration, is to choose a bound that ensures high coverage without overwhelming the analysis. This paper works through these three tradeoffs when we applied Corral, an SMT-based verifier, inside Microsoft's Static Driver Verifier (SDV). Our decisions\u00a0\u2026", "num_citations": "37\n", "authors": ["1741"]}
{"title": "Engineering a static verification tool for GPU kernels\n", "abstract": " We report on practical experiences over the last 2.5 years related to the engineering of GPUVerify, a static verification tool for OpenCL and CUDA GPU kernels, plotting the progress of GPUVerify from a prototype to a fully functional and relatively efficient analysis tool. Our hope is that this experience report will serve the verification community by helping to inform future tooling efforts.", "num_citations": "36\n", "authors": ["1741"]}
{"title": "Goldilocks: Efficiently computing the happens-before relation using locksets\n", "abstract": " We present a new lockset-based algorithm, Goldilocks, for precisely computing the happens-before relation and thereby detecting data-races at runtime. Dynamic race detection algorithms in the literature are based on vector clocks or locksets. Vector-clock-based algorithms precisely compute the happens-before relation but have significantly more overhead. Previous lockset-based race detection algorithms, on the other hand, are imprecise. They check adherence to a particular synchronization discipline, i.e., a sufficient condition for race freedom and may generate false race warnings. Our algorithm, like vector clocks, is precise, yet it is efficient since it is purely lockset based.               We have implemented our algorithm inside the Kaffe Java Virtual Machine. Our implementation incorporates lazy evaluation of locksets and certain \u201cshort-circuit checks\u201d which contribute significantly to its efficiency\u00a0\u2026", "num_citations": "36\n", "authors": ["1741"]}
{"title": "On the completeness of verifying message passing programs under bounded asynchrony\n", "abstract": " We address the problem of verifying message passing programs, defined as a set of processes communicating through unbounded FIFO buffers. We introduce a bounded analysis that explores a special type of computations, called k-synchronous. These computations can be viewed as (unbounded) sequences of interaction phases, each phase allowing at most k send actions (by different processes), followed by a sequence of receives corresponding to sends in the same phase. We give a procedure for deciding k-synchronizability of a program, i.e., whether every computation is equivalent (has the same happens-before relation) to one of its k-synchronous computations. We show that reachability over k-synchronous computations and checking k-synchronizability are both PSPACE-complete.", "num_citations": "33\n", "authors": ["1741"]}
{"title": "Systematic testing of asynchronous reactive systems\n", "abstract": " We introduce the concept of a delaying explorer with the goal of performing prioritized exploration of the behaviors of an asynchronous reactive program. A delaying explorer stratifies the search space using a custom strategy, and a delay operation that allows deviation from that strategy. We show that prioritized search with a delaying explorer performs significantly better than existing prioritization techniques. We also demonstrate empirically the need for writing different delaying explorers for scalable systematic testing and hence, present a flexible delaying explorer interface. We introduce two new techniques to improve the scalability of search based on delaying explorers. First, we present an algorithm for stratified exhaustive search and use efficient state caching to avoid redundant exploration of schedules. We provide soundness and termination guarantees for our algorithm. Second, for the cases where the state of the\u00a0\u2026", "num_citations": "33\n", "authors": ["1741"]}
{"title": "Uncovering bugs in distributed storage systems during testing (not in production!)\n", "abstract": " Testing distributed systems is challenging due to multiple sources of nondeterminism. Conventional testing techniques, such as unit, integration and stress testing, are ineffective in preventing serious but subtle bugs from reaching production. Formal techniques, such as TLA+, can only verify high-level specifications of systems at the level of logic-based models, and fall short of checking the actual executable code. In this paper, we present a new methodology for testing distributed systems. Our approach applies advanced systematic testing techniques to thoroughly check that the executable code adheres to its high-level specifications, which significantly improves coverage of important system behaviors.", "num_citations": "32\n", "authors": ["1741"]}
{"title": "Verifying controllers against adversarial examples with Bayesian optimization\n", "abstract": " Recent successes in reinforcement learning have lead to the development of complex controllers for realworld robots. As these robots are deployed in safety-critical applications and interact with humans, it becomes critical to ensure safety in order to avoid causing harm. A first step in this direction is to test the controllers in simulation. To be able to do this, we need to capture what we mean by safety and then efficiently search the space of all behaviors to see if they are safe. In this paper, we present an active-testing framework based on Bayesian Optimization. We specify safety constraints using logic and exploit structure in the problem in order to test the system for adversarial counter examples that violate the safety specifications. These specifications are defined as complex boolean combinations of smooth functions on the trajectories and, unlike reward functions in reinforcement learning, are expressive and\u00a0\u2026", "num_citations": "31\n", "authors": ["1741"]}
{"title": "Move: A language with programmable resources\n", "abstract": " We present Move, a safe and flexible programming language for the Libra Blockchain [1][2]. Move is an executable bytecode language used to implement custom transactions and smart contracts. The key feature of Move is the ability to define custom resource types with semantics inspired by linear logic [3]: a resource can never be copied or implicitly discarded, only moved between program storage locations. These safety guarantees are enforced statically by Move\u2019s type system. Despite these special protections, resources are ordinary program values\u2014they can be stored in data structures, passed as arguments to procedures, and so on. First-class resources are a very general concept that programmers can use not only to implement safe digital assets but also to write correct business logic for wrapping assets and enforcing access control policies. The safety and expressivity of Move have enabled us to implement significant parts of the Libra protocol in Move, including Libra coin, transaction processing, and validator management.", "num_citations": "30\n", "authors": ["1741"]}
{"title": "A case for system support for concurrency exceptions\n", "abstract": " In this position paper we argue that concurrency errors should be fail-stop. We want to put concurrency errors in the same category as division-by-zero, segmentation fault in unmanaged languages and cast exceptions in managed languages. This would make nondeterminism in multithreaded execution be much more manageable. Concurrency exceptions would improve the debugging process during development and make crashes due to concurrency errors that happen in the field be more descriptive. Our goal in this paper is to justify our position, propose a general approach to concurrency exceptions and discuss system requirements and implications. Specifically, we discuss the semantics of concurrency exceptions at the language level, their implications in the compiler and runtime systems, how they should be delivered and, finally, how they are enabled by efficient architecture support.", "num_citations": "29\n", "authors": ["1741"]}
{"title": "Exploiting purity for atomicity\n", "abstract": " The notion that certain procedures are atomic is a fundamental correctness property of many multithreaded software systems. A procedure is atomic if for every execution there is an equivalent serial execution in which the actions performed by any thread while executing the atomic procedure are not interleaved with actions of other threads. Several existing tools verify atomicity by using commutativity of actions to show that every execution reduces to a corresponding serial execution. However, experiments with these tools have highlighted a number of interesting procedures that, while intuitively atomic, are not reducible. In this paper, we exploit the notion of pure code blocks to verify the atomicity of such irreducible procedures. If a pure block terminates normally, then its evaluation does not change the program state, and hence these evaluation steps can be removed from the program trace before reduction. We\u00a0\u2026", "num_citations": "29\n", "authors": ["1741"]}
{"title": "Barrier invariants: a shared state abstraction for the analysis of data-dependent GPU kernels\n", "abstract": " Data-dependent GPU kernels, whose data or control flow are dependent on the input of the program, are difficult to verify because they require reasoning about shared state manipulated by many parallel threads. Existing verification techniques for GPU kernels achieve soundness and scalability by using a two-thread reduction and making the contents of the shared state nondeterministic each time threads synchronise at a barrier, to account for all possible thread interactions. This coarse abstraction prohibits verification of data-dependent kernels. We present barrier invariants, a novel abstraction technique which allows key properties about the shared state of a kernel to be preserved across barriers during formal reasoning. We have integrated barrier invariants with the GPUVerify tool, and present a detailed case study showing how they can be used to verify three prefix sum algorithms, allowing efficient modular\u00a0\u2026", "num_citations": "28\n", "authors": ["1741"]}
{"title": "Complexity and algorithms for monomial and clausal predicate abstraction\n", "abstract": " In this paper, we investigate the asymptotic complexity of various predicate abstraction problems relative to the asymptotic complexity of checking an annotated program in a given assertion logic. Unlike previous approaches, we pose the predicate abstraction problem as a decision problem, instead of the traditional inference problem. For assertion logics closed under weakest (liberal) precondition and Boolean connectives, we show two restrictions of the predicate abstraction problem where the two complexities match. The restrictions correspond to the case of monomial and clausal abstraction. For these restrictions, we show a symbolic encoding that reduces the predicate abstraction problem to checking the satisfiability of a single formula whose size is polynomial in the size of the program and the set of predicates. We also provide a new iterative algorithm for solving the clausal abstraction problem that\u00a0\u2026", "num_citations": "28\n", "authors": ["1741"]}
{"title": "Synchronizing the asynchronous\n", "abstract": " Synchronous programs are easy to specify because the side effects of an operation are finished by the time the invocation of the operation returns to the caller. Asynchronous programs, on the other hand, are difficult to specify because there are side effects due to pending computation scheduled as a result of the invocation of an operation. They are also difficult to verify because of the large number of possible interleavings of concurrent computation threads. We present synchronization, a new proof rule that simplifies the verification of asynchronous programs by introducing the fiction, for proof purposes, that asynchronous operations complete synchronously. Synchronization summarizes an asynchronous computation as immediate atomic effect. Modular verification is enabled via pending asynchronous calls in atomic summaries, and a complementary proof rule that eliminates pending asynchronous calls when components and their specifications are composed. We evaluate synchronization in the context of a multi-layer refinement verification methodology on a collection of benchmark programs.", "num_citations": "25\n", "authors": ["1741"]}
{"title": "Identifying implicit assumptions associated with a software product\n", "abstract": " A framework is described herein for identifying implicit assumptions associated with an SDK and its accompanying documentation (eg, dev guide). An implicit assumption is information that is not expressly stated in the documentation, but which would be useful in assisting an application developer in building an application. The framework also describes a systematic approach for identifying one or more vulnerability patterns based on the identified implicit assumptions. An application developer may run a test on an application that is being developed to ensure that it does not have any deficiency which matches a vulnerability pattern.", "num_citations": "24\n", "authors": ["1741"]}
{"title": "Computer Aided Verification: 23rd International Conference, CAV 2011, Snowbird, UT, USA, July 14-20, 2011, Proceedings\n", "abstract": " This book constitutes the refereed proceedings of the 23rd International Conference on Computer Aided Verification, CAV 2011, held in Snowbird, UT, USA, in July 2011. The 35 revised full papers presented together with 20 tool papers were carefully reviewed and selected from 161 submissions. The papers are organized in topical sections on the following workshops: 4th International Workshop on Numerical Software Verification (NSV 2011), 10th International Workshop on Parallel and Distributed Methods in Verifications (PDMC 2011), 4th International Workshop on Exploiting Concurrency Efficiently and Correctly (EC2 2011), Frontiers in Analog Circuit Synthesis and Verification (FAC 2011), International Workshop on Satisfiability Modulo Theories, including SMTCOMP (SMT 2011), 18th International SPIN Workshop on Model Checking of Software (SPIN 2011), Formal Methods for Robotics and Automation (FM-R 2011), and Practical Synthesis for Concurrent Systems (PSY 2011).", "num_citations": "24\n", "authors": ["1741"]}
{"title": "Intra-module inference\n", "abstract": " Contract-based property checkers hold the potential for precise, scalable, and incremental reasoning. However, it is difficult to apply such checkers to large program modules because they require programmers to provide detailed contracts, including an interface specification, module invariants, and internal specifications. We argue that given a suitably rich assertion language, modest effort suffices to document the interface specification and the module invariants. However, the burden of providing internal specifications is still significant and remains a deterrent to the use of contract-based checkers. Therefore, we consider the problem of intra-module inference, which aims to infer annotations for internal procedures and loops, given the interface specification and the module invariants. We provide simple and scalable techniques to search for a broad class of desired internal annotations, comprising\u00a0\u2026", "num_citations": "24\n", "authors": ["1741"]}
{"title": "Compositional programming and testing of dynamic distributed systems\n", "abstract": " A real-world distributed system is rarely implemented as a standalone monolithic system. Instead, it is composed of multiple independent interacting components that together ensure the desired system-level specification. One can scale systematic testing to large, industrial-scale implementations by decomposing the system-level testing problem into a collection of simpler component-level testing problems.   This paper proposes techniques for compositional programming and testing of distributed systems with two central contributions: (1) We propose a module system based on the theory of compositional trace refinement for dynamic systems consisting of asynchronously-communicating state machines, where state machines can be dynamically created, and communication topology of the existing state machines can change at runtime; (2) We present ModP, a programming system that implements our module\u00a0\u2026", "num_citations": "21\n", "authors": ["1741"]}
{"title": "Runtime refinement checking of concurrent data structures\n", "abstract": " We present a runtime technique for checking that a concurrent implementation of a data structure conforms to a high-level executable specification with atomic operations. The technique consists of two phases. In the first phase, the implementation code is instrumented in order to record informa- tion about its execution into a log. In the second phase, a verification thread runs concurrently with the implementation and uses the logged information to check that the execution conforms to the high-level specification. We pay special attention to reducing the impact of the runtime analysis on the concurrency characteristics and performance of the implementation. We are currently applying our technique to Boxwood [http://research.microsoft.com/research/sv/Boxwood], a distributed implementation of a B-link tree data structure.", "num_citations": "20\n", "authors": ["1741"]}
{"title": "Formal verification of FIRE: A case study\n", "abstract": " We present our experiences with the formal verification of an automotivechip used to control the safety features in a car. We useda BDD based model checker in our work. We describe our verificationmethodology for verifying a very complicated property on arelatively large design. We also describe the bugs that were foundand present our views on how to make model checking an effectiveintegrated part of the design flow for complex hardware systems.", "num_citations": "20\n", "authors": ["1741"]}
{"title": "Latch redundancy removal without global reset\n", "abstract": " For circuits where there may be latches with no reset line, we show how to replace some of them with combinational logic. All previous work in sequential optimization by latch removal assumes a designated initial state. Without this assumption, the design can power up in any state and earlier techniques are not applicable. We present an algorithm for identifying and replacing redundant latches by combinational logic such that no environment of the design can detect the change. The new design preserves the steady state behavior as well as all initializing sequences of the old design. We report experimental results on benchmark circuits and demonstrate savings in area without adverse impact on delay.", "num_citations": "20\n", "authors": ["1741"]}
{"title": "Model checking with bounded context switches\n", "abstract": " Validity of one or more assertions for any concurrent execution of a plurality of software instructions with at most k\u2212 1 context switches can be determined. Validity checking can account for execution of the software instructions in an unbounded stack depth scenario. A finite data domain representation can be used. The software instructions can be represented by a pushdown system. Validity checking can account for thread creation during execution of the plurality of software instructions.", "num_citations": "19\n", "authors": ["1741"]}
{"title": "A program transformation for faster goal-directed search\n", "abstract": " A goal-directed search attempts to reveal only relevant information needed to establish reachability (or unreachability) of the goal from the initial state of the program. The further apart the goal is from the initial state, the harder it can get to establish what is relevant. This paper addresses this concern in the context of programs with assertions that may be nested deeply inside its call graph - thus, far away interprocedurally from main. We present a source-to-source transformation on programs that lifts all assertions in the input program to the entry procedure of the output program, thus, revealing more information about the assertions close to the entry of the program. The transformation is easy to implement and applies to sequential as well as concurrent programs. We empirically validate using multiple goal-directed verifiers that applying this transformation before invoking the verifier results in significant speedups\u00a0\u2026", "num_citations": "18\n", "authors": ["1741"]}
{"title": "Poirot\u2014A Concurrency Sleuth\n", "abstract": " Concurrent programming is difficult. The challenges are foundational: unlike sequential control flow, asynchronous control flow is difficult to understand and reason about. Not surprisingly, even expert programmers find it difficult to write concurrent software. We desperately need software engineering techniques and tools to move concurrent programming from black art to a rigorous engineering discipline. I believe that automated tools that reduce the cognitive burden of reasoning about concurrency can help tremendously in improving the productivity of concurrent programmers. In collaboration with my colleagues at Microsoft Research, I have developed Poirot (http://research.microsoft.com/ en-us/projects/poirot/), a tool for answering semantic queries about a concurrent program by statically searching over its executions. Poirot exploits sequential encodings of concurrent semantics, structural under- and\u00a0\u2026", "num_citations": "18\n", "authors": ["1741"]}
{"title": "Static verification of parallel program code\n", "abstract": " A symbolic encoding of predicated execution for static verification, based on a plurality of data parallel program instructions, is obtained. A result of static verification of one or more attributes associated with the plurality of data parallel program instructions is obtained, based on the symbolic encoding.", "num_citations": "17\n", "authors": ["1741"]}
{"title": "Approximate synchrony: An abstraction for distributed almost-synchronous systems\n", "abstract": " Forms of synchrony can greatly simplify modeling, design, and verification of distributed systems. Thus, recent advances in clock synchronization protocols and their adoption hold promise for system design. However, these protocols synchronize the distributed clocks only within a certain\u00a0tolerance, and there are transient phases while synchronization is still being achieved. Abstractions used for modeling and verification of such systems should accurately capture these imperfections that cause the system to only be \u201calmost synchronized.\u201d In this paper, we present approximate synchrony, a sound and tunable abstraction for verification of almost-synchronous systems. We show how approximate synchrony can be used for verification of both time synchronization protocols and applications running on top of them. We provide an algorithmic approach for constructing this abstraction for symmetric, almost\u00a0\u2026", "num_citations": "17\n", "authors": ["1741"]}
{"title": "The case for context-bounded verification of concurrent programs\n", "abstract": " Concurrent programs are difficult to get right. Subtle interactions among communicating threads in the program can result in behaviors unexpected to the programmer. These behaviors typically result in bugs that occur late in the software development cycle or even after the software is released. Such bugs are difficult to reproduce and difficult to debug. As a result, they have a huge adverse impact on the productivity of programmers and the cost of software development. Therefore, tools that can help detect and debug concurrency errors will likely provide a significant boost to software productivity.", "num_citations": "17\n", "authors": ["1741"]}
{"title": "Precise race detection and efficient model checking using locksets\n", "abstract": " Many software systems depend critically on concurrent components for performance. Such systems are used extensively, which makes their functional correctness very important. To improve the reliability of these systems, we need efficient and easy-to-use analysis and verification tools specific to concurrency-related problems. Detection of race conditions on shared data is a central issue in such tools. Even though some race conditions may be benign, awareness of race conditions or their absence allows programmers to optimize their programs and to make them safer. Numerous techniques and tools have been developed to analyze races and to guard against them [28, 32, 5, 3].Race conditions on shared data variables are usually defined in terms of the happens-before relation. The Java memory model [18], for instance, defines the important notion of a race-free execution in terms of the happens-before relation. An action \u03b11 happens-before another action action \u03b12 in a concurrent execution if \u03b11 occurs before \u03b12 and either both \u03b11 and \u03b12 are performed by the same thread or \u03b11 is transitively connected to \u03b12 by a series of synchronization actions, such as acquire or release of a lock, or fork of a thread, or join with a thread.", "num_citations": "17\n", "authors": ["1741"]}
{"title": "Layered concurrent programs\n", "abstract": " We present layered concurrent programs, a compact and expressive notation for specifying refinement proofs of concurrent programs. A layered concurrent program specifies a sequence of connected concurrent programs, from most concrete to most abstract, such that common parts of different programs are written exactly once. These programs are expressed in the ordinary syntax of imperative concurrent programs using gated atomic actions, sequencing, choice, and (recursive) procedure calls. Each concurrent program is automatically extracted from the layered program. We reduce refinement to the safety of a sequence of concurrent checker programs, one each to justify the connection between every two consecutive concurrent programs. These checker programs are also automatically extracted from the layered program. Layered concurrent programs have been implemented in the Civl verifier which\u00a0\u2026", "num_citations": "15\n", "authors": ["1741"]}
{"title": "Linear maps\n", "abstract": " Verification of large programs is impossible without proof techniques that allow local reasoning and information hiding. In this paper, we take the approach of modeling the heap as a collection of partial functions with disjoint domains. We call each such partial function a linear map. Programmers may select objects from linear maps, update linear maps or transfer addresses and their contents from one linear map to another. Programmers may also declare new linear map variables and pass linear maps as arguments to procedures. The program logic prevents any of these operations from duplicating locations and thereby breaking the key heap representation invariant: the domains of all linear maps remain disjoint. Linear maps facilitate modular reasoning because programs that use them are also able to use simple, classical frame rules to preserve information about heap state across procedure calls. We illustrate\u00a0\u2026", "num_citations": "14\n", "authors": ["1741"]}
{"title": "Goldilocks: a race-aware Java runtime\n", "abstract": " We present Goldilocks, a Java runtime that monitors program executions and throws a DataRaceException when a data race is about to occur. This prevents racy accesses from taking place, and allows race conditions to be handled before they cause errors that may be difficult to diagnose later. The DataRaceException is a valuable debugging tool, and, if supported with reasonable computational overhead, can be an important safety feature for deployed programs. Experiments by us and others on raceaware Java runtimes indicate that the DataRaceException may be a viable mechanism to enforce the safety of executions of multithreaded Java programs. An important benefit of DataRaceException is that executions in our runtime are guaranteed to be race free and thus sequentially consistent as per the Java Memory Model. This strong guarantee provides an easy-to-use, clean semantics to programmers, and\u00a0\u2026", "num_citations": "14\n", "authors": ["1741"]}
{"title": "Programming safe robotics systems: Challenges and advances\n", "abstract": " A significant challenge for large-scale deployment of autonomous mobile robots is to program them with formal guarantees and high assurance of correct operation. Our approach towards enabling safe programming of robotics system consists of two parts:(1) a programming language for implementing, specifying, and compositionally (assume-guarantee) testing the high-level reactive robotics software;(2) a runtime assurance system to ensure that the assumptions used during design-time testing of high-level software hold at runtime. Combining high-level programming language and its systematic testing with runtime enforcement helps us bridge the gap between software testing that makes assumptions about the low-level controllers and the physical world, and the actual execution of the software on a real robotic platform in the physical world. We implement our approach in, a programming framework for building\u00a0\u2026", "num_citations": "13\n", "authors": ["1741"]}
{"title": "Transactions for software model checking\n", "abstract": " This paper presents a software model checking algorithm that combats state explosion by decomposing each thread's execution into a sequence of transactions that execute atomically. Our algorithm infers transactions using the theory of reduction, and supports both left and right movers, thus yielding larger transactions and fewer context switches than previous methods. Our approach uses access predicates to support a wide variety of synchronization mechanisms. In addition, we automatically infer these predicates for programs that use lock-based synchronization.", "num_citations": "13\n", "authors": ["1741"]}
{"title": "Securing multiparty online services via certification of symbolic transactions\n", "abstract": " The prevalence of security flaws in multiparty online services (e.g., Single-sign-on, third-party payment, etc.) calls for rigorous engineering supported by formal program verification. However, the adoption of program verification faces several hurdles in the real world: how to formally specify logic properties given that protocol specifications are often informal and vague, how to precisely model the attacker and the runtime platform, how to deal with the unbounded set of all potential transactions. We introduce Certification of Symbolic Transaction (CST), an approach to significantly lower these hurdles. CST tries to verify a protocol-independent safety property jointly defined over all parties, thus avoids the burden of individually specifying every party's property for every protocol, CST invokes static verification at runtime, i.e., It symbolically verifies every transaction on-the-fly, and thus (1) avoids the burden of modeling the\u00a0\u2026", "num_citations": "12\n", "authors": ["1741"]}
{"title": "Unifying type checking and property checking for low level programs\n", "abstract": " This document describes a unified type checker and property checker for a low level program's heap and its types. The type checker can use the full power of the property checker to express and verify subtle, program specific type and memory safety invariants well beyond what the native low level program system can check. Meanwhile, the property checker can rely on the type checker to provide structure and disambiguation for the program's heap, enabling more concise and more powerful type-based specifications. This approach makes use of a fully automated Satisfiability Modulo Theories (SMT) solver and a decision procedure for checking type safety, which means that the programmer's only duty is to provide high-level type and property annotations as part of the original program's source.", "num_citations": "12\n", "authors": ["1741"]}
{"title": "Method for verifying abstract memory models of shared memory multiprocessors\n", "abstract": " A method of verifying a protocol for a shared-memory multiprocessor system for sequential consistency. In the system there are n processors and m memory locations that are shared by the processors. A protocol automaton, such as a cache coherence protocol automaton, is developed. The protocol automaton and a plurality of checker automata are provided to a model checker which exhaustively searches the state space of the protocol automaton. During the search, the plurality of checker automata check for the presence of cycles in a graph that is the union of the total orders of the processor references and the partial orders at each memory location. If the plurality of checker automata detect the presence of a cycle, then the protocol does not meet the sequential consistency requirement.", "num_citations": "12\n", "authors": ["1741"]}
{"title": "On the verification of memory models of shared-memory multiprocessors\n", "abstract": " The memory model of a shared-memory multiprocessor is a contract between the designer and programmer of the multiprocessor. We present a model checking algorithm to verify this contract for finite values of the parameters\u2014number of processors and number of memory locations\u2014for a large class of shared-memory systems and memory models. A memory model is a generalization of serial memory, which behaves as if there is a centralized memory that services read and write requests atomically such that a read to a location returns the latest value written to that location. We formalize a memory model as an irreflexive partial order among the memory (read and write) events performed locally at each processor. A run of a memory system satisfies a memory model if there exists a total order of all memory events that is both consistent with all the partial orders and a trace of serial memory. Sequential consistency is an example of a well-known memory model. It has been shown that even for finite parameter values, verifying sequential consistency on general memory systems is undecidable. We show that certain properties of shared-memory systems occurring in practice allow us to do better. In particular, we use the properties of data independence and simple write ordering to design a model checking algorithm which decides whether a system satisfies a memory model.", "num_citations": "12\n", "authors": ["1741"]}
{"title": "Identifying execution paths that satisfy reachability queries\n", "abstract": " Various technologies pertaining to answering reachability queries are described herein. A reachability query includes a user-specified destination line of code in source code that is desirably analyzed. A theorem prover is employed to identify an execution path through the source code that reaches the destination line of code. Graphical data is presented to the user that illustrates to the user the execution path through the source code that reaches the destination line of code.", "num_citations": "11\n", "authors": ["1741"]}
{"title": "Back and forth: Prophecy variables for static verification of concurrent programs\n", "abstract": " These proof systems make use of auxiliary variables to express mutual exclusion or non-interference among shared variable accesses. Typically, the values of these variables summarize the past of the program execution; consequently, they are known as history variables. Prophecy variables, on the other hand, are the temporal dual of history variables and their values summarize the future of the program execution. In this paper, we show that prophecy variables are useful for locally constructing proofs of systems with optimistic concurrency. To enable the fullest use of prophecy variables in proof construction, we introduce tressa annotations, as the dual of the well-known assert annotations. A tressa claim states a condition for reverse reachability from an end state of the program, much like an assert claim states a condition for forward reachability from the initial state of the program.We present the proof rules and\u00a0\u2026", "num_citations": "11\n", "authors": ["1741"]}
{"title": "Sequential optimisation without state space exploration.\n", "abstract": " We propose an algorithm for area optimisation of sequential circuits through redundancy removal. The algorithm finds compatible redundancies by implying values over nets in the circuit. The potentially exponential cost of state space traversal is avoided and the redundancies found can all be removed at once. The optimised circuit is a safe delayed replacement of the original circuit. The algorithm computes a set of compatible sequential redundancies and simplifies the circuit by propagating them through the circuit. We demonstrate the efficacy of the algorithm even for large circuits through experimental results on benchmark circuits.", "num_citations": "11\n", "authors": ["1741"]}
{"title": "Inductive sequentialization of asynchronous programs\n", "abstract": " Asynchronous programs are notoriously difficult to reason about because they spawn computation tasks which take effect asynchronously in a nondeterministic way. Devising inductive invariants for such programs requires understanding and stating complex relationships between an unbounded number of computation tasks in arbitrarily long executions. In this paper, we introduce inductive sequentialization, a new proof rule that sidesteps this complexity via a sequential reduction, a sequential program that captures every behavior of the original program up to reordering of coarse-grained commutative actions. A sequential reduction of a concurrent program is easy to reason about since it corresponds to a simple execution of the program in an idealized synchronous environment, where processes act in a fixed order and at the same speed. We have implemented and integrated our proof rule in the CIVL verifier\u00a0\u2026", "num_citations": "10\n", "authors": ["1741"]}
{"title": "DAG inlining: a decision procedure for reachability-modulo-theories in hierarchical programs\n", "abstract": " A hierarchical program is one with multiple procedures but no loops or recursion. This paper studies the problem of deciding reachability queries in hierarchical programs where individual statements can be encoded in a decidable logic (say in SMT). This problem is fundamental to verification and most directly applicable to doing bounded reachability in programs, i.e., reachability under a bound on the number of loop iterations and recursive calls. The usual method of deciding reachability in hierarchical programs is to first inline all procedures and then do reachability on the resulting single-procedure program. Such inlining unfolds the call graph of the program to a tree and may lead to an exponential increase in the size of the program. We design and evaluate a method called DAG inlining that unfolds the call graph to a directed acyclic graph (DAG) instead of a tree by sharing the bodies of procedures at certain\u00a0\u2026", "num_citations": "10\n", "authors": ["1741"]}
{"title": "Reachability modulo theories\n", "abstract": " Program verifiers that attempt to verify programs automatically pose the verification problem as the decision problem: Does there exist a proof that establishes the absence of errors? In this paper, we argue that program verification should instead be posed as the following decision problem: Does there exist an execution that establishes the presence of an error? We formalize the latter problem as Reachability Modulo Theories (RMT) using an imperative programming language parameterized by a multi-sorted first-order signature. We present complexity results, algorithms, and the Corral solver for the RMT problem. We present our experience using Corral on problems from a variety of application domains.", "num_citations": "10\n", "authors": ["1741"]}
{"title": "Runtime verification of concurrency-specific correctness criteria\n", "abstract": " We give an overview of correctness criteria specific to concurrent shared-memory programs and runtime verification techniques for verifying these criteria. We cover a spectrum of criteria, from ones focusing on low-level thread interference such as races to higher-level ones such as linearizability. We contrast these criteria in the context of runtime verification. We present the key ideas underlying the runtime verification techniques for these criteria and summarize the state of the art. Finally, we discuss the issue of coverage for runtime verification for concurrency and present techniques that improve the set of covered thread interleavings.", "num_citations": "10\n", "authors": ["1741"]}
{"title": "BCT: A translator from MSIL to Boogie\n", "abstract": " We describe the design and implementation of BCT, a translator from Microsoft MSIL into Boogie, a verification language that in turn targets SMT (Satisifiability-Modulo-Theories) solvers. BCT provides a vechicle for converting any program checker for the Boogie programming language into a checker for a language that compiles to Microsoft\u2019s .NET platform. BCT is methodology-neutral, precise in encoding the operational semantics of the .NET runtime, and comprehensively covers all features of .NET.", "num_citations": "10\n", "authors": ["1741"]}
{"title": "Assume-guarantee model checking\n", "abstract": " We present assume-guarantee model checking, a novel technique for verifying correctness properties of loosely-coupled multithreaded software systems. Assume-guarantee model checking verifies each thread of a multithreaded system separately by constraining the actions of other threads with an automatically inferred environment assumption. Separate verification of each thread allows the enumeration of the local state of only one thread at a time, thereby yieldig significant savings in the time and space needed for model checking. Suppose G is the size of the global store, L the size of the local store per thread, and n the number of threads. If each thread is finite-state (without a stack), the naive model checking algorithm is O (nG 2. Ln+ 1) whereas assume-guarantee model checking is O (nG 2. L.(n+ L)). If each thread has a stack, the reachability problem is undecidable. However, assume-guarantee model checking terminates in time O (nG 3. L3. F) where F is the number of stack symbols.", "num_citations": "10\n", "authors": ["1741"]}
{"title": "Algorithms and methodology for scalable model checking\n", "abstract": " Model checking algorithms for the verification of reactive systems proceed by a systematic and exhaustive exploration of the system state space. They do not scale to large designs because of the state explosion problem\u2014the number of states grows exponentially with the number of components in the design. Consequently, the model checking problem is PSPACE-hard in the size of the design description. This dissertation proposes three novel techniques to combat the state explosion problem.", "num_citations": "10\n", "authors": ["1741"]}
{"title": "Lasso detection using partial-state caching\n", "abstract": " We study the problem of finding liveness violations in real-world asynchronous and distributed systems. Unlike a safety property, which asserts that certain bad states should never occur during execution, a liveness property states that a program should not remain in a bad state for an infinitely long period of time. Checking for liveness violations is essential to ensure that a system will always make progress in production. The violation of a liveness property can be demonstrated by a finite execution where the same system state repeats twice (known as lasso). However, this requires the ability to capture the state precisely, which is arguably impossible in real-world systems. For this reason, previous approaches have instead relied on demonstrating a long execution where the system remains in a bad state. However, this hampers debugging because the produced trace can be very long, making it hard to understand\u00a0\u2026", "num_citations": "9\n", "authors": ["1741"]}
{"title": "Corral: A whole-program analyzer for Boogie\n", "abstract": " This paper presents Corral, a whole-program analyzer for Boogie programs. Corral looks for a feasible execution of the program that leads to an assertion failure. The execution may span multiple procedures and may iterate loops multiple times. Unlike the Boogie verifier, Corral does not require any user annotations.", "num_citations": "9\n", "authors": ["1741"]}
{"title": "Tressa: Claiming the future\n", "abstract": " Unlike sequential programs, concurrent programs have to account for interference on shared variables. Static verification of a desired property for such programs crucially depends on precisely asserting the conditions for interference. In a static proof system, in addition to program variables, auxiliary (history) variables summarizing the past of the program execution are used in these assertions. Capable of expressing reachability only, assertions (and history variables) are not as useful in the proofs of programs using optimistic concurrency. Pessimistic implementations which allow access to shared data only after synchronization (e.g. locks) guarantee exclusivity; optimistic concurrency implementations which check for interference after shared data is accessed abandon exclusivity in favor of performance.               In this paper, we propose a new construct, tressa, to express properties, including interference\u00a0\u2026", "num_citations": "9\n", "authors": ["1741"]}
{"title": "Abstract threads\n", "abstract": " Verification of large multithreaded programs is challenging. Automatic approaches cannot overcome the state explosion in the number of threads; semi-automatic methods require expensive human time for finding global inductive invariants. Ideally, automatic methods should not deal with the composition of the original threads and a human should not supply a global invariant. We provide such an approach. In our approach, a human supplies a specification of each thread in the program. Here he has the freedom to ignore or to use the knowledge about the other threads. The checks whether specifications of threads are sound as well as whether the composition of the specifications is error-free are handed over to the off-the-shelf verifiers. We show how to apply this divide-and-conquer approach for the interleaving semantics with shared variables communication where specifications are targeted to real\u00a0\u2026", "num_citations": "7\n", "authors": ["1741"]}
{"title": "Taming concurrency: A program verification perspective\n", "abstract": " Concurrency, as a basic primitive for software construction, is more relevant today than ever before, primarily due to the multi-core revolution. General-purpose software applications must find ways to exploit concurrency explicitly in order to take advantage of multiple cores. However, experience has shown that explicitly parallel programs are difficult to get right. To deliver compelling software products in the multi-core era, we must improve our ability to reason about concurrency.", "num_citations": "7\n", "authors": ["1741"]}
{"title": "An annotation assistant for interactive debugging of programs with common synchronization idioms\n", "abstract": " This paper explores an approach to improving the practical usability of static verification tools for debugging synchronization idioms. Synchronization idioms such as mutual exclusion and readers/writer locks are widely-used to ensure atomicity of critical regions. We present an annotation assistant that automatically generates program annotations. These annotations express noninterference between program statements, ensured by the synchronization idioms, and are used to identify atomic code regions. This allows the programmer to debug the use of the idioms in the program. We start by formalizing several well-known idioms by providing an abstract semantics for each idiom. For programs that use these idioms, we require the programmer to provide a few predicates linking the idiom with its realization in terms of program variables. From these, we automatically generate a proof script that is mechanically\u00a0\u2026", "num_citations": "6\n", "authors": ["1741"]}
{"title": "Promising directions in hardware design verification\n", "abstract": " Ensuring the functional correctness of hardware early in the design cycle is crucial for both economic and methodological reasons. However, current verification techniques are inadequate for industrial designs. Formal verification techniques are exhaustive but do not scale; partial verification techniques based on simulation scale well but are not exhaustive. This paper discusses promising approaches for improving the scalability of formal verification and comprehensiveness of partial verification.", "num_citations": "6\n", "authors": ["1741"]}
{"title": "Exact and linear-time gas-cost analysis\n", "abstract": " Blockchains support execution of smart contracts: programs encoding complex transactions between distrusting parties. Due to their distributed nature, blockchains rely on third-party miners to execute and validate transactions. Miners are compensated by charging users with gas based on the execution cost of the transaction. To compute the exact gas cost, blockchains track gas cost dynamically creating its own overhead. This paper presents a static exact gas-cost analysis technique that can be employed to eliminate dynamic gas tracking. This approach presents further benefits such as providing miners with a trusted gas bound that can be verified in linear time, and eliminating out-of-gas exceptions. To handle recursion and unbounded computation, we propose a novel amortization technique that stores gas inside data structures. We have implemented our analysis technique in a tool called GasBoX that\u00a0\u2026", "num_citations": "5\n", "authors": ["1741"]}
{"title": "Refinement for structured concurrent programs\n", "abstract": " This paper presents a foundation for refining concurrent programs with structured control flow. The verification problem is decomposed into subproblems that aid interactive program development, proof reuse, and automation. The formalization in this paper is the basis of a new design and implementation of the Civl verifier.", "num_citations": "5\n", "authors": ["1741"]}
{"title": "Systematic testing of failover and recovery for distributed system components\n", "abstract": " In various embodiments, methods and systems for testing failover and recovery are provided. Systematic testing of a distributed system is performed, where the systematic testing probabilistically determines a processing order of events to effectuate system states for the plurality of state machines. An iteration of the systematic testing tests one the system states and includes sending a termination message to a state machine; receiving a termination acknowledgment message, the termination message causing the state machine to halt at the state and event of the state machine for the system state; and instantiating a recovery state machine. The recovery state machine is instantiated with a same state and same role as the halted state machine. Results of the systematic testing are verified against an expected outcome, the results being generated by running the distributed system with the instantiated recovery state\u00a0\u2026", "num_citations": "5\n", "authors": ["1741"]}
{"title": "Algorithmic verification of systems software using SMT solvers\n", "abstract": " Program verification is an undecidable problem; all program verifiers must make a tradeoff between precision and scalability. Over the past decade, a variety of scalable program analysis tools have been developed. These tools, based primarily on techniques such as type systems and dataflow analysis, scale to large and realistic programs. However, to achieve scalability they sacrifice precision, resulting in a significant number of false error reports and adversely affecting the usability of the tool.               In this talk, I will present a different approach to program verification realized in the HAVOC verifier for low-level systems software. HAVOC works directly on the operational semantics of C programs based on a physical model of memory that allows precise modeling of pointer arithmetic and other unsafe operations prevalent in low-level software. To achieve scalability, HAVOC performs modular verification\u00a0\u2026", "num_citations": "5\n", "authors": ["1741"]}
{"title": "A decision procedure for well-founded reachability\n", "abstract": " In earlier work, we introduced the logic of well-founded reachability for reasoning about linked data structures. In this paper, we present a rewriting-based decision procedure for the ground (quantifierfree) logic. We also extend the logic with restricted set constraints to allow specifications involving unbounded collections of objects. We have implemented this decision procedure within a satisfiability modulo theories (SMT) framework. Our implementation substantially improves the automation and the time taken for verifying our benchmarks compared to our earlier approach based on an incomplete axiomatization of wellfounded reachability.", "num_citations": "4\n", "authors": ["1741"]}
{"title": "Sequential optimization in the absence of global reset\n", "abstract": " We study the problem of optimizing synchronous sequential circuits. There have been previous efforts to optimize such circuits. However, all previous attempts make implicit or explicit assumptions about the design or the environment of the design. For example, it is widespread practice to assume the existence of a hardware reset line and consequently a fixed power-up state; in the absence of the same, a common premise is that the design's environment will apply an initializing sequence. We review the concept of safe replaceability which does away with these assumptions and the delay-safe replaceability notion, which is applicable when the design's output is not used for a certain number of cycles after power-up. We then develop procedures for optimizing the combinational next-state and output logic, as well as routines for reencoding the state space and removing state bits under these replaceability criteria\u00a0\u2026", "num_citations": "4\n", "authors": ["1741"]}
{"title": "Runtime Verification: Third International Conference, RV 2012, Istanbul, Turkey, September 25-28, 2012, Revised Selected Papers\n", "abstract": " This book constitutes the thoroughly refereed post-conference proceedings of the Third International Conference on Runtime Verification, RV 2012, held in Istanbul, Turkey, in September 2012. The 25 revised full papers presented together with 3 invited papers and 2 tutorials were carefully reviewed and selected from 50 submissions. The papers address a wide range of specification languages and formalisms for traces, specification mining, program instrumentation, monitor construction techniques, logging, recording, and replay, fault detection, localization, recovery and repair, program steering and adaptation, metrics and statistical information gathering, combination of static and dynamic analyses and program execution visualization.", "num_citations": "3\n", "authors": ["1741"]}
{"title": "Call invariants\n", "abstract": " Program verifiers based on first-order theorem provers model the program heap as a collection of mutable maps. In such verifiers, preserving unmodified facts about the heap across procedure calls is difficult because of scoping and modification of possibly unbounded set of heap locations. Existing approaches to deal with this problem are either too imprecise, require introducing untrusted assumptions in the verifier, or resort to unpredictable reasoning using quantifiers. In this work, we propose a new approach to solve this problem. The centerpiece of our approach is the call invariant, a new annotation for procedure calls. A call invariant allows the user to specify at a call site an assertion that is inductively preserved across an arbitrary update to a heap location modified in the call. Our approach allows us to leverage existing techniques for reasoning about call-free programs to precisely and predictably\u00a0\u2026", "num_citations": "3\n", "authors": ["1741"]}
{"title": "P: modular and safe asynchronous programming\n", "abstract": " We describe the design and implementation of P, an asynchronous event-driven programming language. P allows the programmer to specify the system as a collection of interacting state machines, which communicate with each other using events. P unifies modeling and programming into one activity for the programmer. Not only can a P program be compiled into executable code, but it can also be validated using systematic testing. P was first used to implement and validate the USB device driver stack that ships with Microsoft Windows 8 and Windows Phone. P is now also being used for the design and implementation of robotics and distributed systems inside Microsoft and in academia.", "num_citations": "2\n", "authors": ["1741"]}
{"title": "Building reliable distributed systems with P\n", "abstract": " Fault-tolerant distributed systems are difficult to get right because they must deal with concurrency and failures. Despite decades of research, current approaches for a more rigorous way of building robust distributed systems are unsatisfactory. In this paper, we present P, a new approach that makes it easier to build, specify, and test distributed systems. Our programming framework provides two important features. First, we provide a high-level language for formally specifying implementations, abstractions, and specifications of protocols. The P compiler automatically generates efficient C code from the input program. Second, we provide a tool for compositional systematic testing of a P program. Together, these attributes have the power to generate and reproduce within minutes, executions that could take months or even years to manifest in a live distributed system.", "num_citations": "2\n", "authors": ["1741"]}
{"title": "Get me here: Using verification tools to answer developer questions\n", "abstract": " While working developers often struggle to answer reachability questions (eg How can execution reach this line of code? How can execution get into this state?), the research community has created analysis and verification technologies whose purpose is systematic exploration of program execution. In this paper, we show the feasibility of using verification tools to create a query engine that automatically answers certain kinds of reachability questions. For a simple query, a developer invokes the \u201cGet Me Here\u201d command on a line of code. Our tool uses an SMT-based static analysis to search for an execution that reaches that line of code. If the line is reachable, the tool visualizes the trace using a Code Bubbles representation to show the methods invoked, the lines executed within the methods and the values of variables. The GetMeHere tool also supports more complex queries where the user specifies a start point, intermediate points, and an end point, each of which can specify a predicate over the program\u2019s state at that point. We evaluate the tool on a set of three benchmark programs. We compare the performance of the tool with professional developers answering the same reachability questions. We conclude that the tool has sufficient accuracy, robustness and performance for future testing with professional users.", "num_citations": "2\n", "authors": ["1741"]}
{"title": "Call invariants: An approach to the frame problem for procedure calls\n", "abstract": " The problem of preserving unmodified facts across a statement is often referred to as the frame problem in program verification. The problem manifests most often while reasoning about procedure calls, because of scoping and modification of possibly unbounded set of heap locations. Existing approaches to deal with the frame problem are either too imprecise, require specialized extension to the assertion logic or require introducing untrusted assumptions in the verifier. In this work, we propose a frame rule for arbitrary statements, without requiring specialized assertion logic. We show how to exploit this frame rule for procedure calls to deal with scoping. We also provide a new annotation called call invariants that allows the user to specify the frame when dealing with unbounded updates in a call. Our approach allows us to leverage existing techniques for reasoning about call-free programs to precisely reason about programs with procedure calls. We have implemented the approach and applied it to the verification of examples containing dynamic memory allocations, linked lists, and arrays. We observe that most call invariants have a fairly simple shape and discuss ways to reduce the annotation overhead.", "num_citations": "2\n", "authors": ["1741"]}
{"title": "Benchmarking and analysis of architectures for CAD applications\n", "abstract": " The SPEC benchmark system has traditionally been used for evaluating computer architectures. However, this system is too general and does not accurately reflect the performance of architectures on domain-specific applications. Moreover the CPU95 benchmark suite used in the SPEC system is compute-intensive, while many important domains of applications have memory intensive algorithms. In this work, we present a benchmarking methodology for such an application domain-CAD for VLSI design. We have created a benchmark suite consisting of CAD applications from each stage in a typical VLSI design flow. To exercise the memory organization, each application is run on a sequence of input designs of increasing size. We observed that increasing the input size causes non-monotonic variations in the performance of different machines. We simulate the caches of the benchmarked architectures to assess\u00a0\u2026", "num_citations": "2\n", "authors": ["1741"]}
{"title": "Goldilocks: Efficiently Computing the Happens-Before Relation Using Locksets, 2006. Full version available at http://www. research. microsoft. com/~ qadeer/fatesrv06\u00a0\u2026\n", "abstract": " We present a new lockset-based algorithm, Goldilocks, for precisely computing the happens-before relation and thereby detecting data-races at runtime. Dynamic race detection algorithms in the liter-ature are based on vector clocks or locksets. Vector-clock-based algo-rithms precisely compute the happens-before relation but have signifi-cantly more overhead. Previous lockset-based race detection algorithms, on the other hand, are imprecise. They check adherence to a particu-lar synchronization discipline, ie, a sufficient condition for race freedom and may generate false race warnings. Our algorithm, like vector clocks, is precise, yet it is efficient since it is purely lockset based. We have implemented our algorithm inside the Kaffe Java Virtual Ma-chine. Our implementation incorporates lazy evaluation of locksets and certain \u201cshort-circuit checks\u201d which contribute significantly to its effi-ciency. Experimental results indicate that our algorithm\u2019s overhead is much less than that of the vector-clock algorithm and is very close to our implementation of the Eraser lockset algorithm. 1", "num_citations": "2\n", "authors": ["1741"]}
{"title": "Building Reliable Cloud Services Using P#(Experience Report)\n", "abstract": " Cloud services must typically be distributed across a large number of machines in order to make use of multiple compute and storage resources. This opens the programmer to several sources of complexity such as concurrency, order of message delivery, lossy network, timeouts and failures, all of which impose a high cognitive burden. This paper presents evidence that technology inspired by formal-methods, delivered as part of a programming framework, can help address these challenges. In particular, we describe the experience of several engineering teams in Microsoft Azure that used the open-source P# programming framework to build multiple reliable cloud services. P# imposes a principled design pattern that allows writing formal specifications alongside production code that can be systematically tested, without deviating from routine engineering practices. Engineering teams that have been using P# have reported dramatically increased productivity (in time taken to push new features to production) as well as services that have been running live for months without any issues in features developed and tested with P#.", "num_citations": "1\n", "authors": ["1741"]}
{"title": "SVAuth\u2013A Single-Sign-On Integration Solution with Runtime Verification\n", "abstract": " SSO (single-sign-on) services, such as those provided by Facebook, Google and Microsoft Azure, are integrated into tens of millions of websites and cloud services, just like lock manufacturers offering locks for every home. Imagine you are a website developer, typically unfamiliar with SSO protocols. Your manager wants you to integrate a particular SSO service into a website written in a particular language (e.g., PHP, ASP.NET or Python). You are likely overwhelmed by the amount of work for finding a suitable SSO library, understanding its programming guide, and writing your code. Moreover, studies have shown that many SSO integrations on real-world websites are incorrect, and thus vulnerable to security attacks! SVAuth is an open-source project that tries to provide integration solutions for all major SSO services in all major web languages. Its correctness is ensured by a technology called self\u00a0\u2026", "num_citations": "1\n", "authors": ["1741"]}
{"title": "Self-Verifying Execution (Position Paper)\n", "abstract": " This paper proposes a notion called self-verifying execution (SVX). SVX substantially lowers several hurdles that real-world programmers face when adopting traditional program verification approaches. The current focus of SVX is to verify safety properties for programs that implement cloud-API integrations. We envision that, if adopted by real-world programmers, the SVX approach will enable a positive paradigm shift in the community toward more rigorous reasoning about security goals of cloud-API protocols.", "num_citations": "1\n", "authors": ["1741"]}
{"title": "Formal analysis techniques for reliable GPU programming: Current solutions and call to action\n", "abstract": " GPU-accelerated computing is being adopted increasingly in a number of areas, ranging from highend scientific computing to mobile and embedded computing. While GPU programs routinely provide high computational throughput in a number of areas, they also prove to be notoriously difficult to write and optimize correctly, largely due to the subtleties of GPU concurrency. This chapter discusses several issues that make GPU programming hard, and examines recent progress on rigorous methods for formal analysis of GPU software. Our key observation is that given the fastpaced advances in GPU programming, the use of rigorous specification and verification methods must be an integral part of the culture of programming and training, and not an afterthought.", "num_citations": "1\n", "authors": ["1741"]}
{"title": "A practical approach to protocol-agnostic security for multiparty online services\n", "abstract": " Serious logic vulnerabilities exist in real-world services that use security protocols such as OpenID, OAuth, and PayPal Standard. We introduce Certified Symbolic Transaction (CST), an approach for building provably secure multiparty online services. The kind of provable security that we focus on is actually an extreme form, which we call protocol-agnostic security\u2013it holds a system implementation to an end-to-end global security predicate completely independent of the adopted protocol, and thus fundamentally guards the implementation against logic flaws in the protocol and developers\u2019 misunderstandings of the protocol.We show that it is entirely practical for developers to apply CST on real-world systems. Unlike traditional verification approaches, CST invokes static verifications at runtime: it treats every multiparty transaction as a runtime process for creating a proof obligation for a generalpurpose (thus protocol-agnostic) static program verifier. We have applied CST on five commercially deployed systems, and show that, with only tens (or 100+) of lines of code changes per party, the enhanced implementations achieve protocol-agnostic security. We also stress-tested CST by building a gambling system integrating four different services, for which there is no existing protocol to follow. Our security analysis shows that 12 out of 14 logic vulnerabilities reported in the literature will be prevented by CST. Because transactions are symbolic and cacheable, CST has near-zero amortized runtime overhead. We make the source code of these systems public, which can be immediately deployed for real-world uses.", "num_citations": "1\n", "authors": ["1741"]}
{"title": "How to Shop for Free Online\n", "abstract": " Web applications increasingly integrate third-party services. The integration introduces new security challenges due to the complexity for an application to coordinate its internal states with those of the component services and the web client across the Internet. In this paper, we study the security implications of this problem to merchant websites that accept payments through third-party cashiers (eg, PayPal,", "num_citations": "1\n", "authors": ["1741"]}
{"title": "Run-time verification of optimistic concurrency\n", "abstract": " Assertion based specifications are not suitable for optimistic concurrency where concurrent operations are performed assuming no conflict among threads and correctness is cast in terms of the absence or presence of conflicts that happen in the future. What is needed is a formalism that allows expressing constraints about the future. In previous work, we introduced tressa claims and incorporated prophecy variables as one such formalism. We investigated static verification of tressa claims and how tressa claims improve reduction proofs.               In this paper, we consider tressa claims in the run-time verification of optimistic concurrency implementations. We formalize, via a simple grammar, the annotation of a program with tressa claims. Our method relieves the user from dealing with explicit manipulation of prophecy variables. We demonstrate the use of tressa claims in expressing complex properties with\u00a0\u2026", "num_citations": "1\n", "authors": ["1741"]}
{"title": "Bounded context switch analysis of mutithreaded programs with dynamic linked structures\n", "abstract": " Bounded context switch reachability analysis is an adequate and efficient approach for bug detection in multithreaded programs. We address in this paper the application of this approach to the analysis of multithreaded programs with procedure calls and dynamic linked structures. We define a program semantics based on concurrent pushdown systems with visible heaps as stack symbols.(Visible heaps are the heap parts reachable from global and local variables.) Then, based on pushdown analysis techniques, we define an algorithm allowing, given a bound on the number of context switches, and a bound on the size of visible heaps, to explore the whole configuration space reachable under these bounds.", "num_citations": "1\n", "authors": ["1741"]}