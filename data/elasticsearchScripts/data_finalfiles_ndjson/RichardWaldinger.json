{"title": "A deductive approach to program synthesis\n", "abstract": " Program synthesis is the systematic derivation of a program from a given specification. A deductive approach to program synthesis is presented for the construction of recursive programs. This approach regards program synthesis as a theorem-proving task and relies on a theorem-proving method that combines the features of transformation rules, unification, and mathematical induction within a single framework.", "num_citations": "818\n", "authors": ["1698"]}
{"title": "Achieving several goals simultaneously\n", "abstract": " In the synthesis of a plan or computer program, the problem of achieving several goals simultaneously presents special difficulties, since a plan to achieve one goal may interfere with attaining the others. This paper develops the following strategy: to achieve two goals simultaneously, develop a plan to achieve one of them and then modify that plan to achieve the second as well. A systematic program modification technique is presented to support this strategy. The technique requires the introduction of a special \u201cskeleton model\u201d to represent a changing world that can accommodate modifications in the plan. This skeleton model also provides a novel approach to the \u201cframe problem.\u201dThe strategy is illustrated by its application to three examples. Two examples involve synthesizing the following programs: interchanging the values of two variables and sorting three variables. The third entails formulating tricky blocks\u00a0\u2026", "num_citations": "505\n", "authors": ["1698"]}
{"title": "The logical basis for computer programming. Volume 1: deductive reasoning\n", "abstract": " Although \u201clogic\u201d is a standard topic in the increasing number of courses on discrete mathematics that are turning up in university departments of computer science and mathematics, published material that does a good job for students interested in computational applications of logic are rare. The problem is that texts specializing in logic aim at a primarily mathematical or philosophical audience, while books written for the new market in discrete mathematics contain a little of everything and usually no more than one or two chapters on logic. T-he disadvantage of the latter approach is that logic, more thany any other stan-dard topic in a discrete mathematics course, needs thorough foundations if it is to be understood systematically rather than as a bag of tricks for manipulating symbols. This book seems to be the first to answer the need. It is also written from a practicing computer scientist's viewpoint. The authors state\u00a0\u2026", "num_citations": "352\n", "authors": ["1698"]}
{"title": "Toward automatic program synthesis\n", "abstract": " An elementary outline of the theorem-proving approach to automatic program synthesis is given, without dwelling on technical details. The method is illustrated by the automatic construction of both recursive and iterative programs operating on natural numbers, lists, and trees. In order to construct a program satisfying certain specifications, a theorem induced by those specifications is proved, and the desired program is extracted from the proof. The same technique is applied to transform recursively defined functions into iterative programs, frequently with a major gain in efficiency. It is emphasized that in order to construct a program with loops or with recursion, the principle of mathematical induction must be applied. The relation between the version of the induction rule used and the form of the program constructed is explored in some detail.", "num_citations": "345\n", "authors": ["1698"]}
{"title": "Synthesis: dreams\u2192 programs\n", "abstract": " Deductive techniques are presented for deriving programs systematically from given specifications. The specifications express the purpose of the desired program without giving any hint of the algorithm to be employed. The basic approach is to transform the specifications repeatedly according to certain rules, until a satisfactory program is produced. The rules are guided by a number of strategic controls. These techniques have been incorporated in a running program-synthesis system, called DEDALUS.", "num_citations": "243\n", "authors": ["1698"]}
{"title": "Deductive composition of astronomical software from subroutine libraries\n", "abstract": " Automated deduction techniques are being used in a system called Amphion to derive, from graphical specifications, programs composed from a subroutine library. The system has been applied to construct software for the planning and analysis of interplanetary missions. The library for that application is a collection of subroutines written in FORTRAN-77 at JPL to perform computations in solar-system kinematics. An application domain theory has been developed that describes the procedures in a portion of the library, as well as some basic properties of solar-system astronomy, in the form of first-order axioms.             Specifications are elicited from the user through a menu-driven graphical user interface; space scientists have found the graphical notation congenial. The specification is translated into a theorem, which is proved constructively in the astronomical domain theory by an automated theorem prover\u00a0\u2026", "num_citations": "230\n", "authors": ["1698"]}
{"title": "Fundamentals of deductive program synthesis\n", "abstract": " An informal tutorial is presented for program synthesis, with an emphasis on deductive methods. According to this approach, to construct a program meeting a given specification, we prove the existence of an object meeting the specified conditions. The proof is restricted to be sufficiently constructive, in the sense that, in establishing the existence of the desired output, the proof is forced to indicate a computational method for finding it. That method becomes the basis for a program that can be extracted from the proof. The exposition is based on the deductive-tableau system, a theorem-proving framework particularly suitable for program synthesis. The System includes a non-causal resolution rule, facilities for reasoning about equality, and a well-founded induction rule.Descriptors:", "num_citations": "195\n", "authors": ["1698"]}
{"title": "PROW: A step toward automatic program writing\n", "abstract": " This paper Describes a program, called\" PROW\", which writes programs PROW accepts the specification of the program in the language of predicate calculus, decides the algorithm for the program and then produces a LISP program which is an implementation of the algorithm. Since the construction of the algorithm is obtained by formal theorem-proving techniques, the programs that PROW writes are free from logical errors and do not have to be debugged The user of PROW can make PROW write programs in languages other than LISP by modifying the part of PROW that translates an algorithm to a LISP program. Thus PROW can be modified to write programs in any language In the end of this paper, it is shown that PROW can also be used as a question-answering program", "num_citations": "177\n", "authors": ["1698"]}
{"title": "An assessment of techniques for proving program correctness\n", "abstract": " The purpose of th] s paper is to point out the sigmficant quantity of work in progress on techmques that will enable programmers to prove their programs correct This work has included: investigations m the theory of program schemas or abstract programs, development of the art of the informal or manual proof of correctness; and development of mechanical or semi-mechanical approaches to proving correctness At present, these mechanical approaches rely upon the availability of powerful theorem-provers, development of which is being actively pursued. All of these technical areas are here surveyed in detail, and recommendatmns are made concerning the direction of future research toward producing a sem~-mechamcal program verifier.", "num_citations": "175\n", "authors": ["1698"]}
{"title": "QA4: A Procedural Calculus for Intuitive Reasoning.\n", "abstract": " This report presents a language, called QA4, designed to facilitate the construction of problem-solving systems used for robot planning, theorem proving, and automatic program synthesis and verification. QA4 integrates an omega-order logic language with canonical composition, associative retrieval, and pattern matching of expressions process structure programming goal-directed searching and demons. Thus it provides many useful programming aids. More importantly, however, it provides a semantic framework for common sense reasoning about these problem domains. The interpreter for the language is extraordinarily general, and is therefore an adaptable tool for developing the specialized techniques of intuitive, symbolic reasoning used by the intelligent systems.Descriptors:", "num_citations": "143\n", "authors": ["1698"]}
{"title": "Knowledge and reasoning in program synthesis\n", "abstract": " Program synthesis is the construction of a computer program from given specifications. An automatic program synthesis system must combine reasoning and programming ability with a good deal of knowledge about the subject matter of the program. This ability and knowledge must be manifested both procedurally (by programs) and structurally (by choice of representation).We describe some of the reasoning and programming capabilities of a projected synthesis system. Special attention is paid to the introduction of conditional tests, loops, and instructions with side effects in the program being constructed. The ability to satisfy several interacting goals simultaneously proves to be important in many contexts. The modification of an already existing program to solve a somewhat different problem has been found to be a powerful approach.We illustrate these concepts with hand simulations of the synthesis of a number\u00a0\u2026", "num_citations": "130\n", "authors": ["1698"]}
{"title": "Deductive Question Answering from Multiple Resources.\n", "abstract": " Questions in natural language are answered by consulting multiple sources and inferring answers from information they provide. An automated deduction system, equipped with an axiomatic application-domain theory, serves as the coordinator for the process. Sources include data bases, Web pages, programs, and unstructured text. Answers may contain text or visualizations. Although the approach is domain-independent, many of our experiments have dealt with geographic questions.", "num_citations": "121\n", "authors": ["1698"]}
{"title": "Is \u201csometime\u201d sometimes better than \u201calways\u201d? Intermittent assertions in proving program correctness\n", "abstract": " This paper explores a technique for proving the correctness and termination of programs simultaneously. This approach, the intermittent-assertion method, involves documenting the program with assertions that must be true at some time when control passes through the corresponding point, but that need not be true every time. The method, introduced by Burstall, promises to provide a valuable complement to the more conventional methods. The intermittent-assertion method is presented with a number of examples of correctness and termination proofs. Some of these proofs are markedly simpler than their conventional counterparts. On the other hand, it is shown that a proof of correctness or termination by any of the conventional techniques can be rephrased directly as a proof using intermittent assertions. Finally, it is shown how the intermittent-assertion method can be applied to prove the validity of program\u00a0\u2026", "num_citations": "108\n", "authors": ["1698"]}
{"title": "The deductive foundations of computer programming: a one-volume version of \u201cthe logical basis for computer programming\u201d\n", "abstract": " Manna and Waldinger have written a shortened version of their two-volume textbook,< __? __Pub Fmt italic> The logical basis for computer programming< __? __Pub Fmt/italic>[1, 2]. It may come as a surprise to a logic programming\u2013oriented reader that the main examples of applications of logic to computer programming given are not knowledge representation, but simple abstract data types like lists and trees, and recursively defined operations on these types. The book starts with propositional logic in Part 1. Chapter 1 describes basic logical operations, validity, equivalence, truth tables, and well-known (and useful) propositional formulas. The chapter ends with the notions of polarity (positive and negative occurrences) and substitution (which will be useful for predicate calculus) and with examples of logical puzzles. Chapter 2 describes a Gentzen-style calculus that is presented in the form of deductive tableaus\u00a0\u2026", "num_citations": "98\n", "authors": ["1698"]}
{"title": "Deductive synthesis of the unification algorithm\n", "abstract": " The deductive approach is a formal program construction method in which the derivation of a program from a given specification is regarded as a theorem-proving task. To construct a program whose output satisfies the conditions of the specification, we prove a theorem stating the existence of such an output. The proof is restricted to be sufficiently constructive so that a program computing the desired output can be extracted directly from the proof. The program we obtain is applicative and may consist of several mutually recursive procedures. The proof constitutes a demonstration of the correctness of this program.To exhibit the full power of the deductive approach, we apply it to a nontrivial example\u2014the synthesis of a unification algorithm. Unification is the process of finding a common instance of two expressions. Algorithms to perform unification have been central to many theorem-proving systems and to some\u00a0\u2026", "num_citations": "97\n", "authors": ["1698"]}
{"title": "How to clear a block: A theory of plans\n", "abstract": " Problems in commonsense and robot planning are approached by methods adapted from program synthesis research; planning is regarded as an application of automated deduction. To support this approach, we introduce a variant of situational logic, called plan theory, in which plans are explicit objects.               A machine-oriented deductive-tableau inference system is adapted to plan theory. Equations and equivalences of the theory are built into a unification algorithm for the system. Frame axioms are built into the resolution rule.               Special attention is paid to the derivation of conditional and recursive plans. Inductive proofs of theorems for even the simplest planning problems, such as clearing a block, have been found to require challenging generalizations.", "num_citations": "92\n", "authors": ["1698"]}
{"title": "Reasoning about programs\n", "abstract": " This paper describes a theorem prover that embodies knowledge about programming constructs, such as numbers, arrays, lists, and expressions. The program can reason about these concepts and is used as part of a program verification system that uses the Floyd-Naur explication of program semantics. It is implemented in the qa4 language; the qa4 system allows many pieces of strategic knowledge, each expressed as a small program, to be coordinated so that a program stands forward when it is relevant to the problem at hand. The language allows clear, concise representation of this sort of knowledge. The qa4 system also has special facilities for dealing with commutative functions, ordering relations, and equivalence relations; these features are heavily used in this deductive system. The program interrogates the user and asks his advice in the course of a proof. Verifications have been found for Hoare's FIND\u00a0\u2026", "num_citations": "88\n", "authors": ["1698"]}
{"title": "The logic of computer programming\n", "abstract": " Techniques derived from mathematical logic promise to provide an alternative to the conventional methodology for constructing, debugging, and optimizing computer programs. Ultimately, these techniques are intended to lead to the automation of many of the facets of the programming process.", "num_citations": "86\n", "authors": ["1698"]}
{"title": "Special relations in automated deduction\n", "abstract": " Two deduction rules are introduced to give streamlined treatment to relations of special importance in an automated theorem-proving system. These rules, the relation replacement and relation matching rules, generalize to an arbitrary binary relation the paramodulation and E-resolution rules, respectively, for equality, and may operate within a nonclausal or clausal system. The new rules depend on an extension of the notion of polarity to apply to subterms as well as to subsentences, with respect to a given binary relation. The rules allow us to eliminate troublesome axioms, such as transitivity and monotonicity, from the system; proofs are shorter and more comprehensible, and the search space is correspondingly deflated.", "num_citations": "83\n", "authors": ["1698"]}
{"title": "Web agents cooperating deductively\n", "abstract": " A framework called guide is presented in which many agents can cooperate to answer a query or perform a task. Agents may be heterogeneous: they need not be intended to work together and need not share any vocabulary or representational conventions. The query can be phrased without knowing which agents are available or appropriate to carry it out. Query and agents are linked by a common application-domain theory. The query is phrased as a theorem; the answer is extracted from a proof in the theory. The answer may depend on background knowledge implied by the theory. The guide\u2019s approach is domain-independent but is illustrated by answering questions involving maps and directories.", "num_citations": "82\n", "authors": ["1698"]}
{"title": "Knowledge-intensive query processing\n", "abstract": " Innovative query interfaces to knowledge and database systems must go beyond simply returning the requested information. They must be capable of producing intentional answers when a description improves the understanding of an answer [Mot94], producing conditional answers when no one answer matches the conditions of a query, and using ontological information in processing a query. They should be able to call upon stand-alone reasoning modules that are most suitable for a given query. When answering a question involves reasoning beyond a simple lookup, the system must be able to explain the answer to the user. We are building a question answering system with these objectives. The heart of the system is a knowledge base (KB) and a collection of reasoning methods. The KB is being constructed by a combination of manual and semiautomatic methods. The reasoning methods include conventional database query processing, frame-based reasoning, and full first-order theorem proving. The performance of this system will be tested on the Crisis Management Benchmark (CMB), which defines a collection of queries of interest to a crisis analyst.", "num_citations": "76\n", "authors": ["1698"]}
{"title": "A guide to SNARK\n", "abstract": " Snark, SRIs New Automated Reasoning Kit, is a theorem prover intended for applications in artificial intelligence and software engineering. Snark is geared toward dealing with large sets of assertions it can be specialized with strategic controls that tune its performance and it has facilities for integrating special-purpose reasoning procedures with general-purpose inference. Snark has been used as the reasoning component of SRIs High Performance Knowledge Base HPKB system, which deduces answers to questions based on large repositories of information. It constitutes the deductive core of the NASA Amphion system, which composes software from components to meet users specifications, eg, to perform computations in planetary astronomy. Snark has also been connected to Kestrels specware environment for software development.Descriptors:", "num_citations": "74\n", "authors": ["1698"]}
{"title": "Consistency checking of semantic web ontologies\n", "abstract": " Ensuring that ontologies are consistent is an important part of ontology development and testing. This is especially important when autonomous software agents are to use ontologies in their reasoning. Reasoning with inconsistent ontologies may lead to erroneous conclusions. In this paper we introduce the ConsVISor tool for consistency checking of ontologies. This tool is a consistency checker for formal ontologies, including both traditional data modeling languages and the more recent ontology languages. ConsVISor checks consistency by verifying axioms. ConsVISor is part of the UBOT toolkit that uses a variety of techniques such as theorem proving and logic programming. Some examples of the use of these tools are given.", "num_citations": "73\n", "authors": ["1698"]}
{"title": "Accessing Information and Services on the DAML-Enabled Web.\n", "abstract": " The DARPA Agent Markup Language (DAML) program aims to allow one to mark up web pages to indicate the meaning of their content; it is intended that the results delivered by a DAML-enabled browser will more closely match the intentions of the user than is possible with today\u2019s syntactically oriented search engines. In this paper we present our vision of a DAML-enabled search architecture. We present a set of queries of increasing complexity that should be answered efficiently in a Semantic Web. We describe several scenarios illustrating how queries are processed, identifying the main software components necessary to facilitate the search. We examine the issue of inference in search, and we address how to characterize procedures and services in DAML, enabling a DAML query language to find web sites with specified capabilities.", "num_citations": "58\n", "authors": ["1698"]}
{"title": "Progress report on program-understanding systems\n", "abstract": " This progress report covers the first year and one half of work by our automatic-programming research group at the Stanford Artificial Intelligence Laboratory. Major emphasis has been placed on methods of program specification, codification of programming knowledge, and implementation of pilot systems for program writing and understanding. List processing has been used as the general problem domain for this work.", "num_citations": "45\n", "authors": ["1698"]}
{"title": "Systems and methods for natural language processing using machine-oriented inference rules\n", "abstract": " Systems and methods are presented for performing natural language processing and reasoning. In some embodiments, a computer-implemented methods is presented. The method may include accessing a natural language query from a user, parsing the natural language query into a computer-interpretable semantic representation, converting the semantic representation into a computer-interpretable logical syntax, determining a solution to the computer-interpretable logical syntax using a reasoning engine and at least one data source, and outputting an answer to the natural language query using the solution to the computer-interpretable logical syntax.", "num_citations": "42\n", "authors": ["1698"]}
{"title": "Constructing programs automatically using theorem proving.\n", "abstract": " The paper describes a method by which programs may be constructed mechanically. The problem of writing a program is transformed into a theorem proving task. The specifications for the program are used to construct a theorem, the theorem is proved, and the program is derived from the proof of the theorem. The specifications for the program are described as a relation between the input and output variables expressed in predicate calculus. Mechanical theorem proving techniques are used to prove the existence of output variables satisfying the specifications. Existence is proven constructively, so that embedded in the proof is a method to compute the desired output values. A program is extracted from the proof. Restrictions to Robinsons resolution principle are proposed so that only constructive proofs are produced. A proof of the soundness of the method is presented. It is also shown that programs for the entire class of recursive functions may be written by automatic program writing. Thus nothing is lost by restricting application of the resolution principle. An implementation of the method which writes LISP programs is described. AuthorDescriptors:", "num_citations": "39\n", "authors": ["1698"]}
{"title": "TABLOG: The deductive-tableau programming language\n", "abstract": " TABLOG (Tableau Logic Programming Language) is a language combining functional and logic programming using first-order (quantifier-free) predicate logic with equality. TABLOG incorporates advantages of LISP and PROLOG.", "num_citations": "33\n", "authors": ["1698"]}
{"title": "Problematic features of programming languages: a situational-calculus approach\n", "abstract": " Certain features of programming languages, such as data structure operations and procedure call mechanisms, have been found to resist formalization by conventional program verification techniques. An alternate approach is presented, based on a \u201csituational calculus,\u201d which makes explicit reference to the states of a computation. For each state, a distinction is drawn between an expression, its value, and the location of the value.               Within this conceptual framework, the features of a programming language can be described axiomatically. Programs in the language can then be synthesized, executed, verified, or transformed by performing deductions in this axiomatic system. Properties of entire classes of programs, and of programming languages, can also be expressed and proved in this way. The approach is amenable to machine implementation.               In a situational-calculus formalism it is\u00a0\u2026", "num_citations": "33\n", "authors": ["1698"]}
{"title": "Proving properties of rule-based systems\n", "abstract": " Rule-based systems are being applied to tasks of increasing responsibility. Deductive methods are being applied to their validation, to detect flaws in these systems and to enable us to use them with more confidence.         Each system of rules is encoded as a set of axioms that define the system theory. The operation of the rule language and information about the subject domain are also described in the system theory. Validation tasks, such as establishing termination, unreachability, or consistency, or verifying properties of the system, are all phrased as conjectures. If we succeed in establishing the validity of the conjecture in the system theory, we have carried out the corresponding validation task.         If the proof is restricted to be sufficiently constructive, we may extract from it information other than a simple yes/no answer. For example, we may obtain a description of a situation in which an error or anomaly may\u00a0\u2026", "num_citations": "32\n", "authors": ["1698"]}
{"title": "An improved program-synthesizing algorithm and its correctness\n", "abstract": " An improved program-synthesizing algorithm based on the algorithm proposed by Waldinger and Lee in 1969 is given. In the old algorithm, the program-synthesizing problem is translated into a theorem-proving problem, and a program is obtained by analyzing a proof. For the improved algorithm, the analysis is not necessary, and a program is obtained as soon as the proof is completed. This is achieved by using a modified variable tracing mechanism invented by Green in 1969. The correctness of the improved algorithm is also proved; i.e. the program thus obtained always satisfies the specification.", "num_citations": "32\n", "authors": ["1698"]}
{"title": "A language for writing problem-solving programs\n", "abstract": " This paper describes a language for constructing problem-solving programs. The language can manipulate several data structures, including ordered and unordered sets. Pattern matching facilities may be used in various ways, including the binding of variables. Implicit backtracking facilitates the compact representation of search procedures. Expressions are treated analogously to atoms in LISP. A context device is used to implement variable bindings, to effect conditional proofs, and to solve the frame problem in robot planning.Descriptors:", "num_citations": "32\n", "authors": ["1698"]}
{"title": "The origin of a binary-search paradigm\n", "abstract": " In a binary-search algorithm for the computation of a numerical function, the interval in which the desired output is sought is divided in half at each iteration. The paper considers how such algorithms might be derived from their specifications by an automatic system for program synthesis. The derivation of the binary-search concept has been found to be surprisingly straight-forward. The programs obtained, though reasonably simple and efficient, are quite different from those that would have been constructed by informal means.", "num_citations": "31\n", "authors": ["1698"]}
{"title": "A theory of plans\n", "abstract": " A THEORY OF PLANS Zohar Manna Stanford University Weizmann Institute Richard Waldinger SRI International ABSTRACT Problems in commonsense and robot planning are approached by methods adapted from program synthesis research; planning is regarded as an application of automated deduction. To support this approach, we introduce a variant of situational logic, called plan theory, in which plans are explicit objects. A machine-oriented deductive-tableau inference system is adapted to plan theory. Equations and equivalences of the theory are built into a unification algorithm for the system. Special attention is paid to the derivation of conditional and recursive plans. Inductive proofs of theorems for even the simplest planning problems, such as clearing a block, have been found to require challenging generalizations. II J2 Manna and Waldinger 1. INTRODUCTION For many years, the authors have been\u00a0\u2026", "num_citations": "31\n", "authors": ["1698"]}
{"title": "Ontology Construction Tool Kit\n", "abstract": " The goal of this project was to enable knowledge engineers to construct knowledge bases KBs faster. To achieve this goal, we investigated two techniques knowledge reuse and axiom templates. The results were demonstrated by developing a question-answering system for the crisis management challenge problem CMCP. The solution of the CMCP required addressing problems broader than just knowledge reuse and axiom templates. The technical issues addressed in the process can be broadly classified into two categories knowledge base content development and knowledge server development. We developed a geo-political KB for the CMCP. Specifically, we represented knowledge about international actions, terrorist groups, terrorist events, military capabilities, escalation and de-escalation of conflict, threats, and so forth. In the process of encoding the domain knowledge, we developed and adapted techniques for representing temporal knowledge and qualitative influences, and identified principles for taxonomy design. The knowledge server development focused on extending several of our existing tools. Our theorem prover SNARK Stickel, Waldinger et al. June 1994 was extended to accept Knowledge Interchange Format KIF and a subset of the OKBC knowledge model Chaudhri, Farquhar et al. 1998, to reason efficiently with Meta classes and temporal knowledge, and to produce explanations in HTML. We developed a worldwide web WWW interface to the GKB-Editor, which is a graphical tool for browsing and editing KBs. We developed tools for translating, loading, and saving ontologies encoded in a subset of KIF. The ontologies\u00a0\u2026", "num_citations": "27\n", "authors": ["1698"]}
{"title": "The QA4 language applied to robot planning\n", "abstract": " This paper introduces an implemented version of a problem-solving language called QA4 (Question Answerer 4) and illustrates the application of that language to some simple robot problems. This application is especially appropriate, because the QA4 language has features that are recognized as useful for problemsolving programs; these features include built-in backtracking, parallel processing, pattern matching, and set manipulation. Expressions are put into a canonical form and stored uniquely, so that they can have property lists. A context mechanism is provided, so that the same expression can be given different properties in different contexts. The QA4 interpreter is implemented in LISP and can interface with LISP programs. The language is especially intended to be useful for research leading to program verification, modification, and synthesis, to semantically oriented theorem proving, and to various forms\u00a0\u2026", "num_citations": "25\n", "authors": ["1698"]}
{"title": "Proving authentication properties in the Protocol Derivation Assistant\n", "abstract": " We present a formal framework for incremental reasoning about authentication protocols, supported by the Protocol Derivation Assistant (Pda). A salient feature of our derivational approach is that proofs of properties of complex protocols are factored into simpler proofs of properties of their components, combined with proofs that the relevant refinement and composition operations preserve the proven properties or transform them in the desired way.In the present paper, we introduce an axiomatic theory of authentication suitable for the automatic proof of authentication properties. We describe a proof of the authentication property of a simple protocol, as derived in Pda, for which the the proof obligations have been automatically generated and discharged. Producing the proof forced us to spell out previously unrecognized assumptions, on which the correctness of the protocol depends.", "num_citations": "23\n", "authors": ["1698"]}
{"title": "Qlisp: a language for the interactive development of complex systems\n", "abstract": " This paper presents a functional overview of the features and capabilities of QLISP, one of the newest of the current generation of very high level languages developed for use in Artificial Intelligence (AI) research.", "num_citations": "23\n", "authors": ["1698"]}
{"title": "A transaction logic for database specification\n", "abstract": " We introduce a logical formalism for the specification of the dynamic behavior of databases. The evolution of databases is characterized by both the dynamic integrity constraints which describe the properties of state transitions and the transactions whose executions lead to state transitions. Our formalism is based on a variant of first-order situational logic in which the states of computations are explicit objects. Integrity constraints and transactions are uniformly specifiable as expressions in our language. We also point out the application of the formalism to the verification and synthesis of transactions.", "num_citations": "22\n", "authors": ["1698"]}
{"title": "The automatic synthesis of recursive programs\n", "abstract": " We describe a deductive technique for the automatic construction of recursive programs to meet given input-output specifications. These specifications express what conditions the output of the desired program is expected to satisfy. The deductive technique involves transforming the specifications by a collection of rules, summoned by pattern-directed function invocation. Some of these transformation rules express the semantics of the subject domain; others represent more general programming techniques. The rules that introduce conditional expressions and recursive calls into the program are discussed in some detail. The deductive techniques described are embedded in a running system called SYNSYS. This system accepts specifications expressed in high-level descriptive language and attempts to transform them into a corresponding LISP program. The transformation rules are expressed in the QLISP\u00a0\u2026", "num_citations": "22\n", "authors": ["1698"]}
{"title": "Deductive biocomputing\n", "abstract": " BackgroundAs biologists increasingly rely upon computational tools, it is imperative that they be able to appropriately apply these tools and clearly understand the methods the tools employ. Such tools must have access to all the relevant data and knowledge and, in some sense, \u201cunderstand\u201d biology so that they can serve biologists' goals appropriately and \u201cexplain\u201d in biological terms how results are computed.Methodology/Principal FindingsWe describe a deduction-based approach to biocomputation that semiautomatically combines knowledge, software, and data to satisfy goals expressed in a high-level biological language. The approach is implemented in an open source web-based biocomputing platform called BioDeducta, which combines SRI's SNARK theorem prover with the BioBike interactive integrated knowledge base. The biologist/user expresses a high-level conjecture, representing a biocomputational goal query, without indicating how this goal is to be achieved. A subject domain theory, represented in SNARK's logical language, transforms the terms in the conjecture into capabilities of the available resources and the background knowledge necessary to link them together. If the subject domain theory enables SNARK to prove the conjecture\u2014that is, to find paths between the goal and BioBike resources\u2014then the resulting proofs represent solutions to the conjecture/query. Such proofs provide provenance for each result, indicating in detail how they were computed. We demonstrate BioDeducta by showing how it can approximately replicate a previously published analysis of genes involved in the adaptation of cyanobacteria to\u00a0\u2026", "num_citations": "21\n", "authors": ["1698"]}
{"title": "Using prior knowledge: Problems and solutions\n", "abstract": " Encoding knowledge is time consuming and expensive. A possible solution to reduce the cost of developing a new knowledge base (KB) is to reuse existing knowledge. Previous work addressing this problem has focused on standards for representing, exchanging, and accessing knowledge (Genesereth and Fikes 1992),(Chaudhri et al. 1998), and on creating large repositories of knowledge (Lenat and Guha 1990). Results on the level of reuse achievable have been reported (Cohen et al. 1999). In this paper, we focus on the process of reuse and report a case study on constructing a KB by reusing existing knowledge. The reuse process involved the following steps: translation, comprehension, slicing, reformulation, and merging. We discuss technical problems encountered at each of these steps and explain how we solved them.", "num_citations": "21\n", "authors": ["1698"]}
{"title": "The Deductive Synthesis of Imperative LISP Programs.\n", "abstract": " A framework is described for the automatic synthesis of imperative programs, which may alter data structures and produce destructive side effects as part of their intended behavior. A program meeting a given specification is extracted from the proof of a theorem in a variant of situational logic, in which the states of a computation are explicit objects. As an example, an in-place reverse program has been derived in an imperative LISP, which includes assignment and destructive list operations (rplacu and rplacd).", "num_citations": "20\n", "authors": ["1698"]}
{"title": "How to clear a block: Plan formation in situational logic\n", "abstract": " Problems in robot planning are approached by proving theorems in a new formulation of situational logic. A machine-oriented deductive-tableau inference system is adapted to this logic, with special attention being paid to the derivation of conditional and recursive plans. Equations and equivalences of the situational logic have been built into a unification algorithm for the system. Inductive proofs of theorems for even the simplest planning problems have been found to require challenging generalizations.", "num_citations": "20\n", "authors": ["1698"]}
{"title": "Special relations in program-synthetic deduction\n", "abstract": " Program synthesis is the automated derivation of a computer program from a given specification. In the deductive approach, the synthesis of a program is regarded as a theorem-proving problem the desired program is constructed as a by-product of the proof. This paper presents a formal deduction system for program synthesis, with special features for handling equality, the equivalence connective, and ordering relations. In proving theorems involving the equivalence connective, it is awkward to remove all the quantifiers before attempting the proof. The system therefore deals with partially skolemized sentences, in which some of the quantifiers may be left in place. A rule is provided for removing individual quantifiers when required after the proof is under way. The system is also nonclausal ie, the theorem does not need to be put into conjunctive normal form. The equivalence, implication, and other connectives may be left intact. AuthorDescriptors:", "num_citations": "19\n", "authors": ["1698"]}
{"title": "Fundamentals of deductive program synthesis\n", "abstract": " This is an introduction to program synthesis, the derivation of a program to meet a given specification. It focuses on the deductive approach, in which the derivation task is regarded as a problem of proving a mathematical theorem.", "num_citations": "16\n", "authors": ["1698"]}
{"title": "TABLOG: A new approach to logic programming\n", "abstract": " TABLOG is a programming language based on first-order predicate logic with equality that combines relational and functional programming. In addition to featuring both the advantages of functional notation and the power of unification as a binding mechanism, TABLOG also supports a more general subset of standard first-order logic than PROLOG and most other logic-programming languages. The Manna-Waldinger deductive-tableau proof system is employed as an interpreter for TABLOG in the same way that PROLOG uses a resolution proof system. Unification is used by TABLOG to match a query with a line in the program and to bind arguments. The basic rules of deduction used for computing are a nonclausal resolution rule that generalizes classical resolution to arbitrary first-order sentences and an equality rule that is a generalization of narrowing and paramodulation. In this article we described the basic features of TABLOG and its implemented sequential interpreter, and we discuss some of its properties. We give examples to demonstrate when TABLOG is better than a functional language like LISP and when it is better than a relational language like PROLOG.Descriptors:", "num_citations": "16\n", "authors": ["1698"]}
{"title": "DEDALUS-The DEDuctive ALgorithm Ur-Synthesizer.\n", "abstract": " Programsynthesis is theautomatic construction ofprograms to meet givenspecifications. These specificationsconstitute a high-level description of the desired program which expresses the purpose of the program, without indicating the methodby which that purpose is to be achieved. The specifications are expressed in terms of many con-structs which are endemic to theparticular subject domain of the desired program (eg, numbers, sets, lists). Because these constructs are only intended to describe the purpose of the program and need not be computed, they can be of amuch higherlevel thantheconstructs of anyprogramming language (eg, theycan include logicalquantifiers, set con-structors, and other noncomputableoperations). The spec-ification language can correspond closely with the concepts a programmeractually uses in thinking about the problem. The techniques we are developingare independentof the choice of a target programming language. The particular language we use in our examples and in our experimental system is asimple LISP-like languagecontainingonlybasic numerical and list-processing operations, conditional expressions, and recursion. In considering the formation of programs with side effects, we extend the language to include assignments to variables, array elements, and other data-structure components. Cur basic approach is to transform the specifications repeatedly according to certain rules; each rule replaces one segment of a program description by another, equivalent, segment. The process continues until a description is ob-that is entirely in terms of the primitive constructs of the target language; this\u00a0\u2026", "num_citations": "14\n", "authors": ["1698"]}
{"title": "Whatever happened to deductive question answering?\n", "abstract": " Deductive question answering, the extraction of answers to questions from machine-discovered proofs, is the poor cousin of program synthesis. It involves much of the same technology\u2013theorem proving and answer extraction\u2013but the bar is lower. Instead of constructing a general program to meet a given specification for any input\u2013the program synthesis problem\u2013we need only construct answers for specific inputs; question answering is a special case of program synthesis. Since the input is known, there is less emphasis on case analysis (to construct conditional programs) and mathematical induction (to construct looping constructs), those bugbears of theorem proving that are central to general program synthesis. Program synthesis as a byproduct of automatic theorem proving has been a largely dormant field in recent years, while those seeking to apply theorem proving have been scurrying to find smaller\u00a0\u2026", "num_citations": "11\n", "authors": ["1698"]}
{"title": "The synthesis of structure-changing programs\n", "abstract": " Deductive techniques are presented for deriving programs systematically from given specifications. The specifications express the purpose of the desired program without giving any hint of the algorithm to be employed. The desired program is intended to achieve this purpose by means of such low-level primitives as assignment statements, the conditional statements, and recursion. The basic approach is to transform the specifications repeatedly according to certain rules, until a satisfactory program is produced. The rules are guided by a number of strategic controls.", "num_citations": "11\n", "authors": ["1698"]}
{"title": "Monotonicity properties in automated deduction\n", "abstract": " Monotonicity properties in automated deduction | Artificial intelligence and mathematical theory of computation ACM Digital Library home ACM home Google, Inc. (search) Advanced Search Browse About Sign in Register Advanced Search Journals Magazines Proceedings Books SIGs Conferences People More Search ACM Digital Library SearchSearch Advanced Search Browse Browse Digital Library Collections More HomeBrowse by TitleBooksArtificial intelligence and mathematical theory of computation: papers in honor of John McCarthyMonotonicity properties in automated deduction chapter Monotonicity properties in automated deduction Share on Authors: Zohar Manna profile image Zohar Manna View Profile , Mark E. Stickel profile image Mark Stickel View Profile , Richard J Waldinger profile image Richard Waldinger View Profile Authors Info & Affiliations Publication: Artificial intelligence and mathematical \u2026", "num_citations": "10\n", "authors": ["1698"]}
{"title": "Towards a theory of simultaneous actions\n", "abstract": " We will lay down a model of concurrency for planning problems. The model will be expressive enough for representing real simultaneity of primitive actions without getting too complicated for the plan synthesis process. The model will be described in detail and its use in respect to the synthesis of terminating plans is demonstrated in an example.", "num_citations": "10\n", "authors": ["1698"]}
{"title": "Deductive synthesis of the unification algorithm\n", "abstract": " The deductive approach is a formal program-construction method in which the derivation of a program from a given specification is regarded as a theoremproving ask. To construct a program whose output satisfies the conditions of the specification, we prove a theorem stating the existence of such an output. The proof is restricted to be sufficiently constructive so that a program computing the desired output can be extracted directly from the proof. The program we obtain is applicative and may consist of several mutually recursive procedures. The proof constitutes a demonstration of the correctness of this program.             To exhibit the full power of the deductive approach, we apply it to a nontrivial example \u2014 the synthesis of a unification algorithm. Unification is the process of finding a common instance of two expressions. Algorithms to perform unification have been central to many theorem-proving systems\u00a0\u2026", "num_citations": "10\n", "authors": ["1698"]}
{"title": "A First-Order Logic Semantics for Semantic Web Markup Languages\n", "abstract": " We present a case study in providing a declarative semantics for three semantic markup languages being developed as ontology representation languages for the Semantic Web by specifying for each language an equivalence-preserving translation into first-order logic (FOL). The translation includes for each language a set of axioms that are included in the resulting FOL theories and that thereby constrain the possible interpretations of those theories. An important advantage of this form of semantics specification is that the axioms can be tested for logical inconsistencies or redundancies, and for whether they entail intended consequences. We describe such tests that we have made on these axioms using existing FOL reasoners. Also, we include a set of theorems that express intended consequences of the axioms and that a FOL reasoner can use to facilitate finding inconsistencies in and answering queries from Semantic Web ontologies.", "num_citations": "9\n", "authors": ["1698"]}
{"title": "The special-relation rules are incomplete\n", "abstract": " The special-relation rules give accelerated treatment to transitivity, substitutivity, and other axioms classed as \u201cmonotonicity properties\u201d. These rules extend paramodulation and other equality rules to relations other than equality. In this paper, it is established that these rules are all logically incomplete. The incompleteness of the negative paramodulation rule of Wos and McCune is also demonstrated.", "num_citations": "9\n", "authors": ["1698"]}
{"title": "Accessing structured health information through English queries and automatic deduction\n", "abstract": " While much health data is available online, patients who are not technically astute may be unable to access it because they may not know the relevant resources, they may be reluctant to confront an unfamiliar interface, and they may not know how to compose an answer from information provided by multiple heterogeneous resources. We describe ongoing research in using natural English text queries and automated deduction to obtain answers based on multiple structured data sources in a specific subject domain. Each English query is transformed using natural language technology into an unambiguous logical form; this is submitted to a theorem prover that operates over an axiomatic theory of the subject domain. Symbols in the theory are linked to relations in external databases known to the system. An answer is obtained from the proof, along with an English language explanation of how the answer was obtained. Answers need not be present explicitly in any of the databases, but rather may be deduced or computed from the information they provide. Although English is highly ambiguous, the natural language technology is informed by subject domain knowledge, so that readings of the query that are syntactically plausible but semantically impossible are discarded. When a question is still ambiguous, the system can interrogate the patient to determine what meaning was intended. Additional queries can clarify earlier ones or ask questions referring to previously computed answers. We describe a prototype system, Quadri, which answers questions about HIV treatment using the Stanford HIV Drug Resistance Database and other resources\u00a0\u2026", "num_citations": "8\n", "authors": ["1698"]}
{"title": "Pointing to places in a deductive geospatial theory\n", "abstract": " Issues in the description of places are discussed in the context of a logical geospatial theory. This theory lies at the core of the system GeoLogica, which deduces answers to geographical questions based on knowledge provided by multiple agents. Many questions cannot be answered from information in a single geographical source often the answer must be deduced from information provided by several sources. It may not be obvious which sources to consult. Because multiple sources seldom agree on conventions of nomenclature or notation, it becomes a problem to determine what place corresponds to a particular description. The same name may apply to many places, and the same place may have many names. In the system GeoLogica, the coordination between multiple information sources is carried out by an automated deduction system, or theorem prover, that operates in a formal geospatial theory. GeoLogica differs from a search engine in that, instead of merely finding a list of documents with vocabulary that matches the question, it attempts to understand the question and provide an answer.Descriptors:", "num_citations": "8\n", "authors": ["1698"]}
{"title": "English access to structured data\n", "abstract": " We present work on using a domain model to guide text interpretation, in the context of a project that aims to interpret English questions as a sequence of queries to be answered from structured databases. We adapt a broad-coverage and ambiguity-enabled natural language processing (NLP) system to produce domain-specific logical forms, using knowledge of the domain to zero in on the appropriate interpretation. The vocabulary of the logical forms is drawn from a domain theory that constitutes a higher-level abstraction of the contents of a set of related databases. The meanings of the terms are encoded in an axiomatic domain theory. To retrieve information from the databases, the logical forms must be instantiated by values constructed from fields in the database. The axiomatic domain theory is interpreted by the first-order theorem prover SNARK to identify the groundings, and then retrieve the values through\u00a0\u2026", "num_citations": "7\n", "authors": ["1698"]}
{"title": "Natural Language Access to Data: It Takes Common Sense!\n", "abstract": " Commonsense reasoning proves to be an essential tool for natural-language access to data. In a deductive approach to this problem, language processing technology translates English queries into a first-order logical form, which is regarded as a conjecture to be established by a theorem prover. Subject domain knowledge is encoded in an axiomatic theory equipped with links to appropriate databases. Commonsense reasoning is necessary to disambiguate the query, to connect the query with relevant tables in the databases, to deal with logical relationships in the query, and to achieve interoperability between disparate databases. This is illustrated with examples from a proof-of-concept system called Quest, which deals with queries over business enterprise data for an industrial QA system.", "num_citations": "6\n", "authors": ["1698"]}
{"title": "Deducing answers to English questions from structured data\n", "abstract": " We describe ongoing research using natural English text queries as an intelligent interface for inferring answers from structured data in a specific domain. Users can express queries whose answers need to be deduced from data in different databases, without knowing the structures of those databases nor even the existence of the sources used. Users can pose queries incrementally, elaborating on an initial query, and ask follow-up questions based on answers to earlier queries.", "num_citations": "6\n", "authors": ["1698"]}
{"title": "Deductive discovery and composition of resources\n", "abstract": " We consider the problem of answering a query, where the answer is not provided explicitly by any one resource, but has to be deduced from information provided by many resources; where the resources include both data and software; and where the resources are heterogeneous and not designed to work together. We adopt a deductive approach to this problem, in which the discovery of the appropriate resources and their composition is performed by a theorem prover. The techniques are domain-independent and are applied here to problems in molecular biology.", "num_citations": "6\n", "authors": ["1698"]}
{"title": "Annotation-based deduction in temporal logic\n", "abstract": " This paper presents a deductive system for predicate temporal logic with induction.             Representing temporal operators by first-order expressions enables temporal deduction to use the already developed techniques of first-order deduction. But when translating from temporal logic to first-order logic is done indiscriminately, the ensuing quantifications and comparisons of time expressions encumber formulas, hindering deduction. So in the deductive system presented here, translation occurs more carefully, via reification rules. These rules paraphrase selected temporal formulas as nontemporal first-order formulas with time annotations. This time reification process suppresses quantifications (the process is analogous to quantifier skolemization) and uses addition instead of complicated combinations of comparisons. Some ordering conditions on arithmetic expressions can arise, but such are handled\u00a0\u2026", "num_citations": "5\n", "authors": ["1698"]}
{"title": "On Program Synthesis and Program Verification\n", "abstract": " Certain similarities between program verification and program synthesis are pointed out. The analogy is illustrated using a bubble-sort program. Recent work has shewn that automatic deductive methods may be applied to the problems of program verification 1 and program synthesis 2. As it turns out, these techniques are closely related. We demonstrate this relation using a particular program.Descriptors:", "num_citations": "5\n", "authors": ["1698"]}
{"title": "Preserving confidentiality during the migration of virtual SDN topologies: A formal approach\n", "abstract": " Network virtualization provides a flexible solution to reduce costs, share network resources and improve recovery time upon failure. An important part of virtual network management consists in migrating them in order to optimize resource allocation and react to link failures. However, the migration process might entail the loss of security properties in the virtual network, such as confidentiality. In this paper, we present the first approach combining formal models and virtualization to prove confidentiality preservation during the migration process. We describe the network environment, the migration process and the confidentiality with a set of logical predicates that will be used by SNARK to obtain the formal proof of the preservation. We validate our theoretical approach by exhibiting confidentiality violation detection on an illustrative use case.", "num_citations": "4\n", "authors": ["1698"]}
{"title": "Using deduction to choreograph multiple data sources\n", "abstract": " Automatic theorem proving is employed to coordinate multiple data and knowledge sources. Sources are related to a central axiomatic theory so that their interaction can be inferred. The method is applied to human language question answering in geography and earth science.", "num_citations": "4\n", "authors": ["1698"]}
{"title": "Towards deductive synthesis of dataflow networks\n", "abstract": " We present a method for deductive synthesis of deterministic dataflow networks. A network is specified by a relation between sequences of input values and sequences of output values. From the specification, an applicative program in the form of recursive equations is derived as a side-effect of proving the specification as a theorem. The recursive equations can subsequently be transformed into a dataflow network. We also indicate how the recursive equations can be transformed into a dataflow language, Lucid. The theorem-proving part of the method uses the deductive-tableau techniques of (MWa). processes, and ingenious theorem-proving techniques are required. Our synthesis method therefore consists of two stages. The first stage, the deductive-synthesis stage, starts from a specification of the network. Using the deductivetableau techniques of (MWa), a system of recursive equations is synthesized. This system can be regarded as an applicative program that satisfies the specification for the network, but it does not directly represent any structure or parallelism of a network. In the second stage, the system of recursive equations is transformed into a dataflow network. The deductive-tableau techniques are oriented towards synthesis of terminating programs. We therefore restrict our method to networks that do not diverge, ie, if the network is given a finite amount of input, it produces only a finite amount of output.In section 2 we present our model of dataflow networks. Section 3 contains an informal outline of both stages of our synthesis method. The deductive-synthesis stage is described in more detail in section 4. In section 5 it is illustrated\u00a0\u2026", "num_citations": "4\n", "authors": ["1698"]}
{"title": "Structured Programming with Recursion.\n", "abstract": " Q) 2J7. 4Ol and MCS7643655, 6, Me Office of Naval Research soider Contracts NO0O]~ Yi t. 0687 and N00014. 75. C. 0816, b~ the Advanced Research Pr* cts Agents of the Dqsrnnssst of I) ef. ni. under Contract MDA9-76-C. 0206, and 6, a erant from the United St\u00e0tss-Isracl Binatlonal Science Foundat BSFTA. views and conclusions contained In this document are thos. o\u2019f the authors and should nat b inleT pitted as nc ss~ TU~ upv. unUng. the off d~ 1 policies, eUher. xpvess. d or Implied of Stamford Urdv. rslt,, SRI International, or an, agenc, of the US Gowrnsw~ st.", "num_citations": "4\n", "authors": ["1698"]}
{"title": "Studies in automatic programming logic\n", "abstract": " Studies in Automatic Programming Logic | Guide books ACM Digital Library home ACM home Google, Inc. (search) Advanced Search Browse About Sign in Register Advanced Search Journals Magazines Proceedings Books SIGs Conferences People More Search ACM Digital Library SearchSearch Advanced Search Browse Browse Digital Library Collections More HomeBrowse by TitleBooksStudies in Automatic Programming Logic ABSTRACT No abstract available. Comments Login options Check if you have access through your login credentials or your institution to get full access on this article. Sign in Full Access Get this Publication Information Contributors Published in Guide books cover image Studies in Automatic Programming Logic January 1977 192 pages ISBN:0444002243 Authors: Zohar Manna profile image Zohar Manna, Richard J Waldinger profile image Richard Waldinger Copyright \u00a9 1977 \u2026", "num_citations": "4\n", "authors": ["1698"]}
{"title": "Knowledge and reasoning in program synthesis\n", "abstract": " Prograin synthesis is the construction of a computer program from given specifications. An automatic program synthesis system must combine reasoning and programming ability with a good deal of knowledge about the subject matter of the program. This ability and knowledge must be manifested both procedurally (by programs) and structurally (by choice of representation). We describe some of the reasoning and programming capabilities of a projected synthesis system. Special attention is paid to the introduction of conditional tests, loops, and Instructions with side effects in the program being constructed. The ability to satisfy several interacting goals simultaneously proves to be important in many contexts. The modfication of an already existing program to solve a somewhat different problem has been found to be a powerful approach. Some of these techniques have already been implemented, some are in the\u00a0\u2026", "num_citations": "4\n", "authors": ["1698"]}
{"title": "QA4 Working Paper\n", "abstract": " I GENERAL GOALS OF THE LANGUAGE A. The Language and Its Data Base The QA4 language is an enhanced omega\u2014order language1* embedded in a system of control statements. The declarative facets of the language include atomic symbols, tuples, unordered tuples, sets, function definitions, and applications; the imperative facets include (in addition to normal program control features) set iteration, backtracking, and parallelism. The language is intended to be a natural formalism for the description of problem\u2014domain\u2014oriented theorem\u2014proving strategies. More-over, the specification of problems to be solved by QA4 programs have a natural, compact formulation in the same language, That is, the state-ment of theorems to be proved or the specification of programs to be written is a task similar in nature to writing theorem provers or program synthesizers. For this reason, the data base for QA4 programs is\u00a0\u2026", "num_citations": "4\n", "authors": ["1698"]}
{"title": "Program synthesis for multi-agent question answering\n", "abstract": " Techniques that were developed for program synthesis are being applied to allow multiple agents to communicate with each other and cooperate to solve a single problem. We illustrate the use of program synthesis techniques in a system that answers questions about geography.", "num_citations": "3\n", "authors": ["1698"]}
{"title": "Deductive response to geographic queries\n", "abstract": " When we have a question, there may be many sources of information, including programs and data, relevant to finding the answer. We may not know which sources are appropriate. They may reside on different machines in diverse locations. Knowledge may be represented according to different frameworks, notations, or coordinate systems. The answer may not exist anywhere explicitly; it may need to be inferred, and it may depend on more than one source.", "num_citations": "3\n", "authors": ["1698"]}
{"title": "Deduction with relation matching\n", "abstract": " A new deduction rule is introduced to give streamlined treatment to relations of special importance in an automated theorem-proving system. This relation matching rule generalizes to an arbitrary binary relation the E-resolution and RUE-resolution rules for equality, and may operate within a nonclausal or clausal system. The new rule depends on an extension of the notion of polarity to apply to subterms as well as to subsentences, with respect to a given binary relation. It allows the system to draw a conclusion even if the unification algorithm fails to find a complete match, provided the polarities of the mismatched terms are auspicious. The rule allows us to eliminate troublesome axioms, such as transitivity and monotonicity, from the system; proofs are shorter and more comprehensible, and the search space is correspondingly deflated.", "num_citations": "3\n", "authors": ["1698"]}
{"title": "Problematic Features of Programming Languages: A Situational-Calculus Approach. Part I. Assignment Statements.\n", "abstract": " Certain features of programming languages, such as data structure operations and procedure call mechanisms, have been found to resist formalization by classical techniques. An alternate approach is presented, based on a situational calculus, which makes explicit reference to the states of a computation. For each state, a distinction is drawn between an expression, its value, and the location of the value. Within this conceptual framework, the features of a programming language can be described axiomatically. Programs in the language can then be synthesized, executed, verified, or transformed by performing deductions in this axiomatic system. Properties of entire classes of programs, and of programming languages, can also be expressed and proved in this way. The approach is amenable to machine implementation. In a situational-calculus formalism it is possible to model precisely many problematic features of programming languages, including operations on such data structures as arrays, pointers, lists, and records, and such procedure call mechanisms as call-by-reference, call-by-value, and call-by-name. No particular obstacle is presented by aliasing between variables, by declarations, or by recursive procedures. The paper is divided into three parts, focusing respectively on the assignment statement, on data structure operations, and on procedure call mechanisms.Descriptors:", "num_citations": "3\n", "authors": ["1698"]}
{"title": "Answering Science Questions: Deduction with Answer Extraction and Procedural Attachment.\n", "abstract": " An approach to question answering through automated deduction is advocated. Answers to questions are extracted from proofs of associated conjectures over an axiomatic theory of the subject domain. External knowledge resources, including data and software, are consulted through a mechanism known as procedural attachment. A researcher ignorant of the subject domain theory or its logical language can formulate questions via a query elicitation facility. A similar device allows an expert to extend the theory. An English explanation for each answer, and a justification for its correctness, is constructed automatically from the proof by which it was extracted. A deductive approach has been applied in planetary astronomy, geography, intelligence analysis, and, most recently, molecular biology and medical research applications. It is argued that the constructs in the Semantic Web languages, including OWL with SWRL, are insufficiently expressive for this kind of application.", "num_citations": "2\n", "authors": ["1698"]}
{"title": "Deductive Chat Lines for Multiple Agents\n", "abstract": " Deductive synthesis techniques provide a medium by which multiple agents can communicate and cooperate with each other to solve a common task, even though they don\u2019t know about each other and haven\u2019t been designed to work together. These methods are being applied to geographic question answering and the development of a personal deductive organizer.Biography. Richard Waldinger has done pioneering work in deductive program synthesis and other applications of automated deduction to software engineering and artificial intelligence, including program verification, knowledge representation, and planning. He received the Ph. D. from Carnegie-MeUon in 1969, supervised by Herbert Simon. Since then, he has been affiliated with the Artificial Intelligence Center of SKI International, where he is a Principal Scientist. He has published several books with Zohar Manna, of Stanford University, and has also visited the NASA Ames Research Center and the Kestrel Institute, for extended collaborations. He is both a AAAI Fellow and an SKI International Fellow.", "num_citations": "2\n", "authors": ["1698"]}
{"title": "AMPHION: Specification-based programming for scientific subroutine libraries\n", "abstract": " OVERVIEW over manual program development. AMPHION is currently undergoing alpha testing in preparation for distribution to the NAIF community. Other NASA domains are under consideration. Future research will address the technology needed for domain experts to develop their own AMPHION domain theories with only minimal consultation from experts in formal methods.AMPHION is a knowledge-based software engineering(KBSE) system that guides a user in developing a diagram representing a formal problem specification. It then automatically implements a solution to this specification as a program consisting of calls to subroutines from a library. The diagram provides an intuitive domainoriented notation for creating a specification that also facilitates reuse and modification. AMPHION'S architecture is domain independent. AMPHION is specialized to an application domain by developing a declarative domain theory. Creating a domain theory is an iterative process that currently requires the joint expertise of domain experts and experts in automated formal methods for software development. AMPHION has been applied to JPL's NAIF domain through a declarative domain theory that includes an axiomatization of JPL's SPICELIB subroutine library. Testing with planetary scienfists demonstrates that AMPHION's interactive specification acquisition paradigm enables users to easily develop, modify, and reuse specifications after only a short tutorial. AMPHION routinely synthesizes programs consisting of dozens of SPICELIB subroutine calls from these specifications in just a few minutes. Qualitative assessments indicate an order of\u00a0\u2026", "num_citations": "2\n", "authors": ["1698"]}
{"title": "The bomb in the toilet\n", "abstract": " Sauf mention contraire ci-dessus, le contenu de cette notice bibliographique peut \u00eatre utilis\u00e9 dans le cadre d\u2019une licence CC BY 4.0 Inist-CNRS/Unless otherwise stated above, the content of this bibliographic record may be used under a CC BY 4.0 licence by Inist-CNRS/A menos que se haya se\u00f1alado antes, el contenido de este registro bibliogr\u00e1fico puede ser utilizado al amparo de una licencia CC BY 4.0 Inist-CNRS", "num_citations": "2\n", "authors": ["1698"]}
{"title": "Zohar Manna (1939\u20132018)\n", "abstract": " Zohar received his bachelor\u2019s and master\u2019s degrees in mathematics from the Technion in Haifa in 1961 and 1965, respectively, serving as a scientific programmer, with the rank of First Lieutenant, in the Israel Defense Forces from 1962 to 1964. Afterwards, he attended Carnegie Mellon University in Pittsburgh (together with one of us, Richard), where he earned his Ph. D. in computer science in the spring of 1968 under the guidance of Robert W Floyd and Alan J. Perlis.", "num_citations": "1\n", "authors": ["1698"]}
{"title": "Natural language access: When reasoning makes sense\n", "abstract": " Natural language is one of the more appealing ways by which people can interact with computers, but up to now its application has been severely constrained. We argue that to use natural language effectively, we must have both a deep understanding of the subject domain and a general-purpose reasoning capability. We illustrate the issues with SAP-QUEST, a proof-of-concept system for natural language question answering over a set of data sources for business enterprise applications, but the argument can be applied more generally to dialogue-style interfaces over a variety of subject domains.", "num_citations": "1\n", "authors": ["1698"]}
{"title": "Deductive formation of recursive workflows\n", "abstract": " In this work, we present an action theory with the power to represent recursive plans and the capability to reason about and synthesize recursive workflow control structures. In contrast with the software verification setting, reasoning does not take place solely over predefined data structures, and neither is there a process specification available in recursive form. Rather, specification takes the form of goals, and domain structure takes the form of a physical application setting containing objects. For this reason, well-founded induction is employed for its suitability for practical action domains where recursive structures must be described or inferred. Under this method, termination of the synthesized recursive workflow is a property that follows automatically. We show how a general workflow recursive construct is added to an action language which is then augmented with induction. This formalism is then transformed in a way amenable to automated reasoning. We then demonstrate the method with a particular example specified in the theory, and then extracted from a proof constructed by the SNARK first order theorem prover.", "num_citations": "1\n", "authors": ["1698"]}
{"title": "Tutorial on program-synthetic deduction\n", "abstract": " Theorem proving involving equality has been one of the most exciting research areas in atitomated deduction. Wos and Robinson proposed the paramodulation inference rule and its demodulation refinement in 1967. At about the same time, Knuth and Bendix presented the method of term rewriting. Term rewriting orients equations into rules according to a well-founded ordering and selects the deductive consequences via a notion of superposition. In addition to equational theories, term rewriting has been successfully extended to inductive theories, first-order logic, first-order logic with equality, as well as having been applied to functional and logic programming. In fact, it has already become one of the most active and versatile areas in automated deduction.In this tutorial, we introduce term rewriting and survey its diverse applications. We shall emphasize more recent developments and point out the most promising\u00a0\u2026", "num_citations": "1\n", "authors": ["1698"]}
{"title": "Problematic features of programming languages: A situational-calculus approach. Part 1: Assignment statements\n", "abstract": " Certain features of programming languages, such as data structure operations and procedure call mechanisms, have been found to resist formalization by classical techniques. An alternate approach is presented, based on a \"situational calculus,\" which makes explicit reference to the states of a computation. For each state, a distinction is drawn between an expression, its value, and the location of the value. Within this conceptual framework, the features of a programming language can be described axiomatically. Programs in the language can then be synthesized, executed, verified, or transformed by performing deductions in this axiomatic system. Properties of entire classes of programs, and of programming languages, can also be expressed and proved in this way. The approach is amenable to machine implementation. In a situational calculus formalism it is possible to model precisely many \"problematic\"\u00a0\u2026", "num_citations": "1\n", "authors": ["1698"]}
{"title": "Synthesis: programs\n", "abstract": " Synthesis - CERN Document Server CERN Accelerating science Sign in Directory CERN Document Server Access articles, reports and multimedia content in HEP Main menu Search Submit Help Personalize Your alerts Your baskets Your comments Your searches Home > Synthesis Information Discussion (0) Files Report Report number AIM-302 Title Synthesis : programs Author(s) Manna, Z ; Waldinger, R Affiliation (Stanford Univ.) ; (Stanford Res. Inst.) Publication Stanford, CA : Calif. Univ. Stanford. Comput. Sci. Dept., 1977. - 96 p. Subject category Computing and Computers [] Back to search Record created 1990-01-28, last modified 2014-12-15 Similar records Add to personal basket Export as BibTeX, MARC, MARCXML, DC, EndNote, NLM, RefWorks CERN Document Server :: Search :: Submit :: Personalize :: Help :: Privacy Notice Powered by Invenio v1.1.3.1106-62468 Maintained by cds.support@cern.ch \u2026", "num_citations": "1\n", "authors": ["1698"]}
{"title": "A more mechanical approach to program verification\n", "abstract": " Program verification is the process of showing that a program satisfies the intentions of the programmer. Several approaches to this problem have been proposed. Ftogd [1967] suggests a method that requires that the programmer sprinkle the program~ ith comments or\" assertions.\" This method has been implemented~ but the need to construct complete assertions places a heavg burden on the programmer. Furthermore, incorrect or incomplete assertions can cause the sgstem to fail to verifg the program, whether or not there are bugs in the program itself. Finallg. even in cases. here it can be proved that a program terminates. with Flogd's method, this must be sho. n in a separate proof. Manna [1968] suggested a method that proved termination and correctness simultaneouslg and did not require ang intermediate comments or assertions but onlg the input and output assertions necessarg to express the intentions of\u00a0\u2026", "num_citations": "1\n", "authors": ["1698"]}
{"title": "Research in Advanced Formal Theorem-proving Techniques\n", "abstract": " This report summarizes the results of a three-year project aimed at the design and implementation of computer languages to aid in expressing problem solving procedures in several areas of artificial intelligence including automatic programming, theorem proving, and robot planning. The principal results of the project have been the design and implementation of two complete systems, QA4 and QLISP, and their preliminary experimental use. QA4 has been documented in detail in a previous technical report. x This report contains a description of how both QA4 and QLISP have been used; the Preliminary QLISP Manual is attached as an appendix.", "num_citations": "1\n", "authors": ["1698"]}