{"title": "Verification and validation and artificial intelligence\n", "abstract": " Artificial Intelligence (AI) is useful. AI can deliver more functionality for reduced cost. AI should be used more widely but won't be unless developers can trust adaptive, nondeterministic, or complex AI systems.Verification and validation is one method used by software analysts to gain that trust. AI systems have features that make them hard to check using conventional V&V methods. Nevertheless, as we show in this chapter, there are enough alternative readily-available methods that enable the V&V of AI software.", "num_citations": "84\n", "authors": ["1405"]}
{"title": "Symbolic model checking of logics with actions\n", "abstract": " Reasoning about agents and modalities such as knowledge and belief leads to models where different relations over states co-exist, or equivalently, where information (labels, actions) is associated to state transitions. This paper discusses how to augment classical CTL symbolic model-checking to support logics with actions such as A-CTL (action-CTL), and how this can be implemented using BDDs in tools such as the SMV/NuSMV package. Considering general action-state structures, we first propose a natural extension of CTL to actions, called Action-Restricted CTL (ARCTL) and adapt classical results from CTL to express model checking based on three functions eax, eau and eag. On these grounds, we present two different implementations of symbolic model checking with actions. The first approach encodes action-state models and logics into pure state-based models and logics, that can be checked\u00a0\u2026", "num_citations": "63\n", "authors": ["1405"]}
{"title": "Automatic verification of knowledge and time with NuSMV\n", "abstract": " We show that the problem of model checking multidimensional modal logics can be reduced to the problem of model checking ARCTL, an extension of the temporal logic CTL with action labels and operators to reason about actions. In particular, we introduce a methodology for model checking a temporal-epistemic logic by building upon an extension of the model checker NuSMV that enables the verification of ARCTL. We briefly present the implementation and report experimental results for the verification of a typical security protocol involving temporal-epistemic properties: the protocol of the dining cryptographers.", "num_citations": "57\n", "authors": ["1405"]}
{"title": "Towards automatic verification of autonomous systems\n", "abstract": " While autonomous systems offer great promise in terms of capability and flexibility, their reliability is particularly hard to assess. This paper describes research to apply formal verification methods to languages used to develop autonomy software. In particular, we describe tools that automatically convert autonomy software into formal models that are then verified using model checking. This approach has been applied to MPL code for the Livingstone fault diagnosis system and to TDL task descriptions for mobile robot systems. Our long-term objective is to create tools that enable engineers and roboticists to use formal verification as part of the normal software development cycle.", "num_citations": "55\n", "authors": ["1405"]}
{"title": "From livingstone to SMV\n", "abstract": " To fulfill the needs of its deep space exploration program, NASA is actively supporting research and development in autonomy software. However, the reliable and cost-effective development and validation of autonomy systems poses a tough challenge. Traditional scenario-based testing methods fall short because of the combinatorial explosion of possible situations to be analyzed, and formal verification techniques typically require a tedious, manual modeling by formal method experts. This paper presents the application of formal verification techniques in the development of autonomous controllers based on Livingstone, a model-based health-monitoring system that can detect and diagnose anomalies and suggest possible recovery actions. We present a translator that converts the models used by Livingstone into specifications that can be verified with the SMV model checker. The translation frees the\u00a0\u2026", "num_citations": "44\n", "authors": ["1405"]}
{"title": "A bisimulation-based approach to the analysis of human-computer interaction\n", "abstract": " This paper discusses the use of formal methods for analysing human-computer interaction. We focus on the mode confusion problem that arises whenever the user thinks that the system is doing something while it is in fact doing another thing. We consider two kinds of models: the system model describes the actual behaviour of the system and the mental model represents the user's knowledge of the system. The user interface is modelled as a subset of system transitions that the user can control or observe. We formalize a full-control property which holds when a mental model and associated user interface are complete enough to allow proper control of the system. This property can be verified using model-checking techniques on the parallel composition of the two models. We propose a bisimulation-based equivalence relation on the states of the system and show that, if the system satisfies a determinism\u00a0\u2026", "num_citations": "43\n", "authors": ["1405"]}
{"title": "Using model checking to validate AI planner domain models\n", "abstract": " This report describes an investigation into using model checking to assist validation of domain models for the HSTS planner. The planner models are speci ed using a qualitative temporal interval logic with quantitative duration constraints. We conducted several experiments to translate the domain modeling language into the SMV, Spin and Murphi model checkers. This allowed a direct comparison of how the di erent systems would support speci c types of validation tasks. The preliminary results indicate that model checking is useful for nding faults in models that may not be easily identi ed by generating test plans.", "num_citations": "43\n", "authors": ["1405"]}
{"title": "A formal framework for design and analysis of human-machine interaction\n", "abstract": " Automated systems are increasingly complex, making it hard to design interfaces for human operators. Human-machine interaction (HMI) errors like automation surprises are more likely to appear and lead to system failures or accidents. In previous work, we studied the problem of generating system abstractions, called mental models, that facilitate system understanding while allowing proper control of the system by operators as defined by the full-control property. Both the domain and its mental model have Labelled Transition Systems (LTS) semantics, and we proposed algorithms for automatically generating minimal mental models as well as checking full-control. This paper presents a methodology and an associated framework for using the above and other formal method based algorithms to support the design of HMI systems. The framework can be used for modelling HMI systems and analysing models against\u00a0\u2026", "num_citations": "39\n", "authors": ["1405"]}
{"title": "Verification and validation of autonomy software at NASA\n", "abstract": " Autonomous software holds the promise of new operation possibilities, easier design and development and lower operating costs. However, as those systems close control loops and arbitrate resources on board with specialized reasoning, the range of possible situations becomes very large and uncontrollable from the outside, making conventional scenario-based testing very inefficient. Analytic verification and validation (V&V) techniques, and model checking in particular, can provide significant help for designing autonomous systems in a more efficient and reliable manner, by providing a better coverage and allowing early error detection. This article discusses the general issue of V&V of autonomy software, with an emphasis towards model-based autonomy, model-checking techniques and concrete experiments at NASA.", "num_citations": "36\n", "authors": ["1405"]}
{"title": "Cadp\u201997\u2013status, applications and perspectives\n", "abstract": " This article gives an overview of the most recent features implemented in Cadp (C\u00e6sar/Ald\u00e9baran Development Package), a toolbox dedicated to the design and verification of communication protocols and distributed systems. Besides the description of the new features, this paper also lists the latest applications of Cadp to industrial case-studies and mentions the current research directions for improving Cadp.", "num_citations": "35\n", "authors": ["1405"]}
{"title": "Verification of railway interlocking systems\n", "abstract": " In the railway domain, an interlocking is a computerised system that controls the railway signalling objects in order to allow a safe operation of the train traffic. Each interlocking makes use of particular data, called application data, that reflects the track layout of the station under control. The verification and validation of the application data are performed manually and is thus error-prone and costly. In this paper, we explain how we built an executable model in NuSMV of a railway interlocking based on the application data. We also detail the tool that we have developed in order to translate the application data into our model automatically. Finally we show how we could verify a realistic set of safety properties on a real-size station model by customizing the existing model-checking algorithm with PyNuSMV a Python library based on NuSMV.", "num_citations": "33\n", "authors": ["1405"]}
{"title": "Reasoning about memoryless strategies under partial observability and unconditional fairness constraints\n", "abstract": " Abstract Alternating-time Temporal Logic is a logic to reason about strategies that agents can adopt to achieve a specified collective goal. A number of extensions for this logic exist; some of them combine strategies and partial observability, some others include fairness constraints, but to the best of our knowledge no work provides a unified framework for strategies, partial observability and fairness constraints. Integration of these three concepts is important when reasoning about the capabilities of agents without full knowledge of a system, for instance when the agents can assume that the environment behaves in a fair way. We present ATLK irF, a logic combining strategies under partial observability in a system with fairness constraints on states. We introduce a model-checking algorithm for ATLK irF by extending the algorithm for a full-observability variant of the logic and we investigate its complexity. We validate\u00a0\u2026", "num_citations": "29\n", "authors": ["1405"]}
{"title": "Specification and verification of a TTP protocol for the conditional access to services\n", "abstract": " [en] We use the formal language LOTOS to specify the Equicrypt protocol and verify its robustness to attacks by an intruder. We use the model-based CADP verification tools from the Eucalyptus toolbox to discover some successful attacks against this protocol.Target: Researchers", "num_citations": "28\n", "authors": ["1405"]}
{"title": "Learning system abstractions for human operators\n", "abstract": " This paper is concerned with the use of formal techniques for the analysis of human-machine interactions (HMI). The focus is on generating system abstractions for human operators. Such abstractions, once expressed in rigorous, formal notations, can be used for analysis or for user training. They should ideally be minimal in order to concisely capture the system behaviour. They should also contain enough information to allow full-control of the system.", "num_citations": "23\n", "authors": ["1405"]}
{"title": "Verification of railway interlocking-compositional approach with OCRA\n", "abstract": " In the railway domain, an electronic interlocking is a computerised system that controls the railway signalling components (e.g. switches or signals) in order to allow a safe operation of the train traffic. Interlockings are controlled by a software logic that relies on a generic software and a set of application data particular to the station under control. The verification of the application data is time consuming and error prone as it is mostly performed by human testers.                 In the first stage of our research [3], we built a model of a small Belgian railway station and we performed the verification of the application data with the nusmv model checker. However, the verification of larger stations fails due to the state space explosion problem. The intuition is that large stations can be split into smaller components that can be verified separately. This concept is known as compositional verification. This article explains how\u00a0\u2026", "num_citations": "22\n", "authors": ["1405"]}
{"title": "Improving the model checking of strategies under partial observability and fairness constraints\n", "abstract": " Reasoning about strategies has been a concern for several years, and many extensions of Alternating-time Temporal Logic have been proposed. One extension, ATLK                                irF               , allows the user to reason about the strategies of the agents of a system under partial observability and unconditional fairness constraints. However, the existing model-checking algorithm for ATLK                                irF                is inefficient when the user is only interested in the satisfaction of a formula in a small subset of states, such as the set of initial states of the system. We propose to generate fewer strategies by only focusing on partial strategies reachable from this subset of states, reducing the time needed to perform the verification. We also describe several practical improvements to further reduce the verification time and present experiments showing the practical impact of the approach.", "num_citations": "21\n", "authors": ["1405"]}
{"title": "PDVer, a tool to verify PDDL planning domains.\n", "abstract": " We present a methodology and a tool for the problem of testing and verifying that a PDDL planning domain satisfies a set of requirements, a need that arises for instance in space missions. We first review and analyse coverage conditions for requirement-based testing, and present how test cases can be derived automatically from requirements. Additionally, we show how test cases can be translated into additional planning goals. To automate this process, we introduce PDVer, an Eclipse plug-in for the automatic generation of PDDL code from requirements expressed in LTL. We evaluate the effectiveness of our approach and the usability of our tool against the Rovers domain from the fifth International Planning Competition (IPC-5).", "num_citations": "21\n", "authors": ["1405"]}
{"title": "Automating model checking for autonomous systems\n", "abstract": " While autonomous systems offer great promise in terms of capability and flexibility, their reliability is particularly hard to assess. This paper describes research in the use of model checking to support the development of reliable autonomy software. In particular, it presents tools and techniques that we are developing to facilitate the integration of model checking into the main software development cycle. The basic approach is to translate highlevel models used by autonomy systems into the specification language of the SMV model checker, verify them using SMV, translate diagnostics back to the source language and visualize and explain those diagnostics. This approach has been applied to MPL models for the Livingstone fault diagnosis system and to TDL task descriptions for mobile robot systems.", "num_citations": "20\n", "authors": ["1405"]}
{"title": "A formal analysis of requirements-based testing\n", "abstract": " The aim of requirements-based testing is to generate test cases from a set of requirements for a given system or piece of software. In this paper we propose a formal semantics for the generation of test cases from requirements by revising and extending the results presented in previous works (eg:[21, 20, 13]). We give a syntactic characterisation of our method, defined inductively over the syntax of LTL formulae, and prove that this characterisation is sound and complete, given some restrictions on the formulae that can be used to encode requirements. We provide various examples to show the applicability of our approach.", "num_citations": "19\n", "authors": ["1405"]}
{"title": "Simulation-based verification of autonomous controllers via Livingstone Pathfinder\n", "abstract": " AI software is often used as a means for providing greater autonomy to automated systems, capable of coping with harsh and unpredictable environments. Due in part to the enormous space of possible situations that they aim to address, autonomous systems pose a serious challenge to traditional test-based verification approaches. Efficient verification approaches need to be perfected before these systems can reliably control critical applications. This publication describes Livingstone PathFinder (LPF), a verification tool for autonomous control software. LPF applies state space exploration algorithms to an instrumented testbed, consisting of the controller embedded in a simulated operating environment. Although LPF has focused on NASA\u2019s Livingstone model-based diagnosis system applications, the architecture is modular and adaptable to other systems. This article presents different facets of LPF and\u00a0\u2026", "num_citations": "18\n", "authors": ["1405"]}
{"title": "PyNuSMV: NuSMV as a Python library\n", "abstract": " NuSMV is a state-of-the-art model checker providing BDD-based and SAT-based techniques and a rich modeling language. While the tool is powerful, it is hard to customize it because of the size and complexity of its code base (more than 200K LOC). This paper presents PyNuSMV, a Python framework for prototyping and experimenting with BDD-based model-checking algorithms based on NuSMV.               PyNuSMV provides a rich and flexible programmable platform to implement new logics and experiment with custom model-checking algorithms. Thanks to PyNuSMV, it is possible to use NuSMV functionalities without understanding its whole code base or struggling with implementation details such as memory management. PyNuSMV has already been used to implement model-checking algorithms for rich logics such as ARCTL and CTLK.               This paper describes the structure and usage of\u00a0\u2026", "num_citations": "17\n", "authors": ["1405"]}
{"title": "Advanced modelling and verification techniques applied to a cluster file system\n", "abstract": " This paper describes the application of advanced formal modelling techniques and tools from the CADP toolset to the verification of CFS, a distributed file system kernel. After a short overview of the specification of CFS, we describe the techniques used for model generation and verification, and their application to CFS. Two original aspects are put forth: firstly, the model is generated in a compositional way, by putting together separately generated sub-components, secondly, the extensible, data-aware temporal logic checker XTL is used to express and verify properties of the system. In particular an XTL extension providing richer diagnostics is presented.", "num_citations": "17\n", "authors": ["1405"]}
{"title": "Improving the specification of data types in LOTOS.\n", "abstract": " Degree: Ph. D.DegreeYear: 1996Institute: Universite de l''Etat a Liege (Belgium)Publisher: Universite De Liege Faculty Of Applied Sciences Bat. D1, B-4000 Liege, Belgium.Our general goal is to provide solutions for making the specification of data types in LOTOS more concise, easier to write and understand and less dependent on environment constraints.", "num_citations": "14\n", "authors": ["1405"]}
{"title": "Autonomous control of an in-situ propellant production plant\n", "abstract": " Utilization of extraterrestrial resources, or In-Situ Resource Utilization (ISRU), is viewed as an enabling technology for the exploration and commercial development of our solar system. A key subset of ISRU is In-Situ Propellant Production (ISPP), which involves the partially autonomous production of propellants for planetary ascent or Earth return. NASA has scheduled pilot ISPP demonstrations on Mars starting with the 2001 Mars Surveyor Lander, with human Mars mission scenarios as early as 2011. Such automated manufacturing facilities could also be applied to terrestrial space-port systems in the automation of launch vehicle and payload test, checkout and launch operations. Automation would allow for the more efficient use of personnel resources and enhance the safety of safety-critical operations where human intervention would be to slow or undesirable (eg situations where system safing would require placing personnel into a hazardous situation).Operating an In-Situ Propellant Production (ISPP) plant on Mars poses significant challenges. One such challenge is the ability to maintain continuous plant operation without a Mars-based human presence, despite component failures and operational degradation. An Autonomous Controller (AC) can be used to monitor an ISPP plant for anomalous conditions, can diagnose component failures, and can provide recovery recommendations. The Livingstone system, developed at NASA Ames, is a model-based health management and control system that tracks the state of a device, detects and diagnoses anomalies and suggests alternative recovery actions. Livingstone is used at NASA\u00a0\u2026", "num_citations": "11\n", "authors": ["1405"]}
{"title": "Using LOTOS for specifying the CHORUS distributed operating system kernel\n", "abstract": " The goal of the work presented in this paper was to test the adequacy of LOTOS for the specification of operating systems, by specifying the basic structures and functionalities of the distributed operating system chorus V3. The paper focuses on discussing the issues encountered during the development of the specification, rather than on the specification itself. Three successive approaches based on different specification styles are presented and discussed. A difficulty related to the specification of processing systems is analysed.", "num_citations": "11\n", "authors": ["1405"]}
{"title": "Formal verification for a next-generation space shuttle\n", "abstract": " This paper discusses the verification and validation (V&V) of advanced software used for integrated vehicle health monitoring (IVHM), in the context of NASA\u2019s next-generation space shuttle. We survey the current V&V practice and standards used in selected NASA projects, review applicable formal verification techniques, and discuss their integration into existing development practice and standards. We also describe two verification tools, JMPL2SMV and Livingstone PathFinder, that can be used to thoroughly verify diagnosis applications that use model-based reasoning, such as the Livingstone system.", "num_citations": "10\n", "authors": ["1405"]}
{"title": "Information Technology and Control Needs For In-Situ Resource Utilization\n", "abstract": " With the rapidly increasing performance of information technologies, a new capability is being developed that holds the clear promise of greatly increased exploration possibilities, along with dramatically reduced design, development, and operating costs. In addition, specific technologies such as neural nets will provide a degree of machine intelligence and associated autonomy which has previously been unavailable to the mission and spacecraft designer and the system operator. One of the most promising applications of these new information technologies is to the area of in-situ resource utilization.", "num_citations": "10\n", "authors": ["1405"]}
{"title": "Model-based verification of a security protocol for conditional access to services\n", "abstract": " We use the formal language LOTOS to specify and verify the robustness of the Equicrypt protocol under design in the European OKAPI project for conditional access to multimedia services. We state some desired security properties and formalize them. We describe a generic intruder process and its modelling, and show that some properties are falsified in the presence of this intruder. The diagnostic sequences can be used almost directly to exhibit the scenarios of possible attacks on the protocol. Finally, we propose an improvement of the protocol which satisfies our properties.", "num_citations": "10\n", "authors": ["1405"]}
{"title": "Towards a proposal for datatypes in E-LOTOS\n", "abstract": " This document makes proposals for the data language of Enhanced LOTOS. It describes a core language, plus a module system and standard libraries. Possible approaches to the dynamic and static semantics of the language are sketched out. The relationship of the model to the behavioural part of LOTOS and the other E-LOTOS enhancements are discussed.", "num_citations": "10\n", "authors": ["1405"]}
{"title": "Reasoning about strategies under partial observability and fairness constraints\n", "abstract": " A number of extensions exist for Alternating-time Temporal Logic; some of these mix strategies and partial observability but, to the best of our knowledge, no work provides a unified framework for strategies, partial observability and fairness constraints. In this paper we propose ATLK^F_po, a logic mixing strategies under partial observability and epistemic properties of agents in a system with fairness constraints on states, and we provide a model checking algorithm for it.", "num_citations": "9\n", "authors": ["1405"]}
{"title": "Combining Partial Order Reduction with Bounded Model Checking.\n", "abstract": " Model checking is an efficient technique for verifying properties on reactive systems. Partial-order reduction (POR) and symbolic model checking are two common approaches to deal with the state space explosion problem in model checking. Traditionally, symbolic model checking uses BDDs which can suffer from space blowup. More recently bounded model checking (BMC) using SAT-based procedures has been used as a very successful alternative to BDDs. However, this approach gives poor results when it is applied to models with a lot of asynchronism. This paper presents an algorithm which combines partial order reduction methods and bounded model checking techniques in an original way that allows efficient verification of temporal logic properties (LTLX) on models featuring asynchronous processes. The encoding to a SAT problem strongly reduces the complexity and non-determinism of each transition step, allowing efficient analysis even with longer execution traces. The starting-point of our work is the Two-Phase algorithm (Namalesu and Gopalakrishnan) which performs partial-order reduction on process-based models. At first, we adapt this algorithm to the bounded model checking method. Then, we describe our approach formally and demonstrate its validity. Finally, we present a prototypal implementation and report encouraging experimental results on a small example.", "num_citations": "9\n", "authors": ["1405"]}
{"title": "Efficient symbolic model checking for process algebras\n", "abstract": " Different approaches have been developed to mitigate the state space explosion of model checking techniques. Among them, symbolic verification techniques use efficient representations such as BDDs to reason over sets of states rather than over individual states. Unfortunately, past experience has shown that these techniques do not work well for loosely-synchronized models. This paper presents a new algorithm and a new tool that combines BDD-based model checking with partial order reduction (POR) to allow the verification of models featuring asynchronous processes, with significant performance improvements over currently available tools. We start from the ImProviso algorithm (Lerda et al.) for computing reachable states, which combines POR and symbolic verification. We merge it with the FwdUntil method (Iwashita et al.) that supports verification of a subset of CTL. Our algorithm has been\u00a0\u2026", "num_citations": "9\n", "authors": ["1405"]}
{"title": "Simulation-Based Verification of Livingstone Applications\n", "abstract": " AI software is viewed as a means to give greater autonomy to automated systems, capable of coping with harsh and unpredictable environments in deep space missions. Autonomous systems pose a serious challenge to traditional test-based verification approaches, because of the enormous space of possible situations that they aim to address. Before these systems are put in control of critical applications, appropriate new verification approaches need to be developed. This article describes Livingstone PathFinder (LPF), a verification tool for autonomous diagnosis applications based on NASA\u2019s Livingstone model-based diagnosis system. LPF applies state space exploration algorithms to an instrumented testbed, consisting of the Livingstone diagnosis system embedded in a simulated operating environment. The article describes different facets of LPF and reports some experimental results from applying LPF to a Livingstone model of the main propulsion feed subsystem of the X-34 space vehicle.", "num_citations": "8\n", "authors": ["1405"]}
{"title": "Survey of NASA V&V processes/methods\n", "abstract": " 1.1 The purpose of this appendix is to provide quantifiable criteria for determining whether IV&V should be applied to a given software development. Since IV&V should begin in the Formulation Subprocess(as defined in NPG 7120.5, paragraph 1.4. 3) of a project, the process described here is based on metrics which are available before project approval.", "num_citations": "8\n", "authors": ["1405"]}
{"title": "Specification and verification of the Co/sub 4/distributed knowledge system using LOTOS\n", "abstract": " This paper relates the formal specification and verification of a consensual decision protocol based on Co/sub 4/, a computer environment dedicated to the building of a distributed knowledge base. This protocol has been specified in the ISO formal description technique LOTOS. The CADP tools from the EUCALYPTUS LOTOS toolset have been used to verify different safety and liveness properties. The verification work has confirmed an announced violation of knowledge consistency and has put forth a case of inconsistent hierarchy, four cases of unexpected message reception and some further local corrections in the definition of the protocol.", "num_citations": "8\n", "authors": ["1405"]}
{"title": "Automatic detection of potential automation surprises for ADEPT models\n", "abstract": " This paper describes how to automatically detect potential automation surprises in interactive systems, within a rapid automation interface design tool named ADEPT. The proposed analysis method in this paper is based on a conformance relation, called full-control, between the model of the actual system and a mental model of it, that is, its behavior as perceived by the operator. The method can, among other things, automatically generate a so-called minimal full-control mental model for a given system. Systems are well designed if they can be described by relatively simple mental models for their operators, which can be assessed with the minimal full-control mental model generation algorithms. During the generation, potential automation surprises are detected and highlighted with execution examples that may lead to confusion. The analysis methods are based on an enriched version of labeled transition\u00a0\u2026", "num_citations": "7\n", "authors": ["1405"]}
{"title": "Rich counter-examples for temporal-epistemic logic model checking\n", "abstract": " Model checking verifies that a model of a system satisfies a given property, and otherwise produces a counter-example explaining the violation. The verified properties are formally expressed in temporal logics. Some temporal logics, such as CTL, are branching: they allow to express facts about the whole computation tree of the model, rather than on each single linear computation. This branching aspect is even more critical when dealing with multi-modal logics, i.e. logics expressing facts about systems with several transition relations. A prominent example is CTLK, a logic that reasons about temporal and epistemic properties of multi-agent systems. In general, model checkers produce linear counter-examples for failed properties, composed of a single computation path of the model. But some branching properties are only poorly and partially explained by a linear counter-example. This paper proposes richer counter-example structures called tree-like annotated counter-examples (TLACEs), for properties in Action-Restricted CTL (ARCTL), an extension of CTL quantifying paths restricted in terms of actions labeling transitions of the model. These counter-examples have a branching structure that supports more complete description of property violations. Elements of these counter-examples are annotated with parts of the property to give a better understanding of their structure. Visualization and browsing of these richer counter-examples become a critical issue, as the number of branches and states can grow exponentially for deeply-nested properties. This paper formally defines the structure of TLACEs, characterizes adequate counter-examples\u00a0\u2026", "num_citations": "7\n", "authors": ["1405"]}
{"title": "Applications of model checking for multi-agent systems: verification of diagnosability and recoverability\n", "abstract": " This paper presents a practical application of model checking for multi-agent systems to the automatic verification of diagnosability. First, a characterisation of diagnosability in terms of epistemic properties of agents is given; then, experimental results are presented for preliminary investigations in the automatic verification of diagnosability of Livingstone models.", "num_citations": "7\n", "authors": ["1405"]}
{"title": "State event models for the formal analysis of human-machine interactions\n", "abstract": " The work described in this paper was motivated by our experience with applying a framework for formal analysis of human-machine interactions (HMI) to a realistic model of an autopilot. The framework is built around a formally defined conformance relation called\" full-control\" between an actual system and the mental model according to which the system is operated. Systems are well-designed if they can be described by relatively simple, full-control, mental models for their human operators. For this reason, our framework supports automated generation of minimal full-control mental models for HMI systems, where both the system and the mental models are described as labelled transition systems (LTS). The autopilot that we analysed has been developed in the NASA Ames HMI prototyping tool ADEPT. In this paper, we describe how we extended the models that our HMI analysis framework handles to allow adequate representation of ADEPT models. We then provide a property-preserving reduction from these extended models to LTSs, to enable application of our LTS-based formal analysis algorithms. Finally, we briefly discuss the analyses we were able to perform on the autopilot model with our extended framework.", "num_citations": "6\n", "authors": ["1405"]}
{"title": "V&V of Advanced Systems at NASA\n", "abstract": " This report was prepared by the NASA Ames Research Center Automated Software Engineering(ASE) group as the deliverable for Task 5.3. 3.2\" Analyze Formal Methods for V&V\", highlighted in green on Figure 1: SLI 2nd Generation RLV TA-5 IVHM Project Structure. It is the second of three reports for Task 5.3. 3\" V&V\", highlighted in blue on Figure 1.", "num_citations": "5\n", "authors": ["1405"]}
{"title": "Milestones: A model checker combining symbolic model checking and partial order reduction\n", "abstract": " Symbolic techniques and partial order reduction (POR) are two fruitful approaches to deal with the combinatorial explosion of model checking. Unfortunately, past experience has shown that symbolic techniques do not work well for loosely-synchronized models, whereas, by applying POR methods, explicit-state model checkers are able to deal with large concurrent models. This paper presents the Milestones model checker which combines symbolic techniques and POR. Its goal is to verify temporal properties on concurrent systems. On such a system, Milestones allows to check the absence of deadlock, LTL properties, and CTL properties. In order to compare our approach to others, Milestones is able to translate a model into an equivalent Spin model [7] or NuSMV model [4]. We briefly present the theoretical foundation on which Milestones is based on. Then, we present the Milestones model checker, and\u00a0\u2026", "num_citations": "4\n", "authors": ["1405"]}
{"title": "Combining partial-order reduction and symbolic model checking to verify LTL properties\n", "abstract": " BDD-based symbolic techniques and partial-order reduction (POR) are two fruitful approaches to deal with the combinatorial explosion of model checking. Unfortunately, past experience has shown that BDD-based techniques do not work well for loosely-synchronized models, whereas POR methods allow explicit-state model checkers to deal with large concurrent models. This paper presents an algorithm that combines symbolic model checking and POR to verify linear temporal logic properties without the next operator (LTL                   X                 ), which performs better on models featuring asynchronous processes. Our algorithm adapts and combines three methods: Clarke et al.\u2019s tableau-based symbolic LTL model checking, Iwashita et al.\u2019s forward symbolic CTL model checking and Lerda et al.\u2019s ImProviso symbolic reachability with POR. We present our approach, outline the proof of its correctness, and\u00a0\u2026", "num_citations": "4\n", "authors": ["1405"]}
{"title": "Model-based verification of diagnostic systems\n", "abstract": " This paper discusses problems and opportunities inherent in the verification and validation (V&V) of diagnostic (health monitoring) systems. In complex client systems it can be difficult or impossible to even define the system requirements without reference to a functional model of the client system, causing the verification requirements to themselves require verification. This circularity becomes explicit when the diagnostic system to be verified contains, or uses in its development, a functional model of the client system; in some cases identical to or derived from the functional model used to define the verification requirements. In this discussion the system verification problem is decomposed into separate verifications of the algorithms, software engines, and client system models. Formal methods are proposed as being particularly well suited to verification of models representing physical systems.", "num_citations": "4\n", "authors": ["1405"]}
{"title": "A methodology for analyzing human-automation interactions in flight operations using formal verification techniques\n", "abstract": " When designing and developing systems in safety critical or cost intensive environments it is important to identify as much potential risks as possible prior to operating the system. This includes aspects of the interaction between human and automation systems that are prone to issues. This work-in-progress paper describes a methodology that systematically derives relevant analysis questions for complex human-automation interaction systems. It demonstrates how formal models for all components of the human-automation system can be created. These models are used by model checking algorithms to verify the safety properties associated with the selected analysis questions. While this paper includes no evaluation of the methodology, an ongoing evaluation study is outlined based on the life support system (ECLS) of the European science laboratory Columbus, which is part of the International Space Station. Each step of the formal verification methodology is illustrated with the results obtained so far on the ECLS case study.", "num_citations": "3\n", "authors": ["1405"]}
{"title": "Formal verification of autonomy models\n", "abstract": " As NASA\u2019s missions continue to explore Mars and beyond, the great distances from Earth will require that they be able to perform many of their tasks with an increasing amount of autonomy, including navigation, selfdiagnosis, and on-board science. For example, the Autonomous Controller for the In-Situ Propellant Production facility, designed to produce spacecraft fuel on Mars, must operate with infrequent and severely limited human intervention to control complex, real-time, and mission-critical processes over many months in poorly understood environments [9]. While autonomy offers promises of improved capabilities at a reduced operational cost, there are concerns about being able to design, implement and verify such autonomous systems in a reliable and cost-effective manner. Traditional scenario-based testing methods fall short of providing the desired confidence level, because of the combinatorial\u00a0\u2026", "num_citations": "3\n", "authors": ["1405"]}
{"title": "Correctoz\u2013recognizing common mistakes in the programming exercises of a computer science mooc\n", "abstract": " The development of the Internet has led to radical changes in our daily lives. Among these changes, the idea of offering college-level courses freely on the Internet has quickly gained in popularity. The concept, called MOOC, is now promoted by many organizations. edX is one of them and provides on-line courses from the best universities since 2012.The platform is developed on its own open source software that promotes the addition of new tools to improve the quality of learning. One of these tools is called INGInious. It is an automatic on-line grader that takes the submission of a programming exercise as input and provides a feedback in return. Unfortunately, these feedback lack accuracy.", "num_citations": "3\n", "authors": ["1405"]}
{"title": "Learning Safe Interactions and Full-Control\n", "abstract": " This chapter is concerned with the problem of learning how to interact safely with complex automated systems. With large systems, human\u2013machine interaction errors like automation surprises are more likely to happen. Full-control mental models are formal system abstractions embedding the required information to completely control a system and avoid interaction surprises. They represent the internal system understanding that should be achieved by perfect operators. However, this concept provides no information about how operators should reach that level of competence. This work investigates the problem of splitting the teaching of full-control mental models into smaller independent learning units. These units each allow to control a subset of the system and can be learned incrementally to control more and more features of the system. This chapter explains how to formalize the learning process based\u00a0\u2026", "num_citations": "2\n", "authors": ["1405"]}
{"title": "Automatic Generation of Full-Control System Abstraction for Human-Machine Interaction\n", "abstract": " Automated systems are increasingly complex, making it hard to design interfaces for human operators. Human-machine interaction (HMI) errors like automation surprises are more likely to appear and lead to system failures or accidents as testified by several cases detailed in the literature [9, 13, 16]. Researchers in psychology, human factors and ergonomics have been working on HMI issues for several years. Since the mid-1980s, researchers are investigating the use of formal methods to analyse behavioural aspects of HMI. Initially focused on the analysis of specific situations and on the system and it properties [17, 3], the field moved to more generic results based on theories like graph theory, model-checking or theorem proving [19, 2, 8].", "num_citations": "2\n", "authors": ["1405"]}
{"title": "A JavaPathfinder extension to analyse human-machine interactions\n", "abstract": " We present jpf-hmi, a Java Pathfinder (JPF) extension that supports the description and analysis of human machine interaction (HMI) systems. The extension is built on top of jpf-statechart, but differentiates between events in terms of commands, observations and internal actions, as it is typical in the HMI domain. jpf-hmi implements two algorithms for generating concise system models for human operators. It also supports the detection of several types of HMI-specific anomalies known as \u201cautomation surprises\u201d, such as non full-control determinism and mode confusion. These capabilities are provided in addition to the existing more generic property verification that is supported by JPF, and which can also be applied to HMI systems.", "num_citations": "2\n", "authors": ["1405"]}
{"title": "ASE'10: Proceedings of the IEEE/ACM international conference on Automated software engineering\n", "abstract": " La presente simulazione \u00e8 stata realizzata sulla base delle regole riportate nel DM 598/2018 e allegata Tabella A. Cineca non si assume alcuna responsabilit\u00e0 in merito all\u2019uso che il diretto interessato o terzi faranno della simulazione. Si specifica inoltre che la simulazione contiene calcoli effettuati con dati e algoritmi di pubblico dominio e deve quindi essere considerata come un mero ausilio al calcolo svolgibile manualmente o con strumenti equivalenti. Informazioni sui dati: vengono considerati tutti i prodotti in stato definitivo. Per i prodotti indicizzati wos/scopus, l\u2019anno di riferimento e la tipologia sono quelli riportati in banca-dati.", "num_citations": "2\n", "authors": ["1405"]}
{"title": "Verification of Scenario-based Behavioural Models using Capella and PyNuSMV.\n", "abstract": " Scenarios are widely use to capture a set of key system behaviours. They are part of standardised modelling languages like UML and SysML. Precise semantics enable to analyse them at a formal level. In this paper, we show how scenarios can be used to perform early checks on behavioural models in an industrial context by providing a bridge between system modelling with Capella and the NuSMV model checker through the PyNuSMV integration library and using hMSC semantics. Both the modelling front-end and verification backend are discussed and illustrated on a case study of unmanned aerial vehicles. Some interesting extensions to increase the value of the integration are also identified and discussed.", "num_citations": "1\n", "authors": ["1405"]}
{"title": "Une structure de donn\u00e9es pour repr\u00e9senter de grands ensembles de termes \u00e9gaux\n", "abstract": " Nous introduisons une nouvelle structure de donn\u00e9es, appel\u00e9e collection de structures, con\u00e7ue dans le but de simplifier efficacement des expressions. Nous d\u00e9crivons pr\u00e9cis\u00e9ment sa s\u00e9mantique et nous en donnons une impl\u00e9mentation optimale. Nous fournissons une \u00e9tude d\u00e9taill\u00e9e de sa complexit\u00e9 th\u00e9orique que nous compl\u00e9tons par une \u00e9tude exp\u00e9rimentale approfondie. Nous utilisons les collections de structures pour calculer la congruence d\u00e9finie par un ensemble d\u2019\u00e9quations non closes et un ensemble de g\u00e9n\u00e9rateurs, lorsque cette congruence poss\u00e8de un nombre fini de classes d\u2019\u00e9quivalence. Ce r\u00e9sultat nous permet de minimiser en temps lin\u00e9aire les expressions appartenant \u00e0 de telles th\u00e9ories, par exemple, les expressions bool\u00e9ennes utilisant au plus trois variables propositionnelles distinctes. Nous \u00e9tendons cet algorithme pour l\u2019appliquer \u00e0 des th\u00e9ories plus g\u00e9n\u00e9rales comportant trop de classes d\u2019\u00e9quivalence pour \u00eatre repr\u00e9sentables, en th\u00e9orie ou en pratique. Nous obtenons ainsi un algorithme g\u00e9n\u00e9rique de simplification d\u2019expressions dont nous d\u00e9montrons l\u2019utilit\u00e9 pratique en l\u2019appliquant \u00e0 la simplification d\u2019expressions bool\u00e9ennes comportant jusqu\u2019\u00e0 100.000 symboles et 20 variables propositionnelles. Notre algorithme de calcul de congruence g\u00e9n\u00e9ralise les algorithmes connus de fermeture congruente utilis\u00e9s en d\u00e9monstration automatique de th\u00e9or\u00e8me. Nous montrons que notre algorithme, bas\u00e9 sur les collections de structures, est plus simple \u00e0 comprendre et tout aussi efficace que ces m\u00e9thodes, pour la r\u00e9solution d\u2019\u00e9quations closes entre termes. Ind\u00e9pendamment de ces d\u00e9veloppements, nous proposons, dans un\u00a0\u2026", "num_citations": "1\n", "authors": ["1405"]}
{"title": "Adding SAT-based model checking to the PyNuSMV framework\n", "abstract": " NuSMV is an open-source reimplementation and extension of the well known SMV model checker developed at Carnegie Mellon University. While this tool provides a rich set of high performance, state of the art verification features; the size and complexity of its code base make the extension and customization of this tool uneasy. In order to alleviate that problem, PyNuSMV was developed at Louvain Verification Lab as a simpler platform to implement verification tools for new logics in Python. However, in its current version, PyNuSMV is limited to symbolic model checking with BDDs. This thesis proposes an extension of PyNuSMV which features SAT-BMC capabilities available in NuSMV. After that, it describes two experiments that were made to validate the usefulness and performance of our addition to the framework. The first one consists in an implementation of an LTL bounded model checker in Python while the second implements a diagnosability test tool which shows how SAT-BMC tools working with multiple parallel traces can be developed using our addition to the framework. The performance evaluation made in the scope of both experiments revealed that the verification tools developed using our addition to PyNuSMV only add a low overhead compared to an equivalent verification done with NuSMV and, in some cases significantly outperforms what is feasible with the regular NuSMV.", "num_citations": "1\n", "authors": ["1405"]}
{"title": "Tasks Decomposition of System Models for Human-Machine Interaction Analysis\n", "abstract": " This paper is concerned with the problem of learning how to interact safely with complex automated systems. With large systems, human-machine interaction errors like automation surprises are more likely to happen. Previous works have introduced the notion of full-control mental models for operators. These are formal system abstractions embedding the required information to control a system completely and without surprises. Full-control mental models can be used as training material but are ineffective as their control over a system is only guaranteed when fully learned. Operators that have learnt all the possible behaviours of a system have built a full-control mental model. Such models have been defined in [4] and techniques to build minimal ones have been described in [3] and [2]. These models allow to control safely all the features of a system. However, learning full-control mental-models is impractical as it implies to learn all the features of a system in one big step. This means that newly hired operators are useless before they master the full complexity of the system. Large systems might even be too complex for one operator to manage. In that case, the system must be split in tasks dedicated to different operators. This work investigates the problem of decomposing full-control mental models into smaller independent tasks. These tasks each allow to control a subset of the system and can be learned incrementally to control more and more features of the system. This paper proposes an operator that describes how two mental models are merged when learned sequentially....", "num_citations": "1\n", "authors": ["1405"]}
{"title": "Verification of embedded software: from mars to actions\n", "abstract": " Embedded controllers are more and more pervasive and feature more and more advanced capabilities. For space applications in particular, the development of autonomous controllers is seen as a critical technology to enable new mission objectives and scale down operating costs. On the flip side, the validation of intelligent control software poses a huge challenge, both due to the increased complexity of the system itself and the broad spectrum of normal and abnormal conditions in which it has to be able to operate. This talk will follow our journey in applying some modern, analytical verification technologies and tools to the validation of autonomy software, in the context of space applications, at NASA Ames Research Center in California. This route will take us from the concrete, practical dependability requirements for space-bound software that motivated the work down to the deeper, broader issues in\u00a0\u2026", "num_citations": "1\n", "authors": ["1405"]}
{"title": "Verification of Intelligent Control Software\n", "abstract": " Autonomous embedded controllers are seen as a critical technology to enable new mission objectives and scale down operating costs for space applications. However, the validation of intelligent controls software poses a huge challenge, where traditional testing approaches fall short of providing the required level of confidence for such safety-critical applications. This is an overview of recent research in applying modern, analytical verification technologies and tools to the validation of autonomy software, in the context of space applications, at NASA Ames Research Center in California, with a particular focus on model-based approaches to autonomous control, and more specifically fault diagnosis systems. We have developed and experimented with two lines of tools, both related to model checking techniques. Verifying diagnosis systems and models has led to considering the issue of diagnosability, in the sense of checking whether a system provides sufficient observations to determine and track its internal state with sufficient accuracy. We discuss how this kind of question can be reduced to a modified model checking problem. Diagnosability analysis also expands to the domain of epistemic (ie knowledge) models and logics.", "num_citations": "1\n", "authors": ["1405"]}
{"title": "Challenges arising from applications\n", "abstract": " The Application: Health Maintenance for a Next-Gen Space Shuttle NASA is investigating automated and integrated technologies for monitoring the health of future space shuttles and their ground support equipment. This application .eld, known as Integrated Vehicle Health Management (IVHM), is being developed in by the aerospace industry under the auspices of NASA\u2019s Space Launch Initiative (SLI) program. The proposed IVHM system includes advanced software technologies such as model-based diagnosis using NASA\u2019s Livingstone system. This holds the promise of automating the diagnosis across a number of subsystem components and possible scenarios that is not tractable for more conventional diagnosis techniques. On the .ip side, however, it also raises multiple technical challenges, both related to the diagnosis techniques themselves and to their veri.cation and validation (V&V) for fight\u00a0\u2026", "num_citations": "1\n", "authors": ["1405"]}
{"title": "Model Checking for Software\n", "abstract": " Model Checking for Software Page 1 Model Checking for Software Charles Pecheur UC Louvain Charles.Pecheur@uclouvain.be Page 2 MoVES WP5-6-7 meeting \u00a9 Charles Pecheur and Willem Visser 2000\u20132008 2 Credits \u2022 Based on: Model Checking for Software Willem Visser Charles Pecheur RIACS / NASA Ames {wvisser,pecheur}@ptolemy.arc.nasa.gov 2000 Page 3 MoVES WP5-6-7 meeting \u00a9 Charles Pecheur and Willem Visser 2000\u20132008 3 Menu \u2022 Part I - Explicit State Model Checking \u2013 What is model checking? \u2013 Kripke structures, temporal logic \u2013 Automata-theoretic model checking \u2013 Partial-order reduction, abstraction \u2013 Model Checking Programs: Java PathFinder \u2022 Part II - Symbolic Model Checking \u2013 Principles: BDDs \u2013 Tools: SMV \u2013 Application: model-based diagnosis Page 4 Part I Explicit State Model Checking Page 5 MoVES WP5-6-7 meeting \u00a9 Charles Pecheur and Willem Visser 2000\u20132008 5 \u2026", "num_citations": "1\n", "authors": ["1405"]}