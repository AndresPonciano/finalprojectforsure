{"title": "Toward reference models for requirements traceability\n", "abstract": " Requirements traceability is intended to ensure continued alignment between stakeholder requirements and various outputs of the system development process. To be useful, traces must be organized according to some modeling framework. Indeed, several such frameworks have been proposed, mostly based on theoretical considerations or analysis of other literature. This paper, in contrast, follows an empirical approach. Focus groups and interviews conducted in 26 major software development organizations demonstrate a wide range of traceability practices with distinct low-end and high-end users of traceability. From these observations, reference models comprising the most important kinds of traceability links for various development tasks have been synthesized. The resulting models have been validated in case studies and are incorporated in a number of traceability tools. A detailed case study on the use of\u00a0\u2026", "num_citations": "1305\n", "authors": ["1444"]}
{"title": "Query optimization in database systems\n", "abstract": " These methods are presented in the framework of a general query evaluation procedure using the relational calculus representation of queries. In addition, nonstandard query optimization issues such as higher level query evaluation, query optimization in distributed databases, and use of database machines are addressed. The focus, however, is on query optimization in centralized database systems.", "num_citations": "1003\n", "authors": ["1444"]}
{"title": "Fundamentals of data warehouses\n", "abstract": " Data warehouses have captured the attention of practitioners and researchers alike. But the design and optimization of data warehouses remains an art rather than a science. This book presents the first comparative review of the state of the art and best current practice of data warehouses. It covers source and data integration, multidimensional aggregation, query optimization, update propagation, metadata management, quality assessment, and design optimization. Also, based on results of the European Data Warehouse Quality project, it offers a conceptual framework by which the architecture and quality of data warehouse efforts can be assessed and improved using enriched metadata management combined with advanced techniques from databases, business modeling, and artificial intelligence. For researchers and database professionals in academia and industry, the book offers an excellent introduction to the issues of quality and metadata usage in the context of data warehouses.", "num_citations": "896\n", "authors": ["1444"]}
{"title": "Integrated Fact and Rule Management Based on Database Technology\n", "abstract": " Database programming languages integrate concepts of databases and programming languages to provide both, implementation tools for data-intensive applications and high-level user interfaces to databases. Frequently, database programs contain a large amount of application knowledge which is hidden in the procedural code and thus di cult to maintain with changing data and user views.This chapter presents a rst attempt to improve the situation by supporting the integrated de nition and management of data and rules based on a set-oriented and predicative approach. For the de nition of rules, we introduce and justify a new declarative language construct called constructor. Furthermore, we demonstrate how a Recursive Database Model can be used for constructor representation, thus allowing for the de nition, update, and querying of large rule bases. The use of database technology for integrated fact and rule base management is shown to have some important advantages in terms of fact and rule integrity, question-answering, and explanation of results.", "num_citations": "719\n", "authors": ["1444"]}
{"title": "ConceptBase\u2014a deductive object base for meta data management\n", "abstract": " Deductive object bases attempt to combine the advantages of deductive relational databases with those of object-oriented databases. We review modeling and implementation issues encountered during the development of ConceptBase, a prototype deductive object manager supporting the Telos object model. Significant features include: 1) The symmetric treatment of object-oriented, logic-oriented and graph-oriented perspectives, 2) an infinite metaclass hierarchy as a prerequisite for extensibility and schema evolution, 3) a simple yet powerful formal semantics used as the basis for implementation, 4) a client-server architecture supporting collaborative work in a wide-area setting. Several application experiences demonstrate the value of the approach especially in the field of meta data management.", "num_citations": "449\n", "authors": ["1444"]}
{"title": "The future of e-learning: a shift to knowledge networking and social software\n", "abstract": " The main aim of Knowledge Management (KM) is to connect people to quality knowledge as well as people to people in order to peak performance. This is also the primary goal of Learning Management (LM). In fact, in the world of e-learning, it is more widely recognised that how learning content is used and distributed by learners might be more important than how it is designed. In the last few years, there has been an increasing focus on social software applications and services as a result of the rapid development of Web 2.0 concepts. In this paper, we argue that LM and KM can be viewed as two sides of the same coin, and explore how Web 2.0 technologies can leverage knowledge sharing and learning and enhance individual performance whereas previous models of LM and KM have failed, and present a social software driven approach to LM and KM.", "num_citations": "400\n", "authors": ["1444"]}
{"title": "Scenario management: An interdisciplinary approach\n", "abstract": " Scenario management (SM) means different things to different people, even though everyone seems to admit its current importance and its further potential. In this paper, we seek to provide an interdisciplinary framework for SM from three major disciplines that use scenarios \u2013 strategic management, human\u2013computer interaction, and software and systems engineering \u2013 to deal with description of current and future realities. In particular, we attempt to answer the following questions: How are scenarios developed and used in each of the three disciplines? Why are they becoming important? What are current research contributions in scenario management? What are the research and practical issues related to the creation and use of scenarios, in particular in the area of requirements engineering? Based on brainstorming techniques, this paper proposes an interdisciplinary definition of scenarios, frameworks for\u00a0\u2026", "num_citations": "358\n", "authors": ["1444"]}
{"title": "MEDIATOR: Towards a negotiation support system\n", "abstract": " Mediator is a negotiation support system (NSS) based on evolutionary systems design (ESD) and database-centered implementation. It supports negotiations by consensus seeking through exchange of information and, where consensus is incomplete, by compromise. The negotiation problem is shown\u2014graphically or as relational data in matrix form\u2014in three spaces as a mapping from control space to goal space and (through marginal utility functions) to utility space. Within each of these spaces the negotiation process is characterized by adaptive change, ie, mappings of group target and feasible sets by which these sets are redefined in seeking a solution characterized by a single-point intersection between them. This concept is being implemented in Mediator, a data-based micro-mainframe NSS intended to support the players and a human mediator in multi-player decision situations. Each player employs\u00a0\u2026", "num_citations": "321\n", "authors": ["1444"]}
{"title": "A clustering approach for collaborative filtering recommendation using social network analysis.\n", "abstract": " Collaborative Filtering (CF) is a well-known technique in recommender systems. CF exploits relationships between users and recommends items to the active user according to the ratings of his/her neighbors. CF suffers from the data sparsity problem, where users only rate a small set of items. That makes the computation of similarity between users imprecise and consequently reduces the accuracy of CF algorithms. In this article, we propose a clustering approach based on the social information of users to derive the recommendations. We study the application of this approach in two application scenarios: academic venue recommendation based on collaboration information and trust-based recommendation. Using the data from DBLP digital library and Epinion, the evaluation shows that our clustering technique based CF performs better than traditional CF algorithms.", "num_citations": "282\n", "authors": ["1444"]}
{"title": "Architecture and quality in data warehouses: An extended repository approach\n", "abstract": " Most database researchers have studied data warehouses (DW) in their role as buffers of materialized views, mediating between update-intensive OLTP systems and query-intensive decision support. This neglects the organizational role of data warehousing as a means of centralized information flow control. As a consequence, a large number of quality aspects relevant for data warehousing cannot be expressed with the current DW meta models. This paper makes two contributions towards solving these problems. Firstly, we enrich the meta data about DW architectures by explicit enterprise models. Secondly, many very different mathematical techniques for measuring or optimizing certain aspects of DW quality are being developed. We adapt the Goal-Question-Metric approach from software quality management to a meta data management environment in order to link these special techniques to a generic\u00a0\u2026", "num_citations": "275\n", "authors": ["1444"]}
{"title": "Requirements tracing\n", "abstract": " In this ever-changing business and tech-nology environment, the risk of inconsis-tencies in systems development and evolution multiplies. Experience reuse becomes a necessity in order to control quality, costs, and time, even when personnel changes. Requirements tracing is emerging as an effective bridge that aligns system evolution with changing stakeholder needs. It also helps uncover unexpected problems and innovative opportunities, and lays the groundwork for corporate knowledge management. However, few organizations fully recognize\u2014or even understand\u2014the true potential of the new methods and tools in requirements tracing. A network of projects worldwide has investigated the issues, studied advanced industry solutions, and developed research prototypes in order to provide a more coherent view of where we are moving. Far removed from its time-honored definition as a fuzzy early phase of\u00a0\u2026", "num_citations": "266\n", "authors": ["1444"]}
{"title": "An ontology-based approach to knowledge management in design processes\n", "abstract": " Engineering design processes comprise highly creative and knowledge-intensive tasks that involve extensive information exchange and communication among distributed teams. In such dynamic settings, traditional information management systems fail to provide adequate support due to their inflexible data structures and hard-wired usage procedures, as well as their restricted ability to integrate process and product information. In this paper, we advocate the idea of Process Data Warehousing as a means to provide a knowledge management and integration platform for such design processes. The key idea behind our approach is a flexible ontology-based schema with formally defined semantics that enables the capture and reuse of design experience, supported by advanced computer science methods.", "num_citations": "228\n", "authors": ["1444"]}
{"title": "Mobile web service provisioning\n", "abstract": " This paper, discusses the confluence of two major recent trends in distributed information systems engineering: the evolution from static content via personalized adaptive information provisioning to Web Services, and the emergence of mobile terminals with sufficient speed to serve as parts of information systems. The combination of both trends yields the idea of mobile Web Services. While a few pioneering mobile Web Service client systems have appeared recently, this paper explores the logical next step. Whether it is feasible to use mobile terminals such as Smart Phones also as Web Service providers (\"Mobile Hosts\"). We first discuss the desirability of such Mobile Hosts, then discuss the challenges for design and implementation, and finally present a prototype implementation that has been developed and evaluated in cooperation with a major mobile phone vendor.", "num_citations": "219\n", "authors": ["1444"]}
{"title": "Toward a personal learning environment framework\n", "abstract": " Over the past decade, it has been argued that technology-enhanced learning (TEL) could respond to the needs of the new knowledge society and transform learning. However, despite isolated achievements, TEL has not succeeded in revolutionizing education and learning processes. Most current TEL initiatives still take a centralized technology-push approach in which learning content is pushed to a predefined group of learners in closed environments. A fundamental shift toward a more open and learner-pull model for learning is needed. Recently, the Personal Learning Environment (PLE) concept has emerged to open new doors for more effective learning and overcome many of the limitations of traditional TEL models. In this paper, the authors present theoretical, design, implementation, and evaluation details of PLEF, a framework for mashup personal learning environments. The primary aim of PLEF is to help\u00a0\u2026", "num_citations": "198\n", "authors": ["1444"]}
{"title": "Managing multiple requirements perspectives with metamodels\n", "abstract": " Stakeholder conflicts can be productive in requirements engineering. Capturing, monitoring, and resolving multiple perspectives is difficult and time consuming when done by hand. Our experience with ConceptBase shows that a simple but customizable metamodeling approach, combined with an advanced query facility, produces higher quality requirements documents in less time.", "num_citations": "188\n", "authors": ["1444"]}
{"title": "An optimizing prolog front-end to a relational query system\n", "abstract": " An optimizing translation mechanism for the dynamic interaction between a logic-based expert system written in PROLOG and a relational database accessible through SQL is presented. The mechanism makes use of an intermediate language that decomposes the optimization problem and makes the proposed approach target-language independent. It can either facilitate expert system - database interaction, e.g., when integrating expert systems into business systems, or augment existing databases with (external) deductive capabilities.", "num_citations": "182\n", "authors": ["1444"]}
{"title": "The Web 2.0 driven SECI model based learning process\n", "abstract": " Nonaka and his knowledge transformation model SECI revolutionized the thinking about organizations as social learning systems. He introduced technical concepts like hypertext into organizational theory. Now, after 15 years Web 2.0 concepts seem to be an ideal fit with Nonaka's SECI approach opening new doors for more personal, dynamic, and social learning on a global scale. In this paper, we present an extended view of blended learning which includes the combination of formal and informal learning, knowledge management, and Web 2.0 concepts into one integrated solution, by discussing what we call the Web 2.0 driven SECI model based learning process.", "num_citations": "173\n", "authors": ["1444"]}
{"title": "Design and analysis of quality information for data warehouses\n", "abstract": " Data warehouses are complex systems that have to deliver highly-aggregated, high quality data from heterogeneous sources to decision makers. Due to the dynamic change in the requirements and the environment, data warehouse system rely on meta databases to control their operation and to aid their evolution. In this paper, we present an approach to assess the quality of the data warehouse via a semantically rich model of quality management in a data warehouse. The model allows stakeholders to design abstract quality goals that are translated to executable analysis queries on quality measurements in the data warehouse\u2019s meta database. The approach is being implemented using the ConceptBase meta database system.", "num_citations": "164\n", "authors": ["1444"]}
{"title": "Performance modeling of distributed and replicated databases\n", "abstract": " The paper surveys performance models for distributed and replicated database systems. Over the last 20 years (1980-2000), a variety of such performance models have been developed and they differ in: (1) which aspects of a real system are or are not captured in the model (e.g., replication, communication, nonuniform data access, etc.); and (2) how these aspects are modeled. We classify the different alternatives and modeling assumptions and discuss their interdependencies and expressiveness for the representation of distributed databases. This leads to a set of building blocks for analytical performance models. To illustrate the work that is surveyed, we select a combination of these proven modeling concepts and give an example of how to compose a balanced analytical model of a replicated database. We use this example to show how to derive meaningful performance values and to discuss the applicability\u00a0\u2026", "num_citations": "161\n", "authors": ["1444"]}
{"title": "Theories underlying requirements engineering: An overview of NATURE at genesis\n", "abstract": " NATURE is a collaborative basic research project on theories underlying requirements engineering funded by the ESPRIT III program of the European communities. Its goals are to develop a theory of knowledge representation that embraces subject, usage and development worlds surrounding the system, including expressive freedoms; a theory of domain engineering that facilitates the identification, acquisition and formalization of domain knowledge as well as similarity-based matching and classifying of software engineering knowledge; and a process engineering theory that promotes context and decision-based control of the development process. These theories are integrated and evaluated in a prototype environment constructed around an extended version of the conceptual modeling language Telos.< >", "num_citations": "152\n", "authors": ["1444"]}
{"title": "Domain specific DSS tools for knowledge-based model building\n", "abstract": " The formulation of complex planning models, such as linear programming (LP) systems, is a difficult task that enjoys little support by current decision support systems. It is hypothesized that current artificial intelligence technology is insufficient to build generalized formulation tools that would be usable by OR-naive end users. As an alternative, this paper presents a domain-specific approach to knowledge-based model formulation which combines the use of \u2018syntactic\u2019 knowledge about linear programming with \u2018semantic\u2019 guidance by knowledge specific to some application domain. As a prototype of this approach, a model formulation tool for LP-based production management is being developed at New York University.", "num_citations": "151\n", "authors": ["1444"]}
{"title": "Incremental maintenance of externally materialized views\n", "abstract": " With the advent of the Internet, access to database servers from autonomous clients will become more and more popular. In this paper, we propose a monitoring service that could be o ered by such database servers, and present algorithms for its implementation. In contrast to published view maintenance algorithms, we do not assume that the server has access to the original materialization when computing di erential view changes to be noti ed. We also do not assume any database capabilities on the client side and therefore compute precisely the required di erentials rather than just an approximation, as is done by cache coherence techniques in homogeneous clientserver databases. The method has been implemented in ConceptBase, a meta data management system supporting an Internet-based client-server architecture, and tried out in some cooperative design applications.", "num_citations": "149\n", "authors": ["1444"]}
{"title": "Data provenance: A Cctegorization of existing approaches\n", "abstract": " In many application areas like e-science and data-warehousing detailed information about the origin of data is required. This kind of information is often referred to as data provenance or data lineage. The provenance of a data item includes information about the processes and source data items that lead to its creation and current representation. The diversity of data representation models and application domains has lead to a number of more or less formal definitions of provenance. Most of them are limited to a special application domain, data representation model or data processing facility. Not surprisingly, the associated implementations are also restricted to some application domain and depend on a special data model. In this paper we give a survey of data provenance models and prototypes, present a general categorization scheme for provenance models and use this categorization scheme to study the properties of the existing approaches. This categorization enables us to distinguish between different kinds of provenance information and could lead to a better understanding of provenance in general. Besides the categorization of provenance types, it is important to include the storage, transformation and query requirements for the different kinds of provenance information and application domains in our considerations. The analysis of existing approaches will assist us in revealing open research problems in the area of data provenance.", "num_citations": "143\n", "authors": ["1444"]}
{"title": "Communications design for Co-oP: a group decision support system\n", "abstract": " Decision Support Systems (DSSs), computer-based systems intended to assist managers in preparing and analyzing decisions, have been single-user systems for most of the past decade. Only recently has DSS research begun to study the implications of the fact that most complex managerial decisions involve multiple decision makers and analysts. A number of tools for facilitating group decisions have been proposed under the label Group Decision Support Systems (GDSSs). One of the most important functions of a GDSS is to provide problem-oriented services for communication among decision makers. On the basis of an analysis of the communication requirements in various group decision settings, this paper presents an architecture for defining and enforcing dynamic application-level protocols that organize decision group interaction. The architecture has been implemented on a network of personal\u00a0\u2026", "num_citations": "142\n", "authors": ["1444"]}
{"title": "Common subexpression isolation in multiple query optimization\n", "abstract": " The simultaneous optimization of multiple queries submitted to a database system may lead to substantial savings over the current approach of optimizing each query separately. Isolating common subexpressions in multiple queries and treating their execution as a sharable resource are important prerequisites. This chapter presents techniques for recognizing, supporting, and exploiting common subexpressions in record-oriented, relational algebra, domain relational calculus, and tuple relational calculus query representations. It also investigates preconditions that transaction management mechanisms must satisfy to make multiple query optimization effective.", "num_citations": "140\n", "authors": ["1444"]}
{"title": "The 3P learning model.\n", "abstract": " Recognizing the failures of traditional Technology Enhanced Learning (TEL) initiatives to achieve performance improvement, we need to rethink how we design new TEL models that can respond to the learning requirements of the 21st century and mirror the characteristics of knowledge and learning which are fundamentally personal, social, distributed, ubiquitous, flexible, dynamic, and complex in nature. In this paper, we discuss the 3P learning model; a vision of learning characterized by the convergence of lifelong, informal, and personalized learning within a social context. The 3P learning model encompasses three core elements: Personalization, Participation, and Knowledge-Pull. We then present the social software supported learning framework as a framework that illustrates the 3P learning model in action, based on Web 2.0 concepts and social software technologies.", "num_citations": "122\n", "authors": ["1444"]}
{"title": "A framework for choosing a database query language\n", "abstract": " This paper presents a systematic approach to matching categories of query language interfaces with the requirements of certain user types. The method is based on a trend model of query language development on the dimensions of functional capabilities and usability. From the trend model the following are derived: a classification scheme for query languages, a criterion hierarchy for query language evaluation, a comprehensive classification scheme of query language users and their requirements, and preliminary recommendations for allocating language classes to user types.The method integrates the results of existing human factors studies and provides a structured framework for future research in this area. Current and expected developments are exemplified by the description of \u201cnew generation\u201d database query languages. In a practical query language selection problem, the results of this paper can be\u00a0\u2026", "num_citations": "114\n", "authors": ["1444"]}
{"title": "A field evaluation of natural language for data retrieval\n", "abstract": " Although a large number of natural language database interfaces have been developed, there have been few empirical studies of their practical usefulness. This paper presents the design and results of a field evaluation of a natural language system-NLS-used for data retrieval.", "num_citations": "105\n", "authors": ["1444"]}
{"title": "Data warehouse process management\n", "abstract": " Previous research has provided metadata models that enable the capturing of the static components of a data warehouse architecture, along with information on different quality factors over these components. This paper complements this work with the modeling of the dynamic parts of the data warehouse. The proposed metamodel of data warehouse operational processes is capable of modeling complex activities, their interrelationships, and the relationship of activities with data sources and execution details. Moreover, the metamodel complements the existing architecture and quality models in a coherent fashion, resulting in a full framework for quality-oriented data warehouse management, capable of supporting the design, administration and especially evolution of a data warehouse. Finally, we exploit our framework to revert the widespread belief that data warehouses can be treated as collections of\u00a0\u2026", "num_citations": "103\n", "authors": ["1444"]}
{"title": "Knowledge sharing and negotiation support in multiperson decision support systems\n", "abstract": " A number of DSS for supporting decisions by more than one person have been proposed. These can be categorized by spatial distance (local vs. remote), temporal distance (meeting vs. mailing), commonality of goals (cooperation vs. bargaining), and control (democratic vs. hierarchical). Existing frameworks for model management in single-user DSS seem insufficient for such systems. This paper views multiperson DSS as a loosely coupled system of model and data bases which may be human (the DSS builders and users) or computerized. The system's components have different knowledge bases and may have different interests. Their interaction is characterized by knowledge sharing for uncertainty reduction and cooperative problem-solving, and negotiation for view integration, consensus-seeking, and compromise. Requirements for the different types of multiperson DSS can be formalized as application-level\u00a0\u2026", "num_citations": "103\n", "authors": ["1444"]}
{"title": "Continuous requirements management for organisation networks: a (dis) trust-based approach\n", "abstract": " Recently, viewpoint resolution methods which make conflicts productive for requirements engineering have gained popularity in organisational information systems. However, when extending such methods beyond organisational boundaries to inter-organisational social networks, sociological research indicates that a delicate balance of trust in individuals, confidence in the network as a whole, and watchful distrust becomes a key success factor. We capture these relationships in the so-called TCD (Trust\u2013Confidence\u2013Distrust) approach and demonstrate how this approach can be supported by a dynamic requirements engineering environment that combines the structural analysis of strategic dependencies and rationales, with the interaction between planning, tracing, and communicative action. An example drawn from an ongoing case study in entrepreneurship networks illustrates our approach\u00a0\u2026", "num_citations": "102\n", "authors": ["1444"]}
{"title": "Coupling expert systems with database management systems\n", "abstract": " The combined use of Database Management Systems (DBMS) and Artificial Intelligence-based Expert Systems (ES) is potentially very valuable for modern business applications. The large body of facts usually required in business information systems can be made available to an ES through an existing commercial DBMS. Furthermore, the DBMS itself can be used more intelligently and operated more efficiently if enhanced with ES features. However, the implementation of a DBMS-ES cooperation is very difficult. We explore practical benefits of the cooperative use of DBMS and ES, as well as the research challenges it presents. Strategies for providing data from a DBMS to an ES are given; complementary strategies for providing intelligence from an ES to a DBMS are also presented. Finally, we discuss architechural issues such as degree of coupling, and combination with quantitative methods. As an illustration, a research effort at New York University to integrate a logic-based business ES with a relational DBMS is described.", "num_citations": "101\n", "authors": ["1444"]}
{"title": "A DSS for cooperative multiple criteria group decision making\n", "abstract": " Many decisions in organizations are made, or at least prepared, by multiple cooperatingdecision makers. A distributed DSS architecture is presented that connects multipleindividual DSS to a group DSS. The group decision making process is supported by content-orientedmethods based on extensions of multiple criteria decision making methods, as wellas by process-oriented techniques using a computerized conferencing system. A prototypeof the system is operational on a personal computer configuration.", "num_citations": "98\n", "authors": ["1444"]}
{"title": "ConceptBase V3. 0 user manual\n", "abstract": " ConceptBase is a deductive object base management system. Its data model is a conceptual modeling language making it particularily well-suited for design applications. Earlier prototypes [JJR88, EJJ* 89] have been used in projects ranging from development support for data-intensive applications [JMSV90], requirements engineering [RD92], and version&configuration management [RJG* 91] to co-authoring of technical documents [HJEK90].", "num_citations": "96\n", "authors": ["1444"]}
{"title": "Systematic development of data mining-based data quality tools\n", "abstract": " Publisher SummaryThe widespread use of source-integrating, analysis-oriented data warehouses emphasizes the value of quality information in today's business success. This chapter reveals that the successful data auditing requires sophisticated error detection facilities in combination with high quality proposals for replacing erroneous data values. To screen the full database, only data mining algorithms that scale well with the size of training sets can be employed. For both performance and quality, the search space of such inducers should be pre-restricted by a domain analysis, which also helps to construct the test environment. Further, a data-auditing tool should work both when training sets and test data are separate and when there is only a single database, which serves both for training and data audit. These demands are covered by the approach for the systematic development of a data-auditing tool that\u00a0\u2026", "num_citations": "95\n", "authors": ["1444"]}
{"title": "On integrating logic programming and databases\n", "abstract": " On integrating logic programming and databases | Proceedings from the first international workshop on Expert database systems ACM Digital Library home ACM home Google, Inc. (search) Advanced Search Browse About Sign in Register Advanced Search Journals Magazines Proceedings Books SIGs Conferences People More Search ACM Digital Library SearchSearch Advanced Search Browse Browse Digital Library Collections More HomeBrowse by TitleProceedingsProceedings from the first international workshop on Expert database systemsOn integrating logic programming and databases Article On integrating logic programming and databases Share on Authors: Michael L. Brodie profile image ML Brodie View Profile , Matthias Jarke profile image M Jarke View Profile Authors Info & Affiliations Publication: Proceedings from the first international workshop on Expert database systemsJanuary 1986 Pages \u2026", "num_citations": "95\n", "authors": ["1444"]}
{"title": "Communications requirements for group decision support systems\n", "abstract": " Despite the increasing interest in developing group decision support systems (gdss), it remains unclear how communications between participants of a group problem solving process can be designed, implemented, and utilized in a computer-based distributed GDSS. This paper presents a framework for developing a Communications component for the GDSS. It supports conceptualization of a communication system as being composed of four main modules: the Group Norm Monitor, the Group Norm Filter, the Invocation Mechanism, and the individual decision support system (idss)-to-gdss Document Formatter. In reference to the International Standard Organization (ISo) Open System Architecture, the three first modules are integrated in the Application layer, and the last module in the Presentation layer.", "num_citations": "90\n", "authors": ["1444"]}
{"title": "Designing a generalized multiple criteria decision support system\n", "abstract": " Decision support systems are of many kinds depending on the models and techniques employed in them. Multiple criteria decision making techniques constitute an important class of DSS with unique software requirements. This paper stresses the importance of interactive MCDM methods since these facilitate learning through all stages of the decision making process. We first describe some features of Multiple Criteria Decision Support Systems (MCDSSs) that distinguish them from classical DSSs. We then outline a software architecture for a MCDSS which has three basic components: a Dialog Manager, an MCDM Model Manager, and a Data Manager. We describe the interactions that occur between these three software components in an integrated MCDSS and outline a design for the Data Manager which is based on a concept of levels of data abstraction.", "num_citations": "90\n", "authors": ["1444"]}
{"title": "LaaN: Convergence of knowledge management and technology-enhanced learning\n", "abstract": " Knowledge Management (KM) and Technology-Enhanced Learning (TEL) have attracted attention over the past two decades and are meanwhile considered as important means to increase individual and organizational performance. There is, however, a wide agreement that traditional KM and TEL models have failed to cope with the fast-paced change and critical challenges of the new knowledge era. In this paper, we propose a vision for future KM/TEL approaches which aims to fulfill the needs of the new knowledge landscape by introducing the Learning as a Network (LaaN) theory as a new learning theory characterized by the convergence of KM and TEL within a learner-centric knowledge environment. We further discuss a possible implementation of the LaaN theory based on the personal learning environment (PLE) concept.", "num_citations": "88\n", "authors": ["1444"]}
{"title": "The nature of requirements Engineering\n", "abstract": " Archive ouverte HAL - The NATURE of Requirements Engineering Acc\u00e9der directement au contenu Acc\u00e9der directement \u00e0 la navigation Toggle navigation CCSD HAL HAL HALSHS TEL M\u00e9diHAL Liste des portails AUR\u00e9HAL API Data Documentation Episciences.org Episciences.org Revues Documentation Sciencesconf.org Support hal Accueil D\u00e9p\u00f4t Consultation Les derniers d\u00e9p\u00f4ts Par type de publication Par discipline Par ann\u00e9e de publication Par structure de recherche Les portails de l'archive Recherche Documentation hal-00707563, version 1 Chapitre d'ouvrage The NATURE of Requirements Engineering Mattias Jarke Colette Rolland 1 Alistair Sutcliffe Ralf Domges D\u00e9tails 1 CRI - Centre de Recherche en Informatique de Paris 1 Type de document : Chapitre d'ouvrage Domaine : Informatique [cs] / Autre [cs.OH] Liste compl\u00e8te des m\u00e9tadonn\u00e9es Voir https://hal.archives-ouvertes.fr/hal-00707563 Contributeur \u2026", "num_citations": "87\n", "authors": ["1444"]}
{"title": "The AI potential of model management and its central role in decision support\n", "abstract": " The paper stresses the general idea that \u2018intelligence\u2019 may be viewed to a great extent as the ability to model relevant parts of reality and to draw relevant conclusions from such models. Consequently, future software systems should be able to adequately handle a significant body of models for specific domains together with associated algorithmic tools. With respect to decision making and decision support, which require a high degree of cognitive sophistication, this leads to the quest for integrating into DSS results from model-oriented research in fields such as stochastics, statistics, decision theory, operations research and business applications. Based on such modelling capabilities, a DSS should be able to take a more active, normatively based role in aiding a decision maker. This kind of support requires strong interactive capabilities, driven by online comput\u00e4tional results and based on parallel problem\u00a0\u2026", "num_citations": "86\n", "authors": ["1444"]}
{"title": "Learn-as-you-go: new ways of cloud-based micro-learning for the mobile web\n", "abstract": " Micro-learning refers to short-term learning activities on small learning units. In our contemporary mobile/web society, micro-learning pertains to small pieces of knowledge based on web resources. Micro-learning falls into the group of informal learning processes. The existing web and mobile services have great potential to support informal learning processes, especially micro-learning. However, several specific aspects need to be considered. In this paper, we propose a micro-learning model based on three technical aspects: (i) ubiquitous learning resource acquisition; (ii) cloud-based data management; and (iii) tag-based regulation of learning processes and content. A micro-learning prototype consisting of an Android application and a web browser add-on is evaluated in the use case of bilingual vocabulary learning. The initial prototype evaluation study shows promising results in enhanced\u00a0\u2026", "num_citations": "85\n", "authors": ["1444"]}
{"title": "GeRoMe: A Generic Role Based Metamodel for Model Management\n", "abstract": " Abstract                              The goal of Model Management is the development of new technologies and mechanisms to support the integration, evolution and matching of data models at the conceptual and logical design level. Such tasks are to be performed by means of a set of model management operators which work on models and their elements, without being restricted to a particular metamodel (e.g. the relational or UML metamodel).               We propose that generic model management should employ a generic metamodel (GMM) which serves as an abstraction of particular metamodels and preserves as much of the original features of modeling constructs as possible. A naive generalization of the elements of concrete metamodels in generic metaclasses would lose some of the specific features of the metamodels, or yield a prohibitive number of metaclasses in the GMM. To avoid these problems, we\u00a0\u2026", "num_citations": "84\n", "authors": ["1444"]}
{"title": "ConceptBase: Managing conceptual models about information systems\n", "abstract": " ConceptBase is a meta data management system intended to support the cooperative development and evolution of information systems with multiple interacting formalisms. It supports a simple logic-based core language, O-Telos, which integrates deductive and object-oriented features in order to support the syntactical, graphical, and semantic customization of modeling languages as well as analysis in multi-language modeling environments.", "num_citations": "79\n", "authors": ["1444"]}
{"title": "A software process data model for knowledge engineering in information systems\n", "abstract": " Knowledge engineering for information systems is a long-term, multi-person task that requires tight control and memorization not only of what knowledge is acquired but also of why and how it is acquired. We propose a software process data model as the foundation of a knowledge-based software information system that emphasizes control, support and documentation of design decision-making and tool integration in information systems environments.The model is developed along two dimensions. Firstly, it defines how to represent and integrate design objects (what), design decisions (why) and design tools (how). Secondly, it exploits the abstraction mechanisms of the extensible hybrid knowledge representation language CML/Telos to manage the evolution not only of particular software projects, but also of the software development environment in which these projects operate. Modular aggregation relates\u00a0\u2026", "num_citations": "79\n", "authors": ["1444"]}
{"title": "The economics of end-user development\n", "abstract": " The productivity paradox raised concerns that IT investment rarely leads to productivity gains [1]. End-user development (EUD), however, may provide the answer to this concern if increased productivity can be demonstrated. Recent research has questioned the productivity paradox and substantially improved our understanding about how IT productivity may be influenced by the manner of change.", "num_citations": "78\n", "authors": ["1444"]}
{"title": "Requirements bazaar: Social requirements engineering for community-driven innovation\n", "abstract": " The innovation potential of niche communities often remains inaccessible to service providers due to a lack of awareness and effective negotiation between these two groups. Requirements Bazaar, a browser-based social software for Social Requirements Engineering (SRE), aims at bringing together communities and service providers into such a negotiation process. Communities should be supported to express and trace their requirements and eventually receive a realization. Service providers should be supported in discovering relevant innovative requirements to maximize impact with a realization. In this paper we present Requirements Bazaar with focus on four aspects: requirements specification, a workflow for co-creation, workspace integration and personalizable requirements prioritization.", "num_citations": "75\n", "authors": ["1444"]}
{"title": "Web-based learning with non-linear multimedia stories\n", "abstract": " Stories and story-telling are a cultural achievement of significant relevance, even in modern times. Since ancient times stories have served to entertain and teach mankind to \u201ctransmit\u201d knowledge from generation to generation. Story-telling ranges from simple aural narrations to traditional inter-generational discourse and, in modern times, workflow-oriented organizational learning. Web-based systems are by nature well-suited to support learning from digital stories in communities of practice. Despite the potential of story-telling to foster knowledge sharing in communities its full power to stimulate community-based learning processes in yet only marginally exploited. Although there are many story-telling approaches, most of them are not suitable for non-linear story creation and consumption. In addition, most of these are not based on a well defined methodology that underpins the story development process\u00a0\u2026", "num_citations": "72\n", "authors": ["1444"]}
{"title": "Scenarios for modeling\n", "abstract": " 48 January 1999/Vol. 42, No. 1 COMMUNICATIONS OF THE ACM direction (what impact has the system on its environment?). Scenario purpose and impact showed much more variation than expected from the research literature. While researchers discuss the application of scenarios for making abstract models understandable, to reach partial agreement and consistency, practitioners also use scenarios for task decomposition in complex projects, as a linkage between development phases, and as design aids and boundary conditions for object models. Consequently, the life cycle of scenarios is also much more involved than is addressed by current research. The framework shown in Figure 1 covers a broad variety of possible methodologies. Many software companies follow an informal development cycle that contains general goals and future scenarios, but no models. At the other extreme, formal scenario\u00a0\u2026", "num_citations": "72\n", "authors": ["1444"]}
{"title": "Architecture and quality in data warehouses\n", "abstract": " Most database researchers have studied data warehouses (DW) in their role as buffers of materialized views, mediating between update-intensive OLTP systems and query-intensive decision support. This neglects the organizational role of data warehousing as a means of centralized information flow control. As a consequence, a large number of quality aspects relevant for data warehousing cannot be expressed with the current DW meta models. This paper makes two contributions towards solving these problems. Firstly, we enrich the meta data about DW architectures by explicit enterprise models. Secondly, many very different mathematical techniques for measuring or optimizing certain aspects of DW quality are being developed. We adapt the Goal-Question-Metric approach from software quality management to a meta data management environment in order to link these special techniques to a generic\u00a0\u2026", "num_citations": "70\n", "authors": ["1444"]}
{"title": "Teamwork support in a knowledge-based information systems environment\n", "abstract": " DAIDA is an experimental environment for the knowledge-assisted development and maintenance of database-intensive information systems from object-oriented requirements and specifications. Within the DAIDA framework, the CoNeX project has developed an approach to integrate different tasks encountered in software projects via a conceptual modeling strategy. Emphasis is placed on: 1. integrating the semantics of the software development domain with aspects of group work, 2. social strategies for negotiating problems by argumentation, and 3. assigning responsibilities for task fulfillment by way of contracting. The implementation of a CoNeX prototype is demonstrated with a sample session.", "num_citations": "70\n", "authors": ["1444"]}
{"title": "Dependence directed reasoning and learning in systems maintenance support\n", "abstract": " The maintenance of large information systems involves continuous modifications in response to evolving business conditions or changing user requirements. Based on evidence from a case study, it is shown that the system maintenance activity would benefit greatly if the process knowledge reflecting the teleology of a design could be captured and used in order to reason about he consequences of changing conditions or requirements, A formalism called REMAP (representation and maintenance of process knowledge) that accumulates design process knowledge to manage systems evolution is described. To accomplish this, REMAP acquires and maintains dependencies among the design decisions made during a prototyping process, and is able to learn general domain-specific design rules on which such dependencies are based. This knowledge cannot only be applied to prototype refinement and systems\u00a0\u2026", "num_citations": "69\n", "authors": ["1444"]}
{"title": "Towards an infrastructure enabling the internet of production\n", "abstract": " New levels of cross-domain collaboration between manufacturing companies throughout the supply chain are anticipated to bring benefits to both suppliers and consumers of products. Enabling a fine-grained sharing and analysis of data among different stakeholders in an automated manner, such a vision of an Internet of Production (IoP) introduces demanding challenges to the communication, storage, and computation infrastructure in production environments. In this work, we present three example cases that would benefit from an IoP (a fine blanking line, a high pressure die casting process, and a connected job shop) and derive requirements that cannot be met by today's infrastructure. In particular, we identify three orthogonal research objectives: (i) real-time control of tightly integrated production processes to offer seamless low-latency analysis and execution, (ii) storing and processing heterogeneous\u00a0\u2026", "num_citations": "67\n", "authors": ["1444"]}
{"title": "From relational to object-oriented integrity simplification\n", "abstract": " Relational integrity checking technology can be transfered to deductive object bases by utilizing a simple logical framework for objects. The principles of object identity, aggregation and classification allow a more efficient constraint control by finer granularity of updates, composite updates and semantic constraint simplification. In many cases, meta-level constraints and deductive rules can be handled efficiently by a stepwise compilation approach. An extended integrity subsystem with these features has been implemented in the deductive object manager Concept Base.", "num_citations": "67\n", "authors": ["1444"]}
{"title": "On the retrieval of reusable software components\n", "abstract": " Starting from the principle of software reusability through formal specifications, the authors suggest a model for the retrieval of reusable components utilizing the search techniques in database management systems. The formal specification language of software components is ASL. Component specifications will be translated into a specification written in the knowledge representation Telos for storage and other manipulation. The retrieval of software components is based on signature matching between the signatures of goal specifications and those of reusable components. In this way, the authors overcome some of the main problems with respect to retrieval such as representation of reusable components, representation of goal specification, and name differences in the software. The retrieval mechanism is supported by the database management system ConceptBase.< >", "num_citations": "66\n", "authors": ["1444"]}
{"title": "Supporting distributed software development by modes of collaboration\n", "abstract": " Work processes in team based software development need to be structured to minimise and resolve conflicting or divergent work. Current software development methodologies propose ways for dividing the whole task of software development between team members. This paper suggests a different way of working by introducing modes of collaboration (MoCs), which support concurrent and collaborative work. A MoC defines how tight two people can work together and how much the rest of the group can demand to know about a programmer. Different MoCs are ordered in a spectrum from single user\u2019s offline usage up to concurrent editing of the same source code. Special emphasis is put on balancing gains and efforts that are related to a specific MoC. The second part of the paper presents how MoCs are implemented in the distributed co-operative software development environment TUKAN. TUKAN\u00a0\u2026", "num_citations": "64\n", "authors": ["1444"]}
{"title": "CoAUTHOR: A hypermedia group authoring environment\n", "abstract": " The CoAUTHOR system provides a real-time-oriented environment for multiple authors who wish to collaborate on the production of hypermedia documents. In this report, we describe a model of hypermedia document authoring, consider the group aspects of co-authoring, and the technical communication and coordination tools we areusing as a baSis for the implementation of a CoAUTHOR prototype. The interactions among the members of the authoring team concerning idea processing, document design and generation as well as group-specific activities such as critiquing issues, negotiating divergent-opinions, and treating inconsistent or incoin~ plete specifications are shown to be fairly knowledge-intensive and thus require maintenance facilities provided by a sophisticated knowledge base management system underlying the hypermedia surface.", "num_citations": "64\n", "authors": ["1444"]}
{"title": "Designing a multi-sided data platform: findings from the International Data Spaces case\n", "abstract": " The paper presents the findings from a 3-year single-case study conducted in connection with the International Data Spaces (IDS) initiative. The IDS represents a multi-sided platform (MSP) for secure and trusted data exchange, which is governed by an institutionalized alliance of different stakeholder organizations. The paper delivers insights gained during the early stages of the platform\u2019s lifecycle (i.e. the platform design process). More specifically, it provides answers to three research questions, namely how alliance-driven MSPs come into existence and evolve, how different stakeholder groups use certain governance mechanisms during the platform design process, and how this process is influenced by regulatory instruments. By contrasting the case of an alliance-driven MSP with the more common approach of the keystone-driven MSP, the results of the case study suggest that different evolutionary paths can\u00a0\u2026", "num_citations": "61\n", "authors": ["1444"]}
{"title": "Future directions in dbms research-the laguna beach participants\n", "abstract": " On February 4-5, 1988, the International Computer Science Institute sponsored a two day workshop at which 16 senior members of the data base research community discussed future research topics in the DBMS area. This paper summarizes the discussion which took place.", "num_citations": "61\n", "authors": ["1444"]}
{"title": "Mobile Host: A Feasibility Analysis of Mobile Web Service Provisioning.\n", "abstract": " This paper, discusses the feasibility of mobile Web Service provisioning from Smart Phones, confluencing two major recent trends in distributed information systems engineering: the evolution from static content via personalized adaptive information provisioning to Web Services, and the emergence of mobile terminals with sufficient speed to serve as parts of information systems. The research of mobile Web Services has been mainly concentrated on Web Service client systems. Mobile Web Service provisioning was ignored, since a realization seemed beyond the resource capabilities of present mobile terminals. Complementing this work, here we discuss one such prototype of a mobile Web Service provider, developed and evaluated in cooperation with a major mobile phone vendor. We also present a detailed performance analysis of this Mobile Host, proving its feasibility.", "num_citations": "59\n", "authors": ["1444"]}
{"title": "Repository support for multi-perspective requirements engineering\n", "abstract": " Relationships among different modeling perspectives have been systematically investigated focusing either on given notations (e.g. UML) or on domain reference models (e.g. ARIS/SAP). In contrast, many successful informal methods for business analysis and requirements engineering (e.g. JAD) emphasize team negotiation, goal orientation and flexibility of modeling notations. This paper addresses the question how much formal and computerized support can be provided in such settings without destroying their creative tenor. Our solution is based on a novel modeling language, M-Telos, that integrates the adaptability and analysis advantages of the logic-based meta modeling language Telos with a module concept covering the structuring mechanisms of scalable software architectures. It comprises four components: (1) A modular conceptual modeling formalism organizes individual perspectives and their\u00a0\u2026", "num_citations": "58\n", "authors": ["1444"]}
{"title": "The challenge of process data warehousing\n", "abstract": " The Challenge of Process Data Warehousing | Proceedings of the 26th International Conference on Very Large Data Bases ACM Digital Library home ACM home Google, Inc. (search) Advanced Search Browse About Sign in Register Advanced Search Journals Magazines Proceedings Books SIGs Conferences People More Search ACM Digital Library SearchSearch Advanced Search vldb Conference Proceedings Upcoming Events Authors Affiliations Award Winners More HomeConferencesVLDBProceedingsVLDB '00The Challenge of Process Data Warehousing ARTICLE The Challenge of Process Data Warehousing Share on Authors: Matthais Jarke profile image Matthias Jarke View Profile , Thomas List profile image Thomas List View Profile , J\u00f6rg K\u00f6ller profile image J\u00f6rg K\u00f6ller View Profile Authors Info & Affiliations Publication: VLDB '00: Proceedings of the 26th International Conference on Very Large Data \u2026", "num_citations": "54\n", "authors": ["1444"]}
{"title": "A decision-based configuration process environment\n", "abstract": " In the context of the ESPRIT project DAIDA, we have developed an experimental environment intended to achieve consistency-in-the-large in a multi-person setting. Our conceptual model of configuration processes, the CAD\u00b0 model, centres around decisions that work on configured objects and are subject to structured conversations. The environment, extending the knowledge-based software information system ConceptBase, supports co-operation within development teams by integrating models and tools for argumentation and co-ordination with those for versioning and configuration. Versioning decisions are discussed and decided on within an argument editor, and executed by specialised tools for programming-in-the-small. Tasks are assigned and monitored through a contract tool, and carried out within co-ordinated workspaces under a conflict-tolerant transaction protocol. Consistent configuration and\u00a0\u2026", "num_citations": "53\n", "authors": ["1444"]}
{"title": "Query languages-A taxonomy\n", "abstract": " A third scenario is required to descrihe the most realistic circumstances for interactively querying a datahase. The user sits in front of her CRT terminal, makes sure she has the right description of the datahase\u2014which field appears where, what relationships exist hetween the data\u2014and starts typing the query on the keyhoard. Is it FIND or GET I have to use here, do I put the GROUP BY hefore the WHERE? Then appears the message:\" ILLEGAL COMMAND.\" After two more tries she gets the answer, hut is this what she wanted? The three scenarios give an indication of where some hypothesize we are going, what direction we are taking, and where we are today with datahase query languages.", "num_citations": "52\n", "authors": ["1444"]}
{"title": "Generic schema mappings for composition and query answering\n", "abstract": " In this article, we present extensional mappings, that are based on second-order tuple generating dependencies between models in our Generic Role-based Metamodel GeRoMe. Our mappings support data translation between heterogeneous models, such as XML schemas, relational schemas, or OWL ontologies. The mapping language provides grouping functionalities that allow for complete restructuring of data, which is necessary for handling object oriented models and nested data structures such as XML. Furthermore, we present algorithms for mapping composition and optimization of the composition result. To verify the genericness, correctness, and composability of our approach we implemented a data translation tool and mapping export for several data manipulation languages. Furthermore, we address the question how generic schema mappings can be harnessed for answering queries against an\u00a0\u2026", "num_citations": "50\n", "authors": ["1444"]}
{"title": "Reducing interference in single display groupware through transparency\n", "abstract": " Single Display Groupware (SDG) supports face-to-face collaborators working over a single shared display, where all people have their own input device. Although SDG is simple in concept, there are surprisingly many problems in how interactions within SDG are managed. One problem is the potential for interference, where one person can raise an interface component (such as a menu or dialog box) in a way that hinders what another person is doing i.e., by obscuring another person\u2019s working area that happens to be underneath the raised component. We propose transparent interface components as one possible solution to interference: while one person can raise and interact with the component, others can see through it and can continue to work underneath it. To test this concept, we first implemented a simple SDG game using both opaque and transparent SDG menus. Through a controlled experiment\u00a0\u2026", "num_citations": "50\n", "authors": ["1444"]}
{"title": "Scenario management\n", "abstract": " Sauf mention contraire ci-dessus, le contenu de cette notice bibliographique peut \u00eatre utilis\u00e9 dans le cadre d\u2019une licence CC BY 4.0 Inist-CNRS/Unless otherwise stated above, the content of this bibliographic record may be used under a CC BY 4.0 licence by Inist-CNRS/A menos que se haya se\u00f1alado antes, el contenido de este registro bibliogr\u00e1fico puede ser utilizado al amparo de una licencia CC BY 4.0 Inist-CNRS", "num_citations": "49\n", "authors": ["1444"]}
{"title": "Natural language for database queries: A laboratory study\n", "abstract": " Are natural language systems for database queries meeting their goals?, and, are these goals appropriate? The recently completed Advanced Language Project at New York University combined a field experiment with two laboratory studies to examine these issues by comparing performance between subjects using the formal database language SQL and subjects using the proto-type natural language system, USL. This article describes the design and results of the larger laboratory experiment. The results presented offer some promise for the usability of natural language under certain conditions.", "num_citations": "49\n", "authors": ["1444"]}
{"title": "Scalable mobile web service discovery in peer to peer networks\n", "abstract": " Due to the astonishing development in memory and processing capabilities of hand held devices such as smart phones, it is not a dream anymore to enable mobile devices not only as conventional web service requesters but even as providers. The willingness and enthusiasm of service providers place abundant services at the disposal. But this abundance makes the efficiency of service discovery a critical issue. Centralized registries have severe drawbacks in such a scenario due to the dynamic and spontaneous nature of mobile peers. In the quest for a more appropriate approach for mobile web service discovery, we observed P2P to share very similar characteristics with behaviors of peers in mobile network. Hence we tried to find alternate mobile web service discovery mechanisms by using the features of the P2P networks like JXTA modules. The scalability analysis of the approach proves that the discovery\u00a0\u2026", "num_citations": "48\n", "authors": ["1444"]}
{"title": "Development of computer science disciplines: a social network analysis approach\n", "abstract": " In contrast to many other scientific disciplines, computer science considers conference publications. Conferences have the advantage of providing fast publication of papers and of bringing researchers together to present and discuss the paper with peers. Previous work on knowledge mapping focused on the map of all sciences or a particular domain based on ISI published Journal Citation Report (JCR). Although this data cover most of the important journals, it lacks computer science conference and workshop proceedings, which results in an imprecise and incomplete analysis of the computer science knowledge. This paper presents an analysis on the computer science knowledge network constructed from all types of publications, aiming at providing a complete view of computer science research. Based on the combination of two important digital libraries (DBLP and CiteSeerX), we study the knowledge\u00a0\u2026", "num_citations": "47\n", "authors": ["1444"]}
{"title": "A mediation framework for mobile web service provisioning\n", "abstract": " Web Services and mobile data services are the newest trends in information systems engineering in wired and wireless domains, respectively. Web Services have a broad range of service distributions while mobile phones have large and expanding user base. To address the confluence of Web Services and pervasive mobile devices and communication environments, a basic mobile Web Service provider was developed for smart phones. The performance of this Mobile Host was also analyzed in detail. Further analysis of the Mobile Host to provide proper QoS and to check Mobile Host's feasibility in the P2P networks, identified the necessity of a mediation framework. The paper describes the research conducted with the Mobile Host, identifies the tasks of the mediation framework and then discusses the feasible realization details of such a mobile Web Services mediation framework.", "num_citations": "47\n", "authors": ["1444"]}
{"title": "Pattern-based cross media social network analysis for technology enhanced learning in Europe\n", "abstract": " It is extremely challenging to get an overview of the state-of-the-art in technology enhanced learning in Europe. Rapid technological and pedagogical innovations, constantly changing markets, a vivid number of small and medium enterprises, complex policy processes, ongoing political and societal debates on the pros and cons of technology enhanced leaning, combined with many languages and different cultures, make it almost impossible for people to be informed. We want to introduce the media base and the measure tools for pattern-based cross media social network analysis, created by the PROLEARN network of excellence in professional learning. The main goal of this endeavour is the reduction of complexity for actors in digital social networks by applying ideas from social software and already successful methods for complexity reduction, such as information visualization, social network analysis\u00a0\u2026", "num_citations": "47\n", "authors": ["1444"]}
{"title": "Modeling the impact of trust and distrust in agent networks\n", "abstract": " Recently, the role of trust in agent networks has received a lot of attention. In his paper, we argue that an explicit consideration of distrust and its complex interaction with individual trust and confidence in the network as a whole is equally important, especially when designing hybrid networks of human and machine agents. We propose a trust-confidence-distrust (TCD) model of agent network dynamics, and present a multi-perspective methodology according to which such networks can be modeled and simulated. We are currently validating this methodology in the context of designing specialized computer support for networks of organizations, eg in the context of high-tech entrepreneurship or continuing education.", "num_citations": "47\n", "authors": ["1444"]}
{"title": "A toolkit for negotiation support interfaces to multi-dimensional data\n", "abstract": " CoDecide is an experimental user interface toolkit that offers an extension to spreadsheet concepts specifically geared towards support for cooperative analysis of the kinds of multi-dimensional data encountered in data warehousing. It is distinguished from previous proposals by direct support for drill-down/roll-up analysis without redesign of an interface; more importantly, CoDecide can link multiple views on a data cube for synchronous or asynchronoous cooperation by multiple analysts, through a conceptual model visualizing the problem dimensions on so-called tapes. Tapes generalize the ideas of ranging and pivoting in current data warehouses for the multi-perspective and multi-user case. CoDecide allows the rapid composition of multi-matrix interfaces and their linkage to underlying data sources. A LAN version of CoDecide has been used in a number of design decision support applications. A WWW\u00a0\u2026", "num_citations": "47\n", "authors": ["1444"]}
{"title": "Deliberation in a metadata-based modeling and simulation environment for inter-organizational networks\n", "abstract": " In the emerging field of database centric business process management, inter-organizational networks of people, information and communication systems are often described by the interplay between individual goals and actions and the strategic dependencies among individuals and subgroups. Our research aims at improving requirements engineering for such networks by not just representing these goals and dependencies statically, but also by studying the dynamic interactions between both. In previous work, we proposed the prototype environment SNet for the representation and dynamic simulation of agent-based designs for inter-organizational networks. A key feature of SNet was the automatic translation of extended i* models into the action language ConGolog. While this allowed the simulation of agent networks specified in i*, the resulting agents were purely reactive. In this paper, we explicitly incorporate\u00a0\u2026", "num_citations": "45\n", "authors": ["1444"]}
{"title": "An evaluation framework for traffic information systems based on data streams\n", "abstract": " Traffic information systems have to process and analyze huge amounts of data in real-time to effectively provide traffic information to road users. Progress in mobile communication technology with higher bandwidths and lower latencies enables the use of data provided by in-car sensors. Data stream management systems have been proposed to address the challenges of such applications which have to process a continuous data flow from various data sources in real-time. Data mining methods, adapted to data streams, can be used to analyze the data and to identify interesting patterns such as congestion or road hazards. Although several data stream mining methods have been proposed, an evaluation of such methods in the context of traffic applications is yet missing. In this paper, we present an evaluation framework for traffic information systems based on data streams. We apply a traffic simulation software to\u00a0\u2026", "num_citations": "43\n", "authors": ["1444"]}
{"title": "Reality is our laboratory: communities of practice in applied computer science\n", "abstract": " The present paper presents a longitudinal study of the course \u2018High-tech Entrepreneurship and New Media\u2019. The course design is based on socio-cultural theories of learning and considers the role of social capital in entrepreneurial networks. By integrating student teams into the communities of practice of local start-ups, we offer learning opportunities to students, companies and academia. The student teams are connected to each other and to their supervisors in academia and practice through a community-system. Moreover, the course is accompanied by a series of lectures and group discussions. In this paper we want to present our experiences and to reflect upon the design changes between the first and the second instance of the course. The evaluation of the course showed that the work on real-world problems and the collaboration in teams together with partners from start-up companies were evaluated as\u00a0\u2026", "num_citations": "43\n", "authors": ["1444"]}
{"title": "External semantic query simplification: A graph-theoretic approach and its implementation in Prolog\n", "abstract": " Semantic query simplification utilizes integrity constraints enforcedin a database system for reducing the number of tuple variables andterms in a relational calculus query. To a large degree, this can bedone by a system that is external to the DBMS. The paper advocatesthe application of database theory in such a system and describes aworking prototype of an external semantic query simplifier implementedin Prolog. The system employs a graph-theoretic approach to integratetableau techniques and algorithms for the syntactic simplification ofqueries containing inequality conditions. The use of integrityconstraints is shown not only to improve efficiency but also to permitmore meaningful error messages to be generated, particularly in thecase of an empty query result. The paper concludes with outlining anextension to the multi-user case.", "num_citations": "43\n", "authors": ["1444"]}
{"title": "Mobile web services mediation framework\n", "abstract": " Mobile data services in combination with profluent Web services are seemingly the path breaking domain in current information systems research. In mobile Web services sphere, resource constrained mobile terminals are used as both Web services clients and providers. While service delivery and management from Mobile Host are technically feasible, the ability to provide proper quality of service (QoS) and discovery mechanisms for the huge number of services possible with Mobile Hosts is observed to be very critical. We have studied the security, scalability and discovery aspects of the mobile Web services and the analysis has identified the necessity of a mediation framework. This paper summarizes our QoS and discovery research and discusses the realization details and features of our enterprise service bus technology based integration framework for mobile Web service provisioning.", "num_citations": "42\n", "authors": ["1444"]}
{"title": "Range nesting: A fast method to evaluate quantified queries\n", "abstract": " Database queries explicitly containing existential and universal quantification become increasingly important in a number of areas such as integrity checking, interaction of databases and AI systems, heterogeneous databases, and statistical databases. Using a concept of range nesting in relational calculus expressions, the paper describes evaluation algorithms and transformation methods for an important class of quantified relational calculus queries called perfect expressions. This class includes well-known classes of \"easy\" queries such as tree queries (with free and existentially quantified variables only), and complacent (disconnected) queries.", "num_citations": "42\n", "authors": ["1444"]}
{"title": "Database application engineering with DAIDA\n", "abstract": " In the early 1980s, a trend towards formal undeIStanding and knowledge-based assistance for the development and maintenance of database-intensive information systems became apparent. The group of John Mylopoulos at the UniveISity of Toronto and their European collaboratoIS moved from semantic models of information systems design (Taxis project) towards earlier stages of the software lifecycle. Joachim Schmidt's group at the University of Hamburg completed their early work on the design and implementation of database programming languages (Pascal/R) and began to consider tools for the development of large database program packages. The Belgian company BIM developed a fast commercial Prolog which turned out to be useful as an implementation language for object oriented knowledge representation schemes and as a prototyping tool for formal design models. Case studies by Vasant Dhar and Matthias Jarke in New York pointed out the need for formally representing process knowledge, and a number of projects in the US and Europe began to consider computer assistance (CASE) as a viable approach to support software engineering. In 1985, the time appeared ripe for an attempt at integrating these experiences in a comprehensive CASE framework relating all phases of an information systems lifecycle. The Commission of the European Communities decided in early 1986 to fund this joint effort by six European software houses and research institutions in the Software Technology section of the ESPRIT I program. The project was given the number 892 and the title DAIDA-Development Assistance for Intelligent Database\u00a0\u2026", "num_citations": "40\n", "authors": ["1444"]}
{"title": "Adaptive multimodal exploration of music collections\n", "abstract": " Discovering music that we like rarely happens as a result of a directed search. Except for the case where we have exact meta data at hand it is hard to articulate what song is attractive to us. Therefore it is essential to develop and evaluate systems that support guided exploratory browsing of the music space. While a number of algorithms for organizing music collections according to a given similarity measure have been applied successfully, the generated structure is usually only presented visually and listening requires cumbersome skipping through the individual pieces. To close this media gap we describe an immersive multimodal exploration environment which extends the presentation of a song collection in a video-game-like virtual 3-D landscape by carefully adjusted spatialized plackback of songs. The user can freely navigate through the virtual world guided by the acoustic clues surrounding him. Observing his interaction with the environment the system furthermore learns the user\u2019s way of structuring his collection by adapting a weighted combination of a wide range of integrated content-based, meta-data-based and collaborative similarity measures. Our evaluation proves the importance of auditory feedback for music exploration and shows that our system is capable of adjusting to different notions of similarity.", "num_citations": "40\n", "authors": ["1444"]}
{"title": "Query processing strategies in the Pascal/R relational database management system\n", "abstract": " In the database language PASCAL/R, the programming language PASCAL and concepts based on the relational data model are integrated. The paper investigates transformation strategies used in the PASCAL/R system to evaluate queries with existential and universal quantifiers. Intermediate data structures are described using a high-level language tool called a reference to a selected variable. The predicate calculus approach used in PASCAL/R offers new insight into recently proposed query optimization techniques and allows some of them to be extended.", "num_citations": "40\n", "authors": ["1444"]}
{"title": "Access to specific declarative knowledge by expert systems: The impact of logic programming\n", "abstract": " As part of the operation of an Expert System, a deductive component accesses a database of facts to help simulate the behavior of a human expert in a particular problem domain. The nature of this access is examined, and four access strategies are identified. Features of each of these strategies are addressed within the framework of a logic-based deductive component and the relational model of data.", "num_citations": "39\n", "authors": ["1444"]}
{"title": "How does an expert system get its data?\n", "abstract": " An Expert System(Es) is a problem-8olving computer- that system incorporates enough knowledge in Borne speciali2ed problem domain to reach a level of performance comparable to that of a human expert. In the heart of an expert system lie8 the program that\" reasons\" and make8 deduction8(\" inference engine\"). To reason, knowledge both of general rules(eg if a person work8 for a company then he/ehe zts employee benefits) and of swzic declarative fact8 (eg jOhn work8 for nyu) is needed. With few exceptione, little attention is given in Es8 to the handling of very large populations Of 8PeCifiC facts. Since early prototype BSs represented specific fact8 which were characterized by large variety and a very Sma11 population, the inefficiency of data handling was not an issue. As ES8 increase in sophistication and ambition, they deal with application8 requiring a very large population of facts, often in the form of existing databases manipulated by generalized DBMS. This short paper (see [Vassiliou et al 19831 for more details) investigates the technical issue8 of enhancing expert systems with database management facilities in four stages, leading to the coupling of the ES with a large DBMS. Our vehicles are first-order logic (with Prolog) and relational databaae management.1.'o BLBMNTARY DATABASE MANAGEMENT-STAGE 1Cm the simplest level, the whole population of facts can be represented directly in the knowledge base of the expert system. While this approach is feasible for any expert system, using Prolog can take us a step further. Relational databases can be represented directly in Prolog [l] a8 a listing of all instantiated predicate8\u00a0\u2026", "num_citations": "39\n", "authors": ["1444"]}
{"title": "Connectivism: The network metaphor of learning\n", "abstract": " Connectivism is a new learning theory introduced by George Siemens in 2004 in order to cope with the increasing complexity and fast-paced change of the new knowledge era. This paper addresses the network metaphor of learning, which explains learning in terms of networks. We begin by introducing the connectivism approach to learning based on Siemens' work, and then provide an account of our view of connectivism by discussing the learning as a network (LaaN) perspective. We then present knowledge ecology as a social landscape that mirrors the complex nature and wide scope of knowledge, and continue by contrasting knowledge ecology to popular social forms that have been introduced in the CSCL and CSCW literature. These include communities of practice, knots, coalitions, intensional networks, and ad hoc transient communities. We end by comparing the connectivism/LaaN perspective with\u00a0\u2026", "num_citations": "38\n", "authors": ["1444"]}
{"title": "Mobile hosts in enterprise service integration\n", "abstract": " Mobile data services in combination with profluent web services are seemingly the path-breaking domain in current information systems research. In the Mobile Web Service (MWS) sphere, resource-constrained mobile terminals are used as both web service clients and providers (mobile hosts). Mobile hosts enable seamless integration of user-specific services into the enterprise. This paper addresses several technical aspects of the MWS provisioning domain, such as providing proper Quality of Service (QoS), especially in terms of security and reasonable scalability, and discovery aspects of the huge number of services possible with each mobile host that provides some services. The paper also discusses the features, components and realisation details of our enterprise service-bus-technology-based integration framework, which ensures QoS and discovery of MWS and helps in providing a bird's-eye view of the\u00a0\u2026", "num_citations": "38\n", "authors": ["1444"]}
{"title": "MWSMF: a mediation framework realizing scalable mobile web service provisioning\n", "abstract": " It is now feasible to invoke basic web services on a smart phone due to the advances in wireless devices and mobile communication technologies. While mobile web service clients are common these days, we have studied the scope of providing web services from smart phones. Although the applications possible with Mobile Host are quite welcoming, the scalability of such a Mobile Host is observed to be considerably low. In the scalability analysis of our Mobile Host, we have observed that binary compression of SOAP messages being exchanged over cellular network have greatly improved the performance of the Mobile Host. While binary compression is observed to be very efficient, the mechanism has raised the need for an intermediary in the mobile web service invocation cycle. The paper addresses our mobile web service message optimization scenario, at the enterprise service bus technology based mediation framework, with evaluation results.", "num_citations": "38\n", "authors": ["1444"]}
{"title": "Using restricted natural language for data retrieval: A plan for field evaluation\n", "abstract": " One strategy that has heen proposed for dealing with the growing hacklog for development of applications is to give casual users languages for interacting directly with datahases. Yet there is little agreement on the form such languages should take. Should they he natural-like, conforming closely to a user's native tongue, or should they he structured to take advantage of the characteristics of formal languages? This paper presents the rationale for and design of a field evaluation of natural language for data retrieval. The natural language system and application are descrihed, along with the research design of the project. The results of the first part of the study, a lahoratory experiment to investigate whether users perform hetter with an artificial or natural language, suggests that, after equal amounts of training, no difference in suhject performance is found hetween languages, using a paper and pencil test. The insights gained to date are summarized.", "num_citations": "38\n", "authors": ["1444"]}
{"title": "Group work in software projects\n", "abstract": " Group work in software projects | Proceedings of the IFIP WG 8.4 confernece on Multi-user interfaces and applications ACM Digital Library home ACM home Google, Inc. (search) Advanced Search Browse About Sign in Register Advanced Search Journals Magazines Proceedings Books SIGs Conferences People More Search ACM Digital Library SearchSearch Advanced Search Browse Browse Digital Library Collections More HomeBrowse by TitleProceedingsProceedings of the IFIP WG 8.4 confernece on Multi-user interfaces and applicationsGroup work in software projects ARTICLE Group work in software projects Share on Authors: Udo Hahn profile image Udo Hahn View Profile , Matthais Jarke profile image Matthias Jarke View Profile , Thomas Rose profile image Thomas Rose View Profile Authors Info & Affiliations Publication: Proceedings of the IFIP WG 8.4 confernece on Multi-user interfaces and \u2026", "num_citations": "37\n", "authors": ["1444"]}
{"title": "Data constructors: On the integration of rules and relations\n", "abstract": " Although the goals and means of rule-based and data-based systems are too different to be fully integrated at the present time, it seems appropriate to investigate a closer integration of language constructs and a better cooperation of execution models for both kinds of approaches. In this paper, we propose a new language construct called constructor that \u00e2     when applied to a base relation \u00e2     causes relation membership to become true for all tuples constructable through the predicates provided by the constructor definition. The approach is shown to provide expressive power at least equivalent to PROLOG's declarative semantics while blending well both with a strongly typed modular programming language and with a relational calculus query formalism. A three-step compilation, optimization, and evaluation methodology for expressions with constructed relations is described that integrates constructors with the surrounding database programming environment. In particular, many recursive queries can be evaluated more efficiently within the set-construction framework of database systems than with proof-oriented methods typical for a rule-based approach.", "num_citations": "37\n", "authors": ["1444"]}
{"title": "SNet: A modeling and simulation environment for agent networks based on i* and ConGolog\n", "abstract": " SNet is a prototype environment supporting the representation and dynamic evaluation of designs for social networks comprising human, hardware, and software agents. The environment employs metadata management technology to integrate an extended version of the i* formalism for static network modeling with the ConGolog logic-based activity simulator. The paper defines the formal mappings necessary to achieve the integration and describes an operational prototype demonstration. SNet\u2019s intended application domain is requirements management and mediation support for inter-organizational and embedded process systems, as well as simulation support for inter-organizational studies e.g. in hightech entrepreneurship networks.", "num_citations": "36\n", "authors": ["1444"]}
{"title": "When worlds collide: Molecular biology as interdisciplinary collaboration\n", "abstract": " The field of molecular biology is in a remarkably rapid period of change, as the genome sequencing projects and new experimental technologies have generated an explosion of data. To analyze and draw insights from the vast amounts of information, biologists use a new generation of bioinformatics software tools, often working closely with mathematicians and computer scientists. There are elements of both collision and convergence in these interdisciplinary encounters. We conducted user studies with biologists engaged in investigating the molecular basis of disease. We describe several issues that arise in this collision/convergence of disciplines, drawing on the notion of boundary objects in-the-making. We provide recommendations on building technology for people whose work now sits at the crossroads of diverse and rapidly changing scientific fields.", "num_citations": "36\n", "authors": ["1444"]}
{"title": "Follow me, follow you-spatiotemporal community context modeling and adaptation for mobile information systems\n", "abstract": " Nowadays various mobile platforms from PDA, smart phones to iPhones can deliver road warriors or trippers much mobile information. However, most mobile applications are lacking the \"social intelligence\" of real companionship. One reason is that community context and spatiotemporal context information are not well taken into consideration. In this paper we propose an ontology-based context model using OWL/RDF. With the enhanced interoperability substantial context information can be expressed and reasoned across systems. Based on the context model and the middleware Context-Aware Adaptation Service (CAAS), we introduce a mobile tourist guide as proof- of-concept that provides users context-aware information. We employ the MPEG-7 and MPEG-21 metadata standards to realize multimedia adaptation to device preferences. The evaluation result proves the feasibility of the context model and\u00a0\u2026", "num_citations": "35\n", "authors": ["1444"]}
{"title": "MECCA: Hypermedia Capturing of Collaborative Scientific Discourses about Movies.\n", "abstract": " The success of collaborative hypermedia systems in business, engineering, or humanities heavily depends on the discursive nature of knowledge creation. Informing systems that assist crossdisciplinary communities of practice in these fields should therefore be able to capture, to visualize, and to support the ongoing scientific discourse to keep participants informed and committed to the knowledge creation process. We present a solution for this issue, using the MECCA discourse support system for a movie research community as an example. MECCA integrates research processes with teaching processes in the humanities. Our study demonstrates that knowledge creation discourses involve a lot of re-\u201cwriting\u201d(transcription) of discourse artifacts within or across media. We introduce an underlying formal technique to support flexible and adaptable transcription on hypermedia artifacts in the community. Our approach includes a linkage of knowledge to action which aims at seamless de-contextualization from action and recontextualization into action.", "num_citations": "35\n", "authors": ["1444"]}
{"title": "Logic-based formula management strategies in an actuarial consulting system\n", "abstract": " In many decision support systems, multiple decision methods and models must be combined for solving a complex problem. Expertise is required for selecting, adapting and coordinating appropriate models. This paper describes the design and implementation of a knowledge-based model management system called the Actuarial Consulting System (ACS). The ACS supports actuaries in making pricing decisions in the domain of life insurance. Actuarial knowledge is organized using a graph formalism called Formula Derivation Network (FDN), represented in Prolog as a hierarchy of predicates. On the user level, a Problem Analyzer converts a problem specification by the user into a search problem on the stored collection of FDNs. Using different search strategies, including human expert rules, the Surface Planner generates an efficient solution strategy (sequence of models). At the lowest level, a Plan Executor\u00a0\u2026", "num_citations": "35\n", "authors": ["1444"]}
{"title": "Iot link: An internet of things prototyping toolkit\n", "abstract": " The Internet of Things (IoT) application development is a complex task that requires a wide range of expertise. Currently, the IoT community lacks a development toolkit that enables inexperienced developers to develop IoT prototypes rapidly. Filling this gap, we propose a development toolkit based on a model-driven approach, called IoT Link. IoT Link allows inexperienced developers to compose mash up applications through a graphical domain-specific language that can be easily configured and wired together to create an IoT application. Through visual components, IoT Link encapsulates the complexity of communicating with devices and services on the internet and abstracts them as virtual objects that are accessible through different communication technologies. Consequently, it solves interoperability between heterogeneous IoT components. Based on the visual model, IoT Link is able to generate a complete\u00a0\u2026", "num_citations": "34\n", "authors": ["1444"]}
{"title": "Big data\n", "abstract": " Physicists and astronomers have been dealing with massive swaths of data for years in order to answer basic questions about the origin and state of the universe. In the late 1990s, Jim Gray initiated an ambitious astronomy data project at Microsoft, identifying issues unique to the new age of \u201cdata science\u201d(Microsoft 2009). What does it mean? Is there something unique about it? What skills do data scientists need to be productive in a world deluged by data? What are the implications for scientific inquiry? Data Science is the systematic study of the extraction of knowledge from data (Dhar 2013). Data science aims to discover and extract actionable knowledge from the data, that is, knowledge that can be used to make decisions and predictions, not just to explain what\u2019s going on. The central issues in Data Science have to do with how to endow machines with capabilities that enable them or humans to ask the right\u00a0\u2026", "num_citations": "34\n", "authors": ["1444"]}
{"title": "Scalable mobile web services mediation framework\n", "abstract": " Web services are going mobile. A Mobile Enterprise can be established in a cellular network by participating Mobile Hosts, which act as web service providers, and their clients. Mobile Hosts enable seamless integration of user- specific services to the enterprise, by following web service standards, also on the radio link and via resource constrained smart phones. However, establishing such a Mobile Enterprise poses several technical challenges, like the quality of service (QoS) and discovery aspects, for the network and as well as for mobile phone users. The paper summarizes the challenges and research in this domain, along with our developed mobile web service mediation framework (MWSMF). We used a cloud computing infrastructure to setup one possible load balancing solution and also conducted number of tests to show that MWSMF is horizontally scalable. We also showed that elasticity of cloud\u00a0\u2026", "num_citations": "34\n", "authors": ["1444"]}
{"title": "Concept based design of data warehouses: The DWQ demonstrators\n", "abstract": " The ESPRIT Project DWQ (Foundations of Data Warehouse Quality) aimed at improving the quality of DW design and operation through systematic enrichment of the semantic foundations of data warehousing. Logic-based knowledge representation and reasoning techniques were developed to control accuracy, consistency, and completeness via advanced conceptual modeling techniques for source integration, data reconciliation, and multi-dimensional aggregation. This is complemented by quantitative optimization techniques for view materialization, optimizing timeliness and responsiveness without losing the semantic advantages from the conceptual approach. At the operational level, query rewriting and materialization refreshment algorithms exploit the knowledge developed at design time. The demonstration shows the interplay of these tools under a shared metadata repository, based on an example\u00a0\u2026", "num_citations": "34\n", "authors": ["1444"]}
{"title": "Panel: Is generic metadata management feasible?\n", "abstract": " The database field has worked on metadata-related problems for 30 years. Examples include data translation and migration, schema evolution, database design, schema/ontology integration, XML wrapper generation, data scrubbing and transformation for data warehouses, message mapping for e-business, and schema-driven web site design. Tools that address these problems are strikingly similar in their design. Arguably, we are making very little progress, since we keep reapplying the same old 1970\u2019s techniques of data translation [9] and views to one new problem after another, without getting much leverage from each succeeding step. Despite all the research on the above tools, we have so far been unable to offer generalpurpose database technology that factors out the similar aspects of these tools into generic database infrastructure.", "num_citations": "33\n", "authors": ["1444"]}
{"title": "Multidimensional data models and aggregation\n", "abstract": " This chapter is devoted to the modeling of multidimensional information in the context of data warehousing and knowledge representation, with a particular emphasis on the operation of aggregation.", "num_citations": "33\n", "authors": ["1444"]}
{"title": "Ontology-based data quality management for data streams\n", "abstract": " Data Stream Management Systems (DSMS) provide real-time data processing in an effective way, but there is always a tradeoff between data quality (DQ) and performance. We propose an ontology-based data quality framework for relational DSMS that includes DQ measurement and monitoring in a transparent, modular, and flexible way. We follow a threefold approach that takes the characteristics of relational data stream management for DQ metrics into account. While (1) Query Metrics respect changes in data quality due to query operations, (2) Content Metrics allow the semantic evaluation of data in the streams. Finally, (3) Application Metrics allow easy user-defined computation of data quality values to account for application specifics. Additionally, a quality monitor allows us to observe data quality values and take counteractions to balance data quality and performance. The framework has been designed\u00a0\u2026", "num_citations": "32\n", "authors": ["1444"]}
{"title": "Model-driven mashup personal learning environments\n", "abstract": " Mashups have become the driving force behind the development of personal learning environments (PLEs). Creating mashups in an ad hoc manner is, however, for end users with little or no programming background not an easy task. Various tools and platforms have been built in an attempt to support mashup creation. These platforms, however, are still considered complex and do not address crucial challenges in mashup development today, such as scalability, interoperability, reuse, and automatic service invocation and mediation. In this paper, we leverage the possibility to use the concept of model-driven mashup development (MDMD) as an approach that can drastically tackle the aforementioned issues and drive the rapid and user-friendly creation of mashups. We then present the conceptual and technical details of PLEF-Ext as a flexible framework for end-user, model-driven development (MDD) of mashup\u00a0\u2026", "num_citations": "32\n", "authors": ["1444"]}
{"title": "Three aspects of intelligent cooperation in the quality cycle\n", "abstract": " The WibQuS project investigates distributed computer and communication support for Total Quality Management in industrial organizations. An interdisciplinary study of this task reveals three aspects of intelligent cooperation required from such a system which we call conceptual, technical, and social integration. We use the repository standard IRDS to characterize these aspects. A solution concept derived from this characterization employs advanced conceptual modeling techniques to derive interoperability among technical subsystems and coordination technology for the human subsystem semi-automatically while taking important social factors into account.", "num_citations": "32\n", "authors": ["1444"]}
{"title": "A decision-based configuration process model\n", "abstract": " Configuration management is linked to a data model of software processes in order to clarify the relationship between programming-in-the-large, in-the-small, and in-the-many. The data model also allows for the separation of conceptual from document-based version and configuration management by focusing on careful modeling of design decisions as a unifying concept to describe versioning, configuration, and mapping tasks. The close relationship to in-the-small ideas suggest applicability in process reusability. The authors also report on a prototype implementation on the knowledge base management system ConceptBase and experiences in a real-world case study.< >", "num_citations": "32\n", "authors": ["1444"]}
{"title": "Logic programming and databases\n", "abstract": " Logic programming and databases | Proceedings from the first international workshop on Expert database systems ACM Digital Library home ACM home Google, Inc. (search) Advanced Search Browse About Sign in Register Advanced Search Journals Magazines Proceedings Books SIGs Conferences People More Search ACM Digital Library SearchSearch Advanced Search Browse Browse Digital Library Collections More HomeBrowse by TitleProceedingsProceedings from the first international workshop on Expert database systemsLogic programming and databases Article Logic programming and databases Share on Chairman: DS Parker View Profile Authors Info & Affiliations Publication: Proceedings from the first international workshop on Expert database systemsJanuary 1986 Pages 35\u201348 6citation 0 Downloads Metrics Total Citations6 Total Downloads0 Last 12 Months0 Last 6 weeks0 Get Citation Alerts \u2026", "num_citations": "32\n", "authors": ["1444"]}
{"title": "SMashup personal learning environments\n", "abstract": " Mashups have become the driving force behind the development of Personal Learning Environments (PLE). Creating mashups in an ad hoc manner is, however, for end users with little or no programming background not an easy task. In this paper, we leverage the possibility to use Semantic Mashups (SMashups) for a scalable approach to creating mashups. We present the conceptual and technical details of PLEF\u01e6Ext as a flexible framework for mashup\u01e6driven end\u01e6user development of PLEs. PLEF\u01e6Ext uses the Service Mapping Description (SMD) approach to adding semantic annotations to RESTful Web services, and leverages the SMD annotations to facilitate the automatic data mediation and user\u01e6friendly creation of learning mashups.", "num_citations": "31\n", "authors": ["1444"]}
{"title": "A hypermedia Afghan sites and monuments database\n", "abstract": " Cultural heritage management is an excellent application domain for geographical hypermedia information systems. Many people with different tasks and levels of profession like fieldworkers, researchers, project and campaign officers, cultural bureaucrats etc. collaboratively producing and consuming different media like photographs, video, drawings, books, etc. must deal with exact geographic information about moveable or unmovable objects of interest. Implemented information systems must obey all standards in the different domains to overcome classical failures of isolated solutions which do not scale beyond the scope of a single project. We present a conceptual approach which integrates geographic information, multimedia information, cultural heritage information and collaborative aspects in a single information model. This conceptual approach was used to design and implement a web-based\u00a0\u2026", "num_citations": "31\n", "authors": ["1444"]}
{"title": "Managing knowledge about information system evolution\n", "abstract": " This paper describes the design and initial prototype implementation of a knowledge base management system (KBMS) for controlling database software development and maintenance. The KBMS employs a version of the conceptual modelling language CML to represent knowledge about the tool-aided development process of an information system from requirements analysis to conceptual design to implementation, together with the relationship of these system components to the real-world environment in which the information system is intended to function. A decision-centered documentation methodology facilitates communication across time and among multiple developers (and possibly users), thus enabling improved maintenance support.", "num_citations": "31\n", "authors": ["1444"]}
{"title": "Information integration in research information systems\n", "abstract": " Information integration is an on-going challenge in data management and various approaches have been proposed in database research. New technologies and application areas create different requirements for integration systems. Research information management (RIM) is yet another challenge for data integration. RIM has many properties that are typical for data integration scenarios: many data sources, various modeling languages and data models, heterogeneity in syntax and semantics. Furthermore, many stakeholders are involved in RIM, usually with diverting goals. The combination of these properties makes RIM a particular difficult integration problem.In this paper, we discuss the applicability of data integration approaches to research information management. In particular, we want to highlight the lessons which have been learned in data integration in the recent years. Early approaches in data\u00a0\u2026", "num_citations": "30\n", "authors": ["1444"]}
{"title": "Ontology-based information management in design processes\n", "abstract": " Engineering design processes are highly creative and knowledge-intensive tasks that involve extensive information exchange and communication among diverse developers. In such dynamic settings, traditional information management systems fail to provide adequate support due to their inflexible data structures and hard-wired usage procedures, as well as their restricted ability to integrate processes and product information. In this paper, we advocate the idea of Process Data Warehousing as a means to provide an information management and integration platform for such design processes. The key idea behind our approach is a flexible ontology-based schema with formally defined semantics that enables the capture and reuse of design knowledge, supported by advanced computer science methods.", "num_citations": "30\n", "authors": ["1444"]}
{"title": "Visual knowledge management with adaptable document maps\n", "abstract": " Analyzing, structuring and organizing documented knowledge is an important aspect of knowledge management. In literature so-called document maps have been proposed for visualizing the semantic similarity structure of a corpus of documents. So far, however, a method which is specifically designed for typical document analysis tasks in knowledge management\u2013along with an applicationoriented evaluation\u2013was missing. Based on an empirical task-model this work presents an adaptable framework for generating document maps. The benefits of this framework are a flexible combination of similarity-and topology-preserving visualization methods and the exchangeability of the component for assessing the similarity of documents. An extension of the basic method allows the analyst to adapt the map\u2019s generation by incorporating a personal analysis interest. The interactive document map system DocMINER implements the developed method and comprises additional map-oriented tools for analyzing text collections. Industrial and scientific case studies help to better understand whether the proposed graphical overview can be effectively applied to real-world problems. Moreover, a comparative empirical study in a laboratory setting evaluates the document map concept against an alternative text-access interface.", "num_citations": "30\n", "authors": ["1444"]}
{"title": "Strategies for integrating CASE environments\n", "abstract": " An experimental information-system environment, called DAIDA (development assistance for integrated database applications), developed as part of the European Community's ESPRIT program is described. DAIDA goes beyond traditional knowledge-based techniques for CASE by addressing three important dimensions of integration in a process-oriented model: how to handle dependencies among development stages, how to manage the evolving relationship among systems and their technical and social environments, and how to integrate development tasks-from both development in the small, in which the focus is the content of actions and results, and development in the large, which is concerned with object and process management and the collaboration of people involved in developing and using systems. This threefold integration strategy is discussed, along with the DAIDA architecture and a\u00a0\u2026", "num_citations": "30\n", "authors": ["1444"]}
{"title": "Gamification for enforcing coding conventions\n", "abstract": " Software is a knowledge intensive product, which can only evolve if there is effective and efficient information exchange between developers. Complying to coding conventions improves information exchange by improving the readability of source code. However, without some form of enforcement, compliance to coding conventions is limited. We look at the problem of information exchange in code and propose gamification as a way to motivate developers to invest in compliance. Our concept consists of a technical prototype and its integration into a Scrum environment. By means of two experiments with agile software teams and subsequent surveys, we show that gamification can effectively improve adherence to coding conventions.", "num_citations": "29\n", "authors": ["1444"]}
{"title": "PLEF: a conceptual framework for mashup personal learning environments\n", "abstract": " SID.ir | PLEF: A CONCEPTUAL FRAMEWORK FOR MASHUP PERSONAL LEARNING ENVIRONMENTS Click for new scientific resources and news about Corona[COVID-19] Use Online Translation Powered By Click Here STRS STRS www.SID.ir Home Journals Authors ISI Iranian Journals Updated Journals JCR About Us Contact Us Help Others Scientific Information Databases \u0628\u0627\u0646\u06a9 \u0646\u0634\u0631\u06cc\u0627\u062a \u0641\u0627\u0631\u0633\u06cc \u0627\u06cc\u0631\u0627\u0646 \u0628\u0627\u0646\u06a9 \u0647\u0645\u0627\u06cc\u0634 \u0647\u0627\u06cc \u0639\u0644\u0645\u06cc \u0641\u0627\u0631\u0633\u06cc \u0627\u06cc\u0631\u0627\u0646 \u0628\u0627\u0646\u06a9 \u0637\u0631\u062d \u0647\u0627\u06cc \u067e\u0698\u0648\u0647\u0634\u06cc \u0641\u0627\u0631\u0633\u06cc \u0627\u06cc\u0631\u0627\u0646 \u0645\u0631\u0627\u06a9\u0632 \u0639\u0644\u0645\u06cc \u062a\u062e\u0635\u0635\u06cc \u0627\u06cc\u0631\u0627\u0646 English Journals Database of Iran English Seminars Database of Iran Today: 5/30/2021 Advanced Search Papers ... English \u0641\u0627\u0631\u0633\u06cc Paper Information Journal: TECHNICAL COMMITTEE ON LEARNING TECHNOLOGY 2009 , Volume 11 , Number 3; Page(s) 0 To 0. Paper: PLEF: A CONCEPTUAL FRAMEWORK FOR MASHUP PERSONAL LEARNING ENVIRONMENTS Author(s): CHATTI MA, JARKE M., SPECHT M. * * \u2026", "num_citations": "29\n", "authors": ["1444"]}
{"title": "Context management and personalisation: A tool suite for context-and user-aware computing\n", "abstract": " Recent trends towards computing paradigms such as ubiquitous and pervasive computing claim for moving computing off the desktop and into the environment in order to create a more natural appearance of the computer (Weiser, 1991). The computer as a tool disappears from the centre of the user\u2019s attention and the human-computer interaction moves beyond the desktop into the real world. In contrast to the desktop, which constitutes a well-known and well-controlled environment, the real world exposes complexity and dynamics. The challenge in ubiquitous and pervasive computing lies in the creation of usable applications and services that are functional in all those manifold situations emerging in the real world.Changing requirements and dynamic environments are drivers for context-aware applications because they are highly autonomous and responsive to changes in the context of use and in the user\u2019s demands. Context constitutes a powerful concept in human-human and humancomputer interaction because implicit context information allows for the interpretation of explicit activities. The objective of context-aware applications consists in the assistance of the users by pro-actively supplying what is actually relevant and needed with respect to the current situation. Thus, such an application enhances the quality of system usage through adapting aspects like the supplied information, functionality or presentation.", "num_citations": "29\n", "authors": ["1444"]}
{"title": "Cooperative interfaces to information systems\n", "abstract": " Information systems are large repositories of factual and inferential knowledge intended to be queried and maintained by a wide variety of users with different backgrounds and work tasks. The community of potential information system users is growing rapidly with advances in hardware and software technology that permit computer/communications support for more and more application areas.Unfortunately, it is often felt that progress in user interface technology has not quite matched that of other areas. Technical solutions such as computer graphics, natural language processing, or man-machine-man communications in office systems are not enough by themselves. They should be complemented by system features that ensure cooperative behavior of the interfaces, thus reducing the training and usage effort required for successful interaction. In analogy to a human dialog partner, we call an interface cooperative\u00a0\u2026", "num_citations": "29\n", "authors": ["1444"]}
{"title": "Databases and expert systems: opportunities and architectures for integration\n", "abstract": " This paper addresses an interesting and increasingly important topic: the coupling of Expert Systems (ES) of artificial intelligence and DataBase Management Systems (DBMS). For information management, can ES be used for query optimization and database consistency maintenance__? __ For AI, can database techniques be applied to manage the facts of large knowledge systems__? __ The paper has a large reference section and the authors briefly describe several approaches for ES-DBMS integration including internal expert system databases, intelligent database systems, and coupled, independent ES/DBMS. The authors' own work is described. Their reasoned view is to couple existing systems. This is an interesting paper which contains much food for thought.", "num_citations": "27\n", "authors": ["1444"]}
{"title": "Enhancing decision and negotiation support in enterprise networks through semantic web technologies\n", "abstract": " C c RU RU c cdEefRgfqhgi j0k lgmRn o pXqr (sctEuw vgx (yXz|{} yX Ez} tE cq us (tEu|(q~ q ((q (q X 1 X (1 XX~ X\u00a6 XX X\u00a1(\u00a2 0\u00a3\u00a5\u00a4\u00a6\u00a6\u00a4 \u00a7 \u00a9 \u00aa \u00ab\u00ac 0\u00a4\u00ac 0\u00a4 \u00a7 1\u00ae~ \u00aa\u00b1(\u00b2X\u00ac 0\u00a4\u00ab\u00b3 (\u00a4 \u00aa~ \u00b5\u00b6 \u00aa\u00a6\u00ac g\u00a4\u00a6\u00abq\u00aa\u00a6\u00b7\u00a4 \u00b3X\u00a4 \u00a7 \u00b6 X \u00a7 1\u00a4 \u00b2 \u00ab\u00b9\u00a9 \u00b2 \u00ba\u00bb X\u00bc\u00bdc\u00be\u00be\u00a6 \u00ba\u00bf X\u00bd (\u00bb X\u00bc\u00c0 \u00ba\u00bb \u00c1 (\u00c2X\u00c30\u00c4 \u00c5X\u00bc\u00ba\u00c2\u00bb\u00a9 \u00c6 \u00c2 \u00c7X\u00c30\u00c8 (\u00bd (\u00c6\u00ca \u00c9\u00cb\u00ca \u00cc\u00cd\u00ce \u00cb0\u00cf1\u00d0\u00ce\u00d1 (\u00d2X\u00cc\u00c9\u00d3 (\u00d1 (\u00d4\u00d4\u00a6 \u00d5\u00ce \u00cf1\u00d2 \u00d6q\u00c9\u00a6 \u00d31\u00d7 \u00ce \u00cc\u00a6\u00d7 \u00cf \u00d8 \u00d1 (\u00cc\u00d1 \u00cb0\u00cd \u00d9X\u00d6q\u00d3 (\u00cf (\u00cb\u00db \u00da \u00d5\u00dc \u00c9\u00a6 \u00d2\u00a4 \u00cc\u00a6 \u00cf1\u00d4\u00d4\u00c9\u00dd \u00cf (\u00d2 \u00cc6 \u00d1 (\u00dd \u00cf (\u00d2 \u00cc\u00cbc\u00de \u00df\u00c0\u00d9X\u00d6q\u00cc\u00d7 \u00cfc\u00d6q\u00d0 \u00cdX\u00d6 \u00cf (\u00e0\u00c0 \u00cc\u00d7 X\u00cf\u00e2 \u00e1\u00c0\u00e3\u00e5\u00e4\u00e7\u00e6 \u00e1| \u00e8q\u00e3\u00ea \u00e9X\u00d6q\u00cdu\u00ebC\u00cf (\u00d3 (\u00cc6 \u00ec \u00c9\u00d4\u00d46 \u00d8 \u00cf (\u00edX\u00cf1\u00d4\u00a6 \u00cd \u00e9\u00ee \u00d1\u00f0 \u00efX\u00f1X\u00f2 (\u00f3R\u00f4 \u00f5\u00f0\u00f6\u00f7 X\u00f6X\u00f8\u00f2\u00f5\u00f2\u00f7 X\u00f9\u00ca \u00fa1\u00fb% \u00f5\u00fd\u00fc6\u00fb\u00f7 \u00f2\u00f7 X\u00f9 \u00fe\u00ff\u00a1(\u00fe\u00a3\u00a2\u00a4\u00a5\u00a7 \u00a6\u00a9 \u00fe\u00a1(\u00fe c\u00fe\u00a3 \u00ff\u00a1\u00a2(\u00ff\u00a1(\u00fe\u00a4\u00a9\u00a1!\u00a4\"!#\u00a6\u00a9 \u00ee\u00fe% $\u00a9 &\u00a9'\u00a9\u00a2\u00a9\u00a7 (\u00a9\u00a4) \u00a7 !\u00a4 \u00fe0 1 3 2\u00a9 4! 576\u00a3 8!(9 4\u00a9\u00a2 \u00fe\u00a2\u00a1(\u00a9@ \u00f0\u00fe\u00ff\u00a1 A 2\u00a9\u00a1 \u00a7 ! 59 BC \u00a7 (\u00a9 \u00a7 D\u00a1)\u00a2\"\u00a9 B\u00a5\u00a6\u00a9\u00a2(\u00a9 \u00ea\u00fe\u00ff\u00a1 3 &\u00a4\u00a1 \u00fe\u00a4 E&!\u00a1 B\u00a1\u00a2 0E&E! \u00a7 !(\u00feF\u00a4\u00a9\u00a1! \u00a7 G\u00a4 H (\u00a9 $\u00a1 & G\u00a4 IG (\u00fe\u00a5 \u00fe \u00ee\u00fe\u00a6 \u00ff\u00a1\"\u00a9\u00a4 I GP (#\u00a2 0 (\u00fe0 \u00a7 D\u00a9 & (\u00fe# G (\u00a1# Q \u00a7 \u00a9(\u00a1\u00a2 0 \u00a7 & $\u00a1!\u00a4 G (\u00fe (\u00fe\u00a2\u00a9(#\u00a9 E \u00fe \u00ff\u00a1 R (\u00a1\u00a4) F'\u00a1\u00a2 R TS\u00a9 UV WY X\u00a9 aV Wb \u00a7 c\u00a9 d Vfe g1 hpi\u00a9 q \u00a7 r st! srR t! u\u00a1 r \u00a7 v\u00a9 h\u00a3 w) sxx y\u00a1 qR R v\u00a9 hIq &! t&! sq\u00a9\u00a1 x\u00a5\u00a1\" i\u00a9 i\u00a1 xsr su\u00a9\u00a1 q \u00a7 t! t&qGr s\u00a9 qs\u00a9 q \u00a7 Q \u00a7 r s0u\u00a1 q\u00a9\u00a1 s &u\u00a9\u00a9\u00a5 q \u00a7 \u00a9\u00a1 u\u00a9 A u\u00a1\u00a1 xt! u\u00a1 9\u00a1 qq\u00a1 v\u00a1 hpq \u00a7 ! hy\u00a9 v\u00a9 xh u t&u\u00a9 9\u00a9 q s\u00a1 t&u\u00a9!\u00a5 \u00a7 su\u00a9# \u00a7 \u00a1 Cs\u00a1 sh & u\u00a1 &hH w)\u00a9 u\u00a5\u00a1 d\u00a1 qT\u00a9 u\u00a1 C \u00a7 s0 C u\u00a9\u00a9 u\u00a9 xu\u00a9 d\u00a1 sq he qf\u00a9 i\u00a1 x0u4s0 s\u00a1 d\u00a9 q \u00a7 hpr \u00a7 ! si\u00a9 s0u\u00a1 x0u4d\u00a9 sr qr \u00a7 \u00a9\u00a1 u\u00a9 xu\u00a1 d\u00a1 s0q \u00a7 hge g) h) shu\u00a1\u00a9 qe ijq C\u00a1 0sr\u00a5 k3q yh i\u00a9 i\u00a1! u\u00a1 rG\u00a1 qh) l&qmed7eo np) q rts7uv oq itr souvw&x! 7 y) q z3 qr\u00a9\u00a1 u\u00a9 xu\u00a1 d\u00a9 sq h hv\u00a1 rG h){Yp)| joy) q zA itr 4qG\u00a5 7 u\u00a9 Y yRq z3}) v\u00a1 q &~ w) sxx i\u00a1 xh\u00a5 rq\u00a1 & x &u\u00a9 xqC sh\u00a9 q\u00a5 it Fk3g) i! i\u00a1! uv qr \u00a7 eP\u00a1 qhq hp G\u00a1\u00a1 G &\u00a9 hw) sxx y\u00a9 q C \u00a7 s0 4x0 v\u00a9 hqu\u00a9 qhr &s0y\u00a1 q G\u00a1 q \u00a7 f\u00a9 r\u00a1\u00a9 d4q\u00a9 s0\u00a9 q", "num_citations": "26\n", "authors": ["1444"]}
{"title": "Distributed, interoperable workflow support for electronic commerce\n", "abstract": " This paper describes a flexible distributed transactional workflow environment based on an extensible object-oriented framework built around class libraries, application programming interfaces, and shared services. The purpose of this environment is to support a range of EC-like business activities including the support of financial transactions and electronic contracts. This environment has as its aim to provide key infrastructure services for mediating and monitoring electronic commerce.", "num_citations": "26\n", "authors": ["1444"]}
{"title": "Sharing processes: Team coordination in design repositories\n", "abstract": " Information systems support for design environments emphasizes object management and tends to neglect the growing demand for team support. Process management is often tackled by rigid technological protocols which are likely to get in the way of group productivity and quality. Group tools must be introduced in an unobtrusive way which extends current practice yet provides structure and documentation of development experiences. The concept of sharing processes allows agents to coordinate the sharing of ideas, tasks, and results by interacting protocol automata which can be dynamically adapted to situational requirements. Inconsistency is managed with equal emphasis as consistency. The sharing process approach has been implemented in a system called ConceptTalk which has been experimentally integrated with design environments for information and hypertext systems.", "num_citations": "26\n", "authors": ["1444"]}
{"title": "Mobile access to MPEG-7 based multimedia services\n", "abstract": " Multimedia information systems have been developed into service-ware. With the paradigms of web services, service oriented architectures (SOA), and Web 2.0 widgets, multimedia has become truly ubiquitous. However, interoperability, scalability, reliability and security are arising challenges at mobile multimedia service development. This paper focuses on the analysis, design, development and evaluation of a middleware that allows access from mobile devices to a bundle of multimedia services. The services are based on the international multimedia metadata description standard MPEG-7. The implementation is based on new generation of service-oriented application servers called Lightweight Application Server (LAS). Mobile web services refer to the fact that mobile servers host web services. A prototype was developed as a proof of concept, showing how to access MPEG-7 based multimedia services from a\u00a0\u2026", "num_citations": "25\n", "authors": ["1444"]}
{"title": "A process data warehouse for tracing and reuse of engineering design processes\n", "abstract": " The design and development processes of complex technical systems are of crucial importance to the competitiveness of an enterprise. These processes are characterized by high creativity and strong non-deterministic dynamics. Traditional information science methods, however, are intended for more deterministic work processes. They cannot be effectively applied to support creative activities like conceptual synthesis, analysis, and decision making. Therefore methods of experience management need to be exploited here. This paper presents a new integrated approach to such design process guidance based on capturing the process traces in a Process Data Warehouse (PDW). Both the products to be designed and the process steps corresponding are structured and stored as extended method traces. This trace capture facilitates the processing and subsequent reuse of the information through a process\u00a0\u2026", "num_citations": "25\n", "authors": ["1444"]}
{"title": "Broker's lounge-an environment for multi-dimensional user-adaptive knowledge management\n", "abstract": " The Broker's Lounge is a shell for knowledge structuring and dynamic user interface generation which supports the personalisation of both information structures and user interfaces, emphasising options for context change and multi-dimensional constraint propagation. Two major applications have been developed so far: ELFI, an advisor that manages knowledge about research programs in Germany such that proposers can identify appropriate funding schemes; and MarketMonitor, a tool that helps companies monitor the web pages of competitors, suppliers, and customers for early detection of changes in the market situation.", "num_citations": "25\n", "authors": ["1444"]}
{"title": "Increasing the expressiveness of analytical performance models for replicated databases\n", "abstract": " The vast number of design options in replicated databases requires efficient analytical performance evaluations so that the considerable overhead of simulations or measurements can be focused on a few promising options. A review of existing analytical models in terms of their modeling assumptions, replication schemata considered, and network properties captured, shows that data replication and intersite communication as well as workload patterns should be modeled more accurately. Based on this analysis, we define a new modeling approach named 2RC (2-dimensional replication model with integrated communication). We derive a complete analytical queueing model for 2RC and demonstrate that it is of higher expressiveness than existing models. 2RC also yields a novel bottleneck analysis and permits to evaluate the trade-off between throughput and availability.", "num_citations": "25\n", "authors": ["1444"]}
{"title": "CREWS: towards systematic usage of scenarios, use cases and scenes\n", "abstract": " In the wake of object-oriented software engineering, use cases have gained enormous popularity as tools for bridging the gap between electronic business management and information systems engineering. A wide variety of practices has emerged but their relationships to each other, and with respect to the traditional change management process, are poorly understood. The ESPRIT Long Term Research Project CREWS (Cooperative Requirements Engineering With Scenarios) has conducted surveys of the research literature and of the industry practice in scenario-based requirements engineering as a basis to develop a framework of approaches and research issues in the field. In two demonstrator prototypes, one based on textual scenario representations, the other on multimedia scenes, solutions to some of the most critical open problems from these surveys are being explored. The project results\u00a0\u2026", "num_citations": "25\n", "authors": ["1444"]}
{"title": "Adaptive predicate managers in database systems\n", "abstract": " Adaptive Predicate Managers in Database Systems | Proceedings of the 12th International Conference on Very Large Data Bases ACM Digital Library home ACM home Google, Inc. (search) Advanced Search Browse About Sign in Register Advanced Search Journals Magazines Proceedings Books SIGs Conferences People More Search ACM Digital Library SearchSearch Advanced Search vldb Conference Proceedings Upcoming Events Authors Affiliations Award Winners More HomeConferencesVLDBProceedingsVLDB '86Adaptive Predicate Managers in Database Systems ARTICLE Adaptive Predicate Managers in Database Systems Share on Authors: Stefan B\u00f6ttcher profile image Stefan B\u00f6ttcher View Profile , Matthais Jarke profile image Matthias Jarke View Profile , Joachim William Schmidt profile image Joachim W. Schmidt View Profile Authors Info & Affiliations Publication: VLDB '86: Proceedings of the \u2026", "num_citations": "25\n", "authors": ["1444"]}
{"title": "Techology Enhanced Professional Learning: Process, Challenges and Requirements\n", "abstract": " Since we cannot transfer knowledge from one person to another person, learning, also known as knowledge creation, is the social process of acquiring and applying knowledge. Our claim is that the oscillating process of knowledge acquisition and application for workplace learning can be best described by the SECI model introduced by Nonaka in 1994. In this paper, we analysis the learning process in terms of the SECI model, identify the challenges for technology enhanced professional learning and define the requirements for future applications such as personalized adaptive learning. We report the results of a roadmap survey done in the framework of PROLEARN to disclose the desired state of the art in technology enhanced professional learning in the year 2015 and show ways how to proceed on the way to the desired state.", "num_citations": "24\n", "authors": ["1444"]}
{"title": "Metadata and cooperative knowledge management\n", "abstract": " Cooperative knowledge management refers to the work practice or culture facet of information systems engineering; it plays a key role especially in engineering and consulting domains. However, in comparison to technology-centered and business-process-centered meta modeling approaches (exemplified by UML and ERP), this aspect has received significantly less attention in research and is much less mature in terms of international standardization. We claim that additional interdisciplinary research effort is needed in this direction, and discuss different points of attack, largely in terms of their implications for better metadata management and meta modeling.", "num_citations": "24\n", "authors": ["1444"]}
{"title": "Business models for eGovernment services\n", "abstract": " Public sector information furnishes a valuable information resource for many businesses. Thus, the design of value chains across different stakeholders and corresponding business models capitalising on public sector information is a challenge. Business models have been investigated mostly in the realms of eCommerce and rarely for public private partnerships. Thus, they are strongly tailored to financial incentives. So far, the modelling of policies and arguments have been neglected in eCommerce approaches. This paper describes a new modelling method named BMeG (Business Models for eGovernment) supporting the planning of business models for eGovernment services. BMeG facilitates the modelling of options of value chains with public and private partners, their relationships with individual advantages and disadvantages for policies. Hence, BMeG unveils business opportunities and their rationales.", "num_citations": "23\n", "authors": ["1444"]}
{"title": "Requirements engineering for control systems development in small and medium-sized enterprises\n", "abstract": " Since nowadays more and more control systems are realised within software on electronic control units, a conceptual integration of control systems engineering and software engineering must be aimed at. Within this work, we build on a proposal to use the software requirements formalism i* to enable a combined investigation of control systems' and software requirements. While i*'s modelling means have turned out to be sufficiently expressive, two characteristics of control systems still need to be addressed: firstly, how to incorporate domain knowledge especially about the system to be controlled in the requirements development process and secondly, how to specifically support small and medium-sized companies (SMEs) that are the main driver for innovations in this domain. Due to their innovativeness and flexibility, the SMEs usually follow a project-oriented customer-specific development approach. To be\u00a0\u2026", "num_citations": "23\n", "authors": ["1444"]}
{"title": "Towards Web 2.0 Driven Learning Environments.\n", "abstract": " Over the last decade, it has been widely argued that technology-enhanced learning could respond to the needs of the new knowledge society and transform the way we learn. However, despite isolated achievements, technology-enhanced learning has not really succeeded yet in revolutionizing our education and learning processes. In fact, most current initiatives do not focus on the social aspect of learning and learning content is still pushed to a pre-defined group of learners in closed environments. Recently, Web 2.0 concepts have started to open new doors for more effective learning and have the potential to overcome many of the limitations of traditional learning models. In this paper we show in which way the communitydriven platform Learnr, under development at the University of M\u00fcnster, puts crucial success factors for future technology enhanced learning into practice, applying well known concepts like networking and social tagging. As a consequence, a Web 2.0 perspective on learners, learning content and learning communities can be derived.", "num_citations": "23\n", "authors": ["1444"]}
{"title": "Software process modeling as a strategy for KBMS implementation\n", "abstract": " Deductive and object-oriented databases should not be viewed as competitors but as two layers of abstraction (specification and implementation) within an overall knowledge base management systems (KBMS) architecture. Software process modeling is proposed as an efficient means to maintain the relationships between the two layers. A detailed account of experiences with implementing a deductive and structurally object-oriented system called ConceptBase gives preliminary evidence of the value of our proposal; ConceptBase may also serve as a basis for bootstrapping an environment for fully object-oriented databases.", "num_citations": "23\n", "authors": ["1444"]}
{"title": "Transkriptivit\u00e4t: Operative medientheorien als grundlage von informationssystemen f\u00fcr die kulturwissenschaften\n", "abstract": " Die Mediendebatte in den Geisteswissenschaften war lange Zeit durch zwei weitgehend separierte Str\u00e4nge gekennzeichnet. Zum einen wurden neue technische Ph\u00e4nomene, oftmals unter R\u00fcckgriff auf Konzepte der Technikwissenschaften oder der Informatik, in ihrem Stellenwert f\u00fcr die Geisteswissenschaften diskutiert\u2013wie etwa das Konzept der Adressierung. Zum anderen gab es eine umfangreiche kulturpessimistische Debatte, die\u2013so etwa Baudrillard [2] in seiner historischen Perspektive der Mediennutzung von vorindustrieller Imitation \u00fcber industrielle Produktion bis hin zur postindustriellen Simulation\u2013vor einem Realit\u00e4tsverlust durch eine \u00fcberm\u00e4\u00dfig realit\u00e4tsnahe Mediengestaltung und vor einer entsprechenden Verflachung der Kultur warnt. Wenngleich die Beobachtung der zunehmend virtualisierten Kriegsberichterstattung und vieler politischer Kampagnen zugegebenerma\u00dfen eine solche Debatte nahe\u00a0\u2026", "num_citations": "22\n", "authors": ["1444"]}
{"title": "Security analysis of mobile web service provisioning\n", "abstract": " Mobile data services in combination with profluent web services are seemingly the path breaking domain in current information systems research. Mobile web services have vast application domains and effectively pave the way for exciting performance and security challenges. Though numerous standardised security specifications and implementations exist for web services in general, not much has been analysed and standardised for mobile web services. This paper explores some of the critical challenges in providing security to the mobile web services domain and addresses the realisation of security for mobile web service provisioning with special focus at our Mobile Host.", "num_citations": "22\n", "authors": ["1444"]}
{"title": "Manifest*: Strategische bedeutung des software engineering in deutschland\n", "abstract": " Software ist der fundamentale Werkstoff des Informationszeitalters. Innovative Produkte und Dienstleistungen sind ohne Software nicht mehr denkbar. Die Wettbewerbsf\u00e4higkeit der deutschen Wirtschaft h\u00e4ngt entscheidend von der F\u00e4higkeit ab, Software-intensive Produkte und Dienstleistungen mit h\u00f6chster Qualit\u00e4t zu erstellen. Software Engineering \u00fcber dem Weltniveau ist die Voraussetzung daf\u00fcr, dass Deutschland seine f\u00fchrende Stellung im Ingenieurbereich, etwa im Maschinenbau, halten und ausbauen und entsprechende Positionen in neuen Sparten, etwa im modernen Gesundheitswesen (e-Health), aufbauen kann. Software wird in der Zukunft integrierter\u2013in vielen F\u00e4llen sogar dominierender\u2013Teil gro\u00dfer komplexer Systemesein. Nicht nur in der Automobil-und Luftfahrtindustrie wird dieser Trend bereits heute deutlich sichtbar. Die erforderliche Integration von Mechanik, Elektronik und Software und die Vermeidung unerw\u00fcnschter Wechselwirkungen kann nur durch die fr\u00fchzeitige Integration der Modellierungskompetenzen des Software Engineering in den Entwicklungsprozess beherrscht werden. Diese neue Positionierung von Software Engineering als systemische Disziplin erfordert eine neue Ausrichtung und St\u00e4rkung der Bereiche Forschung, Lehre und Technologietransfer. Es ist die auf sorgf\u00e4ltige Analysen abgest\u00fctzte \u00dcberzeugung der Unterzeichner, dass verst\u00e4rkte Anstrengungen in allen drei Bereichen notwendig sind, um die Herausforderungen des Informationszeitalters und der Globalisierung anzunehmen. Dieses Manifest stellt", "num_citations": "22\n", "authors": ["1444"]}
{"title": "The design of knowledge-based systems for managing ill-structured software projects\n", "abstract": " Current planning and control procedures for large-scale software projects are not sufficiently equipped to deal with changing or imprecise requirements, resource breakdowns, unexpected delays, etc. We propose a solution for managing change in projects, based on a semantic model of the software design and development processes. At the heart of this technique is the formation of islands of project knowledge in a way that facilitates dealing with most design and plan revisions locally. A protocol for interactive change management is presented that advocates need-based formation of coalitions between islands as a means for graceful degradation in the place of strict hierarchical control. The results of initial empirical investigations of the usability of the approach and plans for its continuing evaluation are also reported.", "num_citations": "22\n", "authors": ["1444"]}
{"title": "Panel on time and databases\n", "abstract": " Nowhere is the lag between database theory and database practice more apparent than with respect to the issue of time. Beg inning long before the advent of database management systems, econometr ic ians, industrial applications programmers and systems staff have been building programs and procedures for handling time-series data. It is one of the failures of the\" three great data models\u201d that none has addressed this issue. With the promise of several new technologies that will make feasible the storage of orders of magnitude more data on a single type of storage medium, it behooves us in the database research community to address the issue of databases and time. We have the opportunity to explore theoretical issues of time and its database properties and to develop d isc ipl ined models for its use, so as to guide and enhance practical attempts to deal with these issues, and to avoid merely ad hoc\u00a0\u2026", "num_citations": "22\n", "authors": ["1444"]}
{"title": "A short introduction to expert systems\n", "abstract": " It is a generally accepted view among researchers in Artificial Intelligence that the 1980's will witness a tremendous upsurge in the number of successful applications of A1 expertise to real-world systems. High on the list of the technologies that are expected to be applied in the marketplace are expert, or knowledge-based, systems. The formation of a number of expert system companies, often in close collaboration with major academic A1 research centers, attests to the growing belief in the economic viability of this technology transfer. Although there is yet to be developed a formal theory of what constitutes an expert system, there are some general features that can be identified.", "num_citations": "22\n", "authors": ["1444"]}
{"title": "\u201cComplexity of Systems Evolution: Requirements Engineering Perspective\u201d\n", "abstract": " Walking on water, and programming according to specifications is easy\u2014as long as both of them are frozen. --Robert Glass This introduction discusses the changing nature of complexity associated with requirements engineering (RE) tasks and how it has shifted from managing internal complexity to adapting and leveraging upon external and dynamic complexity. We note several significant drivers in the requirements knowledge that have resulted in this change and discuss in light of complexity theory how the RE research community can respond to this. We observe several research challenges associated with \u201cnew complexity\u201d and highlight how the articles included in the special issue advance the field by defining complexity more accurately, observing more vigilantly new sources of complexity, and suggesting new ways to manage complexity in terms of economic assessments, knowledge flows, and modeling\u00a0\u2026", "num_citations": "21\n", "authors": ["1444"]}
{"title": "The Hero's Journey-Template-Based Storytelling for Ubiquitous Multimedia Management.\n", "abstract": " Professional communities in research domains including much fieldwork and mobile multimedia acquisition such as the domain of cultural heritage management lack support to create, access, organize and share multimedia within their communities. Digital storytelling is an excellent means to share knowledge represented by ubiquitous multimedia in communities. However, it is not easy for those professional communities to tell and share good digital stories, since they are amateurs in storytelling in many cases. This paper proposes the application of professional story templates to enhance (non-linear) digital storytelling with a template engine allowing users\u2019 collaborative design, adaptation and mashing up of story templates. A prototype of the template engine YouTell TE was integrated in a community storytelling platform. A set of case studies demonstrates the usefulness of this approach.", "num_citations": "21\n", "authors": ["1444"]}
{"title": "A modular approach for exploring the semantic structure of technical document collections\n", "abstract": " The identification and analysis of an enterprise's knowledge available in a documented form is a key element of knowledge management. Visual methods which allow easy access to a document collection's contents are an enabling technology. However, no single information retrieval technique is likely to adequately deal with such tasks independent of the specific situation. In this paper, we therefore present a visualization technique based on a modular approach that allows a variety of techniques from semantic document analysis to be used in the visualization of the structure of technical document collections.", "num_citations": "21\n", "authors": ["1444"]}
{"title": "KBMS requirements of knowledge-based systems\n", "abstract": " This overview paper provides a customer perspective of the requirements for knowledge base management systems. The customer is taken to be the developer of knowledge-based application systems,, such as rule-based expert systems, natural language interfaces, vision systems, and design support environments. We conclude that there are area-specific knowledge base management functions that, if provided by a KBMS, could substantially simplify the development and maintenance of knowledge-based applications. However, the range of requirements appears too wide to permit the development of a completely generalized KBMS, in the same sense as existing generalized DBMS.", "num_citations": "21\n", "authors": ["1444"]}
{"title": "Preservation and management of the UNESCO World Heritage Site of Bamiyan: Laser scan documentation and virtual reconstruction of the destroyed Buddha figures and the\u00a0\u2026\n", "abstract": " G. Toubekisa*, I. Mayerb, M. D\u00f6ring-Williamsb, K. Maedac, K. Yamauchic, Y. Taniguchic, S. Morimotod, M. Petzete, M. Jarkef, M. Jansena a RWTH Aachen University, Aachen Center for Documentation and Conservation, Templergraben 49, 52056 Aachen, Germany (toubekis, jansen)@ sbg. arch. rwth-aachen. de b Technical University Vienna, Department of Art History, Karlsplatz 13/251, 1040 Vienna, Austria c Japan Center for International Cooperation in Conservation, NRICPT, 13-43 Ueno Park, Tokyo, Japan d Nara National Research Institute for Cultural Properties, 2-9-1 Nijo-cho, Nara, Japan e ICOMOS Germany, PO Box 100 517, 80079 Munich, Germany f RWTH Aachen University, Information Systems & Database Technology, Ahornstr. 55, 52056 Aachen, Germany jarke@ dbis. rwth-aachen. de", "num_citations": "20\n", "authors": ["1444"]}
{"title": "Tagging diversity in personal learning environments\n", "abstract": " Tagging is a prevalent practice in the Web 2.0. It has been widely used to annotate different media like video. However, in personal learning environments (PLEs), tagging is supporting not only content indexing but also the self-regulated learning process consisting of different phases like planning, learning, and reflecting. In particular, in the reflection phase, tags support the organization of learning outcomes. We have researched the interrelations of learning content, learning processes, and learning phases to provide a comprehensive overview about diverse tagging behavior in PLEs like using multi-granular tagging, semantic tagging, community-based tagging, and expert\u2013amateur tagging. We have exemplified these behaviors by the design, realization, and evaluation of a PLE for classical Chinese poetry.", "num_citations": "20\n", "authors": ["1444"]}
{"title": "Vigils in a wilderness of knowledge: Metadata in learning environments\n", "abstract": " The paper presents two computer-supported learning environments which are built on top metadata defined in XML; a comprehensive study environment for a Talmudic tractate and a video based learning environment called Virtual Entrepreneurship lab used in entrepreneurship education. While expressive metadata standards like MPEG-7 help us technically to implement multimedia learning environments by offering comprehensive coverage of all needed aspects, the century spanning editing process of knowledge encyclopaedias like the Babylonian Talmud offers useful hints what kind of metadata are necessary to disclose the knowledge structures in non-linear material.", "num_citations": "20\n", "authors": ["1444"]}
{"title": "Experience-based knowledge management: a cooperative information systems perspective\n", "abstract": " Experience-based knowledge management is the art of capitalizing on failures and missed opportunities. Building on a number of interdisciplinary research projects, we study three possible approaches within a cooperative information systems framework, focussing on the facets of pragmatic technology usage, model-based management control, and social work practice and learning, respectively.", "num_citations": "20\n", "authors": ["1444"]}
{"title": "Multi-Perspective Modeling and Analysis of Cooperation Processes\n", "abstract": " The success of an organization depends on its ability to cooperate internally and externally in its business processes. Cooperation processes, both within and between organizations, are thus of key importance to an organization. However, cross-functional cooperation in particular often suffers from problems such as communication gaps, conflicting goals and priorities, misunderstandings, and lack of long-term knowledge management.The capturing and evaluation of cooperation processes often focuses on an activity-oriented perspective of the process, leading to a bird\u2019s eye view of the intended process, while neglecting the real process and its problem areas. In this thesis, the CO-MAP methodology for modeling and analyzing real cooperation processes is introduced. CO-MAP focuses on the process stakeholders and the impact of the cooperation processes on their work. To do so, CO-MAP provides a method for capturing the process stakeholders\u2019 perspectives of the cooperation process in an informal process diagram. These informal process diagrams are then mapped into four different formal models, representing the strategic, activity-oriented, service-oriented, and information flow-oriented perspective of the process, respectively. The integration of these four perspectives provides a holistic representation of the process.", "num_citations": "20\n", "authors": ["1444"]}
{"title": "Improving OLTP data quality using data warehouse mechanisms\n", "abstract": " Research and products for the integration of heterogeneous legacy source databases in data warehousing have addressed numerous data quality problems in or between the sources. Such a solution is marketed by Team4 for the decision support of mobile sales representatives, using advanced view maintenance and replication management techniques in an environment based on relational data warehouse technology and Lotus Notes-based client systems. However, considering total information supply chain management, the capture of poor operational data, to be cleaned later in the data warehouse, appears sub-optimal. Based on the observation that decision support clients are often closely linked to operational data entry, we have addressed the problem of mapping the data warehouse data quality techniques back to data quality measures for improving OLTP data. The solution requires a warehouse-to\u00a0\u2026", "num_citations": "20\n", "authors": ["1444"]}
{"title": "Developing decision support systems: a container management example\n", "abstract": " The problem of managing an intercontinental containertransportation system is used as an example of howknowledge from the areas of database design, managementscience, and human factors research can be combined in thedesign of a decision support system. Using a newrepresentation of time-related database objects, we firstpresent a logical data model of a container transportationsystem. A hierarchically distributed decision supportsystem can be based on this model. A physical databasestructure is proposed and a survey of partial optimizationmodels to be used in the decision support system is given.", "num_citations": "20\n", "authors": ["1444"]}
{"title": "Eve: A sketch-based software prototyping workbench\n", "abstract": " Prototyping involves the evolution of an idea into various stages of design until it reaches a certain level of maturity. These design stages include low, medium and high fidelity prototypes. Workload analysis of prototyping using NASA-TLX showed an increase in workload specifically in frustration, temporal demand, effort, and decline in performance as the participants progressed from low to high fidelity. Upon reviewing numerous commercial and academic tools that directly or indirectly support software prototyping in one aspect or another, we identified a need for a comprehensive solution to support the entire software prototyping process. In this paper, we introduce Eve, a prototyping workbench that enables the users to sketch their concept as low fidelity prototype. It generates the consequent medium and high fidelity prototypes by means of UI element detection and code generation. We evaluated Eve using SUS\u00a0\u2026", "num_citations": "19\n", "authors": ["1444"]}
{"title": "Mobile web service discovery in peer to peer networks\n", "abstract": " The advanced features of today's smart phones and hand held devices, like the increased memory and processing capabilities, allowed them to act even as information providers. Thus a smart phone hosting web services is not a fancy anymore. But the relevant discovery of these services provided by the smart phones has became quite complex, because of the volume of services possible with each Mobile Host providing some services. Centralized registries have severe drawbacks in such a scenario and alternate means of service discovery are to be addressed. P2P domain with it resource sharing capabilities comes quite handy and here in this paper we provide an alternate approach to UDDI registry for discovering mobile web services. The services are published into the P2P network as JXTA modules and the discovery issues of these module advertisements are addressed. The approach also provides alternate means of identifying the Mobile Host.", "num_citations": "19\n", "authors": ["1444"]}
{"title": "Towards (dis) trust-based simulations of agent networks\n", "abstract": " While the importance of trust in agent networks has been recognized for some time, the role of distrust has largely been ignored. In this paper, we argue that an explicit consideration of distrust and its complex interaction with individual trust and confidence in the network as a whole is necessary for the design and analysis of hybrid networks of human and machine agents. We propose a trust-confidencedistrust (TCD) model of agent network dynamics, and show how the dynamics of such networks can be modeled by extending Yu\u2019si* framework and combining it with the plan language ConGolog. This results in a simulation environment in which network processes and their dependence on trust, confidence in the networks and distrust can be studied.", "num_citations": "19\n", "authors": ["1444"]}
{"title": "A flowsheet-centered architecture for conceptual design\n", "abstract": " Publisher SummaryThis chapter discusses the flowsheet-centered architecture for conceptual design. The flowsheet-centered integration architecture is proposed that\u2014in contrast to commercial solutions\u2013\u2013takes into account the central role of flowsheets in chemical engineering design. A novel flowsheet editor has been realized as the center of such an architecture, which allows the creation and management of hierarchical flowsheets for various design alternatives in different versions on different levels of detail for a variety of applications in the design process. It has an open architecture for data exchange with application tools and is integrated with a coordinating workflow component. Integration with additional application tools is planned. A coupling of the flowsheet editor with administrative support systems for managing design processes in collaborative teams is described. Another focus will be laid on the\u00a0\u2026", "num_citations": "19\n", "authors": ["1444"]}
{"title": "DAIDA: conceptual modeling and knowledge-based support of information systems development processes\n", "abstract": " Sauf mention contraire ci-dessus, le contenu de cette notice bibliographique peut \u00eatre utilis\u00e9 dans le cadre d\u2019une licence CC BY 4.0 Inist-CNRS/Unless otherwise stated above, the content of this bibliographic record may be used under a CC BY 4.0 licence by Inist-CNRS/A menos que se haya se\u00f1alado antes, el contenido de este registro bibliogr\u00e1fico puede ser utilizado al amparo de una licencia CC BY 4.0 Inist-CNRS", "num_citations": "19\n", "authors": ["1444"]}
{"title": "View integration in negotiation support systems\n", "abstract": " In decision support systems (DSS), attention has recently shifted from systems supporting a single decision maker to those supporting a group of analysts and/or decision makers who try to solve a problem cooperatively", "num_citations": "19\n", "authors": ["1444"]}
{"title": "Information systems engineering with digital shadows: concept and case studies\n", "abstract": " The production sector has faced many difficulties in taking full advantage of opportunities found in other web application domains. Production research has focused on sophisticated mathematical models ranging from molecular materials modeling to efficient production control to inter-company supply network logistics. Often, these models have no closed-form solutions; this led to intense simulation research for individual modeling viewpoints, often labeled \u201cDigital Twins\u201d.                 However, the complexity of the overall system precludes Digital Twins covering more than just a few system perspectives, especially if near-realtime performance is required. Moreover, the wide variety of individual situations and behaviors is usually captured only as statistical uncertainty. In order to achieve better performance and more context adaptation, the interdisciplinary research cluster \u201cInternet of Production\u201d at RWTH\u00a0\u2026", "num_citations": "18\n", "authors": ["1444"]}
{"title": "A performance evaluation of mobile web services security\n", "abstract": " It is now feasible to host basic web services on a smart phone due to the advances in wireless devices and mobile communication technologies. The market capture of mobile web services also has increased significantly, in the past years. While the applications are quite welcoming, the ability to provide secure and reliable communication in the vulnerable and volatile mobile ad-hoc topologies is vastly becoming necessary. Even though a lot of standardized security specifications like WS-Security, SAML exist for web services in the wired networks, not much has been analyzed and standardized in the wireless environments. In this paper we give our analysis of adapting some of the security standards, especially WS-Security to the cellular domain, with performance statistics. The performance latencies are obtained and analyzed while observing the performance and quality of service of our Mobile Host.", "num_citations": "18\n", "authors": ["1444"]}
{"title": "PLEM: a Web 2.0 driven Long Tail aggregator and filter for e\u2010learning\n", "abstract": " The personal learning environment driven approach to learning suggests a shift in emphasis from a teacher\u2010driven knowledge\u2010push to a learner\u2010driven knowledge\u2010pull learning model. One concern with knowledge\u2010pull approaches is knowledge overload. The concepts of collective intelligence and the Long Tail provide a potential solution to help learners cope with the problem of knowledge overload. The paper aims to address these issues.", "num_citations": "18\n", "authors": ["1444"]}
{"title": "SNet reloaded: Roles, monitoring and agent evolution\n", "abstract": " In previous work, we proposed the prototype environment SNet for the representation and dynamic evaluation of agent-based designs for inter-organizational networks. A key feature of SNet is the automatic translation of extended i* models into the action language ConGolog. In order to run realistic simulations, the resulting agents are deliberative in that they can choose between different courses of action according to some utility measure. When applying SNet to modelling an existing entrepreneurship network, we discovered a number of deficiencies of our current proposal, in particular, the lack of a role concept, the ability to monitor the execution of plans that depend on other agents\u2019 contributions and the ability to model agents that evolve over time. In this paper we will sketch the example domain and discuss how these new features can be incorporated in the SNet framework.", "num_citations": "18\n", "authors": ["1444"]}
{"title": "A process-integrated conceptual design environment for chemical engineering\n", "abstract": " The process industries (chemicals, food, oil,...) are characterized by \u2014 continuous or batch \u2014 processes of material transformation. The design of such processes, and their mapping to the available equipment (plants composed of production units in which reactions take place), is a complex process that determines the competitiveness of these industries, as well as their environmental impact. In cooperation with researchers and industry from chemical engineering, we have developed the idea to capture and evaluate the experiences gained about process designs in so-called process data warehouses. The data sources for such process data warehouses are highly heterogeneous tools, e.g. for conceptual design (termed flowsheeting in chemical engineering), for mathematical simulations of large non-linear differential equation systems, for measurements gained with experimental usage of equipment at\u00a0\u2026", "num_citations": "18\n", "authors": ["1444"]}
{"title": "Driving the organizational learning cycle: the case of computer-aided failure management.\n", "abstract": " Nonaka describes the process of creating knowledge in enterprises as an interplay of tacit and explicit knowledge. In the interdisciplinary German FOQUS project, industrial engineers and computer scientists have investigated information systems support for this process in the context of a specific knowledge creation strategy,\" learning from failures\". In the domain of failure management for complex production machinery, Nonaka\u2019s socialization is supported by service-oriented workflows, externalization is supported by a domain-oriented meta model facilitating the construction of failure models, combination and internalization are supported by formal conflict resolution techniques and informal hypermedia representations. All of these representations are held in a knowledge-based repository. A implementation of the approach is operational in the Aditec demonstration factory at Aachen.", "num_citations": "18\n", "authors": ["1444"]}
{"title": "On modeling processes\n", "abstract": " While other work in model management has looked at models as static objects to be administered in database-like fashion, we emphasize the central role of process knowledge in model construction, usage, and maintenance. We claim that tools are needed to collaboratively elicit knowledge, to represent it conceptually, and to maintain its consistency over time by constraint propagation and reason maintenance. We describe examples of such tools and propose a general approach for integrating them.", "num_citations": "18\n", "authors": ["1444"]}
{"title": "Support for security modeling in information systems design\n", "abstract": " We present a set of modeling constructs and reasoning tools that extend the use of computer-supported conceptual modeling for information systems to the study of security aspects. The modeling framework is the Group Security Model (GSM) which describes access rights through a teamwork-oriented organizational model. Reasoning about GSM application models is enabled by representing them in a deductive and object-oriented database language, Telos. A prototype implementation in the software information system ConceptBase is reported.", "num_citations": "18\n", "authors": ["1444"]}
{"title": "Introduction to query processing\n", "abstract": " Query processing in databases can be divided into two steps: selecting an \u2018optimal\u2019 evaluation strategy, and executing it. We first present elementary nested loop and relational algebra algorithms for query execution and point out some opportunities for improving their performance. A survey of optimization strategies, structured in query transformation techniques and access planning methods, follows. Finally, extensions for special-purpose query systems are briefly addressed.", "num_citations": "18\n", "authors": ["1444"]}
{"title": "A data-driven user interface generator for a generalized multiple criteria decision support system\n", "abstract": " The development of reliable user friendly software is a difficult and error prone task. And yet, as amply demonstrated by the current wave of popularity of spread-sheet programs, the rewards can be great. Software that combines functionality with a good interface will be used by management personnel on a voluntary, everyday basis and in ways that, pernaps, were not even dreamed of by the software designers. The apalications that have so far been developed have, for the most part, been fairly rudimentary from a management science point-of-view. However, we believe that the existence and popularity of these elementary models will inexorably create a demand for more sophisticated ones. In fact the processing of information in more and more complex ways will become a major focus of economic competition and survival.In this paper we describe a software system that is designed specifically to facilitate the development of decision support systems (DSS). Our objective is to help the management scientist build successful software. Our focus is on DSS employing Multi-Criteria Decision Making (MCDM) models. But this is not the only possible area of application. Since our goal is to develop software that will help others develop software there is a possibility for confusion. To clarify the discussion we will call the set of software tools that we are designing a\" Generatorw for multi-criterion decision support systems (GMCDSS). The generator provides an environment for model builders to develop\" targetw software in the area of multi-criterion DSS (MCDSS). The builders therefore are the users of the GMCDSS while the decision makers use the\u00a0\u2026", "num_citations": "18\n", "authors": ["1444"]}
{"title": "Mobile mining and information management in healthnet scenarios\n", "abstract": " Health and mobility of elderly people is gaining importance in aging societies. New communication-based methods to provide health services with personal health care devices are considered promising elements of first-class medical care services for everybody. To achieve this vision, several technological issues have to be solved: (i) body sensors to monitor vital functions have to be developed; (ii) these sensors should be integrated into textile structures to guarantee ease of use and patient acceptance; (iii) the collected sensor data has to be analyzed to detect emergency situations and to reduce the data volume; (iv) relevant data has to be integrated with other information systems in the work environment of medical experts. These challenges are addressed within the HealthNet project at RWTH Aachen University. The goal of the project is to develop a framework in which health professionals can remotely\u00a0\u2026", "num_citations": "17\n", "authors": ["1444"]}
{"title": "GeRoMe: A generic role based metamodel for model management\n", "abstract": " The goal of Model Management is the development of new technologies and mechanisms to support the integration, evolution and matching of models. Such tasks are to be performed by means of a set of model management operators which work on models and their elements, without being restricted to a particular metamodel (e.g. the relational or UML metamodel).                 We propose that generic model management should employ a generic metamodel (GMM) which serves as an abstraction of the features of particular metamodels while preserving the semantics of its different elements. A naive generalization of the elements of concrete metamodels in generic metaclasses would loose some of the specific features of the metamodels, or yield a prohibitive number of metaclasses in the GMM. To avoid these problems, we propose the Generic Role Based MetamodelGeRoMe in which each model\u00a0\u2026", "num_citations": "17\n", "authors": ["1444"]}
{"title": "ATLAS: A web-based software architecture for multimedia e-learning environments in virtual communities\n", "abstract": " Multi-perspective problem solutions, leading to an increasing complexity in creating authentic learning scenarios and collaborative learning strategies, have gained the focus of scientific research. In order to assist learners in virtual communities working with digital media artifacts we analyze the needs of communities in different scientific domains ranging from the humanities to engineering. We combine our results with a media theory developed in Germany\u2019s first interdisciplinary and collaborative research center on \u201dMedia and Cultural Communication\u201d. Based on the operational processes named transcription, localization, and addressing we introduce ATLAS, a web-based software architecture for multimedia e-learning environments in virtual communities. Further, we test metadata standards like MPEG-7 for digital media management in virtual communities. Exemplarily, we present the movie triage\u00a0\u2026", "num_citations": "17\n", "authors": ["1444"]}
{"title": "Requirements analysis from multiple perspectives: Experiences with conceptual modeling technology\n", "abstract": " The paper discusses experiences in several commercial requirements engineering (RE) projects in augmenting an informal, teamwork oriented method with formally based computer support for the analysis and interrelation of heterogeneous perspectives. For several years, the German consulting firm USU had been working with a methodology called PFR (Presence and Future Requirements analysis). PFR is targeted towards the rapid and focused requirements capture in a setting that alternates between team workshops and distributed interviews, in order to avoid the well known problem that requirements change while they are being analyzed. PFR creates a lot of visual, partially overlapping and conflicting requirements perspectives in a very short time. The successful evolution of an RE project depends on the rapid and accurate cross analysis of these viewpoints for possible incompleteness, inconsistency\u00a0\u2026", "num_citations": "17\n", "authors": ["1444"]}
{"title": "Database Application Development as an Object Modeling Activity.\n", "abstract": " The DAIDA project has made an attempt of formally defining and relating declarative and computational entities considered relevant to the process of database application development. Such entities range from objectoriented specifications to executable modules of database programs. To bridge the gap between semantics and computation, they also include abstract machine-based formal specifications and transformational theories. In an second contribution, selected characteristics of such entities and relationships are modeled uniformly in a software information system. Emphasis is placed on those properties that may become relevant when applications have to be modified or adjusted. Besides discussing the interaction of these aspects of the DAIDA methodology, the paper outlines an operational project prototype and reports first experiences.", "num_citations": "17\n", "authors": ["1444"]}
{"title": "Views on the past, present, and future of business and information systems engineering\n", "abstract": " \u201cThe times they are a-changin,\u201d a famous song title by Bob Dylan, also applies to our profession and our subject of study. Information technology has always been a driver for innovation. The recent years, however, have seen IT-based innovations that truly impact everybody\u2019s lives. Everything that can be digitized will be digitized, and this trend is continuing at an amazing speed. For a discipline that looks at the design and utilization of information systems these are exciting times. Yet, it is also a time full of challenges. While our discipline has much to contribute, it competes with other disciplines for topics and ideas. Also, the scope of topics studied has become broader and broader, and so have our methods. While initial work in Business and Information Systems Engineering (BISE) was often rooted in artificial intelligence, database systems, or operations research, the community has adopted new approaches to\u00a0\u2026", "num_citations": "16\n", "authors": ["1444"]}
{"title": "An evolving pattern library for collaborative project documentation\n", "abstract": " Innerhalb verteilter Verbundprojekte erwirbt das beteiligte Personal eine gro\u00dfe Menge an technischem und dom\u00e4nenspezifischem Wissen. Verallgemeinerbare Ergebnisse einzelner Projektpartner die f\u00fcr alle Interessensvertreter von Bedeutung sind, m\u00fcssen innerhalb des Projektes zug\u00e4nglich gemacht werden. Da die beteiligten Parteien zumeist \u00fcber sehr unterschiedliche fachliche Hintergr\u00fcnde verf\u00fcgen, k\u00f6nnen verwendetes Fachvokabular und verschiedene Arten der Ergebnisdokumentation zu ineffizientem Austausch f\u00fchren. Deshalb ist es m\u00fchsam, allgemeines Projektwissen innerhalb dieser Art von Projekten zu kommunizieren und aktuell zu halten. Es ist ebenfalls schwierig, erreichte Ergebnisse f\u00fcr zuk\u00fcnftige Projekte bereitzustellen. Der Ansatz dieser Arbeit besteht darin, Projektergebnisse sowie gesammelte Erkenntnisse \u00fcber die Anwendungsdom\u00e4ne gemeinsam als sich entwickelnde Entwurfsmuster\u00a0\u2026", "num_citations": "16\n", "authors": ["1444"]}
{"title": "Model Driven Development for Internet of Things Application Prototyping.\n", "abstract": " Things prototype development that emphasizes the separation of domain modeling from technological implementations. Using the provided model driven tool, domain experts are able to construct domain models easily by composing virtual objects and linking them to the implementation technologies. Having them linked, a prototype code in Java can be generated by the tool. The generated code allows developers to extend it into full applications simply by interfacing the virtual objects without dealing with the complexity of specific sensors and actuators technologies. Subsequently, participants involved in the European research projects evaluated the architecture and the tool using a software walk-through technique whose results are discussed in this paper.", "num_citations": "16\n", "authors": ["1444"]}
{"title": "Conflict analysis across heterogeneous viewpoints: formalization and visualization\n", "abstract": " Negotiation in cooperative modeling environments requires stakeholders to achieve a shared understanding while maintaining their own interpretation, in order to achieve creative design solutions. Complementing meeting oriented groupware systems which continuously enforce a central group perspective, we present an approach that maintains multiple perspectives and knowledge about their interrelationships and conflicts simultaneously. The approach comprises three aspects: a meta modeling strategy aiming at controlled use of redundancy for conflict analysis; a flexible multi-matrix visualization strategy generalizing the \"House of Quality\" notation of TQM; and an object oriented query class concept by which knowledge about the evolution of negotiation problems is automatically maintained. The approach has been implemented using the meta data manager ConceptBase for modeling and query class\u00a0\u2026", "num_citations": "16\n", "authors": ["1444"]}
{"title": "Knowledge base support for hypermedia co-authoring\n", "abstract": " Hypertext systems can be characterized by the interactions they provide. Systems like Document Examiner [26] and Hyperties [19] are intended to present hypertexts developed by a small group of experts, whereas the user shall only read them. On the other hand, systems like Augment [7], Guide [10], Intermedia [9], KMS [1], Neptune [4], NoteCards [12], and WE [20] provide facilities to edit hypertext documents, i.e. the users themselves are able to create nodes and links. KMS and NoteCards have been extended by components which support groups of users working with the system. However, none of them tries to control the usage of the system by integrating a knowledge base component.", "num_citations": "16\n", "authors": ["1444"]}
{"title": "Near real-time collaborative modeling for view-based Web information systems engineering\n", "abstract": " Conceptual modeling is a creative, social process driven by the views of stakeholders. In modern, agile development \u2013 especially for continuously evolving Web applications \u2013 contributions from a wide variety of geographically distributed stakeholders, their involvement in negotiation and impact analysis from different perspectives and the rapid prototype generation from specifications gain much importance. Moreover, people have come to expect easy near real-time system support with few restrictions. While conceptual modeling or CSCW environments exist for each of these individual aspects, their interplay has barely been studied. This paper presents a collaborative conceptual modeling approach called SyncMeta that aims to close this gap by supporting view-based modeling in the Web browser in a near real-time shared editing environment1. In addition to domain-specific graphical modeling languages\u00a0\u2026", "num_citations": "15\n", "authors": ["1444"]}
{"title": "Flexible IT-platform to synchronize energy demands with volatile markets\n", "abstract": " Based on the goal of exiting nuclear and fossil energies within the electricity generation, the percentage of renewable energies in the energy mix rises. Due to renewable energies\u2019 dependence on natural resources like sun or wind this development leads to a volatile energy supply on the markets. To satisfy their customers\u2019 needs even with a volatile energy supply, especially companies of the manufacturing sector need to consider this development. Production processes need to be developed further to be more energy efficient and to be adaptable in their energy demand to volatile supply. This includes being operable on various power levels or with different kinds of energy such as electricity or gas. Energy-flexible production processes need to be supported by flexible IT solutions. While there are already solutions for demand-side-management on the company side as well as on the market side, there are no\u00a0\u2026", "num_citations": "15\n", "authors": ["1444"]}
{"title": "A longitudinal study of community-oriented open source software development\n", "abstract": " End-users are often argued to be the source of innovation in Open Source Software (OSS). However, most of the existing empirical studies about OSS projects have been restricted to developer sub-communities only. In this paper, we address the question, if and under which conditions the requirements and ideas from end-users indeed influence the development processes in OSS. We present an approach for automated requirements elicitation process discovery in OSS communities. The empirical basis are three large-scale interdisciplinary OSS projects in bioinformatics, focusing on communication in the mailing lists and source code histories over ten years. Our study results in preliminary guidelines for the organization of community-oriented software development.", "num_citations": "15\n", "authors": ["1444"]}
{"title": "Community application editor: collaborative near real-time modeling and composition of microservice-based web applications\n", "abstract": " Research shows a gap in terms of requirements elicitation between developers and endusers. Due to the low technical expertise of some members of online communities, they often cannot collaborate efficiently with developers and cannot provide continuous feedback during application development processes. However, collaborative modeling processes can play an important role in education, enforcing best-practices, support rapid prototyping and lower the communication and collaboration barriers between developers and end-users. This paper presents a tool for collaborative modeling of Web applications in near real-time and their automatic generation. Early evaluation with end-users in simulated community settings show promising results for the interplay of modeling and collaboration in requirements gathering and Web application design and development. We claim that near real-time modeling on the Web has the potential to bring together stakeholders during design and development and offers a new perspective on model-based Web Engineering.", "num_citations": "15\n", "authors": ["1444"]}
{"title": "Gemeinsamkeiten und Unterschiede der Prozess-und Fertigungstechnik\n", "abstract": " In der industriellen Produktion haben sich diskrete Fertigung und Prozesstechnik als weitgehend getrennte Dom\u00e4nen herausgebildet. Immer h\u00e4ufiger erfordern heutzutage jedoch sowohl Entwicklungssystematiken als auch konkrete Produktionsanforderungen die Integration der unterschiedlichen Systeme und Modelle. Als Voraussetzung f\u00fcr eine dom\u00e4nen\u00fcbergreifende, bessere Integration bis hin zur Steuerung hybrider Produktionsanlagen werden in diesem Beitrag physikalische Grundlagen, technische Aufgabenstellungen aber auch entwickelte Modelle und Systeme beider Dom\u00e4nen vergleichend beschrieben und analysiert.", "num_citations": "15\n", "authors": ["1444"]}
{"title": "Metamodelling with Datalog and Classes: ConceptBase at the Age of 21\n", "abstract": " ConceptBase is a deductive object-oriented database system intended for the management of metadata. A distinguishing feature of the Telos language underlying ConceptBase is the ability to manage rules and constraints across multiple levels of instantiation in so-called meta formulas, thus offering uniform consistency management across heterogeneous notations or ontologies. Originally developed in the context of model-driven database design in the late 1980\u2019s, ConceptBase has been used in several thousand installations all over the world for numerous applications in areas such as requirements engineering, engineering information management, model management, eLearning, cultural information systems, and data warehousing. The internal representation is based on a quadruple object structure, combined with advanced Datalog engines, such that many optimization techniques in ConceptBase\u00a0\u2026", "num_citations": "15\n", "authors": ["1444"]}
{"title": "Exploring the semantic structure of technical document collections: A cooperative systems approach\n", "abstract": " Identifying and analyzing the knowledge available in document form is a key element of corporate knowledge management. In engineering-intensive organizations, it involves tasks such as standard generation and evaluation, comparison of related cases and experience reuse in their treatment. In this paper, we present the design, implementation, and some application experiences with a modular approach that allows a variety of techniques from semantic document analysis to interoperate with a tailorable map-centered visualization of the structure of technical document collections.", "num_citations": "15\n", "authors": ["1444"]}
{"title": "Conceptbase v5. 0 user manual\n", "abstract": " ConceptBase is a multi-user deductive object manager mainly intended for conceptual modeling and coordination in design environments. The system implements O-Telos, a dialect of Telos which amalgamates properties of deductive and object-oriented languages. It uniformly represents all information regardless of its abstraction level (data, class, meta class, meta meta class etc.) in a single data structure. The powerful deductive query language is seamlessly integrated into the class hierarchy. Modeling is supported by meta classing, rules and constraints (at any abstration level), active rules, a module concept, and a historical database allowing to query past states of the database. The usage environment offers an extensible palette of graphical, tabular, and textual user interfaces and is based on Java. The communication between the windows and the object base is organized in a client-server architecture\u00a0\u2026", "num_citations": "15\n", "authors": ["1444"]}
{"title": "Workflow support for failure management in federated organizations\n", "abstract": " Failure management for complex products (such as production machinery) exemplifies a class of reactive workflow management tasks for which current WFMS offer few solutions. This class is characterized by great variation of tasks and cooperation patterns, the need to bring rich context knowledge to many different kinds of workplaces, and the need to interlink effective workflow execution with continuous organizational learning. In the German FOQUS project, we have prototyped and evaluated a WFMS architecture which addresses these problems through (a) the encapsulation of problem context in electronic circulation folders; (b) a semantic trading mechanism managing the flow of such folders in a highly flexible manner; (c) a concept for process-integrated workplaces in which the necessary information is made effectively available in the usual working environment of the different kinds of users; (d\u00a0\u2026", "num_citations": "15\n", "authors": ["1444"]}
{"title": "Knowledge-based formulation of linear planning models\n", "abstract": " As decision support systems (DSS) move towards more strategic application domains, there is a growing need for the capability of aiding the decision maker in modelling unanticipated planning problems efficiently without the support of scarce operations research specialists. A major contribution towards the development of model formation subsystems in DSS is expected from the use of Artificial Intelligence (AI) techniques. However, it is claimed in this paper that under current AI technology, model formation subsystems cannot be made fully general and user-friendly at the same time. Instead, a problem-solving approach to model formation is proposed that combines the use of knowledge-based classification techniques as employed in many expert systems, with interactive construction of specialized submodels based on structural knowledge about an operations research technique and domain-specific\u00a0\u2026", "num_citations": "15\n", "authors": ["1444"]}
{"title": "Preparing research projects for sustainable software engineering in society\n", "abstract": " With the pervasive need for digitization in modern information society, publicly funded research projects increasingly focus on engineering digital approaches to manage societal processes. Such projects inherently face the challenge of establishing a sustainable software engineering culture. A major challenge thereby is that project consortia need to establish a distributed developer community that effectively and resource-efficiently aligns development efforts with the goals and needs of complex societal constellations beyond project lifetime. In this paper we extract empirical evidence from longitudinal studies in two large-scale research projects to outline typical challenges in such problem contexts and to develop an open source software engineering methodology for research projects, including supportive infrastructure and social instruments of community building and awareness. We thus contribute a\u00a0\u2026", "num_citations": "14\n", "authors": ["1444"]}
{"title": "On warehouses, lakes, and spaces: the changing role of conceptual modeling for data integration\n", "abstract": " The role of conceptual models, their formalization and implementation as knowledge bases, and the related metadata and metamodel management, has continuously evolved since their inception in the late 1970s. In this paper, we trace this evolution from traditional database design, to data warehouse integration, to the recent data lake architectures. Concerning future developments, we argue that much of the research has perhaps focused too much on the design perspective of individual companies or strongly managed centralistic company networks, culminating in today\u2019s huge oligopolistic web players, and propose a vision of interacting data spaces which seems to offer more sovereignty of small and medium enterprises over their own data.", "num_citations": "14\n", "authors": ["1444"]}
{"title": "IS success awareness in community-oriented design science research\n", "abstract": " Design efforts on innovative IS artifacts are increasingly taking place in agile, small, and specialized long-tail communities supported by academic research. Long-tail communities need to reflect and develop awareness for the success of community-specific IS (CIS) artifacts in their particular practice context in an ongoing manner. In community-oriented DSR, researchers participate as active community members contributing CIS success awareness with the help of CIS success models resulting from ongoing CIS evaluation. However, CIS success awareness is challenging to achieve compared to organizational IS due to diversity, dynamicity, informal structures and permeable boundaries. In this paper, we emphasize the benefits of ongoing CIS success awareness with the help of custom-tailored CIS success models in community-oriented DSR contexts. We demonstrate our approach in a longitudinal case\u00a0\u2026", "num_citations": "14\n", "authors": ["1444"]}
{"title": "Data-centric intelligent information integration\u2014from concepts to automation\n", "abstract": " Intelligent integration of information continues to challenge database research for over 35\u00a0years. While data integration processes of all kinds are now reasonably well understood and widely used in practice, the growth and heterogeneity of data requires much higher degrees of automation to limit the need for human specialist work. This requires deeper insights in data-centric approaches of Enterprise Information Integration which focus on the semantics of information integration. Recent formalizations and algorithms enable both significant improvement in schema integration, and in its automated transformation to efficient data-level integration, in a wide variety of architectural settings such as data warehouses or peer-to-peer databases. In addition to giving a short overview of developments in this field for the past 20\u00a0years, this paper focuses particularly on the challenges posed by heterogeneity in data\u00a0\u2026", "num_citations": "14\n", "authors": ["1444"]}
{"title": "Well-balanced usability & annotation complexity in interactive video semantization\n", "abstract": " In the recent years more and more people have begun to edit video files, as technologies are becoming more sophisticated and affordable. Web 2.0 has raised tagging functionality to a growing number of websites such as Flickr and YouTube. However, these services only provide basic video annotation support. In comparison to those well-known services there are many research efforts towards video semantization tools. These tools provide highly precise annotation functionality based on metadata standards such as MPEG-7, but tend to exhibit very complex user interfaces. In this paper we present the design, implementation and evaluation of SeViAnno, an MPEG-7 based interactive semantic video annotation Web platform with the main objective to find a well-balanced trade-off between a simple user interface and video semantization complexity.", "num_citations": "14\n", "authors": ["1444"]}
{"title": "Evolution in domain model-based requirements engineering for control systems development\n", "abstract": " When developing software-based control systems, knowledge and experiences in the relevant domain are of great importance. Small- and medium-sized enterprises (SMEs) that are most active here need to capture requirements under severe time and costs pressures. In previous work we have shown that a domain model based on the requirements formalism i* accelerates the requirements capture. Furthermore, the domain model-based similarity search supports the detection of reusable components from earlier projects. But due to the innovativeness, flexibility, and customer-orientation of control systems development, this domain model is subject to continuous change. Within this paper, we investigate the effects of model evolution on our domain model-based requirements engineering approach. Building on examples from industrial practice, we develop a classification of possible domain model modifications\u00a0\u2026", "num_citations": "14\n", "authors": ["1444"]}
{"title": "Aphasic communities of learning on the web\n", "abstract": " This article presents the case study of a cooperative Web-learning environment\u2014SOCRATES\u2014to foster barrier-free learning on the Web. While the growth of the Internet was exponential in the last years, still many communities don\u2019t benefit from Web-learning technology due to improper tools and constricted communication processes. These problems increase when developing applications for communities of people with special needs. SOCRATES supports a community of learning comprising patients suffering from aphasia (aphasics), therapists, researchers on linguistics, and system developers. Aphasics can improve their conversation skills with a specially designed talk/chat tool, while therapists and linguistic researchers can monitor conversations from automatically generated transcripts. Aphasics in remote areas using SOCRATES are now able to communicate freely among each other without being afraid\u00a0\u2026", "num_citations": "14\n", "authors": ["1444"]}
{"title": "SOCRATES: Barrier free communities of aphasics on the internet\n", "abstract": " The barrier free internet is one of the greatest challenges for computer science in the future. While in the last years the growth of the internet was exponential, still many potential user communities can not use internet technology for their communication needs because of inappropriate tools and narrowly designed communication processes. These problems become obvious when transferring applications to communities of people with special needs. Many people suffering from aphasia are not able to interact with current chat tools while need for money for therapists could be eased by such virtual self-help groups in a geographically distributed setting. This is because massive word finding problems can sum up typing a simple sentence up to several minutes. We have designed, implemented and preliminary evaluated a new chat tool for such groups. By using the tool aphasics can constantly monitor their\u00a0\u2026", "num_citations": "14\n", "authors": ["1444"]}
{"title": "Regionale Kooperationskompetenz: Probleme und Modellierungstechniken\n", "abstract": " Unternehmen, Politik und Verwaltung in einer innovativen Region. Theoretische Erkla\u00c8rungsversuche fu\u00c8r neuere, elektronisch zu unterstu\u00c8tzende Netzwerke sind noch rar und fokussieren, wo vorhanden, eher auf die Verteidigung strategischer Positionen, wie etwa im Frankfurter SFB,, Vernetzung als Wettbewerbsfaktor``[BuKW97]. Wie im folgenden gezeigt, lassen sich jedoch aus Untersuchungen zu allgemeinen Kooperationsnetzen unschwer Begru\u00c8ndungen ableiten, warum Regionalita\u00c8t auch bei globaler Vernetzung wichtig bleibt. Aus organisationssoziologischer Sicht spielt die Regionalita\u00c8t insbesondere fu\u00c8r den Aufbau des fu\u00c8r die Kooperation essentiellen Vertrauens zu den Kooperationspartnern eine gro\u00fbe Rolle. Vertrauensfo\u00c8rdernd wirken nach [SiSi99] insbesondere u\u00c8ber la\u00c8ngere Zeit hinweg aufgebaute perso\u00c8nliche Beziehungen sowie eine gemeinsame,, Bank der Gefa\u00c8lligkeiten``(favour\u00a0\u2026", "num_citations": "14\n", "authors": ["1444"]}
{"title": "Knowledge representation and reasoning in software engineering\n", "abstract": " It has been widely recognized that in order to solve difficult problems using computers one will usually have to use a great deal of knowledge (often domain specific), rather than a few general principles. The intent of this special issue was to study how this attitude has affected research on tools for improved software productivity and quality. Many such tools and problems related to them were discussed at a Workshop on the Development of Intelligent and Cooperative Information Systems, held in Niagara-on-the-Lake in April 1991, from which the idea for this issue originated.", "num_citations": "14\n", "authors": ["1444"]}
{"title": "Community and trust-aware fake media detection\n", "abstract": " Nowadays, it becomes increasingly difficult to find reliable multimedia content in the Web 2.0. Open decentralized networks (on the Web) are populated with lots of unauthenticated agents providing fake multimedia. Conventional automatic detection and authentication approaches lack scalability and the ability to capture media semantics by means of forgery. Using them in online scenarios is computationally expensive. Thus, our aim was to develop a trust-aware community approach to facilitate fake media detection. In this paper, we present our approach and highlight four important outcomes. First, a Media Quality Profile (MQP) is proposed for multimedia evaluation and semantic classification with one substantial part on estimating media authenticity based on trust-aware community ratings. Second, we employ the concept of serious gaming in our collaborative fake media detection approach overcoming\u00a0\u2026", "num_citations": "13\n", "authors": ["1444"]}
{"title": "Mobile multimedia management for Virtual Campfire-the german excellence research cluster UMIC\n", "abstract": " Frequent usage of mobile devices such as cell phones, smart phones, PDAs, or GPS navigators creates a large amount of multimedia data. Ultra High-Speed Mobile Information and Communication (UMIC) is one of the research clusters established under the excellence initiative of the German government. Within UMIC, research is being carried out on next generation mobile applications. Based on experiences of developing a set of advanced mobile applications for communities of practice within the scenario Virtual Campfire, the framework for mobile multimedia management is concerned with mobile multimedia semantics, with multimedia metadata, with multimedia context management, with ontology models, and with multimedia uncertainty management. Results are evaluated on a mobile multimedia community testbed MobSOS. We aim at creation, annotation, adaptation, sharing, and consumption of mobile\u00a0\u2026", "num_citations": "13\n", "authors": ["1444"]}
{"title": "ACIS: Intergenerational community learning supported by a hypermedia Afghan sites and monuments database\n", "abstract": " Intergenerational learning is based on processing experiences from one generation to another. However, this process is up to now mostly based on face to face communication neglecting the capabilities of computer supported learning communities. In this paper we describe ACIS (Afghan Community IS), a system that has been designed to support intergenerational learning communities by geographical hypermedia information systems in the area of cultural heritage. ACIS is designed to bring together generations of scientists in cultural heritage management which has been disrupted by the civil war and the Taliban regime in Afghanistan. ACIS has been deployed for a project in the conservation of cultural heritage in Afghanistan to prove the validity of the concepts.", "num_citations": "13\n", "authors": ["1444"]}
{"title": "A model for data warehouse operational processes\n", "abstract": " Previous research has provided metadata models that enable the capturing of the static components of a Data Warehouse (DW) architecture, along with information on different quality factors over these components. This paper complements this work with the modeling of the dynamic parts of the DW, i.e., with a metamodel for DW operational processes. The proposed metamodel is capable of modeling complex activities, their interrelationships, and the relationship of activities with data sources and execution details. Finally, the metamodel complements proposed architecture and quality models in a coherent fashion, resulting in a full framework for DW metamodeling, capable of supporting the design, administration and evolution of a DW. We have implemented this metamodel using the language Telos and the metadata repository system ConceptBase.", "num_citations": "13\n", "authors": ["1444"]}
{"title": "Application experience with a repository system for information systems development\n", "abstract": " The purpose of a computerized information system is to improve dataintensive business processes in an organization. The development of such systems itself is data-intensive. Tools have been developed to support the development process, among others repository systems which serve as the common database used by the development team. This paper reports on application experience with the ConceptBase system which we developed over the last 12 years. Eight applications are presented in more detail to show which properties the users demanded and how different applications used the base functionalities of the system in a different way. In summary, extensibility, performance, and advanced query facilities turned out to be most important.", "num_citations": "13\n", "authors": ["1444"]}
{"title": "Tools for data warehouse quality\n", "abstract": " We show three interrelated tools intended to improve different aspects of the quality of data warehouse solutions. Firstly, the deductive object manager ConceptBase is intended to enrich the semantics of data warehouse solutions by including an explicit enterprise-centered concept of quality. The positive impact of precise multidimensional data models on the client interface is demonstrated by CoDecide, an Internet-based toolkit for the flexible visualization of multiple, interrelated data cubes. Finally, MIDAS is a hybrid data mining system which analyses multi-dimensional data to further enrich the semantics of the meta database, using a combination of neural network techniques, fuzzy logic and machine learning.", "num_citations": "13\n", "authors": ["1444"]}
{"title": "Foundations of data warehouse quality\n", "abstract": " DWQ is a cooperative project in the ESPRIT program of the European Communities. It aims at establishing foundations of data warehouse quality through linking semantic models of data warehouse architecture to explicit models of data quality. This paper provides an overview of the project goals and offers an architectural framework in which the individual research contributions are embedded.", "num_citations": "13\n", "authors": ["1444"]}
{"title": "Simulating the impact of information flows in networked organizations\n", "abstract": " Information and communication technology are crucial enablers of networked organizations, but effective Cooperative Information Systems remain difficult to design because there are no tools to assess their short-term operational effectiveness and long-term impact on organizational knowledge. We present three contributions toward a solution of these problems: 1) we identify information flow categories as a crucial conceptual abstraction;(2) we show how successful simulation models for long-term analysis of team performance can be extended to include the crucial problems of cross-unit information management and exception handling;(3) we exploit recent results on multi-simulation to enable an integration of these long-term models with queuing-type simulation models usually applied in operational business process analysis. The approach has been implemented in an interactive analysis environment called MultiSim, and has been tested in a case study in the production industry.", "num_citations": "13\n", "authors": ["1444"]}
{"title": "A global KBMS for database software evolution-documentation of first ConceptBase prototype\n", "abstract": " A global KBMS for database software evolution - documentation of first ConceptBase prototype \u2014 Tilburg University Research Portal Skip to main navigation Skip to search Skip to main content Tilburg University Research Portal Logo Contact, Help & FAQ Home Profiles Research output Research Units Activities Projects Press / Media Prizes / Recognition Search by expertise, name or affiliation A global KBMS for database software evolution - documentation of first ConceptBase prototype M. Jarke, MA Jeusfeld, T. Rose Research output: Book/Report \u203a Report Overview Original language English Place of Publication Passau Publisher University of Passau Publication status Published - 1988 Externally published Yes Publication series Name No. Technical Report MIP-8819 Cite this APA Author BIBTEX Harvard Standard RIS Vancouver Jarke, M., Jeusfeld, MA, & Rose, T. (1988). A global KBMS for database software \u2026", "num_citations": "13\n", "authors": ["1444"]}
{"title": "Verhandlungskonzepte f\u00fcr die rechnergest\u00fctzte Teamarbeit\n", "abstract": " Nach einer \u00dcbersicht \u00fcber unterschiedliche Formen der technischen und konzeptionellen Unterst\u00fctzung von Gruppenarbeit durch Informationssysteme werden am Beispiel von Verhandlungskonzepten f\u00fcr Teams weitergehende gruppenorientierte Probleml\u00f6sungsmodelle aus der K\u00fcnstlichen Intelligenz (Kontraktnetze, Argumentationsmodelle, Kooperationsformen rationaler Agenten) auf ihre Eignung f\u00fcr die Teamunterst\u00fctzung untersucht. Anschlie\u00dfend wird ein objektorientierter Integrationsversuch von Verhandlungskonzepten f\u00fcr die rechnergest\u00fctzte Teamarbeit skizziert, mit dem diese bislang getrennt behandelten Konstrukte zu einer koh\u00e4renten Methodik zusammengefa\u00dft werden sollen.", "num_citations": "13\n", "authors": ["1444"]}
{"title": "Managers, Micros and Mainframes: Integrating Systems for End Users\n", "abstract": " Brings together a range of expertise for taking advantage of the opportunities from growing end-user computing in the micro-mainframe environment. Presents the state of the art in end-user computing technology and reports on empirical studies of its diffusion and management. Offers strategies for controlling individual end-user computer systems. Proposes integrated computer/communications infrastructures as central business strategies that have an impact on the whole organization and its position in the market. An excellent reference work, textbook, or starting point for research in end-user computing and its management.", "num_citations": "13\n", "authors": ["1444"]}
{"title": "Database access requirements of knowledge-based systems\n", "abstract": " Knowledge bases constitute the core of those Artificial Intelligence programs which have come to be known as Expert Systems. An examination of the most dominant knowledge representation schemes used in these systems reveals that a knwledge base can, and possibly should, be described at several levels using different schemes, including those traditionally used in operational databases. This chapter provides evidence that solutions to the organization and access problem for very large knowledge bases require the employment of appropriate database management methods, at least for the lowest level of description \u2014 the facts or data. We identify the database access requirements of knowledge-based or expert systems and then present four general architectural strategies for the design of expert systems that interact with databases, together with specific recommendations for their suitability in\u00a0\u2026", "num_citations": "13\n", "authors": ["1444"]}
{"title": "Data Base Approach for Multicriteria Decision Support Systems (MCDSS)\n", "abstract": " Traditional intuitive methods of decision making are no longer adequate to deal with the complex problems faced by the modern decision maker. The difficulty in addressing these problems is complicated by the interrelations, immediacy and far-reaching implications of actions taken (Donovan 1976). Decision support systems have been developed to provide the information and analysis necessary for the decisions. Personal computers, computer networks, data bases, colour graphics and computer-based models are among the technological developments which are stimulating interest in the use of computers to support decision making (Sprague and Carlson 1982). The characteristics of the problems associated with decision support are different from those to which data base systems and other computational technologies have normally been applied in the past.", "num_citations": "13\n", "authors": ["1444"]}
{"title": "Data sovereignty and data space ecosystems\n", "abstract": " Data analytics/artificial intelligence and business process automation require an ever-increasing wealth of data. To remain competitive, organizations cannot just use internal and publicly available data sources, but need information also from external individuals and organizations. As, eg, supply chains evolve into highly flexible supply and demand networks, much of the required data exchange cannot be prepared any longer by lengthy human negotiations but must be semi-automatically negotiated, executed and monitored for contractual and legal compliance. Furthermore, on top of exchanging data within a business network, an increasing number of innovative business services requires data sharing, ie, the joint use of data from different sources within the network. An example is collaborative predictive maintenance which is based on the analysis of and learning from production process data from several\u00a0\u2026", "num_citations": "12\n", "authors": ["1444"]}
{"title": "Flexible IT platform for synchronizing energy demands with volatile markets\n", "abstract": " Abandoning fossil and nuclear energy sources in the long run and increasing amount of renewable energies in electricity production causes a more volatile power supply. Depending on external realities, renewable energy production emphasizes the need for measures to guarantee the necessary balance of demand and supply in the electricity system at all times. Energy intensive industry processes theoretically include high Demand Response potentials suitable to tackle this increasing supply volatility. Nevertheless, most companies do not operate their production in a flexible manner due to multiple reasons: among others, the companies lack know-how, technologies and a clear business case to introduce an additional level of flexibility into their production processes, they are concerned about possible impacts on their processes by varying the electricity demand and need assistance in exploiting their flexibility\u00a0\u2026", "num_citations": "12\n", "authors": ["1444"]}
{"title": "Engineering web applications using real-time collaborative modeling\n", "abstract": " In agile practices, near real-time collaboration on the Web facilitates stakeholder activities, their communication and joint impact analysis. In providing an abstraction layer on the software development process, modeling enables participatory design and improves requirements negotiation by close involvement of end users. However, model-driven engineering is mostly used in classical software development to achieve standardization and mature processes. Little research in Model-Driven Web Engineering focuses on leveraging near real-time collaboration and collaborative modeling in order to support agile Web engineering processes. This paper proposes a new approach for Web-based collaborative near real-time modeling and generation of Web applications by tying together frontend components and microservices as key elements. This leads to well-defined service interfaces that facilitate inter\u00a0\u2026", "num_citations": "12\n", "authors": ["1444"]}
{"title": "Near real-time collaborative conceptual modeling on the web\n", "abstract": " Collaboration during the creation of conceptual models is an integral pillar of design processes in many disciplines. Synchronous collaboration, in particular, has received little attention in the conceptual modeling literature so far. There are many modeling and meta-modeling tools available, however most of these do not support synchronous collaboration, are offered under restrictive licenses, or build on proprietary libraries and technologies. To close this gap, this paper introduces the lightweight meta-modeling framework SyncMeta, which supports near real-time collaborative modeling, meta-modeling and generation of model editors in the Web browser. It employs well-proven Operational Transformation algorithms in a peer-to-peer architecture to resolve conflicts occurring during concurrent user edits. SyncMeta was successfully used to create meta-models of various conceptual modeling languages\u00a0\u2026", "num_citations": "12\n", "authors": ["1444"]}
{"title": "Reflective community information systems\n", "abstract": " The Internet has not only enabled worldwide access to heterogeneous information sources such as web pages or traditional database contents, but also increasingly serves as a medium for multimedia information and opinion exchange. Community Information Systems address the combination of these two trends of heterogeneous worldwide information access and cooperative discussion and work. This combination creates a lot of new opportunities e.g. in the educational and cultural sector, but entails also serious risks and socio-political problems. New technical solutions are required for problems such as share definition of IS structure in such communities, high variability and strong guidance in user interfaces, security and trust management. In particular, this requires a schema organization that can adapt itself gradually, yet in a controlled manner, i.e. has the property of being reflexive. This paper gives\u00a0\u2026", "num_citations": "12\n", "authors": ["1444"]}
{"title": "Identification and reuse of experience knowledge in continuous production processes\n", "abstract": " Extrusion of rubber profiles is a time- and resource-intensive process. The experience of individuals supervising the production is difficult to gather and to convey to others. The aim of the MErKoFer project is to gather accumulated knowledge on the production process and established procedures, which are employed in handling occurring malfunctions and ensuring specified quality standards, and to give advisory feedback based on this knowledge. This approach is based on case-based reasoning, an ontological representation of domain-specific information and dependencies, associations and rules identified by data mining techniques, and neural networks. Solutions of similar situations are provided to the machine operators as hints from the knowledge base to support their decisions and improve their autonomy and the quality of their actions.", "num_citations": "12\n", "authors": ["1444"]}
{"title": "2 Designing Standards for Open Simulation Environments in the Chemical Industries: A Computer\u2010Supported Use\u2010Case Approach\n", "abstract": " Under the double pressures of global competition and increasing environmental awareness, the importance of high\u2010performance simulation tools in the process industries (food, chemicals, oil, \u2026) is rapidly growing. However, traditional simulation environments are closed monolithic systems which are extensible only by a small group of market\u2010leading vendors. The resulting bottlenecks in interoperability, reuse and innovationled to the CAPE\u2010OPEN project, in which the chemical and oil industries are defining standards for a component\u2010based approach to process simulation, in order to open up the market to smaller vendors and to facilitate rapid industrial uptake of academic research prototypes. For general systems engineering, the CAPE\u2010OPEN standardising process has at least two interesting features: (a) it has experimented on a large scale with a distributed use case approach, following a variant of the UML\u00a0\u2026", "num_citations": "12\n", "authors": ["1444"]}
{"title": "Micro-mainframe DSS for remote multi-person decisions\n", "abstract": " Micro-mainframe DSS for remote multi-person decisions | Managers, micros and mainframes: integrating systems for end-users ACM Digital Library home ACM home Google, Inc. (search) Advanced Search Browse About Sign in Register Advanced Search Journals Magazines Proceedings Books SIGs Conferences People More Search ACM Digital Library SearchSearch Advanced Search Browse Browse Digital Library Collections More HomeBrowse by TitleBooksManagers, micros and mainframes: integrating systems for end-usersMicro-mainframe DSS for remote multi-person decisions chapter Micro-mainframe DSS for remote multi-person decisions Share on Authors: Matthias Jarke View Profile , X. Tung Bui View Profile , Tawfik Jelassi View Profile Authors Info & Affiliations Publication: Managers, micros and mainframes: integrating systems for end-usersAugust 1986 Pages 205\u2013218 0citation 0 Downloads \u2026", "num_citations": "12\n", "authors": ["1444"]}
{"title": "Digital shadows in the internet of production\n", "abstract": " Due to highly sophisticated, specialised models and data in production, digital twins, as defined as full digital representations, are neither computationally feasible nor useful. The complementary concept of digital shadows will provide cross-domain data access in real time by combining reduced engineering models and production data analytics.", "num_citations": "11\n", "authors": ["1444"]}
{"title": "Data spaces: combining goal-driven and data-driven approaches in community decision and negotiation support\n", "abstract": " In the last decade, social network analytics and related data analysis methodologies have helped big players gain enormous influence on the web, largely due to clever centralistic data collection in major data lakes. In the form of recommender systems, this can also be seen as world-scale group decision support. In our research, we have been more interested in how these kinds of technologies can spill over to smaller-scale communities of interest in the long tail of the internet. Examples include learning communities and open source software development communities of individuals, but also questions of controlled data and knowledge sharing among small and medium enterprises or medical institutions. Especially in the latter cases, we often face strongly conflicting goals that need to be negotiated to mutually acceptable solutions, quite along the original GDSS and NSS visions of Mel Shakun and\u00a0\u2026", "num_citations": "11\n", "authors": ["1444"]}
{"title": "Digital transformation within the emobility market\u2013Learnings and insights from early market development\n", "abstract": " This paper presents a generic classification of digital artifact integration in electric vehicle supply equipment (EVSE) and resulting possibilities for emobility service provider (EMSP) to develop business models. Additionally, the results strongly support the assumption that EMSP value creation, capturing and business model sustainability are highly reliant on the grade of digitalization within the business model. The paper provides background and deeper insights into digitization and digitalization in the field of emobility. Furthermore, it shows the applicability of the \u201cLayered Modular Architecture\u201d (LMA) in business modeling as an instrument for the identification of digital technology enhanced value propositions. Finally, LMA and Service-oriented Architecture (SOA)-concept are proposed to enhance business modeling in digitally transforming ecosystems.", "num_citations": "11\n", "authors": ["1444"]}
{"title": "Virtual Campfire-Cultural Heritage Management and Presentation on Mobile Devices based on Interoperable Cross-Platform MPEG-7 Multimedia Web Services\n", "abstract": " Smart devices, application mobility, portability, service reliability and data interoperability raise much attention of the international cultural heritage community recently. Web 2.0 and social software turn users into prosumers which results in a great amount of multimedia content and metadata for the community on the one hand. On the other hand, it asks for new concepts to develop better mobile applications for cultural heritage data management. We designed and realized a cross media and cross community framework called Virtual Campfire within the German excellence research cluster UMIC (Ultra High Speed Mobile Information and Communication). It consists of a set of services providing diverse mobile communities MPEG-7 based multimedia content processing services to use heterogeneous data sources. The services include real-time multimedia creation and processing, collaborative semantic enrichment of multimedia content and collaborative storytelling on different mobile devices. Based on such a service oriented architecture Virtual Campfire enables the flexible realization of community information systems with diverse and complex multimedia content such as videos, images and 3D data. The Virtual Campfire prototype realized on the iPhone and Nokia smart phones is able to support documentation activities on-site in cultural heritage fieldwork.", "num_citations": "11\n", "authors": ["1444"]}
{"title": "Vernetztes Verbesserungsmanagement\n", "abstract": " Voraussetzung f\u00fcr die Innovationsf\u00e4higkeit eines Unternehmens ist die Lernf\u00e4higkeit in einer dynamischen Umwelt. Innovationen in Unternehmen der Fertigungsindustrie umfassen sowohl die Produktgestaltung als auch die Neugestaltung von Prozessen der Fertigung und des Service. Die organisationstheoretische Forschung hat hierf\u00fcr eine Reihe von Konzepten entwickelt. Sie werden im folgenden kurz vorgestellt und anschlie\u00fbend auf die VVM-Strategie angepasst.", "num_citations": "11\n", "authors": ["1444"]}
{"title": "Query classes\n", "abstract": " Deductive object-oriented databases advocate the advantage of combining object-oriented and deductive paradigms into a single data model. Certainly, the query language in such a data model has to reflect the amalgamation because it works as the interface to the user and/or application program. This paper proposes a language to formulate queries as classes related to the schema classes and constrained by an associative membership condition. Answers are then regarded as their instances. The interpretation is based on a deductive database view of queries. Generic query classes are introduced with a simple parameter substitution construct. The syntactic separation of structural and associative conditions opens the way to semantic query optimization: subsumption between the structural parts of queries can be decided efficiently.", "num_citations": "11\n", "authors": ["1444"]}
{"title": "Rule representation and management in ConceptBase\n", "abstract": " ConceptBase is an experimental knowledge base management system for design applications, especially in the software engineering area. The knowledge representation language it supports, CML/Telos, combines the functionalities of deductive and temporal databases with structural object orientation. In this paper, we demonstrate how to exploit a process-oriented software data model that uses just the object-oriented structural language kernel, to bootstrap efficient internal representations of the rule sub-language.", "num_citations": "11\n", "authors": ["1444"]}
{"title": "A retrospective on Telos as a metamodeling language for requirements engineering\n", "abstract": " Telos is a conceptual modeling language intended to capture software knowledge, such as software system requirements, domain knowledge, architectures, design decisions and more. To accomplish this, Telos was designed to be extensible in the sense that the concepts used to capture software knowledge can be defined in the language itself, instead of being built-in. This extensibility is accomplished through powerful metamodeling features, which proved very useful for interrelating heterogeneous models from requirements, model-driven software engineering, data integration, cultural informatics and eLearning. We trace the evolution of ideas and research results in the Telos project from its origins in the late eighties. Our account looks at the semantics of Telos, its various implementations and its applications. We also recount related research by other groups and the cross-influences of ideas thereof. We conclude with lessons learnt.", "num_citations": "10\n", "authors": ["1444"]}
{"title": "Service-oriented Business Model Framework-A Service-dominant Logic based Approach for Business Modeling in the Digital Era\n", "abstract": " The business model (BM) concept has been described as an intermediating tool for managing the transition from technology\u2019s potential value into market outcomes. Unfortunately, current business modeling methodologies do not meet specific needs of modeling value (co-) creation in digitally transforming ecosystems (DTE). Based on desktop research and empirical findings this paper proposes a Service-oriented Business Modeling (SoBM) framework to advance the development of market solutions in these environments. Adopting a service-dominant logic\u2019s (SD logic) perspective a service-centric, network-oriented, and transcending solution proposal is presented. It has been designed to identify and leverage digital technology\u2019s potential value and to improve the conceptualization of value creation and capturing in a digitally connected physical world.", "num_citations": "10\n", "authors": ["1444"]}
{"title": "An interactive system for visual analytics of dynamic topic models\n", "abstract": " The vast amount and rapid growth of data on the Web and in document repositories make knowledge extraction and trend analysis a challenging task. A well-proven approach for the unsupervised analysis of large text corpora is dynamic topic modeling. While there is a solid body of research on fundamentals and applications of this technique, visual-interactive analysis systems for allowing end-users to perform analysis tasks using topic models are still rare. In this paper, we present D-VITA, an interactive text analysis system that exploits dynamic topic modeling to detect the latent topic structure and dynamics in a collection of documents. D-VITA supports end-users in understanding and exploiting the topic modeling results by providing interactive visualizations of the topic evolution in document collections and by browsing documents based on keyword search and similarity of their topic distributions. The\u00a0\u2026", "num_citations": "10\n", "authors": ["1444"]}
{"title": "High impact requirements engineering\n", "abstract": " Beeindruckende Erfolge in den beiden letzten Jahrzehnten t\u00e4uschen nicht dar\u00fcber hinweg, dass die Forschung im Requirements Engineering (RE) einer erneuten Abstimmung mit der Praxis bedarf. Der Kontext f\u00fcr RE enth\u00e4lt heute Elemente, die bei der Entwicklung der etablierten Methoden vor 20 bis 30 Jahren noch nicht pr\u00e4sent waren. Erstens haben sich die wirtschaftlichen Grundlagen ver\u00e4ndert. Der Kostendruck verlangt genauere ROI-Analysen, w\u00e4hrend sich gleichzeitig deren Zeithorizonte durch massive Wiederverwendung auf 18 bis 20 Monate verk\u00fcrzt haben. Zweitens gibt es kaum noch Neuentwicklungen auf der gr\u00fcnen Wiese; der Analytiker \u00e4hnelt immer mehr dem doppelgesichtigen r\u00f6mischen Gott Janus, der zum einen neue gesch\u00e4ftliche und technische Herausforderungen annimmt, zum anderen aber auch das Erbe der existierenden Technik, Organisation und sozio-politischen Situation\u00a0\u2026", "num_citations": "10\n", "authors": ["1444"]}
{"title": "Netlearn: social network analysis and visualizations for learning\n", "abstract": " The most valuable and innovative knowledge is hard to find, and it lies within distributed communities and networks. Locating the right community or person who can provide us with exactly the knowledge that we need and who can help us solve exactly the problems that we come upon, can be an efficient way to learn forward. In this paper, we present the details of NetLearn; a service that acts as a knowledge filter for learning. The primary aim of NetLearn is to leverage social network analysis and visualization techniques to help learners mine communities and locate experts that can populate their personal learning environments.", "num_citations": "10\n", "authors": ["1444"]}
{"title": "A Web 2.0 personal learning environment for classical Chinese poetry\n", "abstract": " Classical Chinese Poetry (CCP) is a valuable but almost locked treasure chest of human wisdom and civilization since 2000 years. With the advent of the Web 2.0 a renaissance of CCP is possible even outside Chinese-speaking communities world-wide. With mobile technologies and educational games we can address new learning communities for CCP and open the chest again. In this paper, we introduce a Web 2.0 personal learning environment for CCP. We have developed a generic and interoperable data model for CCP we utilize not only for mobile learning scenarios but also for educational gaming with different levels of difficulty. Learners are empowered to learn Chinese poetry, language, history, and culture. This research work shows how modern information technologies assist users to diffuse knowledge across the borderlines of communities and societies.", "num_citations": "10\n", "authors": ["1444"]}
{"title": "Mapping requirement models to mathematical models in control system development\n", "abstract": " When developing control systems software, mathematically based modelling tools such as Matlab/Simulink are used for design, simulation, and implementation. Thus, a continuous model-based approach does not need to map requirements to, for example, UML class diagrams but to this mathematical representation. In this paper, we build on previous work that has applied the requirements formalism i* to the development of control systems software and present a mapping from i* models to Matlab/Simulink models. During a first manual transformation step, design alternatives are resolved. The second, automated step generates a Matlab/Simulink skeleton model from the i* model. Finally, an interactive step allows incorporating existing hardware and platform components into the skeleton. As a running example, we consider the development of a parking assistant.", "num_citations": "10\n", "authors": ["1444"]}
{"title": "Heterogeneity in model management: A meta modeling approach\n", "abstract": " As models are always abstractions of reality, we often need multiple modeling perspectives for analysis. The interplay of such modeling perspectives can take many forms and plays a role both at the design level, and during the operation of information systems. Examples include viewpoint resolution in requirements management, mapping between conceptual and implementation design in databases, and the integration or interoperation of multiple data and media sources. Starting from early experiences with our now 20-year old ConceptBase implementation of the Telos language, we describe a logic-based conceptual modeling and model management approach to these issues, focusing on recent work which employs a generic meta model to facilitate mappings and transformations between heterogeneous model representations both at the schema and the data level.", "num_citations": "10\n", "authors": ["1444"]}
{"title": "Using developers\u2019 experience in cooperative design processes\n", "abstract": " The process industries are characterized by continuous or batch processes of material transformation with the aim of converting raw materials or chemicals into more useful and valuable forms. The design of such processes is a complex process itself that determines the competitiveness of these industries, as well as their environmental impact. Especially the early phases of such design processes, the so-called conceptual design and basic engineering, reveal an inherent creative character that is less visible in other engineering domains, such as in mechanical engineering. This special character constitutes a key problem largely impacting final product quality and cost.               As a remedy to this problem, in cooperation with researchers and industrial partners from chemical and plastics engineering, we have developed an approach to capture and reuse experiences captured during the design process\u00a0\u2026", "num_citations": "10\n", "authors": ["1444"]}
{"title": "Modellbasierte Anforderungserfassung f\u00fcr softwarebasierte Regelungen\n", "abstract": " Regelungstechnik und Softwaretechnik haben sich \u00fcber lange Zeit getrennt voneinander entwickelt. Aber immer h\u00e4ufiger werden heute Reglerfunktionen, etwa im Fahrzeug, in Software realisiert. Im Projekt ZAMOMO wird versucht, die immer noch getrennten Entwicklungsprozesse besser miteinander zu verzahnen. In diesem Beitrag wird dazu ein zielorientiertes Rahmenwerk zur Erfassung von Anforderungen aus der Softwaretechnik, i*, auf seine Eignung fu \u0308r die Erfassung regelungstechnischer Probleme untersucht. Des Weiteren werden resultierende Herausforderungen f\u00fcr die Werkzeugunterst\u00fctzung diskutiert. Insgesamt erm\u00f6glicht der Ansatz, die bereits weitreichend modellbasierte Reglerentwicklung auch in der Anforderungserfassung mo- dellbasiert zu unterst\u00fctzen und zugleich den Weg f\u00fcr eine gemeinsame Betrachtung regelungstechnischer und softwaretechnischer Anforderungen zu ebnen.", "num_citations": "10\n", "authors": ["1444"]}
{"title": "Gr\u00fcnderausbildung und Gr\u00fcndernetze im Umfeld technischer Hochschulen: ein wirtschaftsinformatischer Versuch\n", "abstract": " Vor allem innovative und wissensintensive Unternehmensgr\u00fcndungen haben aufgrund ihres Beitrages zum wirtschaftlichen Strukturwandel und ihrer potentiellen Besch\u00e4ftigungsdynamik das Image, f\u00f6rderlich f\u00fcr die positive \u00f6konomische Entwicklung von Regionen zu sein. In diesem Zusammenhang ist gew\u00fcnscht, das Wissen aus Hochschulen und Universit\u00e4ten f\u00fcr zuk\u00fcnftige Gr\u00fcndungen besser auszusch\u00f6pfen. Bisher machen sich nur ein geringer Anteil aller Hochschulabsolventen selbst\u00e4ndig, meist nicht im zeitlich nahen Anschluss an das Studium oder die Promotion, sondern zwischen 8-15 Jahre danach (vgl.[ScKl96, Alba98, Moog00]). Die Hochschulen sollen daher einerseits das Gr\u00fcndungspotential unter den Studierenden erh\u00f6hen und ihnen andererseits eine unternehmerische Qualifikation f\u00fcr eine erfolgreiche Unternehmensgr\u00fcndung an die Hand geben [Walt98, S. 3].In den USA haben diese \u00dcberlegungen in den letzten 25 Jahren zu einer rasanten Entwicklung der Gr\u00fcndungslehre gef\u00fchrt. Bis in die 1960er Jahre gab in den USA nur an der Harvard University Entrepreneurship Lehre, weil man viele Jahre annahm, man m\u00fcsse zum Gr\u00fcnder geboren sein und k\u00f6nnte dies nicht erlernen. Nach [USMo95, S. 1] ist diese Diskussion \u00fcberholt. Der Gro\u00dfteil der notwendigen Kompetenz f\u00fcr eine Gr\u00fcndung gilt als lehrbar und kann \u201c... im Rahmen eines Lehrprozesses entwickelt werden \u201c[Neub98, S. 312]. So offerieren in den USA etwa 1.500 Colleges und Universit\u00e4ten diverse Kurse f\u00fcr \u201aEntrepreneurial Education \u2018. Es gibt mehr als 100 aktive, universit\u00e4tsnahe Entrepreneurship Center und 270", "num_citations": "10\n", "authors": ["1444"]}
{"title": "Enabling communities by constructed media: The case of a web-based study environment for a Talmudic tractate\n", "abstract": " The Babylonian Talmud is still an authoritative source for many orthodox Jews, an dialogic encyclopaedia of knowledge and one of the most impressive pieces of world literature. However, the distribution of this knowledge is limited by the burdensome task of studying this complex work. The paper presents a comprehensive study environment for a Talmudic tractate which transcribes an original printed edition into a structured electronic version, thus enabling much easier ways of studying the text with hypertextual annotations and dynamic knowledge level-dependent features. This radically changes the addressable knowledge communities.", "num_citations": "10\n", "authors": ["1444"]}
{"title": "Knowledge management cultures: A comparison of engineering and cultural science projects\n", "abstract": " This work in progress presents an approach to compare patterns of communication and knowledge organization in cultural and engineering science projects under the leading point of media use. The goal of the underlying project is to gain a better understanding on similarities and di erences in both areas and to develop more appropriate information system support for both areas. Central to the comparative analysis approach is a process knowledge repository which was successfully used in two case studies about real world information systems.", "num_citations": "10\n", "authors": ["1444"]}
{"title": "Enterprise integration by market-driven schema evolution\n", "abstract": " The way enterprises are organizing their processes is ultimately dictated by the requirements of their markets Enterprises serving slowly changing markets prefer a functional decomposition of their work force into departments with information flows along the hierarchy Quickly changing markets require quick redefinition of implemented functions and information flows in the distributed information systems of the enterprise This paper proposes conceptual modeling facilities and a trader architecture which enable a bottom-up market-driven evolution of the information system schemes A case study has been undertaken in the area of distributed quality management The trader has been im plemented with the meta database manager ConceptBase The information systems realize the information flows via federated SQL servers", "num_citations": "10\n", "authors": ["1444"]}
{"title": "An application perspective to deductive object bases\n", "abstract": " Deductive object bases (DOBs) attempt to combine the advantages of deductive relational databases with those of object-oriented databases. From an application perspective it is often not clear for what kind of applications this combination yields signi cant advantages. We argue for supporting distributed design environments by deductive object bases as repositories and summarize experiences made with our system ConceptBase.", "num_citations": "10\n", "authors": ["1444"]}
{"title": "Using teleological design knowledge for large systems development and maintenance\n", "abstract": " Using teleological design knowledge for large systems development and maintenance | 6th Internation Workshop Vol. 1 on Expert Systems & Their Applications ACM Digital Library home ACM home Google, Inc. (search) Advanced Search Browse About Sign in Register Advanced Search Journals Magazines Proceedings Books SIGs Conferences People More Search ACM Digital Library SearchSearch Advanced Search Browse Browse Digital Library Collections More HomeBrowse by TitleProceedings6th Internation Workshop Vol. on Expert Systems & Their ApplicationsUsing teleological design knowledge for large systems development and maintenance Article Using teleological design knowledge for large systems development and maintenance Share on Authors: Vasant Dhar profile image V Dhar View Profile , Matthais Jarke profile image M Jarke View Profile Authors Info & Affiliations Publication: 6th \u2026", "num_citations": "10\n", "authors": ["1444"]}
{"title": "Kopplung qualitativer und quantitativer Theorien in der Entscheidungsunterst\u00fctzung\n", "abstract": " Entscheidungsunterst\u00fctzende Systeme (EUS) kombinieren Methoden der Betriebswirtschaftslehre, der Mathematik, der Datenbanken und der Dialogsysteme zur Modellierung und L\u00f6sung komplexer Entscheidungsprobleme. Zur Erstellung eines EUS sind jeweils spezielle, meist mathematische Werkzeuge f\u00fcr den vorgegebenen Anwendungsbereich zu konfigurieren. Die traditionelle Schwierigkeit, da\u00df die verwendeten Modelle entweder sehr einfach sein m\u00fcssen oder aber vom Entscheidungstr\u00e4ger wegen ihrer Un\u00fcbersichtlichkeit nicht verwendet werden, kann durch eine wissensbasierte Steuerung mindestens zum Teil \u00fcberwunden werden. Der Aufsatz stellt Sprachkonzepte und Beispielsysteme vor, die diesen Kopplungsansatz realisieren, und entwickelt ein Konzept f\u00fcr integrierte, normativ orientierte EUS-Modellierungs- und Einsatzumgebungen.", "num_citations": "10\n", "authors": ["1444"]}
{"title": "Designing expert systems in a business environment\n", "abstract": " The integration of an ES into a business environment presents a different set of problems to the designer. First, it can be difficult to isolate and draw boundaries around the domain of the business problem. Second, there is often a need to generate a large number of expert decisions in a short period of time. That is, there can be many transactions requiring some expertise to process, such as applications for life insurance. Finally, there may exist a number of computerized transactions processing systems which interact with very large databases and there may be a need to integrate the ES with these existing systems. This paper discusses these general issues involved in developing expert systems for business applications, with particular examples drawn from the domain of insurance underwriting.", "num_citations": "10\n", "authors": ["1444"]}
{"title": "Data ecosystems: sovereign data exchange among organizations (Dagstuhl Seminar 19391)\n", "abstract": " This report documents the program and the outcomes of Dagstuhl Seminar 19391``Data Ecosystems: Sovereign Data Exchange among Organizations''. The goal of the seminar was to bring together people from different disciplines (also outside the computer science area), in order to identify (i) a set of research challenges for the future development of data ecosystems and a catalogue of major approaches relevant to the field and (ii) a set of developed use cases of particular interest to the further development of data ecosystems. Towards the objectives, the seminar included tutorials, invited talks, presentations of open problems, working groups. This report presents the most relevant findings and contributions.", "num_citations": "9\n", "authors": ["1444"]}
{"title": "Echtzeitmetamodellierung im Web-Browser\n", "abstract": " Modellierung ist ein integraler Bestandteil von Schaffensprozessen in vielen Disziplinen. Der Modellierungsprozess wird durch vielf\u00e4ltige Tools unterst\u00fctzt, von denen jedoch die wenigsten eine gemeinsame Modellierung durch mehrere Modellierer erm\u00f6glichen und die mittels offener Technologien und Protokolle realisiert sind. Um diese L\u00fccke zu schlie\u00dfen, konzipieren wir in diesem Beitrag ein Framework f\u00fcr Echtzeitmetamodellierung, das als Widget-basierte Anwendung realisiert wird und ausschlie\u00dflich auf quelloffenen Programmbibliotheken und breit implementierten Web-Technologien basiert. Der Beitrag berichtet \u00fcber eine vorab durchgef\u00fchrte Technologiestudie, bei der ein Echtzeitmodellierungstool f\u00fcr eine bestimmte Anwendung realisiert und erfolgreich evaluiert wurde. Das Metamodellierungsframework wurde durch Abstrahierung und Erweiterung der Technologiestudie auf Metamodellebene konzipiert und soll die Verbreitung von Echtzeitkollaborationsfunktionen in Web-Anwendungen vorantreiben.", "num_citations": "9\n", "authors": ["1444"]}
{"title": "Evolution of the CAiSE author community: a social network analysis\n", "abstract": " The CAiSE community has always prided itself as more than just a normal conference \u2013 a successful social network with a very special culture. In this chapter, we apply formal social network analysis to study this community and its evolution of its first quarter-centennial of existence. Using a methodology and dataset developed for an analysis of Computer Science as a whole, we demonstrate the unusual positioning of CAiSE as a quasi-interdisciplinary conference between several sub-disciplines of Computer Science. We show that under an evolution model developed in our research CAiSE pursues a very successful and promising path, and we identify key topics and key players among the CAiSE authors. As the social network analysis focusses on formal aspects such as co-authorship and citations, we unfortunately must leave out one of the undoubtedly most critical success factors: the fun of being in the\u00a0\u2026", "num_citations": "9\n", "authors": ["1444"]}
{"title": "Security aware mobile Web Service provisioning\n", "abstract": " Mobile data services in combination with profluent web services are seemingly the path breaking domain in current information research. Effectively, these mobile web services will pave the way for exciting performance and security challenges, the core need-to-be-addressed issues. On security front, though a lot of standardized security specifications and implementations exist for web services in the wired networks, not much has been analysed and standardized in the wireless environments. This paper addresses some of the critical challenges in providing security to the mobile web service domain. We first explore mobile web services and their key security issues, with special focus on provisioning based on a mobile web service provider realized by us. Later we discuss state-of-the-art security awareness in the wired and wireless web services, and finally address the realization of security for the mobile web service provisioning with performance analysis results.", "num_citations": "9\n", "authors": ["1444"]}
{"title": "Supporting mobile web service provisioning with cloud computing\n", "abstract": " Web services are going mobile. A Mobile Enter-prise can be established in a cellular network by participating Mobile Hosts, which act as web service providers, and their clients. Mobile Hosts enable seamless integration of user-specific services to the enterprise, by following web service standards, also on the radio link and via resource constrained smart phones. However, establishing such a Mobile Enterprise poses several technical challenges, like the quality of service (QoS) and discovery aspects, for the network and as well as for mobile phone users. The paper summarizes the challenges and research in this domain, along with our developed mobile web service mediation framework (MWSMF). However, to scale Mobile Enterprise to the loads possible in cellular networks, we shifted some of its components to the new utility computing paradigm, cloud computing. The cloud based load balancing for the Mobile Enterprise can be provided at the middleware framework level or at the individual services level. This paper described both the approaches, with two Mobile Host appli-cation scenarios, in collaborative m-learning and multimedia services domains. The analysis concludes that MWSMF and its components are horizontally scalable, thus allowing to utilize elasticity of cloud platform to meet load requirements of Mobile Enterprise in an easy and quick manner.", "num_citations": "9\n", "authors": ["1444"]}
{"title": "New approaches to media-supported project work at the university level\n", "abstract": " We present experiences made with a course in applied computer science which was based on the concept of communities of practice. Within the scope of the course \"entrepreneurship and new media\" we offered a project lab which was accompanied by a set of lectures given by internal and external lecturers. In the project groups, the students worked in close cooperation with start-up companies. The students were connected through a community system to each other and to their supervisors in academia and practice. As the communities of practice emerged we discuss the role they may play in teaching.", "num_citations": "9\n", "authors": ["1444"]}
{"title": "Different IS research communities: Are they competitors, complements, or ignoring each other?\n", "abstract": " The paper is based on an ICIS 2002 panel on the role of four different IS Research communities with regard to topic choice, project/study acquisition, research strategy, respondents and site access, and expected, measurable outcome and dissemination channel. Although differences are clear and although a probably healthy degree of competition among the communities cannot be denied, at the end all panelists expressed the need for more complementarity and thus cooperation among the different communities.", "num_citations": "9\n", "authors": ["1444"]}
{"title": "Data integration for multimedia e-learning environments with XML and MPEG-7\n", "abstract": " Integration of heterogeneous data is one of the greatest challenges for versatile e-learning environments, since support for different multimedia data formats is often restricted or adaptions are necessary to fit strict requirements. Therefore, we examine the opportunities given by new metadata standards like MPEG-7 and XML for knowledge management in terms of automated processing, evaluation and presentation of e-content. In Germany\u2019s first interdisciplinary and collaborative research center on \u201cMedia and Cultural Communications\u201d, we are studying the influence of transcription, localization and (re-) addressing on e-learning environments. Exemplarily, we want to introduce our Virtual Entrepreneurship Lab (VEL) as an approach to comply with these tasks in a multimedia e-learning environment.", "num_citations": "9\n", "authors": ["1444"]}
{"title": "On meta-modeling\n", "abstract": " On meta-modeling \u2014 Tilburg University Research Portal Skip to main navigation Skip to search Skip to main content Tilburg University Research Portal Logo Help & FAQ Home Profiles Research Output Research Units Activities Projects Press / Media Prizes / Recognition On meta-modeling M. Jarke, M. Papazoglou Research output: Chapter in Book/Report/Conference proceeding \u203a Chapter \u203a Scientific \u203a peer-review Overview Original language English Title of host publication Information Systems Interoperability Editors B. Kraamer, M. Papazoglou Place of Publication Chichester Publisher John Wiley & Sons ISBN (Print) 471981249 Publication status Published - 1998 Cite this APA Author BIBTEX Harvard Standard RIS Vancouver Jarke, M., & Papazoglou, M. (1998). On meta-modeling. In B. Kraamer, & M. Papazoglou (Eds.), Information Systems Interoperability John Wiley & Sons. Jarke, M. ; Papazoglou, M. / On meta-\u2026", "num_citations": "9\n", "authors": ["1444"]}