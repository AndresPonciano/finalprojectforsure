{"title": "SNIAFL: Towards a static noninteractive approach to feature location\n", "abstract": " To facilitate software maintenance and evolution, a helpful step is to locate features concerned in a particular maintenance task. In the literature, both dynamic and interactive approaches have been proposed for feature location. In this article, we present a static and noninteractive method for achieving this objective. The main idea of our approach is to use information retrieval (IR) technology to reveal the basic connections between features and computational units in the source code. Due to the imprecision of retrieved connections, we use a static representation of the source code named BRCG (branch-reserving call graph) to further recover both relevant and specific computational units for each feature. A premise of our approach is that programmers should use meaningful names as identifiers. We also performed an experimental study based on two real-world software systems to evaluate our approach\u00a0\u2026", "num_citations": "286\n", "authors": ["317"]}
{"title": "Inferring specifications for resources from natural language API documentation\n", "abstract": " Many software libraries, especially those commercial ones, provide API documentation in natural languages to describe correct API usages. However, developers may still write code that is inconsistent with API documentation, partially because many developers are reluctant to carefully read API documentation as shown by existing research. As these inconsistencies may indicate defects, researchers have proposed various detection approaches, and these approaches need many known specifications. As it is tedious to write specifications manually for all APIs, various approaches have been proposed to mine specifications automatically. In the literature, most existing mining approaches rely on analyzing client code, so these mining approaches would fail to mine specifications when client code is not sufficient. Instead of analyzing client code, we propose an approach, called Doc2Spec, that infers resource\u00a0\u2026", "num_citations": "229\n", "authors": ["317"]}
{"title": "A Unified Test Case Prioritization Approach\n", "abstract": " Test case prioritization techniques attempt to reorder test cases in a manner that increases the rate at which faults are detected during regression testing. Coverage-based test case prioritization techniques typically use one of two overall strategies: a total strategy or an additional strategy. These strategies prioritize test cases based on the total number of code (or code-related) elements covered per test case and the number of additional (not yet covered) code (or code-related) elements covered per test case, respectively. In this article, we present a unified test case prioritization approach that encompasses both the total and additional strategies. Our unified test case prioritization approach includes two models (basic and extended) by which a spectrum of test case prioritization techniques ranging from a purely total to a purely additional technique can be defined by specifying the value of a parameter referred to as\u00a0\u2026", "num_citations": "227\n", "authors": ["317"]}
{"title": "A Static Approach to Prioritizing JUnit Test Cases\n", "abstract": " Test case prioritization is used in regression testing to schedule the execution order of test cases so as to expose faults earlier in testing. Over the past few years, many test case prioritization techniques have been proposed in the literature. Most of these techniques require data on dynamic execution in the form of code coverage information for test cases. However, the collection of dynamic code coverage information on test cases has several associated drawbacks including cost increases and reduction in prioritization precision. In this paper, we propose an approach to prioritizing test cases in the absence of coverage information that operates on Java programs tested under the JUnit framework-an increasingly popular class of systems. Our approach, JUnit test case Prioritization Techniques operating in the Absence of coverage information (JUPTA), analyzes the static call graphs of JUnit test cases and the\u00a0\u2026", "num_citations": "174\n", "authors": ["317"]}
{"title": "An experimental study of four typical test suite reduction techniques\n", "abstract": " In software development, developers often rely on testing to reveal bugs. Typically, a test suite should be prepared before initial testing, and new test cases may be added to the test suite during the whole testing process. This may usually cause the test suite to contain more or less redundancy. In other words, a subset of the test suite (called the representative set) may still satisfy all the test objectives. As the redundancy can increase the cost of executing the test suite, quite a few test suite reduction techniques have been brought out in spite of the NP-completeness of the general problem of finding the optimal representative set of a test suite. In the literature, there have been some experimental studies of test suite reduction techniques, but the limitations of the these experimental studies are quite obvious. Recently proposed techniques are not experimentally compared against each other, and reported experiments\u00a0\u2026", "num_citations": "162\n", "authors": ["317"]}
{"title": "Building program vector representations for deep learning\n", "abstract": " Deep learning has made significant breakthroughs in various fields of artificial intelligence. However, it is still virtually impossible to use deep learning to analyze programs since deep architectures cannot be trained effectively with pure back propagation. In this pioneering paper, we propose the \u201ccoding criterion\u201d to build program vector representations, which are the premise of deep learning for program analysis. We evaluate the learned vector representations both qualitatively and quantitatively. We conclude, based on the experiments, the coding criterion is successful in building program representations. To evaluate whether deep learning is beneficial for program analysis, we feed the representations to deep neural networks, and achieve higher accuracy in the program classification task than \u201cshallow\u201d methods. This result confirms the feasibility of deep learning to analyze programs.", "num_citations": "139\n", "authors": ["317"]}
{"title": "\u8f6f\u4ef6\u5206\u6790\u6280\u672f\u8fdb\u5c55\n", "abstract": " \u6458 \u8981 \u8f6f\u4ef6\u5206\u6790\u6280\u672f\u7684\u7814\u7a76\u5df2\u6709\u8f83\u957f\u5386\u53f2, \u76f8\u5173\u6210\u679c\u4e5f\u5728\u8f6f\u4ef6\u751f\u547d\u5468\u671f\u7684\u4e0d\u540c\u9636\u6bb5\u4e2d\u5f97\u5230\u4e86\u5e7f\u6cdb\u5e94\u7528. \u8f6f\u4ef6\u751f\u547d\u5468\u671f\u4e2d\u4e0d\u540c\u6d3b\u52a8\u6240\u9700\u8981\u7684\u8f6f\u4ef6\u5206\u6790\u6280\u672f\u65e2\u4e0d\u5b8c\u5168\u76f8\u540c, \u53c8\u6709\u8bb8\u591a\u4ea4\u53e0, \u4e14\u4e0d\u540c\u7684\u5206\u6790\u6280\u672f\u4e4b\u95f4\u4e92\u76f8\u5f71\u54cd. \u6587\u7ae0\u5728\u8ba8\u8bba\u4e86\u8f6f\u4ef6\u5206\u6790\u7684\u57fa\u672c\u6982\u5ff5\u4e4b\u540e, \u4e3b\u8981\u4ece\u9759\u6001\u5206\u6790\u4e0e\u52a8\u6001\u5206\u6790\u4e24\u4e2a\u65b9\u9762\u4ecb\u7ecd\u4e86\u4e00\u4e9b\u4e3b\u8981\u7684\u8f6f\u4ef6\u5206\u6790\u6280\u672f\u4ee5\u53ca\u90e8\u5206\u76f8\u5173\u5206\u6790\u5de5\u5177. \u7ed3\u5408\u8f6f\u4ef6\u7684\u8d28\u91cf\u95ee\u9898, \u6587\u7ae0\u8fd8\u63a2\u8ba8\u4e86\u4e00\u4e9b\u5206\u6790\u6280\u672f\u4e0e\u8f6f\u4ef6\u8d28\u91cf\u5c5e\u6027\u7684\u76f8\u5173\u6027, \u4ee5\u4fbf\u4e8e\u4eba\u4eec\u5728\u5206\u6790\u7279\u5b9a\u7684\u8f6f\u4ef6\u8d28\u91cf\u5c5e\u6027\u65f6, \u9009\u53d6\u5408\u9002\u7684\u6280\u672f\u4e0e\u5de5\u5177. \u6700\u540e, \u6587\u7ae0\u5c55\u671b\u4e86\u8f6f\u4ef6\u5206\u6790\u6280\u672f\u7684\u53d1\u5c55\u8d8b\u52bf.", "num_citations": "138\n", "authors": ["317"]}
{"title": "On similarity-awareness in testing-based fault localization\n", "abstract": " In the process of software development and maintenance, software debugging is an inevitable and time-consuming task. To accelerate software debugging, various approaches have been proposed to automate fault localization. Among them, testing-based fault-localization approaches are most promising, which use the execution information of many test cases to localize the faults. However, these existing testing-based fault-localization approaches ignore the similarity between test cases, which may harm the effectiveness of these approaches according to our previous research. Therefore, in this paper we propose a similarity-aware fault-localization approach, which takes each test case as a fuzzy set to deal with the similarity between test cases and calculates statements\u2019 suspicions based on the probability theory. To investigate whether SAFL can address the similarity issue effectively, we manually\u00a0\u2026", "num_citations": "107\n", "authors": ["317"]}
{"title": "A History-Based Matching Approach to Identification of Framework Evolution\n", "abstract": " In practice, it is common that a framework and its client programs evolve simultaneously. Thus, developers of client programs may need to migrate their programs to the new release of the framework when the framework evolves. As framework developers can hardly always guarantee backward compatibility during the evolution of a framework, migration of its client program is often time-consuming and error-prone. To facilitate this migration, researchers have proposed two categories of approaches to identification of framework evolution: operation-based approaches and matching-based approaches. To overcome the main limitations of the two categories of approaches, we propose a novel approach named HiMa, which is based on matching each pair of consecutive revisions recorded in the evolution history of the framework and aggregating revision-level rules to obtain framework-evolution rules. We implemented\u00a0\u2026", "num_citations": "91\n", "authors": ["317"]}
{"title": "On-Demand Test Suite Reduction\n", "abstract": " Most test suite reduction techniques aim to select, from a given test suite, a minimal representative subset of test cases that retains the same code coverage as the suite. Empirical studies have shown, however, that test suites reduced in this manner may lose fault detection capability. Techniques have been proposed to retain certain redundant test cases in the reduced test suite so as to reduce the loss in fault-detection capability, but these still do concede some degree of loss. Thus, these techniques may be applicable only in cases where loose demands are placed on the upper limit of loss in fault-detection capability. In this work we present an on-demand test suite reduction approach, which attempts to select a representative subset satisfying the same test requirements as an initial test suite conceding at most l% loss in fault-detection capability for at least c% of the instances in which it is applied. Our technique\u00a0\u2026", "num_citations": "88\n", "authors": ["317"]}
{"title": "Threshold tuning for improved classification association rule mining\n", "abstract": " One application of Association Rule Mining (ARM) is to identify Classification Association Rules (CARs) that can be used to classify future instances from the same population as the data being mined. Most CARM methods first mine the data for candidate rules, then prune these using coverage analysis of the training data. In this paper we describe a CARM algorithm that avoids the need for coverage analysis, and a technique for tuning its threshold parameters to obtain more accurate classification. We present results to show this approach can achieve better accuracy than comparable alternatives at lower cost.", "num_citations": "82\n", "authors": ["317"]}
{"title": "\u4e00\u79cd\u652f\u6301\u9886\u57df\u7279\u6027\u7684 Web \u670d\u52a1\u7ec4\u88c5\u65b9\u6cd5\n", "abstract": " Web\u670d\u52a1\u4e3a\u8f6f\u4ef6\u6784\u4ef6\u6280\u672f\u63d0\u4f9b\u4e86\u826f\u597d\u7684\u5de5\u4e1a\u5316\u57fa\u7840.\u8f6f\u4ef6\u6784\u4ef6\u548c\u6784\u67b6\u6280\u672f\u7684\u7814\u7a76\u4e5f\u4e3aWeb\u670d\u52a1\u7684\u5e94\u7528\u5960\u5b9a\u4e86\u4e00\u5b9a\u7684\u5e94\u7528\u57fa\u7840.\u5728\u6784\u4ef6\u7ec4\u88c5\u4e2d,\u5982\u4f55\u652f\u6301\u9002\u5e94\u7528\u6237\u9700\u6c42\u7684Web\u670d\u52a1\u7684\u7ec4\u88c5\u662f\u5f53\u524d\u7814\u7a76\u7684\u70ed\u70b9\u4e4b\u4e00.\u8be5\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u4f18\u5316\u7b97\u6cd5\u7684,\u652f\u6301\u9886\u57df\u7279\u6027\u7684Web\u670d\u52a1\u7ec4\u88c5\u65b9\u6cd5,\u8be5\u65b9\u6cd5\u7684\u6838\u5fc3\u662f\u9762\u5411Web\u670d\u52a1\u5e94\u7528,\u6309\u7167\u7528\u6237\u786e\u5b9a\u7684\u529f\u80fd\u548cQoS\u9700\u6c42,\u57fa\u4e8e\u73b0\u6709\u9886\u57df\u6a21\u578b\u548cWeb\u670d\u52a1QoS\u5c5e\u6027,\u5c06\u7279\u5b9a\u9886\u57df\u7684\u4f18\u5316\u7ec4\u88c5\u8f6c\u5316\u4e3a\u6570\u5b66\u4f18\u5316\u95ee\u9898\u52a0\u4ee5\u89e3\u51b3.\u8fd9\u4e00\u65b9\u6cd5\u53ef\u4ee5\u8f83\u597d\u5730\u9002\u5e94\u7528\u6237\u9700\u6c42\u7684\u66f4\u6539\u5e76\u53ef\u4ee5\u8f85\u52a9\u7528\u6237\u9009\u62e9\u670d\u52a1.\u8be5\u6587\u6700\u540e\u7ed9\u51fa\u4e86\u652f\u6301\u8be5\u65b9\u6cd5\u7684\u539f\u578b\u5de5\u5177\u7684\u5b9e\u9a8c\u7ed3\u679c,\u7528\u4ee5\u8bf4\u660e\u8be5\u65b9\u6cd5\u7684\u53ef\u884c\u6027\u4e0e\u6709\u6548\u6027.", "num_citations": "82\n", "authors": ["317"]}
{"title": "How does regression test prioritization perform in real-world software evolution?\n", "abstract": " In recent years, researchers have intensively investigated various topics in test prioritization, which aims to re-order tests to increase the rate of fault detection during regression testing. While the main research focus in test prioritization is on proposing novel prioritization techniques and evaluating on more and larger subject systems, little effort has been put on investigating the threats to validity in existing work on test prioritization. One main threat to validity is that existing work mainly evaluates prioritization techniques based on simple artificial changes on the source code and tests. For example, the changes in the source code usually include only seeded program faults, whereas the test suite is usually not augmented at all. On the contrary, in real-world software development, software systems usually undergo various changes on the source code and test suite augmentation. Therefore, it is not clear whether the\u00a0\u2026", "num_citations": "79\n", "authors": ["317"]}
{"title": "Predicting Consistency-Maintenance Requirement of Code Clones at Copy-and-Paste Time\n", "abstract": " Code clones have always been a double edged sword in software development. On one hand, it is a very convenient way to reuse existing code, and to save coding effort. On the other hand, since developers may need to ensure consistency among cloned code segments, code clones can lead to extra maintenance effort and even bugs. Recently studies on the evolution of code clones show that only some of the code clones experience consistent changes during their evolution history. Therefore, if we can accurately predict whether a code clone will experience consistent changes, we will be able to provide useful recommendations to developers onleveraging the convenience of some code cloning operations, while avoiding other code cloning operations to reduce future consistency maintenance effort. In this paper, we define a code cloning operation as consistency-maintenance-required if its generated code\u00a0\u2026", "num_citations": "79\n", "authors": ["317"]}
{"title": "\u4e00\u79cd\u65b0\u7684\u53d8\u5f02\u6d4b\u8bd5\u6570\u636e\u81ea\u52a8\u751f\u6210\u65b9\u6cd5\n", "abstract": " \u6458 \u8981 \u53d8\u5f02\u6d4b\u8bd5\u662f\u4e00\u79cd\u884c\u4e4b\u6709\u6548\u7684\u8f6f\u4ef6\u6d4b\u8bd5\u65b9\u6cd5, \u901a\u8fc7\u4f7f\u7528\u53d8\u5f02\u7b97\u5b50\u4ea7\u751f\u53d8\u5f02\u4f53\u7cfb\u7edf\u5730\u6a21\u62df\u8f6f\u4ef6\u4e2d\u7684\u5404\u79cd\u7f3a\u9677, \u7136\u540e\u6784\u9020\u80fd\u591f\u6740\u6b7b\u8fd9\u4e9b\u53d8\u5f02\u4f53\u7684\u6d4b\u8bd5\u6570\u636e\u96c6. \u81ea\u52a8\u751f\u6210\u80fd\u591f\u6740\u6b7b\u53d8\u5f02\u4f53\u7684\u6d4b\u8bd5\u6570\u636e\u5c06\u63d0\u9ad8\u53d8\u5f02\u6d4b\u8bd5\u7684\u6548\u7387\u548c\u6709\u6548\u6027. \u5f53\u524d\u7684\u7814\u7a76\u5de5\u4f5c\u53ea\u8003\u8651\u751f\u6210\u6740\u6b7b\u5355\u4e2a\u53d8\u5f02\u4f53\u7684\u6d4b\u8bd5\u6570\u636e. \u6587\u4e2d\u6839\u636e\u6740\u6b7b\u540c\u4e00\u4f4d\u7f6e\u7684\u591a\u4e2a\u53d8\u5f02\u4f53\u7684\u6761\u4ef6\u76f8\u8fd1\u7684\u7279\u70b9, \u63d0\u51fa\u4e00\u79cd\u5bf9\u6740\u6b7b\u8fd9\u4e9b\u53d8\u5f02\u4f53\u7684\u6761\u4ef6\u8fdb\u884c\u7ec4\u5408, \u7136\u540e\u751f\u6210\u540c\u65f6\u6740\u6b7b\u8be5\u4f4d\u7f6e\u591a\u4e2a\u53d8\u5f02\u4f53\u7684\u6d4b\u8bd5\u6570\u636e\u7684\u65b9\u6cd5; \u7ed9\u51fa\u76f8\u5e94\u7684\u652f\u6301\u5de5\u5177, \u5e76\u4e14\u901a\u8fc7\u5b9e\u9a8c\u9a8c\u8bc1\u65b9\u6cd5\u7684\u6709\u6548\u6027.", "num_citations": "75\n", "authors": ["317"]}
{"title": "\u4e00\u79cd Web \u670d\u52a1\u7684\u6d4b\u8bd5\u6570\u636e\u81ea\u52a8\u751f\u6210\u65b9\u6cd5\n", "abstract": " \u8f6f\u4ef6\u6d4b\u8bd5\u662f\u4fdd\u8bc1Web\u670d\u52a1\u8d28\u91cf\u7684\u91cd\u8981\u6280\u672f\u624b\u6bb5.\u6d4b\u8bd5\u6570\u636e\u751f\u6210\u662fWeb\u670d\u52a1\u6d4b\u8bd5\u7684\u91cd\u8981\u5185\u5bb9.\u6d4b\u8bd5\u6570\u636e\u7684\u8d28\u91cf\u5c06\u76f4\u63a5\u5f71\u54cdWeb\u670d\u52a1\u6d4b\u8bd5\u7684\u6548\u7387\u548c\u6210\u672c.\u6587\u7ae0\u57fa\u4e8e\u5408\u7ea6\u5f0f\u8bbe\u8ba1\u7684Web\u670d\u52a1\u6d4b\u8bd5\u6280\u672f,\u63d0\u51fa\u4e00\u79cdWeb\u670d\u52a1\u7684\u6d4b\u8bd5\u6570\u636e\u81ea\u52a8\u751f\u6210\u65b9\u6cd5.\u9996\u5148\u6839\u636eWSDL\u6587\u6863\u91c7\u7528\u968f\u673a\u6cd5\u81ea\u52a8\u751f\u6210\u521d\u59cb\u6d4b\u8bd5\u6570\u636e,\u7136\u540e\u4f7f\u7528\u5408\u7ea6\u53d8\u5f02\u6280\u672f\u8fdb\u884c\u6d4b\u8bd5\u6570\u636e\u7684\u9009\u62e9,\u636e\u6b64\u53ef\u4ee5\u751f\u6210\u4e00\u7ec4\u8fbe\u5230\u4e00\u5b9a\u5408\u7ea6\u53d8\u5f02\u5145\u5206\u5ea6\u7684\u6709\u6548\u6d4b\u8bd5\u6570\u636e,\u4ece\u800c\u63d0\u9ad8Web\u670d\u52a1\u7684\u6d4b\u8bd5\u8d28\u91cf\u548c\u6548\u7387.\u6700\u540e\u5b9e\u73b0\u4e86\u4e00\u4e2aWeb\u670d\u52a1\u7684\u6d4b\u8bd5\u6570\u636e\u81ea\u52a8\u751f\u6210\u5de5\u5177\u539f\u578b,\u5e76\u901a\u8fc7\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u65b9\u6cd5\u7684\u6709\u6548\u6027.", "num_citations": "73\n", "authors": ["317"]}
{"title": "A component-based software configuration management model and its supporting system\n", "abstract": " Software configuration management (SCM) is an important key technology in software development. Component-based software development (CBSD) is an emerging paradigm in software development. However, to apply CBSD effectively in real world practice, supporting SCM in CBSD needs to be further investigated. In this paper, the objects that need to be managed in CBSD is analyzed and a component-based SCM model is presented. In this model, components, as the integral logical constituents in a system, are managed as the basic configuration items in SCM, and the relationships between/among components are defined and maintained. Based on this model, a configuration management system is implemented.", "num_citations": "71\n", "authors": ["317"]}
{"title": "Effective Message-Sequence Generation for Testing BPEL Programs\n", "abstract": " With the popularity of Web Services and Service-Oriented Architecture (SOA), quality assurance of SOA applications, such as testing, has become a research focus. Programs implemented by the Business Process Execution Language for Web Services (WS-BPEL), which can be used to compose partner Web Services into composite Web Services, are one popular kind of SOA applications. The unique features of WS-BPEL programs bring new challenges into testing. A test case for testing a WS-BPEL program is a sequence of messages that can be received by the WS-BPEL program under test. Previous research has not studied the challenges of message-sequence generation induced by unique features of WS-BPEL as a new language. In this paper, we present a novel methodology to generate effective message sequences for testing WS-BPEL programs. To capture the order relationship in a message\u00a0\u2026", "num_citations": "61\n", "authors": ["317"]}
{"title": "Extracting paraphrases of technical terms from noisy parallel software corpora\n", "abstract": " In this paper, we study the problem of extracting technical paraphrases from a parallel software corpus, namely, a collection of duplicate bug reports. Paraphrase acquisition is a fundamental task in the emerging area of text mining for software engineering. Existing paraphrase extraction methods are not entirely suitable here due to the noisy nature of bug reports. We propose a number of techniques to address the noisy data problem. The empirical evaluation shows that our method significantly improves an existing method by up to 58%.", "num_citations": "57\n", "authors": ["317"]}
{"title": "TCA: An Efficient Two-Mode Meta-Heuristic Algorithm for Combinatorial Test Generation\n", "abstract": " Covering arrays (CAs) are often used as test suites for combinatorial interaction testing to discover interaction faults of real-world systems. Most real-world systems involve constraints, so improving algorithms for covering array generation (CAG) with constraints is beneficial. Two popular methods for constrained CAG are greedy construction and meta-heuristic search. Recently, a meta-heuristic framework called two-mode local search has shown great success in solving classic NPhard problems. We are interested whether this method is also powerful in solving the constrained CAG problem. This work proposes a two-mode meta-heuristic framework for constrained CAG efficiently and presents a new meta-heuristic algorithm called TCA. Experiments show that TCA significantly outperforms state-of-the-art solvers on 3-way constrained CAG. Further experiments demonstrate that TCA also performs much better than its\u00a0\u2026", "num_citations": "56\n", "authors": ["317"]}
{"title": "Matching dependence-related queries in the system dependence graph\n", "abstract": " In software maintenance and evolution, it is common that developers want to apply a change to a number of similar places. Due to the size and complexity of the code base, it is challenging for developers to locate all the places that need the change. A main challenge in locating the places that need the change is that, these places share certain common dependence conditions but existing code searching techniques can hardly handle dependence relations satisfactorily. In this paper, we propose a technique that enables developers to make queries involving dependence conditions and textual conditions on the system dependence graph of the program. We carried out an empirical evaluation on four searching tasks taken from the development history of two real-world projects. The results of our evaluation indicate that, compared with code-clone detection, our technique is able to locate many required code\u00a0\u2026", "num_citations": "56\n", "authors": ["317"]}
{"title": "Inflow and retention in oss communities with commercial involvement: A case study of three hybrid projects\n", "abstract": " Motivation: Open-source projects are often supported by companies, but such involvement often affects the robust contributor inflow needed to sustain the project and sometimes prompts key contributors to leave. To capture user innovation and to maintain quality of software and productivity of teams, these projects need to attract and retain contributors. Aim: We want to understand and quantify how inflow and retention are shaped by policies and actions of companies in three application server projects. Method: We identified three hybrid projects implementing the same JavaEE specification and used published literature, online materials, and interviews to quantify actions and policies companies used to get involved. We collected project repository data, analyzed affiliation history of project participants, and used generalized linear models and survival analysis to measure contributor inflow and retention. Results: We\u00a0\u2026", "num_citations": "54\n", "authors": ["317"]}
{"title": "Mutation-based test-case prioritization in software evolution\n", "abstract": " During software evolution, to assure the software quality, test cases for an early version tend to be reused by its latter versions. As a large number of test cases may aggregate during software evolution, it becomes necessary to schedule the execution order of test cases so that the faults in the latter version may be detected as early as possible, which is test-case prioritization in software evolution. In this paper, we proposed a novel test-case prioritization approach for software evolution, which first uses mutation faults on the difference between the early version and the latter version to simulate real faults occurred in software evolution, and then schedules the execution order of test cases based on their fault-detection capability, which is defined based on mutation faults. In particular, we present two models on calculating fault-detection capability, which are statistics-based model and probability-based model. Moreover\u00a0\u2026", "num_citations": "53\n", "authors": ["317"]}
{"title": "An Approach to Testing Black-box Components Using Contract-Based Mutation\n", "abstract": " Component Based Software Development (CBSD) is gaining popularity in recent years. In this way of software development, software components, which are typically black-box components, are intensively reused to construct new systems. To ensure the quality of software systems composed of black-box components, a primary concern is how to ensure the quality of black-box components. Thus, adequate testing of those black-box components that will be reused is a necessary step in CBSD. However, due to the unavailability of the source code of black-box components, ensuring test adequacy becomes one of the hardest issues for testing black-box components. To tackle this problem, it is a natural idea to apply mutation testing, which is a fault-based testing method used for measuring test adequacy, for component contracts, whose aim is to improve the testability of the component. Though powerful, mutation\u00a0\u2026", "num_citations": "53\n", "authors": ["317"]}
{"title": "Applying OO metrics to assess UML meta-models\n", "abstract": " UML has been coming of age through more than seven years development, in which there are not only minor revision like from UML 1.1 to UML 1.2, but also significant improvement like final adoption of UML 2.0 submissions. However there is so far lack of an objective assessment to UML meta-models, which can be used to control and predict the evolution of the UML. In this paper we regard UML meta-models as the equivalent of Object-Oriented (OO) design models. Therefore, we can adapt OO design metrics and criteria as a method to assess UML meta-models. Our method conducts the assessment of stability and design quality to UML meta-models in versions of 1.1, 1.3, 1.4 (with Action Semantics), 1.5, and 2.0. Based on the results we analyze the evolution of the UML versions and provide the applicability suggestions to the method.", "num_citations": "51\n", "authors": ["317"]}
{"title": "Identifying use cases in source code\n", "abstract": " Understanding the behavior of a software system is an important problem in software maintenance. As use cases have been accepted as an effective means for describing behavioral requirements for a software system, it should be helpful for maintainers to acquire the use case model from source code. In this paper, we propose a novel approach to identifying use cases in source code. The central idea of our approach is based on the observation that branch statements are a primary mechanism to separate one use case from another in source code. Following this idea, we design a static representation of software systems through incorporating branch information into the traditional call graph, which is named the Branch-Reserving Call Graph (BRCG). To effectively use this representation for use case identification, branches that do not serve as the separations of use cases should be pruned off in the BRCG. In this\u00a0\u2026", "num_citations": "49\n", "authors": ["317"]}
{"title": "Summary-based context-sensitive data-dependence analysis in presence of callbacks\n", "abstract": " Building a summary for library code is a common approach to speeding up the analysis of client code. In presence of callbacks, some reachability relationships between library nodes cannot be obtained during library-code summarization. Thus, the library code may have to be analyzed again during the analysis of the client code with the library summary. In this paper, we propose to summarize library code with tree-adjoining-language (TAL) reachability. Compared with the summary built with context-free-language (CFL) reachability, the summary built with TAL reachability further contains conditional reachability relationships. The conditional reachability relationships can lead to much lighter analysis of the library code during the client code analysis with the TAL-reachability-based library summary. We also performed an experimental comparison of context-sensitive data-dependence analysis with the TAL\u00a0\u2026", "num_citations": "47\n", "authors": ["317"]}
{"title": "A framework for testing Web services and its supporting tool\n", "abstract": " With the increase of the popularity of Web services, more and more Web applications are developed with this new kind of components. This new way of software development brings about new issues for software testing, which has been widely recognized as a realistic means for ensuring the quality of software systems. In this paper, we focus on facilitating the testing of Web services. In particular, we propose a framework for testing Web services, which can help a tester of Web services in two ways: firstly, it can help the tester to acquire effective test data; and secondly, it can help the tester to execute the test data for the testing. We also discuss some issues for the implementation of its supporting tool. Furthermore, we report an experimental study of our framework. The results can validate the effectiveness of our approach.", "num_citations": "45\n", "authors": ["317"]}
{"title": "VIDA: Visual interactive debugging\n", "abstract": " Software debugging is time-consuming and effort-consuming. Although software debugging, especially fault-localization, has been studied for long, few practical debugging tools have been developed and used by the industry. In this paper we present VIDA, a visual interactive debugging tool, which has been integrated with the Eclipse Integrated Development Environment to support a programmer's debugging process. During the programmer's conventional debugging process, VIDA continuously recommends break-points for the programmer based on the analysis of execution information and the gathered feedback from the programmer. Moreover, VIDA provides a program outline to help the programmer choose breakpoints and visualizes the static dependency relation to help the programmer make estimation at breakpoints.", "num_citations": "39\n", "authors": ["317"]}
{"title": "Adaptive Test-Case Prioritization Guided by Output Inspection\n", "abstract": " Test-case prioritization is to schedule the execution order of test cases so as to maximize some objective (e.g., revealing faults early). The existing test-case prioritization approaches separate the process of test-case prioritization and the process of test-case execution by presenting the execution order of all test cases before programmers start running test cases. As the execution information of the modified program is not available for the existing test-case prioritization approaches, these approaches mainly rely on only the execution information of the previous program before modification. To address this problem, we present an adaptive test-case prioritization approach, which determines the execution order of test cases simultaneously during the execution of test cases. In particular, the adaptive approach selects test cases based on their fault-detection capability, which is calculated based on the output of selected\u00a0\u2026", "num_citations": "38\n", "authors": ["317"]}
{"title": "Learning to Rank for Question-Oriented Software Text Retrieval\n", "abstract": " Question-oriented text retrieval, aka natural language-based text retrieval, has been widely used in software engineering. Earlier work has concluded that questions with the same keywords but different interrogatives (such as how, what) should result in different answers. But what is the difference? How to identify the right answers to a question? In this paper, we propose to investigate the \"answer style\" of software questions with different interrogatives. Towards this end, we build classifiers in a software text repository and propose a re-ranking approach to refine search results. The classifiers are trained by over 16,000 answers from the StackOverflow forum. Each answer is labeled accurately by its question's explicit or implicit interrogatives. We have evaluated the performance of our classifiers and the refinement of our re-ranking approach in software text retrieval. Our approach results in 13.1% and 12.6\u00a0\u2026", "num_citations": "37\n", "authors": ["317"]}
{"title": "Locating Need-to-Externalize Constant Strings for Software Internationalization with Generalized String-Taint Analysis\n", "abstract": " Nowadays, a software product usually faces a global market. To meet the requirements of different local users, the software product must be internationalized. In an internationalized software product, user-visible hard-coded constant strings are externalized to resource files so that local versions can be generated by translating the resource files. In many cases, a software product is not internationalized at the beginning of the software development process. To internationalize an existing product, the developers must locate the user-visible constant strings that should be externalized. This locating process is tedious and error-prone due to 1) the large number of both user-visible and non-user-visible constant strings and 2) the complex data flows from constant strings to the Graphical User Interface (GUI). In this paper, we propose an automatic approach to locating need-to-externalize constant strings in the source\u00a0\u2026", "num_citations": "37\n", "authors": ["317"]}
{"title": "Eliminating harmful redundancy for testing-based fault localization using test suite reduction: An experimental study\n", "abstract": " In the process of software maintenance, it is usually a time-consuming task to track down bugs. To reduce the cost on debugging, several approaches have been proposed to localize the fault(s) to facilitate debugging. Intuitively, testing-based fault localization (TBFL), such as dicing and TRANTULA, is quite promising as it can take the advantage of a large set of execution traces at the same time. However, redundant test cases may bias the distribution of the test suite and harm this kind of approaches. Therefore, we suggest that the test suite, which is the input of TBFL, should be reduced before used in TBFL. To evaluate whether and to what extent TBFL can benefit from test suite reduction, we performed an experimental study on two source programs. The experimental results show that, for test suites containing unevenly distributed redundant test cases, performing test suite reduction before applying TBFL may be\u00a0\u2026", "num_citations": "37\n", "authors": ["317"]}
{"title": "\u57fa\u4e8e\u6784\u4ef6\u7684\u8f6f\u4ef6\u914d\u7f6e\u7ba1\u7406\u6280\u672f\u7814\u7a76\n", "abstract": " \u672c\u6587\u5206\u6790\u4e86\u57fa\u4e8e\u6784\u4ef6\u7684\u8f6f\u4ef6\u5f00\u53d1\u5bf9\u914d\u7f6e\u7ba1\u7406\u6280\u672f\u7684\u9700\u6c42, \u63d0\u51fa\u4e86\u57fa\u4e8e\u6784\u4ef6\u7684\u8f6f\u4ef6\u914d\u7f6e\u7ba1\u7406\u7cfb\u7edf\u6a21\u578b, \u5e76\u4ecb\u7ecd\u4e86\u4e00\u4e2a\u57fa\u4e8e\u8be5\u6a21\u578b\u7684\u7cfb\u7edf, \u8ba8\u8bba\u4e86\u7cfb\u7edf\u4e2d\u7684\u7ba1\u7406\u7b56\u7565\u548c\u5173\u952e\u6280\u672f.", "num_citations": "34\n", "authors": ["317"]}
{"title": "Can big data bring a breakthrough for software automation?\n", "abstract": " Software automation [1] aims to automatically generate computer programs from formal or informal requirements. Since it may release programmers from tedious programming tasks, software automation has long been a dream of computer scientists. Practically, since software systems constantly evolve during their life cycles, software automation should cover all development activities related to both generating new code and changing existing code. Compilers for high-level programming languages (eg, C and FORTRAN) can be viewed as pioneer work in the field of software automation. With compilers, programs written in high-level programming languages can be automatically transformed into their executable forms using some transformation rules. However, to realize software automation in the modern sense, where software systems written in high-level programming languages need to be automatically generated based on their requirements, three major challenges need to be further addressed: informality, non-operationality, and incompleteness.\u2022 Informality. Instead of representing requirements for computers to process (eg, a formal language), humans tend to represent requirements in a manner for humans to process (eg, a natural language). To address this challenge, researchers have investigated various specification languages [2](which can be either formal, semiformal, or graphical) to provide a compromise.", "num_citations": "33\n", "authors": ["317"]}
{"title": "Mining API Usage Examples from Test Code\n", "abstract": " Lack of effective usage examples in API documents has been proven to be a great obstacle to API learning. To deal with this issue, several approaches have been proposed to automatically extract usage examples from client code or related web pages, which are unfortunately not available for newly released API libraries. In this paper, we propose a novel approach to mining API usage examples from test code. Although test code can be a good source of usage examples, the issue of multiple test scenarios might lead to repetitive and interdependent API usages in a test method, which make it complicated and difficult to extract API usage examples. To address this issue, we study the JUnit test code and summarize a set of test code patterns. We employ a code pattern based heuristic slicing approach to separate test scenarios into code examples. Then we cluster the similar usage examples for recommendation. An\u00a0\u2026", "num_citations": "32\n", "authors": ["317"]}
{"title": "Inferring specifications of object oriented APIs from API source code\n", "abstract": " API libraries are becoming increasingly popular in modern software industries because these libraries provide various methods and classes for reuse. However, as pointed out by researchers, libraries are typically difficult to use. It is desirable to infer some specifications for libraries so that programmers can learn the correct usages of these libraries. In this paper, we propose an approach to infer specifications from source code of API libraries. Our approach is based on the observation that rules in object-oriented programs can be traced from basic constraints such as memory usage, file usage, and network protocol. In addition, rules of one class spread to its dependent classes through the features of object-oriented programs such as derivation, invocation relationship, and field access among methods. Based on our approach, we implemented a prototype named Java Rule Finder (JRF) to infer specifications from\u00a0\u2026", "num_citations": "31\n", "authors": ["317"]}
{"title": "Relevancy based semantic interoperation of reuse repositories\n", "abstract": " Software reuse is a promising solution to the software crisis. Reuse repositories are the basic infrastructure for software reuse. During the past decade, various academic, commercial, governmental, and industrial organizations have developed many Internet-enabled reuse repositories to provide access to software components and related resources. It has necessitated semantic interoperation to allow distributed maintenance and management of these repositories while enabling users to efficiently and conveniently access resources from multiple reuse repositories via a single representation view. In this paper, we have proposed an approach to enhancing the semantic interoperability of reuse repositories, called the improved relevancy matching and ranking (IRMR) method, based on analyzing the correlation of terms in representation methods of the repositories. A prototype system, the Virtual Repository\u00a0\u2026", "num_citations": "31\n", "authors": ["317"]}
{"title": "Understanding how the requirements are implemented in source code\n", "abstract": " For software maintenance and evolution, a common problem is to understand how each requirement is implemented in the source code. The basic solution of this problem is to find the fragment of source code that is corresponding to the implementation of each requirement. This can be viewed as a requirement-slicing problem - slicing the source code according to each individual requirement. We present an approach to find the set of functions that is corresponding to each requirement. The main idea of our method is to combine the information retrieval technology with the static analysis of source code structures. First, we retrieve the initial function sets through some information retrieval model using functional requirements as the queries and identifier information (such as function names, parameter names, variable names etc.) of functions in the source code as target documents. Then we complement each\u00a0\u2026", "num_citations": "29\n", "authors": ["317"]}
{"title": "Optimizing test prioritization via test distribution analysis\n", "abstract": " Test prioritization aims to detect regression faults faster via reordering test executions, and a large number of test prioritization techniques have been proposed accordingly. However, test prioritization effectiveness is usually measured in terms of the average percentage of faults detected concerned with the number of test executions, rather than the actual regression testing time, making it unclear which technique is optimal in actual regression testing time. To answer this question, this paper first conducts an empirical study to investigate the actual regression testing time of various prioritization techniques. The results reveal a number of practical guidelines. In particular, no prioritization technique can always perform optimal in practice.", "num_citations": "28\n", "authors": ["317"]}
{"title": "On the classification of uml's meta model extension mechanism\n", "abstract": " Although the UML meta model extension mechanism has been used in many modeling fields in which extension of UML is needed, UML specification has little necessary classification and application guidance on the meta model extension mechanism. This paper defines four levels of UML\u2019s meta model extension mechanism, and discusses the readability, expression capability, use scope and tool support on the basis of precise definitions of each level. The work on the paper reinforces the maneuverability of the UML meta model extension mechanism, and provides a reliable theoretical base for the development of modeling tools that support meta model extension.", "num_citations": "25\n", "authors": ["317"]}
{"title": "How do assertions impact coverage-based test-suite reduction?\n", "abstract": " Code coverage is the dominant criterion in test-suite reduction. Typically, most test-suite reduction techniques repeatedly remove tests covering code that has been covered by other tests from the test suite. However, test-suite reduction based on code coverage alone may incur fault-detection capability loss, because a test detects faults if and only if its execution covers buggy code and its test oracle catches the buggy state. In other words, test oracles may also affect test-suite reduction, However, to our knowledge, their impacts have never been studied before. In this paper, we conduct the first empirical study on such impacts by using 10 real-world GitHub Java projects, and find that assertions (i.e., a typical type of test oracles) are significantly correlated with coverage-based test-suite reduction. Based on our preliminary study results, we also proposed an assertion-aware test-suite reduction technique which\u00a0\u2026", "num_citations": "23\n", "authors": ["317"]}
{"title": "Test-data generation guided by static defect detection\n", "abstract": " Software testing is an important technique to assure the quality of software systems, especially high-confidence systems. To automate the process of software testing, many automatic test-data generation techniques have been proposed. To generate effective test data, we propose a test-data generation technique guided by static defect detection in this paper. Using static defect detection analysis, our approach first identifies a set of suspicious statements which are likely to contain faults, then generates test data to cover these suspicious statements by converting the problem of test-data generation to the constraint satisfaction problem. We performed a case study to validate the effectiveness of our approach, and made a simple comparison with another test-data generation on-line tool, JUnit Factory. The results show that, compared with JUnit Factory, our approach generates fewer test data that are\u00a0\u2026", "num_citations": "23\n", "authors": ["317"]}
{"title": "Comments on 'On the Applicability of Weyuker Property 9 to Object-Oriented Structural Inheritance Complexity Metrics'\n", "abstract": " In this paper, we point out some discrepancies in a correspondence published in this journal recently by Gursaran and G. Roy (see ibid., vol. 27, no. 4, p. 381-4 (2001)). Due to the discrepancies, the central two \"theorems\" and two \"corollaries\" claimed in that correspondence may not be held true in some extreme circumstances and, therefore, its main conclusion cannot be drawn for all the possible cases.", "num_citations": "23\n", "authors": ["317"]}
{"title": "\u4e00\u79cd\u57fa\u4e8e\u529f\u80fd\u9700\u6c42\u5c42\u6b21\u51dd\u805a\u7684\u7a0b\u5e8f\u805a\u7c7b\u65b9\u6cd5\n", "abstract": " \u5bf9\u5927\u578b\u590d\u6742\u7cfb\u7edf\u8fdb\u884c\u805a\u7c7b\u5206\u6790\u80fd\u591f\u6539\u5584\u8f6f\u4ef6\u7ef4\u62a4\u7684\u6548\u7387\u548c\u6548\u679c, \u540c\u65f6\u4e5f\u662f\u83b7\u53d6\u53ef\u590d\u7528\u6784\u4ef6\u7684\u57fa\u7840. \u63d0\u51fa\u4e00\u79cd\u57fa\u4e8e\u9700\u6c42\u5c42\u6b21\u51dd\u805a\u7684\u7a0b\u5e8f\u805a\u7c7b\u65b9\u6cd5\u6765\u89e3\u51b3\u8fd9\u4e2a\u95ee\u9898. \u8be5\u65b9\u6cd5\u5229\u7528\u5b58\u5728\u4e8e\u9700\u6c42\u63cf\u8ff0\u4e2d\u7684\u8bed\u4e49\u4fe1\u606f\u83b7\u53d6\u95ee\u9898\u57df\u7684\u9ad8\u5c42\u903b\u8f91, \u7ed3\u5408\u5bf9\u6e90\u4ee3\u7801\u7684\u52a8\u6001\u5206\u6790, \u6700\u7ec8\u83b7\u53d6\u5bf9\u6e90\u4ee3\u7801\u7684\u5206\u89e3\u5212\u5206. \u4f7f\u7528\u8be5\u65b9\u6cd5\u83b7\u53d6\u7684\u5212\u5206\u7ed3\u679c\u5177\u6709\u5230\u95ee\u9898\u57df\u7684\u6620\u5c04; \u5e76\u4e14\u7531\u4e8e\u91c7\u7528\u4e86\u52a8\u6001\u7684\u5206\u6790\u7b56\u7565, \u8be5\u65b9\u6cd5\u5177\u6709\u7075\u6d3b\u7684\u5212\u5206\u7c92\u5ea6.", "num_citations": "22\n", "authors": ["317"]}
{"title": "History-driven build failure fixing: how far are we?\n", "abstract": " Build systems are essential for modern software development and maintenance since they are widely used to transform source code artifacts into executable software. Previous work shows that build systems break frequently during software evolution. Therefore, automated build-fixing techniques are in huge demand. In this paper we target a mainstream build system, Gradle, which has become the most widely used build system for Java projects in the open-source community (eg, GitHub). HireBuild, state-of-the-art build-fixing tool for Gradle, has been recently proposed to fix Gradle build failures via mining the history of prior fixes. Although HireBuild has been shown to be effective for fixing real-world Gradle build failures, it was evaluated on only a limited set of build failures, and largely depends on the quality/availability of historical fix information. To investigate the efficacy and limitations of the history-driven build\u00a0\u2026", "num_citations": "21\n", "authors": ["317"]}
{"title": "Test-data generation for web services based on contract mutation\n", "abstract": " Software testing is one of the most important techniques used to assure the quality of Web services at present. Test-data generation is an important topic in Web services testing. The quality of test data will influence the efficiency and cost when testing Web services. Based on the contract-based mutation testing technique, this paper presents a method of automated test-data generation for Web services. First, according to the description information and contracts in WSDL documents of Web services, initial test data are generated automatically by the random method. Then the test data are selected using contract mutation testing. This method can generate a test suite meeting a certain contract mutation score, which indicates the quality and efficiency of testing. Finally, we have developed a prototype on the Microsoft .NET platform, and carried out some experiments. The results have shown that the proposed method is\u00a0\u2026", "num_citations": "21\n", "authors": ["317"]}
{"title": "\u57fa\u4e8e\u590d\u7528\u7684\u8f6f\u4ef6\u5f00\u53d1\u8fc7\u7a0b\u4e2d\u7684\u914d\u7f6e\u7ba1\u7406\n", "abstract": " Both software reuse and cc> r~ iguration martagomet~ thave thesa~ legoat, which is t [lm provesoftware quality and productivity W hite software relise mainly focuses on rP. ethod issues, conflguratiortm ar~ agementm ainly focuses. rJmanagem ent: ssues In many ways, both Technologies arl2corttplem entary to each other In thispaper, software reuse and configuratiortrll&na~ ertlerttarcd overviewed first; then theissue ofhow to useconfiguration mattagem entfor bettersoftwarerouse zsdiscussed", "num_citations": "21\n", "authors": ["317"]}
{"title": "A multi-property trust model for reconfiguring component software\n", "abstract": " While component software continues to grow in size and complexity, it becomes increasingly difficult to ensure qualities for component services, especially at run-time. This paper focuses on a framework on middleware for dynamic re-configuration of components of different qualities from the view of trust. Firstly, a trust management model is built, in which the management framework and measurement model are presented. Secondly, the reconfiguration algorithm is described based on the model. Thirdly, the trust management is implemented as a kind of public services and some tools on a J2EE-compliant middleware platform, i.e., PKUAS. Finally, the related work is discussed and compared with our research.", "num_citations": "20\n", "authors": ["317"]}
{"title": "Formalising optimal feature weight setting in case based diagnosis as linear programming problems\n", "abstract": " Many approaches to case based reasoning (CBR) exploit feature weight setting algorithms to reduce the sensitivity to distance functions. In this paper, we demonstrate that optimal feature weight setting in a special kind of CBR problems can be formalised as linear programming problems. Therefore, the optimal weight settings can be calculated in polynomial time instead of searching in exponential weight space using heuristics to get sub-optimal settings. We also demonstrate that our approach can be used to solve classification problems.", "num_citations": "20\n", "authors": ["317"]}
{"title": "Can automated program repair refine fault localization? a unified debugging approach\n", "abstract": " A large body of research efforts have been dedicated to automated software debugging, including both automated fault localization and program repair. However, existing fault localization techniques have limited effectiveness on real-world software systems while even the most advanced program repair techniques can only fix a small ratio of real-world bugs. Although fault localization and program repair are inherently connected, their only existing connection in the literature is that program repair techniques usually use off-the-shelf fault localization techniques (eg, Ochiai) to determine the potential candidate statements/elements for patching. In this work, we propose the unified debugging approach to unify the two areas in the other direction for the first time, ie, can program repair in turn help with fault localization? In this way, we not only open a new dimension for more powerful fault localization, but also extend\u00a0\u2026", "num_citations": "19\n", "authors": ["317"]}
{"title": "Compiler bug isolation via effective witness test program generation\n", "abstract": " Compiler bugs are extremely harmful, but are notoriously difficult to debug because compiler bugs usually produce few debugging information. Given a bug-triggering test program for a compiler, hundreds of compiler files are usually involved during compilation, and thus are suspect buggy files. Although there are lots of automated bug isolation techniques, they are not applicable to compilers due to the scalability or effectiveness problem. To solve this problem, in this paper, we transform the compiler bug isolation problem into a search problem, ie, searching for a set of effective witness test programs that are able to eliminate innocent compiler files from suspects. Based on this intuition, we propose an automated compiler bug isolation technique, DiWi, which (1) proposes a heuristic-based search strategy to generate such a set of effective witness test programs via applying our designed witnessing mutation rules to\u00a0\u2026", "num_citations": "19\n", "authors": ["317"]}
{"title": "A biting\u2010down approach to hierarchical decomposition of object\u2010oriented systems based on structure analysis\n", "abstract": " System decomposition has been widely viewed as an effective means to facilitate the comprehension of complex software systems and/or capture potentially reusable components in them. In fact, various approaches to system decomposition have been intensively documented in the literature. However, during the process of system decomposition, only a few of them can also capture the target system's hierarchical organization structure, which is essential when the target system is very complex. In this paper, we present a biting\u2010down approach to hierarchical decomposition of object\u2010oriented systems. Compared with the previous hierarchical approaches, the distinct features of this approach are as follows. First, our approach does not rely on agglomeration, and thus can avoid some unnecessary calculations. Second, our approach does not require merging nodes when performing high\u2010level decomposition, and\u00a0\u2026", "num_citations": "18\n", "authors": ["317"]}
{"title": "Shortening retrieval sequences in browsing-based component retrieval using information entropy\n", "abstract": " Reuse repositories are an essential element in component-based software development (CBSD). Querying-based retrieval and browsing-based retrieval are two main retrieval mechanisms provided in real world reuse repositories, especially web-based repositories. Although browsing-based retrieval is superior to querying-based retrieval in some aspects, the tedious retrieval process is its main drawback, because the browsing-based component retrieval usually involves long retrieval sequences. In this paper, we propose a novel approach to shorten the retrieval sequences in browsing-based component retrieval using information entropy. The basic idea of our approach is to build a navigation model by ranking the features into a tree structure using the components\u2019 indexing information. According to our experimental results on real data, our approach can effectively shorten the average length of retrieval\u00a0\u2026", "num_citations": "18\n", "authors": ["317"]}
{"title": "\u57fa\u4e8e\u6709\u5411\u5e26\u6743\u56fe\u8fed\u4ee3\u7684\u9762\u5411\u5bf9\u8c61\u7cfb\u7edf\u5206\u89e3\u65b9\u6cd5\n", "abstract": " \u9488\u5bf9\u5982\u4f55\u4ece\u73b0\u5b58\u7684\u7cfb\u7edf\u4e2d\u63d0\u53d6\u6784\u4ef6\u7684\u95ee\u9898, \u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u6709\u5411\u5e26\u6743\u56fe\u8fed\u4ee3\u5206\u6790\u7684\u9762\u5411\u5bf9\u8c61\u7cfb\u7edf\u5206\u89e3\u65b9\u6cd5. \u5b83\u5c06\u9762\u5411\u5bf9\u8c61\u7cfb\u7edf\u62bd\u8c61\u4e3a\u4e00\u4e2a\u6709\u5411\u5e26\u6743\u56fe, \u4f7f\u7528\u8fed\u4ee3\u7b97\u6cd5\u8003\u5bdf\u4e0d\u540c\u7c92\u5ea6\u7684\u5b50\u56fe\u7684\u72ec\u7acb\u6027, \u5e76\u9009\u62e9\u72ec\u7acb\u6027\u9ad8\u7684\u4f5c\u4e3a\u5019\u9009\u6784\u4ef6. \u5b9e\u9a8c\u7ed3\u679c\u8868\u660e, \u8be5\u65b9\u6cd5\u662f\u4e00\u79cd\u6709\u6548\u7684\u7cfb\u7edf\u5206\u89e3\u65b9\u6cd5, \u5728\u51c6\u786e\u6027\u4e0a\u6bd4\u73b0\u6709\u7cfb\u7edf\u5206\u89e3\u65b9\u6cd5\u6709\u6240\u63d0\u9ad8.", "num_citations": "18\n", "authors": ["317"]}
{"title": "\u57fa\u4e8e\u6784\u4ef6\u7684\u8f6f\u4ef6\u7248\u672c\u7ba1\u7406\u7cfb\u7edf\n", "abstract": " \u4f20\u7edf\u7684\u8f6f\u4ef6\u914d\u7f6e\u7ba1\u7406\u5efa\u7acb\u5728\u6587\u4ef6\u7248\u672c\u63a7\u5236\u7684\u57fa\u7840\u4e4b\u4e0a, \u73b0\u4ee3\u5927\u578b\u8f6f\u4ef6\u7cfb\u7edf\u7684\u5f00\u53d1\u8981\u6c42\u5728\u66f4\u5927\u7c92\u5ea6\u4e0a\u8fdb\u884c\u7248\u672c\u63a7\u5236. \u540c\u65f6, \u57fa\u4e8e\u6784\u4ef6\u7684\u8f6f\u4ef6\u5f00\u53d1\u662f\u5f53\u524d\u7684\u53d1\u5c55\u8d8b\u52bf, \u4e5f\u9700\u8981\u9002\u5e94\u5176\u7279\u70b9\u7684\u914d\u7f6e\u7ba1\u7406\u652f\u6301\u5de5\u5177. \u672c\u6587\u63d0\u51fa\u4e86\u57fa\u4e8e\u6784\u4ef6\u7684\u8f6f\u4ef6\u7248\u672c\u63a7\u5236\u6a21\u578b, \u91c7\u7528\u5c06\u7248\u672c\u63a7\u5236\u4e0e\u5e76\u53d1\u63a7\u5236\u5355\u4f4d\u5206\u79bb\u7684\u7b56\u7565, \u4ece\u800c\u5728\u5927\u7c92\u5ea6\u7248\u672c\u63a7\u5236\u7684\u540c\u65f6, \u4fdd\u8bc1\u4e86\u5e76\u884c\u5f00\u53d1\u7684\u7075\u6d3b\u6027.", "num_citations": "17\n", "authors": ["317"]}
{"title": "Adaptive fuzzy collaborative task assignment for heterogeneous multirobot systems\n", "abstract": " Heterogeneity in robot model mix is advantageous in emerging and future robotic applications. For instance, in a fully automated industrial package loading and unloading scenario, a variety uncertain types of packages need to be continuously sorted and loaded onto designated trucks. To handle the variation of tasks, multiple types of robots, or heterogeneous robots, are designed in the system. However, in such a collaborative system consisting of heterogeneous robots, ineffective task assignments often lead to bad collaboration and thus poor efficiency. To improve the robot collaboration, we herein define the collaborative task assignment problem and develop a fuzzy collaborative intelligence based algorithm to optimize the assignment plans. Specifically, the collaboration type, the collaboration matrix, and the assignment matrix are defined and the new algorithm for adaptive fuzzy collaborative task assignment\u00a0\u2026", "num_citations": "16\n", "authors": ["317"]}
{"title": "Supporting oracle construction via static analysis\n", "abstract": " In software testing, the program under test is usually executed with test inputs and checked against a test oracle, which is a mechanism to verify whether the program behaves as expected. Selecting the right oracle data to observe is crucial in test oracle construction. In the literature, researchers have proposed two dynamic approaches to oracle data selection by analyzing test execution information (e.g., variables' values or interaction information). However, collecting such information during program execution may incur extra cost. In this paper, we present the first static approach to oracle data selection, SODS (Static Oracle Data Selection). In particular, SODS first identifies the substitution relationships between candidate oracle data by constructing a probabilistic substitution graph based on the definition-use chains of the program under test, then estimates the fault-observing capability of each candidate oracle\u00a0\u2026", "num_citations": "15\n", "authors": ["317"]}
{"title": "Jtop: Managing JUnit Test Cases in Absence of Coverage Information\n", "abstract": " Test case management may make the testing process more efficient and thus accelerate software delivery. With the popularity of using JUnit for testing Java software, researchers have paid attention to techniques to manage JUnit test cases in regression testing of Java software. Typically, most existing test case management tools are based on the coverage information. However, coverage information may need extra efforts to obtain. In this paper, we present an Eclipse IDE plug-in (named Jtop) for managing JUnit test cases in absence of coverage information. Jtop statically analyzes the program under test and its corresponding JUnit test cases to perform the following management tasks: regression test case selection, test suite reduction and test case prioritization. Furthermore, Jtop also enables the programmer to manually manipulate test cases through a graphical user interface.", "num_citations": "12\n", "authors": ["317"]}
{"title": "ABC: a method of software architecture modeling in the whole lifecycle\n", "abstract": " With the continually-increasing capability of computer hardware and scale of computer software, the complexity of software is also continually increasing, and has manifest itself as one of the key factors that limit the significant improvement of software quality and productivity. The structural complexity, especially the high-level structural complexity, is considered as the most important complexity of a software system. How to control the high-level structural complexity in efficient and effective ways has become a critical issue for large-scale software development in the Internet computing environment, which is open, dynamic and constantly changing. To resolve this problem, this article extends the software architecture (SA) models-a kind of model aiming to control the high-level structural complexity on software designing-into the whole software lifecycle, and proposes an SA centric software development method, called ABC. The ABC method unifies the core artifacts in different software lifecycle phases into different kinds of SA models, and then the core activities of software development, deployment, maintenance and evolution are performed as the continual refinement, mapping, and transformation to these different kinds of SA models. In particular, this article aims to give a systematic introduction to the ABC method, and present some latest research outputs in collaborative feature modeling, runtime SA generation, and SA recovering.", "num_citations": "11\n", "authors": ["317"]}
{"title": "An experimental study of two graph analysis based component capture methods for object-oriented systems\n", "abstract": " The problem of how to partition a software system and thus capture its overall architecture and its constituent components has become a research focus in the community of software engineering. In the literature, many methods have been proposed for solving this problem. For example, both top-down and bottom-up methods based on analyzing the graph representation of software systems have been proposed. We report an experimental study of a top-down method and a bottom-up method. In our study, we focus on the capability of component capture, the capability of architecture recovery and the time complexity for the two methods. According to our results on two real world systems, the studied bottom-up method is superior to the studied top-down method in both aspects, although the time complexity of the bottom-up method remains a big concern for large systems.", "num_citations": "10\n", "authors": ["317"]}
{"title": "Setting attribute weights for k-NN based binary classification via quadratic programming\n", "abstract": " The k-Nearest Neighbour (k-NN) method is a typical lazy learning paradigm for solving classification problems. Although this method was originally proposed as a non-parameterised method, attribute weight setting has been commonly adopted to deal with irrelevant attributes. In this paper, we propose a new attribute weight setting method for k-NN based classifiers using quadratic programming, which is particularly suitable for binary classification problems. Our method formalises the attribute weight setting problem as a quadratic programming problem and exploits commercial software to calculate attribute weights. To evaluate our method, we carried out a series of experiments on six established data sets. Experiments show that our method is quite practical for various problems and can achieve a stable increase in accuracy over the standard k-NN method as well as a competitive performance. Another merit of\u00a0\u2026", "num_citations": "10\n", "authors": ["317"]}
{"title": "Understanding build issue resolution in practice: symptoms and fix patterns\n", "abstract": " Build systems are essential for modern software maintenance and development, while build failures occur frequently across software systems, inducing non-negligible costs in development activities. Build failure resolution is a challenging problem and multiple studies have demonstrated that developers spend non-trivial time in resolving encountered build failures; to relieve manual efforts, automated resolution techniques are emerging recently, which are promising but still limitedly effective. Understanding how build failures are resolved in practice can provide guidelines for both developers and researchers on build issue resolution. Therefore, this work presents a comprehensive study of fix patterns in practical build failures. Specifically, we study 1,080 build issues of three popular build systems Maven, Ant, and Gradle from Stack Overflow, construct a fine-granularity taxonomy of 50 categories regarding to the\u00a0\u2026", "num_citations": "9\n", "authors": ["317"]}
{"title": "Learning to detect relevant contexts and knowledge for response selection in retrieval-based dialogue systems\n", "abstract": " Recently, knowledge-grounded conversations in the open domain gain great attention from researchers. Existing works on retrieval-based dialogue systems have paid tremendous efforts to utilize neural networks to build a matching model, where all of the context and knowledge contents are used to match the response candidate with various representation methods.", "num_citations": "9\n", "authors": ["317"]}
{"title": "Early filtering of polluting method calls for mining temporal specifications\n", "abstract": " Temporal specifications can describe the legal call sequences of API libraries. With these specifications, verification tools can find defects in existing clients automatically. However, temporal specifications are often not provided due to the high cost of writing them manually or being out-of-date due to the rapid evolution of software. As API clients contain many usages of libraries including temporal rules, various approaches have been proposed to automatically mine temporal specifications from these clients. Typically, only a small part of the mined specifications are real specifications because the generated traces from clients are quite large and polluted. In this paper, we analyze four types of unwanted method calls that are not useful for mining, and we refer to these method calls as polluting method calls. As these method calls are not useful for mining, it is desirable to filter out them as early as possible. To address\u00a0\u2026", "num_citations": "9\n", "authors": ["317"]}
{"title": "Result Refinement in Web Services Retrieval Based on Multiple Instances Learning\n", "abstract": " Web services retrieval is a critical step for reusing existing services in the SOA paradigm. In the UDDI registry, traditional category-based approaches have been used to locate candidate services. However, these approaches usually achieve relatively low precision because some candidate Web Services in the result set cannot provide actually suitable operations for users. In this article, we present a new approach to improve this kind of category-based Web Services retrieval process that can refine the coarse matching results step by step. The refinement is based on the idea that operation specification is very important to service reuse. Therefore, a Web Service is investigated via multiple instances view in our approach, which indicates that a service is labeled as positive if and only if at least one operation provided by this service is usable to the user. Otherwise, it is labeled as negative. Experimental results\u00a0\u2026", "num_citations": "9\n", "authors": ["317"]}
{"title": "Enhancing defect prediction with static defect analysis\n", "abstract": " In the software development process, how to develop better software at lower cost has been a major issue of concern. One way that helps is to find more defects as early as possible, on which defect prediction can provide effective guidance. The most popular defect prediction technique is to build defect prediction models based on machine learning. To improve the performance of defect prediction model, selecting appropriate features is critical. On the other hand, static analysis is usually used in defect detection. As static defect analyzers detects defects by matching some well-defined\" defect patterns\", its result is useful for locating defects. However, defect prediction and static defect analysis are supposed to be two parallel areas due to the differences in research motivation, solution and granularity.", "num_citations": "8\n", "authors": ["317"]}
{"title": "Viewing use cases as active objects\n", "abstract": " In this paper, we propose an idea of viewing use cases as active objects in the analysis model. Based on the idea, we present a new approach to use case-driven object-oriented analysis. This approach gives a systematic and natural way of incorporating use cases into the analysis model, and an effective way of localizing the effect of requirement changes.", "num_citations": "8\n", "authors": ["317"]}
{"title": "Active control for wall drag reduction: Methods, mechanisms and performance\n", "abstract": " Active reducing the skin friction drag of vehicles (such as missiles, rockets, aircraft, high-speed train, submarines, etc.) during the navigation process can improve the respond speed effectively, save the energy consumption and increase the endurance time. As lots of active drag reduction methods were proposed for different applications, a review article is urgently needed to guide researchers to choose suitable methods for their pre-research. In this review, the generation mechanisms of skin friction drag under the action of disturbing the turbulent boundary layer are discussed, and the main active drag reduction methods are summarized. According to the actuation modes, we divided the active drag reduction methods into: drag reduction based on wall motion; drag reduction based on volume force control; drag reduction based on wall deformation and drag reduction based on micro vibration generated by\u00a0\u2026", "num_citations": "7\n", "authors": ["317"]}
{"title": "Tree-based convolution: A new neural architecture for sentence modeling\n", "abstract": " This paper proposes a new convolutional neural architecture based on treestructures, called the tree-based convolutional neural network (TBCNN). Two variants take advantage of constituency trees and dependency trees, respectively, to model sentences. Compared with traditional \u201cflat\u201d convolutional neural networks (CNNs), TBCNNs explore explicitly sentences\u2019 structural information; compared with recursive neural networks, TBCNNs have shorter propagation paths, enabling more effective feature learning and extraction. We evaluated our model in two widely applied benchmarks\u2014sentiment analysis and question classification. Our models outperformed most state-of-the-art results, including both existing neural networks and dedicated feature/rule engineering.", "num_citations": "7\n", "authors": ["317"]}
{"title": "Towards the uml evaluation using taxonomic patterns on meta-classes\n", "abstract": " In order to evaluate the design quality of the UML, understanding meta-classes is a key activity as they are the primary weapons by which the UML specifies the application domains. The paper introduces taxonomic patterns for clustering the UML meta-classes based on the observation of their evolution and fitness. The result sets of the patterns assist in finding the evidence of the concerns about the UML design and quality. It not only helps to find out problematic meta-classes, possible design defects of the UML and the inconsistency between the UML meta-models and the application domains; but also provides valuable information for guiding the development and evaluation of the UML. The work can be the basis of further quality analysis of the UML meta-models.", "num_citations": "7\n", "authors": ["317"]}
{"title": "Towards a user-perceived service availability metric\n", "abstract": " Web services availability has been regarded as one of the key properties for (critical) service-oriented applications. Based on analyzing the limitations of current metrics for \"User-perceived\" availability, we propose a service status based availability metric and a corresponding estimating approach. Experiments demonstrate that this metric and the corresponding estimation approach could get reasonable measurement on web services' availability.", "num_citations": "6\n", "authors": ["317"]}
{"title": "Requirements guided dynamic software clustering\n", "abstract": " In this paper, we propose a requirements guided dynamic approach to address software clustering -which aims at providing the logically meaningful and high-level decompositions of large and complex systems. In our approach, the hierarchical structure of functional requirements are constructed by a text document clustering technique named hierarchical agglomerative clustering (HAC) as a high-level skeleton to facilitate the further decomposition of source code through dynamic analysis. We also perform an experimental study based on a GNU system and present the quantitative and qualitative analysis of the experimental results.", "num_citations": "6\n", "authors": ["317"]}
{"title": "Extraction and visualization of architectural structure based on cross references among object files\n", "abstract": " Reverse engineering of legacy systems is a knowledge-intensive process to reconstruct the understanding of a system. A semi-automatic process that can extract architecture level structure from legacy systems is introduced in This work. Exact facts related to cross-references among ELF objects are extracted from files automatically, and then partitioned into hierarchical groups by close cooperation between domain experts and an assistant tool DEREF. By resolving the cross references among these groups, the architectural structure is reconstructed and then visualized using auto-layout techniques. A case study on three embedded operating system demonstrates that this process can be used to obtain a comprehensive understanding about legacy systems even without any a priori knowledge about its design.", "num_citations": "6\n", "authors": ["317"]}
{"title": "UML \u4e2d\u884d\u578b\u7684\u7cbe\u786e\u5b9a\u4e49\u4e0e\u5206\u6790\n", "abstract": " UML \u89c4\u8303\u5bf9\u4e8e\u884d\u578b\u8fd9\u79cd\u6269\u5c55\u673a\u5236\u63cf\u8ff0\u7684\u4e0d\u591f\u6e05\u6670\u548c\u4e25\u683c, \u5e38\u88ab\u7528\u6237\u548c\u7814\u7a76\u8005\u8bef\u7528, \u5e76\u4e14\u4e5f\u65e0\u6cd5\u5f88\u597d\u5730\u652f\u6301\u53ef\u6269\u5c55\u7684\u5efa\u6a21\u5de5\u5177\u7684\u5f00\u53d1. \u672c\u6587\u7cbe\u786e\u5730\u5b9a\u4e49 UML \u4e2d\u7684\u884d\u578b\u4ee5\u53ca\u884d\u578b\u4e4b\u95f4\u7684\u5173\u7cfb, \u5728\u6b64\u57fa\u7840\u4e0a\u5b9a\u4e49\u884d\u578b\u4e0e\u5143\u6a21\u578b\u4e4b\u95f4\u7684\u8f6c\u5316\u5e76\u63d0\u51fa\u8fd0\u7528\u884d\u578b\u7684\u6307\u5bfc\u89c4\u5219, \u4f7f\u5f97 UML \u884d\u578b\u7684\u4f7f\u7528\u8005\u80fd\u591f\u66f4\u6df1\u5165\u5730\u7406\u89e3\u8fd9\u79cd\u6269\u5c55\u673a\u5236, \u5e76\u4e3a\u652f\u6301\u884d\u578b\u7684\u5efa\u6a21\u5de5\u5177\u7684\u5f00\u53d1\u63d0\u4f9b\u53ef\u9760\u7684\u7406\u8bba\u57fa\u7840.", "num_citations": "6\n", "authors": ["317"]}
{"title": "Comments on A fast and efficient processor allocation scheme for mesh-connected multicomputers\n", "abstract": " In a recent paper by B.S. Yoo and C.R. Das (2002), the so-called stack-based allocation (SBA) algorithm is claimed to be, at worst, O(B/sup 2/) expensive. In this paper, we present an exception for which the time complexity of SBA is at least O(B/sup 3/). Furthermore, we point out the discrepancy in the complexity analysis.", "num_citations": "6\n", "authors": ["317"]}
{"title": "Achieving Flexibility in Off-the-Shelf Middleware Services Integration.\n", "abstract": " The development of component-based software engineering enables the construction of application servers by integrating reliable OTS middleware services. However it is difficult to achieve flexibility in conventional hard coding way. In this paper, we propose a flexible OTS middleware services integration framework to address this problem. In this framework, we define two kinds of modules: the middleware service contract module to represent the stable contract which specifies the abstract interaction logic between the application server and a kind of middleware services, and the middleware service implementation module to encapsulate the mutable implementation details of different OTS middleware services in a unified way. Additionally, we propose a module management mechanism to enable the application server to replace the OTS products at runtime via configuration. We implement the framework in a J2EE application server, and the evaluations show that our framework effectively reduces the cost and the time of maintaining and customizing the OTS middleware services-based application server.", "num_citations": "5\n", "authors": ["317"]}
{"title": "An objective-oriented approach to program comprehension using multiple information sources\n", "abstract": " Program comprehension is a key activity throughout software maintenance and reuse. The knowledge acquired through comprehending programs can guide engineers to perform various kinds of software maintenance and reuse tasks. The effective comprehension strategy and the associated efficient approach, as well as the sophisticated tool support, are the indispensable elements for an entire solution to program comprehension to reduce the high costs of this nontrivial activity. This paper presents an objective-oriented comprehension strategy, contrasting to the traditional comprehensive understanding strategy in the literature. It is a kind of on-demand understanding for specific tasks and more effective in practice. In addition, using multiple information sources to understand programs is proposed with the corresponding framework. From these two points of views, we propose a feature-oriented program\u00a0\u2026", "num_citations": "5\n", "authors": ["317"]}
{"title": "An experimental study of increasing diversity for case-based diagnosis\n", "abstract": " Increasing dversity for case-based reasoning (CBR) is an issue that has recently drawn the attention of researchers in the CBR field. Several diversification techniques have been proposed and discussed in the literature. However, whether and to what extent those techniques can bring about benefits to end-users remains in question. In this paper, we report an experiment in applying a diversification technique to a case-based diagnosis tool in a product maintenance domain. The results of this offer some evidence in support of diversification techniques.", "num_citations": "5\n", "authors": ["317"]}
{"title": "\u4e00\u4e2a\u53ef\u534a\u81ea\u52a8\u5316\u6269\u5c55\u7684\u9759\u6001\u4ee3\u7801\u7f3a\u9677\u5206\u6790\u5de5\u5177\n", "abstract": " \u672f\u5177\u6709\u4f7f\u7528\u7b80\u5355, \u67e5\u627e\u901f\u5ea6\u5feb\u7b49\u4f18\u70b9, \u662f\u8fd1\u5e74\u6765\u9759\u6001\u4ee3\u7801\u7f3a\u9677\u5206\u6790\u65b9\u6cd5\u4e2d\u53d1\u5c55\u6bd4\u8f83\u8fc5\u901f\u7684\u65b0\u6280\u672f. \u4f46\u662f\u76ee\u524d\u57fa\u4e8e\u8fd9\u79cd\u5206\u6790\u6280\u672f\u7684\u5927\u591a\u6570\u5de5\u5177\u5e76\u6ca1\u6709\u4e3a\u7528\u6237\u63d0\u4f9b\u8db3\u591f\u6613\u7528, \u9ad8\u6548\u7684\u6269\u5c55\u65b9\u5f0f\u4ee5\u6269\u5145\u5176\u7f3a\u9677\u68c0\u6d4b\u80fd\u529b. \u9488\u5bf9\u8fd9\u4e00\u95ee\u9898, \u4f5c\u8005\u63d0\u51fa\u4e86\u4e00\u4e2a \u201c\u53ef\u534a\u81ea\u52a8\u5316\u6269\u5c55\u201d \u7684\u4ee3\u7801\u7f3a\u9677\u9759\u6001\u5206\u6790\u65b9\u6cd5, \u8bbe\u8ba1\u5e76\u5b9e\u73b0\u4e86\u4e00\u4e2a\u652f\u6301\u8be5\u65b9\u6cd5\u7684\u5de5\u5177\u2014\u2014\u2014CODA (COdeDefectAnalysistool). CODA \u4e0d\u4ec5\u63d0\u4f9b\u4e86 \u201c\u7f3a\u9677\u6a21\u5f0f\u63cf\u8ff0\u6a21\u677f\u201d \u4ee5\u5e2e\u52a9\u7528\u6237\u5feb\u901f\u5730\u624b\u5de5\u6269\u5145\u7f3a\u9677\u6a21\u5f0f\u5e93, \u8fd8\u80fd\u5728\u7528\u6237\u7684\u6307\u5bfc\u4e0b\u534a\u81ea\u52a8\u5316\u5730\u6316\u6398\u65b0\u7f3a\u9677\u6a21\u5f0f\u4ee5\u5feb\u901f\u6269\u5145\u5176\u7f3a\u9677\u6a21\u5f0f\u5e93. \u4e00\u65e6\u65b0\u7684\u7f3a\u9677\u6a21\u5f0f\u88ab\u5b9a\u4e49\u5e76\u6dfb\u52a0\u81f3\u7f3a\u9677\u6a21\u5f0f\u5e93\u4e2d, CODA \u4fbf\u80fd\u81ea\u52a8\u5177\u6709\u9488\u5bf9\u8be5\u7c7b\u7f3a\u9677\u7684\u68c0\u6d4b\u80fd\u529b.", "num_citations": "4\n", "authors": ["317"]}
{"title": "Refining component description by leveraging user query logs\n", "abstract": " How to help reusers retrieve components efficiently and conveniently is critical to the success of the component-based software development (CBSD). In the literature, many research efforts have been devoted to the improvement of component retrieval mechanisms. Although various retrieval methods have been proposed, nowadays retrieving software component by the description text is still prevalent in most real-world scenarios. Therefore, the quality of the component description text is vital for the component retrieval. Unfortunately, the descriptions of components often contain improper or even noisy information which could deteriorate the effectiveness of the retrieval mechanism. To alleviate the problem, in this paper, we propose an approach which can improve the component description by leveraging user query logs. The key idea of our approach is to refine the description of a component by extracting proper\u00a0\u2026", "num_citations": "4\n", "authors": ["317"]}
{"title": "\u57fa\u4e8e\u8bed\u6cd5\u4e0e\u8bed\u4e49\u5206\u6790\u7684\u4ee3\u7801\u641c\u7d22\u7ed3\u679c\u4f18\u5316\n", "abstract": " \u6458 \u8981 \u901a\u8fc7\u793a\u4f8b\u4ee3\u7801\u5b66\u4e60\u7b80\u5355\u7b97\u6cd5\u7684\u5b9e\u73b0\u548c\u5177\u4f53 API \u7684\u4f7f\u7528\u65b9\u5f0f\u662f\u7a0b\u5e8f\u5f00\u53d1\u4eba\u5458\u5728\u8f6f\u4ef6\u5f00\u53d1\u4e2d\u8fdb\u884c\u8f6f\u4ef6\u590d\u7528\u7684\u9ad8\u6548\u624b\u6bb5, \u4e5f\u662f\u4f7f\u7528\u4ee3\u7801\u641c\u7d22\u5f15\u64ce\u7684\u4e3b\u8981\u76ee\u7684. \u4ee3\u7801\u641c\u7d22\u5f15\u64ce\u4ece\u7f51\u9875\u641c\u7d22\u6280\u672f\u53d1\u5c55\u800c\u6765, \u63d0\u4f9b\u5bf9\u7f51\u7edc\u4e0a\u6e90\u4ee3\u7801\u8d44\u6e90\u7684\u68c0\u7d22\u529f\u80fd, \u80fd\u591f\u6709\u6548\u5b9a\u4f4f\u4e0e\u641c\u7d22\u5185\u5bb9\u76f8\u5173\u7684\u4ee3\u7801, \u4e3a\u7a0b\u5e8f\u5f00\u53d1\u4eba\u5458\u63d0\u4f9b\u5e2e\u52a9. \u4f46\u73b0\u6709\u7684\u4ee3\u7801\u641c\u7d22\u5f15\u64ce\u6ca1\u6709\u5728\u641c\u7d22\u7ed3\u679c\u4e2d\u533a\u522b API \u7684\u5b9e\u73b0\u4ee3\u7801\u4e0e\u4f7f\u7528\u4ee3\u7801, \u641c\u7d22\u7ed3\u679c\u5b58\u5728\u5197\u4f59, \u5bfc\u81f4\u7528\u6237\u65e0\u6cd5\u5feb\u901f\u6709\u6548\u5730\u627e\u5230\u63d0\u4f9b\u6709\u7528\u4fe1\u606f\u7684\u4ee3\u7801\u7247\u6bb5. \u4e3a\u4e86\u4f7f\u7528\u6237\u66f4\u597d\u66f4\u5feb\u5730\u627e\u5230\u4ee3\u7801\u641c\u7d22\u76ee\u6807, \u9610\u8ff0\u4e86\u5e94\u7528\u8bed\u6cd5\u4e0e\u8bed\u4e49\u5206\u6790\u6280\u672f\u4ece \u533a\u5206 API \u5b9e\u73b0\u4ee3\u7801\u548c\u4f7f\u7528\u4ee3\u7801, \u76f8\u4f3c\u4ee3\u7801\u805a\u7c7b, \u641c\u7d22\u7ed3\u679c\u6458\u8981 3 \u4e2a\u65b9\u9762\u5bf9\u4ee3\u7801\u641c\u7d22\u7ed3\u679c\u8fdb\u884c\u4f18\u5316\u7684\u65b9\u6cd5, \u7ed9\u51fa\u4e86\u4e00\u4e2a\u4ee3\u7801\u641c\u7d22\u5f15\u64ce\u7684\u5b9e\u73b0, \u5e76\u5728\u5b9e\u4f8b\u7814\u7a76\u4e2d\u5c55\u793a\u4e86\u8be5\u65b9\u6cd5\u7684\u6709\u6548\u6027.", "num_citations": "4\n", "authors": ["317"]}
{"title": "\u4e00\u79cd\u57fa\u4e8e P2P \u652f\u6301\u68c0\u7d22\u6761\u4ef6\u91cd\u6784\u7684\u6784\u4ef6\u5e93\u4e92\u8054\u6280\u672f\n", "abstract": " \u8f6f\u4ef6\u590d\u7528\u662f\u89e3\u51b3\u8f6f\u4ef6\u5371\u673a\u7684\u6709\u6548\u9014\u5f84. \u968f\u7740\u8f6f\u4ef6\u590d\u7528\u6280\u672f\u548c\u7f51\u7edc\u6280\u672f\u7684\u53d1\u5c55, \u5728 Internet \u4e0a\u51fa\u73b0\u4e86\u8d8a\u6765\u8d8a\u591a\u7684\u8f6f\u4ef6\u6784\u4ef6\u5e93. \u590d\u7528\u8005\u9700\u8981\u7684\u6784\u4ef6\u5f80\u5f80\u5206\u6563\u5728\u591a\u4e2a\u6784\u4ef6\u5e93\u4e2d, \u800c\u5404\u4e2a\u5e93\u4e2d\u6784\u4ef6\u7684\u63cf\u8ff0\u65b9\u5f0f\u4e5f\u5404\u4e0d\u76f8\u540c; \u8fd9\u7ed9\u590d\u7528\u8005\u83b7\u53d6\u6784\u4ef6\u5e26\u6765\u4e86\u4e00\u5b9a\u7684\u56f0\u96be. \u56e0\u6b64, \u9700\u8981\u6709\u4e00\u79cd\u6709\u6548\u7684\u673a\u5236\u6765\u5e2e\u52a9\u4ed6\u4eec\u5728\u591a\u4e2a\u6784\u4ef6\u5e93\u4e2d\u83b7\u53d6\u6784\u4ef6. \u63d0\u51fa\u4e00\u79cd\u6784\u4ef6\u5e93\u4e92\u8054\u6280\u672f DCLITTA \u4ee5\u652f\u6301\u5728\u5206\u5e03\u7684\u6784\u4ef6\u5e93\u4e4b\u95f4\u5b9e\u73b0\u8d44\u6e90\u5171\u4eab, \u5e76\u4e3a\u590d\u7528\u8005\u63d0\u4f9b\u4e86 \u201c\u900f\u660e\u201d \u7684\u68c0\u7d22\u673a\u5236. DCLITTA \u91c7\u7528\u5bf9\u7b49\u7f51\u7edc (P2P) \u4f53\u7cfb\u7ed3\u6784\u5c06\u5404\u4e2a\u72ec\u7acb\u7684\u6784\u4ef6\u5e93\u7ec4\u7ec7\u5728\u4e00\u8d77. \u540c\u65f6, \u9488\u5bf9\u6784\u4ef6\u5e93\u95f4\u6784\u4ef6\u63cf\u8ff0\u6a21\u578b\u7684\u5dee\u5f02, DCLITTA \u901a\u8fc7\u81ea\u52a8\u5730\u5c06\u590d\u7528\u8005\u7684\u68c0\u7d22\u8bf7\u6c42\u8fdb\u884c\u91cd\u6784\u6765\u6539\u5584\u68c0\u7d22\u7684\u6548\u679c. \u57fa\u4e8e\u8be5\u4e92\u8054\u6280\u672f, \u5df2\u8bbe\u8ba1\u5b9e\u73b0\u4e86\u76f8\u5e94\u7684\u652f\u6301\u7cfb\u7edf, \u5e76\u5b9e\u9645\u5e94\u7528\u4e8e\u5317\u4eac, \u4e0a\u6d77\u7b49\u8f6f\u4ef6\u56ed\u7684\u6784\u4ef6\u5e93\u4e2d.", "num_citations": "4\n", "authors": ["317"]}
{"title": "\u57fa\u4e8e\u914d\u7f6e\u7ba1\u7406\u7cfb\u7edf\u7684\u8f6f\u4ef6\u8fc7\u7a0b\u7ba1\u7406\u673a\u5236\u7814\u7a76\n", "abstract": " Sohware processes are a group of relating activities in the lifecycle of software. Process man-agement is the central technique in software developing and maintaining. Based on configuration man-agement system that manages tht: resource of an enterprise, process management will be more effective. This paper discusses the issues of process managementtask, rule and role. Based on the discussions, we makemanagementin configuration management systems, such assome study on mechanisms of computer aided", "num_citations": "4\n", "authors": ["317"]}
{"title": "Can Automated Program Repair Refine Fault Localization?\n", "abstract": " Software bugs are prevalent in modern software systems and notoriously hard to debug manually. Therefore, a large body of research efforts have been dedicated to automated software debugging, including both automated fault localization and program repair. However, the existing fault localization techniques are usually ineffective on real-world software systems while even the most advanced program repair techniques can only fix a small ratio of real-world bugs. Although fault localization and program repair are inherently connected, we observe that in the literature their only connection is that program repair techniques usually use off-the-shelf fault localization techniques (e.g., Ochiai) to determine the potential candidate statements/elements for patching. In this work, we explore their connection in the other direction, i.e., can program repair in turn help with fault localization? In this way,we not only open a new dimension for more powerful fault localization, but also extend the application scope of program repair to all possible bugs (not only the bugs that can be directly automatically fixed).We have designed ProFL, a simplistic approach using patch-execution results (from program repair) as the feedback information for fault localization. The experimental results on the widely used Defects4J benchmark show that the basic ProFL can already localize 161 of the 395 studied bugs within Top-1, while state-of-the-art spectrum and mutation based fault localization techniques at most localize 117 within Top-1. We also demonstrate ProFL's effectiveness under different settings. Lastly, we show that ProFL can further boost state-of-the-art fault\u00a0\u2026", "num_citations": "3\n", "authors": ["317"]}
{"title": "Evolution of incommensurate superstructure and electronic structure with Pb substitution in (Bi2\u2212 x Pb x) Sr2CaCu2O8+ \u03b4 superconductors\n", "abstract": " High-quality Bi 2\u2212 x Pb x Sr 2 CaCu 2 O 8+ \u03b4 (Bi2212) single crystals have been successfully grown by the traveling solvent floating zone technique with a wide range of Pb substitution (x= 0\u20130.8). The samples are characterized by transmission electron microscope (TEM) and measured by high resolution laser-based angle-resolved photoemission spectroscopy (ARPES) with different photon energies. A systematic evolution of the electronic structure and superstructure with Pb substitution has been revealed for the first time. The superstructure shows a significant change with Pb substitution and the incommensurate modulation vector () decreases with increasing Pb substitution. In the meantime, the superstructure intensity from ARPES measurements also decreases dramatically with increasing Pb concentration. The superstructure in Bi2212 can be effectively suppressed by Pb substitution and it nearly\u00a0\u2026", "num_citations": "3\n", "authors": ["317"]}
{"title": "ABC: \u4e00\u79cd\u5168\u751f\u547d\u5468\u671f\u8f6f\u4ef6\u4f53\u7cfb\u7ed3\u6784\u5efa\u6a21\u65b9\u6cd5\n", "abstract": " \u968f\u7740\u8ba1\u7b97\u673a\u786c\u4ef6\u80fd\u529b\u7684\u5feb\u901f\u589e\u957f\u548c\u8f6f\u4ef6\u5e94\u7528\u89c4\u6a21\u7684\u4e0d\u65ad\u6269\u5927, \u8f6f\u4ef6\u7684\u590d\u6742\u6027\u4e5f\u5728\u6301\u7eed\u589e\u957f, \u5e76\u59cb\u7ec8\u5236\u7ea6\u7740\u8f6f\u4ef6\u5f00\u53d1\u6548\u7387\u548c\u8d28\u91cf\u7684\u6709\u6548\u63d0\u5347. \u8f6f\u4ef6\u7684\u7ed3\u6784\u590d\u6742\u6027, \u5c24\u5176\u662f\u9ad8\u5c42\u7ed3\u6784\u7684\u590d\u6742\u6027, \u662f\u8f6f\u4ef6\u590d\u6742\u6027\u7684\u4e00\u79cd\u91cd\u8981\u8868\u73b0. \u5982\u4f55\u5b9e\u73b0\u5bf9\u8f6f\u4ef6\u9ad8\u5c42\u7ed3\u6784\u590d\u6742\u6027\u7684\u6709\u6548\u63a7\u5236, \u662f\u5f53\u524d\u5f00\u653e, \u52a8\u6001, \u96be\u63a7\u7684\u7f51\u7edc\u73af\u5883\u4e0b\u5927\u89c4\u6a21\u8f6f\u4ef6\u7cfb\u7edf\u5f00\u53d1\u4e0e\u6f14\u5316\u6240\u9762\u4e34\u7684\u4e3b\u8981\u95ee\u9898. \u9488\u5bf9\u8fd9\u4e2a\u95ee\u9898, \u6211\u4eec\u5c06\u8bbe\u8ba1\u9636\u6bb5\u9ad8\u5c42\u7ed3\u6784\u590d\u6742\u6027\u7684\u63a7\u5236\u6a21\u578b\u2015\u8f6f\u4ef6\u4f53\u7cfb\u7ed3\u6784\u6a21\u578b\u2015\u6269\u5c55\u5230\u6574\u4e2a\u8f6f\u4ef6\u751f\u547d\u5468\u671f, \u63d0\u51fa\u4e86\u4e00\u79cd\u4ee5\u4f53\u7cfb\u7ed3\u6784\u4e3a\u4e2d\u5fc3\u7684\u8f6f\u4ef6\u5f00\u53d1\u65b9\u6cd5\u2015ABC. \u8be5\u65b9\u6cd5\u5c06\u8f6f\u4ef6\u751f\u547d\u5468\u671f\u5404\u9636\u6bb5\u7684\u6838\u5fc3\u5236\u54c1\u4e0e\u6d3b\u52a8, \u7edf\u4e00\u5230\u8f6f\u4ef6\u4f53\u7cfb\u7ed3\u6784\u6a21\u578b\u53ca\u5bf9\u5176\u8fde\u7eed\u8fed\u4ee3\u7684\u7ec6\u5316, \u6620\u5c04\u548c\u8f6c\u6362, \u5b9e\u73b0\u5bf9\u8f6f\u4ef6\u9ad8\u5c42\u7ed3\u6784\u590d\u6742\u6027\u7684\u4e00\u81f4, \u7075\u6d3b, \u7cfb\u7edf\u5316\u7684\u5efa\u6a21\u548c\u7ba1\u7406. \u672c\u6587\u65e8\u5728\u7cfb\u7edf\u6027\u5730\u603b\u7ed3 ABC \u65b9\u6cd5\u5728\u8f6f\u4ef6\u4f53\u7cfb\u7ed3\u6784\u5efa\u6a21\u65b9\u9762\u7684\u6210\u679c, \u5e76\u91cd\u70b9\u4ecb\u7ecd\u8fd1\u51e0\u5e74\u5728\u534f\u540c\u5f0f\u7279\u5f81\u5efa\u6a21, \u8fd0\u884c\u65f6\u4f53\u7cfb\u7ed3\u6784\u751f\u6210, \u4f53\u7cfb\u7ed3\u6784\u9006\u5411\u6062\u590d\u4e0e\u5efa\u6a21\u7b49\u65b9\u9762\u53d6\u5f97\u7684\u65b0\u8fdb\u5c55.", "num_citations": "3\n", "authors": ["317"]}
{"title": "\u5d4c\u5165\u5f0f\u7cfb\u7edf\u8f6f\u4ef6\u6d4b\u8bd5\n", "abstract": " \u4e13\u9898 \u7b2c 8 \u5377 \u7b2c 2 \u671f 2012 \u5e74 2 \u6708 async (\u4ee3\u8868\u5f02\u6b65) \u6807\u8bc6\u7684\u5b50\u4f8b\u7a0b\u4ee5\u5f02\u6b65\u65b9\u5f0f\u54cd\u5e94\u8fd9\u4e2a\u4e2d\u65ad\u4e8b\u4ef6. \u8fd9\u79cd\u5b50\u7a0b\u5e8f\u53eb\u505a\u4e8b\u4ef6\u5904\u7406\u7a0b\u5e8f. \u4e3a\u4e86\u4fdd\u8bc1\u9ad8\u54cd\u5e94\u80fd\u529b, \u4e8b\u4ef6\u5904\u7406\u7a0b\u5e8f\u901a\u5e38\u4f1a\u8bbe\u8ba1\u6210\u6bd4\u8f83\u8f7b\u91cf\u7ea7\u7684. \u5728\u4e2d\u65ad\u89e6\u53d1\u590d\u6742\u7684\u8ba1\u7b97\u65f6, \u54cd\u5e94\u8fd9\u4e2a\u4e2d\u65ad\u7684\u4e8b\u4ef6\u5904\u7406\u7a0b\u5e8f\u4f1a\u884d\u751f (post) \u989d\u5916\u7684\u4efb\u52a1\u6765\u8fdb\u884c\u590d\u6742\u7684\u8ba1\u7b97. \u4e0e\u4f20\u7edf\u7684\u51fd\u6570\u8c03\u7528/\u8fd4\u56de\u7684\u8bed\u4e49\u4e0d\u540c, \u4efb\u52a1\u5e76\u4e0d\u662f\u5728\u5b83\u884d\u751f\u65f6\u5c31\u7acb\u523b\u6267\u884c\u7684. \u76f8\u53cd, \u884d\u751f\u673a\u5236\u53ea\u662f\u7b80\u5355\u5730\u5c06\u4efb\u52a1\u6dfb\u52a0\u5230\u4efb\u52a1\u961f\u5217\u7684\u672b\u5c3e, \u5e76\u7acb\u5373\u5c06\u63a7\u5236\u8fd4\u56de\u7ed9\u8be5\u4e8b\u4ef6\u5904\u7406\u7a0b\u5e8f. \u76f4\u5230\u6ca1\u6709\u672a\u5b8c\u6210\u7684\u4e2d\u65ad\u65f6, \u88ab\u884d\u751f\u4efb\u52a1\u624d\u5f00\u59cb\u6267\u884c. \u53e6\u5916, \u884d\u751f\u7684\u4efb\u52a1\u662f\u57fa\u4e8e\u884d\u751f\u7684\u987a\u5e8f\u4f9d\u6b21\u88ab\u6267\u884c\u7684. \u4e00\u4e2a\u4e8b\u4ef6\u5904\u7406\u7a0b\u5e8f\u53ef\u62a2\u5360\u4e00\u4e2a\u4efb\u52a1\u7684\u6267\u884c. \u5728\u4e8b\u4ef6\u5904\u7406\u7a0b\u5e8f\u5b8c\u6210\u4e4b\u540e, \u88ab\u62a2\u5360\u7684\u4efb\u52a1\u7684\u6267\u884c\u624d\u5f97\u4ee5\u6062\u590d. \u56fe 1 \u6a21\u5757\u6539\u7f16\u81ea TinyOS \u7cfb\u7edf\u4e2d\u7684 OscilloscopeM \u6a21\u5757 (\u7528 OM \u6765\u8868\u793a). OM \u53ef\u7528\u4e8e\u63a7\u5236\u5ba4\u5185\u73af\u5883\u6761\u4ef6. \u5728\u56fe\u4e2d, \u6211\u4eec\u7f29\u51cf\u4e86\u5176\u4e2d\u7684\u4ee3\u7801, \u4ee5\u4fbf\u89e3\u91ca\u4e00\u4e2a nesC \u6545\u969c. \u5728 nesC \u4e2d\u5b9e\u73b0\u7a0b\u5e8f\u903b\u8f91\u7684\u6a21\u5757\u53eb\u505a\u7ec4\u4ef6. \u5728# 10 \u548c# 12 \u884c, OM \u58f0\u660e\u4e86\u4e24\u4e2a\u5171\u4eab\u53d8\u91cf packetReadingNumber \u548c msg, \u5728# 13 \u548c# 38 \u884c\u4e4b\u95f4\u5b9a\u4e49\u4e86\u56db\u4e2a\u4efb\u52a1 task1, task2, task3, task4, \u5728# 39 \u548c# 59 \u884c\u4e4b\u95f4\u5b9e\u73b0\u4e86\u4e09\u4e2a\u4e8b\u4ef6\u5904\u7406\u7a0b\u5e8f PhotoSensor. dataReady, SendMsg. sendDone, TempSensor. dataReady. OM \u8bf7\u6c42\u5e95\u5c42\u786c\u4ef6\u5e73\u53f0\u6765\u91c7\u96c6\u7167\u7247\u548c\u6e29\u5ea6\u4f20\u611f\u5668\u7684\u8bfb\u6570, \u628a\u8bfb\u5165\u7684\u6570\u636e\u7f6e\u4e8e\u4e00\u4e2a\u7f13\u51b2\u533a, \u7136\u540e\u5904\u7406\u7f13\u51b2\u533a\u7684\u6570\u636e, \u5e76\u628a\u5904\u7406\u540e\u7684\u7ed3\u679c\u53d1\u5230\u4e00\u4e2a\u6307\u5b9a\u7684\u57fa\u7ad9 (base station).", "num_citations": "3\n", "authors": ["317"]}
{"title": "\u6784\u4ef6\u63d0\u53d6\u6280\u672f\u7efc\u8ff0\n", "abstract": " \u6458 \u8981 \u968f\u7740\u8f6f\u4ef6\u6784\u4ef6\u6280\u672f\u7684\u53d1\u5c55, \u4f5c\u4e3a\u4e00\u79cd\u6709\u6548\u7684\u6784\u4ef6\u83b7\u53d6\u624b\u6bb5, \u4ece\u73b0\u6709\u7cfb\u7edf\u4e2d\u63d0\u53d6\u6784\u4ef6\u56e0\u5176\u6210\u672c\u4e0e\u6548\u7387\u4f18\u52bf\u800c\u6210\u4e3a\u8f6f\u4ef6\u590d\u7528\u4e0e\u7a0b\u5e8f\u7406\u89e3\u9886\u57df\u7684\u91cd\u8981\u4ea4\u53c9\u7814\u7a76\u9886\u57df. \u9488\u5bf9\u6784\u4ef6\u63d0\u53d6\u7684\u57fa\u672c\u6b65\u9aa4, \u672c\u6587\u4ece\u7cfb\u7edf\u5206\u89e3\u548c\u5ea6\u91cf\u4e24\u4e2a\u65b9\u9762\u5bf9\u6784\u4ef6\u63d0\u53d6\u7684\u7814\u7a76\u73b0\u72b6\u8fdb\u884c\u4e86\u7efc\u8ff0. \u5728\u6b64\u57fa\u7840\u4e0a\u672c\u6587\u8fd8\u4ecb\u7ecd\u4e86\u51e0\u4e2a\u5178\u578b\u7684\u6784\u4ef6\u63d0\u53d6\u7cfb\u7edf, \u5e76\u5bf9\u6784\u4ef6\u63d0\u53d6\u7684\u7814\u7a76\u524d\u666f\u4e0e\u7814", "num_citations": "3\n", "authors": ["317"]}
{"title": "\u8f6f\u4ef6\u53d8\u5316\u7ba1\u7406\u7cfb\u7edf\u7814\u7a76\n", "abstract": " \u8f6f\u4ef6\u53d8\u5316\u7ba1\u7406\u662f\u8f6f\u4ef6\u5f00\u53d1\u7ba1\u7406\u7684\u4e00\u4e2a\u5173\u952e\u56e0\u7d20.\u672c\u6587\u7814\u7a76\u4e86\u8f6f\u4ef6\u53d8\u5316\u7ba1\u7406\u7684\u76ee\u6807,\u4e3b\u8981\u5185\u5bb9\u76f8\u5e94\u7684\u652f\u6301\u7cfb\u7edf,\u63d0\u51fa\u4e0e\u914d\u7f6e\u7ba1\u7406\u548c\u8fc7\u7a0b\u7ba1\u7406\u7cfb\u7edf\u76f8\u7ed3\u5408\u7684\u8f6f\u4ef6\u53d8\u5316\u7ba1\u7406\u7cfb\u7edf\u7ed3\u6784,\u5e76\u4ecb\u7ecd\u4e00\u4e2a\u5b9e\u9645\u8f6f\u4ef6\u53d8\u5316\u7ba1\u7406\u7cfb\u7edf\u7684\u5b9e\u73b0.", "num_citations": "3\n", "authors": ["317"]}
{"title": "How Does Regression Test Selection Affect Program Repair? An Extensive Study on 2 Million Patches\n", "abstract": " APR techniques can be extremely time consuming since (1) a large number of patches can be generated for a given bug, and (2) each patch needs to be executed on the original tests to ensure its correctness. In the literature, various techniques (e.g., based on learning, mining, and constraint solving) have been proposed/studied to reduce the number of patches. However, there is limited study on the impact of test selection for each patch (e.g., only the tests affected by the patch need to be executed as the other tests would keep the same outcomes and can be skipped), and few APR systems actually apply test selection. Therefore, this paper conducts the first extensive study to investigate the impact of Regression Test Selection (RTS) on APR. More specifically, we implemented widely-used RTS techniques at different levels for 12 state-of-the-art APR systems with over 2M patches. Our study reveals various practical guidelines for future APR, including: (1) the number of patches widely used for measuring APR efficiency can incur skewed conclusions, and the use of inconsistent RTS configurations can further skew the conclusion; (2) all studied RTS techniques can substantially improve APR efficiency and should be considered in future APR work; (3) method- and statement-level RTS outperform class-level RTS substantially, and should be preferred; (4) RTS techniques can substantially outperform state-of-the-art test prioritization techniques for APR, and combining them can further improve APR efficiency; and (5) traditional regression test prioritization widely studied in regression testing performs even better than APR-specific test prioritization\u00a0\u2026", "num_citations": "2\n", "authors": ["317"]}
{"title": "A Study of Bug Resolution Characteristics in Popular Programming Languages\n", "abstract": " Bug resolution is an essential part of software development. The impact of programming language on bug resolution has been a topic of much debate. Taking Python as an example, some hold the view that bugs in the language are easy to handle because its code is easy to read and understand, while others believe that the absence of static typing leads to more bug-handling effort. This paper presents the first large-scale study that investigates the connection between programming language and bug resolution characteristics. It follows the recent trend of empirical scientific reformulation of long-standing, but hitherto anecdotal, `great debates' about the influence of programming language and paradigm on software engineering concerns. We analyse bug resolution data from over 70 million SLOC drawn from 3 million commits to 600 GitHub projects in 10 languages. The results suggest that statistically significant\u00a0\u2026", "num_citations": "2\n", "authors": ["317"]}
{"title": "Petrological Investigations and Zircon U\u2010Pb Dating of High Pressure Felsic Granulites from the Yushugou Complex, South Tianshan, China\n", "abstract": " As a window of insight into the lower crust, high pressure granulite has received much attention since last decade. Yushugou high pressure granulite\u2010peridotite Complex was located in the northeast margin of Southern Tianshan, NW China. Previous ideas agreed that the peridotite unit in Yushugou, combined with the ultramafic rocks in Tonghuashan and Liuhuangshan, represent an ophiolite belt. However, the metamorphic evolution and tectonic mechanism of the Yushugou high pressure (HP) granulite remain controversial. Petrological investigations and phase equilibrium modelling for two representative felsic granulite samples suggest two stages metamorphism of the rocks in Yushugou Complex. Granulite facies metamorphism (Stage I) with P\u2010T conditions of 9.8\u201310.4 kbar at 895\u2013920\u00b0C was recorded by the porphyroblastic garnet core; HP granulite facies metamorphism (Stage II) shows P\u2010T conditions of 13\u00a0\u2026", "num_citations": "2\n", "authors": ["317"]}
{"title": "PathART: Path-Sensitive Adaptive Random Testing\n", "abstract": " As test data widely spreading on the input domain may not thoroughly test the program's logic, in this paper, we propose an approach to generating test data widely spreading on a program's execution paths. In particular, we analyze execution paths of the program, distill constraints for executing the paths, calculate the path distance between test data according to their satisfaction for paths' constraints, and then generate test data far away from each other based on their path distance. The experimental results show that our approach significantly reduces the number of test data generated before the first fault is found.", "num_citations": "2\n", "authors": ["317"]}
{"title": "\u5b57\u7b26\u4e32\u5206\u6790\u7814\u7a76\u8fdb\u5c55\n", "abstract": " \u968f\u7740\u8f6f\u4ef6\u5e94\u7528\u8303\u56f4\u7684\u4e0d\u65ad\u6269\u5927, \u5c24\u5176\u662f\u6570\u636e\u5e93\u8f6f\u4ef6\u548c Web \u8f6f\u4ef6\u7684\u5e7f\u6cdb\u5e94\u7528, \u5b57\u7b26\u4e32\u53d8\u91cf\u5728\u8f6f\u4ef6\u7a0b\u5e8f\u4e2d\u626e\u6f14\u7684\u89d2\u8272\u65e5\u76ca\u91cd\u8981. \u4e0e\u6b64\u540c\u65f6, \u9488\u5bf9\u5b57\u7b26\u4e32\u53d8\u91cf\u7684\u7a0b\u5e8f\u5206\u6790\u6280\u672f\u2014\u2014\u5b57\u7b26\u4e32\u5206\u6790, \u4e5f\u53d6\u5f97\u4e86\u957f\u8db3\u7684\u53d1\u5c55, \u5e76\u5728\u8f6f\u4ef6\u5de5\u7a0b\u4e2d\u7684\u5f88\u591a\u9886\u57df\u4e2d\u5f97\u5230\u4e86\u6210\u529f\u7684\u5e94\u7528. \u5b57\u7b26\u4e32\u5206\u6790\u7684\u57fa\u672c\u5e94\u7528\u6a21\u5f0f\u662f\u9996\u5148\u4f7f\u7528\u5b57\u7b26\u4e32\u503c\u5206\u6790\u83b7\u5f97\u5b57\u7b26\u4e32\u53d8\u91cf\u7684\u6240\u6709\u53ef\u80fd\u53d6\u503c, \u7136\u540e\u4f7f\u7528\u5b57\u7b26\u4e32\u7ea6\u675f\u6c42\u89e3\u5224\u65ad\u8fd9\u4e9b\u53d8\u91cf\u7684\u53d6\u503c\u662f\u5426\u6ee1\u8db3\u4e00\u5b9a\u7ea6\u675f, \u4ece\u800c\u5bf9\u7a0b\u5e8f\u8fdb\u884c\u6b63\u786e\u6027\u9a8c\u8bc1. \u4e3a\u4e86\u4f7f\u5f97\u5b57\u7b26\u4e32\u5206\u6790\u80fd\u591f\u5e94\u7528\u5728\u5b89\u5168\u5206\u6790\u548c\u8f6f\u4ef6\u7ef4\u62a4\u5e94\u7528\u4e2d, \u7814\u7a76\u4eba\u5458\u5bf9\u5b57\u7b26\u4e32\u5206\u6790\u8fdb\u884c\u4e86\u6269\u5c55, \u8fdb\u4e00\u6b65\u5206\u6790\u5b57\u7b26\u4e32\u53d8\u91cf\u7684\u6570\u636e\u6765\u6e90. \u7efc\u8ff0\u4e86\u5b57\u7b26\u4e32\u5206\u6790\u6280\u672f\u7684\u7814\u7a76\u8fdb\u5c55, \u63d0\u51fa\u4e86\u5b57\u7b26\u4e32\u5206\u6790\u7684\u95ee\u9898\u6784\u578b, \u4ecb\u7ecd\u4e86\u8fd9\u4e00\u9886\u57df\u73b0\u5728\u7684\u4e3b\u8981\u7814\u7a76\u5185\u5bb9: \u5b57\u7b26\u4e32\u503c\u5206\u6790, \u5b57\u7b26\u4e32\u7ea6\u675f\u6c42\u89e3, \u5b57\u7b26\u4e32\u6570\u636e\u6765\u6e90\u5206\u6790\u4ee5\u53ca\u5b57\u7b26\u4e32\u5206\u6790\u5728\u8f6f\u4ef6\u5de5\u7a0b\u4e2d\u7684\u5e94\u7528.", "num_citations": "2\n", "authors": ["317"]}
{"title": "An empirical study of execution-data classification based on machine learning\n", "abstract": " As it may be difficult for users to distinguish a passing ex-ecution from a failing execution for a released software sys-tem, researchers have proposed to apply the Random For-est algorithm to classify remotely-collected program execu-tion data. In general, execution-data classification can be viewed as a machine-learning problem, in which a trained learner needs to classify whether each execution is a pass-ing execution or a failing execution. In this paper, we report an empirical study that further investigates various issues in execution-data classification based on machine learning. Compared with previous research, our study further investi-gates the impact of the following issues: different machine-learning algorithms, the numbers of training instances to construct a classification model, and different types of exe-cution data. 1.", "num_citations": "2\n", "authors": ["317"]}
{"title": "Alternative scalable algorithms for lattice-based feature location\n", "abstract": " Considering the scalability of using formal concept analysis to locate features in source code, we present a set of alternative straightforward algorithms to achieve the same objectives. A preliminary experiment indicates that the alternative algorithms are more scalable to deal with the large numbers of data to some extent.", "num_citations": "2\n", "authors": ["317"]}
{"title": "Extending timed abstract state machines for real-time embedded software\n", "abstract": " According to the deficiency of Timed Abstract State Machine (TASM), TASM is extended with the data type of arrays, a loop rule named\" while\", and some operators such as\"%\",\" &\",\"|\",\"^\",\"\u226b\",\"\u226a\", etc. The syntax and semantics of the extended TASM are defined. The extended TASM is applied to actual real-time embedded software to validate its effectiveness for requirements modeling.", "num_citations": "1\n", "authors": ["317"]}
{"title": "Building application-specific operating systems: a profile-guided approach\n", "abstract": " Although operating system optimization has been studied extensively, previous work mainly focuses on solving performance problems. In the cloud era, many servers only run a single application, making it desirable to provide an application-specific operating system (ASOS) that is most suitable for the application. In contrast to existing approaches that build ASOS by manual redesign and reimplementation, this paper presents Tarax, a compiler-based approach to constructing an ASOS for each application. With profile collected from executing the target application on an instrumented Linux kernel, Tarax recompiles the kernel while applying profile-guided optimizations (PGOs). Although GCC has already implemented the optimization process that can be applied to user applications, it does not work on the Linux kernel directly. We modify the Linux kernel and GCC to support kernel instrumentation and\u00a0\u2026", "num_citations": "1\n", "authors": ["317"]}
{"title": "Tree-based convolution: A new architecture for sentence modeling\n", "abstract": " This paper proposes a new convolutional neural architecture based on treestructures, called the tree-based convolutional neural network (TBCNN). Two variants take advantage of constituency trees and dependency trees, respectively, to model sentences. Compared with traditional \u201cflat\u201d convolutional neural networks (CNNs), TBCNNs explore explicitly the structural information of sentences; compared with recursive neural networks, TBCNNs have much shorter propagation paths, enabling more effective feature learning and extraction. In the experiment of sentiment analysis, our two models consistently outperform CNNs and RNNs in a controlled setting. Our models are also competitive to most stateof-the-art results, including RNNs based on long short term memory and deep CNNs/RNNs.", "num_citations": "1\n", "authors": ["317"]}
{"title": "Rational construction of a cellular memory inverter\n", "abstract": " Robust and reliable biological memory computing systems are lacking, although many biological computing systems are implemented. We successfully designed, constructed, and tested a cellular memory inverter in the bacterium Escherichia coli in a predictable way. We selected isopropyl -D-1-thiogalactopyranoside (IPTG) as the input and green fluorescent protein (GFP) as the output. We selected negative regulation of lac operon and excision function of Cre recombinase as computing tools. The GFP can express and produce output without IPTG. The input, IPTG, can induce the expression of Cre recombinase. The Cre recombinase can excise the GFP gene between site lox71 and site lox66, and hence turn off the output. We also selected ordinary differential equations (ODEs) to predict the dynamic behaviors for the precise design and implementation of the inverter. We used sodium dodecyl sulfate\u00a0\u2026", "num_citations": "1\n", "authors": ["317"]}
{"title": "\u8f6f\u4ef6\u5e93\u8c03\u7528\u89c4\u7ea6\u6316\u6398\n", "abstract": " \u8f6f\u4ef6\u5e93\u8c03\u7528\u89c4\u7ea6\u662f\u4e00\u79cd\u63cf\u8ff0\u8f6f\u4ef6\u5e93\u63d0\u4f9b\u51fd\u6570\u6b63\u786e\u8c03\u7528\u987a\u5e8f\u7684\u89c4\u7ea6. \u5ba2\u6237\u4ee3\u7801\u5e94\u6309\u6b64\u89c4\u7ea6\u63cf\u8ff0\u7684\u5185\u5bb9\u8c03\u7528\u51fd\u6570, \u5426\u5219\u53ef\u80fd\u5f15\u5165\u7f3a\u9677, \u4ece\u800c\u964d\u4f4e\u8f6f\u4ef6\u7684\u53ef\u4fe1\u6027. \u7531\u4e8e\u80fd\u591f\u63cf\u8ff0\u53ef\u4fe1\u8f6f\u4ef6\u5e94\u8be5\u6ee1\u8db3\u7684\u6027\u8d28, \u8f6f\u4ef6\u5e93\u8c03\u7528\u89c4\u7ea6\u5728\u53ef\u4fe1\u8f6f\u4ef6, \u6a21\u578b\u68c0\u6d4b\u7b49\u7814\u7a76\u4e2d\u626e\u6f14\u7279\u6b8a\u7684\u89d2\u8272. \u4f46\u662f, \u53d7\u5236\u4e8e\u7f16\u5199\u89c4\u7ea6\u7684\u5de8\u5927\u4ee3\u4ef7, \u8f6f\u4ef6\u5e93\u901a\u5e38\u5e76\u4e0d\u63d0\u4f9b\u5df2\u7f16\u5199\u597d\u7684\u8c03\u7528\u89c4\u7ea6. \u4e3a\u6b64, \u7814\u7a76\u8005\u63d0\u51fa\u4e86\u5404\u79cd\u81ea\u52a8\u6316\u6398\u6b64\u79cd\u89c4\u7ea6\u7684\u65b9\u6cd5. \u9610\u8ff0\u4e86\u5176\u4e2d\u4ee3\u8868\u6027\u7684\u65b9\u6cd5\u53ca\u5176\u6700\u65b0\u7684\u7814\u7a76\u8fdb\u5c55, \u5e76\u5728\u6b64\u57fa\u7840\u4e0a\u63a2\u8ba8\u4e86\u5c06\u6765\u7684\u7814\u7a76\u65b9\u5411.", "num_citations": "1\n", "authors": ["317"]}
{"title": "Ranking Component Retrieval Results by Leveraging User History Information.\n", "abstract": " In the literature, many research efforts have been put into the improvement of component retrieval in reuse repositories. However, when retrieving components from a large reuse repository, it is usually unavoidable for a retriever to browse the retrieved component set to locate the appropriate ones. Therefore, the strategy for ranking the retrieved results may be essential for facilitating this task. In this paper, we propose a ranking strategy by considering user preference calculated from the user\u2019s history information. Furthermore, we also demonstrate that our strategy can be easily combined with other strategies. To evaluate the effectiveness of our strategy, we performed an experimental study. The experimental results demonstrate that our approach is effective and the combination of our strategy and a previous strategy may be more effective than either of the two.", "num_citations": "1\n", "authors": ["317"]}
{"title": "Can Domain Knowledge Help Case Based Diagnosis?\n", "abstract": " The quality of case data can be an important factor for a Case Based Reasoning (CBR) system. In this paper, we report an experimental study in using domain knowledge to help case-based diagnosis in a product maintenance context. For the problem we are facing, cases are based on the descriptions of customers who have little knowledge of their products. As each case can be associated with some domain knowledge provided by domain experts, we try to use the domain knowledge to assist case matching. Our experimental results show that the domain knowledge can significantly improve the performance of the case-based diagnosis.", "num_citations": "1\n", "authors": ["317"]}
{"title": "\u5b50\u7c7b\u578b\u7684\u6307\u79f0\u8bed\u4e49\n", "abstract": " \u7ee7\u627f\u88ab\u8ba4\u4e3a\u662f\u9762\u5411\u5bf9\u8c61\u7a0b\u5e8f\u8bbe\u8ba1\u7684\u91cd\u8981\u7279\u5f81\u4e4b\u4e00,\u5982\u4f55\u89e3\u91ca\u7ee7\u627f\u4e00\u76f4\u662f\u9762\u5411\u5bf9\u8c61\u5f62\u5f0f\u8bed\u4e49\u7814\u7a76\u7684\u96be\u9898,\u672c\u6587\u9488\u5bf9\u7ee7\u627f\u5173\u7cfb\u7684\u4e00\u79cd\u5f62\u5f0f\u4e00\u4e00\u5bf9\u8c61\u95f4\u884c\u4e3a\u89c4\u8303\u7684\u7ee7\u627f,\u5373\u7c7b\u578b\u5173\u7cfb,\u63a2\u8ba8\u4e86\u5176\u6307\u79f0\u8bed\u4e49,\u57fa\u672c\u601d\u60f3\u662f\u5c06\u4e88\u7c7b\u578b\u5173\u7cfb\u89c6\u4e3a\u7c7b\u578b\u5f3a\u5236\u901a\u8fc7\u7c7b\u578b\u5f3a\u5236\u51fd\u6570\u5c06\u5b50\u7c7b\u578b\u5bf9\u8c61\u89e3\u91ca\u7236\u7c7b\u578b\u57df\u4e2d.", "num_citations": "1\n", "authors": ["317"]}