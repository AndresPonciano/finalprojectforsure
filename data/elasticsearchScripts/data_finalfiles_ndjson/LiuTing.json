{"title": "Document modeling with gated recurrent neural network for sentiment classification\n", "abstract": " Document level sentiment classification remains a challenge: encoding the intrinsic relations between sentences in the semantic meaning of a document. To address this, we introduce a neural network model to learn vector-based document representation in a unified, bottom-up fashion. The model first learns sentence representation with convolutional neural network or long short-term memory. Afterwards, semantics of sentences and their relations are adaptively encoded in document representation with gated recurrent neural network. We conduct document level sentiment classification on four large-scale review datasets from IMDB and Yelp Dataset Challenge. Experimental results show that:(1) our neural model shows superior performances over several state-of-the-art algorithms;(2) gated recurrent neural network dramatically outperforms standard recurrent neural network in document modeling for sentiment classification. 1", "num_citations": "1433\n", "authors": ["1179"]}
{"title": "Learning sentiment-specific word embedding for twitter sentiment classification\n", "abstract": " We present a method that learns word embedding for Twitter sentiment classification in this paper. Most existing algorithms for learning continuous word representations typically only model the syntactic context of words but ignore the sentiment of text. This is problematic for sentiment analysis as they usually map words with similar syntactic context but opposite sentiment polarity, such as good and bad, to neighboring word vectors. We address this issue by learning sentimentspecific word embedding (SSWE), which encodes sentiment information in the continuous representation of words. Specifically, we develop three neural networks to effectively incorporate the supervision from sentiment polarity of text (eg sentences or tweets) in their loss functions. To obtain large scale training corpora, we learn the sentiment-specific word embedding from massive distant-supervised tweets collected by positive and negative emoticons. Experiments on applying SSWE to a benchmark Twitter sentiment classification dataset in SemEval 2013 show that (1) the SSWE feature performs comparably with hand-crafted features in the top-performed system;(2) the performance is further improved by concatenating SSWE with existing feature set.", "num_citations": "1283\n", "authors": ["1179"]}
{"title": "Effective LSTMs for Target-Dependent Sentiment Classification\n", "abstract": " Target-dependent sentiment classification remains a challenge: modeling the semantic relatedness of a target with its context words in a sentence. Different context words have different influences on determining the sentiment polarity of a sentence towards the target. Therefore, it is desirable to integrate the connections between target word and context words when building a learning system. In this paper, we develop two target dependent long short-term memory (LSTM) models, where target information is automatically taken into account. We evaluate our methods on a benchmark dataset from Twitter. Empirical results show that modeling sentence representation with standard LSTM does not perform well. Incorporating target information into LSTM can significantly boost the classification accuracy. The target-dependent LSTM models achieve state-of-the-art performances without using syntactic parser or external sentiment lexicons.", "num_citations": "640\n", "authors": ["1179"]}
{"title": "Aspect level sentiment classification with deep memory network\n", "abstract": " We introduce a deep memory network for aspect level sentiment classification. Unlike feature-based SVM and sequential neural models such as LSTM, this approach explicitly captures the importance of each context word when inferring the sentiment polarity of an aspect. Such importance degree and text representation are calculated with multiple computational layers, each of which is a neural attention model over an external memory. Experiments on laptop and restaurant datasets demonstrate that our approach performs comparable to state-of-art feature based SVM system, and substantially better than LSTM and attention-based LSTM architectures. On both datasets we show that multiple computational layers could improve the performance. Moreover, our approach is also fast. The deep memory network with 9 layers is 15 times faster than LSTM with a CPU implementation.", "num_citations": "632\n", "authors": ["1179"]}
{"title": "Deep learning for event-driven stock prediction\n", "abstract": " We propose a deep learning method for event-driven stock market prediction. First, events are extracted from news text, and represented as dense vectors, trained using a novel neural tensor network. Second, a deep convolutional neural network is used to model both short-term and long-term influences of events on stock price movements. Experimental results show that our model can achieve nearly 6% improvements on S&P 500 index prediction and individual stock prediction, respectively, compared to state-of-the-art baseline methods. In addition, market simulation results show that our system is more capable of making profits than previously reported systems trained on S&P 500 stock historical data", "num_citations": "624\n", "authors": ["1179"]}
{"title": "Ltp: A chinese language technology platform\n", "abstract": " LTP (Language Technology Platform) is an integrated Chinese processing platform which includes a suite of high performance natural language processing (NLP) modules and relevant corpora. Especially for the syntactic and semantic parsing modules, we achieved good results in some relevant evaluations, such as CoNLL and SemEval. Based on XML internal data representation, users can easily use these modules and corpora by invoking DLL (Dynamic Link Library) or Web service APIs (Application Program Interface), and view the processing results directly by the visualization tool.", "num_citations": "600\n", "authors": ["1179"]}
{"title": "\u6587\u672c\u60c5\u611f\u5206\u6790\n", "abstract": " \u5bf9\u6587\u672c\u60c5\u611f\u5206\u6790\u7684\u7814\u7a76\u73b0\u72b6\u4e0e\u8fdb\u5c55\u8fdb\u884c\u4e86\u603b\u7ed3. \u9996\u5148\u5c06\u6587\u672c\u60c5\u611f\u5206\u6790\u5f52\u7eb3\u4e3a 3 \u9879\u4e3b\u8981\u4efb\u52a1, \u5373\u60c5\u611f\u4fe1\u606f\u62bd\u53d6, \u60c5\u611f\u4fe1\u606f\u5206\u7c7b\u4ee5\u53ca\u60c5\u611f\u4fe1\u606f\u7684\u68c0\u7d22\u4e0e\u5f52\u7eb3, \u5e76\u5bf9\u5b83\u4eec\u8fdb\u884c\u4e86\u7ec6\u81f4\u7684\u4ecb\u7ecd\u548c\u5206\u6790; \u8fdb\u800c\u4ecb\u7ecd\u4e86\u6587\u672c\u60c5\u611f\u5206\u6790\u7684\u56fd\u5185\u5916\u8bc4\u6d4b\u548c\u8d44\u6e90\u5efa\u8bbe\u60c5\u51b5; \u6700\u540e\u4ecb\u7ecd\u4e86\u6587\u672c\u60c5\u611f\u5206\u6790\u7684\u5e94\u7528. \u91cd\u5728\u5bf9\u6587\u672c\u60c5\u611f\u5206\u6790\u7814\u7a76\u7684\u4e3b\u6d41\u65b9\u6cd5\u548c\u524d\u6cbf\u8fdb\u5c55\u8fdb\u884c\u6982\u62ec, \u6bd4\u8f83\u548c\u5206\u6790.", "num_citations": "476\n", "authors": ["1179"]}
{"title": "Attention-over-attention neural networks for reading comprehension\n", "abstract": " Cloze-style queries are representative problems in reading comprehension. Over the past few months, we have seen much progress that utilizing neural network approach to solve Cloze-style questions. In this paper, we present a novel model called attention-over-attention reader for the Cloze-style reading comprehension task. Our model aims to place another attention mechanism over the document-level attention, and induces \"attended attention\" for final predictions. Unlike the previous works, our neural network model requires less pre-defined hyper-parameters and uses an elegant architecture for modeling. Experimental results show that the proposed attention-over-attention model significantly outperforms various state-of-the-art systems by a large margin in public datasets, such as CNN and Children's Book Test datasets.", "num_citations": "394\n", "authors": ["1179"]}
{"title": "Computer-aided writing system and method with cross-language writing wizard\n", "abstract": " A computer-aided writing system offers assistance to a user writing in a non-native language, as the user needs help, without requiring the user to divert attention away from the entry task. The writing system provides a user interface (UI) that integrates writing assistance with in-line text entry. When the user is unsure of a word's spelling or whether the word is appropriate, the user may enter a corresponding native word directly in line with the ongoing sentence. An error tolerant spelling tool accepts the native word (even if it is misspelled or mistyped) and derives the most probable non-native word for the given context. The spelling tool consults a bilingual dictionary to determine possible non-native word translation candidates, a non-native language model (eg, a trigram language model) to generate probabilities associated with the candidates given the current sentence or phrase context, and a translation model to\u00a0\u2026", "num_citations": "351\n", "authors": ["1179"]}
{"title": "Learning semantic representations of users and products for document level sentiment classification\n", "abstract": " Neural network methods have achieved promising results for sentiment classification of text. However, these models only use semantics of texts, while ignoring users who express the sentiment and products which are evaluated, both of which have great influences on interpreting the sentiment of text. In this paper, we address this issue by incorporating user-and product-level information into a neural network approach for document level sentiment classification. Users and products are modeled using vector space models, the representations of which capture important global clues such as individual preferences of users or overall qualities of products. Such global evidence in turn facilitates embedding learning procedure at document level, yielding better text representations. By combining evidence at user-, product-and documentlevel in a unified neural framework, the proposed model achieves state-of-the-art performances on IMDB and Yelp datasets1.", "num_citations": "324\n", "authors": ["1179"]}
{"title": "Learning semantic hierarchies via word embeddings\n", "abstract": " Semantic hierarchy construction aims to build structures of concepts linked by hypernym\u2013hyponym (\u201cis-a\u201d) relations. A major challenge for this task is the automatic discovery of such relations. This paper proposes a novel and effective method for the construction of semantic hierarchies based on word embeddings, which can be used to measure the semantic relationship between words. We identify whether a candidate word pair has hypernym\u2013hyponym relation by using the word-embedding-based semantic projections between words and their hypernyms. Our result, an F-score of 73.74%, outperforms the state-of-theart methods on a manually labeled test dataset. Moreover, combining our method with a previous manually-built hierarchy extension method can further improve F-score to 80.29%.", "num_citations": "287\n", "authors": ["1179"]}
{"title": "Pre-training with whole word masking for chinese bert\n", "abstract": " Bidirectional Encoder Representations from Transformers (BERT) has shown marvelous improvements across various NLP tasks. Recently, an upgraded version of BERT has been released with Whole Word Masking (WWM), which mitigate the drawbacks of masking partial WordPiece tokens in pre-training BERT. In this technical report, we adapt whole word masking in Chinese text, that masking the whole word instead of masking Chinese characters, which could bring another challenge in Masked Language Model (MLM) pre-training task. The proposed models are verified on various NLP tasks, across sentence-level to document-level, including machine reading comprehension (CMRC 2018, DRCD, CJRC), natural language inference (XNLI), sentiment classification (ChnSentiCorp), sentence pair matching (LCQMC, BQ Corpus), and document classification (THUCNews). Experimental results on these datasets show that the whole word masking could bring another significant gain. Moreover, we also examine the effectiveness of the Chinese pre-trained models: BERT, ERNIE, BERT-wwm, BERT-wwm-ext, RoBERTa-wwm-ext, and RoBERTa-wwm-ext-large. We release all the pre-trained models: \\url{https://github.com/ymcui/Chinese-BERT-wwm", "num_citations": "276\n", "authors": ["1179"]}
{"title": "Coooolll: A deep learning system for twitter sentiment classification\n", "abstract": " In this paper, we develop a deep learning system for message-level Twitter sentiment classification. Among the 45 submitted systems including the SemEval 2013 participants, our system (Coooolll) is ranked 2nd on the Twitter2014 test set of SemEval 2014 Task 9. Coooolll is built in a supervised learning framework by concatenating the sentiment-specific word embedding (SSWE) features with the state-of-the-art hand-crafted features. We develop a neural network with hybrid loss function 1 to learn SSWE, which encodes the sentiment information of tweets in the continuous representation of words. To obtain large-scale training corpora, we train SSWE from 10M tweets collected by positive and negative emoticons, without any manual annotation. Our system can be easily re-implemented with the publicly available sentiment-specific word embedding.", "num_citations": "273\n", "authors": ["1179"]}
{"title": "Sentiment embeddings with applications to sentiment analysis\n", "abstract": " We propose learning sentiment-specific word embeddings dubbed sentiment embeddings in this paper. Existing word embedding learning algorithms typically only use the contexts of words but ignore the sentiment of texts. It is problematic for sentiment analysis because the words with similar contexts but opposite sentiment polarity, such as  good  and  bad , are mapped to neighboring word vectors. We address this issue by encoding sentiment information of texts (e.g., sentences and words) together with contexts of words in sentiment embeddings. By combining context and sentiment level evidences, the nearest neighbors in sentiment embedding space are semantically similar and it favors words with the same sentiment polarity. In order to learn sentiment embeddings effectively, we develop a number of neural networks with tailoring loss functions, and collect massive texts automatically with sentiment signals\u00a0\u2026", "num_citations": "247\n", "authors": ["1179"]}
{"title": "A language-independent neural network for event detection\n", "abstract": " Event detection remains a challenge because of the difficulty of encoding the word semantics in various contexts. Previous approaches have heavily depended on language-specific knowledge and preexisting natural language processing tools. However, not all languages have such resources and tools available compared with English language. A more promising approach is to automatically learn effective features from data, without relying on language-specific resources. In this study, we develop a language-independent neural network to capture both sequence and chunk information from specific contexts and use them to train an event detector for multiple languages without any manually encoded features. Experiments show that our approach can achieve robust, efficient and accurate results for various languages. In the ACE 2005 English event detection task, our approach achieved a 73.4% F-score\u00a0\u2026", "num_citations": "214\n", "authors": ["1179"]}
{"title": "Building large-scale twitter-specific sentiment lexicon: A representation learning approach\n", "abstract": " In this paper, we propose to build large-scale sentiment lexicon from Twitter with a representation learning approach. We cast sentiment lexicon learning as a phrase-level sentiment classification task. The challenges are developing effective feature representation of phrases and obtaining training data with minor manual annotations for building the sentiment classifier. Specifically, we develop a dedicated neural architecture and integrate the sentiment information of text (eg sentences or tweets) into its hybrid loss function for learning sentiment-specific phrase embedding (SSPE). The neural network is trained from massive tweets collected with positive and negative emoticons, without any manual annotation. Furthermore, we introduce the Urban Dictionary to expand a small number of sentiment seeds to obtain more training data for building the phrase-level sentiment classifier. We evaluate our sentiment lexicon (TS-Lex) by applying it in a supervised learning framework for Twitter sentiment classification. Experiment results on the benchmark dataset of SemEval 2013 show that, TS-Lex yields better performance than previously introduced sentiment lexicons.", "num_citations": "211\n", "authors": ["1179"]}
{"title": "Codebert: A pre-trained model for programming and natural languages\n", "abstract": " We present CodeBERT, a bimodal pre-trained model for programming language (PL) and nat-ural language (NL). CodeBERT learns general-purpose representations that support downstream NL-PL applications such as natural language codesearch, code documentation generation, etc. We develop CodeBERT with Transformer-based neural architecture, and train it with a hybrid objective function that incorporates the pre-training task of replaced token detection, which is to detect plausible alternatives sampled from generators. This enables us to utilize both bimodal data of NL-PL pairs and unimodal data, where the former provides input tokens for model training while the latter helps to learn better generators. We evaluate CodeBERT on two NL-PL applications by fine-tuning model parameters. Results show that CodeBERT achieves state-of-the-art performance on both natural language code search and code documentation generation tasks. Furthermore, to investigate what type of knowledge is learned in CodeBERT, we construct a dataset for NL-PL probing, and evaluate in a zero-shot setting where parameters of pre-trained models are fixed. Results show that CodeBERT performs better than previous pre-trained models on NL-PL probing.", "num_citations": "206\n", "authors": ["1179"]}
{"title": "Using structured events to predict stock price movement: An empirical investigation\n", "abstract": " It has been shown that news events influence the trends of stock price movements. However, previous work on news-driven stock market prediction rely on shallow features (such as bags-of-words, named entities and noun phrases), which do not capture structured entity-relation information, and hence cannot represent complete and exact events. Recent advances in Open Information Extraction (Open IE) techniques enable the extraction of structured events from web-scale data. We propose to adapt Open IE technology for event-based stock price movement prediction, extracting structured events from large-scale public news without manual efforts. Both linear and nonlinear models are employed to empirically investigate the hidden and complex relationships between events and the stock market. Largescale experiments show that the accuracy of S&P 500 index prediction is 60%, and that of individual stock prediction can be over 70%. Our event-based system outperforms bags-of-words-based baselines, and previously reported systems trained on S&P 500 stock historical data.", "num_citations": "205\n", "authors": ["1179"]}
{"title": "Sentiment analysis\n", "abstract": " This paper surveys the state of the art of sentiment analysis. First, three important tasks of sentiment analysis are summarized and analyzed in detail, including sentiment extraction, sentiment classification, sentiment retrieval and summarization. Then, the evaluation and corpus for sentiment analysis are introduced. Finally, the applications of sentiment analysis are concluded. This paper aims to take a deep insight into the mainstream methods and recent progress in this field, making detailed comparison and analysis.", "num_citations": "192\n", "authors": ["1179"]}
{"title": "User modeling with neural network for review rating prediction\n", "abstract": " We present a neural network method for review rating prediction in this paper. Existing neural network methods for sentiment prediction typically only capture the semantics of texts, but ignore the user who expresses the sentiment. This is not desirable for review rating prediction as each user has an influence on how to interpret the textual content of a review. For example, the same word (eg good) might indicate different sentiment strengths when written by different users. We address this issue by developing a new neural network that takes user information into account. The intuition is to factor in user-specific modification to the meaning of a certain word. Specifically, we extend the lexical semantic composition models and introduce a user-word composition vector model (UWCVM), which effectively captures how user acts as a function affecting the continuous word representation. We integrate UWCVM into a supervised learning framework for review rating prediction, andconduct experiments on two benchmark review datasets. Experimental results demonstrate the effectiveness of our method. It shows superior performances over several strong baseline methods.", "num_citations": "161\n", "authors": ["1179"]}
{"title": "Towards better UD parsing: Deep contextualized word embeddings, ensemble, and treebank concatenation\n", "abstract": " This paper describes our system (HIT-SCIR) submitted to the CoNLL 2018 shared task on Multilingual Parsing from Raw Text to Universal Dependencies. We base our submission on Stanford's winning system for the CoNLL 2017 shared task and make two effective extensions: 1) incorporating deep contextualized word embeddings into both the part of speech tagger and parser; 2) ensembling parsers trained with different initialization. We also explore different ways of concatenating treebanks for further improvements. Experimental results on the development data show the effectiveness of our methods. In the final evaluation, our system was ranked first according to LAS (75.84%) and outperformed the other systems by a large margin.", "num_citations": "160\n", "authors": ["1179"]}
{"title": "Cross-lingual Dependency Parsing Based on Distributed Representations\n", "abstract": " This paper investigates the problem of cross-lingual dependency parsing, aiming at inducing dependency parsers for low-resource languages while using only training data from a resource-rich language (eg English). Existing approaches typically don\u2019t include lexical features, which are not transferable across languages. In this paper, we bridge the lexical feature gap by using distributed feature representations and their composition. We provide two algorithms for inducing cross-lingual distributed representations of words, which map vocabularies from two different languages into a common vector space. Consequently, both lexical features and non-lexical features can be used in our model for cross-lingual transfer.Furthermore, our framework is able to incorporate additional useful features such as cross-lingual word clusters. Our combined contributions achieve an average relative error reduction of 10.9% in labeled attachment score as compared with the delexicalized parser, trained on English universal treebank and transferred to three other languages. It also significantly outperforms McDonald et al.(2013) augmented with projected cluster features on identical data.", "num_citations": "160\n", "authors": ["1179"]}
{"title": "\u81ea\u52a8\u95ee\u7b54\u7efc\u8ff0\n", "abstract": " (\u54c8\u5c14\u6ee8\u5de5\u4e1a\u5927\u5b66\u4fe1\u606f\u68c0\u7d22\u5b9e\u9a8c\u5ba4 \u54c8\u5c14\u6ee8 150001) \u6458\u8981: \u81ea\u52a8\u95ee\u7b54\u6280\u672f\u662f\u81ea\u7136\u8bed\u8a00\u5904\u7406\u9886\u57df\u4e2d\u4e00\u4e2a\u975e\u5e38\u70ed\u95e8\u7684\u7814\u7a76\u65b9\u5411, \u5b83\u7efc\u5408\u8fd0\u7528\u4e86\u5404\u79cd\u81ea\u7136\u8bed\u8a00\u5904\u7406\u6280\u672f. \u672c\u6587\u4ecb\u7ecd\u4e86\u81ea\u52a8\u95ee\u7b54\u6280\u672f\u7684\u53d1\u5c55\u73b0\u72b6\u548c\u81ea\u52a8\u95ee\u7b54\u7cfb\u7edf\u4e2d\u5e38\u7528\u7684\u6280\u672f. \u81ea\u52a8\u95ee\u7b54\u7cfb\u7edf\u4e00\u822c\u5305\u62ec\u4e09\u4e2a\u4e3b\u8981\u7ec4\u6210\u90e8\u5206: \u95ee\u9898\u5206\u6790, \u4fe1\u606f\u68c0\u7d22\u548c\u7b54\u6848\u62bd\u53d6. \u672c\u6587\u5206\u522b\u4ecb\u7ecd\u4e86\u8fd9\u4e09\u4e2a\u4e3b\u8981\u7ec4\u6210\u90e8\u5206\u7684\u4e3b\u8981\u529f\u80fd\u548c\u5e38\u7528\u7684\u65b9\u6cd5. \u6700\u540e\u8fd8\u4ecb\u7ecd\u4e86\u81ea\u52a8\u95ee\u7b54\u7cfb\u7edf\u7684\u8bc4\u4ef7\u95ee\u9898.", "num_citations": "160\n", "authors": ["1179"]}
{"title": "\u57fa\u4e8e\u53e5\u6cd5\u7ed3\u6784\u5206\u6790\u7684\u4e2d\u6587\u95ee\u9898\u5206\u7c7b\n", "abstract": " (\u54c8\u5c14\u6ee8\u5de5\u4e1a\u5927\u5b66\u4fe1\u606f\u68c0\u7d22\u7814\u7a76\u5ba4, \u9ed1\u9f99\u6c5f\u54c8\u5c14\u6ee8 150001) \u6458\u8981: \u95ee\u9898\u5206\u7c7b\u662f\u95ee\u7b54\u7cfb\u7edf\u4e2d\u91cd\u8981\u7684\u7ec4\u6210\u90e8\u5206, \u95ee\u9898\u5206\u7c7b\u7ed3\u679c\u7684\u597d\u574f\u76f4\u63a5\u5f71\u54cd\u95ee\u7b54\u7cfb\u7edf\u7684\u8d28\u91cf. \u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u7528\u4e8e\u95ee\u9898\u5206\u7c7b\u7684\u7279\u5f81\u63d0\u53d6\u7684\u65b0\u65b9\u6cd5, \u8be5\u65b9\u6cd5\u4e3b\u8981\u4f7f\u7528\u53e5\u6cd5\u5206\u6790\u7684\u7ed3\u679c, \u63d0\u53d6\u95ee\u9898\u7684\u4e3b\u5e72\u548c\u7591\u95ee\u8bcd\u53ca\u5176\u9644\u5c5e\u6210\u5206\u4f5c\u4e3a\u5206\u7c7b\u7684\u7279\u5f81, \u6b64\u65b9\u6cd5\u5927\u5e45\u5ea6\u5730\u51cf\u5c11\u4e86\u566a\u97f3, \u7a81\u51fa\u4e86\u95ee\u9898\u5206\u7c7b\u7684\u4e3b\u8981\u7279\u5f81, \u5229\u7528\u8d1d\u53f6\u65af\u5206\u7c7b\u5668\u5206\u7c7b, \u6709\u6548\u5730\u63d0\u9ad8\u4e86\u95ee\u9898\u5206\u7c7b\u7684\u7cbe\u5ea6. \u5b9e\u9a8c\u7ed3\u679c\u8bc1\u660e\u4e86\u8be5\u65b9\u6cd5\u7684\u6709\u6548\u6027, \u5927\u7c7b\u548c\u5c0f\u7c7b\u7684\u5206\u7c7b\u7cbe\u5ea6\u5206\u522b\u8fbe\u5230\u4e86 86162% \u548c 71192%, \u53d6\u5f97\u4e86\u8f83\u597d\u7684\u6548\u679c.", "num_citations": "153\n", "authors": ["1179"]}
{"title": "Revisiting embedding features for simple semi-supervised learning\n", "abstract": " Recent work has shown success in using continuous word embeddings learned from unlabeled data as features to improve supervised NLP systems, which is regarded as a simple semi-supervised learning mechanism. However, fundamental problems on effectively incorporating the word embedding features within the framework of linear models remain. In this study, we investigate and analyze three different approaches, including a new proposed distributional prototype approach, for utilizing the embedding features. The presented approaches can be integrated into most of the classical linear models in NLP. Experiments on the task of named entity recognition show that each of the proposed approaches can better utilize the word embedding features, among which the distributional prototype approach performs the best. Moreover, the combination of the approaches provides additive improvements, outperforming the dense and continuous embedding features by nearly 2 points of F1 score.", "num_citations": "147\n", "authors": ["1179"]}
{"title": "Deep learning for sentiment analysis: successful approaches and future challenges\n", "abstract": " Sentiment analysis (also known as opinion mining) is an active research area in natural language processing. It aims at identifying, extracting and organizing sentiments from user generated texts in social networks, blogs or product reviews. A lot of studies in literature exploit machine learning approaches to solve sentiment analysis tasks from different perspectives in the past 15 years. Since the performance of a machine learner heavily depends on the choices of data representation, many studies devote to building powerful feature extractor with domain expert and careful engineering. Recently, deep learning approaches emerge as powerful computational models that discover intricate semantic representations of texts automatically from data without feature engineering. These approaches have improved the state\u2010of\u2010the\u2010art in many sentiment analysis tasks including sentiment classification of sentences\u00a0\u2026", "num_citations": "140\n", "authors": ["1179"]}
{"title": "\u8bdd\u9898\u68c0\u6d4b\u4e0e\u8ddf\u8e2a\u7684\u8bc4\u6d4b\u53ca\u7814\u7a76\u7efc\u8ff0\n", "abstract": " \u8bdd\u9898\u68c0\u6d4b\u4e0e\u8ddf\u8e2a\u662f\u4e00\u9879\u9762\u5411\u65b0\u95fb\u5a92\u4f53\u4fe1\u606f\u6d41\u8fdb\u884c\u672a\u77e5\u8bdd\u9898\u8bc6\u522b\u548c\u5df2\u77e5\u8bdd\u9898\u8ddf\u8e2a\u7684\u4fe1\u606f\u5904\u7406\u6280\u672f. \u81ea\u4ece 1996 \u5e74\u524d\u77bb\u6027\u7684\u63a2\u7d22\u4ee5\u6765, \u8be5\u9886\u57df\u8fdb\u884c\u7684\u591a\u6b21\u5927\u89c4\u6a21\u8bc4\u6d4b\u4e3a\u4fe1\u606f\u8bc6\u522b, \u91c7\u96c6\u548c\u7ec4\u7ec7\u7b49\u76f8\u5173\u6280\u672f\u63d0\u4f9b\u4e86\u65b0\u7684\u6d4b\u8bd5\u5e73\u53f0. \u7531\u4e8e\u8bdd\u9898\u68c0\u6d4b\u4e0e\u8ddf\u8e2a\u76f8\u5bf9\u4e8e\u4fe1\u606f\u68c0\u7d22, \u4fe1\u606f\u6316\u6398\u548c\u4fe1\u606f\u62bd\u53d6\u7b49\u81ea\u7136\u8bed\u8a00\u5904\u7406\u6280\u672f\u5177\u5907\u5f88\u591a\u5171\u6027, \u5e76\u9762\u5411\u5177\u5907\u7a81\u53d1\u6027\u548c\u5ef6\u7eed\u6027\u89c4\u5f8b\u7684\u65b0\u95fb\u8bed\u6599, \u56e0\u6b64\u9010\u6e10\u6210\u4e3a\u5f53\u524d\u4fe1\u606f\u5904\u7406\u9886\u57df\u7684\u7814\u7a76\u70ed\u70b9. \u672c\u6587\u7b80\u8981\u4ecb\u7ecd\u4e86\u8bdd\u9898\u68c0\u6d4b\u4e0e\u8ddf\u8e2a\u7684\u7814\u7a76\u80cc\u666f, \u4efb\u52a1\u5b9a\u4e49, \u8bc4\u6d4b\u65b9\u6cd5\u4ee5\u53ca\u76f8\u5173\u6280\u672f, \u5e76\u901a\u8fc7\u5206\u6790\u76ee\u524d TD T \u9886\u57df\u7684\u7814\u7a76\u73b0\u72b6\u5c55\u671b\u672a\u6765\u7684\u53d1\u5c55\u8d8b\u52bf.", "num_citations": "140\n", "authors": ["1179"]}
{"title": "Application-driven statistical paraphrase generation\n", "abstract": " Paraphrase generation (PG) is important in plenty of NLP applications. However, the research of PG is far from enough. In this paper, we propose a novel method for statistical paraphrase generation (SPG), which can (1) achieve various applications based on a uniform statistical model, and (2) naturally combine multiple resources to enhance the PG performance. In our experiments, we use the proposed method to generate paraphrases for three different applications. The results show that the method can be easily transformed from one application to another and generate valuable and interesting paraphrases.", "num_citations": "138\n", "authors": ["1179"]}
{"title": "\u57fa\u4e8e\u8bed\u4e49\u4f9d\u5b58\u7684\u6c49\u8bed\u53e5\u5b50\u76f8\u4f3c\u5ea6\u8ba1\u7b97\n", "abstract": " \u53e5\u5b50\u95f4\u76f8\u4f3c\u5ea6\u7684\u8ba1\u7b97\u5728\u81ea\u7136\u8bed\u8a00\u5904\u7406\u7684\u5404\u4e2a\u9886\u57df\u90fd\u5360\u6709\u5f88\u91cd\u8981\u7684\u5730\u4f4d,\u5728\u591a\u6587\u6863\u81ea\u52a8\u6587\u6458\u6280\u672f\u4e2d,\u53e5\u5b50\u95f4\u76f8\u4f3c\u5ea6\u7684\u8ba1\u7b97\u662f\u4e00\u4e2a\u5173\u952e\u7684\u95ee\u9898.\u7531\u4e8e\u6c49\u8bed\u53e5\u5b50\u7684\u8868\u8fbe\u5f62\u5f0f\u662f\u591a\u79cd\u591a\u6837\u7684,\u8981\u51c6\u786e\u5730\u523b\u753b\u4e00\u4e2a\u53e5\u5b50\u6240\u8868\u8fbe\u7684\u610f\u601d,\u5fc5\u987b\u6df1\u5165\u5230\u8bed\u4e49\u4e00\u7ea7\u5e76\u7ed3\u5408\u8bed\u6cd5\u7ed3\u6784\u4fe1\u606f,\u7531\u6b64\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u8bed\u4e49\u4f9d\u5b58\u7684\u6c49\u8bed\u53e5\u5b50\u76f8\u4f3c\u5ea6\u8ba1\u7b97\u7684\u65b9\u6cd5,\u8be5\u65b9\u6cd5\u53d6\u5f97\u4e86\u4ee4\u4eba\u6ee1\u610f\u7684\u5b9e\u9a8c\u6548\u679c.", "num_citations": "121\n", "authors": ["1179"]}
{"title": "An entity-mention model for coreference resolution with inductive logic programming\n", "abstract": " The traditional mention-pair model for coreference resolution cannot capture information beyond mention pairs for both learning and testing. To deal with this problem, we present an expressive entity-mention model that performs coreference resolution at an entity level. The model adopts the Inductive Logic Programming (ILP) algorithm, which provides a relational way to organize different knowledge of entities and mentions. The solution can explicitly express relations between an entity and the contained mentions, and automatically learn first-order rules important for coreference decision. The evaluation on the ACE data set shows that the ILP based entity-mention model is effective for the coreference resolution task.", "num_citations": "115\n", "authors": ["1179"]}
{"title": "Document representation and feature combination for deceptive spam review detection\n", "abstract": " Deceptive spam reviews of products or service are harmful for customers in decision making. Existing approaches to detect deceptive spam reviews are concerned in feature designing. Hand-crafted features can show some linguistic phenomena, however can hardly reveal the latent semantic meaning of the review. We present a neural network based model to learn the representation of reviews. The model makes a hard attention through the composition from sentence representation into document representation. Specifically, we compute the importance weights of each sentence and incorporate them into the composition process of document representation. In the mixed-domain detection experiment, the results verify the effectiveness of our model by comparing with other neural network based methods. As the feature selection is very important in this direction, we make a feature combination to enhance the\u00a0\u2026", "num_citations": "109\n", "authors": ["1179"]}
{"title": "Sentence Compression for Aspect-Based Sentiment Analysis\n", "abstract": " Sentiment analysis, which addresses the computational treatment of opinion, sentiment, and subjectivity in text, has received considerable attention in recent years. In contrast to the traditional coarse-grained sentiment analysis tasks, such as document-level sentiment classification, we are interested in the fine-grained aspect-based sentiment analysis that aims to identify aspects that users comment on and these aspects' polarities. Aspect-based sentiment analysis relies heavily on syntactic features. However, the reviews that this task focuses on are natural and spontaneous, thus posing a challenge to syntactic parsers. In this paper, we address this problem by proposing a framework of adding a sentiment sentence compression (Sent_Comp) step before performing the aspect-based sentiment analysis. Different from the previous sentence compression model for common news sentences, Sent_Comp seeks to\u00a0\u2026", "num_citations": "109\n", "authors": ["1179"]}
{"title": "Mining User Consumption Intention from Social Media Using Domain Adaptive Convolutional Neural Network.\n", "abstract": " Social media platforms are often used by people to express their needs and desires. Such data offer great opportunities to identify users\u2019 consumption intention from user-generated contents, so that better tailored products or services can be recommended. However, there have been few efforts on mining commercial intents from social media contents. In this paper, we investigate the use of social media data to identify consumption intentions for individuals. We develop a Consumption Intention Mining Model (CIMM) based on convolutional neural network (CNN), for identifying whether the user has a consumption intention. The task is domain-dependent, and learning CNN requires a large number of annotated instances, which can be available only in some domains. Hence, we investigate the possibility of transferring the CNN mid-level sentence representation learned from one domain to another by adding an adaptation layer. To demonstrate the effectiveness of CIMM, we conduct experiments on two domains. Our results show that CIMM offers a powerful paradigm for effectively identifying users\u2019 consumption intention based on their social media data. Moreover, our results also confirm that the CNN learned in one domain can be effectively transferred to another domain. This suggests that a great potential for our model to significantly increase effectiveness of product recommendations and targeted advertising.", "num_citations": "104\n", "authors": ["1179"]}
{"title": "Constructing narrative event evolutionary graph for script event prediction\n", "abstract": " Script event prediction requires a model to predict the subsequent event given an existing event context. Previous models based on event pairs or event chains cannot make full use of dense event connections, which may limit their capability of event prediction. To remedy this, we propose constructing an event graph to better utilize the event network information for script event prediction. In particular, we first extract narrative event chains from large quantities of news corpus, and then construct a narrative event evolutionary graph (NEEG) based on the extracted chains. NEEG can be seen as a knowledge base that describes event evolutionary principles and patterns. To solve the inference problem on NEEG, we present a scaled graph neural network (SGNN) to model event interactions and learn better event representations. Instead of computing the representations on the whole graph, SGNN processes only the concerned nodes each time, which makes our model feasible to large-scale graphs. By comparing the similarity between input context event representations and candidate event representations, we can choose the most reasonable subsequent event. Experimental results on widely used New York Times corpus demonstrate that our model significantly outperforms state-of-the-art baseline methods, by using standard multiple choice narrative cloze evaluation.", "num_citations": "101\n", "authors": ["1179"]}
{"title": "\u5b9e\u4f53\u5173\u7cfb\u81ea\u52a8\u62bd\u53d6\n", "abstract": " (\u54c8\u5c14\u6ee8\u5de5\u4e1a\u5927\u5b66\u8ba1\u7b97\u673a\u5b66\u9662, \u9ed1\u9f99\u6c5f\u54c8\u5c14\u6ee8 150001) \u6458\u8981: \u5b9e\u4f53\u5173\u7cfb\u62bd\u53d6\u662f\u4fe1\u606f\u62bd\u53d6\u9886\u57df\u4e2d\u7684\u91cd\u8981\u7814\u7a76\u8bfe\u9898. \u672c\u6587\u4f7f\u7528\u4e24\u79cd\u57fa\u4e8e\u7279\u5f81\u5411\u91cf\u7684\u673a\u5668\u5b66\u4e60\u7b97\u6cd5, Winnow \u548c\u652f\u6301\u5411\u91cf\u673a (SVM), \u5728 2004 \u5e74 ACE (Automatic Content Extraction) \u8bc4\u6d4b\u7684\u8bad\u7ec3\u6570\u636e\u4e0a\u8fdb\u884c\u5b9e\u4f53\u5173\u7cfb\u62bd\u53d6\u5b9e\u9a8c. \u4e24\u79cd\u7b97\u6cd5\u90fd\u8fdb\u884c\u9002\u5f53\u7684\u7279\u5f81\u9009\u62e9, \u5f53\u9009\u62e9\u6bcf\u4e2a\u5b9e\u4f53\u7684\u5de6\u53f3\u4e24\u4e2a\u8bcd\u4e3a\u7279\u5f81\u65f6, \u8fbe\u5230\u6700\u597d\u7684\u62bd\u53d6\u6548\u679c, Win2 now \u548c SVM \u7b97\u6cd5\u7684\u52a0\u6743\u5e73\u5747 F2Score \u5206\u522b\u4e3a 73108% \u548c 73127%. \u53ef\u89c1\u5728\u4f7f\u7528\u76f8\u540c\u7684\u7279\u5f81\u96c6, \u4e0d\u540c\u7684\u5b66\u4e60\u7b97\u6cd5\u8fdb\u884c\u5b9e\u4f53\u5173\u7cfb\u7684\u8bc6\u522b\u65f6, \u6700\u7ec8\u6027\u80fd\u5dee\u522b\u4e0d\u5927. \u56e0\u6b64\u4f7f\u7528\u81ea\u52a8\u7684\u65b9\u6cd5\u8fdb\u884c\u5b9e\u4f53\u5173\u7cfb\u62bd\u53d6\u65f6, \u5e94\u5f53\u96c6\u4e2d\u7cbe\u529b\u5bfb\u627e\u597d\u7684\u7279\u5f81.", "num_citations": "101\n", "authors": ["1179"]}
{"title": "Target-dependent sentiment classification with long short term memory\n", "abstract": " Target-dependent sentiment classification remains a challenge: modeling the semantic relatedness of a target with its context words in a sentence. Different context words have different influences on determining the sentiment polarity of a sentence towards the target. Therefore, it is desirable to integrate the connections between target word and context words when building a learning system. In this paper, we develop two target dependent long short-term memory (LSTM) models, where target information is automatically taken into account. We evaluate our methods on a benchmark dataset from Twitter. Empirical results show that modeling sentence representation with standard LSTM does not perform well. Incorporating target information into LSTM can significantly boost the classification accuracy. The target-dependent LSTM models achieve state-of-the-art performances without using syntactic parser or external sentiment lexicons. 1", "num_citations": "99\n", "authors": ["1179"]}
{"title": "\u57fa\u4e8e\u5e38\u95ee\u95ee\u9898\u96c6\u7684\u4e2d\u6587\u95ee\u7b54\u7cfb\u7edf\u7814\u7a76\n", "abstract": " \u9996\u5148\u6839\u636e\u7528\u6237\u7684\u63d0\u95ee\u5efa\u7acb\u4e00\u4e2a\u5019\u9009\u95ee\u9898\u96c6,\u7136\u540e\u901a\u8fc7\u8ba1\u7b97\u53e5\u5b50\u8bed\u4e49\u76f8\u4f3c\u5ea6,\u5728\u5019\u9009\u95ee\u9898\u96c6\u4e2d\u627e\u5230\u76f8\u4f3c\u7684\u95ee\u53e5,\u5e76\u5c06\u7b54\u6848\u8fd4\u56de\u7ed9\u7528\u6237.\u8be5\u7cfb\u7edf\u8fd8\u80fd\u591f\u81ea\u52a8\u5730\u66f4\u65b0\u548c\u7ef4\u62a4FAQ\u5e93.\u5b9e\u9a8c\u8868\u660e,\u4e0e\u57fa\u4e8e\u5173\u952e\u8bcd\u7684\u53e5\u5b50\u76f8\u4f3c\u5ea6\u8ba1\u7b97\u76f8\u6bd4,\u57fa\u4e8e\u8bed\u4e49\u7684\u53e5\u5b50\u76f8\u4f3c\u5ea6\u8ba1\u7b97\u63d0\u9ad8\u4e86\u95ee\u9898\u5339\u914d\u7684\u51c6\u786e\u7387.", "num_citations": "99\n", "authors": ["1179"]}
{"title": "Named entity recognition with bilingual constraints\n", "abstract": " Different languages contain complementary cues about entities, which can be used to improve Named Entity Recognition (NER) systems. We propose a method that formulates the problem of exploring such signals on unannotated bilingual text as a simple Integer Linear Program, which encourages entity tags to agree via bilingual constraints. Bilingual NER experiments on the large OntoNotes 4.0 Chinese-English corpus show that the proposed method can improve strong baselines for both Chinese and English. In particular, Chinese performance improves by over 5% absolute F1 score. We can then annotate a large amount of bilingual text (80k sentence pairs) using our method, and add it as uptraining data to the original monolingual NER training corpus. The Chinese model retrained on this new combined dataset outperforms the strong baseline by over 3% F1 score.", "num_citations": "95\n", "authors": ["1179"]}
{"title": "Pivot approach for extracting paraphrase patterns from bilingual corpora\n", "abstract": " Paraphrase patterns are useful in paraphrase recognition and generation. In this paper, we present a pivot approach for extracting paraphrase patterns from bilingual parallel corpora, whereby the English paraphrase patterns are extracted using the sentences in a foreign language as pivots. We propose a loglinear model to compute the paraphrase likelihood of two patterns and exploit feature functions based on maximum likelihood estimation (MLE) and lexical weighting (LW). Using the presented method, we extract over 1,000,000 pairs of paraphrase patterns from 2M bilingual sentence pairs, the precision of which exceeds 67%. The evaluation results show that:(1) The pivot approach is effective in extracting paraphrase patterns, which significantly outperforms the conventional method DIRT. Especially, the log-linear model with the proposed feature functions achieves high performance.(2) The coverage of the extracted paraphrase patterns is high, which is above 84%.(3) The extracted paraphrase patterns can be classified into 5 types, which are useful in various applications.", "num_citations": "95\n", "authors": ["1179"]}
{"title": "Learning sense-specific word embeddings by exploiting bilingual resources\n", "abstract": " Recent work has shown success in learning word embeddings with neural network language models (NNLM). However, the majority of previous NNLMs represent each word with a single embedding, which fails to capture polysemy. In this paper, we address this problem by representing words with multiple and sense-specific embeddings, which are learned from bilingual parallel data. We evaluate our embeddings using the word similarity measurement and show that our approach is significantly better in capturing the sense-level word similarities. We further feed our embeddings as features in Chinese named entity recognition and obtain noticeable improvements against single embeddings.", "num_citations": "94\n", "authors": ["1179"]}
{"title": "A span-extraction dataset for chinese machine reading comprehension\n", "abstract": " Machine Reading Comprehension (MRC) has become enormously popular recently and has attracted a lot of attention. However, the existing reading comprehension datasets are mostly in English. In this paper, we introduce a Span-Extraction dataset for Chinese machine reading comprehension to add language diversities in this area. The dataset is composed by near 20,000 real questions annotated on Wikipedia paragraphs by human experts. We also annotated a challenge set which contains the questions that need comprehensive understanding and multi-sentence inference throughout the context. We present several baseline systems as well as anonymous submissions for demonstrating the difficulties in this dataset. With the release of the dataset, we hosted the Second Evaluation Workshop on Chinese Machine Reading Comprehension (CMRC 2018). We hope the release of the dataset could further accelerate the Chinese machine reading comprehension research. Resources are available: https://github.com/ymcui/cmrc2018", "num_citations": "93\n", "authors": ["1179"]}
{"title": "\u4e32\u9891\u7edf\u8ba1\u548c\u8bcd\u5f62\u5339\u914d\u76f8\u7ed3\u5408\u7684\u6c49\u8bed\u81ea\u52a8\u5206\u8bcd\u7cfb\u7edf\n", "abstract": " \u54c8\u5c14\u6ee8\u5de5\u4e1a\u5927\u5b66\u8ba1\u7b97\u673a\u7cfb 150001 [\u6458\u8981] \u672c\u6587\u4ecb\u7ecd\u4e86\u4e00\u79cd\u6c49\u8bed\u81ea\u52a8\u5206\u8bcd\u8f6f\u4ef6\u7cfb\u7edf, \u8be5\u7cfb\u7edf\u5bf9\u539f\u6587\u8fdb\u884c\u4e09\u904d\u626b\u63cf: \u7b2c\u4e00\u904d, \u5229\u7528\u5207\u5206\u6807\u8bb0\u5c06\u6587\u672c\u5207\u5206\u6210\u6c49\u5b57\u77ed\u4e32\u7684\u5e8f\u5217; \u7b2c\u4e8c\u904d, \u6839\u636e\u5404\u77ed\u4e32\u7684\u6bcf\u4e2a\u5b50\u4e32\u5728\u4e0a\u4e0b\u6587\u4e2d\u7684\u9891\u5ea6\u8ba1\u7b97\u5176\u6743\u503c, \u6743\u503c\u5927\u7684\u5b50\u4e32\u89c6\u4e3a\u5019\u9009\u8bcd; \u7b2c\u4e09\u904d, \u5229\u7528\u5019\u9009\u8bcd\u96c6\u548c\u4e00\u90e8\u5e38\u7528\u8bcd\u8bcd\u5178\u5bf9\u6c49\u5b57\u77ed\u4e32\u8fdb\u884c\u5207\u5206. \u5b9e\u9a8c\u8868\u660e, \u8be5\u5206\u8bcd\u7cfb\u7edf\u7684\u5206\u8bcd\u7cbe\u5ea6\u5728 1. 5% \u5de6\u53f3, \u80fd\u591f\u8bc6\u522b\u5927\u90e8\u5206\u751f\u8bcd, \u7279\u522b\u9002\u7528\u4e8e\u6587\u732e\u68c0\u7d22\u7b49\u9886\u57df.", "num_citations": "91\n", "authors": ["1179"]}
{"title": "A stack-propagation framework with token-level intent detection for spoken language understanding\n", "abstract": " Intent detection and slot filling are two main tasks for building a spoken language understanding (SLU) system. The two tasks are closely tied and the slots often highly depend on the intent. In this paper, we propose a novel framework for SLU to better incorporate the intent information, which further guides the slot filling. In our framework, we adopt a joint model with Stack-Propagation which can directly use the intent information as input for slot filling, thus to capture the intent semantic knowledge. In addition, to further alleviate the error propagation, we perform the token-level intent detection for the Stack-Propagation framework. Experiments on two publicly datasets show that our model achieves the state-of-the-art performance and outperforms other previous methods by a large margin. Finally, we use the Bidirectional Encoder Representation from Transformer (BERT) model in our framework, which further boost our performance in SLU task.", "num_citations": "87\n", "authors": ["1179"]}
{"title": "A general framework for content-enhanced network representation learning\n", "abstract": " This paper investigates the problem of network embedding, which aims at learning low-dimensional vector representation of nodes in networks. Most existing network embedding methods rely solely on the network structure, i.e., the linkage relationships between nodes, but ignore the rich content information associated with it, which is common in real world networks and beneficial to describing the characteristics of a node. In this paper, we propose content-enhanced network embedding (CENE), which is capable of jointly leveraging the network structure and the content information. Our approach integrates text modeling and structure modeling in a general framework by treating the content information as a special kind of node. Experiments on several real world net- works with application to node classification show that our models outperform all existing network embedding methods, demonstrating the merits of content information and joint learning.", "num_citations": "86\n", "authors": ["1179"]}
{"title": "Chinese parsing exploiting characters\n", "abstract": " Characters play an important role in the Chinese language, yet computational processing of Chinese has been dominated by word-based approaches, with leaves in syntax trees being words. We investigate Chinese parsing from the character-level, extending the notion of phrase-structure trees by annotating internal structures of words. We demonstrate the importance of character-level information to Chinese processing by building a joint segmentation, part-of-speech (POS) tagging and phrase-structure parsing system that integrates character-structure features. Our joint system significantly outperforms a state-of-the-art word-based baseline on the standard CTB5 test, and gives the best published results for Chinese parsing.", "num_citations": "86\n", "authors": ["1179"]}
{"title": "Topic detection and tracking review\n", "abstract": " Topic detection and tracking, as one of natural language processing technologies, is to detect unknown topic and track known topic from the information of news medium. Since its pilot research in 1996, several large-scale evaluation conferences have provided a good environment for evaluating technologies of recognition, collection and organization. As topic detection and tracking shares similar challenges with information retrieval, data mining and information extraction in abrupt and successive data, it has become a hot research issue in the field of nature language processing. This paper introduced the background, definition, evaluation and methods in topic detection and tracking, and explored its future development trend through analyzing current research.", "num_citations": "86\n", "authors": ["1179"]}
{"title": "Consensus attention-based neural networks for chinese reading comprehension\n", "abstract": " Reading comprehension has embraced a booming in recent NLP research. Several institutes have released the Cloze-style reading comprehension data, and these have greatly accelerated the research of machine comprehension. In this work, we firstly present Chinese reading comprehension datasets, which consist of People Daily news dataset and Children's Fairy Tale (CFT) dataset. Also, we propose a consensus attention-based neural network architecture to tackle the Cloze-style reading comprehension problem, which aims to induce a consensus attention over every words in the query. Experimental results show that the proposed neural network significantly outperforms the state-of-the-art baselines in several public datasets. Furthermore, we setup a baseline for Chinese reading comprehension task, and hopefully this would speed up the process for future research.", "num_citations": "84\n", "authors": ["1179"]}
{"title": "\u81ea\u52a8\u6587\u6458\u7684\u56db\u79cd\u4e3b\u8981\u65b9\u6cd5\n", "abstract": " \u672c\u6587\u5c06\u73b0\u6709\u7684\u81ea\u52a8\u6587\u6458\u65b9\u6cd5\u6982\u62ec\u4e3a\u56db\u79cd: \u81ea\u52a8\u6458\u5f55, \u57fa\u4e8e\u7406\u89e3\u7684\u81ea\u52a8\u6587\u6458, \u4fe1\u606f\u62bd\u53d6\u548c\u57fa\u4e8e\u7ed3\u6784\u7684\u81ea\u52a8\u6587\u6458, \u5e76\u8be6\u7ec6\u4ecb\u7ecd\u4e86\u8fd9\u56db\u79cd\u65b9\u6cd5\u7684\u57fa\u672c\u539f\u7406, \u5256\u6790\u4e86\u5b83\u4eec\u7684\u4f18\u70b9\u548c\u4e0d\u8db3. \u6700\u540e, \u6982\u8ff0\u4e86\u4e2d\u6587\u81ea\u52a8\u6587\u6458\u7684\u7814\u7a76\u72b6\u51b5.", "num_citations": "84\n", "authors": ["1179"]}
{"title": "Hashtag recommendation with topical attention-based LSTM\n", "abstract": " Microblogging services allow users to create hashtags to categorize their posts. In recent years, the task of recommending hashtags for microblogs has been given increasing attention. However, most of existing methods depend on hand-crafted features. Motivated by the successful use oflong short-term memory (LSTM) for many natural language processing tasks, in this paper, weadopt LSTM to learn the representation of a microblog post. Observing that hashtags indicatethe primary topics of microblog posts, we propose a novel attention-based LSTM model whichincorporates topic modeling into the LSTM architecture through an attention mechanism. Weevaluate our model using a large real-world dataset. Experimental results show that our modelsignificantly outperforms various competitive baseline methods. Furthermore, the incorporationof topical attention mechanism gives more than 7.4% improvement in F1\u00a0\u2026", "num_citations": "83\n", "authors": ["1179"]}
{"title": "Combining multiple resources to improve SMT-based paraphrasing model\n", "abstract": " This paper proposes a novel method that exploits multiple resources to improve statistical machine translation (SMT) based paraphrasing. In detail, a phrasal paraphrase table and a feature function are derived from each resource, which are then combined in a log-linear SMT model for sentence-level paraphrase generation. Experimental results show that the SMT-based paraphrasing model can be enhanced using multiple resources. The phrase-level and sentence-level precision of the generated paraphrases are above 60% and 55%, respectively. In addition, the contribution of each resource is evaluated, which indicates that all the exploited resources are useful for generating paraphrases of high quality.", "num_citations": "83\n", "authors": ["1179"]}
{"title": "\u57fa\u4e8e\u6539\u8fdb\u7f16\u8f91\u8ddd\u79bb\u7684\u4e2d\u6587\u76f8\u4f3c\u53e5\u5b50\u68c0\u7d22\n", "abstract": " \u4e2d\u6587\u76f8\u4f3c\u53e5\u5b50\u68c0\u7d22\u7684\u65b9\u6cd5\u5728\u57fa\u4e8e\u5b9e\u4f8b\u7684\u673a\u5668\u7ffb\u8bd1\u7b49\u4e2d\u6587\u4fe1\u606f\u5904\u7406\u9886\u57df,\u5177\u6709\u975e\u5e38\u5e7f\u6cdb\u7684\u5e94\u7528\u80cc\u666f.\u672c\u6587\u63d0\u51fa\u7684\u57fa\u4e8e\u6539\u8fdb\u7f16\u8f91\u8ddd\u79bb\u7684\u4e2d\u6587\u76f8\u4f3c\u53e5\u5b50\u68c0\u7d22\u65b9\u6cd5,\u5728\u4f7f\u7528\u4fe1\u606f\u68c0\u7d22\u6280\u672f\u63d0\u9ad8\u68c0\u7d22\u6548\u7387\u7684\u540c\u65f6,\u4ee5\u666e\u901a\u7f16\u8f91\u8ddd\u79bb\u7b97\u6cd5\u4e3a\u57fa\u7840,\u52a0\u5165\u4e86\u8bcd\u6c47\u7684\u8bed\u4e49\u4fe1\u606f,\u4f7f\u4e4b\u66f4\u52a0\u7b26\u5408\u4e2d\u6587\u53e5\u5b50\u76f8\u4f3c\u5ea6\u8ba1\u7b97\u7684\u8981\u6c42.\u6539\u8fdb\u7f16\u8f91\u8ddd\u79bb\u4e0e\u5355\u7eaf\u57fa\u4e8e\u8bed\u4e49\u8f9e\u5178\u8ba1\u7b97\u53e5\u5b50\u76f8\u4f3c\u5ea6\u7684\u65b9\u6cd5\u76f8\u6bd4,\u5177\u6709\u4fbf\u4e8e\u6269\u5c55,\u51c6\u786e\u7387\u9ad8\u7b49\u4f18\u70b9.\u5728\u57fa\u4e8e\u5927\u89c4\u6a21\u53cc\u8bed\u53e5\u5bf9\u68c0\u7d22\u7684\u82f1\u6587\u8f85\u52a9\u5199\u4f5c\u7cfb\u7edf\u4e2d\u4f7f\u7528\u8be5\u7b97\u6cd5\u8fdb\u884c\u4e2d\u6587\u53e5\u5b50\u68c0\u7d22,\u6700\u540e\u83b7\u5f97\u4e8681.33%\u7684\u67e5\u51c6\u7387\u548c95.31%\u7684\u67e5\u5168\u7387.", "num_citations": "82\n", "authors": ["1179"]}
{"title": "Joint models for Chinese POS tagging and dependency parsing\n", "abstract": " Part-of-speech (POS) is an indispensable feature in dependency parsing. Current research usually models POS tagging and dependency parsing independently. This may suffer from error propagation problem. Our experiments show that parsing accuracy drops by about 6% when using automatic POS tags instead of gold ones. To solve this issue, this paper proposes a solution by jointly optimizing POS tagging and dependency parsing in a unique model. We design several joint models and their corresponding decoding algorithms to incorporate different feature sets. We further present an effective pruning strategy to reduce the search space of candidate POS tags, leading to significant improvement of parsing speed. Experimental results on Chinese Penn Treebank 5 show that our joint models significantly improve the state-of-the-art parsing accuracy by about 1.5%. Detailed analysis shows that the joint method is able to choose such POS tags that are more helpful and discriminative from parsing viewpoint. This is the fundamental reason of parsing accuracy improvement.", "num_citations": "81\n", "authors": ["1179"]}
{"title": "Sequence-to-sequence data augmentation for dialogue language understanding\n", "abstract": " In this paper, we study the problem of data augmentation for language understanding in task-oriented dialogue system. In contrast to previous work which augments an utterance without considering its relation with other utterances, we propose a sequence-to-sequence generation based data augmentation framework that leverages one utterance's same semantic alternatives in the training data. A novel diversity rank is incorporated into the utterance representation to make the model produce diverse utterances and these diversely augmented utterances help to improve the language understanding module. Experimental results on the Airline Travel Information System dataset and a newly created semantic frame annotation on Stanford Multi-turn, Multidomain Dialogue Dataset show that our framework achieves significant improvements of 6.38 and 10.04 F-scores respectively when only a training set of hundreds utterances is represented. Case studies also confirm that our method generates diverse utterances.", "num_citations": "79\n", "authors": ["1179"]}
{"title": "Research on Chinese event extraction\n", "abstract": " Event Extraction is an important research point in the area of Information Extraction. This paper makes an intensive study of the two stages of Chinese event extraction, namely event type recognition and event argument recognition. A novel method combining event trigger expansion and a binary classifier is presented in the step of event type recognition while in the step of argument recognition, one with multi-class classification based on maximum entropy is introduced. The above methods solved the data unbalanced problem in training model and the data sparseness problem brought by the small set of training data effectively, and finally our event extraction system achieved a better performance.", "num_citations": "79\n", "authors": ["1179"]}
{"title": "A Representation Learning Framework for Multi-Source Transfer Parsing.\n", "abstract": " Cross-lingual model transfer has been a promising approach for inducing dependency parsers for low-resource languages where annotated treebanks are not available. The major obstacles for the model transfer approach are two-fold: 1. Lexical features are not directly transferable across languages; 2. Target language-specific syntactic structures are difficult to be recovered. To address these two challenges, we present a novel representation learning framework for multi-source transfer parsing. Our framework allows multi-source transfer parsing using full lexical features straightforwardly. By evaluating on the Google universal dependency treebanks (v2. 0), our best models yield an absolute improvement of 6.53% in averaged labeled attachment score, as compared with delexicalized multi-source transfer models. We also significantly outperform the state-of-the-art transfer system proposed most recently.", "num_citations": "78\n", "authors": ["1179"]}
{"title": "A joint segmentation and classification framework for sentence level sentiment classification\n", "abstract": " In this paper, we propose a joint segmentation and classification framework for sentence-level sentiment classification. It is widely recognized that phrasal information is crucial for sentiment classification. However, existing sentiment classification algorithms typically split a sentence as a word sequence, which does not effectively handle the inconsistent sentiment polarity between a phrase and the words it contains, such as {\u201cnot bad,\u201d \u201cbad\u201d} and {\u201ca great deal of,\u201d \u201cgreat\u201d}. We address this issue by developing a joint framework for sentence-level sentiment classification. It simultaneously generates useful segmentations and predicts sentence-level polarity based on the segmentation results. Specifically, we develop a candidate generation model to produce segmentation candidates of a sentence; a segmentation ranking model to score the usefulness of a segmentation candidate for sentiment classification; and a\u00a0\u2026", "num_citations": "78\n", "authors": ["1179"]}
{"title": "Knowledge-driven event embedding for stock prediction\n", "abstract": " Representing structured events as vectors in continuous space offers a new way for defining dense features for natural language processing (NLP) applications. Prior work has proposed effective methods to learn event representations that can capture syntactic and semantic information over text corpus, demonstrating their effectiveness for downstream tasks such as event-driven stock prediction. On the other hand, events extracted from raw texts do not contain background knowledge on entities and relations that they are mentioned. To address this issue, this paper proposes to leverage extra information from knowledge graph, which provides ground truth such as attributes and properties of entities and encodes valuable relations between entities. Specifically, we propose a joint model to combine knowledge graph information into the objective function of an event embedding learning model. Experiments on event similarity and stock market prediction show that our model is more capable of obtaining better event embeddings and making more accurate prediction on stock market volatilities.", "num_citations": "77\n", "authors": ["1179"]}
{"title": "Chinese Sentence Similarity Computing Based on Semantic Dependency Relationship Analysis\n", "abstract": " Sentence similarity computation is very important in all the fields of Natural Language Processing. In Multi-document Summarization Technology, sentence similarity computation is a key problem. As we know, a Chinese sentence can be presented by many kinds of style, if we want to describe what a sentence means, we should dip into the semantic level and consider about the dependency structure. In this paper, we applied a method that based on semantic dependency relationship analysis to compute sentence similarity, and the experiment result of this method is satisfied.", "num_citations": "77\n", "authors": ["1179"]}
{"title": "Character-level chinese dependency parsing\n", "abstract": " Recent work on Chinese analysis has led to large-scale annotations of the internal structures of words, enabling characterlevel analysis of Chinese syntactic structures. In this paper, we investigate the problem of character-level Chinese dependency parsing, building dependency trees over characters. Character-level information can benefit downstream applications by offering flexible granularities for word segmentation while improving wordlevel dependency parsing accuracies. We present novel adaptations of two major shift-reduce dependency parsing algorithms to character-level parsing. Experimental results on the Chinese Treebank demonstrate improved performances over word-based parsing methods. 1 IntroductionAs a light-weight formalism offering syntactic information to downstream applications such as SMT, the dependency grammar has received increasing interest in the syntax parsing community (McDonald et al., 2005; Nivre and Nilsson, 2005; Carreras et al., 2006; Duan et al., 2007; Koo and Collins, 2010; Zhang and Clark, 2008; Nivre, 2008; Bohnet, 2010; Zhang and Nivre, 2011; Choi and McCallum, 2013). Chinese dependency trees were conventionally defined over words (Chang et al., 2009; Li et al., 2012), requiring word segmentation and POS-tagging as pre-processing steps. Recent work on Chinese analysis has embarked on investigating the syntactic roles of characters, leading to large-scale annotations of word internal structures (Li, 2011; Zhang et al., 2013). Such annotations enable dependency parsing on the character level, building dependency trees over Chinese characters. Figure 1 (c) shows an example of", "num_citations": "76\n", "authors": ["1179"]}
{"title": "Multilingual dependency-based syntactic and semantic parsing\n", "abstract": " Our CoNLL 2009 Shared Task system includes three cascaded components: syntactic parsing, predicate classification, and semantic role labeling. A pseudo-projective high-order graph-based model is used in our syntactic dependency parser. A support vector machine (SVM) model is used to classify predicate senses. Semantic role labeling is achieved using maximum entropy (MaxEnt) model based semantic role classification and integer linear programming (ILP) based post inference. Finally, we win the first place in the joint task, including both the closed and open challenges.", "num_citations": "74\n", "authors": ["1179"]}
{"title": "Predicting movie Box-office revenues by exploiting large-scale social media content\n", "abstract": " Predicting the box-office revenue of a movie before its theatrical release is an important but challenging problem that requires a high level of Artificial Intelligence. Nowadays, social media has shown its predictive power in various domains, which motivates us to exploit social media content to predict box-office revenues. In this study, we employ both linear and non-linear regression models, which are based on the crowd wisdom of social media, especially the posts of users, to predict movie box-office revenues. More specifically, the attention and popularity of the movie, purchase intention of users, and comments of users are automatically mined from social media data. In our model, the use of Linear Regression and Support Vector Regression in predicting the box-office revenue of a movie before its theatrical release is explored. To evaluate the effectiveness of the proposed approach, a cross-validation\u00a0\u2026", "num_citations": "73\n", "authors": ["1179"]}
{"title": "\u57fa\u4e8e\u6700\u5927\u71b5\u5206\u7c7b\u5668\u7684\u8bed\u4e49\u89d2\u8272\u6807\u6ce8\n", "abstract": " \u8bed\u4e49\u89d2\u8272\u6807\u6ce8\u662f\u6d45\u5c42\u8bed\u4e49\u5206\u6790\u7684\u4e00\u79cd\u53ef\u884c\u65b9\u6848. \u63cf\u8ff0\u4e86\u4e00\u4e2a\u91c7\u7528\u6700\u5927\u71b5\u5206\u7c7b\u5668\u7684\u8bed\u4e49\u89d2\u8272\u6807\u6ce8\u7cfb\u7edf, \u8be5\u7cfb\u7edf\u628a\u53e5\u6cd5\u6210\u5206\u4f5c\u4e3a\u8bed\u4e49\u6807\u6ce8\u7684\u57fa\u672c\u5355\u5143, \u7528\u6700\u5927\u71b5\u5206\u7c7b\u5668\u5bf9\u53e5\u5b50\u4e2d\u8c13\u8bcd\u7684\u8bed\u4e49\u89d2\u8272\u540c\u65f6\u8fdb\u884c\u8bc6\u522b\u548c\u5206\u7c7b. \u6700\u5927\u71b5\u5206\u7c7b\u5668\u4e2d\u4f7f\u7528\u4e86\u4e00\u4e9b\u6709\u7528\u7684\u7279\u5f81\u53ca\u5176\u7ec4\u5408. \u5728\u540e\u5904\u7406\u9636\u6bb5, \u5728\u5177\u6709\u5d4c\u5957\u5173\u7cfb\u7684\u7ed3\u679c\u4e2d, \u53ea\u6709\u6982\u7387\u6700\u9ad8\u7684\u8bed\u4e49\u89d2\u8272\u88ab\u4fdd\u7559. \u5728\u9884\u6d4b\u4e86\u5168\u90e8\u80fd\u591f\u5728\u53e5\u6cd5\u5206\u6790\u6811\u4e2d\u627e\u5230\u5339\u914d\u6210\u5206\u7684\u89d2\u8272\u4ee5\u540e, \u91c7\u7528\u7b80\u5355\u7684\u540e\u5904\u7406\u89c4\u5219\u53bb\u8bc6\u522b\u90a3\u4e9b\u627e\u4e0d\u5230\u5339\u914d\u6210\u5206\u7684\u89d2\u8272. \u6700\u7ec8\u5728\u5f00\u53d1\u96c6\u548c\u6d4b\u8bd5\u96c6\u4e0a\u5206\u522b\u83b7\u5f97\u4e86 75.49% \u548c 75.60% \u7684 F1 \u503c, \u6b64\u7ed3\u679c\u662f\u5df2\u77e5\u7684\u57fa\u4e8e\u5355\u4e00\u53e5\u6cd5\u5206\u6790\u7ed3\u679c\u4e2d\u6700\u597d\u7684. \u6700\u540e\u63d0\u51fa\u4e86\u5bf9\u8be5\u4efb\u52a1\u7684\u4e00\u4e9b\u96be\u70b9\u95ee\u9898\u7684\u89e3\u51b3\u65b9\u6848\u4ee5\u53ca\u5bf9\u8bed\u4e49\u89d2\u8272\u6807\u6ce8\u53d1\u5c55\u7684\u4e00\u4e2a\u521d\u6b65\u5c55\u671b.", "num_citations": "71\n", "authors": ["1179"]}
{"title": "System and method for automatic detection of collocation mistakes in documents\n", "abstract": " A method and computer-readable medium are provided that construct a collocation mistake pattern database for use in writing in a first language by a person whose native language is a second language. The method includes obtaining a bilingual corpus having sentences in first and second languages and extracting second language word pairs from the second language sentences in the corpus. For each second language word pair extracted from the corpus, a corresponding first language word pair is extracted from the corresponding first language sentence in the corpus to determine a correct first language translation for the second language word pair. Also, for each second language word pair extracted from the corpus, a set of combinations of first language translation words corresponding to the second language word pair is created. Finally, for each second language word pair extracted from the corpus, the\u00a0\u2026", "num_citations": "69\n", "authors": ["1179"]}
{"title": "Domain adaptation for CRF-based Chinese word segmentation using free annotations\n", "abstract": " Supervised methods have been the dominant approach for Chinese word segmentation. The performance can drop significantly when the test domain is different from the training domain. In this paper, we study the problem of obtaining partial annotation from freely available data to help Chinese word segmentation on different domains. Different sources of free annotations are transformed into a unified form of partial annotation and a variant CRF model is used to leverage both fully and partially annotated data consistently. Experimental results show that the Chinese word segmentation model benefits from free partially annotated data. On the SIGHAN Bakeoff 2010 data, we achieve results that are competitive to the best reported in the literature.", "num_citations": "68\n", "authors": ["1179"]}
{"title": "Neural personalized response generation as domain adaptation\n", "abstract": " One of the most crucial problem on training personalized response generation models for conversational robots is the lack of large scale personal conversation data. To address the problem, we propose a two-phase approach, namely initialization then adaptation, to first pre-train an optimized RNN encoder-decoder model (LTS model) in a large scale conversational data for general response generation and then fine-tune the model in a small scale personal conversation data to generate personalized responses. For evaluation, we propose a novel human aided method, which can be seen as a quasi-Turing test, to evaluate the performance of the personalized response generation models. Experimental results show that the proposed personalized response generation model outperforms the state-of-the-art approaches to language model personalization and persona-based neural conversation generation\u00a0\u2026", "num_citations": "66\n", "authors": ["1179"]}
{"title": "The structure of customer satisfaction with cruise-line services: an empirical investigation based on online word of mouth\n", "abstract": " Given the importance of the cruise segment in the tourism industry and the limited number of prior studies in the area, this study empirically explores the structure of customer satisfaction with cruise-line services by evaluating the attributes of cruises that are significant to passengers. Using 44,993 voluntarily provided customer reviews published on a cruise guide website, a stepwise regression analysis is conducted to examine the effects of the attribute performance of cruises on customer satisfaction and dissatisfaction. The findings empirically confirm the validity of the two-factor theory of customer satisfaction in the cruise tourism context. The asymmetric relationship of some attributes makes it possible to identify dissatisfiers, satisfiers, and hybrid factors for the cruise industry overall and cruises on ships of different tonnage. The results can help managers in the cruise industry understand what aspects of cruises\u00a0\u2026", "num_citations": "66\n", "authors": ["1179"]}
{"title": "\u8bc4\u4ef7\u5bf9\u8c61\u62bd\u53d6\u53ca\u5176\u503e\u5411\u6027\u5206\u6790\n", "abstract": " \u60c5\u611f\u5206\u6790\u8fd1\u5e74\u6765\u5df2\u7ecf\u6210\u4e3a\u81ea\u7136\u8bed\u8a00\u5904\u7406\u9886\u57df\u7684\u70ed\u70b9\u95ee\u9898, \u8be5\u6587\u5bf9\u60c5\u611f\u5206\u6790\u4e2d\u7684\u4e24\u9879\u5173\u952e\u6280\u672f\u2014\u2014\u2014\u8bc4\u4ef7\u5bf9\u8c61\u62bd\u53d6\u548c\u503e\u5411\u6027\u5224\u65ad\u8fdb\u884c\u4e86\u6df1\u5165\u7814\u7a76. \u5728\u8bc4\u4ef7\u5bf9\u8c61\u62bd\u53d6\u9636\u6bb5, \u9996\u5148\u4f7f\u7528\u53e5\u6cd5\u5206\u6790\u7ed3\u679c\u83b7\u53d6\u5019\u9009\u8bc4\u4ef7\u5bf9\u8c61, \u7ee7\u800c\u7ed3\u5408\u57fa\u4e8e\u7f51\u7edc\u6316\u6398\u7684 PMI \u7b97\u6cd5\u548c\u540d\u8bcd\u526a\u679d\u7b97\u6cd5\u5bf9\u5019\u9009\u8bc4\u4ef7\u5bf9\u8c61\u8fdb\u884c\u7b5b\u9009. \u5728\u503e\u5411\u6027\u5224\u65ad\u9636\u6bb5, \u901a\u8fc7\u5206\u6790\u60c5\u611f\u53e5\u53e5\u578b, \u5f52\u7eb3\u76f8\u5e94\u7684\u5206\u6790\u89c4\u5219, \u4f7f\u7528\u65e0\u6307\u5bfc\u7684\u65b9\u6cd5\u5b8c\u6210\u8bc4\u4ef7\u5bf9\u8c61\u5728\u60c5\u611f\u53e5\u4e2d\u7684\u503e\u5411\u6027\u5224\u65ad. \u8be5\u7cfb\u7edf\u53c2\u52a0\u4e86 COA E2008 \u4efb\u52a1\u4e09\u7684\u8bc4\u6d4b, \u53d6\u5f97\u4e86\u8f83\u597d\u6210\u7ee9.", "num_citations": "66\n", "authors": ["1179"]}
{"title": "Comment target extraction and sentiment classification\n", "abstract": " The research on sentiment analysis is a hot issue in natural language processing. This paper makes an intensive study of the two stages of sentiment analysis: the comment target extraction and the corresponding sentiment classification. For the first task, we use the syntactic analysis to obtain the candidats, and then combine PMI based on web mining and NN filtering algorithm to decide the targets. For the second task, we design certain heuristic rules by analyzing subjective sentences, and then apply these rules to predict the orientation of opinion in the sentences. This method performs well in Task Three of the COAE2008 i.", "num_citations": "66\n", "authors": ["1179"]}
{"title": "Question answering system based on frequently asked questions\n", "abstract": " CiNii \u8ad6\u6587 - Chinese question answering system based on frequently asked questions CiNii \u56fd\u7acb\u60c5\u5831\u5b66\u7814\u7a76\u6240 \u5b66\u8853\u60c5\u5831\u30ca\u30d3\u30b2\u30fc\u30bf[\u30b5\u30a4\u30cb\u30a3] \u65e5\u672c\u306e\u8ad6\u6587\u3092\u3055\u304c\u3059 \u5927\u5b66\u56f3\u66f8\u9928\u306e\u672c\u3092\u3055\u304c\u3059 \u65e5\u672c\u306e\u535a\u58eb\u8ad6\u6587\u3092\u3055\u304c\u3059 \u65b0\u898f\u767b\u9332 \u30ed\u30b0\u30a4\u30f3 English \u691c\u7d22 \u3059\u3079\u3066 \u672c\u6587\u3042\u308a \u3059\u3079\u3066 \u672c\u6587\u3042\u308a \u9589\u3058\u308b \u30bf\u30a4\u30c8\u30eb \u8457\u8005\u540d \u8457\u8005ID \u8457\u8005\u6240\u5c5e \u520a\u884c\u7269\u540d ISSN \u5dfb\u53f7\u30da\u30fc\u30b8 \u51fa\u7248\u8005 \u53c2\u8003\u6587\u732e \u51fa\u7248\u5e74 \u5e74\u304b\u3089 \u5e74\u307e\u3067 \u691c\u7d22 \u691c\u7d22 \u691c\u7d22 CiNii\u7a93\u53e3\u696d\u52d9\u306e\u518d\u958b\u306b\u3064\u3044\u3066 Chinese question answering system based on frequently asked questions QIN B. \u88ab\u5f15\u7528\u6587\u732e: 1\u4ef6 \u8457\u8005 QIN B. \u53ce\u9332\u520a\u884c\u7269 J. Harbin Institute of Technology J. Harbin Institute of Technology 10, 1179-1182, 2003 \u88ab\u5f15\u7528\u6587\u732e: 1\u4ef6\u4e2d 1-1\u4ef6\u3092 \u8868\u793a 1 A New Question Answering System for Chinese Restricted Domain HU Haiqing , JIANG Peilin , REN Fuji , KUROIWA Shingo IEICE transactions on information and systems 89(6), 1848-1859, 2006-06-01 \u53c2\u8003\u6587\u732e36\u4ef6 \u88ab\u5f15\u7528\u6587\u732e2\u4ef6 Tweet \u5404\u7a2e\u30b3\u30fc\u30c9 NII\u8ad6\u6587ID(NAID) \u2026", "num_citations": "65\n", "authors": ["1179"]}
{"title": "Effective Deep Memory Networks for Distant Supervised Relation Extraction.\n", "abstract": " Distant supervised relation extraction (RE) has been an effective way of finding novel relational facts from text without labeled training data. Typically it can be formalized as a multi-instance multilabel problem. In this paper, we introduce a novel neural approach for distant supervised RE with special focus on attention mechanisms. Unlike the feature-based logistic regression model and compositional neural models such as CNN, our approach includes two major attention-based memory components, which are capable of explicitly capturing the importance of each context word for modeling the representation of the entity pair, as well as the intrinsic dependencies between relations. Such importance degree and dependency relationship are calculated with multiple computational layers, each of which is a neural attention model over an external memory. Experiment on real-world datasets shows that our approach performs significantly and consistently better than various baselines.", "num_citations": "64\n", "authors": ["1179"]}
{"title": "\u4e2d\u6587\u4e8b\u4ef6\u62bd\u53d6\u6280\u672f\u7814\u7a76\n", "abstract": " \u4e8b\u4ef6\u62bd\u53d6\u662f\u4fe1\u606f\u62bd\u53d6\u9886\u57df\u4e00\u4e2a\u91cd\u8981\u7684\u7814\u7a76\u65b9\u5411, \u672c\u6587\u5bf9\u4e8b\u4ef6\u62bd\u53d6\u7684\u4e24\u9879\u5173\u952e\u6280\u672f\u2014\u2014\u2014\u4e8b\u4ef6\u7c7b\u522b\u8bc6\u522b\u4ee5\u53ca\u4e8b\u4ef6\u5143\u7d20\u8bc6\u522b\u8fdb\u884c\u4e86\u6df1\u5165\u7814\u7a76. \u5728\u4e8b\u4ef6\u7c7b\u522b\u8bc6\u522b\u9636\u6bb5, \u672c\u6587\u91c7\u7528\u4e86\u4e00\u79cd\u57fa\u4e8e\u89e6\u53d1\u8bcd\u6269\u5c55\u548c\u4e8c\u5143\u5206\u7c7b\u76f8\u7ed3\u5408\u7684\u65b9\u6cd5; \u5728\u4e8b\u4ef6\u5143\u7d20\u8bc6\u522b\u9636\u6bb5, \u672c\u6587\u91c7\u7528\u4e86\u57fa\u4e8e\u6700\u5927\u71b5\u7684\u591a\u5143\u5206\u7c7b\u7684\u65b9\u6cd5. \u8fd9\u4e9b\u65b9\u6cd5\u5f88\u597d\u7684\u89e3\u51b3\u4e86\u4e8b\u4ef6\u62bd\u53d6\u4e2d\u8bad\u7ec3\u5b9e\u4f8b\u6b63\u53cd\u4f8b\u4e0d\u5e73\u8861\u4ee5\u53ca\u6570\u636e\u7a00\u758f\u95ee\u9898, \u53d6\u5f97\u4e86\u8f83\u597d\u7684\u7cfb\u7edf\u6027\u80fd.", "num_citations": "64\n", "authors": ["1179"]}
{"title": "Constructing and embedding abstract event causality networks from text snippets\n", "abstract": " In this paper, we formally define the problem of representing and leveraging abstract event causality to power downstream applications. We propose a novel solution to this problem, which build an abstract causality network and embed the causality network into a continuous vector space. The abstract causality network is generalized from a specific one, with abstract event nodes represented by frequently co-occurring word pairs. To perform the embedding task, we design a dual cause-effect transition model. Therefore, the proposed method can obtain general, frequent, and simple causality patterns, meanwhile, simplify event matching. Given the causality network and the learned embeddings, our model can be applied to a wide range of applications such as event prediction, event clustering and stock market movement prediction. Experimental results demonstrate that 1) the abstract causality network is effective\u00a0\u2026", "num_citations": "62\n", "authors": ["1179"]}
{"title": "Joint word alignment and bilingual named entity recognition using dual decomposition\n", "abstract": " Translated bi-texts contain complementary language cues, and previous work on Named Entity Recognition (NER) has demonstrated improvements in performance over monolingual taggers by promoting agreement of tagging decisions between the two languages. However, most previous approaches to bilingual tagging assume word alignments are given as fixed input, which can cause cascading errors. We observe that NER label information can be used to correct alignment mistakes, and present a graphical model that performs bilingual NER tagging jointly with word alignment, by combining two monolingual tagging models with two unidirectional alignment models. We introduce additional cross-lingual edge factors that encourage agreements between tagging and alignment decisions. We design a dual decomposition inference algorithm to perform joint decoding over the combined alignment and NER output space. Experiments on the OntoNotes dataset demonstrate that our method yields significant improvements in both NER and word alignment over state-of-the-art monolingual baselines.", "num_citations": "62\n", "authors": ["1179"]}
{"title": "Cross-lingual BERT transformation for zero-shot dependency parsing\n", "abstract": " This paper investigates the problem of learning cross-lingual representations in a contextual space. We propose Cross-Lingual BERT Transformation (CLBT), a simple and efficient approach to generate cross-lingual contextualized word embeddings based on publicly available pre-trained BERT models (Devlin et al., 2018). In this approach, a linear transformation is learned from contextual word alignments to align the contextualized embeddings independently trained in different languages. We demonstrate the effectiveness of this approach on zero-shot cross-lingual transfer parsing. Experiments show that our embeddings substantially outperform the previous state-of-the-art that uses static embeddings. We further compare our approach with XLM (Lample and Conneau, 2019), a recently proposed cross-lingual language model trained with massive parallel data, and achieve highly competitive results.", "num_citations": "59\n", "authors": ["1179"]}
{"title": "A graph-based method for entity linking\n", "abstract": " In this paper, we formalize the task of finding a knowledge base entry that a given named entity mention refers to, namely entity linking, by identifying the most \u201cimportant\u201d node among the graph nodes representing the candidate entries. With the aim of ranking these entities by their \u201cimportance\u201d, we introduce three degree-based measures of graph connectivity. Experimental results on the TACKBP benchmark data sets show that our graph-based method performs comparably with the state-of-the-art methods. We also show that using the name phrase feature outperforms the commonly used bagof-word feature for entity linking.", "num_citations": "59\n", "authors": ["1179"]}
{"title": "Generalizing syntactic structures for product attribute candidate extraction\n", "abstract": " Noun phrases (NP) in a product review are always considered as the product attribute candidates in previous work. However, this method limits the recall of the product attribute extraction. We therefore propose a novel approach by generalizing syntactic structures of the product attributes with two strategies: intuitive heuristics and syntactic structure similarity. Experiments show that the proposed approach is effective.", "num_citations": "59\n", "authors": ["1179"]}
{"title": "Hierarchical attention flow for multiple-choice reading comprehension\n", "abstract": " In this paper, we focus on multiple-choice reading comprehension which aims to answer a question given a passage and multiple candidate options. We present the hierarchical attention flow to adequately leverage candidate options to model the interactions among passages, questions and candidate options. We observe that leveraging candidate options to boost evidence gathering from the passages play a vital role in this task, which is ignored in previous works. In addition, we explicitly model the option correlations with attention mechanism to obtain better option representations, which are further fed into a bilinear layer to obtain the ranking score for each option. On a large-scale multiple-choice reading comprehension dataset (ie the RACE dataset), the proposed model outperforms two previous neural network baselines on both RACE-M and RACE-H subsets and yields the state-of-the-art overall results.", "num_citations": "58\n", "authors": ["1179"]}
{"title": "\u81ea\u7136\u8bed\u8a00\u6587\u672c\u6c34\u5370\n", "abstract": " (\u54c8\u5c14\u6ee8\u5de5\u4e1a\u5927\u5b66\u8ba1\u7b97\u673a\u5b66\u9662\u4fe1\u606f\u68c0\u7d22\u5b9e\u9a8c\u5ba4, \u9ed1\u9f99\u6c5f\u54c8\u5c14\u6ee8 150001) \u6458\u8981: \u672c\u6587\u4e3b\u8981\u4ecb\u7ecd\u4e86\u57fa\u4e8e\u81ea\u7136\u8bed\u8a00\u5904\u7406\u7684\u6587\u672c\u6c34\u5370\u6280\u672f, \u4e5f\u5373\u81ea\u7136\u8bed\u8a00\u6587\u672c\u6c34\u5370\u6280\u672f. \u8be5\u6280\u672f\u662f\u5728\u4e0d\u6539\u53d8\u6587\u672c\u539f\u610f\u7684\u524d\u63d0\u4e0b, \u5c06\u9700\u8981\u9690\u85cf\u7684\u6587\u672c\u4fe1\u606f (\u6c34\u5370\u4fe1\u606f) \u63d2\u5165\u5230\u539f\u59cb\u6587\u672c\u4e2d\u7684\u4e00\u79cd\u4fe1\u606f\u9690\u85cf\u6280\u672f. \u8fd9\u79cd\u6280\u672f\u5bf9\u4e8e\u786e\u8ba4\u4fe1\u606f\u6765\u6e90\u548c\u4fe1\u606f\u7684\u79d8\u5bc6\u4f20\u9001, \u4ee5\u53ca\u7248\u6743\u7ef4\u62a4\u7b49\u65b9\u9762\u90fd\u6709\u7740\u5f88\u5927\u7684\u5e94\u7528\u4ef7\u503c. \u672c\u6587\u9996\u5148\u7ed9\u51fa\u4e86\u57fa\u4e8e\u81ea\u7136\u8bed\u8a00\u5904\u7406\u6280\u672f\u7684\u6587\u672c\u6c34\u5370\u7684\u6982\u5ff5, \u7279\u70b9\u53ca\u653b\u51fb\u6a21\u578b, \u5e76\u5bf9\u6587\u672c\u6c34\u5370\u7684\u7814\u7a76\u73b0\u72b6\u8fdb\u884c\u4e86\u5206\u6790. \u901a\u8fc7\u5206\u6790\u53ef\u4ee5\u770b\u51fa, \u81ea\u7136\u8bed\u8a00\u6587\u672c\u6c34\u5370\u6280\u672f\u6709\u7740\u66f4\u597d\u7684\u7075\u6d3b\u6027, \u5e76\u4e14\u5728\u9002\u5ea6\u7684\u653b\u51fb\u4e0b, \u4e0d\u4f1a\u7834\u574f\u6c34\u5370\u4fe1\u606f. \u672c\u6587\u8be6\u7ec6\u4ecb\u7ecd\u4e86\u6587\u672c\u6c34\u5370\u7cfb\u7edf\u7684\u8bbe\u8ba1\u8fc7\u7a0b, \u5305\u62ec\u8be5\u6280\u672f\u7684\u57fa\u7840\u6570\u5b66\u7406\u8bba-\u4e8c\u6b21\u4f59\u6570\u7406\u8bba. \u6700\u540e\u8be6\u7ec6\u4ecb\u7ecd\u4e86\u4e24\u79cd\u81ea\u7136\u8bed\u8a00\u6587\u672c\u6c34\u5370\u5d4c\u5165\u65b9\u6cd5, \u5206\u522b\u662f\u57fa\u4e8e\u53e5\u6cd5\u5206\u6790\u548c\u57fa\u4e8e\u8bed\u4e49\u7684\u6c34\u5370\u5d4c\u5165\u65b9\u6cd5.", "num_citations": "58\n", "authors": ["1179"]}
{"title": "Chinese question answering system based on frequently asked questions\n", "abstract": " CiNii \u8ad6\u6587 - Chinese question answering system based on frequently asked questions CiNii \u56fd\u7acb\u60c5\u5831\u5b66\u7814\u7a76\u6240 \u5b66\u8853\u60c5\u5831\u30ca\u30d3\u30b2\u30fc\u30bf[\u30b5\u30a4\u30cb\u30a3] \u65e5\u672c\u306e\u8ad6\u6587\u3092\u3055\u304c\u3059 \u5927\u5b66\u56f3\u66f8\u9928\u306e\u672c\u3092\u3055\u304c\u3059 \u65e5\u672c\u306e\u535a\u58eb\u8ad6\u6587\u3092\u3055\u304c\u3059 \u65b0\u898f\u767b\u9332 \u30ed\u30b0\u30a4\u30f3 English \u691c\u7d22 \u3059\u3079\u3066 \u672c\u6587\u3042\u308a \u3059\u3079\u3066 \u672c\u6587\u3042\u308a \u9589\u3058\u308b \u30bf\u30a4\u30c8\u30eb \u8457\u8005\u540d \u8457\u8005ID \u8457\u8005\u6240\u5c5e \u520a\u884c\u7269\u540d ISSN \u5dfb\u53f7\u30da\u30fc\u30b8 \u51fa\u7248\u8005 \u53c2\u8003\u6587\u732e \u51fa\u7248\u5e74 \u5e74\u304b\u3089 \u5e74\u307e\u3067 \u691c\u7d22 \u691c\u7d22 \u691c\u7d22 CiNii\u7a93\u53e3\u696d\u52d9\u306e\u518d\u958b\u306b\u3064\u3044\u3066 Chinese question answering system based on frequently asked questions QIN B. \u88ab\u5f15\u7528\u6587\u732e: 1\u4ef6 \u8457\u8005 QIN B. \u53ce\u9332\u520a\u884c\u7269 J. Harbin Institute of Technology J. Harbin Institute of Technology 10, 1179-1182, 2003 \u88ab\u5f15\u7528\u6587\u732e: 1\u4ef6\u4e2d 1-1\u4ef6\u3092 \u8868\u793a 1 A New Question Answering System for Chinese Restricted Domain HU Haiqing , JIANG Peilin , REN Fuji , KUROIWA Shingo IEICE transactions on information and systems 89(6), 1848-1859, 2006-06-01 \u53c2\u8003\u6587\u732e36\u4ef6 \u88ab\u5f15\u7528\u6587\u732e2\u4ef6 Tweet \u5404\u7a2e\u30b3\u30fc\u30c9 NII\u8ad6\u6587ID(NAID) \u2026", "num_citations": "57\n", "authors": ["1179"]}
{"title": "A neural multi-task learning framework to jointly model medical named entity recognition and normalization\n", "abstract": " State-of-the-art studies have demonstrated the superiority of joint modeling over pipeline implementation for medical named entity recognition and normalization due to the mutual benefits between the two processes. To exploit these benefits in a more sophisticated way, we propose a novel deep neural multi-task learning framework with explicit feedback strategies to jointly model recognition and normalization. On one hand, our method benefits from the general representations of both tasks provided by multi-task learning. On the other hand, our method successfully converts hierarchical tasks into a parallel multi-task setting while maintaining the mutual supports between tasks. Both of these aspects improve the model performance. Experimental results demonstrate that our method performs significantly better than state-of-theart approaches on two publicly available medical literature datasets.", "num_citations": "56\n", "authors": ["1179"]}
{"title": "Semantic parsing with syntax-and table-aware sql generation\n", "abstract": " We present a generative model to map natural language questions into SQL queries. Existing neural network based approaches typically generate a SQL query word-by-word, however, a large portion of the generated results are incorrect or not executable due to the mismatch between question words and table contents. Our approach addresses this problem by considering the structure of table and the syntax of SQL language. The quality of the generated SQL query is significantly improved through (1) learning to replicate content from column names, cells or SQL keywords; and (2) improving the generation of WHERE clause by leveraging the column-cell relation. Experiments are conducted on WikiSQL, a recently released dataset with the largest question-SQL pairs. Our approach significantly improves the state-of-the-art execution accuracy from 69.0% to 74.4%.", "num_citations": "55\n", "authors": ["1179"]}
{"title": "Exploring segment representations for neural segmentation models\n", "abstract": " Many natural language processing (NLP) tasks can be generalized into segmentation problem. In this paper, we combine semi-CRF with neural network to solve NLP segmentation tasks. Our model represents a segment both by composing the input units and embedding the entire segment. We thoroughly study different composition functions and different segment embeddings. We conduct extensive experiments on two typical segmentation tasks: named entity recognition (NER) and Chinese word segmentation (CWS). Experimental results show that our neural semi-CRF model benefits from representing the entire segment and achieves the state-of-the-art performance on CWS benchmark dataset and competitive results on the CoNLL03 dataset.", "num_citations": "55\n", "authors": ["1179"]}
{"title": "\u591a\u6587\u6863\u81ea\u52a8\u6587\u6458\u7efc\u8ff0\n", "abstract": " \u591a\u6587\u6863\u6587\u6458\u662f\u5c06\u540c\u4e00\u4e3b\u9898\u4e0b\u7684\u591a\u4e2a\u6587\u672c\u63cf\u8ff0\u7684\u4e3b\u8981\u7684\u4fe1\u606f\u6309\u538b\u7f29\u6bd4\u63d0\u70bc\u4e3a\u4e00\u4e2a\u6587\u672c\u7684\u81ea\u7136\u8bed\u8a00\u5904\u7406\u6280\u672f. \u968f\u7740\u4e92\u8054\u7f51\u4e0a\u4fe1\u606f\u7684\u65e5\u76ca\u4e30\u5bcc, \u591a\u6587\u6863\u6587\u6458\u6280\u672f\u6210\u4e3a\u65b0\u7684\u7814\u7a76\u70ed\u70b9. \u672c\u6587\u4ecb\u7ecd\u4e86\u591a\u6587\u6863\u6587\u6458\u7684\u4ea7\u751f\u548c\u5e94\u7528\u80cc\u666f, \u9610\u8ff0\u4e86\u591a\u6587\u6863\u6587\u6458\u548c\u5176\u4ed6\u81ea\u7136\u8bed\u8a00\u5904\u7406\u6280\u672f\u7684\u5173\u7cfb, \u5bf9\u591a\u6587\u6863\u6587\u6458\u56fd\u5185\u5916\u7814\u7a76\u73b0\u72b6\u8fdb\u884c\u4e86\u5206\u6790, \u5728\u6b64\u57fa\u7840\u4e0a\u6c47\u603b\u63d0\u51fa\u4e86\u591a\u6587\u6863\u6587\u6458\u7814\u7a76\u7684\u57fa\u672c\u8def\u7ebf\u53ca\u5173\u952e\u6280\u672f, \u5e76\u603b\u7ed3\u4e86\u591a\u6587\u6863\u6587\u6458\u7684\u672a\u6765\u53ca\u53d1\u5c55\u8d8b\u52bf.", "num_citations": "55\n", "authors": ["1179"]}
{"title": "Joint extraction of entities and relations based on a novel graph scheme.\n", "abstract": " Both entity and relation extraction can benefit from being performed jointly, allowing each task to correct the errors of the other. Most existing neural joint methods extract entities and relations separately and achieve joint learning through parameter sharing, leading to a drawback that information between output entities and relations cannot be fully exploited. In this paper, we convert the joint task into a directed graph by designing a novel graph scheme and propose a transition-based approach to generate the directed graph incrementally, which can achieve joint learning through joint decoding. Our method can model underlying dependencies not only between entities and relations, but also between relations. Experiments on NewYork Times (NYT) corpora show that our approach outperforms the state-of-the-art methods.", "num_citations": "54\n", "authors": ["1179"]}
{"title": "Robust extraction of metaphor from novel data\n", "abstract": " This article describes our novel approach to the automated detection and analysis of metaphors in text. We employ robust, quantitative language processing to implement a system prototype combined with sound social science methods for validation. We show results in 4 different languages and discuss how our methods are a significant step forward from previously established techniques of metaphor identification. We use Topical Structure and Tracking, an Imageability score, and innovative methods to build an effective metaphor identification system that is fully automated and performs well over baseline.", "num_citations": "52\n", "authors": ["1179"]}
{"title": "Leveraging multiple MT engines for paraphrase generation\n", "abstract": " This paper proposes a method that leverages multiple machine translation (MT) engines for paraphrase generation (PG). The method includes two stages. Firstly, we use a multi-pivot approach to acquire a set of candidate paraphrases for a source sentence S. Then, we employ two kinds of techniques, namely the selection-based technique and the decoding-based technique, to produce a best paraphrase T for S using the candidates acquired in the first stage. Experimental results show that:(1) The multi-pivot approach is effective for obtaining plenty of valuable candidate paraphrases.(2) Both the selectionbased and decoding-based techniques can make good use of the candidates and produce high-quality paraphrases. Moreover, these two techniques are complementary.(3) The proposed method outperforms a state-of-the-art paraphrase generation approach.", "num_citations": "51\n", "authors": ["1179"]}
{"title": "Event causality extraction based on connectives analysis\n", "abstract": " Causality is an important type of relation which is crucial in numerous tasks, such as predicting future events, generating scenario, question answering, textual entailment and discourse comprehension. Therefore, causality extraction is a fundamental task in text mining. Many efforts have been dedicated to extracting causality from texts utilizing patterns, constraints and machine learning techniques. This paper presents a new Restricted Hidden Naive Bayes model to extract causality from texts. Besides some commonly used features, such as contextual features, syntactic features, position features, we also utilize a new category feature of causal connectives. This new feature is obtained from the tree kernel similarity of sentences containing connectives. In previous studies, the features have been usually assumed to be independent, which is not the case in reality. The advantage of our model lies in its ability to cope\u00a0\u2026", "num_citations": "50\n", "authors": ["1179"]}
{"title": "Semantic role labeling system using maximum entropy classifier\n", "abstract": " A maximum entropy classifier is used in our semantic role labeling system, which takes syntactic constituents as the labeling units. The maximum entropy classifier is trained to identify and classify the predicates\u2019 semantic arguments together. Only the constituents with the largest probability among embedding ones are kept. After predicting all arguments which have matching constituents in full parsing trees, a simple rule-based post-processing is applied to correct the arguments which have no matching constituents in these trees. Some useful features and their combinations are evaluated.", "num_citations": "49\n", "authors": ["1179"]}
{"title": "\u5fae\u535a\u7528\u6237\u7684\u76f8\u4f3c\u6027\u5ea6\u91cf\u53ca\u5176\u5e94\u7528\n", "abstract": " \u6458 \u8981 \u5fae\u535a\u7528\u6237\u7684\u5174\u8da3\u5206\u6790\u548c\u6a21\u578b\u8868\u793a\u662f\u7528\u6237\u5173\u7cfb\u5206\u6790\u7684\u57fa\u7840, \u800c\u7528\u6237\u5173\u7cfb\u5206\u6790\u53c8\u6784\u6210\u4e86\u5fae\u535a\u793e\u4f1a\u7f51\u7edc\u7684\u751f\u6210\u548c\u5206\u6790\u7684\u57fa\u7840. \u8be5\u6587\u4e3b\u8981\u8ba8\u8bba\u5fae\u535a\u7684\u7528\u6237\u5173\u7cfb\u5206\u6790\u6280\u672f. \u4f5c\u8005\u5c06\u5fae\u535a\u793e\u4f1a\u7f51\u7edc\u89c6\u4e3a\u4e00\u4e2a\u52a0\u6743\u65e0\u5411\u56fe, \u8282\u70b9\u8868\u793a\u7528\u6237, \u8fb9\u8868\u793a\u7528\u6237\u4e4b\u95f4\u7684\u5173\u7cfb, \u8fb9\u7684\u6743\u503c\u8868\u793a\u7528\u6237\u4e4b\u95f4\u7684\u5173\u7cfb\u5f3a\u5ea6. \u8be5\u6587\u5c06\u7528\u6237\u5173\u7cfb\u5f3a\u5ea6\u5b9a\u4e49\u4e3a\u7528\u6237\u4e4b\u95f4\u7684\u76f8\u4f3c\u5ea6, \u5206\u522b\u7ed9\u51fa\u4e86\u57fa\u4e8e\u5404\u79cd\u7528\u6237\u5c5e\u6027\u4fe1\u606f (\u80cc\u666f\u4fe1\u606f, \u5fae\u535a\u6587\u672c, \u793e\u4ea4\u4fe1\u606f) \u7684\u7528\u6237\u76f8\u4f3c\u5ea6\u8ba1\u7b97\u65b9\u6cd5, \u5e76\u901a\u8fc7\u5b9e\u9a8c\u7cfb\u7edf\u6027\u5bf9\u6bd4\u4e86\u4e0a\u8ff0\u65b9\u6cd5\u7684\u4f18\u52a3. \u5b9e\u9a8c\u7ed3\u679c\u663e\u793a: \u57fa\u4e8e\u793e\u4ea4\u4fe1\u606f\u7684\u7528\u6237\u76f8\u4f3c\u5ea6\u5728\u7528\u6237\u5173\u7cfb\u5206\u6790\u65b9\u9762\u53d6\u5f97\u4e86\u6700\u597d\u7684\u6548\u679c. \u4e3a\u4e86\u8fdb\u4e00\u6b65\u9a8c\u8bc1\u4e0a\u8ff0\u7528\u6237\u76f8\u4f3c\u5ea6\u7684\u5b9e\u9645\u6027\u80fd, \u8be5\u6587\u5c06\u5b83\u4eec\u5e94\u7528\u4e8e\u7528\u6237\u63a8\u8350\u7684\u76f8\u5173\u5b9e\u9a8c, \u57fa\u4e8e\u793e\u4ea4\u4fe1\u606f\u7684\u7528\u6237\u76f8\u4f3c\u5ea6\u53c8\u53d6\u5f97\u4e86\u6700\u597d\u7684\u63a8\u8350\u6548\u679c. \u6700\u540e, \u8be5\u6587\u5e94\u7528\u57fa\u4e8e\u793e\u4ea4\u4fe1\u606f\u7684\u7528\u6237\u76f8\u4f3c\u5ea6\u751f\u6210\u4e86\u5fae\u535a\u7684\u793e\u4f1a\u7f51\u7edc (\u79f0\u4f5c\u7528\u6237\u76f8\u4f3c\u6027\u7f51\u7edc), \u5728\u8be5\u793e\u4f1a\u7f51\u7edc\u4e0a\u8fdb\u884c\u4e86\u56e2\u4f53\u6316\u6398\u7684\u5b9e\u9a8c, \u5b9e\u9a8c\u7ed3\u679c\u663e\u793a\u4e86\u8be5\u76f8\u4f3c\u5ea6\u5728\u56e2\u4f53\u6316\u6398\u4e0a\u7684\u6709\u6548\u6027.", "num_citations": "48\n", "authors": ["1179"]}
{"title": "Semantic role labeling using a grammar-driven convolution tree kernel\n", "abstract": " Convolution tree kernel has shown promising results in semantic role labeling (SRL). However, this kernel does not consider much linguistic knowledge in kernel design and only performs hard matching between subtrees. To overcome these constraints, this paper proposes a grammar-driven convolution tree kernel for SRL by introducing more linguistic knowledge. Compared with the standard convolution tree kernel, the proposed grammar-driven kernel has two advantages: 1) grammar-driven approximate substructure matching, and 2) grammar-driven approximate tree node matching. The two approximate matching mechanisms enable the proposed kernel to better explore linguistically motivated structured knowledge. Experiments on the CoNLL-2005 SRL shared task and the PropBank I corpus show that the proposed kernel outperforms the standard convolution tree kernel significantly. Moreover, we present a\u00a0\u2026", "num_citations": "48\n", "authors": ["1179"]}
{"title": "Syntacticstructureparsingbased Chinesequestionclassification\n", "abstract": " Question classification is very important for question answering, and the result of question classification directly affects the quality of question answering. This paper presents a new method on feature extraction for question classification. The output of syntactic parsing is used in this method to extract the Subject-Predicate structure as well as interrogative words and their adjunctive parts as features for classification, leading to substantial reduction in noise, and emphasis on the main features of question classification. A bayesian classifier is used in classification, which effectively increases the precision of question classification. The experimental result validates the effectiveness of this method: the classification precision of coarse classes and fine classes reach 86.62% and 71.92% respectively, which attains the expected effects.", "num_citations": "48\n", "authors": ["1179"]}
{"title": "Generating and exploiting large-scale pseudo training data for zero pronoun resolution\n", "abstract": " Most existing approaches for zero pronoun resolution are heavily relying on annotated data, which is often released by shared task organizers. Therefore, the lack of annotated data becomes a major obstacle in the progress of zero pronoun resolution task. Also, it is expensive to spend manpower on labeling the data for better performance. To alleviate the problem above, in this paper, we propose a simple but novel approach to automatically generate large-scale pseudo training data for zero pronoun resolution. Furthermore, we successfully transfer the cloze-style reading comprehension neural network model into zero pronoun resolution task and propose a two-step training mechanism to overcome the gap between the pseudo training data and the real one. Experimental results show that the proposed approach significantly outperforms the state-of-the-art systems with an absolute improvements of 3.1% F-score on OntoNotes 5.0 data.", "num_citations": "47\n", "authors": ["1179"]}
{"title": "Exploiting persona information for diverse generation of conversational responses\n", "abstract": " In human conversations, due to their personalities in mind, people can easily carry out and maintain the conversations. Giving conversational context with persona information to a chatbot, how to exploit the information to generate diverse and sustainable conversations is still a non-trivial task. Previous work on persona-based conversational models successfully make use of predefined persona information and have shown great promise in delivering more realistic responses. And they all learn with the assumption that given a source input, there is only one target response. However, in human conversations, there are massive appropriate responses to a given input message. In this paper, we propose a memory-augmented architecture to exploit persona information from context and incorporate a conditional variational autoencoder model together to generate diverse and sustainable conversations. We evaluate the proposed model on a benchmark persona-chat dataset. Both automatic and human evaluations show that our model can deliver more diverse and more engaging persona-based responses than baseline approaches.", "num_citations": "46\n", "authors": ["1179"]}
{"title": "\u57fa\u4e8e\u6539\u8fdb\u8d1d\u53f6\u65af\u6a21\u578b\u7684\u95ee\u9898\u5206\u7c7b\n", "abstract": " (\u54c8\u5c14\u6ee8\u5de5\u4e1a\u5927\u5b66\u8ba1\u7b97\u673a\u5b66\u9662\u4fe1\u606f\u68c0\u7d22\u7814\u7a76\u5ba4, \u9ed1\u9f99\u6c5f\u54c8\u5c14\u6ee8 150001) \u6458\u8981: \u968f\u7740\u8ba1\u7b97\u673a\u53ca\u4e92\u8054\u7f51\u7edc\u6280\u672f\u7684\u53d1\u5c55, \u5f00\u653e\u57df\u95ee\u7b54\u7cfb\u7edf\u8d8a\u6765\u8d8a\u53d7\u5230\u4eba\u4eec\u7684\u5173\u6ce8, \u56e0\u4e3a\u5b83\u80fd\u591f\u7ed9\u7528\u6237\u63d0\u4f9b\u76f8\u5bf9\u7b80\u6d01, \u51c6\u786e\u7684\u7ed3\u679c. \u5f00\u653e\u57df\u95ee\u7b54\u7cfb\u7edf\u901a\u5e38\u5305\u62ec\u95ee\u9898\u5206\u7c7b, \u95ee\u9898\u6269\u5c55, \u641c\u7d22\u5f15\u64ce, \u7b54\u6848\u62bd\u53d6\u548c\u7b54\u6848\u9009\u62e9\u4e94\u4e2a\u4e3b\u8981\u90e8\u5206. \u95ee\u9898\u5206\u7c7b\u5728\u95ee\u7b54\u7cfb\u7edf\u4e2d\u8d77\u7740\u5f88\u91cd\u8981\u7684\u4f5c\u7528, \u5b83\u7684\u51c6\u786e\u6027\u76f4\u63a5\u5f71\u54cd\u5230\u6700\u7ec8\u62bd\u53d6\u7684\u7b54\u6848\u7684\u51c6\u786e\u6027. \u672c\u6587\u5728\u5bf9\u5df2\u6709\u7684\u8d1d\u53f6\u65af\u5206\u7c7b\u65b9\u6cd5\u8fdb\u884c\u5206\u6790\u7684\u57fa\u7840\u4e0a, \u5bf9\u8be5\u65b9\u6cd5\u8fdb\u884c\u4e86\u6539\u8fdb. \u4e3a\u4e86\u9a8c\u8bc1\u8be5\u65b9\u6cd5\u7684\u6548\u679c, \u6784\u9020\u4e86\u95ee\u9898\u7684\u8bad\u7ec3\u96c6\u548c\u6d4b\u8bd5\u96c6. \u4ece\u5b9e\u9a8c\u7ed3\u679c\u53ef\u4ee5\u770b\u51fa, \u8be5\u65b9\u6cd5\u5728\u5b9e\u9645\u5e94\u7528\u4e2d\u83b7\u5f97\u4e86\u8f83\u597d\u7684\u6548\u679c.", "num_citations": "45\n", "authors": ["1179"]}
{"title": "Type-supervised domain adaptation for joint segmentation and pos-tagging\n", "abstract": " We report an empirical investigation on type-supervised domain adaptation for joint Chinese word segmentation and POS-tagging, making use of domainspecific tag dictionaries and only unlabeled target domain data to improve target-domain accuracies, given a set of annotated source domain sentences. Previous work on POS-tagging of other languages showed that type-supervision can be a competitive alternative to tokensupervision, while semi-supervised techniques such as label propagation are important to the effectiveness of typesupervision. We report similar findings using a novel approach for joint Chinese segmentation and POS-tagging, under a cross-domain setting. With the help of unlabeled sentences and a lexicon of 3,000 words, we obtain 33% error reduction in target-domain tagging. In addition, combined type-and token-supervision can lead to improved cost-effectiveness.", "num_citations": "44\n", "authors": ["1179"]}
{"title": "Semantic role labeling with maximum entropy classifier\n", "abstract": " Semantic role labeling is a feasible proposal to shallow semantic parsing. A maximum entropy classifier is used in the semantic role labeling system, which takes syntactic constituents as the labeled units. The maximum entropy classifier is trained to identify and classify the predicates\u2019 semantic roles at the same time. Some useful features and their combinations are used in the classifier. In the post-processing step, only the roles with the highest probability among the embedding ones are kept. After predicting all the arguments, which have matched the constituents in full parsing trees, a simple rule-based post-processing is applied to correct the arguments that have not matched the constituents in these trees. F1= 75.49% and F1= 75.60% results are obtained on the development and test set respectively. So far as it is known, this is the best result based on single syntactic parser in literatures. Finally, some proposals for solving the difficulties in semantic role labeling and the future works are given.", "num_citations": "44\n", "authors": ["1179"]}
{"title": "Social sentiment sensor: a visualization system for topic detection and topic sentiment analysis on microblog\n", "abstract": " As a new form of social media, microblogging provides platform sharing, wherein users can share their feelings and ideas on certain topics. Bursty topics from microblogs are the results of the emerging issues that instantly attract more followers and more attention online, which provide a unique opportunity to gauge the relation between expressed public sentiment and hot topics. This paper presents a Social Sentiment Sensor (SSS) system on Sina Weibo to detect daily hot topics and analyze the sentiment distributions toward these topics. SSS includes two main techniques, namely, hot topic detection and topic-oriented sentiment analysis. Hot topic detection aims to detect the most popular topics online based on the following steps, topic detection, topic clustering, and topic popularity ranking. We extracted topics from the hashtags using a hashtag filtering model because they can cover almost all the topics\u00a0\u2026", "num_citations": "43\n", "authors": ["1179"]}
{"title": "Building a Dependency Treebank for Improving Chinese Parser.\n", "abstract": " In this paper we design and develop an annotated corpus\u2014Chinese Dependency Treebank (CDT). With large scale of corpus and diversity of information, this treebank attempts to provide a resource which is more effective on training statistical parser. It is annotated within dependency formalism. Different from some existing treebanks which focus on syntactic and semantic annotation, CDT pays additional attention on annotation of lexical and phrasal information. Besides dependency relations, verb subclasses and noun compounds are annotated in this treebank. All of them are used to improve the performance of the parser. In addition, an incremental strategy that efficiently speeds up the annotation is described. We also discuss the mapping between dependency structures and phrase structures.", "num_citations": "43\n", "authors": ["1179"]}
{"title": "A Neural Transition-Based Approach for Semantic Dependency Graph Parsing.\n", "abstract": " Semantic dependency graph has been recently proposed as an extension of tree-structured syntactic or semantic representation for natural language sentences. It particularly features the structural property of multi-head, which allows nodes to have multiple heads, resulting in a directed acyclic graph (DAG) parsing problem. Yet most statistical parsers focused exclusively on shallow bi-lexical tree structures, DAG parsing remains under-explored. In this paper, we propose a neural transition-based parser, using a variant of list-based arc-eager transition algorithm for dependency graph parsing. Particularly, two non-trivial improvements are proposed for representing the key components of the transition system, to better capture the semantics of segments and internal sub-graph structures. We test our parser on the SemEval-2016 Task 9 dataset (Chinese) and the SemEval-2015 Task 18 dataset (English). On both benchmark datasets, we obtain superior or comparable results to the best performing systems. Our parser can be further improved with a simple ensemble mechanism, resulting in the state-of-the-art performance.", "num_citations": "42\n", "authors": ["1179"]}
{"title": "A grammar-driven convolution tree kernel for semantic role classification\n", "abstract": " Convolution tree kernel has shown promising results in semantic role classification. However, it only carries out hard matching, which may lead to over-fitting and less accurate similarity measure. To remove the constraint, this paper proposes a grammardriven convolution tree kernel for semantic role classification by introducing more linguistic knowledge into the standard tree kernel. The proposed grammar-driven tree kernel displays two advantages over the previous one: 1) grammar-driven approximate substructure matching and 2) grammardriven approximate tree node matching. The two improvements enable the grammardriven tree kernel explore more linguistically motivated structure features than the previous one. Experiments on the CoNLL-2005 SRL shared task show that the grammardriven tree kernel significantly outperforms the previous non-grammar-driven one in SRL. Moreover, we present a composite kernel to integrate feature-based and tree kernel-based methods. Experimental results show that the composite kernel outperforms the previously best-reported methods.", "num_citations": "42\n", "authors": ["1179"]}
{"title": "Gaussian transformer: a lightweight approach for natural language inference\n", "abstract": " Natural Language Inference (NLI) is an active research area, where numerous approaches based on recurrent neural networks (RNNs), convolutional neural networks (CNNs), and self-attention networks (SANs) has been proposed. Although obtaining impressive performance, previous recurrent approaches are hard to train in parallel; convolutional models tend to cost more parameters, while self-attention networks are not good at capturing local dependency of texts. To address this problem, we introduce a Gaussian prior to selfattention mechanism, for better modeling the local structure of sentences. Then we propose an efficient RNN/CNN-free architecture named Gaussian Transformer for NLI, which consists of encoding blocks modeling both local and global dependency, high-order interaction blocks collecting the evidence of multi-step inference, and a lightweight comparison block saving lots of parameters. Experiments show that our model achieves new state-of-the-art performance on both SNLI and MultiNLI benchmarks with significantly fewer parameters and considerably less training time. Besides, evaluation using the Hard NLI datasets demonstrates that our approach is less affected by the undesirable annotation artifacts.", "num_citations": "41\n", "authors": ["1179"]}
{"title": "Deep reinforcement learning for chinese zero pronoun resolution\n", "abstract": " Deep neural network models for Chinese zero pronoun resolution learn semantic information for zero pronoun and candidate antecedents, but tend to be short-sighted---they often make local decisions. They typically predict coreference chains between the zero pronoun and one single candidate antecedent one link at a time, while overlooking their long-term influence on future decisions. Ideally, modeling useful information of preceding potential antecedents is critical when later predicting zero pronoun-candidate antecedent pairs. In this study, we show how to integrate local and global decision-making by exploiting deep reinforcement learning models. With the help of the reinforcement learning agent, our model learns the policy of selecting antecedents in a sequential manner, where useful information provided by earlier predicted antecedents could be utilized for making later coreference decisions. Experimental results on OntoNotes 5.0 dataset show that our technique surpasses the state-of-the-art models.", "num_citations": "41\n", "authors": ["1179"]}
{"title": "A cascaded syntactic and semantic dependency parsing system\n", "abstract": " We describe our CoNLL 2008 Shared Task system in this paper. The system includes two cascaded components: a syntactic and a semantic dependency parsers. A firstorder projective MSTParser is used as our syntactic dependency parser. In order to overcome the shortcoming of the MST-Parser, that it cannot model more global information, we add a relabeling stage after the parsing to distinguish some confusable labels, such as ADV, TMP, and LOC. Besides adding a predicate identification and a classification stages, our semantic dependency parsing simplifies the traditional four stages semantic role labeling into two: a maximum entropy based argument classification and an ILP-based post inference. Finally, we gain the overall labeled macro F1= 82.66, which ranked the second position in the closed challenge.", "num_citations": "41\n", "authors": ["1179"]}
{"title": "Cross-lingual machine reading comprehension\n", "abstract": " Though the community has made great progress on Machine Reading Comprehension (MRC) task, most of the previous works are solving English-based MRC problems, and there are few efforts on other languages mainly due to the lack of large-scale training data. In this paper, we propose Cross-Lingual Machine Reading Comprehension (CLMRC) task for the languages other than English. Firstly, we present several back-translation approaches for CLMRC task, which is straightforward to adopt. However, to accurately align the answer into another language is difficult and could introduce additional noise. In this context, we propose a novel model called Dual BERT, which takes advantage of the large-scale training data provided by rich-resource language (such as English) and learn the semantic relations between the passage and question in a bilingual context, and then utilize the learned knowledge to improve reading comprehension performance of low-resource language. We conduct experiments on two Chinese machine reading comprehension datasets CMRC 2018 and DRCD. The results show consistent and significant improvements over various state-of-the-art systems by a large margin, which demonstrate the potentials in CLMRC task. Resources available: https://github.com/ymcui/Cross-Lingual-MRC", "num_citations": "40\n", "authors": ["1179"]}
{"title": "Story ending prediction by transferable BERT\n", "abstract": " Recent advances, such as GPT and BERT, have shown success in incorporating a pre-trained transformer language model and fine-tuning operation to improve downstream NLP systems. However, this framework still has some fundamental problems in effectively incorporating supervised knowledge from other related tasks. In this study, we investigate a transferable BERT (TransBERT) training framework, which can transfer not only general language knowledge from large-scale unlabeled data but also specific kinds of knowledge from various semantically related supervised tasks, for a target task. Particularly, we propose utilizing three kinds of transfer tasks, including natural language inference, sentiment classification, and next action prediction, to further train BERT based on a pre-trained model. This enables the model to get a better initialization for the target task. We take story ending prediction as the target task to conduct experiments. The final result, an accuracy of 91.8%, dramatically outperforms previous state-of-the-art baseline methods. Several comparative experiments give some helpful suggestions on how to select transfer tasks. Error analysis shows what are the strength and weakness of BERT-based models for story ending prediction.", "num_citations": "40\n", "authors": ["1179"]}
{"title": "Improving Low Resource Named Entity Recognition using Cross-lingual Knowledge Transfer.\n", "abstract": " Neural networks have been widely used for high resource language (eg English) named entity recognition (NER) and have shown state-of-the-art results. However, for low resource languages, such as Dutch and Spanish, due to the limitation of resources and lack of annotated data, NER models tend to have lower performances. To narrow this gap, we investigate cross-lingual knowledge to enrich the semantic representations of low resource languages. We first develop neural networks to improve low resource word representations via knowledge transfer from high resource language using bilingual lexicons. Further, a lexicon extension strategy is designed to address out-of lexicon problem by automatically learning semantic projections. Finally, we regard word-level entity type distribution features as an external languageindependent knowledge and incorporate them into our neural architecture. Experiments on two low resource languages (Dutch and Spanish) demonstrate the effectiveness of these additional semantic representations (average 4.8% improvement). Moreover, on Chinese OntoNotes 4.0 dataset, our approach achieves an F-score of 83.07% with 2.91% absolute gain compared to the state-of-the-art systems.", "num_citations": "40\n", "authors": ["1179"]}
{"title": "CCG supertagging via Bidirectional LSTM-CRF neural architecture\n", "abstract": " Sequence labeling is the widely used method for CCG supertagging task where a supertag (lexical category) is assigned to each word in an input sentence. In CCG supertagging the major challenging problem is due to the large number of lexical categories. To address this, machine learning and deep learning methods have been used and achieved promising results. However, these models whether use many hand-crafted features case of machine learning methods or use sentence level representation processing a sequence without any correlations between labels in neighborhoods which have great influences on predicting the current label case of deep learning models. More recently, there is a marriage of machine learning and deep learning models. In this paper, we use the combination of Conditional Random Field and Bidirectional Long Short-Term Memory models. So first the model learns sentence\u00a0\u2026", "num_citations": "40\n", "authors": ["1179"]}
{"title": "Automatically generating questions from queries for community-based question answering\n", "abstract": " This paper proposes a method that automatically generates questions from queries for community-based question answering (cQA) services. Our query-to-question generation model is built upon templates induced from search engine query logs. In detail, we first extract pairs of queries and user-clicked questions from query logs, with which we induce question generation templates. Then, when a new query is submitted, we select proper templates for the query and generate questions through template instantiation. We evaluated the method with a set of short queries randomly selected from query logs, and the generated questions were judged by human annotators. Experimental results show that, the precision of 1-best and 5-best generated questions is 67% and 61%, respectively, which outperforms a baseline method that directly retrieves questions for queries in a cQA site search engine. In addition, the results also suggest that the proposed method can improve the search of cQA archives.", "num_citations": "40\n", "authors": ["1179"]}
{"title": "\u57fa\u4e8e\u53e5\u6cd5\u8def\u5f84\u7684\u60c5\u611f\u8bc4\u4ef7\u5355\u5143\u8bc6\u522b\n", "abstract": " \u4e0d\u540c\u4e8e\u5df2\u6709\u7684\u57fa\u4e8e\u624b\u5de5\u6a21\u677f\u548c\u89c4\u5219\u7684\u65b9\u6cd5, \u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u53e5\u6cd5\u8def\u5f84\u7684\u60c5\u611f\u8bc4\u4ef7\u5355\u5143\u81ea\u52a8\u8bc6\u522b\u65b9\u6cd5. \u8be5\u65b9\u6cd5\u81ea\u52a8\u83b7\u53d6\u53e5\u6cd5\u8def\u5f84\u6765\u63cf\u8ff0\u8bc4\u4ef7\u5bf9\u8c61\u53ca\u5176\u8bc4\u4ef7\u8bcd\u8bed\u4e4b\u95f4\u7684\u4fee\u9970\u5173\u7cfb, \u5e76\u901a\u8fc7\u8ba1\u7b97\u53e5\u6cd5\u8def\u5f84\u7f16\u8f91\u8ddd\u79bb\u6765\u6539\u8fdb\u60c5\u611f\u8bc4\u4ef7\u5355\u5143\u62bd\u53d6\u7684\u7cfb\u7edf\u6027\u80fd. \u5b9e\u9a8c\u8bed\u6599\u6765\u81ea\u6570\u7801\u76f8\u673a\u548c MP3 \u64ad\u653e\u5668\u4e24\u4e2a\u5178\u578b\u7684\u7535\u5b50\u4ea7\u54c1\u9886\u57df. \u5b9e\u9a8c\u7ed3\u679c\u8868\u660e:(1) \u53e5\u6cd5\u8def\u5f84\u80fd\u591f\u6709\u6548\u63cf\u8ff0\u8bc4\u4ef7\u5bf9\u8c61\u53ca\u5176\u8bc4\u4ef7\u8bcd\u8bed\u4e4b\u95f4\u7684\u5173\u7cfb, \u5bf9\u60c5\u611f\u8bc4\u4ef7\u5355\u5143\u7684\u8bc6\u522b\u6709\u5f88\u5927\u5e2e\u52a9;(2) \u57fa\u4e8e\u7f16\u8f91\u8ddd\u79bb\u7684\u53e5\u6cd5\u8def\u5f84\u6539\u8fdb\u7b56\u7565\u80fd\u591f\u8fdb\u4e00\u6b65\u63d0\u9ad8\u60c5\u611f\u8bc4\u4ef7\u5355\u5143\u8bc6\u522b\u7684\u7cfb\u7edf\u6027\u80fd.", "num_citations": "40\n", "authors": ["1179"]}
{"title": "Integrating intra-and inter-document evidences for improving sentence sentiment classification\n", "abstract": " Sentence sentiment classification is an important task of sentiment analysis. It aims to classify the sentences into positive, negative, or objective. One can consider sentence sentiment classification as a standard text categorization problem. However, determining the sentiment orientation of a review sentence requires more than the features inside the sentence itself, especially for the sentences with little or ambiguous inside sentence features. Through observing, some features outside the sentence can interact with its inside features to enhance the overall performance of sentence sentiment classification. Thus in this paper, we propose two such outside sentence features: intra-document evidence and inter-document evidence. Then in order to improve the sentence sentiment classification performance, a graph-based propagation approach is presented to incorporate these inside and outside sentence features. The\u00a0\u2026", "num_citations": "40\n", "authors": ["1179"]}
{"title": "\u4e2d\u6587\u8bed\u4e49\u89d2\u8272\u6807\u6ce8\u7684\u7279\u5f81\u5de5\u7a0b\n", "abstract": " \u57fa\u4e8e\u7edf\u8ba1\u673a\u5668\u5b66\u4e60\u7684\u8bed\u4e49\u89d2\u8272\u6807\u6ce8\u5728\u81ea\u7136\u8bed\u8a00\u5904\u7406\u9886\u57df\u8d8a\u6765\u8d8a\u53d7\u5230\u91cd\u89c6, \u4e30\u5bcc\u591a\u6837\u7684\u7279\u5f81\u76f4\u63a5\u51b3\u5b9a\u8bed\u4e49\u89d2\u8272\u6807\u6ce8\u7cfb\u7edf\u7684\u6027\u80fd. \u672c\u6587\u9488\u5bf9\u4e2d\u6587\u7684\u7279\u70b9, \u5728\u82f1\u6587\u8bed\u4e49\u89d2\u8272\u6807\u6ce8\u7279\u5f81\u7684\u57fa\u7840\u4e0a, \u63d0\u51fa\u4e86\u4e00\u4e9b\u66f4\u6709\u6548\u7684\u65b0\u7279\u5f81\u548c\u7ec4\u5408\u7279\u5f81: \u4f8b\u5982, \u53e5\u6cd5\u6210\u5206\u540e\u4e00\u4e2a\u8bcd, \u8c13\u8bed\u52a8\u8bcd\u548c\u77ed\u8bed\u7c7b\u578b\u7684\u7ec4\u5408, \u8c13\u8bed\u52a8\u8bcd\u7c7b\u522b\u4fe1\u606f\u548c\u8def\u5f84\u7684\u7ec4\u5408\u7b49, \u5e76\u5728 Chinese Proposition Bank (CPB) \u8bed\u6599\u6570\u636e\u4e0a, \u4f7f\u7528\u6700\u5927\u71b5\u5206\u7c7b\u5668\u8fdb\u884c\u4e86\u5b9e\u9a8c, \u7cfb\u7edf F2Score \u7531 89. 76% \u589e\u52a0\u5230 91. 31%. \u7ed3\u679c\u8868\u660e, \u8fd9\u4e9b\u65b0\u7279\u5f81\u548c\u7ec4\u5408\u7279\u5f81\u663e\u8457\u63d0\u9ad8\u4e86\u7cfb\u7edf\u7684\u6027\u80fd. \u56e0\u6b64, \u76ee\u524d\u8fdb\u884c\u8bed\u4e49\u89d2\u8272\u6807\u6ce8\u5e94\u96c6\u4e2d\u7cbe\u529b\u5bfb\u627e\u4e30\u5bcc\u6709\u6548\u7684\u7279\u5f81.", "num_citations": "40\n", "authors": ["1179"]}
{"title": "\u5728\u7ebf\u793e\u4f1a\u7f51\u7edc\u4e2d\u4fe1\u606f\u6269\u6563\n", "abstract": " \u6458 \u8981 \u5728\u7ebf\u793e\u4f1a\u7f51\u7edc\u4e2d\u4fe1\u606f\u6269\u6563\u7814\u7a76\u53ef\u4ee5\u5e2e\u52a9\u7f51\u7edc\u7528\u6237\u83b7\u53d6\u6709\u4ef7\u503c\u4fe1\u606f, \u5e2e\u52a9\u4f01\u4e1a\u63a8\u5e7f\u4ea7\u54c1, \u5e2e\u52a9\u653f\u5e9c\u8c03\u63a7\u8206\u60c5, \u5e94\u7528\u4ef7\u503c\u5de8\u5927. \u8be5\u6587\u65e8\u5728\u7efc\u8ff0\u5728\u7ebf\u793e\u4f1a\u7f51\u7edc\u4e2d\u4fe1\u606f\u6269\u6563\u7814\u7a76\u7684\u73b0\u72b6. \u9996\u5148\u8be6\u7ec6\u9610\u8ff0\u4e86\u7814\u7a76\u80cc\u666f\u548c\u7814\u7a76\u610f\u4e49; \u968f\u540e\u5c06\u5f53\u524d\u7814\u7a76\u5212\u5206\u4e3a\u57fa\u4e8e\u7406\u8bba\u6269\u6563\u6a21\u578b\u7684\u7814\u7a76\u548c\u57fa\u4e8e\u4fe1\u606f\u6269\u6563\u7ea7\u8054\u7684\u7814\u7a76\u4e24\u7c7b, \u524d\u8005\u5305\u62ec\u4fe1\u606f\u6269\u6563\u7279\u6027\u7814\u7a76, \u4fe1\u606f\u6269\u6563\u6982\u7387\u8ba1\u7b97, \u4fe1\u606f\u6269\u6563\u6700\u5927\u5316\u95ee\u9898\u548c\u7ade\u4e89\u6027\u7684\u4fe1\u606f\u6269\u6563\u6700\u5927\u5316\u95ee\u9898, \u540e\u8005\u5305\u62ec\u4fe1\u606f\u6269\u6563\u7279\u6027\u7814\u7a76, \u7528\u6237\u5f71\u54cd\u529b\u8ba1\u7b97\u548c\u4fe1\u606f\u6269\u6563\u9884\u6d4b\u6a21\u578b, \u5bf9\u4e0a\u8ff0\u5404\u65b9\u5411\u7684\u7814\u7a76\u65b9\u6cd5\u548c\u7814\u7a76\u8fdb\u5c55\u8fdb\u884c\u4e86\u6982\u62ec, \u6bd4\u8f83\u548c\u5f52\u7eb3, \u540c\u65f6\u5bf9\u5404\u7814\u7a76\u65b9\u5411\u4e4b\u95f4\u7684\u5185\u5728\u5173\u8054\u8fdb\u884c\u4e86\u6df1\u5165\u5206\u6790; \u63a5\u7740\u63a2\u8ba8\u4e86\u4fe1\u606f\u6269\u6563\u52a8\u6001\u6027\u548c\u5728\u7ebf\u793e\u4f1a\u7f51\u7edc\u52a8\u6001\u6027\u7684\u5173\u7cfb; \u6700\u540e\u5bf9\u8be5\u7814\u7a76\u76ee\u524d\u5b58\u5728\u7684\u95ee\u9898\u548c\u4e00\u4e9b\u672a\u6765\u53d1\u5c55\u65b9\u5411\u8fdb\u884c\u4e86\u603b\u7ed3.", "num_citations": "39\n", "authors": ["1179"]}
{"title": "The Comparison of SOM and K-means for Text Clustering.\n", "abstract": " SOM and k-means are two classical methods for text clustering. In this paper some experiments have been done to compare their performances. The sample data used is 420 articles which come from different topics. K-means method is simple and easy to implement; the structure of SOM is relatively complex, but the clustering results are more visual and easy to comprehend. The comparison results also show that k-means is sensitive to initiative distribution, whereas the overall clustering performance of SOM is better than that of k-means, and it also performs well for detection of noisy documents and topology preservation, thus make it more suitable for some applications such as navigation of document collection, multi-document summarization and etc. whereas the clustering results of SOM is sensitive to output layer topology.", "num_citations": "39\n", "authors": ["1179"]}
{"title": "Topic-to-Essay Generation with Neural Networks.\n", "abstract": " We focus on essay generation, which is a challenging task that generates a paragraph-level text with multiple topics. Progress towards understanding different topics and expressing diversity in this task requires more powerful generators and richer training and evaluation resources. To address this, we develop a multi-topic-aware long short-term memory (MTA-LSTM) network. In this model, we maintain a novel multi-topic coverage vector, which learns the weight of of each topic and is sequentially updated during the decoding process. Afterwards this vector is fed to an attention model to guide the generator. Moreover, we automatically construct two paragraph-level Chinese essay corpora, 305,000 essay paragraphs and 55,000 question-and-answer pairs. Empirical results show that our approach obtains much better BLEU-2 score compared to various baselines. Furthermore, human judgment shows that MTA-LSTM has the ability to generate essays that are not only coherent but also closely related to the input topics.", "num_citations": "38\n", "authors": ["1179"]}
{"title": "Semeval-2016 task 9: Chinese semantic dependency parsing\n", "abstract": " This paper describes the SemEval-2016 Shared Task 9: Chinese semantic Dependency Parsing. We extend the traditional treestructured representation of Chinese sentence to directed acyclic graphs that can capture richer latent semantics, and the goal of this task is to identify such semantic structures from a corpus of Chinese sentences. We provide two distinguished corpora in the NEWS domain with 10,068 sentences and the TEXTBOOKS domain with 14,793 sentences respectively. We will first introduce the motivation for this task, and then present the task in detail including data preparation, data format, task evaluation and so on. At last, we briefly describe the submitted systems and analyze these results.", "num_citations": "37\n", "authors": ["1179"]}
{"title": "Using imageability and topic chaining to locate metaphors in linguistic corpora\n", "abstract": " The reliable automated identification of metaphors still remains a challenge in metaphor research due to ambiguity between semantic and contextual interpretation of individual lexical items. In this article, we describe a novel approach to metaphor identification which is based on three intersecting methods: imageability, topic chaining, and semantic clustering. Our hypothesis is that metaphors are likely to use highly imageable words that do not generally have a topical or semantic association with the surrounding context. Our method is thus the following: (1) identify the highly imageable portions of a paragraph, using psycholinguistic measures of imageability, (2) exclude imageability peaks that are part of a topic chain, and (3) exclude imageability peaks that show a semantic relationship to the main topics. We are currently working towards fully automating this method for a number of languages.", "num_citations": "37\n", "authors": ["1179"]}
{"title": "\u57fa\u4e8e\u8bed\u4e49\u57df\u8bed\u8a00\u6a21\u578b\u7684\u4e2d\u6587\u8bdd\u9898\u5173\u8054\u68c0\u6d4b\n", "abstract": " \u5173\u8054\u68c0\u6d4b\u662f\u8bdd\u9898\u68c0\u6d4b\u4e0e\u8ddf\u8e2a\u9886\u57df\u7684\u57fa\u7840\u6027\u7814\u7a76, \u5176\u4efb\u52a1\u662f\u68c0\u6d4b\u4efb\u610f\u65b0\u95fb\u62a5\u9053\u5bf9\u662f\u5426\u8bba\u8ff0\u540c\u4e00\u8bdd\u9898. \u901a\u8fc7\u5206\u6790\u62a5\u9053\u5185\u5bb9\u7684\u7ed3\u6784\u5173\u7cfb\u548c\u8bed\u4e49\u7684\u5206\u5e03\u89c4\u5f8b, \u63d0\u51fa\u57fa\u4e8e\u8bed\u4e49\u57df\u8bed\u8a00\u6a21\u578b\u7684\u5173\u8054\u6027\u68c0\u6d4b\u65b9\u6cd5, \u5e76\u5728\u6b64\u57fa\u7840\u4e0a\u68c0\u9a8c\u878d\u5165\u4f9d\u5b58\u5206\u6790\u7684\u8bed\u4e49\u63cf\u8ff0\u7b56\u7565\u5bf9\u8be5\u6a21\u578b\u6027\u80fd\u7684\u5f71\u54cd. \u5b9e\u9a8c\u91c7\u7528 TDT4 \u4e2d\u6587\u8bed\u6599\u8fdb\u884c\u8bc4\u6d4b, \u7ed3\u679c\u663e\u793a\u8bed\u4e49\u57df\u8bed\u8a00\u6a21\u578b\u663e\u8457\u6539\u8fdb\u4e86\u73b0\u6709\u68c0\u6d4b\u7cfb\u7edf\u7684\u6027\u80fd, \u5176\u6700\u5c0f DET \u4ee3\u4ef7\u964d\u4f4e\u4e86\u7ea6 3 \u4e2a\u767e\u5206\u70b9.", "num_citations": "37\n", "authors": ["1179"]}
{"title": "Learning Question Paraphrases for QA from Encarta Logs.\n", "abstract": " Question paraphrasing is critical in many Natural Language Processing (NLP) applications, especially for question reformulation in question answering (QA). However, choosing an appropriate data source and developing effective methods are challenging tasks. In this paper, we propose a method that exploits Encarta logs to automatically identify question paraphrases and extract templates. Questions from Encarta logs are partitioned into small clusters, within which a perceptron classier is used for identifying question paraphrases. Experiments are conducted and the results have shown:(1) Encarta log data is an eligible data source for question paraphrasing and the user clicks in the data are indicative clues for recognizing paraphrases;(2) the supervised method we present is effective, which can evidently outperform the unsupervised method. Besides, the features introduced to identify paraphrases are sound;(3) the obtained question paraphrase templates are quite effective in question reformulation, enhancing the MRR from 0.2761 to 0.4939 with the questions of TREC QA 2003.", "num_citations": "37\n", "authors": ["1179"]}
{"title": "Improved-edit-distance kernel for Chinese relation extraction\n", "abstract": " In this paper, a novel kernel-based method is presented for the problem of relation extraction between named entities from Chinese texts. The kernel is defined over the original Chinese string representations around particular entities. As a kernel function, the Improved-Edit-Distance (IED) is used to calculate the similarity between two Chinese strings. By employing the Voted Perceptron and Support Vector Machine (SVM) kernel machines with the IED kernel as the classifiers, we tested the method by extracting person-affiliation relation from Chinese texts. By comparing with traditional feature-based learning methods, we conclude that our method needs less manual efforts in feature transformation and achieves a better performance.", "num_citations": "37\n", "authors": ["1179"]}
{"title": "Question answering by pattern matching, web-proofing, semantic form proofing\n", "abstract": " In this paper, we introduce the University at Albany\u2019s question answering system, ILQUA. It is developed on the following methods: pattern matching over annotated text, web-proofing and semantic form proofing. These methods are currently used in other QA systems, however, we revised them to work together in our QA system.", "num_citations": "37\n", "authors": ["1179"]}
{"title": "HITIQA: An Interactive Question Answering System. A Preliminary Report\n", "abstract": " HITIQA is an interactive question answering technology designed to allow intelligence analysts and other users of information systems to pose questions in natural language and obtain relevant answers, or the assistance they require in order to perform their tasks. Our objective in HITIQA is to allow the user to submit exploratory, analytical, non-factual questions, such as What has been Russias reaction to US bombing of Kosovo The distinguishing property of such questions is that one cannot generally anticipate what might constitute the answer. While certain types of things may be expected eg, diplomatic statements, the answer is heavily conditioned by what information is in fact available on the topic. From a practical viewpoint, analytical questions are often underspecified, thus casting a broad net on a space of possible answers. Therefore, clarification dialogue is often needed to negotiate with the user the exact scope and intent of the question.Descriptors:", "num_citations": "36\n", "authors": ["1179"]}
{"title": "Chinese zero pronoun resolution with deep memory network\n", "abstract": " Existing approaches for Chinese zero pronoun resolution typically utilize only syntactical and lexical features while ignoring semantic information. The fundamental reason is that zero pronouns have no descriptive information, which brings difficulty in explicitly capturing their semantic similarities with antecedents. Meanwhile, representing zero pronouns is challenging since they are merely gaps that convey no actual content. In this paper, we address this issue by building a deep memory network that is capable of encoding zero pronouns into vector representations with information obtained from their contexts and potential antecedents. Consequently, our resolver takes advantage of semantic information by using these continuous distributed representations. Experiments on the OntoNotes 5.0 dataset show that the proposed memory network could substantially outperform the state-of-the-art systems in various experimental settings.", "num_citations": "35\n", "authors": ["1179"]}
{"title": "Learning sentence representation for emotion classification on microblogs\n", "abstract": " This paper studies the emotion classification task on microblogs. Given a message, we classify its emotion as happy, sad, angry or surprise. Existing methods mostly use the bag-of-word representation or manually designed features to train supervised or distant supervision models. However, manufacturing feature engines is time-consuming and not enough to capture the complex linguistic phenomena on microblogs. In this study, to overcome the above problems, we utilize pseudo-labeled data, which is extensively explored for distant supervision learning and training language model in Twitter sentiment analysis, to learn the sentence representation through Deep Belief Network algorithm. Experimental results in the supervised learning framework show that using the pseudo-labeled data, the representation learned by Deep Belief Network outperforms the Principal Components Analysis based and Latent\u00a0\u2026", "num_citations": "35\n", "authors": ["1179"]}
{"title": "Transition-based disfluency detection using lstms\n", "abstract": " In this paper, we model the problem of disfluency detection using a transition-based framework, which incrementally constructs and labels the disfluency chunk of input sentences using a new transition system without syntax information. Compared with sequence labeling methods, it can capture non-local chunk-level features; compared with joint parsing and disfluency detection methods, it is free for noise in syntax. Experiments show that our model achieves state-of-the-art f-score of 87.5% on the commonly used English Switchboard test set, and a set of in-house annotated Chinese data.", "num_citations": "34\n", "authors": ["1179"]}
{"title": "Creating a fine-grained corpus for chinese sentiment analysis\n", "abstract": " Writing comments on products or news has become a popular activity in social media. The amount of opinionated text available online has been growing rapidly, increasing the need for techniques that can analyze opinions expressed in such text so that reviews can be easily absorbed by users. To date, most techniques depend on annotated corpora. However, existing corpora are almost sentence-level works that ignore important global sentiment information in other sentences. Given the rise of advanced applications, more fine-grained corpora are needed, even at the sentence level. The authors aim to create a fine-grained corpus for Chinese sentiment analysis, and more importantly, explore new sentiment analysis tasks by analyzing the annotated corpus. The proposed fine-grained annotation scheme not only introduces cross-sentence and global sentiment information (such as \"target entity\"') but also includes\u00a0\u2026", "num_citations": "34\n", "authors": ["1179"]}
{"title": "A novel approach to update summarization using evolutionary manifold-ranking and spectral clustering\n", "abstract": " Update summarization is a new challenge in automatic text summarization. Different from the traditional static summarization, it deals with the dynamically evolving document collections of a single topic changing over time, which aims to incrementally deliver salient and novel information to a user who has already read the previous documents. How to have a content selection and linguistic quality control in a temporal context are the two new challenges brought by update summarization. In this paper, we address a novel content selection framework based on evolutionary manifold-ranking and normalized spectral clustering. The proposed evolutionary manifold-ranking aims to capture the temporal characteristics and relay propagation of information in dynamic data stream and user need. This approach tries to keep the summary content to be important, novel and relevant to the topic. Incorporation with normalized\u00a0\u2026", "num_citations": "33\n", "authors": ["1179"]}
{"title": "Sentences optimum selection for multi-document summarization\n", "abstract": " An approach for sentence optimum selection based on sub-topics of multi-documents is proposed. Multi-documents can be clustered into sub-topics after sentence similarity calculation, which can be sorted by scoring. Then sentences from all sub-topics are selected in order to get maximum coverage ratio of effective words. Using this method, the information redundancy of each sub-topic and among sub-topics is reduced. The information coverage ratio of the summarization is better improved. The experiment shows that the result is satisfied.", "num_citations": "33\n", "authors": ["1179"]}
{"title": "Hitiqa: Towards analytical question answering\n", "abstract": " In this paper we describe the analytic question answering system HITIQA High-Quality Interactive Question Answering which has been developed over the last 2 years as an advanced research tool for information analysts. HITIQA is an interactive opendomain question answering technology designed to allow analysts to pose complex exploratory questions in natural language and obtain relevant information units to prepare their briefing reports. The system uses novel data-driven semantics to conduct a clarification dialogue with the user that explores the scope and the context of the desired answer space. The system has undergone extensive hands-on evaluations by a group of intelligence analysts. This evaluation validated the overall approach in HITIQA but also exposed limitations of the current prototype.Descriptors:", "num_citations": "33\n", "authors": ["1179"]}
{"title": "Context-sensitive generation of open-domain conversational responses\n", "abstract": " Despite the success of existing works on single-turn conversation generation, taking the coherence in consideration, human conversing is actually a context-sensitive process. Inspired by the existing studies, this paper proposed the static and dynamic attention based approaches for context-sensitive generation of open-domain conversational responses. Experimental results on two public datasets show that the proposed static attention based approach outperforms all the baselines on automatic and human evaluation.", "num_citations": "32\n", "authors": ["1179"]}
{"title": "Chinese grammatical error diagnosis with long short-term memory networks\n", "abstract": " Grammatical error diagnosis is an important task in natural language processing. This paper introduces our Chinese Grammatical Error Diagnosis (CGED) system in the NLP-TEA-3 shared task for CGED. The CGED system can diagnose four types of grammatical errors which are redundant words (R), missing words (M), bad word selection (S) and disordered words (W). We treat the CGED task as a sequence labeling task and describe three models, including a CRF-based model, an LSTM-based model and an ensemble model using stacking. We also show in details how we build and train the models. Evaluation includes three levels, which are detection level, identification level and position level. On the CGED-HSK dataset of NLP-TEA-3 shared task, our system presents the best F1-scores in all the three levels and also the best recall in the last two levels.", "num_citations": "32\n", "authors": ["1179"]}
{"title": "Transition-Based Syntactic Linearization\n", "abstract": " Syntactic linearization algorithms take a bag of input words and a set of optional constraints, and construct an output sentence and its syntactic derivation simultaneously. The search problem is NP-hard, and the current best results are achieved by bottom-up bestfirst search. One drawback of the method is low efficiency; and there is no theoretical guarantee that a full sentence can be found within bounded time. We propose an alternative algorithm that constructs output structures from left to right using beam-search. The algorithm is based on incremental parsing algorithms. We extend the transition system so that word ordering is performed in addition to syntactic parsing, resulting in a linearization system that runs in guaranteed quadratic time. In standard evaluations, our system runs an order of magnitude faster than a state-of-the-art baseline using best-first search, with improved accuracies.", "num_citations": "32\n", "authors": ["1179"]}
{"title": "\u8bed\u8a00\u6280\u672f\u5e73\u53f0\n", "abstract": " \u6458! \u8981\"(\")*+,]^ d $\u00a4\u00a5 \u00db\u00dc. \u00b3! Ld $\u00a4\u00a5 \u00db\u00dc. \u00b3#!\" \u00d4\u00d5'A\u00dd\u00de-; \u00df4]\u00a1:. 89 \u00db\u00dc, 45), ABMRAME4EILB898MX59AFP8OH*#! \u00db\u00dcwx (\" So?@ $ no?@ 23 8i?@ 7\u00a1(\"+,! \u00d8 (. no8i?@ \u00d2. 8*,,! $$@ \u00e2\u00e0\u00e1\u00e2 (S&\u00e3a\u00e4. 0\u00e5#! \u00db\u00dc! $$#-M: \u00e6\u00e7\u00e8H\u00e9!! $% $-S& (\u00e2 (\")*:,% \u00ea\u00eb\u00ec (\")*+, \u00aa: \u00eda7\u00ed&! y\u00eb\u00cf m= $$ m\u00e2}#;<\u00b6 \u00cc\u00ee\u00efH\u00e9! \u00db\u00dc#! $%%-# \u00dd!! \u00db\u00dc\u00f0\u00f1k\u00f2! \u00f6]^ 2\u00f3\u00ac! \u00db\u00dc. 1: \u00f6\u00f0s;<! L2\u00aaAa:! \u00db\u00dc \u00f4#", "num_citations": "32\n", "authors": ["1179"]}
{"title": "A statistical dependency parser of Chinese under small training data\n", "abstract": " CiNii \u8ad6\u6587 - A statistical dependency parser of Chinese under small training data CiNii \u56fd\u7acb \u60c5\u5831\u5b66\u7814\u7a76\u6240 \u5b66\u8853\u60c5\u5831\u30ca\u30d3\u30b2\u30fc\u30bf[\u30b5\u30a4\u30cb\u30a3] \u65e5\u672c\u306e\u8ad6\u6587\u3092\u3055\u304c\u3059 \u5927\u5b66\u56f3\u66f8\u9928\u306e\u672c\u3092\u3055\u304c\u3059 \u65e5\u672c\u306e\u535a\u58eb \u8ad6\u6587\u3092\u3055\u304c\u3059 \u65b0\u898f\u767b\u9332 \u30ed\u30b0\u30a4\u30f3 English \u691c\u7d22 \u3059\u3079\u3066 \u672c\u6587\u3042\u308a \u3059\u3079\u3066 \u672c\u6587\u3042\u308a \u9589\u3058\u308b \u30bf\u30a4\u30c8\u30eb \u8457\u8005 \u540d \u8457\u8005ID \u8457\u8005\u6240\u5c5e \u520a\u884c\u7269\u540d ISSN \u5dfb\u53f7\u30da\u30fc\u30b8 \u51fa\u7248\u8005 \u53c2\u8003\u6587\u732e \u51fa\u7248\u5e74 \u5e74\u304b\u3089 \u5e74\u307e\u3067 \u691c\u7d22 \u691c\u7d22 \u691c\u7d22 [\u6a5f\u95a2\u8a8d\u8a3c] \u5229\u7528\u7d99\u7d9a\u624b\u7d9a\u304d\u306e\u3054\u6848\u5185 \u5b66\u8a8d\u8a8d\u8a3c\u306e\u4e0d\u5177\u5408\u306b\u3064\u3044\u3066 A statistical dependency parser of Chinese under small training data JINSHAN M. \u88ab\u5f15\u7528\u6587\u732e: 1\u4ef6 \u8457\u8005 JINSHAN M. \u53ce\u9332\u520a\u884c\u7269 Proc. 1st International Joint Conference on Natural Language Processing (IJCNLP), Sanya City, Hainan Island, China, 2004 Proc. 1st International Joint Conference on Natural Language Processing (IJCNLP), Sanya City, Hainan Island, China, 2004, 2004 \u88ab\u5f15\u7528 \u6587\u732e: 1\u4ef6\u4e2d 1-1\u4ef6\u3092 \u8868\u793a 1 Dependency Parsing with Lattice Structures for Resource-Poor \u2026", "num_citations": "32\n", "authors": ["1179"]}
{"title": "Event representation learning enhanced with external commonsense knowledge\n", "abstract": " Prior work has proposed effective methods to learn event representations that can capture syntactic and semantic information over text corpus, demonstrating their effectiveness for downstream tasks such as script event prediction. On the other hand, events extracted from raw texts lacks of commonsense knowledge, such as the intents and emotions of the event participants, which are useful for distinguishing event pairs when there are only subtle differences in their surface realizations. To address this issue, this paper proposes to leverage external commonsense knowledge about the intent and sentiment of the event. Experiments on three event-related tasks, i.e., event similarity, script event prediction and stock market prediction, show that our model obtains much better event embeddings for the tasks, achieving 78% improvements on hard similarity task, yielding more precise inferences on subsequent events under given contexts, and better accuracies in predicting the volatilities of the stock market.", "num_citations": "31\n", "authors": ["1179"]}
{"title": "Capturing the semantics of key phrases using multiple languages for question retrieval\n", "abstract": " In the age of Web 2.0, community user contributed questions and answers provide an important alternative for knowledge acquisition through web search. Question retrieval in current community-based question answering (CQA) services do not, in general, work well for long and complex queries, such as the questions. The main reasons are the verboseness in natural language queries and the word mismatch between the queries and the candidate questions in the CQA archive during retrieval. To address these two problems, existing solutions try to refine the search queries by distinguishing the key concepts in the queries and expanding the queries with relevant content. However, using the existing query refinement approaches can only identify the key and non-key concepts, while the differences between the key concepts are overlooked. Moreover, the existing query expansion approaches, not only overlook the\u00a0\u2026", "num_citations": "31\n", "authors": ["1179"]}
{"title": "Microblog entity linking by leveraging extra posts\n", "abstract": " Linking name mentions in microblog posts to a knowledge base, namely microblog entity linking, is useful for text mining tasks on microblog. Entity linking in long text has been well studied in previous works. However few work has focused on short text such as microblog post. Microblog posts are short and noisy. Previous method can extract few features from the post context. In this paper we propose to use extra posts for the microblog entity linking task. Experimental results show that our proposed method significantly improves the linking accuracy over traditional methods by 8.3% and 7.5% respectively.", "num_citations": "31\n", "authors": ["1179"]}
{"title": "\u7edf\u8ba1\u4e0e\u8bcd\u5178\u76f8\u7ed3\u5408\u7684\u9886\u57df\u81ea\u9002\u5e94\u4e2d\u6587\u5206\u8bcd\n", "abstract": " \u6458! \u8981\" \u57fa\u4e8e\u7edf\u8ba1\u7684\u4e2d\u6587\u5206\u8bcd\u65b9\u6cd5\u7531\u4e8e\u8bad\u7ec3\u8bed\u6599\u9886\u57df\u7684\u9650\u5236! \u5bfc\u81f4\u5176\u9886\u57df\u81ea\u9002\u5e94\u6027\u80fd\u529b\u8f83\u5dee% \u76f8\u6bd4\u5206\u8bcd\u8bad\u7ec3\u8bed\u6599! \u9886\u57df\u8bcd\u5178\u7684\u83b7\u53d6\u8981\u5bb9\u6613\u8bb8\u591a! \u800c i \u80fd\u4e3a\u5206\u8bcd\u63d0\u4f9b\u4e30\u5bcc\u7684\u9886\u57df\u4fe1\u606f% \u8be5\u6587\u901a\u8fc7\u5c06\u8bcd\u5178\u4fe1\u606f U \u7279\u5f81\u7684\u65b9\u5f0f\u878d \u5230\u7edf\u8ba1\u5206\u8bcd\u6a21\u578b & \u8be5\u6587\u4f7f\u7528.)-\u7edf\u8ba1\u6a21\u578b'\u4e2d\u6765\u5b9e\u73b0\u9886\u57df\u81ea\u9002\u5e94\u6027% \u5b9e\u9a8c\u8868\u660e! \u8fd9# \u65b9\u6cd5\u663e\u8457\u63d0\u9ad8\u4e86\u7edf\u8ba1\u4e2d\u6587\u5206\u8bcd\u7684\u9886\u57df\u81ea\u9002\u5e94\u80fd\u529b% \u5f53\u6d4b\u8bd5\u9886\u57df\u548c\u8bad\u7ec3\u9886\u57df\u76f8\u540c\u65f6! \u5206\u8bcd\u7684-> RJ; TM< J \u503c\u63d0\u5347\u4e86! e (\u5f53\u6d4b\u8bd5\u9886\u57df\u548c\u8bad\u7ec3\u9886\u57df\u4e0d\u540c\u65f6! \u5206\u8bcd\u7684-> RJ; TM< J \u503c\u63d0\u5347\u4e86\" e%", "num_citations": "31\n", "authors": ["1179"]}
{"title": "\u7edf\u8ba1\u8bcd\u4e49\u6d88\u6b67\u7684\u7814\u7a76\u8fdb\u5c55\n", "abstract": " \u672c\u6587\u53c2\u8003\u5927\u91cf\u7684\u6587\u732e\u8d44\u6599, \u5206\u6790\u4e86\u5f53\u524d\u56fd\u5185\u5916\u7edf\u8ba1\u8bcd\u4e49\u6d88\u6b67\u7814\u7a76\u4e2d\u91c7\u7528\u7684\u591a\u79cd\u65b9\u6cd5\u548c\u6280\u672f, \u6307\u51fa\u4e86\u7edf\u8ba1\u8bcd\u4e49\u6d88\u6b67\u7814\u7a76\u7684\u5173\u952e\u95ee\u9898, \u5e76\u56f4\u7ed5\u5173\u952e\u95ee\u9898\u9610\u8ff0\u4e86\u7edf\u8ba1\u8bcd\u4e49\u6d88\u6b67\u7684\u7814\u7a76\u8fdb\u5c55, \u63a2\u8ba8\u4e86\u7814\u7a76\u4e2d\u5b58\u5728\u7684\u95ee\u9898\u548c\u672a\u6765\u7814\u7a76\u7684\u91cd\u70b9.", "num_citations": "31\n", "authors": ["1179"]}
{"title": "Entity-consistent end-to-end task-oriented dialogue system with kb retriever\n", "abstract": " Querying the knowledge base (KB) has long been a challenge in the end-to-end task-oriented dialogue system. Previous sequence-to-sequence (Seq2Seq) dialogue generation work treats the KB query as an attention over the entire KB, without the guarantee that the generated entities are consistent with each other. In this paper, we propose a novel framework which queries the KB in two steps to improve the consistency of generated entities. In the first step, inspired by the observation that a response can usually be supported by a single KB row, we introduce a KB retrieval component which explicitly returns the most relevant KB row given a dialogue history. The retrieval result is further used to filter the irrelevant entities in a Seq2Seq response generation model to improve the consistency among the output entities. In the second step, we further perform the attention mechanism to address the most correlated KB column. Two methods are proposed to make the training feasible without labeled retrieval data, which include distant supervision and Gumbel-Softmax technique. Experiments on two publicly available task oriented dialog datasets show the effectiveness of our model by outperforming the baseline systems and producing entity-consistent responses.", "num_citations": "30\n", "authors": ["1179"]}
{"title": "Joint optimization for Chinese pos tagging and dependency parsing\n", "abstract": " Dependency parsing has gained more and more interest in natural language processing in recent years due to its simplicity and general applicability for diverse languages. Previous work demonstrates that part-of-speech (POS) is an indispensable feature in dependency parsing since pure lexical features suffer from serious data sparseness problem. However, due to little morphological changes, Chinese POS tagging has proven to be much more challenging than morphology-richer languages such as English (94% vs. 97% on POS tagging accuracy). This leads to severe error propagation for Chinese dependency parsing. Our experiments show that parsing accuracy drops by about 6% when replacing manual POS tags of the input sentence with automatic ones generated by a state-of-the-art statistical POS tagger. To address this issue, this paper proposes a solution by jointly optimizing POS tagging and\u00a0\u2026", "num_citations": "30\n", "authors": ["1179"]}
{"title": "Exploiting multiple treebanks for parsing with quasi-synchronous grammars\n", "abstract": " We present a simple and effective framework for exploiting multiple monolingual treebanks with different annotation guidelines for parsing. Several types of transformation patterns (TP) are designed to capture the systematic annotation inconsistencies among different treebanks. Based on such TPs, we design quasisynchronous grammar features to augment the baseline parsing models. Our approach can significantly advance the state-of-the-art parsing accuracy on two widely used target treebanks (Penn Chinese Treebank 5.1 and 6.0) using the Chinese Dependency Treebank as the source treebank. The improvements are respectively 1.37% and 1.10% with automatic part-of-speech tags. Moreover, an indirect comparison indicates that our approach also outperforms previous work based on treebank conversion.", "num_citations": "30\n", "authors": ["1179"]}
{"title": "Appraisal expression recognition with syntactic path for sentence sentiment classification\n", "abstract": " An appraisal expression is described as a collocation of the polarity word and its modified target, which can be considered as an atomic unit expressing an evaluative stance towards a target. Recognizing appraisal expressions is essential for sentence sentiment classification. However, the relevant research is far from enough. This paper proposes a novel method that uses syntactic paths to recognize appraisal expressions. Compared with the previous work, the proposed syntactic path based method has two advantages: 1) it automatically explores syntactic knowledge, and 2) it covers more syntactic relationships between polarity words and targets. Based on these, this paper applies appraisal expressions to sentence sentiment classification. Some novel features based on appraisal expressions, including semantic features, syntactic features, lexical features and polarity features, are designed to classify sentiment\u00a0\u2026", "num_citations": "30\n", "authors": ["1179"]}
{"title": "Identification of web query intent based on query text and web knowledge\n", "abstract": " In this paper, we propose a novel approach to identifying user intents of search engine queries. Specifically, we recast it as a classification problem, in which four types of features are adopted. The classification features are based on deep linguistic analysis of queries as well as search engine feedbacks. We evaluate the method with the real web query data. The results show that about 88% of the test queries can be correctly identified with the classification framework via combining all the 4 types of features.", "num_citations": "30\n", "authors": ["1179"]}
{"title": "\u6700\u5927\u6982\u7387\u5206\u8bcd\u95ee\u9898\u53ca\u5176\u89e3\u6cd5\n", "abstract": " \u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u6c49\u65cf\u81ea\u52a8\u5206\u8bcd\u7b97\u6cd5,\u8be5\u7b97\u6cd5\u8fd0\u7528\u4eba\u5de5\u667a\u80fd\u4e2d\u7684\u95ee\u9898\u6c42\u89e3\u6280\u672f,\u5148\u5c06\u6c49\u65cf\u53e5\u5b50\u7684\u5207\u5206\u95ee\u9898\u5f52\u7ea6\u4e3a\u82e5\u5e72\u5b57\u6bb5\u7684\u5207\u5206\u95ee\u9898,\u518d\u7528\u542f\u53d1\u5f0f\u72b6\u6001\u7a7a\u95f4\u641c\u7d22\u6280\u672f\u5c06\u6bcf\u4e2a\u5b57\u6bb5\u5206\u522b\u8f6c\u6362\u4e3a\u6982\u7387\u6700\u5927\u7684\u8bcd\u5e8f\u5217.", "num_citations": "30\n", "authors": ["1179"]}
{"title": "HIT-SCIR at MRP 2019: A unified pipeline for meaning representation parsing via efficient training and effective encoding\n", "abstract": " This paper describes our system (HIT-SCIR) for CoNLL 2019 shared task: Cross-Framework Meaning Representation Parsing. We extended the basic transition-based parser with two improvements: a) Efficient Training by realizing Stack LSTM parallel training; b) Effective Encoding via adopting deep contextualized word embeddings BERT. Generally, we proposed a unified pipeline to meaning representation parsing, including framework-specific transition-based parsers, BERT-enhanced word representation, and post-processing. In the final evaluation, our system was ranked first according to ALL-F1 (86.2%) and especially ranked first in UCCA framework (81.67%).", "num_citations": "29\n", "authors": ["1179"]}
{"title": "Learning to ask unanswerable questions for machine reading comprehension\n", "abstract": " Machine reading comprehension with unanswerable questions is a challenging task. In this work, we propose a data augmentation technique by automatically generating relevant unanswerable questions according to an answerable question paired with its corresponding paragraph that contains the answer. We introduce a pair-to-sequence model for unanswerable question generation, which effectively captures the interactions between the question and the paragraph. We also present a way to construct training data for our question generation models by leveraging the existing reading comprehension dataset. Experimental results show that the pair-to-sequence model performs consistently better compared with the sequence-to-sequence baseline. We further use the automatically generated unanswerable questions as a means of data augmentation on the SQuAD 2.0 dataset, yielding 1.9 absolute F1 improvement with BERT-base model and 1.7 absolute F1 improvement with BERT-large model.", "num_citations": "29\n", "authors": ["1179"]}
{"title": "Generating Chinese named entity data from parallel corpora\n", "abstract": " Annotating named entity recognition (NER) training corpora is a costly but necessary process for supervised NER approaches. This paper presents a general framework to generate large-scale NER training data from parallel corpora. In our method, we first employ a high performance NER system on one side of a bilingual corpus. Then, we project the named entity (NE) labels to the other side according to the word level alignments. Finally, we propose several strategies to select high-quality auto-labeled NER training data. We apply our approach to Chinese NER using an English-Chinese parallel corpus. Experimental results show that our approach can collect high-quality labeled data and can help improve Chinese NER.", "num_citations": "29\n", "authors": ["1179"]}
{"title": "Table-to-text generation with effective hierarchical encoder on three dimensions (row, column and time)\n", "abstract": " Although Seq2Seq models for table-to-text generation have achieved remarkable progress, modeling table representation in one dimension is inadequate. This is because (1) the table consists of multiple rows and columns, which means that encoding a table should not depend only on one dimensional sequence or set of records and (2) most of the tables are time series data (e.g. NBA game data, stock market data), which means that the description of the current table may be affected by its historical data. To address aforementioned problems, not only do we model each table cell considering other records in the same row, we also enrich table's representation by modeling each table cell in context of other cells in the same column or with historical (time dimension) data respectively. In addition, we develop a table cell fusion gate to combine representations from row, column and time dimension into one dense vector according to the saliency of each dimension's representation. We evaluated our methods on ROTOWIRE, a benchmark dataset of NBA basketball games. Both automatic and human evaluation results demonstrate the effectiveness of our model with improvement of 2.66 in BLEU over the strong baseline and outperformance of state-of-the-art model.", "num_citations": "28\n", "authors": ["1179"]}
{"title": "Sequence-to-sequence learning for task-oriented dialogue with dialogue state representation\n", "abstract": " Classic pipeline models for task-oriented dialogue system require explicit modeling the dialogue states and hand-crafted action spaces to query a domain-specific knowledge base. Conversely, sequence-to-sequence models learn to map dialogue history to the response in current turn without explicit knowledge base querying. In this work, we propose a novel framework that leverages the advantages of classic pipeline and sequence-to-sequence models. Our framework models a dialogue state as a fixed-size distributed representation and use this representation to query a knowledge base via an attention mechanism. Experiment on Stanford Multi-turn Multi-domain Task-oriented Dialogue Dataset shows that our framework significantly outperforms other sequence-to-sequence based baseline models on both automatic and human evaluation.", "num_citations": "28\n", "authors": ["1179"]}
{"title": "A neural attention model for disfluency detection\n", "abstract": " In this paper, we study the problem of disfluency detection using the encoder-decoder framework. We treat disfluency detection as a sequence-to-sequence problem and propose a neural attention-based model which can efficiently model the long-range dependencies between words and make the resulting sentence more likely to be grammatically correct. Our model firstly encode the source sentence with a bidirectional Long Short-Term Memory (BI-LSTM) and then use the neural attention as a pointer to select an ordered sub sequence of the input as the output. Experiments show that our model achieves the state-of-the-art f-score of 86.7% on the commonly used English Switchboard test set. We also evaluate the performance of our model on the in-house annotated Chinese data and achieve a significantly higher f-score compared to the baseline of CRF-based approach.", "num_citations": "28\n", "authors": ["1179"]}
{"title": "Modeling sociocultural phenomena in discourse\n", "abstract": " In this paper, we describe a novel approach to computational modeling and understanding of social and cultural phenomena in multi-party dialogues. We developed a two-tier approach in which we first detect and classify certain sociolinguistic behaviors, including topic control, disagreement, and involvement, that serve as first-order models from which presence the higher level social roles, such as leadership, may be inferred.", "num_citations": "28\n", "authors": ["1179"]}
{"title": "Jointly modeling wsd and srl with markov logic\n", "abstract": " Semantic role labeling (SRL) and word sense disambiguation (WSD) are two fundamental tasks in natural language processing to find a sentence-level semantic representation. To date, they have mostly been modeled in isolation. However, this approach neglects logical constraints between them. We therefore exploit some pipeline systems which verify the automatic all word sense disambiguation could help the semantic role labeling and vice versa. We further propose a Markov logic model that jointly labels semantic roles and disambiguates all word senses. By evaluating our model on the OntoNotes 3.0 data, we show that this joint approach leads to a higher performance for word sense disambiguation and semantic role labeling than those pipeline approaches.", "num_citations": "28\n", "authors": ["1179"]}
{"title": "\u57fa\u4e8e\u5b50\u8bdd\u9898\u5206\u6cbb\u5339\u914d\u7684\u65b0\u4e8b\u4ef6\u68c0\u6d4b\n", "abstract": " \u6458 \u8981 \u65b0\u4e8b\u4ef6\u68c0\u6d4b\u662f\u8bdd\u9898\u68c0\u6d4b\u4e0e\u8ddf\u8e2a\u9886\u57df\u7684\u4e00\u9879\u91cd\u8981\u7814\u7a76, \u5176\u4efb\u52a1\u662f\u5b9e\u65f6\u76d1\u63a7\u65b0\u95fb\u62a5\u9053\u6d41\u5e76\u4ece\u4e2d\u8bc6\u522b\u65b0\u8bdd\u9898. \u73b0\u6709\u65b9\u6cd5\u5c06\u8bdd\u9898\u548c\u62a5\u9053\u63cf\u8ff0\u4e3a\u5355\u4e00\u7ed3\u6784\u7684\u7279\u5f81\u5411\u91cf\u8fdb\u884c\u5339\u914d, \u9020\u6210\u5b50\u8bdd\u9898\u95f4\u4e92\u4e3a\u566a\u58f0\u5e76\u5f62\u6210\u9519\u8bef\u8bed\u4e49, \u4ece\u800c\u8bef\u5bfc\u65b0\u8bdd\u9898\u7684\u8bc6\u522b. \u9488\u5bf9\u8fd9\u4e00\u7f3a\u9677, \u6587\u4e2d\u63d0\u51fa\u57fa\u4e8e\u5b50\u8bdd\u9898\u5206\u6cbb\u5339\u914d\u7684\u65b0\u4e8b\u4ef6\u68c0\u6d4b\u65b9\u6cd5, \u5c06\u8bdd\u9898\u548c\u62a5\u9053\u5212\u5206\u4e3a\u4e0d\u540c\u5b50\u8bdd\u9898, \u6839\u636e\u76f8\u5173\u5b50\u8bdd\u9898\u7684\u6bd4\u4f8b\u5173\u7cfb\u548c\u5206\u5e03\u5173\u7cfb\u5efa\u7acb\u65b0\u8bdd\u9898\u8bc6\u522b\u6a21\u578b. \u5b9e\u9a8c\u5728 TDT4 \u548c TDT5 \u4e2d\u83b7\u5f97\u663e\u8457\u6539\u8fdb, \u6700\u5c0f\u68c0\u6d4b\u9519\u8bef\u4ee3\u4ef7\u4e3a 0.4061, \u76f8\u5e94\u6f0f\u68c0\u7387\u4e3a 0.1859.", "num_citations": "28\n", "authors": ["1179"]}
{"title": "Topical Co-Attention Networks for hashtag recommendation on microblogs\n", "abstract": " Hashtags provide a simple and natural way of organizing content in microblog services. Along with the fast growing of microblog services, the task of recommending hashtags for microblogs has been given increasing attention in recent years. However, much of the research depends on hand-crafted features. Motivated by the successful use of neural models for many natural language processing tasks, in this paper, we adopt an attention based neural network to learn the representation of a microblog post. Unlike previous works, which only focus on content attention of microblogs, we propose a novel Topical Co-Attention Network (TCAN) that jointly models content attention and topic attention simultaneously, in the sense that the content representation(s) are used to guide the topic attention and the topic representation is used to guide content attention. We conduct experiments and test with different settings of\u00a0\u2026", "num_citations": "27\n", "authors": ["1179"]}
{"title": "Generating reasonable and diversified story ending using sequence to sequence model with adversarial training\n", "abstract": " Story generation is a challenging problem in artificial intelligence (AI) and has received a lot of interests in the natural language processing (NLP) community. Most previous work tried to solve this problem using Sequence to Sequence (Seq2Seq) model trained with Maximum Likelihood Estimation (MLE). However, the pure MLE training objective much limits the power of Seq2Seq model in generating high-quality storys. In this paper, we propose using adversarial training augmented Seq2Seq model to generate reasonable and diversified story endings given a story context. Our model includes a generator that defines the policy of generating a story ending, and a discriminator that labels story endings as human-generated or machine-generated. Carefully designed human and automatic evaluation metrics demonstrate that our adversarial training augmented Seq2Seq model can generate more reasonable and diversified story endings compared to purely MLE-trained Seq2Seq model. Moreover, our model achieves better performance on the task of Story Cloze Test with an accuracy of 62.6% compared with state-of-the-art baseline methods.", "num_citations": "27\n", "authors": ["1179"]}
{"title": "Extracting paraphrase patterns from bilingual parallel corpora\n", "abstract": " Paraphrase patterns are semantically equivalent patterns, which are useful in both paraphrase recognition and generation. This paper presents a pivot approach for extracting paraphrase patterns from bilingual parallel corpora, whereby the paraphrase patterns in English are extracted using the patterns in another language as pivots. We make use of log-linear models for computing the paraphrase likelihood between pattern pairs and exploit feature functions based on maximum likelihood estimation (MLE), lexical weighting (LW), and monolingual word alignment (MWA). Using the presented method, we extract more than 1 million pairs of paraphrase patterns from about 2 million pairs of bilingual parallel sentences. The precision of the extracted paraphrase patterns is above 78%. Experimental results show that the presented method significantly outperforms a well-known method called discovery of inference rules\u00a0\u2026", "num_citations": "27\n", "authors": ["1179"]}
{"title": "Dependency based chinese sentence realization\n", "abstract": " This paper describes log-linear models for a general-purpose sentence realizer based on dependency structures. Unlike traditional realizers using grammar rules, our method realizes sentences by linearizing dependency relations directly in two steps. First, the relative order between head and each dependent is determined by their dependency relation. Then the best linearizations compatible with the relative order are selected by log-linear models. The log-linear models incorporate three types of feature functions, including dependency relations, surface words and headwords. Our approach to sentence realization provides simplicity, efficiency and competitive accuracy. Trained on 8,975 dependency structures of a Chinese Dependency Treebank, the realizer achieves a BLEU score of 0.8874.", "num_citations": "27\n", "authors": ["1179"]}
{"title": "\u57fa\u4e8e\u8bcd\u6c47\u652f\u914d\u5ea6\u7684\u6c49\u8bed\u4f9d\u5b58\u5206\u6790\u6a21\u578b\n", "abstract": " \u6458\u8981; \u5982\u4f55\u5e94\u7528\u53e5\u6cd5\u7ed3\u6784\u548c\u8bcd\u6c47\u5316\u662f\u53e5\u6cd5\u5206\u6790\u5efa\u6a21\u6240\u9762\u4e34\u7684\u4e24\u4e2a\u4e3b\u8981\u95ee\u9898. \u6c49\u8bed\u4f9d\u5b58\u5206\u6790\u5bf9\u8fd9\u4e24\u65b9\u9762\u505a\u4e86\u521d\u6b65\u7684\u63a2\u7d22. \u9996\u5148\u901a\u8fc7\u5bf9\u5927\u89c4\u6a21\u4f9d\u5b58\u6811\u5e93\u7684\u7edf\u8ba1\u5b66\u4e60, \u83b7\u53d6\u5176\u4e2d\u7684\u8bcd\u6c47\u4f9d\u5b58\u4fe1\u606f, \u5efa\u7acb\u4e86\u4e00\u4e2a\u8bcd\u6c47\u5316\u7684\u6982\u7387\u5206\u6790\u6a21\u578b. \u7136\u540e\u5f15\u5165\u8bcd\u6c47\u652f\u914d\u5ea6\u7684\u6982\u5ff5. \u4ee5\u5145\u5206\u5229\u7528\u4e86\u53e5\u5b50\u4e2d\u7684\u7ed3\u6784\u4fe1\u606f. \u8bcd\u6c47\u5316\u65b9\u6cd5\u6709\u6548\u5730\u5f25\u8865\u4e86\u4ee5\u524d\u5de5\u4f5c\u4e2d\u8bcd\u6027\u4fe1\u606f\u7684\u7c92\u5ea6\u8fc7\u7c97\u95ee\u9898. \u540c\u65f6, \u8bcd\u6c47\u652f\u914d\u5ea6\u589e\u5f3a\u4e86\u5bf9\u53e5\u6cd5\u7ed3\u6784\u7684\u8bc6\u522b, \u6709\u6548\u5730\u907f\u514d\u4e86\u975e\u6cd5\u7ed3\u6784\u7684\u751f\u6210. \u5728 4000 \u53e5\u7684\u6d4b\u8bd5\u96c6\u4e0a. \u4f9d\u5b58\u5206\u6790\u83b7\u5f97\u4e86\u7ea6 74% \u7684\u6b63\u786e\u7387.", "num_citations": "27\n", "authors": ["1179"]}
{"title": "A hybrid convolution tree kernel for semantic role labeling\n", "abstract": " A hybrid convolution tree kernel is proposed in this paper to effectively model syntactic structures for semantic role labeling (SRL). The hybrid kernel consists of two individual convolution kernels: a Path kernel, which captures predicateargument link features, and a Constituent Structure kernel, which captures the syntactic structure features of arguments. Evaluation on the datasets of CoNLL-2005 SRL shared task shows that the novel hybrid convolution tree kernel outperforms the previous tree kernels. We also combine our new hybrid tree kernel based method with the standard rich flat feature based method. The experimental results show that the combinational method can get better performance than each of them individually.", "num_citations": "27\n", "authors": ["1179"]}
{"title": "Retrieval-enhanced adversarial training for neural response generation\n", "abstract": " Dialogue systems are usually built on either generation-based or retrieval-based approaches, yet they do not benefit from the advantages of different models. In this paper, we propose a Retrieval-Enhanced Adversarial Training (REAT) method for neural response generation. Distinct from existing approaches, the REAT method leverages an encoder-decoder framework in terms of an adversarial training paradigm, while taking advantage of N-best response candidates from a retrieval-based system to construct the discriminator. An empirical study on a large scale public available benchmark dataset shows that the REAT method significantly outperforms the vanilla Seq2Seq model as well as the conventional adversarial training approach.", "num_citations": "26\n", "authors": ["1179"]}
{"title": "Zero pronoun resolution with attention-based neural network\n", "abstract": " Recent neural network methods for zero pronoun resolution explore multiple models for generating representation vectors for zero pronouns and their candidate antecedents. Typically, contextual information is utilized to encode the zero pronouns since they are simply gaps that contain no actual content. To better utilize contexts of the zero pronouns, we here introduce the self-attention mechanism for encoding zero pronouns. With the help of the multiple hops of attention, our model is able to focus on some informative parts of the associated texts and therefore produces an efficient way of encoding the zero pronouns. In addition, an attention-based recurrent neural network is proposed for encoding candidate antecedents by their contents. Experiment results are encouraging: our proposed attention-based model gains the best performance on the Chinese portion of the OntoNotes corpus, substantially surpasses existing Chinese zero pronoun resolution baseline systems.", "num_citations": "26\n", "authors": ["1179"]}
{"title": "A separately passive-aggressive training algorithm for joint POS tagging and dependency parsing\n", "abstract": " Recent study shows that parsing accuracy can be largely improved by the joint optimization of part-of-speech (POS) tagging and dependency parsing. However, the POS tagging task does not benefit much from the joint framework. We argue that the fundamental reason behind is because the POS features are overwhelmed by the syntactic features during the joint optimization, and the joint models only prefer such POS tags that are favourable solely from the parsing viewpoint. To solve this issue, we propose a separately passive-aggressive learning algorithm (SPA), which is designed to separately update the POS features weights and the syntactic feature weights under the joint optimization framework. The proposed SPA is able to take advantage of previous joint optimization strategies to significantly improve the parsing accuracy, but also overcome their shortages to significantly boost the tagging accuracy by effectively solving the syntax-insensitive POS ambiguity issues. Experiments on the Chinese Penn Treebank 5.1 (CTB5) and the English Penn Treebank (PTB) demonstrate the effectiveness of our proposed methodology and empirically verify our observations as discussed above. We achieve the best tagging and parsing accuracies on both datasets, 94.60% in tagging accuracy and 81.67% in parsing accuracy on CTB5, and 97.62% and 93.52% on PTB.", "num_citations": "26\n", "authors": ["1179"]}
{"title": "Bridging topic modeling and personalized search\n", "abstract": " This work presents a study to bridge topic modeling and personalized search. A probabilistic topic model is used to extract topics from user search history. These topics can be seen as a roughly summary of user preferences and further treated as feedback within the KL-Divergence retrieval model to estimate a more accurate query model. The topics more relevant to current query contribute more in updating the query model which helps to distinguish between relevant and irrelevant parts and filter out noise in user search history. We designed task oriented user study and the results show that:(1) The extracted topics can be used to cluster queries according to topics.(2) The proposed approach improves ranking quality consistently for queries matching user past interests and is robust for queries not matching past interests.", "num_citations": "26\n", "authors": ["1179"]}
{"title": "Event type recognition based on trigger expansion\n", "abstract": " Event extraction is an important research point in information extraction, which includes two important sub-tasks of event type recognition and event argument recognition. This paper describes a method based on automatic expansion of the event triggers for event type recognition. The event triggers are first extended through a thesaurus to enable the extraction of the candidate events and their candidate types. Then, a binary classification method is used to recognize the candidate event types. This method effectively improves the unbalanced data problem in training models and the data sparseness problem with a small corpus. Evaluations on the ACE2005 dataset give a final F-score of 61.24%, which outperforms traditional methods based on pure machine learning.", "num_citations": "26\n", "authors": ["1179"]}
{"title": "Feature engineering for Chinese semantic role labeling\n", "abstract": " In the natural language processing field, researchers have experienced a growth of interest in semantic role labeling by applying statistical and machine-learning methods. Using rich features is the most important part of semantic parsing system. In this paper, some new effective features and combination features are proposed, such as next word of the constituent, predicate and phrase type combination, predicate class and path combination, and so on. And then we report the experiments on the dataset from Chinese Proposition Bank (CPB). After these new features used, the final system improves the F-Score from 89.76% to 91.31%. The results show that the performance of the system has a statistically significant increase. Therefore it is very important to find better features for semantic role labeling.", "num_citations": "26\n", "authors": ["1179"]}
{"title": "An AMR aligner tuned by transition-based parser\n", "abstract": " In this paper, we propose a new rich resource enhanced AMR aligner which produces multiple alignments and a new transition system for AMR parsing along with its oracle parser. Our aligner is further tuned by our oracle parser via picking the alignment that leads to the highest-scored achievable AMR graph. Experimental results show that our aligner outperforms the rule-based aligner in previous work by achieving higher alignment F1 score and consistently improving two open-sourced AMR parsers. Based on our aligner and transition system, we develop a transition-based AMR parser that parses a sentence into its AMR graph directly. An ensemble of our parsers with only words and POS tags as input leads to 68.4 Smatch F1 score.", "num_citations": "25\n", "authors": ["1179"]}
{"title": "Contradiction detection with contradiction-specific word embedding\n", "abstract": " Contradiction detection is a task to recognize contradiction relations between a pair of sentences. Despite the effectiveness of traditional context-based word embedding learning algorithms in many natural language processing tasks, such algorithms are not powerful enough for contradiction detection. Contrasting words such as \u201coverfull\u201d and \u201cempty\u201d are mostly mapped into close vectors in such embedding space. To solve this problem, we develop a tailored neural network to learn contradiction-specific word embedding (CWE). The method can separate antonyms in the opposite ends of a spectrum. CWE is learned from a training corpus which is automatically generated from the paraphrase database, and is naturally applied as features to carry out contradiction detection in SemEval 2014 benchmark dataset. Experimental results show that CWE outperforms traditional context-based word embedding in contradiction detection. The proposed model for contradiction detection performs comparably with the top-performing system in accuracy of three-category classification and enhances the accuracy from 75.97% to 82.08% in the contradiction category. View Full-Text", "num_citations": "25\n", "authors": ["1179"]}
{"title": "Exploiting multiple sources for open-domain hypernym discovery\n", "abstract": " Hypernym discovery aims to extract such noun pairs that one noun is a hypernym of the other. Most previous methods are based on lexical patterns but perform badly on opendomain data. Other work extracts hypernym relations from encyclopedias but has limited coverage. This paper proposes a simple yet effective distant supervision framework for Chinese open-domain hypernym discovery. Given an entity name, we try to discover its hypernyms by leveraging knowledge from multiple sources, ie, search engine results, encyclopedias, and morphology of the entity name. First, we extract candidate hypernyms from the above sources. Then, we apply a statistical ranking model to select correct hypernyms. A set of novel features is proposed for the ranking model. We also present a heuristic strategy to build a large-scale noisy training data for the model without human annotation. Experimental results demonstrate that our approach outperforms the state-of-the-art methods on a manually labeled test dataset.", "num_citations": "25\n", "authors": ["1179"]}
{"title": "The use of dependency relation graph to enhance the term weighting in question retrieval\n", "abstract": " With the emergence of community-based question answering (cQA) services, question retrieval has become an integral part of information and knowledge acquisition. Though existing information retrieval (IR) technologies have been found to be successful for document retrieval, they are less effective for question retrieval due to the inherent characteristics of questions, which have shorter texts. One of the major common drawbacks for the term weightingbased question retrieval models is that they overlook the relations between term pairs when computing their weights. To tackle this problem, we propose a novel term weighting scheme by incorporating the dependency relation cues between term pairs. Given a question, we first construct a dependency graph and compute the relation strength between each term pairs. Next, based on the dependency relation scores, we refine the initial term weights estimated by conventional term weighting approaches. We demonstrate that the proposed term weighting scheme can be seamlessly integrated with popular question retrieval models. Comprehensive experiments well validate our proposed scheme and show that it achieves promising performance as compared to the state-of-the-art methods.", "num_citations": "25\n", "authors": ["1179"]}
{"title": "Paraphrasing with search engine query logs\n", "abstract": " This paper proposes a method that extracts paraphrases from search engine query logs. The method first extracts paraphrase query-title pairs based on an assumption that a search query and its corresponding clicked document titles may mean the same thing. It then extracts paraphrase query-query and title-title pairs from the query-title paraphrases with a pivot approach. Paraphrases extracted in each step are validated with a binary classifier. We evaluate the method using a query log from Baidu1, a Chinese search engine. Experimental results show that the proposed method is effective, which extracts more than 3.5 million pairs of paraphrases with a precision of over 70%. The results also show that the extracted paraphrases can be used to generate high-quality paraphrase patterns.", "num_citations": "25\n", "authors": ["1179"]}
{"title": "\u57fa\u4e8e\u793e\u4f1a\u7f51\u7edc\u7684\u4eba\u540d\u68c0\u7d22\u7ed3\u679c\u91cd\u540d\u6d88\u89e3\n", "abstract": " \u6458 \u8981 \u4eba\u7269\u91cd\u540d\u73b0\u8c61\u5341\u5206\u666e\u904d, \u641c\u7d22\u5f15\u64ce\u7684\u4eba\u540d\u68c0\u7d22\u7ed3\u679c\u901a\u5e38\u662f\u591a\u4e2a\u540c\u540d\u4eba\u7269\u76f8\u5173\u7f51\u9875\u7684\u6df7\u5408. \u8be5\u6587\u4f9d\u636e\u540c\u540d\u7684\u4e0d\u540c\u4eba\u7269\u5177\u6709\u4e0d\u540c\u7684\u793e\u4f1a\u7f51\u7edc\u7684\u601d\u60f3, \u5229\u7528\u68c0\u7d22\u7ed3\u679c\u4e2d\u5171\u73b0\u7684\u4eba\u540d\u53d1\u73b0\u5e76\u62d3\u5c55\u68c0\u7d22\u4eba\u7269\u76f8\u5173\u7684\u6f5c\u5728\u793e\u4f1a\u7f51\u7edc, \u7ed3\u5408\u56fe\u7684\u8c31\u5206\u5272\u7b97\u6cd5\u548c\u6a21\u5757\u5ea6\u6307\u6807\u8fdb\u884c\u793e\u4f1a\u7f51\u7edc\u7684\u81ea\u52a8\u805a\u7c7b, \u5728\u6b64\u57fa\u7840\u4e0a\u5b9e\u73b0\u4eba\u540d\u68c0\u7d22\u7ed3\u679c\u7684\u91cd\u540d\u6d88\u89e3. \u5728\u4eba\u5de5\u6807\u6ce8\u7684\u4e2d\u6587\u4eba\u540d\u8bed\u6599\u4e0a\u8fdb\u884c\u5b9e\u9a8c, \u6574\u4f53\u6027\u80fd\u8fbe\u5230\u8f83\u597d\u6c34\u5e73, \u56fe\u805a\u7c7b\u7b97\u6cd5\u80fd\u5e2e\u52a9\u8fde\u901a\u793e\u4f1a\u7f51\u7edc\u7684\u8fdb\u4e00\u6b65\u5212\u5206, \u4ece\u800c\u63d0\u9ad8\u6d88\u89e3\u6548\u679c.", "num_citations": "25\n", "authors": ["1179"]}
{"title": "Automatic Acquisition of Context-Specific Lexical Paraphrases.\n", "abstract": " Lexical paraphrasing aims at acquiring word-level paraphrases. It is critical for many Natural Language Processing (NLP) applications, such as Question Answering (QA), Information Extraction (IE), and Machine Translation (MT). Since the meaning and usage of a word can vary in distinct contexts, different paraphrases should be acquired according to the contexts. However, most of the existing researches focus on constructing paraphrase corpora, in which little contextual constraints for paraphrase application are imposed. This paper presents a method that automatically acquires context-specific lexical paraphrases. In this method, the obtained paraphrases of a word depend on the specific sentence the word occurs in. Two stages are included, ie candidate paraphrase extraction and paraphrase validation, both of which are mainly based on web mining. Evaluations are conducted on a news title corpus and the presented method is compared with a paraphrasing method that exploits a Chinese thesaurus of synonyms--Tongyi Cilin (Extended)(CilinE for short). Results show that the f-measure of our method (0.4852) is significantly higher than that using CilinE (0.1127). In addition, over 85% of the correct paraphrases derived by our method cannot be found in CilinE, which suggests that our method is effective in acquiring out-of-thesaurus paraphrases.", "num_citations": "25\n", "authors": ["1179"]}
{"title": "Improving candidate generation for entity linking\n", "abstract": " Entity linking is the task of linking names in free text to the referent entities in a knowledge base. Most recently proposed linking systems can be broken down into two steps: candidate generation and candidate ranking. The first step searches candidates from the knowledge base and the second step disambiguates them. Previous works have been focused on the recall of the generation because if the target entity is absent in the candidate set, no ranking method can return the correct result. Most of the recall-driven generation strategies will increase the number of the candidates. However, with large candidate sets, memory/time consuming systems are impractical for online applications. In this paper, we propose a novel candidate generation approach to generate high recall candidate set with small size. Experimental results on two KBP data sets show that the candidate generation recall achieves more\u00a0\u2026", "num_citations": "24\n", "authors": ["1179"]}
{"title": "Combining Statistical Model and Dictionary for Domain Adaption of Chinese Word Segmentation\n", "abstract": " Generally, statistical methods for Chinese Word Segmentation don't have good domain adaptability owing to the specific training corpus. In practice, domain dictionaries are more easily achieved than humanly annotated segmentation corpus, and it contains plenty of domain information. We propose an approach which integrates dictionary information into statistical models (ie, CRF model in this paper) to realize domain adaption for Chinese Word Segmentation. Experimental results show that our approach have good domain adaption. When the test corpus is identical to the domain of training corpus, the F-measure value increases 2%; when test corpus is in a different domain of the training corpus, the F-measure value increases 6%.[Fund]: \u56fd\u5bb6\u81ea\u7136\u79d1\u5b66\u57fa\u91d1\u91cd\u70b9\u9879\u76ee (61133012); \u56fd\u5bb6\u81ea\u7136\u79d1\u5b66\u57fa\u91d1\u8d44\u52a9\u9879\u76ee (60803093);; \u56fd\u5bb6 863 \u91cd\u5927\u9879\u76ee (2011AA01A207);; \u6838\u9ad8\u57fa\u91cd\u5927\u4e13\u9879 (2011ZX01042-001-001);; \u54c8\u5c14\u6ee8\u5de5\u4e1a\u5927\u5b66\u79d1\u7814\u521b\u65b0\u57fa\u91d1 (HIT. NSRIF. 2009069);; \u4e2d\u592e\u9ad8\u6821\u57fa\u672c\u79d1\u7814\u4e1a\u52a1\u8d39\u4e13\u9879\u8d44\u91d1 (HIT. KLOF. 2010064)", "num_citations": "24\n", "authors": ["1179"]}
{"title": "\u57fa\u4e8e\u4f9d\u5b58\u5206\u6790\u548c\u9519\u8bef\u9a71\u52a8\u7684\u4e2d\u6587\u65f6\u95f4\u8868\u8fbe\u5f0f\u8bc6\u522b\n", "abstract": " \u65f6\u95f4\u8868\u8fbe\u5f0f\u8bc6\u522b\u662f\u8fdb\u884c\u65f6\u95f4\u8868\u8fbe\u5f0f\u5f52\u4e00\u5316\u7684\u57fa\u7840, \u5176\u8bc6\u522b\u7ed3\u679c\u7684\u597d\u574f\u76f4\u63a5\u5f71\u54cd\u5f52\u4e00\u5316\u7684\u6548\u679c. \u672c\u6587\u63d0\u51fa\u4e00\u79cd\u57fa\u4e8e\u4f9d\u5b58\u5206\u6790\u548c\u9519\u8bef\u9a71\u52a8\u8bc6\u522b\u4e2d\u6587\u65f6\u95f4\u8868\u8fbe\u5f0f\u7684\u65b0\u65b9\u6cd5. \u9996\u5148\u4ee5\u65f6\u95f4\u89e6\u53d1\u8bcd\u4e3a\u5207\u5165\u70b9, \u636e\u4f9d\u5b58\u5173\u7cfb\u9012\u5f52\u5730\u8bc6\u522b\u65f6\u95f4\u8868\u8fbe\u5f0f, \u5927\u5927\u5730\u63d0\u9ad8\u4e86\u8bc6\u522b\u6548\u679c; \u7136\u540e, \u91c7\u7528\u9519\u8bef\u9a71\u52a8\u5b66\u4e60\u6765\u8fdb\u4e00\u6b65\u589e\u5f3a\u8bc6\u522b\u6548\u679c, \u6839\u636e\u9519\u8bef\u8bc6\u522b\u7ed3\u679c\u548c\u4eba\u5de5\u6807\u6ce8\u7684\u5dee\u5f02\u81ea\u52a8\u5730\u83b7\u53d6\u548c\u6539\u8fdb\u89c4\u5219, \u4f7f\u7cfb\u7edf\u7684\u6027\u80fd\u53c8\u63d0\u9ad8\u4e86\u8fd1 3. 5%. \u6700\u7ec8\u5728\u5c01\u95ed\u6d4b\u8bd5\u96c6\u548c\u5f00\u653e\u6d4b\u8bd5\u96c6\u4e0a, F1 \u503c\u8fbe\u5230\u4e86 76. 38% \u548c 76. 57%.", "num_citations": "24\n", "authors": ["1179"]}
{"title": "The Role of\" Condition\" A Novel Scientific Knowledge Graph Representation and Construction Model\n", "abstract": " Conditions play an essential role in scientific observations, hypotheses, and statements. Unfortunately, existing scientific knowledge graphs (SciKGs) represent factual knowledge as a flat relational network of concepts, as same as the KGs in general domain, without considering the conditions of the facts being valid, which loses important contexts for inference and exploration. In this work, we propose a novel representation of SciKG, which has three layers. The first layer has concept nodes, attribute nodes, as well as the attaching links from attribute to concept. The second layer represents both fact tuples and condition tuples. Each tuple is a node of the relation name, connecting to the subject and object that are concept or attribute nodes in the first layer. The third layer has nodes of statement sentences traceable to the original paper and authors. Each statement node connects to a set of fact tuples and/or condition\u00a0\u2026", "num_citations": "23\n", "authors": ["1179"]}
{"title": "Open-categorical text classification based on multi-LDA models\n", "abstract": " We present a new and realistic problem, open-categorical text classification, which requires us to classify documents without the categorization system known beforehand. To solve this problem, we propose a novel approach to construct the categorization system and classify documents based on multi-latent Dirichlet allocation (LDA) models. We cluster topics and extract topical keywords to help category annotation. Subsequently, the LDA models are applied to predict the categories of documents comprehensively. Our result, a macro-averaged F1 measure of 84.02\u00a0%, outperforms the state-of-the-art supervised and semi-supervised text classification methods.", "num_citations": "23\n", "authors": ["1179"]}
{"title": "Mining user's real social circle in microblog\n", "abstract": " As a media and communication platform, microblog is more and more popular around the world. Users can follow anyone ranges from well-known individuals to real friends, and read their tweets without their permission. Most users follow a large number of celebrities and public media in microblog, however, these celebrities do not necessarily follow all their fans. Such one-way relationship abounds in the user network and is displayed in the forms of users' followees and followers, which make it difficult to identify users' real friends who are contained in the merged list of followees and followers. The aim of this paper is to propose a general algorithm for mining users' real friends in social media and dividing them into different social circles automatically according to the closeness of their relationships. To verify the effectiveness of the proposed algorithm, we build a microblog application which presents the social\u00a0\u2026", "num_citations": "23\n", "authors": ["1179"]}
{"title": "\u6c49\u8bed\u81ea\u52a8\u53e5\u6cd5\u5206\u6790\u7684\u7406\u8bba\u4e0e\u65b9\u6cd5\n", "abstract": " \u672c\u6587\u6982\u8ff0\u5f53\u524d\u6c49\u8bed\u53e5\u6cd5\u5206\u6790\u7684\u7406\u8bba\u548c\u65b9\u6cd5,\u4e3b\u8981\u5305\u62ec\u4e09\u90e8\u5206\u5185\u5bb9:(1)\u53e5\u6cd5\u5206\u6790\u7684\u8bed\u6cd5\u4f53\u7cfb,\u4ecb\u7ecd\u4e86\u53e5\u6cd5\u5206\u6790\u5de5\u4f5c\u6240\u9075\u5faa\u7684\u4e3b\u8981\u8bed\u6cd5\u7406\u8bba\u548c\u6811\u5e93\u8d44\u6e90\u5efa\u8bbe\u65b9\u9762\u7684\u5de5\u4f5c\u8fdb\u5c55;(2)\u53e5\u6cd5\u5206\u6790\u7684\u4e3b\u8981\u65b9\u6cd5,\u5bf9\u53e5\u6cd5\u5206\u6790\u4e2d\u7684\u96be\u70b9\u95ee\u9898\u4ee5\u53ca\u5f53\u524d\u4e3b\u6d41\u7684\u4e00\u4e9b\u53e5\u6cd5\u5206\u6790\u6280\u672f\u8fdb\u884c\u4e86\u8ba8\u8bba;(3)\u6c49\u8bed\u53e5\u6cd5\u5206\u6790\u7684\u7814\u7a76\u73b0\u72b6,\u4e3b\u8981\u4ecb\u7ecd\u4e86\u5f53\u524d\u6c49\u8bed\u53e5\u6cd5\u5206\u6790\u5de5\u4f5c\u7684\u7814\u7a76\u8fdb\u5c55\u4ee5\u53ca\u5b58\u5728\u7684\u4e00\u4e9b\u4e3b\u8981\u95ee\u9898.", "num_citations": "23\n", "authors": ["1179"]}
{"title": "\u57fa\u4e8e\u4f9d\u5b58\u5206\u6790\u6539\u8fdb\u8d1d\u53f6\u65af\u6a21\u578b\u7684\u8bcd\u4e49\u6d88\u6b67\n", "abstract": " \u8bcd\u4e49\u6d88\u6b67\u4e00\u76f4\u662f\u81ea\u7136\u8bed\u8a00\u5904\u7406\u9886\u57df\u7684\u5173\u952e\u95ee\u9898\u548c\u96be\u70b9\u4e4b\u4e00.\u76ee\u524d\u8fdb\u884c\u7684\u5f88\u591a\u8bcd\u4e49\u6d88\u6b67\u7814\u7a76\u591a\u91c7\u7528\u51e0\u4e2a\u591a\u4e49\u8bcd\u4f5c\u4e3a\u5b9e\u9a8c\u6d4b\u8bd5\u5bf9\u8c61,\u5728\u5b9e\u9645\u5e94\u7528\u65b9\u9762\u5b58\u5728\u7740\u5c40\u9650\u6027.\u672c\u6587\u5bf9\u5927\u89c4\u6a21\u771f\u5b9e\u6587\u672c\u8fdb\u884c\u4e86\u8bcd\u4e49\u6d88\u6b67\u7814\u7a76,\u91c7\u7528\u4e86\u57fa\u4e8e\u4f9d\u5b58\u5206\u6790\u6539\u8fdb\u8d1d\u53f6\u65af\u5206\u7c7b\u6a21\u578b\u7684\u6709\u6307\u5bfc\u8bcd\u4e49\u6d88\u6b67\u65b9\u6cd5.\u8be5\u6a21\u578b\u5145\u5206\u5229\u7528\u4f9d\u5b58\u53e5\u6cd5\u5206\u6790,\u4ece\u53e5\u5b50\u7684\u5185\u90e8\u7ed3\u6784,\u5bfb\u627e\u8bcd\u8bed\u4e4b\u95f4\u652f\u914d\u4e0e\u88ab\u652f\u914d\u7684\u5173\u7cfb,\u501f\u4ee5\u786e\u5b9a\u80fd\u591f\u5bf9\u8bcd\u8bed\u8bed\u4e49\u6784\u6210\u5185\u5728\u9650\u5236\u7684\u4e0a\u4e0b\u6587,\u6709\u6548\u5730\u514b\u670d\u4e86\u5355\u7eaf\u8d1d\u53f6\u65af\u5206\u7c7b\u5668\u4e2d\u65e0\u5173\u4e0a\u4e0b\u6587\u9020\u6210\u7684\u566a\u58f0\u5f71\u54cd.\u672c\u5b9e\u9a8c\u7684\u5f00\u653e\u6d4b\u8bd5\u6b63\u786e\u7387\u53ef\u4ee5\u8fbe\u523091.89%,\u5c01\u95ed\u5b9e\u9a8c\u6b63\u786e\u7387\u53ef\u8fbe99.4%,\u9a8c\u8bc1\u4e86\u6539\u8fdb\u6a21\u578b\u7684\u6709\u6548\u6027.", "num_citations": "23\n", "authors": ["1179"]}
{"title": "Dynamic Fusion Network for Multi-Domain End-to-end Task-Oriented Dialog\n", "abstract": " Recent studies have shown remarkable success in end-to-end task-oriented dialog system. However, most neural models rely on large training data, which are only available for a certain number of task domains, such as navigation and scheduling. This makes it difficult to scalable for a new domain with limited labeled data. However, there has been relatively little research on how to effectively use data from all domains to improve the performance of each domain and also unseen domains. To this end, we investigate methods that can make explicit use of domain knowledge and introduce a shared-private network to learn shared and specific knowledge. In addition, we propose a novel Dynamic Fusion Network (DF-Net) which automatically exploit the relevance between the target domain and each domain. Results show that our model outperforms existing methods on multi-domain dialogue, giving the state-of-the-art in the literature. Besides, with little training data, we show its transferability by outperforming prior best model by 13.9\\% on average.", "num_citations": "22\n", "authors": ["1179"]}
{"title": "Improving Entity Recommendation with Search Log and Multi-Task Learning.\n", "abstract": " Entity recommendation, providing search users with an improved experience by assisting them in finding related entities for a given query, has become an indispensable feature of today\u2019s Web search engine. Existing studies typically only consider the query issued at the current time step while ignoring the in-session preceding queries. Thus, they typically fail to handle the ambiguous queries such as \u201capple\u201d because the model could not understand which apple (company or fruit) is talked about. In this work, we believe that the in-session contexts convey valuable evidences that could facilitate the semantic modeling of queries, and take that into consideration for entity recommendation. Furthermore, in order to better model the semantics of queries, we learn the model in a multi-task learning setting where the query representation is shared across entity recommendation and contextaware ranking. We evaluate our approach using large-scale, real-world search logs of a widely used commercial Web search engine. The experimental results show that incorporating context information significantly improves entity recommendation, and learning the model in a multi-task learning setting could bring further improvements.", "num_citations": "22\n", "authors": ["1179"]}
{"title": "A comparison of chinese parsers for stanford dependencies\n", "abstract": " Stanford dependencies are widely used in natural language processing as a semanticallyoriented representation, commonly generated either by (i) converting the output of a constituent parser, or (ii) predicting dependencies directly. Previous comparisons of the two approaches for English suggest that starting from constituents yields higher accuracies. In this paper, we re-evaluate both methods for Chinese, using more accurate dependency parsers than in previous work. Our comparison of performance and efficiency across seven popular open source parsers (four constituent and three dependency) shows, by contrast, that recent higher-order graph-based techniques can be more accurate, though somewhat slower, than constituent parsers. We demonstrate also that n-way jackknifing is a useful technique for producing automatic (rather than gold) partof-speech tags to train Chinese dependency parsers. Finally, we analyze the relations produced by both kinds of parsing and suggest which specific parsers to use in practice.", "num_citations": "22\n", "authors": ["1179"]}
{"title": "Appraisal Expression Recognition Based on Syntactic Path [J]\n", "abstract": " Different from previous works such as hand-crafted patterns and rule based methods, this paper proposes a novel method that uses syntactic paths to automatically recognize the appraisal expressions. In detail, the syntactic paths are first automatically collected to describe the relationships between the polarity words and their corresponding targets. Next, an edit distance based syntactic path matching strategy is used to improve the performance of the exact syntactic path matching method. Experimental results on the camera and MP3 player domains show that (1) syntactic paths are helpful for appraisal expression recognition, and (2) edit distance based syntactic path matching method can further improve the performance of appraisal expression recognition.", "num_citations": "22\n", "authors": ["1179"]}
{"title": "Person name disambiguation of searching results using social network\n", "abstract": " BackgroundAbstract The person names are so ambiguous that the results for searching a person name are usually a mixture of pages about the namesakes. This paper presents a novel approach leveraging the fact that each namesake has a unique social community. Firstly, the social network of the person name to search is found and extended by employing the co-occurrence of person names in snippets returned by a search engine, then automatically clustered into different social communities by the algorithm combining spectral partition and modularity evaluation. Finally, the search results are clustered into different groups where each contains pages referring to the same individual. On the corpus of Chinese person names, experimental results show that the whole performance achieves high level and graph clustering algorithm benefits improving disambiguation effect from further dividing the connecting social\u00a0\u2026", "num_citations": "22\n", "authors": ["1179"]}
{"title": "An equivalent pseudoword solution to Chinese word sense disambiguation\n", "abstract": " This paper presents a new approach based on Equivalent Pseudowords (EPs) to tackle Word Sense Disambiguation (WSD) in Chinese language. EPs are particular artificial ambiguous words, which can be used to realize unsupervised WSD. A Bayesian classifier is implemented to test the efficacy of the EP solution on Senseval-3 Chinese test set. The performance is better than state-of-the-art results with an average F-measure of 0.80. The experiment verifies the value of EP for unsupervised WSD.", "num_citations": "22\n", "authors": ["1179"]}
{"title": "The first evaluation of Chinese human-computer dialogue technology\n", "abstract": " In this paper, we introduce the first evaluation of Chinese human-computer dialogue technology. We detail the evaluation scheme, tasks, metrics and how to collect and annotate the data for training, developing and test. The evaluation includes two tasks, namely user intent classification and online testing of task-oriented dialogue. To consider the different sources of the data for training and developing, the first task can also be divided into two sub tasks. Both the two tasks are coming from the real problems when using the applications developed by industry. The evaluation data is provided by the iFLYTEK Corporation. Meanwhile, in this paper, we publish the evaluation results to present the current performance of the participants in the two tasks of Chinese human-computer dialogue technology. Moreover, we analyze the existing problems of human-computer dialogue as well as the evaluation scheme itself.", "num_citations": "21\n", "authors": ["1179"]}
{"title": "A unified architecture for semantic role labeling and relation classification\n", "abstract": " This paper describes a unified neural architecture for identifying and classifying multi-typed semantic relations between words in a sentence. We investigate two typical and well-studied tasks: semantic role labeling (SRL) which identifies the relations between predicates and arguments, and relation classification (RC) which focuses on the relation between two entities or nominals. While mostly studied separately in prior work, we show that the two tasks can be effectively connected and modeled using a general architecture. Experiments on CoNLL-2009 benchmark datasets show that our SRL models significantly outperform state-of-the-art approaches. Our RC models also yield competitive performance with the best published records. Furthermore, we show that the two tasks can be trained jointly with multi-task learning, resulting in additive significant improvements for SRL.", "num_citations": "21\n", "authors": ["1179"]}
{"title": "A deep neural network for chinese zero pronoun resolution\n", "abstract": " Existing approaches for Chinese zero pronoun resolution overlook semantic information. This is because zero pronouns have no descriptive information, which results in difficulty in explicitly capturing their semantic similarities with antecedents. Moreover, when dealing with candidate antecedents, traditional systems simply take advantage of the local information of a single candidate antecedent while failing to consider the underlying information provided by the other candidates from a global perspective. To address these weaknesses, we propose a novel zero pronoun-specific neural network, which is capable of representing zero pronouns by utilizing the contextual information at the semantic level. In addition, when dealing with candidate antecedents, a two-level candidate encoder is employed to explicitly capture both the local and global information of candidate antecedents. We conduct experiments on the Chinese portion of the OntoNotes 5.0 corpus. Experimental results show that our approach substantially outperforms the state-of-the-art method in various experimental settings.", "num_citations": "21\n", "authors": ["1179"]}
{"title": "Learning semantic hierarchies: A continuous vector space approach\n", "abstract": " Semantic hierarchy construction aims to build structures of concepts linked by hypernym-hyponym (\u201cis-a\u201d) relations. A major challenge for this task is the automatic discovery of such relations. This paper proposes a novel and effective method for the construction of semantic hierarchies based on continuous vector representation of words, named word embeddings, which can be used to measure the semantic relationship between words. We identify whether a candidate word pair has hypernym-hyponym relation by using the word-embedding-based semantic projections between words and their hypernyms. Our result, an F-score of 73.74%, outperforms the state-of-the-art methods on a manually labeled test dataset. Moreover, combining our method with a previous manually built hierarchy extension method can further improve F-score to 80.29%.", "num_citations": "21\n", "authors": ["1179"]}
{"title": "Exploring key concept paraphrasing based on pivot language translation for question retrieval\n", "abstract": " Question retrieval in current community-based question answering (CQA) services does not, in general, work well for long and complex queries. One of the main difficulties lies in the word mismatch between queries and candidate questions. Existing solutions try to expand the queries at word level, but they usually fail to consider concept level enrichment. In this paper, we explore a pivot language translation based approach to derive the paraphrases of key concepts. We further propose a unified question retrieval model which integrates the keyconcepts and their paraphrases for the query question. Experimental results demonstrate that the paraphrase enhanced retrieval model significantly outperforms the state-of-the-art models in question retrieval.", "num_citations": "21\n", "authors": ["1179"]}
{"title": "Encoding World Knowledge in the Evaluation of Local Coherence\n", "abstract": " Previous work on text coherence was primarily based on matching multiple mentions of the same entity in different parts of the text; therefore, it misses the contribution from semantically related but not necessarily coreferential entities (eg, Gates and Microsoft). In this paper, we capture such semantic relatedness by leveraging world knowledge (eg, Gates is the person who created Microsoft), and use two existing evaluation frameworks. First, in the unsupervised framework, we introduce semantic relatedness as an enrichment to the original graph-based model of Guinaudeau and Strube (2013). In addition, we incorporate semantic relatedness as additional features into the popular entity-based model of Barzilay and Lapata (2008). Across both frameworks, our enriched model with semantic relatedness outperforms the original methods, especially on short documents.", "num_citations": "21\n", "authors": ["1179"]}
{"title": "Dependency parsing based on dynamic local optimization\n", "abstract": " This paper presents a deterministic parsing algorithm for projective dependency grammar. In a bottom-up way the algorithm finds the local optimum dynamically. A constraint procedure is made to use more structure information. The algorithm parses sentences in linear time and labeling is integrated with the parsing. This parser achieves 63.29% labeled attachment score on the average in CoNLL-X Shared Task.", "num_citations": "21\n", "authors": ["1179"]}
{"title": "PENS: A machine-aided English writing system for Chinese users\n", "abstract": " Writing English is a big barrier for most Chinese users. To build a computer-aided system that helps Chinese users not only on spelling checking and grammar checking but also on writing in the way of native-English is a challenging task. Although machine translation is widely used for this purpose, how to find an efficient way in which human collaborates with computers remains an open issue. In this paper, based on the comprehensive study of Chinese users requirements, we propose an approach to machine aided English writing system, which consists of two components: 1) a statistical approach to word spelling help, and 2) an information retrieval based approach to intelligent recommendation by providing suggestive example sentences. Both components work together in a unified way, and highly improve the productivity of English writing. We also developed a pilot system, namely PENS (Perfect ENglish System). Preliminary experiments show very promising results.", "num_citations": "21\n", "authors": ["1179"]}
{"title": "Molweni: A Challenge Multiparty Dialogues-based Machine Reading Comprehension Dataset with Discourse Structure\n", "abstract": " Research into the area of multiparty dialog has grown considerably over recent years. We present the Molweni dataset, a machine reading comprehension (MRC) dataset with discourse structure built over multiparty dialog. Molweni's source samples from the Ubuntu Chat Corpus, including 10,000 dialogs comprising 88,303 utterances. We annotate 30,066 questions on this corpus, including both answerable and unanswerable questions. Molweni also uniquely contributes discourse dependency annotations in a modified Segmented Discourse Representation Theory (SDRT; Asher et al., 2016) style for all of its multiparty dialogs, contributing large-scale (78,245 annotated discourse relations) data to bear on the task of multiparty dialog discourse parsing. Our experiments show that Molweni is a challenging dataset for current MRC models: BERT-wwm, a current, strong SQuAD 2.0 performer, achieves only 67.7% F1 on Molweni's questions, a 20+% significant drop as compared against its SQuAD 2.0 performance.", "num_citations": "20\n", "authors": ["1179"]}
{"title": "A universal framework for inductive transfer parsing across multi-typed treebanks\n", "abstract": " Various treebanks have been released for dependency parsing. Despite that treebanks may belong to different languages or have different annotation schemes, they contain common syntactic knowledge that is potential to benefit each other. This paper presents a universal framework for transfer parsing across multi-typed treebanks with deep multi-task learning. We consider two kinds of treebanks as source: the multilingual universal treebanks and the monolingual heterogeneous treebanks. Knowledge across the source and target treebanks are effectively transferred through multi-level parameter sharing. Experiments on several benchmark datasets in various languages demonstrate that our approach can make effective use of arbitrary source treebanks to improve target parsing models.", "num_citations": "20\n", "authors": ["1179"]}
{"title": "A topic clustering approach to finding similar questions from large question and answer archives\n", "abstract": " With the blooming of Web 2.0, Community Question Answering (CQA) services such as Yahoo! Answers (http://answers.yahoo.com), WikiAnswer (http://wiki.answers.com), and Baidu Zhidao (http://zhidao.baidu.com), etc., have emerged as alternatives for knowledge and information acquisition. Over time, a large number of question and answer (Q&A) pairs with high quality devoted by human intelligence have been accumulated as a comprehensive knowledge base. Unlike the search engines, which return long lists of results, searching in the CQA services can obtain the correct answers to the question queries by automatically finding similar questions that have already been answered by other users. Hence, it greatly improves the efficiency of the online information retrieval. However, given a question query, finding the similar and well-answered questions is a non-trivial task. The main challenge is the word mismatch between question query (query) and candidate question for retrieval (question). To investigate this problem, in this study, we capture the word semantic similarity between query and question by introducing the topic modeling approach. We then propose an unsupervised machine-learning approach to finding similar questions on CQA Q&A archives. The experimental results show that our proposed approach significantly outperforms the state-of-the-art methods.", "num_citations": "20\n", "authors": ["1179"]}
{"title": "\u4e00\u79cd\u57fa\u4e8e\u4e3b\u9898\u7684\u6587\u672c\u805a\u7c7b\u65b9\u6cd5\n", "abstract": " \u73b0\u6709\u7684\u6587\u672c\u805a\u7c7b\u65b9\u6cd5\u96be\u4ee5\u6b63\u786e\u8bc6\u522b\u548c\u63cf\u8ff0\u6587\u672c\u7684\u4e3b\u9898, \u4ece\u800c\u96be\u4ee5\u5b9e\u73b0\u6309\u7167\u4e3b\u9898\u5bf9\u6587\u672c\u8fdb\u884c\u805a\u7c7b. \u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u57fa\u4e8e\u4e3b\u9898\u7684\u6587\u672c\u805a\u7c7b\u65b9\u6cd5: L FIC. \u8be5\u65b9\u6cd5\u80fd\u591f\u51c6\u786e\u8bc6\u522b\u6587\u672c\u4e3b\u9898\u5e76\u6839\u636e\u6587\u672c\u7684\u4e3b\u9898\u5bf9\u5176\u8fdb\u884c\u805a\u7c7b. \u672c\u65b9\u6cd5\u5b9a\u4e49\u548c\u62bd\u53d6\u4e86 \u201c\u4e3b\u9898\u5143\u7d20\u201d, \u5e76\u5229\u7528\u5176\u8fdb\u884c\u57fa\u672c\u7c7b\u7d22\u5f15. \u540c\u65f6\u8fd8\u6574\u5408\u5229\u7528\u4e86\u8bed\u8a00\u5b66\u7279\u5f81. \u5b9e\u9a8c\u8868\u660e, L FIC \u7684\u805a\u7c7b\u51c6\u786e\u7387\u8fbe\u5230 94. 66%, \u4f18\u4e8e\u51e0\u79cd\u4f20\u7edf\u805a\u7c7b\u65b9\u6cd5.", "num_citations": "20\n", "authors": ["1179"]}
{"title": "\u9762\u5411\u53d8\u5f02\u77ed\u6587\u672c\u7684\u5feb\u901f\u805a\u7c7b\u7b97\u6cd5\n", "abstract": " \u672c\u6587\u4e3b\u8981\u9488\u5bf9\u8fd1\u4e9b\u5e74\u6765\u5927\u91cf\u51fa\u73b0\u5728\u804a\u5929\u8bed\u8a00\u4e2d\u548c\u624b\u673a\u77ed\u4fe1\u4e2d\u7684\u77ed\u6587\u672c, \u63d0\u51fa\u4e86\u4e00\u79cd\u5feb\u901f\u6709\u6548\u7684\u805a\u7c7b\u7b97\u6cd5. \u8fd9\u4e9b\u77ed\u6587\u672c\u7531\u4e8e\u5177\u6709\u4e0d\u89c4\u8303\u6027\u548c\u5927\u91cf\u76f8\u4f3c\u6027\u7b49\u7279\u70b9, \u6211\u4eec\u79f0\u5176\u4e3a\u53d8\u5f02\u77ed\u6587\u672c. \u672c\u6587\u5728\u539f\u6709\u7684\u7f51\u9875\u53bb\u91cd\u7b97\u6cd5 [1~ 3] \u7684\u57fa\u7840\u4e0a, \u6839\u636e\u53d8\u5f02\u77ed\u6587\u672c\u7684\u7279\u70b9, \u91c7\u53d6\u4e86\u7279\u5b9a\u7684\u7279\u5f81\u4e32\u62bd\u53d6\u65b9\u6cd5, \u5e76\u878d\u5408\u4e86\u538b\u7f29\u7f16\u7801\u7684\u601d\u60f3, \u4ece\u800c\u52a0\u5feb\u4e86\u5904\u7406\u901f\u5ea6. \u5b9e\u9a8c\u8868\u660e, \u57fa\u4e8e\u8be5\u7b97\u6cd5\u7684\u805a\u7c7b\u7cfb\u7edf\u5bf9\u4e8e\u5927\u91cf\u7684\u53d8\u5f02\u77ed\u6587\u672c\u5904\u7406\u901f\u5ea6\u53ef\u4ee5\u8fbe\u5230\u6bcf\u5c0f\u65f6\u767e\u4e07\u7ea7\u4ee5\u4e0a, \u5e76\u4e14\u6709\u6bd4\u8f83\u9ad8\u7684\u51c6\u786e\u7387.", "num_citations": "20\n", "authors": ["1179"]}
{"title": "\u81ea\u7136\u98ce\u683c\u8a00\u8bed\u7684\u6c49\u8bed\u53e5\u91cd\u97f3\u81ea\u52a8\u5224\u522b\u7814\u7a76\n", "abstract": " \u91cd\u97f3\u662f\u8bed\u97f3\u5408\u6210\u4e2d\u97f5\u5f8b\u5904\u7406\u7684\u4e00\u4e2a\u91cd\u8981\u53c2\u6570.\u672c\u6587\u5206\u6790\u4e86\u8f7b\u58f0\u548c\u91cd\u8bfb\u97f3\u8282\u540c\u6b63\u5e38\u91cd\u97f3\u5728\u5404\u58f0\u5b66\u53c2\u6570\u4e0a\u7684\u5dee\u5f02,\u5305\u62ec\u57fa\u9891,\u97f3\u8282\u65f6\u957f,\u5f3a\u5ea6,\u505c\u987f\u957f\u5ea6\u7b49,\u8fd8\u7279\u522b\u8003\u5bdf\u4e86\u65f6\u957f\u540c\u57fa\u9891\u53c2\u6570\u4e4b\u95f4\u7684\u5173\u7cfb,\u4ee5\u53ca\u4e0a\u58f0\u97f3\u8c03\u540c\u57fa\u9891\u7684\u5173\u7cfb.\u5efa\u7acb\u4e86\u57fa\u4e8e\u4eba\u5de5\u795e\u7ecf\u7f51\u7edc\u7684\u4e09\u79cd\u91cd\u97f3\u9884\u6d4b\u6a21\u578b,\u5373\u58f0\u5b66\u9884\u6d4b\u6a21\u578b,\u8bed\u8a00\u5b66\u9884\u6d4b\u6a21\u578b\u548c\u6df7\u5408\u9884\u6d4b\u6a21\u578b,\u5bf9\u6c49\u8bed\u53e5\u91cd\u97f3(\u5305\u62ec\u8f7b\u58f0,\u6b63\u5e38\u91cd\u97f3,\u91cd\u8bfb)\u8fdb\u884c\u4e86\u81ea\u52a8\u5224\u522b,\u7ed3\u679c\u663e\u793a\u6df7\u5408\u6a21\u578b\u8981\u4f18\u4e8e\u53e6\u5916\u4e24\u79cd\u6a21\u578b.\u6b64\u5916,\u672c\u6587\u8fd8\u6839\u636e\u91cd\u97f3\u6807\u6ce8\u7684\u591a\u6837\u6027\u73b0\u8c61\u8bbe\u8ba1\u4e86\u652f\u6301\u7387\u7684\u8bc4\u4ef7\u65b9\u6cd5.", "num_citations": "20\n", "authors": ["1179"]}
{"title": "The research progress of statistical word sense disambiguation\n", "abstract": " Abstract: Many kinds of statistical word sense disambiguation (WSD) methods and technologies in home and abroad are analyzed, and lots of literatures are referred to in this paper. Key questions of statistical WSD research are pointed out, and the research progress is illustrated around them. In the final section the problems and future research emphases in WSD are explored in this paper.", "num_citations": "20\n", "authors": ["1179"]}
{"title": "\u4e2d\u6587\u81ea\u52a8\u6587\u6458\u539f\u7406\u4e0e\u65b9\u6cd5\u63a2\u7d22\n", "abstract": " \u6458\u8981 \u672c\u6587\u9996\u5148\u4ecb\u7ecd\u4e86\u81ea\u52a8\u6587\u6458\u7684\u7814\u7a76\u60c5\u51b5\u53ca\u5b58\u5728\u95ee\u9898, \u7136\u540e\u7ed9\u51fa\u4e86\u8ba1\u7b97\u673a\u81ea\u52a8\u6587\u6458\u7684\u4e00\u822c\u6a21\u578b, \u6700\u540e\u4ecb\u7ecd\u4e86\u6211\u4eec\u6240\u7814\u7a76\u7684\u4e24\u79cd\u81ea\u52a8\u6587\u6458\u7684\u539f\u7406\u548c\u65b9\u6cd5, \u53ca\u5176\u5b9e\u9a8c\u7ed3\u679c.", "num_citations": "20\n", "authors": ["1179"]}
{"title": "Keywords extraction with deep neural network model\n", "abstract": " Keywords can express the main content of an article or a sentence. Keywords extraction is a critical issue in many Natural Language Processing (NLP) applications and can improve the performance of many NLP systems. The traditional methods of keywords extraction are based on machine learning or graph model. The performance of these methods is influenced by the feature selection and the manually defined rules. In recent years, with the emergence of deep learning technology, learning features automatically with the deep learning algorithm can improve the performance of many tasks. In this paper, we propose a deep neural network model for the task of keywords extraction. We make two extensions on the basis of traditional LSTM model. First, to better utilize both the historic and following contextual information of the given target word, we propose a target center-based LSTM model (TC-LSTM), which\u00a0\u2026", "num_citations": "19\n", "authors": ["1179"]}
{"title": "Improve statistical machine translation with context-sensitive bilingual semantic embedding model\n", "abstract": " We investigate how to improve bilingual embedding which has been successfully used as a feature in phrase-based statistical machine translation (SMT). Despite bilingual embedding\u2019s success, the contextual information, which is of critical importance to translation quality, was ignored in previous work. To employ the contextual information, we propose a simple and memory-efficient model for learning bilingual embedding, taking both the source phrase and context around the phrase into account. Bilingual translation scores generated from our proposed bilingual embedding model are used as features in our SMT system. Experimental results show that the proposed method achieves significant improvements on large-scale Chinese-English translation task.", "num_citations": "19\n", "authors": ["1179"]}
{"title": "Computing affect in metaphors\n", "abstract": " This article describes a novel approach to automated determination of affect associated with metaphorical language. Affect in language is understood to mean the attitude toward a topic that a writer attempts to convey to the reader by using a particular metaphor. This affect, which we will classify as positive, negative or neutral with various degrees of intensity, may arise from the target of the metaphor, from the choice of words used to describe it, or from other elements in its immediate linguistic context. We attempt to capture all these contributing elements in an Affect Calculus and demonstrate experimentally that the resulting method can accurately approximate human judgment. The work reported here is part of a larger effort to develop a highly accurate system for identifying, classifying, and comparing metaphors occurring in large volumes of text across four different languages: English, Spanish, Russian, and Farsi.", "num_citations": "19\n", "authors": ["1179"]}
{"title": "Investigating the portability of corpus-derived cue phrases for dialogue act classification\n", "abstract": " We present recent work in the area of Cross-Domain Dialogue Act tagging. Our experiments investigate the use of a simple dialogue act classifier based on purely intra-utterance features-principally involving word n-gram cue phrases. We apply automatically extracted cues from one corpus to a new annotated data set, to determine the portability and generality of the cues we learn. We show that our automatically acquired cues are general enough to serve as a cross-domain classification mechanism.", "num_citations": "19\n", "authors": ["1179"]}
{"title": "Chinese dependency parsing model based on lexical governing degree.\n", "abstract": " Use of structural information and lexicalization are two of the main challenges facing syntactic analysis, and they are investigated in this paper. First, the probabilities of lexical dependencies are obtained by training a large-scale dependency treebank and used to build the lexical model. Second, the governing degree of words is introduced to utilize the structure information. The lexical method overcomes the weakness of POS dependencies in the past work; meanwhile the governing degree of words is helpful to distinguish the syntactic structures so some ill-formed structures are avoided. Finally, the paper shows a good experimental result of around 74% accuracy on the test set that consists of 4000 sentences.", "num_citations": "19\n", "authors": ["1179"]}
{"title": "Chinese word segmentation with multiple postprocessors in HIT-IRLab\n", "abstract": " This paper presents the results of the system IRLAS1 from HIT-IRLab in the Second International Chinese Word Segmentation Bakeoff. IRLAS consists of several basic components and multiple postprocessors. The basic components include basic segmentation, factoid recognition, and named entity recognition. These components maintain a segment graph together. The postprocessors include merging of adjoining words, morphologically derived word recognition, and new word identification. These postprocessors do some modifications on the best word sequence which is selected from the segment graph. Our system participated in the open and closed tracks of PK corpus and ranked# 4 and# 3 respectively. Our scores were very close to the highest level. It proves that our system has reached the current state of the art.", "num_citations": "19\n", "authors": ["1179"]}
{"title": "Survey of Multi-document Summarization [J]\n", "abstract": " multi-document summarization is a technology of natural languages processing, which extract important information from multiple texts about same topic according to ratio of compression. Multi-document summarization becomes new research spot with increasing of information in internet. In this paper, the background of multi-document summarization is introduced, the relationship with other technologies of natural language processing and the state of arts is analyzed, the key technologies and the methods of research of multi-document summarization are proposed. Finally, the feature of multi-document summarization is forecasted.", "num_citations": "19\n", "authors": ["1179"]}
{"title": "Combining neural networks and statistics for chinese word sense disambiguation\n", "abstract": " The input of network is the key problem for Chinese Word sense disambiguation utilizing the Neural Network. This paper presents an input model of Neural Network that calculates the Mutual Information between contextual words and ambiguous word by using statistical method and taking the contextual words to certain number beside the ambiguous word according to (-M,+ N). The experiment adopts triple-layer BP Neural Network model and proves how the size of training set and the value of M and N affect the performance of Neural Network model. The experimental objects are six pseudowords owning three word-senses constructed according to certain principles. Tested accuracy of our approach on a close-corpus reaches 90.31%,, and 89.62% on a open-corpus. The experiment proves that the Neural Network model has good performance on Word sense disambiguation.", "num_citations": "19\n", "authors": ["1179"]}
{"title": "\u5927\u89c4\u6a21\u7f51\u9875\u5feb\u901f\u53bb\u91cd\u7b97\u6cd5\n", "abstract": " \u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u7279\u5f81\u7801\u6280\u672f\u7684\u76f8\u540c\u5185\u5bb9\u7f51\u9875\u7684\u53bb\u9664\u5408\u5e76\u7b97\u6cd5. \u7279\u5f81\u7801\u901a\u8fc7\u9ad8\u6548\u7684 B-Tree \u6765\u7d22\u5f15, \u4f7f\u6574\u4e2a\u7cfb\u7edf\u5177\u6709\u6781\u9ad8\u7684\u5904\u7406\u6548\u7387. \u4ece\u800c\u514b\u670d\u4e86\u91c7\u7528\u4e00\u822c\u805a\u7c7b\u65b9\u6cd5\u6240\u5177\u6709\u7684\u5904\u7406\u901f\u5ea6\u6162, \u5224\u65ad\u51c6\u786e\u7387\u4f4e\u7684\u7f3a\u70b9. \u901a\u8fc7\u5bf9\u5927\u91cf\u7f51\u9875\u7684\u6d4b\u8bd5\u4e0e\u5206\u6790, \u8be5\u7b97\u6cd5\u80fd\u5b9e\u73b0\u5f88\u9ad8\u7684\u5224\u65ad\u6b63\u786e\u7387.", "num_citations": "19\n", "authors": ["1179"]}
{"title": "\u57fa\u4e8e\u7bc7\u7ae0\u591a\u7ea7\u4f9d\u5b58\u7ed3\u6784\u7684\u81ea\u52a8\u6587\u6458\u7814\u7a76\n", "abstract": " \u81ea\u52a8\u6587\u6458\u662f\u81ea\u7136\u8bed\u8a00\u5904\u7406\u9886\u57df\u7684\u4e00\u9879\u91cd\u8981\u7684\u7814\u7a76\u5185\u5bb9,\u5176\u7814\u7a76\u76ee\u7684\u662f\u63a2\u7d22\u4eba\u7c7b\u4ece\u81ea\u7136\u8bed\u8a00\u7bc7\u7ae0\u4e2d\u83b7\u5f97\u53d6\u4fe1\u606f,\u63d0\u70bc\u4fe1\u606f\u7684\u601d\u7ef4\u673a\u5236,\u5e76\u5728\u6b64\u57fa\u7840\u4e0a\u5f00\u53d1\u51fa\u80fd\u591f\u81ea\u52a8\u7f16\u5199\u6587\u732e\u6458\u8981\u7684\u8f6f\u4ef6,\u4ece\u9762\u63d0\u9ad8\u4fe1\u606f\u68c0\u7d22,\u4f20\u64ad\u7684\u6548\u7387.", "num_citations": "19\n", "authors": ["1179"]}
{"title": "Negation scope detection with recurrent neural networks models in review texts\n", "abstract": " Identifying negation scopes in a text is an important subtask of information extraction that can benefit other natural language processing tasks, like relation extraction, question answering and sentiment analysis, and serves the task of social media text understanding. The task of negation scope detection can be regarded as a token-level sequence labelling problem. In this paper, we propose different models based on recurrent neural networks (RNNs) and word embedding that can be successfully applied to such tasks without any task-specific feature engineering effort. Our experimental results show that RNNs, without using any hand-crafted features, outperform feature-rich CRF-based model.", "num_citations": "18\n", "authors": ["1179"]}
{"title": "Collocation polarity disambiguation using web-based pseudo contexts\n", "abstract": " This paper focuses on the task of collocation polarity disambiguation. The collocation refers to a binary tuple of a polarity word and a target (such as (long, battery life) or (long, startup)), in which the sentiment orientation of the polarity word (\u201clong\u201d) changes along with different targets (\u201cbattery life\u201d or \u201cstartup\u201d). To disambiguate a collocation\u2019s polarity, previous work always turned to investigate the polarities of its surrounding contexts, and then assigned the majority polarity to the collocation. However, these contexts are limited, thus the resulting polarity is insufficient to be reliable. We therefore propose an unsupervised three-component framework to expand some pseudo contexts from web, to help disambiguate a collocation\u2019s polarity. Without using any additional labeled data, experiments show that our method is effective.", "num_citations": "18\n", "authors": ["1179"]}
{"title": "Hit: Web based scoring method for english lexical substitution\n", "abstract": " This paper describes the HIT system and its participation in SemEval-2007 English Lexical Substitution Task. Two main steps are included in our method: candidate substitute extraction and candidate scoring. In the first step, candidate substitutes for each target word in a given sentence are extracted from WordNet. In the second step, the extracted candidates are scored and ranked using a web-based scoring method. The substitute ranked first is selected as the best substitute. For the multiword subtask, a simple WordNet-based approach is employed.", "num_citations": "18\n", "authors": ["1179"]}
{"title": "\u57fa\u4e8e\u957f\u5ea6\u548c\u4f4d\u7f6e\u4fe1\u606f\u7684\u53cc\u8bed\u53e5\u5b50\u5bf9\u9f50\u65b9\u6cd5\n", "abstract": " \u63d0\u51fa\u4e86\u4e00\u79cd\u5229\u7528\u53e5\u5b50\u957f\u5ea6\u548c\u4f4d\u7f6e\u4fe1\u606f\u7684\u53cc\u8bed\u53e5\u5b50\u5bf9\u9f50\u65b9\u6cd5, \u8be5\u65b9\u6cd5\u7684\u6839\u672c\u601d\u60f3\u662f: \u4e00\u5b9a\u957f\u5ea6\u7684\u53e5\u5bf9\u5728\u53cc\u8bed\u6587\u672c\u4e2d\u7684\u4f4d\u7f6e\u5206\u5e03\u662f\u76f8\u4f3c\u7684, \u5229\u7528 (1\u2236 1) \u578b\u7684\u53e5\u73e0\u4ee3\u66ff\u9ad8\u9891\u8bcd\u4f5c\u4e3a\u5019\u9009\u951a\u70b9, \u4f7f\u8fd9\u79cd\u65b9\u6cd5\u5177\u6709\u901a\u7528\u6027. \u5229\u7528\u591a\u79cd\u5f62\u5f0f\u7684\u6d4b\u8bd5\u6570\u636e\u8fdb\u884c\u7684\u8bc4\u4ef7\u7ed3\u679c\u663e\u793a, \u8fd9\u79cd\u65b9\u6cd5\u6709\u7740\u826f\u597d\u7684\u5065\u58ee\u6027\u548c\u8bed\u8a00\u65e0\u5173\u6027, \u6709\u6548\u5730\u89e3\u51b3\u4e86\u53cc\u8bed\u771f\u5b9e\u6587\u672c\u7684\u53e5\u5b50\u5bf9\u9f50\u95ee\u9898.", "num_citations": "18\n", "authors": ["1179"]}
{"title": "Neural multitask learning for simile recognition\n", "abstract": " Simile is a special type of metaphor, where comparators such as like and as are used to compare two objects. Simile recognition is to recognize simile sentences and extract simile components, ie, the tenor and the vehicle. This paper presents a study of simile recognition in Chinese. We construct an annotated corpus for this research, which consists of 11.3 k sentences that contain a comparator. We propose a neural network framework for jointly optimizing three tasks: simile sentence classification, simile component extraction and language modeling. The experimental results show that the neural network based approaches can outperform all rule-based and feature-based baselines. Both simile sentence classification and simile component extraction can benefit from multitask learning. The former can be solved very well, while the latter is more difficult.", "num_citations": "17\n", "authors": ["1179"]}
{"title": "Discourse mode identification in essays\n", "abstract": " Discourse modes play an important role in writing composition and evaluation. This paper presents a study on the manual and automatic identification of narration, exposition, description, argument and emotion expressing sentences in narrative essays. We annotate a corpus to study the characteristics of discourse modes and describe a neural sequence labeling model for identification. Evaluation results show that discourse modes can be identified automatically with an average F1-score of 0.7. We further demonstrate that discourse modes can be used as features that improve automatic essay scoring (AES). The impacts of discourse modes for AES are also discussed.", "num_citations": "17\n", "authors": ["1179"]}
{"title": "\u5fae\u535a\u4fe1\u606f\u4f20\u64ad\u9884\u6d4b\u7814\u7a76\u7efc\u8ff0\n", "abstract": " \u5fae\u535a\u5df2\u7ecf\u9010\u6e10\u6210\u4e3a\u4eba\u4eec\u83b7\u53d6\u4fe1\u606f, \u5206\u4eab\u4fe1\u606f\u7684\u91cd\u8981\u793e\u4f1a\u5a92\u4f53, \u6df1\u523b\u5f71\u54cd\u5e76\u6539\u53d8\u4e86\u4fe1\u606f\u7684\u4f20\u64ad\u65b9\u5f0f. \u9488\u5bf9\u5fae\u535a\u4fe1\u606f\u4f20\u64ad\u9884\u6d4b\u95ee\u9898\u5c55\u5f00\u7efc\u8ff0. \u8be5\u7814\u7a76\u5bf9\u8206\u60c5\u76d1\u63a7, \u5fae\u535a\u8425\u9500, \u4e2a\u6027\u5316\u63a8\u8350\u5177\u6709\u91cd\u8981\u610f\u4e49. \u9996\u5148\u6982\u8ff0\u5fae\u535a\u4fe1\u606f\u4f20\u64ad\u8fc7\u7a0b, \u901a\u8fc7\u4ecb\u7ecd\u5fae\u535a\u4fe1\u606f\u4f20\u64ad\u7684\u5b9a\u6027\u7814\u7a76\u5de5\u4f5c, \u63ed\u793a\u5fae\u535a\u4fe1\u606f\u4f20\u64ad\u7684\u7279\u70b9; \u63a5\u7740, \u4ece\u4ee5\u4fe1\u606f\u4e3a\u4e2d\u5fc3, \u4ee5\u7528\u6237\u4e3a\u4e2d\u5fc3\u4ee5\u53ca\u4ee5\u4fe1\u606f\u548c\u7528\u6237\u4e3a\u4e2d\u5fc3\u8fd9 3 \u4e2a\u89d2\u5ea6\u4ecb\u7ecd\u5fae\u535a\u4fe1\u606f\u4f20\u64ad\u9884\u6d4b\u76f8\u5173\u7814\u7a76\u5de5\u4f5c, \u5bf9\u5e94\u7684\u4e3b\u8981\u7814\u7a76\u4efb\u52a1\u5206\u522b\u662f\u5fae\u535a\u4fe1\u606f\u6d41\u884c\u5ea6\u9884\u6d4b, \u7528\u6237\u4f20\u64ad\u884c\u4e3a\u9884\u6d4b\u548c\u5fae\u535a\u4fe1\u606f\u4f20\u64ad\u8def\u5f84\u9884\u6d4b; \u7ee7\u800c\u4ecb\u7ecd\u53ef\u7528\u4e8e\u5fae\u535a\u4fe1\u606f\u4f20\u64ad\u9884\u6d4b\u7814\u7a76\u7684\u516c\u5f00\u6570\u636e\u8d44\u6e90; \u6700\u540e, \u5c55\u671b\u5fae\u535a\u4fe1\u606f\u4f20\u64ad\u9884\u6d4b\u7814\u7a76\u7684\u95ee\u9898\u4e0e\u6311\u6218.", "num_citations": "17\n", "authors": ["1179"]}
{"title": "\u65e0\u6307\u5bfc\u7684\u4e2d\u6587\u5f00\u653e\u5f0f\u5b9e\u4f53\u5173\u7cfb\u62bd\u53d6\n", "abstract": " \u4f20\u7edf\u7684\u5b9e\u4f53\u5173\u7cfb\u62bd\u53d6\u9700\u8981\u9884\u5148\u5b9a\u4e49\u5173\u7cfb\u7c7b\u578b\u4f53\u7cfb, \u7136\u800c\u5b9a\u4e49\u4e00\u4e2a\u5168\u9762\u7684\u5b9e\u4f53\u5173\u7cfb\u7c7b\u578b\u4f53\u7cfb\u662f\u5f88\u56f0\u96be\u7684. \u5f00\u653e\u5f0f\u5b9e\u4f53\u5173\u7cfb\u62bd\u53d6\u6280\u672f\u89e3\u51b3\u4e86\u9884\u5148\u5b9a\u4e49\u5173\u7cfb\u7c7b\u578b\u4f53\u7cfb\u7684\u95ee\u9898, \u4f46\u662f\u5728\u4e2d\u6587\u4e0a\u7684\u7814\u7a76\u8fd8\u6bd4\u8f83\u5c11. \u63d0\u51fa\u9762\u5411\u5927\u89c4\u6a21\u7f51\u7edc\u6587\u672c\u7684\u65e0\u6307\u5bfc\u5f00\u653e\u5f0f\u4e2d\u6587\u5b9e\u4f53\u5173\u7cfb\u62bd\u53d6\u65b9\u6cd5, \u9996\u5148\u4f7f\u7528\u5b9e\u4f53\u4e4b\u95f4\u7684\u8ddd\u79bb\u9650\u5236\u548c\u5173\u7cfb\u6307\u793a\u8bcd\u7684\u4f4d\u7f6e\u9650\u5236\u83b7\u53d6\u5019\u9009\u5173\u7cfb\u4e09\u5143\u7ec4; \u7136\u540e\u91c7\u7528\u5168\u5c40\u6392\u5e8f\u548c\u7c7b\u578b\u6392\u5e8f\u7684\u65b9\u6cd5\u6765\u6316\u6398\u5173\u7cfb\u6307\u793a\u8bcd; \u6700\u540e\u4f7f\u7528\u5173\u7cfb\u6307\u793a\u8bcd\u548c\u53e5\u5f0f\u89c4\u5219\u5bf9\u5173\u7cfb\u4e09\u5143\u7ec4\u8fdb\u884c\u8fc7\u6ee4. \u5728\u83b7\u53d6\u5927\u91cf\u5173\u7cfb\u4e09\u5143\u7ec4\u7684\u540c\u65f6, \u8fd8\u4fdd\u8bc1\u4e86 80% \u4ee5\u4e0a\u7684\u5fae\u89c2\u5e73\u5747\u51c6\u786e\u7387.", "num_citations": "17\n", "authors": ["1179"]}
{"title": "Bootstrapping events and relations from text\n", "abstract": " In this paper, we describe a new approach to semi-supervised adaptive learning of event extraction from text. Given a set of examples and an un-annotated text corpus, the BEAR system (Bootstrapping Events And Relations) will automatically learn how to recognize and understand descriptions of complex semantic relationships in text, such as events involving multiple entities and their roles. For example, given a series of descriptions of bombing and shooting incidents (eg, in newswire) the system will learn to extract, with a high degree of accuracy, other attack-type events mentioned elsewhere in text, irrespective of the form of description. A series of evaluations using the ACE data and event set show a significant performance improvement over our baseline system.", "num_citations": "17\n", "authors": ["1179"]}
{"title": "\u57fa\u4e8e SVMTool \u7684\u4e2d\u6587\u8bcd\u6027\u6807\u6ce8\n", "abstract": " SVMTool \u662f\u5efa\u7acb\u5728\u652f\u6301\u5411\u91cf\u673a (SVM) \u539f\u7406\u4e0a\u7684\u5e8f\u5217\u6807\u6ce8\u5de5\u5177, \u5177\u6709\u7b80\u5355, \u7075\u6d3b, \u9ad8\u6548\u7684\u7279\u70b9, \u53ef\u4ee5\u878d\u5165\u5927\u91cf\u7684\u8bed\u8a00\u7279\u5f81. \u8be5\u6587\u5c06 SVMTool \u5e94\u7528\u4e8e\u4e2d\u6587\u8bcd\u6027\u6807\u6ce8\u4efb\u52a1, \u5c06\u57fa\u4e8e\u9690\u9a6c\u5c14\u79d1\u592b\u6a21\u578b\u7684\u57fa\u7ebf\u7cfb\u7edf\u51c6\u786e\u7387\u63d0\u5347\u4e86 2.07%. \u9488\u5bf9\u672a\u767b\u5f55\u8bcd\u51c6\u786e\u7387\u4e0d\u9ad8\u7684\u95ee\u9898, \u8be5\u6587\u52a0\u5165\u4e86\u4e2d\u6587\u5b57, \u8bcd\u7684\u7279\u5f81, \u5305\u62ec\u6784\u6210\u6c49\u5b57\u7684\u90e8\u9996\u7279\u5f81\u548c\u8bcd\u91cd\u53e0\u7279\u5f81, \u5e76\u4ece\u7406\u8bba\u4e0a\u5206\u6790\u4e86\u8fd9\u4e24\u4e2a\u7279\u5f81\u7684\u53ef\u884c\u6027, \u5b9e\u9a8c\u663e\u793a\u52a0\u5165\u8fd9\u4e9b\u7279\u5f81\u540e, \u672a\u767b\u5f55\u8bcd\u6807\u6ce8\u7684\u51c6\u786e\u7387\u63d0\u5347\u4e86 1.16%. \u5e73\u5747\u9500\u8bef\u7387\u4e0b\u964d\u4e86 7.40%.", "num_citations": "17\n", "authors": ["1179"]}
{"title": "Using a hybrid convolution tree kernel for semantic role labeling\n", "abstract": " As a kind of Shallow Semantic Parsing, Semantic Role Labeling (SRL) is gaining more attention as it benefits a wide range of natural language processing applications. Given a sentence, the task of SRL is to recognize semantic arguments (roles) for each predicate (target verb or noun). Feature-based methods have achieved much success in SRL and are regarded as the state-of-the-art methods for SRL. However, these methods are less effective in modeling structured features. As an extension of feature-based methods, kernel-based methods are able to capture structured features more efficiently in a much higher dimension. Application of kernel methods to SRL has been achieved by selecting the tree portion of a predicate and one of its arguments as feature space, which is named as predicate-argument feature (PAF) kernel. The PAF kernel captures the syntactic tree structure features using convolution tree\u00a0\u2026", "num_citations": "17\n", "authors": ["1179"]}
{"title": "Automated generalization of phrasal paraphrases from the web\n", "abstract": " Rather than creating and storing thousands of paraphrase examples, paraphrase templates have strong representation capacity and can be used to generate many paraphrase examples. This paper describes a new template representation and generalization method. Combing a semantic dictionary, it uses multiple semantic codes to represent a paraphrase template. Using an existing search engine to extend the word clusters and generalize the examples. We also design three metrics to measure our generalized templates. The experimental results show that the representation method is reasonable and the generalized templates have a higher precision and coverage.", "num_citations": "17\n", "authors": ["1179"]}
{"title": "A review of relevance feedback experiments at the 2003 reliable information access (RIA) workshop.\n", "abstract": " We review here the results of one of the experiments performed at the 2003 Reliable Information Access (RIA) Workshop, hosted by Mitre Corporation and the Northeast Regional Research Center (NRRC). The experiment concentrates on query expansion using relevance feedback and explores the behaviour of several information retrieval systems using variable numbers of relevant documents.", "num_citations": "17\n", "authors": ["1179"]}
{"title": "HITIQA: A Data Driven Approach to Interactive Question Answering: A Preliminary Report.\n", "abstract": " HITIQA is an interactive question answering technology designed to allow intelligence analysts and other users of information systems to pose questions in natural language and obtain relevant, factual answers, or the assistance they require in order to perform their tasks. Furthermore, our objective in HITIQA is to allow the user to submit exploratory, analytical, nonfactual questions, such as \u201cWhat has been Russia\u2019s reaction to US bombing of Kosovo?\u201d HITIQA uses interactive natural language dialogue to score passages of the retrieved documents in relation to the query. The information obtained from this dialogue will aid the system in clarifying the user\u2019s query, retrieving additional relevant documents and generating succinct answers to analytical questions. This paper will present a preliminary series of results and the results of a pilot evaluation by NIST.", "num_citations": "17\n", "authors": ["1179"]}
{"title": "Learning Multi-Domain Adversarial Neural Networks for Text Classification\n", "abstract": " Deep neural networks have been applied to learn transferable features for adapting text classification models from a source domain to a target domain. Conventional domain adaptation used to adapt models from an individual specific domain with sufficient labeled data to another individual specific target domain without any (or with little) labeled data. However, in this paradigm, we lose sight of correlation among different domains where common knowledge could be shared to improve the performance of both the source domain and the target domain. Multi-domain learning proposes learning the sharable features from multiple source domains and the target domain. However, previous work mainly focuses on improving the performance of the target domain and lacks the effective mechanism to ensure that the shared feature space is not contaminated by domain-specific features. In this paper, we use an adversarial\u00a0\u2026", "num_citations": "16\n", "authors": ["1179"]}
{"title": "Joint learning of question answering and question generation\n", "abstract": " Question answering (QA) and question generation (QG) are closely related tasks that could improve each other; however, the connection of these two tasks is not well explored in the literature. In this paper, we present two training algorithms for learning better QA and QG models through leveraging one another. The first algorithm extends Generative Adversarial Network (GAN), which selectively incorporates artificially generated instances as additional QA training data. The second algorithm is an extension of dual learning, which incorporates the probabilistic correlation of QA and QG as additional regularization in training objectives. To test the scalability of our algorithms, we conduct experiments on both document based and table based question answering tasks. Results show that both algorithms improve a QA model in terms of accuracy and QG model in terms of BLEU score. Moreover, we find that the\u00a0\u2026", "num_citations": "16\n", "authors": ["1179"]}
{"title": "Learning to recommend related entities with serendipity for web search users\n", "abstract": " Entity recommendation, providing entity suggestions to assist users in discovering interesting information, has become an indispensable feature of today\u2019s Web search engine. However, the majority of existing entity recommendation methods are not designed to boost the performance in terms of serendipity, which also plays an important role in the appreciation of users for a recommendation system. To keep users engaged, it is important to take into account serendipity when building an entity recommendation system. In this article, we propose a learning to recommend framework that consists of two components: related entity finding and candidate entity ranking. To boost serendipity performance, three different sets of features that correlate with the three aspects of serendipity are employed in the proposed framework. Extensive experiments are conducted on large-scale, real-world datasets collected from a widely\u00a0\u2026", "num_citations": "16\n", "authors": ["1179"]}
{"title": "Dataset for the first evaluation on chinese machine reading comprehension\n", "abstract": " Machine Reading Comprehension (MRC) has become enormously popular recently and has attracted a lot of attention. However, existing reading comprehension datasets are mostly in English. To add diversity in reading comprehension datasets, in this paper we propose a new Chinese reading comprehension dataset for accelerating related research in the community. The proposed dataset contains two different types: cloze-style reading comprehension and user query reading comprehension, associated with large-scale training data as well as human-annotated validation and hidden test set. Along with this dataset, we also hosted the first Evaluation on Chinese Machine Reading Comprehension (CMRC-2017) and successfully attracted tens of participants, which suggest the potential impact of this dataset.", "num_citations": "16\n", "authors": ["1179"]}
{"title": "Chinese discourse relation semantic taxonomy and annotation\n", "abstract": " Discourse Relation is an important part of discourse semantic analysis. This paper analyses the differences between Chinese and English discourses, then presents the first Chinese discourse relation taxonomy based on the English discourse relation researches in details. Aiming at the rationality of the hierarchy, we conducts annotation experiments on Chinese internet news texts and analyses all difficulties happened during the data annotation together with the resolution to lay a foundation for the future discourse semantic analysis.", "num_citations": "16\n", "authors": ["1179"]}
{"title": "\u4e00\u79cd\u57fa\u4e8e\u52a0\u6743\u6295\u7968\u7684\u672f\u8bed\u81ea\u52a8\u8bc6\u522b\u65b9\u6cd5\n", "abstract": " \u6458! \u8981\"(&,%(K,!% LM* FK,/0'\u00a1\u00a2\u00a3! J= 5\u00a4:;(\u00a5^ 2\u00a6 R \u00a7 ! H^.> 7; 9CK**.> 7; 9CK* 4KMO1XLM; QL8M\u00a9 t:;'\u00aa%! m \u00abI5\u00a4\"\u00ac R_\u00ae,:;\u00b1\u00b2\u00b3'EFOP\u00b5\u00b6\u00b7(K\u00b9\u00ba (,\u00bb k\u00bc! h\u00bd1 \u00be\u00bf(! \u00c0\u00c1J=^ 5\u00a4\"\u00ac\u00ae m\u00c2\u00c3\u00be\u00bf(R_\u00c4\u00c5'30111! ? \u00c6\u00c7\u00c8\u00c9 F\u00caD, V\u00cb\u00ccu \u00cd!\u00ae:; z/2U\u00ce\"\u00ac, tu \u00cf'", "num_citations": "16\n", "authors": ["1179"]}
{"title": "\u57fa\u4e8e\u7c7b\u522b\u7279\u5f81\u57df\u7684\u6587\u672c\u5206\u7c7b\u7279\u5f81\u9009\u62e9\u65b9\u6cd5\n", "abstract": " (\u54c8\u5c14\u6ee8\u5de5\u4e1a\u5927\u5b66\u4fe1\u606f\u68c0\u7d22\u7814\u7a76\u5ba4, \u9ed1\u9f99\u6c5f\u54c8\u5c14\u6ee8 150001) \u6458\u8981: \u7279\u5f81\u9009\u62e9\u662f\u6587\u672c\u5206\u7c7b\u7684\u5173\u952e\u95ee\u9898\u4e4b\u4e00, \u800c\u566a\u97f3\u4e0e\u6570\u636e\u7a00\u758f\u5219\u662f\u7279\u5f81\u9009\u62e9\u8fc7\u7a0b\u4e2d\u9047\u5230\u7684\u4e3b\u8981\u969c\u788d. \u672c\u6587\u4ecb\u7ecd\u4e86\u4e00\u79cd\u57fa\u4e8e\u7c7b\u522b\u7279\u5f81\u57df\u7684\u7279\u5f81\u9009\u62e9\u65b9\u6cd5. \u8be5\u65b9\u6cd5\u9996\u5148\u5229\u7528 \u201c\u7ec4\u5408\u7279\u5f81\u62bd\u53d6\u201d[1] \u7684\u65b9\u6cd5\u53bb\u9664\u539f\u59cb\u7279\u5f81\u7a7a\u95f4\u4e2d\u7684\u566a\u97f3, \u4ece\u4e2d\u62bd\u53d6\u51fa\u5019\u9009\u7279\u5f81. \u8fd9\u91cc,\u201c\u7ec4\u5408\u7279\u5f81\u62bd\u53d6\u201d \u662f\u6307\u5148\u5229\u7528\u6587\u6863\u9891\u7387 (DF) \u7684\u65b9\u6cd5\u53bb\u6389\u4e00\u90e8\u5206\u4f4e\u9891\u8bcd, \u518d\u7528\u4e92\u4fe1\u606f\u7684\u65b9\u6cd5\u9009\u62e9\u51fa\u5019\u9009\u7279\u5f81. \u63a5\u4e0b\u6765, \u672c\u65b9\u6cd5\u4e3a\u5206\u7c7b\u4f53\u7cfb\u4e2d\u7684\u6bcf\u4e2a\u7c7b\u522b\u6784\u5efa\u4e00\u4e2a\u7c7b\u522b\u7279\u5f81\u57df, \u5bf9\u51fa\u73b0\u5728\u7c7b\u522b\u7279\u5f81\u57df\u4e2d\u7684\u5019\u9009\u7279\u5f81\u8fdb\u884c\u7279\u5f81\u7684\u5408\u5e76\u548c\u5f3a\u5316, \u4ece\u800c\u89e3\u51b3\u6570\u636e\u7a00\u758f\u7684\u95ee\u9898. \u5b9e\u9a8c\u8868\u660e, \u8fd9\u79cd\u65b0\u7684\u65b9\u6cd5\u8f83\u4e4b\u5404\u79cd\u4f20\u7edf\u65b9\u6cd5\u5728\u7279\u5f81\u9009\u62e9\u7684\u6548\u679c\u4e0a\u6709\u7740\u660e\u663e\u6539\u5584, \u5e76\u80fd\u663e\u8457\u63d0\u9ad8\u6587\u672c\u5206\u7c7b\u7cfb\u7edf\u7684\u6027\u80fd.", "num_citations": "16\n", "authors": ["1179"]}
{"title": "\u5173\u4e8e\u6b67\u4e49\u5b57\u6bb5\u5207\u5206\u7684\u601d\u8003\u4e0e\u5b9e\u9a8c\n", "abstract": " \u54c8\u5c14\u6ee8\u5de5\u4e1a\u5927\u5b66\u8ba1\u7b97\u673a\u7cfb \u54c8\u5c14\u6ee8\u5de5\u4e1a\u5927\u5b66 319 \u4fe1\u7bb1 150001 \u901a\u5e38\u8ba4\u4e3a: \u5982\u679c\u4e00\u4e2a\u5b57\u6bb5\u5b58\u5728\u4e0d\u540c\u7684\u5207\u5206\u5f62\u5f0f, \u5219\u79f0\u8be5\u5b57\u6bb5\u4e3a\u6b67\u4e49\u5b57\u6bb5. \u5047\u8bbe A, B, C \u5206\u522b\u4ee3\u8868\u4e00\u4e2a\u6216\u591a\u4e2a\u5b57\u7ec4\u6210\u7684\u5b57\u4e32, \u5728\u5b57\u6bb5 ABC \u4e2d\u5982\u679c A, AB, BC, C \u90fd\u662f\u8bcd, \u5219\u79f0 ABC \u4e3a\u4ea4\u96c6\u578b\u6b67\u4e49\u5b57\u6bb5. \u5728\u5b57\u6bb5 AB \u4e2d, \u5982\u679c A, B, AB \u90fd\u662f\u8bcd, \u5219\u79f0 AB \u4e3a\u7ec4\u5408\u578b\u6b67\u4e49\u5b57\u6bb5. \u4ea4\u96c6\u578b\u6b67\u4e49\u5b57\u6bb5\u5360\u5b57\u6bb5\u603b\u6570\u7684 85%-90%.\u7b14\u8005\u611f\u5230\u4ee5\u4e0a\u7684\u5b9a\u4e49\u548c\u5206\u7c7b\u4e0d\u591f\u4e25\u683c, \u6bd4\u5982: \u4f55\u4e3a\u5b57\u6bb5? \u5b57\u6bb5\u7b49\u540c\u4e8e\u6c49\u5b57\u4e32\u5417? \u5982\u679c\u5728\u5b57\u6bb5 ABC \u4e2d, A, AB, BC, C \u662f\u8bcd, B, ABC \u4e5f\u662f\u8bcd, \u90a3\u4e48 ABC \u662f\u4ea4\u96c6\u5b57\u6bb5\u8fd8\u662f\u7ec4\u5408\u5b57\u6bb5? \u6291\u6216\u79f0\u4e3a\u6df7\u5408\u5b57\u6bb5, \u6c49\u8bed\u4e2d\u80fd\u7528\u505a\u5355\u5b57\u8bcd\u7684\u6c49\u5b57\u5c11\u8bf4\u4e5f\u6709 2000 \u4ee5\u4e0a, \u6839\u636e\u4e0a\u8ff0\u7ec4\u5408\u5b57\u6bb5\u7684\u5b9a\u4e49, \u7edd\u5927\u591a\u6570\u4e8c\u5b57\u53ca\u4e8c\u5b57\u4ee5\u4e0a\u8bcd\u5747\u5e94\u89c6\u4e3a\u7ec4\u5408\u5b57\u6bb5, \u8fd9\u6837\u7ec4\u5408\u5b57\u6bb5\u7684\u6570\u91cf\u5c06\u8fdc\u8fdc\u8d85\u8fc7\u4ea4\u96c6\u5b57\u6bb5\u7684\u6570\u91cf.", "num_citations": "16\n", "authors": ["1179"]}
{"title": "A syntactic path-based hybrid neural network for negation scope detection\n", "abstract": " The automatic detection of negation is a crucial task in a wide-range of natural language processing (NLP) applications, including medical data mining, relation extraction, question answering, and sentiment analysis. In this paper, we present a syntactic path-based hybrid neural network architecture, a novel approach to identify the scope of negation in a sentence. Our hybrid architecture has the particularity to capture salient information to determine whether a token is in the scope or not, without relying on any human intervention. This approach combines a bidirectional long short-term memory (Bi-LSTM) network and a convolutional neural network (CNN). The CNN model captures relevant syntactic features between the token and the cue within the shortest syntactic path in both constituency and dependency parse trees. The Bi-LSTM learns the context representation along the sentence in both forward and\u00a0\u2026", "num_citations": "15\n", "authors": ["1179"]}
{"title": "Exploring implicit feedback for open domain conversation generation\n", "abstract": " User feedback can be an effective indicator to the success of the human-robot conversation. However, to avoid to interrupt the online real-time conversation process, explicit feedback is usually gained at the end of a conversation. Alternatively, users' responses usually contain their implicit feedback, such as stance, sentiment, emotion, etc., towards the conversation content or the interlocutors. Therefore, exploring the implicit feedback is a natural way to optimize the conversation generation process. In this paper, we propose a novel reward function which explores the implicit feedback to optimize the future reward of a reinforcement learning based neural conversation model. A simulation strategy is applied to explore the state-action space in training and test. Experimental results show that the proposed approach outperforms the Seq2Seq model and the state-of-the-art reinforcement learning model for conversation generation on automatic and human evaluations on the OpenSubtitles and Twitter datasets.", "num_citations": "15\n", "authors": ["1179"]}
{"title": "The HIT-SCIR system for end-to-end parsing of universal dependencies\n", "abstract": " This paper describes our system (HIT-SCIR) for the CoNLL 2017 shared task: Multilingual Parsing from Raw Text to Universal Dependencies. Our system includes three pipelined components: tokenization, Part-of-Speech (POS) tagging and dependency parsing. We use character-based bidirectional long short-term memory (LSTM) networks for both tokenization and POS tagging. Afterwards, we employ a list-based transition-based algorithm for general non-projective parsing and present an improved Stack-LSTM-based architecture for representing each transition state and making predictions. Furthermore, to parse low/zero-resource languages and cross-domain data, we use a model transfer approach to make effective use of existing resources. We demonstrate substantial gains against the UDPipe baseline, with an average improvement of 3.76% in LAS of all languages. And finally, we rank the 4th place on the official test sets.", "num_citations": "15\n", "authors": ["1179"]}
{"title": "Learning Document Representation for Deceptive Opinion Spam Detection\n", "abstract": " Deceptive opinion spam in reviews of products or service is very harmful for customers in decision making. Existing approaches to detect deceptive spam are concern on feature designing. Hand-crafted features can show some linguistic phenomenon, but is time-consuming and can not reveal the connotative semantic meaning of the review. We present a neural network to learn document-level representation. In our model, we not only learn to represent each sentence but also represent the whole document of the review. We apply traditional convolutional neural network to represent the semantic meaning of sentences. We present two variant convolutional neural-network models to learn the document representation. The model taking sentence importance into consideration shows the better performance in deceptive spam detection which enhances the value of F1 by 5\u00a0%.", "num_citations": "15\n", "authors": ["1179"]}
{"title": "Improving semantic role labeling with word sense\n", "abstract": " Semantic role labeling (SRL) not only needs lexical and syntactic information, but also needs word sense information. However, because of the lack of corpus annotated with both word senses and semantic roles, there is few research on using word sense for SRL. The release of OntoNotes provides an opportunity for us to study how to use word sense for SRL. In this paper, we present some novel word sense features for SRL and find that they can improve the performance significantly.", "num_citations": "15\n", "authors": ["1179"]}
{"title": "Recognizing the Extent of Chinese time expressions based on the Dependency parsing and Error-Driven learning\n", "abstract": " Recognizing time expressions is the foundation of its normalization, and its performance directly influences the robustness of the normalization. This paper proposes a new method for recognizing the extents of the time expressions based on dependency parsing and error-driven learning, which begins with time trigger word (namely, the syntactic head of dependency relation), uses Chinese dependency parsing to recognize the extents of the time expressions, Subsequently, we use the transformation-based error-driven learning to improve the performance., which can automatically acquire and modify the rules and get 3.5% increase after applying the learned rules. Finally, F1= 76.38% and F1= 76.57% results are obtained on the closed and the open test set respectively.", "num_citations": "15\n", "authors": ["1179"]}
{"title": "Learning target-specific representations of financial news documents for cumulative abnormal return prediction\n", "abstract": " Texts from the Internet serve as important data sources for financial market modeling. Early statistical approaches rely on manually defined features to capture lexical, sentiment and event information, which suffers from feature sparsity. Recent work has considered learning dense representations for news titles and abstracts. Compared to news titles, full documents can contain more potentially helpful information, but also noise compared to events and sentences, which has been less investigated in previous work. To fill this gap, we propose a novel target-specific abstract-guided news document representation model. The model uses a target-sensitive representation of the news abstract to weigh sentences in the news content, so as to select and combine the most informative sentences for market modeling. Results show that document representations can give better performance for estimating cumulative abnormal returns of companies when compared to titles and abstracts. Our model is especially effective when it used to combine information from multiple document sources compared to the sentence-level baselines.", "num_citations": "14\n", "authors": ["1179"]}
{"title": "Domain Adaptation via Tree Kernel Based Maximum Mean Discrepancy for User Consumption Intention Identification.\n", "abstract": " Identifying user consumption intention from social media is of great interests to downstream applications. Since such task is domain-dependent, deep neural networks have been applied to learn transferable features for adapting models from a source domain to a target domain. A basic idea to solve this problem is reducing the distribution difference between the source domain and the target domain such that the transfer error can be bounded. However, the feature transferability drops dramatically in higher layers of deep neural networks with increasing domain discrepancy. Hence, previous work has to use a few target domain annotated data to train domain-specific layers. In this paper, we propose a deep transfer learning framework for consumption intention identification, to reduce the data bias and enhance the transferability in domainspecific layers. In our framework, the representation of the domain-specific layer is mapped to a reproducing kernel Hilbert space, where the mean embeddings of different domain distributions can be explicitly matched. By using an optimal tree kernel method for measuring the mean embedding matching, the domain discrepancy can be effectively reduced. The framework can learn transferable features in a completely unsupervised manner with statistical guarantees. Experimental results on five different domain datasets show that our approach dramatically outperforms state-of-the-art baselines, and it is general enough to be applied to more scenarios. The source code and datasets can be found at http://ir. hit. edu. cn/\\% 7exding/index_english. htm.", "num_citations": "14\n", "authors": ["1179"]}
{"title": "A deep learning approach for question answering over knowledge base\n", "abstract": " With the increase of the scale of the knowledge base, it\u2019s important to answer question over knowledge base. In this paper, we will introduce a method to extract answers from Chinese knowledge base for Chinese questions. Our method uses a classifier to judge whether the relation in the triple is what the question asked, question-relation pairs are used to train the classifier. It\u2019s difficult to identify the right relation, so we find out the focus of the question and leverage the resource of lexical paraphrase in the preprocessing of the question. And the use of lexical paraphrase also can alleviate the out of vocabulary (OOV) problem. In order to let the right answer at the top of candidate answers, we present a ranking method to rank these candidate answers. The result of the final evaluation shows that our method achieves a good result.", "num_citations": "14\n", "authors": ["1179"]}
{"title": "A joint segmentation and classification framework for sentiment analysis\n", "abstract": " In this paper, we propose a joint segmentation and classification framework for sentiment analysis. Existing sentiment classification algorithms typically split a sentence as a word sequence, which does not effectively handle the inconsistent sentiment polarity between a phrase and the words it contains, such as \u201cnot bad\u201d and \u201ca great deal of\u201d. We address this issue by developing a joint segmentation and classification framework (JSC), which simultaneously conducts sentence segmentation and sentence-level sentiment classification. Specifically, we use a log-linear model to score each segmentation candidate, and exploit the phrasal information of top-ranked segmentations as features to build the sentiment classifier. A marginal log-likelihood objective function is devised for the segmentation model, which is optimized for enhancing the sentiment classification performance. The joint model is trained only based on the annotated sentiment polarity of sentences, without any segmentation annotations. Experiments on a benchmark Twitter sentiment classification dataset in SemEval 2013 show that, our joint model performs comparably with the state-of-the-art methods.", "num_citations": "14\n", "authors": ["1179"]}
{"title": "\u4e2d\u6587\u7bc7\u7ae0\u7ea7\u53e5\u95f4\u8bed\u4e49\u5173\u7cfb\u4f53\u7cfb\u53ca\u6807\u6ce8\n", "abstract": " \u968f\u7740\u8bcd\u6c47\u8bed\u4e49 & \u53e5\u5b50\u8bed\u4e49\u7814\u7a76\u7684\u9010\u6e10\u6210\u719f! \u7bc7\u7ae0\u7ea7\u8bed\u4e49\u5206\u6790\u9010\u6e10\u6210\u4e3a\u7814\u7a76\u70ed\u70b9! \u4f5c\u4e3a\u7bc7\u7ae0\u8bed\u4e49\u5206\u6790\u7684\u91cd\u8981\u5185\u5bb9! \u7bc7\u7ae0\u53e5\u95f4\u5173\u7cfb\u7814\u7a76# YDRS9I= RC* C:<> OD9F $ \u4e5f\u5f00\u59cb\u53d7\u5230\u8d8a\u6765\u8d8a\u591a\u7684\u5173\u6ce8) \u8be5\u7814\u7a76\u4ee5\u5206\u6790\u6587\u672c\u5757\u95f4\u7684\u56e0\u679c & \u6bd4\u8f83\u7b49\u8bed\u4e49\u5173\u8054\u4e3a\u76ee\u6807! \u5728\u7f3a\u5c11\u7bc7\u7ae0\u7ea7\u8d44\u6e90\u548c\u65b9\u6cd5\u7684\u60c5\u51b5\u4e0b! \u5229\u7528\u7bc7\u7ae0\u53e5\u95f4\u5173\u7cfb\u5c06\u8bcd\u6c47\u8bed\u4e49\u878d\u5408\u6210\u4e3a\u7bc7\u7ae0\u7ea7\u8bed\u4e49\u4fe1\u606f! \u6210\u4e3a\u8bed\u4e49\u5206\u6790\u7684\u91cd\u8981\u89e3\u51b3\u9014\u5f84\u4e4b! \u5bf9\u81ea\u52a8\u6587\u6458* $+ & \u81ea\u52a8\u95ee\u7b54*!+ & \u503e\u5411\u6027\u5206\u6790* &>%+ \u4ee5\u53ca\u6587\u672c\u8d28\u91cf\u8bc4\u4ef7*@+ & \u6587\u672c\u8fde\u8d2f\u6027\u8bc4\u4ef7*[+ \u7b49\u8bb8\u591a+-6 \u4efb\u52a1\u8d77\u5230\u4e86\u5f88\u5927\u7684\u5e2e\u52a9) \u6839\u636e\u4f9d\u8d56\u7684\u6838\u5fc3\u5185\u5bb9\u4e0d\u540c! \u4f20\u7edf\u7684\u8bed\u4e49\u5206\u6790\u65b9\u6cd5\u5927\u81f4\u53ef\u4ee5\u5206\u4e3a\u4ee5\u4e0b & \u7c7b)# $$ \u4ee5\u8bcd\u6c47\u8bed\u4e49\u4e3a\u6838\u5fc3\u7684\u5206\u6790\u7406\u8bba) \u8bcd\u6c47\u94fe\u7406\u8bba#-CZDS<:/9HCRD9F $ \u901a\u8fc7\u5206\u6790\u8bcd\u6c47\u8bed\u4e49\u6784\u5efa\u4e3b\u9898\u8bcd\u6c47\u94fe! \u5229\u7528\u4e3b\u9898\u8bcd\u6c47\u7684\u5206\u5e03\u548c\u8f6c\u79fb\u60c5\u51b5\u5206\u6790\u7bc7\u7ae0\u8bed\u4e49*?+) \u8be5\u7406\u8bba\u7684\u64cd\u4f5c\u6027\u8f83\u5f3a! \u4f46\u4ee5\u8bcd\u6c47\u4e3a\u4e3b\u8981\u5206\u6790\u5bf9\u8c61! \u8868\u73b0\u529b\u6bd4\u8f83\u6709\u9650% \u4e2d\u5fc3\u7406\u8bba*\"+ \u5728\u7ed9\u5b9a\u7684\u53e5\u5b50\u4e2d\u8ddf\u8e2a\u7126\u70b9\u53d8\u5316! \u901a\u8fc7\u5b9a\u4e49\u4e0d\u540c\u7684\u7126\u70b9\u53d8\u5316\u65b9\u5f0f\u6765\u63cf\u8ff0\u7bc7\u7ae0\u7ed3\u6784\u5e76\u83b7\u77e5\u8bed\u4e49\u4fe1\u606f) \u8be5\u7406\u8bba\u4e3b\u8981\u5173\u6ce8\u53e5\u5b50\u95f4\u7684\u7126\u70b9\u8f6c\u6362! \u5bf9\u7bc7\u7ae0\u4fe1\u606f\u5173\u6ce8\u8f83\u5c11! \u8f6c\u79fb\u5173\u7cfb\u7c7b\u578b\u6bd4\u8f83\u5355)", "num_citations": "14\n", "authors": ["1179"]}
{"title": "An svmtool-based chinese pos tagger\n", "abstract": " The SVMTool is a simple, flexible and effective generator of sequential tagger based on Support Vector Machines, capable of dealing with a large number of linguistic features. In this paper. SVMTool is applied in Chinese POS tagging task and improves the accuracy by 2.07% compared with the baseline system on the Hidden Markov Model. To further improve the accuracy of unknown words, we introduce some features of Chinese characters and words, such as radicals of Chinese characters and reduplicate words, and probe into a theoretical analysis for their feasibility. Experiments indicate that these features can improve the accuracy of unknown words by 1.16% as well as reduce the error rate by 7.40%.", "num_citations": "14\n", "authors": ["1179"]}
{"title": "HIT-IR-WSD: A wsd system for english lexical sample task\n", "abstract": " HIT-IR-WSD is a word sense disambiguation (WSD) system developed for English lexical sample task (Task 11) of Semeval 2007 by Information Retrieval Lab, Harbin Institute of Technology. The system is based on a supervised method using an SVM classifier. Multi-resources including words in the surrounding context, the partof-speech of neighboring words, collocations and syntactic relations are used. The final micro-avg raw score achieves 81.9% on the test set, the best one among participating runs.", "num_citations": "14\n", "authors": ["1179"]}
{"title": "HITIQA: A question answering analytical tool\n", "abstract": " Abstract\u2020HITIQA (High Quality Interactive Question Answering) is currently being developed to assist analysts in finding answers to complex intelligence problems, efficiently and thoroughly. The system uses event-based, data-driven semantic processing and natural language dialogue, coupled with an advanced information visualization interface, to deliver accurate answers to the analyst\u2019s questions along with related contextual information. The first version of the system has undergone a series of preliminary evaluations with the analysts from the US Naval Reserve, producing valuable usage and performance data. These evaluations suggest that HITIQA creates a measurable cognitive augmentation effect for the analyst. The second more advanced version of the system is currently being implemented.", "num_citations": "14\n", "authors": ["1179"]}
{"title": "\u57fa\u4e8e\u591a\u7279\u5f81\u878d\u5408\u7684\u53e5\u5b50\u76f8\u4f3c\u5ea6\u8ba1\u7b97\n", "abstract": " \u53e5\u5b50\u76f8\u4f3c\u5ea6\u8ba1\u7b97\u5728\u4e2d\u6587\u81ea\u7136\u8bed\u8a00\u5904\u7406\u9886\u57df\u6709\u7740\u975e\u5e38\u5e7f\u6cdb\u7684\u5e94\u7528\u80cc\u666f. \u672c\u6587\u901a\u8fc7\u5bf9\u53e5\u5b50\u7684\u6df1\u5165\u5206\u6790, \u5728\u5206\u522b\u5bf9\u57fa\u4e8e\u8bcd\u7279\u5f81, \u8bcd\u4e49\u7279\u5f81\u4ee5\u53ca\u53e5\u6cd5\u7279\u5f81\u7684\u53e5\u5b50\u76f8\u4f3c\u5ea6\u8ba1\u7b97\u7684\u57fa\u7840\u4e0a, \u63d0\u51fa\u4e00\u79cd\u57fa\u4e8e\u591a\u7279\u5f81\u878d\u5408\u7684\u53e5\u5b50\u76f8\u4f3c\u5ea6\u7684\u8ba1\u7b97\u65b9\u6cd5. \u8be5\u65b9\u6cd5\u901a\u8fc7\u5bf9\u4e0d\u540c\u7684\u7279\u5f81\u52a0\u4e0d\u540c\u7684\u6743\u503c\u6765\u8c03\u8282\u5404\u4e2a\u7279\u5f81\u5bf9\u76f8\u4f3c\u5ea6\u8ba1\u7b97\u7684\u8d21\u732e, \u4ece\u800c\u4f7f\u8ba1\u7b97\u7ed3\u679c\u8fbe\u5230\u6700", "num_citations": "14\n", "authors": ["1179"]}
{"title": "\u57fa\u4e8e\u4fe1\u606f\u62bd\u53d6\u548c\u6587\u672c\u751f\u6210\u7684\u81ea\u52a8\u6587\u6458\u7cfb\u7edf\u8bbe\u8ba1\n", "abstract": " \u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u81ea\u52a8\u6587\u6458\u7cfb\u7edf\u7684\u8bbe\u8ba1\u65b9\u6848,\u8be5\u65b9\u6848\u5c06\u6587\u6458\u8fc7\u7a0b\u5206\u89e3\u4e3a\u4fe1\u606f\u62bd\u53d6\u548c\u6587\u672c\u751f\u6210\u4e24\u4e2a\u5b50\u8fc7\u7a0b.\u4fe1\u606f\u62bd\u53d6\u8fc7\u7a0b\u5bf9\u539f\u6587\u8fdb\u884c\u8bcd\u8bed\u9891\u7387,\u8bcd\u8bed\u5206\u5e03\u548c\u4fee\u8f9e\u7ed3\u6784\u7684\u5206\u6790,\u5e76\u5728\u6b64\u57fa\u7840\u4e0a\u53c2\u8003\u7528\u6237\u5bf9\u6458\u8981\u7684\u9700\u6c42,\u62bd\u53d6\u539f\u6587\u7684\u90e8\u5206\u5185\u5bb9\u586b\u5199\u6587\u6458\u6846\u67b6.\u6587\u672c\u751f\u6210\u8fc7\u7a0b\u5bf9\u6587\u6458\u6846\u67b6\u4e2d\u7684\u53e5\u5b50\u8fdb\u884c\u52a0\u5de5,\u7ec4\u7ec7,\u751f\u6210\u8fde\u8d2f\u7684\u6bb5\u843d", "num_citations": "14\n", "authors": ["1179"]}
{"title": "Causaltriad: toward pseudo causal relation discovery and hypotheses generation from medical text data\n", "abstract": " Deriving pseudo causal relations from medical text data lies at the heart of medical literature mining. Existing studies have utilized extraction models to find pseudo causal relation from single sentences, while the knowledge created by causation transitivity-often spanning multiple sentences-has not been considered. Furthermore, we observe that many pseudo causal relations follow the rule of causation transitivity, which makes it possible to discover unseen casual relations and generate new causal relation hypotheses. In this paper, we address these two issues by proposing a factor graph model to incorporate three clues to discover causation expressions in the text data. We propose four types of triad structures to represent the rules of causation transitivity among causal relations. Our proposed model, called CausalTriad, uses textual and structural knowledge to infer pseudo causal relations from the triad\u00a0\u2026", "num_citations": "13\n", "authors": ["1179"]}
{"title": "HFL-RC system at SemEval-2018 task 11: hybrid multi-aspects model for commonsense reading comprehension\n", "abstract": " This paper describes the system which got the state-of-the-art results at SemEval-2018 Task 11: Machine Comprehension using Commonsense Knowledge. In this paper, we present a neural network called Hybrid Multi-Aspects (HMA) model, which mimic the human's intuitions on dealing with the multiple-choice reading comprehension. In this model, we aim to produce the predictions in multiple aspects by calculating attention among the text, question and choices, and combine these results for final predictions. Experimental results show that our HMA model could give substantial improvements over the baseline system and got the first place on the final test set leaderboard with the accuracy of 84.13%.", "num_citations": "13\n", "authors": ["1179"]}
{"title": "Truth discovery with memory network\n", "abstract": " Truth discovery aims to resolve conflicts among multiple sources and find the truth. Conventional methods for truth discovery mainly investigate the mutual effect between the reliability of sources and the credibility of statements. These methods use real numbers, which have a lower representation capability than vectors to represent the reliability. In addition, neural networks have not been used for truth discovery. In this work, we propose memory-network-based models to address truth discovery. Our proposed models use feedforward and feedback memory networks to learn the representation of the credibility of statements. Specifically, our models adopt a memory mechanism to learn the reliability of sources for truth prediction. The proposed models use categorical and continuous data during model learning by automatically assigning different weights to the loss function on the basis of their own effects\u00a0\u2026", "num_citations": "13\n", "authors": ["1179"]}
{"title": "ANEW+: Automatic expansion and validation of affective norms of words lexicons in multiple languages\n", "abstract": " In this article we describe our method of automatically expanding an existing lexicon of words with affective valence scores. The automatic expansion process was done in English. In addition, we describe our procedure for automatically creating lexicons in languages where such resources may not previously exist. The foreign languages we discuss in this paper are Spanish, Russian and Farsi. We also describe the procedures to systematically validate our newly created resources. The main contributions of this work are: 1) A general method for expansion and creation of lexicons with scores of words on psychological constructs such as valence, arousal or dominance; and 2) a procedure for ensuring validity of the newly constructed resources.", "num_citations": "13\n", "authors": ["1179"]}
{"title": "A distributed representation-based framework for cross-lingual transfer parsing\n", "abstract": " This paper investigates the problem of cross-lingual transfer parsing, aiming at inducing dependency parsers for low-resource languages while using only training data from a resource-rich language (e.g., English). Existing model transfer approaches typically don't include lexical features, which are not transferable across languages. In this paper, we bridge the lexical feature gap by using distributed feature representations and their composition. We provide two algorithms for inducing cross-lingual distributed representations of words, which map vocabularies from two different languages into a common vector space. Consequently, both lexical features and nonlexical features can be used in our model for cross-lingual transfer. Furthermore, our framework is flexible enough to incorporate additional useful features such as cross-lingual word clusters. Our combined contributions achieve an average relative error reduction of 10.9% in labeled attachment score as compared with the delexicalized parser, trained on English universal treebank and transferred to three other languages. It also significantly outperforms state-of-the-art delexicalized models augmented with projected cluster features on identical data. Finally, we demonstrate that our models can be further boosted with minimal supervision (e.g., 100 annotated sentences) from target languages, which is of great significance for practical usage.", "num_citations": "13\n", "authors": ["1179"]}
{"title": "Sentence compression for target-polarity word collocation extraction\n", "abstract": " Target-polarity word (TP) collocation extraction, a basic sentiment analysis task, relies primarily on syntactic features to identify the relationships between targets and polarity words. A major problem of current research is that this task focuses on customer reviews, which are natural or spontaneous, thus posing a challenge to syntactic parsers. We address this problem by proposing a framework of adding a sentiment sentence compression (Sent Comp) step before performing TP collocation extraction. Sent Comp seeks to remove the unnecessary information for sentiment analysis, thereby compressing a complicated sentence into one that is shorter and easier to parse. We apply a discriminative conditional random field model, with some special sentimentrelated features, in order to automatically compress sentiment sentences. Experiments show that Sent Comp significantly improves the performance of TP collocation extraction.", "num_citations": "13\n", "authors": ["1179"]}
{"title": "Question Popularity Analysis and Prediction in Community Question Answering Services\n", "abstract": " With the blooming of online social media applications, Community Question Answering (CQA) services have become one of the most important online resources for information and knowledge seekers. A large number of high quality question and answer pairs have been accumulated, which allow users to not only share their knowledge with others, but also interact with each other. Accordingly, volumes of efforts have been taken to explore the questions and answers retrieval in CQA services so as to help users to finding the similar questions or the right answers. However, to our knowledge, less attention has been paid so far to question popularity in CQA. Question popularity can reflect the attention and interest of users. Hence, predicting question popularity can better capture the users\u2019 interest so as to improve the users\u2019 experience. Meanwhile, it can also promote the development of the community. In this paper, we investigate the problem of predicting question popularity in CQA. We first explore the factors that have impact on question popularity by employing statistical analysis. We then propose a supervised machine learning approach to model these factors for question popularity prediction. The experimental results show that our proposed approach can effectively distinguish the popular questions from unpopular ones in the Yahoo! Answers question and answer repository.", "num_citations": "13\n", "authors": ["1179"]}
{"title": "Automatic Expansion of the MRC Psycholinguistic Database Imageability Ratings.\n", "abstract": " Recent studies in metaphor extraction across several languages (Broadwell et al., 2013; Strzalkowski et al., 2013) have shown that word imageability ratings are highly correlated with the presence of metaphors in text. Information about imageability of words can be obtained from the MRC Psycholinguistic Database (MRCPD) for English words and L\u00e9xico Informatizado del Espa\u00f1ol Programa (LEXESP) for Spanish words, which is a collection of human ratings obtained in a series of controlled surveys. Unfortunately, word imageability ratings were collected for only a limited number of words: 9,240 words in English, 6,233 in Spanish; and are unavailable at all in the other two languages studied: Russian and Farsi. The present study describes an automated method for expanding the MRCPD by conferring imageability ratings over the synonyms and hyponyms of existing MRCPD words, as identified in Wordnet. The result is an expanded MRCPD+ database with imagea-bility scores for more than 100,000 words. The appropriateness of this expansion process is assessed by examining the structural coherence of the expanded set and by validating the expanded lexicon against human judgment. Finally, the performance of the metaphor extraction system is shown to improve significantly with the expanded database. This paper describes the process for English MRCPD+ and the resulting lexical resource. The process is analogous for other languages.", "num_citations": "13\n", "authors": ["1179"]}
{"title": "Dependency Graph Based Chinese Semantic Parsing\n", "abstract": " Semantic Dependency Parsing (SDP) is a deep semantic analysis task. A well-formed dependency scheme is the foundation of SDP. In this paper, we refine the HIT dependency scheme using stronger linguistic theories, yielding a dependency scheme with more clear hierarchy. To cover Chinese semantics more comprehensively, we make a break away from the constraints of dependency trees, and extend to graphs. Moreover, we utilize SVM to parse semantic dependency graphs on the basis of parsing of dependency trees.", "num_citations": "13\n", "authors": ["1179"]}
{"title": "\u57fa\u4e8e URL \u4e3b\u9898\u7684\u67e5\u8be2\u5206\u7c7b\u65b9\u6cd5\n", "abstract": " \u6458 \u8981 \u4e92\u8054\u7f51\u4e0a\u5f88\u591a\u8d44\u6e90\u8574\u542b\u4eba\u7c7b\u7fa4\u4f53\u667a\u6167. \u5206\u7c7b\u7f51\u7ad9\u76ee\u5f55\u4eba\u5de5\u5730\u5bf9\u7f51\u7ad9\u6309\u7167\u4e3b\u9898\u8fdb\u884c\u7ec4\u7ec7. \u57fa\u4e8e\u7f51\u7ad9\u76ee\u5f55\u4e2d\u5177\u6709\u4e3b\u9898\u6807\u6ce8\u7684 URL \u8bbe\u8ba1 URL \u4e3b\u9898\u5206\u7c7b\u5668, \u7ed3\u5408\u4f2a\u76f8\u5173\u53cd\u9988\u6280\u672f\u4ee5\u53ca\u641c\u7d22\u5f15\u64ce\u67e5\u8be2\u65e5\u5fd7, \u63d0\u51fa\u4e86\u81ea\u52a8, \u5feb\u901f, \u6709\u6548\u7684\u67e5\u8be2\u4e3b\u9898\u5206\u7c7b\u65b9\u6cd5. \u5177\u4f53\u5730, \u65b9\u6cd5\u4e3a 2 \u79cd\u7b56\u7565\u7684\u7ed3\u5408. \u7b56\u7565 1 \u901a\u8fc7\u8ba1\u7b97\u641c\u7d22\u7ed3\u679c\u4e2d URL \u7684\u4e3b\u9898\u5206\u5e03\u9884\u6d4b\u67e5\u8be2\u4e3b\u9898, \u7b56\u7565 2 \u57fa\u4e8e\u67e5\u8be2\u65e5\u5fd7\u70b9\u51fb\u5173\u7cfb, \u5229\u7528\u5177\u6709\u4e3b\u9898\u6807\u6ce8\u7684 URL, \u5bf9\u67e5\u8be2\u8fdb\u884c\u6807\u6ce8\u83b7\u53d6\u6570\u636e\u5e76\u8bad\u7ec3\u7edf\u8ba1\u5206\u7c7b\u5668\u9884\u6d4b\u67e5\u8be2\u4e3b\u9898. \u5b9e\u9a8c\u8868\u660e, \u65b9\u6cd5\u53ef\u83b7\u5f97\u6bd4\u5f53\u524d\u6700\u597d\u7b97\u6cd5\u66f4\u597d\u7684\u51c6\u786e\u7387, \u66f4\u597d\u7684\u5728\u7ebf\u5904\u7406\u6548\u7387\u5e76\u4e14\u53ef\u57fa\u4e8e\u67e5\u8be2\u65e5\u5fd7\u81ea\u52a8\u83b7\u53d6\u8bad\u7ec3\u6570\u636e, \u5177\u6709\u826f\u597d\u7684\u53ef\u6269\u5c55\u6027.", "num_citations": "13\n", "authors": ["1179"]}
{"title": "\u5f00\u653e\u57df\u95ee\u7b54\u6280\u672f\u7814\u7a76\u8fdb\u5c55\n", "abstract": " \u95ee\u7b54\u6280\u672f\u662f\u4fe1\u606f\u68c0\u7d22\u548c\u81ea\u7136\u8bed\u8a00\u7406\u89e3\u4e2d\u7684\u7814\u7a76\u70ed\u70b9. \u672c\u6587\u5bf9\u5f00\u653e\u57df\u95ee\u7b54\u6280\u672f\u5728\u8fd1\u5e74\u6765\u7684\u7814\u7a76\u8fdb\u5c55\u8fdb\u884c\u4e86\u603b\u7ed3. \u9488\u5bf9\u4e0d\u540c\u7c7b\u578b\u7684\u95ee\u9898, \u6bd4\u8f83\u4e86\u95ee\u7b54\u7cfb\u7edf\u4e2d\u95ee\u9898\u5206\u6790, \u6587\u6863\u548c\u53e5\u6bb5\u68c0\u7d22, \u7b54\u6848\u62bd\u53d6\u5404\u4e2a\u90e8\u5206\u4e0d\u540c\u5b9e\u73b0\u65b9\u6cd5\u7684\u7279\u70b9, \u8ba8\u8bba\u4e86\u8fd9\u4e9b\u6280\u672f\u4e2d\u5b58\u5728\u7684\u4e0d\u8db3. \u6700\u540e, \u5bf9\u95ee\u7b54\u6280\u672f\u672a\u6765\u7684\u7814\u7a76\u8d8b\u52bf\u8fdb\u884c\u4e86\u5206\u6790\u4e0e\u5c55\u671b.", "num_citations": "13\n", "authors": ["1179"]}
{"title": "Theories and methods of Chinese automatic syntactic parsing: A critical survey\n", "abstract": " This paper reviews the theories and methods of Chinese parsing in three closely related areas. First, several important syntactic theories underlying both the parsing technology and Chinese treebank compilation are examined. Second, several popular parsing methods and the difficult problems associated with them are reviewed. Third, the state of the art of Chinese syntactic parsing is presented. The paper concludes by summing up the general progress of Chinese parsing and discussing some persistent open problems.", "num_citations": "13\n", "authors": ["1179"]}
{"title": "Topic tracking based on keywords dependency profile\n", "abstract": " Topic tracking is an important task of Topic Detection and Tracking (TDT). Its purpose is to detect stories, from a stream of news, related to known topics. Each topic is \u201cknown\u201d by its association with several sample stories that discuss it. In this paper, we propose a new method to build the keywords dependency profile (KDP) of each story and track topic basing on similarity between the profiles of topic and story. In this method, keywords of a story are selected by document summarization technology. The KDP is built by keywords co-occurrence frequency in the same sentences of the story. We demonstrate this profile can describe the core events in a story accurately. Experiments on the mandarin resource of TDT4 and TDT5 show topic tracking system basing on KDP improves the performance by 13.25% on training dataset and 7.49% on testing dataset comparing to baseline.", "num_citations": "13\n", "authors": ["1179"]}
{"title": "Hitiqa: Scenario based question answering\n", "abstract": " In this paper we describe some preliminary results of qualitative evaluation of the answering system HITIQA (High-Quality Interactive Question Answering) which has been developed over the last 2 years as an advanced research tool for information analysts. HITIQA is an interactive open-domain question answering technology designed to allow analysts to pose complex exploratory questions in natural language and obtain relevant information units to prepare their briefing reports in order to satisfy a given scenario. The system uses novel data-driven semantics to conduct a clarification dialogue with the user that explores the scope and the context of the desired answer space. The system has undergone extensive hands-on evaluations by a group of intelligence analysts representing various foreign intelligence services. This evaluation validated the overall approach in HITIQA but also exposed limitations of the current prototype.", "num_citations": "13\n", "authors": ["1179"]}
{"title": "Research on automatic abstracting based on text multilevel dependency structure\n", "abstract": " Automatic abstracting is an important direction in the area of natural language processing. The purpose of this technique is to explore the mechanism of acquiring and abstracting information from natural language texts, and then the programs which can automatically write abstracts will improve the efficiency of information retrieval and spread. A new abstracting method based on text multilevel dependency structure is presented in the paper. The new method is neither superficial as the mechanic method, nor limited as the understanding method. The formal description of the text multilevel dependency structure is given and it is proved that the text multilevel dependency structure is very suitable for automatic abstracting. Also presented are the methods of text structures recognition, reduction, and abstract generation from the compressed structure. The experiments show the expected results obtained, and the feasibility and advantage of the new abstracting method is validated.", "num_citations": "13\n", "authors": ["1179"]}
{"title": "Learning sentence representations over tree structures for target-dependent classification\n", "abstract": " Target-dependent classification tasks, such as aspect-level sentiment analysis, perform fine-grained classifications towards specific targets. Semantic compositions over tree structures are promising for such tasks, as they can potentially capture long-distance interactions between targets and their contexts. However, previous work that operates on tree structures resorts to syntactic parsers or Treebank annotations, which are either subject to noise in informal texts or highly expensive to obtain. To address above issues, we propose a reinforcement learning based approach, which automatically induces target-specific sentence representations over tree structures. The underlying model is a RNN encoder-decoder that explores possible binary tree structures and a reward mechanism that encourages structures that improve performances on downstream tasks. We evaluate our approach on two benchmark tasks: firm-specific cumulative abnormal return prediction (based on formal news texts) and aspect-level sentiment analysis (based on informal social media texts). Experimental results show that our model gives superior performances compared to previous work that operates on parsed trees. Moreover, our approach gives some intuitions on how target-specific sentence representations can be achieved from its word constituents.", "num_citations": "12\n", "authors": ["1179"]}
{"title": "Distilling knowledge for search-based structured prediction\n", "abstract": " Many natural language processing tasks can be modeled into structured prediction and solved as a search problem. In this paper, we distill an ensemble of multiple models trained with different initialization into a single model. In addition to learning to match the ensemble's probability output on the reference states, we also use the ensemble to explore the search space and learn from the encountered states in the exploration. Experimental results on two typical search-based structured prediction tasks -- transition-based dependency parsing and neural machine translation show that distillation can effectively improve the single model's performance and the final model achieves improvements of 1.32 in LAS and 2.65 in BLEU score on these two tasks respectively over strong baselines and it outperforms the greedy structured prediction models in previous literatures.", "num_citations": "12\n", "authors": ["1179"]}
{"title": "\u590d\u8ff0\u6280\u672f\u7814\u7a76\n", "abstract": " \u5bf9\u81ea\u7136\u8bed\u8a00\u5904\u7406\u7814\u7a76\u4e2d\u7684\u590d\u8ff0\u7684\u7814\u7a76\u73b0\u72b6\u4e0e\u8fdb\u5c55\u8fdb\u884c\u4e86\u603b\u7ed3, \u5206\u522b\u4ecb\u7ecd\u4e86\u590d\u8ff0\u7684\u5e94\u7528, \u590d\u8ff0\u8d44\u6e90\u7684\u83b7\u53d6, \u590d\u8ff0\u53e5\u7684\u751f\u6210, \u590d\u8ff0\u7684\u8bc4\u6d4b\u4ee5\u53ca\u4e0e\u590d\u8ff0\u7d27\u5bc6\u8054\u7cfb\u7684\u76f8\u5173\u7814\u7a76\u7b49. \u91cd\u5728\u5bf9\u590d\u8ff0\u7814\u7a76\u7684\u4e3b\u6d41\u65b9\u6cd5\u548c\u524d\u6cbf\u8fdb\u5c55\u8fdb\u884c\u6982\u62ec, \u6bd4\u8f83\u548c\u5206\u6790, \u4ee5\u671f\u5bf9\u540e\u7eed\u7814\u7a76\u6709\u6240\u52a9\u76ca.", "num_citations": "12\n", "authors": ["1179"]}
{"title": "Bilingual sentence alignment method based on sentence length and location information [J]\n", "abstract": " This paper describes a new method for aligning real bilingual texts using sentence pairs' length and location information. The model was motivated by the observation that the location of a sentence pair with certain length is distributed in the whole text similarly. It uses (1: 1) sentence beads instead of high frequency words as the candidate anchors to make the method general. The method was developed and evaluated through many different test data. The results show that it can achieve good aligned performance and be robust and language independent. It can resolve the alignment problem on real bilingual text.", "num_citations": "12\n", "authors": ["1179"]}
{"title": "\u590d\u8ff0\u6280\u672f\u7814\u7a76\u7efc\u8ff0\n", "abstract": " (\u54c8\u5c14\u6ee8\u5de5\u4e1a\u5927\u5b66\u8ba1\u7b97\u673a\u5b66\u9662\u4fe1\u606f\u68c0\u7d22\u7814\u7a76\u5ba4, \u9ed1\u9f99\u6c5f\u54c8\u5c14\u6ee8 150001) \u6458\u8981: \u590d\u8ff0\u662f\u81ea\u7136\u8bed\u8a00\u4e2d\u6bd4\u8f83\u666e\u904d\u7684\u4e00\u4e2a\u73b0\u8c61, \u5b83\u96c6\u4e2d\u53cd\u6620\u4e86\u8bed\u8a00\u7684\u591a\u6837\u6027. \u590d\u8ff0\u7814\u7a76\u7684\u5bf9\u8c61\u4e3b\u8981\u662f\u77ed\u8bed\u6216\u8005\u53e5\u5b50\u7684\u540c\u4e49\u73b0\u8c61. \u81ea\u7136\u8bed\u8a00\u5904\u7406\u5404\u79cd\u5e95\u5c42\u6280\u672f\u7684\u4e0d\u65ad\u53d1\u5c55\u548c\u6210\u719f, \u4e3a\u590d\u8ff0\u7814\u7a76\u63d0\u9ad8\u4e86\u53ef\u80fd, \u4f7f\u4e4b\u53d7\u5230\u8d8a\u6765\u8d8a\u591a\u7684\u5173\u6ce8. \u5728\u82f1\u6587\u548c\u65e5\u6587\u65b9\u9762, \u590d\u8ff0\u6280\u672f\u5df2\u7ecf\u88ab\u6210\u529f\u7684\u5e94\u7528\u5230\u4fe1\u606f\u68c0\u7d22, \u81ea\u52a8\u95ee\u7b54, \u4fe1\u606f\u62bd\u53d6, \u81ea\u52a8\u6587\u6458\u4ee5\u53ca\u673a\u5668\u7ffb\u8bd1\u7b49\u591a\u4e2a\u9886\u57df, \u6709\u6548\u5730\u63d0\u9ad8\u4e86\u7cfb\u7edf\u7684\u6027\u80fd. \u672c\u6587\u4e3b\u8981\u5bf9\u590d\u8ff0\u5b9e\u4f8b\u5e93\u7684\u6784\u5efa, \u590d\u8ff0\u89c4\u5219\u7684\u62bd\u53d6\u4ee5\u53ca\u590d\u8ff0\u7684\u751f\u6210\u7b49\u51e0\u65b9\u9762\u7684\u6700\u65b0\u7814\u7a76\u8fdb\u5c55\u8fdb\u884c\u8be6\u7ec6\u7684\u7efc\u8ff0, \u5e76\u7b80\u8981\u4ecb\u7ecd\u4e86\u6211\u4eec\u5728\u4e2d\u6587\u590d\u8ff0\u65b9\u9762\u8fdb\u884c\u7684\u521d\u6b65\u7814\u7a76\u5de5\u4f5c. \u5728\u6587\u7ae0\u7684\u6700\u540e\u4e00\u90e8\u5206, \u6211\u4eec\u5bf9\u590d\u8ff0\u6280\u672f\u7684\u96be\u70b9\u53ca\u672a\u6765\u7684\u53d1\u5c55\u65b9\u5411\u8fdb\u884c\u4e86\u5c55\u671b, \u5e76\u5bf9\u5168\u6587\u8fdb\u884c\u4e86\u603b\u7ed3.", "num_citations": "12\n", "authors": ["1179"]}
{"title": "A data driven approach to interactive question answering\n", "abstract": " HITIQA is an interactive question answering technology designed to allow intelligence analysts and other users of information systems to pose questions in natural language and obtain relevant answers, or the assistance they require in order to perform their tasks. Our objective in HITIQA is to allow the user to submit exploratory, analytical questions, such as \u201cWhat has been Russia\u2019s reaction to US bombing of Kosovo?\u201d The distinguishing property of such questions is that one cannot generally anticipate what might constitute the answer. While certain types of things may be expected (eg, diplomatic statements), the answer is heavily conditioned by what information is in fact available on the topic. From a practical viewpoint, analytical questions are often underspecified, thus casting a broad net on a space of possible answers. Therefore, clarification dialogue is often needed to negotiate with the user the exact scope and intent of the question.", "num_citations": "12\n", "authors": ["1179"]}
{"title": "Encoding Distributional Semantics into Triple-Based Knowledge Ranking for Document Enrichment\n", "abstract": " Document enrichment focuses on retrieving relevant knowledge from external resources, which is essential because text is generally replete with gaps. Since conventional work primarily relies on special resources, we instead use triples of Subject, Predicate, Object as knowledge and incorporate distributional semantics to rank them. Our model first extracts these triples automatically from raw text and converts them into real-valued vectors based on the word semantics captured by Latent Dirichlet Allocation. We then represent these triples, together with the source document that is to be enriched, as a graph of triples, and adopt a global iterative algorithm to propagate relevance weight from source document to these triples so as to select the most relevant ones. Evaluated as a ranking problem, our model significantly outperforms multiple strong baselines. Moreover, we conduct a task-based evaluation by incorporating these triples as additional features into document classification and enhances the performance by 3.02%.", "num_citations": "11\n", "authors": ["1179"]}
{"title": "\u878d\u5408\u591a\u7c7b\u7279\u5f81\u7684 Web \u67e5\u8be2\u610f\u56fe\u8bc6\u522b\n", "abstract": " \u8bc6\u522b\u641c\u7d22\u5f15\u64ce\u7528\u6237\u7684\u67e5\u8be2\u610f\u56fe\u5728\u4fe1\u606f\u68c0\u7d22\u9886\u57df\u662f\u5907\u53d7\u5173\u6ce8\u7684\u7814\u7a76\u5185\u5bb9. \u6587\u4e2d\u63d0\u51fa\u4e00\u79cd\u878d\u5408\u591a\u7c7b\u7279\u5f81\u8bc6\u522b Web \u67e5\u8be2\u610f\u56fe\u7684\u65b9\u6cd5. \u5c06 Web \u67e5\u8be2\u610f\u56fe\u8bc6\u522b\u4f5c\u4e3a\u4e00\u4e2a\u5206\u7c7b\u95ee\u9898, \u5e76\u4ece\u4e0d\u540c\u7c7b\u578b\u7684\u8d44\u6e90\u5305\u62ec\u67e5\u8be2\u6587\u672c, \u641c\u7d22\u5f15\u64ce\u8fd4\u56de\u5185\u5bb9\u53ca Web \u67e5\u8be2\u65e5\u5fd7\u4e2d\u62bd\u53d6\u51fa\u6709\u6548\u7684\u5206\u7c7b\u7279\u5f81. \u5728\u4eba\u5de5\u6807\u6ce8\u7684\u771f\u5b9e Web \u67e5\u8be2\u8bed\u6599\u4e0a\u91c7\u7528\u6587\u4e2d\u65b9\u6cd5\u8fdb\u884c\u67e5\u8be2\u610f\u56fe\u8bc6\u522b\u5b9e\u9a8c, \u5b9e\u9a8c\u7ed3\u679c\u663e\u793a\u6587\u4e2d\u91c7\u7528\u7684\u5404\u7c7b\u7279\u5f81\u5bf9\u4e8e\u63d0\u9ad8\u67e5\u8be2\u610f\u56fe\u8bc6\u522b\u7684\u6548\u679c\u7686\u6709\u4e00\u5b9a\u5e2e\u52a9, \u7efc\u5408\u4f7f\u7528\u8fd9\u4e9b\u7279\u5f81\u8fdb\u884c\u67e5\u8be2\u610f\u56fe\u8bc6\u522b, 88.5% \u7684\u6d4b\u8bd5\u67e5\u8be2\u83b7\u5f97\u51c6\u786e\u7684\u610f\u56fe\u8bc6\u522b\u7ed3\u679c.", "num_citations": "11\n", "authors": ["1179"]}
{"title": "Enriching smt training data via paraphrasing\n", "abstract": " This paper proposes a novel method to resolve the coverage problem of SMT system. The method generates paraphrases for source-side sentences of the bilingual parallel data, which are then paired with the target-side sentences to generate new parallel data. Within a statistical paraphrase generation framework, we employ an object function, named Sentence Novelty, to select paraphrases which having the most novel information to the bilingual training corpus of the SMT model. Meanwhile, the context is considered via a language model in the source language to ensure the fluency and accuracy of paraphrase substitution. Compared to a state-of-the-art phrase based SMT system (Moses), our method achieves an improvement of 1.66 points in terms of BLEU on a small training corpus which simulates a resource-poor environment, and 1.06 points on a training corpus of medium size.", "num_citations": "11\n", "authors": ["1179"]}
{"title": "\u97f3\u4e50\u9886\u57df\u5178\u578b\u4e8b\u4ef6\u62bd\u53d6\u65b9\u6cd5\u7814\u7a76\n", "abstract": " \u6458! \u8981\" \u00e0\u00e1\u00e2\u00e34\u00de\u00df\u00e2\u00e3\u00e4\u00e52 \u00e6\u00a6'()*'fd\u00e7\u00e8\u00e9\u00e4\u00e5'\u00e0\u00e1\u00e2\u00e3a! xy\u00e4\u00e5\u00e0\u00e1\u00ea\u00eb3'*+\u00a3\u00a4{\u00e8\u00e9\u00e4\u00e5tN\u00ecw'\u00e0\u00e1! \u00ed\u00eeQ. 56 \u00ea\u00ef\u00f0\u00ea\u00f1\u00ac'y\u00f2*+ \u00f3? \u00e0\u00e13\u00f4'\u00f5 y:'h\u00e0\u00e1\u00f6\u00f7 \u00f5,! fdQ. 56/V\u00f8'\u00e0\u00e1\u00f6\u00f7 \u00f5*+'hfd\u00ba\u00f9'! RX\u00fa!/\u00fb\u00e0\u00e1 3\u00f4\u00f5'\u00fc\u00fd-\u00fe\u00ff \u5230 C!: C! b! \u00e0\u00e1\u00f6\u00f7 \u00f5'\u00fc\u00fd-\u00fe\u00ff \u5230 A\": A? b'", "num_citations": "11\n", "authors": ["1179"]}
{"title": "Using word sense disambiguation for semantic role labeling\n", "abstract": " Word sense disambiguation (WSD) is the process of identifying the correct meaning, or sense of a word in a given context. Semantic role labeling (SRL) aims at identifying the relations between predicates in a sentence and their associated arguments. They are two fundamental tasks in natural language processing to find a sentence-level semantic representation. To date, they have mostly been modeled in isolation. However, this approach neglects logical constraints between them. In this work, we present some novel word sense features for SRL and find that they can improve the performance significantly. Later, we exploit pipeline strategies which verify the automatic all word sense disambiguation could help the semantic role labeling and vice versa. We further propose a Markov logic model that jointly labels semantic roles and disambiguates all word senses. We show that this joint approach leads to a higher\u00a0\u2026", "num_citations": "11\n", "authors": ["1179"]}
{"title": "\u57fa\u4e8e\u6d45\u5c42\u8bed\u4e49\u6811\u6838\u7684\u9605\u8bfb\u7406\u89e3\u7b54\u6848\u53e5\u62bd\u53d6\n", "abstract": " \u9605\u8bfb\u7406\u89e3\u7cfb\u7edf\u662f\u901a\u8fc7\u5bf9\u4e00\u7bc7\u81ea\u7136\u8bed\u8a00\u6587\u672c\u7684\u5206\u6790\u7406\u89e3, \u5bf9\u7528\u6237\u6839\u636e\u8be5\u6587\u672c\u6240\u63d0\u7684\u95ee\u9898, \u81ea\u52a8\u62bd\u53d6\u6216\u8005\u751f\u6210\u7b54\u6848. \u672c\u6587\u63d0\u51fa\u4e00\u79cd\u5229\u7528\u6d45\u5c42\u8bed\u4e49\u4fe1\u606f\u7684\u82f1\u6587\u9605\u8bfb\u7406\u89e3\u62bd\u53d6\u65b9\u6cd5, \u9996\u5148\u5c06\u95ee\u9898\u548c\u6240\u6709\u5019\u9009\u53e5\u7684\u8bed\u4e49\u89d2\u8272\u6807\u6ce8\u7ed3\u679c\u8868\u793a\u6210\u6811\u72b6\u7ed3\u6784, \u7528\u6811\u6838 (tree kernel) \u7684\u65b9\u6cd5\u8ba1\u7b97\u95ee\u9898\u548c\u6bcf\u4e2a\u5019\u9009\u53e5\u4e4b\u95f4\u7684\u8bed\u4e49\u7ed3\u6784\u76f8\u4f3c\u5ea6, \u5c06\u8be5\u76f8\u4f3c\u5ea6\u503c\u548c\u8bcd\u888b\u65b9\u6cd5\u83b7\u5f97\u7684\u8bcd\u5339\u914d\u6570\u878d\u5408\u5728\u4e00\u8d77, \u9009\u62e9\u5177\u6709\u6700\u9ad8\u5206\u503c\u7684\u5019\u9009\u53e5\u4f5c\u4e3a\u6700\u7ec8\u7684\u7b54\u6848\u53e5. \u5728 Remedia \u6d4b\u8bd5\u8bed\u6599\u4e0a, \u672c\u6587\u65b9\u6cd5\u53d6\u5f97 43. 3% \u7684 HumSent \u51c6\u786e\u7387.", "num_citations": "11\n", "authors": ["1179"]}
{"title": "Chinese unknown word identification based on local bigram model\n", "abstract": " This paper presents a Chinese unknown word identification system based on  a local bigram model. Generally, our word segmentation system employs a  statistical-based unigram model. But to identify those unknown words, we  take advantage of their contextual information and apply a bigram model  locally. By adjusting the value of interpolation which is derived from a  smoothing method, we combine these two models with different dimensions.  As a simplification of bigram, this method is simple as well as feasible,  since the complexity of its algorithm is quite low and not so many training  corpora are needed. The results of our experiments show the solution is effective.", "num_citations": "11\n", "authors": ["1179"]}
{"title": "Research on multi-document summarization based on latent semantic indexing\n", "abstract": " A multi-document summarization method based on Latent Semantic Indexing (LSI) is proposed. The method combines several reports on the same issue into a matrix of terms and sentences, and uses a Singular Value Decomposition (SVD) to reduce the dimension of the matrix and extract features, and then the sentence similarity is computed. The sentences are clustered according to similarity of sentences. The centroid sentences are selected from each class. Finally, the selected sentences are ordered to generate the summarization. The evaluation and results are presented, which prove that the proposed methods are efficient.", "num_citations": "11\n", "authors": ["1179"]}
{"title": "HMM \u4e0e\u81ea\u52a8\u89c4\u5219\u63d0\u53d6\u76f8\u7ed3\u5408\u7684\u4e2d\u6587\u547d\u540d\u5b9e\u4f53\u8bc6\u522b\n", "abstract": " \u672c\u6587\u5b9e\u73b0\u7684\u4e2d\u6587\u547d\u540d\u5b9e\u4f53\u8bc6\u522b\u7cfb\u7edf\u91c7\u7528\u4e86\u9690\u9a6c\u5c14\u53ef\u592b\u6a21\u578b (Hidden MarkovMode1, HMM) \u4e0e\u81ea\u52a8\u89c4\u5219\u63d0\u53d6\u76f8\u7ed3\u5408\u7684\u65b9\u6cd5. \u6574\u4e2a\u8bc6\u522b\u8fc7\u7a0b\u53ef\u4ee5\u5206\u4e3a\u4e24\u4e2a\u6b65\u9aa4, \u9996\u5148\u4f7f\u7528 HMM \u8bc6\u522b, \u7136\u540e\u518d\u5229\u7528\u81ea\u52a8\u63d0\u53d6\u7684\u89c4\u5219\u5bf9\u8bc6\u522b\u7ed3\u679c\u8fdb\u884c\u4fee\u6b63. \u4e8c\u8005\u7684\u6709\u673a\u7ed3\u5408\u4f7f\u5f97\u7cfb\u7edf\u6027\u80fd\u6709\u4e86\u5f88\u5927\u7684\u63d0\u9ad8. \u5b9e\u9a8c\u8868\u660e, \u4e2d\u6587\u547d\u540d\u5b9e\u4f53\u8bc6\u522b\u603b\u7684\u7cbe\u786e\u7387, \u53ec\u56de\u7387\u548c F \u4f4d\u5206\u522b\u8fbe\u5230\u4e86 86.93%, 83.69%,", "num_citations": "11\n", "authors": ["1179"]}
{"title": "\u53e5\u5b50\u76f8\u4f3c\u5ea6\u8ba1\u7b97\u5728 FAQ \u4e2d\u7684\u5e94\u7528\n", "abstract": " \u672c\u6587\u8bbe\u8ba1\u5e76\u5b9e\u73b0\u4e86\u4e00\u4e2a\u57fa\u4e8e\u5e38\u95ee\u95ee\u9898\u5e93\u7684\u4e2d\u6587\u95ee\u7b54\u7cfb\u7edf. \u5bf9\u7528\u6237\u4ee5\u81ea\u7136\u8bed\u8a00\u8f93\u5165\u7684\u95ee\u9898, \u8be5\u7cfb\u7edf\u80fd\u591f\u81ea\u52a8\u5730\u5728 FAQ (Frequenty-Asked Question) \u5e93\u4e2d\u5bfb\u627e\u5019\u9009\u95ee\u9898\u96c6, \u901a\u8fc7\u8ba1\u7b97\u53e5\u5b50\u76f8\u4f3c\u5ea6, \u5c06\u5339\u914d\u7684\u7b54\u6848\u8fd4\u56de\u7ed9\u7528\u6237. \u8be5\u7cfb\u7edf\u8fd8\u80fd\u591f\u81ea\u52a8\u5730\u66f4\u65b0\u548c\u7ef4\u62a4 FAQ \u5e93. \u6587\u4e2d\u7740\u91cd\u4ecb\u7ecd\u4e86\u7528\u4e8e\u67e5\u627e\u5019\u9009\u95ee\u9898\u96c6\u7684\u6570\u636e\u7ed3\u6784\u4ee5\u53ca\u53e5\u5b50\u76f8\u4f3c\u5ea6\u7684\u8ba1\u7b97\u65b9\u6cd5.", "num_citations": "11\n", "authors": ["1179"]}
{"title": "\u4e2d\u6587\u81ea\u52a8\u6821\u5bf9\u7cfb\u7edf\u7684\u7814\u7a76\u4e0e\u5b9e\u73b0\n", "abstract": " \u63d0\u51fa\u4e86\u4e00\u79cd\u8bcd\u5339\u914d\u548c\u8bed\u6cd5\u5206\u6790\u76f8\u7ed3\u5408\u7684\u4e2d\u6587\u6587\u672c\u81ea\u52a8\u6821\u5bf9\u6cd5,\u91c7\u7528\u89c4\u5219\u4e0e\u7edf\u8ba1\u76f8\u7ed3\u5408\u7684\u65b9\u6cd5,\u4e0d\u4f7f\u7528\u5927\u89c4\u6a21\u8bed\u6599\u5e93;\u800c\u4e14\u6839\u636e\u539f\u6587\u7684\u8f93\u5165\u65b9\u5f0f,\u7528\u9006\u5411\u6700\u5927\u5339\u914d\u548c\u5c40\u90e8\u8bed\u6599\u7edf\u8ba1\u7684\u7b97\u6cd5,\u627e\u51fa\u6563\u4e32,\u901a\u8fc7\u8bcd\u5339\u914d\u548c\u8bed\u6cd5\u5206\u6790\u5904\u7406\u6563\u4e32,\u5f97\u5230\u9519\u8bef\u4e32\u7684\u5019\u9009\u4e32,\u901a\u8fc7\u4eba\u673a\u4ea4\u4e92\u7684\u65b9\u6cd5\u5bf9\u9519\u8bef\u4e32\u8fdb\u884c\u81ea\u52a8\u6821\u6b63. \u5b9e\u9a8c\u8868\u660e,\u7cfb\u7edf\u7684\u67e5\u9519\u7387\u8fbe80%\u4ee5\u4e0a,\u8bef\u62a5\u7387\u57285%\u5de6\u53f3,\u57fa\u672c\u6ee1\u8db3\u4e86\u5e94\u7528\u8981\u6c42.", "num_citations": "11\n", "authors": ["1179"]}
{"title": "\u81ea\u52a8\u6587\u6458\u7efc\u8ff0\n", "abstract": " \u672c\u6587\u56de\u987e\u4e86\u81ea\u52a8\u6587\u6458\u6280\u672f\u7684\u53d1\u5c55\u5386\u53f2, \u4ecb\u7ecd\u4e86\u4e09\u79cd\u4e3b\u8981\u7684\u6587\u6458\u65b9\u6cd5, \u5373\u57fa\u4e8e\u6587\u672c\u7269\u7406\u4fe1\u606f\u5206\u6790\u7684\u65b9\u6cd5, \u57fa\u4e8e\u81ea\u7136\u8bed\u8a00\u7406\u89e3\u7684\u65b9\u6cd5\u4ee5\u53ca\u57fa\u4e8e\u6587\u672c\u7ed3\u6784\u5206\u6790\u7684\u65b9\u6cd5. \u540c\u65f6\u6307\u51fa\u4e86\u81ea\u52a8\u6587\u6458\u6280\u672f\u76ee\u524d\u5b58\u5728\u7684\u95ee\u9898, \u5305\u62ec\u6458\u8981\u5185\u5bb9\u5197\u4f59\u7684\u95ee\u9898, \u6458\u8981\u7684\u8bed\u8a00\u7f3a\u4e4f\u8fde\u8d2f\u6027\u7684\u95ee\u9898\u7b49, \u5e76\u63a2\u8ba8\u4e86\u6587\u6458\u6280\u672f\u672a\u6765\u7684\u53d1\u5c55\u65b9\u5411.", "num_citations": "11\n", "authors": ["1179"]}
{"title": "Transforming Wikipedia into Augmented Data for Query-Focused Summarization\n", "abstract": " The manual construction of a query-focused summarization corpus is costly and timeconsuming. The limited size of existing datasets renders training data-driven summarization models challenging. In this paper, we use Wikipedia to automatically collect a large query-focused summarization dataset (named as WIKIREF) of more than 280,000 examples, which can serve as a means of data augmentation. Moreover, we develop a query-focused summarization model based on BERT to extract summaries from the documents. Experimental results on three DUC benchmarks show that the model pre-trained on WIKIREF has already achieved reasonable performance. After fine-tuning on the specific datasets, the model with data augmentation outperforms the state of the art on the benchmarks.", "num_citations": "10\n", "authors": ["1179"]}
{"title": "Eeg: Knowledge base for event evolutionary principles and patterns\n", "abstract": " The evolution and development of events has its underlying principles, leading to events happened sequentially. Therefore, the discovery of such evolutionary patterns between events are of great value for event prediction, decision-making and scenario design of dialog system. In this paper, we propose Event Evolutionary Graph (EEG), which reveals evolutionary patterns and development logics between events. Specifically, we propose to construct EEG by recognizing the sequential relation between events and the direction of each sequential relation. For sequential relation and direction recognition, we explore the effectiveness of 4 categories of features: count-based, ratio-based, context-based and association-based features for correctly identifying sequential relations and corresponding directions. Experimental results show that (1) the framework we proposed is promising for EEG construction and (2\u00a0\u2026", "num_citations": "10\n", "authors": ["1179"]}
{"title": "A Gaussian copula regression model for movie box-office revenues prediction\n", "abstract": " In this article, we revisit the task of movie box-office revenues prediction using multi-type features. The movie box-office revenues are affected by numerous factors. Previous work with discriminative models assumes these factors are identically and independently distributed. The correlations between these factors are rarely considered, which limited the performances of discriminative models in this task. To address these problems, we investigate a novel Gaussian copula regression model. Based on this model, we do not need to make any prior assumptions about the marginal distributions of the features. In particular, we perform a cumulative probability estimation on each of the smoothed features. The estimation learns the marginal distributions and maps all features into a uniform vector space. Sequentially, we bridge the marginal distributions with a copula function to create their joint distribution, and\u00a0\u2026", "num_citations": "10\n", "authors": ["1179"]}
{"title": "Triple based background knowledge ranking for document enrichment\n", "abstract": " Document enrichment is the task of retrieving additional knowledge from external resource over what is available through source document. This task is essential because of the phenomenon that text is generally replete with gaps and ellipses since authors assume a certain amount of background knowledge. The recovery of these gaps is intuitively useful for better understanding of document. Conventional document enrichment techniques usually rely on Wikipedia which has great coverage but less accuracy, or Ontology which has great accuracy but less coverage. In this study, we propose a document enrichment framework which automatically extracts \u201cargument1, predicate, argument2\u201d triple from any text corpus as background knowledge, so that to ensure the compatibility with any resource (eg news text, ontology, and on-line encyclopedia) and improve the enriching accuracy. We first incorporate source document and background knowledge together into a triple based document-level graph and then propose a global iterative ranking model to propagate relevance score and select the most relevant knowledge triple. We evaluate our model as a ranking problem and compute the MAP and P&N score to validate the ranking result. Our final result, a MAP score of 0.676 and P&20 score of 0.417 outperform a strong baseline based on search engine by 0.182 in MAP and 0.04 in P&20.", "num_citations": "10\n", "authors": ["1179"]}
{"title": "Clustering Product Aspects Using Two Effective Aspect Relations for Opinion Mining\n", "abstract": " Aspect recognition and clustering is important for many sentiment analysis tasks. To date, many algorithms for recognizing product aspects have been explored, however, limited work have been done for clustering the product aspects. In this paper, we focus on the problem of product aspect clustering. Two effective aspect relations: relevant aspect relation and irrelevant aspect relation are proposed to describe the relationships between two aspects. According to these two relations, we can explore many relevant and irrelevant aspects into two different sets as background knowledge to describe each product aspect. Then, a hierarchical clustering algorithm is designed to cluster these aspects into different groups, in which aspect similarity computation is conducted with the relevant aspect set and irrelevant aspect set of each product aspect. Experimental results on camera domain demonstrate that the\u00a0\u2026", "num_citations": "10\n", "authors": ["1179"]}
{"title": "\u4e2d\u6587\u7bc7\u7ae0\u7ea7\u53e5\u95f4\u8bed\u4e49\u5173\u7cfb\u8bc6\u522b\n", "abstract": " \u6458 \u8981\" $3; \u5173% \u8bc6\u522b $@ AHE9RCHB* B: DGA9L* BE9QLAGA9L% \u662f $ \u5206\u6790\u7684 RS-! \u8be5\u6587\u5bf9\u4e2d\u6587 $3; \u5173% \u8bc6\u522b \u8fdb\u884c \u6b65\u63a2 I!./\u663e\u5f0f $3; \u5173% \u8bc6\u522b\u4e0e \u5f0f $3; \u5173% \u8bc6\u522b\u4e24\u7c7b'\u9488\u5bf9\u663e\u5f0f $3; \u5173%! \u6211\u4eec\u63d0 i \u57fa\u4e8e\u5173< \u8bcd\u89c4\u5219\u7684\u65b9\u6cd5\u8fdb\u884c\u8bc6\u522b! \u53d6\u5f97\u4e86 \u7684\u6548\u679c (\u9488\u5bf9 \u5f0f $3; \u5173%! \u6211\u4eec \u53d6\u8bcd\u6c47* 3 \u6cd5* \u8bed\u4e49 B \u7279\u5f81! \u91c7\u7528\u6709\u6307\u5bfc\u6a21\u578b\u8fdb\u884c\u8bc6\u522b'\u8be5\u6587\u7684\u5206\u6790\u548c\u5b9e\u9a8c\u7ed3\u679c\u4e3a\u540e \u00ecW \u7a76\u63d0\u4f9b\u4e86\u53c2\u8003\u548c\u57fa & \u5bf9% \u7edf'", "num_citations": "10\n", "authors": ["1179"]}
{"title": "\u57fa\u4e8e\u5fae\u535a\u5206\u7c7b\u7684\u7528\u6237\u5174\u8da3\u8bc6\u522b\n", "abstract": " \u793e\u4f1a\u5a92\u4f53\u6210\u4e3a\u7528\u6237\u5206\u4eab\u4e0e\u83b7\u53d6\u4fe1\u606f\u7684\u91cd\u8981\u5e73\u53f0.\u53d1\u73b0\u611f\u5174\u8da3\u7684\u5fae\u535a\u8d26\u6237\u4e0e\u4fe1\u606f\u662f\u793e\u4ea4\u5a92\u4f53\u5e73\u53f0\u6700\u91cd\u8981\u7684\u6d3b\u52a8,\u5176\u5173\u952e\u95ee\u9898\u5728\u4e8e\u7528\u6237\u5174\u8da3\u6a21\u578b\u7684\u6784\u5efa.\u63d0\u51fa\u57fa\u4e8e\u5fae\u535a\u5206\u7c7b\u7684\u7528\u6237\u5174\u8da3\u8bc6\u522b\u65b9\u6cd5.\u9996\u5148\u4eba\u5de5\u6784\u5efa\u76ee\u6807\u5206\u7c7b\u4f53\u7cfb,\u57fa\u4e8e\u5178\u578b\u5fae\u535a\u8d26\u6237\u91c7\u96c6\u5fae\u535a\u8bad\u7ec3\u8bed\u6599\u8bad\u7ec3\u5fae\u535a\u5206\u7c7b\u5668,\u800c\u540e\u901a\u8fc7\u5bf9\u7528\u6237\u5fae\u535a\u8fdb\u884c\u5206\u7c7b\u8bc6\u522b\u51fa\u7528\u6237\u611f\u5174\u8da3\u7684\u7c7b\u522b.\u5b9e\u9a8c\u8868\u660e\u57fa\u4e8e\u5178\u578b\u4e3b\u9898\u7c7b\u522b\u5fae\u535a,\u7ed3\u5408\u8bcd\u8bed\u4e0e\u4e3b\u9898\u7684\u7279\u5f81\u53ef\u6709\u6548\u8fdb\u884c\u5fae\u535a\u5206\u7c7b\u8fbe\u523086%\u7684F\u503c,\u8f93\u51fa\u7684\u7c7b\u522b\u53ef\u51c6\u786e\u8868\u793a\u7528\u6237\u5174\u8da3.", "num_citations": "10\n", "authors": ["1179"]}
{"title": "Modeling leadership and influence in multi-party online discourse\n", "abstract": " In this article, we present a novel approach towards the detection and modeling of complex social phenomena in multi-party discourse, including leadership, influence, pursuit of power and group cohesion. We have developed a two-tier approach that relies on observable and computable linguistic features of conversational text to make predictions about sociolinguistic behaviors such as Topic Control and Disagreement, that speakers deploy in order to achieve and maintain certain positions and roles in a group. These sociolinguistic behaviors are then used to infer higher-level social phenomena such as Leadership and Influence, which is the focus of this paper. We show robust performance results by comparing our automatically computed results to participants\u2019 own perceptions and rankings. We use weights learnt from correlations with training examples known leadership and influence rankings of participants to optimize our models and to show performance significantly above baseline for two different languages\u2013English and Mandarin Chinese.", "num_citations": "10\n", "authors": ["1179"]}
{"title": "Multi-aspect query summarization by composite query\n", "abstract": " Conventional search engines usually return a ranked list of web pages in response to a query. Users have to visit several pages to locate the relevant parts. A promising future search scenario should involve:(1) understanding user intents;(2) providing relevant information directly to satisfy searchers' needs, as opposed to relevant pages. In this paper, we present a search paradigm to summarize a query's information from different aspects. Query aspects could be aligned to user intents. The generated summaries for query aspects are expected to be both specific and informative, so that users can easily and quickly find relevant information. Specifically, we use a Composite Query for Summarization\" method, where a set of component queries are used for providing additional information for the original query. The system leverages the search engine to proactively gather information by submitting multiple component\u00a0\u2026", "num_citations": "10\n", "authors": ["1179"]}
{"title": "HIT Approaches to Entity Linking at TAC 2011.\n", "abstract": " This paper describes the system of HIT at the 2011 Text Analysis Conference (TAC) Knowledge Base Population (KBP) track English Entity Linking task. Based on structured and unstructured information extracted from Wikipedia, this system predicts the most probable entity that a query mention might refer to. A similarity score is assigned to the candidate entity by computing the the relatedness between the query and the entity, and augmented by the popularity of the entity. We model the query context as a graph of the entities and utilize the referential relationship between the context entities and the candidate entities in Wikipedia to measure the relatedness between the query context and the candidate entity. E-valuation results show the performance of our system reaches the median value of all the participating systems.", "num_citations": "10\n", "authors": ["1179"]}
{"title": "\u77ed\u8bed\u7ed3\u6784\u6811\u5e93\u5411\u4f9d\u5b58\u7ed3\u6784\u6811\u5e93\u8f6c\u5316\u7814\u7a76\n", "abstract": " \u6c49\u8bed\u4f9d\u5b58\u6811\u5e93\u7684\u5efa\u8bbe\u76f8\u5bf9\u5176\u4ed6\u8bed\u8a00\u5982\u82f1\u8bed, \u5728\u89c4\u6a21\u548c\u8d28\u91cf\u4e0a\u8fd8\u6709\u4e00\u4e9b\u5dee\u8ddd. \u6811\u5e93\u6807\u6ce8\u9700\u8981\u4ed8\u51fa\u5f88\u5927\u7684\u4eba\u529b\u7269\u529b, \u5e76\u4e14\u4fdd\u8bc1\u6811\u5e93\u8d28\u91cf\u4e5f\u6bd4\u8f83\u56f0\u96be. \u8be5\u6587\u5c1d\u8bd5\u901a\u8fc7\u89c4\u5219\u548c\u7edf\u8ba1\u76f8\u7ed3\u5408\u7684\u65b9\u6cd5, \u5c06\u5bbe\u5dde\u6c49\u8bed\u77ed\u8bed\u6811\u5e93 Penn Chinese Treebank \u8f6c\u5316\u4e3a\u54c8\u5de5\u5927\u4f9d\u5b58\u6811\u5e93 HIT2IR2CD T \u7684\u4f53\u7cfb\u7ed3\u6784, \u4ece\u800c\u589e\u5927\u73b0\u6709\u4f9d\u5b58\u6811\u5e93\u7684\u89c4\u6a21. \u5c06\u8f6c\u5316\u540e\u7684\u6811\u5e93\u52a0\u5165 HIT2IR2CD T, \u8bad\u7ec3\u548c\u6d4b\u8bd5\u4f9d\u5b58\u53e5\u6cd5\u5206\u6790\u5668\u7684\u6027\u80fd. \u5b9e\u9a8c\u8868\u660e, \u52a0\u5165\u5c11\u91cf\u7ecf\u8f6c\u5316\u540e\u7684\u6811\u5e93\u540e, \u4f9d\u5b58\u53e5\u6cd5\u5206\u6790\u5668\u7684\u6027\u80fd\u6709\u6240\u63d0\u9ad8; \u4f46\u52a0\u5165\u5927\u91cf\u6811\u5e93\u540e, \u6027\u80fd\u53cd\u800c\u4e0b\u964d. \u7ecf\u8fc7\u7ec6\u81f4\u5206\u6790, \u4f5c\u4e3a\u4e00\u79cd\u5229\u7528\u591a\u79cd\u6811\u5e93\u63d0\u9ad8\u4f9d\u5b58\u53e5\u6cd5\u5206\u6790\u5668\u6027\u80fd\u7684\u65b9\u6cd5, \u77ed\u8bed\u8f6c\u4f9d\u5b58\u8fd8\u5b58\u5728\u5f88\u591a\u9700\u8981\u6df1\u5165\u7814\u7a76\u7684\u65b9\u9762.", "num_citations": "10\n", "authors": ["1179"]}
{"title": "A topical document clustering method\n", "abstract": " Few of the existing document clustering methods can detect or describe document topics properly, which makes it difficult to conduct clustering based on topics. In this paper, we introduce a novel topical document clustering method called Linguistic Features Indexing Clustering (LFIC), which can identify topics accurately and cluster documents according to these topics. In LFIC,\u201ctopic elements\u201d are de\ufb01ned and extracted for indexing base clusters. Additionally, linguistic features are investigated and exploited. Experimental results show that LFIC can gain a higher precision (94.66%) than some widely used traditional clustering methods.", "num_citations": "10\n", "authors": ["1179"]}
{"title": "A fast clustering algorithm for abnormal and short texts\n", "abstract": " This paper discusses mainly about the short texts, which occurs on mobile short messages and chat rooms. Because of their irregular style and similarity, we call them abnormal texts. We propose an efficient clustering algorithm based on the duplication information deletion algorithm. It concerns about the features of the abnormal short texts and takes some special methods such as extracting feature code and compressing code to solve this problem. Experiments show that the clustering system based on this algorithm can depose millions of abnormal short texts per hour with high accuracy.", "num_citations": "10\n", "authors": ["1179"]}
{"title": "LTP: \u8bed\u8a00\u6280\u672f\u5e73\u53f0\n", "abstract": " \u672c\u6587\u63cf\u8ff0\u4e86\u4e00\u5957\u9762\u5411 Web \u57fa\u4e8e XML \u7684\u4e2d\u6587\u8bed\u8a00\u5904\u7406\u5e73\u53f0, \u547d\u540d\u4e3a \u201c\u8bed\u8a00\u6280\u672f\u5e73\u53f0 LTP\u201d. LTP \u5305\u542b 5 \u9879\u4e3b\u8981\u5185\u5bb9: \u8bed\u8a00\u6280\u672f\u7f6e\u6807\u8bed\u8a00 LTML, \u57fa\u4e8e DOM Tree \u7684\u4e00\u5957 DLL \u6a21\u5757, \u4e00\u5957\u53ef\u89c6\u5316\u5de5\u5177, \u57fa\u4e8e LTML \u7684\u8bed\u6599\u5e93\u8d44\u6e90, \u4ee5\u53ca\u57fa\u4e8e Web Service \u7684\u7f51\u7edc\u5e94\u7528. \u76ee\u524d LTP \u96c6\u6210\u4e86\u8bcd\u6cd5, \u8bcd\u4e49, \u53e5\u6cd5, \u8bed\u4e49, \u7bc7\u7ae0\u5206\u6790\u7b49 10 \u9879\u4e2d\u6587\u5904\u7406\u6838\u5fc3\u6280\u672f. \u8be5\u5e73\u53f0\u5c06\u4e3a\u81ea\u7136\u8bed\u8a00\u5904\u7406\u53ca\u4fe1\u606f\u68c0\u7d22\u9886\u57df\u7684\u7814\u7a76\u8005\u63d0\u4f9b\u4e00\u5957\u7cfb\u7edf\u5316\u5de5\u5177, \u5e2e\u52a9\u4ed6\u4eec\u6df1\u5165\u7814\u7a76\u8bed\u8a00\u5404\u4e2a\u5c42\u9762\u4e4b\u95f4\u7684\u5173\u7cfb\u5e76\u4e14\u5229\u7528\u8fd9\u4e9b\u57fa\u7840\u6280\u672f\u53bb\u7814\u7a76\u4e00\u4e9b\u9ad8\u7ea7\u5e94\u7528\u8bdd\u9898.", "num_citations": "10\n", "authors": ["1179"]}
{"title": "\u795e\u7ecf\u7f51\u7edc\u548c\u8d1d\u53f6\u65af\u7f51\u7edc\u5728\u6c49\u8bed\u8bcd\u4e49\u6d88\u6b67\u4e0a\u7684\u5bf9\u6bd4\u7814\u7a76\n", "abstract": " \u795e\u7ecf\u7f51\u7edc\u548c\u8d1d\u53f6\u65af\u7f51\u7edc\u662f\u4e24\u79cd\u7ecf\u5178\u7684\u673a\u5668\u5b66\u4e60\u65b9\u6cd5.\u672c\u6587\u901a\u8fc7\u5b9e\u9a8c\u8003\u5bdf\u4e86\u8fd9\u4e24\u79cd\u7f51\u7edc\u6a21\u578b\u5728\u6c49\u8bed\u8bcd\u4e49\u6d88\u6b67\u4e0a\u7684\u5e94\u7528\u6548\u679c.\u5b9e\u9a8c\u5bf9\u8c61\u662f\u901a\u8fc7\u7279\u5b9a\u89c4\u5219\u6784\u9020\u76846\u4e2a\u4f2a\u8bcd.\u4f7f\u7528\u4f2a\u8bcd\u53ef\u4ee5\u907f\u514d\u6709\u6307\u5bfc\u7684\u8bcd\u4e49\u6d88\u6b67\u65b9\u6cd5\u4e2d\u7684\u6570\u636e\u7a00\u758f\u95ee\u9898,\u5145\u5206\u9a8c\u8bc1\u8bcd\u4e49\u5206\u7c7b\u5668\u7684\u5b9e\u9a8c\u6548\u679c.\u8d1d\u53f6\u65af\u7f51\u7edc\u7528\u4e8e\u8bcd\u4e49\u5206\u7c7b\u7b80\u5355\u9ad8\u6548,\u6a21\u578b\u5bb9\u6613\u6784\u9020,\u800c\u795e\u7ecf\u7f51\u7edc\u7684\u7ed3\u6784\u5219\u76f8\u5bf9\u590d\u6742,\u7528\u4e8e\u8bcd\u4e49\u6d88\u6b67\u9700\u8981\u5148\u89e3\u51b3\u8f93\u5165\u95ee\u9898.\u5b9e\u9a8c\u4e2d\u91c7\u7528\u8bcd\u95f4\u4e92\u4fe1\u606f\u6210\u529f\u6784\u9020\u4e86\u795e\u7ecf\u7f51\u7edc\u7684\u8f93\u5165\u6a21\u578b,\u5b9e\u9a8c\u6548\u679c\u8f83\u4e3a\u7406\u60f3.\u5b9e\u9a8c\u6570\u636e\u8868\u660e\u8d1d\u53f6\u65af\u7f51\u7edc\u6bd4\u795e\u7ecf\u7f51\u7edc\u66f4\u9002\u5408\u89e3\u51b3\u6c49\u8bed\u8bcd\u4e49\u6d88\u6b67\u95ee\u9898.\u4f46\u8d1d\u53f6\u65af\u7f51\u7edc\u7684\u6297\u566a\u58f0\u80fd\u529b\u5374\u660e\u663e\u900a\u8272\u4e8e\u795e\u7ecf\u7f51\u7edc.", "num_citations": "10\n", "authors": ["1179"]}
{"title": "\u57fa\u4e8e\u5c40\u90e8\u4e3b\u9898\u5224\u5b9a\u4e0e\u62bd\u53d6\u7684\u591a\u6587\u6863\u6587\u6458\u6280\u672f\n", "abstract": " \u6458 \u8981 \u63d0\u51fa\u4e86\u4e00\u4e2a\u901a\u8fc7\u5bf9\u540c\u4e00\u4e3b\u9898\u7684\u591a\u6587\u6863\u96c6\u5408\u5185\u5c40\u90e8\u4e3b\u9898\u7684\u5224\u5b9a\u548c\u62bd\u53d6\u751f\u6210\u591a\u6587\u6863\u6587\u6458\u7684\u65b9\u6cd5. \u9996\u5148\u5728\u5bf9\u591a\u6587\u6863\u96c6\u5408\u4e2d\u53e5\u5b50\u4f9d\u5b58\u5206\u6790\u548c\u8bed\u4e49\u5206\u6790\u7684\u57fa\u7840\u4e0a\u8fdb\u884c\u76f8\u4f3c\u5ea6\u8ba1\u7b97, \u5c06\u76f8\u4f3c\u53e5\u5b50\u7ecf\u8fc7\u805a\u7c7b\u5f62\u6210\u591a\u6587\u6863\u96c6\u5408\u5185\u4e0d\u540c\u7684\u5c40\u90e8\u4e3b\u9898, \u7136\u540e\u8fdb\u884c\u6bcf\u4e2a\u5c40\u90e8\u4e3b\u9898\u4e2d\u8d28\u5fc3\u53e5\u7684\u62bd\u53d6\u548c\u6392\u5e8f, \u751f\u6210\u591a\u6587\u6863\u6587\u6458, \u8be5\u65b9\u6cd5\u5b9e\u73b0\u4e86\u6587\u6458\u957f\u5ea6\u968f\u6587\u6863\u5185\u5bb9\u81ea\u52a8\u786e\u5b9a, \u4ece\u800c\u4fdd\u8bc1\u4e86\u6587\u6458\u4e2d\u5305\u542b\u7684\u4fe1\u606f\u7684\u5168\u9762\u548c\u7b80\u6d01. \u6700\u540e\u6587\u4e2d\u8fd8\u7ed9\u51fa\u4e86\u591a\u6587\u6863\u6587\u6458\u7684\u8bc4\u4ef7\u65b9\u6cd5\u548c\u5b9e\u9a8c\u7ed3\u679c, \u6587\u6458\u7684\u5e73\u5747\u7cbe\u786e\u7387\u548c\u5e73\u5747\u538b\u7f29\u7387\u5206\u522b\u4e3a 71.4% \u548c 25.2%.", "num_citations": "10\n", "authors": ["1179"]}
{"title": "Detecting chinese text errors based on trigram and dependency parsing\n", "abstract": " Automatic proofreading opens up broad possibilities for the application of natural language processing. In this paper, n-gram is used to analyze the part of sentence and detect local errors, and experiments made with the different four methods show that character trigram is the best. Then dependency parsing is introduced into automatic proofreading and helps to detect collocation errors with long distance. Dependency grammar parses the whole sentence and denotes dominating and dominated relation among the words, efficiently filling up the deficiency of n-gram. Finally an ideal system of automatically detecting errors is obtained with processing separate string of text. Experiments show that our method achieves precision of 64 91% and recall of 69 05%.", "num_citations": "10\n", "authors": ["1179"]}
{"title": "English-chinese knowledge base translation with neural network\n", "abstract": " Knowledge base (KB) such as Freebase plays an important role for many natural language processing tasks. English knowledge base is obviously larger and of higher quality than low resource language like Chinese. To expand Chinese KB by leveraging English KB resources, an effective way is to translate English KB (source) into Chinese (target). In this direction, two major challenges are to model triple semantics and to build a robust KB translator. We address these challenges by presenting a neural network approach, which learns continuous triple representation with a gated neural network. Accordingly, source triples and target triples are mapped in the same semantic vector space. We build a new dataset for English-Chinese KB translation from Freebase, and compare with several baselines on it. Experimental results show that the proposed method improves translation accuracy compared with baseline methods. We show that adaptive composition model improves standard solution such as neural tensor network in terms of translation accuracy.", "num_citations": "9\n", "authors": ["1179"]}
{"title": "Exploiting multi-typed treebanks for parsing with deep multi-task learning\n", "abstract": " Various treebanks have been released for dependency parsing. Despite that treebanks may belong to different languages or have different annotation schemes, they contain syntactic knowledge that is potential to benefit each other. This paper presents an universal framework for exploiting these multi-typed treebanks to improve parsing with deep multi-task learning. We consider two kinds of treebanks as source: the multilingual universal treebanks and the monolingual heterogeneous treebanks. Multiple treebanks are trained jointly and interacted with multi-level parameter sharing. Experiments on several benchmark datasets in various languages demonstrate that our approach can make effective use of arbitrary source treebanks to improve target parsing models.", "num_citations": "9\n", "authors": ["1179"]}
{"title": "SocialRobot: a big data-driven humanoid intelligent system in social media services\n", "abstract": " The blooming of social media services makes them the attractive resources for publishing and seeking information (posting, reposting and searching tweets) as well as socializing and interacting with other users (following and messaging other users) in social media services. With the increasing number of users and the interacting frequency between users, tremendous user-generated contents are bursting out every day. Hence, users may face a overload of information. To address the above problem, in this paper, we present SocialRobot, a humanoid intelligent system that has been deployed in Sina Weibo. For its socialization characteristic, we naturally implement it as a virtual user in Sina Weibo. By following and interacting with SocialRobot, high-quality and user-interested content can be recommended to the users from the big social media data. And the need for searching specific information can be\u00a0\u2026", "num_citations": "9\n", "authors": ["1179"]}
{"title": "Mining intention-related products on online q&a community\n", "abstract": " User generated content on social media has attracted much attention from service/product providers, as it contains plenty of potential commercial opportunities. However, previous work mainly focuses on user consumption intention (CI) identification, and little effort has been spent to mine intention-related products. In this paper, focusing on the Baby & Child Care domain, we propose a novel approach to mine intention-related products on online question and answer (Q&A) community. Making use of the question-answering pairs as data source, we first automatically extract candidate products based on dependency parser. And then by means of the collocation extraction model, we identify the real intention-related products from the candidate set. The experimental results on our carefully constructed evaluation dataset show that our approach achieves better performance than two natural baseline methods.", "num_citations": "9\n", "authors": ["1179"]}
{"title": "Hit dependency parsing: Bootstrap aggregating heterogeneous parsers\n", "abstract": " The paper describes our system of Shared Task on Parsing the Web. We only participate in dependency parsing task. A number of methods have been developed for dependency parsing. Each of the methods adopts very different view of dependency parsing, and each view can have its strengths and limitations. Thus system combination can have great potential to further improve the performance of dependency parsing. In this work, Bootstrap Aggregating (Bagging) is chosen to combine these methods. This approach obtains significantly improvements for dependency parsing, and especially we achieves a UAS of 93.88%, LAS of 91.88% on WSJ domain, which is the top result of all participated systems. We tried to use unlabeled data offered by this task as well, and unfortunately we received little improvements through tri-training. Finally, our final bagging system ranked thirdly of the shared task.", "num_citations": "9\n", "authors": ["1179"]}
{"title": "A framework for personalized information retrieval model\n", "abstract": " Existing search engines ignore the user's search context and return results to the user solely based on their relevance value to the query. Hence, the need for personalized information retrieval system which takes into account the actual user's profile during the retrieval process is \u201cmandatory.\u201d In this paper, we propose a framework for personalized information retrieval model using user profiles. It incorporates the user profile module into the retrieval process to filter results returned by traditional search engine so that they meet the specific needs of the user.", "num_citations": "9\n", "authors": ["1179"]}
{"title": "\u57fa\u4e8e\u67f1\u641c\u7d22\u7684\u9ad8\u9636\u4f9d\u5b58\u53e5\u6cd5\u5206\u6790\n", "abstract": " \u8be5\u6587\u63d0\u51fa\u4f7f\u7528\u6240\u6709\u7684\u5b59\u5b50\u8282\u70b9\u6784\u6210\u7956\u5b59\u7279\u5f81\u7684\u9ad8\u9636\u4f9d\u5b58\u6a21\u578b, \u5e76\u4e14\u4f7f\u7528\u67f1\u641c\u7d22\u7b56\u7565\u9650\u5236\u641c\u7d22\u7a7a\u95f4, \u6700\u7ec8\u627e\u5230\u8fd1\u4f3c\u6700\u4f18\u4f9d\u5b58\u6811. \u53e6\u5916, \u8be5\u6587\u4ee5\u8f83\u5c0f\u7684\u65f6\u95f4\u590d\u6742\u5ea6\u4e3a\u4ee3\u4ef7, \u4f7f\u7528\u4e86\u4e30\u5bcc\u7684\u4f9d\u5b58\u5173\u7cfb\u7279\u5f81, \u5e76\u4e14\u5141\u8bb8\u6a21\u578b\u5728\u89e3\u7801\u7684\u8fc7\u7a0b\u4e2d\u8fdb\u884c\u4f9d\u5b58\u5173\u7cfb\u9009\u62e9. \u4f5c\u8005\u53c2\u52a0\u4e86 CoNLL 2009 \u5e74\u591a\u8bed\u4f9d\u5b58\u53e5\u6cd5\u5206\u6790\u548c\u8bed\u4e49\u89d2\u8272\u6807\u6ce8\u56fd\u9645\u8bc4\u6d4b, \u6700\u7ec8\u83b7\u5f97\u8054\u5408\u4efb\u52a1\u603b\u6210\u7ee9\u7b2c\u4e00\u540d, \u4f9d\u5b58\u53e5\u6cd5\u5206\u6790\u603b\u6210\u7ee9\u7b2c\u4e09\u540d.", "num_citations": "9\n", "authors": ["1179"]}
{"title": "\u96c6\u6210\u591a\u79cd\u80cc\u666f\u8bed\u4e49\u77e5\u8bc6\u7684\u5171\u6307\u6d88\u89e3\n", "abstract": " \u5171\u6307\u6d88\u89e3\u662f\u4fe1\u606f\u62bd\u53d6\u4e2d\u4e00\u4e2a\u91cd\u8981\u5b50\u4efb\u52a1. \u8fd1\u5e74\u6765, \u8bb8\u591a\u5b66\u8005\u5c1d\u8bd5\u5229\u7528\u7edf\u8ba1\u673a\u5668\u5b66\u4e60\u7684\u65b9\u6cd5\u6765\u8fdb\u884c\u5171\u6307\u6d88\u89e3\u5e76\u53d6\u5f97\u4e86\u4e00\u5b9a\u7684\u8fdb\u5c55. \u80cc\u666f\u77e5\u8bc6\u4f5c\u4e3a\u65b0\u7684\u7814\u7a76\u70ed\u70b9\u5df2\u7ecf\u88ab\u8d8a\u6765\u8d8a\u591a\u5730\u5229\u7528\u5728\u81ea\u7136\u8bed\u8a00\u5904\u7406\u7684\u5404\u4e2a\u9886\u57df. \u8be5\u6587\u96c6\u6210\u591a\u79cd\u80cc\u666f\u8bed\u4e49\u77e5\u8bc6\u4f5c\u4e3a\u57fa\u4e8e\u4e8c\u5143\u5206\u7c7b\u7684\u5171\u6307\u6d88\u89e3\u6846\u67b6\u7684\u7279\u5f81, \u5206\u522b\u5728 WordNet, \u7ef4\u57fa\u767e\u79d1\u4e0a\u63d0\u53d6\u80cc\u666f\u77e5\u8bc6, \u540c\u65f6\u5229\u7528\u53e5\u5b50\u4e2d\u7684\u6d45\u5c42\u8bed\u4e49\u5173\u7cfb, \u5e38\u89c1\u6587\u672c\u6a21\u5f0f\u4ee5\u53ca\u5f85\u6d88\u89e3\u8bcd\u4e0a\u4e0b\u6587\u6587\u672c\u7279\u5f81. \u5e76\u5229\u7528\u7279\u5f81\u9009\u62e9\u7b97\u6cd5\u81ea\u52a8\u9009\u62e9\u6700\u4f18\u7684\u7279\u5f81\u7ec4\u5408, \u540c\u65f6\u5bf9\u6bd4\u540c\u6837\u7684\u7279\u5f81\u4e0b\u6700\u5927\u57d4\u6a21\u578b\u4e0e\u652f\u6301\u5411\u91cf\u673a\u6a21\u578b\u7684\u8868\u73b0. \u5728 ACE \u6570\u636e\u96c6\u4e0a\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e, \u901a\u8fc7\u96c6\u6210\u5404\u79cd\u7ecf\u8fc7\u7279\u5f81\u9009\u62e9\u540e\u7684\u80cc\u666f\u8bed\u4e49\u77e5\u8bc6, \u5171\u6307\u6d88\u89e3\u7684\u7ed3\u679c\u6709\u8fdb\u4e00\u6b65\u63d0\u9ad8.", "num_citations": "9\n", "authors": ["1179"]}
{"title": "Advances in open-domain question answering\n", "abstract": " Question answering is one of the research hotspots in information retrieval and natural language understanding. This paper summarizes the up-to-date research advances in open-domain question answering, compares the different approaches in question analysis, document and passage retrieval, answer extraction according to different question types. The shortcomings of state-of-art techniques are also discussed, and further research directions for question answering are analyzed and prospected at last.", "num_citations": "9\n", "authors": ["1179"]}
{"title": "Cross-Domain Dialogue Act Tagging.\n", "abstract": " We present recent work in the area of Cross-Domain Dialogue Act (DA) tagging. We have previously reported on the use of a simple dialogue act classifier based on purely intra-utterance features\u2014principally involving word n-gram cue phrases automatically generated from a training corpus. Such a classifier performs surprisingly well, rivalling scores obtained using far more sophisticated language modelling techniques. In this paper, we apply these automatically extracted cues to a new annotated corpus, to determine the portability and generality of the cues we learn.", "num_citations": "9\n", "authors": ["1179"]}
{"title": "\u97f5\u5f8b\u53c2\u6570\u548c\u9891\u8c31\u5305\u7edc\u4fee\u6539\u76f8\u7ed3\u5408\u7684\u60c5\u611f\u8bed\u97f3\u5408\u6210\u6280\u672f\u7814\u7a76\n", "abstract": " \u60c5\u611f\u8bed\u97f3\u5408\u6210\u53ef\u4ee5\u589e\u5f3a\u5408\u6210\u8bed\u97f3\u7684\u8868\u73b0\u529b,\u4eba\u60c5\u5473,\u662f\u8fd1\u5e74\u6765\u7684\u65b0\u5174\u8bfe\u9898.\u9664\u4e86\u97f5\u5f8b\u7279\u5f81\u4e4b\u5916,\u97f3\u8d28\u7c7b\u548c\u53d1\u58f0\u5668\u5b98\u7c7b\u53c2\u6570\u5bf9\u60c5\u611f\u8bed\u97f3\u7684\u8868\u8fbe\u4e5f\u6709\u7740\u81f3\u5173\u91cd\u8981\u7684\u5f71\u54cd,\u800c\u901a\u5e38\u7684\u7814\u7a76\u5927\u591a\u90fd\u662f\u57fa\u4e8e\u89c4\u5219\u6216\u8005\u9884\u5148\u4e3a\u67d0\u79cd\u60c5\u611f\u8bbe\u8ba1\u7684\u6ee4\u6ce2\u5668\u6765\u8fdb\u884c\u8fd9\u4e24\u7c7b\u53c2\u6570\u7684\u4fee\u6539.\u672c\u6587\u63d0\u51fa\u4e86\u901a\u8fc7\u9891\u8c31\u5305\u7edc\u7efc\u5408\u5730\u8c03\u6574\u97f3\u8d28\u7c7b\u548c\u53d1\u58f0\u5668\u5b98\u7c7b\u53c2\u6570\u6765\u5408\u6210\u60c5\u611f\u8bed\u97f3\u7684\u65b9\u6cd5,\u5e76\u901a\u8fc7\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u8fd9\u4e00\u65b9\u6cd5\u7684\u6709\u6548\u6027.\u53e6\u5916,\u5b9e\u9a8c\u7ed3\u679c\u4e5f\u663e\u793a\u4e86\u5f53\u97f5\u5f8b\u53c2\u6570\u548c\u9891\u8c31\u5305\u7edc\u540c\u65f6\u5f97\u5230\u4fee\u6539\u65f6,\u76f8\u5bf9\u4e8e\u5355\u72ec\u4fee\u6539\u67d0\u7c7b\u53c2\u6570\u53ef\u4ee5\u83b7\u5f97\u66f4\u597d\u7684\u60c5\u611f\u5408\u6210\u6548\u679c.", "num_citations": "9\n", "authors": ["1179"]}
{"title": "\u547d\u540d\u5b9e\u4f53\u8bc6\u522b\u548c\u6307\u4ee3\u6d88\u89e3\u5728\u6587\u6458\u7cfb\u7edf\u4e2d\u7684\u5e94\u7528\n", "abstract": " \u4ecb\u7ecd\u4e86\u4e00\u4e2a\u57fa\u4e8e\u53e5\u5b50\u62bd\u53d6\u7684\u5355\u6587\u6863\u81ea\u52a8\u6587\u6458\u7cfb\u7edf,\u5728\u8be5\u7cfb\u7edf\u57fa\u7840\u4e0a\u5e94\u7528\u4e86\u547d\u540d\u5b9e\u4f53\u8bc6\u522b\u548c\u6307\u4ee3\u6d88\u89e3\u6280\u672f,\u6700\u540e\u901a\u8fc7\u4eba\u5de5\u8bc4\u4ef7\u548c\u81ea\u52a8\u8bc4\u4ef7\u7ed3\u679c\u8ba8\u8bba\u547d\u540d\u5b9e\u4f53\u8bc6\u522b\u548c\u6307\u4ee3\u6d88\u89e3\u5bf9\u6587\u6458\u7cfb\u7edf\u7684\u8d21\u732e.", "num_citations": "9\n", "authors": ["1179"]}
{"title": "A feature selection method based on class feature domains for text categorization\n", "abstract": " Feature selection is one of the key problems in text categorization. The chief obstacles to feature selection are noise and sparseness. This paper presents a novel feature selection method which is based on class feature domains. First, we will make use of the combined feature selection method~([1]) to remove noisy features from the original feature space and extract candidate features. That is, we'll take off low frequency words using Document Frequency method firstly and then select candidate features using Mutual Information method. Then, we will construct a class feature domain for each class and conquer the sparseness of trainning datas by merging and strengthening the candidate features which appear in the class feature domains. Experiments show that our method is much better than kinds of traditional feature selection methods and it can improve the performance of text categorization systems markedly.", "num_citations": "9\n", "authors": ["1179"]}
{"title": "\u9762\u5411\u4e2d\u6587\u7279\u5b9a\u4fe1\u606f\u53d8\u5f02\u7684\u8fc7\u6ee4\u6280\u672f\u7814\u7a76\n", "abstract": " \u7814\u7a76\u4e86\u5982\u4f55\u5feb\u901f\u8bc6\u522b\u5e76\u8fc7\u6ee4\u7ecf\u8fc7\u53d8\u5f02\u5904\u7406\u7684\u4e2d\u6587\u4fe1\u606f\u7684\u6280\u672f,\u5e76\u5c06\u53d8\u5f02\u89c4\u5219\u9650\u5b9a\u5728\u5f53\u524d\u4e2d\u6587\u7f51\u7edc\u6700\u5e38\u89c1\u76845\u79cd\u53d8\u5f02\u65b9\u6cd5\u4e0a.\u63d0\u51fa\u4e86\u4e00\u4e2a\u5feb\u901f\u800c\u51c6\u786e\u7684\u4e2d\u6587\u4fe1\u606f\u591a\u6a21\u5f0f\u6a21\u7cca\u5339\u914d\u7b97\u6cd5,\u8be5\u7b97\u6cd5\u5728WM\u7b97\u6cd5\u7684\u57fa\u7840\u4e0a\u878d\u5408\u4e86\u538b\u7f29\u7f16\u7801\u7684\u601d\u60f3,\u9002\u4e8e\u5b9e\u65f6\u5730\u5bf9\u7f51\u7edc\u4fe1\u606f\u8fdb\u884c\u5904\u7406.\u5b9e\u9a8c\u8868\u660e,\u57fa\u4e8e\u8be5\u7b97\u6cd5\u7684\u4fe1\u606f\u8fc7\u6ee4\u7cfb\u7edf\u80fd\u591f\u652f\u6301\u5927\u91cf\u7684\u8f93\u5165\u6a21\u5f0f,\u7cfb\u7edf\u5bf9\u6a21\u5f0f\u7684\u8bc6\u522b\u51c6\u786e\u7387\u8d85\u8fc7\u4e8699%,\u5e76\u4e14\u8fbe\u5230\u4e86\u5f88\u9ad8\u7684\u6267\u884c\u6548\u7387.\u8be5\u7b97\u6cd5\u5728\u4e2d\u6587\u4fe1\u606f\u8fc7\u6ee4\u9886\u57df\u6709\u7740\u5e7f\u9614\u7684\u5e94\u7528\u524d\u666f.", "num_citations": "9\n", "authors": ["1179"]}
{"title": "\u6d45\u5c42\u8bed\u4e49\u5206\u6790\n", "abstract": " \u901a\u8fc7\u8bed\u4e49\u5206\u6790\u53ef\u4ee5\u7406\u89e3\u81ea\u7136\u8bed\u8a00\u8bed\u53e5, \u5e76\u8fdb\u884c\u6df1\u5165\u7684\u77e5\u8bc6\u83b7\u53d6\u548c\u63a8\u7406, \u4f7f\u8ba1\u7b97\u673a\u80fd\u591f\u4e0e\u4eba\u7c7b\u65e0\u969c\u788d\u7684\u6c9f\u901a. \u4e3a\u8fbe\u6b64\u76ee\u7684, \u4eba\u4eec\u5df2\u7ecf\u8fdb\u884c\u4e86\u591a\u5e74\u7684\u52aa\u529b, \u7136\u800c\u76ee\u524d\u53d6\u5f97\u7684\u6548\u679c\u5e76\u4e0d\u7406\u60f3. \u6d45\u5c42\u8bed\u4e49\u5206\u6790, \u53c8\u88ab\u79f0\u4f5c\u8bed\u4e49\u89d2\u8272\u6807\u6ce8, \u662f\u5bf9\u6df1\u5c42\u8bed\u4e49\u5206\u6790\u7684\u4e00\u79cd\u7b80\u5316, \u5b83\u53ea\u6807\u6ce8\u4e0e\u53e5\u5b50\u4e2d\u8c13\u8bcd\u6709\u5173\u7684\u6210\u4efd\u7684\u8bed\u4e49\u89d2\u8272, \u5982\u65bd\u4e8b, \u53d7\u4e8b, \u65f6\u95f4\u548c\u5730\u70b9\u7b49\u7b49. \u7531\u4e8e\u73b0\u6709\u81ea\u7136\u8bed\u8a00\u5904\u7406\u6280\u672f\u4ee5\u53ca\u7edf\u8ba1\u5b66\u4e60\u6280\u672f\u7684\u6210\u719f, \u4f7f\u6d45\u5c42\u8bed\u4e49\u5206\u6790\u5f97\u4ee5\u5b9e\u73b0.", "num_citations": "9\n", "authors": ["1179"]}
{"title": "Multi-document summarization based on local topics identification and extraction\n", "abstract": " This paper describes a multi-document summarization method based on localtopics identification and extraction. The similarity of sentences is measured by analysis ofdependency and semantics. Local topics are found by sentence clustering. The centroidsentence is extracted from each local topic and is ordered to generate summarization. Thesize of summarization is determined according to content of multiple documents, as a result, the summarization becomes general and concise. Finally, the evaluation and experiment aregiven, the average precision of summarization and the average ratio of compressibility are71. 4% and 25.2%, respectively.", "num_citations": "9\n", "authors": ["1179"]}
{"title": "A Multi-View\u2013Based Collective Entity Linking Method\n", "abstract": " Facing lots of name mentions appearing on the web, entity linking is essential for many information processing applications. To improve linking accuracy, the relations between entities are usually considered in the linking process. This kind of method is called collective entity linking and can obtain high-quality results. There are two kinds of information helpful to reveal the relations between entities, i.e., contextual information and structural information of entities. Most traditional collective entity linking methods consider them separately. In fact, these two kinds of information represent entities from specific and diverse views and can enhance each other, respectively. Besides, if we look into each view closely, it can be separated into sub-views that are more meaningful. For this reason, this article proposes a multi-view\u2013based collective entity linking algorithm, which combines several views of entities into an objective\u00a0\u2026", "num_citations": "8\n", "authors": ["1179"]}
{"title": "Multi-level cross-lingual attentive neural architecture for low resource name tagging\n", "abstract": " Neural networks have been widely used for English name tagging and have delivered state-of-the-art results. However, for low resource languages, due to the limited resources and lack of training data, taggers tend to have lower performance, in comparison to the English language. In this paper, we tackle this challenging issue by incorporating multi-level cross-lingual knowledge as attention into a neural architecture, which guides low resource name tagging to achieve a better performance. Specifically, we regard entity type distribution as language independent and use bilingual lexicons to bridge cross-lingual semantic mapping. Then, we jointly apply word-level cross-lingual mutual influence and entity-type level monolingual word distributions to enhance low resource name tagging. Experiments on three languages demonstrate the effectiveness of this neural architecture: for Chinese, Uzbek, and Turkish, we\u00a0\u2026", "num_citations": "8\n", "authors": ["1179"]}
{"title": "A Gaussian Copula Regression Model for Movie Box-office Revenue Prediction with Social Media\n", "abstract": " Previous work explored many kinds of features for the task of movie box-office prediction. However, little prior work has investigated the dependency relationships among these features. In this paper, we propose a novel Gaussian Copula regression model to study the correlation among predictive features. In particular, we first extract structured movie metadata and user activities on social media as features. We then apply Gaussian kernel to smooth out the data and learn the covariance matrix among the marginal distributions by maximum likelihood. We propose to approximately infer the movie box-office revenue by exploiting the covariance matrix. Experimental results show that our proposed method outperforms the baseline methods in the first week revenue prediction task and can achieve comparable performance on the gross revenue prediction task with a state-of-the art baseline in gross revenue\u00a0\u2026", "num_citations": "8\n", "authors": ["1179"]}
{"title": "Aspect-Object Alignment with Integer Linear Programming in Opinion Mining\n", "abstract": " Target extraction is an important task in opinion mining. In this task, a complete target consists of an aspect and its corresponding object. However, previous work has always simply regarded the aspect as the target itself and has ignored the important \"object\" element. Thus, these studies have addressed incomplete targets, which are of limited use for practical applications. This paper proposes a novel and important sentiment analysis task, termed aspect-object alignment, to solve the \"object neglect\" problem. The objective of this task is to obtain the correct corresponding object for each aspect. We design a two-step framework for this task. We first provide an aspect-object alignment classifier that incorporates three sets of features, namely, the basic, relational, and special target features. However, the objects that are assigned to aspects in a sentence often contradict each other and possess many complicated features that are difficult to incorporate into a classifier. To resolve these conflicts, we impose two types of constraints in the second step: intra-sentence constraints and inter-sentence constraints. These constraints are encoded as linear formulations, and Integer Linear Programming (ILP) is used as an inference procedure to obtain a final global decision that is consistent with the constraints. Experiments on a corpus in the camera domain demonstrate that the three feature sets used in the aspect-object alignment classifier are effective in improving its performance. Moreover, the classifier with ILP inference performs better than the classifier without it, thereby illustrating that the two types of constraints that we impose are beneficial.", "num_citations": "8\n", "authors": ["1179"]}
{"title": "Influence and power in group interactions\n", "abstract": " In this article, we present a novel approach towards the detection and modeling of complex social phenomena in multiparty interactions, including leadership, influence, pursuit of power and group cohesion. We have developed a two-tier approach that relies on observable and computable linguistic features of conversational text to make predictions about sociolinguistic behaviors such as Topic Control and Disagreement, that speakers deploy in order to achieve and maintain certain positions and roles in a group. These sociolinguistic behaviors are then used to infer higher-level social phenomena such as Influence and Pursuit of Power, which is the focus of this paper. We show robust performance results by comparing our automatically computed results to participants\u2019 own perceptions and rankings. We use weights learned from correlations with training examples to optimize our models and to show\u00a0\u2026", "num_citations": "8\n", "authors": ["1179"]}
{"title": "Stanford\u2019s system for parsing the English web\n", "abstract": " We describe the Stanford entries to the SANCL 2012 shared task on parsing noncanonical language. Stanford submitted three entries:(i) a self-trained generative constituency parser,(ii) a graph-based dependency parser, and (iii) a stacked dependency parser using the output from the constituency parser as features while parsing. The stacked parser obtained 2nd place in the dependency parsing track. Our overall approach involved exploring techniques which improved performance consistently across domains without using many external resources.", "num_citations": "8\n", "authors": ["1179"]}
{"title": "Improving chinese pos tagging with dependency parsing\n", "abstract": " Recent research usually models POS tagging as a sequential labeling problem, in which only local context features can be used. Due to the lack of morphological inflections, many tagging ambiguities in Chinese are difficult to handle unless consulting larger contexts. In this paper, we try to improve Chinese POS tagging by using long-distance dependencies produced by a statistical dependency parser. Experimental results show that, despite error propagation, the syntactic features can significantly improve the tagging accuracy from 93.88% to 94.41%(p< 10\u2212 5). Detailed analysis shows that these features are helpful for ambiguous pairs like {NN, VV} and {DEC, DEG}. 1", "num_citations": "8\n", "authors": ["1179"]}
{"title": "Research on typical event extraction method in the field of music\n", "abstract": " Event extraction is an important research issue in information extraction. This paper focuses on the music domain, and describes a method based on trigger clustering for event type discovering. Then we propose a method based on the filtering of keywords and triggers for event type recognition. For the event argument recognition, the method which is based on maximum entropy model is proposed in this paper. Evaluations on our corpus give a final F-score of 82.82% and 75.79% for type recognition and argument recognition.", "num_citations": "8\n", "authors": ["1179"]}
{"title": "\u57fa\u4e8e\u68c0\u7d22\u5386\u53f2\u4e0a\u4e0b\u6587\u7684\u4e2a\u6027\u5316\u67e5\u8be2\u91cd\u6784\u6280\u672f\u7814\u7a76\n", "abstract": " \u57fa\u4e8e\u68c0\u7d22\u5386\u53f2\u9690\u5f0f\u5730\u5b66\u4e60\u7528\u6237\u504f\u597d\u662f\u4e2a\u6027\u5316\u68c0\u7d22\u7814\u7a76\u7684\u70ed\u70b9, \u800c\u6839\u636e\u7528\u6237\u68c0\u7d22\u5386\u53f2\u91cd\u6784\u65b0\u7684\u67e5\u8be2\u8f93\u5165\u662f\u5176\u4e2d\u4e3b\u8981\u7684\u7814\u7a76\u5185\u5bb9. \u5df2\u6709\u7684\u7814\u7a76\u5728\u5229\u7528\u68c0\u7d22\u5386\u53f2\u8fdb\u884c\u67e5\u8be2\u91cd\u6784\u65f6, \u901a\u5e38\u4e0d\u533a\u5206\u68c0\u7d22\u5386\u53f2\u4e2d\u7684\u5185\u5bb9\u662f\u5426\u4e0e\u5f53\u524d\u67e5\u8be2\u76f8\u5173, \u800c\u662f\u5c06\u5168\u90e8\u68c0\u7d22\u5386\u53f2\u89c6\u4e3a\u6574\u4f53, \u56e0\u800c\u4f7f\u91cd\u6784\u540e\u7684\u67e5\u8be2\u542b\u6709\u8f83\u591a\u566a\u58f0. \u8be5\u6587\u57fa\u4e8e\u76f8\u5173\u8bcd\u8bed\u5728\u4e0a\u4e0b\u6587\u4e2d\u5927\u91cf\u5171\u73b0\u7684\u7279\u5f81, \u5c06\u7528\u6237\u5386\u53f2\u68c0\u7d22\u7ed3\u679c\u7684\u7f51\u9875\u6458\u8981\u4f5c\u4e3a\u4e0a\u4e0b\u6587\u8bed\u5883, \u7ed3\u5408\u7528\u6237\u70b9\u51fb, \u9009\u62e9\u68c0\u7d22\u5386\u53f2\u4e2d\u4e0e\u5f53\u524d\u67e5\u8be2\u5171\u73b0\u7a0b\u5ea6\u6700\u9ad8\u7684\u8bcd\u8bed\u91cd\u6784\u67e5\u8be2\u6a21\u578b. \u5bf9\u521d\u59cb\u68c0\u7d22\u7ed3\u679c\u91cd\u6392\u5e8f\u7684\u5b9e\u9a8c\u8868\u660e, \u8be5\u65b9\u6cd5\u53ef\u4ee5\u6709\u6548\u5730\u9009\u62e9\u76f8\u5173\u8bcd\u8bed, \u51cf\u5c11\u566a\u58f0. \u7528 p@ 5 \u548c NDCG \u4e24\u79cd\u6307\u6807\u8bc4\u4ef7, \u6bd4\u6700\u597d\u7684\u57fa\u51c6\u7cfb\u7edf\u5206\u522b\u76f8\u5bf9\u63d0\u9ad8 12. 8% \u548c 7.2%, \u6bd4\u521d\u59cb\u6392\u5e8f\u7ed3\u679c\u76f8\u5bf9\u63d0\u9ad8", "num_citations": "8\n", "authors": ["1179"]}
{"title": "\u57fa\u4e8e\u7ebf\u7d22\u8bcd\u8bc6\u522b\u548c\u8bad\u7ec3\u96c6\u6269\u5c55\u7684\u4e2d\u6587\u95ee\u9898\u5206\u7c7b\n", "abstract": " \u9488\u5bf9\u95ee\u9898\u5206\u7c7b\u7684\u6570\u636e\u7a00\u758f\u95ee\u9898,\u63d0\u51fa\u4e86\u4e00\u79cd\u4ee5\u7591\u95ee\u8bcd\u548c\u7126\u70b9\u8bcd\u4e3a\u5173\u952e\u7ebf\u7d22\u7684\u4e2d\u6587\u4e8b\u5b9e\u578b\u95ee\u9898\u5206\u7c7b\u65b9\u6cd5.\u8be5\u65b9\u6cd5\u9996\u5148\u81ea\u52a8\u8bc6\u522b\u7528\u6237\u63d0\u51fa\u7684\u95ee\u9898\u4e2d\u7684\u7591\u95ee\u8bcd\u548c\u7126\u70b9\u8bcd,\u82e5\u7591\u95ee\u8bcd\u548c\u7126\u70b9\u8bcd\u5b58\u5728,\u5219\u7528\u6700\u8fd1\u90bb\u6a21\u578b\u8fdb\u884c\u5206\u7c7b,\u800c\u5bf9\u6ca1\u6709\u7528\u6700\u8fd1\u90bb\u65b9\u6cd5\u5206\u7c7b\u7684\u5176\u4ed6\u95ee\u9898,\u5219\u7528\u652f\u6301\u5411\u91cf\u673a(SVM)\u6a21\u578b\u8fdb\u884c\u5206\u7c7b.\u8bad\u7ec3SVM\u6a21\u578b\u65f6,\u4eceWeb\u4e0a\u81ea\u52a8\u83b7\u53d6\u65b0\u95ee\u9898\u6765\u5bf9\u8bad\u7ec3\u96c6\u8fdb\u884c\u6269\u5c55,\u6700\u8fd1\u90bb\u65b9\u6cd5\u53ea\u5229\u7528\u7ebf\u7d22\u8bcd\u8bcd\u4e49\u8ddd\u79bb\u8fdb\u884c\u7c7b\u522b\u5224\u65ad.\u5b9e\u9a8c\u8868\u660e,\u8fd9\u79cd\u6309\u7167\u95ee\u9898\u7ed3\u6784\u7684\u4e0d\u540c\u800c\u9009\u62e9\u4e0d\u540c\u5206\u7c7b\u5668\u7684\u65b9\u6cd5,\u5728\u6027\u80fd\u4e0a\u8981\u4f18\u4e8e\u5355\u4e00\u5206\u7c7b\u65b9\u6cd5;\u8bcd\u4e49\u8ddd\u79bb\u7684\u5e94\u7528\u548c\u8bad\u7ec3\u96c6\u81ea\u52a8\u6269\u5c55\u6539\u5584\u4e86\u8bad\u7ec3\u6570\u636e\u7684\u7a00\u758f,\u63d0\u9ad8\u4e86\u5206\u7c7b\u6027\u80fd.", "num_citations": "8\n", "authors": ["1179"]}
{"title": "Combining syntax and word sense for Chinese pronoun resolution\n", "abstract": " Syntactic knowledge is important for pronoun resolution. In recent years, research on dependency parsing becomes active because dependency grammar benefits representing the relations between terms. We propose a SVM based method for Chinese pronoun resolution, employing effective syntactic role features and word sense similarities between head words of noun phrases. The experimental result on the ACE 2005 data shows that these dependency parsing based features are effective.", "num_citations": "8\n", "authors": ["1179"]}
{"title": "Bootstrapping for extracting relations from large corpora\n", "abstract": " A new approach of relation extraction is described in this paper. It adopts a bootstrapping model with a novel iteration strategy, which generates more precise examples of specific relation. Compared with previous methods, the proposed method has three main advantages: first, it needs less manual intervention; second, more abundant and reasonable information are introduced to represent a relation pattern; third, it reduces the risk of circular dependency occurrence in bootstrapping. Scalable evaluation methodology and metrics are developed for our task with comparable techniques over TianWang 100G corpus. The experimental results show that it can get 90% precision and have excellent expansibility.", "num_citations": "8\n", "authors": ["1179"]}
{"title": "\u57fa\u4e8e\u7f51\u7edc\u6316\u6398\u7684\u5b9e\u4f53\u5173\u7cfb\u5143\u7ec4\u81ea\u52a8\u83b7\u53d6\n", "abstract": " \u4e8c\u5143\u5b9e\u4f53\u5173\u7cfb\u5143\u7ec4\u53ef\u4ee5\u5e94\u7528\u5230\u77e5\u8bc6\u5e93\u6784\u5efa, \u6570\u636e\u6316\u6398, \u6a21\u5f0f\u62bd\u53d6\u7b49\u591a\u4e2a\u9886\u57df. \u672c\u6587\u5229\u7528\u7279\u5b9a\u5173\u7cfb\u7684\u4e00\u4e2a\u5143\u7ec4\u548c\u4e00\u4e2a\u5173\u952e\u8bcd\u4f5c\u4e3a\u79cd\u5b50, \u7ed3\u5408\u591a\u79cd\u81ea\u7136\u8bed\u8a00\u5904\u7406\u5e95\u5c42\u6280\u672f, \u91c7\u53d6\u6539\u8fdb\u7684\u6a21\u5f0f\u83b7\u53d6\u65b9\u6cd5\u548c\u81ea\u4e3e\u8fed\u4ee3\u7b56\u7565, \u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u4ece Web \u4e0a\u62bd\u53d6\u5b9e\u4f53\u5173\u7cfb\u5143\u7ec4\u7684\u65b9\u6cd5. \u57fa\u51c6\u65b9\u6cd5\u7684\u5e73\u5747\u51c6\u786e\u7387\u8fbe\u5230\u4e86 78.12%, \u91c7\u7528\u8fc7\u6ee4\u63aa\u65bd\u540e\u62bd\u53d6\u65b9\u6cd5\u7684\u5e73\u5747\u51c6\u786e\u7387\u8fbe\u5230\u4e86 98.42%. \u5b9e\u9a8c\u7ed3\u679c\u8868\u660e, \u5229\u7528\u7f51\u7edc\u6316\u6398\u65b9\u6cd5\u83b7\u53d6\u7684\u5b9e\u4f53\u5173\u7cfb\u5143\u7ec4\u80fd\u591f\u5f88\u597d\u6ee1\u8db3\u4fe1\u606f\u62bd\u53d6\u7684\u5e94\u7528, \u5bf9\u62bd\u53d6\u51fa\u7684\u5143\u7ec4\u8fdb\u4e00\u6b65\u5904\u7406, \u80fd\u591f\u83b7\u53d6\u66f4\u591a\u6709\u4ef7\u503c\u7684\u4fe1\u606f.", "num_citations": "8\n", "authors": ["1179"]}
{"title": "Word sense language model for information retrieval\n", "abstract": " This paper proposes a word sense language model based method for information retrieval. This method, differing from most of traditional ones, combines word senses defined in a thesaurus with a classic statistical model. The word sense language model regards the word sense as a form of linguistic knowledge, which is helpful in handling mismatch caused by synonym and data sparseness due to data limit. Experimental results based on TREC-Mandarin corpus show that this method gains 12.5% improvement on MAP over traditional tf-idf retrieval method but 5.82% decrease on MAP compared to a classic language model. A combination result of this method and the language model yields 8.92% and 7.93% increases over either respectively. We present analysis and discussions on the not-so-exciting results and conclude that a higher performance of word sense language model will owe to high\u00a0\u2026", "num_citations": "8\n", "authors": ["1179"]}
{"title": "\u6c49\u8bed\u6587\u8bed\u8f6c\u6362\u7cfb\u7edf\u4e2d\u505c\u987f\u6307\u6570\u7684\u81ea\u52a8\u6807\u6ce8\n", "abstract": " (\u54c8\u5c14\u6ee8\u5de5\u4e1a\u5927\u5b66\u8ba1\u7b97\u673a\u5b66\u9662\u4fe1\u606f\u68c0\u7d22\u7814\u7a76\u5ba4, \u9ed1\u9f99\u6c5f\u54c8\u5c14\u6ee8 150001; \u54c8\u5c14\u6ee8\u5de5\u4e1a\u5927\u5b66\u8ba1\u7b97\u673a\u5b66\u9662\u8bed\u97f3\u5904\u7406\u7814\u7a76\u5ba4, \u9ed1\u9f99\u6c5f\u54c8\u5c14\u6ee8 150001) \u6458\u8981: \u672c\u6587\u91c7\u7528\u4e86\u4e00\u4e2a\u57fa\u4e8e C2TOBI \u7684\u505c\u987f\u6307\u6570\u6807\u6ce8\u7684\u8bed\u6599\u5e93, \u5229\u7528\u6709\u6307\u5bfc\u7684\u5b66\u4e60\u65b9\u6cd5\u5bf9\u81ea\u52a8\u505c\u987f\u6307\u6570\u6807\u6ce8\u65b9\u9762\u505a\u4e86\u4e00\u4e9b\u6709\u76ca\u7684\u63a2\u7d22. \u672c\u6587\u5171\u5b9e\u73b0\u4e86\u4e09\u79cd\u65b9\u6cd5: \u57fa\u672c\u7684\u9a6c\u5c14\u79d1\u592b\u6a21\u578b, \u5f15\u5165\u4e86\u8bcd\u957f\u4fe1\u606f\u7684\u9a6c\u5c14\u79d1\u592b\u6a21\u578b, \u5f15\u5165\u8bcd\u957f\u4fe1\u606f\u7684\u9a6c\u5c14\u79d1\u592b\u6a21\u578b\u7ed3\u5408\u57fa\u4e8e\u8f6c\u6362\u7684\u9519\u8bef\u9a71\u52a8\u7684\u5b66\u4e60\u65b9\u6cd5. \u7136\u540e\u901a\u8fc7\u5bf9 3000 \u53e5\u7684\u771f\u5b9e\u6587\u672c\u8fdb\u884c\u5f00\u653e\u6d4b\u8bd5, \u4ee5\u57fa\u672c\u7684\u9a6c\u5c14\u79d1\u592b\u6a21\u578b\u7684\u7ed3\u679c\u4f5c\u4e3a\u57fa\u51c6, \u5b9e\u9a8c\u7ed3\u679c\u4e0d\u65ad\u6539\u8fdb, \u6700\u7ec8\u8fbe\u5230\u4e86 7816% \u7684\u51c6\u786e\u7387, \u9519\u8bef\u4ee3\u4ef7\u964d\u4f4e\u4e86 1415%.", "num_citations": "8\n", "authors": ["1179"]}
{"title": "Aligning bilingual corpora using sentences location information\n", "abstract": " Large amounts of bilingual resource on the Internet provide us with the probability of building a large scale of bilingual corpus. The irregular characteristics of the real texts, especially without the strictly aligned paragraph boundaries, bring a challenge to alignment technology. The traditional alignment methods have some difficulties in competency for doing this. This paper describes a new method for aligning real bilingual texts using sentence pair location information. The model was motivated by the observation that the location of a sentence pair with certain length is distributed in the whole text similarly. It uses (1: 1) sentence beads instead of high frequency words as the candidate anchors. The method was developed and evaluated through many different test data. The results show that it can achieve good aligned performance and be robust and language independent. It can resolve the alignment problem on real bilingual text.", "num_citations": "8\n", "authors": ["1179"]}
{"title": "Local contexts are effective for neural aspect extraction\n", "abstract": " Recently, long short-term memory based recurrent neural network (LSTM-RNN), which is capable of capturing long dependencies over sequence, obtained state-of-the-art performance on aspect extraction. In this work, we would like to investigate to which extent could we achieve if we only take into account of the local dependencies. To this end, we develop a simple feed-forward neural network which takes a window of context words surrounding the aspect to be processed. Surprisingly, we find that a purely window-based neural network obtain comparable performance with a LSTM-RNN approach, which reveals the importance of local contexts for aspect extraction. Furthermore, we introduce a simple and natural way to leverage local contexts and global contexts together, which is not only computationally cheaper than existing LSTM-RNN approach, but also gets higher classification accuracy.", "num_citations": "7\n", "authors": ["1179"]}
{"title": "Personalized microtopic recommendation on microblogs\n", "abstract": " Microblogging services such as Sina Weibo and Twitter allow users to create tags explicitly indicated by the # symbol. In Sina Weibo, these tags are called microtopics, and in Twitter, they are called hashtags. In Sina Weibo, each microtopic has a designate page and can be directly visited or commented on. Recommending these microtopics to users based on their interests can help users efficiently acquire information. However, it is non-trivial to recommend microtopics to users to satisfy their information needs. In this article, we investigate the task of personalized microtopic recommendation, which exhibits two challenges. First, users usually do not give explicit ratings to microtopics. Second, there exists rich information about users and microtopics, for example, users' published content and biographical information, but it is not clear how to best utilize such information. To address the above two challenges, we\u00a0\u2026", "num_citations": "7\n", "authors": ["1179"]}
{"title": "\u5bf9\u8bdd\u7cfb\u7edf\u8bc4\u4ef7\u65b9\u6cd5\u7efc\u8ff0\n", "abstract": " \u6458\u8981 \u672c\u6587\u4ecb\u7ecd\u4e86\u5bf9\u8bdd\u7cfb\u7edf\u7684\u53d1\u5c55\u5386\u53f2\u4ee5\u53ca\u968f\u7740\u5bf9\u8bdd\u7cfb\u7edf\u53d1\u5c55\u800c\u884d\u751f\u51fa\u7684\u591a\u79cd\u5bf9\u8bdd\u7cfb\u7edf\u8bc4\u4ef7\u65b9\u6cd5, \u4ece\u4efb\u52a1\u578b\u5bf9\u8bdd\u7cfb\u7edf\u4e0e\u5f00\u653e\u57df\u5bf9\u8bdd\u7cfb\u7edf\u4e24\u4e2a\u65b9\u5411\u8fdb\u884c\u4e86\u8c03\u7814\u548c\u603b\u7ed3, \u5206\u6790\u4e86\u4e0d\u540c\u8bc4\u4ef7\u65b9\u6cd5\u7684\u5229\u5f0a, \u6bcf\u79cd\u8bc4\u4ef7\u65b9\u6cd5\u7684\u4fa7\u91cd\u70b9\u548c\u4e0d\u540c\u65b9\u5411\u4e0a\u6700\u65b0\u7684\u7814\u7a76\u8fdb\u5c55. \u5728\u4efb\u52a1\u578b\u5bf9\u8bdd\u7cfb\u7edf\u65b9\u9762, \u4ecb\u7ecd\u4e86 Steve Young \u7b49\u4eba\u7684\u8fd1\u671f\u7814\u7a76\u6210\u679c, \u603b\u7ed3\u4e86\u51e0\u79cd\u88ab\u5e7f\u6cdb\u4f7f\u7528\u7684\u8bc4\u4ef7\u601d\u8def. \u5728\u5f00\u653e\u57df\u5bf9\u8bdd\u7cfb\u7edf\u65b9\u9762, \u4ece\u5ba2\u89c2\u6307\u6807\u8bc4\u4ef7\u548c\u6a21\u62df\u4eba\u5de5\u8bc4\u5206\u4e24\u4e2a\u89d2\u5ea6\u63a2\u7d22\u4e86\u5f00\u653e\u57df\u804a\u5929\u7cfb\u7edf\u7684\u8bc4\u4ef7\u65b9\u6cd5, \u5bf9\u4e8e\u4e0d\u540c\u7684\u6307\u6807\u548c\u4e0d\u540c\u7684\u7814\u7a76\u601d\u8def\u505a\u4e86\u5206\u6790\u53ca\u4ecb\u7ecd. \u6700\u540e, \u672c\u6587\u901a\u8fc7\u603b\u7ed3\u53ca\u5206\u6790\u5bf9\u8bdd\u7cfb\u7edf\u7684\u7ecf\u5178\u8bc4\u4ef7\u65b9\u6cd5\u548c\u5f53\u524d\u6700\u65b0\u7684\u57fa\u4e8e\u795e\u7ecf\u7f51\u7edc\u6a21\u578b\u7684\u5bf9\u8bdd\u8bc4\u4ef7\u65b9\u6cd5, \u5bf9\u5bf9\u8bdd\u7cfb\u7edf\u8bc4\u4ef7\u65b9\u6cd5\u7684\u53d1\u5c55\u8d8b\u52bf\u8fdb\u884c\u4e86\u5c55\u671b.", "num_citations": "7\n", "authors": ["1179"]}
{"title": "\u804a\u5929\u673a\u5668\u4eba\u4e2d\u7528\u6237\u51fa\u884c\u6d88\u8d39\u610f\u56fe\u8bc6\u522b\u65b9\u6cd5\u7814\u7a76\n", "abstract": " \u968f\u7740\u8ba1\u7b97\u673a\u6280\u672f\u5c24\u5176\u662f\u4eba\u5de5\u667a\u80fd\u6280\u672f\u7684\u5feb\u901f\u53d1\u5c55, \u804a\u5929\u673a\u5668\u4eba\u8fd9\u4e00\u65b0\u5f62\u6001\u7684\u667a\u80fd\u5bf9\u8bdd\u7cfb\u7edf\u51fa\u73b0\u5e76\u666e\u53ca, \u57fa\u4e8e\u6b64, \u672c\u6587\u63d0\u51fa \u201c\u7528\u6237\u51fa\u884c\u6d88\u8d39\u610f\u56fe\u8bc6\u522b\u201d \u4efb\u52a1. \u6240\u8c13\u51fa\u884c\u6d88\u8d39\u610f\u56fe, \u662f\u6307\u5728\u804a\u5929\u673a\u5668\u4eba\u4e2d, \u7528\u6237\u4e3a\u4e86\u6ee1\u8db3\u51fa\u884c\u7684\u9700\u8981, \u901a\u8fc7\u6587\u672c\u8868\u8fbe\u51fa\u5bf9\u51fa\u884c\u7c7b\u4ea7\u54c1\u6216\u8005\u670d\u52a1\u7684\u8d2d\u4e70\u610f\u613f. \u8bc6\u522b\u51fa\u7528\u6237\u7684\u51fa\u884c\u6d88\u8d39\u610f\u56fe, \u4e0d\u4ec5\u80fd\u4e30\u5bcc\u804a\u5929\u673a\u5668\u4eba\u7684\u5bf9\u8bdd\u7b56\u7565, \u8fd8\u80fd\u8f85\u52a9\u4e4b\u540e\u7684\u4ea7\u54c1\u63a8\u8350\u5de5\u4f5c, \u5177\u6709\u91cd\u8981\u610f\u4e49. \u672c\u6587\u5c06\u51fa\u884c\u6d88\u8d39\u610f\u56fe\u8bc6\u522b\u4efb\u52a1\u770b\u6210\u4e00\u4e2a\u5206\u7c7b\u95ee\u9898, \u9996\u5148\u4f7f\u7528\u57fa\u4e8e\u7279\u5f81\u5de5\u7a0b\u7684\u673a\u5668\u5b66\u4e60\u65b9\u6cd5\u8fdb\u884c\u51fa\u884c\u610f\u56fe\u8bc6\u522b. \u7ecf\u8fc7\u5206\u6790, \u7528\u6237\u7684\u804a\u5929\u6587\u672c\u4e00\u822c\u8f83\u77ed\u4e14\u53e3\u8bed\u6027\u8f83\u5f3a, \u8bc6\u522b\u8d77\u6765\u5341\u5206\u56f0\u96be. \u56e0\u800c\u672c\u6587\u5c1d\u8bd5\u4f7f\u7528\u5171\u73b0\u5173\u7cfb\u6316\u6398 Apriori \u7b97\u6cd5\u4ee5\u53ca\u4e3b\u9898\u6316\u6398 LDA \u7b97\u6cd5, \u5bf9\u7528\u6237\u7684\u804a\u5929\u6587\u672c\u8fdb\u884c\u5185\u5bb9\u548c\u8bed\u4e49\u8bdd\u9898\u4e24\u65b9\u9762\u7684\u6269\u5145, \u4e30\u5bcc\u7528\u6237\u7684\u8868\u8fbe\u5e76\u5b8c\u5584\u804a\u5929\u4fe1\u606f, \u4f7f\u6a21\u578b\u66f4\u6613\u4e8e\u8bc6\u522b\u51fa\u7528\u6237\u7684\u51fa\u884c\u610f\u56fe. \u5b9e\u9a8c\u7ed3\u679c\u8868\u660e, \u57fa\u4e8e\u5185\u5bb9\u4e0e\u4e3b\u9898\u6269\u5145\u7684\u8bc6\u522b\u7b56\u7565\u5bf9\u6700\u7ec8\u7ed3\u679c\u6709\u4e00\u5b9a\u63d0\u5347. \u7531\u4e8e\u57fa\u4e8e\u7279\u5f81\u5de5\u7a0b\u7684\u673a\u5668\u5b66\u4e60\u65b9\u6cd5\u5341\u5206\u8017\u8d39\u4eba\u529b\u5e76\u4e14\u6709\u8f83\u5f3a\u7684\u5c40\u9650\u6027, \u5373\u4fbf\u5bf9\u804a\u5929\u5185\u5bb9\u8fdb\u884c\u6269\u5c55, \u5728\u523b\u753b\u6587\u672c\u7684\u6df1\u5c42\u8bed\u4e49\u4fe1\u606f\u4e0a\u4f9d\u7136\u6bd4\u8f83\u56f0\u96be. \u8fdb\u800c\u672c\u6587\u5c1d\u8bd5\u4f7f\u7528\u7aef\u5230\u7aef\u7684\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\u8fdb\u884c\u7279\u5f81\u62bd\u53d6\u4e0e\u51fa\u884c\u610f\u56fe\u8bc6\u522b\u5de5\u4f5c. \u5177\u4f53\u800c\u8a00, \u672c\u6587\u6784\u5efa\u4e86\u57fa\u4e8e\u5377\u79ef\u7684\u957f\u77ed\u671f\u8bb0\u5fc6\u795e\u7ecf\u7f51\u7edc (Convolutional-LSTM) \u6a21\u578b\u8fdb\u884c\u51fa\u884c\u6d88\u8d39\u610f\u56fe\u7279\u5f81\u6316\u6398\u4e0e\u8bc6\u522b, \u9996\u5148\u901a\u8fc7\u5377\u79ef\u795e\u7ecf\u7f51\u7edc (CNN) \u5bf9\u7528\u6237\u7684\u804a\u5929\u6587\u672c\u8fdb\u884c\u7279\u5f81\u62bd\u53d6, \u968f\u540e\u8fdb\u884c\u7279\u5f81\u7ec4\u5408\u540e\u9001\u5165\u957f\u77ed\u8bb0\u5fc6\u795e\u7ecf\u7f51\u7edc (LSTM) \u8fdb\u884c\u7279\u5f81\u8868\u793a\u5b66\u4e60, \u6700\u540e\u8f93\u51fa\u8bc6\u522b\u7ed3\u679c. \u5b9e\u9a8c\u7ed3\u679c\u8868\u660e, \u5728\u51fa\u884c\u6d88\u8d39\u610f\u56fe\u8bc6\u522b\u4efb\u52a1\u4e0a, \u57fa\u4e8e Convolutional-LSTM \u7684\u6a21\u578b\u76f8\u5bf9\u4f20\u7edf\u7279\u5f81\u5de5\u7a0b\u65b9\u6cd5\u6709\u8f83\u5927\u63d0\u5347, \u5e76\u76f8\u6bd4 CNN \u4e0e LSTM \u6a21\u578b\u8868\u73b0\u4e5f\u6709\u4f18\u52bf, \u5728\u51fa\u884c\u6d88\u8d39\u610f\u56fe\u8bc6\u522b\u4efb\u52a1\u4e0a\u662f\u884c\u4e4b\u6709\u6548\u7684. \u51fa\u884c\u610f\u56fe\u5305\u542b\u591a\u4e2a\u9886\u57df, \u5728\u5b9e\u9645\u7684\u610f\u56fe\u8bc6\u522b\u8fc7\u7a0b\u4e2d, \u67d0\u4e9b\u610f\u56fe\u9886\u57df\u7684\u8bed\u6599\u5341\u5206\u7a00\u5c11, \u800c\u4e14\u83b7\u53d6\u6bd4\u8f83\u56f0\u96be, \u8fd9\u5c31\u7ed9\u610f\u56fe\u8bc6\u522b\u7684\u9886\u57df\u6269\u5c55\u5e26\u6765\u4e86\u8bf8\u591a\u4e0d\u4fbf. \u672c\u6587\u5c1d\u8bd5\u4f7f\u7528\u5e95\u5c42\u53c2\u6570\u5171\u4eab\u4e0e\u591a\u4efb\u52a1\u5b66\u4e60\u4e24\u79cd\u4e0d\u540c\u7684\u8fc1\u79fb\u5b66\u00a0\u2026", "num_citations": "7\n", "authors": ["1179"]}
{"title": "Discourse element identification in student essays based on global and local cohesion\n", "abstract": " We present a method of using cohesion to improve discourse element identification for sentences in student essays. New features for each sentence are derived by considering its relations to global and local cohesion, which are created by means of cohesive resources and subtopic coverage. In our experiments, we obtain significant improvements on identifying all discourse elements, especially of+ 5% F1 score on thesis and main idea. The analysis shows that global cohesion can better capture thesis statements.", "num_citations": "7\n", "authors": ["1179"]}
{"title": "Emotion Analysis Platform on Chinese Microblog\n", "abstract": " Weibo, as the largest social media service in China, has billions of messages generated every day. The huge number of messages contain rich sentimental information. In order to analyze the emotional changes in accordance with time and space, this paper presents an Emotion Analysis Platform (EAP), which explores the emotional distribution of each province, so that can monitor the global pulse of each province in China. The massive data of Weibo and the real-time requirements make the building of EAP challenging. In order to solve the above problems, emoticons, emotion lexicon and emotion-shifting rules are adopted in EAP to analyze the emotion of each tweet. In order to verify the effectiveness of the platform, case study on the Sichuan earthquake is done, and the analysis result of the platform accords with the fact. In order to analyze from quantity, we manually annotate a test set and conduct experiment on it. The experimental results show that the macro-Precision of EAP reaches 80% and the EAP works effectively.", "num_citations": "7\n", "authors": ["1179"]}
{"title": "Extending the MPC corpus to Chinese and Urdu-a multiparty multi-lingual chat corpus for modeling social phenomena in language\n", "abstract": " In this paper, we report our efforts in building a multi-lingual multi-party online chat corpus in order to develop a firm understanding in a set of social constructs such as agenda control, influence, and leadership as well as to computationally model such constructs in online interactions. These automated models will help capture the dialogue dynamics that are essential for developing, among others, realistic human-machine dialogue systems, including autonomous virtual chat agents. In this paper, we first introduce our experiment design and data collection method in Chinese and Urdu, and then report on the current stage of our data collection. We annotated the collected corpus on four levels: communication links, dialogue acts, local topics, and meso-topics. Results from the analyses of annotated data on different languages indicate some interesting phenomena, which are reported in this paper.", "num_citations": "7\n", "authors": ["1179"]}
{"title": "\u65c5\u6e38\u91cd\u8981\u6027\u611f\u77e5, \u65c5\u6e38\u52a8\u673a\u4e0e\u4eba\u53e3\u7279\u5f81: \u57fa\u4e8e\u9999\u6e2f\u5c45\u6c11\u8c03\u67e5\u6570\u636e\u7684\u5b9e\u8bc1\u7814\u7a76\n", "abstract": " \u672c\u6587\u57fa\u4e8e\u5bf9\u9999\u6e2f\u5c45\u6c11\u7684\u5927\u89c4\u6a21\u7535\u8bdd\u8c03\u67e5,\u91c7\u7528\u6700\u4f18\u5c3a\u5ea6\u56de\u5f52\u6a21\u578b.\u63a2\u8ba8\u51fa\u6e38\u52a8\u673a\u548c\u4eba\u53e3\u7edf\u8ba1\u7279\u5f81\u5982\u4f55\u5f71\u54cd\u9999\u6e2f\u5c45\u6c11\u5bf9\u65c5\u6e38\u91cd\u8981\u6027\u7684\u611f\u77e5\u4ee5\u53ca\u4eba\u53e3\u7edf\u8ba1\u7279\u5f81\u5982\u4f55\u5f71\u54cd\u9999\u6e2f\u5c45\u6c11\u7684\u51fa\u6e38\u52a8\u673a.\u56de\u5f52\u7ed3\u679c\u663e\u793a:\u4f11\u95f2\u653e\u677e\u548c\u53d1\u6398\u65b0\u4e8b\u7269\u662f\u5f71\u54cd\u65c5\u6e38\u91cd\u8981\u6027\u611f\u77e5\u7684\u4e3b\u8981\u65c5\u6e38\u52a8\u673a,\u5bb6\u5ead\u6708\u6536\u5165\u548c\u53d7\u6559\u80b2\u7a0b\u5ea6\u662f\u5f71\u54cd\u65c5\u6e38\u91cd\u8981\u6027\u611f\u77e5\u7684\u4e3b\u8981\u4eba\u53e3\u7edf\u8ba1\u7279\u5f81;\u4e0e\u4eb2\u670b\u597d\u53cb\u805a\u4f1a,\u793e\u4ea4,\u4f11\u95f2\u653e\u677e,\u9003\u8131\u65e5\u5e38\u4e8b\u52a1\u548c\u53d1\u6398\u65b0\u4e8b\u7269\u52a8\u673a\u6700\u76f8\u5173\u7684\u4eba\u53e3\u7edf\u8ba1\u7279\u5f81\u5206\u522b\u662f\u5bb6\u5ead\u6708\u6536\u5165,\u5e74\u9f84,\u5bb6\u5ead\u6708\u6536\u5165,\u5e74\u9f84\u548c\u53d7\u6559\u80b2\u7a0b\u5ea6,\u800c\u6027\u522b\u5bf9\u9999\u6e2f\u5c45\u6c11\u7684\u5404\u79cd\u51fa\u6e38\u52a8\u673a\u65e0\u663e\u8457\u5f71\u54cd.", "num_citations": "7\n", "authors": ["1179"]}
{"title": "HITSCIR System in NTCIR-9 Subtopic Mining Task.\n", "abstract": " Web queries tend to have multiple user intents. Automatically identifying query intents will benefit search result navigation, search result diversity and personalized search. This paper presents the HITSCIR system in NTCIR-9 subtopic mining task. Firstly, the system collects query intent candidates from multiple resources. Secondly, Affinity Propagation algorithm is applied for clustering these query intent candidates. It could decide the number of clusters automatically. Each cluster has a representative intent candidate called exemplar. Prior preference and heuristic pair-wise preferences could be incorporated in the clustering framework. Finally, the exemplars are ranked by considering each own quality and the popularity of the clusters they represent. The NTCIR-9 evaluation results show that our system could effectively mine query intents with good relevance, diversity and readability.", "num_citations": "7\n", "authors": ["1179"]}
{"title": "Reordering with source language collocations\n", "abstract": " This paper proposes a novel reordering model for statistical machine translation (SMT) by means of modeling the translation orders of the source language collocations. The model is learned from a word-aligned bilingual corpus where the collocated words in source sentences are automatically detected. During decoding, the model is employed to softly constrain the translation orders of the source language collocations, so as to constrain the translation orders of those source phrases containing these collocated words. The experimental results show that the proposed method significantly improves the translation quality, achieving the absolute improvements of 1.1~ 1.4 BLEU score over the baseline methods.", "num_citations": "7\n", "authors": ["1179"]}
{"title": "\u57fa\u4e8e\u8bdd\u9898\u548c\u4fee\u8f9e\u8bc6\u522b\u7684\u9605\u8bfb\u7406\u89e3 why \u578b\u95ee\u9898\u56de\u7b54\n", "abstract": " \u9488\u5bf9\u9605\u8bfb\u7406\u89e3\u95ee\u7b54\u4e2d\u7684 why \u578b\u95ee\u9898, \u63d0\u51fa\u57fa\u4e8e\u95ee\u9898\u8bdd\u9898\u548c\u8bdd\u9898\u95f4\u56e0\u679c\u4fee\u8f9e\u5173\u7cfb\u8bc6\u522b\u7684\u7b54\u6848\u53e5\u62bd\u53d6\u65b9\u6cd5. \u62bd\u53d6\u65f6\u5229\u7528\u673a\u5668\u5b66\u4e60\u65b9\u6cd5, \u9009\u62e9\u53ef\u8bc6\u522b\u51fa\u5bf9\u5e94\u95ee\u9898\u8bdd\u9898\u7684\u53e5\u5b50\u7279\u5f81, \u95ee\u9898\u8bdd\u9898\u4e0e\u53e5\u5b50\u4e0a\u4e0b\u6587\u4e4b\u95f4\u56e0\u679c\u5173\u7cfb\u7279\u5f81, \u5bf9\u7bc7\u7ae0\u5185\u7684\u53e5\u5b50\u6309\u7167\u6210\u4e3a\u7b54\u6848\u53e5\u7684\u6982\u7387\u8fdb\u884c\u6392\u5e8f. \u5bf9\u5e94\u95ee\u9898\u8bdd\u9898\u7684\u53e5\u5b50\u8bc6\u522b\u5229\u7528\u57fa\u4e8e idf \u548c\u8bed\u4e49\u89d2\u8272\u7684\u76f8\u4f3c\u5ea6; \u56e0\u679c\u4fee\u8f9e\u5173\u7cfb\u7684\u8bc6\u522b\u5229\u7528\u7ebf\u7d22\u77ed\u8bed, \u7279\u5b9a\u8bed\u4e49\u89d2\u8272, \u4ece\u6587\u6863\u96c6\u4e2d\u6316\u6398\u7684\u8bcd\u95f4\u8574\u542b\u7684\u56e0\u679c\u5173\u7cfb\u6982\u7387\u4fe1\u606f, \u53e5\u5b50\u4e0a\u4e0b\u6587\u7684\u4f4d\u7f6e\u4e0e\u8868\u8fbe\u5f62\u5f0f. Remedia \u8bed\u6599\u4e0a\u7684\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e, \u8be5\u65b9\u6cd5\u660e\u663e\u63d0\u9ad8\u4e86 why \u578b\u95ee\u9898\u56de\u7b54\u7684\u6027\u80fd.", "num_citations": "7\n", "authors": ["1179"]}
{"title": "Modeling Socio-Cultural Phenomena in Online Multi-Party Discourse.\n", "abstract": " We present in this paper, the application of a novel approach to computational modeling, understanding and detection of social phenomena in online multi-party discourse. A two-tiered approach was developed to detect a collection of social phenomena deployed by participants, such as topic control, task control, disagreement and involvement. We discuss how the mid-level social phenomena can be reliably detected in discourse and these measures can be used to differentiate participants of online discourse. Our approach works across different types of online chat and we show results on two specific data sets.", "num_citations": "7\n", "authors": ["1179"]}
{"title": "Improving dependency parsing using punctuation\n", "abstract": " The high-order graph-based dependency parsing model achieves state-of-the-art accuracy by incorporating rich feature representations. However, its parsing efficiency and accuracy degrades dramatically when the input sentence gets longer. This paper presents a novel two-stage method to improve high-order graph-based parsing, which uses punctuation, such as commas and semicolons, to segment the input sentence into fragments, and then applies a two-level parsing. Experimental results on the Chinese data set of the CoNLL 2009 shared task show that our two-stage method significantly outperforms both the conventional one-stage method and previously-proposed three-stage method in terms of both parsing efficiency and accuracy.", "num_citations": "7\n", "authors": ["1179"]}
{"title": "\u57fa\u4e8e\u6539\u8fdb TextTiling \u65b9\u6cd5\u7684\u7528\u6237\u65b0\u5174\u8da3\u53d1\u73b0\u7684\u7814\u7a76\n", "abstract": " \u4e2a\u6027\u5316\u4fe1\u606f\u68c0\u7d22\u53ef\u4ee5\u6839\u636e\u7528\u6237\u7684\u68c0\u7d22\u5174\u8da3\u8fd4\u56de\u4e2a\u6027\u5316\u7684\u68c0\u7d22\u7ed3\u679c. \u63d0\u51fa\u4e86\u7528\u6237\u65b0\u5174\u8da3\u53d1\u73b0\u5b50\u4efb\u52a1, \u6839\u636e\u7528\u6237\u68c0\u7d22\u5bf9\u8c61\u7684\u53d8\u5316\u8bc6\u522b\u5305\u542b\u65b0\u68c0\u7d22\u5174\u8da3\u7684\u67e5\u8be2. \u540c\u65f6, \u5f15\u5165 TextTiling \u65b9\u6cd5\u5e76\u5bf9\u5176\u8fdb\u884c\u6539\u8fdb, \u4f7f\u7cfb\u7edf\u53ef\u4ee5\u81ea\u52a8\u9009\u62e9\u5408\u9002\u7684\u52a8\u6001\u9608\u503c\u5e76\u51c6\u786e\u53d1\u73b0\u7528\u6237\u68c0\u7d22\u5174\u8da3\u7684\u8f6c\u79fb. \u5728\u6784\u5efa\u7684\u6807\u51c6\u8bc4\u6d4b\u96c6\u4e0a\u7684\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e, \u6539\u8fdb\u7684 TextTiling \u65b9\u6cd5\u4f7f\u5f97\u7528\u6237\u65b0\u5174\u8da3\u53d1\u73b0\u7cfb\u7edf\u6027\u80fd\u63d0\u9ad8\u4e86 16.4%, \u800c\u4e14\u6b64\u5b50\u4efb\u52a1\u4f7f\u5f97\u6700\u7ec8\u7684\u4e2a\u6027\u5316\u68c0\u7d22\u7cfb\u7edf\u7684\u6027\u80fd\u63d0\u9ad8\u4e86 3.8%.", "num_citations": "7\n", "authors": ["1179"]}
{"title": "Recommended or not? Give advice on online products\n", "abstract": " This paper introduces an opinion judgment system that automatically gives advice on whether to recommend this product and furthermore provides corresponding reasons.The core task of the system can be considered as a binary sentence sentiment classification problem. A novel \"polarityword-target\" related feature extraction method is proposed. An opinion judgment system is then built based on the sentiment of each sentence predicted by a maximum entropy (ME) classifier with the novel features. The experimental results on two domains show that the special feature extraction methods are promising; the opinion judgment system with 91.5% average accuracy is highly effective.", "num_citations": "7\n", "authors": ["1179"]}
{"title": "Subdividing verbs to improve syntactic parsing\n", "abstract": " This paper proposes a new way to improve the performance of dependency parser: subdividing verbs according to their grammatical functions and integrating the information of verb subclasses into lexicalized parsing model. Firstly, the scheme of verb subdivision is described. Secondly, a maximum entropy model is presented to distinguish verb subclasses. Finally, a statistical parser is developed to evaluate the verb subdivision. Experimental results indicate that the use of verb subclasses has a good influence on parsing performance.", "num_citations": "7\n", "authors": ["1179"]}
{"title": "\u53ef\u5206\u6027\u5224\u636e\u5728\u4e2d\u6587\u7f51\u9875\u5206\u7c7b\u4e2d\u7684\u5e94\u7528\n", "abstract": " \u63d0\u51fa\u4e86\u4e00\u79cd\u6539\u8fdb\u7684\u57fa\u4e8e\u7edf\u8ba1\u7684\u4e2d\u6587\u7f51\u9875\u7684\u5206\u7c7b\u7b97\u6cd5,\u901a\u8fc7\u5bf9\u4f20\u7edf\u7684\u57fa\u4e8e\u8ba1\u7b97\u76f8\u4f3c\u5ea6\u6587\u672c\u5206\u7c7b\u65b9\u6cd5\u548c\u57fa\u4e8e\u8d1d\u53f6\u65af\u6a21\u578b\u6587\u672c\u5206\u7c7b\u7b97\u6cd5\u7684\u7814\u7a76,\u6211\u4eec\u5bf9\u8d1d\u53f6\u65af\u6a21\u578b\u5206\u7c7b\u7b97\u6cd5\u8fdb\u884c\u4e86\u6539\u8fdb,\u63d0\u51fa\u4e86\u5229\u7528\u4e00\u79cd\u57fa\u4e8e\u6982\u7387\u5206\u5e03\u7684\u53ef\u5206\u6027\u5224\u636e\u5206\u7c7b\u65b9\u6cd5,\u5373\u7528\u7c7b\u522b\u5bc6\u5ea6\u51fd\u6570\u4f3c\u7136\u6bd4\u6765\u589e\u52a0\u7279\u5f81\u8bcd\u7684\u53ef\u5206\u6027\u4fe1\u606f\u7684\u7b97\u6cd5.\u901a\u8fc7\u5bf9\u8ba1\u7b97\u76f8\u4f3c\u5ea6\u65b9\u6cd5,\u8d1d\u53f6\u65af\u65b9\u6cd5\u53ca\u6539\u8fdb\u7684\u8d1d\u53f6\u65af\u65b9\u6cd5\u7684\u5bf9\u6bd4\u5b9e\u9a8c\u8868\u660e,\u6539\u8fdb\u7b97\u6cd5\u53ef\u4ee5\u4f7f\u7c7b\u4e0e\u7c7b\u7684\u95f4\u9694\u6700\u5927\u5316,\u56e0\u800c\u5177\u6709\u8f83\u9ad8\u7684\u5206\u7c7b\u7cbe\u786e\u7387\u548c\u53ec\u56de\u7387.", "num_citations": "7\n", "authors": ["1179"]}
{"title": "\u4e2d\u6587\u8ba1\u7b97\u673a\u8f85\u52a9\u6821\u5bf9\u7cfb\u7edf\u539f\u7406\n", "abstract": " \u6587\u5b57\u6821\u5bf9\u662f\u62a5\u520a, \u56fe\u4e66\u51fa\u7248\u5de5\u4f5c\u4e2d\u7684\u4e00\u4e2a\u91cd\u8981\u73af\u8282, \u5176\u4efb\u52a1\u662f\u6839\u636e\u539f\u7a3f\u6838\u5bf9\u6821\u6837, \u8ba2\u6b63\u5dee\u9519, \u4ee5\u4fdd\u8bc1\u51fa\u7248\u7269\u7684\u8d28\u91cf. \u6821\u5bf9\u901a\u5e38\u5206\u4e3a\u51e0\u4e2a\u6821\u6b21 (\u6bdb\u6821, \u521d\u6821, \u4e8c\u6821, \u4e09\u6821, \u6821\u7ea2\u7b49), \u6bcf\u4e00\u6821\u6b21\u53c8\u5305\u62ec\u6821\u6837\u6253\u5370, \u7eb8\u4e0a\u6821\u5bf9, \u91cd\u65b0\u5f55\u5165\u7b49\u6b65\u9aa4.", "num_citations": "7\n", "authors": ["1179"]}
{"title": "CTGA: Graph-based Biomedical Literature Search\n", "abstract": " Scientists are relying heavily on biomedical literature search (BLS) engines (e.g., PubMed) to acquire knowledge. Existing BLS systems adopt a \u201cC-A\u201d paradigm that is to design query-document similarity measurement based on words/phrases in the unstructured Content and to develop search Algorithms. In this work, we argue that structures should be extracted and utilized to bridge the gap between text content and knowledge-based search. And graph is one of the most effective structured forms of knowledge and more informative than words or phrases. So we carry out a paradigm shift from \u201cC-A\u201d to \u201cCTGA\u201d. Here \u201cT\u201d is for factual tuple of concepts and relations, and \u201cG\u201d is for knowledge graph. Our proposed graph-based BLS system has three parts: (1) it uses neural information extraction models to turn text into tuples; (2) it represents the tuples of a query or a document as a knowledge graph of linked concept\u00a0\u2026", "num_citations": "6\n", "authors": ["1179"]}
{"title": "CCG supertagging with bidirectional long short-term memory networks\n", "abstract": " Neural Network-based approaches have recently produced good performances in Natural language tasks, such as Supertagging. In the supertagging task, a Supertag (Lexical category) is assigned to each word in an input sequence. Combinatory Categorial Grammar Supertagging is a more challenging problem than various sequence-tagging problems, such as part-of-speech (POS) tagging and named entity recognition due to the large number of the lexical categories. Specifically, simple Recurrent Neural Network (RNN) has shown to significantly outperform the previous state-of-the-art feed-forward neural networks. On the other hand, it is well known that Recurrent Networks fail to learn long dependencies. In this paper, we introduce a new neural network architecture based on backward and Bidirectional Long Short-Term Memory (BLSTM) Networks that has the ability to memorize information for long\u00a0\u2026", "num_citations": "6\n", "authors": ["1179"]}
{"title": "ContextCare: Incorporating Contextual Information Networks to Representation Learning on Medical Forum Data.\n", "abstract": " Online users have generated a large amount of health-related data on medical forums and search engines. However, exploiting these rich data for orienting patient online and assisting medical checkup offline is nontrivial due to the sparseness of existing symptom-disease links, which caused by the natural and chatty expressions of symptoms. In this paper, we propose a novel and general representation learning method CONTEXTCARE for human generated health-related data, which learns latent relationship between symptoms and diseases from the symptom-disease diagnosis network for disease prediction, disease category prediction and disease clustering. To alleviate the network sparseness, CONTEXTCARE adopts regularizations from rich contextual information networks including a symptom co-occurrence network and a disease evolution network. Therefore, our representations of symptoms and diseases incorporate knowledge from these three networks. Extensive experiments on medical forum data demonstrate that CONTEXTCARE outperforms the state-of-theart methods in disease category prediction, disease prediction and disease clustering.", "num_citations": "6\n", "authors": ["1179"]}
{"title": "Learning to identify sentence parallelism in student essays\n", "abstract": " Parallelism is an important rhetorical device. We propose a machine learning approach for automated sentence parallelism identification in student essays. We build an essay dataset with sentence level parallelism annotated. We derive features by combining generalized word alignment strategies and the alignment measures between word sequences. The experimental results show that sentence parallelism can be effectively identified with a F1 score of 82% at pair-wise level and 72% at parallelism chunk level. Based on this approach, we automatically identify sentence parallelism in more than 2000 student essays and study the correlation between the use of sentence parallelism and the types and quality of essays.", "num_citations": "6\n", "authors": ["1179"]}
{"title": "Product Aspect Clustering by Incorporating Background Knowledge for Opinion Mining\n", "abstract": " Product aspect recognition is a key task in fine-grained opinion mining. Current methods primarily focus on the extraction of aspects from the product reviews. However, it is also important to cluster synonymous extracted aspects into the same category. In this paper, we focus on the problem of product aspect clustering. The primary challenge is to properly cluster and generalize aspects that have similar meanings but different representations. To address this problem, we learn two types of background knowledge for each extracted aspect based on two types of effective aspect relations: relevant aspect relations and irrelevant aspect relations, which describe two different types of relationships between two aspects. Based on these two types of relationships, we can assign many relevant and irrelevant aspects into two different sets as the background knowledge to describe each product aspect. To obtain abundant background knowledge for each product aspect, we can enrich the available information with background knowledge from the Web. Then, we design a hierarchical clustering algorithm to cluster these aspects into different groups, in which aspect similarity is computed using the relevant and irrelevant aspect sets for each product aspect. Experimental results obtained in both camera and mobile phone domains demonstrate that the proposed product aspect clustering method based on two types of background knowledge performs better than the baseline approach without the use of background knowledge. Moreover, the experimental results also indicate that expanding the available background knowledge using the Web is feasible.", "num_citations": "6\n", "authors": ["1179"]}
{"title": "Learning to start for sequence to sequence architecture\n", "abstract": " The sequence to sequence architecture is widely used in the response generation and neural machine translation to model the potential relationship between two sentences. It typically consists of two parts: an encoder that reads from the source sentence and a decoder that generates the target sentence word by word according to the encoder's output and the last generated word. However, it faces to the cold start problem when generating the first word as there is no previous word to refer. Existing work mainly use a special start symbol to generate the first word. An obvious drawback of these work is that there is not a learnable relationship between words and the start symbol. Furthermore, it may lead to the error accumulation for decoding when the first word is incorrectly generated. In this paper, we proposed a novel approach to learning to generate the first word in the sequence to sequence architecture rather than using the start symbol. Experimental results on the task of response generation of short text conversation show that the proposed approach outperforms the state-of-the-art approach in both of the automatic and manual evaluations.", "num_citations": "6\n", "authors": ["1179"]}
{"title": "Personalized microtopic recommendation with rich information\n", "abstract": " Sina Weibo allows users to create tags enclosed in a pair of # which are called microtopics. Each microtopic has a designate page, and can be directly visited and commented on. Microtopic recommendation can facilitate users to efficiently acquire information by summarizing trending online topics and feeding comments with high quality. However, it is non-trivial to recommend microtopics to the users of Sina Weibo to satisfy their information needs. In this paper, we focus on personalized microtopic recommendation. Collaborative filtering based methods only utilize the user adoption matrix, while content based methods only use textual information. However, both of them can not achieve satisfactory performance in real scenarios. Moreover, auxiliary information on social media provides great potential to improve the recommendation performance. Therefore, we propose a novel hierarchical Bayesian model\u00a0\u2026", "num_citations": "6\n", "authors": ["1179"]}
{"title": "Web \u67e5\u8be2\u65e5\u5fd7\u7814\u7a76\u7efc\u8ff0\n", "abstract": " \u672c\u6587\u5bf9\u67e5\u8be2\u65e5\u5fd7\u5728\u76f8\u5173\u9886\u57df\u5185\u7684\u7814\u7a76\u73b0\u72b6\u4e0e\u8fdb\u5c55\u8fdb\u884c\u4e86\u603b\u7ed3. \u9996\u5148\u4ecb\u7ecd\u4e86 web \u67e5\u8be2\u65e5\u5fd7\u7684\u5e38\u7528\u4fe1\u606f\u548c\u516c\u5f00\u7684\u6570\u636e\u96c6; \u8fdb\u800c\u9610\u8ff0\u4e86\u67e5\u8be2\u65e5\u5fd7\u5728 web \u641c\u7d22, \u4fe1\u606f\u62bd\u53d6\u7b49\u65b9\u9762\u7684\u76f8\u5173\u7814\u7a76, \u5e76\u5bf9\u5b83\u4eec\u8fdb\u884c\u4e86\u7ec6\u81f4\u7684\u4ecb\u7ecd\u548c\u5206\u6790; \u6700\u540e\u6307\u51fa\u57fa\u4e8e\u67e5\u8be2\u65e5\u5fd7\u7814\u7a76\u6240\u9762\u4e34\u7684\u95ee\u9898\u548c\u6311\u6218. \u91cd\u5728\u5bf9\u57fa\u4e8e\u67e5\u8be2\u65e5\u5fd7\u7814\u7a76\u7684\u4e3b\u6d41\u65b9\u6cd5\u548c\u524d\u6cbf\u8fdb\u5c55\u8fdb\u884c\u6982\u62ec, \u6bd4\u8f83\u548c\u5206\u6790, \u4ee5\u671f\u5bf9\u540e\u7eed\u7814\u7a76\u6709\u6240\u52a9\u76ca.", "num_citations": "6\n", "authors": ["1179"]}
{"title": "\u57fa\u4e8e\u4e3b\u52a8\u5b66\u4e60\u7684\u4e2d\u6587\u4f9d\u5b58\u53e5\u6cd5\u5206\u6790\n", "abstract": " \u6458! \u8981\" JK \u4f9d LM \u6cd5\u5206\u6790 NO \u8981 P \u7528\u6709 Q \u5bfc\u7684 RSTU \u65b9\u6cd5!) \u9700\u8981\u5927\u89c4\u6a21\u9ad8\u8d28\u91cf\u7684 VWX \u4e3a\u8bad\u7ec3\u8bed\u6599! \u800c\u73b0 Y Z \u4e2d\u6587\u4f9d LVW \u8d44\u6e90\u76f8\u5bf9\u8f83?! VW \u6807\u6ce8 [\u662f \u00ca\\] \u65f6] \u529b\u7684^ X% _ \u5bf9\u5927\u91cf\u672a\u6807\u6ce8\u8bed\u6599! \u8be5\u6587\u5c06 O \u52a8 TU \u5e94\u7528\u5230\u4e2d\u6587\u4f9d LM \u6cd5\u5206\u6790!\u5148 abM \u6cd5\u6a21\u578b c \u6d4b\u4e0d\u51c6\u7684\u5b9e de \u7531 \u00e7^ \u6807\u6ce8% \u8be5\u6587\u63d0 i \u5e76\u6bd4\u8f83\u4e86\u591a# f \u91cf\u4f9d LM \u6cd5\u6a21\u578b c \u6d4b\u53ef\u4fe1\u5ea6\u7684\u51c6 g% \u5b9e\u9a8c\u8868\u660e! \u00ca \u65b9 _! hiRab \u6807\u6ce8\u5b9e d \u76f8\u6bd4! \u5f53\u4f7f\u7528\u76f8\u540c jJ \u8bad\u7ec3\u5b9e d \u65f6! O \u52a8 TU \u4f7f\u4e2d\u6587\u4f9d L \u5206\u6790\u6027\u80fd\u6700\u9ad8\u63d0\u5347#:= e (k\u00ca \u65b9 _! O \u52a8 TU \u4f7f\u4f9d L \u5206\u6790\u8fbe\u5230\u76f8\u540c\u51c6 l \u7387\u65f6 m \u9700\u6807\u6ce8 n? \u91cf\u5b9e d! \u00e7^ \u6807\u6ce8\u91cf\u6700\u591a\u53ef o?%# e%", "num_citations": "6\n", "authors": ["1179"]}
{"title": "Unsupervised Coreference Resolution with HyperGraph Partitioning.\n", "abstract": " Unsupervised-learning based coreference resolution obviates the need for annotation of training data. However, unsupervised approaches have traditionally been relying on the use of mention-pair models, which only consider information pertaining to a pair of mentions at a time. In this paper, it is proposed the use of hypergraph partitioning to overcome this limitation. The mentions are modeled as vertices. By allowing a hyperedge to cover multiple mentions that share a common property, the additional information beyond a mention pair can be captured. This paper introduces a hypergraph partitioning algorithm that divides mentions directly into equivalence classes representing individual entities. Evaluation on the ACE dataset shows that our unsupervised hypergraph based approach outperforms previous unsupervised methods.", "num_citations": "6\n", "authors": ["1179"]}
{"title": "\u57fa\u4e8e\u4eba\u5de5\u6807\u6ce8\u7684\u4e2a\u6027\u5316\u68c0\u7d22\u7cfb\u7edf\u8bc4\u6d4b\u7684\u7814\u7a76\n", "abstract": " \u4e2a\u6027\u5316\u4fe1\u606f\u68c0\u7d22\u53ef\u4ee5\u6839\u636e\u7528\u6237\u7684\u68c0\u7d22\u5174\u8da3\u8fd4\u56de\u4e2a\u6027\u5316\u7684\u68c0\u7d22\u7ed3\u679c. \u8be5\u6587\u6784\u5efa\u4e86\u4e2a\u6027\u5316\u68c0\u7d22\u6807\u6ce8\u7cfb\u7edf\u548c\u4e2a\u6027\u5316\u68c0\u7d22\u8bc4\u6d4b\u7cfb\u7edf, \u751f\u6210\u4e2a\u6027\u5316\u68c0\u7d22\u7cfb\u7edf\u6240\u9700\u7684\u8bed\u6599\u96c6; \u5e76\u63d0\u51fa\u4e86\u4ee5\u7528\u6237\u4e3a\u4e2d\u5fc3\u7684\u57fa\u4e8e\u4eba\u5de5\u6807\u6ce8\u7684\u4e2a\u6027\u5316\u68c0\u7d22\u8bc4\u4ef7\u65b9\u6cd5. \u4e2a\u6027\u5316\u68c0\u7d22\u8bc4\u6d4b\u7cfb\u7edf\u91c7\u7528\u4e86 NTST \u6240\u5efa\u7acb\u7684\u8bc4\u4ef7\u4f53\u7cfb, \u6839\u636e\u7528\u6237\u7684\u6807\u6ce8\u7ed3\u679c\u5bf9\u4e2a\u6027\u5316\u68c0\u7d22\u7cfb\u7edf\u7684\u751f\u80fd\u8fdb\u884c\u81ea\u52a8\u8bc4\u4ef7, \u5e76\u7ed9\u51fa\u91cf\u5316, \u76f4\u89c2\u7684\u6027\u80fd\u6307\u6807.", "num_citations": "6\n", "authors": ["1179"]}
{"title": "HITIR's Update Summary at TAC 2008: Extractive Content Selection for Language Independence.\n", "abstract": " The update summary aims to capture evolving information of a single topic changing over time. It delivers salient and novel information to a user who has already read a set of older documents covering the same topic. According to the new challenges brought by update summary, we propose the evolutionary manifold-ranking algorithm, and further integrate the sub-topics partition with spectral clustering to have a content selection, which is completely language independence. Three systems: 11, 41 and 62 are submitted. Our best system ranks three top 1 under average modified (pyramid) score, average numSCUs and macro-average modified score with 3 models of PYRAMID, ranks 13th in ROUGE-2, ranks 15th in ROUGE-SU4 and ranks 17th in BE. Though the evaluation results show the interesting performance of the proposed method, yet the problem is far from solved.", "num_citations": "6\n", "authors": ["1179"]}
{"title": "Search result clustering based on centroid optimization by ontology extraction\n", "abstract": " Along with the constant development of the Internet and the ever-increasing amount of data, the role of search engines has become increasingly evident. More users rely on search engines to find the information needed. In order to more effectively cluster the search results, thus facilitating the positioning of information among the original unstructured results, a new label-based clustering algorithm is introduced in this paper. The key idea is to use the dictionary resource and Dependency Syntax Parsing in NLP to extract the ontologies related to the query. These extracted ontologies will further guide the choosing of centroids in K-means clustering. Furthermore, the various features of K-means algorithm have been fully investigated, and a way of improvement is proposed by using the cluster labels. Experiments show that this algorithm not only yields more effective cluster results but also provides more informative descriptions of the results; meanwhile, the efficiency has also been largely improved.", "num_citations": "6\n", "authors": ["1179"]}
{"title": "Answer sentence extraction of reading comprehension based on shallow sematic tree kernel\n", "abstract": " Automatic reading comprehension systems can analyze a given passage and generate/extract answers in response to questions about the passage. An approach integrating shallow semantic information to extract answer sentence is proposed in this paper. The labeled semantic roles in question and candidate sentences are represented as semantic trees, then the structure similarity is calculated using tree kernel between them. After combining the similarity with matching words count obtained using bag-of-words method, the sentence with the highest score is chosen as answer sentence. The proposed approach achieves 43.3% HumSent accuracy on the Remedia corpora.", "num_citations": "6\n", "authors": ["1179"]}
{"title": "Survey on paraphrasing technology\n", "abstract": " Paraphrase is a common phenomenon in natural language which captures core aspects of variability in language. The study of paraphrase is about the synonymy phenomena of phrases or sentences. With the development of foundation technology of natural language processing, research on paraphrase has been recently received growing attention. Currently, paraphrasing technology has been applied in many NLP fields, such as, information retrieval, question answering, information extraction, automatic text summarization, machine translation and text watermark, to improve the performance of these systems. This paper will mainly survey several aspects of paraphrasing technology as followed: paraphrases corpus construction, paraphrases rules extraction, paraphrases generation and paraphrase evaluation. And some of our work about paraphrase are also introduced in brief. At the last section, some challenges, together with the future directions of paraphrasing technology are indicated.", "num_citations": "6\n", "authors": ["1179"]}
{"title": "Sentence Similarity Computing Based on Multi-Features Fusion\n", "abstract": " Sentence similarity computing has been widely used in the field of natural language processing. Through the in-depth analysis of sentence and the sentence similarity computing method based on the keywords feature, the semantic feature and the syntactic feature, we propose a new method based on the multi-features fusion. Using the weight to describe the contribution of each feature of the sentence, then we can get a better experiment result. Comparing to other sentence similarity computing methods, our method can fully describe the features of the sentence, and then we can get the more accurate result.", "num_citations": "6\n", "authors": ["1179"]}
{"title": "Assigning Break Indices for Unrestricted Texts in Mandarin Text to Speech System [J]\n", "abstract": " This paper uses a corpus with break indices based on C-TOBI. Applying supervised learning method, some useful attempts are made in the field of automatic break indices intonation. Three approaches, namely, the basic Markov model approach, the Markov model using word length approach, and the Markov model using word length combining transformation-based error-driven learning approach, are presented. After implementing these three approaches, open tests are made on a corpus of 3,000 sentences. The performances are getting better and the last approach produces the highest accuracy, 78.5%, and results in 14.5% decrease in error-cost taking the result of Markov model as baseline.", "num_citations": "6\n", "authors": ["1179"]}
{"title": "\u5229\u7528\u4e09\u5143\u6a21\u578b\u53ca\u4f9d\u5b58\u5206\u6790\u67e5\u627e\u4e2d\u6587\u6587\u672c\u9519\u8bef\n", "abstract": " \u81ea\u52a8\u6821\u5bf9\u662f\u81ea\u7136\u8bed\u8a00\u5904\u7406\u9886\u57df\u4e2d\u6709\u7740\u5e7f\u9614\u5e94\u7528\u524d\u666f\u7684\u4e00\u4e2a\u7814\u7a76\u65b9\u5411.\u9488\u5bf9\u76ee\u524d\u67e5\u9519\u65b9\u6cd5\u7684\u8bf8\u591a\u4e0d\u8db3,\u672c\u6587\u5e94\u7528n-gmm\u6a21\u578b\u8fdb\u884c\u6587\u672c\u5c40\u90e8\u9519\u8bef\u7684\u67e5\u627e,\u5e76\u5bf9\u75284\u79cd\u65b9\u6cd5\u5efa\u7acb\u7684\u6a21\u578b\u5206\u522b\u8fdb\u884c\u4e86\u81ea\u52a8\u6821\u5bf9\u7684\u5b9e\u9a8c,\u4ece\u4e2d\u9009\u51fa\u67e5\u627e\u5c40\u90e8\u9519\u8bef\u6548\u679c\u6700\u597d\u7684\u4e09\u5143\u5b57\u6a21\u578b.\u540c\u65f6\u5c06\u4f9d\u5b58\u6587\u6cd5\u5206\u6790\u5e94\u7528\u4e8e\u81ea\u52a8\u6821\u5bf9\u4e2d,\u8fdb\u884c\u8fdc\u8ddd\u79bb\u642d\u914d\u9519\u8bef\u7684\u67e5\u627e,\u8f83\u597d\u5730\u89e3\u51b3\u4e86\u6587\u672c\u4e2d\u7684\u4e00\u4e9b\u5168\u5c40\u9519\u8bef.\u7ed3\u5408\u5bf9\u6587\u672c\u7684\u6563\u4e32\u5904\u7406,\u8be5\u65b9\u6cd5\u83b7\u5f97\u4e8664.91%\u7684\u51c6\u786e\u7387\u548c69.05%\u7684\u53ec\u56de\u7387,\u8bc1\u660e\u4e86\u4e09\u5143\u5b57\u7ed3\u5408\u4f9d\u5b58\u5206\u6790\u53ca\u6563\u4e32\u5904\u7406\u8fd9\u79cd\u65b9\u6cd5\u7684\u53ef\u884c\u6027.", "num_citations": "6\n", "authors": ["1179"]}
{"title": "Investigation on Pollution in Urban Gutters\n", "abstract": " Gutters are main inlets through them urban runoff gets into drainage system and non-point source pollutants into receiving waters. Once they are filled up with litter, not only flooding could happen but also it should result in serious pollution of the waters. This article gives a spot investigation on the gutters in Beijing urban area and carries out a simulated experiment with the litters from gutters and gives a quantitative estimation of the pollutants from the litters. The ponderance of the pollution from gutter-litter and significance of management for Chinese cities is discussed.", "num_citations": "6\n", "authors": ["1179"]}
{"title": "Benben: A Chinese intelligent conversational robot\n", "abstract": " Recently, conversational robots are widely used in mobile terminals as the virtual assistant or companion. The goals of prevalent conversational robots mainly focus on four categories, namely chitchat, task completion, question answering and recommendation. In this paper, we present a Chinese intelligent conversational robot, Benben, which is designed to achieve these goals in a unified architecture. Moreover, it also has some featured functions such as diet map, implicit feedback based conversation, interactive machine reading, news recommendation, etc. Since the release of Benben at June 6, 2016, there are 2,505 users (till Feb 22, 2017) and 11,107 complete humanrobot conversations, which totally contain 198,998 single turn conversation pairs.", "num_citations": "5\n", "authors": ["1179"]}
{"title": "\u5927\u89c4\u6a21\u60c5\u611f\u8bcd\u5178\u7684\u6784\u5efa\u53ca\u5176\u5728\u60c5\u611f\u5206\u7c7b\u4e2d\u7684\u5e94\u7528\n", "abstract": " \u6458! \u8981\"\u00b6 \u5fae\u535a\u4e3a\u4ee3\u8868\u7684\u793e\u4f1a \u00f8 \u4f53\u7684\u98de\u901f\u53d1\u5c55\u4e3a\u60c5\u611f\u5206\u6790\u65b9\u5411\u5e26\u6765\u5de8\u5927\u7684\u8d44\u6e90! \u540c\u65f6\u4e5f\u5bf9\u60c5\u611f\u5206\u6790\u7b97\u6cd5\u7684\u6027\u80fd\u63d0 i \u4e86\u66f4\u5927\u7684 \u00fa \u6218% \u5176\u4e2d! \u73b0\u6709\u7684\u60c5\u611f\u8bcd\u5178\u5c24\u5176\u662f\u4e2d\u6587\u60c5\u611f\u8bcd\u5178\u89c4\u6a21\u4e0d\u8db3\u662f\u5f71\u54cd\u60c5\u611f\u5206\u6790\u6027\u80fd\u7684# \u4e2a\u91cd\u8981\u56e0\u7d20% \u4e3a\u6b64! \u8be5\u6587\u57fa\u4e8e\u6d77\u91cf\u7684\u5fae\u535a\u6570\u636e! \u4f7f\u7528\u7b80\u5355\u7684\u6587 & \u7edf\u8ba1\u7b97\u6cd5! \u6784\u5efa\u4e86# \u4e2a\u5341\u4e07\u8bcd\u8bed \u8bcd\u7ec4\u7684\u5927\u89c4\u6a21\u60c5\u611f\u8bcd\u5178% \u6211\u4eec\u00b6 \u60c5\u611f\u5206\u6790\u7684\u57fa\u7840\u4efb\u52a1 \u60c5\u611f\u5206\u7c7b\u4e3a\u4f8b! \u5c06\u5927\u89c4\u6a21\u60c5\u611f\u8bcd\u5178\u4f5c\u4e3a\u7279\u5f81\u7528\u4e8e\u8be5\u4efb\u52a1\u4e0a! \u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\u5927\u89c4\u6a21\u8bcd\u5178\u6709\u52a9\u4e8e\u60c5\u611f\u5206\u7c7b\u6027\u80fd\u7684\u63d0\u9ad8%", "num_citations": "5\n", "authors": ["1179"]}
{"title": "\u6587\u672c\u8574\u542b\u5173\u7cfb\u8bc6\u522b\u4e0e\u77e5\u8bc6\u83b7\u53d6\u7814\u7a76\u8fdb\u5c55\u53ca\u5c55\u671b\n", "abstract": " \u6458 \u8981 \u6587\u672c\u8574\u542b\u5173\u7cfb\u662f\u5e7f\u6cdb\u5206\u5e03\u4e8e\u81ea\u7136\u8bed\u8a00\u6587\u672c\u4e2d\u7684\u5355\u5411\u63a8\u7406\u5173\u7cfb, \u6587\u672c\u8574\u542b\u76f8\u5173\u7814\u7a76\u662f\u81ea\u7136\u8bed\u8a00\u5904\u7406\u9886\u57df\u7684\u4e00\u9879\u57fa\u7840\u6027\u7814\u7a76, \u5b83\u53ef\u4ee5\u8f85\u52a9\u5176\u4ed6\u81ea\u7136\u8bed\u8a00\u5904\u7406\u4efb\u52a1\u7684\u8fdb\u884c, \u5e76\u4e14\u5177\u6709\u4e30\u5bcc\u7684\u5e94\u7528\u573a\u666f. \u6587\u4e2d\u9996\u5148\u754c\u5b9a\u4e86\u6587\u672c\u8574\u542b\u7814\u7a76\u7684\u8303\u7574. \u4f5c\u4e3a\u4e00\u79cd\u4e8c\u5143\u5173\u7cfb, \u6587\u672c\u8574\u542b\u6709 3 \u4e2a\u57fa\u672c\u7814\u7a76\u4efb\u52a1\u2014\u2014\u2014\u5173\u7cfb\u8bc6\u522b, \u77e5\u8bc6\u83b7\u53d6\u548c\u8574\u542b\u5bf9\u751f\u6210. \u5176\u4e2d, \u5173\u7cfb\u8bc6\u522b\u6709\u4e24\u4e2a\u6838\u5fc3\u95ee\u9898\u2014\u2014\u2014\u8bed\u4e49\u8868\u793a\u4e0e\u63a8\u7406\u673a\u5236; \u77e5\u8bc6\u83b7\u53d6\u4e5f\u6709\u4e24\u4e2a\u6838\u5fc3\u95ee\u9898\u2014\u2014\u2014\u77e5\u8bc6\u8868\u793a\u4e0e\u77e5\u8bc6\u6765\u6e90; \u8574\u542b\u5bf9\u751f\u6210\u7814\u7a76\u8fdb\u5c55\u6bd4\u8f83\u7f13\u6162, \u6587\u4e2d\u7ec6\u81f4\u5730\u5206\u6790\u4e86\u5176\u5185\u56e0\u548c\u5916\u56e0. \u6587\u4e2d\u56f4\u7ed5\u8bed\u4e49\u8868\u793a\u4e0e\u63a8\u7406\u673a\u5236\u8fd9\u4e24\u4e2a\u6838\u5fc3\u95ee\u9898\u68b3\u7406\u4e86\u5173\u7cfb\u8bc6\u522b\u7684\u7814\u7a76\u8fdb\u5c55, \u56f4\u7ed5\u77e5\u8bc6\u8868\u793a\u4e0e\u77e5\u8bc6\u6765\u6e90\u68b3\u7406\u4e86\u77e5\u8bc6\u83b7\u53d6\u7684\u7814\u7a76\u8fdb\u5c55, \u5e76\u6307\u51fa\u4e86\u5404\u7c7b\u65b9\u6cd5\u7684\u53ef\u53d6\u4e4b\u5904\u4e0e\u4e0d\u8db3\u4e4b\u5904. \u6587\u672c\u8574\u542b\u7814\u7a76\u7684\u8fdb\u5c55\u79bb\u4e0d\u5f00\u76f8\u5173\u56fd\u9645\u8bc4\u6d4b, \u6587\u4e2d\u4e5f\u5bf9\u8fd9\u4e9b\u56fd\u9645\u8bc4\u6d4b\u548c\u6570\u636e\u96c6\u8fdb\u884c\u4e86\u5f52\u7eb3\u603b\u7ed3. \u5927\u6570\u636e\u65f6\u4ee3\u7684\u5230\u6765\u548c\u6df1\u5ea6\u5b66\u4e60\u7406\u8bba\u7684\u4e0d\u65ad\u53d1\u5c55, \u4e3a\u6587\u672c\u8574\u542b\u76f8\u5173\u7814\u7a76\u63d0\u4f9b\u4e86\u4e30\u5bcc\u7684\u77e5\u8bc6\u6765\u6e90\u548c\u6709\u529b\u7684\u7814\u7a76\u5de5\u5177, \u540c\u65f6\u4e5f\u5e26\u6765\u4e86\u8bb8\u591a\u5d2d\u65b0\u7684\u7814\u7a76\u8bfe\u9898. \u6587\u4e2d\u7acb\u8db3\u5f53\u524d\u7814\u7a76\u5f62\u52bf, \u5c55\u671b\u4e86\u672a\u6765\u7814\u7a76\u65b9\u5411, \u5e76\u4ece\u7406\u8bba\u4e0a\u63a2\u8ba8\u4e86\u5176\u53ef\u884c\u6027.", "num_citations": "5\n", "authors": ["1179"]}
{"title": "A joint model for ellipsis identification and recovery\n", "abstract": " An ellipsis is a gap in a sentence due to the pragmatics conventional use of grammar. Ellipsis is a ubiquitous phenomenon in daily conversation, especially in Chinese. A question-answering (QA) system can hardly automatically understand sentences with ellipsis. As a result, the QA system may produce wrong answer and thus cannot naturally interact with humans. Therefore, it is important to recover these ellipses in order to gain a better QA system. To automatically recover these ellipsis elements, we take the recovery system into two parts: zero anaphora identification and zero anaphora resolution. When connecting these two parts together, previous work always models the two steps separately, which suffers the error accumulation problem. In order to deal with this problem, we propose a joint model method that performs the zero anaphora identification and zero anaphora resolution simultaneously in a unified framework. Besides, we focus on Chinese dialogue text, which is collected from the interview of broadcast. The experimental results show that the proposed joint model method outperforms the state-of-the-art methods significantly.", "num_citations": "5\n", "authors": ["1179"]}
{"title": "Predicting the popularity of messages on micro-blog services\n", "abstract": " Micro-blogging is one of the most popular social media services on which users can publish new messages (usually called tweets), submit their comments and retweet their followees\u2019 messages. It is retweeting behavior that leading the information diffusion in a faster way. However, why some tweets are more popular than others? Whether a message will be popular in the future? These problems have attracted great attention. In this paper, we focus on predicting the popularity of a tweet on Weibo, a famous micro-blogging service in China. It is important for tremendous tasks such as breaking news detection, personalized message recommendation, advertisement placement, viral marketing etc. We propose a novel approach to predict the retweet count of a tweet by finding top-k similar tweets published by the same author. To find the top-k similar tweets we consider both content similarity and temporal\u00a0\u2026", "num_citations": "5\n", "authors": ["1179"]}
{"title": "Discovering conceptual metaphors using source domain spaces\n", "abstract": " This article makes two contributions towards the use of lexical resources and corpora specifically making use of them for gaining access to and using word associations. The direct application of our approach is for detecting linguistic and conceptual metaphors automatically in text. We describe our method of building conceptual spaces, that is, defining the vocabulary that characterizes a Source Domain eg, Disease of a conceptual metaphor eg, Poverty is a Disease. We also describe how these conceptual spaces are used to group linguistic metaphors into conceptual metaphors. Our method works in multiple languages, including English, Spanish, Russian and Farsi. We provide details of how our method can be evaluated and evaluation results that show satisfactory performance across all languages.Descriptors:", "num_citations": "5\n", "authors": ["1179"]}
{"title": "Jointly or separately: Which is better for parsing heterogeneous dependencies?\n", "abstract": " For languages such as English, several constituent-to-dependency conversion schemes are proposed to construct corpora for dependency parsing. It is hard to determine which scheme is better because they reflect different views of dependency analysis. We usually obtain dependency parsers of different schemes by training with the specific corpus separately. It neglects the correlations between these schemes, which can potentially benefit the parsers. In this paper, we study how these correlations influence final dependency parsing performances, by proposing a joint model which can make full use of the correlations between heterogeneous dependencies, and finally we can answer the following question: parsing heterogeneous dependencies jointly or separately, which is better? We conduct experiments with two different schemes on the Penn Treebank and the Chinese Penn Treebank respectively, arriving at the same conclusion that jointly parsing heterogeneous dependencies can give improved performances for both schemes over the individual models.", "num_citations": "5\n", "authors": ["1179"]}
{"title": "A Multi-Cultural Repository of Automatically Discovered Linguistic and Conceptual Metaphors.\n", "abstract": " In this article, we present details about our ongoing work towards building a repository of Linguistic and Conceptual Metaphors. This resource is being developed as part of our research effort into the large-scale detection of metaphors from unrestricted text. We have stored a large amount of automatically extracted metaphors in American English, Mexican Spanish, Russian and Iranian Farsi in a relational database, along with pertinent metadata associated with these metaphors. A substantial subset of the contents of our repository has been systematically validated via rigorous social science experiments. Using information stored in the repository, we are able to posit certain claims in a cross-cultural context about how peoples in these cultures (America, Mexico, Russia and Iran) view particular concepts related to Governance and Economic Inequality through the use of metaphor. Researchers in the field can use this resource as a reference of typical metaphors used across these cultures. In addition, it can be used to recognize metaphors of the same form or pattern, in other domains of research.", "num_citations": "5\n", "authors": ["1179"]}
{"title": "\u4e2d\u6587\u5fae\u535a\u60c5\u611f\u503e\u5411\u6027\u5206\u6790\u7279\u5f81\u5de5\u7a0b\n", "abstract": " 1 \u54c8\u5c14\u6ee8\u5de5\u4e1a\u5927\u5b66\u8ba1\u7b97\u673a\u79d1\u5b66\u4e0e\u6280\u672f\u5b66\u9662\u4fe1\u606f\u68c0\u7d22\u7814\u7a76\u4e2d\u5fc3, \u54c8\u5c14\u6ee8, 150001 2 \u54c8\u5c14\u6ee8\u5de5\u4e1a\u5927\u5b66\u673a\u7535\u5b66\u9662\u5a92\u4f53\u7cfb, \u54c8\u5c14\u6ee8, 150001 E-mail:{zkli, yyzhao, qinb, tliu}@ ir. hit. edu. cn \u6458 \u8981: \u60c5\u611f\u503e\u5411\u6027\u5206\u6790\u662f\u60c5\u611f\u5206\u6790\u7684\u91cd\u8981\u7ec4\u6210\u90e8\u5206, \u662f\u4e00\u79cd\u6309\u7167\u60c5\u611f\u503e\u5411\u5bf9\u6587\u672c\u8fdb\u884c\u5206\u7c7b\u7684\u4efb\u52a1. \u5fae\u535a, \u4e0e\u4f20\u7edf\u7684\u8bc4\u8bba\u6587\u672c\u76f8\u6bd4\u66f4\u52a0\u53e3\u8bed\u5316\u4e0e\u7b26\u53f7\u5316, \u56e0\u6b64\u5bf9\u5fae\u535a\u8fdb\u884c\u60c5\u611f\u503e\u5411\u6027\u5206\u6790\u662f\u4e00\u4e2a\u975e\u5e38\u6709\u6311\u6218\u6027\u7684\u4efb\u52a1. \u57fa\u4e8e\u673a\u5668\u5b66\u4e60\u7684\u65b9\u6cd5\u662f\u60c5\u611f\u503e\u5411\u6027\u5206\u6790\u6700\u7ecf\u5178\u7684\u7b97\u6cd5, \u6838\u5fc3\u662f\u8981\u8fdb\u884c\u7279\u5f81\u7684\u5206\u6790\u548c\u9009\u62e9, \u4f8b\u5982\u8bcd\u888b\u7279\u5f81\u7b49. \u7136\u800c, \u7531\u4e8e\u4e2d\u6587\u8bed\u8a00\u7684\u72ec\u7279\u6027, \u524d\u4eba\u5f88\u591a\u6709\u6548\u7684\u7279\u5f81\u90fd\u662f\u8bed\u8a00\u76f8\u5173\u7684, \u5c06\u5176\u76f4\u63a5\u7528\u4e8e\u4e2d\u6587\u5fae\u535a\u6548\u679c\u4e0d\u4f73. \u5728\u4e2d\u6587\u5fae\u535a\u8bed\u6599\u4e0a, \u8fd8\u6ca1\u6709\u5b66\u8005\u8fdb\u884c\u7ec6\u81f4\u7684\u7279\u5f81\u5de5\u7a0b\u5efa\u8bbe. \u57fa\u4e8e\u6b64, \u672c\u6587\u7efc\u5408\u56fd\u5185\u5916\u8bf8\u591a\u7279\u5f81, \u5e76\u8003\u8651\u5230\u4e2d\u6587\u7684\u72ec\u7279\u6027, \u5bf9\u4e2d\u6587\u5fae\u535a\u7684\u8912\u8d2c\u4e2d\u503e\u5411\u6027\u5224\u522b\u7279\u5f81\u5de5\u7a0b\u7684\u8bcd, \u8bcd\u7ec4, \u6570\u503c\u548c\u53e5\u6cd5\u7279\u5f81\u5206\u522b\u8fdb\u884c\u4e86\u7814\u7a76, \u5e76\u63d0\u51fa\u4e86\u57fa\u4e8e\u8bcd\u5178\u89c4\u5219\u7684\u60c5\u611f\u8bc4\u5206\u7684\u65b0\u7279\u5f81. \u6700\u540e\u7ecf\u8fc7\u5927\u91cf\u5b9e\u9a8c\u4e0e\u5206\u6790, \u5f97\u51fa\u4e86\u53ef\u9760\u7684\u7279\u5f81\u7ec4\u5408. \u5b9e\u9a8c\u7ed3\u679c\u8868\u660e, \u672c\u6587\u7684\u65b9\u6cd5\u80fd\u591f\u660e\u663e\u63d0\u9ad8\u60c5\u611f\u503e\u5411\u6027\u5206\u6790\u7684\u7ed3\u679c.", "num_citations": "5\n", "authors": ["1179"]}
{"title": "\u57fa\u4e8e\u4f17\u5305\u7684\u8bcd\u6c47\u8054\u60f3\u7f51\u7edc\u7684\u83b7\u53d6\u548c\u5206\u6790\n", "abstract": " \u6458! \u8981\" H \u5178 \u6c49 5 569: N \u975e \u00fc n+ Rp \u8d44\u6e90! \u5b83@ & \u6c49 5H*)* 0L5M# $ z [\\\u8d44\u6e90 _ \u00f5& kl \u00ab\u00ac c\u00f8s* \u00db\u00dc \u6c49 55M\u00edy \u6027 H \u5178! kH \u5178 \u901a\u8fc7\u89e6 H \u8054\u00b7+ s\u00c0O \u63a5\u83b7\u53d6+! abC \u79f0 &H \u6c47\u8054\u00b7 \u7f51\u7edc &H \u6c47\u8054\u00b7 \u7f51\u7edc \u00ed\u4f20< H \u5178\u5177] 0\u00bb \u7279\u70b9\"#% $ \u83b7\u53d6, \u4ef7\u4f4e%#! $| \u4e92\u8054\u7f51! \u6613\u6269}%## $ H5y; \u00aa\u00e1+ \u8ba4 \u00fd\u00cf\u00cc \u00dc \u7acb! \u7b26\u5408 \u00e1+ AC&kl~ \u00d3\u00d4H \u6c47\u8054\u00b7 \u7f51\u7edc+ \u83b7\u53d6 s*= \u5df2\u83b7\u53d6+ \u00c6\u00c7VW# $! \u53e6\u5916! fH \u6c47\u8054\u00b7 \u7f51\u7edc\u00a5 5\u00fd \u7f51 6'5 \u540c MHH \u6797 60L \u5fae\u535a l\u00caEDM< I VW\u8f83\u8bf4\u660e\u5176 j \u7279\u70b9 &", "num_citations": "5\n", "authors": ["1179"]}
{"title": "Micro blogs oriented word segmentation system\n", "abstract": " We present a Chinese word segmentation system submitted to the first task on CLP 2012 back-offs. Our segmenter is built using a conditional random field sequence model. We set the combination of a few annotated micro blogs and People Daily corpus as the training data. We encode special words detected by rules and information extracted from unlabeled data into features. These features are used to improve our model\u2019s performance. We also derive a micro blog specified lexicon from auto-analyzed data and use lexicon related features to assist the model. When testing on the sample data of this task, these features result in 1. 8% improvement over the baseline model. Finally, our model achieves F-score of 94. 07% on the bakeoff\u2019s test set.", "num_citations": "5\n", "authors": ["1179"]}
{"title": "Modeling influence in online multi-party discourse\n", "abstract": " In this article, we present our novel approach towards the detection and modeling of complex social phenomena in multi-party discourse, including leadership, influence, pursuit of power and group cohesion. We have developed a two-tier approach that relies on observable and computable linguistic features of conversational text to make predictions about sociolinguistic behaviors such as Topic Control and Disagreement, that speakers deploy in order to achieve and maintain certain positions and roles in a group. These sociolinguistic behaviors are then used to infer higher-level social phenomena such as Influence, which is the focus of this paper. We show robust performance results by comparing our computational results to participants' own perceptions and rankings of influence. We use weights learnt from correlations with known influence rankings to compute and score sociolinguistic behaviors and show\u00a0\u2026", "num_citations": "5\n", "authors": ["1179"]}
{"title": "Chinese and American Leadership Characteristics: Discovery and Comparison in Multi-party On-Line Dialogues\n", "abstract": " Recent advances in automated analysis of on-line chat data allow us to draw conclusions about social behavior, such as leadership, in small groups previously possible only through manual methods of observation and analysis. We have applied such methods to comparable English and Chinese language data, defined a new language use called Tension Focus, and demonstrate its different effects in the data in these two languages.", "num_citations": "5\n", "authors": ["1179"]}
{"title": "\u5229\u7528\u7edf\u8ba1\u642d\u914d\u6a21\u578b\u6539\u8fdb\u57fa\u4e8e\u5b9e\u4f8b\u7684\u673a\u5668\u7ffb\u8bd1\n", "abstract": " \u57fa\u4e8e\u5b9e\u4f8b\u7684\u673a\u5668\u7ffb\u8bd1 (example-based machine translation, \u7b80\u79f0 EBMT) \u4f7f\u7528\u9884\u5904\u7406\u8fc7\u7684\u53cc\u8bed\u4f8b\u53e5\u4f5c\u4e3a\u4e3b\u8981\u7ffb\u8bd1\u8d44\u6e90, \u901a\u8fc7\u7f16\u8f91\u4e0e\u5f85\u7ffb\u8bd1\u53e5\u5b50\u5339\u914d\u7684\u7ffb\u8bd1\u5b9e\u4f8b\u6765\u751f\u6210\u8bd1\u6587. \u5728 EBMT \u7cfb\u7edf\u4e2d, \u7ffb\u8bd1\u5b9e\u4f8b\u9009\u62e9\u53ca\u8bd1\u6587\u9009\u62e9\u5bf9\u7cfb\u7edf\u6027", "num_citations": "5\n", "authors": ["1179"]}
{"title": "Active learning for Chinese dependency parsing\n", "abstract": " It is necessary to have a large annotated Treebank to build a statistical dependency parser. Acquisition of such a Treebank is time consuming, tedious and expensive. This paper presents a method to reduce this demand via active learning, which selects the most uncertain samples for annotation instead of the whole training corpus. Experiments are carried out on the HIT-CIR-CDT, our results show that the parsing accuracy rises about 0.8 percent by active learning when using the same amount of training samples. In other words, for about the same parsing accuracy, we only need to annotate 70% of the samples as compared to the usual random selection method.[Fund]: \u56fd\u5bb6\u81ea\u7136\u79d1\u5b66\u57fa\u91d1\u91cd\u70b9\u9879\u76ee (61133012); \u56fd\u5bb6\u81ea\u7136\u79d1\u5b66\u57fa\u91d1\u8d44\u52a9\u9879\u76ee (60803093);; \u56fd\u5bb6 863 \u91cd\u5927\u9879\u76ee (2011AA01A207);; \u6838\u9ad8\u57fa\u91cd\u5927\u4e13\u9879 (2011ZX01042-001-001);; \u54c8\u5c14\u6ee8\u5de5\u4e1a\u5927\u5b66\u79d1\u7814\u521b\u65b0\u57fa\u91d1 (HIT. NSRIF. 2009069);; \u4e2d\u592e\u9ad8\u6821\u57fa\u672c\u79d1\u7814\u4e1a\u52a1\u8d39\u4e13\u9879\u8d44\u91d1 (HIT. KLOF. 2010064)", "num_citations": "5\n", "authors": ["1179"]}
{"title": "Coreference resolution system using maximum entropy classifier\n", "abstract": " In this paper, we present our supervised learning approach to coreference resolution in ConLL corpus. The system relies on a maximum entropy-based classifier for pairs of mentions, and adopts a rich linguisitically motivated feature set, which mostly has been introduced by Soon et al (2001), and experiment with alternaive resolution process, preprocessing tools, and classifiers. We optimize the system\u2019s performance for MUC (Vilain et al, 1995), BCUB (Bagga and Baldwin, 1998) and CEAF (Luo, 2005).", "num_citations": "5\n", "authors": ["1179"]}
{"title": "Beam-search based high-order dependency parser [J]\n", "abstract": " We propose a high-order parsing model which uses all grandchildren nodes to compose high-order features, constrains the searching space by the beam-search strategy, and finds the approximately optimal dependency tree. In addition, we explore rich dependency label features and allow multiple relations for one arc during decoding. In the CoNLL 2009 international evaluation task of multilingual syntactic and semantic dependency parsing, this method ranks first in the joint task, and third in the syntactic parsing task.", "num_citations": "5\n", "authors": ["1179"]}
{"title": "\u57fa\u4e8e ontology \u62bd\u53d6\u4f18\u5316\u521d\u59cb\u9009\u62e9\u7684\u68c0\u7d22\u7ed3\u679c\u805a\u7c7b\n", "abstract": " \u672c\u6587\u9488\u5bf9\u4e92\u8054\u7f51\u7684\u6570\u636e\u91cf\u7684\u4e0d\u65ad\u589e\u52a0, \u51c6\u786e\u641c\u7d22\u5f15\u64ce\u7684\u4f5c\u7528\u65e5\u76ca\u56f0\u96be\u7684\u95ee\u9898, \u4e3a\u4e86\u63d0\u9ad8\u641c\u7d22\u5f15\u64ce\u8fd4\u56de\u7ed3\u679c\u7ed3\u6784\u5316\u805a\u7c7b\u7684\u6548\u679c, \u8ba9\u4fe1\u606f\u7684\u5b9a\u4f4d\u66f4\u8fc5\u901f, \u672c\u6587\u91c7\u7528\u57fa\u4e8e\u6807\u7b7e\u7684\u805a\u7c7b\u7b97\u6cd5, \u5e76\u4f7f\u7528\u81ea\u7136\u8bed\u8a00\u5904\u7406\u6280\u672f\u4e2d\u7684\u4f9d\u5b58\u53e5\u6cd5\u5206\u6790\u548c\u8bcd\u5178\u8d44\u6e90, \u6df1\u5ea6\u6316\u6398\u8bed\u4e49\u7ed3\u6784, \u63d0\u51fa\u57fa\u4e8e\u4f18\u5316\u521d\u59cb\u9009\u62e9\u7684 K \u5747\u503c\u805a\u7c7b\u65b9\u6cd5. \u672c\u6587\u6df1\u5165\u5206\u6790 K \u5747\u503c\u805a\u7c7b\u7b97\u6cd5\u7279\u70b9, \u5e76\u5229\u7528\u7c7b\u522b\u6807\u7b7e\u6280\u672f\u5bf9\u8be5\u7b97\u6cd5\u8fdb\u884c\u6709\u6548\u6539\u8fdb. \u5b9e\u9a8c\u8bc1\u660e\u8be5\u7b97\u6cd5\u4e0d\u4ec5\u5728\u6548\u679c\u4e0a\u4f18\u4e8e\u4e00\u822c\u805a\u7c7b\u7b97\u6cd5, \u5bf9\u7ed3\u679c\u63cf\u8ff0\u4e5f\u6709\u5f88\u5927\u5e2e\u52a9, \u5728\u6548\u7387\u4e0a\u4e5f\u5f97\u5230\u5f88\u5927\u63d0\u9ad8.", "num_citations": "5\n", "authors": ["1179"]}
{"title": "A simple single-carrier space-time transmission scheme for asynchronous cooperative communications over frequency-selective channels\n", "abstract": " This paper presents a simple single-carrier (SC) distributed space-time block coded transmission scheme for asynchronous cooperative communications over frequency-selective channels. The cyclic prefix (CP) at the source node and relay nodes is used to combat inter-symbol interference from multi-path fading and the timing errors from the relay nodes. In this scheme, the relay nodes only implement very simple operations on their received signals to construct distributed space-time block code, and decoding, DFT and IDFT operations are only needed at the destination node. The low complexity SC zero-forcing frequency domain equalization (ZF-FDE) is applied at the destination node to recover the transmitted signals. The analysis and simulation results demonstrate that this simple SC scheme can achieve order-two spatial diversity gain for amplify-and-forward based cooperative communication over frequency\u00a0\u2026", "num_citations": "5\n", "authors": ["1179"]}
{"title": "Modifying spectral envelope to synthetically adjust voice quality and articulation parameters for emotional speech synthesis\n", "abstract": " Both of the prosody and spectral features are important for emotional speech synthesis. Besides prosody effects, voice quality and articulation parameters are the factors that should be considered to modify in emotional speech synthetic systems. Generally, rules and filters are designed to process these parameters respectively. This paper proves that by modifying spectral envelope, the voice quality and articulation could be adjusted as a whole. Thus, it will not need to modify each of the parameter separately depending on rules. Accordingly, it will make the synthetic system more flexible by designing an automatic spectral envelope model based on some machine learning methods. The perception test in this paper also shows that when prosody and spectral features are all modified, the best emotional synthetic speech will be obtained.", "num_citations": "5\n", "authors": ["1179"]}
{"title": "A new Chinese natural language understanding architecture based on multilayer search mechanism\n", "abstract": " A classical Chinese Natural Language Understanding (NLU) architecture usually includes several NLU components which are executed with some mechanism. A new Multilayer Search Mechanism (MSM) which integrates and quantifies these components into a uniform multilayer treelike architecture is presented in this paper. The mechanism gets the optimal result with search algorithms. The components in MSM affect each other. At last, the performance of each component is enhanced. We built a practical system\u2013CUP (Chinese Understanding Platform) based on MSM with three layers. By the experiments on Word Segmentation, a better performance was achieved. In theory the normal cascade and feedback mechanism are just some special cases of MSM.", "num_citations": "5\n", "authors": ["1179"]}
{"title": "\u9690\u9a6c\u5c14\u53ef\u592b\u6a21\u578b\u548c HowNet \u5728\u6c49\u8bed\u8bcd\u4e49\u6807\u6ce8\u4e2d\u7684\u5e94\u7528\n", "abstract": " \u8bcd\u4e49\u6d88\u6b67\u4e00\u76f4\u662f\u81ea\u7136\u8bed\u8a00\u5904\u7406\u9886\u57df\u7684\u5173\u952e\u95ee\u9898\u548c\u96be\u70b9\u4e4b\u4e00. \u76ee\u524d\u8fdb\u884c\u7684\u5f88\u591a\u8bcd\u4e49\u6d88\u6b67\u7814\u7a76\u591a\u91c7\u7528\u51e0\u4e2a\u591a\u4e49\u8bcd\u4f5c\u4e3a\u8bd5\u9a8c\u6d4b\u8bd5\u5bf9\u8c61, \u5728\u5b9e\u9645\u5e94\u7528\u65b9\u9762\u5b58\u5728\u7740\u5c40\u9650\u6027. \u672c\u6587\u91c7\u7528\u9690\u9a6c\u5c14\u53ef\u592b\u6a21\u578b\u7ed3\u5408\u4e49\u7c7b\u8bcd\u5178 HowNet \u5bf9\u5927\u89c4\u6a21\u771f\u5b9e\u6587\u672c\u8fdb\u884c\u4e86\u8bcd\u4e49\u6d88\u6b67\u7814\u7a76, \u5b9e\u9a8c\u7684\u5f00\u653e\u6d4b\u8bd5\u6b63\u786e\u7387\u53ef\u4ee5\u8fbe\u5230 85.05%, \u5c01\u95ed\u5b9e\u9a8c\u6b63\u786e\u7387\u53ef\u8fbe 88.46%.", "num_citations": "5\n", "authors": ["1179"]}
{"title": "Prosodic word boundaries prediction for Mandarin text-to-speech\n", "abstract": " In Mandarin speech, the Prosodic Word (PW) is the basic rhythmic unit instead of Lexical Word (LW), and the naturalness of TTS will be directly influenced by the segmentation of PW. Most of the PWs are the combination of some LWs. In this paper, three models, ie a directed acyclic graph (DAG) model, segmentation model and Markov Model (MM) combined with Transformation-Based Error Driven (TBED) learning algorithm are designed to combine lexical words into prosodic words. Considering some long LWs should be broken into two or more PWs, a long word break model is also applied to those LWs. Experimental results show that MM combined with TBED plus a long word break model is the best one among the three methods, and 93.00% precision and 93.23% recall are achieved.", "num_citations": "5\n", "authors": ["1179"]}
{"title": "\u5f00\u653e\u57df\u4e2d\u6587\u95ee\u7b54\u7cfb\u7edf\u7684\u7814\u7a76\u4e0e\u5b9e\u73b0\n", "abstract": " \u672c\u6587\u4ecb\u7ecd\u4e86\u5f00\u653e\u57df\u4e2d\u6587\u95ee\u7b54\u7cfb\u7edf\u7684\u6280\u672f, \u5e76\u7ed9\u51fa\u4e86\u4e00\u79cd\u5b9e\u73b0\u65b9\u6848. \u5f00\u653e\u57df\u7684\u95ee\u7b54\u7cfb\u7edf\u662f\u96c6\u77e5\u8bc6\u8868\u793a, \u4fe1\u606f\u68c0\u7d22, \u81ea\u7136\u8bed\u8a00\u5904\u7406\u6280\u672f\u4e8e\u4e00\u4f53\u7684\u96be\u5ea6\u5f88\u9ad8\u7684\u7814\u7a76\u8bfe\u9898. \u7cfb\u7edf\u53ef\u4ee5\u91c7\u7528\u5927\u91cf\u7684\u65e0\u9700\u624b\u5de5\u52a0\u5de5\u7684\u6587\u672c\u4f5c\u4e3a\u95ee\u7b54\u7cfb\u7edf\u7684\u77e5\u8bc6\u5e93, \u4e3a\u5f00\u653e\u57df\u95ee\u7b54\u63d0\u4f9b\u4e86\u6761\u4ef6. \u540c\u65f6\u7ed9\u51fa\u4e86\u4e00\u79cd\u9002\u5408\u4e8e\u95ee\u7b54\u7cfb\u7edf\u7684\u68c0\u7d22\u4e2d\u6743\u91cd\u8ba1\u7b97\u65b9\u6cd5.", "num_citations": "5\n", "authors": ["1179"]}
{"title": "\u6b67\u4e49\u5b57\u6bb5\u7684\u6700\u5927\u6982\u7387\u5207\u5206\u7b97\u6cd5\n", "abstract": " \u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u6c49\u8bed\u6b67\u4e49\u5b57\u6bb5\u7684\u5207\u5206\u7b97\u6cd5, \u8be5\u7b97\u6cd5\u6839\u636e\u8bcd\u9891\u4f30\u7b97\u6bcf\u4e00\u79cd\u5207\u5206\u5f62\u5f0f\u51fa\u73b0\u7684\u6982\u7387, \u5e76\u4ee5\u6982\u7387\u6700\u5927\u7684\u5207\u5206\u5f62\u5f0f\u4f5c\u4e3a\u5206\u8bcd\u7ed3\u679c.", "num_citations": "5\n", "authors": ["1179"]}
{"title": "Experiences in the treatment of electrical burns covering deep wounds with various tissue flaps.\n", "abstract": " From 1979 to 1986, 121 patients with electrical burns were admitted to our, unit (6% of all the burned patients admitted during that period). Of these cases 64 were regarded as having deep burns (eg burns which injured muscles, tendons, nerves, bones and capsules of the joints etc.). Thirty-five flaps of various types of tissues (including one free muscle flap, two island fascial flaps, four island skin flaps, three arterial skin flaps, two musculocutaneous flaps and twenty-three random skin flaps) were used for the coverage of deep burns in twenty-seven patients. Thirty three flaps survived completely while two were partially lost; three flaps developed severe sub-flap infections but the tissue of the flaps survived totally. Three typical cases are reported in this paper. The advantages of early extensive exploration and thorough debridement of the deep electrical wounds are discussed. It also introduces the practical usage of various flaps for wound coverage in these typical cases. When flaps were needed for deep electrical burns, we chose local flaps first, and used axial pattern flaps, island flaps, etc. as much as possible; if only a random flap was available in the site, we elevated it with some deep fascia to enhance its ability to prevent infection. We considered the free tissue transfer and the transfer of fascial flaps to be important alternatives. Debridement followed by immediate wound coverage should be done as soon after resuscitation as possible. Generally the operations were performed within the third to fifth days after the electrical burn. This is the best period for active treatment in order to salvage the remaining functions of the burned extremities\u00a0\u2026", "num_citations": "5\n", "authors": ["1179"]}
{"title": "\u865a\u5047\u8bc4\u8bba\u68c0\u6d4b\u7814\u7a76\u7efc\u8ff0\n", "abstract": " \u6458\u8981 \u968f\u7740\u7535\u5b50\u5546\u52a1\u7f51\u7ad9\u53ca\u70b9\u8bc4\u7f51\u7ad9\u7684\u53d1\u5c55, \u8bc4\u8bba\u4fe1\u606f\u65e5\u76ca\u5f71\u54cd\u7740\u4eba\u4eec\u7684\u751f\u6d3b. \u8d8a\u6765\u8d8a\u591a\u7684\u7f51\u7edc\u7528\u6237\u901a\u8fc7\u53d1\u5e03\u8bc4\u8bba\u5206\u4eab\u6d88\u8d39\u4f53\u9a8c, \u8bc4\u4ef7\u4ea7\u54c1\u7684\u8d28\u91cf, \u5e76\u5728\u505a\u51fa\u6d88\u8d39\u51b3\u7b56\u65f6\u53c2\u8003\u5176\u4ed6\u7528\u6237\u7684\u8bc4\u8bba. \u4eba\u4eec\u5bf9\u8bc4\u8bba\u4fe1\u606f\u7684\u4f9d\u8d56\u50ac\u5316\u4e86\u865a\u5047\u8bc4\u8bba\u7684\u4e0d\u65ad\u6d8c\u73b0. \u865a\u5047\u8bc4\u8bba, \u6307\u4e00\u4e9b\u7528\u6237\u51fa\u4e8e\u5546\u4e1a\u6216\u5176\u4ed6\u4e0d\u826f\u52a8\u673a, \u5728\u8bc4\u8bba\u4e2d\u7f16\u9020\u4e0d\u5b9e\u6d88\u8d39\u7ecf\u5386, \u5bf9\u8bc4\u4ef7\u5bf9\u8c61\u7684\u8d28\u91cf\u7b49\u8fdb\u884c\u9f13\u5439\u6216\u8bfd\u8c24. \u865a\u5047\u8bc4\u8bba\u5bb9\u6613\u5bf9\u7528\u6237\u7684\u89c2\u70b9\u6216\u51b3\u7b56\u4ea7\u751f\u8bef\u5bfc, \u5e72\u6270\u4eba\u4eec\u7684\u65e5\u5e38\u751f\u6d3b. \u7531\u4e8e\u4eba\u7c7b\u8bc6\u522b\u865a\u5047\u8bc4\u8bba\u7684\u51c6\u786e\u7387\u8f83\u4f4e, \u7efc\u5408\u8fd0\u7528\u81ea\u7136\u8bed\u8a00\u5904\u7406\u6280\u672f\u6709\u6548\u68c0\u6d4b\u865a\u5047\u8bc4\u8bba, \u5e2e\u52a9\u7528\u6237\u83b7\u53d6\u771f\u5b9e\u8bc4\u8bba\u4fe1\u606f, \u5728\u5b66\u672f\u7814\u7a76\u53ca\u4ea7\u4e1a\u5e94\u7528\u5c42\u9762\u5747\u5177\u6709\u6df1\u8fdc\u610f\u4e49. \u5bf9\u865a\u5047\u8bc4\u8bba\u68c0\u6d4b\u4efb\u52a1, \u7814\u7a76\u8005\u4eec\u4e3b\u8981\u4ece\u865a\u5047\u8bc4\u8bba\u6587\u672c, \u865a\u5047\u8bc4\u8bba\u53d1\u5e03\u8005\u53ca\u865a\u5047\u8bc4\u8bba\u7fa4\u7ec4\u4e09\u4e2a\u89d2\u5ea6\u5f00\u5c55\u7814\u7a76. \u6211\u4eec\u5c06\u4f9d\u6b21\u5bf9\u4e09\u7c7b\u7814\u7a76\u8fdb\u884c\u5f52\u7eb3\u5206\u6790, \u5177\u4f53\u5206\u522b\u4ece\u7279\u5f81\u8bbe\u8ba1, \u6a21\u578b\u65b9\u6cd5, \u6570\u636e\u96c6, \u8bc4\u7ea7\u6307\u6807\u7b49\u65b9\u9762\u8fdb\u884c\u4e86\u5bf9\u6bd4\u603b\u7ed3. \u6700\u540e\u5bf9\u672a\u6765\u7814\u7a76\u65b9\u5411\u8fdb\u884c\u4e86\u63a2\u8ba8\u5c55\u671b.", "num_citations": "4\n", "authors": ["1179"]}
{"title": "\u57fa\u4e8e\u8868\u793a\u5b66\u4e60\u7684\u5f00\u653e\u57df\u4e2d\u6587\u77e5\u8bc6\u63a8\u7406\n", "abstract": " \u6458! \u8981\" \u77e5\u8bc6\u5e93\u901a\u5e38 g \u7f51\u7edc\u7684\u5f62\u5f0f\u88ab\u7ec4\u7ec7\u8d77\u6765! \u7f51\u7edc\u4e2d\u6bcf\u4e2a\u8282\u70b9\u4ee3\u8868\u5b9e\u4f53! \u800c\u6bcf\u6761\u8fde\u8fb9\u5219\u4ee3\u8868\u5b9e\u4f53\u95f4\u7684\u5173%'\u4e3a\u4e86\u5229\u7528\u8fd9# \u7f51\u72b6\u77e5\u8bc6\u5e93\u4e2d\u7684\u77e5\u8bc6! \u5f80\u5f80\u9700\u8981\u8bbe\u8ba1\u4e13\u95e8\u7684+ \u590d\u6742\u5ea6\u8f83\u9ad8\u7684\u56fe\u7b97\u6cd5'\u7136\u800c\u8fd9\u4e9b\u7b97\u6cd5\u5e76\u4e0d\u80fd\u5f88\u597d\u9002\u7528\u4e8e\u77e5\u8bc6\u63a8\u7406! \u5c24\u5176\u662f\u968f\u7740\u77e5\u8bc6\u5e93\u7684\u77e5\u8bc6\u89c4\u6a21\u4e0d\u65ad\u6269\u5927! \u57fa\u4e8e\u7f51\u72b6\u7ed3\u6784\u77e5\u8bc6\u5e93\u7684\u63a8\u7406\u5f88\u96be\u8f83\u597d\u5730\u6ee1\u8db3\u5b9e\u65f6\u8ba1\u7b97\u7684\u9700\u6c42'\u8be5\u6587\u4f7f\u7528\u57fa\u4e8e 4<; GM1 \u6a21\u578b\u7684\u77e5\u8bc6\u8868\u793a\u5b66\u4e60\u8fdb\u884c\u77e5\u8bc6\u63a8\u7406! \u5305\u62ec\u5bf9\u5b9e\u4f53\u5173% 7 \u5143\u7ec4\u4e2d\u5173% \u6307\u793a\u8bcd g \u53ca \u5b9e\u4f53\u7684\u63a8\u7406! \u5176\u4e2d\u5173% \u6307\u793a\u8bcd\u63a8\u7406\u7684\u5b9e\u9a8c\u53d6\u5f97\u4e86\u8f83\u597d\u7684\u7ed3\u679c! i \u63a8\u7406\u8fc7\u7a0b\u65e0\u9700\u8bbe\u8ba1\u590d\u6742\u7684\u7b97\u6cd5! \u4ec5< \u53ca\u5411\u91cf\u7684\u7b80\u5355\u8fd0\u7b97'\u53e6\u5916! \u8be5\u6587\u5bf9\u539f\u59cb 4<; GM1 \u6a21\u578b\u7684\u4ee3\u4ef7\u51fd\u6570\u8fdb\u884c\u6539\u8fdb! g \u66f4\u597d\u5730\u9002\u7528\u4e8e\u5f00\u653e\u57df\u4e2d\u6587\u77e5\u8bc6\u5e93\u8868\u793a\u5b66\u4e60'", "num_citations": "4\n", "authors": ["1179"]}
{"title": "Inferring User Consumption Preferences from Social Media\n", "abstract": " Social Media has already become a new arena of our lives and involved different aspects of our social presence. Users' personal information and activities on social media presumably reveal their personal interests, which offer great opportunities for many e-commerce applications. In this paper, we propose a principled latent variable model to infer user consumption preferences at the category level (e.g. inferring what categories of products a user would like to buy). Our model naturally links users' published content and following relations on microblogs with their consumption behaviors on e-commerce websites. Experimental results show our model outperforms the state-of-the-art methods significantly in inferring a new user's consumption preference. Our model can also learn meaningful consumption-specific topics automatically.", "num_citations": "4\n", "authors": ["1179"]}
{"title": "Transition-based Chinese semantic dependency graph parsing\n", "abstract": " Chinese semantic dependency graph is extended from semantic dependency tree, which uses directed acyclic graphs to capture richer latent semantics of sentences. In this paper, we propose two approaches for Chinese semantic dependency graph parsing. In the first approach, we build a non-projective transition-based dependency parser with the Swap-based algorithm. Then we use a classifier to add arc candidates generated by rules to the tree, forming a graph. In the second approach, we build a transition-based graph parser directly using a variant of the list-based transition system. For both approaches, neural networks are adopted to represent the parsing states. Both approaches yield significantly better results than the top systems in the SemEval-2016 Task 9: Chinese Semantic Dependency Parsing.", "num_citations": "4\n", "authors": ["1179"]}
{"title": "Topical key concept extraction from folksonomy through graph-based ranking\n", "abstract": " Existing studies for concept extraction mainly focus on text corpora and indiscriminately mix numerous topics, which may lead to a knowledge acquisition bottleneck and misconception. We thus propose a novel method for extracting topical key concepts from folksonomy. This method can overcome the aforementioned problems through rich user-generated content and topic-sensitive concept extraction. We first identify topics from folksonomy by using topic models. Tags are then ranked according to importance relative to a certain topic through graph-based ranking. The top-ranking tags are extracted as topical key concepts. The combination of a novel edge weight and preference is proposed in tag importance propagation. The proposed method is applied to different datasets and is found to outperform the state-of-the-art baselines significantly. From the perspectives of parameter influence and case study\u00a0\u2026", "num_citations": "4\n", "authors": ["1179"]}
{"title": "\u4e2d\u6587\u7bc7\u7ae0\u7ea7\u53e5\u95f4\u5173\u7cfb\u81ea\u52a8\u5206\u6790\n", "abstract": " \u7bc7\u7ae0\u7ea7\u53e5\u95f4\u5173\u7cfb\u5206\u6790\u5305\u62ec\u8bed\u4e49\u5355\u5143\u7684\u5207\u5206\u548c\u5404\u4e2a\u5355\u5143\u4e4b\u95f4\u7684\u8bed\u4e49\u5173\u7cfb\u8bc6\u522b.\u5df2\u6709\u7684\u7814\u7a76\u4e3b\u8981\u9762\u5411\u82f1\u6587,\u5230\u76ee\u524d\u4e3a\u6b62,\u5c1a\u65e0\u53ef\u7528\u7684\u4e2d\u6587\u7bc7\u7ae0\u7ea7\u53e5\u95f4\u5173\u7cfb\u81ea\u52a8\u5206\u6790\u7cfb\u7edf\u53d1\u5e03.\u5728\u4e2d\u6587\u7bc7\u7ae0\u5173\u7cfb\u8bed\u6599\u5e93\u7684\u57fa\u7840\u4e0a,\u9996\u6b21\u5b9e\u73b0\u9762\u5411\u4e2d\u6587\u7684\u7bc7\u7ae0\u7ea7\u53e5\u95f4\u5173\u7cfb\u81ea\u52a8\u5206\u6790\u7cfb\u7edf,\u5305\u62ec\u8bed\u4e49\u5355\u5143\u5207\u5206,\u8fde\u8bcd\u8bc6\u522b,\u663e\u5f0f\u8bed\u4e49\u5173\u7cfb\u8bc6\u522b\u4ee5\u53ca\u9690\u5f0f\u8bed\u4e49\u5173\u7cfb\u8bc6\u522b\u7b49.\u5b9e\u9a8c\u7ed3\u679c\u663e\u793a:\u8be5\u7cfb\u7edf\u5728\u663e\u5f0f\u53e5\u95f4\u5173\u7cfb\u8bc6\u522b\u4e0aF-score\u4e3a89.8%,\u9690\u5f0f\u53e5\u95f4\u5173\u7cfb\u8bc6\u522b\u4e0aF-score\u4e3a55.5%.", "num_citations": "4\n", "authors": ["1179"]}
{"title": "\u5b9e\u4f53\u94fe\u6307\u6280\u672f\u7814\u7a76\u8fdb\u5c55\n", "abstract": " \u5b9e\u4f53\u94fe\u6307\u662f\u8fd1\u4e9b\u5e74\u63d0\u51fa\u7684\u4e00\u9879\u81ea\u7136\u8bed\u8a00\u5904\u7406\u4efb\u52a1.\u672c\u6587\u4ece\u5b9e\u4f53\u94fe\u6307\u7684\u6982\u5ff5\u51fa\u53d1,\u4ecb\u7ecd\u4e86\u5b9e\u4f53\u94fe\u6307\u7684\u7814\u7a76\u76ee\u7684\u548c\u610f\u4e49,\u8bc4\u6d4b\u548c\u8bed\u6599,\u4ee5\u53ca\u5b9e\u4f53\u94fe\u6307\u7684\u4e3b\u8981\u65b9\u6cd5.\u672c\u6587\u5c06\u5b9e\u4f53\u94fe\u6307\u4e0e\u76f8\u5173\u7814\u7a76\u8fdb\u884c\u5bf9\u6bd4\u5206\u6790,\u5c06\u5b9e\u4f53\u94fe\u6307\u5206\u4e3a\u5019\u9009\u751f\u6210\u548c\u5019\u9009\u6392\u5e8f\u4e24\u4e2a\u90e8\u5206\u5206\u522b\u9610\u91ca,\u5e76\u7740\u91cd\u4ecb\u7ecd\u4e86\u5b9e\u4f53\u94fe\u6307\u7684\u51e0\u79cd\u5e38\u89c1\u7684\u6392\u5e8f\u65b9\u6cd5.\u6700\u540e\u7ed9\u51fa\u4e86\u5b9e\u4f53\u94fe\u6307\u6280\u672f\u7684\u53d1\u5c55\u8d8b\u52bf.", "num_citations": "4\n", "authors": ["1179"]}
{"title": "\u57fa\u4e8e\u4f9d\u5b58\u53e5\u6cd5\u5206\u6790\u7684\u793e\u4f1a\u5a92\u4f53\u6587\u672c\u6316\u6398\u65b9\u6cd5\u2014\u2014\u4ee5\u996e\u98df\u4e60\u60ef\u7279\u8272\u5206\u6790\u4e3a\u4f8b\n", "abstract": " \u6458 \u8981\" & \u8fdb\u884c\u793e\u4f1a \u00b2 \u4f53\u6587 &JK \u65f6! \u4f20\u7edf\u7684\u57fa\u4e8e\u8bcd\u8868\u7684\u65b9\u6cd5! \u5b58 & \u51c6\u786e\u7387\u8f83 \u00b3) \u8bcd\u8868 \u83b7\u5f97\u7b49\u95ee\u9898 (\u8be5\u6587\u63d0 i># \u57fa\u4e8e\u4f9d\u5b58\u53e5\u6cd5\u5206\u6790\u7684\u6587 &JK \u65b9\u6cd5! \u901a\u8fc7\u89c4\u5219\u914d\u7684\u65b9\u5f0f\u4ece\u793e\u4f1a \u00b2 \u4f53\u6587 & \u4e2d\u63d0\u53d6\u4fe1\u606f (\u8be5\u65b9\u6cd5\u4e0d\u4f9d\u8d56\u8bcd\u8868!] \u5b9e\u9a8c\u8bc1\u660e\u4e86\u76f8\u6bd4\u57fa\u4e8e\u8bcd\u8868\u7684\u65b9\u6cd5 & \u51c6\u786e\u7387\u4e0a\u6709\u5927 \u00b5 \u63d0\u9ad8 (\u5e94\u7528\u57fa\u4e8e\u4f9d\u5b58\u53e5\u6cd5\u5206\u6790\u7684\u6587 &JK \u65b9\u6cd5! \u6211\u4eec &FG \u6587 & \u4e0a\u8fdb\u884c\u4e86\u00b6\u00b7 \u4e60\u7279\u8272\u5206\u6790! \u5b9e\u73b0\u4e86\u6027\u522b) \u5730\u00a2) \u65f6\u95f4\u7b49 h \u5ea6\u7684\u00b6\u00b7 \u4e60\u7279\u8272\u5206\u6790\u5e76\u53ef\u8fdb\u884c\u4ea4 \u00b9 \u5206\u6790! \u6700 \u00ba \u7528\u8bcd\u4e91\u7684\u65b9\u5f0f\u5c55\u793a\u4e86\u7ed3\u679c (", "num_citations": "4\n", "authors": ["1179"]}
{"title": "A comparison study of sequence labeling methods for Chinese word segmentation, POS tagging models\n", "abstract": " In this paper, we compare three different Chinese word segmentation and POS tagging models. Accuracy and speed are considered during the comparison. First of these three models are pipelinesequential model. The second is a joint model for word segmentation and POS tagging, andthe last one is a combination of two modelsmentionedabove with a stacked learning framework. We conduct experiments on four data sets, including People Daily, CoNLL09, CTB5. 0 and CTB7. 0. Experimental results show that the joint model achieves the fastest speed while the stacked learning model achievesthe highest accuracy. Finally, we compare our stacked learning model with state-of-the-art systems on data sets CTB5. 0 and CTB7. 0 and our model achieve the best performance in this comparison.", "num_citations": "4\n", "authors": ["1179"]}
{"title": "\u57fa\u4e8e\u5e8f\u5217\u6807\u6ce8\u7684\u4e2d\u6587\u5206\u8bcd, \u8bcd\u6027\u6807\u6ce8\u6a21\u578b\u6bd4\u8f83\u5206\u6790\n", "abstract": " \u6458! \u8981\" \u8be5\u6587\u5bf9]#^ _ \u7684\u5206\u8bcd\u8bcd\u6027a \u6a21\u578b\u8fdb\u884c\u4e86 b \u8f83 &c]# \u6a21\u578b\u5206\u522b\u4e3a \u00cf \u4e2a Jdae \u884c\u6a21\u578b! \u00cf \u4e2a\u57fa\u4e8e f \u5206 g \u7684 h) \u6a21\u578b\u548c \u00cf \u4e2a\u5c06 c \u4e24# \u6a21\u578b+ \u7528 3JDIZFN-FDOBABGij \u8fdb\u884c\u96c6\u6210\u7684 () \u6a21\u578b && \u8fc7 &4< \u6c11 kl5'/9+--$?'/5V]; $ \u548c/5V\"; $ m \u4e2a\u6570\u636e\u96c6\u4e0a\u8fdb\u884c b \u8f83\u5206\u6790! \u6700 n \u5b9e 5 \u7ed3 678 \u5206 gh) \u6a21\u578b\u80fd\u53d6\u5f97 b \u8f83 o \u7684 D \u5ea6!() \u6a21\u578b\u80fd\u53d6\u5f97 b \u8f83 o \u7684:; \u7387! \u800c p&e \u884c\u6a21\u578b\u5904\u4e8e D \u5ea6\u548c:; \u7387\u7684\u5e73 qrs& \u6700 t \u8be5\u6587\u5c06:; \u7387\u6700 o \u7684 () \u6a21\u578b\u548c\u76f8\u5173\u524d uWv&/5V]; $ \u548c/5V\"; $ \u4e0a\u8fdb\u884c\u4e86\u5bf9 b! \u8be5 () \u6a21\u578b w \u53d6\u5f97\u4e86\u6700 o \u7684\u7ed3 6&", "num_citations": "4\n", "authors": ["1179"]}
{"title": "\u57fa\u4e8e\u968f\u673a\u6e38\u8d70\u6a21\u578b\u7684\u67e5\u8be2\u65e5\u5fd7\u4e2d\u547d\u540d\u5b9e\u4f53\u6316\u6398\n", "abstract": " \u63d0\u51fa\u4e86\u4e00\u79cd\u5f31\u6307\u5bfc\u7684\u65b9\u6cd5\u4ece\u641c\u7d22\u5f15\u64ce\u67e5\u8be2\u65e5\u5fd7\u4e2d\u6316\u6398\u547d\u540d\u5b9e\u4f53.\u8be5\u65b9\u6cd5\u4e2d\u91c7\u7528\u4eba\u5de5\u9009\u62e9\u7684\u5c11\u91cf\u547d\u540d\u5b9e\u4f53\u540d\u79f0\u4f5c\u4e3a\u79cd\u5b50,\u4f7f\u7528\u968f\u673a\u6e38\u8d70\u6a21\u578b\u4ece\u67e5\u8be2\u65e5\u5fd7\u4e2d\u83b7\u5f97\u5927\u91cf\u7684\u547d\u540d\u5b9e\u4f53.\u5176\u4e2d\u91c7\u7528\u4e86\u67e5\u8be2\u65e5\u5fd7\u4e2d\u7684\u5b9e\u4f53\u4e0a\u4e0b\u6587\u6a21\u677f,\u7528\u6237\u70b9\u51fbURL\u548c\u5019\u9009\u547d\u540d\u5b9e\u4f53\u6784\u5efa\u4e09\u5206\u56fe,\u6839\u636e\u5728\u8be5\u56fe\u4e0a\u7684\u968f\u673a\u6e38\u8d70\u8ba1\u7b97\u5019\u9009\u547d\u540d\u5b9e\u4f53\u5c5e\u4e8e\u6307\u5b9a\u76ee\u6807\u5b9e\u4f53\u7c7b\u522b\u7684\u6982\u7387,\u4ece\u800c\u5728\u67e5\u8be2\u65e5\u5fd7\u4e2d\u83b7\u53d6\u8be5\u7c7b\u522b\u7684\u547d\u540d\u5b9e\u4f53.\u5728\u771f\u5b9e\u7684\u67e5\u8be2\u65e5\u5fd7\u4e0a\u5bf97\u4e2a\u5b9e\u4f53\u7c7b\u522b\u8fdb\u884c\u7684\u5b9e\u9a8c,\u5b9e\u9a8c\u7ed3\u679c\u663e\u793a\u672c\u6587\u65b9\u6cd5\u5728\u5404\u4e2a\u7c7b\u522b\u4e0a\u5747\u83b7\u5f97\u8f83\u597d\u7684\u547d\u540d\u5b9e\u4f53\u6316\u6398\u6548\u679c.", "num_citations": "4\n", "authors": ["1179"]}
{"title": "Coreference resolution based on head match\n", "abstract": " Coreference Resolution is one of the core issues in Natural Language Processing. Based on flat features for traditional machine learning method, we propose a new method for exploiting information of the head. Firstly, we introduce an instance-matching algorithm based on simple flat features for coreference resolution. With such instance-matching algorithm, we introduce the head string of antecedent and anaphora as new feature, and propose a competition mode to integrate the head-string feature into instance-matching. Compared to other traditional machine learning methods which just consider flat features, our method can fully exploit the feature information for each training instance and the fusion of head string feature produces more accurate result.", "num_citations": "4\n", "authors": ["1179"]}
{"title": "Semi-supervised domain adaptation for WSD: Using a word-by-word model selection approach\n", "abstract": " This paper proposes a word-by-word model selection approach to domain adaptation for Word Sense Disambiguation. By this approach, the model for a target word is automatically selected from a candidate model set, which is comprised of improved self-training models and a supervised model. The improved self-training uses sense priors to prevent its iteration from converging into undesirable states. Experimental results on a domain-specific corpus show that: (1) our improved self-training model is effective for the words which have target domain linked senses; (2) the selected models obtain higher accuracies than each single model and effectively improve the performance compared to the state-of-the-art supervised model.", "num_citations": "4\n", "authors": ["1179"]}
{"title": "Cascaded regression analysis based temporal multi-document summarization\n", "abstract": " Multi-document summarization is a technology of information compression, which is largely an outgrowth of the late twentieth-century ability to gather large collections of unstructured information on-line. The explosion of the World Wide Web has brought a vast amount of information, and thus created a demand for new ways of managing changing information. Multi-document summarization is the process of automatically producing a summary delivering the main information content from a set of documents about an explicit or implicit topic, which helps to acquire information efficiently. It has drawn much attention in recent years and is valuable in many applications, such as intelligence gathering, hand-held devices and aids for the handicapped. Temporal multi-document summarization (TMDS) is the natural extension of multi-document summarization, which captures evolving information of a single topic over time. The greatest difference from traditional multi-document summarization is that it deals with the dynamic collection about a topic changing over time. It is assumed that a user has access to a stream of news stories that are on the same topic, but that the stream flows rapidly enough that no one has the time to look at every story. In this situation, a person would prefer to dive into the details that include the most important, evolving concepts within the topic and have a trend analysis.", "num_citations": "4\n", "authors": ["1179"]}
{"title": "\u57fa\u4e8e\u6f5c\u5728\u8bed\u4e49\u7d22\u5f15\u548c\u81ea\u7ec4\u7ec7\u6620\u5c04\u7f51\u7684\u68c0\u7d22\u7ed3\u679c\u805a\u7c7b\u65b9\u6cd5\n", "abstract": " \u968f\u7740\u4e92\u8054\u7f51\u7684\u4e0d\u65ad\u53d1\u5c55\u548c\u6570\u636e\u91cf\u7684\u4e0d\u65ad\u589e\u52a0,\u641c\u7d22\u5f15\u64ce\u7684\u4f5c\u7528\u65e5\u76ca\u660e\u663e,\u7528\u6237\u66f4\u591a\u5730\u4f9d\u9760\u641c\u7d22\u5f15\u64ce\u6765\u67e5\u627e\u9700\u8981\u7684\u4fe1\u606f.\u5229\u7528\u6f5c\u5728\u8bed\u4e49\u7d22\u5f15(LSI)\u7406\u8bba\u548c\u81ea\u7ec4\u7ec7\u6620\u5c04\u795e\u7ecf\u7f51\u7edc(SOM)\u7406\u8bba,\u63d0\u51fa\u4e86\u4e00\u79cd\u6587\u672c\u805a\u7c7b\u7684\u65b0\u65b9\u6cd5\u2014\u2014LSOM.\u8be5\u65b9\u6cd5\u5e94\u7528SOM\u7f51\u7edc\u6765\u5b9e\u73b0\u68c0\u7d22\u7ed3\u679c\u6587\u672c\u805a\u7c7b,\u4e0d\u5fc5\u9884\u5148\u7ed9\u5b9a\u7c7b\u522b\u4e2a\u6570,\u5177\u6709\u805a\u7c7b\u7075\u6d3b\u548c\u7cbe\u5ea6\u9ad8\u7b49\u7279\u70b9;\u540c\u65f6,\u8be5\u65b9\u6cd5\u5e94\u7528LSI\u7406\u8bba\u6765\u5efa\u7acb\u5411\u91cf\u7a7a\u95f4\u6a21\u578b,\u5728\u8bcd\u6761\u7684\u6743\u91cd\u4e2d\u5f15\u5165\u4e86\u8bed\u4e49\u5173\u7cfb,\u5bf9\u4e8e\u9ad8\u7ef4\u7684\u6587\u672c\u7279\u5f81\u5411\u91cf,\u6d88\u51cf\u539f\u8bcd\u6761\u77e9\u9635\u4e2d\u5305\u542b\u7684\u566a\u58f0,\u63d0\u9ad8\u805a\u7c7b\u901f\u5ea6.LSOM\u4f7f\u7528\u4e00\u79cd\u65b0\u7684\u7c7b\u522b\u6807\u7b7e\u63d0\u53d6\u65b9\u6cd5,\u5e76\u5c06\u63d0\u53d6\u7684\u6807\u7b7e\u7528\u4e8e\u89e3\u51b3SOM\u57fa\u672c\u7c7b\u5212\u5206\u95ee\u9898,\u7b97\u6cd5\u5728\u7c7b\u522b\u6807\u7b7e\u548c\u805a\u7c7b\u6548\u679c\u8bc4\u4ef7\u6307\u6807\u4e0a\u90fd\u6bd4\u5df2\u6709\u7684\u7b97\u6cd5\u6709\u6240\u63d0\u9ad8.", "num_citations": "4\n", "authors": ["1179"]}
{"title": "Research on paraphrasing technology\n", "abstract": " This paper surveys the state-of-the-art research on paraphrasing in natural language processing, including the applications, the acquisition of resources, the generation, and the evaluation of paraphrases, as well as some closely related topics. This paper aims to make a summary, comparison and analysis of the mainstream methods and the latest progress in the field, expecting to be helpful to the future research.", "num_citations": "4\n", "authors": ["1179"]}
{"title": "\u57fa\u4e8e\u8bed\u8a00\u6a21\u578b\u9a8c\u8bc1\u7684\u8bcd\u4e49\u6d88\u6b67\u8bed\u6599\u83b7\u53d6\n", "abstract": " \u4f5c\u4e3a\u4e00\u79cd\u7a00\u7f3a\u8d44\u6e90, \u4eba\u5de5\u6807\u6ce8\u8bed\u6599\u7684\u532e\u4e4f\u9650\u5236\u4e86\u6709\u6307\u5bfc\u8bcd\u4e49\u6d88\u6b67\u7cfb\u7edf\u7684\u5927\u89c4\u6a21\u5e94\u7528. \u6709\u4eba\u63d0\u51fa\u4e86\u5229\u7528\u76ee\u6807\u8bcd\u7684\u5355\u4e49\u540c\u4e49\u8bcd\u5728\u751f\u8bed\u6599\u4e2d\u81ea\u52a8\u83b7\u53d6\u8bcd\u4e49\u6d88\u6b67\u8bed\u6599\u7684\u65b9\u6cd5, \u7136\u800c, \u5728\u67d0\u4e9b\u4e0a\u4e0b\u6587\u5f53\u4e2d, \u7528\u76ee\u6807\u8bcd\u66ff\u6362\u8fd9\u4e9b\u5355\u4e49\u7684\u540c\u4e49\u8bcd\u5e76\u4e0d\u5408\u9002, \u4ece\u800c\u5e26\u6765\u566a\u58f0. \u4e3a\u6b64, \u7b14\u8005\u4f7f\u7528\u8bed\u8a00\u6a21\u578b\u8fc7\u6ee4\u8fd9\u4e9b\u566a\u58f0, \u8fbe\u5230\u51c0\u5316\u8bad\u7ec3\u6570\u636e, \u63d0\u9ad8\u7cfb\u7edf\u6027\u80fd\u7684\u76ee\u7684. \u7b14\u8005\u5728 Senseval23 \u56fd\u9645\u8bc4\u6d4b\u4e2d\u6587\u91c7\u6837\u8bcd\u8bcd\u4e49\u6d88\u6b67\u6570\u636e\u96c6\u4e0a\u8fdb\u884c\u4e86\u5b9e\u9a8c, \u7ed3\u679c\u8868\u660e\u7ecf\u8fc7\u8bed\u8a00\u6a21\u578b\u8fc7\u6ee4\u7684\u8bcd\u4e49\u6d88\u6b67\u7cfb\u7edf\u6027\u80fd\u660e\u663e\u9ad8\u4e8e\u672a\u7ecf\u8fc7\u6ee4\u7684\u7cfb\u7edf.", "num_citations": "4\n", "authors": ["1179"]}
{"title": "\u4fe1\u606f\u8fc7\u6ee4\u4e2d\u57fa\u4e8e\u4e8c\u5143\u8fd1\u4f3c\u5173\u7cfb\u5206\u5e03\u7684\u566a\u58f0\u5c4f\u853d\u7b97\u6cd5\n", "abstract": " \u9488\u5bf9\u4fe1\u606f\u8fc7\u6ee4\u53cd\u9988\u4e2d\u5145\u65a5\u566a\u58f0\u7684\u7f3a\u9677, \u63d0\u51fa\u4e00\u79cd\u57fa\u4e8e\u4e8c\u5143\u8fd1\u4f3c\u5173\u7cfb\u5206\u5e03 (distribution of two-dimension similarity, \u7b80\u79f0 DTS) \u7684\u8fc7\u6ee4\u7b56\u7565. DTS \u6839\u636e\u566a\u58f0\u548c\u7528\u6237\u6a21\u578b\u7684\u76f8\u6096\u5173\u7cfb, \u4e3a\u4fe1\u606f\u6d41\u5efa\u7acb\u4e8c\u5143\u8fd1\u4f3c\u5173\u7cfb\u6a21\u578b. \u540c\u65f6, \u6839\u636e\u4fe1\u606f\u5728\u4e8c\u7ef4\u8fd1\u4f3c\u5173\u7cfb\u7a7a\u95f4\u4e2d\u7684\u5206\u5e03, \u91c7\u7528\u57fa\u4e8e LMS (least mean square) \u5206\u7c7b\u5668\u7684 AdaBoost \u7b97\u6cd5\u5efa\u7acb\u566a\u58f0\u548c\u76f8\u5173\u4fe1\u606f\u7684\u5206\u7c7b\u66f2\u7ebf, \u4ece\u800c\u8f85\u52a9\u4fe1\u606f\u8fc7\u6ee4\u7cfb\u7edf\u8bc6\u522b\u548c\u5c4f\u853d\u53cd\u9988\u4e2d\u7684\u566a\u58f0. \u901a\u8fc7\u5b9e\u9a8c\u9a8c\u8bc1, \u8be5\u7b97\u6cd5\u663e\u8457\u63d0\u9ad8\u4e86\u8fc7\u6ee4\u7cfb\u7edf\u5c4f\u853d\u566a\u58f0\u7684\u80fd\u529b.", "num_citations": "4\n", "authors": ["1179"]}
{"title": "\u57fa\u4e8e\u542f\u53d1\u5f0f\u9519\u8bef\u9a71\u52a8\u5b66\u4e60\u7684\u4e2d\u6587\u65f6\u95f4\u8868\u8fbe\u5f0f\u8bc6\u522b\n", "abstract": " \u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u542f\u53d1\u5f0f\u9519\u8bef\u9a71\u52a8\u5b66\u4e60\u7684\u4e2d\u6587\u65f6\u95f4\u8868\u8fbe\u5f0f\u8bc6\u522b\u7684\u65b0\u65b9\u6cd5.\u8be5\u65b9\u6cd5\u5148\u91c7\u7528\u4f9d\u5b58\u5206\u6790\u65b9\u6cd5\u4ee5\u65f6\u95f4\u89e6\u53d1\u8bcd\u4e3a\u5207\u5165\u70b9\u9012\u5f52\u5730\u8bc6\u522b\u65f6\u95f4\u8868\u8fbe\u5f0f,\u6709\u6548\u5730\u89e3\u51b3\u4e86\u957f\u8ddd\u79bb\u4f9d\u8d56\u7684\u95ee\u9898,\u5927\u5927\u63d0\u9ad8\u4e86\u8bc6\u522b\u6548\u679c;\u5728\u6b64\u57fa\u7840\u4e0a,\u5bf9\u6bd4\u9519\u8bef\u8bc6\u522b\u7ed3\u679c\u548c\u4eba\u5de5\u6807\u6ce8,\u91c7\u7528\u542f\u53d1\u5f0fA*\u7b97\u6cd5\u641c\u7d22\u7b56\u7565\u8fdb\u884c\u9519\u8bef\u9a71\u52a8\u5b66\u4e60,\u964d\u4f4e\u4e86\u89c4\u5219\u5b66\u4e60\u7684\u590d\u6742\u5ea6,\u5e76\u5177\u6709\u533a\u5206\u6bcf\u6761\u89c4\u5219\u7684\u6709\u6548\u6027\u548c\u89c4\u5219\u95f4\u76f8\u5bb9\u6027\u7684\u4f18\u70b9,\u4f7f\u7cfb\u7edf\u6027\u80fd\u63d0\u9ad8\u8fd16%.\u6700\u7ec8\u5728\u5c01\u95ed\u6d4b\u8bd5\u96c6\u548c\u5f00\u653e\u6d4b\u8bd5\u96c6\u4e0a,F\u503c\u5206\u522b\u8fbe\u5230\u4e8677.96%\u548c77.92%.", "num_citations": "4\n", "authors": ["1179"]}
{"title": "Full-words Automatic Word Sense I Tagging Based on Unsupervised Learning Algorithm\n", "abstract": " For the purpose of implementing automatic Chinese word sense tagging, this paper presents a new method for word sense disambiguation based on unsupervised machine learning strategies. Four models of word sense disambiguation are built and compared. The model with two unsupervised machine learning strategies and selecting contextual features using dependence grammar obtains the best performance. And it can be trained with large-scale corpus to deal with the problem of data sparseness. In addition, it has such characteristics as high accuracy, high speed, easy extension and so on. Thus this technique is competent for word sense tagging on large-scale real-world text.", "num_citations": "4\n", "authors": ["1179"]}
{"title": "Summarization based on physical features and logical structure of multi documents\n", "abstract": " With the rapid development of the Internet, multi documents summarization is becoming a very hot research topic. In order to generate a summarization that can effectively characterize the original information from documents, this paper proposes a multi documents summarization approach based on the physical features and logical structure of the document set. This method firstly clusterssimilar sentences into several Logical Topics (LTs), and then orders these topics according to their physical features of multi documents. After that, sentences used for the summarization are extracted from these LTs, and finally the summarization is generated via certain sorting algorithms. Our experiments show that the information coverage rate of our method is 8.83% higher than those methods based solely on logical structures, and 14.31% higher than Top-N method.", "num_citations": "4\n", "authors": ["1179"]}
{"title": "\u9762\u5411\u4f9d\u5b58\u6587\u6cd5\u5206\u6790\u7684\u642d\u914d\u62bd\u53d6\u65b9\u6cd5\u7814\u7a76\n", "abstract": " \u672c\u6587\u901a\u8fc7\u5bf9\u7ecf\u5206\u8bcd\u548c\u8bcd\u6027\u6807\u6ce8\u7684\u5927\u89c4\u6a21\u8bed\u6599\u5e93 (18GB) \u7684\u7edf\u8ba1, \u8ba1\u7b97\u51fa\u8bed\u6599\u5e93\u4e2d\u51fa\u73b0\u7684\u8bcd\u5bf9\u4e2a\u6570,", "num_citations": "4\n", "authors": ["1179"]}
{"title": "Recent Advances in Deep Learning Based Sentiment Analysis\n", "abstract": " Sentiment analysis is one of the most popular research areas in natural language processing. It is extremely useful in many applications, such as social media monitoring and e-commerce. Recent application of deep learning based methods has dramatically changed the research strategies and improved the performance of many traditional sentiment analysis tasks, such as sentiment classification and aspect based sentiment analysis. Moreover, it also pushed the boundary of various sentiment analysis task, including sentiment classification of different text granularities and in different application scenarios, implicit sentiment analysis, multimodal sentiment analysis and generation of sentiment-bearing text. In this paper, we give a brief introduction to the recent advance of the deep learning-based methods in these sentiment analysis tasks, including summarizing the approaches and analyzing the dataset. This\u00a0\u2026", "num_citations": "4\n", "authors": ["1179"]}
{"title": "Learning to Select Bi-Aspect Information for Document-Scale Text Content Manipulation.\n", "abstract": " In this paper, we focus on a new practical task, document-scale text content manipulation, which is the opposite of text style transfer and aims to preserve text styles while altering the content. In detail, the input is a set of structured records and a reference text for describing another recordset. The output is a summary that accurately describes the partial content in the source recordset with the same writing style of the reference. The task is unsupervised due to lack of parallel data, and is challenging to select suitable records and style words from bi-aspect inputs respectively and generate a high-fidelity long document. To tackle those problems, we first build a dataset based on a basketball game report corpus as our testbed, and present an unsupervised neural model with interactive attention mechanism, which is used for learning the semantic relationship between records and reference texts to achieve better content transfer and better style preservation. In addition, we also explore the effectiveness of the back-translation in our task for constructing some pseudo-training pairs. Empirical results show superiority of our approaches over competitive methods, and the models also yield a new state-of-the-art result on a sentence-level dataset. 1", "num_citations": "3\n", "authors": ["1179"]}
{"title": "Collective entity linking: a random walk-based perspective\n", "abstract": " Facing the large amount of name mentions appearing on the web, entity linking turns to be a hot researching topic recently, in which an entity in a resource is assigned to one name mention to help users grasp the meaning of this name mention. Unfortunately, like word disambiguation, one name mention can refer to several entities without considering its context. Apparently, the name mentions that usually co-occur are related and can be considered together to determine their suitable entities. This approach is called collective entity linking and is often conducted based on entity graph. However, traditional collective entity linking methods either consume much time due to the large scale of entity graph or obtain low accuracy due to simplifying graph to boost speed. To improve both accuracy and efficiency, this paper proposes a novel collective entity linking algorithm. It constructs a complete entity graph by\u00a0\u2026", "num_citations": "3\n", "authors": ["1179"]}
{"title": "\u804a\u5929\u673a\u5668\u4eba\u4e2d\u7528\u6237\u51fa\u884c\u6d88\u8d39\u610f\u56fe\u8bc6\u522b\u65b9\u6cd5\n", "abstract": " \u6458\u8981 \u804a\u5929\u673a\u5668\u4eba\u4e2d\u7684\u51fa\u884c\u6d88\u8d39\u610f\u56fe\u662f\u6307\u7528\u6237\u4e3a\u4e86\u6ee1\u8db3\u51fa\u884c\u7684\u9700\u8981, \u901a\u8fc7\u6587\u672c\u8868\u8fbe\u51fa\u5bf9\u51fa\u884c\u7c7b\u4ea7\u54c1\u6216\u8005\u670d\u52a1\u7684\u8d2d\u4e70\u610f\u613f. \u8bc6\u522b\u51fa\u7528\u6237\u7684\u6d88\u8d39\u610f\u56fe\u53ef\u4ee5\u8fdb\u884c\u76f8\u5e94\u7684\u4ea7\u54c1\u63a8\u8350, \u589e\u5f3a\u7528\u6237\u4f53\u9a8c. \u4f20\u7edf\u7684\u6d88\u8d39\u610f\u56fe\u8bc6\u522b\u4e3b\u8981\u4f7f\u7528\u57fa\u4e8e\u6a21\u677f\u5339\u914d\u6216\u8005\u57fa\u4e8e\u4eba\u5de5\u7279\u5f81\u96c6\u5408\u7684\u673a\u5668\u5b66\u4e60\u65b9\u6cd5, \u8fd9\u7c7b\u65b9\u6cd5\u8d39\u65f6\u8d39\u529b, \u6269\u5c55\u6027\u4e0d\u5f3a. \u672c\u6587\u5c06\u51fa\u884c\u6d88\u8d39\u610f\u56fe\u8bc6\u522b\u4efb\u52a1\u770b\u6210\u4e00\u4e2a\u5206\u7c7b\u95ee\u9898, \u7ed3\u5408\u6df1\u5ea6\u5b66\u4e60\u65b9\u6cd5\u8bc6\u522b\u7528\u6237\u7684\u51fa\u884c\u6d88\u8d39\u610f\u56fe, \u8be5\u65b9\u6cd5\u4e0d\u9700\u8981\u4eba\u5de5\u6784\u9020\u7279\u5f81\u96c6\u5408\u6216\u5339\u914d\u6a21\u677f. \u5177\u4f53\u800c\u8a00, \u672c\u6587\u6784\u5efa\u4e86\u57fa\u4e8e\u5377\u79ef\u7684\u957f\u77ed\u671f\u8bb0\u5fc6\u795e\u7ecf\u7f51\u7edc (Convolutional-LSTM) \u6a21\u578b\u8fdb\u884c\u51fa\u884c\u6d88\u8d39\u610f\u56fe\u8bc6\u522b, \u9996\u5148\u901a\u8fc7\u5377\u79ef\u795e\u7ecf\u7f51\u7edc (CNN) \u5bf9\u7528\u6237\u7684\u804a\u5929\u6587\u672c\u8fdb\u884c\u7279\u5f81\u62bd\u53d6, \u968f\u540e\u8fdb\u884c\u7279\u5f81\u7ec4\u5408\u5e76\u9001\u5165\u957f\u77ed\u8bb0\u5fc6\u795e\u7ecf\u7f51\u7edc (LSTM) \u8fdb\u884c\u7279\u5f81\u8868\u793a\u5b66\u4e60, \u6700\u540e\u8f93\u51fa\u5206\u7c7b\u7ed3\u679c. \u5b9e\u9a8c\u7ed3\u679c\u8868\u660e, \u5728\u51fa\u884c\u6d88\u8d39\u610f\u56fe\u8bc6\u522b\u4efb\u52a1\u4e0a, \u57fa\u4e8e Convolutional-LSTM \u7684\u6a21\u578b\u5728 F \u503c\u4e0a\u4f18\u4e8e\u6700\u597d\u7684\u57fa\u7ebf\u65b9\u6cd5 2 \u4e2a\u767e\u5206\u70b9.", "num_citations": "3\n", "authors": ["1179"]}
{"title": "What Causes Different Emotion Distributions of a Hot Event? A Deep Event-Emotion Analysis System on Microblogs\n", "abstract": " Current online public opinion analysis systems can explore lots of hot events and present the public emotion distribution for each event, which are useful for the governments and companies. However, the public emotion distributions are just the shallow analysis of the hot events, more and more people want to know the hidden causation behind the emotion distributions. Thus, this paper presents a deep Event-Emotion analysis system on Microblogs to reveal what causes different emotions of a hot event. We here use several related sub-events to describe a hot event in different perspectives, accordingly these sub-events combined with their different emotion distributions can be used to explain the total emotion distribution of a hot event. Experiments on 15 hot events show that the above idea is reasonable to exploit the emotion causation and can help people better understand the evolution of the hot event\u00a0\u2026", "num_citations": "3\n", "authors": ["1179"]}
{"title": "\u57fa\u4e8e\u611f\u77e5\u5668\u7684\u4e2d\u6587\u5206\u8bcd\u589e\u91cf\u8bad\u7ec3\u65b9\u6cd5\u7814\u7a76\n", "abstract": " \u6458! \u8981\" \u8be5\u6587v \u4e86 W# \u57fa\u4e8e\u611f\u77e5\u5668\u7684\u4e2d\u6587\u5206^ \u589e \u00d6 \u8bad\u7ec3 {\u00c0 (\u8be5 {\u00c0 \u53ef & \u8bad\u7ec3\u597d\u7684\u6a21\u578b\u57fa \u4e0a\u6dfb\u52a0\u76ee\u6807\u9886 \u00cd \u6807\u6ce8\u6570\u636e\u7ee7 \u00d3 \u8bad\u7ec3! \u00b9 \u51b3\u4e86\u5927\u89c4\u6a21\u5207\u5206\u6570\u636e\u96be\u4e8e \u00c5\u00d7!\u00b6 \u9886 \u00cd \u4e0e\u76ee\u6807\u9886 \u00cd \u6570\u636e\u6df7 \u00a7 \u9700\u8981\u91cd \u00bd \u8bad\u7ec3\u7b49 c \u9898 (\u5b9e\u9a8c\u8868 $! \u589e \u00d6 \u8bad\u7ec3\u53ef; \u6548\u5347\u9886 \u00cd \u9002! \u8fbe\u5230\u4e0e\u4f20 \u00bc \u6570\u636e\u6df7 \u00a7 \u76f8\u7c7b\u4f3c\u7684\u6548 \u00dd (\u540c\u65f6\u8be5\u6587 {\u00c0 \u6a21\u578b\u5360\u7528\u7a7a\u95f4\u5c0f! \u8bad\u7ec3\u65f6\u95f4\u77ed! \u53ef\u5feb\u901f\u8bad\u7ec3 4 \u5f97\u76ee\u6807\u9886 \u00cd \u7684\u6a21\u578b (", "num_citations": "3\n", "authors": ["1179"]}
{"title": "ReliAble dependency arc recognition\n", "abstract": " We propose a novel natural language processing task, ReliAble dependency arc recognition (RADAR), which helps high-level applications better utilize the dependency parse trees. We model RADAR as a binary classification problem with imbalanced data, which classifies each dependency parsing arc as correct or incorrect. A logistic regression classifier with appropriate features is trained to recognize reliable dependency arcs (correct with high precision). Experimental results show that the classification method can outperform a probabilistic baseline method, which is calculated by the original graph-based dependency parser.", "num_citations": "3\n", "authors": ["1179"]}
{"title": "\u4e00\u79cd\u9762\u5411\u793e\u533a\u578b\u95ee\u53e5\u68c0\u7d22\u7684\u4e3b\u9898\u7ffb\u8bd1\u6a21\u578b\n", "abstract": " \u6458 \u8981 \u57fa\u4e8e\u7edf\u8ba1\u673a\u5668\u7ffb\u8bd1\u6a21\u578b\u7684\u95ee\u53e5\u68c0\u7d22\u6a21\u578b, \u5176\u76f8\u5173\u6027\u6392\u5e8f\u673a\u5236\u4e3b\u8981\u4f9d\u8d56\u4e8e\u8bcd\u9879\u95f4\u7684\u7ffb\u8bd1\u6982\u7387, \u7136\u800c\u5df2\u6709\u7684\u6a21\u578b\u6ca1\u6709\u5f88\u597d\u5730\u63a7\u5236\u7ffb\u8bd1\u6a21\u578b\u7684\u566a\u58f0, \u4f7f\u5f97\u5f53\u524d\u7684\u95ee\u53e5\u68c0\u7d22\u6a21\u578b\u5b58\u5728\u4e0d\u5b8c\u5584\u4e4b\u5904. \u6587\u4e2d\u63d0\u51fa\u4e00\u79cd\u57fa\u4e8e\u4e3b\u9898\u7ffb\u8bd1\u6a21\u578b\u7684\u95ee\u53e5\u68c0\u7d22\u6a21\u578b, \u4ece\u7406\u8bba\u4e0a\u8bf4\u660e, \u8be5\u6a21\u578b\u5229\u7528\u4e3b\u9898\u4fe1\u606f\u5bf9\u7ffb\u8bd1\u8fdb\u884c\u5408\u7406\u7684\u7ea6\u675f, \u8fbe\u5230\u63a7\u5236\u7ffb\u8bd1\u6a21\u578b\u566a\u58f0\u7684\u6548\u679c, \u4ece\u800c\u63d0\u9ad8\u95ee\u53e5\u68c0\u7d22\u7684\u7ed3\u679c. \u5b9e\u9a8c\u7ed3\u679c\u8868\u660e, \u6587\u4e2d\u63d0\u51fa\u7684\u6a21\u578b\u5728 MAP (MeanAveragePrecision), MRR (Mean ReciprocalRank) \u4ee5\u53ca p@ 1 (precisionatpositionone) \u7b49\u6307\u6807\u4e0a\u663e\u8457\u4f18\u4e8e\u5f53\u524d\u6700\u5148\u8fdb\u7684\u95ee\u53e5\u68c0\u7d22\u6a21\u578b.", "num_citations": "3\n", "authors": ["1179"]}
{"title": "Building chinese event type paradigm based on trigger clustering\n", "abstract": " Traditional Event Extraction mainly focuses on event type identification and event participants extraction based on pre-specified event type annotations. However, different domains have different event type paradigms. When transferring to a new domain, we have to build a new event type paradigm. It is a costly task to discover and annotate event types manually. To address this problem, this paper proposes a novel approach of building an event type paradigm by clustering event triggers. Based on the trigger clusters, the event type paradigm can be built automatically. Experimental results on three different corpora\u2013ACE (small, homogeneous, open corpus), Financial News and Musical News (large scale, specific domain, web corpus) indicate that our method can effectively build an event type paradigm and can be easily adapted to new domains.", "num_citations": "3\n", "authors": ["1179"]}
{"title": "Domain-Specific Sentiment Word Extraction by Seed Expansion and Pattern Generation\n", "abstract": " This paper focuses on the automatic extraction of domain-specific sentiment word (DSSW), which is a fundamental subtask of sentiment analysis. Most previous work utilizes manual patterns for this task. However, the performance of those methods highly relies on the labelled patterns or selected seeds. In order to overcome the above problem, this paper presents an automatic framework to detect large-scale domain-specific patterns for DSSW extraction. To this end, sentiment seeds are extracted from massive dataset of user comments. Subsequently, these sentiment seeds are expanded by synonyms using a bootstrapping mechanism. Simultaneously, a synonymy graph is built and the graph propagation algorithm is applied on the built synonymy graph. Afterwards, syntactic and sequential relations between target words and high-ranked sentiment words are extracted automatically to construct large-scale patterns, which are further used to extracte DSSWs. The experimental results in three domains reveal the effectiveness of our method.", "num_citations": "3\n", "authors": ["1179"]}
{"title": "Stacking Heterogeneous Joint Models of Chinese POS Tagging and Dependency Parsing\n", "abstract": " Previous joint models of Chinese part-of-speech (POS) tagging and dependency parsing are extended from either graph-or transition-based dependency models. Our analysis shows that the two models have different error distributions. In addition, integration of graph-and transition-based dependency parsers by stacked learning (stacking) has achieved significant improvements. These motivate us to study the problem of stacking graph-and transition-based joint models. We conduct experiments on Chinese Penn Treebank 5.1 (CTB5. 1). The results demonstrate that the guided transition-based joint model obtains better performance than the guided graph-based joint model. Further, we introduce a constituent-based joint model which derives the POS tag sequence and dependency tree from the output of PCFG parsers, and then integrate it into the guided transition-based joint model. Finally, we achieve the best performance on CTB5. 1, 94.95% in tagging accuracy and 83.98% in parsing accuracy respectively.", "num_citations": "3\n", "authors": ["1179"]}
{"title": "\u4e2d\u6587\u4ea4\u4e92\u5f0f\u95ee\u7b54\u7528\u6237\u95ee\u9898\u76f8\u5173\u68c0\u6d4b\u7814\u7a76\n", "abstract": " \u6458! \u8981\" \u4ea4\u4e92\u5f0f\u95ee\u7b54\u662f\u5177\u5907\u5904\u7406% \u5217\u76f8\u5173\u95ee\u9898: \u53ca\u4e0e\u7528\u6237\u8fdb\u884c\u5bf9\u8bdd\u5f0f\u4ea4\u4e92\u7684\u95ee\u7b54\u6280\u6728! \u662f\u8fd1\u5e74\u6765\u56fd\u9645\u4e0a\u95ee\u7b54\u6280\u6728 W \u7a76\u7684. \u4e2a\u70ed\u95e8\u65b9\u5411! \u4f46\u662f\u76ee\u524d & \u4e2d\u6587\u95ee\u7b54\u9886\u57df\u51e0\u4e4e\u6ca1\u6709\u5f00\u5c55\u76f8\u5173\u7684 W \u7a76'\u5b9e\u73b0\u4ea4\u4e92\u5f0f\u95ee\u7b54% \u7edf\u9996\u5148\u8981\u5224\u522b\u7528\u6237% \u5217\u95ee\u9898\u4e4b\u95f4\u7684\u76f8\u5173\u6027'\u8be5\u6587\u63a2\u8ba8\u4e86\u63d0\u53d6\u95ee\u9898\u4e2d\u4e0d\u540c\u7279\u5f81\u5bf9\u4e2d\u6587\u4ea4\u4e92\u5f0f\u95ee\u7b54\u95ee\u9898\u76f8\u5173\u68c0\u6d4b\u7684\u4f5c\u7528! \u5e76 i \u6839\u636e\u8bc6\u522b i \u7684\u6709\u6548\u7279\u5f81\u91c7\u7528\u57fa\u4e8e \u00e1 \u5143\u5206\u7c7b\u65b9\u6cd5\u5206\u522b\u5bf9 \u00e5\u00e6 \u6210\u4e2d\u6587\u7684 5* 2/X, \u95ee\u9898\u96c6\u8bed\u6599\u548c\u771f\u5b9e\u7684\u4ea4\u4e92\u5f0f\u95ee\u7b54\u8bed\u6599\u8fdb\u884c\u95ee\u9898\u76f8\u5173\u68c0\u6d4b\u5b9e\u9a8c! \u5b9e\u9a8c\u7ed3\u679c\u663e\u793a\u8be5\u6587\u7684\u65b9\u6cd5\u83b7\u5f97\u4e86\u8f83\u597d\u7684\u95ee\u9898\u76f8\u5173\u68c0\u6d4b\u6548\u679c'", "num_citations": "3\n", "authors": ["1179"]}
{"title": "\u57fa\u4e8e\u5b8f\u5fae\u89c2\u91cd\u8981\u6027\u5224\u522b\u6a21\u578b\u7684\u65f6\u5e8f\u591a\u6587\u6863\u6587\u6458\n", "abstract": " \u65f6\u5e8f\u591a\u6587\u6863\u6587\u6458\u662f\u9488\u5bf9\u65b0\u95fb\u9886\u57df\u8de8\u65f6\u6bb5\u7684\u76f8\u5173\u6587\u6863\u96c6, \u5373\u7cfb\u5217\u65b0\u95fb\u62a5\u9053\u8fdb\u884c\u95ee\u9898\u65e0\u5173\u7684, \u62bd\u53d6\u5f0f\u6587\u6458. \u6839\u636e\u7cfb\u5217\u65b0\u95fb\u62a5\u9053\u4e0d\u540c\u7ec6\u8282\u5c42\u6b21\u7684\u65f6\u5e8f\u7279\u6027, \u63d0\u51fa\u4e00\u79cd\u57fa\u4e8e\u5b8f\u5fae\u89c2\u91cd\u8981\u6027\u5224\u522b\u6a21\u578b\u7684\u5185\u5bb9\u9009\u62e9\u65b9\u6cd5. \u4ece\u5b8f\u89c2\u548c\u5fae\u89c2\u89d2\u5ea6\u6316\u6398\u4fe1\u606f\u968f\u7740\u65f6\u95f4\u8fdb\u5316\u7684\u65f6\u5e8f\u7279\u6027, \u4ee5\u6307\u5bfc\u65f6\u5e8f\u591a\u6587\u6863\u6587\u6458\u7684\u5185\u5bb9\u9009\u62e9. \u9996\u5148\u901a\u8fc7\u5b8f\u89c2\u6a21\u578b\u786e\u5b9a\u91cd\u8981\u7684\u65f6\u95f4\u70b9, \u7136\u540e\u901a\u8fc7\u5fae\u89c2\u6a21\u578b\u5728\u91cd\u8981\u7684\u65f6\u95f4\u70b9\u9009\u62e9\u91cd\u8981\u7684\u53e5\u5b50, \u4ece\u800c\u66f4\u6709\u6548\u5730\u83b7\u53d6\u6587\u6458. \u5b9e\u9a8c\u8bc1\u660e\u8be5\u65b9\u6cd5\u662f\u6709\u6548\u7684.", "num_citations": "3\n", "authors": ["1179"]}
{"title": "Context Dependent lexical paraphrasing based an Web mining [J]\n", "abstract": " Lexical paraphrasing is the task of extracting word-level paraphrases. Lexical paraphrases should be context dependent since a word may have different paraphrases in distinct contexts. This paper investigates a framework for acquiring context-dependent lexical paraphrases, in which a web mining method is developed for extracting candidate paraphrases and a classification method is introduced in paraphrase validation. Evaluations are carried out on the People\u2019s Daily corpus and the results show that:(1) the web mining method performs well in candidate paraphrase extraction, which extracts 2.3 correct paraphrases on average for each test word in each given context sentence;(2) the classifier for paraphrase validation is effective, which achieves an f-measure of 0.6023;(3) 75.11% and 98.31% of the paraphrases extracted by our method cannot be recognized by the two widely used context-independent methods, ie, the thesaurus-based and clustering-based methods respectively. This indicates that the presented context-dependent method is a considerable supplement to the context-independent ones.", "num_citations": "3\n", "authors": ["1179"]}
{"title": "\u53e5\u6cd5\u4e0e\u8bcd\u4e49\u76f8\u7ed3\u5408\u7684\u4e2d\u6587\u4ee3\u8bcd\u6d88\u89e3\n", "abstract": " \u53e5\u6cd5\u77e5\u8bc6\u5bf9\u4ee3\u8bcd\u6d88\u89e3\u6709\u5f88\u5927\u7684\u5e2e\u52a9. \u8fd1\u5e74\u6765\u4f9d\u5b58\u5411\u6cd5\u7531\u4e8e\u5176\u5229\u4e8e\u63cf\u8ff0\u8bed\u8a00\u4e2d\u8bcd\u4e0e\u8bcd\u4e4b\u95f4\u7684\u5173\u7cfb, \u7a81\u51fa\u6838\u5fc3\u8bcd\u7684\u7279\u70b9\u65e5\u76ca\u5f97\u5230\u91cd\u89c6. \u8be5\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u4e2d\u6587\u7b2c\u4e09\u4eba\u79f0\u4ee3\u8bcd\u6d88\u89e3\u65b9\u6cd5, \u76f4\u63a5\u5229\u7528\u4f9d\u5b58\u53e5\u6cd5\u5206\u6790\u5668\u7684\u7ed3\u679c, \u6784\u5efa\u6709\u6548\u7684\u53e5\u6cd5\u89d2\u8272\u7279\u5f81\u548c\u540d\u8bcd\u77ed\u8bed\u7684\u652f\u914d\u8bcd\u4e4b\u95f4\u7684\u8bcd\u4e49\u76f8\u4f3c\u548c\u8bcd\u8bed\u76f8\u5173\u7279\u5f81, \u91c7\u7528\u652f\u6301\u5411\u91cf\u673a\u4f5c\u4e3a\u5206\u7c7b\u5668, \u5728 ACE2005 \u8bed\u6599\u4e0a\u7684\u5b9e\u9a8c\u8bc1\u660e\u4e86\u8fd9\u4e9b\u7279\u5f81\u7684\u6709\u6548\u6027.", "num_citations": "3\n", "authors": ["1179"]}
{"title": "\u4e2d\u6587\u4eba\u79f0\u540d\u8bcd\u77ed\u8bed\u5355\u590d\u6570\u81ea\u52a8\u8bc6\u522b\n", "abstract": " \u6458 \u8981 \u540d\u8bcd\u77ed\u8bed\u7684\u5355\u590d\u6570\u4fe1\u606f\u5728\u5171\u6307\u6d88\u89e3\u4e2d\u662f\u5fc5\u4e0d\u53ef\u5c11\u7684\u7279\u5f81. \u4e0e\u82f1\u8bed\u4e0d\u540c, \u4e2d\u6587\u5c5e\u4e8e\u6c49\u85cf\u8bed\u7cfb, \u540d\u8bcd\u672c\u8eab\u4e0d\u80fd\u660e\u663e\u4f53\u73b0\u5355\u590d\u6570\u4fe1\u606f, \u9700\u8981\u501f\u52a9\u5176\u6240\u5728\u7684\u540d\u8bcd\u77ed\u8bed\u6765\u8fdb\u884c\u4f53\u73b0. \u672c\u6587\u5728\u81ea\u52a8\u5185\u5bb9\u62bd\u53d6 (Automatic content extraction, ACE) \u8bed\u6599\u4e0a\u62bd\u53d6\u5f97\u5230\u4eba\u79f0\u540d\u8bcd\u77ed\u8bed\u7684\u5355\u590d\u6570\u4fe1\u606f, \u5206\u522b\u91c7\u7528\u4e86\u57fa\u4e8e\u89c4\u5219\u548c\u673a\u5668\u5b66\u4e60\u7684\u65b9\u6cd5\u6765\u8fdb\u884c\u4eba\u79f0\u540d\u8bcd\u77ed\u8bed\u7684\u5355\u590d\u6570\u81ea\u52a8\u8bc6\u522b. \u57fa\u4e8e\u89c4\u5219\u7684\u65b9\u6cd5, \u5728\u4e00\u4e9b\u77e5\u8bc6\u8d44\u6e90\u7684\u57fa\u7840\u4e0a\u5b9a\u4e49\u4e86\u89c4\u5219\u6a21\u677f\u5e93, \u6bcf\u6761\u89c4\u5219\u91c7\u7528\u69fd\u548c\u69fd\u503c\u7684\u65b9\u6cd5\u6765\u8fdb\u884c\u4f53\u73b0; \u673a\u5668\u5b66\u4e60\u65b9\u6cd5\u91c7\u7528\u6700\u5927\u71b5\u6a21\u578b\u7ec4\u5408\u8003\u5bdf\u4e86\u8bcd\u5f62, \u8bcd\u6027, \u8bcd\u4e49, \u6570\u91cf\u5173\u7cfb\u7b49\u7279\u5f81. \u4e24\u79cd\u65b9\u6cd5\u5206\u522b\u8fbe\u5230\u4e86 48.24% \u548c 87.48% \u7684\u6b63\u786e\u7387. \u5b9e\u9a8c\u7ed3\u679c\u663e\u793a, \u57fa\u4e8e\u89c4\u5219\u7684\u65b9\u6cd5\u80fd\u591f\u4fdd\u8bc1\u7cbe\u786e\u7387\u800c\u4e0d\u80fd\u4fdd\u8bc1\u53ec\u56de\u7387, \u673a\u5668\u5b66\u4e60\u7684\u65b9\u6cd5\u53ef\u4ee5\u66f4\u597d\u5730\u5b8c\u6210\u5355\u590d\u6570\u4fe1\u606f\u7684\u8bc6\u522b\u4efb\u52a1.", "num_citations": "3\n", "authors": ["1179"]}
{"title": "A Study on Constituentto-Dependency Conversion\n", "abstract": " The progress of Chinese dependency treebank construction has fallen behind other languages, such as English, in terms of scale and quality. Building a large scale treebank needs a lot of human and material resources. Meanwhile, it is very difficult to guarantee the quality of the treebank. In this paper, we explore a new method which combines rule-based method and statistical-based method to convert a constituent treebank named Penn Chinese Treebank to a dependency treebank which follows the annatation standard of HIT Chinese Dependency Treebank (HIT-IR-CDT). We increase the size of training data by adding converted treebank into HIT-IR-CDT and re-train the dependency parser. Experiments show that small addition of converted treebank can improve the performance of dependency parser, while large addition will bring it down. Through detailed analysis, we believe that convertion of constituent-to-dependency treebank still needs in-depth research as a method of improving performance of dependency parser by utilizing different treebanks.", "num_citations": "3\n", "authors": ["1179"]}
{"title": "A novel heuristic Error-Driven learning for recognizing Chinese time expression\n", "abstract": " Recognizing time expression is useful in many natural language processing tasks, which can be used to temporal reasoning and anchoring events on the time line. In this paper, a heuristic error-driven learning framework is proposed for recognizing Chinese time expression, which integrates the heuristic search strategy* A algorithm into error-driven learning. The heuristic function is designed and its monotonicity is theoretically proved, so that the correctness of* A algorithm is guaranteed. Our method begins with time trigger word, uses Chinese dependency parsing to identify the extents of time expressions, availably resolves the problem of long distance dependency, and greatly improves the system performance; Subsequently, comparing incorrectly recognized time expressions with the standard ones and learning some rules, then we use the error-driven learning based on the* A algorithm to heuristically filter the rules, which not only decreases the time complexity of learning rules, but also distinguishes the validity of each rule and the compatibility among rules. We evaluated this new method on the Chinese corpus of ACE2005 and got 6% increase of system performance. Finally, F= 77.96%, F= 77.92% was obtained on the closed and the open test set, respectively.", "num_citations": "3\n", "authors": ["1179"]}
{"title": "\u7bc7\u7ae0\u5171\u6307\u6d88\u89e3\u7814\u7a76\u7efc\u8ff0\n", "abstract": " \u6458 \u8981\u7bc7\u7ae0\u5171\u6307\u6d88\u89e3\u5c31\u662f\u5c06\u7bc7\u7ae0\u5185\u7684\u6240\u6709\u8868\u8ff0\u5212\u5206\u4e3a\u73b0\u5b9e\u4e16\u754c\u4e2d\u4e0d\u540c\u5b9e\u4f53\u7b49\u4ef7\u63cf\u8ff0\u7684\u8fc7\u7a0b, \u4e3b\u8981\u5305\u542b\u4eba\u79f0\u4ee3\u8bcd\u6d88\u89e3\u548c\u540d\u8bcd\u77ed\u8bed\u6d88\u89e3. \u8be5\u95ee\u9898\u4e00\u76f4\u662f\u81ea\u7136\u8bed\u8a00\u5904\u7406\u4e2d\u7684\u6838\u5fc3\u95ee\u9898, \u8fd1\u5e74\u6765\u5f97\u5230\u7684\u5e7f\u6cdb\u5173\u6ce8\u548c\u5feb\u901f\u7684\u53d1\u5c55. \u672c\u6587\u533a\u5206\u4e86\u51e0\u4e2a\u5bb9\u6613\u6df7\u6dc6\u7684\u76f8\u5173\u6982\u5ff5, \u603b\u7ed3\u4e86\u5171\u6307\u7684\u57fa\u672c\u7c7b\u578b, \u5206\u6790\u4e86\u8fd1\u4e09\u5341\u5e74\u6765\u5171\u6307\u6d88\u89e3\u7684\u7814\u7a76\u8def\u7ebf, \u8ba4\u4e3a\u5168\u5c40\u4f18\u5316, \u6df1\u5c42\u8bed\u8a00\u5b66\u77e5\u8bc6\u4ee5\u53ca\u80cc\u666f\u77e5\u8bc6\u7684\u5229\u7528, \u8bed\u8a00\u5b66\u6a21\u578b\u548c\u7edf\u8ba1\u6a21\u578b\u7684\u878d\u5408\u662f\u5f53\u524d\u7684\u5173\u952e\u95ee\u9898\u548c\u7814\u7a76\u8d8b\u52bf, \u5e76\u8be6\u7ec6\u4ecb\u7ecd\u4e86\u5171\u6307\u6d88\u89e3\u76f8\u5173\u7684\u56fd\u9645\u8bc4\u6d4b, \u8bc4\u6d4b\u65b9\u6cd5, \u8bed\u6599\u8d44\u6e90\u548c\u5de5\u5177. \u5173\u952e\u8bcd", "num_citations": "3\n", "authors": ["1179"]}
{"title": "\u57fa\u4e8e\u76f8\u5173\u6027\u6a21\u578b\u7684\u4e2d\u6587\u8bdd\u9898\u8ddf\u8e2a\u7814\u7a76\n", "abstract": " DepartmentofComputcrScienceandTechnology, Harbin InsituteofTechnology, Harbin150001 E-mal:{zwzhangyu, bwZOuhy, diu}@ irhitedu. cn Abstract: Asanimportantsubtaskoftopicdetectionandtracking, topictrackingidenifesandcolectsrelevantstoneson certaintopicsfrominformadonstream. Tofndandbacktopicshifintopictrackingtask, thispapcrproposestheimproved relevancemodeltodetectthenovelyinformationintopictrackingfeedbackandmodifestopicmodelbascdonthisnovely infomation, Thismethodcantrackthe topicshifiand decreasehighmisateintopic mcang Thispapcruthe Chinese sourceinTDT4andteTDT2003evaluationcntenon, theresultprovesthsapproach canimprovetheefectoftopic tracking\ufe51", "num_citations": "3\n", "authors": ["1179"]}
{"title": "\u57fa\u4e8e XML \u7684\u5f00\u653e\u5f0f\u8bed\u8a00\u6280\u672f\u5e73\u53f0: LTP\n", "abstract": " \u672c\u6587\u63cf\u8ff0\u4e86\u4e00\u5957\u9762\u5411 Web \u57fa\u4e8e XML \u7684\u5f00\u653e\u5f0f\u4e2d\u6587\u8bed\u8a00\u5904\u7406\u5e73\u53f0, \u547d\u540d\u4e3a \u201c\u8bed\u8a00\u6280\u672f\u5e73\u53f0 LTP\u201d. LTP \u5305\u542b 5 \u9879\u4e3b\u8981\u5185\u5bb9: \u8bed\u8a00\u6280\u672f\u7f6e\u6807\u8bed\u8a00 LTML, \u57fa\u4e8e DOM Tree \u7684\u4e00\u5957 DLL \u6a21\u5757, \u4e00\u5957\u53ef\u89c6\u5316\u5de5\u5177, \u57fa\u4e8e LTML \u7684\u8bed\u6599\u5e93\u8d44\u6e90, \u4ee5\u53ca\u57fa\u4e8e Web Service \u7684\u7f51\u7edc\u5e94\u7528. \u76ee\u524d LTP \u96c6\u6210\u4e86\u5305\u62ec\u8bcd\u6cd5, \u8bcd\u4e49, \u53e5\u6cd5, \u8bed\u4e49, \u7bc7\u7ae0\u5206\u6790\u7b49 10 \u9879\u4e2d\u6587\u5904\u7406\u6838\u5fc3\u6280\u672f. \u8be5\u5e73\u53f0\u5c06\u5e2e\u52a9\u521d\u6d89\u81ea\u7136\u8bed\u8a00\u5904\u7406\u4ee5\u53ca\u4fe1\u606f\u68c0\u7d22\u9886\u57df\u7684\u7814\u7a76\u8005\u63d0\u4f9b\u4e00\u5957\u7cfb\u7edf\u5316\u5de5\u5177, \u5e2e\u52a9\u4ed6\u4eec\u6df1\u5165\u7814\u7a76\u8bed\u8a00\u5404\u4e2a\u5c42\u9762\u4e4b\u95f4\u7684\u5173\u7cfb\u4ee5\u53ca\u5229\u7528\u8fd9\u4e9b\u57fa\u7840\u6280\u672f\u53bb\u7814\u7a76\u4e00\u4e9b\u9ad8\u7ea7\u5e94\u7528\u8bdd\u9898. \u76ee\u524d\u8be5\u5e73\u53f0\u5bf9\u5916\u514d\u8d39\u5171\u4eab.", "num_citations": "3\n", "authors": ["1179"]}
{"title": "\u57fa\u4e8e\u53cc\u8bed\u8bed\u6599\u5e93\u7684\u77ed\u8bed\u590d\u8ff0\u5b9e\u4f8b\u83b7\u53d6\u7814\u7a76\n", "abstract": " \u672c\u6587\u63d0\u51fa\u4e00\u79cd\u57fa\u4e8e\u53cc\u8bed\u8bed\u6599\u5e93\u7684\u77ed\u8bed\u590d\u8ff0\u5b9e\u4f8b\u83b7\u53d6\u65b9\u6cd5, \u5c24\u5176\u80fd\u591f\u5f88\u597d\u7684\u62bd\u53d6\u6b67\u4e49\u77ed\u8bed\u7684\u590d\u8ff0\u5b9e\u4f8b. \u8be5\u65b9\u6cd5\u901a\u8fc7\u8f93\u5165\u4e00\u4e2a\u53cc\u8bed\u77ed\u8bed\u5bf9\u7ea6\u675f\u77ed\u8bed\u7684\u8bed\u4e49, \u5229\u7528\u8bcd\u5bf9\u9f50\u7684\u53cc\u8bed\u8bed\u6599\u5e93, \u6784\u9020\u4e00\u4e2a\u53cc\u5411\u62bd\u53d6\u6a21\u578b\u4ece\u4e2d\u62bd\u53d6\u53cc\u8bed\u5bf9\u7684\u590d\u8ff0\u5b9e\u4f8b. \u53cc\u5411\u62bd\u53d6\u6a21\u578b\u901a\u8fc7\u6bd4\u8f83\u6bcf\u4e00\u4e2a\u5019\u9009\u590d\u8ff0\u77ed\u8bed\u548c\u8f93\u5165\u77ed\u8bed\u4e4b\u95f4\u7684\u8bed\u4e49\u4e00\u81f4\u6027, \u6765\u786e\u5b9a\u6bcf\u4e2a\u5019\u9009\u662f\u5426\u6210\u4e3a\u6700\u7ec8\u7684\u590d\u8ff0\u5b9e\u4f8b. \u5b9e\u9a8c\u7ed3\u679c\u8868\u660e, \u672c\u6587\u77ed\u8bed\u590d\u8ff0\u5b9e\u4f8b\u83b7\u53d6\u65b9\u6cd5\u7684\u7efc\u5408\u51c6\u786e\u7387\u8fbe\u5230\u4e86 60%, \u83b7\u53d6\u4e86\u8f83\u597d\u7684\u6027\u80fd.", "num_citations": "3\n", "authors": ["1179"]}
{"title": "Learning Algorithm of Adaptive Information Filtering Based on Hierarchy Clustering [J]\n", "abstract": " This paper adopts an adaptive learning algorithm based on hierarchy clustering to update user profile, which continuously abstract the cancroids of one class of optimum information from the feedback flow of system, which effectively shield the learning process from plenty of feedback noises produced by distorted threshold and sparseness of initial information, which also can imitate artificial feedback approximately to perfect the intelligence of adaptive learning mechanism.", "num_citations": "3\n", "authors": ["1179"]}
{"title": "Application of Named Entity and Coreference Resolution to Summarization System [J]\n", "abstract": " We have introduced information extraction technique such as named entity tagging and coreference resolution to a summarization system based on sentence extraction technique, and evaluated the contribution of named entity tagging and coreference resolution to the summarization system by human evaluations and automatic evaluation.", "num_citations": "3\n", "authors": ["1179"]}
{"title": "\u4e2d\u56fd\u4eba\u540d\u6027\u522b\u81ea\u52a8\u8bc6\u522b\n", "abstract": " \u4eba\u540d\u6027\u522b\u8bc6\u522b\u80fd\u5e94\u7528\u5728\u81ea\u7136\u8bed\u8a00\u5904\u7406\u548c\u4fe1\u606f\u68c0\u7d22\u4e2d. \u672c\u6587\u5c1d\u8bd5\u4e86\u4e2d\u56fd\u4eba\u540d\u6027\u522b\u81ea\u52a8\u8bc6\u522b\u7684\u4e24\u79cd\u65b9\u6cd5. \u4e00\u79cd\u65b9\u6cd5\u662f\u91c7\u7528\u8d1d\u53f6\u65af\u65b9\u6cd5\u5bf9\u6bd4\u4e86\u4e09\u79cd\u4eba\u540d\u7528\u5b57\u6a21\u578b, \u5bf9 10 \u4e07\u4eba\u540d\u7684\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e, \u4eba\u540d\u5c3e\u5b57\u5bf9\u6027\u522b\u8bc6\u522b\u5177\u6709\u66f4\u597d\u7684\u5e94\u7528\u80fd\u529b, \u5f00\u653e\u6d4b\u8bd5\u51c6\u786e\u7387\u4e3a 82.95%. \u53e6\u4e00\u79cd\u65b9\u6cd5\u4f9d\u8d56\u4eba\u540d\u4e0a\u4e0b\u6587, \u4ece Hownet \u548c\u7f51\u7edc\u6316\u6398\u5206\u522b\u62bd\u53d6\u7537, \u5973\u6027\u522b\u6307\u793a\u8bcd, \u91c7\u7528\u5728\u767e\u5ea6\u68c0\u7d22\u4eba\u540d\u7684\u7ed3\u679c\u4e2d\u5bf9\u6027\u522b\u6307\u793a\u8bcd\u8ba1\u6570\u6765\u83b7\u53d6\u5bf9\u5e94\u7684\u6027\u522b. \u5bf9 81 \u4e2a\u4eba\u540d\u7684\u6d4b\u8bd5, \u51c6\u786e\u7387\u8fbe\u5230 96.3%. \u7ed3\u679c\u663e\u793a Hownet \u7684\u6027\u522b\u6307\u793a\u8bcd\u5177\u6709\u8f83\u597d\u7684\u901a\u7528\u6027, \u7f51\u7edc\u6316\u6398\u7684\u6027\u522b\u6307\u793a\u8bcd\u5177\u6709\u8f83\u597d\u7684\u9886\u57df\u9002\u5e94\u6027.", "num_citations": "3\n", "authors": ["1179"]}
{"title": "\u81ea\u52a8\u6d45\u5c42\u8bed\u4e49\u5206\u6790\n", "abstract": " Automatic semantic parsing is one of the main tasks for the natural language understanding. The natural language sentences can be translated into formal language by deep semantic paring. Consequently computer and human beings can communicate with each other freely. In order to achieve the dream, people have done lots of efforts for many years. However the results are not up to much. Shallow semantic parsing is a simplified form of deep semantic parsing. It only labels the constituents with semantic roles which have direct relation with the predicate in a sentence. The semantic roles include Agent, Patient. Temporal, Locative and so on. In addition, it can give great support to many NLP applications, such as information extraction, question and answering, machine translation and so on. Semantic role labeling (SRL) is one kind of shallow semantic paring. It is currently a well defined task with a substantial\u00a0\u2026", "num_citations": "3\n", "authors": ["1179"]}
{"title": "Chinese word sense disambiguation based on neural networks\n", "abstract": " The input of a network is the key problem for Chinese word sense disambiguation utilizing the neural network. This paper presents an input model of the neural network that calculates the mutual information between contextual words and the ambiguous word by using statistical methodology and taking the contextual words of a certain number beside the ambiguous word according to ( - M, + N). The experiment adopts triple-layer BP Neural Network model and proves how the size of a training set and the value of M and N affect the performance of the Neural Network Model. The experimental objects are six pseudowords owning three word-senses constructed according to certain principles. The tested accuracy of our approach on a closed-corpus reaches 90. 31% ,and 89. 62% on an open-corpus. The experiment proves that the Neural Network Model has a good performance on Word Sense Disambiguation.", "num_citations": "3\n", "authors": ["1179"]}
{"title": "\u4e00\u4e2a\u5168\u6587\u8bcd\u4e49\u81ea\u52a8\u6807\u6ce8\u7cfb\u7edf\u7684\u5b9e\u73b0\n", "abstract": " \u4e3a\u7814\u7a76\u5728\u7ed9\u5b9a\u4e0a\u4e0b\u6587\u4e2d\u5982\u4f55\u786e\u5b9a\u591a\u4e49\u8bcd\u7684\u8bcd\u4e49,\u4ecb\u7ecd\u4e86\u4e00\u79cd\u65e0\u6307\u5bfc\u7684\u8bcd\u4e49\u6d88\u6b67\u6280\u672f\u548c\u4e00\u4e2a\u6c49\u8bed\u5168\u6587\u8bcd\u4e49\u6807\u6ce8\u7cfb\u7edf\u7684\u8bbe\u8ba1\u5b9e\u73b0\u8fc7\u7a0b.\u8be5\u7cfb\u7edf\u57fa\u4e8e\u8d1d\u53f6\u65af\u6a21\u578b,\u4f7f\u7528\u5927\u89c4\u6a21\u8bed\u6599\u8fdb\u884c\u8bad\u7ec3,\u8f83\u597d\u5730\u89e3\u51b3\u4e86\u77e5\u8bc6\u83b7\u53d6\u4e2d\u6570\u636e\u7a00\u758f\u7684\u95ee\u9898.\u8be5\u7cfb\u7edf\u5177\u6709\u6807\u6ce8\u6b63\u786e\u7387\u9ad8\u548c\u8fd0\u884c\u901f\u5ea6\u5feb\u7b49\u7279\u70b9,\u9002\u5408\u5927\u89c4\u6a21\u6587\u672c\u7684\u8bcd\u4e49\u6807\u6ce8\u5de5\u4f5c.", "num_citations": "3\n", "authors": ["1179"]}
{"title": "Multi-documents summarization based on sub-topics\n", "abstract": " The theme of multi-document set is composed of some aspect information, each aspect is named sub-topic of multi-document set. In this paper, the definition and features of sub-topic in multi-document set was described, based on sub-topic, the method of sub-topic ordering and sentence extracting were proposed, and then multi-document summarization was generated. The experiment shows that this method is satisfied.", "num_citations": "3\n", "authors": ["1179"]}
{"title": "\u57fa\u4e8e\u4f9d\u5b58\u5206\u6790\u548c\u8d1d\u53f6\u65af\u7f51\u7edc\u7684\u65e0\u6307\u5bfc\u6c49\u8bed\u8bcd\u4e49\u6d88\u6b67\n", "abstract": " \u91c7\u7528\u57fa\u4e8e\u4f9d\u5b58\u5206\u6790\u6539\u8fdb\u8d1d\u53f6\u65af\u7f51\u7edc\u7684\u65e0\u6307\u5bfc\u7684\u673a\u5668\u5b66\u4e60\u65b9\u6cd5\u5bf9\u6c49\u8bed\u5927\u89c4\u6a21\u771f\u5b9e\u6587\u672c\u8fdb\u884c\u8bcd\u4e49\u6d88\u6b67\u5b9e\u9a8c.\u8be5\u5b66\u4e60\u7b97\u6cd5\u5145\u5206\u5229\u7528\u4f9d\u5b58\u6587\u6cd5\u5206\u6790\u786e\u5b9a\u80fd\u591f\u5bf9\u8bcd\u8bed\u8bcd\u4e49\u6784\u6210\u5185\u5728\u9650\u5236\u7684\u4e0a\u4e0b\u6587,\u6709\u6548\u5730\u514b\u670d\u4e86\u7b80\u5355\u8d1d\u53f6\u65af\u5206\u7c7b\u5668\u4e2d\u65e0\u5173\u4e0a\u4e0b\u6587\u9020\u6210\u7684\u566a\u58f0\u5f71\u54cd.\u5b9e\u9a8c\u7ed3\u679c\u8bc1\u660e\u57fa\u4e8e\u4f9d\u5b58\u6539\u8fdb\u7684\u8d1d\u53f6\u65af\u6a21\u578b\u5728\u6c49\u8bed\u8bcd\u4e49\u6d88\u6b67\u4e0a\u8868\u73b0\u826f\u597d,\u5f00\u653e\u6d4b\u8bd5\u6b63\u786e\u7387\u53ef\u8fbe86.27%.", "num_citations": "3\n", "authors": ["1179"]}
{"title": "Designing a Realistic Evaluation of an End-to-end Interactive Question Answering System.\n", "abstract": " We report on the development of material for an evaluation exercise designed to assess the overall design and usability of HITIQA, an interactive question-answering system for preparing broad ranging reports on complex issues. The two basic objectives of the evaluation were (1) To perform a realistic assessment of the usefulness and usability of HITIQA as an end-to-end system, from the information seeker's initial questions to completion of a draft report; and (2) To develop metrics to compare the answers obtained by different analysts and evaluate the quality of the support that HITIQA provides. We used qualitative and quantitative tools to obtain data about analyst's comfort with the HITIQA system, especially its novel features such as the ability to answer complex questions and the interactive dialogue. Because of the impracticality of measuring the quality of HITIQA output with the standard metrics of precision and recall, we developed a new task-cross-evaluation-to indirectly measure the quality of the answers obtained using HITIQA; in this black-box assessment, analysts rate the quality of their own and their colleagues' reports.", "num_citations": "3\n", "authors": ["1179"]}
{"title": "\u591a\u6587\u6863\u96c6\u5408\u4e2d\u903b\u8f91\u4e3b\u9898\u7684\u786e\u5b9a\n", "abstract": " \u628a\u591a\u6587\u6863\u96c6\u5408\u4e2d\u5177\u6709\u76f8\u540c\u6216\u76f8\u4f3c\u7684\u53e5\u5b50\u901a\u8fc7\u805a\u7c7b\u7684\u65b9\u6cd5\u5f52\u5e76\u6210\u4e00\u7c7b, \u6bcf\u7c7b\u5373\u4e3a\u591a\u6587\u6863\u96c6\u5408\u7684\u4e00\u4e2a\u903b\u8f91\u4e3b\u9898. \u5c06\u591a\u6587\u6863\u96c6\u5408\u63cf\u8ff0\u4e3a\u82e5\u5e72\u903b\u8f91\u4e3b\u9898\u7684\u96c6\u5408, \u662f\u4ece\u7406\u89e3\u7684\u89d2\u5ea6\u6765\u63cf\u8ff0\u591a\u6587\u6863\u96c6\u5408, \u5728\u6b64\u57fa\u7840\u4e0a\u53ef\u4ee5\u63d0\u9ad8\u591a\u6587\u6863\u6587\u6458\u7684\u8d28\u91cf. \u672c\u6587\u9996\u5148\u6839\u636e\u6807\u51c6\u8bed\u6599\u786e\u5b9a\u5212\u5206\u903b\u8f91\u4e3b\u9898\u7684\u9608\u503c, \u901a\u8fc7\u5c42\u6b21\u805a\u7c7b\u65b9\u6cd5\u786e\u5b9a\u903b\u8f91\u4e3b\u9898\u7684\u4e2a\u6570, \u7136\u540e\u5229\u7528 k \u5747\u503c\u65b9\u6cd5\u5bf9\u5404\u4e2a\u7c7b\u522b\u8fdb\u884c\u8fed\u4ee3\u8c03\u6574, \u4ece\u800c\u63d0\u9ad8\u5212\u5206\u903b\u8f91\u4e3b\u9898\u7684\u51c6\u786e\u7387. \u5b9e\u9a8c\u8868\u660e, \u57fa\u4e8e\u5c42\u6b21\u805a\u7c7b\u7684 k \u5747\u503c\u65b9\u6cd5\u5f97\u5230\u7684\u903b\u8f91\u4e3b\u9898\u6b63\u786e\u7387\u6bd4\u5c42\u6b21\u805a\u7c7b\u65b9\u6cd5\u5f97\u5230\u7684\u903b\u8f91\u4e3b\u9898\u6b63\u786e\u7387\u5e73\u5747\u7ea6\u9ad8 8%.", "num_citations": "3\n", "authors": ["1179"]}
{"title": "\u57fa\u4e8e\u6539\u8fdb\u8d1d\u53f6\u65af\u6a21\u578b\u7684\u95ee\u9898\u5206\u7c7b\n", "abstract": " \u968f\u7740\u8ba1\u7b97\u673a\u53ca\u4e92\u8054\u7f51\u7edc\u6280\u672f\u7684\u53d1\u5c55, \u5f00\u653e\u57df\u95ee\u7b54\u7cfb\u7edf\u8d8a\u6765\u8d8a\u53d7\u5230\u4eba\u4eec\u7684\u5173\u6ce8, \u56e0\u4e3a\u5b83\u80fd\u591f\u7ed9\u7528\u6237\u63d0\u4f9b\u76f8\u5bf9\u7b80\u6d01, \u51c6\u786e\u7684\u7ed3\u679c. \u5f00\u653e\u57df\u95ee\u7b54\u7cfb\u7edf\u901a\u5e38\u5305\u62ec\u95ee\u9898\u5206\u7c7b, \u95ee\u9898\u6269\u5c55, \u641c\u7d22\u5f15\u64ce, \u7b54\u6848\u62bd\u53d6\u548c\u7b54\u6848\u9009\u62e9\u4e94\u4e2a\u4e3b\u8981\u90e8\u5206. \u95ee\u9898\u5206\u7c7b\u5728\u95ee\u7b54\u7cfb\u7edf\u4e2d\u8d77\u7740\u5f88\u91cd\u8981\u7684\u4f5c\u7528, \u5b83\u7684\u51c6\u786e\u6027\u76f4\u63a5\u5f71\u54cd\u5230\u6700\u7ec8\u62bd\u53d6\u7684\u7b54\u6848\u7684\u51c6\u786e\u6027. \u672c\u6587\u5728\u5bf9\u5df2\u6709\u7684\u8d1d\u53f6\u65af\u5206\u7c7b\u65b9\u6cd5\u8fdb\u884c\u5206\u6790\u7684\u57fa\u7840\u4e0a, \u5bf9\u8be5\u65b9\u6cd5\u8fdb\u884c\u4e86\u6539\u8fdb. \u4e3a\u4e86\u9a8c\u8bc1\u8be5\u65b9\u6cd5\u7684\u6548\u679c, \u6784\u9020\u4e86\u95ee\u9898\u7684\u8bad\u7ec3\u96c6\u548c\u6d4b\u8bd5\u96c6. \u4ece\u5b9e\u9a8c\u7ed3\u679c\u53ef\u4ee5\u770b\u51fa, \u8be5\u65b9\u6cd5\u5728\u5b9e\u9645\u5e94\u7528\u4e2d\u83b7\u5f97\u4e86\u8f83\u597d\u7684\u6548\u679c.", "num_citations": "3\n", "authors": ["1179"]}
{"title": "\u9762\u5411\u7f51\u7edc\u5b9e\u65f6\u6570\u636e\u6d41\u7684\u4e2d\u6587\u4fe1\u606f\u591a\u6a21\u5f0f\u6a21\u7cca\u5339\u914d\n", "abstract": " \u672c\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u7b80\u5355\u800c\u5feb\u901f\u7684\u591a\u6a21\u5f0f\u4e2d\u6587\u4fe1\u606f\u6a21\u7cca\u5339\u914d\u7b97\u6cd5. \u8be5\u7b97\u6cd5\u57fa\u4e8e WM \u7b97\u6cd5, \u5229\u7528\u4e86\u538b\u7f29\u7f16\u7801\u7684\u601d\u60f3. \u4ece\u800c\u5728\u5b9e\u9645\u8fdb\u884c\u591a\u6a21\u5f0f\u5339\u914d\u7684\u8fc7\u7a0b\u4e2d\u83b7\u5f97\u4e86\u5f88\u597d\u7684\u6267\u884c\u6548\u7387. \u5728\u8be5\u7b97\u6cd5\u7684\u57fa\u7840\u4e0a, \u672c\u6587\u5b9e\u73b0\u4e86\u9762\u5411\u7f51\u7edc\u5b9e\u65f6\u6570\u636e\u6d41\u7684\u8fc7\u6ee4\u7cfb\u7edf, \u6d4b\u8bd5\u8868\u660e, \u8be5\u7cfb\u7edf\u80fd\u591f\u652f\u6301\u5927\u91cf\u7684\u6a21\u5f0f, \u5728\u5b9e\u9645\u7684\u5e94\u7528\u4e2d\u62e5\u6709\u975e\u5e38\u5feb\u7684\u901f\u5ea6.", "num_citations": "3\n", "authors": ["1179"]}
{"title": "Decision trees-based Chinese noun phrase coreference resolution\n", "abstract": " CiNii \u8ad6\u6587 - Decision trees-based Chinese noun phrase coreference resolution CiNii \u56fd\u7acb\u60c5\u5831\u5b66 \u7814\u7a76\u6240 \u5b66\u8853\u60c5\u5831\u30ca\u30d3\u30b2\u30fc\u30bf[\u30b5\u30a4\u30cb\u30a3] \u65e5\u672c\u306e\u8ad6\u6587\u3092\u3055\u304c\u3059 \u5927\u5b66\u56f3\u66f8\u9928\u306e\u672c\u3092\u3055\u304c\u3059 \u65e5\u672c\u306e\u535a\u58eb\u8ad6\u6587\u3092 \u3055\u304c\u3059 \u65b0\u898f\u767b\u9332 \u30ed\u30b0\u30a4\u30f3 English \u691c\u7d22 \u3059\u3079\u3066 \u672c\u6587\u3042\u308a \u3059\u3079\u3066 \u672c\u6587\u3042\u308a \u9589\u3058\u308b \u30bf\u30a4\u30c8\u30eb \u8457\u8005\u540d \u8457\u8005ID \u8457\u8005\u6240\u5c5e \u520a\u884c\u7269\u540d ISSN \u5dfb\u53f7\u30da\u30fc\u30b8 \u51fa\u7248\u8005 \u53c2\u8003\u6587\u732e \u51fa\u7248\u5e74 \u5e74\u304b\u3089 \u5e74\u307e\u3067 \u691c\u7d22 \u691c\u7d22 \u691c\u7d22 CiNii\u7a93\u53e3\u696d\u52d9\u306e\u518d\u958b\u306b\u3064\u3044\u3066 Decision trees-based Chinese noun phrase coreference resolution LANG J. \u88ab\u5f15\u7528\u6587\u732e: 1\u4ef6 \u8457\u8005 LANG J. \u53ce\u9332\u520a\u884c\u7269 Student Workshop of Computational Linguistics, 2004 Student Workshop of Computational Linguistics, 2004, 2004 \u88ab\u5f15\u7528\u6587\u732e: 1\u4ef6\u4e2d 1-1\u4ef6\u3092 \u8868\u793a 1 Improving Definite Anaphora Resolution by Effective Weight Learning and Web-Based Knowledge Acquisition WU Dian-Song , LIANG Tyne IEICE transactions on information and systems 94(3), 535-541, 2011-03-01 \u53c2\u8003\u6587\u732e23\u4ef6 Tweet \u5404\u7a2e\u30b3\u30fc\u30c9 NII\u2026", "num_citations": "3\n", "authors": ["1179"]}
{"title": "\u57fa\u4e8e n-gram \u53ca\u4f9d\u5b58\u5206\u6790\u7684\u4e2d\u6587\u81ea\u52a8\u67e5\u9519\u65b9\u6cd5\n", "abstract": " \u81ea\u52a8\u6821\u5bf9\u662f\u81ea\u7136\u8bed\u8a00\u5904\u7406\u9886\u57df\u4e2d\u4e00\u4e2a\u6709\u7740\u5e7f\u9614\u5e94\u7528\u524d\u666f\u7684\u7814\u7a76\u65b9\u5411. \u672c\u6587\u4f7f\u7528\u5b57\u7684\u4e09\u5143\u6a21\u578b\u5bf9\u6587\u672c\u8fdb\u884c\u5c40\u90e8\u7684\u5206\u6790\u4e0e\u9519\u8bef\u67e5\u627e, \u540c\u65f6\u5c06\u4f9d\u5b58\u6587\u6cd5\u5206\u6790\u5e94\u7528\u4e8e\u81ea\u52a8\u6821\u5bf9\u4e2d, \u7531\u4e8e\u4f9d\u5b58\u6587\u6cd5\u5bf9\u53e5\u5b50\u8fdb\u884c\u5168\u5c40\u5206\u6790, \u6307\u51fa\u4e86\u53e5\u5b50\u4e2d\u8bcd\u4e0e\u8bcd\u4e4b\u95f4\u7684\u4f9d\u5b58\u5173\u7cfb, \u6240\u4ee5\u80fd\u591f\u6709\u6548\u7684\u67e5\u627e\u51fa\u6587\u672c\u4e2d\u7684\u8fdc\u8ddd\u79bb\u642d\u914d\u9519\u8bef, \u8865\u5145\u4e86 n \u5143\u8bed\u6cd5\u7684\u4e0d\u8db3. \u7ed3\u5408\u5bf9\u6587\u672c\u7684\u6563\u4e32\u5206\u6790, \u672c\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u8f83\u4e3a\u7406\u60f3\u7684\u4e2d\u6587\u81ea\u52a8\u67e5\u9519\u65b9\u6cd5.", "num_citations": "3\n", "authors": ["1179"]}
{"title": "\u9762\u5411\u53cc\u8bed\u53e5\u5bf9\u68c0\u7d22\u7684\u6c49\u8bed\u53e5\u5b50\u76f8\u4f3c\u5ea6\u8ba1\u7b97\n", "abstract": " \u5728\u57fa\u4e8e\u5927\u89c4\u6a21\u7684\u53cc\u8bed\u53e5\u5bf9\u8bed\u6599\u5e93\u7684\u82f1\u6587\u8f85\u52a9\u5199\u4f5c\u7cfb\u7edf\u4e2d, \u6211\u4eec\u91c7\u7528\u4e86\u4e00\u79cd\u6539\u8fdb\u7f16\u8f91\u8ddd\u79bb\u7684\u53e5\u5b50\u76f8\u4f3c\u5ea6\u8ba1\u7b97\u65b9\u6cd5, \u5373\u5bf9\u4ee5\u5f80\u7684\u7f16\u8f91\u8ddd\u79bb\u7b97\u6cd5\u8fdb\u884c\u9002\u5f53\u7684\u8c03\u6574, \u8003\u8651\u4e86\u66f4\u591a\u7684\u6c49\u8bed\u7ed3\u6784\u4fe1\u606f, \u4f7f\u4e4b\u66f4\u52a0\u7b26\u5408\u6c49\u8bed\u7684\u53e5\u5b50\u76f8\u4f3c\u5ea6\u8ba1\u7b97. \u540c\u65f6\u4f7f\u7528\u4e86 HowNet \u548c\u300a \u540c\u4e49\u8bcd\u8bcd\u6797\u300b \u4e24\u90e8\u8bed\u4e49\u8f9e\u5178\u4f5c\u4e3a\u8bed\u4e49\u8d44\u6e90, \u8ba1\u7b97\u8bcd\u6c47\u4e4b\u95f4\u7684\u76f8\u4f3c\u5ea6. \u6539\u8fdb\u7f16\u8f91\u8ddd\u79bb\u7684\u7b97\u6cd5\u4e0e\u5355\u7eaf\u57fa\u4e8e\u8bed\u4e49\u8f9e\u5178\u8ba1\u7b97\u53e5\u5b50\u76f8\u4f3c\u5ea6\u7684\u7b97\u6cd5\u76f8\u6bd4, \u5177\u6709\u4fbf\u4e8e\u6269\u5c55, \u51c6\u786e\u7387\u9ad8\u7b49\u4f18\u70b9, \u5728\u82f1\u6587\u8f85\u52a9\u5199\u4f5c\u9886\u57df\u53d6\u5f97\u4e86\u4ee4\u4eba\u6ee1\u610f\u7684\u6548\u679c. \u5bf9\u5176\u8fdb\u884c\u9002\u5f53\u7684\u6539\u8fdb\u540e, \u53ef\u9002\u4e8e\u591a\u6570\u9700\u8981\u8ba1\u7b97\u53e5\u5b50\u76f8\u4f3c\u5ea6\u7684\u5e94", "num_citations": "3\n", "authors": ["1179"]}
{"title": "The genus Lophodermium on pinus in the southern part of China.\n", "abstract": " Among the 8 L. spp. reported, L. ellipticum is described as new on Pinus pinus Subject Category: Organism Names", "num_citations": "3\n", "authors": ["1179"]}
{"title": "Enhanced Neural Machine Translation by Joint Decoding with Word and POS-tagging Sequences\n", "abstract": " Machine translation has become an irreplaceable application in the use of mobile phones. However, the current mainstream neural machine translation models depend on continuously increasing the amount of parameters to achieve better performance, which is not applicable to the mobile phone. In this paper, we improve the performance of neural machine translation (NMT) with shallow syntax (e.g., POS tag) of target language, which has better accuracy and latency than deep syntax such as dependency parsing. In particular, our models take less parameters and runtime than other complex machine translation models, making mobile applications possible. In detail, we present three RNN-based NMT decoding models (independent decoder, gates shared decoder and fully shared decoder) to jointly predict target word and POS tag sequences. Experiments on Chinese-English and German-English translation\u00a0\u2026", "num_citations": "2\n", "authors": ["1179"]}
{"title": "Improved neural machine translation with pos-tagging through joint decoding\n", "abstract": " In this paper, we improve the performance of neural machine translation (NMT) with shallow syntax (e.g., POS tag) of target language, which has better accuracy and latency than deep syntax such as dependency parsing. We present three NMT decoding models (independent decoder, gates shared decoder and fully shared decoder) to jointly predict target word and POS tag sequences. Experiments on Chinese-English and German-English translation tasks show that the fully shared decoder can acquire the best performance, which increases the BLEU score by 1.4 and 2.25 points respectively compared with the attention-based NMT model.", "num_citations": "2\n", "authors": ["1179"]}
{"title": "\u57fa\u4e8e DQN \u7684\u5f00\u653e\u57df\u591a\u8f6e\u5bf9\u8bdd\u7b56\u7565\u5b66\u4e60\n", "abstract": " \u6458! \u8981\" \u6709\u6548\u5730\u8fdb\u884c\u591a\u8f6e\u5bf9\u8bdd\u662f\u5f00\u653e\u57df \u00c7 \u673a\u5bf9\u8bdd% \u7edf\u7684\u4e3b\u8981\u76ee\u6807\u4e4b*'\u76ee\u524d\u7684\u795e\u7ecf\u7f51\u7edc\u5bf9\u8bdd\u751f\u6210\u6a21\u578b & \u5f00\u653e\u57df\u591a\u8f6e\u5bf9\u8bdd\u8fc7\u7a0b\u4e2d\u5b58 & \u7740\u5bb9\u6613\u4ea7\u751f\u4e07\u80fd\u56de\u590d & \u5f88\u5feb\u9677 \u00db \u6b7b\u5faa\u73af\u7684\u95ee\u9898% \u800c\u5df2\u6709\u7684\u591a\u8f6e\u5bf9\u8bdd W \u7a76 \u00c8 \u4f5c\u5b58 & \u7740\u6ca1\u6709\u8003\u8651\u672a\u6765\u5bf9\u8bdd\u8d70\u5411\u7684\u95ee\u9898'\u501f\u9274\u5f3a\u5316\u5b66\u4e60\u65b9\u6cd5\u8003\u8651\u5168\u5c40\u7684\u89c6\u89d2! \u8be5\u6587\u5229\u7528\u6df1\u5ea6\u5f3a\u5316\u5b66\u4e60\u7b97\u6cd5 Qg+# DUUXg> JUPR9C\\$! \u63d0 i \u4e86\u4f7f\u7528\u6df1\u5ea6\u4ef7\u503c\u7f51\u7edc\u5bf9\u6bcf* \u8f6e\u7684\u5019\u9009\u53e5\u5b50\u8fdb\u884c\u8bc4\u4f30! \u5e76\u9009\u62e9\u672a\u6765\u6536\u76ca\u6700\u5927\u7684\u800c\u975e\u751f\u6210\u6982\u7387\u6700\u5927\u7684\u53e5\u5b50\u4f5c\u4e3a\u56de\u590d\u7684\u591a\u8f6e\u5bf9\u8bdd\u7b56\u7565\u5b66\u4e60\u65b9\u6cd5'\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e! \u8be5\u6587\u63d0 i \u7684\u65b9\u6cd5\u5c06\u591a\u8f6e\u5bf9\u8bdd\u7684\u5e73\u5747\u5bf9\u8bdd\u8f6e\u6570\u63d0\u9ad8\u4e86\u4e24\u8f6e! \u540c\u65f6 & \u4e3b\u89c2\u5bf9\u6bd4\u8bc4\u4ef7\u6307\u6807\u4e0a\u83b7\u80dc\u6bd4\u4f8b\u9ad8 i \u4e86?@ A'", "num_citations": "2\n", "authors": ["1179"]}
{"title": "\u57fa\u4e8e\u4e3b\u9898\u589e\u5f3a\u5377\u79ef\u795e\u7ecf\u7f51\u7edc\u7684\u7528\u6237\u5174\u8da3\u8bc6\u522b\n", "abstract": " \u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u4e3b\u9898\u589e\u5f3a\u5377\u79ef\u795e\u7ecf\u7f51\u7edc\u7684\u7528\u6237\u5174\u8da3\u8bc6\u522b\u7684\u65b9\u6cd5, \u901a\u8fc7\u6784\u9020\u4e00\u4e2a\u53cc\u901a\u9053 CNN \u6a21\u578b, \u878d\u5408\u8fde\u7eed\u8bed\u4e49\u4fe1\u606f\u548c\u79bb\u6563\u4e3b\u9898\u4fe1\u606f, \u83b7\u53d6\u7528\u6237\u5fae\u535a\u7c7b\u522b\u5206\u5e03, \u5728\u6b64\u57fa\u7840\u4e0a, \u901a\u8fc7\u6781\u5927\u4f3c\u7136\u4f30\u8ba1\u8bc6\u522b\u7528\u6237\u7684\u5174\u8da3. \u5b9e\u9a8c\u7ed3\u679c\u8868\u660e, \u76f8\u8f83\u4e8e\u57fa\u4e8e Labeled LDA \u4e3b\u9898\u6a21\u578b\u7684\u65b9\u6cd5\u548c\u4f20\u7edf\u5377\u79ef\u795e\u7ecf\u7f51\u7edc\u7684\u65b9\u6cd5, \u63d0\u51fa\u7684\u4e3b\u9898\u589e\u5f3a\u5377\u79ef\u795e\u7ecf\u7f51\u7edc\u7f13\u89e3\u4e86\u566a\u58f0\u8bcd\u5bf9\u7528\u6237\u5174\u8da3\u8bcd\u7684\u5f71\u54cd, \u5e76\u4e14\u901a\u8fc7\u878d\u5165\u4e3b\u9898\u4fe1\u606f\u63d0\u9ad8\u4e86\u5bf9\u4e8e\u5305\u542b\u566a\u58f0\u8bcd\u8f83\u591a\u7684\u5fae\u535a\u7684\u5206\u7c7b\u6548\u679c, \u5728\u5fae\u535a\u5206\u7c7b\u53ca\u7528\u6237\u5174\u8da3\u8bc6\u522b\u4e0a\u7684\u6548\u679c\u83b7\u5f97\u4e86\u663e\u8457\u7684\u63d0\u5347.", "num_citations": "2\n", "authors": ["1179"]}
{"title": "Topic hierarchy construction from heterogeneous evidence\n", "abstract": " Existing studies on hierarchy constructionmainly focus on text corpora and indiscriminately mix numerous topics, thus increasing the possibility of knowledge acquisition bottlenecks and misconceptions. To address these problems and provide a comprehensive and in-depth representation of domain specific topics, we propose a novel topic hierarchy construction method with real-time update. This method combines heterogeneous evidence from multiple sources including folksonomy and encyclopedia, separately in both initial topic hierarchy construction and topic hierarchy improvement. Results of comprehensive experiments indicate that the proposed method significantly outperforms state-of-theart methods (t-test, p-value < 0.000 1); recall has particularly improved by 20.4% to 38.7%.", "num_citations": "2\n", "authors": ["1179"]}
{"title": "\u793e\u4f1a\u5a92\u4f53\u4e2d\u7528\u6237\u7684\u9690\u5f0f\u6d88\u8d39\u610f\u56fe\u8bc6\u522b\n", "abstract": " \u4e0d\u540c\u4e8e\u5df2\u6709\u7684\u663e\u5f0f\u6d88\u8d39\u610f\u56fe\u8bc6\u522b\u7684\u7814\u7a76, \u63d0\u51fa\u4e86\u793e\u4f1a\u5a92\u4f53\u4e2d\u7528\u6237\u7684\u9690\u5f0f\u6d88\u8d39\u610f\u56fe\u81ea\u52a8\u8bc6\u522b\u65b9\u6cd5. \u8be5\u65b9\u6cd5\u5c06\u9690\u5f0f\u6d88\u8d39\u610f\u56fe\u8bc6\u522b\u89c6\u4f5c\u591a\u6807\u8bb0\u5206\u7c7b\u95ee\u9898, \u5e76\u7efc\u5408\u4f7f\u7528\u4e86\u57fa\u4e8e\u7528\u6237\u5173\u6ce8\u884c\u4e3a, \u610f\u56fe\u5173\u6ce8\u884c\u4e3a, \u610f\u56fe\u8f6c\u53d1\u884c\u4e3a\u4ee5\u53ca\u4e2a\u4eba\u4fe1\u606f\u7684\u591a\u79cd\u7279\u5f81. \u7531\u4e8e\u9690\u5f0f\u6d88\u8d39\u610f\u56fe\u8bc6\u522b\u96be\u4ee5\u8bc4\u4ef7, \u81ea\u52a8\u62bd\u53d6\u4e86\u5927\u91cf\u8de8\u793e\u4f1a\u5a92\u4f53\u7684\u7528\u6237\u94fe\u6307\u4fe1\u606f, \u5229\u7528\u8be5\u65b9\u6cd5, \u5171\u62bd\u53d6\u51fa 12 \u4e07\u4f59\u5bf9\u7684\u7528\u6237\u94fe\u6307. \u5728\u6b64\u81ea\u52a8\u8bc4\u4ef7\u96c6\u4e0a\u7684\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e, \u6240\u91c7\u7528\u7684\u591a\u6807\u8bb0\u5206\u7c7b\u65b9\u6cd5\u5bf9\u4e8e\u8bc6\u522b\u7528\u6237\u7684\u9690\u5f0f\u6d88\u8d39\u610f\u56fe\u662f\u884c\u4e4b\u6709\u6548\u7684, \u5176\u4e2d\u4f7f\u7528\u7684\u5404\u79cd\u7279\u5f81\u5bf9\u4e8e\u63d0\u9ad8\u9690\u5f0f\u6d88\u8d39\u610f\u56fe\u8bc6\u522b\u7684\u6548\u679c\u7686\u6709\u5e2e\u52a9.", "num_citations": "2\n", "authors": ["1179"]}
{"title": "Generating Triples Based on Dependency Parsing for Contradiction Detection\n", "abstract": " Contradiction detection is a task to detect the contradictory relation between two texts. In the social media, the phenomenon of contradictory descriptions of the same event is common and harmful. It is urgent to detect contradictory texts. Previous methods on detecting contradiction are mostly deriving features from shallow semantic representations like predicate-argument structures. They meet a problem of the low coverage of contradiction. We propose a joint method to extract more contradiction pairs. We utilize dependency parsing tree to generate tripes (dp-triple) which represent semantic information of the text. The dp-triple extraction method extract more contradiction pairs than present shallow semantic extraction methods like open IE or SRL. Due to the coverage limitation of triples, we also derive features from the context of the matching words between texts as backup. We demonstrate the joint method\u00a0\u2026", "num_citations": "2\n", "authors": ["1179"]}
{"title": "Understanding Cultural Conflicts using Metaphors and Sociolinguistic Measures of Influence\n", "abstract": " In this article, we outline a novel approach to the automated analysis of cross-cultural conflicts through the discovery and classification of the metaphors used by the protagonist parties involved in the conflict. We demonstrate the feasibility of this approach on a prototypical conflict surrounding the appropriate management and oversight of gun-ownership in the United States. In addition, we present a way of incorporating sociolinguistic measures of influence in discourse to draw further insights from complex data. The results presented in this article should be considered as illustrative of the types of analyses that can be obtained using our methodology; however, no attempt was made to rigorously validate the specific findings reported here. We address open issues such as how our approach could be generalized to analyze cross-cultural conflicts around the world.", "num_citations": "2\n", "authors": ["1179"]}
{"title": "\u57fa\u4e8e\u56fe\u6392\u5e8f\u7684\u793e\u4f1a\u5a92\u4f53\u7528\u6237\u7684\u6d88\u8d39\u610f\u56fe\u68c0\u6d4b\n", "abstract": " \u6d88\u8d39\u610f\u56fe\u662f\u6307\u7528\u6237\u4e3a\u6ee1\u8db3\u67d0\u79cd\u9700\u8981, \u5728\u4e00\u5b9a\u8d2d\u4e70\u52a8\u673a\u7684\u652f\u914d\u4e0b, \u901a\u8fc7\u6587\u672c\u5185\u5bb9\u8868\u8fbe\u51fa\u5bf9\u4ea7\u54c1\u6216\u670d\u52a1\u7684\u8d2d\u4e70\u610f\u613f. \u6d88\u8d39\u610f\u56fe\u68c0\u6d4b\u65e8\u5728\u63a8\u65ad\u7528\u6237\u5728\u6587\u672c\u4e2d\u662f\u5426\u8868\u8fbe\u51fa\u6d88\u8d39\u610f\u56fe\u7684\u542b\u4e49. \u6211\u4eec\u5b9a\u4e49\u5fae\u535a\u4e2d\u7684\u6d88\u8d39\u610f\u56fe\u5fc5\u987b\u5305\u542b\u4e24\u4e2a\u91cd\u8981\u5143\u7d20, \u5206\u522b\u662f\u6d88\u8d39\u610f\u56fe\u89e6\u53d1\u8bcd\u548c\u6d88\u8d39\u610f\u56fe\u5bf9\u8c61 (\u5373\u9700\u8981\u8d2d\u4e70\u7684\u4ea7\u54c1), \u8fd9\u4e24\u79cd\u5143\u7d20\u76f4\u63a5\u5f15\u53d1\u7528\u6237\u7684\u8d2d\u4e70\u610f\u613f, \u662f\u51b3\u5b9a\u7528\u6237\u6d88\u8d39\u610f\u56fe\u7684\u91cd\u8981\u7279\u5f81. \u672c\u6587\u63d0\u51fa\u4e86\u57fa\u4e8e\u5f31\u76d1\u7763\u7684\u56fe\u6392\u5e8f\u7b97\u6cd5, \u8be5\u65b9\u6cd5\u9002\u7528\u4e8e\u6570\u636e\u603b\u91cf\u8f83\u5927, \u5df2\u6807\u6ce8\u6570\u636e\u91cf\u76f8\u5bf9\u8f83\u5c0f\u7684\u60c5\u5f62\u4e2d, \u5e76\u4e14\u53ef\u4ee5\u4f7f\u672a\u6807\u6ce8\u6570\u636e\u548c\u6807\u6ce8\u6570\u636e\u540c\u65f6\u53c2\u4e0e\u5230\u56fe\u6392\u5e8f\u7b97\u6cd5\u7684\u5b66\u4e60\u8fc7\u7a0b\u4e2d. \u5b9e\u9a8c\u7ed3\u679c\u8868\u660e, \u6240\u91c7\u7528\u7684\u56fe\u6392\u5e8f\u65b9\u6cd5\u5bf9\u4e8e\u6d88\u8d39\u610f\u56fe\u68c0\u6d4b\u662f\u884c\u4e4b\u6709\u6548\u7684.", "num_citations": "2\n", "authors": ["1179"]}
{"title": "BUEES: a bottom-up event extraction system\n", "abstract": " Traditional event extraction systems focus mainly on event type identification and event participant extraction based on pre-specified event type paradigms and manually annotated corpora. However, different domains have different event type paradigms. When transferring to a new domain, we have to build a new event type paradigm and annotate a new corpus from scratch. This kind of conventional event extraction system requires massive human effort, and hence prevents event extraction from being widely applicable. In this paper, we present BUEES, a bottom-up event extraction system, which extracts events from the web in a completely unsupervised way. The system automatically builds an event type paradigm in the input corpus, and then proceeds to extract a large number of instance patterns of these events. Subsequently, the system extracts event arguments according to these patterns. By\u00a0\u2026", "num_citations": "2\n", "authors": ["1179"]}
{"title": "Gender identification on social media\n", "abstract": " Accurate identification of hidden demographic attributes from social media is very useful for advertisement, personalized recommendation and etc. We investigate the effect of two different classification models for the gender identification problem over different attributes of Sina Weibo users. To improve the accuracy of the classfication models, we propose a novel feature selection algorithm and a retrained multiattribute model. Experimental results show that the accuracy of our approach achieves 89.01% which is better than any previous work in this problem.", "num_citations": "2\n", "authors": ["1179"]}
{"title": "A semantics oriented grammar for chinese treebanking\n", "abstract": " Chinese grammar engineering has been a much debated task. Whilst semantic information has been reconed crucial for Chinese syntactic analysis and downstream applications, existing Chinese treebanks lack a consistent and strict sentential semantic formalism. In this paper, we introduce a semantics oriented grammar for Chinese, designed to provide basic supports for tasks such as automatic semantic parsing and sentence generation. It has a directed acyclic graph structure with a simple yet expressive label set, and leverages elementary predication to support logical form conversion. To our knowledge, it is the first Chinese grammar representation capable of direct transformation into logical forms.", "num_citations": "2\n", "authors": ["1179"]}
{"title": "Social Media Processing\n", "abstract": " We are living in an increasingly networked world. People, information, and other entities are connected via the World Wide Web, e-mail networks, instant messaging networks, mobile communication networks, online social networks, etc. These generate massive amounts of social data, which present great opportunities in understanding the science of user behavioral patterns and the structure of networks formed by people interactions. The Third National Conference on Social Media Processing (SMP) was held in Beijing, China, in 2014 for the purpose of promoting original research in mining social media and applications, bringing together experts from related fields such as natural language processing, data mining, and information retrieval, and providing a leading forum in which to exchange research ideas and results in emergent social media processing problems.The conference received 101 submissions, of\u00a0\u2026", "num_citations": "2\n", "authors": ["1179"]}
{"title": "\u57fa\u4e8e\u8de8\u793e\u4ea4\u5a92\u4f53\u68c0\u7d22\u7684\u5fae\u535a\u6d88\u8d39\u5bf9\u8c61\u8bc6\u522b\n", "abstract": " \u76ee\u524d, \u5fae\u535a\u6d88\u8d39\u610f\u56fe\u8bc6\u522b\u95ee\u9898\u6210\u4e3a\u65b0\u7684\u7814\u7a76\u70ed\u70b9. \u7136\u800c, \u5df2\u6709\u5de5\u4f5c\u4e3b\u8981\u5224\u65ad\u5fae\u535a\u662f\u5426\u5177\u6709\u5546\u4e1a\u610f\u56fe, \u5f88\u5c11\u7814\u7a76\u6d88\u8d39\u610f\u56fe\u5185\u5bb9\u4e2d\u6d88\u8d39\u5bf9\u8c61\u7684\u8bc6\u522b\u95ee\u9898, \u800c\u6d88\u8d39\u5bf9\u8c61\u7684\u8bc6\u522b\u662f\u7cbe\u786e\u5730\u8fdb\u884c\u5546\u4e1a\u63a8\u8350\u7684\u5173\u952e, \u56e0\u6b64\u5bf9\u5176", "num_citations": "2\n", "authors": ["1179"]}
{"title": "Improving web search ranking by incorporating structured annotation of queries\n", "abstract": " Abstract\uf020Web users are increasingly looking for structured data, such as lyrics, job, or recipes, using unstructured queries on the web. However, retrieving relevant results from such data is a challenging problem due to the unstructured language of the web queries. In this paper, we propose a method to improve web search ranking by detecting Structured Annotation of queries based on top search results. In a structured annotation, the original query is split into different units that are associated with semantic attributes in the corresponding domain. We evaluate our techniques using real world queries and achieve significant improvement.", "num_citations": "2\n", "authors": ["1179"]}
{"title": "Enhancing Chinese Word Segmentation with Character Clustering\n", "abstract": " In semi-supervised learning framework, clustering has been proved a helpful feature to improve system performance in NER and other NLP tasks. However, there hasn\u2019t been any work that employs clustering in word segmentation. In this paper, we proposed a new approach to compute clusters of characters and use these results to assist a character based Chinese word segmentation system. Contextual information is considered when we perform character clustering algorithm to address character ambiguity. Experiments show our character clusters result in performance improvement. Also, we compare our clusters features with widely used mutual information (MI). When two features integrated, further improvement is achieved.", "num_citations": "2\n", "authors": ["1179"]}
{"title": "User behaviors lend a helping hand: Learning paraphrase query patterns from search log sessions\n", "abstract": " Search log sessions contain a large number of paraphrases contributed by users during query rewriting. However, it is a big challenge to distinguish paraphrases from the simply related queries in the sessions. This paper addresses this problem by making innovative use of user behavior information embodied in query sessions. Specifically, we learn paraphrase patterns from the search log sessions with a classification framework, in which three types of user behavior features are exploited besides the conventional features. We evaluate the method using a query log of a commercial search engine. Experimental results demonstrate the effectiveness of our method, especially the significant contribution of the user behavior features. We extract over 250,000 pairs of paraphrase patterns from the used search log, with a precision over 76%.", "num_citations": "2\n", "authors": ["1179"]}
{"title": "Unsupervised query segmentation using monolingual word alignment method\n", "abstract": " In this paper, we propose a novel unsupervised approach to query segmentation using the word alignment model which is usually adopted in statistical machine translation system. Query segmentation is to obtain complete phrases or concepts in a query by segmenting a sequence of query terms, which is an important query processing procedure for improving information retrieval performance in search engines. In this work, we use a novel monolingual word alignment method to segment queries and automatically obtain the query structure in the form of multilevel segmentation. Our approach is language independent and unsupervised so that it is easy to be applied to various language scenarios. Experimental results on a real-world query dataset show that our approach outperforms the state of the art language model based method, which demonstrates the effectiveness of the proposed approach in query segmentation.", "num_citations": "2\n", "authors": ["1179"]}
{"title": "Word Sense Disambiguation Corpora Acquisition via Confirmation Code\n", "abstract": " Word Sense Disambiguation (WSD) is one of the fundamental natural language processing tasks. However, lack of training corpora is a bottleneck to construct a high accurate all-words WSD system. Annotating a large-scale corpus by experts costs enormous time and financial resources. Human Computation is a novel idea for integrating human resources behind the Web, which has been wasted, to solve practical problems that are difficult for computers. Based on human computation, we design a confirmation code system, which can not only distinguish between human beings and computers (the function of normal confirmation code system), but also annotate WSD corpora. The preliminary experimental result shows that the proposed method can annotate large-scale and high-quality WSD corpora within a short time. To the best of our knowledge, this is the first attempt to use confirmation code in natural language processing for corpora acquisition.", "num_citations": "2\n", "authors": ["1179"]}
{"title": "\u57fa\u4e8e\u4e2d\u5fc3\u8bed\u5339\u914d\u7684\u5171\u6307\u6d88\u89e3\n", "abstract": " \u73b0\u5b9e\u4e16\u754c\u4e2d\u540c\u00a5 \u4e2a\u4e8b\u7269\u7ecf\u5e38\u4f1a\u6709\u4e0d\u540c\u7684\u540d\u79f0\u4ee5\u53ca\u63cf \u8ff0! \u6211\u4eec\u79f0\u8fd9\u4e9b\u540d\u79f0\u4ee5\u53ca\u63cf\u8ff0\u79f0\u4e3a# \u8868 \u8ff0 & $3 KGLF8G%! \u79f0\u8fd9\u4e9b\u8868\u8ff0\u6240\u5bf9\u5e94\u7684\u4e8b\u7269\u4e3a# \u5b9e \u4f53 & $1 GLFL<%'\u6240\u8c13\u7684\u5171\u6307\u6d88\u89e3 $. 8> MKNKMKGQK) KU89C> LF8G%! \u5c31\u662f\u6839\u636e\u00a5 \u7bc7\u6587\u6863\u4e2d\u5404\u4e2a\u8868\u8ff0\u7684\u5185\u5bb9\u4ee5\u53ca\u4e0a\u4e0b\u6587\u4fe1\u606f\u5c06\u8fd9\u4e9b\u8868\u8ff0\u5bf9\u5e94\u5230\u5177\u4f53\u5b9e\u4f53\u7684\u8fc7\u7a0b+%>!,'\u5b9e\u8d28\u4e0a! \u5171\u6307\u6d88\u89e3\u662f\u00a5 \u4e2a\u5bf9\u6240\u6709\u8868\u8ff0\u8fdb\u884c\u7b49\u4ef7\u7c7b\u5212\u5206\u7684\u8fc7\u7a0b! \u5b83\u53ef\u4ee5\u4f7f\u9690\u85cf\u5728\u9648\u8ff0\u4e2d\u7684\u7b49\u4ef7\u5173\u7cfb\u53d8\u5f97\u6e05\u6670! \u8fd9\u5bf9\u4e8e\u4fe1\u606f\u62bd\u53d6* \u4fe1\u606f\u68c0\u7d22* \u673a\u5668\u7ffb\u8bd1\u7b49\u4e0a\u5c42\u5e94\u7528\u7684\u8fdb\u00a5 \u6b65\u53d1 \u041c \u662f\u975e\u5e38\u6709\u5e2e\u52a9\u7684'\u8fd1! $ \u5e74\u6765! \u5171\u6307\u6d88\u89e3\u7814\u7a76\u53d7\u5230\u4e86\u7279\u522b\u5173\u6ce8! \u5927", "num_citations": "2\n", "authors": ["1179"]}
{"title": "Why-Questions Answering for Reading Comprehension Based on Topic and Rhetorical Identification\n", "abstract": " As an important branch in the study of question answering system, automatic reading comprehension (RC) system involves reading a short passage of text and answering a series of questions pertaining to that text. In all question types including who, what, when, where, why studied in the field of RC, answer extraction of why-question should apply the discourse structure information of text and the answer is not an named entity. Concerning these difference of why-question with other types, an answer sentence extraction approach for why-question of reading comprehension is given in this paper based on question topic and causal rhetorical relation identification. It uses machine learning model to rank sentences in text according to their probabilities of becoming answer sentence. In the model, two kinds of feature are used for identification of text sentence corresponding to question topic and that of causal rhetorical relation between question topic and sentence context respectively. In all features, the idf and semantic role similarity features are utilized to identify the sentence corresponding to the question topic, and other features, including cue phrases, special semantic roles, causal relation entailment probabilities between words mined from large scale document collections, position and expression format of sentence context, are used to identify causal rhetorical relation. Experimental results on Remedia corpus show that the method improves significantly the performance of reading comprehension why-question answering.", "num_citations": "2\n", "authors": ["1179"]}
{"title": "Personalized Query Reformulation Based on Search Context [J]\n", "abstract": " Learning user preference implicitly is a hot research topic for personalized search, and query model reformulation based on user search history is a key issue. Existing work considers the search history as a whole without distinguishing whether it is relevant to current query, resulting in much noise. In this paper, assuming that the relevant terms tend to co-occurrence in context, we treat each past snippet as a context and reformulate the query by selecting the most relevant terms to the whole query from the user clicks. The experiment results show that the algorithm can select relevant terms and reduce noise. With the evaluation metrics of p@ 5 and NDCG, the system achieves a relative improvement against the best baseline system by 12.8% and 7.2% respectively, 26.0% and 11.4% against the original ranking.[Fund]: \u56fd\u5bb6\u81ea\u7136\u79d1\u5b66\u57fa\u91d1\u91cd\u70b9\u8d44\u52a9\u9879\u76ee (60736044);; \u56fd\u5bb6\u81ea\u7136\u79d1\u5b66\u57fa\u91d1\u9762\u4e0a\u8d44\u52a9\u9879\u76ee (60675034);; \u56fd\u5bb6 863 \u8ba1\u5212\u63a2\u7d22\u7c7b\u4e13\u9898\u8d44\u52a9\u9879\u76ee (2008AA01Z144);; \u8bed\u8a00\u8bed\u97f3\u6559\u80b2\u90e8\u2014\u5fae\u8f6f\u91cd\u70b9\u5b9e\u9a8c\u5ba4\u5f00\u653e\u57fa\u91d1\u8d44\u52a9 (HTT. KLOF. 2009020)", "num_citations": "2\n", "authors": ["1179"]}
{"title": "\u57fa\u4e8e\u81ea\u52a8\u6784\u5efa\u8bed\u6599\u5e93\u7684\u8bcd\u6c47\u7ea7\u590d\u8ff0\u7814\u7a76\n", "abstract": " \u672c\u6587\u9488\u5bf9\u8bcd\u6c47\u7ea7\u590d\u8ff0\u95ee\u9898\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u65b9\u6cd5. \u8be5\u65b9\u6cd5\u9996\u5148\u5229\u7528\u7ffb\u8bd1\u5f15\u64ce\u5c06\u53cc\u8bed\u5e73\u884c\u8bed\u6599\u5e93\u81ea\u52a8\u8f6c\u6362\u4e3a\u5355\u8bed\u5e73\u884c\u8bed\u6599\u5e93, \u4ee5\u6b64\u6784\u5efa\u590d\u8ff0\u8bed\u6599\u5e93\u5e76\u7528\u4e8e\u5019\u9009\u590d\u8ff0\u7684\u62bd\u53d6. \u5728\u6b64\u57fa\u7840\u4e0a, \u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u7edf\u8ba1\u6a21\u578b. \u8be5\u6a21\u578b\u6839\u636e\u7279\u5b9a\u7684\u4e0a\u4e0b\u6587\u4e3a\u5f85\u590d\u8ff0\u8bcd\u9009\u62e9\u6700\u4e3a\u5408\u9002\u7684\u590d\u8ff0. \u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\u81ea\u52a8\u6784\u5efa\u7684\u590d\u8ff0\u8bed\u6599\u5e93\u5bf9\u4e8e\u8bcd\u6c47\u7ea7\u590d\u8ff0\u7684\u62bd\u53d6\u662f\u6709\u6548\u7684. \u540c\u65f6, \u672c\u6587\u63d0\u51fa\u7684\u6a21\u578b\u660e\u663e\u4f18\u4e8e\u4e24\u79cd\u4f20\u7edf\u6a21\u578b, \u5728\u51c6\u786e\u7387\u548c\u53ec\u56de\u7387\u4e0a\u5206\u522b\u63d0\u9ad8 10% \u5de6\u53f3.", "num_citations": "2\n", "authors": ["1179"]}
{"title": "COLLANE: An experiment in computer-mediated tacit collaboration\n", "abstract": " We introduce COLLANE, an experimental collaborative analytic environment that allows a\u00a0group of professional analysts to work together effectively on complex, multifaceted information problems. COLLANE has been developed to investigate innovative ways of harnessing the power of collaboration so that to maximize the quality of the analytical product while at the same time controlling for its hidden costs: bias, groupthink, compromise, suppression of dissent and individual initiative. The key innovation that we are advancing in this project is the concept of ubiquitous tacit collaboration enabled through computer-mediated information sharing between the participants. By design, tacit collaboration requires no extraneous effort from the users since the information exchange is both automatic and targeted to what each analyst is currently doing. It also requires no specific \u201cengagement\u201d with subject matter\u00a0\u2026", "num_citations": "2\n", "authors": ["1179"]}
{"title": "Research on Evaluation of Personalized Information Retrieval Based on Manual Annotation\n", "abstract": " Personalized information retrieval can grasp the users' retrieval intention and find personalized results. A manual annotation system is designed in this paper to generate the corpus for evaluating personalized IR system. Then the User-centered manual annotation strategy is proposed for personalized IR evaluation. The evaluation system adopts the evaluation scheme provided by NIST performs an automatic evaluation according to the manually annotated results, and generates the quantified and straight-forward measurement results.", "num_citations": "2\n", "authors": ["1179"]}
{"title": "Phrasal Paraphrase Acquisition Based on Bilingual Corpus\n", "abstract": " In this paper a novel method based on bilingual corpus is proposed to extract phrasal paraphrase examples. We focus on extract paraphrases of ambiguous phrases. A bilingual pair is the original input. Then all candidate paraphrases are extracted from word aligned bilingual corpus. The bi-direction model is designed to acquire confident paraphrases according to the coherence between the candidate phrases and the input phrases. The experimental results show that the synthesis precision is about 60%.", "num_citations": "2\n", "authors": ["1179"]}
{"title": "Word Sense Disambiguation based on improved Bayesian classifiers\n", "abstract": " Word Sense Disambiguation (WSD) is to decide the sense of an ambiguous word on particular context. Most of current studies on WSD only use several ambiguous words as test samples, thus leads to some limitation in practical application. In this paper, we perform WSD study based on large scale real-world corpus using two unsupervised learning algorithms based on \u00b1n-improved Bayesian model and Dependency Grammar (DG)-improved Bayesian model. \u00b1n-improved classifiers reduce the window size of context of ambiguous words with close-distance feature extraction method, and decrease the jamming of useless features, thus obviously improve the accuracy, reaching 83.18% (in open test). DG-improved classifier can more effectively conquer the noise effect existing in Na\u00efve-Bayesian classifier. Experimental results show that this approach does better on Chinese WSD, and the open test\u00a0\u2026", "num_citations": "2\n", "authors": ["1179"]}
{"title": "Using different models to label the break indices for mandarin speech synthesis\n", "abstract": " High quality speech synthesis system requires effective prediction of break indices. This paper adopts a large scale corpus with five-tier break indices annotated according to C-TOBI. Based on it, several models including N-gram, artificial neural network and Markov model are employed to automatically label the break indices for unrestricted mandarin text. These approaches differ not only in models, but also in features. The results show that among these three models, MM can give the best result. The accuracy reaches 77.0% and the average error cost is 0.155. These three models are compared with each other, and some conclusions are made to dig into the problem.", "num_citations": "2\n", "authors": ["1179"]}
{"title": "\u7c7b\u522b\u4e3b\u7279\u5f81\u7ed3\u5408\u53e5\u6cd5\u7279\u5f81\u7684\u4e2d\u6587\u95ee\u9898\u5c42\u6b21\u5206\u7c7b\n", "abstract": " \u95ee\u9898\u5206\u7c7b\u662f\u95ee\u7b54\u7cfb\u7edf\u4e2d\u91cd\u8981\u7684\u7ec4\u6210\u90e8\u5206, \u95ee\u9898\u5206\u7c7b\u7ed3\u679c\u7684\u597d\u574f\u76f4\u63a5\u5f71\u54cd\u95ee\u7b54\u7cfb\u7edf\u7684\u6027\u80fd. \u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u95ee\u9898\u5c42\u6b21\u5206\u7c7b\u65b9\u6cd5, \u8be5\u65b9\u6cd5\u7ed3\u5408\u7c7b\u522b\u4e3b\u7279\u5f81\u4e0e\u95ee\u9898\u53e5\u6cd5\u7279\u5f81, \u5bf9\u6ee1\u8db3\u7c7b\u522b\u4e34\u754c\u6761\u4ef6\u7684\u95ee\u9898, \u5229\u7528\u5177\u6709\u826f\u597d\u5206\u7c7b\u7279\u6027\u7684\u7c7b\u522b\u4e3b\u7279\u5f81\u8fdb\u884c\u5206\u7c7b, \u4f7f\u5176\u5c0f\u7c7b\u5206\u7c7b\u7cbe\u5ea6\u8fbe\u5230 92.99%, \u5bf9\u4e8e\u5176\u4ed6\u95ee\u9898, \u91c7\u7528\u8d1d\u53f6\u65af\u5206\u7c7b\u5668\u5206\u7c7b, \u603b\u7684\u51c6\u786e\u7387\u8fbe\u5230\u5927\u7c7b 88.25% \u548c\u5c0f\u7c7b 73.15%, \u6bd4\u4f20\u7edf\u7684\u5c42\u6b21\u5206\u7c7b\u5206\u522b\u63d0\u9ad8\u4e86 10 \u4e2a\u767e\u5206\u70b9, \u8bc1\u660e\u4e86\u6b64\u65b9\u6cd5\u7684\u6709\u6548\u6027.", "num_citations": "2\n", "authors": ["1179"]}
{"title": "\u57fa\u4e8e\u5b50\u4e3b\u9898\u7684\u591a\u6587\u6863\u6587\u6458\n", "abstract": " \u591a\u6587\u6863\u96c6\u5408\u7684\u4e2d\u5fc3\u4e3b\u9898\u662f\u7531\u5404\u4e2a\u4fa7\u9762\u4fe1\u606f\u7ec4\u5408\u800c\u6210\u7684, \u6bcf\u4e2a\u4fa7\u9762\u7684\u4fe1\u606f\u79f0\u4e4b\u4e3a\u4e00\u4e2a\u5b50\u4e3b\u9898. \u672c\u6587\u9996\u5148\u9610\u8ff0\u4e86\u5b50\u4e3b\u9898\u7684\u5b9a\u4e49\u548c\u7279\u70b9, \u5728\u591a\u6587\u6863\u96c6\u5408\u5b50\u4e3b\u9898\u5f62\u5f0f\u7684\u57fa\u7840\u4e0a, \u901a\u8fc7\u5bf9\u5b50\u4e3b\u9898\u7684\u91cd\u8981\u6027\u6392\u5e8f\u4ee5\u53ca\u5b50\u4e3b\u9898\u4e2d\u6587\u6458\u53e5\u62bd\u53d6\u65b9\u6cd5\u7684\u7814\u7a76, \u751f\u6210\u591a\u6587\u6863\u6587\u6458. \u5b9e\u9a8c\u8868\u660e, \u8be5\u65b9\u6cd5\u83b7\u5f97\u4e86\u8f83\u7406\u60f3\u7684\u6548\u679c.", "num_citations": "2\n", "authors": ["1179"]}
{"title": "Implement a full-text automatic system for word sense tagging\n", "abstract": " Word sense disambiguation has been a very active research topic in the NLP field, which studies how to determine which of the senses of an ambiguous word is invoked in a particular context using sense classifiers. This paper presents a technique for unsupervised word sense disambiguation and implements the process of a full-text word sense tagging system. This system performs word sense disambiguation based on the Nave Bayesian Model, uses largescale corpora as training data, and it is able to preferentially conquer the problem of Sparse Data in Knowledge Acquisition. In addition, this system has the characteristics of high accuracy and quick running speed. Thus, this system is competent for word sense tagging on large-scale, real-word text.", "num_citations": "2\n", "authors": ["1179"]}
{"title": "HITIQA: An Interactive Question Answering System\n", "abstract": " HITIQA is an interactive question answering technology designed to allow intelligence analysts and other users of information systems to pose questions in natural language and obtain relevant answers, or the assistance they require in order to perform their tasks. Our objective in HITIQA is to allow the user to submit exploratory, analytical, non-factual questions, such as\" What has been Russia's reaction to US bombing of Kosovo?\" The distinguishing property of such questions is that one cannot generally anticipate what might constitute the answer. While certain types of things may be expected (eg, diplomatic statements), the answer is heavily conditioned by what information is in fact available on the topic. From a practical viewpoint, analytical questions are often underspecified, thus casting a broad net on a space of possible answers. Therefore, clarification dialogue is often needed to negotiate with the user the exact scope and intent of the question.", "num_citations": "2\n", "authors": ["1179"]}
{"title": "\u53cc\u8bed\u8bed\u6599\u5e93\u6bb5\u843d\u91cd\u7ec4\u5bf9\u9f50\u65b9\u6cd5\u7814\u7a76\n", "abstract": " \u7f51\u7edc\u4e0a\u5b58\u5728\u7684\u5927\u91cf\u53cc\u8bed\u8d44\u6e90, \u7ed9\u6784\u5efa\u5927\u89c4\u6a21\u53cc\u8bed\u8bed\u6599\u5e93\u63d0\u4f9b\u4e86\u53ef\u80fd. \u53cc\u8bed\u5bf9\u9f50\u4f5c\u4e3a\u8bed\u6599\u5e93\u52a0\u5de5\u8fc7\u7a0b\u4e2d", "num_citations": "2\n", "authors": ["1179"]}
{"title": "\u4e2d\u6587\u81ea\u52a8\u6587\u6458\u7cfb\u7edf CAAS \u7684\u7814\u7a76\u4e0e\u5b9e\u73b0\n", "abstract": " \u4ecb\u7ecd\u4e86\u4e00\u79cd\u4e2d\u6587\u81ea\u52a8\u6587\u6458\u7cfb\u7edf; \u8be5\u7cfb\u7edf\u5728\u9ad8\u7cbe\u5ea6\u7684\u6c49\u8bed\u81ea\u52a8\u5206\u8bcd, \u5173\u952e\u8bcd\u81ea\u52a8\u62bd\u53d6\u7b49\u7b97\u6cd5\u7684\u57fa\u7840\u4e0a, \u5f15\u5165\u4e86\u6587\u672c\u7ed3\u6784\u7684\u7edf\u8ba1\u5206\u6790\u548c\u53e5\u95f4\u6307\u4ee3\u5173\u7cfb\u7684\u8bc6\u522b\u7b49\u6280\u672f, \u4f7f\u5f97\u751f\u6210\u7684\u6458\u8981\u66f4\u52a0\u51c6\u786e, \u5168\u9762, \u8fde\u8d2f. \u8be5\u7cfb\u7edf\u9002\u7528\u4e8e\u79d1\u6280\u6587\u732e, \u653f\u8bba\u6587, \u516c\u6587\u7b49\u5b9e\u7528\u6587\u4f53\u7684\u6458\u8981\u751f\u6210.", "num_citations": "2\n", "authors": ["1179"]}
{"title": "Attribute Acquisition in Ontology based on Representation Learning of Hierarchical Classes and Attributes\n", "abstract": " Attribute acquisition for classes is a key step in ontology construction, which is often achieved by community members manually. This paper investigates an attention-based automatic paradigm called TransATT for attribute acquisition, by learning the representation of hierarchical classes and attributes in Chinese ontology. The attributes of an entity can be acquired by merely inspecting its classes, because the entity can be regard as the instance of its classes and inherit their attributes. For explicitly describing of the class of an entity unambiguously, we propose class-path to represent the hierarchical classes in ontology, instead of the terminal class word of the hypernym-hyponym relation (i.e., is-a relation) based hierarchy. The high performance of TransATT on attribute acquisition indicates the promising ability of the learned representation of class-paths and attributes. Moreover, we construct a dataset named \\textbf{BigCilin11k}. To the best of our knowledge, this is the first Chinese dataset with abundant hierarchical classes and entities with attributes.", "num_citations": "1\n", "authors": ["1179"]}
{"title": "Negation scope detection with a conditional random field model\n", "abstract": " Identifying negation cues and their scope in a text is an important subtask of information extraction that can benefit other natural language processing tasks, including but not limited to medical data mining, relation extraction, question answering and sentiment analysis. The tasks of negation cue and negation scope detection can be treated as sequence labelling problems. In this paper, a system is presented having two components: negation cue detection and negation scope detection. In the first phase, a conditional random field (CRF) model is trained to detect the negation cues using a lexicon of negation words and some lexical and contextual features. Then, another CRF model is trained to detect the scope of each negation cue identified in the first phase, using basic lexical and contextual features. These two models are trained and tested using the dataset distributed within the* Sem Shared Task 2012 on resolving the scope and focus of negation. Experimental results show that the system outperformed all the systems submitted to this shared task.", "num_citations": "1\n", "authors": ["1179"]}
{"title": "\u57fa\u4e8e\u4f9d\u5b58\u53e5\u6cd5\u5206\u6790\u7684\u590d\u5408\u4e8b\u5b9e\u578b\u95ee\u53e5\u5206\u89e3\u65b9\u6cd5\n", "abstract": " \u6458! \u8981\" \u95ee\u7b54% \u7edf'A\u00d8 \u6765\u90fd\u662f\u81ea\u7136\u8bed\u8a00\u5904\u7406\u9886\u57df\u7684 W \u7a76\u70ed\u70b9\u4e4b'! \u7136\u800c\u73b0\u6709\u95ee\u7b54% \u7edf\u6280\u6728\u5bf9\u590d\u5408\u4e8b\u5b9e\u578b\u95ee\u53e5\u7684\u5904\u7406\u6548\u679c\u5e76\u4e0d\u5b8c\u7f8e% \u4e3a\u4e86\u589e\u5f3a\u95ee\u7b54% \u7edf\u7406\u89e3\u590d\u5408\u4e8b\u5b9e\u578b\u95ee\u53e5\u7684\u80fd\u529b! \u8be5\u6587\u63d0 i \u4e86'# \u9488\u5bf9\u590d\u5408\u4e8b\u5b9e\u578b\u95ee\u53e5\u7684\u5206\u89e3\u65b9\u6cd5\" \u4f7f\u7528\u57fa\u4e8e\u6811\u6838\u7684\u652f\u6301\u5411\u91cf\u673a\u5bf9\u95ee\u53e5\u7684\u5206\u89e3\u7c7b\u522b\u8fdb\u884c\u8bc6\u522b! \u8fdb\u800c\u4f7f\u7528\u57fa\u4e8e\u4f9d\u5b58\u53e5\u6cd5\u5206\u6790\u7684\u65b9\u6cd5\u751f\u6210\u5206\u89e3\u7ed3\u679c% \u5b9e\u9a8c\u7ed3\u679c\u663e\u793a! & \u6211\u4eec\u6240\u6784\u5efa\u7684\u9ad8\u8d28\u91cf\u95ee\u53e5\u5206\u89e3\u8bed\u6599\u5e93\u4e2d! \u6211\u4eec\u7684\u65b9\u6cd5\u5bf9\u95ee\u53e5\u5206\u89e3\u7c7b\u522b\u8fdb\u884c\u4e86\u51c6\u786e\u7684\u8bc6\u522b! \u540c\u65f6\u4e5f\u53ef \u00d8 \u8f83\u597d\u5730\u751f\u6210 b \u5957\u578b\u95ee\u53e5\u7684\u5b50\u95ee\u53e5%", "num_citations": "1\n", "authors": ["1179"]}
{"title": "Aspect and polarity words extraction based on LSTM Network\n", "abstract": " As more and more users do shopping online, product reviews become a big resource for NLP research. Aspects are the opinion targets in the reviews, and the polarities are the attitude of users towards aspects. The paper treats the aspect and polarity words extraction as a sequence labeling task, and introduces how to use Recurrent Neural Network to solve the sequence labeling task. Also, the paper points out the shortcoming of RNN and uses LSTM instead to extract the aspects and polarities. Finally, the results of experiments show that LSTM model can significantly improve the performance in contrast to the Double Propagation algorithm, a rule-based algorithm for aspects and polarities extraction.", "num_citations": "1\n", "authors": ["1179"]}
{"title": "\u4e2d\u6587\u7bc7\u7ae0\u5173\u7cfb\u4efb\u52a1\u5206\u6790\u53ca\u8bed\u6599\u6807\u6ce8\n", "abstract": " \u7bc7\u7ae0\u5173\u7cfb( Discourse Relation)\u662f\u7bc7\u7ae0\u8bed\u4e49\u5206\u6790\u7684\u91cd\u8981\u5185\u5bb9,\u672c\u6587\u5728\u82f1\u6587\u7bc7\u7ae0\u5173\u7cfb\u7814\u7a76\u7684\u57fa\u7840\u4e0a\u5206\u6790\u4e86\u4e2d\u82f1\u6587\u95f4\u7684\u5dee\u5f02,\u603b\u7ed3\u4e86\u4e2d\u6587\u7bc7\u7ae0\u8bed\u4e49\u5206\u6790\u7684\u7279\u70b9,\u5e76\u5728\u6b64\u57fa\u7840\u4e0a\u63d0\u51fa\u9762\u5411\u4e2d\u6587\u7684\u5c42\u6b21\u5316\u7bc7\u7ae0\u5173\u7cfb\u4f53\u7cfb,\u5bf9\u5176\u5173\u7cfb\u7c7b\u578b\u8fdb\u884c\u8be6\u7ec6\u63cf\u8ff0.\u5728\u5176\u57fa\u7840\u4e0a,\u7814\u7a76\u6784\u5efa\u5305\u542b1096\u7bc7\u8bed\u6599\u7684\u4e2d\u6587\u7bc7\u7ae0\u5173\u7cfb\u8bed\u6599\u5e93,\u4e3a\u8fdb\u4e00\u6b65\u7684\u7bc7\u7ae0\u8bed\u4e49\u5206\u6790\u5de5\u4f5c\u5960\u5b9a\u57fa\u7840.", "num_citations": "1\n", "authors": ["1179"]}
{"title": "Encoding Dependency Representation with Convolutional Neural Network for Target-Polarity Word Collocation Extraction\n", "abstract": " Target-polarity word (T-P) collocation extraction is a basic sentiment analysis task, which aims to extract the targets and their modifying polarity words by analyzing the relationships between them. Recent studies rely primarily on syntactic rule matching. However, the syntactic rules are limited and hard matching is always used during the matching procedure that can result in the low recall value. To tackle this problem, we introduce a dependency representation to explore the most useful semantic features behind the syntactic rules and adopt a framework based on a convolutional neural network (CNN) to extract the T-P collocations. The experimental results on four types of product reviews show that our approach can better capture some latent semantic features that the common feature based methods cannot handle, and further significantly outperform other state-of-the-art methods.", "num_citations": "1\n", "authors": ["1179"]}
{"title": "Enhancing Neural Disfluency Detection with Hand-Crafted Features\n", "abstract": " In this paper, we apply a bidirectional Long Short-Term Memory with a Conditional Random Field to the task of disfluency detection. Long-range dependencies is one of the core problems for disfluency detection. Our model handles long-range dependencies by both using the Long Short-Term Memory and hand-crafted discrete features. Experiments show that utilizing the hand-crafted discrete features significantly improves the model\u2019s performance by achieving the state-of-the-art score of 87.1\u00a0% on the Switchboard corpus.", "num_citations": "1\n", "authors": ["1179"]}
{"title": "The validation of mrcpd cross-language expansions on imageability ratings\n", "abstract": " In this article, we present a method to validate a multi-lingual (English, Spanish, Russian, and Farsi) corpus on imageability ratings automatically expanded from MRCPD (Liu et al., 2014). We employed the corpus (Brysbaert et al., 2014) on concreteness ratings for our English MRCPD+ validation because of lacking human assessed imageability ratings and high correlation between concreteness ratings and imageability ratings (eg r=. 83). For the same reason, we built a small corpus with human imageability assessment for the other language corpus validation. The results show that the automatically expanded imageability ratings are highly correlated with human assessment in all four languages, which demonstrate our automatic expansion method is valid and robust. We believe these new resources can be of significant interest to the research community, particularly in natural language processing and computational sociolinguistics.", "num_citations": "1\n", "authors": ["1179"]}
{"title": "\u57fa\u4e8e\u6587\u91c7\u7279\u5f81\u7684\u9ad8\u8003\u4f5c\u6587\u81ea\u52a8\u8bc4\u5206\n", "abstract": " \u81ea\u52a8\u4f5c\u6587\u8bc4\u5206 (Automated Essay Scoring, AES) \u5c31\u662f\u8ba9\u8ba1\u7b97\u673a\u80fd\u591f\u5bf9\u4f5c\u6587\u8fdb\u884c\u8bc4\u4f30\u548c\u6253\u5206. \u968f\u7740\u81ea\u7136\u8bed\u8a00\u5904\u7406\u6280\u672f\u7684\u65e5\u76ca\u6210\u719f, \u9488\u5bf9\u4e2d\u6587\u4f5c\u6587\u7684\u81ea\u52a8\u8bc4\u5206\u6210\u4e3a\u53ef\u80fd. \u4f5c\u6587\u662f\u5404\u79cd\u6c49\u8bed\u8003\u8bd5\u4e2d\u5fc5\u7136\u8981\u8003\u7684\u79d1\u76ee, \u56fd\u5bb6\u7684\u4e2d\u8003, \u9ad8\u8003\u8003\u751f\u6570\u91cf\u5de8\u5927, \u800c\u4e14\u8fd1\u5e74\u6765\u4e2d\u56fd\u6c49\u8bed\u6c34\u5e73\u8003\u8bd5 (HSK) \u7684\u8003\u751f\u6570\u76ee\u4e5f\u9010\u5e74\u589e\u591a. \u81ea\u52a8\u4f5c\u6587\u8bc4\u5206\u56e0\u5176\u5177\u6709\u6548\u7387\u9ad8, \u5ba2\u89c2\u6027\u597d\u7b49\u7279\u70b9, \u56e0\u6b64\u4e2d\u6587\u4f5c\u6587\u81ea\u52a8\u8bc4\u5206\u6280\u672f\u7684\u6df1\u5165\u7814\u7a76\u5f88\u6709\u5fc5\u8981, \u672c\u6587\u5bf9\u9ad8\u8003\u4f5c\u6587\u81ea\u52a8\u8bc4\u5206\u8fdb\u884c\u4e86\u6df1\u5165\u7814\u7a76. \u672c\u6587\u5229\u7528\u4f5c\u6587\u4e2d\u7684\u6392\u6bd4\u6bd4\u55bb\u4fee\u8f9e\u4ee5\u53ca\u8bd7\u8bcd\u5f15\u7528\u6765\u8868\u5f81\u4f5c\u6587\u7684\u6587\u91c7, \u5bf9\u6392\u6bd4\u4fee\u8f9e\u8fdb\u884c\u4e86\u5206\u7c7b\u603b\u7ed3. \u63d0\u51fa\u4e86\u542f\u53d1\u5f0f\u7684\u65b9\u6cd5\u6765\u5bf9\u6392\u6bd4\u4ee5\u53ca\u6bd4\u55bb\u4fee\u8f9e\u624b\u6cd5\u8fdb\u884c\u81ea\u52a8\u8bc6\u522b. \u5229\u7528\u5b57\u5178\u6811\u7ec4\u7ec7\u53e4\u8bd7\u8bcd\u8d44\u6e90, \u5feb\u901f\u68c0\u7d22\u4f5c\u6587\u4e2d\u51fa\u73b0\u7684\u53e4\u8bd7\u8bcd. \u5c06\u6587\u91c7\u7279\u5f81\u52a0\u5165\u5230\u57fa\u51c6\u7cfb\u7edf\u4e2d, \u4f1a\u5bf9\u4f5c\u6587\u81ea\u52a8\u8bc4\u5206\u7684\u6027\u80fd\u6709\u4e0d\u9519\u7684\u63d0\u9ad8.", "num_citations": "1\n", "authors": ["1179"]}
{"title": "\u7701\u7565\u8bc6\u522b\u53ca\u6062\u590d\u8054\u5408\u6a21\u578b\u7814\u7a76\n", "abstract": " \u7701\u7565\u73b0\u8c61\u5728\u5bf9\u8bdd\u4e2d\u5341\u5206\u666e\u904d, \u5b83\u7684\u5b58\u5728\u5bfc\u81f4\u4e86\u8bed\u53e5\u6210\u5206\u7684\u7f3a\u5931. \u95ee\u7b54\u7cfb\u7edf\u5f80\u5f80\u4e0d\u80fd\u6b63\u786e\u7406\u89e3\u8fd9\u4e9b\u7f3a\u7701\u7684\u8868\u8ff0, \u8fd9\u6837\u5c31\u4f1a\u4ea7\u751f\u9519\u8bef\u7684\u95ee\u7b54\u7ed3\u679c, \u6240\u4ee5, \u7701\u7565\u6062\u590d\u5728\u95ee\u7b54\u7cfb\u7edf\u4e2d\u662f\u5341\u5206\u5fc5\u8981\u7684. \u7701\u7565\u6062\u590d\u901a\u5e38\u5206\u4e3a\u96f6\u4ee3\u8bcd\u7c7b\u522b\u6062\u590d, \u96f6\u4ee3\u8bcd\u6307\u4ee3\u6d88\u89e3 2 \u4e2a\u6b65\u9aa4, \u5df2\u6709\u5de5\u4f5c\u4e3b\u8981\u662f\u5c06\u4e8c\u8005\u987a\u5e8f\u6267\u884c, \u56e0\u6b64\u4f1a\u9020\u6210\u9519\u8bef\u7684\u7d2f\u52a0. \u4e3a\u4e86\u514b\u670d\u4e0a\u8ff0\u95ee\u9898, \u63d0\u51fa\u4e86 1 \u79cd\u96f6\u4ee3\u8bcd\u7c7b\u522b\u6062\u590d\u548c\u96f6\u4ee3\u8bcd\u6307\u4ee3\u6d88\u89e3\u8054\u5408\u6a21\u578b (joint model) \u7684\u65b9\u6cd5, \u65e8\u5728\u901a\u8fc7\u8054\u5408\u6a21\u578b\u878d\u5408\u7701\u7565\u6062\u590d\u7684 2 \u4e2a\u6b65\u9aa4, \u8fdb\u800c\u63d0\u9ad8\u6062\u590d\u6548\u679c. \u5b9e\u9a8c\u7ed3\u679c\u8868\u660e, \u76f8\u6bd4\u8f83\u5df2\u6709\u7684\u65b9\u6cd5, \u5f15\u5165\u8054\u5408\u6a21\u578b\u540e, \u7701\u7565\u6062\u590d\u7684\u6027\u80fd\u5f97\u5230\u4e86\u663e\u8457\u7684\u63d0\u5347.", "num_citations": "1\n", "authors": ["1179"]}
{"title": "Modeling Leadership Behavior of Players in Virtual Worlds\n", "abstract": " In this article, we describe our method of modeling sociolinguistic behaviors of players in massively multi-player online games. The focus of this paper is leadership, as it is manifested by the participants engaged in discussion, and the automated modeling of this complex behavior in virtual worlds. We first approach the research question of modeling from a social science perspective, and ground our models in theories from human communication literature. We then adapt a two-tiered algorithmic model that derives certain mid-level sociolinguistic behaviors--such as Task Control, Topic Control and Disagreement from discourse linguistic indicators--and combines these in a weighted model to reveal the complex role of Leadership. The algorithm is evaluated by comparing its prediction of leaders against ground truth\u2013the participants\u2019 own ratings of leadership of themselves and their conversation peers. We find the algorithm performance to be considerably better than baseline.", "num_citations": "1\n", "authors": ["1179"]}
{"title": "Aspect-Object Alignment Using Integer Linear Programming\n", "abstract": " Target extraction is an important task in opinion mining, in which a complete target consists of an aspect and its corresponding object. However, previous work always simply considers the aspect as the target and ignores an important element \u201cobject.\u201d Thus the incomplete target is of limited use for practical applications. This paper proposes a novel and important sentiment analysis task: aspect-object alignment, which aims to obtain the correct corresponding object for each aspect, to solve the \u201cobject ignoring\u201d problem. We design a two-step framework for this task. We first provide an aspect-object alignment classifier that incorporates three sets of features. However, the objects assigned to aspects in a sentence often contradict each other. To solve this problem, we impose two kinds of constraints: intra-sentence constraints and inter-sentence constraints, which are encoded as linear formulations and use\u00a0\u2026", "num_citations": "1\n", "authors": ["1179"]}
{"title": "\u57fa\u4e8e Folksonomy \u7684\u672c\u4f53\u6784\u5efa\u7efc\u8ff0\n", "abstract": " Folksonomy \u662f\u968f\u7740\u7f51\u7edc\u4fe1\u606f\u6d77\u91cf\u589e\u957f\u800c\u8fc5\u901f\u5174\u8d77\u7684\u65b0\u578b\u7f51\u7edc\u4fe1\u606f\u7ec4\u7ec7\u65b9\u5f0f, \u4e0e\u4f20\u7edf\u7684\u4fe1\u606f\u7ec4\u7ec7\u65b9\u5f0f\u672c\u4f53\u7ed3\u5408\u7684\u7814\u7a76\u548c\u5e94\u7528\u4ef7\u503c\u6b63\u5728\u9010\u6e10\u53d7\u5230\u4eba\u4eec\u7684\u91cd\u89c6. \u5728\u6982\u8ff0\u7684\u57fa\u7840\u4e0a, \u57fa\u4e8e Folksonomy \u5bf9\u672c\u4f53\u6784\u5efa\u7684\u6838\u5fc3\u95ee\u9898\u5c55\u5f00\u8bba\u8ff0, \u91cd\u70b9\u5bf9\u6bd4\u4e3b\u6d41\u6784\u5efa\u65b9\u6cd5, \u5f52\u7eb3\u8bc4\u4ef7\u65b9\u6cd5, \u5e76\u9884\u6d4b\u5e94\u7528\u548c\u7814\u7a76\u8d8b\u52bf, \u4ee5\u671f\u5bf9\u540e\u7eed\u7814\u7a76\u6709\u6240\u52a9\u76ca.", "num_citations": "1\n", "authors": ["1179"]}
{"title": "Parse-realize based paraphrasing and SMT corpus enriching\n", "abstract": " To resolve the low-coverage problem of the statistic machine translation training corpus, a dependency parsing and sentence realization based paraphrasing method is proposed. The input sentence is first parsed into a dependency tree, and then the tree is realized into multiple natural language sentences. Although the generated sentences have the same lexical words, the expressions of word orders are re-arranged. The experiments shows that the paraphrasing method can be used to enlarge the bilingual corpus for statistic machine translation and the method efficiently relieves the low-coverage problem of training corpora without any extra resources, finally the translation quality is improved.", "num_citations": "1\n", "authors": ["1179"]}
{"title": "Constructing Word Association Network by Crowdsourcing\n", "abstract": " Dictionaries are crucial to the natural language processing. It's a fundamental resource for Chinese word segmentation, POS tagging, parsing and so on. This paper presents a method to build semantic relevance dictionary with crowdsourcing, which is triggered by the word association indirectly. Compared with traditional dictionaries, the so called word association network has following advantages: 1) Low cost; 2) Internet oriented and easy to expend; 3) Word relationship is determined from the perspective of human cognition and is consistent with human intuition. In addition to describing the way of building word association network, we also analyzed the data obtained, comparing it with Hownet, TongYiCi CiLin and word ngrams from Weibo to show its characteristics.", "num_citations": "1\n", "authors": ["1179"]}
{"title": "Topical Key Concept Extraction from Folksonomy\n", "abstract": " Concept extraction is a primary subtask of ontology construction. It is difficult to extract new concepts from traditional text corpus. Moreover, building a single ontology for multiple-topic corpus may lead to misconception. To deal with these problems, this paper proposes a novel framework to extract topical key concepts from folksonomy. Folksonomy is a valuable data source due to real-time update and rich user-generated contents. We first identify topics from folksonomy using topic models. Next the tags are ranked according to their importance for a certain topic by applying topic-specific random walk methods. The top-ranking tags are extracted as topical key concepts. Especially, a novel link weight function which combines the local structure information and global semantic similarity is proposed in importance score propagation. From the perspectives of qualitative and quantitative investigation, our method is feasible and effective.", "num_citations": "1\n", "authors": ["1179"]}
{"title": "\u6570\u636e\u9a71\u52a8\u7684\u4f9d\u5b58\u53e5\u6cd5\u5206\u6790\u65b9\u6cd5\u7814\u7a76\n", "abstract": " \u4f9d\u5b58\u53e5\u6cd5\u5206\u6790\u662f\u81ea\u7136\u8bed\u8a00\u5904\u7406\u9886\u57df\u7684\u6838\u5fc3\u7814\u7a76\u8bfe\u9898.\u4f9d\u5b58\u53e5\u6cd5\u5206\u6790\u7684\u76ee\u6807\u662f\u5c06\u8f93\u5165\u7684\u81ea\u7136\u8bed\u8a00\u6587\u672c\u4ece\u5e8f\u5217\u5f62\u5f0f\u8f6c\u5316\u4e3a\u6811\u72b6\u7ed3\u6784,\u4ece\u800c\u523b\u753b\u53e5\u5b50\u5185\u90e8\u8bcd\u8bed\u4e4b\u95f4\u7684\u53e5\u6cd5\u5173\u7cfb.\u8fd1\u5e74\u6765,\u4f9d\u5b58\u53e5\u6cd5\u5206\u6790\u4f5c\u4e3a\u4e00\u4e2a\u7814\u7a76\u70ed\u70b9,\u53d6\u5f97\u4e86\u957f\u8db3\u7684\u53d1\u5c55,\u5e76\u4e14\u9010\u6e10\u5e7f\u6cdb\u5e94\u7528\u4e8e\u5176\u4ed6\u81ea\u7136\u8bed\u8a00\u5904\u7406\u4efb\u52a1\u4e2d.\u5bf9\u524d\u4eba\u63d0\u51fa\u7684\u6570\u636e\u9a71\u52a8\u7684\u4f9d\u5b58\u53e5\u6cd5\u5206\u6790\u65b9\u6cd5\u8fdb\u884c\u603b\u7ed3\u548c\u6bd4\u8f83,\u8fdb\u800c\u63d0\u51fa\u4e86\u4f9d\u5b58\u53e5\u6cd5\u5206\u6790\u672a\u6765\u7684\u6311\u6218.", "num_citations": "1\n", "authors": ["1179"]}
{"title": "\u57fa\u4e8e\u4e2d\u5fc3\u7406\u8bba\u7684\u4e2d\u6587\u5bf9\u8bdd\u7701\u7565\u6062\u590d\u7814\u7a76\n", "abstract": " \u5728\u4e2d\u6587\u5bf9\u8bdd\u4e2d, \u5927\u91cf\u5b58\u5728\u7740\u7701\u7565\u7684\u73b0\u8c61, \u4e3a\u4e86\u907f\u514d\u7531\u4e8e\u7701\u7565\u9020\u6210\u7684\u8868\u8ff0\u6a21\u7cca\u4ee5\u53ca\u6b67\u4e49\u7b49\u95ee\u9898, \u672c\u6587\u8fdb\u884c\u4e86\u76f8\u5173\u7684\u7814\u7a76, \u4ee5\u4e2d\u5fc3\u7406\u8bba\u4f5c\u4e3a\u7406\u8bba\u4f9d\u636e, \u63d0\u51fa\u4e00\u79cd\u9002\u7528\u4e8e\u4e2d\u6587\u5bf9\u8bdd\u7cfb\u7edf\u6216\u4e2d\u6587\u4ea4\u4e92\u5f0f\u95ee\u7b54\u7cfb\u7edf\u7684\u7701\u7565\u6062\u590d\u6a21\u578b, \u5e76\u4e14\u901a\u8fc7\u5b9e\u9a8c\u9a8c\u8bc1\u8be5\u6a21\u578b\u7684\u6b63\u786e\u6027\u548c\u6548\u7528\u6027. \u672c\u6587\u9009\u7528 TRECQA2004-2007 \u7684\u7ffb\u8bd1\u8bed\u6599\u4f5c\u4e3a\u5b9e\u9a8c\u6570\u636e\u96c6, \u901a\u8fc7\u7701\u7565\u5224\u5b9a, \u5f85\u6062\u590d\u8bcd\u8bc6\u522b\u4ee5\u53ca\u7701\u7565\u6062\u590d\u4e09\u4e2a\u8fc7\u7a0b\u7684\u5904\u7406, \u6700\u7ec8\u5f97\u51fa\u7684\u5b9e\u9a8c\u7ed3\u679c\u51c6\u786e\u7387\u4e3a 68.67%, \u53ec\u56de\u7387\u4e3a 75.00%, F \u503c\u4e3a 71.64%, \u76f8\u5bf9\u4e8e\u4e0d\u4f7f\u7528\u4e2d\u5fc3\u7406\u8bba\u65b9\u6cd5\u7684\u7701\u7565\u6062\u590d\u6a21\u578b, \u672c\u6587\u7684\u65b9\u6cd5\u5728\u51c6\u786e\u7387\u53ca F \u503c\u4e0a\u9762\u90fd\u6709\u8f83\u5927\u7684\u63d0\u5347.", "num_citations": "1\n", "authors": ["1179"]}
{"title": "Improve Chinese Semantic Dependency Parsing via Syntactic Dependency Parsing\n", "abstract": " We address the problem of Chinese semantic dependency parsing. Dependency parsing is traditionally oriented to syntax analysis, which we denote by syntactic dependency parsing to distinguish it from semantic dependency parsing. In this paper, firstly we compare Chinese semantic dependency parsing and syntactic dependency parsing systematically, showing that syntactic dependency parsing can potentially improve the performance of semantic dependency parsing. Thus then we suggest an approach based on quasi-synchronous grammar to incorporate the auto-parsed syntactic dependency tree into semantic dependency parsing. We conduct experiments on the Chinese semantic dependency parsing corpus of SemEval-2012. Finally we achieve 65.25% LAS on test corpus, gaining increases of 2.45% compared to the top result of 62.80% in SemEval-2012.", "num_citations": "1\n", "authors": ["1179"]}
{"title": "\u9762\u5411\u82f1\u6587\u8f85\u52a9\u5199\u4f5c\u7684\u8bcd\u8bed\u76f8\u4f3c\u5ea6\u5e94\u7528\u7814\u7a76\n", "abstract": " \u8bcd\u8bed\u76f8\u4f3c\u5ea6\u8ba1\u7b97\u662f\u81ea\u7136\u8bed\u8a00\u5904\u7406\u9886\u57df\u4e2d\u7684\u5173\u952e\u95ee\u9898\u4e4b\u4e00,\u5728\u673a\u5668\u7ffb\u8bd1,\u4fe1\u606f\u68c0\u7d22\u7b49\u65b9\u9762\u6709\u7740\u91cd\u8981\u7684\u5e94\u7528\u4ef7\u503c.\u5728\u82f1\u6587\u8f85\u52a9\u5199\u4f5c\u7cfb\u7edf\u4e2d,\u56e0\u4e3a\u7f3a\u5c11\u76f8\u5173\u63d0\u793a,\u7528\u6237\u8d77\u521d\u5f80\u5f80\u4e0d\u80fd\u660e\u786e\u81ea\u5df1\u7684\u67e5\u8be2\u9700\u6c42,\u5bfc\u81f4\u4e0d\u80fd\u5feb\u901f\u800c\u51c6\u786e\u5730\u68c0\u7d22\u5230\u9700\u8981\u7684\u4fe1\u606f,\u4ece\u800c\u5f71\u54cd\u7528\u6237\u4f7f\u7528\u6ee1\u610f\u5ea6.\u7ed3\u5408\u4e86\u8bed\u4e49\u8bcd\u5178WordNet\u548c\u5229\u7528\u4e0a\u4e0b\u6587\u4fe1\u606f\u5bf9\u8bcd\u8bed\u8bed\u4e49\u7684\u7ea6\u675f\u6027\u6765\u533a\u5206\u8bed\u5883\u53d8\u6362\u5e26\u6765\u7684\u8bcd\u8bed\u95f4\u76f8\u4f3c\u5ea6\u7684\u5dee\u5f02\u7684\u65b9\u6cd5,\u63d0\u51fa\u4e86\u4e00\u79cd\u82f1\u6587\u8f85\u52a9\u5199\u4f5c\u7cfb\u7edf\u4e2d\u7684\u76f8\u5173\u63d0\u793a\u8bcd\u7684\u751f\u6210\u65b9\u6cd5,\u8be5\u65b9\u6cd5\u751f\u6210\u4f18\u8d28\u7684\u76f8\u5173\u63d0\u793a\u8bcd,\u5e2e\u52a9\u7528\u6237\u5feb\u901f\u4e14\u51c6\u786e\u5730\u68c0\u7d22\u5230\u6240\u9700\u4fe1\u606f.", "num_citations": "1\n", "authors": ["1179"]}
{"title": "\u57fa\u4e8e\u51b3\u7b56\u6811\u7684\u4e2d\u6587\u5bf9\u8bdd\u7701\u7565\u53e5\u5224\u522b\n", "abstract": " \u7701\u7565\u53e5\u7684\u5224\u522b\u662f\u7701\u7565\u6062\u590d\u7684\u524d\u5e8f\u5de5\u4f5c, \u5728\u4e2d\u6587\u5bf9\u8bdd\u53ca\u95ee\u7b54\u7cfb\u7edf\u4e2d\u5e7f\u6cdb\u5b58\u5728\u7740\u7701\u7565\u7684\u73b0\u8c61, \u7701\u7565\u53e5\u5224\u522b\u7684\u51c6\u786e\u4e0e\u5426\u76f4\u63a5\u5173\u7cfb\u5230\u7701\u7565\u6062\u590d\u7684\u7ed3\u679c, \u56e0\u6b64\u5bf9\u7701\u7565\u53e5\u7684\u5224\u522b\u5219\u5c24\u4e3a\u91cd\u8981. \u672c\u6587\u7ed9\u51fa\u4e86\u4e00\u79cd\u91c7\u7528\u51b3\u7b56\u6811\u5206\u7c7b\u7b97\u6cd5\u8fdb\u884c\u4e2d\u6587\u5bf9\u8bdd\u4e2d\u7684\u7701\u7565\u53e5\u5224\u522b\u7684\u65b9\u6cd5, \u91c7\u7528\u624b\u5de5\u6536\u96c6\u7684\u8bbf\u8c08\u7c7b\u5bf9\u8bdd\u548c TREC2004-2007 \u7684\u90e8\u5206\u7ffb\u8bd1\u53e5\u5b50\u4e3a\u8bed\u6599, \u9009\u53d6\u4e86 6 \u4e2a\u7279\u5f81\u4f5c\u4e3a\u51b3\u7b56\u6811\u5206\u7c7b\u5668\u7684\u6761\u4ef6\u5c5e\u6027, \u4ee5\u5b8c\u5168\u5229\u7528\u89c4\u5219\u5b9e\u73b0\u7684\u7701\u7565\u53e5\u5224\u522b\u65b9\u6cd5\u4f5c\u4e3a baseline, \u672c\u6587\u7684\u65b9\u6cd5\u5f97\u5230\u4e86\u8f83\u597d\u7684\u6548\u679c. \u5b9e\u9a8c\u7ed3\u679c\u663e\u793a, \u5bf9\u7701\u7565\u53e5\u5224\u522b\u7684\u51c6\u786e\u7387\u4e3a 97.4%, F \u6307\u6570\u4e3a 84.1%.", "num_citations": "1\n", "authors": ["1179"]}
{"title": "Chinese Semantic Dependency Parsing [J]\n", "abstract": " Semantic Dependency Parsing (SDP) is a deep semantic analysis theory, integrates dependency structure and semantic information in the sentence, based on dependency grammar, which can present the implicit semantic information of a full sentence. Semantic information is extremely valuable for many applications, such as Information Retrieval, Question Answering and Machine Translation, etc. Semantic Dependency Parsing mainly faces two problems, one of which is the semantic scheme problem, and the other is algorithm for automatic semantic dependency parsing. The paper focuses on such two points as the determination of semantic system and automatic semantic dependency parsing algorithm for the systematic introduction on semantic dependency parsing.[Fund]: \u81ea\u7136\u79d1\u5b66\u57fa\u91d1 (60803093 \u548c 60975055);; \u54c8\u5c14\u6ee8\u5de5\u4e1a\u5927\u5b66\u79d1\u7814\u521b\u65b0\u57fa\u91d1\u8d44\u52a9 (HIT. NSRIF. 2009069);; \u4e2d\u592e\u9ad8\u6821\u57fa\u672c\u79d1\u7814\u4e1a\u52a1\u8d39\u4e13\u9879\u8d44\u91d1\u8d44\u52a9 (HIT. KLOF. 2010064)", "num_citations": "1\n", "authors": ["1179"]}
{"title": "\u57fa\u4e8e\u4f9d\u5b58\u53e5\u6cd5\u548c\u77ed\u8bed\u7ed3\u6784\u53e5\u6cd5\u7ed3\u5408\u7684\u91d1\u878d\u9886\u57df\u4e8b\u4ef6\u5143\u7d20\u62bd\u53d6\n", "abstract": " Eventextractonisanimportantresearcharcaininformation exbachonfeld Aimingto extractingthe event aguments ofparticulareventinfnancialfeld, thispaperpresentsthe extractionmehodofthe eventargumentskeyword basedOndependencyparsingandwehavealsoappledtheNounPhraseparsingtotherecognition ofthenounphrasewhere theeventargumentlocates. Theexperimentshowsthatthe dependencyparsingandtherulescouldeficientyextractthekey wordoftheeventagumentandtheNounPhraseparsingcouldaccurateyrecognizethewholeeventargument Keywords dependencyparsingnounphraseparsingeventextractiongeventagumentextracton", "num_citations": "1\n", "authors": ["1179"]}
{"title": "\u6c49\u8bed\u8bed\u4e49\u4f9d\u5b58\u5206\u6790\n", "abstract": " \u8bed\u4e49\u4f9d\u5b58\u5206\u6790\u5efa\u7acb\u5728\u4f9d\u5b58\u7406\u8bba\u57fa\u7840\u4e0a,\u662f\u4e00\u79cd\u6df1\u5c42\u7684\u8bed\u4e49\u5206\u6790\u7406\u8bba.\u540c\u65f6\u878d\u5408\u4e86\u53e5\u5b50\u7684\u4f9d\u5b58\u7ed3\u6784\u548c\u8bed\u4e49\u4fe1\u606f,\u66f4\u597d\u5730\u8868\u8fbe\u4e86\u53e5\u5b50\u7684\u7ed3\u6784\u4e0e\u9690\u542b\u4fe1\u606f.\u5728\u8bb8\u591a\u9ad8\u5c42\u6b21\u7684\u7814\u7a76\u548c\u5e94\u7528\u4e0a,\u8bed\u4e49\u4f9d\u5b58\u5206\u6790\u90fd\u5927\u6709\u7528\u6b66\u4e4b\u5730.\u8bed\u4e49\u4f9d\u5b58\u5206\u6790\u4e3b\u8981\u9762\u4e34\u4e24\u65b9\u9762\u7684\u96be\u9898,\u4e00\u662f\u8bed\u4e49\u4f53\u7cfb\u7684\u786e\u5b9a,\u5176\u6b21\u662f\u81ea\u52a8\u8bed\u4e49\u4f9d\u5b58\u5206\u6790\u7b97\u6cd5.\u5c06\u91cd\u70b9\u4ece\u8bed\u4e49\u4f53\u7cfb\u7684\u786e\u5b9a\u4ee5\u53ca\u81ea\u52a8\u8bed\u4e49\u4f9d\u5b58\u5206\u6790\u7b97\u6cd5\u7684\u89d2\u5ea6\u4e0a\u5bf9\u8bed\u4e49\u4f9d\u5b58\u5206\u6790\u8fdb\u884c\u7cfb\u7edf\u7684\u4ecb\u7ecd.", "num_citations": "1\n", "authors": ["1179"]}
{"title": "HIT-CIR: An unsupervised WSD system based on domain most frequent sense estimation\n", "abstract": " This paper presents an unsupervised system for all-word domain specific word sense disambiguation task. This system tags target word with the most frequent sense which is estimated using a thesaurus and the word distribution information in the domain. The thesaurus is automatically constructed from bilingual parallel corpus using paraphrase technique. The recall of this system is 43.5% on SemEval-2 task 17 English data set.", "num_citations": "1\n", "authors": ["1179"]}
{"title": "\u4e00\u79cd\u57fa\u4e8e\u5206\u7c7b\u65b9\u6cd5\u7684\u97f3\u4e50\u547d\u540d\u5b9e\u4f53\u8bc6\u522b\u6280\u672f\n", "abstract": " \u9488\u5bf9\u97f3\u4e50\u547d\u540d\u5b9e\u4f53\u7684\u7279\u70b9, \u63d0\u51fa\u4e86\u4e00\u4e2a\u57fa\u4e8e\u5206\u7c7b\u7684\u547d\u540d\u5b9e\u4f53 (NE) \u8bc6\u522b\u65b9\u6cd5. \u8bc6\u522b\u8fc7\u7a0b\u5206\u4e3a\u4e24\u4e2a\u6b65\u9aa4, \u9996\u5148\u57fa\u4e8e\u97f3\u4e50\u4e13\u4e1a\u8bcd\u5178\u548c\u7b80\u5355\u89c4\u5219\u4ece\u539f\u59cb\u6587\u672c\u4e2d\u5339\u914d\u627e\u51fa NE \u7684\u5019\u9009, \u7136\u540e\u5229\u7528\u6700\u5927\u71b5\u6a21\u578b (Maximum Entropy, ME) \u5bf9\u5019\u9009\u8fdb\u884c\u5206\u7c7b. \u5b9e\u9a8c\u8868\u660e, \u672c\u7cfb\u7edf\u97f3\u4e50\u547d\u540d\u5b9e\u4f53\u8bc6\u522b\u603b\u7684\u7cbe\u786e\u7387, \u53ec\u56de\u7387\u548c F \u503c\u5206\u522b\u8fbe\u5230\u4e86 89.89%, 81.01%, 87.93%, \u9ad8\u4e8e\u5e38\u7528\u7684\u57fa\u4e8e\u5e8f\u5217\u6807\u6ce8\u7684\u65b9\u6cd5, \u540c\u65f6\u7cfb\u7edf\u7684\u6548\u7387\u6709\u5f88\u5927\u7684\u63d0\u9ad8.", "num_citations": "1\n", "authors": ["1179"]}
{"title": "\u5229\u7528 URL \u7c7b\u522b\u6539\u8fdb\u67e5\u8be2\u4e3b\u9898\u5206\u7c7b\n", "abstract": " Web query classification is a crucial way to understand user intents. Due to the shortness and ambiguity of web queries, many works classify queries based on enriched query presentations that lead to better performance. Search results are widely used for this purpose. However, most previous methods focus on making use of texts in search results but neglect the effect of URLs. This paper presents an approach utilizing returned URLs for query classification. We make use of manually collected web directory on the web to train URL classifiers. The category distributions of URLs in search results are integrated to predict a query\u2019s category. We sampled more than 2500 queries from query log and manually labeled the category of each query. The experiments on this data shows that URL based method can achieve comparative precision as classifiers based on text-expanded queries, but improve the efficiency\u00a0\u2026", "num_citations": "1\n", "authors": ["1179"]}
{"title": "\u57fa\u4e8e\u7f51\u7edc\u6316\u6398\u7684\u4e0a\u4e0b\u6587\u76f8\u5173\u8bcd\u6c47\u7ea7\u590d\u8ff0\u7814\u7a76\n", "abstract": " \u8bcd\u6c47\u7ea7\u590d\u8ff0\u7814\u7a76\u65e8\u5728\u4e3a\u8bcd\u6c47\u83b7\u53d6\u590d\u8ff0. \u8bcd\u6c47\u7ea7\u590d\u8ff0\u662f\u4e0a\u4e0b\u6587\u76f8\u5173\u7684, \u5373\u5bf9\u540c\u4e00\u4e2a\u8bcd\u5728\u4e0d\u540c\u4e0a\u4e0b\u6587\u4e2d\u5e94\u83b7\u53d6\u4e0d\u540c\u7684\u590d\u8ff0\u8bcd. \u63d0\u51fa\u4e86\u4e00\u79cd\u83b7\u53d6\u4e0a\u4e0b\u6587\u76f8\u5173\u8bcd\u6c47\u7ea7\u590d\u8ff0\u7684\u65b9\u6cd5. \u8be5\u65b9\u6cd5\u5305\u62ec\u4e24\u90e8\u5206: \u57fa\u4e8e\u7f51\u7edc\u6316\u6398\u7684\u5019\u9009\u590d\u8ff0\u8bcd\u83b7\u53d6\u4ee5\u53ca\u57fa\u4e8e\u4e8c\u5143\u5206\u7c7b\u7684\u590d\u8ff0\u8bcd\u786e\u8ba4. \u5728\u300a \u4eba\u6c11\u65e5\u62a5\u300b \u8bed\u6599\u5e93\u4e0a\u7684\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e:(1) \u57fa\u4e8e\u7f51\u7edc\u6316\u6398\u7684\u5019\u9009\u590d\u8ff0\u8bcd\u83b7\u53d6\u65b9\u6cd5\u662f\u5207\u5b9e\u53ef\u884c\u7684, \u5e73\u5747\u4e3a\u6bcf\u4e2a\u5f85\u590d\u8ff0\u8bcd\u5728\u6bcf\u4e2a\u7ed9\u5b9a\u7684\u4e0a\u4e0b\u6587\u53e5\u5b50\u4e2d\u83b7\u53d6 2.3 \u4e2a\u6b63\u786e\u590d\u8ff0\u8bcd;(2) \u5229\u7528\u4e8c\u5143\u5206\u7c7b\u7684\u65b9\u6cd5\u8fdb\u884c\u590d\u8ff0\u786e\u8ba4\u662f\u6709\u6548\u7684, \u5176 F \u503c\u8fbe\u5230 0.6023;(3) \u5229\u7528\u8be5\u65b9\u6cd5\u62bd\u53d6\u5f97\u5230\u7684\u590d\u8ff0\u4e2d, \u6709 75.11% \u548c 98.31% \u65e0\u6cd5\u901a\u8fc7\u4e24\u79cd\u5e38\u7528\u7684\u4e0a\u4e0b\u6587\u65e0\u5173\u65b9\u6cd5, \u5373\u57fa\u4e8e\u8f9e\u5178\u548c\u57fa\u4e8e\u805a\u7c7b\u7684\u65b9\u6cd5\u6765\u83b7\u5f97. \u8fd9\u8bc1\u660e\u4e86\u6240\u63d0\u51fa\u7684\u4e0a\u4e0b\u6587\u76f8\u5173\u590d\u8ff0\u65b9\u6cd5\u53ef\u4ee5\u6709\u6548\u5730\u8865\u5145\u4f20\u7edf\u7684\u4e0a\u4e0b\u6587\u65e0\u5173\u65b9\u6cd5.", "num_citations": "1\n", "authors": ["1179"]}
{"title": "Research on Personalized Information Retrieval Based on User's New Interest Detection [J]\n", "abstract": " An important characteristic of next generation search engine is personalization. Personalized information retrieval (PIR) focuses on users. It captures users\u2019 interest in different kinds (explicit, implicit interest and interest of similar users). These information of users are integrated and used to improve the result of information retrieval system. Personalized information retrieval can grasp the users\u2019 retrieval intention and find personalized results. The authors propose the new interest detection task, which identifies the queries containing users\u2019 new retrieval interest by the change of retrieval object. Simultaneously, by using and improving the TextTiling algorithm, the retrieval system is enabled to automatically choose the appropriate dynamic threshold and detect the change of users\u2019 interest. The retrieval information and labeled answers of users are used to establish the experimental dataset. The evaluation matrix includes false alarm rate, miss alarm rate, and cost of detection. In the experiment of personalized information retrieval system, the improved TextTiling algorithm improves the new interest detection system by 16.4%. What\u2019s more, the new interest detection task improves the performance of the personalized information retrieval system is by 3.8%. The experiment shows that mining users\u2019 interest with this method can decrease the false information in users\u2019 models and improve the result of precision of users\u2019 interest detection.", "num_citations": "1\n", "authors": ["1179"]}
{"title": "Temporal Multi-Document Summarization Based on Macro-Micro Importance Discriminative Model [J]\n", "abstract": " Temporal multi-document summarization (TMDS) aims to capture the evolving information of relevant document sets across periods. Different from the traditional static multi-document summarization, it handles the dynamical collection relevant to a topic. How to resolve the key problems in the temporal context is a new challenge. This paper focuses on how to summarize the series news reports by a generic and extractive way. According to the temporal characteristics of series news reports at different levels of topical detail, a content selection method based on the macro-micro importance discriminative model is proposed. This method mines the temporal characteristics of series news reports from macro and micro views in order to provide the cue for content selection. Firstly, important time points are selected based on the macro importance discriminative model; then important sentences are selected by the micro importance discriminative model; and then these two models are integrated into a macro-micro importance discriminative model. Lastly, summary sentences are ordered chronologically. The experimental results on five groups of Chinese news corpus prove that this method is effective. It also shows that the macro and micro temporal characteristics of series news have the recursive property to some extent and macro coarse filtering helps to the content selection of TMDS.", "num_citations": "1\n", "authors": ["1179"]}
{"title": "Iterative Feedback Based Manifold-Ranking for Update Summary\n", "abstract": " The update summary as defined for the DUC2007 new task aims to capture evolving information of a single topic over time. It delivers focused information to a user who has already read a set of older documents covering the same topic. This paper presents a novel manifold-ranking frame based on iterative feedback mechanism to this summary task. The topic set is extended by using the summarization of previous timeslices and the first sentences of documents in current timeslice. Iterative feedback mechanism is applied to model the dynamically evolving characteristic and represent the relay propagation of information in temporally evolving data. Modified manifold-ranking process also can naturally make use of both the relationships among all the sentences in the documents and relationships between the topic and the sentences. The ranking score for each sentence obtained in the manifold-ranking process denotes the importance of sentence biased towards topic, and then the greedy algorithm is employed to rerank the sentences for removing the redundant information. The summary is produced by choosing the sentences with high ranking score. Experiments on dataset of DUC2007 update task demonstrate the encouraging performance of the proposed approach.", "num_citations": "1\n", "authors": ["1179"]}
{"title": "Recent advances on NLP research in Harbin Institute of Technology\n", "abstract": " In the 1960s, the researchers of Harbin Institute of Technology (HIT) attempted to do relevant research on natural language processing. With more than 40-year\u2019s effort, HIT has already established three research laboratories for Chinese information processing, i.e. the Machine Intelligence and Translation Laboratory (MI&T Lab), the Intelligent Technology and Natural Language Processing Laboratory (ITNLP) and the Information Retrieval Laboratory (IR-Lab). At present, it has a well-balanced research team of over 200 persons, and the research interests have extended to language processing, machine translation, text retrieval and other fields. Harbin Institute of Technology has accumulated a batch of key techniques and data resources, won many prizes in the technical evaluations at home and abroad. Harbin Institute of Technology has become one of the most important natural language processing\u00a0\u2026", "num_citations": "1\n", "authors": ["1179"]}
{"title": "\u57fa\u4e8e\u57fa\u97f3\u540c\u6b65\u7684\u65f6\u9891\u57df\u63d2\u503c\u7684\u6c49\u8bed\u8bed\u97f3\u5408\u6210\n", "abstract": " \u9488\u5bf9TD\u2014PSOLA\u97f5\u5f8b\u8c03\u6574\u80fd\u529b\u7684\u4e0d\u8db3,\u5c06\u57fa\u4e8e\u57fa\u97f3\u540c\u6b65\u7684\u65f6\u9891\u57df\u63d2\u503c(TFI)\u65b9\u6cd5\u5e94\u7528\u4e8e\u6c49\u8bed\u8bed\u97f3\u5408\u6210\u4e2d,\u8be5\u65b9\u6cd5\u80fd\u591f\u4fdd\u8bc1\u57fa\u9891\u8c03\u6574\u548c\u65f6\u957f\u7684\u8c03\u6574\u4e0d\u4f1a\u76f8\u4e92\u5f71\u54cd.\u4e3a\u4e86\u63d0\u9ad8\u8ba1\u7b97\u7cbe\u5ea6,\u5728\u9891\u8c31\u7684\u63d2\u503c\u8ba1\u7b97\u4e2d\u8fd8\u5f15\u5165\u4e86\u5dee\u5546\u578b\u63d2\u503c\u65b9\u6cd5.\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e,\u91c7\u7528\u5dee\u5546\u578b\u63d2\u503c\u7684TFI\u65b9\u6cd5\u80fd\u53d6\u5f97\u6bd4\u8f83\u597d\u7684\u5408\u6210\u6548\u679c.", "num_citations": "1\n", "authors": ["1179"]}
{"title": "\u57fa\u4e8e\u5c42\u6b21\u805a\u7c7b\u7684\u81ea\u9002\u5e94\u4fe1\u606f\u8fc7\u6ee4\u5b66\u4e60\u7b97\u6cd5\n", "abstract": " \u672c\u6587\u91c7\u7528\u4e00\u79cd\u57fa\u4e8e\u5c42\u6b21\u805a\u7c7b\u7684\u81ea\u9002\u5e94\u5b66\u4e60\u7b56\u7565, \u4ece\u7cfb\u7edf\u53cd\u9988\u7684\u4fe1\u606f\u6d41\u4e2d, \u52a8\u6001\u63d0\u53d6\u4e00\u7c7b\u6700\u4f18\u4fe1\u606f\u7684\u8d28\u5fc3\u66f4\u65b0\u7528\u6237\u6a21\u578b, \u6709\u6548\u5c4f\u853d\u4e86\u9608\u503c\u5931\u771f\u548c\u521d\u59cb\u4fe1\u606f\u7a00\u758f\u9020\u6210\u7684\u5927\u91cf\u53cd\u9988\u566a\u58f0, \u5e76\u4e14\u80fd\u591f\u8fd1\u4f3c\u6a21\u4eff\u4eba\u5de5\u53cd\u9988, \u5b8c\u5584\u81ea\u9002\u5e94\u5b66\u4e60\u673a\u5236\u7684\u667a\u80fd\u6027.", "num_citations": "1\n", "authors": ["1179"]}
{"title": "Mandarin speech synthesis based on pitch synchronous time-frequency interpolation [J]\n", "abstract": " The ability of wide range of prosody adjustment will be helpful to improve the naturalness and expressiveness of synthesized speech. The method of pitch synchronous time-frequency interpolation (TFI) is applied to Mandarin speech synthesis. Compared with TD-PSOLA, TFI can adjust the pitch without affecting the duration. The difference quotient interpolation is also used to improve the accuracy of the interpolation calculation, which shows satisfied quality of synthesized speech.", "num_citations": "1\n", "authors": ["1179"]}
{"title": "\u4e00\u4e2a\u666e\u901a\u8bdd\u6587\u8bed\u8f6c\u6362\u7cfb\u7edf\u4e2d\u7684\u97f5\u5f8b\u6a21\u578b\n", "abstract": " \u97f5\u5f8b\u6a21\u578b\u662f\u6587\u8bed\u8f6c\u6362\u7cfb\u7edf\u4e2d\u7684\u91cd\u8981\u7ec4\u6210\u90e8\u5206,\u5bf9\u5408\u6210\u8bed\u97f3\u7684\u81ea\u7136\u5ea6\u8d77\u7740\u81f3\u5173\u91cd\u8981\u7684\u4f5c\u7528.\u7ed3\u5408\u4eba\u5de5\u795e\u7ecf\u7f51\u7edc\u548c\u5355\u5143\u9009\u62e9\u7b97\u6cd5,\u5c06\u5b83\u4eec\u5206\u522b\u5e94\u7528\u4e8e\u97f5\u5f8b\u6a21\u578b\u4e2d\u65f6\u957f\u548c\u57fa\u9891\u66f2\u7ebf\u7684\u751f\u6210,\u5176\u4e2d\u65f6\u957f\u6a21\u578b\u91c7\u7528\u4e09\u5c42\u7684\u53cd\u5411\u4f20\u64ad\u7f51\u7edc,\u800c\u57fa\u9891\u6a21\u578b\u5219\u91c7\u7528\u4e00\u79cd\u57fa\u4e8e\u6700\u5c0f\u8ddd\u79bb\u548c\u7684\u5355\u5143\u9009\u62e9\u7b97\u6cd5.", "num_citations": "1\n", "authors": ["1179"]}
{"title": "Prosody Model for Mandarin Text-to-Speech System [J]\n", "abstract": " Prosody model is a essential part in text-to-speech system. It plays an important role in naturalness of synthesized speech. This paper integrates artificial neural networks with unit selection in prosody model, and applies them to the generation of duration and pitch. It presents a three-layer back-propagation neural network in duration model, and an algorithm based on minimizing distance summation of a whole utterance in pitch model.", "num_citations": "1\n", "authors": ["1179"]}
{"title": "\u57fa\u4e8e\u53ef\u62d3\u5b66\u7406\u8bba\u7684\u6c49\u8bed\u8bcd\u4e49\u6d88\u6b67\n", "abstract": " \u5e94\u7528\u53ef\u62d3\u5b66\u539f\u7406,\u5bf9\u6b67\u4e49\u8bcd\u8fdb\u884c\u53ef\u62d3\u5206\u89e3,\u53ef\u62d3\u7f6e\u6362\u7b49\u53ef\u62d3\u53d8\u6362,\u4e3a\u6b67\u4e49\u8bcd\u7684\u5404\u4e2a\u8bcd\u4e49\u5efa\u7acb\u76f8\u5e94\u7684\u53ef\u62d3\u96c6\u5408,\u5229\u7528\u53ef\u62d3\u96c6\u5408\u4e2d\u4e49\u539f\u8bcd\u8bed\u4ece\u5927\u89c4\u6a21\u8bed\u6599\u4e2d\u81ea\u52a8\u83b7\u53d6\u6b67\u4e49\u8bcd\u7684\u8bed\u8a00\u4fe1\u606f,\u5efa\u7acb\u65e0\u6307\u5bfc\u7684\u8bcd\u4e49\u6d88\u6b67\u6a21\u578b.\u8be5\u65b9\u6cd5\u514b\u670d\u4e86\u4ece\u65e0\u8bcd\u4e49\u6807\u6ce8\u8bed\u6599\u4e2d\u83b7\u53d6\u8bcd\u4e49\u6d88\u6b67\u77e5\u8bc6\u7684\u96be\u9898.\u5b9e\u9a8c\u8bc1\u660e,\u8be5\u65b9\u6cd5\u7528\u4e8e\u6c49\u8bed\u7684\u8bcd\u4e49\u6d88\u6b67\u5207\u5b9e\u53ef\u884c.\u5e73\u5747\u6b63\u786e\u7387\u8fbe\u523090.16%.", "num_citations": "1\n", "authors": ["1179"]}
{"title": "\u4e2d\u6587\u4e8b\u4ef6\u62bd\u53d6\u4e2d\u4e8b\u4ef6\u7c7b\u522b\u7684\u81ea\u52a8\u8bc6\u522b\n", "abstract": " \u4e8b\u4ef6\u62bd\u53d6\u662f\u76ee\u524d\u4fe1\u606f\u62bd\u53d6\u7814\u7a76\u9886\u57df\u7684\u4e00\u4e2a\u65b0\u7684\u91cd\u8981\u7684\u7814\u7a76\u8bfe\u9898. \u672c\u6587\u7ed3\u5408\u7f8e\u56fd\u56fd\u5bb6\u6807\u51c6\u6280\u672f\u7814\u7a76\u9662 (NIST) \u7ec4\u7ec7\u7684\u81ea\u52a8\u5185\u5bb9\u62bd\u53d6 (ACE, Automatic Content Extraction) \u8bc4\u6d4b\u4e2d\u7684\u4e8b\u4ef6\u62bd\u53d6\u4efb\u52a1\u7684\u8981\u6c42, \u5728 ACE2005 \u7684\u8bad\u7ec3\u6570\u636e\u4e0a\u8fdb\u884c\u4e8b\u4ef6\u62bd\u53d6\u4e2d\u4e8b\u4ef6\u7c7b\u522b\u8bc6\u522b\u7684\u5b9e\u9a8c. \u5b9e\u9a8c\u4e2d\u91c7\u7528\u300a \u540c\u4e49\u8bcd\u8bcd\u6797 (\u6269\u5c55\u7248)\u300b \u6269\u5c55\u4ece\u8bad\u7ec3\u8bed\u6599\u4e2d\u63d0\u53d6\u51fa\u7684\u89e6\u53d1\u8bcd, \u6784\u5efa\u89e6\u53d1\u8bcd\u8868, \u5e76\u7ed3\u5408\u4e24\u79cd\u673a\u5668\u5b66\u4e60\u65b9\u6cd5\u2014\u2014\u6700\u5927\u71b5 (ME, Maximum Entropy) \u548c\u652f\u6301\u5411\u91cf\u673a (SVM, Support Vector Machine), \u62bd\u53d6\u5408\u9002\u7684\u7279\u5f81, \u4f7f\u5f97\u4e8b\u4ef6\u7c7b\u522b\u8bc6\u522b\u7684 F-Score \u5206\u522b\u8fbe\u5230\u4e86 69.2% \u548c 69.9%.", "num_citations": "1\n", "authors": ["1179"]}
{"title": "The topic detection and tracking with topic sensitive language model\n", "abstract": " \uc18c\uc18d\uae30\uad00\uc5d0\uc11c \uac80\uc0c9\ub418\uc9c0 \uc54a\ub294 \uae30\uad00\uc740 \ubb34\ub8cc\uc6d0\ubb38\ub2e4\uc6b4\uc774 \ubd88\uac00\ub2a5\ud569\ub2c8\ub2e4. \uac1c\uc778\ud68c\uc6d0 \uac00\uc785\ud6c4 \uc720\ub8cc\uad6c\ub9e4\ub97c \ud558\uc2dc\uac70\ub098 \uc18c\uc18d\uae30\uad00 \ub3c4\uc11c\uad00\uc5d0 \uc774\uc6a9\ubb38\uc758\ud574 \uc8fc\uc138\uc694.", "num_citations": "1\n", "authors": ["1179"]}
{"title": "\u57fa\u4e8e\u4f9d\u5b58\u5206\u6790\u7684\u6c49\u8bed\u6587\u8bed\u8f6c\u6362\u505c\u987f\u6307\u6570\u81ea\u52a8\u6807\u6ce8\u7814\u7a76\n", "abstract": " \u4e0d\u540c\u7684\u505c\u987f\u6307\u6570\u53ef\u4ee5\u5c06\u6587\u672c\u5207\u5206\u6210\u9002\u5408\u6717\u8bfb\u4e0e\u7406\u89e3\u7684\u97f5\u5f8b\u7ec4\u5757, \u4ece\u800c\u4fdd\u8bc1\u5408\u6210\u8bed\u97f3\u80fd\u591f\u4ee5\u81ea\u7136\u7684\u8282\u594f\u8868\u73b0\u51fa\u6765. \u76ee\u524d\u7684\u505c\u987f\u6307\u6570\u6807\u6ce8\u6240\u91c7\u7528\u7684\u7279\u5f81\u7edd\u5927\u591a\u6570\u90fd\u662f\u8f83\u4e3a\u6d45\u5c42\u7684\u8bcd\u6cd5\u7279\u5f81\u5982\u8bcd\u6027, \u8bcd\u957f\u7b49. \u672c\u6587\u5229\u7528\u4f9d\u5b58\u53e5\u6cd5\u5206\u6790\u7684\u7ed3\u679c, \u62bd\u53d6\u51fa\u82e5\u5e72\u540c\u505c\u987f\u6307\u6570\u76f8\u5173\u7684\u6df1\u5c42\u53e5\u6cd5\u7279\u5f81, \u5b9e\u9a8c\u8bc1\u660e, \u5176\u4e2d\u5185\u5f27\u8de8\u5ea6\u548c\u5185\u5f27\u7c7b\u578b\u7b49\u7279\u5f81\u5bf9\u6d45\u5c42\u7279\u5f81\u8f83\u96be\u89e3\u51b3\u7684\u97f5\u5f8b\u77ed\u8bed\u5212\u5206\u95ee\u9898\u53ef\u4ee5\u8d77\u5230\u5f88\u5927\u7684\u63d0\u9ad8\u4f5c\u7528, \u4f7f\u97f5\u5f8b\u77ed\u8bed\u6807\u6ce8\u7684\u7efc\u5408 F \u503c\u63d0\u9ad8\u4e86 48%.", "num_citations": "1\n", "authors": ["1179"]}
{"title": "\u57fa\u4e8e\u5e38\u95ee\u95ee\u9898\u96c6\u7684\u5728\u7ebf\u5ba2\u670d\u5b9e\u9a8c\u7814\u7a76\n", "abstract": " \u76ee\u524d, \u4f01\u4e1a\u7684\u5ba2\u670d\u4e2d\u5fc3\u5728\u5ba2\u6237\u670d\u52a1\u548c\u4ea7\u54c1\u54a8\u8be2\u4e0a\u8d77\u7740\u91cd\u8981\u7684\u4f5c\u7528, \u4f46\u662f\u4f01\u4e1a\u9700\u8981\u627f\u62c5\u5927\u91cf\u7684\u76f8\u5e94\u5f00\u9500, \u800c\u4e14\u7535\u8bdd\u54a8\u8be2\u7684\u65b9\u5f0f\u7ed9\u7528\u6237\u5e26\u6765\u4e86\u5f88\u5927\u7684\u4e0d\u4fbf. \u9488\u5bf9\u8fd9\u4e00\u95ee\u9898, \u672c\u6587\u7814\u7a76\u4e86\u57fa\u4e8e\u5e38\u95ee\u95ee\u9898\u96c6\u7684\u95ee\u7b54\u7cfb\u7edf\u5728\u4f01\u4e1a\u5728\u7ebf\u5ba2\u670d\u4e2d\u7684\u5e94\u7528, \u6587\u4e2d\u63d0\u51fa\u4e86\u57fa\u4e8e\u5e38\u95ee\u95ee\u9898\u96c6\u7684\u5728\u7ebf\u5ba2\u670d\u7cfb\u7edf\u7684\u6846\u67b6, \u5e76\u9488\u5bf9\u7cfb\u7edf\u4e2d\u7684\u53e5\u5b50\u76f8\u4f3c\u5ea6\u8ba1\u7b97\u8fdb\u884c\u4e86\u8be6\u7ec6\u7684\u8ba8\u8bba\u548c\u5206\u6790. \u6700\u540e, \u9488\u5bf9\u91d1\u5c71\u5728\u7ebf\u5ba2\u670d\u7cfb\u7edf\u5b9e\u9645\u5e94\u7528, \u8fdb\u884c\u4e86\u8be6\u7ec6\u7684\u5b9e\u9a8c\u53ca\u5206\u6790. \u901a\u8fc7\u5b9e\u9a8c\u8868\u660e, \u57fa\u4e8e\u5e38\u95ee\u95ee\u9898\u96c6\u7684\u95ee\u7b54\u7cfb\u7edf\u5728\u4f01\u4e1a\u7684\u5728\u7ebf\u5ba2\u670d\u4e2d\u6709\u7740\u826f\u597d\u7684\u6548\u679c\u548c\u5e94\u7528\u524d\u666f.", "num_citations": "1\n", "authors": ["1179"]}
{"title": "\u4e24\u79cd\u57fa\u4e8e\u7edf\u8ba1\u7684\u6c49\u8bed\u8bcd\u4e49\u6d88\u6b67\u6a21\u578b\n", "abstract": " Abstract\u02d6 Word Sense Disambiguation (WSD) has always been a difficult and hot points in natural language processing. At present, only some ambiguous words are selected as research objects in most WSD research, which has large gap with the real application. In this paper, large scale real texts are applied in WSD based on two classical statistics model. The supervised WSD method based on Hidden Markov Model (HMM) got a lower precision, only about 85% in open test. The method based on Na\u00efve Bayes Model (NBM) is 92%, it\u2019sa higher precision. And the unsupervised WSD based on NBM got a little lower precision in comparison to the supervised, but it is worthy further researching since it has a well extension performance.", "num_citations": "1\n", "authors": ["1179"]}
{"title": "\u9690\u9a6c\u5c14\u53ef\u592b\u6a21\u578b\u548c\u8d1d\u53f6\u65af\u6a21\u578b\u8bcd\u4e49\u6d88\u6b67\u5bf9\u6bd4\u7814\u7a76\n", "abstract": " \u6709\u4ee3\u8868\u6027\u7684\u6b67\u4e49\u8bcd\u4f5c\u4e3a\u7814\u7a76\u4e0e\u6d4b\u8bd5\u7684\u5bf9\u8c61, \u4e0e\u5b9e\u9645\u5e94\u7528\u8fd8\u5b58\u5728\u4e00\u5b9a\u7684\u8ddd\u79bb, \u4f5c\u8005\u9488\u5bf9\u771f\u5b9e\u7684\u5e94\u7528\u60c5\u51b5, \u5bf9\u5927\u89c4\u6a21\u6587\u672c\u8fdb\u884c\u4e86\u8bcd\u4e49\u6d88\u6b67\u7814\u7a76. \u672c\u6587\u6bd4\u8f83\u4e86\u4e24\u4e2a\u7ecf\u5178\u7684\u7edf\u8ba1\u6a21\u578b\u89e3\u51b3\u5927\u89c4\u6a21\u7684\u8bcd\u4e49\u6d88\u6b67\u96be\u9898\u7684\u4f18\u7f3a\u70b9, \u4e00\u9636\u9690\u9a6c\u5c14\u53ef\u592b\u6a21\u578b\u8003\u5bdf\u4e86\u90bb\u63a5\u7684\u4e0a\u4e0b\u6587, \u6709\u4e9b\u65f6\u5019\u8ddd\u79bb\u6b67\u4e49\u8bcd\u8f83\u8fdc\u7684\u8bcd\u8bed\u5f80\u5f80\u5bf9\u8bcd\u4e49\u7684\u786e\u5b9a\u8d77\u7740\u81f3\u5173\u91cd\u8981\u7684\u4f5c\u7528, \u6240\u4ee5\u8fd9\u79cd\u65b9\u6cd5\u7684\u6d88\u6b67\u6b63\u786e\u7387\u6bd4\u8f83\u4f4e, \u5f00\u653e\u6d4b\u8bd5\u5728 85% \u5de6\u53f3; \u5355\u7eaf\u8d1d\u53f6\u65af\u6982\u7387\u6a21\u578b\u7684\u6d88\u6b67\u65b9\u6cd5\u5728\u62bd\u53d6\u4e0a\u4e0b\u6587\u7279\u5f81\u65f6\u52a0\u5927\u4e86\u4e0a\u4e0b\u6587\u7684\u7a97\u53e3, \u4f7f\u4e0e\u591a\u4e49\u8bcd\u6d88\u6b67\u76f8\u5173\u7684\u4fe1\u606f\u5145\u5206\u8003\u8651\u8fdb\u6765, \u8fd9\u79cd\u65b9\u6cd5\u7684\u5f00\u653e\u6d88\u6b67\u6b63\u786e\u7387\u6700\u9ad8\u53ef\u8fbe 92%, \u6d88\u6b67\u6548\u679c\u660e\u663e. \u7531\u6b64\u8bc1\u660e\u4e86\u8d1d\u53f6\u65af\u6a21\u578b\u8bcd\u4e49\u6d88\u6b67\u7684\u6709\u6548\u6027\u548c\u6bd4\u8f83\u4f18\u52bf.", "num_citations": "1\n", "authors": ["1179"]}
{"title": "\u4e2d\u6587\u8bcd\u53e5\u5feb\u901f\u67e5\u627e\u7cfb\u7edf\u7684\u7814\u7a76\u4e0e\u5b9e\u73b0\n", "abstract": " \u4ecb\u7ecd\u4e86\u4e00\u79cd\u4e2d\u6587\u8bcd\u53e5\u5feb\u901f\u627e\u7cfb\u7edf\u8be5\u7cfb\u7edf\u5c06\u4e2d\u6587\u6587\u732e\u8f6c\u6362\u4e3a\u6587\u732e\u4e2d\u6bcf\u4e2a\u6c49\u5b57\u7684\u4f4d\u7f6e\u5217\u8868,\u6839\u636e\u4f4d\u7f6e\u5217\u8868\u7cfb\u7edf\u80fd\u591f\u8fc5\u901f\u5730\u627e\u51fa\u7528\u6237\u5173\u5fc3\u7684\u67d0\u4e2a\u8bcd\u53e5\u5728\u6587\u732e\u4e2d\u7684\u6240\u6709\u51fa\u73b0\u4f4d\u7f6e,\u5e76\u5c06\u8be5\u8bcd\u53e5\u6240\u5728\u7684\u4e0a\u4e0b\u6587\u63d0\u4f9b\u7ed9\u7528\u6237.", "num_citations": "1\n", "authors": ["1179"]}
{"title": "\u4e2d\u56fd\u4fe1\u606f\u81ea\u52a8\u5316\u7684\u5148\u5bfc\n", "abstract": " \u672c\u6587\u4ecb\u7ecd\u4e86\u4e2d\u6587\u4fe1\u606f\u5904\u7406\u7684\u5404\u9879\u7814\u7a76\u5185\u5bb9\u548c\u76ee\u524d\u7684\u6280\u672f\u6c34\u5e73,\u5e76\u63a2\u8ba8\u4e86\u672a\u6765\u7684\u53d1\u5c55\u524d\u666f.", "num_citations": "1\n", "authors": ["1179"]}
{"title": "Determination of ionization constants of primaquine and study of its coordination ratio with vitamin C\n", "abstract": " Primaquine (P) has long been used as an antimalarial drug. The following formulas are derived for determination of the ionization constants of PH3+ 3 by pH-titration method: Ka1=[aH+(3-a) Cp]/[(a-2) Cp/aH-1] Ka3=[(1-a) Cp aH-Kw]/(a Cp+ Kw/aH)=(1/Ka2)[(2-a) Cp a2H-Kw aH]/(Kw/aH+ a Cp)+[(1-a) Cp aH-Kw]/(Kw/aH+ a Cp) in which Kw is the ionic product of water, a is the mole ratio of HClO4 to primaquine and Cp is the total concentration of primaquine. The ionization constants of primaquine in 50%(v/v) ethanol in water determined at 25 degrees C in the ionic strength range of 5 x 10 (-3)-5 x 10 (-2) mol/L are: Ka1=(3.84+/-2.35) x 10 (-2)(attributed to the secondary ammonium group of primaquine); Ka2=(1.50+/-1.17) x 10 (-8)(attributed to the tertiary ammonium group); Ka3=(2.07+/-0.27) x 10 (-10)(attributed to the primary ammonium group). The coordination ratio of primaquine to vitamin C in the above solvent is determined by continuous variation and mole ratio methods based on pH and conductance measurements to be 1: 1, indicating that the coordination compound formed in the solution is mainly a 1: 1 compound.", "num_citations": "1\n", "authors": ["1179"]}
{"title": "The gene effects of erucic and eicosenoic acids in Brassica napus L.\n", "abstract": " Analysis of parental, F 1, F 2, BC 1 and BC 2 populations of crosses involving 4 rape genotypes showed that inheritance of erucic acid erucic acid Subject Category: Chemicals and Chemical Groups", "num_citations": "1\n", "authors": ["1179"]}
{"title": "Isolation and identification of cytochalasin D from Engleromyces goetzii\n", "abstract": " Isolation and identification of cytochalasin D from Engleromyces goetzii FAO_logo home-icon English Espa\u00f1ol Fran\u00e7ais \u0627\u0644\u0639\u0631\u0628\u064a\u0629 \u4e2d\u6587 \u0420\u0443\u0441\u0441\u043a\u0438\u0439 home-icon Translate with Google Access the full text NOT AVAILABLE Lookup at Google Scholar google-logo Bibliographic information Language : Chinese Type : Journal Article In AGRIS since : 2013 Volume : 18 Issue : 3 Extent : 248-252. ill. All titles : \" Isolation and identification of cytochalasin D from Engleromyces goetzii \" \" Isolation and identification of cytochalasin D from [a fungus] Engleromyces goetzii \" Save as: AGRIS_AP RIS EndNote(XML) Isolation and identification of cytochalasin D from Engleromyces goetzii Loading... Paper Written Paper Isolation and identification of cytochalasin D from Engleromyces goetzii [1978] Wang, C. Wang, SL Liu, HH Wan, HI et al. Access the full text NOT AVAILABLE Lookup at Google Scholar google-logo Access the full text NOT \u2026", "num_citations": "1\n", "authors": ["1179"]}