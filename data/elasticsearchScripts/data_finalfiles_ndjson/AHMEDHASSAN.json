{"title": "Predicting faults using the complexity of code changes\n", "abstract": " Predicting the incidence of faults in code has been commonly associated with measuring complexity. In this paper, we propose complexity metrics that are based on the code change process instead of on the code. We conjecture that a complex code change process negatively affects its product, i.e., the software system. We validate our hypothesis empirically through a case study using data derived from the change history for six large open source projects. Our case study shows that our change complexity metrics are better predictors of fault potential in comparison to other well-known historical predictors of faults, i.e., prior modifications and prior faults.", "num_citations": "722\n", "authors": ["141"]}
{"title": "The road ahead for mining software repositories\n", "abstract": " Source control repositories, bug repositories, archived communications, deployment logs, and code repositories are examples of software repositories that are commonly available for most software projects. The mining software repositories (MSR) field analyzes and cross-links the rich data available in these repositories to uncover interesting and actionable information about software systems. By transforming these repositories from static record-keeping ones into active repositories, we can guide decision processes in modern software projects. For example, data in source control repositories, traditionally used to archive code, could be linked with data in bug repositories to help practitioners propagate complex changes and to warn them about risky code based on prior changes and bugs. In this paper, we present a brief history of the MSR field and discuss several recent achievements and results of using MSR\u00a0\u2026", "num_citations": "385\n", "authors": ["141"]}
{"title": "Predicting change propagation in software systems\n", "abstract": " Software systems contain entities, such as functions and variables, which are related to each other. As a software system evolves to accommodate new features and repair bugs, changes occur to these entities. Developers must ensure that related entities are updated to be consistent with these changes. This paper addresses the question: How does a change in one source code entity propagate to other entities? We propose several heuristics to predict change propagation. We present a framework to measure the performance of our proposed heuristics. We validate our results empirically using data obtained by analyzing the development history for five large open source software systems.", "num_citations": "337\n", "authors": ["141"]}
{"title": "Clustering wsdl documents to bootstrap the discovery of web services\n", "abstract": " The increasing use of the Web for everyday tasks is making Web services an essential part of the Internet customer's daily life. Users query the Internet for a required Web service and get back a set of Web services that may or may not satisfy their request. To get the most relevant Web services that fulfill the user's request, the user has to construct the request using the keywords that best describe the user's objective and match correctly with the Web Service name or location. Clustering Web services based on function similarities would greatly boost the ability of Web services search engines to retrieve the most relevant Web services. This paper proposes a novel technique to mine Web Service Description Language (WSDL) documents and cluster them into functionally similar Web service groups. The application of our approach to real Web services description files has shown good performance for clustering Web\u00a0\u2026", "num_citations": "310\n", "authors": ["141"]}
{"title": "System and method for controlling device usage\n", "abstract": " Mobile device usage may be monitored and restricted by pushing enabling/disabling events from an administrator the device. The events impose a certain set of rules that can \u201clock\u201d certain features provided by the device, according to permissions and pre-established policies, for a certain period of time. Such restricted periods may coincide with meetings or other events in which distractions should be kept to a minimum or be during regular, predetermined time periods. Preferably, the rules include conditional locks that allow a user to use a feature a reasonable number of times before the lock is activated to place the onus on the user for minimizing such distractions, while enabling the user to maintain access to such a vital communication tool. Cancel packets may also be used to not only control but to monitor the application of the rule sets and when certain conditions are breaches, which provides an employer with\u00a0\u2026", "num_citations": "306\n", "authors": ["141"]}
{"title": "System and method for controlling device usage\n", "abstract": " Mobile device usage may be monitored and restricted by pushing enabling/disabling events from an administrator the device. The events impose a certain set of rules that can \u201clock\u201d certain features provided by the device, according to permissions and pre-established policies, for a certain period of time. Such restricted periods may coincide with meetings or other events in which distractions should be kept to a minimum. Preferably, the rules include conditional locks that allow a user to use a feature a reasonable number of times before the lock is activated to require the user to minimize such distractions, while enabling the user to maintain access to such a vital communication tool. Cancel packets may also be used to not only control but to monitor the application of the rule sets and when certain conditions are breaches, which provides an employer with sufficient information to use in auditing device usage or in\u00a0\u2026", "num_citations": "262\n", "authors": ["141"]}
{"title": "The top ten list: Dynamic fault prediction\n", "abstract": " To remain competitive in the fast paced world of software development, managers must optimize the usage of their limited resources to deliver quality products on time and within budget. In this paper, we present an approach (the top ten list) which highlights to managers the ten most susceptible subsystems (directories) to have a fault. Managers can focus testing resources to the subsystems suggested by the list. The list is updated dynamically as the development of the system progresses. We present heuristics to create the top ten list and develop techniques to measure the performance of these heuristics. To validate our work, we apply our presented approach to six large open source projects (three operating systems: NetBSD, FreeBSD, OpenBSD; a window manager: KDE; an office productivity suite: KOffice; and a database management system: Postgres). Furthermore, we examine the benefits of increasing the\u00a0\u2026", "num_citations": "262\n", "authors": ["141"]}
{"title": "Surgical site infection after gastrointestinal surgery in high-income, middle-income, and low-income countries: a prospective, international, multicentre cohort study\n", "abstract": " BackgroundSurgical site infection (SSI) is one of the most common infections associated with health care, but its importance as a global health priority is not fully understood. We quantified the burden of SSI after gastrointestinal surgery in countries in all parts of the world.MethodsThis international, prospective, multicentre cohort study included consecutive patients undergoing elective or emergency gastrointestinal resection within 2-week time periods at any health-care facility in any country. Countries with participating centres were stratified into high-income, middle-income, and low-income groups according to the UN's Human Development Index (HDI). Data variables from the GlobalSurg 1 study and other studies that have been found to affect the likelihood of SSI were entered into risk adjustment models. The primary outcome measure was the 30-day SSI incidence (defined by US Centers for Disease Control\u00a0\u2026", "num_citations": "200\n", "authors": ["141"]}
{"title": "Computing device with environment aware features\n", "abstract": " An electronic device that includes a processor, an output device connected to the processor for issuing a stimulus to a user of the device, at least one input device connected to the processor and responsive to user input activity, and a device lock module associated with the processor for (i) implementing restrictions on user access to the device if user input activity falls below a threshold; and (ii) redetermining the threshold if a stimulus is issued by the output device. Also, a mobile device that includes a processor, at least a first input device connected to the processor for providing input signals thereto, an output device connected to the processor for providing output to a user of the mobile device, the processor being configured for determining location information for the mobile device based on input signals received from the first input device and adjusting an operating characteristic of the electronic device based on\u00a0\u2026", "num_citations": "193\n", "authors": ["141"]}
{"title": "Modeling dwell time to predict click-level satisfaction\n", "abstract": " Clicks on search results are the most widely used behavioral signals for predicting search satisfaction. Even though clicks are correlated with satisfaction, they can also be noisy. Previous work has shown that clicks are affected by position bias, caption bias, and other factors. A popular heuristic for reducing this noise is to only consider clicks with long dwell time, usually equaling or exceeding 30 seconds. The rationale is that the more time a searcher spends on a page, the more likely they are to be satisfied with its contents. However, having a single threshold value assumes that users need a fixed amount of time to be satisfied with any result click, irrespective of the page chosen. In reality, clicked pages can differ significantly. Pages have different topics, readability levels, content lengths, etc. All of these factors may affect the amount of time spent by the user on the page. In this paper, we study the effect of different\u00a0\u2026", "num_citations": "185\n", "authors": ["141"]}
{"title": "Security versus performance bugs: a case study on firefox\n", "abstract": " A good understanding of the impact of different types of bugs on various project aspects is essential to improve software quality research and practice. For instance, we would expect that security bugs are fixed faster than other types of bugs due to their critical nature. However, prior research has often treated all bugs as similar when studying various aspects of software quality (eg, predicting the time to fix a bug), or has focused on one particular type of bug (eg, security bugs) with little comparison to other types. In this paper, we study how different types of bugs (performance and security bugs) differ from each other and from the rest of the bugs in a software project. Through a case study on the Firefox project, we find that security bugs are fixed and triaged much faster, but are reopened and tossed more frequently. Furthermore, we also find that security bugs involve more developers and impact more files in a project\u00a0\u2026", "num_citations": "185\n", "authors": ["141"]}
{"title": "Fresh apps: an empirical study of frequently-updated mobile apps in the Google play store\n", "abstract": " Mobile app stores provide a unique platform for developers to rapidly deploy new updates of their apps. We studied the frequency of updates of 10,713 mobile apps (the top free 400 apps at the start of 2014 in each of the 30 categories in the Google Play store). We find that a small subset of these apps (98 apps representing \u02dc1 % of the studied apps) are updated at a very frequent rate \u2014 more than one update per week and 14 % of the studied apps are updated on a bi-weekly basis (or more frequently). We observed that 45 % of the frequently-updated apps do not provide the users with any information about the rationale for the new updates and updates exhibit a median growth in size of 6 %. This paper provides information regarding the update strategies employed by the top mobile apps. The results of our study show that 1) developers should not shy away from updating their apps very frequently\u00a0\u2026", "num_citations": "175\n", "authors": ["141"]}
{"title": "Architecture recovery of web applications\n", "abstract": " Web applications are the legacy software of the future. Developed under tight schedules, with high employee turn over, and in a rapidly evolving environment, these systems are often poorly structured and poorly documented. Maintaining such systems is problematic. This paper presents an approach to recover the architecture of such systems, in order to make maintenance more manageable. Our lightweight approach is flexible and retargetable to the various technologies that are used in developing web applications. The approach extracts the structure of dynamic web applications and shows the interaction between their various components such as databases, distributed objects, and web pages. The recovery process uses a set of specialized extractors to analyze the source code and binaries of web applications. The extracted data is manipulated to reduce the complexity of the architectural diagrams\u00a0\u2026", "num_citations": "174\n", "authors": ["141"]}
{"title": "Comparison of clustering algorithms in the context of software evolution\n", "abstract": " To aid software analysis and maintenance tasks, a number of software clustering algorithms have been proposed to automatically partition a software system into meaningful subsystems or clusters. However, it is unknown whether these algorithms produce similar meaningful clusterings for similar versions of a real-life software system under continual change and growth. This paper describes a comparative study of six software clustering algorithms. We applied each of the algorithms to subsequent versions from five large open source systems. We conducted comparisons based on three criteria respectively: stability (Does the clustering change only modestly as the system undergoes modest updating?), authoritative-ness (Does the clustering reasonably approximate the structure an authority provides?) and extremity of cluster distribution (Does the clustering avoid huge clusters and many very small clusters\u00a0\u2026", "num_citations": "169\n", "authors": ["141"]}
{"title": "System and method for searching a remote database\n", "abstract": " In accordance with the teachings described herein, systems and methods are provided for searching a remote database. A server may be used to communicate with a mobile device over a wireless network. The mobile device may include a local application database for storing data items for one or more software applications. The server may include a server application database for storing copies of data items that are transmitted to the mobile device. A local search module on the mobile device may be used to identify one or more data items in the local application database that match a set of search parameters. If the one or more data items cannot be identified in the local application database, then a remote search module on the server may be used to identify a copy of the one or more data items in the server application database that match the set of search parameters.", "num_citations": "163\n", "authors": ["141"]}
{"title": "What can oss mailing lists tell us? a preliminary psychometric text analysis of the apache developer mailing list\n", "abstract": " Developer mailing lists are a rich source of information about Open Source Software (OSS) development. The unstructured nature of email makes extracting information difficult. We use a psychometrically-based linguistic analysis tool, the LIWC, to examine the Apache httpd server developer mailing list. We conduct three preliminary experiments to assess the appropriateness of this tool for information extraction from mailing lists. First, using LIWC dimensions that are correlated with the big five personality traits, we assess the personality of four top developers against a baseline for the entire mailing list. The two developers that were responsible for the major Apache releases had similar personalities. Their personalities were different from the baseline and the other developers. Second, the first and last 50 emails for two top developers who have left the project are examined. The analysis shows promise in\u00a0\u2026", "num_citations": "150\n", "authors": ["141"]}
{"title": "Analyzing and automatically labelling the types of user issues that are raised in mobile app reviews\n", "abstract": " Mobile app reviews by users contain a wealth of information on the issues that users are experiencing. For example, a review might contain a feature request, a bug report, and/or a privacy complaint. Developers, users and app store owners (e.g. Apple, Blackberry, Google, Microsoft) can benefit from a better understanding of these issues \u2013 developers can better understand users\u2019 concerns, app store owners can spot anomalous apps, and users can compare similar apps to decide which ones to download or purchase. However, user reviews are not labelled, e.g. we do not know which types of issues are raised in a review. Hence, one must sift through potentially thousands of reviews with slang and abbreviations to understand the various types of issues. Moreover, the unstructured and informal nature of reviews complicates the automated labelling of such reviews. In this paper, we study the multi-labelled\u00a0\u2026", "num_citations": "134\n", "authors": ["141"]}
{"title": "A qualitative study on performance bugs\n", "abstract": " Software performance is one of the important qualities that makes software stand out in a competitive market. However, in earlier work we found that performance bugs take more time to fix, need to be fixed by more experienced developers and require changes to more code than non-performance bugs. In order to be able to improve the resolution of performance bugs, a better understanding is needed of the current practice and shortcomings of reporting, reproducing, tracking and fixing performance bugs. This paper qualitatively studies a random sample of 400 performance and non-performance bug reports of Mozilla Firefox and Google Chrome across four dimensions (Impact, Context, Fix and Fix validation). We found that developers and users face problems in reproducing performance bugs and have to spend more time discussing performance bugs than other kinds of bugs. Sometimes performance\u00a0\u2026", "num_citations": "132\n", "authors": ["141"]}
{"title": "Enhancing personalized search by mining and modeling task behavior\n", "abstract": " Personalized search systems tailor search results to the current user intent using historic search interactions. This relies on being able to find pertinent information in that user's search history, which can be challenging for unseen queries and for new search scenarios. Building richer models of users' current and historic search tasks can help improve the likelihood of finding relevant content and enhance the relevance and coverage of personalization methods. The task-based approach can be applied to the current user's search history, or as we focus on here, all users' search histories as so-called\" groupization\"(a variant of personalization whereby other users' profiles can be used to personalize the search experience). We describe a method whereby we mine historic search-engine logs to find other users performing similar tasks to the current user and leverage their on-task behavior to identify Web pages to\u00a0\u2026", "num_citations": "124\n", "authors": ["141"]}
{"title": "Acetylcholine leads to free radical production dependent on KATP channels, Gi proteins, phosphatidylinositol 3-kinase and tyrosine kinase\n", "abstract": " Objective: Acetylcholine (ACh) mimics ischemic preconditioning (PC) and therefore protects the heart against lethal ischemia. Steps common to both ischemic and drug-induced PC are opening of mitochondrial KATP channels (mito KATP) and generation of reactive oxygen species (ROS). The aim of this study was to test whether ACh-induced ROS production could be seen in a vascular smooth muscle cell line, and, if so, to investigate the underlying signaling pathway. Methods: Mitochondrial ROS generation was quantified by measuring changes in fluorescence of ROS-sensitive intracellular markers in vascular smooth muscle cells (A7r5). Results: Fluorescence, and, therefore, ROS production, was increased to 197.5\u00b18.5% of baseline after 45 min of exposure of cells to 2 mM ACh (P<0.001 vs. untreated controls). This effect was blocked by co-treatment with a muscarinic receptor antagonist (atropine\u00a0\u2026", "num_citations": "116\n", "authors": ["141"]}
{"title": "What\u2019s with the attitude? identifying sentences with attitude in online discussions\n", "abstract": " Mining sentiment from user generated content is a very important task in Natural Language Processing. An example of such content is threaded discussions which act as a very important tool for communication and collaboration in the Web. Threaded discussions include e-mails, e-mail lists, bulletin boards, newsgroups, and Internet forums. Most of the work on sentiment analysis has been centered around finding the sentiment toward products or topics. In this work, we present a method to identify the attitude of participants in an online discussion toward one another. This would enable us to build a signed network representation of participant interaction where every edge has a sign that indicates whether the interaction is positive or negative. This is different from most of the research on social networks that has focused almost exclusively on positive links. The method is experimentally tested using a manually labeled set of discussion posts. The results show that the proposed method is capable of identifying attitudinal sentences, and their signs, with high accuracy and that it outperforms several other baselines.", "num_citations": "109\n", "authors": ["141"]}
{"title": "Computing device with environment aware features\n", "abstract": " A method and mobile electronic device are provided which automatically adjust settings based on the environment of the mobile electronic device. The settings of the mobile electronic device which are adjusted may be security settings, filter settings, or status for instant messaging in dependence on the determined location of the mobile electronic device.", "num_citations": "108\n", "authors": ["141"]}
{"title": "Studying the impact of social structures on software quality\n", "abstract": " Correcting software defects accounts for a significant amount of resources such as time, money and personnel. To be able to focus testing efforts where needed the most, researchers have studied statistical models to predict in which parts of a software future defects are likely to occur. By studying the mathematical relations between predictor variables used in these models, researchers can form an increased understanding of the important connections between development activities and software quality. Predictor variables used in past top-performing models are largely based on file-oriented measures, such as source code and churn metrics. However, source code is the end product of numerous interlaced and collaborative activities carried out by developers. Traces of such activities can be found in the repositories used to manage development efforts. In this paper, we investigate statistical models, to study the\u00a0\u2026", "num_citations": "99\n", "authors": ["141"]}
{"title": "Exploring software evolution using spectrographs\n", "abstract": " Software systems become progressively more complex and difficult to maintain. To facilitate maintenance tasks, project managers and developers often turn to the evolution history of the system to recover various kinds of useful information, such as anomalous phenomena and lost design decisions. An informative visualization of the evolution history can help cope with this complexity by highlighting conspicuous evolution events using strong visual cues. We present a scalable visualization technique called evolution spectrographs (ESG). An evolution spectrograph portrays the evolution of a spectrum of components based on a particular property measurement. We describe several special-purpose spectrographs and discuss their use in understanding and supporting software evolution through the case studies of three large software systems (OpenSSH, KOffice and FreeBSD).", "num_citations": "96\n", "authors": ["141"]}
{"title": "A reference architecture for web servers\n", "abstract": " A reference software architecture for a domain defines the fundamental components of the domain and the relations between them. Research has shown the benefits of having a reference architecture for product development, software reuse and maintenance. Many mature domains, such as compilers and operating systems, have well-known reference architectures. We present a process to derive a reference architecture for a domain. We used this process to derive a reference architecture for Web servers, which is a relatively new domain. The paper presents the mapping of this reference architecture to the architectures of three open source Web servers: Apache (80KLOC), AOL-Server (164KLOC), and Jigsaw (106KLOC).", "num_citations": "91\n", "authors": ["141"]}
{"title": "Can we refactor conditional compilation into aspects?\n", "abstract": " Systems software uses conditional compilation to manage crosscutting concerns in a very fine-grained and efficient way, but at the expense of tangled and scattered conditional code. Refactoring of conditional compilation into aspects gets rid of these issues, but it is not clear yet for which patterns of conditional compilation aspects make sense and whether or not current aspect technology is able to express these patterns. To investigate these two problems, this paper presents a graphical``preprocessor blueprint''model which offers a queryable representation of the syntactical interaction of conditional compilation and the source code. A case study on the Parrot VM shows that preprocessor blueprints are able to express and query for the four commonly known patterns of conditional compilation usage, and that they allow to discover seven additional important patterns. By correlating each pattern's potential for\u00a0\u2026", "num_citations": "90\n", "authors": ["141"]}
{"title": "Delayed user notification of events in a mobile device\n", "abstract": " A sender-specified courtesy notification scheme to delay notification by a receiving device of the receipt of a data message is disclosed. A sender may specify a notification parameter defining a delay and send the parameter in association with the data message to a recipient. The recipient's receiving device evaluates the parameter and notifies in response. Local notification data defined by the recipient may also be evaluated. Received data messages subject to delayed notification may be hidden by the receiving device or quietly displayed (eg as per other received messages) until the expiry of the delay. Notification parameters and data can be formulated as one or more rules which may take into account the current location of the receiving device. A notification delay may be ignored in certain situations depending on recent use of the receiving device.", "num_citations": "89\n", "authors": ["141"]}
{"title": "Proximity-dependent events\n", "abstract": " A calendar application for use with a first portable electronic device includes time-dependent events having a start time and an end time and proximity-dependent events having a specified device ID that corresponds to a second portable electronic device. Both the time-dependent events and the proximity-dependent events are stored in the calendar application and the proximity-dependent event is convertible into a time-dependent event. A proximity reminder is generated when the second portable electronic device is in short range radio frequency communication range of the first portable electronic device.", "num_citations": "88\n", "authors": ["141"]}
{"title": "Mining software repositories to assist developers and support managers\n", "abstract": " Software repositories (such as source control repositories) contain a wealth of valuable information regarding the evolutionary history of a software project. This paper presents approaches and tools which mine and transform static record keeping software repositories to active repositories used by researchers to gain empirically based understanding of software development, and by practitioners to predict, plan and understand various aspects of their project. Our work is validated empirically using data based on over 60 years of development history for several open source projects", "num_citations": "87\n", "authors": ["141"]}
{"title": "A case study of bias in bug-fix datasets\n", "abstract": " Software quality researchers build software quality models by recovering traceability links between bug reports in issue tracking repositories and source code files. However, all too often the data stored in issue tracking repositories is not explicitly tagged or linked to source code. Researchers have to resort to heuristics to tag the data (e.g., to determine if an issue is a bug report or a work item), or to link a piece of code to a particular issue or bug. Recent studies by Bird et al. and by Antoniol et al. suggest that software models based on imperfect datasets with missing links to the code and incorrect tagging of issues, exhibit biases that compromise the validity and generality of the quality models built on top of the datasets. In this study, we verify the effects of such biases for a commercial project that enforces strict development guidelines and rules on the quality of the data in its issue tracking repository. Our results show\u00a0\u2026", "num_citations": "85\n", "authors": ["141"]}
{"title": "The chaos of software development\n", "abstract": " We present a new perspective on the problem of complexity in software, using sound mathematical concepts from information theory such as Shannon's entropy [S. Weaver, (1949)]. We study the complexity of the development process by examining the logs of the source control repository for large software projects. We hypothesize that the process of developing code is a good indicator of the current and future problems in the code and the project. A complex process will have negative affects on its outcome, such as producing a complex system or delaying releases. We validate our work by studying the evolution of six large open source projects (three operating systems, a window manager, an office productivity suite, and a database).", "num_citations": "81\n", "authors": ["141"]}
{"title": "Using decision trees to predict the certification result of a build\n", "abstract": " Large teams of practitioners (developers, testers, etc.) usually work in parallel on the same code base. A major concern when working in parallel is the introduction of integration bugs in the latest shared code. These latent bugs are likely to slow down the project unless they are discovered as soon as possible. Many companies have adopted daily or weekly processes which build the latest source code and certify it by executing simple manual smoke/sanity tests or extensive automated integration test suites. Other members of a team can then use the certified build to develop new features or to perform additional analysis, such as performance or usability testing. For large projects the certification process may take a few days. This long certification process forces team members to either use outdated or uncertified (possibly buggy) versions of the code. In this paper, we create decision trees to predict ahead of time the\u00a0\u2026", "num_citations": "79\n", "authors": ["141"]}
{"title": "Which log level should developers choose for a new logging statement?\n", "abstract": " Logging statements are used to record valuable runtime information about applications. Each logging statement is assigned a log level such that users can disable some verbose log messages while allowing the printing of other important ones. However, prior research finds that developers often have difficulties when determining the appropriate level for their logging statements. In this paper, we propose an approach to help developers determine the appropriate log level when they add a new logging statement. We analyze the development history of four open source projects (Hadoop, Directory Server, Hama, and Qpid), and leverage ordinal regression models to automatically suggest the most appropriate level for each newly-added logging statement. First, we find that our ordinal regression model can accurately suggest the levels of logging statements with an AUC (area under the curve; the higher the\u00a0\u2026", "num_citations": "65\n", "authors": ["141"]}
{"title": "Evolution spectrographs: Visualizing punctuated change in software evolution\n", "abstract": " Software evolution is commonly characterized as a slow process of incremental change. Researchers have observed that software systems also exhibit characteristics of punctuation (sudden and discontinuous change) during their evolution. We analyze punctuated evolution from the perspective of structural change. We developed a color-coded visualization technique called the Evolution Spectrograph (ESG). ESG can be applied to highlight conspicuous changes across a historical sequence of software releases. We describe evolution spectrographs and present the empirical results from our studies of three open source software systems: OpenSSH, PostgreSQL, and Linux. We show that punctuated change occurred in the evolution of these three systems, and we validate our empirical results by examining related software documents such as change logs and release notes.", "num_citations": "63\n", "authors": ["141"]}
{"title": "Using development history sticky notes to understand software architecture\n", "abstract": " Maintenance of evolving software systems has become the most frequently performed activity by software developers. A good understanding of the software system is needed to reduce the cost and length of this activity. Various approaches and tools have been proposed to assist in this process such as code browsers, slicing techniques, etc. These techniques neglect to use a central and vital piece of data available - the historical modification records stored in source control systems. These records offer a rich and detailed account of the evolution of the software system to its current state. In this paper, we present an approach which recovers valuable information from source control systems and attaches this information to the static dependency graph of a software system. We call this recovered information - source sticky notes. We show how to use these notes along with the software reflexion framework to assist in\u00a0\u2026", "num_citations": "63\n", "authors": ["141"]}
{"title": "Method and system for providing a honeypot mode for an electronic device\n", "abstract": " A method and system are described of providing an electronic device with a software environment having a honeypot mode of operation to which the device is capable of switching upon recognition of a message from an external device or of a pre-determined internal state. Switching to the honeypot mode of operation may include instituting an automatic sending of reports based on usage of the electronic device to an external device, modifying the non-user-observable behavior of certain user-invokable operations, and manipulating data stored on the electronic device.", "num_citations": "62\n", "authors": ["141"]}
{"title": "An Arabic web-based exam management system\n", "abstract": " Web-based Exam Management Systems (EMS) are an effective solution for mass education evaluation. This paper proposed web based online examination system based. This system carries out the examination and auto-grading for students exams. This system facilitates conducting exams, collection of answers, auto marking the submissions and production of reports for the test. It supports many kinds of questions. It is used via Internet and is therefore suitable for both local and remote examination. This system could help lecturers, instructors, teachers and others who are willing to create new exams or edit existing ones as well as students participating in the exams.The system is built using. various open source technologies AJAX, PHP, HTML and MYSQL database are used in this system. An auto-grading module is generalized to enable different exam and question types. The system is tested in the Mansoura university quality assurance center. The test proved the validity of using this kind of web based systems for evaluates students in the institutions with high rate of students", "num_citations": "62\n", "authors": ["141"]}
{"title": "Androgenetic alopecia, metabolic syndrome, and insulin resistance: Is there any association? A case\u2013control study\n", "abstract": " Aim:We attempted to assess the presence of MS and IR in patients with AGA. This may help to detect if AGA can be considered as a clue for underlying serious systemic diseases.Materials and Methods:One hundred male patients with stages III-VII AGA, in Hamilton-Norwood classification, and 100 normal, gender-and age-matched control subjects were included. Anthropometric measures, blood pressure, fasting glucose, fasting insulin, high-density lipoprotein cholesterol, and triglycerides were measured for the all participants. The presence of MS and IR was evaluated.Results:There were statistically significant differences regarding mean values of body weight (P< 0.001), height (P= 0.002), waist circumference (P< 0.001), body mass index (P< 0.001), systolic (P< 0.001), and diastolic blood pressure (P< 0.001), fasting glucose (P< 0.001), triglycerides (P< 0.001), high-density lipoprotein cholesterol (P< 0.01\u00a0\u2026", "num_citations": "58\n", "authors": ["141"]}
{"title": "Replaying development history to assess the effectiveness of change propagation tools\n", "abstract": " As developers modify software entities such as functions or variables to introduce new features, enhance old ones, or fix bugs, they must ensure that other entities in the software system are updated to be consistent with these new changes. Many hard to find bugs are introduced by developers who did not notice dependencies between entities, and failed to propagate changes correctly. Most modern development environments offer tools to assist developers in propagating changes. For example, dependency browsers show static code dependencies between source code entities. Other sources of information such as historical co-change or code layout information could be used by tools to support developers in propagating changes. We present the Development Replay (DR) approach which empirically assess and compares the effectiveness of several not-yet-existing change propagation tools by\u00a0\u2026", "num_citations": "58\n", "authors": ["141"]}
{"title": "Supporting software evolution using adaptive change propagation heuristics\n", "abstract": " When changing a source code entity (e.g., a function), developers must ensure that the change is propagated to related entities to avoid the introduction of bugs. Accurate change propagation is essential for the successful evolution of complex software systems. Techniques and tools are needed to support developers in propagating changes. Several heuristics have been proposed in the past for change propagation. Research shows that heuristics based on the change history of a project outperform heuristics based on the dependency graph. However, these heuristics being static are not the answer to the dynamic nature of software projects. These heuristics need to adapt to the dynamic nature of software projects and must adjust themselves for the peculiarities of each changed entity. In this paper we propose adaptive change propagation heuristics. These heuristics are metaheuristics that combine various\u00a0\u2026", "num_citations": "56\n", "authors": ["141"]}
{"title": "Automated detection of performance regressions using regression models on clustered performance counters\n", "abstract": " Performance testing is conducted before deploying system updates in order to ensure that the performance of large software systems did not degrade (ie, no performance regressions). During such testing, thousands of performance counters are collected. However, comparing thousands of performance counters across versions of a software system is very time consuming and error-prone. In an effort to automate such analysis, model-based performance regression detection approaches build a limited number (ie, one or two) of models for a limited number of target performance counters (eg, CPU or memory) and leverage the models to detect performance regressions. Such model-based approaches still have their limitations since selecting the target performance counters is often based on experience or gut feeling. In this paper, we propose an automated approach to detect performance regressions by analyzing\u00a0\u2026", "num_citations": "55\n", "authors": ["141"]}
{"title": "Studying the impact of social interactions on software quality\n", "abstract": " Correcting software defects accounts for a significant amount of resources in a software project. To make best use of testing efforts, researchers have studied statistical models to predict in which parts of a software system future defects are likely to occur. By studying the mathematical relations between predictor variables used in these models, researchers can form an increased understanding of the important connections between development activities and software quality. Predictor variables used in past top-performing models are largely based on source code-oriented metrics, such as lines of code or number of changes. However, source code is the end product of numerous interlaced and collaborative activities carried out by developers. Traces of such activities can be found in the various repositories used to manage development efforts. In this paper, we develop statistical models to study the impact of\u00a0\u2026", "num_citations": "55\n", "authors": ["141"]}
{"title": "Secure device sharing\n", "abstract": " A device and method for placing the device in a locked state having an associated set of permitted tasks so as to permit the device owner to share the device with others but maintain security over aspects of the device. A task change request is evaluated to determine whether the requested task is permitted and, if so, the requested task is allowed; if not, then an authorization process is invoked to prompt the user to input authorization data. Upon verification of the authorization data, the device may be unlocked and the requested change implemented. The permitted tasks may designate specific applications, specific operations or functions within applications or at the operating system level, one or more currently open windows, and other levels of granularity.", "num_citations": "55\n", "authors": ["141"]}
{"title": "Unsupervised information extraction approach using graph mutual reinforcement\n", "abstract": " Information Extraction (IE) is the task of extracting knowledge from unstructured text. We present a novel unsupervised approach for information extraction based on graph mutual reinforcement. The proposed approach does not require any seed patterns or examples. Instead, it depends on redundancy in large data sets and graph based mutual reinforcement to induce generalized \u201cextraction patterns\u201d. The proposed approach has been used to acquire extraction patterns for the ACE (Automatic Content Extraction) Relation Detection and Characterization (RDC) task. ACE RDC is considered a hard task in information extraction due to the absence of large amounts of training data and inconsistencies in the available data. The proposed approach achieves superior performance which could be compared to supervised techniques with reasonable training data.", "num_citations": "55\n", "authors": ["141"]}
{"title": "Automated classification of change messages in open source projects\n", "abstract": " Source control systems permit developers to attach a free form message to every committed change. The content of these change messages can support software maintenance activities. We present an automated approach to classify a change message as either a bug fix, a feature introduction, or a general maintenance change. Researchers can study the evolution of project using our classification. For example, researchers can monitor the rate of bug fixes in a project without having access to bug reporting databases like Bugzilla.", "num_citations": "54\n", "authors": ["141"]}
{"title": "Improving named entity translation by exploiting comparable and parallel corpora\n", "abstract": " Translation of named entities (NEs), such as person, organization, country, and location names is very important for several natural language processing applications. It plays a vital role in applications like cross lingual information retrieval, and machine translation. Web and news documents introduce new named entities on regular basis. Those new names cannot be captured by ordinary machine translation systems. In this paper, we introduce a framework for extracting named entity translation pairs. The framework contains methods for exploiting both comparable and parallel corpora to generate a regularly updated list of named entity translation pairs. We evaluate the quality of the extracted translation pairs by showing that it improves the performance of a named entity translation system. We report results on the ACE 2007 Entity Translation (ET) pilot evaluation development set.", "num_citations": "54\n", "authors": ["141"]}
{"title": "Multi-source cross-lingual model transfer: Learning what to share\n", "abstract": " Modern NLP applications have enjoyed a great boost utilizing neural networks models. Such deep neural models, however, are not applicable to most human languages due to the lack of annotated training data for various NLP tasks. Cross-lingual transfer learning (CLTL) is a viable method for building NLP models for a low-resource target language by leveraging labeled data from other (source) languages. In this work, we focus on the multilingual transfer setting where training data in multiple source languages is leveraged to further boost target language performance. Unlike most existing methods that rely only on language-invariant features for CLTL, our approach coherently utilizes both language-invariant and language-specific features at instance level. Our model leverages adversarial networks to learn language-invariant features, and mixture-of-experts models to dynamically exploit the similarity between the target language and each individual source language. This enables our model to learn effectively what to share between various languages in the multilingual setup. Moreover, when coupled with unsupervised multilingual embeddings, our model can operate in a zero-resource setting where neither target language training data nor cross-lingual resources are available. Our model achieves significant performance gains over prior art, as shown in an extensive set of experiments over multiple text classification and sequence tagging tasks including a large-scale industry dataset.", "num_citations": "53\n", "authors": ["141"]}
{"title": "Epilepsy: transition from pediatric to adult care. Recommendations of the Ontario epilepsy implementation task force\n", "abstract": " The transition from a pediatric to adult health care system is challenging for many youths with epilepsy and their families. Recently, the Ministry of Health and Long\u2010Term Care of the Province of Ontario, Canada, created a transition working group (TWG) to develop recommendations for the transition process for patients with epilepsy in the Province of Ontario. Herein we present an executive summary of this work. The TWG was composed of a multidisciplinary group of pediatric and adult epileptologists, psychiatrists, and family doctors from academia and from the community; neurologists from the community; nurses and social workers from pediatric and adult epilepsy programs; adolescent medicine physician specialists; a team of physicians, nurses, and social workers dedicated to patients with complex care needs; a lawyer; an occupational therapist; representatives from community epilepsy agencies; patients\u00a0\u2026", "num_citations": "53\n", "authors": ["141"]}
{"title": "Language independent text correction using finite state automata\n", "abstract": " Many natural language applications, like machine translation and information extraction, are required to operate on text with spelling errors. Those spelling mistakes have to be corrected automatically to avoid deteriorating the performance of such applications. In this work, we introduce a novel approach for automatic correction of spelling mistakes by deploying finite state automata to propose candidates corrections within a specified edit distance from the misspelled word. After choosing candidate corrections, a language model is used to assign scores the candidate corrections and choose best correction in the given context. The proposed approach is language independent and requires only a dictionary and text data for building a language model. The approach have been tested on both Arabic and English text and achieved accuracy of 89%.", "num_citations": "52\n", "authors": ["141"]}
{"title": "Optimistic transactional boosting\n", "abstract": " Herlihy and Koskinen's transactional boosting methodology addressed the challenge of converting concurrent data structures into transactional ones. We present an optimistic methodology for boosting concurrent collections. Optimistic boosting allows greater data structure-specific optimizations, easier integration with STM frameworks, and lower restrictions on the boosted operations than the original boosting methodology.", "num_citations": "51\n", "authors": ["141"]}
{"title": "Studying the Chaos of Code Development.\n", "abstract": " As large software systems evolve, controlling their complexity is a major challenge for many companies, as they strive to deliver future releases on time and within budget. Several source code based metrics have been proposed to assist in determining the complexity of code to help control development costs and outcome.In this paper we offer a novel view on the problem of complexity in software. We present a complexity metric that is based on the process followed by the developers to produce the code instead of on the code directly. We conjecture that a chaotic/complex development process negatively affect its outcome, the source code. We validate our hypothesis empirically using data derived from the development process history of six large open source projects (three operating systems: NetBSD, FreeBSD, OpenBSD; a window manager: KDE; an office productivity suite: KOffice; and a database management system: Postgres).", "num_citations": "51\n", "authors": ["141"]}
{"title": "A framework for measurement based performance modeling\n", "abstract": " Techniques for performance modeling are broadly classified into measurement, analytical and simulation based techniques. Measurement based performance modeling is commonly adopted in practice. Measurement based modeling requires the execution of a large number of performance tests to build accurate performance models. These performance tests must be repeated for every release or build of an application. This is a time consuming and error-prone manual process.", "num_citations": "50\n", "authors": ["141"]}
{"title": "On the relationship between comment update practices and software bugs\n", "abstract": " When changing source code, developers sometimes update the associated comments of the code (a consistent update), while at other times they do not (an inconsistent update). Similarly, developers sometimes only update a comment without its associated code (an inconsistent update). The relationship of such comment update practices and software bugs has never been explored empirically. While some (in)consistent updates might be harmless, software engineering folklore warns of the risks of inconsistent updates between code and comments, because these updates are likely to lead to out-of-date comments, which in turn might mislead developers and cause the introduction of bugs in the future. In this paper, we study comment update practices in three large open-source systems written in C (FreeBSD and PostgreSQL) and Java (Eclipse). We find that these practices can better explain and predict future\u00a0\u2026", "num_citations": "49\n", "authors": ["141"]}
{"title": "The small world of software reverse engineering\n", "abstract": " Research in maintenance and reengineering has flourished and evolved into a central part of software engineering research worldwide. We have a look at this research community through the publications of its members in several international conferences. We analyze our results using various graph and text mining techniques. We contrast our findings to other research communities.", "num_citations": "49\n", "authors": ["141"]}
{"title": "Is it worth responding to reviews? studying the top free apps in google play\n", "abstract": " Up to this point, researchers have not explored the value of responding to user reviews of mobile apps. An analysis of reviews and responses for 10,713 of the top apps in Google Play showed that few developers responded to reviews. However, responding can have positive effects. Users changed their ratings 38.7 percent of the time following a response, with a median rating increase of 20 percent.", "num_citations": "48\n", "authors": ["141"]}
{"title": "An industrial case study of customizing operational profiles using log compression\n", "abstract": " Large customers commonly request on-site capacity testing before upgrading to a new version of a mission critical telecom application. Customers fear that the new version cannot handle their current workload. These on-site engagements are costly and time consuming. These engagements prolong the upgrade cycle for products and reduce the revenue stream of rapidly growing companies. We present an industrial case study for a lightweight simple approach for customizing the operational profile for a particular deployment. The approach flags sequences of repeated events out of millions of events in execution logs. A performance engineer can identify noteworthy usage scenarios using these flagged sequences. The identified scenarios are used to customize the operational profile. Using a customized profile for performance testing alleviates customer\u2019s concerns about the performance of a new version of an\u00a0\u2026", "num_citations": "48\n", "authors": ["141"]}
{"title": "E/R schema for the Datrix C/C++/Java exchange format\n", "abstract": " A SEF (software exchange format), such as GXL (Holt et al., 2000), TA (Holt, 1997) or RSF (Wong, 1996), is used to exchange data between tools that analyze software. Researchers at Bell Canada have specified the Datrix SEF in TA (and soon to be, GXL) for C, C++ and Java. It is designed so that a parser for the language, C, C++ or Java, can read a source program and emit the program's abstract syntax tree (AST) in the Datrix format. This note explains how an entity/relation (E/R) schema (Chen, 1976) was extracted for Datrix, and gives this schema as an E/R diagram.", "num_citations": "46\n", "authors": ["141"]}
{"title": "A 7nm CMOS technology platform for mobile and high performance compute application\n", "abstract": " We present a fully integrated 7nm CMOS platform featuring a 3 rd  generation finFET architecture, SAQP for fin formation, and SADP for BEOL metallization. This technology reflects an improvement of 2.8X routed logic density and >40% performance over the 14nm reference technology described in [1-3]. A full range of Vts is enabled on-chip through a unique multi-workfunction process. This enables both excellent low voltage SRAM response and highly scaled memory area simultaneously. The HD 6-T bitcell size is 0.0269um 2 . This 7nm technology is fully enabled by immersion lithography and advanced optical patterning techniques (like SAQP and SADP). However, the technology platform is also designed to leverage EUV insertion for specific multi-patterned (MP) levels for cycle time benefit and manufacturing efficiency. A complete set of foundation and complex IP is available in this advanced CMOS platform\u00a0\u2026", "num_citations": "44\n", "authors": ["141"]}
{"title": "Security system based on input shortcuts for a computer device\n", "abstract": " A method of activating security functions on a computer device, for example a mobile communications device. The computer device includes a device state that may be realized by way of a first user input or a second user input. The method includes designating the first user input to realize the device state as a security rule having an associated security function, detecting realization of the device state, and activating the associated security function if the device state was realized by way of the second user input rather than the first user input. For example, the first user input may be a shortcut input, and the second user input may be a conventional or normal input.", "num_citations": "42\n", "authors": ["141"]}
{"title": "Mining software engineering data\n", "abstract": " Software engineering data (such as code bases, execution traces, historical code changes, mailing lists, and bug databases) contains a wealth of information about a project's status, progress, and evolution. Using well-established data mining techniques, practitioners and researchers have started exploring the potential of this valuable data in order to better manage their projects and to produce higher quality software systems that are delivered on time and within budget. This tutorial presents the latest research in mining software engineering data, discusses challenges associated with mining software engineering data, highlights success stories of mining software engineering data, and outlines future research directions. Attendees will acquire the knowledge and skills needed to integrate the mining of software engineering data in their own research or practice. This tutorial builds on several successful offerings at\u00a0\u2026", "num_citations": "41\n", "authors": ["141"]}
{"title": "Towards a better understanding of web applications\n", "abstract": " The paper presents a framework to recover the architecture of Web applications. Developers can visualize and navigate the recovered, architecture. Furthermore, they can analyze the architecture to gain a better understanding of their Web application. The Portable Bookshelf (PBS) environment combines much of the knowledge and techniques developed over the last decade in program understanding. It has been used to recover the design of large applications such as Linux, Apache and Mozilla. The paper describes the reuse and extension of the capabilities of PBS to support the design recovery of Web applications. We developed a set of tools capable of parsing and extracting relations between the components of Web applications. Also, we modified PBS's visualizer to handle the heterogenous nature of the Web.", "num_citations": "40\n", "authors": ["141"]}
{"title": "Effect of mechanical milling on the morphologyand structural evaluation of Al-Al2O3 nanocomposite powders\n", "abstract": " The morphological and microstructural changes during mechanical milling of Al powder mixed with 2.5, 5 and 10 wt.% Al2O3 particles were studied. The milling was performed in a planetary ball mill for various times up to 20 h. The produced composite powders were investigated using X-ray diffraction pattern (XRD) to elucidate the role of particle size, secondary phase content and milling time on grain size and lattice strain of Al matrix. The aluminum crystallite size estimated with broadening of XRD peaks by Williamson\u2013Hall formula. To investigate the morphological changes by the scanning electron microscopy (SEM) analysis. The results show that the addition of hard Al2O3 particles accelerates the milling process, leading to faster work hardening rate and fracture of the aluminum matrix. Furthermore, Al becomes smaller crystallite size during ball milling of Al powder in the presence of Al2O3 particles. The results revealed that the grain size of milled powders was about 45 nm with a noticeable presence of agglomerates. Uniform distribution of nano-sized Al2O3 particles in the Al matrix could be achieved with increasing milling time.", "num_citations": "38\n", "authors": ["141"]}
{"title": "An experience report on scaling tools for mining software repositories using mapreduce\n", "abstract": " The need for automated software engineering tools and techniques continues to grow as the size and complexity of studied systems and analysis techniques increase. Software engineering researchers often scale their analysis techniques using specialized one-off solutions, expensive infrastructures, or heuristic techniques (eg, search-based approaches). However, such efforts are not reusable and are often costly to maintain. The need for scalable analysis is very prominent in the Mining Software Repositories (MSR) field, which specializes in the automated recovery and analysis of large data stored in software repositories. In this paper, we explore the scaling of automated software engineering analysis techniques by reusing scalable analysis platforms from the web field. We use three representative case studies from the MSR field to analyze the potential of the MapReduce platform to scale MSR tools with\u00a0\u2026", "num_citations": "38\n", "authors": ["141"]}
{"title": "Design of SOA-based Grid Computing with Enterprise Service Bus.\n", "abstract": " Due to great advantages that Service-Oriented Architecture (SOA) offers to its adopters in almost all fields, many studies tried to leverage it in grid computing. These studies focused on enabling easy access and flexible management to underlying grid resources. However, none of them allowed access to grid resources through various technologies. Rather, most of them utilized SOA in terms of XML web services without considering its limitations. In this paper, we will introduce a high level architecture that goes beyond traditional efforts in leveraging SOA in grid computing. This architecture uses Enterprise Service Bus (ESB) model by leveraging Windows Communication Foundation (WCF) to offer a number of endpoints for published services. With these endpoints different requirements from both grid clients and executors could be easily and efficiently met. Proposed architecture does not tend to supersede other SOA-based grid computing frameworks and standards. Instead, it offers a new method for wrapping grid computing resources with a set of configurable WCF services that could be utilized by these frameworks.", "num_citations": "37\n", "authors": ["141"]}
{"title": "A survey of anomaly detection for connected vehicle cybersecurity and safety\n", "abstract": " Anomaly detection techniques have been applied to the challenging problem of ensuring both cybersecurity and safety of connected vehicles. We propose a taxonomy of prior research in this domain. Our proposed taxonomy has 3 overarching dimensions subsuming 9 categories and 38 subcategories. Key observations emerging from the survey are: Real-world datasets are seldom used, but instead, most results are derived from simulations; V2V/V2I communications and in vehicle communication are not considered together; proposed techniques are seldom evaluated against a baseline; safety of the vehicles does not attract as much attention as cybersecurity.", "num_citations": "35\n", "authors": ["141"]}
{"title": "Pinpointing the subsystems responsible for the performance deviations in a load test\n", "abstract": " Large scale systems (LSS) contain multiple subsystems that interact across multiple nodes in sometimes unforeseen and complicated ways. As a result, pinpointing the subsystems that are the source of performance degradation for a load test in LSS can be frustrating, and might take several hours or even days. This is due to the large volume of performance counter data collected such as CPU utilization, Disk I/O, memory consumption and network traffic, the limited operational knowledge of analysts about all subsystems of an LSS and the unavailability of up-to-date documentation in a LSS. We have developed a methodology that automatically ranks the subsystems according to the deviation of their performance in a load test. Our methodology uses performance counter data of a load test to craft performance signatures for the LSS subsystems. Pair-wise correlations among the performance signatures of\u00a0\u2026", "num_citations": "35\n", "authors": ["141"]}
{"title": "Method and apparatus for reducing power consumption in a display for an electronic device\n", "abstract": " A display module comprising a display screen; a controller, said controller having an input for receiving information, and an output coupled to said display Screen for outputting display information to said display Screen; said controller including a component for determining an area of interest on said display screen; and said controller having a component for dimming at least a portion of said display Screen outside of said area of interest.", "num_citations": "35\n", "authors": ["141"]}
{"title": "Studying the needed effort for identifying duplicate issues\n", "abstract": " Many recent software engineering papers have examined duplicate issue reports. Thus far, duplicate reports have been considered a hindrance to developers and a drain on their resources. As a result, prior research in this area focuses on proposing automated approaches to accurately identify duplicate reports. However, there exists no studies that attempt to quantify the actual effort that is spent on identifying duplicate issue reports. In this paper, we empirically examine the effort that is needed for manually identifying duplicate reports in four open source projects, i.e., Firefox, SeaMonkey, Bugzilla and Eclipse-Platform. Our results show that: (i) More than 50 % of the duplicate reports are identified within half a day. Most of the duplicate reports are identified without any discussion and with the involvement of very few people; (ii) A classification model built using a set of factors that are extracted from\u00a0\u2026", "num_citations": "34\n", "authors": ["141"]}
{"title": "Studying the evolution of software systems using evolutionary code extractors\n", "abstract": " Software systems are continuously changing and adapting to meet the needs of their users. Empirical studies are needed to better understand the evolutionary process followed by software systems. These studies need tools that can analyze and report various details about the software system's history. We propose evolutionary code extractors as a type of tool to assist in empirical source code evolution research. We present the design dimensions for such an extractor and discuss several of the challenges associated with automatically recovering the evolution of source code.", "num_citations": "34\n", "authors": ["141"]}
{"title": "An empirical study of software release notes\n", "abstract": " Release notes are an important source of information about a new software release. Such notes contain information regarding what is new, changed, and/or got fixed in a release. Despite the importance of release notes, they are rarely explored in the research literature. Little is known about the contained information, e.g., contents and structure, in release notes. To better understand the types of contained information in release notes, we manually analyzed 85 release notes across 15 different software systems. In our manual analysis, we identify six different types of information (e.g., caveats and addressed issues) that are contained in release notes. Addressed issues refer to new features, bugs, and improvements that were integrated in that particular release. We observe that most release notes list only a selected number of addressed issues (i.e., 6-26 % of all addressed issues in a release). We\u00a0\u2026", "num_citations": "33\n", "authors": ["141"]}
{"title": "Automated switching of user notification profiles in a mobile device\n", "abstract": " A mobile device such as a wireless communication device includes a component to automatically switch between profiles defining user notification options for notifying of device events such as new data or voice communications, calendar or alarm events. Switching is automated upon the happening of a switching condition defined in response to time or location information or both. For example, a user may enable a profile which disables event notification for a particular duration or while the user is at a particular location. That profile may be expired and automatically switched to another profile to re-enable notification upon the expiry of the duration or change to the location.", "num_citations": "33\n", "authors": ["141"]}
{"title": "Healthcare system of Pakistan\n", "abstract": " Paper is about healthcare delivery system, multiple challenges, weaknesses in health policies and recommendations to improve Healthcare System of Pakistan. Healthcare sector is very important for any country which directly affects the economy of country. If there would be healthy manpower there would be increase in the productivity and as a result the economy of the country will also see an increase that leads to human welfare. Pakistan inherited totally inadequate Healthcare delivery system that was a heritage of grand British period. Healthcare system in Pakistan is practically vertical and in part, horizontal. Healthcare system of Pakistan consists of private and public sector. The private sector serves nearly 70% of population and 30% by public sector (1). Pakistan is a low income country and according to Human Poverty Index (HPI), it ranks 65th among 102 developing countries (2). Only 27% of the population\u00a0\u2026", "num_citations": "31\n", "authors": ["141"]}
{"title": "An empirical study of emergency updates for top android mobile apps\n", "abstract": " The mobile app market continues to grow at a tremendous rate. The market provides a convenient and efficient distribution mechanism for updating apps. App developers continuously leverage such mechanism to update their apps at a rapid pace. The mechanism is ideal for publishing emergency updates (i.e., updates that are published soon after the previous update). In this paper, we study such emergency updates in the Google Play Store. Examining more than 44,000 updates of over 10,000 mobile apps in the Google Play Store, we identify 1,000 emergency updates. By studying the characteristics of such emergency updates, we find that the emergency updates often have a long lifetime (i.e., they are rarely followed by another emergency update). Updates preceding emergency updates often receive a higher ratio of negative reviews than the emergency updates. However, the release notes of\u00a0\u2026", "num_citations": "31\n", "authors": ["141"]}
{"title": "On the unreliability of bug severity data\n", "abstract": " Severity levels, e.g., critical and minor, of bugs are often used to prioritize development efforts. Prior research efforts have proposed approaches to automatically assign the severity label to a bug report. All prior efforts verify the accuracy of their approaches using human-assigned bug reports data that is stored in software repositories. However, all prior efforts assume that such human-assigned data is reliable. Hence a perfect automated approach should be able to assign the same severity label as in the repository \u2013 achieving a 100% accuracy. Looking at duplicate bug reports (i.e., reports referring to the same problem) from three open-source software systems (OpenOffice, Mozilla, and Eclipse), we find that around 51 % of the duplicate bug reports have inconsistent human-assigned severity labels even though they refer to the same software problem. While our results do indicate that duplicate bug reports\u00a0\u2026", "num_citations": "31\n", "authors": ["141"]}
{"title": "Health education program for mothers of children suffering from iron deficiency anemia in United Arab Emirates.\n", "abstract": " The present study was designed to assess knowledge, beliefs and practices of mothers regarding factors leading to iron deficiency anemia among children, to develop a health education (HE) program according to the needs of the target group, to determine the effect of the program in terms of changes in mothers' knowledge, practices and beliefs using Health Belief Model (HBM), and to determine the hemoglobin and hematocrite levels of the children of the target group before and after the program. The sample size was 200 anemic children aged 6-24 months and their mothers, 100 of them were randomly assigned to face to face intervention program (experimental group)(I), the other 100 were the control group (II). Only 16% of mothers of group I and 18% of mothers of group II got satisfactory level of knowledge. After the conduction of HE program, the mothers' knowledge was significantly increased among group I, while almost there was no change of the knowledge's level among group II. Only 7% of mothers of group I and 27% of those of group II had high perceived severity. Only 8% of mothers of group I and 14% of those of group II had low perceived barriers. After the program, 58% of mothers in group I got low perceived barriers. Only 28% of mothers of group I and 21% of those of group II had good dietary practice. After the program, 74% of mothers in group I showed good dietary practice. There were highly significant increases in the levels of hemoglobin and hematocrite of children of group I after the program, while the increases were not significant in group II.", "num_citations": "31\n", "authors": ["141"]}
{"title": "The impact of bug management patterns on bug fixing: A case study of eclipse projects\n", "abstract": " An efficient bug management process is critical for the success of software projects. Prior work has focused on improving this process, for example, by automating bug triaging, detecting duplicate bugs, and understanding the rationale for re-opening bugs. This paper continues this line of work by exploring the people who are involved in the bug management process. In particular we develop four patterns that distill the different relations between the people involved in the process: the reporter, triager, and fixer of a bug. Through a case study on the Eclipse Platform and JDT projects, we demonstrate that these patterns have an impact on the efficiency of the bug management process. For example, we find that using our patterns project personnel can improve their efficiency through better communication about bugs before assigning them.", "num_citations": "30\n", "authors": ["141"]}
{"title": "Empirical evidence for SOC dynamics in software evolution\n", "abstract": " We examine eleven large open source software systems and present empirical evidence for the existence of fractal structures in software evolution. In our study, fractal structures are measured as power laws throughout the lifetime of each software system. We describe two specific power law related phenomena: the probability distribution of software changes decreases as a power function of change sizes; and the time series of software change exhibits long range correlations with power law behavior. The existence of such spatial (across the system) and temporal (over the system lifetime) power laws suggests that self-organized criticality (SOC) occurs in the evolution of open source systems. As a result, SOC may be useful as a conceptual framework for understanding software evolution dynamics (the cause and mechanism of change or growth). We also discuss the implications of SOC to software practices.", "num_citations": "30\n", "authors": ["141"]}
{"title": "C-REX: an evolutionary code extractor for C\n", "abstract": " Software systems are continuously changing to adapt to customer\u2019s evolving needs. However, the source code change process is not well understood. Source control systems record changes to the source code of a software system. These recorded details could be used to gain some insight into the evolutionary process followed by the source code.In this paper, we discuss C-REX, an evolutionary code extractor, which recovers information from source control repositories to study source code evolution. We present our design choices for C-REX, explain the reasoning for these choices, and give an overview of our extraction approach. We also discuss a number of limitations to our approach and show results of using C-REX to recover the evolution of several software systems. We believe that the discussion presented here is beneficial for others interested in recovering and studying data stored in source control repositories.", "num_citations": "30\n", "authors": ["141"]}
{"title": "Using Pig as a data preparation language for large-scale mining software repositories studies: An experience report\n", "abstract": " The Mining Software Repositories (MSR) field analyzes software repository data to uncover knowledge and assist development of ever growing, complex systems. However, existing approaches and platforms for MSR analysis face many challenges when performing large-scale MSR studies. Such approaches and platforms rarely scale easily out of the box. Instead, they often require custom scaling tricks and designs that are costly to maintain and that are not reusable for other types of analysis. We believe that the web community has faced many of these software engineering scaling challenges before, as web analyses have to cope with the enormous growth of web data. In this paper, we report on our experience in using a web-scale platform (i.e., Pig) as a data preparation language to aid large-scale MSR studies. Through three case studies, we carefully validate the use of this web platform to prepare (i.e\u00a0\u2026", "num_citations": "28\n", "authors": ["141"]}
{"title": "A lightweight approach to uncover technical artifacts in unstructured data\n", "abstract": " Developer communication through email, chat, or issue report comments consists mostly of largely unstructured data, i.e., natural language text, mixed with technical artifacts such as project-specific jargon, abbreviations, source code patches, stack traces and identifiers. These technical artifacts represent a valuable source of knowledge on the technical part of the system, with a wide range of applications from establishing traceability links to creating project-specific vocabularies. However, the lack of well-defined boundaries between natural language and technical content make the automated mining of technical artifacts challenging. As a first step towards a general-purpose technique to extracting technical artifacts from unstructured data, we present a lightweight approach to untangle technical artifacts and natural language text. Our approach is based on existing spell checking tools, which are well-understood\u00a0\u2026", "num_citations": "28\n", "authors": ["141"]}
{"title": "Adaptive user interface for web applications\n", "abstract": " User interface has becoming an essential part in the design of software applications. In order to make it easy to deal with user's current task, it is required to simplify and optimize the user interface. Therefore, in this paper, a new design for adaptive user interface is presented. Furthermore, several issues of user interface design for web applications are described. In addition, the guidelines and architecture for the design of web applications as well as the nature of the web medium are discussed. The basic web application technologies are reviewed. Moreover, the languages and frameworks used in building user interface of web applications are described. The concept that the future of web2 could bridge the gab between desktop and web applications user interface is achieved. The web as a platform and building a web operating system could enhance the user interface for web applications.", "num_citations": "28\n", "authors": ["141"]}
{"title": "Designing quality e-learning environments for higher education\n", "abstract": " With the ever-increasing integration of online learning (or e-learning) into university courses, there is strong need for practical guidelines and recommendations to facilitate the development and delivery of pedagogically effective e-learning environments. An investigation by Siragusa (2005) examined factors which make for effective instructional design principles and learning strategies for higher education students studying within these learning environments. Surveys were administered to students and lecturers in Western Australian universities which revealed numerous areas of students\u2019e-learning experiences which they had perceived as being successful and those needing improvements. This paper presents a model containing 24 sets of recommendations that were developed from the study\u2019s survey findings. The 24 recommendations accommodate the varying pedagogical needs of learners as well as modes of course delivery. For each recommendation, a pedagogical dimension is presented to illustrate the pedagogical needs and instructional requirements. These 24 dimensions, which are grouped within nine main sections, highlight the decisions which need to be made during the instructional analysis, design, delivery and evaluation phases of e-learning environments in higher education in order to optimise their pedagogical quality.", "num_citations": "28\n", "authors": ["141"]}
{"title": "The impact of correlated metrics on defect models\n", "abstract": " Defect models are analytical models that are used to build empirical theories that are related to software quality. Prior studies often derive knowledge from such models using interpretation techniques, such as ANOVA Type-I. Recent work raises concerns that prior studies rarely remove correlated metrics when constructing such models. Such correlated metrics may impact the interpretation of models. Yet, the impact of correlated metrics in such models has not been investigated. In this paper, we set out to investigate the impact of correlated metrics, and the benefits and costs of removing correlated metrics on defect models. Through a case study of 15 publicly-available defect datasets, we find that (1) correlated metrics impact the ranking of the highest ranked metric for all of the 9 studied model interpretation techniques. On the other hand, removing correlated metrics (2) improves the consistency of the highest ranked metric regardless of how a model is specified for all of the studied interpretation techniques (except for ANOVA Type-I); and (3) negligibly impacts the performance and stability of defect models. Thus, researchers must (1) mitigate (e.g., remove) correlated metrics prior to constructing a defect model; and (2) avoid using ANOVA Type-I even if all correlated metrics are removed.", "num_citations": "27\n", "authors": ["141"]}
{"title": "A proposed dynamic model of Photovoltaic-DG system\n", "abstract": " Dynamic modeling is important to predict the energy production of Photovoltaic (PV) systems. It is needed to make informed technical and economical decisions. The simulation models of PV systems in literature are good enough for steady state analysis, but they are not suitable for dynamic analysis of grid operating and control conditions. This paper proposes a dynamic PV model suitable for Decentralized Generation (DG) applications. The proposed model relates the electrical output of the PV system to various input environmental parameters. The model is developed in Matlab-Simulink environment, and it is validated comparing the developed PV performance characteristic curves with those of the manufacturer's data sheet and those developed by a commercial software package for a Solarex-MSX 60W PV type.", "num_citations": "27\n", "authors": ["141"]}
{"title": "Detection of out of memory and graceful shutdown\n", "abstract": " A low memory manager configured to cause part of the memory allocated to a specialized application to be held in reserve so that it can be used to support the specialized application during an occurrence of low memory, thus providing time for data backup or remedial steps to be carried out before the affected application crashes.", "num_citations": "27\n", "authors": ["141"]}
{"title": "Effect of deterministic and probabilistic models on slope reliability index\n", "abstract": " Many deterministic and probabilistic models can be applied to reliability analysis of earth slopes. This paper investigates the effect of commonly used models by a set of comparative studies based on three prototype embankments. The deterministic models considered are the simplified Bishop method, the modified Swedish method, and Spencer's method. For Spencer's method, both circular and non-circular failure surfaces are considered. The probabilistic models considered are the mean-value first order second moment method (MFOSM), the point estimate method (PEM), and the advanced first order second moment method (AFOSM). The results indicate that the effect of these different models on the calculated slope reliability index varies with slope geometry and soil strength parameters. The effect of deterministic slope stability method is not significant; but the shape of the failure surface can significantly affect\u00a0\u2026", "num_citations": "27\n", "authors": ["141"]}
{"title": "An automated approach for recommending when to stop performance tests\n", "abstract": " Performance issues are often the cause of failures in today's large-scale software systems. These issues make performance testing essential during software maintenance. However, performance testing is faced with many challenges. One challenge is determining how long a performance test must run. Although performance tests often run for hours or days to uncover performance issues (e.g., memory leaks), much of the data that is generated during a performance test is repetitive. Performance analysts can stop their performance tests (to reduce the time to market and the costs of performance testing) if they know that continuing the test will not provide any new information about the system's performance. To assist performance analysts in deciding when to stop a performance test, we propose an automated approach that measures how much of the data that is generated during a performance test is repetitive. Our\u00a0\u2026", "num_citations": "26\n", "authors": ["141"]}
{"title": "Software development tools\n", "abstract": " This text contains the proceedings of a workshop on software develoDment tools, held at Pingree Park, Colorado in May, 1979. The workshop, for which we were co-chair men, was primarily, but not exclusively, concerned with a variety of tools supporting pre-implementation phases of software development. The workshop brought together researchers and practitioners from industrial, governmental, and academic sectors to compare and assess current work and to set some directions for future work in this emerging technical area. The fifty participants represented research and development efforts in software tools within the United States, Canada, France, Great Britain, and Japan.(A list of participants appears at the end of the text.) Sponsorship was provided by the National Aeronautics and Space Administration, the National Bureau of Standards, the National Science Foundation, and Digital Equipment Corporation. The conference consisted of seven formal sessions and numerous organized and impromptu discussions. Each session (except the last) included invited papers, prepared remarks by discussants, and an open discussion.", "num_citations": "26\n", "authors": ["141"]}
{"title": "Identifying performance deviations in thread pools\n", "abstract": " Large-scale software systems handle increasingly larger workloads by implementing highly concurrent and distributed design patterns. The thread pool pattern uses pools of pre-existing and reusable threads to limit thread lifecycle over-head (thread creation and destruction) and resource thrashing (thread proliferation). However, these advantages are weighed against performance issues caused by concurrency risks, like synchronization errors or deadlock, and thread pool-specific risks, like poorly tuned pool size or thread leakage. Detecting these performance issues during load testing requires a thorough understanding of how thread pools behave, yet most performance analysts have limited knowledge of the system and are flooded with terabytes of data from load tests. We propose a methodology to identify threads with performance deviations in thread pools. Our methodology ranks threads based on the\u00a0\u2026", "num_citations": "26\n", "authors": ["141"]}
{"title": "A lightweight approach for migrating Web frameworks\n", "abstract": " Web application development frameworks, like the Java Server Pages framework (JSP), provide web applications with essential functions such as maintaining state information across the application and access control. In the fast paced world of web applications, new frameworks are introduced and old ones are updated frequently. A framework is chosen during the initial phases of the project. Hence, changing it to match the new requirements and demands is a cumbersome task.We propose an approach (based on Water Transformations) to migrate web applications between various web development frameworks. This migration process preserves the structure of the code and the location of comments to facilitate future manual maintenance of the migrated code. Consequently, developers can move their applications to the framework that meets their current needs instead of being locked into their initial\u00a0\u2026", "num_citations": "26\n", "authors": ["141"]}
{"title": "The impact of changes mislabeled by szz on just-in-time defect prediction\n", "abstract": " Just-in-Time (JIT) defect prediction---a technique which aims to predict bugs at change level---has been paid more attention. JIT defect prediction leverages the SZZ approach to identify bug-introducing changes. Recently, researchers found that the performance of SZZ (including its variants) is impacted by many noises. SZZ may considerably mislabel changes that are used to train a JIT defect prediction model, and thus impact the prediction accuracy.", "num_citations": "25\n", "authors": ["141"]}
{"title": "A proposed web based framework e-learning and dictionary system for deaf Arab students\n", "abstract": " Abstract__ E-learning is a useful tool that has contributed in facilitating education for people around the globe. There is a need, however, for making e-learning available to deaf people. This could facilitate teaching and learning for both teachers of the deaf and deaf people. This paper presents an e-Learning System (LS) which offers Arabic Sign Language (ArSL) in correspondence to the text in the learning environment. The system is designed ably for deaf adults for the purpose of their lifelong learning. In the LS, the special needs of deaf learners are satisfied, eg bilingual information (Arabic text and Arabic sign language), high level of visualization and interactive and explorative learning. The basic objective of our e-learning system is the support of the equal rights of deaf people for their access to the education and training. Also ddictionaries between Arabic and Sign Language are important parts of learning. It is possible for Deaf to find words as a sign language. Also that paper describes a bilingual sign language dictionary that can help Arab deaf student learn sign language directly from their mother language. As the use of computers becomes more widespread, it has become more convenient to study using computer software and/or the Internet facilities. The proposed dictionary system provides deaf students with an easy means of access using their mother-sign language so they don\u2019t have to overcome the barrier of learning the target-spoken language.", "num_citations": "24\n", "authors": ["141"]}
{"title": "User reviews of top mobile apps in Apple and Google app stores\n", "abstract": " The varying review dynamics seen in different app stores can help guide future app development strategies.", "num_citations": "23\n", "authors": ["141"]}
{"title": "Apparatus and method for delivering messages over multiple mediums\n", "abstract": " A method for transmitting data to a communication device that is configured to receive data through a plurality of alternative communications mediums. The method comprises: determining a priority associated with a data message that is to be provided to the communications device; selecting a desired communications medium for providing the data message to the communications device, wherein if the priority is a first priority, the desired communications medium is selected from a first set that includes at least one of the plurality of communications mediums, and if the priority is a second priority, the desired communications medium is selected from a second set that includes at least one of the plurality of communications mediums, the first set including at least one communications medium from the plurality of communications mediums that is not included in the second set; and providing the data message to the\u00a0\u2026", "num_citations": "23\n", "authors": ["141"]}
{"title": "Migrating web frameworks using water transformations\n", "abstract": " We propose an approach (based on water transformations) to migrate Web applications between various Web development frameworks. This migration process preserves the structure of the code and the location of comments to ease future manual maintenance of the migrated code. Developers can move their applications to the framework that meets their current needs instead of being locked into their initial development framework. We give an example of using our approach to migrate a Web application written using active server pages (ASP) framework to Netscape server pages (NSP) framework.", "num_citations": "23\n", "authors": ["141"]}
{"title": "Building integrated Photovoltaic Retrofitting in office buildings\n", "abstract": " The research main goal is to optimize the utilization of innovative renewable energy solutions focusing on the use of BIPV as an alternative to reduce dependency on fossil fuels and consequently reduce buildings carbon emissions.A feasibility analysis of a building scale photovoltaic system retrofitting is conducted for an office building. A series of PV system options will be assessed in terms of the costs and projected energy production of several PV systems through renewable energy simulations modeling software, PVSOL premium. Different types of PV module and different types of mounting structure will be selected for the feasibility analysis based on an analysis of the current PV industry standards. Each system's output capacity (kW) will be calculated, annual energy output (KWh) and initial project cost for these different systems will then be modeled in PVSOL premium.", "num_citations": "22\n", "authors": ["141"]}
{"title": "A proposed reactive power controller for DG grid connected systems\n", "abstract": " Most of currently grid connected Decentralized Generation (DG) systems are power electronics interfaced, and only manage their active power production. With industrial inductive loads, the utility grid has not only to supply their reactive power needs, but also to supply extra reactive power to compensate for the expected power factor deterioration caused by DG active power injection. Among various DG options, Fuel cell technology makes a clean, highly controllable and economically viable DG option. Local reactive power compensation is a particular feature of fuel cell systems, as they will always be very close to the point of usage of electricity. With smart control algorithm of the grid coupling inverter, it is possible to enable reactive power management of the fuel cell DG system. This paper presents a smart control algorithm of the fuel cell DG grid coupling inverter, which provides active/reactive power\u00a0\u2026", "num_citations": "22\n", "authors": ["141"]}
{"title": "Detecting problems in the database access code of large scale systems: An industrial experience report\n", "abstract": " Database management systems (DBMSs) are one of the most important components in modern large-scale systems. Thus, it is important for developers to write code that can access DBMS correctly and efficiently. Since the behaviour of database access code can sometimes be a blackbox for developers, writing good test cases to capture problems in database access code can be very difficult. In addition to testing, static bug detection tools are often used to detect problems in the code. However, existing bug detection tools usually fail to detect functional and performance problems in the database access code. In this paper, we document our industrial experience over the past few years on finding bug patterns of database access code, implementing a bug detection tool, and integrating the tool into daily practice. We discuss the challenges that we encountered and the day-to-day lessons that we learned during\u00a0\u2026", "num_citations": "21\n", "authors": ["141"]}
{"title": "A case study of using geographic cues to predict query news intent\n", "abstract": " Geographic information retrieval encompasses important tasks including finding the location of a user, and locations relevant to their search queries. Web-based search engines receive queries from numerous users located in very different parts of the world. A typical way for people to find news is through a general web search engine, which makes it important for search engines to recognize queries with news intent. An important question for geographic information retrieval is how we can benefit from geographic cues to predict the intent of users. This work presents a case study of an application using geographic features to improve the quality of an important web search task, involving predicting which queries have news intent and hence are likely to receive clicks on news search results. Our case study suggests that information derived from geographic features can help the task. The information we consider\u00a0\u2026", "num_citations": "21\n", "authors": ["141"]}
{"title": "Content based recommendation and summarization in the blogosphere\n", "abstract": " This paper presents a stochastic graph based method for recommending or selecting a small subset of blogs that best represents a much larger set. within a certain topic. Each blog is assigned a score that reflects how representative it is. Blog scores are calculated recursively in terms of the scores of their neighbors in a lexical similarity graph. A random walk is performed on a graph where nodes represent blogs and edges link lexically similar blogs. Lexical similarity is measured using either the cosine similarity measure, or the Kullback-Leibler (KL) divergence. In addition, the presented method combines lexical centrality with information novelty to reduce redundancy in ranked blogs. Blogs similar to highly ranked blogs are discounted to make sure that diversity is maintained in the final rank. The presented method also allows us to include additional initial quality priors to assess the quality of the blogs, such as frequency of new posts per day and the text fluency measured by n-gram model probabilities, etc. We evaluate our approach using data from two large blog datasets. We measure the selection quality by the number of blogs covered in the network as calculated by an information diffusion model. We compare our method to other heuristic and greedy selection methods and show that it significantly outperforms them.", "num_citations": "21\n", "authors": ["141"]}
{"title": "Geographic features in web search retrieval\n", "abstract": " We conduct large-scale search engine relevance experiments, using the 12% of queries that contain placenames, matching the placenames to places in the documents, and examining the impact of geographic features on web retrieval relevance. Specifically we examine distance between query and document place-names mentioned, noting that when a document has multiple places (which we observe in 82% of documents) we must choose a function over those multiple places. We find that the minimum distance between the document locations and query location is the strongest geographical predictor of document relevance, and that combining geographic features with text features gives us a 5% improvement in relevance over using text features alone.", "num_citations": "21\n", "authors": ["141"]}
{"title": "Geotechnical reliability of dam and levee embankments\n", "abstract": " For the past several years, the US Army Corps of Engineers has been applying reliability analysis to the evaluation of existing water-resource structures and using the results as a basis for investment decision-making for rehabilitation projects. Although the current guidance is specifically directed toward navigation structures, and particularly their structural aspects, the Corps has begun applying reliability analysis to other problems, including geotechnical problems. Reliability analysis is a potentially complex technique; however, reasonable characterizations of reliability can be made using several approximate methods, such as the Taylor\u2019s Series Finite Difference (TSFD) method, the point estimate (PE) method, and Monte Carlo simulation. The TSFD and PE methods, in the form presently used by the Corps, produce reasonable and consistent results for linear functions and random variables with small coefficients\u00a0\u2026", "num_citations": "21\n", "authors": ["141"]}
{"title": "Using load tests to automatically compare the subsystems of a large enterprise system\n", "abstract": " Enterprise systems are load tested for every added feature, software updates and periodic maintenance to ensure that the performance demands on system quality, availability and responsiveness are met. In current practice, performance analysts manually analyze load test data to identify the components that are responsible for performance deviations. This process is time consuming and error prone due to the large volume of performance counter data collected during monitoring, the limited operational knowledge of analyst about all the subsystem involved and their complex interactions and the unavailability of up-to-date documentation in the rapidly evolving enterprise. In this paper, we present an automated approach based on a robust statistical technique, Principal Component Analysis (PCA) to identify subsystems that show performance deviations in load tests. A case study on load test data of a large\u00a0\u2026", "num_citations": "20\n", "authors": ["141"]}
{"title": "A visual architectural approach to maintaining web applications\n", "abstract": " Consider a fictitious startup company, WebFlight, which has developed a complex and dynamic software system whose functionality is delivered through the web. Users can surf to WebFlight\u2019s web application where they can browse, buy, and hold airline tickets. All these activities are done using a web browser to follow links and complete order forms. Whenever the user clicks a link on a WebFlight web page, a request is generated and sent to WebFlight\u2019s web server through the HTTP protocol. The web server receives the request and in turn invokes the appropriate actions to generate a response. For example, a new order object may be created to track the user\u2019s request. A database may be queried to retrieve relevant information to fulfill the request. The results are then transcribed to HTML and sent back to the browser, which displays them to the user. To meet a tight development schedule, the\u00a0\u2026", "num_citations": "20\n", "authors": ["141"]}
{"title": "Activity modeling in email\n", "abstract": " We introduce a latent activity model for workplace emails, positing that communication at work is purposeful and organized by activities. We pose the problem as probabilistic inference in graphical models that jointly capture the interplay between latent activities and the email contexts they govern, such as the recipients, subject and body. The model parameters are learned using maximum likelihood estimation with an expectation maximization algorithm. We present three variants of the model that incorporate the recipients, co-occurrence of the recipients, and email body and subject. We demonstrate the model\u2019s effectiveness in an email recipient recommendation task and show that it outperforms a state-of-the-art generative model. Additionally, we show that the activity model can be used to identify email senders who engage in similar activities, resulting in further improvements in recipient recommendation.", "num_citations": "18\n", "authors": ["141"]}
{"title": "User Defined Location Based Zones\n", "abstract": " A method is provided for creating a custom zone in order to an improve the graphical user interface for a user of a mapping application on a mobile device. The method comprising the steps of: requesting creation of the custom zone; establishing a location of the custom zone; defining a boundary for the custom zone; and associating multimedia data with the custom zone for subsequent display to the user. A further method is described for displaying the custom zone to the user. A system and computer readable medium configured to implement the method are also described.", "num_citations": "17\n", "authors": ["141"]}
{"title": "Search algorithm for minimum reliability index of earth slopes\n", "abstract": " In this paper, the authors presented the analysis and design approach for the analysis and design of the slurry walls at the Wilbur D. Mills Dam. The paper presented the analytical as well as actual wall behavior. The discussers were involved in the analysis and design of the Central Artery Tunnel in Boston, and therefore were interested in the work published by the authors. In their comparison between the SOILSTRUCT and the RIDO analyses, the authors state that the RIDO analysis \u2018\u2018provided a realistic model of how the structural slurry wall would behave.\u2019\u2019However, the comparison presented in Fig. 10 indicates that the actual behavior of the wall is quite different from the RIDO analysis (assuming that both curves in Fig. 10 correspond to the same panel). Of particular interest is the deflection at top and bottom of the wall. The RIDO analysis showed almost no deflection at El. 40; however, about 0.25 displacement\u00a0\u2026", "num_citations": "17\n", "authors": ["141"]}
{"title": "A qualitative study of the benefits and costs of logging from developers' perspectives\n", "abstract": " Software developers insert logging statements in their source code to collect important runtime information of software systems. In practice, logging appropriately is a challenge for developers. Prior studies aimed to improve logging by proactively inserting logging statements in certain code snippets or by learning where to log from existing logging code. However, there exists no work that systematically studies developers' logging considerations, i.e., the benefits and costs of logging from developers' perspectives. Without understanding developers' logging considerations, automated approaches for logging decisions are based primarily on researchers' intuition which may not be convincing to developers. In order to fill the gap between developers' logging considerations and researchers' intuition, we performed a qualitative study that combines a survey of 66 developers and a case study of 223 logging-related issue\u00a0\u2026", "num_citations": "16\n", "authors": ["141"]}
{"title": "Using fuzzy code search to link code fragments in discussions to source code\n", "abstract": " When discussing software, practitioners often reference parts of the project's source code. Such references have different motivations, such as mentoring and guiding less experienced developers, pointing out code that needs changes, or proposing possible strategies for the implementation of future changes. The fact that particular parts of a source code are being discussed makes these parts of the software special. Knowing which code is being talked about the most can not only help practitioners to guide important software engineering and maintenance activities, but also act as a high-level documentation of development activities for managers. In this paper, we use clone- detection as specific instance of a code search based approach for establishing links between code fragments that are discussed by developers and the actual source code of a project. Through a case study on the Eclipse project we explore\u00a0\u2026", "num_citations": "16\n", "authors": ["141"]}
{"title": "Computing device with environment aware features\n", "abstract": " A method and mobile electronic device are provided which automatically adjust settings based on the environment of the mobile electronic device. The settings of the mobile electronic device which are adjusted may be security settings, filter settings, or status for instant messaging in dependence on the determined location of the mobile electronic device.", "num_citations": "16\n", "authors": ["141"]}
{"title": "Method and apparatus for preventing action responsive to accidental keystroke\n", "abstract": " An electronic device such as a mobile communication device capable of entering a locked mode of operation, comprising at least one input device for generating an input signal upon actuation thereof, at least one storage element for storing an application for executing a command in response to such actuation, and a processor connected to the storage element and input device for detecting the input signal and in response initiating execution of the command, buffering the command for a period of time, and detecting an action within the period of time, for causing the electronic device to enter a locked operating mode, and in response reverting the command.", "num_citations": "16\n", "authors": ["141"]}
{"title": "Using graph patterns to extract scenarios\n", "abstract": " Scenario diagrams are useful for helping software developers to understand the interactions among the components of a software system. We present a semi-automatic approach to extracting scenarios from the implementation of a software system. In our approach, the source code of a software system is represented as a graph and scenarios are specified as graph patterns. A relational calculator, Grok, is extended to support graph pattern matching. Grok, as extended, is used in our analysis of the Nautilus open source file manager. Multiple scenarios are extracted and analyzed. These scenarios have helped us to analyze Nautilus's architecture.", "num_citations": "16\n", "authors": ["141"]}
{"title": "Treatment of post-burn and post-traumatic atrophic scars with fractional CO 2 laser: experience at a tertiary care centre\n", "abstract": " Scars are abnormal wound responses in predisposed individuals. They occur after any kind of wound and skin inflammation in predisposed individuals. Despite their benign nature, they can be aesthetically disabling. Although several approaches have been tried in their management, most of them have produced poor results. This study aims to assess the efficacy and safety of fractional CO2 laser treatment in the management of post-burn and post-traumatic scars. One hundred consecutive patients (77 females and 23 males) affected by post-burn scars as well as post-traumatic atrophic scars were treated with monthly sessions of fractional CO2 laser treatment. Patient\u2019s response to treatment was assessed clinically as well as improvement of scars by comparing the photographs taken before treatment with those taken 6\u00a0months after the last treatment session. Changes in skin texture, surface irregularity\u00a0\u2026", "num_citations": "15\n", "authors": ["141"]}
{"title": "Recovering a balanced overview of topics in a software domain\n", "abstract": " Domain analysis is a crucial step in the development of product lines and software reuse in general, in which domain experts try to identify the commonalities and variability between different products of a particular domain. This identification is challenging, since it requires significant manual analysis of requirements, design documents, and source code. In order to support domain analysts, this paper proposes to use topic modeling techniques to automatically identify common and unique concepts (topics) from the source code of different software products in a domain. An empirical case study of 19 projects, spread across the domains of web browsers and operating systems (totaling over 39 MLOC), shows that our approach is able to identify commonalities and variabilities at different levels of granularity (sub-domain and domain). In addition, we show how the commonalities are evenly spread across all projects of\u00a0\u2026", "num_citations": "15\n", "authors": ["141"]}
{"title": "Diagnosis of Toxoplasma gondii by ELISA and PCR in mothers and their infants.\n", "abstract": " Congenital Toxoplasma gondii infection may lead to abortion, stillbirth, neonatal death as well as severe congenital toxoplasmosis in the newborn infants. No doubt, early and proper diagnosis of infection pregnant women or her baby pave the way to effective treatment and minimize complications. In this study; the PCR and ELISA-IgM were used to diagnose active toxoplasmosis. The results revealed that PCR detected very recently infection (23/70 subjects) than ELISA-IgM (18/70 ones). However, the use of both ELISA-IgM and PCR together improved the diagnostic sensitivity and specificity.", "num_citations": "14\n", "authors": ["141"]}
{"title": "An empirical study of the copy and paste behavior during development\n", "abstract": " Developers frequently employ Copy and Paste. However, little is known about the copy and paste behavior during development. To better understand the copy and paste behavior, automated approaches are proposed to identify cloned code. However, such automated approaches can only identify the location of the code that has been copied and pasted, but little is known about the context of the copy and paste. On the other hand, prior research studying actual copy and paste behavior is based on a small number of users in an experimental setup. In this paper, we study the behavior of developers copying and pasting code while using the Eclipse IDE. We mine the usage data of over 20,000 Eclipse users. We aim to explore the different patterns of Copy and Paste (C&P) that are used by Eclipse users during development. We compare such usage patterns to the regular users' usage of copy and paste during non\u00a0\u2026", "num_citations": "13\n", "authors": ["141"]}
{"title": "Visualize network anomaly detection by using k-means clustering algorithm\n", "abstract": " With the ever increasing amount of new attacks in today\u2019s world the amount of data will keep increasing, and because of the base-rate fallacy the amount of false alarms will also increase. Another problem with detection of attacks is that they usually isn\u2019t detected until after the attack has taken place, this makes defending against attacks hard and can easily lead to disclosure of sensitive information.In this paper we choose K-means algorithm with the Kdd Cup 1999 network data set to evaluate the performance of an unsupervised learning method for anomaly detection. The results of the evaluation showed that a high detection rate can be achieve while maintaining a low false alarm rate. This paper presents the result of using k-means clustering by applying Cluster 3.0 tool and visualized this result by using TreeView visualization tool.", "num_citations": "13\n", "authors": ["141"]}
{"title": "Wireless/LAN router queuing method and system\n", "abstract": " A queuing method and system for wireless/LAN routers processes and routes an incoming data packet from a wireless mobile network to a destination server. The system uses a wireless transport module to initiate storage of the data packet in a permanent storage device while simultaneously forwarding the data packet to the destination server. A database thread is used to manage the operations being performed on the data packet and for initiating the storage of the data packet in a permanent storage device based on a permanent storage queue. A main thread is used to simultaneously forward the data packet to the destination server. The wireless transport module is adapted to determine whether the data packet has been acknowledged by the destination server and aborting the storage of the data packet in the permanent storage device once acknowledgment from by destination server has been received.", "num_citations": "13\n", "authors": ["141"]}
{"title": "Leveraging historical co-change information for requirements traceability\n", "abstract": " Requirements traceability (RT) links requirements to the corresponding source code entities, which implement them. Information Retrieval (IR) based RT links recovery approaches are often used to automatically recover RT links. However, such approaches exhibit low accuracy, in terms of precision, recall, and ranking. This paper presents an approach (CoChaIR), complementary to existing IR-based RT links recovery approaches. CoChaIR leverages historical co-change information of files to improve the accuracy of IR-based RT links recovery approaches. We evaluated the effectiveness of CoChaIR on three datasets, i.e., iTrust, Pooka, and SIP Communicator. We compared CoChaIR with two different IR-based RT links recovery approaches, i.e., vector space model and Jensen-Shannon divergence model. Our study results show that CoChaIR significantly improves precision and recall by up to 12.38% and 5.67\u00a0\u2026", "num_citations": "12\n", "authors": ["141"]}
{"title": "Systems and methods for facilitating communication over a plurality of communication mediums\n", "abstract": " A processor-implemented method facilitates communication over a plurality of communication mediums by identifying interlocutors in a first communication and searching contact data to determine whether the interlocutors identified have an associated communication capability over a second communication medium. A second communication between the interlocutors determined to have the associated communication capability over the second communication medium may be established.", "num_citations": "12\n", "authors": ["141"]}
{"title": "Visualizing historical data using spectrographs\n", "abstract": " Studying the evolution of long lived processes such as the development history of a software system or the publication history of a research community, requires the analysis of a vast amount of data. Aggregation techniques and data specific techniques are usually used to cope with the large amount of data. In this paper, we introduce a general technique to study historical data derived from tracking the evolution of long lived processes. We present a visualization approach (evolution spectrographs) to assist in identifying interesting patterns and events during evolutionary analysis of such historical data. We demonstrate the usefulness of spectrographs through several case studies. The data for the case studies are derived from the publication history of conferences in the area of software engineering and from the source control of several large open source projects. Our case studies reveal interesting patterns such\u00a0\u2026", "num_citations": "12\n", "authors": ["141"]}
{"title": "Minimum lubrication milling of titanium alloys\n", "abstract": " During excessive fluid application processing, fluid ends up on the floor, the workers, and the machine, entail serious techno-environmental and biological problems. Very little fluid enters the tool/part interface. Recently, this excess fluid has become another costly control problem. Chemicals of all types introduced into the atmosphere must also be reduced to an absolute minimum. In this paper, the technique of minimum quantity of lubrication (MQL), which is the pulverization of a minimum volume of oil in a flow of compressed air, has been studied in face mill Ti-6Al-4V titanium alloys as one alternative to the use of abundant cooling to suppress the cutting heat resulted from low thermal conductivity and the density of the workpiece material. The results showed that MQL of 125ml/h flow amount was found to be the optimum, and there is no significant difference in temperature between MQL of this flow and wet cooling\u00a0\u2026", "num_citations": "12\n", "authors": ["141"]}
{"title": "Identifying user sessions in interactions with intelligent digital assistants\n", "abstract": " Search sessions have traditionally been considered as the focal unit of analysis for seeking behavioral insights from user interactions. While most session identification techniques have focused on the traditional web search setting; in this work, we instead consider user interactions with digital assistants (eg Cortana, Siri) and aim at identifying session boundary cut-offs. To our knowledge, this is one of the first studies investigating user interactions with a desktop based digital assistant. Historically, most user session identification strategies based on inactivity thresholds are either inherently arbitrary, or set at about 30 minutes. We postulate that such 30 minute thresholds may not be optimal for segregating user interactions with intelligent assistants into sessions. Instead, we model user-activity times as a Gaussian mixture model and look for evidence of a valley to identify optimal inter-activity thresholds for identifying\u00a0\u2026", "num_citations": "11\n", "authors": ["141"]}
{"title": "Distributed router application serialization\n", "abstract": " A router, which may be a wireless gateway, for routing messages between communications networks, including a persistent storage, and a transport interface for sending outgoing messages to communications devices associated with a first communications network, and receiving incoming messages from the communications devices, and having a storage for storing pending outgoing and incoming messages for subsequent sending by the interface component, the transport interface being coupled to the persistent storage and having an associated shutdown module for serializing at least some of the pending messages to the persistent storage during shutdown of the interface component. The router may include a plurality of the transport interfaces, and a controller coupled to the transport interfaces for directing at least one of the transport interfaces to retrieve from the persistent storage for subsequent sending the\u00a0\u2026", "num_citations": "11\n", "authors": ["141"]}
{"title": "Tracking the dynamic evolution of participants salience in a discussion\n", "abstract": " We introduce a technique for analyzing the temporal evolution of the salience of participants in a discussion. Our method can dynamically track how the relative importance of speakers evolve over time using graph based techniques. Speaker salience is computed based on the eigenvector centrality in a graph representation of participants in a discussion. Two participants in a discussion are linked with an edge if they use similar rhetoric. The method is dynamic in the sense that the graph evolves over time to capture the evolution inherent to the participants salience. We used our method to track the salience of members of the US Senate using data from the US Congressional Record. Our analysis investigated how the salience of speakers changes over time. Our results show that the scores can capture speaker centrality in topics as well as events that result in change of salience or influence among different participants.", "num_citations": "11\n", "authors": ["141"]}
{"title": "Review dynamics and their impact on software quality\n", "abstract": " Code review is a crucial activity for ensuring the quality of software products. Unlike the traditional code review process of the past where reviewers independently examine software artifacts, contemporary code review processes allow teams to collaboratively examine and discuss proposed patches. While the visibility of reviewing activities including review discussions in a contemporary code review tends to increase developer collaboration and openness, little is known whether such visible information influences the evaluation decision of a reviewer or not (i.e., knowing others' feedback about the patch before providing ones own feedback). Therefore, in this work, we set out to investigate the review dynamics, i.e., a practice of providing a vote to accept a proposed patch, in a code review process. To do so, we first characterize the review dynamics by examining the relationship between the evaluation decision of a\u00a0\u2026", "num_citations": "10\n", "authors": ["141"]}
{"title": "Modeling and optimization of a hybrid power system supplying RO water desalination plant considering CO2 emissions\n", "abstract": " Seawater desalination is an attractive choice especially for remote areas where freshwater is rare. Egypt is moving toward the desalination of water as an alternative solution to the decrease in freshwater. The main objective of this study was to design an optimal, economic, and efficient hybrid system that feeds the electric needs of a small-scale brackish reverse osmosis desalination unit and a tourism motel located in Hurghada, Egypt. The optimization problem of sizing different components of hybrid system is a complicated one; it needs a special tool capable of solving it rapidly and effectively. Three different hybrid system scenarios are discussed to select the most optimum combination of them. These scenarios are the following: wind/PV/battery, wind/PV/diesel, and wind/PV/battery/diesel. In this study, a modified particle swarm optimization technique is applied for optimum sizing of the proposed hybrid system\u00a0\u2026", "num_citations": "10\n", "authors": ["141"]}
{"title": "A road map for integrating a giant field: case study\n", "abstract": " El-Morgan Field was discovered in 1965 and is located offshore in the Gulf of Suez (GoS) approximately 160 miles south of Suez, Egypt. Peak Production was approximately 300,000 BOPD within only three years. El-Morgan is considered one of the giant fields since its STOOIP is estimated to be approximately 2.689 billion BO with an ultimate recoverable reserve around 1.439 billion BO. Over its history, more than 250 wells were drilled. Currently, 179 wells are operating (125 producers & 54 Injectors).", "num_citations": "10\n", "authors": ["141"]}
{"title": "Multi-objective optimization in the milling of titanium alloys using the MQL technique\n", "abstract": " The process for face milling of (\u03b1+\u03b2) titanium alloy while using minimum quantity librication (MQL) as the cooling technique was optimized by using of the Taguchi method to improve characteristics. The cutting speed, feed rate, and depth of cut were optimized with consideration of multiple performance characteristics including tool life, volume removed and surface roughness. The experimental results show that the multiple performance characteristics can be simultaneously improved through this approach, and the feed rate is the most influential cutting parameter in the face milling of titanium alloys.", "num_citations": "10\n", "authors": ["141"]}
{"title": "ADG: Annotated Dependency Graphs for Software Understanding.\n", "abstract": " Dependency graphs such as call and data usage graphs are often used to study software systems and perform impact analysis during maintenance activities. These graphs show the present structure of the software system (eg In a compiler, an Optimizer function calling a P arser function). They fail to reveal details about the structure of the system that are needed to gain a better understanding. For example, traditional call graphs cannot give the rationale behind an Optimizer function calling P arser function.In this position paper, we advocate a new view on dependency graphs\u2013Annotated Dependency Graphs (ADG). ADG can assist maintainers understand better the current structure of large software systems. We show an example of using an ADG to study P ostgres, a large DBMS open source software system.", "num_citations": "10\n", "authors": ["141"]}
{"title": "Investigating Perfor-mance of XML Web Services in Real-Time Business Systems\n", "abstract": " Service-Oriented Architecture (SOA) is being one of the widely accepted methodologies in software market for building and integrating different kinds of software systems. This acceptance comes from the extreme benefits that it offers to their adopters including agility, dynamicity, and loose-coupling. These benefits are usually missed in traditional software terminologies and practices. XML Web Services is the most used technology for applying SOA because it is easy to use and it allows high interoperability between different systems due to its dependency on standards that are widely accepted and supported by almost all large software vendors. However, XML Web Services suffer from a number of drawbacks such as low performance, bad utilization for hardware resources, and high network latency. These pitfalls may prevent some adopters from utilizing SOA in large and complex systems. So, these issues should be first addressed and resolved before leveraging it into real-time systems. This paper presents an experimental evaluation for the performance of XML Web Services in real-time business systems. Furthermore, it offers some tactics and strategies that might be used to enhance the overall performance of XML Web Services.", "num_citations": "9\n", "authors": ["141"]}
{"title": "A study of the performance of general compressors on log files\n", "abstract": " Large-scale software systems and cloud services continue to produce a large amount of log data. Such log data is usually preserved for a long time (e.g., for auditing purposes). General compressors, like the LZ77 compressor used in gzip, are usually used in practice to compress log data to reduce the cost of long-term storage. However, such general compressors do not consider the unique nature of log data. In this paper, we study the performance of general compressors on compressing log data relative to their performance on compressing natural language data. We used 12 widely used general compressors to compress nine log files that are collected based on surveying prior literature on text compression, log compression and log analysis. We observe that log data is more repetitive than natural language data, and that log data can be compressed and decompressed faster with higher compression ratios\u00a0\u2026", "num_citations": "8\n", "authors": ["141"]}
{"title": "Systems & methods for intelligently managing multimedia for emergency response\n", "abstract": " Described herein are systems, devices, methods, and media for connecting a user for transmitting multimedia from electronic devices to emergency service providers. In some embodiments, a method for transmitting multimedia from an electronic device to an emergency service provider by an emergency management system includes the steps of: detecting an emergency alert indicative of an emergency; wherein each sensor within the set of pertinent sensors is determined to be associated with the emergency; obtaining a first set of multimedia contents from the set of pertinent sensors; determining, based on at least one of the set of pertinent sensors and the first set of multimedia contents, a set of relevant sensors from the set of pertinent sensors; and transmitting a second set of multimedia contents from the set of relevant sensors to an emergency service provider.", "num_citations": "8\n", "authors": ["141"]}
{"title": "Will this clone be short-lived? Towards a better understanding of the characteristics of short-lived clones\n", "abstract": " Code clones are created when a developer duplicates a code fragment to reuse existing functionalities. Mitigating clones by refactoring them helps ease the long-term maintenance of large software systems. However, refactoring can introduce an additional cost. Prior work also suggest that refactoring all clones can be counterproductive since clones may live in a system for a short duration. Hence, it is beneficial to determine in advance whether a newly-introduced clone will be short-lived or long-lived to plan the most effective use of resources. In this work, we perform an empirical study on six open source Java systems to better understand the life expectancy of clones. We find that a large number of clones (i.e., 30% to 87%) lived in the systems for a short duration. Moreover, we find that although short-lived clones were changed more frequently than long-lived clones throughout their lifetime, short-lived\u00a0\u2026", "num_citations": "8\n", "authors": ["141"]}
{"title": "An improved version of opt-AiNet algorithm (I-opt-AiNet) for function optimization\n", "abstract": " This paper presents an improved version of opt-aiNet, which is an algorithm for multimodal function optimization based on the natural immune system metaphor. The proposed algorithm has some major and minor changes on the way the clonal selection principle is applied within the original opt-aiNet algorithm which allows for fast localization of the optima. The output of the proposed algorithm is tested on the same data as the original opt-aiNet and the results show the validity of the new improved one.", "num_citations": "8\n", "authors": ["141"]}
{"title": "Method and apparatus for efficient polling\n", "abstract": " An e-mail distribution server may manage many pull e-mail accounts by periodically, as defined by an interval time, polling associated pull e-mail servers for new mail. If the e-mail distribution server receives an e-mail message destined for a recipient having a pull e-mail account managed by the e-mail distribution server, the e-mail distribution server may recognize an opportunity to poll the pull e-mail server associated with the pull e-mail account sooner than the expiration of the interval time.", "num_citations": "8\n", "authors": ["141"]}
{"title": "Developing a Service Oriented Process Management System for University Quality Assurance\n", "abstract": " Quality assurance in universities is an increasing interest in quality and standards reflecting both the growth of higher education and its cost. Institutions should have a policy and associated processes for the assurance of the quality and standards of their programs. To achieve this, institutions should develop and implement a strategy for the continuous enhancement of quality. Formal policies and processes provide a framework within which higher education institutions can develop and monitor the effectiveness of their quality assurance systems. Process management is most suitable model for automating quality assurance in university. Process management is about modeling, design, execution, and monitoring. In this paper we describe quality assurance process management system built on service oriented architecture (SOA). SOA has been chosen for the transparently, scalability, and Integrity of this architecture.", "num_citations": "8\n", "authors": ["141"]}
{"title": "Automated vehicle detection in satellite images using deep learning\n", "abstract": " Automatic detection of small objects such as vehicles in satellite images is a very challenging task, due to the complexity of the background, vehicles colors, the large size of ground sample distance (GSD) for satellite images and jamming caused by buildings and trees. Many methods were proposed for this task by using handcrafted features (such as a Histogram of an Oriented Gradient, Local Binary Pattern, Scale-Invariant Feature Transform, etc.) along with support vector machine classifier, however, Convolutional Neural Networks (CNN) have proved to be potentially more effective. In this paper, we use two advanced deep learning frameworks, Faster Region CNN (Faster R-CNN) and Single Shot Multi-Box (SSD) based on (CNN) with Inception-V2 as a feature map generator instead of VGG-16, to detect vehicles through Transfer Learning, and making an experimental analysis comparison between the two\u00a0\u2026", "num_citations": "7\n", "authors": ["141"]}
{"title": "A genetic overview of 23Y-STR markers in UAE population\n", "abstract": " The United Arab Emirates (UAE) is comprised of seven Emirates that were united in December 2, 1971. They are Abu Dhabi, Dubai, Sharjah, Ajman, Umm Al Qaiwain, Ras Al Khaimah and Fujairah. Geographically, the UAE is situated along the coast of the southern Arabian Gulf Sea, sharing borders with Oman and Saudi Arabia. The indigenous inhabitants are called Emirati and constitute only 20% of the total population. The rest of the population is migrants and include South Asians (Indians, Pakistanis and Bangladeshis), Afghanis, Iranians, and people from other Arab countries such as Palestine, Yemen and Oman (www. vesitabudhabi. ae). This study assessed Y-STR population variation in the UAE that could provide relevant forensic information for the Emirates as well as other countries around the world. Whole blood samples from 278 unrelated, male individuals from UAE populations were collected with\u00a0\u2026", "num_citations": "7\n", "authors": ["141"]}
{"title": "Sharing user defined location based zones\n", "abstract": " A method is provided for sharing data, stored on a central data store, between a first user and a secondary user. The method comprises the following steps. A share request message is received from the first user. The share request message includes a data identifier for identifying which of the data stored on the central data store is to be shared with the secondary user, and a user identifier for identifying the secondary user. The data to be shared is associated with an account of the secondary user for subsequent access by the secondary user. A system and computer readable medium configured to implement the method are also described.", "num_citations": "7\n", "authors": ["141"]}
{"title": "Parametric study of air cooling process via water cooled bundle of wing-shaped tubes\n", "abstract": " This study presents an experimental and numerical study of flow and heat transfer characteristics of a cross flow heat exchanger employing staggered wing shaped tubes with zero angle of attack. Hot air was forced to flow over the external surface of the tubes and exchange heat with the cold water flowing inside. The water side Rew was varied from 5\u00d7 102 to 1\u00d7 103and the air side Rea was varied from 1.85\u00d7 103 to 9.7\u00d7 103. Correlations of Nua, Sta, Pdc, as well as the heat transfer per unit pumping power \u025b against Rea and design parameters are presented. Comparing with other different shapes from literature it is concluded that enhancement in the heat transfer of 34% and reduction in the pressure drop of 37% are achieved by utilizing the wing-shaped tubes as relative to the circular ones. The heat transfer coefficient, effectiveness, and efficiency index for bundles of circular, elliptical and wing-shaped tubes were compared. The results indicate that, the bundle of wing-shaped tubes has better performance over other bundles for similar parameters and conditions.", "num_citations": "7\n", "authors": ["141"]}
{"title": "An English-to-Arabic Prototype Machine Translator for Statistical Sentences\n", "abstract": " Authors of that paper proposed a prototype machine translator system to translate scientific English sentences into Ara- bic sentences. This system is based on natural language processing and machine learning. This proposed system is ap- plied in statistical field, which is very important on a mathematical sub field in Math department. The system is ana- lyzed, designed and developed. Author tested the proposed system on some statistical statements. It proves its validity as a prototype system.", "num_citations": "7\n", "authors": ["141"]}
{"title": "Attachment server network for viewing attachments on a portable electronic device\n", "abstract": " An attachment server network including at least two attachment servers in communication with one another, each of the attachment servers for converting email attachments in response to view requests received from portable electronic devices, each of the attachment servers having a respective cache for storing data corresponding to previously converted attachments, the data being available to any of the attachment servers in the attachment server network.", "num_citations": "7\n", "authors": ["141"]}
{"title": "Data visualization technique framework for intrusion detection\n", "abstract": " Network attacks have become the fundamental threat to today's largely interconnected computer system. Intrusion detection system (IDS) is indispensable to defend the system in the face of increasing vulnerabilities. While a number of information visualization software frameworks exist, creating new visualizations, especially those that involve novel visualization metaphors, interaction techniques, data analysis strategies, and specialized rendering algorithms, is still often a difficult process. To facilitate the creation of novel visualizations this paper presents a new framework that is designed with using data visualization technique for analysis and visualizes snort result data for user. The framework suggests PHP and CSS as data visualization technique and snort as intrusion detection system (IDS).", "num_citations": "7\n", "authors": ["141"]}
{"title": "Design analysis of a fabric based lightweight robotic gripper\n", "abstract": " The development of grasping mechanisms for various grasping applications have enabled robots to perform a wide variety of tasks in both industrial as well as domestic applications. Soft robotic grippers have been very useful in grasping applications with an added advantage of simpler control mechanisms as compared to rigid grippers. In this paper, a two fingered gripper inspired by the fingers of a human hand is introduced. The gripper is made from fabrics and, hence, compliant, lightweight, completely foldable and boasts a high payload capability. The mechanical design of the gripper is optimized through experiments, a maximum bending angle of 180\u00b0 is achieved. We demonstrate grasping of a variety of objects using the new gripper.", "num_citations": "6\n", "authors": ["141"]}
{"title": "A novel framework for spammer detection in social bookmarking systems\n", "abstract": " Social Bookmarking systems enable users to store, organize and search their resources. Furthermore, a social bookmarking system allows users to share their resources with others and even join groups of people with similar interests. The data size in social bookmarking systems has been increased sharply in recent years with the usage of such systems. However, such systems attract spammers due to their ease of use and popularity. Spammers have started misleading search engines and other bookmarking system users in order to direct web traffic towards their own pages. Strong prevention and detection methods in social bookmarking systems are indispensable in order to stop spam activities and guaranty the accuracy and reliability of information. In this paper, we introduce a novel framework for spam detection task in social bookmarking systems. Here, we propose a set of new features to improve the\u00a0\u2026", "num_citations": "6\n", "authors": ["141"]}
{"title": "A Large Scale Empirical Study on User-Centric Performance Analysis\n", "abstract": " Measuring the software performance under load is an important task in both test and production of a software development. In large scale systems, a large amount of metrics and usage logs are analyzed to measure the performance of the software. Most of these metrics are analyzed by aggregating across all users to get general results for the scenario, i.e., how individual users have perceived the performance is typically not considered in software performance research and practice. To analyze a software's performance, user's perception of software performance metrics should be considered along with the scenario-centric perspective of system tester or operator. In our empirical study, we analyzed the impact of performance on individual users to see if performance analysis results based on the user's perception is really different from the scenario-centric (aggregated) one. Case studies on common use case\u00a0\u2026", "num_citations": "6\n", "authors": ["141"]}
{"title": "Using jquery with snort to visualize intrusion\n", "abstract": " The explosive growth of malicious activities on worldwide communication networks, such as the Internet, has highlighted the need for efficient intrusion detection systems. The efficiency of traditional intrusion detection systems is limited by their inability to effectively relay relevant information due to their lack of interactive/immersive technologies. Visualized information is a technique that can encode large amounts of complex interrelated data, being at the same time easily quantified, manipulated, and processed by a human user. Authors have found that the representations can be quite effective at conveying the needed information and resolving the relationships extremely rapidly. To facilitate the creation of novel visualizations this paper presents a new framework that is designed with using data visualization technique by using Jquery & Php for analysis and visualizes snort result data for user.", "num_citations": "6\n", "authors": ["141"]}
{"title": "Respiratory gated simultaneous integrated boost-intensity modulated radiotherapy (SIB-IMRT) after breast conservative surgery for carcinoma of the breast: The Salmaniya Medical\u00a0\u2026\n", "abstract": " PURPOSE: To present our clinical experience using SIB-IMRT Technique for Intact Breast cancer. MATERIALS AND METHODS: A retrospective review of 45 cases of Stage I-IV breast cancer patients treated with SIB-IMRT with respiratory gating after Conservative treatments from 25th November 2008 to 16th February 2010. The most common fractionation was 1.8 Gy to Ipsilateral Breast tissue and 2.2 Gy to the lumpectomy cavity giving whole breast dose as 50.4 Gy and Lumpectomy cavity dose as 61.6 Gy over 28 fractions concomitantly. Respiratory gating was done and CT-images were taken in inspiratory breath hold position. RESULTS: A total of 45 patients with breast cancer-stage I (17.7%), II (71%), III (8.9%), IV (2.2%) were treated with SIB-IMRT with respiratory gated radiotherapy. Out of 45 patients, 24 are of left sided breast cancer and 21 are of right sided breast cancer patients. The median, Dose maximum (D-max) in SIB-IMRT is 106.2% of prescribed lumpectomy site dose. The median isodose line prescribed to PTV-2 is 100%. The Conformity index (CI) is 0.9688 (median value) and Homogeneity index (HI) 1.06 (median). The median ipsilateral lung, mean dose is 21.66 Gy and V-20 is 37.4%. For left sided cases the median value of mean heart dose, V-30 and V-40 are 22.98 Gy, 23.45% and 9.45% respectively. Acute skin toxicity was of Grade-I in 2.2%, Grade-II in 64.4%, Grade-III in 31.1%, and Grade-IV in 2.2%. The global Breast cosmoses were seen excellent in majority (93%) of case at median follow up of 8 months duration. CONCLUSIONS: Breast SIB-IMRT Technique is feasible and comparable with other treatment techniques\u00a0\u2026", "num_citations": "6\n", "authors": ["141"]}
{"title": "Adaptive Optimal Relay Coordination Scheme for Distributed Generation\n", "abstract": " Magdi El-Saadawi, Ahmed Hassan, Mohammed Saeed Dept. of Electrical Engineering Faculty of Engineering Mansoura University, Egypt E-mail: saadawi1@ gmail. com-arwaahmed1@ gmail. com-mohammedsaid@ mans. edu. eg", "num_citations": "6\n", "authors": ["141"]}
{"title": "VISUALIZATION TECHNIQUES FOR INTRUSION DETECTION- A SURVEY\n", "abstract": " In traditional intrusion detection system(IDS) environments, little activity has been applied to using visual analysis as an aid to intrusion detection. With more information systems being attacked and attack techniques evolving, the task of detecting intrusions is becoming an increasingly difficult. Efficient information visualization is an important element required for urgent detection of intruders. This paper presents a survey on using visualization techniques in intrusion detection system. Finally authors proposed a framework for visualization system for ID.", "num_citations": "6\n", "authors": ["141"]}
{"title": "Prototype of Web2-based system for quality assurance evaluation process in higher education institutions\n", "abstract": " Abstract _The process of quality assurance in higher education is a complex process requiring many of the arrangements. This process consists of several stages; the most important stage is the evaluation. This paper provides the unified modeling language diagrams (UML) for the quality assurance evaluation process in any higher education institution. Also, the prototype implementation of this system is discussed. Our work in this paper is based on the Egyptian (QAAP) Quality Assurance and Accreditation Project. There are three stages for the evaluation process: self-evaluation stage, external evaluation stage, and peer reviewing stage. Our system focuses on the first and the second stage. Finally, the implementation of the system is provided", "num_citations": "6\n", "authors": ["141"]}
{"title": "Distributed wireless packet assembly\n", "abstract": " Distributed assembly of data packets into messages at a group of interface devices that receive data packets from within a coverage area. Each interface device in the group will take ownership of a sequence of data packets forming a message when a data packet of the message meeting predetermined criteria is received by that interface device. Once an interface device takes ownership of a sequence of data packets, it sends a request to the other interface devices for any missing data packets of the sequence that the ownership claiming interface does not have, and then assembles message upon receiving all the data packets of the sequence.", "num_citations": "6\n", "authors": ["141"]}
{"title": "Report on MSR 2004: International workshop on mining software repositories\n", "abstract": " A one-day workshop was held on the topic of mining software repositories at ICSE 2004 in Edinburgh, Scotland. The workshop brought together researchers and practitioners in order to consider methods that use data stored in software repositories (such as source control systems, defect tracking systems, and archived project communications) to further understanding of software development practices. We divided submissions into six sessions, each devoted to a particular topic: 1) Infrastructure and Extraction, 2) Integration and Presentation, 3) System Understanding and Change Patterns, 4) Defect Analysis, 5) Process and Community Analysis, and 6) Software Reuse. To maximize interaction and discussion, we limited each session to a survey of the topic area, followed by the presentation of one or two papers, then an open discussion. We also allocated a demo hour to give interested parties the opportunity to\u00a0\u2026", "num_citations": "6\n", "authors": ["141"]}
{"title": "Studying Ad library integration strategies of top free-to-download apps\n", "abstract": " In-app advertisements have become a major revenue source for app developers in the mobile app ecosystem. Ad libraries play an integral part in this ecosystem as app developers integrate these libraries into their apps to display ads. In this paper, we study ad library integration practices by analyzing 35,459 updates of 1,837 top free-to-download apps of the Google Play Store. We observe that ad libraries (e.g., Google AdMob) are not always used for serving ads -- 22.5% of the apps that integrate Google AdMob do not display ads. They instead depend on Google AdMob for analytical purposes. Among the apps that display ads, we observe that 57.9% of them integrate multiple ad libraries. We observe that such integration of multiple ad libraries occurs commonly in apps with a large number of downloads and ones in app categories with a high proportion of ad-displaying apps. We manually analyze a sample of\u00a0\u2026", "num_citations": "5\n", "authors": ["141"]}
{"title": "Enhancing the Security of Biometric Systems on View of BioFM\n", "abstract": " Biometrics is a very important addition to the robustness of security systems. Typically, biometrics is used in many crucial security systems. No doubt, modeling of biometric systems, like any other systems, leads to better understanding of the system and enhancing its security-among its other characteristics. This paper makes use of the Biometric systems Functional Model (BioFM) proposed by the authors, to enhance the security of biometric systems. Also, the paper proposes a new algorithm to countermeasure an attack against processing subsystem. To implement the algorithm, the paper introduces a new layer on top of the processing subsystem. Finally, the paper runs experiments to prove the concept of the proposed algorithm and to validate the feasibility of the new layer.", "num_citations": "5\n", "authors": ["141"]}
{"title": "DiffLDA: topic evolution in software projects\n", "abstract": " Previous research has shown that topics can be automatically discovered in a software project\u2019s source code. Topics are collections of words that co-occur frequently in a text collection and are discovered using topic models such as latent Dirichlet allocation (LDA). Tracking how topics evolve, ie, grow and spread, over time is useful for supporting software maintenance, comprehension, and re-engineering activities. The evolution of topics is typically recovered by applying LDA to all versions of a project\u2019s source code at once, followed by post processing to map topics across versions. Although this technique works well in applications where each version of the data is completely different, for example in the analysis of conference proceedings, the technique does not work well with source code, which typically changes only incrementally and contains significant duplication across versions. In this paper, we present a new approach, called DiffLDA, for automatically mining topic evolution in source code. The approach addresses LDA\u2019s sensitivity to document duplication by operating on the differences between versions of a source code document, resulting in a more accurate, finer-grained representation of topic evolution. We validate our approach through case studies on simulated data and two open source projects. 1", "num_citations": "5\n", "authors": ["141"]}
{"title": "Accessibility system for deaf Arab students\n", "abstract": " This paper presents an accessibility system which offers Arabic sign language (ArSL) for the Arabic deaf. This system enables deaf student to access the Web for learning process. In that system the special needs of deaf learners are satisfied, e.g. bilingual information (Arabic text and ArSL), high level of visualization and interactive and explorative learning. The basic objective of our system is the support of the equal rights of deaf people for their access to the educational and training material on the Web.", "num_citations": "5\n", "authors": ["141"]}
{"title": "Message handling based on receiver display size\n", "abstract": " Before sending an original text-based message to a receiver that is known to have a display screen of limited size, a user may indicate a desire to translate the original message, at least in part, into a visually compressed message, where the visually compressed message uses abbreviations in place of many of the strings of characters in the original message.", "num_citations": "5\n", "authors": ["141"]}
{"title": "Report on msr 2005: international workshop on mining software repositories\n", "abstract": " A one-day workshop on the topic of Mining Software Repositories (MSR) was held at ICSE 2005 in St. Louis, Missouri. Researchers and practitioners in the MSR field try to transform static record keeping software repositories to active ones. These repositories permit researchers to gain empirically based understanding of software development, while software practitioners use these repositories to predict and plan various aspects of their project.Following the success of last year's workshop, MSR 2005 had a large number of high quality submissions and a great number of participants. 22 papers were accepted from 38 submissions - 11 papers were presented as Lightning talks (5 mins) and another 11 papers were presented as regular talks (15 mins). The Lighting talks were followed with a walk-around demo and discussion session.This report includes an overview of the presentations made during the day and a\u00a0\u2026", "num_citations": "5\n", "authors": ["141"]}
{"title": "Mining software repositories to guide software development\n", "abstract": " Software repositories (such as source control repositories) contain a wealth of valuable information regarding the evolutionary history of a software project. In this research we recover such historical data and present several techniques and approaches to guide managers and developers working on large software systems. We validate our work empirically using data based on over 60 years of development history for several open source projects.", "num_citations": "5\n", "authors": ["141"]}
{"title": "MSR 2004: International workshop on mining software repositories\n", "abstract": " The goal of this one-day workshop is to bring together researchers and practitioners to consider methods that use data stored in software repositories (such as source control systems, defect tracking systems, and archived project communications) to further understanding of software development practices.", "num_citations": "5\n", "authors": ["141"]}
{"title": "Source Control Change Messages: How Are They Used And What Do They Mean?\n", "abstract": " Source control systems permit developers to attach a free form message to every committed change. The content of these change messages is rarely investigated and little is known about their use by developers while they maintain their code.We present the results of a survey we conducted with professional software developers. The purpose of this survey was to investigate how developers make use of these messages and what type of information exists in them. We also investigated the possibility of using automated techniques which examine change messages and determine their purpose, for example that a change was done to fix a bug or to indent the code. We also asked developers to compare change messages in open source software systems to change messages in commercial systems.", "num_citations": "5\n", "authors": ["141"]}
{"title": "Groundwater quality model with applications to various aquifers\n", "abstract": " A finite element model was developed in order to solve for both regional groundwater flow and conservative solute transport in porous medium. The model was applied to a 55-sq-km groundwater basin in the Ruehen region of Germany using a network of 1450 elements and 780 nodes. This model was used in simulating a contaminant plume done through injection. Similarly, the model was applied to a 4750-sq-km portion in the eastern Nile Delta aquifer in Egypt. The model was applied to this portion of the delta using a network of 543 elements and 310 nodes with the main objective of simulating the problem of salt water intrusion.", "num_citations": "5\n", "authors": ["141"]}
{"title": "Prevalence of Metabolic Syndrome among Primary Health Care Attendees in King Fahad Armed Forces Hospital in Jeddah\n", "abstract": " Background: The prevalence of the metabolic syndrome in Member States of the Gulf Cooperative Council countries ranged from 20.7% to 45.9%. People with metabolic syndrome are twice as likely to die and three times as likely, to have a heart attack or stroke compared with people without the syndrome.Objective: To estimate the prevalence of metabolic syndrome, compare it using ATP III and IDF definitions as well as to identify the factors associated with metabolic syndrome, among primary health care attendees in KFAFH in Jeddah 2012.Subjects and methods: A cross-sectional study design adopted among a representative random sample of peoples who attended primary care center in King Fahed Armed Forces hospital (KFAFH) in 2012. A systematic random sampling technique was utilized (every 10th patient was chosen). Data collected in a sheet, which includes three parts. First part: socio-demographic data. Second part: checklist about smoking habit, physical activity, past history of diabetes and hypertension, any medication for the treatment of diabetes, hypertension or dyslipidemia. Third part: Results of measurement including measurement of BP, BMI, waist circumference, fasting blood glucose and fasting HDL, triglycerides, cholesterol. NCEP/ATP III and IDF definitions utilized to determine the criteria to diagnose metabolic syndrome.Results: The study included 300 patients (150 males and 150 females). The mean age of males and females were 51.3\u00b114.8 and 48.6\u00b112.4 years, respectively. The prevalence of metabolic syndrome among study population, based on ATP criteria 41.3% while its prevalence was 54.3% based on IDF\u00a0\u2026", "num_citations": "4\n", "authors": ["141"]}
{"title": "Multi-polygon constraint decomposition techniques for use in double patterning applications\n", "abstract": " One illustrative method disclosed herein involves, among other things, decomposing an initial circuit layout into first and second mask patterns, for the first mask pattern, identifying a first four-polygon pattern in the first mask pattern that violates a multi-polygon constraint rule, wherein the first four-polygon pattern comprises four polygons positioned side-by-side in the first mask pattern, and recoloring one or two of the polygons in the first four-polygon pattern in the first mask pattern to the second mask pattern to eliminate the first four-polygon pattern from the first mask pattern without introducing any design rule violations in the initial circuit layout.", "num_citations": "4\n", "authors": ["141"]}
{"title": "Outcome of unimicrobial versus polymicrobial sepsis\n", "abstract": " MethodsOne hundred and one patients with sepsis were studied and divided into two groups. The first group: unimicrobial, where one organism was isolated from cultures; and the second group: polymicrobial, where more than one organism was isolated from the cultures.ResultsThe first group (unimicrobial) was 48 cases (47.5%) and the second group (polymicrobial) was 53 cases (52.47%). Both groups has similar positive sputum cultures (32/48 (66%) versus 38/53 (71%), P value 0.6), but positive blood culture was significantly higher in the second group (27/53 (51%) vs 7/48 (14%), P value 0.0001). There was also a significantly higher incidence of UTI and wound infection in the second group (49.7% vs 6.3% for UTI, P value 0.0001 and 20.7% vs 2.1%, P value 0.004 for wound infection, respectively). The commonest detected organisms were Staphylococci and Klebsiella (48, 22 out of 101 patients); 16/48 (33\u00a0\u2026", "num_citations": "4\n", "authors": ["141"]}
{"title": "Edge-oriented interpolation method for deinterlacing with sub-pixel accuracy\n", "abstract": " An edge-oriented interpolation method for deinterlacing with sub-pixel accuracy. To interpolate a missing pixel of a first scan line, first, a first pixel group of a second scan line and a second pixel group of a third scan line in a first orientation are provided, and a third pixel group of the second scan line and a fourth pixel group of the third scan line in a second orientation are provided. Then, a first sub-pixel of the second scan line is calculated according to the first pixel group and the third pixel group, and a second sub-pixel of the third scan line is calculated according to the second pixel group and the fourth pixel group by employing a linear interpolation method or an ideal interpolation function based on the sampling theorem. Thereafter, the missing pixel is interpolated according to the first sub-pixel and the second sub-pixel.", "num_citations": "4\n", "authors": ["141"]}
{"title": "The Ontario Neurodegenerative Disease Research Initiative\n", "abstract": " Objective: In individuals over the age of 65, concomitant neurodegenerative pathologies contribute to cognitive and/or motor decline and can be aggravated by cerebrovascular disease, but our understanding of how these pathologies synergize to produce the decline represents an important knowledge gap. The Ontario Neurodegenerative Disease Research Initiative (ONDRI), a multi-site, longitudinal, observational cohort study, recruited participants across multiple prevalent neurodegenerative diseases and cerebrovascular disease, collecting a wide array of data and thus allowing for deep investigation into common and unique phenotypes. This paper describes baseline features of the ONDRI cohort, understanding of which is essential when conducting analyses or interpreting results. Methods: Five disease cohorts were recruited: Alzheimer9s disease/amnestic mild cognitive impairment (AD/MCI), amyotrophic lateral sclerosis (ALS), frontotemporal dementia (FTD), Parkinson9s disease (PD), and cerebrovascular disease (CVD). Assessment platforms included clinical, neuropsychology, eye tracking, gait and balance, neuroimaging, retinal imaging, genomics, and pathology. We describe recruitment, data collection, and data curation protocols, and provide a summary of ONDRI baseline characteristics. Results: 520 participants were enrolled. Most participants were in the early stages of disease progression. Participants had a median age of 69 years, a median Montreal Cognitive Assessment score of 25, a median percent of independence of 100 for basic activities of daily living, and a median of 93 for instrumental activities. Variation between\u00a0\u2026", "num_citations": "3\n", "authors": ["141"]}
{"title": "Evaluation of Different Sarcasm Detection Models for Arabic News Headlines\n", "abstract": " Being sarcastic is to say something and to mean something else. Detecting sarcasm is key for social media analysis to differentiate between the two opposite polarities that an utterance may convey. Different techniques for detecting sarcasm are varying from rule-based models to Machine Learning and Deep Learning models. However, researchers tend to leverage Deep Learning in detecting sarcasm recently. On the other hand, the Arabic language has not witnessed much improvement in this research area. Bridging the gap in sarcasm detection of the Arabic language is the target behind this work. In this paper, efficient models in short text classification are tested for detecting sarcasm in the Arabic news headlines for the first time. The dataset used to train and test these different architectures was manually collected by scrapping two different websites, sarcastic and non-sarcastic. Detailed results for each\u00a0\u2026", "num_citations": "3\n", "authors": ["141"]}
{"title": "Novel functionalization treatment of MWCNTs for unmanned aerial vehicle structure\n", "abstract": " Present typescript encompasses the influences of functionalization on the carbon nanotubes (CNTs) using acid oxidation which has been widely reported not only as a purification process but also as functionalization process because it is an effect on the outer surface on CNTs. Therefore, using strong acid effect and high power sonication in addition to the nature of the acid mixture (H2SO4/HNO3) with CNTs confirm that adequate volume of carboxyl groups decorate the outer surface, this functionalization process improve the dispersibility of the CNT in the response of the final dimension of the CNTs. Because of using a high temperature for a long time more than 6 hours. This work interested in the aspect ratio (L/D) and the final shape of the tubes by using a mild temperature process 50\u00b0C with concentration acid for not long time 5 hours, in an attempt to make experimental condition which guarantees good\u00a0\u2026", "num_citations": "3\n", "authors": ["141"]}
{"title": "A deep learning framework for automatic airplane detection in remote sensing satellite images\n", "abstract": " Automated object detection in high-resolution remote sensing satellite images(HRRSSI) is a proper solution for this task rather than manual detection using professional specialists. However, it is more complex due to the varying size, type, orientation, and complex background of the objects to detect. Utilizing artificial intelligence using deep learning is the state of the art technique to achieve this task. The number of labeled satellite images is limited for training a deep neural network therefore; transfer learning techniques were adopted for this task. This paper proposes a framework for airplane detection based on Convolution Neural network (CNN). Faster Region Based CNN (Faster R-CNN) framework is used to perform automatic airplane detection through transfer learning. Inception v2 is added to the network for feature extraction to enhance detection accuracy. The problem of information reduction of the objects\u00a0\u2026", "num_citations": "3\n", "authors": ["141"]}
{"title": "Supplementary material\n", "abstract": " Supplementary Materials to Hepatoprotective Effect of Kombucha Tea in Rodent Model of Nonalcoholic Steatohepatitis Chanbin Lee, Page 1 1 Supplementary Materials to Hepatoprotective Effect of Kombucha Tea in Rodent Model of Nonalcoholic Steatohepatitis Chanbin Lee, Jieun Kim, Sihyung Wang, Sumi Sung, Namgyu Kim, Hyun-Hee Lee, YoungSu Seo, and Youngmi Jung Table of Contents Supplementary Table \u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026.\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026..\u2026\u2026 2 Supplementary Figure \u2026\u2026\u2026..\u2026\u2026\u2026\u2026..\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026..\u2026\u2026\u2026\u2026\u2026\u2026\u2026.\u2026.. 4 Page 2 2 Supplementary Table Table S1. Changes in liver weight and body weight in experimental animal. Liver weight (LW), Body weight (BW), and the ratio of liver to body weight (LW/BW) of CON, M+V and M+K groups. (*p<0.05, **p<0.005 vs CON group, #p<0.05, ##p<0.005 vs M+V group) db/db Mice Parameter CON M + V M + K Liver weight (g\u2026", "num_citations": "3\n", "authors": ["141"]}
{"title": "Computing device with environment aware features\n", "abstract": " A method and mobile electronic device are provided which automatically adjust settings based on the environment of the mobile electronic device. The settings of the mobile electronic device which are adjusted may be security settings, filter settings, or status for instant messaging in dependence on the determined location of the mobile electronic device.", "num_citations": "3\n", "authors": ["141"]}
{"title": "Economic Analysis of a Grid-Connected Hybrid Renewable System Supplying CIT Center at Mansoura University-Egypt\n", "abstract": " Renewable energy is one of the major inputs for the economic and social development of any country. In case of the developing countries, the renewable energy sector represents a critical importance in increasing electrical energy which requires huge investments to meet them. The Hybrid Renewable Energy System (HRES) provides the consumer with reliable and cheap electricity by reducing the dependence on one renewable source. Therefore optimal combination and sizing design of HRES has a very important role in the use of renewable energy effectively and economically. Egypt has a huge potential for renewable energy sources which encourages the implementation of renewable energy projects. This paper presents an economic analysis of applying a HRES to provide Communication and Information Technology (CIT) Centre in Mansoura University-Egypt, with its needs of electricity. A modified Particle Swarm Optimization (PSO) technique is applied to optimize the capacity sizes of different components of hybrid PV/wind power generation system. A Matlab code is developed to represent the proposed method. The results indicate the optimal configuration and sizing of the proposed HRES. Capital budgeting and economic analysis indicate that HRES is technically feasible and economically viable.", "num_citations": "3\n", "authors": ["141"]}
{"title": "Effect Of Deficit Irrigation On The Productivity And Characteristics Of Tomato\n", "abstract": " In order to assess the effect of water irrigation deficit during season on yield and mechanical damage of processing tomato, an open field experiment was carried out in two seasons 2010/2011 \u2013 2011/2012. Four irrigation treatments were studied: (ET1: 1 time potential crop evapotranspiration (ETc), ET2: 0.9 ETc, ET3: 0.8 ETc and 0.7 ETc, ET4). The study investigated the yield and mechanical damage in packing cage under four levels of water requirements. Numerous mechanical impacts on fruit occurred with resulting mechanical damages of 15.9, 9.9, 7.1, and 9.5% for treatments ET1, ET2, ET3, and ET4, respectively. Total productions of tomato were 30.77, 29.50, 28.88 and 25.54 ton/fed, but net productions of tomato were 25.88, 26.58, 26.83 and 23.12 ton/fed for treatments ET1, ET2, ET3 and ET4, respectively. The bruised productions of tomatoes were 4.89, 2.92, 2.05 and 2.43 ton/fed for treatments ET1, ET2, ET3 and ET4, respectively. The net profit values for treatments ET1, ET2, ET3 and ET4 were 68990.7, 68841.5, 68644.2, and 59804.6 LE/fed, respectively. The amounts of water saved from ET2 and ET3 were 163.5 and 327 mm, respectively. The amount of water saved can be used to provide other areas to increase the production and thereby increase the water use efficiency.", "num_citations": "3\n", "authors": ["141"]}
{"title": "Molecular markers associated with drought tolerance in Citrullus colocynthis\n", "abstract": " Herbal remedy drugs production became so important, especially with flooding the pharmaceutical Egyptianmarket with a number of synthetic drugs of questionable efficacy associated with the increasing cost of such drugs. Therefore, the demand of high-yield and highquality medicinal plants will continue to increase in the future. In addition, a growing concern with the awareness of the side effects of the drugs associated with regular exposure to synthetic chemicals has triggered a \u201cback to nature\u201d idea with an appeal of new discovery natural products to meet primary health care.", "num_citations": "3\n", "authors": ["141"]}
{"title": "Performance engineering in industry: current practices and adoption challenges\n", "abstract": " This panel session discusses performance engineering practices in industry. Presentations in the session will explore the use of lightweight techniques and approaches in order to permit the cost effective and rapid adoption of performance modeling research by large industrial software systems.", "num_citations": "3\n", "authors": ["141"]}
{"title": "Mix of acidulated de-calcinated phosphate rock and elemental sulfur as as effective phosphate fertilizer\n", "abstract": " Mix of acidulated de-calcinated phosphate rock and elemental sulfur as as effective phosphate fertilizer FAO_logo home-icon English Espa\u00f1ol Fran\u00e7ais \u0627\u0644\u0639\u0631\u0628\u064a\u0629 \u4e2d\u6587 \u0420\u0443\u0441\u0441\u043a\u0438\u0439 home-icon Translate with Google Access the full text NOT AVAILABLE Lookup at Google Scholar google-logo Bibliographic information Language : English Type : Conference In AGRIS since : 2014 Start Page : 707 All titles : \" Mix of acidulated de-calcinated phosphate rock and elemental sulfur as as effective phosphate fertilizer \" Save as: AGRIS_AP RIS EndNote(XML) Mix of acidulated de-calcinated phosphate rock and elemental sulfur as as effective phosphate fertilizer Loading... Paper Written Paper Mix of acidulated de-calcinated phosphate rock and elemental sulfur as as effective phosphate fertilizer [2002] Razao, IB, Iraq Atomic Energy Commission, Baghdad (Iraq). Agriculture and Biology Research Center Al-Hadithy, AH, Iraq Atomic , (). -\u2026", "num_citations": "3\n", "authors": ["141"]}
{"title": "Improving State-of-the-art Compression Techniques for Log Management Tools\n", "abstract": " Log data records important runtime information about the running of a software system for different purposes including performance assurance, capacity planning, and anomaly detection. Log management tools such as ELK Stack and Splunk are widely adopted to manage and leverage log data in order to assist DevOps in real-time log analytics and decision making. To enable fast queries and to save storage space, such tools split log data into small blocks (e.g., 16KB), then index and compress each block separately. Previous log compression studies focus on improving the compression of either large-sized log files or log streams, without considering improving the compression of small log blocks (the actual compression need by modern log management tools). The evaluation of four state-of-the-art compression approaches (e.g., Logzip, a variation of Logzip by pre-extracting log templates named Logzip-E\u00a0\u2026", "num_citations": "2\n", "authors": ["141"]}
{"title": "Predicting cognitive impairment in cerebrovascular disease using spoken discourse production\n", "abstract": " Purpose: Dementia due to cerebrovascular disease (CVD) is common. Detecting early cognitive decline in CVD is critical because addressing risk factors may slow or prevent dementia. This study used a multidomain discourse analysis approach to determine the spoken language signature of CVD-related cognitive impairment.  Method: Spoken language and neuropsychological assessment data were collected prospectively from 157 participants with CVD as part of the Ontario Neurodegenerative Disease Research Initiative, a longitudinal, observational study of neurodegenerative disease. Participants were categorized as impaired (n = 92) or cognitively normal for age (n = 65) based on neuropsychology criteria. Spoken language samples were transcribed orthographically and annotated for 13 discourse features, across five domains. Discriminant function analyses were used to determine a minimum set of\u00a0\u2026", "num_citations": "2\n", "authors": ["141"]}
{"title": "Surgical site infection after gastrointestinal surgery in children: an international, multicentre, prospective cohort study\n", "abstract": " Introduction Surgical site infection (SSI) is one of the most common healthcare-associated infections (HAIs). However, there is a lack of data available about SSI in children worldwide, especially from low-income and middle-income countries. This study aimed to estimate the incidence of SSI in children and associations between SSI and morbidity across human development settings.Methods A multicentre, international, prospective, validated cohort study of children aged under 16 years undergoing clean-contaminated, contaminated or dirty gastrointestinal surgery. Any hospital in the world providing paediatric surgery was eligible to contribute data between January and July 2016. The primary outcome was the incidence of SSI by 30 days. Relationships between explanatory variables and SSI were examined using multilevel logistic regression. Countries were stratified into high development, middle development\u00a0\u2026", "num_citations": "2\n", "authors": ["141"]}
{"title": "Methods for improving screening for vascular cognitive impairment using the Montreal Cognitive Assessment\n", "abstract": " Background:     Vascular cognitive impairment (VCI) post-stroke is frequent but may go undetected, which highlights the need to better screen cognitive functioning following a stroke. Aim:     We examined the clinical utility of the Montreal Cognitive Assessment (MoCA) in detecting cognitive impairment against a gold-standard neuropsychological battery. Methods:     We assessed cognitive status with a comprehensive battery of neuropsychological tests in 161 individuals who were at least 3-months post-stroke. We used receiver operating characteristic (ROC) curves to identify two cut points for the MoCA to maximize sensitivity and specificity at a minimum 90% threshold. We examined the utility of the Symbol Digit Modalities Test, a processing speed measure, to determine whether this additional metric would improve classification relative to the MoCA total score alone. Results:     Using two cut points, 27% of\u00a0\u2026", "num_citations": "2\n", "authors": ["141"]}
{"title": "Too many images on DockerHub! How different are images for the same system?\n", "abstract": " Containerization is a technique used to encapsulate a software system and its dependencies into one isolated package, which is called a container. The goal of these containers is to deploy or replicate a software system on various platforms and environments without facing any compatibility or dependency issues. Developers can instantiate these containers from images using Docker; one of the most popular containerization platforms. Furthermore, many of these images are publicly available on DockerHub, on which developers can share their images with the community who in turn can leverage such publicly available image. However, DockerHub contains thousands of images for each software system, which makes the selection of an image a nontrivial task. In this paper, we investigate the differences among DockerHub images for five software systems and 936 images with the goal of helping Docker tooling\u00a0\u2026", "num_citations": "2\n", "authors": ["141"]}
{"title": "Implementation of epilepsy multigene panel testing in Ontario, Canada\n", "abstract": " Background:Epilepsy is a common neurological condition that shows a marked genetic predisposition. The advent of next-generation sequencing (NGS) has transformed clinical genetic testing by allowing the rapid screen for causative variants in multiple genes. There are currently no NGS-based multigene panel diagnostic tests available for epilepsy as a licensed clinical diagnostic test in Ontario, Canada. Eligible patient samples are sent out of country for testing by commercial laboratories, which incurs significant cost to the public healthcare system.Objective:An expert Working Group of medical geneticists, pediatric neurologists/epileptologists, biochemical geneticists, and clinical molecular geneticists from Ontario was formed by the Laboratories and Genetics Branch of the Ontario Ministry of Health and Long-Term Care to develop a programmatic approach to implementing epilepsy panel testing as a provincial\u00a0\u2026", "num_citations": "2\n", "authors": ["141"]}
{"title": "Stabilizing Attitude Control For Mobility Of Wing In Ground (WIG) Craft-A Review\n", "abstract": " Wing in ground crafts development have been rapidly advancing in recent years. The current paper reviews the researches and developments of existing stability control system technology\u2019s development and enhancement for wing in ground effect crafts. The review is critically intended for the development of the control system for two-seater Dragonfly 2, a hoverwing type craft. The current review will commence with the introduction on the theory behind the in ground effect phenomenon on the crafts, its regulations and the types of wing in ground crafts, their advantages and disadvantages, and their stability and control issues. This paper also discusses the available attitude control sys-tem types of wing-in-ground craft (WIG), its experiments, simulations and computational methods done especially on both the lon-gitudinal and lateral motion stability.", "num_citations": "2\n", "authors": ["141"]}
{"title": "Suggesting a hybrid approach: Mobile apps with big data analysis to report and prevent crimes\n", "abstract": " Conventional crime prediction techniques rely on location-specific historical crime data. Yet relying on historical crime data alone has deficiencies, as such data is limited in scope and often fails to capture the full complexity of crimes. This chapter proposes a novel approach to employ mobile applications with big data analysis for crime reporting and prevention using aggregate data from multiple sources, the Hybrid Smart Crime Reporting App (HIVICRA). It is an infographic intelligent crime-reporting analysis application that incorporates crime data sourced from local police, social media and crowdsourcing, including sentiment analysis of Twitter streams in conjunction with historical police crime datasets. An evaluation of the approach suggests that by combining sentiment analysis with smart crime reporting applications, it is possible to improve the forecasting of crime.", "num_citations": "2\n", "authors": ["141"]}
{"title": "Human dendritic cell sequestration onto the Necator americanus larval sheath during ex-sheathing: a possible mechanism for immune privilege\n", "abstract": " Despite the profound health implications of Necator americanus infection in humans, many aspects of its interaction with the host immune system are poorly understood. Here we investigated the early events at the interface of N. americanus larvae (L3) and human dendritic cells (DCs). Our data show that co-culturing DCs and the larvae trigger ex-sheathing of hookworms rapidly where a majority of DCs are sequestered onto the larval sheath allowing the ex-sheathed larvae to migrate away unchallenged. Intriguingly, DCs show negligible interaction with the ex-sheathed larvae, alluding to differences between the surface chemistry of the larva and its sheath. Furthermore, blocking of two key C-type lectin receptors on DC surface (i.e. DC-SIGN and mannose receptor) resulted in inhibition of ex-sheathing process and DC sequestration, highlighting the importance of C-type lectins on DCs in the induction of the ex\u00a0\u2026", "num_citations": "2\n", "authors": ["141"]}
{"title": "Learning motivation for slow learners with tablet technology\n", "abstract": " The use of tablet technology and apps has delineated a new ambience in a way of learning for children with learning disabilities. In an attempt to understand the gap, a study has been conducted with children with learning disabilities, specifically slow learners. They have challenges and difficulties to understand complex instructions and take longer time in catching up. Stimulation of multimodal features such as animation, audio, graphics and colors with the intuitive touch-screen interface on the tablet technology and apps have imparted a great deal of learning within the slow learner children. Practically, the uses of tablet technology with apps are complimentary learning tools to support and enhance learning process experience for the slow learners. Employing the apps in the learning activities with the slow learners embrace benefits to their learning. In an observation and focus group discussion within the teachers and slow learners, it was observed that the audio, graphics and ability to touch and swipe the screen have enhanced the motivation of the slow learners in their learning. When completing the learning activities, the slow learners demonstrated an engagement, enjoyment and excitement during task performance. Learning and performing learning activities with the tablet technology and apps have given the opportunity, benefits and new experience for the slow learners to interact at their own way which more relevance to them. The findings emerge after observations of a group of slow learners at school in a suburb area on the use of tablet technology to facilitate their learning. A six weeks of learning observation has been conducted with\u00a0\u2026", "num_citations": "2\n", "authors": ["141"]}
{"title": "MULTIDETECTOR COMPUTED TOMOGRAPHY OF RENAL VASCULATURE. ANATOMY AND NORMAL VARIANTS.\n", "abstract": " Multi Detector Computed Tomography Angiography (MDCTA) provides a fast, non-invasive modality for the evaluation of the renal vascular pedicle. CTA can reliably and accurately depict the renal arteries and veins and approaches conventional angiography in the assessment of most vascular abnormalities. Knowledge of the variations in renal vascular anatomy is important before laparoscopic donor or partial nephrectomy and vascular reconstruction for renal artery stenosis or abdominal aortic aneurysm.Objective: To illustrate the diagnostic accuracy of MDCT for evaluation of renal vasculature anatomy.Design: An analytic, comparative study.Subjects: fifty six patients including 43 living renal donors, 13 hypertension and abdominal pain (27 men and 29 women, mean age 39.5 years) were examined from January 2008 to September 2010 in Radiology department, Farwania hospital Kuwait. Gold standard was the operative data, conventional angiography or DSA.Main outcome: The value of MDCT in assessment of renal vascular anomalies.Results: Renal vascular anatomical variants included multiple arteries (21.4%), multiple veins (7.1%), early arterial bifurcation (8.9%), late venous confluence (7.1%), circum-aortic renal veins (7.1%) and retro-aortic vein (3.6%). The sensitivity and specificity of multiple arterial anomalies were 91.7% and 97.7%, respectively. The sensitivity and specificity of multiple venous anomalies were 85.7% and 97.6%, respectively.Conclusion: MDCT is valuable for detection of renal vascular anomalies.", "num_citations": "2\n", "authors": ["141"]}
{"title": "A modified PSO technique for electrical engineering applications\n", "abstract": " PSO is a promising optimization technique proved a high performability as an\u00a0evolutionary algorithm. Sometimes the conversion of that algorithm is not faster enough\u00a0because the PSO initial setting values of that algorithm are chosen randomly and varies\u00a0as long as the domain of application is varied. By means of classic PSO does not care\u00a0about the limits of those random initial values which impacts the computation time. This\u00a0paper presents a proposed approach that could be used to modify PSO technique which\u00a0adapts the PSO initial values and number of particles for any optimization problem. The\u00a0proposed modification makes the PSO technique faster and more applicable for\u00a0electrical online applications. In most electrical applications, time factor is very\u00a0important especially for on line applications. Protective devices coordination problem is\u00a0a tedious and a time consuming task. To tackle that point of research, one of two cases\u00a0has to be taken. First case is to redesign the coordination system according to any\u00a0system changes. The second one is to maintain the old coordination system unchanged\u00a0up to a specific DG penetration level. The new approach is used to solve the protective\u00a0devices coordination problem in presence of DG in the two cases. A comparison\u00a0between the classic PSO and the proposed modified one shows that the new approach\u00a0gives fast results and shortens the computation time.", "num_citations": "2\n", "authors": ["141"]}
{"title": "Implementation and Evaluation of POV-Ray on Desktop Grids: Parallel Rendering of 3D Images and Animations\n", "abstract": " This paper discusses the implementation details of a grid-based rendering framework for POV-Ray on desktop grids. Our goal is to present how enterprises can build desktop grids in Windows environment in order to enable semi-real time rendering for 3D models, both images and animations, defined with POV-Ray. Algorithms, code and technical details are given for easy and efficient implementations. We think this work could be useful for both researchers and developers who are interested in the grid computing technology and its applications.", "num_citations": "2\n", "authors": ["141"]}
{"title": "Sixty-four multi-slice computed tomography and magnetic resonance imaging in evaluation of hepatic focal lesions\n", "abstract": " ObjectiveThe diagnostic accuracy of MSCT and MRI for evaluation of hepatic focal lesions.DesignAn analytic comparative study.SettingRadiology Department, Farwania Hospital.SubjectsNinety-five hepatic focal lesions, 61 patients were examined from October 2006 to March 2010. Gold standard was biopsy, radiological and clinical follow up.Main outcomeThe value of CT and MRI in characterizing these lesions was assessed.ResultsThe mean sensitivity of MRI was (72.5%) and CT (72.6%) in the detection of overall hepatic focal lesions. However, the positive predictive value for MRI was 96.1% and for CT was 91.5%. False negative results were the problem of MRI and CT in lesions \u2a7d2\u00a0cm (33.8% and 30.5%, respectively). About lesion characterization, MRI was relatively highly specific for diagnosis of HCC (87.5%), hemangioma (91.2%) and metastases (87.8%).ConclusionAn analytic comparative study.", "num_citations": "2\n", "authors": ["141"]}
{"title": "A general PSO modification for electrical applications\n", "abstract": " Particle swarm optimization technique (PSO) is a promising evolutionary technique. Setting initial values of that technique depend on every domain of application. These values are chosen randomly in classic PSO technique which increases the computation time. This paper presents a new approach to modify PSO based on a prediction technique to determine the PSO initial values and number of particles for each optimization problem. The proposed modification makes the PSO technique faster and more applicable for electrical online applications. The new approach is used to solve the protective devices coordination problem by choosing the optimum initial values for the coordination domain. A comparison between the classic PSO and the proposed modified one shows that the new approach gives fast results and shortens the computation time.", "num_citations": "2\n", "authors": ["141"]}
{"title": "Lightweight TCP/IP architecture model for embedded systems using sysML\n", "abstract": " Embedded systems are usually suffering from limited resources which require a modified architecture of software to take the best usage of the resources. TCP/IP is the most important communication protocol for networked embedded systems which provide internet connectivity for hosts. Many of TCP/IP development for embedded systems lack system modeling, analysis and design.", "num_citations": "2\n", "authors": ["141"]}
{"title": "E-Learning system for deaf arab students\n", "abstract": " This paper presents an e-Learning System (LS) which offers Arabic Sign Language (ArSL) in correspondence to the text in the learning environment. The system is designed ably for deaf adults for the purpose of their lifelong learning. In the LS, the special needs of deaf learners are satisfied, eg bilingual information (Arabic text and Arabic sign language), high level of visualization and interactive and explorative learning. The basic objective of our e-learning system is the support of the equal rights of deaf people for their access to the education and training.", "num_citations": "2\n", "authors": ["141"]}
{"title": "Migrating Web Applications\n", "abstract": " Web application development frameworks like the Java Server Pages framework (JSP), provide web applications with essential functions such as maintaining state information across the application and access control. In the fast paced world of web applications, new frameworks are introduced and old ones are updated frequently. A framework is chosen during the initial phases of the project and changing it to match the new requirements and demands is a cumbersome task.We propose an approach to migrate web applications between various web development frameworks. This migration process preserves the structure of the code and the location of comments to ease future manual maintenance of the migrated code. Developers can move their applications to the framework that meets their current needs instead of being locked into their initial development framework. We give an example of using our approach to migrate a web application written using Active Server Pages (ASP) framework to Netscape Server Pages (NSP) framework.", "num_citations": "2\n", "authors": ["141"]}
{"title": "Association of apolipoprotein E variation with cognitive impairment across multiple neurodegenerative diagnoses\n", "abstract": " For many years there has been uncertainty regarding how apolipoprotein E (APOE) E2 and E4 variants may influence overlapping features of neurodegeneration, such as cognitive impairment. We aimed to identify whether the APOE variants are associated with cognitive function across various neurodegenerative and cerebrovascular diagnoses (n\u00a0=\u00a0513). Utilizing a comprehensive neuropsychology battery, multivariate multiple regression was used to assess the influence of APOE carrier status and disease cohort on performance across five cognitive domains. Irrespective of disease cohort, E4 carriers had significantly lower performance in verbal memory and visuospatial domains than those with E3/3, while E2 carriers\u2019 cognitive performance was not significantly different. However, E2 carriers with frontotemporal dementia (FTD) performed significantly worse than those with E3/3 in the attention/working memory\u00a0\u2026", "num_citations": "1\n", "authors": ["141"]}
{"title": "An automated essay grading framework based on neural networks (dept. E)\n", "abstract": " This paper presents a proposed framework depending on Artificial Neural Networks (ANN) that enhances the process of assessing student's essays in order to save the line and cost of manual scoring of these essays. This framework consists of five phases and the UML model of that framework is defined. Also the activity diagrams of that system are explained. During the learning algorithm phase, the network trained on a set of pre-graded student responses by teachers and then a set of essays not used in the training are introduced to a 10 tie network to judge the essay. The proposed framework was tested on case study and presents good results compared 10 a previously published work using the same case study with another\u00a0technique.", "num_citations": "1\n", "authors": ["141"]}
{"title": "Remote Monitoring of Distributed Generation Resources Using Redundant System (Dept. E)\n", "abstract": " As the number and diversity of Distributed Generation (DG) on the grid increases, dispatching these resources at the right time and accounting correctly for the flow of energy become complex problems that require reliable monitoring. There is urgent need for methods of efficient and reliable monitoring and control for such sources,\u00a0 Traditional Supervisory Control and Data Acquisition (SCADA) systems with centralized control rooms, dedicated communication lines, and specialized operators, are not cost effective to handle a large number of DG resources spread over the grid. The Internet provides a convenient point-to-point communication network that replaces dedicated telephone lines. Inexpensive computers equipped with suitable communication and control software manage the distributed resources. A clever new monitoring system to ensure a proper interface between the DGs and the electric utility system will be essential for DG. Such monitoring could need to communicate with the utility to provide the DGs information. Most importantly, they must be fast and reliable to ensure the system runs safely,\u00a0 In that research, the authors proposed a monitoring system which could collect all needed data of DG. This system is based on the concept of redundant communication and redundant display of all information of DGs locally or remotely. The proposed system is designed using GSM as wireless communication and an internet over telephone line as a wired communication to create redundant communication,", "num_citations": "1\n", "authors": ["141"]}
{"title": "ConfigMiner: Identifying the Appropriate Configuration Options for Config-related User Questions by Mining Online Forums\n", "abstract": " While the behavior of a software system can be easily changed by modifying the values of a couple of configuration options, finding one out of hundreds or thousands of available options is, unfortunately, a challenging task. Therefore, users often spend a considerable amount of time asking and searching around for the appropriate configuration options in online forums such as StackOverflow. In this paper, we propose ConfigMiner, an approach to automatically identify the appropriate option(s) to config-related user questions by mining already-answered config-related questions in online forums. Our evaluation on 2,061 config-related user questions for seven software systems shows that ConfigMiner can identify the appropriate option(s) for a median of 83% (up to 91%) of user questions within the top-20 recommended options, improving over state-of-the-art approaches by a median of 130%. Besides, ConfigMiner\u00a0\u2026", "num_citations": "1\n", "authors": ["141"]}
{"title": "Hepatic and Renal Protective Effects of Annona muricata Leaf and Fruit Extracts on Ehrlich Ascites Carcinoma in Mice\n", "abstract": " Cancer is a complicated disease incorporating many factors and causes which could be environmental, metabolic disorder, chemical, and genetic alteration. Many of the already used anticancer therapies are derivatives of natural sources including herbs. The current study was designed to assess the antitumor activity of Egyptian Annona muricata against Ehrlich ascites carcinoma (EAC) in albino mice which induced by intraperitoneal injection with EAC cells (2\u00d7106 cells/mouse). Eighty-eight female adult albino mice were utilized in the beginning of the current study and were separated into five groups, normal control, Ehrlich ascites carcinoma, fruit extract (200 mg/kg), leaf extract (200 mg/kg), and cisplatin (2 mg/kg) treated groups for nine successive days after 48 hours of pre-injection with EAC cells. Viability of tumor ascites cells, the volume of ascites fluid, and EAC cell count were significantly decreased after daily treatment with both extracts. Hematological parameters were enhanced, liver enzymes and creatinine regain their normal values. Oxidative stress was dimensioned via decreasing of lactate dehydrogenase (LDH) and malondialdehyde (MDA). Antioxidant activity was enhanced through the increasing of the total antioxidant capacity (TAC) and reduced glutathione (GSH) concentrations, and the activities of superoxide dismutase (SOD) and catalase (CAT). Histopathologically, residual tumor growth on the outer surface of the liver and kidney were markedly reduced without infiltration onto the tissues. Inflammation of tissues was inhibited and tissue architecture was ameliorated. In conclusion, Annona extracts could have anticancer\u00a0\u2026", "num_citations": "1\n", "authors": ["141"]}
{"title": "Computing device with environment aware features\n", "abstract": " An electronic device is provided which automatically adjusts settings based on the environment of the electronic device. The settings of the electronic device which are adjusted may be security settings, filter settings, or status for instant messaging in dependence on the determined location of the electronic device.", "num_citations": "1\n", "authors": ["141"]}
{"title": "Software engineering in a data science future (keynote)\n", "abstract": " Summary form only given, as follows. The complete presentation was not made available for publication as part of the conference proceedings. Machine Learning (ML) advances continue to be headline news. Enormous investments are being poured into Data Science (DS) and Artificial intelligence (AI) initiatives worldwide. Hiring managers are turning every rock looking for ML, DS, and AI experts and even novices! Forbes proclaims software engineers will be replaced by deep learners in the not so distant future. In this talk I will highlight the crucial role of Software Engineering (SE) in this ML/DS/AI future. I will follow it up with a critical look at many of the challenges and risks that such sophisticated advances bring to software research and practice.", "num_citations": "1\n", "authors": ["141"]}
{"title": "Harmonic reduction for grid-connected photovoltaic system based on multilevel inverter\n", "abstract": " This paper investigates the utilization of Multilevel Inverter (MLI) to reduce the harmonics of grid-connected photovoltaic (PV) system. MLIs act as a promising interface in medium voltage networks for many usages because their modularity and lower voltage stress towards the switches. In addition, they provide a high-form output with low symmetric deformation. It is proposed to use a Cascaded H-Bridge MLI (CHB-MLI) with network-linked PV systems since they require many sources on the DC side with phaseshifted carriers pulse width modulation. The mission of these converts is to synthesize a staircase AC output voltage from several DC voltage levels. A seven-level modular CHB-MLI is analyzed for grid-connected PV system with a Maximum Power Point Tracking (MPPT) algorithm. A free from outside control dc-link voltage controller for each H-bridge is performed by managing a battery system to maintain constant voltage and satisfy the grid-connected power. The simulation results ensure the validity and effectiveness of the introduced algorithm.", "num_citations": "1\n", "authors": ["141"]}
{"title": "Computing device with environment aware features\n", "abstract": " An electronic device is provided which automatically adjusts settings based on the environment of the electronic device. The settings of the electronic device which are adjusted may be security settings, filter settings, or status for instant messaging in dependence on the determined location of the electronic device.", "num_citations": "1\n", "authors": ["141"]}
{"title": "Methods to control fin tip placement\n", "abstract": " A method includes providing a semiconductor structure having a substrate including a longitudinally extending plurality of fins formed thereon. A target layout pattern is determined, which overlays active areas devices disposed on the fins. The target layout pattern includes a first group of sections overlaying devices having more fins than adjacent devices and a second group of sections overlaying devices having less fins than adjacent devices. A first extended exposure pattern is patterned into the structure, and includes extensions that extend sections of the first group toward adjacent sections of the first group. A second extended exposure pattern is patterned into the structure, and includes extensions that extend sections of the second group toward adjacent sections of the second group. Portions of the first and second extended exposure patterns are combined to form a final pattern overlaying the same active\u00a0\u2026", "num_citations": "1\n", "authors": ["141"]}
{"title": "Self-Assisted Upper Limb Rehabilitation Devices, A Comprehensive Review\n", "abstract": " For the purpose of Upper Limb rehabilitation, the use of mechanical and robot assisted rehabilitation therapies are not a new concept. Such systems allow patients to perform therapies with minimal or no assistance. The complexity of such systems vary from being as simple as a custom made bars to highly sophisticated robotic exoskeletons. The advancement of robotics and motor control mechanisms has fuelled interest in this domain and we see a lot of development in the field of robot assisted rehabilitation with in a comparatively short span of time. This paper presents a review and tabulates the results of a few selected rehabilitation devices. The devices include mechanical as well as intelligent robotics based rehabilitation devices.", "num_citations": "1\n", "authors": ["141"]}
{"title": "Three-phase matrix converter based sliding mode controller applied to wind energy conversion system with wind speed estimation\n", "abstract": " This paper presents comprehensive modelling ofWind Energy Conversion System (WECS) based on interfacing a Permanent Magnet Synchronous Generator (PMSG) to the utility grid by using the direct AC/AC matrix converter. To estimate the wind velocity and extracts the maximum power at all wind velocities Wind speed estimation control technique is presented based on sliding mode control. Sliding mode controller has many advantages such as fast transient response and robustness against system parametric variations and unknown external disturbances. The matrix converter controls the maximum power point tracking MPPT by adjusting the PMSG terminal frequency, and hence, the shaft speed. In addition, the matrix converter controls the grid injected current to be in-phase with the grid voltage for the unity power factor. Space Vector Modulation is used to generate the PWM signals of the matrix converter switches. The system dynamic performance is investigated using Matlab/Simulink.", "num_citations": "1\n", "authors": ["141"]}
{"title": "Does geographical distance effect distributed development teams: How aggregation bias in software artifacts causes contradictory findings\n", "abstract": " Does geographic distance affect distributed software development teams? Researchers have been mining software artifacts to find evidence that geographic distance between software team members introduces delay in communication and deliverables. While some studies found that geographical distance negatively impacts software teams, other studies dispute this finding. It has been speculated that various confounding factors are the reason for the contradicting findings. For example, newer tools and practices that enable team members to communicate and collaborate more effectively, might have negated the effects of distance in some studies. In this study, we examine an alternate theory to explain the contradicting findings: the different aggregations of the software artifacts used in past studies. We call this type of bias: the aggregation bias. We replicated the previous studies on detecting the evidence of delay\u00a0\u2026", "num_citations": "1\n", "authors": ["141"]}
{"title": "UNREAMED TIBIAL NAILING FOR OPEN FRACTURE TIBIAL SHAFT\n", "abstract": " Background: Unreamed nails have revolutionized the treatment of tibial shaft fractures. However, authors reported high complications rate. The aim of the present study was to evaluate the unreamed tibial nailing for open fracture tibial shaft. Patients and methods: Between June 2013 and September 2014, a total of 26 cases of open tibial shaft fractures were operated on with unreamed interlocking nails. They were selected from Ghodran General Hospital (KSA); Al-Azhar University Hospital (New Damietta); and Al-Zahraa University Hospital (Cairo). Two patients were lost to follow-up. Thus, 24 patients (4 women and 20 men) were followed up for a mean period ranged from (10-12 months). Motor car accidents were the most common cause of fractures in studied patients. The patients\u2019 mean age was 30.58\u00b16.40 years (range, 21-42 years). There were 12 (50.0%) type-I, 6 (25.0%) type-II, 3 (12.5%) type-IIIA, and 3 (12.5%) type-IIIB fractures. Sixteen fractures were at mid-shaft level and 8 fractures were at the positions of either the upper one third or the lower one third of the tibia. All were operated using open fixation with unreamed intramedullary nailing. Results: delayed union was reported in 3 cases (12.5%); complications were in the form of early superficial wound infection in 3 cases (12.5%), infected non-union with osteomyelitis in 1 case (4.2%), knee stiffness in 1 case (4.2%), nail breakage in 1 case (4.2%), screw breakage in 1 case (4.2%) and no cases reported compartment syndrome. The overall results were excellent in 16 cases (66.7%), good in 4 cases (16.7%), poor in 1 case", "num_citations": "1\n", "authors": ["141"]}
{"title": "Generic Software risk management framework for SCADA system\n", "abstract": " Supervisory Control and Data Acquisition (SCADA) systems is one of important software systems which are used for monitoring and controlling industrial systems that are geographically spread over thousands of kilometers. These systems need to monitor and control so many field sites through thousands of devices that are varying in type, technology and usage. There are different types of people need to access SCADA systems for different purposes. Because of the sensitivity and spreading of these systems, they are vulnerable by hackers and crackers and there are many risks may causes partially or fully breakdown. To managing the SCADA systems, there are number of solutions that had been placed. These solutions varied from detecting one to more of SCADA system risk and assessed them on real system once it occurs. This way causes some damages could happen till the risk is eliminate or could need adaption that difficult or impossible to process.", "num_citations": "1\n", "authors": ["141"]}
{"title": "On Harnessing Desktop Grids for Semi-Real Time 3D Rendering: A Case Study on POV-Ray\n", "abstract": " As is known, 3D rendering puts a huge burden both on computers and artists/programmers. This task is usually slow and requires the use of computational clusters as well as the installation of expensive resources such as multi-processors/cores and optimized graphics processing units to the traditional computers to lessen this burden. Parallelizing the rendering task of complex frames and scenes can cut the total rendering time dramatically. Grid computing is one of the parallel computing paradigms that allow implementers to combine the power of networked computers into a virtual supercomputer. Desktop grids are a form of grid computing that allows enterprises to build grids out of the workstations they already have. This feature could enable enterprises to better utilize their computing resources in order to solve computationally-intensive problems in a quick and costeffective manner. The purpose of this paper is to present how enterprises can build desktop grids in a Windows environment in order to enable semi-real time rendering for 3D models defined with POV-Ray. Algorithms, tools and technical details are presented for easy and efficient implementations.", "num_citations": "1\n", "authors": ["141"]}
{"title": "Design and Implementation of Total Quality Assurance Management System for Universities\n", "abstract": " Quality management standards are seen as a major pillar supporting the drive for continuous quality improvement through total quality management. Planning brings to decision making the capability of being proactive and thus anticipate future events and the necessary actions to meet those events positively. Reaching high level of Quality Assurance (QA) has become an essential goal for educational institutes. Therefore, we have to construct an intelligent computer-based system to manage the quality standards and the evaluation processes within universities. Having such a system will prevent a lot of burden on resident quality in any educational institution. The main objective of this paper is to provide a description of a framework for a total quality assurance management system (TQAMS). This can help the quality evaluator to evaluate the performance of an educational institution without effort, automatically, and without time loss. Full schematic UML charts of the proposed system is given. Moreover, a comprehensive analysis of the system components is presented.", "num_citations": "1\n", "authors": ["141"]}
{"title": "Microleakage and surface hardness of resin based restorative materials cured with led and QTH curing units\n", "abstract": " \u259e ABSTRACTLight-emitting diode, or LED, technology provides certain advantages over halogenbased light polymerization of resin-based composites. Methods: The halogen-based light curing units (Optilux Radiometer Model 100, SDS Kerr; Donbury, CT, USA) and", "num_citations": "1\n", "authors": ["141"]}
{"title": "Dry face milling of titanium alloys\n", "abstract": " In machining titanium alloys, cutting tools generally wear out very rapidly because of the high cutting temperature resulted from the low thermal conductivity and density of the work material. In order to increase the tool life, it is necessary to suppress the cutting heat as much as possible by applying an abundant amount of coolant, but this will entail serious tecbno-environmental and biological problems. To study the performance and avoid these limitations, a PVD-coated insert was used to the dry face mill of (a+\u03b2) titanium alloys. As a result it was found that the inserts exhibit an excellent cutting performance at low cutting speeds and feed rates, and there is no significant difference in the dominant insert failure mode between the wet and dry cutting in discontinuous cutting.", "num_citations": "1\n", "authors": ["141"]}
{"title": "A Visual Architectural Approach to Maintaining Web Applications\n", "abstract": " Web applications are complex software systems which contain a rich structure with many relations between their components. Web developers are faced with many challenges when they need to gain a better understanding of these applications to maintain or evolve them. Current development tools focus primarily on implementation, with little support for the application\u2019s evolution. Web developers need tools to assist in the evolution and maintenance of web applications.We present an approach to assist developers in understanding the structure of their web application. A set of parsers analyze the source code and pages of the web application to produce box-and-arrow architecture diagrams of the application. Using these diagrams developers can see the interactions between the various components in their application. They can also perform impact analysis studies on the application\u2019s architecture. The approach is flexible and can be re-targeted to analyze applications developed using the various current and future web technologies.", "num_citations": "1\n", "authors": ["141"]}