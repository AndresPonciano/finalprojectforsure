{"title": "Software engineering for the internet of things\n", "abstract": " No consolidated set of software engineering best practices for the Internet of Things (IoT) has yet emerged. Too often, the landscape resembles the Wild West, with unprepared programmers putting together IoT systems in ad hoc fashion and throwing them out into the market, often poorly tested. In addition, the academic sector is in danger of fragmenting into specialized, often unrelated research areas. This IEEE Software theme issue aims to help provide the basis for a set of best practices that will guide the industry through the challenges of software engineering for the IoT", "num_citations": "60\n", "authors": ["239"]}
{"title": "Data consistency management\n", "abstract": " A data consistency management system may include a memory storing machine readable instructions to receive a query, and determine a suitability of the query for processing by a NoSQL data store, or a RDBMS. The memory may further include machine readable instructions to rank data tables based on a combination of read queries and query patterns suitable for the NoSQL data store. Based on the ranking, the memory may further include machine readable instructions to determine data tables that are to be managed by the NoSQL data store, or by the RDBMS, determine whether the query is for a data table managed by the NoSQL data store, and based on a determination that the query is for a data table managed by the NoSQL data store, translate the query to NoSQL API calls for using the NoSQL data store to respond to the query.", "num_citations": "24\n", "authors": ["239"]}
{"title": "RUGRAT: Evaluating program analysis and testing tools and compilers with large generated random benchmark applications\n", "abstract": " Benchmarks are heavily used in different areas of computer science to evaluate algorithms and tools. In program analysis and testing, open\u2010source and commercial programs are routinely used as benchmarks to evaluate different aspects of algorithms and tools. Unfortunately, many of these programs are written by programmers who introduce different biases, not to mention that it is very difficult to find programs that can serve as benchmarks with high reproducibility of results. We propose a novel approach for generating random benchmarks for evaluating program analysis and testing tools and compilers. Our approach uses stochastic parse trees, where language grammar production rules are assigned probabilities that specify the frequencies with which instantiations of these rules will appear in the generated programs. We implemented our tool for Java and applied it to generate a set of large benchmark\u00a0\u2026", "num_citations": "16\n", "authors": ["239"]}
{"title": "Linked enterprise data model and its use in real time analytics and context-driven data discovery\n", "abstract": " Traditional approaches for managing enterprise data revolve around a batch driven Extract Transform Load process, a one size fits all approach for storage, and an application architecture that is tightly coupled to the underlying data infrastructure. The emergence of Big Data technologies have led to the creation of alternate instantiations of the traditional approach, one where the storage systems have moved from relational databases to NoSQL technologies like HDFS. This approach to data management has been found wanting as enterprises begin to deal with complex and heterogeneous data, especially in the area of Internet of Things (IoT). IoT environments are characterized by data producers and data processing requirements. In this paper, we articulate the shortcomings of traditional approaches to data management in the context of IoT. We identify the challenges brought forth due to content heterogeneity\u00a0\u2026", "num_citations": "15\n", "authors": ["239"]}
{"title": "Testing framework for policy-based workflows\n", "abstract": " A system comprehensively tests each feasible path in a policy-based Extensible Markup Language (XML) workflow. The system may receive an input workflow and parse workflow (or proxy code of the workflow) to construct a policy control flow graph. The system may identify paths in the policy control flow graph, such as each feasible path in the policy control flow graph. The system may determine path constraints for the identified paths, where the path constraints identify path conditions for traversing the identified path in the policy control flow graph. Then, the system may generate a set of test inputs for the workflow using the path constraints that, when input into the policy-based XML workflow, cause the workflow to traverse the identified paths.", "num_citations": "13\n", "authors": ["239"]}
{"title": "Evaluating program analysis and testing tools with the RUGRAT random benchmark application generator\n", "abstract": " Benchmarks are heavily used in different areas of computer science to evaluate algorithms and tools. In program analysis and testing, open-source and commercial programs are routinely used as bench-marks to evaluate different aspects of algorithms and tools. Unfor-tunately, many of these programs are written by programmers who introduce different biases, not to mention that it is very difficult to find programs that can serve as benchmarks with high reproducibil-ity of results. We propose a novel approach for generating random benchmarks for evaluating program analysis and testing tools. Our approach uses stochastic parse trees, where language grammar production rules are assigned probabilities that specify the frequencies with which instantiations of these rules will appear in the generated pro-grams. We implemented our tool for Java and applied it to generate benchmarks with which we evaluated\u00a0\u2026", "num_citations": "10\n", "authors": ["239"]}