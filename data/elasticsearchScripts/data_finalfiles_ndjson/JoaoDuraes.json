{"title": "Emulation of software faults: A field data study and a practical approach\n", "abstract": " The injection of faults has been widely used to evaluate fault tolerance mechanisms and to assess the impact of faults in computer systems. However, the injection of software faults is not as well understood as other classes of faults (e.g., hardware faults). In this paper, we analyze how software faults can be injected (emulated) in a source-code independent manner. We specifically address important emulation requirements such as fault representativeness and emulation accuracy. We start with the analysis of an extensive collection of real software faults. We observed that a large percentage of faults falls into well-defined classes and can be characterized in a very precise way, allowing accurate emulation of software faults through a small set of emulation operators. A new software fault injection technique (G-SWFIT) based on emulation operators derived from the field study is proposed. This technique consists of\u00a0\u2026", "num_citations": "380\n", "authors": ["481"]}
{"title": "On fault representativeness of software fault injection\n", "abstract": " The injection of software faults in software components to assess the impact of these faults on other components or on the system as a whole, allowing the evaluation of fault tolerance, is relatively new compared to decades of research on hardware fault injection. This paper presents an extensive experimental study (more than 3.8 million individual experiments in three real systems) to evaluate the representativeness of faults injected by a state-of-the-art approach (G-SWFIT). Results show that a significant share (up to 72 percent) of injected faults cannot be considered representative of residual software faults as they are consistently detected by regression tests, and that the representativeness of injected faults is affected by the fault location within the system, resulting in different distributions of representative/nonrepresentative faults across files and functions. Therefore, we propose a new approach to refine the\u00a0\u2026", "num_citations": "210\n", "authors": ["481"]}
{"title": "Emulation of software faults by educated mutations at machine-code level\n", "abstract": " This paper proposes a new technique to emulate software faults by educated mutations introduced at the machine-code level and presents an experimental study on the accuracy of the injected faults. The proposed method consists of finding key programming structures at the machine code-level where high-level software faults can be emulated. The main advantage of emulating software faults at the machine-code level is that software faults can be injected even when the source code of the target application is not available, which is very important for the evaluation of COTS components or for the validation of software fault tolerance techniques in COTS based systems. The technique was evaluated using several real programs and different types of faults and, additionally, it includes our study on the key aspects that may impact on the technique accuracy. The portability of the technique is also addressed. The\u00a0\u2026", "num_citations": "67\n", "authors": ["481"]}
{"title": "Characterization of operating systems behavior in the presence of faulty drivers through software fault emulation\n", "abstract": " This paper proposes a practical way to evaluate the behavior of commercial-off-the-shelf (COTS) operating systems in the presence of faulty device drivers. The proposed method is based on the emulation of software faults in target device drivers and the observation of the behavior of the system and of a workload regarding a comprehensive set of failure modes analyzed according to different dimensions. The emulation of software faults itself is done through the injection at machine-code level of selected mutations that represent the code produced when typical programming errors are made in the high-level language code. An important aspect of the proposed methodology is the use of simple and established practices to evaluate operating systems failure modes, thus allowing its use as a dependability benchmarking technique. The generalization of the methodology to any software system built of discrete and\u00a0\u2026", "num_citations": "66\n", "authors": ["481"]}
{"title": "Experimental risk assessment and comparison using software fault injection\n", "abstract": " One important question in component-based software development is how to estimate the risk of using COTS components, as the components may have hidden faults and no source code available. This question is particularly relevant in scenarios where it is necessary to choose the most reliable COTS when several alternative components of equivalent functionality are available. This paper proposes a practical approach to assess the risk of using a given software component (COTS or non-COTS). Although we focus on comparing components, the methodology can be useful to assess the risk in individual modules. The proposed approach uses the injection of realistic software faults to assess the impact of possible component failures and uses software complexity metrics to estimate the probability of residual defects in software components. The proposed approach is demonstrated and evaluated in a comparison\u00a0\u2026", "num_citations": "63\n", "authors": ["481"]}
{"title": "Injection of faults at component interfaces and inside the component code: are they equivalent?\n", "abstract": " The injection of interface faults through API parameter corruption is a technique commonly used in experimental dependability evaluation. Although the interface faults injected by this approach can be considered as a possible consequence of actual software faults in real applications, the question of whether the typical exceptional inputs and invalid parameters used in these techniques do represent the consequences of software bugs is largely an open issue. This question may not be an issue in the context of robustness testing aimed at the identification of weaknesses in software components. However, the use of interface faults by API parameter corruption as a general approach for dependability evaluation in component-based systems requires an in depth study of interface faults and a close observation of the way internal component faults propagate to the component interfaces. In this paper we present the\u00a0\u2026", "num_citations": "61\n", "authors": ["481"]}
{"title": "Multidimensional characterization of the impact of faulty drivers on the operating systems behavior\n", "abstract": " This paper presents the results of a continuing research work on the practical characterization of operating systems (OS) behavior in the presence of software faults in OS components, such as faulty device drivers. The methodology used is based on the emulation of software faults in device drivers and observation of the behavior of the overall system regarding a comprehensive set of failure modes, analyzed according to different dimensions related to multiple user perspectives. The emulation of the software faults is done through the injection of specific mutations at machine-code level that reproduce the code generated by compilers when typical programming errors occur in the high level language code. Two important aspects of this methodology are the independence of source code availability and the use of simple and established practices to evaluate operating systems failure modes, thus allowing its use as a\u00a0\u2026", "num_citations": "50\n", "authors": ["481"]}
{"title": "Generic Faultloads Based on Software Faults for Dependability Benchmarking.\n", "abstract": " The most critical component of a dependability benchmark is the faultload, as it should represent a repeatable, portable, representative, and generally accepted set of faults. These properties are essential to achieve the desired standardization level required by a dependability benchmark but, unfortunately, are very hard to achieve. This is particularly true for software faults, which surely accounts for the fact that this important class of faults has never been used in known dependability benchmark proposals. This paper proposes a new methodology for the definition of faultloads based on software faults for dependability benchmarking. Faultload properties such as repeatability, portability and scalability are also analyzed and validated through experimentation using a case study of dependability benchmarking of web-servers. We concluded that software fault-based faultloads generated using our methodology are appropriate and useful for dependability benchmarking. As our methodology is not tied to any specific software vendor or platform, it can be used to generate faultloads for the evaluation of any software product such as OLTP systems.", "num_citations": "47\n", "authors": ["481"]}
{"title": "The role of the insula in intuitive expert bug detection in computer code: an fMRI study\n", "abstract": " Software programming is a complex and relatively recent human activity, involving the integration of mathematical, recursive thinking and language processing. The neural correlates of this recent human activity are still poorly understood. Error monitoring during this type of task, requiring the integration of language, logical symbol manipulation and other mathematical skills, is particularly challenging. We therefore aimed to investigate the neural correlates of decision-making during source code understanding and mental manipulation in professional participants with high expertise. The present fMRI study directly addressed error monitoring during source code comprehension, expert bug detection and decision-making. We used C code, which triggers the same sort of processing irrespective of the native language of the programmer. We discovered a distinct role for the insula in bug monitoring and\u00a0\u2026", "num_citations": "39\n", "authors": ["481"]}
{"title": "WAP: understanding the brain at software debugging\n", "abstract": " We propose that understanding functional patterns of activity in mapped brain regions associated with code comprehension tasks and, more specifically, to the activity of finding bugs in traditional code inspections could reveal useful insights to improve software reliability and to improve the software development process in general. This includes helping to select the best professionals for the debugging effort, improving the conditions for code inspections, and identify new directions to follow for training code reviewers. This paper presents an interdisciplinary study to analyze the brain activity during code inspection tasks using functional magnetic resonance imaging (fMRI), which is a well-established tool in cognitive neuroscience research. We used several programs where realistic bugs representing the most frequent types of software faults found in the field were injected. The code inspectors involved in the\u00a0\u2026", "num_citations": "35\n", "authors": ["481"]}
{"title": "Representativeness analysis of injected software faults in complex software\n", "abstract": " Despite of the existence of several techniques for emulating software faults, there are still open issues regarding representativeness of the faults being injected. An important aspect, not considered by existing techniques, is the non-trivial activation condition (trigger) of real faults, which causes them to elude testing and remain hidden until operation. In this paper, we investigate how the representativeness of injected software faults can be improved regarding the representativeness of triggers, by proposing a set of generic criteria to select representative faults from afaultload. We used the G-SWFIT technique to inject software faults in a DBMS, resulting in over 40 thousands faults and 2 million runs of a real test suite. We analyzed faults with respect to their triggers, and concluded that a non-negligible share (15%) would not realistically elude testing. Our proposed criteria decreased the percentage of non-elusive\u00a0\u2026", "num_citations": "31\n", "authors": ["481"]}
{"title": "A methodology for the automated identification of buffer overflow vulnerabilities in executable software without source-code\n", "abstract": " This paper presents a methodology for the automated detection of buffer overflow vulnerabilities in executable software. Buffer overflow exploitation has been used by hackers to breach security or simply to crash computer systems. The mere presence inside the software code of a vulnerability that allows for buffer overflow exploitations presents a serious risk. So far, all methodologies devised to mitigate this problem assume source code availability or prior knowledge on vulnerable functions. Our methodology removes this dependency and allows the analysis of executable code without any knowledge about its internal structure. This independence is fundamental for relevant scenarios such as COTS selection during system integration (for which source code is usually not available), and the definition of attackloads for dependability benchmarking.", "num_citations": "19\n", "authors": ["481"]}
{"title": "Security benchmarks for web serving systems\n", "abstract": " The security of software-based systems is one of the most difficult issues when accessing the suitability of systems to most application scenarios. However, security is very hard to evaluate and quantify, and there are no standard methods to benchmark the security of software systems. This work proposes a novel methodology for benchmarking the security of software-based systems. This methodology uses the notion of risk in a quantifiable way and allows the comparison of functionally-equivalent systems (or different configurations of the same system) to enable users and system integrators to identify and select the most secure one. The benchmark methodology is based on both analytical and experimental steps and can be applicable to any software system. The benchmark procedures and rules guide users on how to instantiate the methodology to specific scenarios and how to execute the benchmark. In this\u00a0\u2026", "num_citations": "17\n", "authors": ["481"]}
{"title": "Component-based software certification based on experimental risk assessment\n", "abstract": " Third-party software certification should attest that the software product satisfies the required confidence level according to certification standards such as ISO/IEC 9126, ISO/IEC 14598 or ISO/IEC 25051. In many application areas, especially in mission-critical applications, certification is essential or even mandatory. However, the certification of software products using common off-the-shelf (COTS) components is difficult to attain, as detailed information about COTS is seldom available. Nevertheless, software products are increasingly being based on COTS components, which mean that traditional certification processes should be enhanced to take COTS into account in an effective way. This paper proposes a mean to help in the certification of component-based systems through an experimental risk assessment methodology based on fault injection and statistical analysis. Using the proposed methodology\u00a0\u2026", "num_citations": "15\n", "authors": ["481"]}
{"title": "Benchmarking the security of web serving systems based on known vulnerabilities\n", "abstract": " This paper proposes a methodology and a tool to evaluate the security risk presented when using software components or systems. The risk is estimated based on known vulnerabilities existing on the software components. An automated tool is used to extract and aggregate information on vulnerabilities reported by users and available on public databases (e.g., OSVDB and NVD). This tool generates comprehensive reports including the vulnerability type frequency, severity, exploitability, impact, and so on, and extracts correlations between aspects such as impact and representativeness, making possible the identification of aspects such as typical and worst impact for a given vulnerability. The proposed methodology, when applied to systems within the same class, enables buyers and system integrators to identify which system or component presents the lower security risk, helping them to select which system to\u00a0\u2026", "num_citations": "11\n", "authors": ["481"]}
{"title": "Pupillography as indicator of programmers' mental effort and cognitive overload\n", "abstract": " Our research explores a recent paradigm called Biofeedback Augmented Software Engineering (BASE) that introduces a strong new element in the software development process: the programmers' biofeedback. In this Practical Experience Report we present the results of an experiment to evaluate the possibility of using pupillography to gather biofeedback from the programmers. The idea is to use pupillography to get meta information about the programmers' cognitive and emotional states (stress, attention, mental effort level, cognitive overload,...) during code development to identify conditions that may precipitate programmers making bugs or bugs escaping human attention, and tag the corresponding code locations in the software under development to provide online warnings to the programmer or identify code snippets that will need more intensive testing. The experiments evaluate the use of pupillography as\u00a0\u2026", "num_citations": "10\n", "authors": ["481"]}
{"title": "A comparison between JAVA and PHP\n", "abstract": " Java and PHP are two of the most popular languages for web-oriented application. With different architectures and following different programming paradigms, they both fulfill the common needs for web-applications design. However, the differences between these languages may also have a measurable impact in several key aspects of the resulting applications, including performance and security. This study compares Java and PHP for web-application according to performance and security. Our results suggest that Java is more scalable and secure than PHP.", "num_citations": "10\n", "authors": ["481"]}
{"title": "Biofeedback augmented software engineering: monitoring of programmers' mental effort\n", "abstract": " This paper presents emergent experimental results showing that mental effort of programmers in code understanding tasks can be monitored through HRV (heart rate variability) using non-intrusive wearable devices. Results suggest that HRV is a good predictor for cognitive load when analyzing code and HRV results are consistent with the mental effort perceived by programmers using NASA-TLX. Furthermore, code complexity metrics do not correlate entirely with mental effort and do not seem a good indicator of the subjective perception of complexity felt by programmers. These first results are presented in the context of the project BASE-Biofeedback Augmented Software Engineering, which is briefly sketched, and proposes a radical neuroscience enabled approach to introduce biofeedback in software development.", "num_citations": "7\n", "authors": ["481"]}
{"title": "Evaluating and comparing the impact of software faults on web servers\n", "abstract": " The impact of software faults present in components to the larger system is currently a relevant and still open research topic. Web-based applications are simultaneously a relevant type of system for our society and are typically exposed to many software components in the server side. The impact of faults in these components to the web servers is an important aspect when evaluating the dependability properties of the entire web-serving system. This paper proposes an experimental approach to evaluate and compare the impact of software faults present in web applications on typical web servers. This approach consists in emulating realistic software faults in server-side web applications and monitoring the behavior of web server from both the server side (e.g., resource consumption) and the client side (e.g., response time, response correctness) perspective. We exemplify our methodology in case studies using\u00a0\u2026", "num_citations": "6\n", "authors": ["481"]}
{"title": "Spotting Problematic Code Lines using Nonintrusive Programmers' Biofeedback\n", "abstract": " Recent studies have shown that programmers' cognitive load during typical code development activities can be assessed using wearable and low intrusive devices that capture peripheral physiological responses driven by the autonomic nervous system. In particular, measures such as heart rate variability (HRV) and pupillography can be acquired by nonintrusive devices and provide accurate indication of programmers' cognitive load and attention level in code related tasks, which are known elements of human error that potentially lead to software faults. This paper presents an experimental study designed to evaluate the possibility of using HRV and pupillography together with eye tracking to identify and annotate specific code lines (or even finer grain lexical tokens) of the program under development (or under inspection) with information on the cognitive load of the programmer while dealing with such lines of\u00a0\u2026", "num_citations": "5\n", "authors": ["481"]}
{"title": "A field data study on the use of software metrics to define representative fault distribution\n", "abstract": " This paper evaluates the use of software complexity metrics to define representative fault distributions for software fault injection experiments. A field data study on more than 350 bug reports available from open software initiatives was used to compare the fault distributions generated by our approach with the real fault distributions observed in the field. Results show that the way we distribute software faults for fault injection is consistent with field observations when the size and complexity of the software modules are not very high. For very large modules the fault density observed are lower than the estimated by our approach. Possible explanations and improvements are discussed.", "num_citations": "5\n", "authors": ["481"]}
{"title": "An Arduino simulator in classroom-a case study\n", "abstract": " The Arduino Platform is increasingly being used as a central component in introductory programming courses of the curricula in middle, high school and even higher education. Given this scenario it is pertinent to understand how the cost-effectiveness, reliability and accessibility of this central component can be improved. We propose the use of an Arduino simulator to improve usability, cost, and class efficiency, allowing for improved and even new forms of use and course benefits. This paper presents and describes an Arduino simulator that we developed for education purposes, and a case study of its use in embedded programming courses from two high-schools. We compared its use against the usual use of real hardware platform analyzing usability, student workload and time efficiency. Our results, that we present and discuss, suggest that there are no apparent drawbacks in using the simulator, and some metrics such as basic exercise-solving efficiency and global effort showed an improvement.", "num_citations": "4\n", "authors": ["481"]}
{"title": "Faultloads based on software faults for dependability benchmarking\n", "abstract": " Faultloads based on software faults for dependability benchmarking | Estudo Geral Skip navigation PT EN Sign on to: Home Communities & Collections Research Outputs Researchers Organizations Projects Explore by Research Outputs Researchers Organizations Projects About About the repository University of Coimbra OA Policy FCT Policy Open Access Useful links Help How to deposit CreativeCommons FAQ's Provas Acad\u00e9micas 1.Estudo Geral 2.Faculdade de Ci\u00eancias e Tecnologia 3.Departamento de Engenharia Inform\u00e1tica 4.FCTUC Eng.Inform\u00e1tica - Teses de Doutoramento ESTUDO GERAL Reposit\u00f3rio cient\u00edfico da UC Home Communities & Collections Research Outputs Researchers Organizations Projects Explore by Research Outputs Researchers Organizations Projects About About the repository University of Coimbra OA Policy FCT Policy Open Access Useful links Help How to deposit FAQ's use : :/\u2026", "num_citations": "4\n", "authors": ["481"]}
{"title": "An Arduino Simulator for Practical Embedded Programming Teaching\n", "abstract": " Embedded systems are currently very relevant in many crucial aspects of modern society. Common daily-use objects are becoming smart, increasingly using micro controllers and embedded systems, and the IoT has amplified this tendency. In this context, the need for tools for training professionals for this type of systems is very relevant. Many courses address teaching programing for embedded systems using the Arduino platform. This platform offers many advantages but has inherent and unavoidable costs: component setup time, flash wear-out due to the many writes involved, wire connection issues and other electronic details not relevant for introduction to programing and so on. We propose the use of a simulator that completely replaces the need for the physical device in classes while keeping the typical development unchanged.This paper presents our Arduino simulator platform that we developed for\u00a0\u2026", "num_citations": "3\n", "authors": ["481"]}
{"title": "EEG monitoring during software development\n", "abstract": " This paper focuses on the analysis of experienced programmers\u2019 central nervous system response during a software development protocol. The main aim was to explore the neurological mechanisms (i.e., involved brain areas and rhythms) triggered by such a complex task. To do this, a 29-channel EEG signal was acquired on ten experienced programmers during a software development-like exercise. Then, the power spectral density at each EEG channel in standard Delta, Theta, Alpha and Beta bands has been computed and evaluated. The acquired subjects show on average a significant increase of Delta, Theta and Beta powers with respect to the baseline condition. Delta and Theta rhythms increase mostly in the frontal and parieto-occipital regions, while the Beta activity is more diffused. Furthermore, from the statistical analysis it emerged that the power increase in these three bands is significant in different\u00a0\u2026", "num_citations": "2\n", "authors": ["481"]}
{"title": "Virtualization technologies for arduino simulation\n", "abstract": " The Arduino platform is currently highly visible due to its ease of use and the growth of the Internet of Things (IoT). In this scenario it becomes useful and relevant the existence of a simulator for academic purposes that allows the introduction, dissemination and training in this platform with lower costs and increased reliability, durability and versatility of use. This paper presents a study on virtualization, simulation and emulation technologies, presenting a systematized view of the state of the art in this topic, allowing to identify the most appropriate techniques for the creation of an Arduino platform simulator in Java.", "num_citations": "2\n", "authors": ["481"]}
{"title": "Real-Time Quality Control of Heat Sealed Bottles Using Thermal Images and Artificial Neural Network\n", "abstract": " Quality control of heat sealed bottles is very important to minimize waste and in some cases protect people\u2019s health. The present paper describes a case study where an automated non invasive and non destructive quality control system was designed to assess the quality of the seals of bottles containing pesticide. In this case study, the integrity of the seals is evaluated using an artificial neural network based on images of the seals processed with computer vision techniques. Because the seals are not directly visible from the bottle exterior, the images are infrared pictures obtained using a thermal camera. The method is non invasive, automated, and can be applied to common conveyor belts currently used in industrial plants. The results show that the inspection process is effective in identifying defective seals with a precision of 98.6% and a recall of 100% and because it is automated it can be scaled up to large bottle processing plants. View Full-Text", "num_citations": "1\n", "authors": ["481"]}
{"title": "Can EEG Be Adopted as a Neuroscience Reference for Assessing Software Programmers\u2019 Cognitive Load?\n", "abstract": " An emergent research area in software engineering and software reliability is the use of wearable biosensors to monitor the cognitive state of software developers during software development tasks. The goal is to gather physiologic manifestations that can be linked to error-prone scenarios related to programmers\u2019 cognitive states. In this paper we investigate whether electroencephalography (EEG) can be applied to accurately identify programmers\u2019 cognitive load associated with the comprehension of code with different complexity levels. Therefore, a controlled experiment involving 26 programmers was carried. We found that features related to Theta, Alpha, and Beta brain waves have the highest discriminative power, allowing the identification of code lines and demanding higher mental effort. The EEG results reveal evidence of mental effort saturation as code complexity increases. Conversely, the classic software complexity metrics do not accurately represent the mental effort involved in code comprehension. Finally, EEG is proposed as a reference, in particular, the combination of EEG with eye tracking information allows for an accurate identification of code lines that correspond to peaks of cognitive load, providing a reference to help in the future evaluation of the space and time accuracy of programmers\u2019 cognitive state monitored using wearable devices compatible with software development activities. View Full-Text", "num_citations": "1\n", "authors": ["481"]}
{"title": "Software code complexity assessment using EEG features\n", "abstract": " This paper provides a study using Electroencephalography (EEG) to investigate the brain activity during code comprehension tasks. Three different code complexity levels according to five complexity metrics were considered. The use of EEG for this purpose is relevant, since the existing studies were mostly focused on neuroimaging techniques. Using Leave-One-Subject-Out cross-validation procedure for 30 subjects, it was found that the features related with the Gamma activity were the most common in all the folds. Regarding the brain regions, right parietal was the most frequent region contributing with more features. A Linear Discriminant Analysis Classifier for task classification, obtained a F-Measure of 92.71% for Code complexity easy, 52.25% for Code complexity intermediate and 53.13% for Code complexity advanced, revealing an evidence of mental effort saturation with the code complexity degree. This\u00a0\u2026", "num_citations": "1\n", "authors": ["481"]}
{"title": "Embedded programming bootcamp for career change\n", "abstract": " It is necessary to foster collaborations between academy and industrial partners, so that the set of skills and competences gained by the students are aligned with the needs of industry. Also, some areas are traditionally of scarce availability in the workforce market. One such area is embedded systems programming, due to the multidisciplinary nature of the required skills.To meet these challenges, a team of Electrical and Computer Science professors from ISEC collaborated with representants of industry to design and offer an intensive course (daylong classes during 6 months) with a narrow focus on embedded systems programming. Paid internships in several industrial partners are available to all students that successfully complete the course. The second edition of the course has recently concluded, with employers reporting students have met or exceeded expectations.", "num_citations": "1\n", "authors": ["481"]}