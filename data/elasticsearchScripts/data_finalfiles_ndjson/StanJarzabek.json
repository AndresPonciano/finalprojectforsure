{"title": "Detecting higher-level similarity patterns in programs\n", "abstract": " Cloning in software systems is known to create problems during software maintenance. Several techniques have been proposed to detect the same or similar code fragments in software, so-called simple clones. While the knowledge of simple clones is useful, detecting design-level similarities in software could ease maintenance even further, and also help us identify reuse opportunities. We observed that recurring patterns of simple clones - so-called structural clones - often indicate the presence of interesting design-level similarities. An example would be patterns of collaborating classes or components. Finding structural clones that signify potentially useful design information requires efficient techniques to analyze the bulk of simple clone data and making non-trivial inferences based on the abstracted information. In this paper, we describe a practical solution to the problem of detecting some basic, but useful\u00a0\u2026", "num_citations": "169\n", "authors": ["1057"]}
{"title": "A data mining approach for detecting higher-level clones in software\n", "abstract": " Code clones are similar program structures recurring in variant forms in software system(s). Several techniques have been proposed to detect similar code fragments in software, so-called simple clones. Identification and subsequent unification of simple clones is beneficial in software maintenance. Even further gains can be obtained by elevating the level of code clone analysis. We observed that recurring patterns of simple clones often indicate the presence of interesting higher-level similarities that we call structural clones. Structural clones show a bigger picture of similarity situation than simple clones alone. Being logical groups of simple clones, structural clones alleviate the problem of huge number of clones typically reported by simple clone detection tools, a problem that is often dealt with postdetection visualization techniques. Detection of structural clones can help in understanding the design of the system\u00a0\u2026", "num_citations": "162\n", "authors": ["1057"]}
{"title": "Efficient token based clone detection with flexible tokenization\n", "abstract": " Code clones are similar code fragments that occur at multiple locations in a software system. Detection of code clones provides useful information for maintenance, reengineering, program understanding and reuse. Several techniques have been proposed to detect code clones. These techniques differ in the code representation used for analysis of clones, ranging from plain text to parse trees and program dependence graphs. Clone detection based on lexical tokens involves minimal code transformation and gives good results, but is computationally expensive because of the large number of tokens that need to be compared. We explored string algorithms to find suitable data structures and algorithms for efficient token based clone detection and implemented them in our tool Repeated Tokens Finder (RTF). Instead of using suffix tree for string matching, we use more memory efficient suffix array. RTF incorporates a\u00a0\u2026", "num_citations": "160\n", "authors": ["1057"]}
{"title": "The case for user-centered CASE tools\n", "abstract": " Ivan Aaen discussed shortcomings of existing CASE tools and showed how they affect the adoption of CASE tools in [1]. The moral from his study is that CASE tools should offer some immediate benefits for the software developers, not just long-term advantages to the company. We should hope that future CASE tools will be more attractive to the developers. But what is it exactly that would make CASE tools more attractive to the developers? We believe CASE tools must address all the major elements that constitute a successful software project. These are software modeling and construction methods, software process, and representation of knowledge about real-world processes supported by software systems. Each of the elements has hard aspects (technique, documentation, and rigor) and soft aspects (creativity, problem solving) that a CASE tool should support. Current CASE tools are particularly weak in\u00a0\u2026", "num_citations": "141\n", "authors": ["1057"]}
{"title": "Effective software maintenance and evolution: A reuse-based approach\n", "abstract": " With software maintenance costs averaging 50% of total computing costs, it is necessary to have an effective maintenance program in place. Aging legacy systems, for example, pose an especially rough challenge as veteran programmers retire and their successors are left to figure out how the systems operate. This book explores program analyzers, reve", "num_citations": "99\n", "authors": ["1057"]}
{"title": "Beyond templates: a study of clones in the STL and some general implications\n", "abstract": " Templates (or generics) help us write compact, generic code, which aids both reuse and maintenance. The STL is a powerful example of how templates help achieve these goals. Still, our study of the STL revealed substantial, and in our opinion, counter-productive repetitions (so-called clones) across groups of similar class or function templates. Clones occurred, as variations across these similar program structures were irregular and could not be unified by suitable template parameters in a natural way. We encountered similar problems in other class libraries as well as in application programs, written in a range of programming languages. In the paper, we present quantitative and qualitative results from our study. We argue that the difficulties we encountered affect programs in general. We present a solution that can treat such template-unfriendly cases of redundancies at the meta-level, complementing and\u00a0\u2026", "num_citations": "97\n", "authors": ["1057"]}
{"title": "Eliminating redundancies with a\" composition with adaptation\" meta-programming technique\n", "abstract": " Redundant code obstructs program understanding and contributes to high maintenance costs. While most experts agree on that, opinions - on how serious the problem of redundancies really is and how to tackle it - differ. In this paper, we present the study of redundancies in the Java Buffer library, JDK 1.4.1, which was recently released by Sun. We found that at least 68% of code in the Buffer library is redundant in the sense that it recurs in many classes in the same or slightly modified form. We effectively eliminated that 68% of code at the meta-level using a technique based on \"composition with adaptation\" called XVCL. We argue that such a program solution is easier to maintain than buffer classes with redundant code. In this experiment, we have designed our meta-representation so that we could produce buffer classes in exactly the same form as they appear in the original Buffer library. While we have been\u00a0\u2026", "num_citations": "97\n", "authors": ["1057"]}
{"title": "Feature location in a collection of product variants\n", "abstract": " Companies often develop and maintain a collection of product variants that share some common features but also support different, customer-specific features. To reengineering such legacy product variants for systematic reuse, one must identify features and their implementing code units (e.g. functions, files) in different product variants. Information retrieval (IR) techniques may be applied for that purpose. In this paper, we discuss problems that hinder direct application of IR techniques to a collection of product variants. To counter these problems, we present an approach to support effective feature location in product variants. The novelty of our approach is that we exploit commonalities and differences of product variants by software differencing and FCA techniques so that IR technique can achieve satisfactory results for feature location in product variants. We have implemented our approach and conducted\u00a0\u2026", "num_citations": "95\n", "authors": ["1057"]}
{"title": "Reuse without compromising performance: industrial experience from RPG software product line for mobile devices\n", "abstract": " It is often believed that reusable solutions, being generic, must necessarily compromise performance. In this paper, we consider a family of Role-Playing Games (RPGs). We analyzed similarities and differences among four RPGs. By applying a reuse technique of XVCL, we built an RPG product line architecture (RPG-PLA) from which we could derive any of the four RPGs. We built into the RPG-PLA a number of performance optimization strategies that could benefit any of the four (and possibly other similar) RPGs. By comparing the original vs. the new RPGs derived from the RPG-PLA, we demonstrated that reuse allowed us to achieve improved performance, both speed and memory utilization, as compared to each game developed individually. At the same time, our solution facilitated rapid development of new games, for new mobile devices, as well as ease of evolving with new features the RPG-PLA and\u00a0\u2026", "num_citations": "85\n", "authors": ["1057"]}
{"title": "An investigation of cloning in web applications\n", "abstract": " Cloning (ad hoc reuse by duplication of design or code) speeds up development, but also hinders future maintenance. Cloning also hints at reuse opportunities that, if exploited systematically, might have positive impact on development and maintenance productivity. Unstable requirements and tight schedules pose unique challenges for Web Application engineering that encourage cloning. We conducted a systematic study of cloning in 17 Web Applications of different sizes, developed using a range of Web technologies, and serving diverse purposes. We found cloning rates 17-63% in both newly developed and already maintained Web Applications. Contribution of this paper is two-fold: (1) our results confirm potential benefits of reuse-based methods in addressing the key challenges of Web engineering, and (2) a framework of metrics and presentation views that we defined and applied in our study may\u00a0\u2026", "num_citations": "84\n", "authors": ["1057"]}
{"title": "Addressing quality attributes in domain analysis for product lines\n", "abstract": " Feature-oriented domain analysis (FODA) is a widely accepted domain analysis method for modelling common and variant requirements for product lines. Goal-oriented analysis, on the other hand, focuses on quality attribute (QA) analysis in single system development. To address QAs in the product line context, the authors extended FODA with concepts of goal-oriented analysis. Their integrated modelling framework improves the current state-of-the art of product line research and practice in two ways. Firstly, during the design of a product line architecture, the proposed framework allows developers to record design rationale in the form of interdependencies among variant features and QAs. Secondly, during system construction, the framework helps developers evaluate the impact of variant features selected for a target system on QAs of that system. In this way, developers and customers can come up with\u00a0\u2026", "num_citations": "82\n", "authors": ["1057"]}
{"title": "Industrial experience with building a web portal product line using a lightweight, reactive approach\n", "abstract": " Imprecise, frequently changing requirements and short time-to-market create challenges for application of conventional software methods in Web Portal engineering. To address these challenges, ST Electronics (Info-Software Systems) Pte. Ltd. applied a lightweight, reactive approach to support a Web Portal product line. Unique characteristics of the approach were fast, low-cost migration from a single conventional Web Portal towards a reusable\" generic Web Portal\" solution, effective handling of large number of functional variants and their dependencies, the ability to rapidly develop new Web Portals from the generic one, and to independently evolve multiple Web Portals without ever losing a connection between them and the\" generic Web Portal\". The initial Web Portal was built using state-of-the-art conventional methods. The Web Portal was not flexible enough to reap the benefits of new business opportunities\u00a0\u2026", "num_citations": "78\n", "authors": ["1057"]}
{"title": "Using server pages to unify clones in web applications: A trade-off analysis\n", "abstract": " Server page technique is commonly used for implementing Web application user interfaces. Server pages can represent many similar Web pages in a generic form. Yet our previous study revealed high rates of repetitions in Web applications, particularly in the user interfaces. Code duplication, commonly known as 'cloning', signals untapped opportunities to achieve simpler, smaller, more generic, and more maintainable Web applications. Using PHP server page technique, we conducted a case study to explore how far server page technique can be pushed to achieve clone-free Web applications. Our study suggests that clone unification using server pages affects system qualities (e.g., runtime performance) to an extent that may not be acceptable in many project situations. Our paper discusses the trade-offs we observed when applying server pages to unify clones in Web applications. We expect our findings to\u00a0\u2026", "num_citations": "68\n", "authors": ["1057"]}
{"title": "Design of flexible static program analyzers with PQL\n", "abstract": " Static program analyzers (SPA) are interactive tools that enhance program understanding during maintenance by answering queries about programs. Depending on the maintenance task in hand, SPAs must process different source programs and answer different types of program queries. Flexibility is, therefore, a desirable property of SPAs. The author describes a program query language, called PQL, that facilitates the design of flexible SPAs. PQL is a conceptual level, source language-independent notation to specify program queries and program views. In PQL, one can query global program design as well as search for detail code patterns. PQL queries are answered automatically by a query evaluation mechanism built into an SPA. Program design models and POL form the core of an SPA conceptual model. He based the SPA's architecture on this conceptual model. By separating the conceptual model from\u00a0\u2026", "num_citations": "60\n", "authors": ["1057"]}
{"title": "Supporting product line evolution with framed aspects\n", "abstract": " This paper discusses how evolution in software product lines can be supported using framed aspects: a combination of aspect-oriented programming and frame technology. Product line architectures and assets are subject to maintenance and evolution throughout their lifetime due to the emergence of new user requirements, new technologies, business rules and features. However, the evolution process can be compromised by inadequate mechanisms for expressing the required changes. It maybe possible to anticipate future evolutions and, therefore, prepare and design the architecture to accommodate this, but there will eventually come a time when a certain feature or scenario appears which could not have been foreseen in the early stages of development. We argue that frames and aspects when used in isolation cannot overcome these weaknesses effectively. However, they can be addressed by using the respective strengths of both technologies in combination. The amalgamation of framing and aspect-oriented techniques can help in the integration of new features and thus reduce the risk of architectural erosion.", "num_citations": "59\n", "authors": ["1057"]}
{"title": "Model-based support for business re-engineering\n", "abstract": " What do we need to know about the business in order to understand and, eventually, to improve business operations? Many business modelling methods have been described in the literature and applied in business re-engineering projects. We feel that current business modelling methods do not have a precise enough model of the underlying business knowledge. A model should be comprehensive enough to allow for a systematic study and precise formulation of re-engineering methods. It should also provide a framework for designing tools to support business re-engineering projects. We identify information requirements for business re-engineering based on the commonly used business re-engineering methods and case studies published in the literature. We formalized these requirements within the conceptual business model that is described in this paper. Business models vary from a company to company\u00a0\u2026", "num_citations": "56\n", "authors": ["1057"]}
{"title": "Unifying clones with a generative programming technique: a case study\n", "abstract": " Software clones\u2014similar program structures repeated in variant forms\u2014increase the risk of update anomalies, blow up the program size and complexity, possibly contributing to high maintenance costs. Yet, programs are often polluted by clones. In this paper, we present a case study of cloning in the Java Buffer library, JDK 1.5. We found that at least 68% of the code in the Buffer library was contained in cloned classes or class methods. Close analysis of program situations that led to cloning revealed difficulties in eliminating clones with conventional program design techniques. As a possible solution, we applied a generative technique of XVCL (XML\u2010based Variant Configuration Language) to represent similar classes and methods in generic, adaptable form. Concrete buffer classes could be automatically produced from the generic structures. We argue, on analytical and empirical grounds, that unifying clones\u00a0\u2026", "num_citations": "55\n", "authors": ["1057"]}
{"title": "Understanding feature evolution in a family of product variants\n", "abstract": " Existing software product variants, developed by ad hoc reuse such as copy-paste-modify, are often a starting point for building Software Product Line (SPL). Understanding of how features evolved in product variants is a prerequisite to transition from ad hoc to systematic SPL reuse. We propose a method that assists analysts in detecting changes to product features during evolution. We first entail that features and their inter-dependencies for each product variant are documented as product feature model. We then apply model differencing algorithm to identify evolutionary changes that occurred to features of different product variants. We evaluate the effectiveness of our approach on a family of medium-size financial systems. We also investigate the scalability of our approach with synthetic data. The evaluation demonstrates that our approach yields good results and scales to large systems. Our approach enables\u00a0\u2026", "num_citations": "49\n", "authors": ["1057"]}
{"title": "Software practices in five ASEAN countries: an exploratory study\n", "abstract": " There is a lack of published studies on software development in Southeast Asia, which is fast becoming an IT outsourcing haven. This paper presents exploratory survey and case study results on software practices of some software firms in five ASEAN countries (Malaysia, Philippines, Singapore, Thailand and Vietnam), and provides directions for further research on software practices in the ASEAN/Southeast Asian region.", "num_citations": "44\n", "authors": ["1057"]}
{"title": "Applying a generative technique for enhanced genericity and maintainability on the J2EE platform\n", "abstract": " One of the themes in building reusable and maintainable software is identifying similarities and designing generic solutions to unify similarity patterns. In this paper, we analyze capabilities of J2EE to effectively unify similarity patterns found in Web Portals (WP). Our experimentation involved a family of WPs to support information sharing and team collaboration, built by our industry partner. While J2EE provides useful mechanisms for reuse of common services across components, we found its limitations in systematic across-the-board reuse in application domain-specific areas. To solve these problems, we applied a generative programming (GP) technique of XVCL on top of J2EE. By unifying similarity patterns, we increased the clarity of portal\u2019s conceptual structure as perceived by developers, reducing also the size of the original J2EE WP by 61%. Our solution enhanced traceability of information that\u00a0\u2026", "num_citations": "42\n", "authors": ["1057"]}
{"title": "Query-based filtering and graphical view generation for clone analysis\n", "abstract": " Code clones are similar program structures recurring in software systems. Clone detectors produce much information and a challenge is to identify useful clones depending on the goals of clone analysis. To do so, further abstraction, filtering and visualization of cloning information, with the involvement of a human expert, is required. In this paper, we describe a technique for filtering and visualization of cloning information generated by Clone Miner, a clone detection tool presented in our earlier work. Unique benefit and contribution of our approach is that a human expert can define a wide range of filters to extract abstract views of the cloning data using a clone-query system to suit specific needs of clone analysis. We then produce standardized graphical presentations of those views for various types of clone queries. We implemented the technique into an Eclipse plug-in called Clone Visualizer. Clone Visualizer\u00a0\u2026", "num_citations": "40\n", "authors": ["1057"]}
{"title": "Frame-based method for customizing generic software architectures\n", "abstract": " One way to support development and maintenance of a software system family is to design a generic software architecture for a family. A generic architecture captures requirements common to all (or most of) the family members. Then, we develop specific software systems, members of a family, by customizing a generic architecture. During customization, we address variant requirements to be met by a specific system we wish to implement. In this paper, we describe how we applied frame technology-an advanced form of pre-processing-to design a mechanism for customizing generic software architectures. Customization of a generic architecture involves selecting architecture components, customization of connectors and customization of components\u2019 code. We turn architecture components and connectors into frames and map variant requirements into sequences of customization activities. The frame processor\u00a0\u2026", "num_citations": "36\n", "authors": ["1057"]}
{"title": "Design of a generic reverse engineering assistant tool\n", "abstract": " Reverse engineering is a knowledge-intensive process. We believe the involvement of a domain expert is critical in any but a trivial reverse engineering task. Our approach to reverse engineering assumes close cooperation between a domain expert and a knowledge-based reverse engineering assistant tool. Reverse engineering progresses in steps. At each step, a tool applies heuristic rules to extract design views, while a domain expert accepts/rejects decisions made by a tool and provides additional input to tune in the reverse engineering process. In our projects, we reverse engineer to enhance program understanding and to facilitate software reengineering. We apply reverse engineering to variety of sources, produce many types of design views, use many design view presentation methods and, finally, deal with a rich, evolving set of reverse engineering heuristics. Therefore, we designed a flexible reverse\u00a0\u2026", "num_citations": "35\n", "authors": ["1057"]}
{"title": "An Empirical Study on Limits of Clone Unification Using Generics.\n", "abstract": " Generics (templates) attempt to unify similar program structures to avoid explosion of redundant code. How well do generics serve this purpose in practice? We try to answer this question through empirical analysis from two case studies. First, we analyzed the Java Buffer library in which 68% of the code was redundant due to cloning. We were able to remove only 40% of the redundant code using the proposed Java generics. Unification failed because the variations between cloned classes were either non-type parametric or nonparametric. To analyze whether this problem is specific to Java generics, we investigated the C++ Standard Template Library (STL), an exemplary application of C++ templates, as our second case study. Even though C++ templates are more powerful, we still found substantial cloning. We believe that we are dealing with a fundamental phenomenon that will cause many other class libraries and application programs to suffer from the code redundancy problem.", "num_citations": "34\n", "authors": ["1057"]}
{"title": "Reengineering a PC-based system into the mobile device product line\n", "abstract": " There is a growing demand to port existing PC-based software systems to mobile device platforms. Systems running on mobile devices share basic characteristics with their PC-based counterparts, but differ from them in details of user interfaces, application models, etc. Systems running on mobile devices must also perform well using less memory than PC-based systems. Mobile devices themselves are different from each other in many ways, too. We describe how we made an existing PC-based City Guide System available on a wide range of mobile devices, in a cost-effective way. We applied \"reengineering into a product line architecture\" approach to achieve the goal. Our product line architecture facilitates reuse via generation. We generate specific City Guide Systems for target platforms including PC, Pocket PC and other mobile devices, from generic meta-components that form the City Guide System product\u00a0\u2026", "num_citations": "34\n", "authors": ["1057"]}
{"title": "A case study of variation mechanism in an industrial product line\n", "abstract": " Fudan Wingsoft Ltd. developed a product Line of Wingsoft Financial Management Systems (WFMS-PL) providing web-based financial services for employees and students at universities in China. The company used a wide range of variation mechanisms such as conditional compilation and configuration files to manage WFMS variant features. We studied this existing product line and found that most variant features had fine-grained impact on product line components. Our study also showed that different variation mechanisms had different, often complementary, strengths and weaknesses, and their choice should be mainly driven by the granularity and scope of feature impact on product line components. We hope our report will help companies evaluate and select variation mechanisms when moving towards the product line approach.", "num_citations": "30\n", "authors": ["1057"]}
{"title": "Domain model-driven software reengineering and maintenance\n", "abstract": " This article describes a method for reengineering business systems. The method's objective is to produce a library of reusable software components based on the analysis of existing code. The library contains conceptual data models, procedural pseudocode, screens, and reports that can be fed into a CASE repository and code generators. The domain model plays a central role in this approach. By grouping procedures around data model entities and attaching procedures to screens and reports, the domain model creates an object-oriented view of a system. In business applications, many domain objects correspond to entities in a conceptual data model. Therefore, we first reconstruct a data model and then derive the first-cut domain model from it. Data definitions in a program are directly linked to domain objects. The programmer inspects a program via the domain model. Combinations of pattern matching\u00a0\u2026", "num_citations": "26\n", "authors": ["1057"]}
{"title": "Engineering components for ease of customisation and evolution\n", "abstract": " Building software systems out of prefabricated components is a very attractive vision. Distributed component platforms (DCP) and their visual-development environments bring this vision closer to reality than ever. At the same time, some experiences with component libraries warn us about potential problems that arise when software-system families or systems evolve over many years of changes. Indeed, implementation-level components, when affected by many independent changes, tend to grow in both size and number, impeding reuse. This unwanted effect is analysed in detail. It is argued that components affected by frequent unexpected changes require higher levels of flexibility than the `plug-and-play' paradigm is able to provide. A program-construction environment is proposed, based on generative programming techniques, to help in customisation and evolution of components that require much flexibility\u00a0\u2026", "num_citations": "25\n", "authors": ["1057"]}
{"title": "From reuse library experiences to application generation architectures\n", "abstract": " Reuse through application generators has been successful in the area of programming language systems. We analyzed three language system projects that realized transition from the initial ad hoc programs, through libraries of reusable modules to application generator solutions. We tried to understand the underlying thinking process and technical factors that made such a transition possible. Based on this study, we generalized reuse experiences gained in the language system domain and formulated a reuse implementation framework. Our framework is to facilitate transition from component-based reuse to application generators in other domains. Ultimately, we hope our framework will offer reuse implementation guidelines for companies to realize such a transition. Initial findings are described in this paper.", "num_citations": "25\n", "authors": ["1057"]}
{"title": "Are clones harmful for maintenance?\n", "abstract": " We often find clones in semantically related programs parts. This semantic relationship, not clones, is a prime reason for maintenance problems, as semantically related program parts must be changed in sync no matter of clones.", "num_citations": "23\n", "authors": ["1057"]}
{"title": "Viewing simple clones from structural clones' perspective\n", "abstract": " In previous work, we described a technique for detecting designlevel similar program structures that we called structural clones. Structural clones are recurring configurations of simple clones (ie, similar code fragments). In this paper, we show how structural clone analysis extends the benefits of analysis based on simple clones only. First, we present experimental results showing that in many cases simple clones participated in structural clones. In such cases, structural clones being larger than simple clones but smaller in number, allow analysts to see the\" forest from the trees\", as far as the similarity situation is concerned. We provide arguments and examples to show how the knowledge of structural clones-their location and exact similarities and differences-helps in program understanding, design recovery, maintenance, and refactoring.", "num_citations": "21\n", "authors": ["1057"]}
{"title": "A comparative study of maintainability of web applications on J2EE,. NET and Ruby on Rails\n", "abstract": " With Web services predicted to become distributed computing architecture in near future, maintainability of the Web applications (WAs) will rank high on selection criteria while choosing a platform for development of a WA. The goal of this paper is to evaluate maintainability of small-scale WAs built on J2EE, .NET and Ruby On Rails (RoR). The maintainability criteria considered comprised of modifiability, testability, understandability and portability. We found that the RoR implementation fared better on modifiability, testability, and understandability, while J2EE implementation was the most portable. The results led us to comment on the maintainability of small WAs with respect to underlying architecture and development environments the three platforms provide. We believe that results are expected to vary for medium and large-size WAs. The work included here is part of an effort to build a decision framework for\u00a0\u2026", "num_citations": "21\n", "authors": ["1057"]}
{"title": "PQL: A language for specifying abstract program views\n", "abstract": " A program query language, PQL for short, described in this paper is a source language-independent notation to specify program queries and program views. We use PQL as an interface to Static Program Analyzers (SPA), interactive tools that enhance program understanding by answering queries about programs. In PQL, we can query on global program design as well as search for detail code patterns. Program queries and patterns supported by other notations described in literature and those supported by commercial tools known to the author, can be written simply and naturally in PQL. Program modeling and PQL notations described in the paper form a basis for an SPA generation system. These notations also allow us to rigorously study tool capabilities in the context of underlying software maintenance process and programmer's behavior models.", "num_citations": "21\n", "authors": ["1057"]}
{"title": "Towards a precise description of reverse engineering methods and tools\n", "abstract": " The potential and limitations of reverse engineering techniques is still a matter of debate and investigation. Both experimental studies and commonsense tell us that design abstractions are useful in program understanding and maintenance. In the case of incomplete program documentation, reverse engineering tools can recover some of the design abstractions from code. However, it is not clear which design abstractions can and which cannot be automatically recovered. This can be attributed to the understandable reluctance of industry to publicize explicit knowledge of this process due to its enormous commercial value and the fact that reverse engineering is a fairly new research discipline. As a start to formalizing what we already know about reverse engineering, we propose a framework for describing and evaluating reverse engineering methods and tools. First, we build design models for a source language\u00a0\u2026", "num_citations": "20\n", "authors": ["1057"]}
{"title": "Towards test case reuse: a study of redundancies in android platform test libraries\n", "abstract": " Similar software systems have similar test cases. We find much redundancy even within test cases of a single system. In this paper, we describe the results of similarity analysis performed on Android platform framework project\u2019s test case libraries. The results confirm our hypothesis that reuse of test cases can boost productivity at least as much as reuse of code. We identified repetition patterns in Android platform framework test case libraries that can be represented in generic form for further reuse using variability techniques adopted from Software Product Line (SPL). By exploiting similarity among test cases, we can design generic test case libraries that are much smaller, easier to develop/evolve than existing test case libraries. In this paper, we present quantitative and qualitative findings from our study of Android platform framework test case libraries. We discuss typical patterns of repetitions and illustrate\u00a0\u2026", "num_citations": "19\n", "authors": ["1057"]}
{"title": "Synergy between component-based and generative approaches\n", "abstract": " Building software systems out of pre-fabricated components is a very attractive vision. Distributed Component Platforms (DCP) and their visual development environments bring this vision closer to reality than ever. At the same time, some experiences with component libraries warn us about potential problems that arise in case of software system families or systems that evolve over many years of changes. Indeed, implementation level components, when affected by many independent changes, tend to grow in both size and number, impeding reuse. In this paper, we analyze in detail this effect and propose a program construction environment, based on generative techniques, to help in customization and evolution of component-based systems. This solution allows us to reap benefits of DCPs during runtime and, at the same time, keep components under control during system construction and evolution. In the\u00a0\u2026", "num_citations": "19\n", "authors": ["1057"]}
{"title": "Clonedifferentiator: Analyzing clones by differentiation\n", "abstract": " Clone detection provides a scalable and efficient way to detect similar code fragments. But it offers limited explanation of differences of functions performed by clones and variations of control and data flows of clones. We refer to such differences as semantic differences of clones. Understanding these semantic differences is essential to correctly interpret cloning information and perform maintenance tasks on clones. Manual analysis of semantic differences of clones is complicated and error-prone. In the paper, we present our clone analysis tool, called Clone-Differentiator. Our tool automatically characterizes clones returned by a clone detector by differentiating Program Dependence Graphs (PDGs) of clones. CloneDifferentiator is able to provide a precise characterization of semantic differences of clones. It can provide an effective means of analyzing clones in a task oriented manner.", "num_citations": "18\n", "authors": ["1057"]}
{"title": "Business-oriented component-based software development and evolution\n", "abstract": " The huge size and high complexity of legacy software are the main sources of today's software evolution problems. While we can ease software evolution with re-engineering tools, in the long term we should look for a more fundamental and effective solution. Component-based software development (CBSD) technology makes it possible to build software systems as collections of cooperating autonomous application components. This new paradigm has the potential to ease software evolution problems, as modification or replacement of components is deemed to be much easier than modification of today's huge monolithic legacy programs. For CBSD to bring its promised benefits, we must identify the right components in a given business domain. The claim of this paper is that, while CBSD is an important enabling technology, the decomposition of a software system into components must be driven by business\u00a0\u2026", "num_citations": "18\n", "authors": ["1057"]}
{"title": "Mining logical clones in software: Revealing high-level business and programming rules\n", "abstract": " Software systems contain many implicit application-specific business and programming rules. These rules represent high-level logical structures and processes for application-specific business and programming concerns. They are crucial for program understanding, consistent evolution, and systematic reuse. However, existing pattern mining and analysis approaches cannot effectively mine such application-specific rules. In this paper, we present an approach for mining logical clones in software that reveal high-level business and programming rules. Our approach extracts a program model from source code, and enriches the program model with code clone information, functional clusters (i.e., a set of methods dealing with similar topics or concerns), and abstract entity classes (representing sibling entity classes). It then analyzes the enriched program model for mining recurring logical structures as logical clones\u00a0\u2026", "num_citations": "17\n", "authors": ["1057"]}
{"title": "A case for structural clones\n", "abstract": " In previous work, we introduced the concept of structural clone as recurring configurations of simple clones (ie, similar code fragments). We also described a technique for detection of certain types of structural clones. The premise of our approach is that structural clones can provide a higher level and more useful view of the similarity situation in software than simple clones alone. In this paper, we set up a ground for systematic analysis of the structural clone phenomenon: We define structural clones more formally and more generally than we did before. We show how structural clone analysis extends the benefits of analysis based on simple clones only in areas of program understanding, maintenance, reuse, refactoring, and plagiarism detection.", "num_citations": "17\n", "authors": ["1057"]}
{"title": "Teaching an advanced design, team-oriented software project course\n", "abstract": " Students learn about design principles and \"best practices\" in many courses. However, small scale assignments do not give enough opportunity for students to appreciate the value of software design principles or even to learn how to apply principles in practice. To fill the gap between theoretical and experiential knowledge, we introduced a team-based project course focused on design and implementation phases of the software development lifecycle. We teach design principles and team work in problem-based way, through architectural concepts and iterative development process. The product students build must meet stated quality requirements in terms of reliability, reusability and documentation. We trust this kind of the course is essential in curricula as it allows students better absorb knowledge learned in other software engineering courses. Such course also plays a role in better preparing students for\u00a0\u2026", "num_citations": "17\n", "authors": ["1057"]}
{"title": "An Industrial Application of a Reuse Technique to a Web Portal Product Line\n", "abstract": " We describe experiences with development of a Web portal product line at SES Systems Pte. Ltd. Interestingly, we developed the product line incrementally, starting with a personal Web portal built by the first author. When the personal portal was converted into the first business product, a Team Collaboration Portal (TCP), all efforts were made to identify patterns of similar design recurring across the portal, and unify them using conventional methods. By exploiting reuse opportunities across the portal, we wanted to cut the development cost and facilitate future enhancements. Building a Web portal product line was not our business or technical goal yet. Despite our efforts to maximize reuse, we were aware of much counter-productive repetition in portal design and implementation that could not be avoided with the design methods we used. At the same time, new business opportunities appeared that required us to build other portals, for seemingly very diverse applications, in a very short time. To meet the challenge, we applied XVCL on top of TCP, converting it into a product line architecture. Our solution allowed us to manage multiple (nine by now) portals from a base of common code smaller than the original TCP, and facilitated rapid development of new Web portals. In the paper, we describe the process that led to building a product line. We explain the difficulties in building an effective generic portal solution using conventional techniques. We analyze our solution in qualitative and quantitative ways.", "num_citations": "16\n", "authors": ["1057"]}
{"title": "Modelling Variant User Requirements in Domain Engineering for Reuse\n", "abstract": " . In domain engineering, one attempts to analyse requirements for a family of similar systems and then design a generic architecture to be reused during system development. We conducted domain engineering projects in the domains of facility reservation systems, library systems and software project support tools. We identified a number of problems during domain analysis as well as during the design of generic software architectures for which we could not find solutions in the literature. One problem was related to modeling variant software requirements for a system family. Requirements may also appear in various, usually not arbitrary, combinations in family members. We found that modelling variant, ie, optional and alternative requirements, as well as legal configurations of requirements that can appear in a single system poses many problems that are critical in applying domain engineering in practice. In this paper, we describe a novel domain modelling approach that we de...", "num_citations": "16\n", "authors": ["1057"]}
{"title": "Modeling multiple domains in software reuse\n", "abstract": " Modeling multiple domains is use@ l in two ways. Firstly, most of real sof~ arw~ sterns are based on more than one domain. In this case, modeiing dqoenderrcies between &mains facilitates better understanding and clearer specljlcation of mferwtce mquiwments for ajiiily of systems. This leaak to a structured andjlexible generic architecture for that family and, therejorw, improves reuse. Secondly, our method encourages one to divide big a% mains into smaller, easier to unabstand and describe subdomairrs. In big domains, w found this an e~ ective ww to identlfi reuse opportunities that may not be easi~ observed otherwise. The method described in the paper builds upon wellkrrown concepts of enterprise information architecture, domain analysis and the Domain-Spect~ c Sof~ are Architecttm(DSM) approach to reuse. We argue tha~ modeling of relationships between the domains is bene> cial 0s it ensures urri\u00a0\u2026", "num_citations": "16\n", "authors": ["1057"]}
{"title": "Specifying and generating multilanguage software development environments\n", "abstract": " Integrated software environments use a project information base (PIB) as a repository of all project-related data. A software environment supporting a lifecycle methodology requires a multilanguage PIB, with component languages dedicated to various aspects and phases of project development (e.g. requirement and design specification notations, implementation language etc.). At the same time, one has to view a PIB as a database (or even a knowledge base), where project information is stored, and from which it may be queried using database methods. Therefore, a model for PIBs should equally address linguistic and database aspects of the project information representation. The goal of this paper is to introduce a formal model for multilanguage environments, suitable for representing PIBs. We build the model by extending attribute grammars and integrating them with the entity-relationship model. We also\u00a0\u2026", "num_citations": "16\n", "authors": ["1057"]}
{"title": "CBT Assistant: mHealth App for Psychotherapy\n", "abstract": " Cognitive Behavioural Therapy (CBT) is psychotherapy recommended for mental disorders such as Social Anxiety Disorder (SAD) and depression. Wide base of evidence across different studies and clinical practices shows the effectiveness and safety of CBT as compared to other types of treatment. After a face-to-face session with therapists, patients would typically carry out Homework, a central concept to CBT. Patients fill in their worksheets or diaries using pen-and-paper forms between two consecutive face-face sessions with the therapist. Homework provides crucial information about patients to the therapist. In this paper, we discuss mobile support for the delivery of CBT interventions in general, and present an Android app called CBT Assistant that supports behavioral interventions for patients suffering from SAD. CBT Assistant, highly adaptable to the specific context of a given patient. is designed for both\u00a0\u2026", "num_citations": "15\n", "authors": ["1057"]}
{"title": "Things structural clones tell that simple clones don't\n", "abstract": " In previous work, we described a technique for detecting design-level similar program structures (structural clones) formed from recurring configurations of similar code fragments (simple clones). In this paper, we analyze in detail how frequently these structural clones occur in software systems and how structural clone analysis extends the benefits of analysis based on simple clones only. Our case study of 11 open source systems revealed that over 50% of simple clones are captured by structural clones that often correspond to meaningful design or application domain concepts. Because of their larger size, it is easier for programmers to perceive the similarity situation in a system from structural clone perspective rather than from simple clone perspective only. We also discuss the contribution of structural clone detection towards program understanding, design recovery, maintenance, and refactoring using examples\u00a0\u2026", "num_citations": "15\n", "authors": ["1057"]}
{"title": "Life\u2010cycle approach to strategic re\u2010engineering of software\n", "abstract": " Software systems must be constantly upgraded to be in tune with an evolving business environment. Owing to the inefficiency of current maintenance methods, many of the old programs do not meet companies' strategic needs. Can we re\u2010engineer those programs or must they be rewritten from scratch? Common goals for re\u2010engineering software have been to improve maintainability of programs and to convert programs into a newer computer, database or language. In this paper, we describe a framework for strategic re\u2010engineering in which programs are substantially redesigned in order to meet companies' strategic goals. Strategic re\u2010engineering is much like redevelopment, accelerated by reuse of information that is extracted from existing, still viable from the business point of view, progams. We discuss the impact of companies' strategic plans on software re\u2010engineering and describe life\u2010cycle phases of\u00a0\u2026", "num_citations": "15\n", "authors": ["1057"]}
{"title": "Model\u2010based design of reverse engineering tools\n", "abstract": " Tools built in an ad hoc way and without proper models often display problems for both tool users and designers. Firstly, without systematic analysis and good understanding of the underlying software process model, we have little chance to design a tool that will adequately address users' needs. Next, because one tool is often used in many different situations and by people who have different working habits, tools should be flexible and allow a user to customize tool functionalities. Ad hoc built tools usually are not flexible enough, as possible variations in tool functions have not been incorporated into the tool architecture to make future customizations possible. Finally, ad hoc design practice does not lead to accumulating the tool design know\u2010how, making it difficult to repeat successful solutions and slowing down the process of understanding and improving tool design methods. We applied conceptual modelling\u00a0\u2026", "num_citations": "14\n", "authors": ["1057"]}
{"title": "Teaching advanced software design in team-based project course\n", "abstract": " Skillful design remains one of the critical success factors in long-lived software projects. Design fundamentals have been established and are pretty stable. How do we teach design in-the-large to equip our graduates with design skills relevant to a plethora of changing software technologies and emerging new application domains? Today programs are built on top of functionalities provided by software platforms. Most often, developers extend existing systems rather than develop from scratch. Programming with application program interfaces (API) that allow newly written code to call middleware or existing application software has become a norm in software industries. While the details of API mechanisms heavily depend on a specific platform or application, the principles behind API design are universal, and can be taught in project courses designed for that purpose. Working knowledge of API design principles\u00a0\u2026", "num_citations": "13\n", "authors": ["1057"]}
{"title": "Handling variant requirements in software architectures for product families\n", "abstract": " A reference architecture implements features that can be reused, after possible customizations, across members of a system family. Family members display similarities but they also vary one from another in user, design or implementation requirements. In this paper, we describe techniques that allow us to handle certain classes of variations at the architecture level and to build systems by customizing the architecture rather than by implementing variations at the code level. To achieve this end, we model variations within a domain model and then define how variations in system requirements affect the configuration of a reference architecture at different levels of granularity and abstraction. During system engineering, we customize a reference architecture by selecting architecture components to be included into the target system, by customizing component interfaces and, finally, by modifying components at\u00a0\u2026", "num_citations": "13\n", "authors": ["1057"]}
{"title": "A large scale linux-kernel based benchmark for feature location research\n", "abstract": " Many software maintenance tasks require locating code units that implement a certain feature (termed as feature location). Feature location has been an active research area for more than two decades. However, there is lack of publicly available, large scale benchmarks for e valuating and comparing feature location approaches. In this paper, we present a LinuxKernel based benchmark for feature location research. This benchmark is large scale and extensible. By providing rich feature and program information and accurate ground-truth links between features and code units, it supports the e valuation of a wide range of feature location approaches. It allows researchers to gain deeper insights into existing approaches and how they can be improved. It also enables communication and collaboration among different researchers. (video: http://www.youtube.com/watch?v=3D_HihwRNeK3I).", "num_citations": "12\n", "authors": ["1057"]}
{"title": "Beyond Generics: Meta-Level Parameterization For Effective Generic Programming\n", "abstract": " Generic (polymorphic) type-safe containers are the primary motivation for generics (in Ada, Eiffel, and recently proposed additions to Java and C#) and templates (in C++). We studied buffer classes and found that they could not be unified by type parameters. At times, unification required non-type parameters (eg, parameters representing operators, keywords or algorithmic details) and at other times\u2013the nature of variations was not parametric which called for a more general unification mechanism. Investigation of the reasons behind the observed symptoms revealed that unification problems were caused by \u201cfeature combinations\u201d: Other than by type, each class was also affected by yet other features and implementation of various features interacted with classes in rather chaotic ways. In the paper, we show examples of how the feature combination manifests in programs. We believe that we are dealing with a fundamental phenomenon that will cause many other class containers and application programs to suffer from the same problem. In our case study, some of the difficulties were caused by limitations specific to Java generics. Yet others were more fundamental and reflected the weakness of parameterization mechanisms supported by today\u2019s programming languages. We suggest that stronger generics systems would considerably enhance capabilities of programming languages in the areas of generic programming, reuse and maintenance. We refer to a meta-level parameterization mechanism that can effectively unify any types of variations triggered by feature combination, and can be applied to any programming language. We discuss the\u00a0\u2026", "num_citations": "11\n", "authors": ["1057"]}
{"title": "Systematic design of static program analyzers\n", "abstract": " Static program analyzers (SPA) are interactive tools that enhance program understanding by answering queries about programs. An SPA parses source programs and builds a so-called program knowledge base (PKB) that enables automatic processing of program queries. An SPA design method described in this paper consists of steps during which we (1) identify, a class of program queries we wish to answer, (2) model program information that is required to resolve queries, (3) define physical representation for programs, based on the concept of a hybrid PKB, and (4) implement other SPA components such as a front-end and user interface. Generally, queries related to global properties of programs are best handled if we store program information in a relational database. On the other hand, detailed queries are best supported if we represent programs as attributed syntax trees. A hybrid PKB described in this\u00a0\u2026", "num_citations": "11\n", "authors": ["1057"]}
{"title": "Clonediff: semantic differencing of clones\n", "abstract": " Clone detection provides a scalable and efficient way to detect similar codes, while program differencing is a powerful and effective way to analyze similar codes. CloneDiff, a Program Dependence Graphs (PDGs) differencing tool, complements clone detection with program differencing for the purpose of characterizing clones. It captures semantic information of clones from PDGs, and uses graph matching techniques to compute a precise characterization of clones in terms of a category of semantic differences.", "num_citations": "10\n", "authors": ["1057"]}
{"title": "Project-driven university-industry collaboration: modes of collaboration, outcomes, benefits, success factors\n", "abstract": " Joint research between National University of Singapore (NUS) and ST Electronics Pte Ltd (STEE) started through a broad collaboration agreement, seven years ago. Collaboration was intensified by a research project that also involved two other partners, namely University of Waterloo and Netron Inc. This new project led to development of a reuse technology called XVCL. The continuity of collaboration was sustained through a project-driven approach, that evolved around development and application of XVCL. Collaboration helped STEE to advance reuse practice via application of XVCL in several software product line projects. Early feedback from industrial applications along with many other inputs from STEE helped NUS team validate and refine XVCL reuse methods, explore new research directions, and ensured that academic research results remained in sync with industrial realities. In the paper, we\u00a0\u2026", "num_citations": "9\n", "authors": ["1057"]}
{"title": "An adaptability-driven model and tool for analysis of service profitability\n", "abstract": " Profitability of adopting Software-as-a-Service (SaaS) solutions for existing applications is currently analyzed mostly in informal way. Informal analysis is unreliable because of the many conflicting factors that affect costs and benefits of offering applications on the cloud. We propose a quantitative economic model for evaluating profitability of migrating to SaaS that enables potential service providers to evaluate costs and benefits of various migration strategies and choices of target service architectures. In previous work, we presented a rudimentary conceptual SaaS economic model enumerating factors that have to do with service profitability, and defining qualitative relations among them. A quantitative economic model presented in this paper extends the conceptual model with equations that quantify these relations, enabling more precise reasoning about profitability of various SaaS implementation\u00a0\u2026", "num_citations": "8\n", "authors": ["1057"]}
{"title": "Flexible generators for software reuse and evolution: NIER Track\n", "abstract": " Developers tend to use models and generators during initial development, but often abandon them later in software evolution and reuse. One reason for that is that code generated from models (e.g., UML) is often manually modified, and changes cannot be easily propagated back to models. Once models become out of sync with code, any future re-generation of code overrides manual modifications. We propose a flexible generator solution that alleviates the above problem. The idea is to let developers weave arbitrary manual modifications into the generation process, rather than modify already generated code. A flexible generator stores specifications of manual modifications in executable form, so that weaving can be automatically re-done any time code is regenerated from modified models. In that way, models and manual modification can evolve independently but in sync with each other, and the generated\u00a0\u2026", "num_citations": "8\n", "authors": ["1057"]}
{"title": "Modeling multiple views of common features in software reengineering for reuse\n", "abstract": " Common objectives of software reengineering are to improve program maintainability, to port programs into new platforms or to support new functions. To meet reengineering objectives, sometimes it is necessary to substantially re-deign programs; then, reengineering becomes an opportune moment to address reusability. In the \u201creengineering for reuse\u201d scenario, a reusability framework is built prior to reengineering efforts. Within the framework, potentially reusable features are modeled and representation structures for capturing reusable features are built. The core of the framework is a family of domain models. Domain models are built in the course of both reverse engineering of existing programs and independent domain analysis. Domain models consist of documentation templates, organized in Object-Oriented way, that describe common (therefore reusable) features and their implementation. Often we\u00a0\u2026", "num_citations": "8\n", "authors": ["1057"]}
{"title": "Generic adaptable test cases for software product line testing: software product line\n", "abstract": " This research study is about constructing\" generic adaptable test cases\" to counter test case libraries explosion problem. Our work focuses on effort reduction via systematic reuse of generic test assets by taking advantage of common aspects and predicted variability in test cases. We envision that the proposed approach to organizing test case libraries will be particularly useful in the context of Software Product Line Testing (SPLT). By exploring strategies for generic test cases, I hope to address problems of domain-level testing. Our work will investigate existing testing (SPLT) practices in variability management context by conducting empirical studies. We plan to synthesize principles for\" generic test case\" design, identify gaps between required and exiting techniques, and finally propose new approach for generic adaptive test case construction.", "num_citations": "7\n", "authors": ["1057"]}
{"title": "Research journey towards industrial application of reuse technique\n", "abstract": " Component-based reuse in mission critical Command and Control system domain was a starting point for a long lasting research collaboration between National University of Singapore (NUS) and ST Electronics Pte. Ltd.(STEE). STEE industrial projects as well as NUS lab studies revealed limitations of conventional architecture-centric, component-based reuse in the area of generic design to unify similarity patterns (eg, similar classes, components or architectural patterns) commonly found in software. Further research showed that meta-level extensions to conventional techniques could strengthen their generic design capabilities, considerably improving effectiveness of reuse solutions, and increasing productivity gains due to reuse. These experiences led to development of\" mixed strategy\" approach based on synergistic application of meta-level generative programming technique of XVCL, together with\u00a0\u2026", "num_citations": "7\n", "authors": ["1057"]}
{"title": "F-metric: a WWW-based framework for intelligent formulation and analysis of metric queries\n", "abstract": " As an organization matures, quantitative techniques are employed to make software project management more systematic, informed and under control. This is typically done through the collection and analysis of software metrics to measure the performance of projects. While many organizations utilize software metrics to analyze project issues and answer management queries, the manner in which such queries are answered varies from organization to organization. As the number of metrics grows, interpretation of raw metrics in the context of management goals becomes difficult. The method and tool that we developed attempts to bridge the gap between the project managers' mental model of a project and raw software metrics. Based on industrial surveys, we identified types of queries about the project progress, resources and schedule that project managers often ask during project execution. Next, we built a\u00a0\u2026", "num_citations": "7\n", "authors": ["1057"]}
{"title": "Model-based design of tools for business understanding and re-engineering\n", "abstract": " Tools can provide useful assistance for business re-engineering planning. Activities such as business knowledge acquisition, business process modeling, performance, quality and impact analysis all can be done more effectively if supported by proper tools. We describe a design scenario for business understanding and re-engineering tools that is based on systematic modeling of business knowledge. The business knowledge model forms conceptual schema for the tool repository. We start by building a generic business model. As both the model and required tool characteristics vary from company to company and from one business re-engineering project to another, we customize the generic model and tools to reflect needs of a given company and a business re-engineering project in hand. We achieve a required level of tool flexibility by applying meta-CASE techniques. The physical repository schema and\u00a0\u2026", "num_citations": "7\n", "authors": ["1057"]}
{"title": "A hybrid program knowledge base for static program analyzers\n", "abstract": " Static program analyzers (SPA) are interactive tools that enhance program understanding by answering queries about programs. An SPA extracts relevant information from input programs and stores it in a program knowledge base (PKB). In this paper, we present a hybrid PKB design model that integrates a relational database with attributed syntax trees. In the hybrid PKB, global properties of programs are stored in a relational database and detailed program structures are stored as attributed syntax trees. The hybrid PKB approach simplifies the structure of the PKB and provides a flexible mechanism for analysis of complex structured objects such as syntax trees and control/data flow graphs. The model reduces the size of the database, and hence program queries can be answered efficiently.< >", "num_citations": "7\n", "authors": ["1057"]}
{"title": "Strategic reengineering of software: Lifecycle approach\n", "abstract": " Software systems must be constantly upgraded to be in tune with an evolving business environment. Due to the inefficiency of current maintenance methods, many of the old programs do not meet current strategic needs. Common goals for reengineering software have been to improve maintainability of programs and to convert programs into a newer computer, database, or language. A framework for strategic reengineering in which target systems are substantially redesigned in order to meet a company's strategic goals is described. Strategic reengineering is much like redevelopment, accelerated by reuse of information that is extracted from existing, still viable, programs. The impact of a company's strategic plans on software reengineering is discussed, and lifecycle phases of strategic reengineering with CASE are described.", "num_citations": "7\n", "authors": ["1057"]}
{"title": "Distilling useful clones by contextual differencing\n", "abstract": " Clone detectors find similar code fragments and report large numbers of them for large systems. Textually similar clones may perform different computations, depending on the program context in which clones occur. Understanding these contextual differences is essential to distill useful clones for a specific maintenance task, such as refactoring. Manual analysis of contextual differences is time consuming and error-prone. To mitigate this problem, we present an automated approach to helping developers find and analyze contextual differences of clones. Our approach represents context of clones as program dependence graphs, and applies a graph differencing technique to identify required contextual differences of clones. We implemented a tool called CloneDifferentiator that identifies contextual differences of clones and allows developers to formulate queries to distill candidate clones that are useful for a given\u00a0\u2026", "num_citations": "6\n", "authors": ["1057"]}
{"title": "Software reuse beyond components with XVCL (Tutorial)\n", "abstract": " The basic idea behind software reuse is to exploit similarities within and across software systems to avoid repetitive development work. Conventional reuse is based on components and architectures. We describe how reuse of structural similarities extends the benefits of conventional component reuse, and realization of the concept with a generative technique of XVCL. Structural similarities are repetition patterns in software of any type or granularity, from similar code fragments to recurring architecture-level component configuration patterns. We represent any significant repetition pattern in subject system(s) with a generic, adaptable, XVCL meta-structure. We develop, reuse and evolve software at the level of meta-structures, deriving specific, custom systems from their meta-level representations. Lab studies and industrial applications of XVCL show that by doing that, on average, we raise reuse rates and\u00a0\u2026", "num_citations": "6\n", "authors": ["1057"]}
{"title": "Structural Clones Higher Level Similarity Patterns in Programs\n", "abstract": " Code clones convey important information about a software system\u2019s design and implementation. Several tools have been proposed to detect code clones. However, mostly the focus so far has been on fragments of duplicated code. In our studies, we observed that certain configurations of duplicated code fragments may signify some higher level patterns of similarities (usually, the result of cloning design solutions). Such higher level similarities often represented some domain or design concepts, comprising much bigger parts of a program (eg, patterns of collaborating components) than just code fragments. Recognizing higher level similarities can have significant value for program understanding, evolution (by reducing the risk of update anomalies), reuse (higher level similarities often are big enough to form attractive candidates for reusable solutions), and possible simplification of a program via re-engineering. In this paper, we describe the phenomenon of higher level similarities, that we call structural clones. We define structural clones as similar program structures that can be built hierarchically, at many levels of abstraction, with similar code fragments at the bottom of such hierarchy. We show some interesting examples of structural clones from industrial projects and our own studies, and highlight their importance and benefits. Finally, we present our approach to automated detection of structural clones. Our work is strongly tied to issues of concept recognition and design recovery, addressed in many research projects in last two decades.", "num_citations": "6\n", "authors": ["1057"]}
{"title": "Documentation Reuse: Managing Similar Documents\n", "abstract": " Many engineering and business domains involve management of similar, but also different documents. Examples are user guides and other manuals for different versions of a product, contracts between vendors and clients, and legal documents. The usual practice is to capture similarities in templates that must be copied and manually customized to a new context - often a slow, tedious, and error-prone process. Our Document Management Environment (DME) exploits similarities among documents to simplify and automate routine tasks involved in creating and updating documents. Built as MS Word add-in, DME can represent any group of recurring fragments as a template that is reused (after adaptations) to create custom document. DME concept is based on proven method for adaptive reuse of software.", "num_citations": "5\n", "authors": ["1057"]}
{"title": "On Interplay between Separation of Concerns and Genericity Principles: beyond code weaving\n", "abstract": " Ideally, we would separate concerns by designing a program so that each    concern is contained in a module. Unfortunately, we often have to deal with    concerns that cannot be modularized, but instead cross-cut modules of our    primary decomposition. Some of the cross-cutting concerns can be separated    using compositional techniques such as Aspect-Oriented Programming (AOP) that    weave code into modules at specified program points. Here, we focus on    cross-cutting concerns that would not be easily separable with code weaving    compositional techniques due to their frequent and complex interactions with    the modules of primary decomposition. Separation of Concerns (SoC) and    genericity are two important Software Engineering principles to better    control software complexity during development, maintenance, and reuse. In    this paper, we study the interplay between these two principles, showing that    there is an overlapping area where the goals of SoC and genericity, as well    as means to achieve these goals, are the same. We make a case that by    integrating the principles of SoC and genericity we can achieve    non-redundancy, and at the same time enhance the visibility of inseparable    concerns, offering a weaker, but still useful form of SoC. We illustrate the    points we make with examples of program representations built with the    Adaptive Reuse Technique (ART) that supports both SoC and generic mechanisms.", "num_citations": "5\n", "authors": ["1057"]}
{"title": "Detecting design similarity patterns using program execution traces\n", "abstract": " This paper aims at detecting an important type of design similarity patterns, so-called collaborative patterns, that has not been addressed in the software clone research so far. Collaborative patterns appear as recurring configurations of collaborating components such as methods or classes. Knowing location of such patterns and exact differences among them is useful in program understanding, better change impact analysis, code compaction, software maintenance, and in reuse. In the proposed approach for detecting collaborative patterns, we instrument the subject program with extra code to generate method execution traces. Then, we analyze generated traces to find collaborative patterns. Preliminary investigation has also been done to validate the proposed approach.", "num_citations": "5\n", "authors": ["1057"]}
{"title": "Improving product line architecture design and customization by raising the level of variability modeling\n", "abstract": " Product Line Architecture (PLA) plays a central role in software product line development. In order to support architecture-level variability modeling, most architecture description languages (ADLs) introduce architectural variation elements, such as optional component, connector and interface, which must be customized during product derivation. Variation elements are many, and design and customization of PLA at the level of individual variation elements are difficult and error-prone. We observed that developers usually perceive architecture variability from the perspective of variant features or variant design decisions that are mapped into groups of architecture variation elements. In the paper, we describe heuristics to identify configurations of variation elements that typically form such groups. We call them variation constructs. We developed an architecture variability management method and a tool that\u00a0\u2026", "num_citations": "5\n", "authors": ["1057"]}
{"title": "Towards generic representation of web applications: solutions and trade\u2010offs\n", "abstract": " Server pages (also called dynamic pages) render a generic web page into many similar ones. The technique is commonly used for implementing web application user interfaces (UIs). Yet our previous study found a high rate of repetitions (also called \u2018clones\u2019) in web applications, particularly in UIs. The finding raised the question as to why such repetitions had not been averted with the use of server pages. For an answer, we conducted an experiment using PHP server pages to explore how far server pages can be pushed to achieve generic web applications. Our initial findings suggested that generic representation obtained using server pages sometimes compromises certain important system qualities such as run\u2010time performance. It may also complicate the use of WYSIWYG editors. We have analysed the nature of these trade\u2010offs, and now propose a mixed\u2010strategy approach to obtain optimum generic\u00a0\u2026", "num_citations": "5\n", "authors": ["1057"]}
{"title": "Managing big clones to ease evolution: Linux kernel example\n", "abstract": " Successful software is often enhanced and adapted to the needs of new users. During evolution, a software system grows in size, becomes more complex, and costly to maintain. In this paper, we point to big clones-large granular duplicated program structures such as files or directories-as one of many reasons why this happens. Using the Linux kernel as an example, we show that big clones arise in the Linux kernel despite careful architecture design and a systematic approach for managing variability. We propose a solution to avoid these big clones by representing them as generalized templates in ART (Adaptive Reuse Technique). ART templates are constructed on top of the Linux code, without conflicts with the state-of-art techniques and tools used to manage the Linux kernel. Benefits include simplification of the Linux kernel due to non-redundancy, easier comprehension, and traceability of the change impact\u00a0\u2026", "num_citations": "4\n", "authors": ["1057"]}
{"title": "Mood self-assessment on smartphones\n", "abstract": " Mood has been systematically studied by psychologists for over 100 years. As mood is a subjective feeling, any study of mood must take into account and accurately capture user's perception of an experienced feeling. In last 40 years, a number of pen-and-paper mood self-assessment scales have been proposed. Typically, a person is asked to separately rate various dimensions of the experienced feeling (eg, pleasure and arousal) or mood items (interested, agitated, excited, etc.) on numeric scales (eg, between 0 and 10). These partial ratings are then combined into an overall mood rating (or into its positive and negative affect). Pen-and-paper mood scales are used in basic research on mood and in clinical practice. Mobile technology makes it possible to extend mood self-assessment from lab to real life rather, collecting mood data frequently, over long time, in variety of life situations. With these motivations, we\u00a0\u2026", "num_citations": "4\n", "authors": ["1057"]}
{"title": "Computer-aided dispatch system family architecture and verification: an integrated formal approach\n", "abstract": " Software architecture is an important level of description for software systems. Formal modelling techniques can be used to define and verify software architectures precisely. An integrated formal approach to the architecture modelling and verification of a computer-aided dispatch (CAD) system family, is presented. An incremental three-layer model, that is, architecture style layer, generic system layer and customised system layer, is presented to capture the design of the CAD system family. Critical CAD system properties in the architecture models are formally verified by using the state and event-based proof techniques of the underlying specification language. In summary, it is demonstrated that integrated formal techniques could be a good candidate for modelling and verifying various levels of descriptions of software architectures.", "num_citations": "4\n", "authors": ["1057"]}
{"title": "Towards automating software maintenance\n", "abstract": " This paper describes an ongoing project on automating program maintenance. We present a methodological framework for program maintenance and discuss detailed techniques for specific maintenance tasks. Our research on a methodology for program maintenance covers the whole maintenance life-cycle. The objective of this research is to delimit boundaries for long-term evolution of the project and to define a framework for integrating specific techniques and tools we develop.             In this paper, we focus on the methodological aspects of program maintenance. First, we review techniques and tools used during the various phases of program maintenance. We analyze relations among these techniques to see how they can work together within a maintenance methodology. Next, we observe that there can be no universal maintenance methodology, because an optimal maintenance process depends on\u00a0\u2026", "num_citations": "4\n", "authors": ["1057"]}
{"title": "CBT Assistant Platform: web/mobile co-design solution for cognitive behavioural therapy\n", "abstract": " CBT Assistant Platform is a web/mobile co-design mHealth solution to support cognitive behavioural therapy (CBT). CBT Assistant Platform supports the end-to-end CBT treatment process for clients suffering from psychological disorders and are currently undergoing CBT sessions with trained professionals. A therapist can create customized treatments through a web-based application that guide clients in following CBT homework routine, through their smartphone CBT app. Client support app utilizes evidence-based behavioural change strategies intelligently enhanced through the use of wearable devices and on-board mobile sensors. We built the CBT Assistant Platform hoping to improve delivery of CBT in the following key areas: two-way communication between clients and therapists, cutting the time of a therapy session and helping therapists serve more clients, and client\u2019s adherence to the therapy rigor by engaging the client in therapy process and making CBT homework easier and more fun to perform.", "num_citations": "3\n", "authors": ["1057"]}
{"title": "A conceptual model to evaluate decisions for service profitability\n", "abstract": " Service profitability depends on the cost of engineering a service for a given base of tenants, on service provisioning cost, and on the revenue gained from selling the service to that tenant base. The tenant base depends on the range of service variability, ie, on Service Provider's ability to vary service requirements to meet tenant expectations. These various factors that have to do with service profitability form a complex web of information that makes it difficult to analyze and see the exact impact of decisions regarding the choice of service architecture or the use of service adaptation techniques. To make this analysis easier for Service Providers, we built a conceptual model that helps Service Providers identity factors affecting service profitability and the interplay among them. Based on that model, Service Providers can answer questions regarding how choices of the service architecture or tenant base affect service profitability.", "num_citations": "3\n", "authors": ["1057"]}
{"title": "DME: Documentation Management Environment for Software Product Lines\u2013Tool Demo Proposal\n", "abstract": " Similar documents arise in software and business situations. Examples are user guides for different versions of a software product, contracts between vendors and clients, and legal documents. The usual practice is to capture similarities in templates that must be copied and manually customized to a new context\u2013often a slow, tedious, and error-prone process. Document Management Environment (DME) automates routine tasks involved in creating and updating documents. DME provides functions to create templates and to generate custom documents from them. Any arbitrary document part can be designated as template\u2019s variation point, and the same interdependent customizations occurring at different variation points can be streamlined. We develop DME to automate generation of documentation of multiple software products (eg, in reuse via Software Product Line approach), but also plan to explore its potentials in management of general business documents.", "num_citations": "3\n", "authors": ["1057"]}
{"title": "An extensible mobile sensing platform for mhealth and telemedicine applications\n", "abstract": " Smartphone apps with self-monitoring and sensing capabilities can help in disease prevention; however, such contextaware applications are difficult to develop, due to the complexities of sensor data acquisition, context modeling, and data management. To ease the development of mHealth and Telemedicine apps, we developed the Mobile Sensing Framework (MSF), which dynamically installs device appropriate context sensing plug-ins that provide a wealth of information about users\u2019 mental and physical states. The MSF automatically collects information about incoming/outgoing/missed calls; apps usage; sound pressure levels; light sensor values; movement data (eg, step count); location; heart rate; etc. The MSF also includes a searchable object-based persistence layer, which is capable of rapidly serializing and de-serializing detected context data. Collected data are stored securely in the phone\u2019s database, where they can be retrieved by applications for local analysis, remote monitoring and alert generation. We developed a fully operational prototype of the MSF platform that was validated using several Android-based devices. This paper presents an overview of our approach along with a description of the experiments that are being conducted using the MSF prototype.", "num_citations": "3\n", "authors": ["1057"]}
{"title": "Genericity-a\" Missing in Action\" Key to Software Simplification and Reuse\n", "abstract": " In controlled lab experiments and industrial projects, we observed 50%-90% rates of repetitions that deliberately recurred in newly developed, well- designed programs. Most often, recurring program structures represented an important concept from software requirements or design spaces. Repetitions increased conceptual complexity and physical size of programs, and also signified unexploited reuse opportunities. Despite potential benefits, avoiding or explicating repetitions with conventional programming techniques was either impossible or would require developers to compromise other important design goals. We believe these problems are common in many program situations. We hypothesize that they have their roots in much similarity that is inherent in software, and not strong enough generic design mechanisms to represent repetitions in a unified, generic way. We discuss mixed-strategy approach that\u00a0\u2026", "num_citations": "3\n", "authors": ["1057"]}
{"title": "Cost-effective engineering of web applications pragmatic reuse: building web application product lines\n", "abstract": " Web Applications (WA) are developed and maintained under tight schedules. Much similarity across WAs creates opportunities for cutting development cost and easing evolution via reuse. This tutorial shows a practical way to exploit similarity patterns-at architecture and code levels-to simplify the design of WAs, helping to meet the unique challenges of Web engineering.", "num_citations": "3\n", "authors": ["1057"]}
{"title": "A need-oriented assessment of technological trends in web engineering\n", "abstract": " As Web technologies change and multiply fast, their comprehension, assessment, selection and adoption are likely to be increasingly difficult, accidental and sub-optimal. Most often, needs are both important elements in technology assessment/selection and drivers of technology proliferation and evolution. We believe a need-oriented organization of Web technologies, as presented in this paper, is a useful starting point for comprehending the multitude of existing and emerging Web technologies from an essential and stable perspective. We identify important technological needs in relation to a reference architecture for Web Applications, and show how different technological trends address each need. We hope the paper will be of interest to those who want to get a grasp of the Web technology landscape and understand major trends.", "num_citations": "3\n", "authors": ["1057"]}
{"title": "Flexible components with frame technology: a case study\n", "abstract": " Components are rarely reused \"as are\" most often, we must adapt components' functions, interfaces and other properties to make them fit into a specific reuse context. Therefore, reusable components must be flexible. This paper is a case study in applying frame technology to inject flexibility into components. During reuse, we can engineer anticipated variant requirements into components by customizing framed components at breakpoints marked, with the frame language commands. Framed components can be also extended with new, unexpected requirements that arise evolution. Frame technology has productivity improvements in engineering data processing COBOL systems for reuse. In this paper we show how frame technology and concepts of flexible manufacturing can be effectively applied to component systems written in Java.", "num_citations": "3\n", "authors": ["1057"]}
{"title": "A generic discretionary access control system for reuse frameworks\n", "abstract": " A reuse framework consists of an asset repository and repository tools. A repository stores assets, while tools help to manage repository and search for assets. Companies set up reuse frameworks to enforce standards and to enable sharing assets across company departments, project teams and individuals. Any reuse framework, independently of its size and purpose, must employ a mechanism to enforce company's security policies such as access control to various assets, rights to create or modify certain assets, etc. In the paper we describe a generic access control system that can be employed in a wide class of reuse frameworks.", "num_citations": "3\n", "authors": ["1057"]}
{"title": "Software reengineering for reusability\n", "abstract": " Programs are often reengineered for better maintainability or in order to migrate programs into newer computer/software platforms. However, many of the aging business systems must be also upgraded in order to meet strategic goals of an organization. To meet such ambitious objectives, we must fundamentally redesign programs, rather than merely restructure them for improved maintainability. When much program re-design is involved, the reengineering option becomes challenging at the technical level, expensive and risky. To increase the value of the reengineering solution, we address reusability issues in the context of reengineering. In this paper, we discuss lifecycle phases and outline a possible technical scenario for reengineering for reusability.< >", "num_citations": "3\n", "authors": ["1057"]}
{"title": "Inferring hints for defect fixing order from requirements-to-test-case mappings\n", "abstract": " In what order should we debug defects reported in regression testing to minimize the overall effort of repairing a program? Other than prioritizing defects from business and project managerial perspectives, technical considerations such as dependencies among defects have also to do with answering this question. Errors ripple through code - on one hand, we may want to fix defects that have wide impact on other program failures revealed by testing. But some of such root causes of failures that are affected by other defects may not be ready for correction. Without systematic impact analysis among functional program units, programmers determine the order of fixing defects mostly manually, relying on intuition. We propose a semi-automated method with filtering, visualizations\u00a0and heuristics-based computations to solve the problem. Instead of dependency graphs for impact analysis, the source\u00a0of information\u00a0\u2026", "num_citations": "2\n", "authors": ["1057"]}
{"title": "Documentation management environment for software product lines\n", "abstract": " Similar documents arise in software and business domains. Examples are user guides for different versions of a software product, contracts between vendors and clients, or legal documents. The usual practice is to capture common document formats and contents in templates that must be manually customized to a new context - often a slow, tedious, and error-prone process. We propose a method based on a proven approach developed for software reuse that simplifies and automates routine tasks involved in creating and updating families of similar documents. Our Document Management Environment (DME) provides functions to create templates capable of higher levels of document contents reuse than templates supported by word processors such as MS Word. DME allows users to designate any arbitrary document part as a template's variation point that can be customized to produce a specific document. DME\u00a0\u2026", "num_citations": "2\n", "authors": ["1057"]}
{"title": "Pragmatic Approach to Test Case Reuse-A Case Study in Android OS BiDiTests Library\n", "abstract": " Test libraries explode in size, but both practitioners and researchers report much redundancy among test cases. Similar functions require similar test cases. Redundancy may be particularly overwhelming in test libraries for mobile computing, where we need to test the same functionality implemented on various models/brands of mobile phones. Redundancies create reuse opportunities. We propose a generic adaptive test template (GATT) approach to contain explosion of test libraries by reusing common recurring test patterns instead of enumerating the same test case in many variant forms. The objective is to ease the test development and maintenance effort. The process starts with automated detection of test clones. We represent a group of similar test cases by a test template along with specifications for automated generation of test cases in a group. We illustrate GATT with examples from Android OS\u00a0\u2026", "num_citations": "2\n", "authors": ["1057"]}
{"title": "An adaptable and extensible mobile sensing framework for patient monitoring\n", "abstract": " Smartphone apps with self-monitoring and sensing capabilities can help in disease prevention; however, such context-aware applications are difficult to develop, due to the complexities of sensor data acquisition, context modeling, and data management. To ease the development of mHealth and Telemedicine apps, we developed the Mobile Sensing Framework (MSF), which dynamically installs device appropriate context sensing plug-ins that provide a wealth of information about users' mental and physical states. The MSF automatically collects information about incoming/outgoing/missed calls; apps usage; sound pressure levels; light sensor values; movement data (e.g., step count); location; heart rate; etc. The MSF also includes a searchable object-based persistence layer, which is capable of rapidly serializing and de-serializing detected context data. Collected data are stored securely in the phone's database\u00a0\u2026", "num_citations": "2\n", "authors": ["1057"]}
{"title": "Variability Management for Product Lines with XVCL.\n", "abstract": " Managing variability is the essence of software product line (PL) practice. With many variant features and complex dependencies among them, it also becomes a major challenge for effective reuse. Without an adequate technique for managing variability, we face problems such as explosion of similar component versions, or difficulty to select and then adapt component configurations during reuse-based product development. These problems often hinder development productivity and may diminish the economic benefit of reuse via PL approach. A variability management technique should also allow us to evolve products, PL members, as required by their customers, without disconnecting them from also evolving reusable assets forming PL architecture. XVCL method [7] directly addresses software reuse and evolution problems that are difficult to solve using conventional OO, architectural, component approaches, and modern platform mechanisms such as .NET, JEE or Ruby on Rails. It does that on top of and in full synergy with any programming language, design technique or platform.", "num_citations": "2\n", "authors": ["1057"]}
{"title": "Product Line Approach\n", "abstract": " What does it take to support a PL?\u2022 find sponsors for reuse among top managers\u2022 select and scope a PL\u2022 study existing systems in a PL\u2022 build system prototypes\u2022 understand commonalties and variants across PL members, gather requirements for a PL\u2022 build a generic PL architecture\u2022 manage changes (people, policies, organization)\u2022 adopt methods and tools to build products with reusable assets", "num_citations": "2\n", "authors": ["1057"]}
{"title": "Pqtl: a language for specifying program transformations\n", "abstract": " We describe a program query and transformation language, PQTL for short, a general-purpose, end-user level language to specify program transformations. PQTL provides a basis for automating program transformations in software evolution, conversion and re-engineering. In PQTL, we specify program transformations in terms of the logical program design model. Separation of the logical program design model from the actual mechanism used to compute and store program designs allows us to design a generic program transformation tool. The generic tool can be customized to the needs of a specific program transformation project, i.e., to the source language,to specific program transformation rules and to an internal program representation. PQTL is an extension of PQL, a program query language, that we use to specify program queries in the interactive analysis of programs for understanding.", "num_citations": "2\n", "authors": ["1057"]}
{"title": "Software Similarity Patterns and Clones: A Curse or Blessing?\n", "abstract": " Similarities are inherent in software. They show as software clones\u2013similar code fragments, functions, classes, source files, and bigger program structures spreading through software systems in multiple variant forms. Often, these recurring program structures represent important concepts from software requirements or design spaces. Interestingly, despite potential benefits, avoiding many of such redundancies is often either impossible or would require developers to compromise important design goals. In this paper, I discuss software similarity phenomenon, its sources, the many roles clones play in programs, the software productivity benefits that can be gained by avoiding clones, and difficulties to realize these benefits with conventional programming languages and design techniques. I point to generative techniques as a promising approach to address software redundancy problems.", "num_citations": "1\n", "authors": ["1057"]}
{"title": "Scalability of variability management: An example of industrial practice and some improvements\n", "abstract": " Having set up reusable core assets for a Software Product Line (SPL), it is a common practice to apply Variation Techniques (VTs) to manage variant features. As each VT can handle only certain types of variability, multiple VTs are often employed, such as conditional compilation, configuration parameters or build tools. Our earlier study of an SPL at Fudan Wingsoft Ltd revealed potential scalability problems of multiple VTs. As a remedy to the above problems, in the follow-up study we replaced multiple VTs originally used in the Fudan Wingsoft product line, with a single, uniform VT of XML-based Variant Configuration Language (XVCL). This paper provides a proof-of-concept that commonly used variation techniques can indeed be superseded by a subset of XVCL, in a simple and natural way. We describe the essence of the XVCL solution, and evaluate the benefits and trade-offs involved in multiple VTs solution and single VT - XVCL solution.", "num_citations": "1\n", "authors": ["1057"]}
{"title": "Pragmatic strategies for variability management in product lines in small-to medium-size companies\n", "abstract": " Most SPLs in small- to medium-size companies evolve from a single successful product. Initially, each new product variant is often developed by ad hoc reuse - copy and modify - of source code files implementing existing products. Versions of source files pertinent to different products are stored under a Software Configuration Management (SCM) tool such as CVS or SVN. As the number of customers and relevant product variants increases, such ad hoc reuse shows its limits: The product size grows as we implement new features in response to customer requests. At the same time, we need maintain all the released product variants, so we have more and more code to maintain. Also with a growing customer base (good for our business!), increasing product variability becomes a challenge for ad hoc reuse: How do we know which versions of source files should be selected from SCM repository for reuse in\u00a0\u2026", "num_citations": "1\n", "authors": ["1057"]}
{"title": "Detection and Reconciliation of Feature Inconsistencies in a Family of Product Variants\n", "abstract": " Existing product variants, developed by ad hoc reuse are often a starting point for setting up software Product Line (SPL). Understanding inconsistent features in product variants is a prerequisite to transition for ad hoc to systematic SPL reuse. We propose a method to detect and reconcile inconsistencies in product features that typically occur during product evolution. We first entail that requirements for each product variant are documented as product feature model, similar to conventional SPL feature diagrams but without variability. We then apply model differencing algorithm to identify evolutionary changes and inconsistencies among product feature models. We evaluate usefulness and scalability of our method in analysis of many product variants, characterized by many features. This paper serves as a proof of concept. We show that our method yields good results and scales to large feature models produced in\u00a0\u2026", "num_citations": "1\n", "authors": ["1057"]}
{"title": "How clones are different semantically\n", "abstract": " Clone detection and program differencing are two general techniques for detecting and analyzing similarities and differences in software. Clone detection provides a scalable and efficient way to detect similar code fragments and larger program units such as classes or directories. But it offers little explanation about the characteristics of clones. Understanding these characteristics is important during program maintenance and evolution that affect clones. Program differencing can identify detailed differences between programs. But it is limited to pair-wise comparison and is computationally expensive in general. In this paper, we propose to complement clone detection with program differencing for the purpose of explaining semantic differences among clone instances, in terms of the differences of Program Dependence Graphs of clones. We evaluate our approach with two real-world Java software systems. Our\u00a0\u2026", "num_citations": "1\n", "authors": ["1057"]}
{"title": "Generative and Component-Based Software Engineering: Second International Symposium, GCSE 2000, Erfurt, Germany, October 9-12, 2000. Revised Papers\n", "abstract": " This book constitutes the thoroughly refereed post-proceedings of the Second International Symposium on Generative and Component-Based Software Engineering, GCSE 2000, held in Erfurt, Germany in October 2000. The twelve revised full papers presented with two invited keynote papers were carefully reviewed and selected from 29 submissions. The book offers topical sections on aspects and patterns, models and paradigms, components and architectures, and Mixin-based composition and metaprogramming.", "num_citations": "1\n", "authors": ["1057"]}
{"title": "A Reuse Framework for Multi-Domain Software Development\n", "abstract": " A Reuse Framework for Multi-Domain Software Development DSpace Repository A Reuse Framework for Multi-Domain Software Development Login DSpace Home \u2192 School of Computing \u2192 Technical Reports \u2192 View Item A Reuse Framework for Multi-Domain Software Development Stan JARZABEK URI: https://dl.comp.nus.edu.sg/xmlui/handle/1900.100/1350 Date: 1996-09-01 Abstract: Abstract not available. Show full item record Files in this item Icon Name: filenotfound.pdf Size: 5.575Kb Format: PDF View/Open This item appears in the following Collection(s) Technical Reports Search DSpace Search DSpace This Collection Browse All of DSpace Communities & Collections By Issue Date Authors Titles Subjects This Collection By Issue Date Authors Titles Subjects My Account Login Register DSpace software copyright \u00a9 2002-2016 DuraSpace Theme by Contact Us | Send Feedback \u2026", "num_citations": "1\n", "authors": ["1057"]}
{"title": "A conceptual model for business re-engineering methods and tools\n", "abstract": " What do we need to know about the business in order to understand and, eventually, to improve business operations? How do we capture the business knowledge? We feel that current business re-engineering methods do not have a precise enough model of the underlying business knowledge. A model should be comprehensive enough to allow for a systematic study and precise formulation of re-engineering methods. It should also provide a framework for designing tools to support business re-engineering projects. We identified information requirements for business re-engineering based on the commonly used business re-engineering methods and case studies published in the literature. We formalized these requirements within the business knowledge model that is described in this paper.", "num_citations": "1\n", "authors": ["1057"]}
{"title": "Conceptual Modeling for Families of Software Systems\n", "abstract": " Conceptual models must be sometimes built for a family of software systems rather than for a single system. Situations when this happens include evolutionary software development, software reengineering and reuse. In all those cases a conceptual model should characterize a given application domain and all the systems in that domain, e.g., payroll. For example, in software reuse, we look for reoccurring features (or concepts) such as objects, business rules, procedures, requirement/design patterns and code modules that can be reused across payroll systems. Capturing commonalties is a primary goal of a conceptual model. But apart from commonalties, we find that there are also some variations in feature specifications from one system to another. For example, some of the employee characteristics or rules for computing employee salary may differ from one payroll system to another. The premise of work described in this paper is that conceptual models should capture both commonalties and differences across a family of similar systems. In the reuse context, if variations in feature specification are not anticipated and explicitly modeled, customization of a component for reuse will not be easy: component customization will be done in an ad hoc way and programmers will have to go through the same customization process many times. Such reuse will be expensive and resulting systems will be difficult to maintain. These problems can be avoided if we explicitly model variations in feature specification. This paper shows how such multi-version models can be created. Conceptual models are composed of frames organized in Object-Oriented way\u00a0\u2026", "num_citations": "1\n", "authors": ["1057"]}
{"title": "An Object-Oriented Model for Recovered Designs in Software Engineering\n", "abstract": " An Object-Oriented Model for Recovered Designs in Software Engineering DSpace Repository An Object-Oriented Model for Recovered Designs in Software Engineering Login DSpace Home \u2192 School of Computing \u2192 Technical Reports \u2192 View Item An Object-Oriented Model for Recovered Designs in Software Engineering Stan Jarzabek; K Tham URI: https://dl.comp.nus.edu.sg/xmlui/handle/1900.100/1282 Date: 1993-03-01 Abstract: Abstract not available. Show full item record Files in this item Icon Name: filenotfound.pdf Size: 5.575Kb Format: PDF View/Open This item appears in the following Collection(s) Technical Reports Search DSpace Search DSpace This Collection Advanced Search Browse All of DSpace Communities & Collections By Issue Date Authors Titles Subjects This Collection By Issue Date Authors Titles Subjects My Account Login Register DSpace software copyright \u00a9 2002-2016 DuraSpace \u2026", "num_citations": "1\n", "authors": ["1057"]}
{"title": "Handling Variants in Component-based Product Lines with XVCL: a Case Study\n", "abstract": " Handling variant requirements is the main challenge in supporting software product lines. In componentbased product lines, variants often affect the software architecture (component configuration and interfaces) as well as component implementation. We applied XVCL2-XML-based Variant Configuration Language\u2013to design product line architectures in a number of domain engineering projects. In this paper, we describe how XVCL helped us organize the architecture-based system engineering into three distinct steps, namely selecting architecture components and connectors, customization of components\u2019 code and connector specifications and assembling components and connectors into a working custom software system that meets required variant requirements. Yet another advantage and contribution of the described approach is that we apply a uniform mechanism to handle variants at both the architecture and code levels. We communicate our findings through a case study on the Facility Reservation System (FRS) product line.", "num_citations": "1\n", "authors": ["1057"]}
{"title": "Software Similarities: a Case Study with Some General Implications\n", "abstract": " Generic design aims at achieving non-redundancy by unifying differences among similar program concepts or structures at the design and code levels, for simplification purpose. The extent to which similar program structures deliberately spread through programs, indicates that potentials of generic design may not be fully exploited. While not all such recurring similar program structures are necessarily bad, the evidence abounds that most of them hinder program understanding and contribute much to high maintenance cost. In this paper, we present a study of similarity patterns in the Java Buffer library, JDK 1.5. We show that, given the design goals, many similarity patterns in buffer classes were difficult to avoid-refactored or otherwise unified, with conventional OO techniques. As the result, we see classes and methods, recurring many times, in the same or slightly modified form. We trace the roots of the problem and argue about the general nature of the problem\u2019s causes and symptoms.", "num_citations": "1\n", "authors": ["1057"]}
{"title": "Unifying Software Similarity Patterns with a Meta-level Generative Technique: A Case Study and Evaluation\n", "abstract": " In a previous study, we analyzed similarity patterns in the Java Buffer library, JDK 1.5. We observed many similar classes, methods and yet smaller fragments-elements of class design. We argued that, given the design goals, it was difficult to avoid those repetitions with conventional design techniques. We also argued that the reasons why the problem arises and its symptoms are common. In this paper, we describe a possible solution to the problem: We apply a meta-level method of XVCL on top of Java code, to unify differences among similar buffer classes. In a meta-level Java-XVCL solution, we represent each of the important similarity patterns in a unique generic, but adaptable, form, along with information necessary to obtain its instances\u2013specific classes or class methods. We believe such explication of similarity patterns reduces program complexity as perceived by developers. Non-redundancy achieved in that way also reduces the risk of update anomalies which helps in maintenance. As the meta-level solution does not come for free, we evaluate its strengths and weaknesses in quantitative and qualitative way, and also by conducting a controlled experiment. The presented method is based on synergistic use of a programming language (eg, Java) and meta-level parameterization and manipulation supported by XVCL, to achieve a non-redundancy of the Java-XVCL meta-level solution. The idea of the solution and the method itself is general, can be applied to any program, independently of an application domain or a programming language. We believe some of the observations from this case study apply to other class libraries, as well\u00a0\u2026", "num_citations": "1\n", "authors": ["1057"]}