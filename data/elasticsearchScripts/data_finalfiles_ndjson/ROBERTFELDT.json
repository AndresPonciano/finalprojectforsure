{"title": "Validity threats in empirical software engineering research-an initial survey.\n", "abstract": " In judging the quality of a research study it is very important to consider threats to the validity of the study and the results. This is particularly important for empirical research where there is often a multitude of possible threats. With a growing focus on empirical research methods in software engineering it is important that there is a consensus in the community on this importance, that validity analysis is done by every researcher and that there is common terminology and support on how to do and report it. Even though there are previous relevant results they have primarily focused on quantitative research methods and in particular experiments. Here we look at the existing advice and guidelines and then perform a review of 43 papers published in the ESEM conference in 2009 and analyse the validity analysis they include and which threats and strategies for overcoming them that were given by the authors. Based on this analysis we then discuss what is working well and less well in validity analysis of empirical software engineering research and present recommendations on how to better support validity analysis in the future.", "num_citations": "270\n", "authors": ["165"]}
{"title": "Behavioral software engineering: A definition and systematic literature review\n", "abstract": " Throughout the history of software engineering, the human aspects have repeatedly been recognized as important. Even though research that investigates them has been growing in the past decade, these aspects should be more generally considered.The main objective of this study is to clarify the research area concerned with human aspects of software engineering and to create a common platform for future research. In order to meet the objective, we propose a definition of the research area behavioral software engineering (BSE) and present results from a systematic literature review based on the definition.The result indicates that there are knowledge gaps in the research area of behavioral software engineering and that earlier research has been focused on a few concepts, which have been applied to a limited number of software engineering areas. The individual studies have typically had a narrow\u00a0\u2026", "num_citations": "203\n", "authors": ["165"]}
{"title": "The surprising creativity of digital evolution: A collection of anecdotes from the evolutionary computation and artificial life research communities\n", "abstract": " Evolution provides a creative fount of complex and subtle adaptations that often surprise the scientists who discover them. However, the creativity of evolution is not limited to the natural world: Artificial organisms evolving in computational environments have also elicited surprise and wonder from the researchers studying them. The process of evolution is an algorithmic process that transcends the substrate in which it occurs. Indeed, many researchers in the field of digital evolution can provide examples of how their evolving algorithms and organisms have creatively subverted their expectations or intentions, exposed unrecognized bugs in their code, produced unexpectedly adaptations, or engaged in behaviors and outcomes, uncannily convergent with ones found in nature. Such stories routinely reveal surprise and creativity by evolution in these digital worlds, but they rarely fit into the standard scientific\u00a0\u2026", "num_citations": "164\n", "authors": ["165"]}
{"title": "Automated system testing using visual gui testing tools: A comparative study in industry\n", "abstract": " Software companies are under continuous pressure to shorten time to market, raise quality and lower costs. More automated system testing could be instrumental in achieving these goals and in recent years testing tools have been developed to automate the interaction with software systems at the GUI level. However, there is a lack of knowledge on the usability and applicability of these tools in an industrial setting. This study evaluates two tools for automated visual GUI testing on a real-world, safety-critical software system developed by the company Saab AB. The tools are compared based on their properties as well as how they support automation of system test cases that have previously been conducted manually. The time to develop and the size of the automated test cases as well as their execution times have been evaluated. Results show that there are only minor differences between the two tools, one\u00a0\u2026", "num_citations": "113\n", "authors": ["165"]}
{"title": "Group development and group maturity when building agile teams: A qualitative and quantitative investigation at eight large companies\n", "abstract": " The agile approach to projects focuses more on close-knit teams than traditional waterfall projects, which means that aspects of group maturity become even more important. This psychological aspect is not much researched in connection to the building of an \u201cagile team.\u201d The purpose of this study is to investigate how building agile teams is connected to a group development model taken from social psychology. We conducted ten semi-structured interviews with coaches, Scrum Masters, and managers responsible for the agile process from seven different companies, and collected survey data from 66 group-members from four companies (a total of eight different companies). The survey included an agile measurement tool and the one part of the Group Development Questionnaire. The results show that the practitioners define group developmental aspects as key factors to a successful agile transition. Also, the\u00a0\u2026", "num_citations": "100\n", "authors": ["165"]}
{"title": "A systematic review of software robustness\n", "abstract": " ContextWith the increased use of software for running key functions in modern society it is of utmost importance to understand software robustness and how to support it. Although there have been many contributions to the field there is a lack of a coherent and summary view.ObjectiveTo address this issue, we have conducted a literature review in the field of robustness.MethodThis review has been conducted by following guidelines for systematic literature reviews. Systematic reviews are used to find and classify all existing and available literature in a certain field.ResultsFrom 9193 initial papers found in three well-known research databases, the 144 relevant papers were extracted through a multi-step filtering process with independent validation in each step. These papers were then further analyzed and categorized based on their development phase, domain, research, contribution and evaluation type. The results\u00a0\u2026", "num_citations": "87\n", "authors": ["165"]}
{"title": "Requirements traceability: a systematic review and industry case study\n", "abstract": " Requirements traceability enables software engineers to trace a requirement from its emergence to its fulfillment. In this paper we examine requirements traceability definitions, challenges, tools and techniques, by the use of a systematic review performing an exhaustive search through the years 1997\u20132007. We present a number of common definitions, challenges, available tools and techniques (presenting empirical evidence when found), while complementing the results and analysis with a static validation in industry through a series of interviews.", "num_citations": "87\n", "authors": ["165"]}
{"title": "The prospects of a quantitative measurement of agility: A validation study on an agile maturity model\n", "abstract": " Agile development has now become a well-known approach to collaboration in professional work life. Both researchers and practitioners want validated tools to measure agility. This study sets out to validate an agile maturity measurement model with statistical tests and empirical data. First, a pretest was conducted as a case study including a survey and focus group. Second, the main study was conducted with 45 employees from two SAP customers in the US. We used internal consistency (by a Cronbach\u2019s alpha) as the main measure for reliability and analyzed construct validity by exploratory principal factor analysis (PFA). The results suggest a new categorization of a subset of items existing in the tool and provides empirical support for these new groups of factors. However, we argue that more work is needed to reach the point where a maturity models with quantitative data can be said to validly measure agility\u00a0\u2026", "num_citations": "80\n", "authors": ["165"]}
{"title": "Alignment of requirements specification and testing: A systematic mapping study\n", "abstract": " Requirements should specify expectations on a software system and testing should ensure these expectations are met. Thus, to enable high product quality and efficient development it is crucial that requirements and testing activities and information are aligned. A lot of research has been done in the respective fields Requirements Engineering and Testing but there is a lack of summaries of the current state of the art on how to link the two. This study presents a systematic mapping of the alignment of specification and testing of functional or nonfunctional requirements in order to identify useful approaches and needs for future research. In particular we focus on results relevant for nonfunctional requirements but since only a few studies was found on alignment in total we also cover the ones on functional requirements. The map summarizes the 35 relevant papers found and discuss them within six major sub\u00a0\u2026", "num_citations": "70\n", "authors": ["165"]}
{"title": "Maintenance of automated test suites in industry: An empirical study on Visual GUI Testing\n", "abstract": " Context: Verification and validation (V&V) activities make up 20\u201350% of the total development costs of a software system in practice. Test automation is proposed to lower these V&V costs but available research only provides limited empirical data from industrial practice about the maintenance costs of automated tests and what factors affect these costs. In particular, these costs and factors are unknown for automated GUI-based testing.Objective: This paper addresses this lack of knowledge through analysis of the costs and factors associated with the maintenance of automated GUI-based tests in industrial practice.Method: An empirical study at two companies, Siemens and Saab, is reported where interviews about, and empirical work with, Visual GUI Testing is performed to acquire data about the technique\u2019s maintenance costs and feasibility.Results: 13 factors are observed that affect maintenance, e.g. tester\u00a0\u2026", "num_citations": "64\n", "authors": ["165"]}
{"title": "Generating diverse software versions with genetic programming: an experimental study\n", "abstract": " Software fault-tolerance schemes often employ multiple software versions developed to meet the same specification. If the versions fail independently of each other, they can be combined to give high levels of reliability. Although design diversity is a means to develop these versions, it has been questioned because it increases development costs and because reliability gains are limited by common-mode failures. The use of genetic programming is proposed to generate multiple software versions by varying parameters of the genetic programming algorithm. An environment is developed to generate programs for a controller in an aircraft arrestment system. Eighty programs have been developed and tested on 10000 test cases. The experimental data show that failure diversity is achieved, but for the top performing programs its levels are limited.", "num_citations": "62\n", "authors": ["165"]}
{"title": "Visual gui testing in practice: challenges, problemsand limitations\n", "abstract": " In today\u2019s software development industry, high-level tests such as Graphical User Interface (GUI) based system and acceptance tests are mostly performed with manual practices that are often costly, tedious and error prone. Test automation has been proposed to solve these problems but most automation techniques approach testing from a lower level of system abstraction. Their suitability for high-level tests has therefore been questioned. High-level test automation techniques such as Record and Replay exist, but studies suggest that these techniques suffer from limitations, e.g. sensitivity to GUI layout or code changes, system implementation dependencies, etc. Visual GUI Testing (VGT) is an emerging technique in industrial practice with perceived higher flexibility and robustness to certain GUI changes than previous high-level (GUI) test automation techniques. The core of VGT is image recognition which\u00a0\u2026", "num_citations": "61\n", "authors": ["165"]}
{"title": "Using factorial experiments to evaluate the effect of genetic programming parameters\n", "abstract": " Statistical techniques for designing and analyzing experiments are used to evaluate the individual and combined effects of genetic programming parameters. Three binary classification problems are investigated in a total of seven experiments consisting of 1108 runs of a machine code genetic programming system. The parameters having the largest effect in these experiments are the population size and the number of generations. A large number of parameters have negligible effects. The experiments indicate that the investigated genetic programming system is robust to parameter variations, with the exception of a few important parameters.", "num_citations": "60\n", "authors": ["165"]}
{"title": "Finding test data with specific properties via metaheuristic search\n", "abstract": " For software testing to be effective the test data should cover a large and diverse range of the possible input domain. Boltzmann samplers were recently introduced as a systematic method to randomly generate data with a range of sizes from combinatorial classes, and there are a number of automated testing frameworks that serve a similar purpose. However, size is only one of many possible properties that data generated for software testing should exhibit. For the testing of realistic software systems we also need to trade off between multiple different properties or search for specific instances of data that combine several properties. In this paper we propose a general search-based framework for finding test data with specific properties. In particular, we use a metaheuristic, differential evolution, to search for stochastic models for the data generator. Evaluation of the framework demonstrates that it is more general\u00a0\u2026", "num_citations": "52\n", "authors": ["165"]}
{"title": "Towards a behavioral software engineering\n", "abstract": " Throughout the history of Software Engineering (SE) it has been repeatedly found that the humans involved, ie the engineers and developers in addition to other stakeholders, are a key factor in determining project outcomes and success. However, the amount of research that focuses on human aspects has been limited compared to research with technology or process focus. With increasing maturity of the field, interest in agile methods and a growing dissatisfaction with the continued challenges of developing high-quality software on time, the amount of SE research putting human aspect in primary focus has increased.", "num_citations": "49\n", "authors": ["165"]}
{"title": "Transitioning manual system test suites to automated testing: An industrial case study\n", "abstract": " Visual GUI testing (VGT) is an emerging technique that provides software companies with the capability to automate previously time-consuming, tedious, and fault prone manual system and acceptance tests. Previous work on VGT has shown that the technique is industrially applicable, but has not addressed the real-world applicability of the technique when used by practitioners on industrial grade systems. This paper presents a case study performed during an industrial project with the goal to transition from manual to automated system testing using VGT. Results of the study show that the VGT transition was successful and that VGT could be applied in the industrial context when performed by practitioners but that there were several problems that first had to be solved, e.g. testing of a distributed system, tool volatility. These problems and solutions have been presented together with qualitative, and quantitative, data\u00a0\u2026", "num_citations": "43\n", "authors": ["165"]}
{"title": "On the long-term use of visual gui testing in industrial practice: a case study\n", "abstract": " Visual GUI Testing (VGT) is a tool-driven technique for automated GUI-based testing that uses image recognition to interact with and assert the correctness of the behavior of a system through its GUI as it is shown to the user. The technique\u2019s applicability, e.g. defect-finding ability, and feasibility, e.g. time to positive return on investment, have been shown through empirical studies in industrial practice. However, there is a lack of studies that evaluate the usefulness and challenges associated with VGT when used long-term (years) in industrial practice. This paper evaluates how VGT was adopted, applied and why it was abandoned at the music streaming application development company, Spotify, after several years of use. A qualitative study with two workshops and five well chosen employees is performed at the company, supported by a survey, which is analyzed with a grounded theory approach to answer\u00a0\u2026", "num_citations": "41\n", "authors": ["165"]}
{"title": "FIPA-compliant agents for real-time control of intelligent network traffic\n", "abstract": " Autonomy, adaptability, scalability, and flexible communications are all attributes of agents and multi-agent systems which suggest that they may offer timely solutions for dealing with the growing complexity of the tasks of traffic control and resource management in telecommunications networks. However, if agent-based solutions to network management problems are to be successful then it will be important that heterogeneous agents and agent platforms inter-operate in accordance with internationally accepted standards. Although standards of this nature are being developed, they are not tailored specifically to the needs of the telecommunications domain, with the result that important issues, such as support for the operation of agent systems in real-time constrained environments, do not seem to be adequately addressed. We present two agent-based systems for control of traffic load and resource allocation in\u00a0\u2026", "num_citations": "41\n", "authors": ["165"]}
{"title": "Investigating intentional distortions in software cost estimation\u2013An exploratory study\n", "abstract": " Cost estimation of software projects is an important activity that continues to be a source of problems for practitioners despite improvement efforts. Most of the research on estimation has focused on methodological issues while the research focused on human factors primarily has targeted cognitive biases or perceived inhibitors. This paper focuses on the complex organizational context of estimation and investigates whether estimates may be distorted, i.e. intentionally changed for reasons beyond legitimate changes due to changing prerequisites such as requirements or scope. An exploratory study was conducted with 15 interviewees at six large companies that develop software-intensive products. The interviewees represent five stakeholder roles in estimation, with a majority being project or line managers. Document analysis was used to complement the interviews and provided additional context. The results\u00a0\u2026", "num_citations": "37\n", "authors": ["165"]}
{"title": "Supporting software decision meetings: Heatmaps for visualising test and code measurements\n", "abstract": " To achieve software quality it is critical to quickly understand the current test status, its changes over time as well as its relation to source code changes. However, even if this information is available in test logs and code repositories it is seldomly put to good use in supporting decision processes in software development. The amount of information is often large, is time consuming to extract and hard to monitor. This case study shows how visualisation and correlation between software measurements can support improvement discussions. In particular, simple heat maps were found to be effective to visualize and monitor changes and identify recurring patterns in the development of a space-bourn, embedded control system. Statistical analysis quantified the correlation between different sources of development data and heat maps then effectively focused the attention of stakeholders to importants parts of the system\u00a0\u2026", "num_citations": "36\n", "authors": ["165"]}
{"title": "Measuring and visualizing code stability--a case study at three companies\n", "abstract": " Monitoring performance of software development organizations can be achieved from a number of perspectives - e.g. using such tools as Balanced Scorecards or corporate dashboards. In this paper we present results from a study on using code stability indicators as a tool for product stability and organizational performance, conducted at three different software development companies - Ericsson AB, Saab AB Electronic Defense Systems (Saab) and Volvo Group Trucks Technology (Volvo Group). The results show that visualizing the source code changes using heat maps and linking these visualizations to defect inflow profiles provide indicators of how stable the product under development is and whether quality assurance efforts should be directed to specific parts of the product. Observing the indicator and making decisions based on its visualization leads to shorter feedback loops between development and test\u00a0\u2026", "num_citations": "35\n", "authors": ["165"]}
{"title": "Integrating User eXperience practices into software development processes: implications of the UX characteristics\n", "abstract": " User eXperience (UX) is a key factor in the success of software systems. Many software companies face challenges in their work with UX. Existing research does not analyze UX practices and challenges in relation to other software quality characteristics or, in particular, in relation to usability. A better understanding of these challenges can help researchers and practitioners better address them in the future. In this empirical study, we have interviewed 17 practitioners with different backgrounds and occupations from eight software development companies. Their responses are coded, and analyzed with thematic analysis. We report eight themes of challenges that practitioners face in their work with UX. While some of these challenges partly overlap with those reported in existing literature about usability or other software quality characteristics, the participants of our study either view many of the challenges as unique to UX, or more severe in the case of UX. Although at a superficial level challenges of UX and other quality characteristics overlap, we differentiate these challenges at a deeper level through the five main characteristics of UX: subjective, holistic, dynamic, context-dependent and worthwhile. In particular, we identified that these characteristics have at least 20 implications (ie additional difficulties) for day-to-day work of practitioners. We found that 11 of these implications have been previously reported in literature. However, to the best of our knowledge, the remaining nine implications are unique to our study. These implications can explain why practitioners perceive the challenges to be more severe than for other quality characteristics\u00a0\u2026", "num_citations": "33\n", "authors": ["165"]}
{"title": "Ways of applying artificial intelligence in software engineering\n", "abstract": " As Artificial Intelligence (AI) techniques become more powerful and easier to use they are increasingly deployed as key components of modern software systems. While this enables new functionality and often allows better adaptation to user needs it also creates additional problems for software engineers and exposes companies to new risks. Some work has been done to better understand the interaction between Software Engineering and AI but we lack methods to classify ways of applying AI in software systems and to analyse and understand the risks this poses. Only by doing so can we devise tools and solutions to help mitigate them. This paper presents the AI in SE Application Levels (AI-SEAL) taxonomy that categorises applications according to their point of application, the type of AI technology used and the automation level allowed. We show the usefulness of this taxonomy by classifying 15 papers from\u00a0\u2026", "num_citations": "32\n", "authors": ["165"]}
{"title": "Dynamic regression test selection based on a file cache an industrial evaluation\n", "abstract": " This paper presents a simple method that computes test case coverage information from information on what files were updated to fix a fault found by the test case. It uses a cache to monitor fault-prone files and recommends test cases to rerun to cover updated files. We present an evaluation of the method during two months of development of a large, industrial, embedded, real-time software system. Our results show that the method is effective, reaching weekly cache hit rates in the range 50-80%.", "num_citations": "30\n", "authors": ["165"]}
{"title": "An initial analysis of software engineers\u2019 attitudes towards organizational change\n", "abstract": " Employees\u2019 attitudes towards organizational change are a critical determinant in the change process. Researchers have therefore tried to determine what underlying concepts that affect them. These extensive efforts have resulted in the identification of several antecedents. However, no studies have been conducted in a software engineering context and the research has provided little information on the relative impact and importance of the identified concepts. In this study, we have combined results from previous social science research with results from software engineering research, and thereby identified three underlying concepts with an expected significant impact on software engineers\u2019 attitudes towards organizational change, i.e. their knowledge about the intended change outcome, their understanding of the need for change, and their feelings of participation in the change process. The result of two\u00a0\u2026", "num_citations": "29\n", "authors": ["165"]}
{"title": "Generic skills in software engineering master thesis projects: Towards rubric-based evaluation\n", "abstract": " There has been much recent interest in how to help students in higher education develop their generic skills, especially since this is a focus of the Bologna process that aims to standardize European higher education. However, even though the Master thesis is the final and often crucial part of a graduate degree and requires many generic skills very little research has directly focused on them. In particular, there is a lack of such knowledge for engineering education programs. In this paper we present results from a survey where we asked 23 students from three different Swedish Universities about which generic skills are needed and developed in a Master thesis project in software engineering. One outcome of our analysis is that there is a lack of understanding on how to define, and thus examine, generic skills in software engineering thesis projects.", "num_citations": "29\n", "authors": ["165"]}
{"title": "Genetic programming as an explorative tool in early software development phases\n", "abstract": " Early in a software development project the developers lack knowledge about the problem to be solved by the software. Any knowledge that can be gained at an early stage can reduce the risk of making erroneous decisions and injecting defects that can be expensive to eliminate in later phases. This paper presents the idea of using genetic programming to explore the difficulty of different input data in the input space, determine the effects of different requirements and identify design trade-offs inherent in the problem. Data from a pilot experiment is analysed and the knowledge gained is used to question and prioritize the requirements on the target system. Coping with high-dimensional input spaces and establishing the relationship between GP-and human-developed programs are identified as the major outstanding problems. An extended experimental environment is proposed based on techniques for visual\u00a0\u2026", "num_citations": "29\n", "authors": ["165"]}
{"title": "Bayesian data analysis in empirical software engineering research\n", "abstract": " Statistics comes in two main flavors: frequentist and Bayesian. For historical and technical reasons, frequentist statistics have traditionally dominated empirical data analysis, and certainly remain prevalent in empirical software engineering. This situation is unfortunate because frequentist statistics suffer from a number of shortcomings---such as lack of flexibility and results that are unintuitive and hard to interpret---that curtail their effectiveness when dealing with the heterogeneous data that is increasingly available for empirical analysis of software engineering practice. In this paper, we pinpoint these shortcomings, and present Bayesian data analysis techniques that provide tangible benefits---as they can provide clearer results that are simultaneously robust and nuanced. After a short, high-level introduction to the basic tools of Bayesian statistics, we present the reanalysis of two empirical studies on the effectiveness\u00a0\u2026", "num_citations": "28\n", "authors": ["165"]}
{"title": "Generating structured test data with specific properties using Nested Monte-Carlo Search\n", "abstract": " Software acting on complex data structures can be challenging to test: it is difficult to generate diverse test data that satisfies structural constraints while simultaneously exhibiting properties, such as a particular size, that the test engineer believes will be effective in detecting faults. In our previous work we introduced G\u00f6delTest, a framework for generating such data structures using non-deterministic programs, and combined it with Differential Evolution to optimize the generation process. Monte-Carlo Tree Search (MCTS) is a search technique that has shown great success in playing games that can be represented as a sequence of decisions. In this paper we apply Nested Monte-Carlo Search, a single-player variant of MCTS, to the sequence of decisions made by the generating programs used by G\u00f6delTest, and show that this combination can efficiently generate random data structures which exhibit the specific\u00a0\u2026", "num_citations": "28\n", "authors": ["165"]}
{"title": "Evolution of statistical analysis in empirical software engineering research: Current state and steps forward\n", "abstract": " Software engineering research is evolving and papers are increasingly based on empirical data from a multitude of sources, using statistical tests to determine if and to what degree empirical evidence supports their hypotheses. To investigate the practices and trends of statistical analysis in empirical software engineering (ESE), this paper presents a review of a large pool of papers from top-ranked software engineering journals. First, we manually reviewed 161 papers and in the second phase of our method, we conducted a more extensive semi-automatic classification of papers spanning the years 2001\u20132015 and 5196 papers.Results from both review steps was used to: i) identify and analyse the predominant practices in ESE (e.g., using t-test or ANOVA), as well as relevant trends in usage of specific statistical methods (e.g., nonparametric tests and effect size measures) and, ii) develop a conceptual model for a\u00a0\u2026", "num_citations": "27\n", "authors": ["165"]}
{"title": "Human factors related challenges in software engineering--an industrial perspective\n", "abstract": " It is increasingly recognised that successful Software Engineering not only depends on technical or process issues, but requires attention to human factors. Researchers include such aspects which has led to both new theories and refined methods. However, it is not clear if professionals in the software industry agree that human factors are critical and what the related challenges and possibilities are. The purpose of the present study is to address this discrepancy. Using a qualitative research method, we elicited information about how and why human factors affect Software Engineering projects, which challenges are of special interest and the context in which they arise. Thematic analysis of data from interviews with nine senior software professionals in multiple Swedish software companies of differing size identified four main challenging areas. As supported by existing research, customer relations and\u00a0\u2026", "num_citations": "27\n", "authors": ["165"]}
{"title": "An initial industrial evaluation of interactive search-based testing for embedded software\n", "abstract": " Search-based software testing promises the ability to generate and evaluate large numbers of test cases at minimal cost. From an industrial perspective, this could enable an increase in product quality without a matching increase in the time and effort required to do so.Search-based software testing, however, is a set of quite complex techniques and approaches that do not immediately translate into a process for use with most companies.For example, even if engineers receive the proper education and training in these new approaches, it can be hard to develop a general fitness function that covers all contingencies. Furthermore, in industrial practice, the knowledge and experience of domain specialists are often key for effective testing and thus for the overall quality of the final software system. But it is not clear how such domain expertise can be utilized in a search-based system.This paper presents an interactive\u00a0\u2026", "num_citations": "26\n", "authors": ["165"]}
{"title": "Generating multiple diverse software versions with genetic programming\n", "abstract": " Software fault tolerance schemes often employ multiple software versions developed to meet the same specification. If the versions fail independently of each other, they can be combined to give high levels of reliability. While design diversity is a means to develop these versions, it has been questioned because it increases development costs and because reliability gains are limited by common mode failures. We propose the use of genetic programming to generate multiple software versions and postulate that these versions can be forced to differ by varying parameters to the genetic programming algorithm. This might prove a cost effective approach to obtain forced diversity and make possible controlled experiments with large numbers of diverse development methodologies. The paper qualitatively compares the proposed approach to design diversity and its sources of diversity. An experimental environment to\u00a0\u2026", "num_citations": "26\n", "authors": ["165"]}
{"title": "State-of-practice in GUI-based system and acceptance testing: An industrial multiple-case study\n", "abstract": " Software testing is an essential means of evaluating software quality. System and acceptance tests aim to validate a system's conformance to its requirements on a high level of system abstraction. Therefore, they are generally performed by executing end-user scenarios through the system's graphical user interface (GUI). However, to the authors' best knowledge, there are no empirical studies that evaluate how GUI-based system and acceptance testing is performed in industrial practice. In this paper, we present a multiple-case study with the goal to investigate the state-of-practice of GUI-based system and acceptance testing at six software development companies of varying context. The main findings are that manual, GUI-based system testing is widespread and that automated GUI-based system and acceptance testing exists only on a small scale. Additionally, the study identifies core problems with GUI-based\u00a0\u2026", "num_citations": "25\n", "authors": ["165"]}
{"title": "Broadening the search in search-based software testing: It need not be evolutionary\n", "abstract": " Search-based software testing (SBST) can potentially help software practitioners create better test suites using less time and resources by employing powerful methods for search and optimization. However, research on SBST has typically focused on only a few search approaches and basic techniques. A majority of publications in recent years use some form of evolutionary search, typically a genetic algorithm, or, alternatively, some other optimization algorithm inspired from nature. This paper argues that SBST researchers and practitioners should not restrict themselves to a limited choice of search algorithms or approaches to optimization. To support our argument we empirically investigate three alternatives and compare them to the de facto SBST standards in regards to performance, resource efficiency and robustness on different test data generation problems: classic algorithms from the optimization literature\u00a0\u2026", "num_citations": "24\n", "authors": ["165"]}
{"title": "Challenges with software verification and validation activities in the space industry\n", "abstract": " Developing software for high-dependable space applications and systems is a formidable task. With new political and market pressures on the space industry to deliver more software at a lower cost, optimization of their methods and standards need to be investigated. The industry has to follow standards that strictly set quality goals and prescribes engineering processes and methods to fulfill them. The overall goal of this study is to evaluate if current use of the standards from the European Cooperation for Space Standardization (ECSS) is cost efficient and if there are ways to make the process leaner while still maintaining quality and to analyze if their verification and validation (V&V) activities can be optimized. This paper presents results from two industrial case studies of companies in the European space industry that are following ECSS standards in various V&V activities. The case studies reported here focus on\u00a0\u2026", "num_citations": "24\n", "authors": ["165"]}
{"title": "A concept for an interactive search-based software testing system\n", "abstract": " Software is an increasingly important part of various products, although not always the dominant component. For these software-intensive systems it is common that the software is assembled, and sometimes even developed, by domain specialists rather than by software engineers. To leverage the domain specialists\u2019 knowledge while maintaining quality we need testing tools that require only limited knowledge of software testing.               Since each domain has unique quality criteria and trade-offs and there is a large variation in both software modeling and implementation syntax as well as semantics it is not easy to envisage general software engineering support for testing tasks. Particularly not since such support must allow interaction between the domain specialists and the testing system for iterative development.               In this paper we argue that search-based software testing can provide this type of\u00a0\u2026", "num_citations": "22\n", "authors": ["165"]}
{"title": "Confirming distortional behaviors in software cost estimation practice\n", "abstract": " Cost estimation of software projects is an important management activity. Despite research efforts the accuracy of estimates does not seem to improve. In this paper we confirm intentional distortions of estimates reported in a previous study. This study is based on questionnaire responses from 48 software practitioners from eight different companies. The results of the questionnaire suggest that prevalence of intentional distortions is affected by the organizational type and the development process in use. Further, we extend the results with information about three companies' estimation practices and related distortions collected in interviews with three managers. Lastly, based on these results and additional organizational politics theory we describe organizational politics tactics that affect cost estimates.", "num_citations": "22\n", "authors": ["165"]}
{"title": "Search-based software testing and test data generation for a dynamic programming language\n", "abstract": " Manually creating test cases is time consuming and error prone. Search-based software testing can help automate this process and thus reduce time and effort and increase quality by automatically generating relevant test cases. Previous research has mainly focused on static programming languages and simple test data inputs such as numbers. This is not practical for dynamic programming languages that are increasingly used by software developers. Here we present an approach for search-based software testing for dynamically typed programming languages that can generate test scenarios and both simple and more complex test data. The approach is implemented as a tool, RuTeG, in and for the dynamic programming language Ruby. It combines an evolutionary search for test cases that give structural code coverage with a learning component to restrict the space of possible types of inputs. The latter is\u00a0\u2026", "num_citations": "22\n", "authors": ["165"]}
{"title": "Comparing four static analysis tools for java concurrency bugs\n", "abstract": " Static analysis (SA) tools are being used for early detection of software defects. Concurrency bugs are different from bugs in sequential programs, and they are often harder to detect. This paper presents the evaluation of four static analysis tools and their capabilities to detect Java concurrency bugs and bug patterns. The tools, ie, Coverity Prevent, Jtest, FindBugs, and Jlint, are evaluated using concurrent benchmark programs and a collection of multithreaded bug patterns. In addition, we have categorized the bug pattern detectors of the tools and also identified 87 unique bug patterns from the tools\u2019 detectors and literature.", "num_citations": "22\n", "authors": ["165"]}
{"title": "Support for different roles in software engineering master's thesis projects\n", "abstract": " Like many engineering programs in Europe, the final part of most Swedish software engineering programs is a longer project in which the students write a Master's thesis. These projects are often conducted in cooperation between a university and industry, and the students often have two supervisors, one at the university and one in industry. In particular, the Bologna Process that is currently underway to align different higher educational programs in Europe discusses industrial Master's theses as a major type of thesis project. However, there is a lack of knowledge on how best to support these projects and the different stakeholders involved. This paper presents a study where students and supervisors from software engineering Master's thesis projects at three different Swedish universities are interviewed. The intention of the study is to explore what the major problems of different stakeholders are during a project\u00a0\u2026", "num_citations": "22\n", "authors": ["165"]}
{"title": "Psychological safety and norm clarity in software engineering teams\n", "abstract": " In the software engineering industry today, companies primarily conduct their work in teams. To increase organizational productivity, it is thus crucial to know the factors that affect team effectiveness. Two team-related concepts that have gained prominence lately are psychological safety and team norms. Still, few studies exist that explore these in a software engineering context.", "num_citations": "21\n", "authors": ["165"]}
{"title": "Heuristic model checking using a monte-carlo tree search algorithm\n", "abstract": " Monte-Carlo Tree Search algorithms have proven extremely effective at playing games that were once thought to be difficult for AI techniques owing to the very large number of possible game states. The key feature of these algorithms is that rather than exhaustively searching game states, the algorithm navigates the tree using information returned from a relatively small number of random game simulations. A practical limitation of software model checking is the very large number of states that a model can take. Motivated by an analogy between exploring game states and checking model states, we propose that Monte-Carlo Tree Search algorithms might also be applied in this domain to efficiently navigate the model state space with the objective of finding counterexamples which correspond to potential software faults. We describe such an approach based on Nested Monte-Carlo Search---a tree search algorithm\u00a0\u2026", "num_citations": "20\n", "authors": ["165"]}
{"title": "Do system test cases grow old?\n", "abstract": " Companies increasingly use either manual or automated system testing to ensure the quality of their software products. As a system evolves and is extended with new features the test suite also typically grows as new test cases are added. To ensure software quality throughout this process the test suite is continously executed, often on a daily basis. It seems likely that newly added tests would be more likely to fail than older tests but this has not been investigated in any detail on large-scale, industrial software systems. Also it is not clear which methods should be used to conduct such an analysis. This paper proposes three main concepts that can be used to investigate aging effects in the use and failure behaviour of system test cases: test case activation curves, test case hazard curves, and test case half-life. To evaluate these concepts and the type of analysis they enable we apply them on an industrial software\u00a0\u2026", "num_citations": "20\n", "authors": ["165"]}
{"title": "Behavioral software engineering-guidelines for qualitative studies\n", "abstract": " Researchers are increasingly recognizing the importance of human aspects in software development and since qualitative methods are used to, in-depth, explore human behavior, we believe that studies using such techniques will become more common. Existing qualitative software engineering guidelines do not cover the full breadth of qualitative methods and knowledge on using them found in the social sciences. The aim of this study was thus to extend the software engineering research community\u2019s current body of knowledge regarding available qualitative methods and provide recommendations and guidelines for their use.With the support of a literature review, we suggest that future research would benefit from (1) utilizing a broader set of research methods,(2) more strongly emphasizing reflexivity, and (3) employing qualitative guidelines and quality criteria. We present an overview of three qualitative methods commonly used in social sciences but rarely seen in software engineering research, namely interpretative phenomenological analysis, narrative analysis, and discourse analysis. Furthermore, we discuss the meaning of reflexivity in relation to the software engineering context and suggest means of fostering it. Our paper will help software engineering researchers better select and then guide the application of a broader set of qualitative research methods.", "num_citations": "19\n", "authors": ["165"]}
{"title": "An interactive software development workbench based on biomimetic algorithms\n", "abstract": " Based on a theory for software development that focus on the internal models of the developer this paper presents a design for an interactive workbench to support the iterative refinement of developers models. The goal for the workbench is to expose unknown features of the software being developed so that the developer can check if they correspond to his expectations. The workbench employs a biomimetic search system to find tests with novel features. The search system assembles test templates from small pieces of test code and data packaged into a cell. We describe a prototype of the workbench implemented in Ruby and focus on the module used for evolving tests. A case study show that the prototype supports development of tests that are both diverse, complete and have a meaning to the developer. Furthermore, the system can easily be extended by the developer when he comes up with new test strategies.", "num_citations": "18\n", "authors": ["165"]}
{"title": "Group Maturity and Agility, Are They Connected?--A Survey Study\n", "abstract": " The focus on psychology has increased within software engineering due to the project management innovation \"agile development processes\". The agile methods do not explicitly consider group development aspects, they simply assume what is described in group psychology as mature groups. This study was conducted with 45 employees and their twelve managers (N=57) from two SAP customers in the US that were working with agile methods, and the data were collected via an online survey. The selected Agility measurement was correlated to a Group Development measurement and showed significant convergent validity, i.e., A more mature team is also a more agile team. This means that the agile methods probably would benefit from taking group development into account when its practices are being introduced.", "num_citations": "17\n", "authors": ["165"]}
{"title": "Predicting fault inflow in highly iterative software development processes: an industrial evaluation\n", "abstract": " This paper addresses the need for accurate predictions on the fault inflow, ie the number of faults found in the consecutive project weeks, in highly iterative processes. In such processes, in contrast to waterfall-like processes, fault repair and development of new features run almost in parallel. Given accurate predictions on fault inflow, managers could dynamically re-allocate resources between these different tasks in a more adequate way. Furthermore, managers could react with process improvements when the expected fault inflow is higher than desired. This study suggests software reliability growth models (SRGMs) for predicting fault inflow. Originally developed for traditional processes, the performance of these models in highly iterative processes is investigated. Additionally, a simple linear model is developed and compared to the SRGMs. The paper provides results from applying these models on fault data from three different industrial projects. One of the key findings of this study is that some SRGMs are applicable for predicting fault inflow in highly iterative processes. Moreover, the results show that the simple linear model represents a valid alternative to the SRGMs, as it provides reasonably accurate predictions and performs better in many cases.", "num_citations": "17\n", "authors": ["165"]}
{"title": "Integrating UX principles and practices into software development organizations: A case study of influencing events\n", "abstract": " Current studies on User eXperience (UX) integration often do not investigate or reflect on the transition companies go through from only developing Graphical User Interfaces (GUI) to also considering usability and more recently UX. Understanding this transition provides a more holistic and realistic picture of integration and can be a rich source of knowledge for improving UX integration in the software industry. Applying case study and grounded theory research we show that UX integration, like other organizational changes, can include a mixture of planned and emergent initiatives, and is influenced by various intertwined events; not only those that reside inside an organization but also those external to it. We also show that different decisions that are made outside the authority of UX practitioners have an inevitable impact on enabling or prohibiting UX integration. In addition, we found that for a successful\u00a0\u2026", "num_citations": "16\n", "authors": ["165"]}
{"title": "Work motivational challenges regarding the interface between agile teams and a non-agile surrounding organization: A case study\n", "abstract": " There are studies showing what happens if agile teams are introduced into a non-agile organization, e.g. Higher overhead costs and the necessity of an understanding of agile methods even outside the teams. This case study shows an example of work motivational aspects that might surface when an agile team exists in the middle of a more traditional structure. This case study was conducted at a car manufacturer in Sweden, consisting of an unstructured interview with the Scrum Master and a semi-structured focus group. The results show that the teams felt that the feedback from the surrounding organization was unsynchronized resulting in them not feeling appreciated when delivering their work. Moreover, they felt frustrated when working on non-agile teams after have been working on agile ones. This study concludes that there were work motivational affects of fitting an agile team into a non-agile surrounding\u00a0\u2026", "num_citations": "15\n", "authors": ["165"]}
{"title": "Industrial application of visual GUI testing: Lessons learned\n", "abstract": " A large body of academic knowledge has been devoted to automated software testing in order to support the software market\u2019s demands for continuous software delivery. However, most of these automated techniques approach testing from lower levels of system abstraction, e.g., component level, which limit their applicability for high-level regression testing of, for instance, system and acceptance tests, thus forcing companies to perform these test activities manually, which is considered time consuming, tedious, and error prone.             In this book chapter, we present visual GUI testing (VGT), a tool driven test technique that uses image recognition in order to interact and assert the correctness of a system under test (SUT) through the bitmap graphical user interface (GUI) that is shown to the user on the computer monitor. This approach makes VGT flexible and applicable to any SUT with a GUI but also allows\u00a0\u2026", "num_citations": "14\n", "authors": ["165"]}
{"title": "Exploring the human and organizational aspects of software cost estimation\n", "abstract": " Cost estimation is important for planning, scheduling, budgeting and pricing of software development. Previous research has mainly focused on improving estimates and the associated processes. However, there is still a lack of research on human and organizational aspects of cost estimation and informal uses of cost estimates. This paper presents initial findings from a qualitative study addressing these questions. Based on four semi-structured interviews with experienced managers from different software developing organizations we have identified a number of aspects not commonly discussed in the cost estimation literature. The analysis indicates that cost estimates are used not only for prediction and planning, but also play a role in power plays within the organizations based on the stakeholders' differing interests. There are also human and organizational factors that are likely to influence the quality of estimates.", "num_citations": "14\n", "authors": ["165"]}
{"title": "Involving external stakeholders in project courses\n", "abstract": " Problem: The involvement of external stakeholders in capstone projects and project courses is desirable due to its potential positive effects on the students. Capstone projects particularly profit from the inclusion of an industrial partner to make the project relevant and help students acquire professional skills. In addition, an increasing push towards education that is aligned with industry and incorporates industrial partners can be observed. However, the involvement of external stakeholders in teaching moments can create friction and could, in the worst case, lead to frustration of all involved parties. Contribution: We developed a model that allows analysing the involvement of external stakeholders in university courses both in a retrospective fashion, to gain insights from past course instances, and in a constructive fashion, to plan the involvement of external stakeholders. Key Concepts: The conceptual model and the\u00a0\u2026", "num_citations": "13\n", "authors": ["165"]}
{"title": "Objective re-weighting to guide an interactive search based software testing system\n", "abstract": " Even hardware-focused industries today develop products where software is both a large and important component. Engineers tasked with developing and integrating these products do not always have a software engineering background. To ensure quality, tools are needed that automate and support software testing while allowing these domain specialists to leverage their knowledge and experience. Search-based testing could be a key aspect in creating an automated tool for supporting testing activities. However, domain specific quality criteria and trade-offs make it difficult to develop a general fitness function a priori, so interaction between domain specialists and such a tool would be critical to its success. In this paper we present a system for interactive search-based software testing and investigate a way for domain specialists to guide the search by dynamically re-weighting quality goals. Our empirical\u00a0\u2026", "num_citations": "13\n", "authors": ["165"]}
{"title": "ECSS standard compliant agile software development: an industrial case study\n", "abstract": " Developing software for high-dependability space applications and systems is a formidable task. The industry has a long tradition of developing standards that strictly sets quality goals and prescribes engineering processes and methods to fulfill them. The ECSS standards is a recent addition, but being built on the PSS-05, it has a legacy of plan-driven software processes. With new political and market pressures on the space industry to deliver more software at a lower cost, alternative methods need to be investigated. In particular, the agile development processes studied and practiced in the Software Engineering field at large has tempting properties. This paper presents results from an industrial case study on a company in the European space industry that is using agile software development methods in ECSS projects. We discuss success factors based on detailed process and document analysis as well as\u00a0\u2026", "num_citations": "13\n", "authors": ["165"]}
{"title": "Towards a framework for specifying software robustness requirements based on patterns\n", "abstract": " [Context and motivation] With increasing use of software, quality attributes grow in relative importance. Robustness is a software quality attribute that has not received enough attention in requirements engineering even though it is essential, in particular for embedded and real-time systems. [Question/Problem] A lack of structured methods on how to specify robustness requirements generally has resulted in incomplete specification and verification of this attribute and thus potentially a lower quality. Currently, the quality of robustness specification is mainly dependent on stakeholder experience and varies wildly between companies and projects. [Principal idea/results] Methods targeting other non-functional properties such as safety and performance suggest that certain patterns occur in specification of requirements, regardless of project and company context. Our initial analysis with industrial\u00a0\u2026", "num_citations": "13\n", "authors": ["165"]}
{"title": "Detecting defects with an interactive code review tool based on visualisation and machine learning\n", "abstract": " Code review is often suggested as a means of improving code quality. Since humans are poor at repetitive tasks, some form of tool support is valuable. To that end we developed a prototype tool to illustrate the novel idea of applying machine learning (based on Normalised Compression Distance) to the problem of static analysis of source code. Since this tool learns by example, it is trivially programmer adaptable. As machine learning algorithms are notoriously difficult to understand operationally (they are opaque) we applied information visualisation to the results of the learner. In order to validate the approach we applied the prototype to source code from the open-source project Samba and from an industrial, telecom software system. Our results showed that the tool did indeed correctly find and classify problematic sections of code based on training examples.", "num_citations": "13\n", "authors": ["165"]}
{"title": "Visualizing test diversity to support test optimisation\n", "abstract": " Diversity has been used as an effective criteria to optimise test suites for cost-effective testing. Particularly, diversity-based (alternatively referred to as similarity-based) techniques have the benefit of being generic and applicable across different Systems Under Test (SUT), and have been used to automatically select or prioritise large sets of test cases. However, there is a challenge in how to present diversity information to developers and testers since results are typically many-dimensional. Furthermore, the generality of diversity-based approaches makes it harder to choose when and where to apply them. In this paper we address these challenges by investigating: i) what are the trade-offs in using different sources of diversity (e.g., diversity of test requirements or test scripts) to optimise large test suites, and ii) how visualisation of test diversity data can assist testers for test optimisation and improvement. We perform\u00a0\u2026", "num_citations": "11\n", "authors": ["165"]}
{"title": "RobusTest: A framework for automated testing of software robustness\n", "abstract": " Robustness of a software system is defined as the degree to which the system can behave ordinarily and in conformance with the requirements in extraordinary situations. By increasing the robustness many failures which decrease the quality of the system can be avoided or masked. When it comes to specifying, testing and assessing software robustness in an efficient manner the methods and techniques are not mature yet. This paper presents RobusTest, a framework for testing robustness properties of a system with currently focus on timing issues. The expected robust behavior of the system is formulated as properties. The properties are then used to automatically generate robustness test cases and assess the results. An implementation of RobusTest in Java is presented here together with results from testing different, open-source implementations of the XMPP instant messaging protocol. By executing 400 test\u00a0\u2026", "num_citations": "11\n", "authors": ["165"]}
{"title": "Misaligned values in software engineering organizations\n", "abstract": " The values of software organizations are crucial for achieving high performance; in particular, agile development approaches emphasize their importance. Researchers have thus far often assumed that a specific set of values, compatible with the development methodologies, must be adopted homogeneously throughout the company. It is not clear, however, to what extent such assumptions are accurate. Preliminary findings have highlighted the misalignment of values between groups as a source of problems when engineers discuss their challenges. Therefore, in this study, we examine how discrepancies in values between groups affect software companies' performance. To meet our objectives, we chose a mixed method research design. First, we collected qualitative data by interviewing fourteen (N\u2009 = \u200914) employees working in four different organizations and processed it using thematic analysis. We then\u00a0\u2026", "num_citations": "10\n", "authors": ["165"]}
{"title": "Transferring interactive search-based software testing to industry\n", "abstract": " Context: Search-Based Software Testing (SBST), and the wider area of Search-Based Software Engineering (SBSE), is the application of optimization algorithms to problems in software testing, and software engineering, respectively. New algorithms, methods, and tools are being developed and validated on benchmark problems. In previous work, we have also implemented and evaluated Interactive Search-Based Software Testing (ISBST) tool prototypes, with a goal to successfully transfer the technique to industry.Objective: While SBST and SBSE solutions are often validated on benchmark problems, there is a need to validate them in an operational setting, and to assess their performance in practice. The present paper discusses the development and deployment of SBST tools for use in industry, and reflects on the transfer of these techniques to industry.Method: In addition to previous work discussing the\u00a0\u2026", "num_citations": "10\n", "authors": ["165"]}
{"title": "Biomimetic software engineering techniques for dependability\n", "abstract": " The powerful information processing capabilities of computers have made them an indispensable part of our modern societies. As we become more reliant on computers and want them to handle more critical and difficult tasks it becomes important that we can depend on the software that controls them. Methods that help ensure software dependability is thus of utmost importance.", "num_citations": "10\n", "authors": ["165"]}
{"title": "Integrating User eXperience Practices into Software Development Processes: Implications of Subjectivity and Emergent Nature of UX\n", "abstract": " Many software companies face challenges in their work with User eXperience (UX) and how to integrate UX practices into existing development processes. A better understanding of these challenges can help researchers and practitioners better address them. Existing research does not analyse UX challenges in relation to other software quality characteristics including usability. In this empirical study, we have interviewed 17 practitioners from eight software development companies. Their responses are coded and analysed with thematic analysis. We report 11 challenges that practitioners face in their work with UX. Some of these challenges partly overlap with those reported in existing literature about usability or software quality characteristics. In contrast to these overlaps, the participants of our study either view many of the challenges unique to UX, or more severe than for usability or other quality characteristics. Although at a superficial level challenges with UX and other quality characteristics overlap, we differentiate these challenges at a deeper level through two main aspects of UX: subjectivity and emergent nature. In particular, we identify at least five issues that are essential to the very nature of UX, and add at least seven extra difficulties to the work of practitioners. These difficulties can explain why practitioners perceive the challenges to be more severe than for other quality characteristics. Our findings can be useful for researchers in identifying industrially relevant research areas and for practitioners to learn from empirically investigated challenges and base their improvement efforts on such knowledge. Investigating the overlaps can help\u00a0\u2026", "num_citations": "9\n", "authors": ["165"]}
{"title": "Using exploration focused techniques to augment search-based software testing: An experimental evaluation\n", "abstract": " Search-based software testing (SBST) often uses objective-based approaches to solve testing problems. There are, however, situations where the validity and completeness of objectives cannot be ascertained, or where there is insufficient information to define objectives at all. Incomplete or incorrect objectives may steer the search away from interesting behavior of the software under test (SUT) and from potentially useful test cases. This papers investigates the degree to which exploration-based algorithms can be used to complement an objective-based tool we have previously developed and evaluated in industry. In particular, we would like to assess how exploration-based algorithms perform in situations where little information on the behavior space is available a priori. We have conducted an experiment comparing the performance of an exploration-based algorithm with an objective-based one on a problem\u00a0\u2026", "num_citations": "9\n", "authors": ["165"]}
{"title": "The automated generation of humancomprehensible XML test sets\n", "abstract": " Extensible Markup Language (XML) is often used to encode complex data structures that are the inputs to software, either in the form of configuration files that the control the behaviour of the software, or the data on which the software operates. There are typically many domain-specific constraints on the hierarchy of elements in the XML, the attributes associated with each element, and the types of data that both elements and attributes contain. As a result, the automatic generation of valid XML inputs is beyond the capabilities of many test data generation techniques. However it is not sufficient to simply generate test sets consisting of valid XML inputs: the test cases must also exhibit other properties that facilitate testing. In the absence of an automated oracle it should not be unnecessarily difficult for a test engineer to predict the correct output of a test case, and thus a desirable property of a test case is its comprehensibility by a human.In this paper we demonstrate the use of the G\u00f6delTest framework in generating XML test inputs, and show the generation strategy can be optimised using Nested Monte-Carlo Search to produce test cases that are more comprehensible by the test engineer. Moreover, when the validity of the inputs is defined using an XML Schema definition, we show that it is possible to automate much of the generation process and thereby realise significant savings of time and effort.", "num_citations": "9\n", "authors": ["165"]}
{"title": "Searching for models to evaluate software technology\n", "abstract": " Modeling and abstraction is key in all engineering processes and have found extensive use also in software engineering. When developing new methodologies and techniques to support software engineers we want to evaluate them on realistic models. However, this is a challenge since (1) it is hard to get industry to give access to their models, and (2) we need a large number of models to systematically evaluate a technology. This paper proposes that search-based techniques can be used to search for models with desirable properties, which can then be used to systematically evaluate model-based technologies. By targeting properties seen in industrial models we can then get the best of both worlds: models that are similar to models used in industry but in quantities that allow extensive experimentation. To exemplify our ideas we consider a specific case in which a model generator is used to create models to\u00a0\u2026", "num_citations": "9\n", "authors": ["165"]}
{"title": "Indirect effects in evidential assessment: a case study on regression test technology adoption\n", "abstract": " Background: There is a need for efficient regression testing in most software development organizations. Often the proposed solutions involve automation. However, despite this being a well researched area, research results are rarely applied in industrial practice. Aim: In this paper we aim to bridge the gap between research and practice by providing examples of how evidence-based regression testing approaches can be adopted in industry. We also discuss challenges for the research community. Method: An industrial case study was carried out to evaluate the possibility to improve regression testing at Sony Ericsson Mobile Communications. We analyse the procedure undertaken based on frameworks from the evidence based software engineering, EBSE, paradigm (with a focus on the evidence) and automation literature (with a focus on the practical effects). Results: Our results pinpoint the need for systematic\u00a0\u2026", "num_citations": "9\n", "authors": ["165"]}
{"title": "Generating controllably invalid and atypical inputs for robustness testing\n", "abstract": " One form of robustness in a software system is its ability to handle, in an appropriate manner, inputs that are unexpected compared to those it would experience in normal operation. In this paper we investigate a generic approach to generating such unexpected test inputs by extending a framework that we have previously developed for the automated creation of complex and high-structured test data. The approach is applied to the generation of valid inputs that are atypical as well as inputs that are invalid. We demonstrate that our approach enables control of the 'degree' to which the test data is invalid or atypical, and show empirically that this can alter the extent to which the robustness of a software system is exercised during testing.", "num_citations": "8\n", "authors": ["165"]}
{"title": "Assessment and support for software capstone projects at the undergraduate level: A survey and rubrics\n", "abstract": " Software engineering and computer science students conduct a capstone project during the final year of their degree programs. These projects are essential in validating that students have gained required knowledge and they can synthesize and use that knowledge to solve real world problems. However, the external requirements on educational programs often do not provide detailed guidelines for how to conduct or support these capstone projects, which may lead to variations among universities. This paper presents the results from a survey conducted at 19 different Pakistani universities of the current management practices and assessment criteria used for the capstone project courses at Undergraduate level. Based upon the results of this survey and similar work on Master Thesis capstone projects in Sweden, we present assessment rubrics for software-related undergraduate capstone projects. We also\u00a0\u2026", "num_citations": "8\n", "authors": ["165"]}
{"title": "Practitioner-oriented visualization in an interactive search-based software test creation tool\n", "abstract": " Search-based software testing uses meta-heuristic search techniques to automate or partially automate testing tasks, such as test case generation or test data generation. It uses a fitness function to encode the quality characteristics that are relevant, for a given problem, and guides the search to acceptable solutions in a potentially vast search space. From an industrial perspective, this opens up the possibility of generating and evaluating lots of test cases without raising costs to unacceptable levels. First, however, the applicability of search-based software engineering in an industrial setting must be evaluated. In practice, it is difficult to develop a priori a fitness function that covers all practical aspects of a problem. Interaction with human experts offers access to experience that is otherwise unavailable and allows the creation of a more informed and accurate fitness function. Moreover, our industrial partner has\u00a0\u2026", "num_citations": "7\n", "authors": ["165"]}
{"title": "Industrial challenges with quality requirements in safety critical software systems\n", "abstract": " Budget constraints and the difficulty to specify quality requirements, such as reliability, robustness, and safety present challenges to many software companies in particular if they develop safety-critical systems. Failing to specify this type of requirements properly can lead to misunderstandings between the developers and the customers, which can threaten the quality of the system. However, little information is available on how companies currently work with these requirements. This paper describes the state of requirements engineering practice and identifies challenges with quality requirements by conducting a requirements analysis on two projects, including 980 requirements, at a company developing safety-critical systems. We also compare to similar results for a company developing end user software. Problematic and ambiguous requirements have caused misunderstandings with the customers and\u00a0\u2026", "num_citations": "7\n", "authors": ["165"]}
{"title": "Evolving the ECSS standards and their Use: Experience based on Industrial Case Studies\n", "abstract": " This paper introduces two case studies conducted at two Swedish companies developing software for the space industry. The overall goal of the project is to evaluate if current use of ECSS is cost efficient and if there are ways to make the process leaner while maintaining quality. The case studies reported on here focused on how the ECSS standard was used by the companies and how that affected software development processes and software quality. This paper describes the results and recommendations based on identified challenges.", "num_citations": "6\n", "authors": ["165"]}
{"title": "Estimating return on investment for GUI test automation tools\n", "abstract": " Automated graphical user interface (GUI) tests can reduce manual testing activities and increase test frequency. This motivates the conversion of manual test cases into automated GUI tests. However, it is not clear whether such automation is cost-effective given that GUI automation scripts add to the code base and demand maintenance as a system evolves. In this paper, we introduce a method for estimating maintenance cost and Return on Investment (ROI) for Automated GUI Testing (AGT). The method utilizes the existing source code change history and can be used for evaluation also of other testing or quality assurance automation technologies. We evaluate the method for a real-world, industrial software system and compare two fundamentally different AGT tools, namely Selenium and EyeAutomate, to estimate and compare their ROI. We also report on their defect-finding capabilities and usability. The quantitative data is complemented by interviews with employees at the case company. The method was successfully applied and estimated maintenance cost and ROI for both tools are reported. Overall, the study supports earlier results showing that implementation time is the leading cost for introducing AGT. The findings further suggest that while EyeAutomate tests are significantly faster to implement, Selenium tests require more of a programming background but less maintenance.", "num_citations": "5\n", "authors": ["165"]}
{"title": "Bayesian Data Analysis in Empirical Software Engineering: The Case of Missing Data\n", "abstract": " Bayesian data analysis (BDA) is today used by a multitude of research disciplines. These disciplines use BDA as a way to embrace uncertainty by using multilevel models and making use of all available information at hand. In this chapter, we first introduce the reader to BDA and then provide an example from empirical software engineering, where we also deal with a common issue in our field, i.e., missing data. The example we make use of presents the steps done when conducting state-of-the-art statistical analysis. First, we need to understand the problem we want to solve. Second, we conduct causal analysis. Third, we analyze non-identifiability. Fourth, we conduct missing data analysis. Finally, we do a sensitivity analysis of priors. All this before we design our statistical model. Once we have a model, we present several diagnostics one can use to conduct sanity checks. We hope that through these examples\u00a0\u2026", "num_citations": "4\n", "authors": ["165"]}
{"title": "Behavioral software engineering: Methodological introduction to psychometrics\n", "abstract": " CCS Concepts:\u2022 Software and its engineering;\u2022 Human-centered computing\u2192 Empirical studies in collaborative and social computing;\u2022 General and reference\u2192 Reference works; Surveys and overviews; General literature; Cross-computing tools and techniques; Empirical studies; Measurement; Evaluation; Validation;\u2022 Applied computing\u2192 Psychology;", "num_citations": "4\n", "authors": ["165"]}
{"title": "Automated random testing in multiple dispatch languages\n", "abstract": " In programming languages that use multiple dispatch, a single function can have multiple implementations, each of which may specialise the function's operation. Which one of these implementations to execute is determined by the data types of all the arguments to the function. Effective testing of functions that use multiple dispatch therefore requires diverse test inputs in terms of the data types of the input's arguments as well as their values. In this paper we describe an approach for generating test inputs where both the values and types are chosen probabilistically. The approach uses reflection to automatically determine how to create inputs with the desired types, and dynamically updates the probability distribution from which types are sampled in order to improve both the test efficiency and efficacy. We evaluate the technique on 247 methods across 9 built-in functions of Julia, a technical computing language that\u00a0\u2026", "num_citations": "4\n", "authors": ["165"]}
{"title": "An effective verification strategy for testing distributed automotive embedded software functions: A case study\n", "abstract": " Integration testing of automotive embedded software functions that are distributed across several Electronic Control Unit (ECU) system software modules is a complex and challenging task in\u00a0today\u2019s automotive industry. They neither have infinite resources, nor have the time to carry out exhaustive testing of these functions. On the other hand, the traditional approach of implementing an ad-hoc selection of test scenarios based on the testers\u2019 experience typically leads to both test gaps and test redundancies. Here, we address this challenge by proposing a verification strategy that enhances the process in order to identify and mitigate such gaps and redundancies in automotive system software testing. This helps increase test coverage by taking more data-driven decisions for integration testing of the functions. The strategy was developed in a case study at a Swedish automotive company that involved\u00a0\u2026", "num_citations": "4\n", "authors": ["165"]}
{"title": "An initial analysis of differences in software engineers' attitudes towards organizational change\n", "abstract": " The ability to manage change is important in software engineering organizations, where rapid progress in technologies and constantly evolving methodologies create a turbulent environment. Research has identified employees' attitudes towards organizational change as a key factor in the change process. Nonetheless, few studies exist that explore such attitudes in a software engineering context.", "num_citations": "4\n", "authors": ["165"]}
{"title": "Optimizing verification and validation activities for software in the space industry\n", "abstract": " Software for space applications has special requirements in terms of reliability and dependability and the verification & validation activities (VAs) of these systems often account for more than 50% of the development effort. The industry is also faced with political and market pressure to deliver software faster and cheaper. Thus new ways are needed to optimize these activities so that high quality can be retained even with reduced costs and effort. Here we present a framework for the management and optimization of verification & validation activities (VAMOS). An initial evaluation of the framework based on historical data as well as data extracted with a new tool has been done and are described briefly.", "num_citations": "4\n", "authors": ["165"]}
{"title": "Professional and Ethical Issues of Software Engineering Curricula\n", "abstract": " The increasing dependence on computers for critical infrastructures essential for the functioning of a society and its economy has given rise to host of ethical, social, and legal issues. The ability to make sound ethical decisions is thus an important part of Computing and Software engineer\u2019s professional skills. This paper argues for the significance of teaching professional, social and ethical issues in Software Engineering in a Swedish context and practice. Examples are presented of teaching materials and experiences from the course Professional Ethics in Science and Engineering at M\u00e4lardalen University, and the PIFF project for support of Software Engineering Master Theses running at M\u00e4lardalen University, Blekinge Institute of Technology and Lund University.", "num_citations": "4\n", "authors": ["165"]}
{"title": "Professional and ethical issues of software engineering curriculum applied in swedish academic context\n", "abstract": " The increasing dependence on computers for critical infrastructures essential for the functioning of a society and its economy has given rise to host of ethical, social, and legal issues. The ability to make sound ethical decisions is thus an important part of Computing and Software engineer  s professional skills. This paper argues for the significance of teaching professional, social and ethical issues in Software Engineering in a Swedish context and practice. Examples are presented of teaching materials and experiences from the course Professional Ethics in Science and Engineering at Malardalen University, and the PIFF project for support of Software Engineering Master Theses running at Malardalen University, Blekinge Institute of Technology and Lund University.", "num_citations": "4\n", "authors": ["165"]}
{"title": "Early detection of sepsis using artificial intelligence: a scoping review protocol\n", "abstract": " Sepsis is a life-threatening organ dysfunction caused by a dysregulated host response to infection. To decrease the high case fatality rates and morbidity for sepsis and septic shock, there is a need to increase the accuracy of early detection of suspected sepsis in prehospital and emergency department settings. This may be achieved by developing risk prediction decision support systems based on artificial intelligence. The overall aim of this scoping review is to summarize the literature on existing methods for early detection of sepsis using artificial intelligence. The review will be performed using the framework formulated by Arksey and O\u2019Malley and further developed by Levac and colleagues. To identify primary studies and reviews that are suitable to answer our research questions, a comprehensive literature collection will be compiled by searching several sources. Constrictions regarding time and language will have to be implemented. Therefore, only studies published between 1 January 1990 and 31 December 2020 will be taken into consideration, and foreign language publications will not be considered, i.e., only papers with full text in English will be included. Databases/web search engines that will be used are PubMed, Web of Science Platform, Scopus, IEEE Xplore, Google Scholar, Cochrane Library, and ACM Digital Library. Furthermore, clinical studies that have completed patient recruitment and reported results found in the database ClinicalTrials.gov will be considered. The term artificial intelligence is viewed broadly, and a wide range of machine learning and mathematical models suitable as base for decision support will be\u00a0\u2026", "num_citations": "3\n", "authors": ["165"]}
{"title": "Towards a Model of Testers' Cognitive Processes: Software Testing as a Problem Solving Approach\n", "abstract": " Software testing is a complex, intellectual activity based (at least) on analysis, reasoning, decision making, abstraction and collaboration performed in a highly demanding environment. Naturally, it uses and allocates multiple cognitive resources in software testers. However, while a cognitive psychology perspective is increasingly used in the general software engineering literature, it has yet to find its place in software testing. To the best of our knowledge, no theory of software testers' cognitive processes exists. Here, we take the first step towards such a theory by presenting a cognitive model of software testing based on how problem solving is conceptualized in cognitive psychology. Our approach is to instantiate a general problem solving process for the specific problem of creating test cases. We then propose an experiment for testing our cognitive test design model. The experiment makes use of verbal protocol\u00a0\u2026", "num_citations": "3\n", "authors": ["165"]}
{"title": "Using mutation testing to measure behavioural test diversity\n", "abstract": " Diversity has been proposed as a key criterion to improve testing effectiveness and efficiency. It can be used to optimise large test repositories but also to visualise test maintenance issues and raise practitioners' awareness about waste in test artefacts and processes. Even though these diversitybased testing techniques aim to exercise diverse behavior in the system under test (SUT), the diversity has mainly been measured on and between artefacts (e.g., inputs, outputs or test scripts). Here, we introduce a family of measures to capture behavioural diversity (b-div) of test cases by comparing their executions and failure outcomes. Using failure information to capture the SUT behaviour has been shown to improve effectiveness of history-based test prioritisation approaches. However, historybased techniques require reliable test execution logs which are often not available or can be difficult to obtain due to flaky tests\u00a0\u2026", "num_citations": "3\n", "authors": ["165"]}
{"title": "On the industrial applicability of augmented testing: An empirical study\n", "abstract": " Testing applications with graphical user Interfaces (GUI) is an important but also a time-consuming task in practice. Tools and frameworks for GUI test automation can make the test execution more efficient and lower the manual labor required for regression testing. However, the test scripts used for automated GUI-based testing still require a substantial development effort and are often reported as sensitive to change, leading to frequent and costly maintenance. The efficiency of development, maintenance, and evolution of such tests are thereby dependent on the readability of scripts and the ease-of-use of test tools/frameworks in which the test scripts are defined. To address these shortcomings in existing state-of-practice techniques, a novel technique referred to as Augmented Testing (AT) has been proposed. AT is defined as testing the System Under Test (SUT) through an Augmented GUI that superimposes\u00a0\u2026", "num_citations": "3\n", "authors": ["165"]}
{"title": "Boundary Value Exploration for Software Analysis\n", "abstract": " For software to be reliable and resilient, it is widely accepted that tests must be created and maintained alongside the software itself. One safeguard from vulnerabilities and failures in code is to ensure correct behavior on the boundaries between subdomains of the input space. So-called boundary value analysis (BVA) and boundary value testing (BVT) techniques aim to exercise those boundaries and increase test effectiveness. However, the concepts of BVA and BVT themselves are not generally well defined, and it is not clear how to identify relevant sub-domains, and thus the boundaries delineating them, given a specification. This has limited adoption and hindered automation. We clarify BVA and BVT and introduce Boundary Value Exploration (BVE) to describe techniques that support them by helping to detect and identify boundary inputs. Additionally, we propose two concrete BVE techniques based on\u00a0\u2026", "num_citations": "3\n", "authors": ["165"]}
{"title": "Estimating return on investment for GUI test automation frameworks\n", "abstract": " Automated graphical user interface (GUI) tests can reduce manual testing activities and increase test frequency. This motivates the conversion of manual test cases into automated GUI tests. However, it is not clear whether such automation is cost-effective given that GUI automation scripts add to the code base and demand maintenance as a system evolves. In this paper, we introduce a method for estimating maintenance cost and Return on Investment (ROI) for Automated GUI Testing (AGT). The method utilizes the existing source code change history and has the potential to be used for the evaluation of other testing or quality assurance automation technologies. We evaluate the method for a real-world, industrial software system and compare two fundamentally different AGT frameworks, namely Selenium and EyeAutomate, to estimate and compare their ROI. We also report on their defect-finding capabilities and\u00a0\u2026", "num_citations": "3\n", "authors": ["165"]}
{"title": "Augmented testing: Industry feedback to shape a new testing technology\n", "abstract": " Manual testing is the most commonly used approach in the industry today for acceptance-and system-testing of software applications. Test automation has been suggested to address drawbacks with manual testing but both test automation and manual testing have several challenges that limit their return of investment for system-and acceptance-test automation. Hence, there is still an industrial need for another approach to testing that can mitigate the challenges associated with system-and acceptance-testing and make it more efficient and cost effective for the industry. In this paper we present a novel technique we refer to as Augmented Testing (AT). AT is defined as testing through a visual layer between the tester and the System Under Test (SUT) that superimposes information on top of the GUI. We created a prototype for AT and performed an industrial workshop study with 10 software developers to get their\u00a0\u2026", "num_citations": "3\n", "authors": ["165"]}
{"title": "Finding a boundary between valid and invalid regions of the input space\n", "abstract": " In the context of robustness testing, the boundary between the valid and invalid regions of the input space can be an interesting source of erroneous inputs. Knowing where a specific software under test (SUT) has a boundary is also essential for validation in relation to requirements. However, finding where a SUT actually implements the boundary is a non-trivial problem that has not gotten much attention. This paper proposes a method of finding the boundary between the valid and invalid regions of the input space, by developing pairs of test sets that describe that boundary in detail. The proposed method consists of two steps. First, test data generators, directed by a search algorithm to maximise distance to known, valid test cases, generate valid test cases that are closer to the boundary. Second, these valid test cases undergo mutations to try to push them over the boundary and into the invalid part of the input\u00a0\u2026", "num_citations": "3\n", "authors": ["165"]}
{"title": "A method to assess and argue for practical significance in software engineering\n", "abstract": " A key goal of empirical research in software engineering is to assess practical significance, which answers whether the observed effects of some compared treatments show a relevant difference in practice in realistic scenarios. Even though plenty of standard techniques exist to assess statistical significance, connecting it to practical significance is not straightforward or routinely done; indeed, only a few empirical studies in software engineering assess practical significance in a principled and systematic way. In this paper, we argue that Bayesian data analysis provides suitable tools to assess practical significance rigorously. We demonstrate our claims in a case study comparing different test techniques. The case study's data was previously analyzed (Afzal et al., 2015) using standard techniques focusing on statistical significance. Here, we build a multilevel model of the same data, which we fit and validate using Bayesian techniques. Our method is to apply cumulative prospect theory on top of the statistical model to quantitatively connect our statistical analysis output to a practically meaningful context. This is then the basis both for assessing and arguing for practical significance. Our study demonstrates that Bayesian analysis provides a technically rigorous yet practical framework for empirical software engineering. A substantial side effect is that any uncertainty in the underlying data will be propagated through the statistical model, and its effects on practical significance are made clear. Thus, in combination with cumulative prospect theory, Bayesian analysis supports seamlessly assessing practical significance in an empirical software\u00a0\u2026", "num_citations": "3\n", "authors": ["165"]}
{"title": "Arguing practical significance in software engineering using Bayesian data analysis\n", "abstract": " This paper provides a case for using Bayesian data analysis (BDA) to make more grounded claims regarding practical significance of software engineering research.We show that using BDA, here combined with cumulative prospect theory (CPT), is appropriate when a researcher or practitioner wants to make clearer connections between statistical findings and practical significance in empirical software engineering research. To illustrate our point we provide an example case using previously published data. We build a multilevel Bayesian model for this data, for which we compare the out of sample predictive power. Finally, we use our model to make out of sample predictions while, ultimately, connecting this to practical significance using CPT.", "num_citations": "3\n", "authors": ["165"]}
{"title": "Searching for test data with feature diversity\n", "abstract": " There is an implicit assumption in software testing that more diverse and varied test data is needed for effective testing and to achieve different types and levels of coverage. Generic approaches based on information theory to measure and thus, implicitly, to create diverse data have also been proposed. However, if the tester is able to identify features of the test data that are important for the particular domain or context in which the testing is being performed, the use of generic diversity measures such as this may not be sufficient nor efficient for creating test inputs that show diversity in terms of these features. Here we investigate different approaches to find data that are diverse according to a specific set of features, such as length, depth of recursion etc. Even though these features will be less general than measures based on information theory, their use may provide a tester with more direct control over the type of diversity that is present in the test data. Our experiments are carried out in the context of a general test data generation framework that can generate both numerical and highly structured data. We compare random sampling for feature-diversity to different approaches based on search and find a hill climbing search to be efficient. The experiments highlight many trade-offs that needs to be taken into account when searching for diversity. We argue that recurrent test data generation motivates building statistical models that can then help to more quickly achieve feature diversity.", "num_citations": "3\n", "authors": ["165"]}
{"title": "Supporting practitioners in prioritizing user experience requirements\n", "abstract": " The success of, in particular, market-driven and customer-oriented software systems is dependent on finding a proper balance among various quality requirements. There is a gap in current theory and practice in prioritizing quality requirements, especially those quality requirements that are not related to performing a task or accomplishing a goal such as joy. To bridge this gap, a shared understanding of these types of requirements is required. This paper includes a review of the current theories, ie quality models in software engineering, and user experience models in interaction design. We then present our results from comparing models from each field. We conclude that the models are complementary, and can and should be merged to form a combined model. The model will bring insight into prioritization by introducing various aspects of user experience, its composing elements, and their functional relation.", "num_citations": "3\n", "authors": ["165"]}
{"title": "Robustest: Towards a framework for automated testing of robustness in software\n", "abstract": " Growing complexity of software systems and increasing demand for higher quality systems has resulted in more focus on software robustness in academia and research. By increasing the robustness of a software many failures which decrease the quality of the system can be avoided or masked. When it comes to specification, testing and assessing software robustness in an efficient manner the methods and techniques are not mature yet.This paper presents the idea of a framework RobusTest for testing robustness properties of a system with focus on timing issues. The test cases provided by the framework are formulated as properties with strong links to robustness requirements. These requirements are categorized into patterns as specified in the ROAST framework for specifying and eliciting robustness requirements. The properties are then used for automatically generating robustness test cases and assessing the results.", "num_citations": "3\n", "authors": ["165"]}
{"title": "Suitability of the Requirements Abstraction Model (RAM) Requirements for High Level System Testing\n", "abstract": " In market-driven requirements engineering requirements are elicited from various internal and external sources. These sources may include engineers, marketing teams, customers etc. This results in a collection of requirements at multiple levels of abstractions. The Requirements Abstraction Model (RAM) is a Market Driven Requirements Engineering (MDRE) model that helps in managing requirements by organizing them at four levels (product, feature, function and component) of abstraction. The model is adaptable and can be tailored to meet the needs of the various organizations eg number of abstraction levels can be changed according to the needs of the organization.Software requirements are an important source of information when developing high-level tests (acceptance and system level tests). In order to place a requirement on a suitable level, workup activities (producing abstraction or breaking down a requirement) can be performed on the requirement. Such activities on the requirements can affect the test cases designed from them. Organizations willing to adopt the RAM need to know the suitability of the RAM requirements for designing high-level tests. This master thesis analyzes the requirements at product, feature, function and component level to evaluate their suitability for supporting the creation of high-level system test. This analysis includes designing test cases from requirements at different levels and evaluating how much of the information needed in the test cases is available in the RAM requirements. Test cases are graded on a 5 to 1 scale according to the level of detail they contain, 5 for better detailed and 1 for very\u00a0\u2026", "num_citations": "3\n", "authors": ["165"]}
{"title": "Ruby developers guide\n", "abstract": " An expert guide to Ruby, a popular new Object-Oriented Programming Language Ruby is quickly becoming a favourite among developers who need a simple, straight forward, portable programming language. Ruby is ideal for quick and easy object-oriented programming such as processing text files or performing system management. Having been compared with other programming languages such as Perl, Python, PCL, Java, Eiffel, and C++; Ruby is popular because of its straight forward syntax and transparent semantics. Using step-by-step examples and real world applications, the Ruby Developer's Guide is designed for programmers and developer's looking to embrace the object-oriented features and functionality of this robust programming language. Readers will learn how to develop, implement, organize and deploy applications using Ruby. Ruby is currently experiencing a rapid rise in popularity in the object-oriented programming community Readers receive up-to-the minute links, white papers, and analysis for two years at solutions@ syngress. com Comes with a wallet-sized CD containing a printable HTML version of the book, all of the source code examples and demos of popular Ruby third-party programming tools and applications", "num_citations": "3\n", "authors": ["165"]}
{"title": "Towards automated boundary value testing with program derivatives and search\n", "abstract": " A natural and often used strategy when testing software is to use input values at boundaries, i.e. where behavior is expected to change the most, an approach often called boundary value testing or analysis (BVA). Even though this has been a key testing idea for long it has been hard to clearly define and formalize. Consequently, it has also been hard to automate.                 In this research note we propose one such formalization of BVA by, in a similar way as to how the derivative of a function is defined in mathematics, considering (software) program derivatives. Critical to our definition is the notion of distance between inputs and outputs which we can formalize and then quantify based on ideas from Information theory.                 However, for our (black-box) approach to be practical one must search for test inputs with specific properties. Coupling it with search-based software engineering is thus required and\u00a0\u2026", "num_citations": "2\n", "authors": ["165"]}
{"title": "Generative secure design, defined\n", "abstract": " In software-intensive industries, companies face the constant challenge of not having enough security experts on staff in order to validate the design of the high-complexity projects they run. Many of these companies are now realizing that increasing automation in their secure development process is the only way forward in order to cope with the ultra-large scale of modern systems. This paper embraces that viewpoint. We chart the roadmap to the development of a generative design tool that iteratively produces several design alternatives, each attempting to solve the security goals by incorporating security mechanisms. The tool explores the possible solutions by starting from well-known security techniques and by creating variations via mutations and crossovers. By incorporating user feedback, the tool generates increasingly better design alternatives.", "num_citations": "2\n", "authors": ["165"]}
{"title": "Replicating Rare Software Failures with Exploratory Visual GUI Testing\n", "abstract": " Saab AB developed software that had a defect that manifested itself only after months of continuous system use. After years of customer failure reports, the defect still persisted, until Saab developed failure replication based on visual GUI testing.", "num_citations": "2\n", "authors": ["165"]}
{"title": "Re-using generators of complex test data\n", "abstract": " The efficiency of random testing can be improved by sampling test inputs using a generating program that incorporates knowledge about the types of input most likely to detect faults in the software-under-test (SUT). But when the input of the SUT is a complex data type--such as a domain-specific string, array, record, tree, or graph--creating such a generator may be time- consuming and may require the tester to have substantial prior experience of the domain. In this paper we propose the re-use of generators created for one SUT on other SUTs that take the same complex data type as input. The re-use of a generator in this way would have little overhead, and we hypothesise that the re-used generator will typically be as least as efficient as the most straightforward form of random testing: sampling test inputs from the uniform distribution. We investigate this proposal for two data types using five generators. We assess\u00a0\u2026", "num_citations": "2\n", "authors": ["165"]}
{"title": "A factorial experiment on scalability of search based software testing\n", "abstract": " Software testing is an expensive process, which is vital in the industry. Construction of the test-data in software testing requires the major cost and to decide which method to use in order to generate the test data is important. This paper discusses the efficiency of search-based algorithms (preferably genetic algorithm) versus random testing, in soft- ware test-data generation. This study differs from all previous studies due to sample programs (SUTs) which are used. Since we want to in- crease the complexity of SUTs gradually, and the program generation is automatic as well, Grammatical Evolution is used to guide the program generation. SUTs are generated according to the grammar we provide, with different levels of complexity. SUTs will first undergo genetic al- gorithm and then random testing. Based on the test results, this paper recommends one method to use for automation of software testing.", "num_citations": "2\n", "authors": ["165"]}
{"title": "Structuring Software Engineering Case Studies to Cover Multiple Perspectives.\n", "abstract": " Case studies are used in software engineering (SE) research for detailed study of phenomena in their real-world context. There are guidelines listing important factors to consider when designing case studies, but there is a lack of advice on how to structure the collected information and ensure its breadth. Without considering multiple perspectives, such as business and organization, there is a risk that too few perspectives are covered. The objective of this paper is to develop a framework to give structure and ensure breadth of a SE case study. For an analysis of the verification and validation practices of a Swedish software company we developed an analytical framework based on two dimensions. The matrix spanned by the dimensions (perspective and time) helped structure data collection and connect different findings. A six-step process was defined to adapt and execute the framework at the company and we exemplify its use and describe its perceived advantages and disadvantages.The framework simplified the analysis and gave a broader understanding of the studied practices but there is a tradeoff with the depth of the results, making the framework more suitable for explorative, open-ended studies.", "num_citations": "2\n", "authors": ["165"]}
{"title": "Improved Support for Master\u2019s Thesis Projects in Software Engineering\n", "abstract": " The aim of the project described in this report was to develop improved support for both students and advisors in the different phases of Master\u2019s thesis projects in software engineering. The work was done in several steps, including a web-based survey among students; an interview study with students, supervisors and examiners; formulation of a support framework; and evaluation of the developed support. The main results of the project are improved understanding of the challenges of thesis projects, a support framework for different project phases, and examples of concrete support for different situations. We believe that the findings are relevant for Master\u2019s thesis projects in areas other than software engineering.", "num_citations": "2\n", "authors": ["165"]}
{"title": "Robustness Verification Challenges in Automotive Telematics Software.\n", "abstract": " The automotive industry has always had a strong pressure of ensuring that only high quality software is allowed to control the vehicle. The general increase in the amount of software in a modern vehicle and trends in the industry is creating more open standards and systems. In particular, the software architectures used will have to support extension with 3rd party components and extension at run-time during normal operation of the vehicle. These trends put additional pressure on the automotive industry to verify and validate the quality of the systems. Since the software often governs safety-critical features there are high demands on the robustness of the final system. It is currently not clear how these robustness testing challenges should be met and previous research have not addressed this fully. We outline the challenges and point to possible solutions that the research community needs to work together with the automotive industry to realize.", "num_citations": "2\n", "authors": ["165"]}
{"title": "Applying Bayesian analysis guidelines to empirical software engineering data: The case of programming languages and code quality\n", "abstract": " Statistical analysis is the tool of choice to turn data into information, and then information into empirical knowledge. To be valid, the process that goes from data to knowledge should be supported by detailed, rigorous guidelines, which help ferret out issues with the data or model, and lead to qualified results that strike a reasonable balance between generality and practical relevance. Such guidelines are being developed by statisticians to support the latest techniques for Bayesian data analysis. In this article, we frame these guidelines in a way that is apt to empirical research in software engineering. To demonstrate the guidelines in practice, we apply them to reanalyze a GitHub dataset about code quality in different programming languages. The dataset's original analysis (Ray et al., 2014) and a critical reanalysis (Berger at al., 2019) have attracted considerable attention -- in no small part because they target a topic (the impact of different programming languages) on which strong opinions abound. The goals of our reanalysis are largely orthogonal to this previous work, as we are concerned with demonstrating, on data in an interesting domain, how to build a principled Bayesian data analysis and to showcase some of its benefits. In the process, we will also shed light on some critical aspects of the analyzed data and of the relationship between programming languages and code quality. The high-level conclusions of our exercise will be that Bayesian statistical techniques can be applied to analyze software engineering data in a way that is principled, flexible, and leads to convincing results that inform the state of the art while highlighting the\u00a0\u2026", "num_citations": "1\n", "authors": ["165"]}
{"title": "Arguing practical significance in empirical software engineering\n", "abstract": " A key goal of empirical research is assessing practical significance, which answers the question of whether the observed effects of some compared treatments show a difference that is relevant in practice in realistic scenarios. Even though plenty of standard techniques exist to assess statistical significance, connecting it to practical significance is something that is not straightforward or routinely done; indeed, only a few empirical studies in software engineering assess practical significance in a principled and systematic way. In this paper, we argue that Bayesian data analysis provides suitable tools to rigorously assess practical significance. We demonstrate our claims in a case study comparing different test techniques. The case study's data was previously analyzed (Afzal et al., 2015) using standard techniques focusing on statistical significance. We build a multilevel model of the same data, which we fit and\u00a0\u2026", "num_citations": "1\n", "authors": ["165"]}
{"title": "Stakeholder Involvement: A Success Factor for Achieving Better UX Integration\n", "abstract": " Stakeholder involvement is one of the major success factors in integrating user experience (UX) practices into software development processes and organizations. It is also a necessity for agile software development. However, practitioners still have limited access to guidelines on successful involvement of UX stakeholders in agile settings. Moreover, agile UX literature does not well address the specific characteristics of UX and it does not clearly differentiate between UX and usability work. This paper presents two guidelines for supporting stakeholder involvement in both UX integration and the daily UX work. In particular, we focus on the special characteristics of UX: being dynamic, subjective, holistic, and context-dependent. The guidelines clarify practical implications of these characteristics for practitioners. In addition, they can help researchers in addressing these characteristics better in agile UX research.", "num_citations": "1\n", "authors": ["165"]}
{"title": "Software engineers' attitudes towards organizational change-an industrial case study\n", "abstract": " In order to cope with a complex and changing environment, industries seek to find new and more efficient ways to conduct their business. According to previous research, many of these change efforts fail to achieve their intended aims. Researchers have therefore sought to identify factors that increase the likelihood of success and found that employees' attitude towards change is one of the most critical. The ability to manage change is especially important in software engineering organizations, where rapid changes in influential technologies and constantly evolving methodologies create a turbulent environment. Nevertheless, to the best of our knowledge, no studies exist that explore attitude towards change in a software engineering organization. In this case study, we have used industry data to examine if the knowledge about the intended change outcome, the understanding of the need for change, and the feelings of participation affect software engineers' openness to change and readiness for change respectively, two commonly used attitude constructs. The result of two separate multiple regression analysis showed that openness to change is predicted by all three concepts, while readiness for change is predicted by need for change and participation. In addition, our research also provides a hierarchy with respect to the three predictive constructs' degree of impact. Ultimately, our result can help managers in software engineering organizations to increase the likelihood of successfully implementing change initiatives that result in a changed organizational behavior. However, the first-order models we propose are to be recognized as early\u00a0\u2026", "num_citations": "1\n", "authors": ["165"]}
{"title": "Challenges and solutions in test staff relocations within a software consultancy company\n", "abstract": " Test staff in modern software consultancy companies often has to work in multiple projects that differ not only technically, but also from organizational, management and social aspects. The ease and speed with which staff can adapt to new projects and environments is crucial for the success and profitability of the consultancy company. This paper investigates how management in a Swedish software company can facilitate test staff relocation practices. Consultants in the testing department were interviewed to elicit the differences between testing projects they are involved in and their views on the challenges of and learning needed when relocating between projects. Based on this we present an approach to better support such staff relocations. The approach is based on a knowledge sharing process and the introduction of specific templates to capture testing experience. Initial, static validation in the associated\u00a0\u2026", "num_citations": "1\n", "authors": ["165"]}
{"title": "A Theory of Software Development\n", "abstract": " We present a theory of software development as an incremental learning process. The focus is on the internal models of the developer. There are two main ways in which a development process can make progress: by refining an internal model or by refining an artefact based on an internal model. Refining the internal models is a prerequisite for being able to write a concrete specification and program that show acceptable behaviour. The theory has implications for tools to support software development. By creating novel test cases they can force the developer to question his internal models and realize where they are incomplete or incorrect.", "num_citations": "1\n", "authors": ["165"]}
{"title": "Ruby Developers Guide\n", "abstract": " Ruby Developers Guide - CERN Document Server CERN Accelerating science Sign in Directory CERN Document Server Access articles, reports and multimedia content in HEP Main menu Search Submit Help Personalize Your alerts Your baskets Your comments Your searches Home > Unclassified Documents > Ruby Developers Guide Information Discussion (0) Files Books Title Ruby Developers Guide Author(s) Neumann, Michael Publication Rockland, MA : Syngress, 2002. Subject category Computing and Computers ISBN 1928994644 (print version) 9781928994640 (print version) 0080480764 (electronic version) 9780080480763 (electronic version) [] Back to search Record created 2008-02-05, last modified 2015-02-05 Similar records External link: Download fulltext ebook Add to personal basket Export as BibTeX, MARC, MARCXML, DC, EndNote, NLM, RefWorks CERN Document Server :: Search :: :: :: :: ..-\u2026", "num_citations": "1\n", "authors": ["165"]}