{"title": "Automating string processing in spreadsheets using input-output examples\n", "abstract": " We describe the design of a string programming/expression language that supports restricted forms of regular expressions, conditionals and loops. The language is expressive enough to represent a wide variety of string manipulation tasks that end-users struggle with. We describe an algorithm based on several novel concepts for synthesizing a desired program in this language from input-output examples. The synthesis algorithm is very efficient taking a fraction of a second for various benchmark examples. The synthesis algorithm is interactive and has several desirable features: it can rank multiple solutions and has fast convergence, it can detect noise in the user input, and it supports an active interaction model wherein the user is prompted to provide outputs on inputs that may have multiple computational interpretations. The algorithm has been implemented as an interactive add-in for Microsoft Excel\u00a0\u2026", "num_citations": "784\n", "authors": ["1694"]}
{"title": "Speed: precise and efficient static estimation of program computational complexity\n", "abstract": " This paper describes an inter-procedural technique for computing symbolic bounds on the number of statements a procedure executes in terms of its scalar inputs and user-defined quantitative functions of input data-structures. Such computational complexity bounds for even simple programs are usually disjunctive, non-linear, and involve numerical properties of heaps. We address the challenges of generating these bounds using two novel ideas. We introduce a proof methodology based on multiple counter instrumentation (each counter can be initialized and incremented at potentially multiple program locations) that allows a given linear invariant generation tool to compute linear bounds individually on these counter variables. The bounds on these counters are then composed together to generate total bounds that are non-linear and disjunctive. We also give an algorithm for automating this proof methodology\u00a0\u2026", "num_citations": "376\n", "authors": ["1694"]}
{"title": "Dimensions in program synthesis\n", "abstract": " Program Synthesis, which is the task of discovering programs that realize user intent, can be useful in several scenarios: enabling people with no programming background to develop utility programs, helping regular programmers automatically discover tricky/mundane details, program understanding, discovery of new algorithms, and even teaching.", "num_citations": "295\n", "authors": ["1694"]}
{"title": "Inferring locks for atomic sections\n", "abstract": " Atomic sections are a recent and popular idiom to support the development of concurrent programs. Updates performed within an atomic section should not be visible to other threads until the atomic section has been executed entirely. Traditionally, atomic sections are supported through the use of optimistic concurrency, either using a transactional memory hardware, or an equivalent software emulation (STM). This paper explores automatically supporting atomic sections using pessimistic concurrency. We present a system that combines compiler and runtime techniques to automatically transform programs written with atomic sections into programs that only use locking primitives. To minimize contention in the transformed programs, our compiler chooses from several lock granularities, using fine-grain locks whenever it is possible. This paper formally presents our framework, shows that our compiler is sound (i.e., it\u00a0\u2026", "num_citations": "170\n", "authors": ["1694"]}
{"title": "Inductive programming meets the real world\n", "abstract": " Inductive programming can liberate users from performing tedious and repetitive tasks.", "num_citations": "167\n", "authors": ["1694"]}
{"title": "Control-flow refinement and progress invariants for bound analysis\n", "abstract": " Symbolic complexity bounds help programmers understand the performance characteristics of their implementations. Existing work provides techniques for statically determining bounds of procedures with simple control-flow. However, procedures with nested loops or multiple paths through a single loop are challenging. In this paper we describe two techniques, control-flow refinement and progress invariants, that together enable estimation of precise bounds for procedures with nested and multi-path loops. Control-flow refinement transforms a multi-path loop into a semantically equivalent code fragment with simpler loops by making the structure of path interleaving explicit. We show that this enables non-disjunctive invariant generation tools to find a bound on many procedures for which previous techniques were unable to prove termination. Progress invariants characterize relationships between consecutive\u00a0\u2026", "num_citations": "165\n", "authors": ["1694"]}
{"title": "Proving programs robust\n", "abstract": " We present a program analysis for verifying quantitative robustness properties of programs, stated generally as:\" If the inputs of a program are perturbed by an arbitrary amount epsilon, then its outputs change at most by (K. epsilon), where K can depend on the size of the input but not its value.\" Robustness properties generalize the analytic notion of continuity---eg, while the function e x is continuous, it is not robust. Our problem is to verify the robustness of a function P that is coded as an imperative program, and can use diverse data types and features such as branches and loops.", "num_citations": "151\n", "authors": ["1694"]}
{"title": "A machine learning framework for programming by example\n", "abstract": " Learning programs is a timely and interesting challenge. In Programming by Example (PBE), a system attempts to infer a program from input and output examples alone, by searching for a composition of some set of base functions. We show how machine learning can be used to speed up this seemingly hopeless search problem, by learning weights that relate textual features describing the provided input-output examples to plausible sub-components of a program. This generic learning framework lets us address problems beyond the scope of earlier PBE systems. Experiments on a prototype implementation show that learning improves search and ranking on a variety of text processing tasks found on help forums.", "num_citations": "145\n", "authors": ["1694"]}
{"title": "The reachability-bound problem\n", "abstract": " We define the reachability-bound problem to be the problem of finding a symbolic worst-case bound on the number of times a given control location inside a procedure is visited in terms of the inputs to that procedure. This has applications in bounding resources consumed by a program such as time, memory, network-traffic, power, as well as estimating quantitative properties (as opposed to boolean properties) of data in programs, such as information leakage or uncertainty propagation. Our approach to solving the reachability-bound problem brings together two different techniques for reasoning about loops in an effective manner. One of these techniques is an abstract-interpretation based iterative technique for computing precise disjunctive invariants (to summarize nested loops). The other technique is a non-iterative proof-rules based technique (for loop bound computation) that takes over the role of doing\u00a0\u2026", "num_citations": "130\n", "authors": ["1694"]}
{"title": "FlashRelate: extracting relational data from semi-structured spreadsheets using examples\n", "abstract": " With hundreds of millions of users, spreadsheets are one of the most important end-user applications. Spreadsheets are easy to use and allow users great flexibility in storing data. This flexibility comes at a price: users often treat spreadsheets as a poor man's database, leading to creative solutions for storing high-dimensional data. The trouble arises when users need to answer queries with their data. Data manipulation tools make strong assumptions about data layouts and cannot read these ad-hoc databases. Converting data into the appropriate layout requires programming skills or a major investment in manual reformatting. The effect is that a vast amount of real-world data is \"locked-in\" to a proliferation of one-off formats. We introduce FlashRelate, a synthesis engine that lets ordinary users extract structured relational data from spreadsheets without programming. Instead, users extract data by supplying\u00a0\u2026", "num_citations": "125\n", "authors": ["1694"]}
{"title": "Continuity analysis of programs\n", "abstract": " We present an analysis to automatically determine if a program represents a continuous function, or equivalently, if infinitesimal changes to its inputs can only cause infinitesimal changes to its outputs. The analysis can be used to verify the robustness of programs whose inputs can have small amounts of error and uncertainty---eg, embedded controllers processing slightly unreliable sensor data, or handheld devices using slightly stale satellite data.", "num_citations": "116\n", "authors": ["1694"]}
{"title": "Speed: Symbolic complexity bound analysis\n", "abstract": " The SPEED project addresses the problem of computing symbolic computational complexity bounds of procedures in terms of their inputs. We discuss some of the challenges that arise and present various orthogonal/complementary techniques recently developed in the SPEED project for addressing these challenges.", "num_citations": "101\n", "authors": ["1694"]}
{"title": "Test-driven synthesis\n", "abstract": " Programming-by-example technologies empower end-users to create simple programs merely by providing input/output examples. Existing systems are designed around solvers specialized for a specific set of data types or domain-specific language (DSL). We present a program synthesizer which can be parameterized by an arbitrary DSL that may contain conditionals and loops and therefore is able to synthesize programs in any domain. In order to use our synthesizer, the user provides a sequence of increasingly sophisticated input/output examples along with an expert-written DSL definition. These two inputs correspond to the two key ideas that allow our synthesizer to work in arbitrary domains. First, we developed a novel iterative synthesis technique inspired by test-driven development---which also gives our technique the name of test-driven synthesis---where the input/output examples are consumed one at a\u00a0\u2026", "num_citations": "100\n", "authors": ["1694"]}
{"title": "A numerical abstract domain based on expression abstraction and max operator with application in timing analysis\n", "abstract": " This paper describes a precise numerical abstract domain for use in timing analysis. The numerical abstract domain is parameterized by a linear abstract domain and is constructed by means of two domain lifting operations. One domain lifting operation is based on the principle of expression abstraction (which involves defining a set of expressions and specifying their semantics using a collection of directed inference rules) and has a more general applicability. It lifts any given abstract domain to include reasoning about a given set of expressions whose semantics is abstracted using a set of axioms. The other domain lifting operation incorporates disjunctive reasoning into a given linear relational abstract domain via introduction of max expressions. We present experimental results demonstrating the potential of the new numerical abstract domain to discover a wide variety of timing bounds (including\u00a0\u2026", "num_citations": "100\n", "authors": ["1694"]}
{"title": "Synthesis from examples: Interaction models and algorithms\n", "abstract": " Examples are often a natural way to specify various computational artifacts such as programs, queries, and sequences. Synthesizing such artifacts from example based specifications has various applications in the domains of end-user programming and intelligent tutoring systems. Synthesis from examples involves addressing two key technical challenges: (i) design of a user interaction model to deal with the inherent ambiguity in the example based specification. (ii) design of an efficient search algorithm - these algorithms have been based on paradigms from various communities including use of SAT/SMT solvers (formal methods community), version space algebras (machine learning community), and A*-style goal-directed heuristics (AI community). This paper describes some effective user interaction models and algorithmic methodologies for synthesis from examples while discussing synthesizers for a variety of\u00a0\u2026", "num_citations": "95\n", "authors": ["1694"]}
{"title": "Automated clustering and program repair for introductory programming assignments\n", "abstract": " Providing feedback on programming assignments is a tedious task for the instructor, and even impossible in large Massive Open Online Courses with thousands of students. Previous research has suggested that program repair techniques can be used to generate feedback in programming education. In this paper, we present a novel fully automated program repair algorithm for introductory programming assignments. The key idea of the technique, which enables automation and scalability, is to use the existing correct student solutions to repair the incorrect attempts. We evaluate the approach in two experiments: (I) We evaluate the number, size and quality of the generated repairs on 4,293 incorrect student attempts from an existing MOOC. We find that our approach can repair 97% of student attempts, while 81% of those are small repairs of good quality. (II) We conduct a preliminary user study on performance and\u00a0\u2026", "num_citations": "90\n", "authors": ["1694"]}
{"title": "A trace-based framework for analyzing and synthesizing educational progressions\n", "abstract": " A key challenge in teaching a procedural skill is finding an effective progression of example problems that the learner can solve in order to internalize the procedure. In many learning domains, generation of such problems is typically done by hand and there are few tools to help automate this process. We reduce this effort by borrowing ideas from test input generation in software engineering. We show how we can use execution traces as a framework for abstracting the characteristics of a given procedure and defining a partial ordering that reflects the relative difficulty of two traces. We also show how we can use this framework to analyze the completeness of expert-designed progressions and fill in holes. Furthermore, we demonstrate how our framework can automatically synthesize new problems by generating large sets of problems for elementary and middle school mathematics and synthesizing hundreds of\u00a0\u2026", "num_citations": "88\n", "authors": ["1694"]}
{"title": "Feedback generation for performance problems in introductory programming assignments\n", "abstract": " Providing feedback on programming assignments manually is a tedious, error prone, and time-consuming task. In this paper, we motivate and address the problem of generating feedback on performance aspects in introductory programming assignments. We studied a large number of functionally correct student solutions to introductory programming assignments and observed:(1) There are different algorithmic strategies, with varying levels of efficiency, for solving a given problem. These different strategies merit different feedback.(2) The same algorithmic strategy can be implemented in countless different ways, which are not relevant for reporting feedback on the student program. We propose a light-weight programming language extension that allows a teacher to define an algorithmic strategy by specifying certain key values that should occur during the execution of an implementation. We describe a dynamic\u00a0\u2026", "num_citations": "73\n", "authors": ["1694"]}
{"title": "Continuity and robustness of programs\n", "abstract": " Computer scientists have long believed that software is different from physical systems in one fundamental way: while the latter have continuous dynamics, the former do not. In this paper, we argue that notions of continuity from mathematical analysis are relevant and interesting even for software. First, we demonstrate that many everyday programs are continuous (i.e., arbitrarily small changes to their inputs only cause arbitrarily small changes to their outputs) or Lipschitz continuous (i.e., when their inputs change, their outputs change at most proportionally). Second, we give an mostly-automatic framework for verifying that a program is continuous or Lipschitz, showing that traditional, discrete approaches to proving programs correct can be extended to reason about these properties. An immediate application of our analysis is in reasoning about the robustness of programs that execute on uncertain inputs. In the\u00a0\u2026", "num_citations": "72\n", "authors": ["1694"]}
{"title": "Compositional program synthesis from natural language and examples\n", "abstract": " Compositionality is a fundamental notion in computation whereby complex abstractions can be constructed from simpler ones, but this property has so far escaped the paradigm of end-user programming from examples or natural language. Existing approaches restrict end users to only give holistic end-to-end specifications, which limits the expressivity and scalability of these approaches to relatively simple programs in very restricted domains. In this paper we propose a new approach to end-user program synthesis in which input can be given in a compositional manner through a combination of natural language and examples. We present a domain-agnostic program synthesis algorithm and demonstrate its application to an expressive string manipulation language. We evaluate on a range of complex examples from help forums that are beyond the scope of previous systems.", "num_citations": "66\n", "authors": ["1694"]}
{"title": "Discovering affine equalities using random interpretation\n", "abstract": " We present a new polynomial-time randomized algorithm for discovering affine equalities involving variables in a program. The key idea of the algorithm is to execute a code fragment on a few random inputs, but in such a way that all paths are covered on each run. This makes it possible to rule out invalid relationships even with very few runs. The algorithm is based on two main techniques. First, both branches of a conditional are executed on each run and at joint points we perform an affine combination of the joining states. Secondly, in the branches of an equality conditional we adjust the data values on the fly to reflect the truth value of the guarding boolean expression. This increases the number of affine equalities that the analysis discovers. The algorithm is simpler to implement than alternative deterministic versions, has better computational complexity, and has an extremely small probability of error for even a\u00a0\u2026", "num_citations": "66\n", "authors": ["1694"]}
{"title": "QuickDraw: improving drawing experience for geometric diagrams\n", "abstract": " We present QuickDraw, a prototype sketch-based drawing tool, that facilitates drawing of precise geometry diagrams that are often drawn by students and academics in several scientific disciplines. Quickdraw can recognize sketched diagrams containing components such as line segments and circles, infer geometric constraints relating recognized components, and use this information to beautify the sketched diagram. Beautification is based on a novel algorithm that iteratively computes various sub-components of the components using an extensible set of deductive rules. We conducted a user study comparing QuickDraw with four state-of-the-art diagramming tools: Microsoft PowerPoint, Cabri II Plus, Geometry Expressions and Geometer's SketchPad. Our study demonstrates a strong interest among participants for the use of sketch-based software for drawing geometric diagrams. We also found that QuickDraw\u00a0\u2026", "num_citations": "59\n", "authors": ["1694"]}
{"title": "Semi-supervised verified feedback generation\n", "abstract": " Students have enthusiastically taken to online programming lessons and contests. Unfortunately, they tend to struggle due to lack of personalized feedback. There is an urgent need of program analysis and repair techniques capable of handling both the scale and variations in student submissions, while ensuring quality of feedback.", "num_citations": "56\n", "authors": ["1694"]}
{"title": "Program verification as probabilistic inference\n", "abstract": " In this paper, we propose a new algorithm for proving the validity or invalidity of a pre/postcondition pair for a program. The algorithm is motivated by the success of the algorithms for probabilistic inference developed in the machine learning community for reasoning in graphical models. The validity or invalidity proof consists of providing an invariant at each program point that can be locally verified. The algorithm works by iteratively randomly selecting a program point and updating the current abstract state representation to make it more locally consistent (with respect to the abstractions at the neighboring points). We show that this simple algorithm has some interesting aspects: (a) It brings together the complementary powers of forward and backward analyses; (b) The algorithm has the ability to recover itself from excessive under-approximation or over-approximation that it may make. (Because the algorithm does\u00a0\u2026", "num_citations": "55\n", "authors": ["1694"]}
{"title": "Example-based learning in computer-aided stem education\n", "abstract": " Example-based reasoning techniques developed for programming languages also help automate repetitive tasks in education.", "num_citations": "54\n", "authors": ["1694"]}
{"title": "Automatic game progression design through analysis of solution features\n", "abstract": " A long-term goal of game design research is to achieve end-to-end automation of much of the design process, one aspect of which is creating effective level progressions. A key difficulty is getting the player to practice with interesting combinations of learned skills while maintaining their engagement. Although recent work in task generation and sequencing has reduced this effort, we still lack end-to-end automation of the entire content design process. We approach this goal by incorporating ideas from intelligent tutoring systems and proposing progression strategies that seek to achieve mastery of not only base concepts but arbitrary combinations of these concepts. The input to our system is a model of what the player needs to do to complete each level, expressed as either an imperative procedure for producing solutions or a representation of features common to all solutions. The output is a progression of levels\u00a0\u2026", "num_citations": "53\n", "authors": ["1694"]}
{"title": "Wrex: A unified programming-by-example interaction for synthesizing readable code for data scientists\n", "abstract": " Data wrangling is a difficult and time-consuming activity in computational notebooks, and existing wrangling tools do not fit the exploratory workflow for data scientists in these environments. We propose a unified interaction model based on programming-by-example that generates readable code for a variety of useful data transformations, implemented as a Jupyter notebook extension called Wrex. User study results demonstrate that data scientists are significantly more effective and efficient at data wrangling with Wrex over manual programming. Qualitative participant feedback indicates that Wrex was useful and reduced barriers in having to recall or look up the usage of various data transform functions. The synthesized code allowed data scientists to verify the intended data transformation, increased their trust and confidence in Wrex, and fit seamlessly within their cell-based notebook workflows. This work\u00a0\u2026", "num_citations": "48\n", "authors": ["1694"]}
{"title": "Global value numbering using random interpretation\n", "abstract": " We present a polynomial time randomized algorithm for global value numbering. Our algorithm is complete when conditionals are treated as non-deterministic and all operators are treated as uninterpreted functions. We are not aware of any complete polynomial-time deterministic algorithm for the same problem. The algorithm does not require symbolic manipulations and hence is simpler to implement than the deterministic symbolic algorithms. The price for these benefits is that there is a probability that the algorithm can report a false equality. We prove that this probability can be made arbitrarily small by controlling various parameters of the algorithm. Our algorithm is based on the idea of random interpretation, which relies on executing a program on a number of random inputs and discovering relationships from the computed values. The computations are done by giving random linear interpretations to the\u00a0\u2026", "num_citations": "48\n", "authors": ["1694"]}
{"title": "Programming by examples: Applications, algorithms, and ambiguity resolution\n", "abstract": " 99\u00a0% of computer end users do not know programming, and struggle with repetitive tasks. Programming by Examples (PBE) can revolutionize this landscape by enabling users to synthesize intended programs from example based specifications. A key technical challenge in PBE is to search for programs that are consistent with the examples provided by the user. Our efficient search methodology is based on two key ideas: (i) Restriction of the search space to an appropriate domain-specific language that offers balanced expressivity and readability (ii) A divide-and-conquer based deductive search paradigm that inductively reduces the problem of synthesizing a program of a certain kind that satisfies a given specification into sub-problems that refer to sub-programs or sub-specifications. Another challenge in PBE is to resolve the ambiguity in the example based specification. We will discuss two\u00a0\u2026", "num_citations": "47\n", "authors": ["1694"]}
{"title": "A polynomial-time algorithm for global value numbering\n", "abstract": " We describe a polynomial-time algorithm for global value numbering, which is the problem of discovering equivalences among program sub-expressions. We treat all conditionals as non-deterministic and all program operators as uninterpreted. We show that there are programs for which the set of all equivalences contains terms whose value graph representation requires exponential size. Our algorithm discovers all equivalences among terms of size at most s in time that grows linearly with s. For global value numbering, it suffices to choose s to be the size of the program. Earlier deterministic algorithms for the same problem are either incomplete or take exponential time.", "num_citations": "45\n", "authors": ["1694"]}
{"title": "Generating text manipulation programs using input-output examples\n", "abstract": " A program creation system is described which generates a data manipulation program based on input-output examples. The created program may include a collection of subprograms together with a collection of corresponding selection conditions. When a new input item is received, a program execution module uses the selection conditions to select one of the subprograms. The program execution module then applies the selected subprogram to generate a new output item. The program creation system generates the program using a three-part approach, involving: generating sets of subprograms for the respective input-output examples; grouping the sets of programs into partitions and choosing representative subprograms for the partitions; and determining the selection conditions. A user interaction module provides various mechanisms which allow a user to interact with the program creation system and thereby\u00a0\u2026", "num_citations": "42\n", "authors": ["1694"]}
{"title": "Programming by examples: PL meets ML\n", "abstract": " Programming by Examples (PBE) involves synthesizing intended programs in an underlying domain-specific language from example-based specifications. PBE systems are already revolutionizing the application domain of data wrangling and are set to significantly impact several other domains including code refactoring.                 There are three key components in a PBE system. (i) A search algorithm that can efficiently search for programs that are consistent with the examples provided by the user. We leverage a divide-and-conquer-based deductive search paradigm that inductively reduces the problem of synthesizing a program expression of a certain kind that satisfies a given specification into sub-problems that refer to sub-expressions or sub-specifications. (ii) Program ranking techniques to pick an intended program from among the many that satisfy the examples provided by the user. We leverage\u00a0\u2026", "num_citations": "37\n", "authors": ["1694"]}
{"title": "Moods\n", "abstract": " Ideas pervade our professional work. We borrow them, we apply them, we solve problems with them, we create new ones, and we try to foster more of them in our teams. We express what we are doing by referring to the ideas behind our work. We hope that some of our ideas become innovations by being adopted.We also believe that ideas launch innovations and that innovations fail for want of good ideas. As soon as we become aware of a successful innovation, we automatically look backward to try to understand where the idea for it originated. When we see failures, we immediately look to beef up our processes for stimulating imagination and creativity.", "num_citations": "37\n", "authors": ["1694"]}
{"title": "Flashnormalize: Programming by examples for text normalization\n", "abstract": " Several applications including text-to-speech require some normalized format of non-standard words in various domains such as numbers, dates, and currencies and in various human languages. The traditional approach of manually constructing a program for such a normalization task requires expertise in both programming and target (human) language and further does not scale to a large number of domain, format, and target language combinations. We propose to learn programs for such normalization tasks through examples. We present a domain-specific programming language that offers appropriate abstractions for succinctly describing such normalization tasks, and then present a novel search algorithm that can effectively learn programs in this language from input-output examples. We also briefly describe domain-specific heuristics for guiding users of our system to provide representative examples for normalization tasks related to that domain. Our experiments show that weare able to effectively learn desired programs for a variety of normalization tasks.", "num_citations": "36\n", "authors": ["1694"]}
{"title": "Precise interprocedural analysis using random interpretation\n", "abstract": " We describe a unified framework for random interpretation that generalizes previous randomized intraprocedural analyses, and also extends naturally to efficient interprocedural analyses. There is no such natural extension known for deterministic algorithms. We present a general technique for extending any intraprocedural random interpreter to perform a context-sensitive interprocedural analysis with only polynomial increase in running time. This technique involves computing random summaries of procedures, which are complete and probabilistically sound. As an instantiation of this general technique, we obtain the first polynomial-time randomized algorithm that discovers all linear relationships interprocedurally in a linear program. We also obtain the first polynomial-time randomized algorithm for precise interprocedural value numbering over a program with unary uninterpreted functions. We present\u00a0\u2026", "num_citations": "33\n", "authors": ["1694"]}
{"title": "Programming by example using least general generalizations\n", "abstract": " Recent advances in Programming by Example (PBE) have supported new applications to text editing, but existing approaches are limited to simple text strings. In this paper we address transformations in richly formatted documents, using an approach based on the idea of least general generalizations from inductive inference, which avoids the scalability issues faced by state-of-the-art PBE methods. We describe a novel domain specific language (DSL) that expresses transformations over XML structures describing richly formatted content, and a synthesis algorithm that generates a minimal program with respect to a natural subsumption ordering in our DSL. We present experimental results on tasks collected from online help forums, showing an average of 4.17 examples required for task completion.", "num_citations": "32\n", "authors": ["1694"]}
{"title": "A framework for automatically generating interactive instructional scaffolding\n", "abstract": " Interactive learning environments such as intelligent tutoring systems and software tutorials often teach procedures with step-by-step demonstrations. This instructional scaffolding is typically authored by hand, and little can be reused across problem domains. In this work, we present a framework for generating interactive tutorials from an algorithmic representation of the problem-solving thought process. Given a set of mappings between programming language constructs and user interface elements, we step through this algorithm line-by-line to trigger visual explanations of each step. This approach allows us to automatically generate tutorials for any example problem that can be solved with this algorithm. We describe two prototype implementations in the domains of K-12 mathematics and educational games, and present results from two user studies showing that educational technologists can author thought\u00a0\u2026", "num_citations": "28\n", "authors": ["1694"]}
{"title": "Automated data extraction using predictive program synthesis\n", "abstract": " In recent years there has been rising interest in the use of programming-by-example techniques to assist users in data manipulation tasks. Such techniques rely on an explicit input-output examples specification from the user to automatically synthesize programs. However, in a wide range of data extraction tasks it is easy for a human observer to predict the desired extraction by just observing the input data itself. Such predictive intelligence has not yet been explored in program synthesis research, and is what we address in this work. We describe a predictive program synthesis algorithm that infers programs in a general form of extraction DSLs (domain specific languages) given input-only examples. We describe concrete instantiations of such DSLs and the synthesis algorithm in the two practical application domains of text extraction and web extraction, and present an evaluation of our technique on a range of extraction tasks encountered in practice.", "num_citations": "27\n", "authors": ["1694"]}
{"title": "Generating programs using context-free compositions and probability of determined transformation rules\n", "abstract": " There is provided a method and system for generating a program. The method includes detecting a number of steps for performing a task on a computing device and detecting an example relating to each of the steps, wherein the example includes input data and corresponding output data relating to the step. The method also includes, for each example, determining a rule that transforms the input data to the corresponding output data based on cues including textual features within the input data and the corresponding output data. The method further includes generating a program for performing the task based on the rules.", "num_citations": "27\n", "authors": ["1694"]}
{"title": "System using backward inter-procedural analysis for determining alternative coarser grained lock when finer grained locks exceeding threshold\n", "abstract": " Locks which protect data structures used within atomic sections of concurrent programs are inferred from atomic sections and acquired in a manner to avoid deadlock. Locks may be inferred by expression correspondence using a backward inter-procedural analysis of an atomic section. Locks may be sorted according to a total order and acquired early in an atomic section to prevent deadlock. Multiple granularity of locks are determined and employed. Fine grained locks may be inferred and acquired to reduce contention. Coarse grained locks may be determined and substituted for fine grained locks when necessary for unbounded locations or to reduce the number of finer grained locks.", "num_citations": "26\n", "authors": ["1694"]}
{"title": "Learning to Learn Programs from Examples: Going Beyond Program Structure.\n", "abstract": " Programming-by-example technologies let end users construct and run new programs by providing examples of the intended program behavior. But, the few provided examples seldom uniquely determine the intended program. Previous approaches to picking a program used a bias toward shorter or more naturally structured programs. Our work here gives a machine learning approach for learning to learn programs that departs from previous work by relying upon features that are independent of the program structure, instead relying upon a learned bias over program behaviors, and more generally over program execution traces. Our approach leverages abundant unlabeled data for semisupervised learning, and incorporates simple kinds of world knowledge for common-sense reasoning during program induction. These techniques are evaluated in two programming-by-example domains, improving the accuracy of program learners.", "num_citations": "23\n", "authors": ["1694"]}
{"title": "Program abstraction based on program control\n", "abstract": " Embodiments described herein relate to determining an abstraction of a computer program and to the refinement of an abstraction of a computer program. The computer program may be a sequential program or may be a concurrent (parallel) program. A directed graph represents a computer program and may be the cross product of threads within a concurrent program. Nodes within a representation of a program are reduced to a single node to produce an abstraction. An abstraction may be refined by determining constraints that produce a refined abstraction that does not comprise infeasible paths.", "num_citations": "22\n", "authors": ["1694"]}
{"title": "Synthesis from examples\n", "abstract": " Examples are often a natural way to specify computational structures such as programs, queries, and sequences. Synthesizing such structures from example based specification has applications in automating end-user programming and in building intelligent tutoring systems. Synthesis from examples involves addressing two key technical challenges:(i) design of an efficient search algorithm\u2013these algorithms have been based on various paradigms including versionspace algebras, SAT/SMT solvers, numerical methods, and even exhaustive search,(ii) design of a user interaction model to deal with the inherent ambiguity in the example based specification. This paper illustrates various algorithmic techniques and user interaction models by describing inductive synthesizers for varied applications including synthesis of tricky bitvector algorithms, spreadsheet macros for automating repetitive data manipulation tasks, ruler/compass based geometry constructions, new algebra problems, sequences for mathematical intellisense, and grading of programming problems.", "num_citations": "22\n", "authors": ["1694"]}
{"title": "Framework for data extraction by examples\n", "abstract": " Various technologies described herein pertain to controlling automated programming for extracting data from an input document. Examples indicative of the data to extract from the input document can be received. The examples can include highlighted regions on the input document. Moreover, the input document can be a semi-structured document (eg a text file, a log file, a word processor document, a semi-structured spreadsheet, a webpage, a fixed-layout document, an image file, etc.). Further, an extraction program for extracting the data from the input document can be synthesized based on the examples. The extraction program can be synthesized in a domain specific language (DSL) for a type of the input document. Moreover, the extraction program can be executed on the input document to extract an instance of an output data schema.", "num_citations": "21\n", "authors": ["1694"]}
{"title": "Program analysis using random interpretation\n", "abstract": " This dissertation describes a new program analysis technique called random interpretation that uses the power of randomization to verify and discover program properties. Random interpretation is inspired by, and combines the strengths of, the two complementary techniques for program analysis: random testing and abstract interpretation. Random testing is simple and finds real bugs in programs, but cannot prove absence of bugs. Abstract interpretation, on the other hand, is a class of sound and deterministic program analyses that find all bugs, but also report spurious bugs (false positives). Often these analyses are complicated and have long running time. In this dissertation, we describe few random interpretation based program analyses that are more efficient as well as simpler than their deterministic counterparts that had been state-of-the-art for almost 30 years. We then show how to extend these intra\u00a0\u2026", "num_citations": "20\n", "authors": ["1694"]}
{"title": "Automatic Diagnosis of Students' Misconceptions in K-8 Mathematics\n", "abstract": " K-8 mathematics students must learn many procedures, such as addition and subtraction. Students frequently learn\" buggy'variations of these procedures, which we ideally could identify automatically. This is challenging because there are many possible variations that reflect deep compositions of procedural thought. Existing approaches for K-8 math use manually specified variations which do not scale to new math algorithms or previously unseen misconceptions. Our system examines students' answers and infers how they incorrectly combine basic skills into complex procedures. We evaluate this approach on data from approximately 300 students. Our system replicates 86% of the answers that contain clear systematic mistakes (13%). Investigating further, we found 77% at least partially replicate a known misconception, with 53% matching exactly. We also present data from 29 participants showing that our\u00a0\u2026", "num_citations": "19\n", "authors": ["1694"]}
{"title": "Generating programs based on input-output examples using converter modules\n", "abstract": " A program generation system is described that generates a program based on a plurality of input-output examples. The input-output examples include input items and corresponding output items. The program generation system can include three component modules. A parsing module processes the input items and output items to provide a plurality of input parts and output parts, respectively. A transformation module determines, for each output part, whether the output part can be produced from a corresponding input part using one or more converter modules selected from a collection of candidate converter modules. A formatting module generates formatting instructions that transform selected output parts into a form specified by the output items. These three modules provide a generated program that embodies logic learned from the input-output examples; the generated program can be subsequently used to\u00a0\u2026", "num_citations": "18\n", "authors": ["1694"]}
{"title": "Test-driven synthesis for automated feedback for introductory computer science assignments\n", "abstract": " With the recent popularity of computer science massive open online courses (MOOCs) and websites for learning programming, there is a need for high-quality automated feedback on introductory computer science assignments. Current courses usually use test cases, which is effective for determining whether is submission is incorrect but not why. Particularly for students new to programming, a counterexample from a failing test suite may be insufficient to guide a student to understanding their error. In a traditional classroom, a teacher may be able to identify where the errors are in a student\u2019s code if the student is close to a correct solution. We present a fully automated tool for producing such corrections given only a single reference solution written by the teacher. Additionally, our tool mines correct solutions submitted by students to better handle multiple approaches to a problem. We use this tool to produce hints\u00a0\u2026", "num_citations": "17\n", "authors": ["1694"]}
{"title": "Program synthesis and debugging using machine learning techniques\n", "abstract": " One embodiment is directed to synthesizing code fragments in a software routine using known inputs and corresponding expected outputs. A computer system provides a software routine with known inputs and corresponding expected outputs, infers software routine instructions based on the known inputs and corresponding expected outputs, and synthesizes a correctly functioning code fragment based on the inferred instructions. Another embodiment is directed to automatically resolving semantic errors in a software routine. A computer system provides the software routine with known inputs and corresponding expected outputs for portions of a program fragment where an error has been localized. The computer system learns a correctly functioning program fragment from pairs of input-output descriptions of the program fragment, determines the program statements that can transform given input states into given\u00a0\u2026", "num_citations": "16\n", "authors": ["1694"]}
{"title": "Semantic query language\n", "abstract": " Various technologies described herein pertain to executing a mixed query to search a database retained in a data repository. The mixed query includes a regular expression, which is a pattern of elements, and a semantic constraint. The elements in the regular expression include a first wildcard, where the semantic constraint restricts a meaning of the first wildcard. Moreover, the elements in the regular expression include explicit lexical constraint (s) and/or disparate wildcard (s). For instance, semantic constraint (s) can restrict meaning (s) of the disparate wildcard (s). The mixed query is executed to retrieve results that match the pattern of the elements in the regular expression and satisfy the semantic constraint (s).", "num_citations": "15\n", "authors": ["1694"]}
{"title": "Mixed-initiative approaches to global editing in slideware\n", "abstract": " Good alignment and repetition of objects across presentation slides can facilitate visual processing and contribute to audience understanding. However, creating and maintaining such consistency during slide design is difficult. To solve this problem, we present two complementary tools:(1) StyleSnap, which increases the alignment and repetition of objects by adaptively clustering object edge positions and allowing parallel editing of all objects snapped to the same spatial extent; and (2) FlashFormat, which infers the least-general generalization of editing examples and applies it throughout the selected range. In user studies of repetitive styling task performance, StyleSnap and FlashFormat were 4-5 times and 2-3 times faster respectively than conventional editing. Both use a mixed-initiative approach to improve the consistency of slide decks and generalize to any situations involving direct editing across disjoint\u00a0\u2026", "num_citations": "15\n", "authors": ["1694"]}
{"title": "Disjunctive program synthesis: A robust approach to programming by example\n", "abstract": " Programming by example (PBE) systems allow end users to easily create programs by providing a few input-output examples to specify their intended task. The system attempts to generate a program in a domain specific language (DSL) that satisfies the given examples. However, a key challenge faced by existing PBE techniques is to ensure the robustness of the programs that are synthesized from a small number of examples, as these programs often fail when applied to new inputs. This is because there can be many possible programs satisfying a small number of examples, and the PBE system has to somehow rank between these candidates and choose the correct one without any further information from the user. In this work we present a different approach to PBE in which the system avoids making a ranking decision at the synthesis stage, by instead synthesizing a disjunctive program that includes the many top-ranked programs as possible alternatives and selects between these different choices upon execution on a new input. This delayed choice brings the important benefit of comparing the possible outputs produced by the different disjuncts on a given input at execution time. We present a generic framework for synthesizing such disjunctive programs in arbitrary DSLs, and describe two concrete implementations of disjunctive synthesis in the practical domains of data extraction from plain text and HTML documents. We present an evaluation showing the significant increase in robustness achieved with our disjunctive approach, as illustrated by an increase from 59% to 93% of tasks for which correct programs can be learnt from a single\u00a0\u2026", "num_citations": "13\n", "authors": ["1694"]}
{"title": "Research for practice: Tracing and debugging distributed systems; programming by examples\n", "abstract": " Expert-curated guides to the best of CS research.", "num_citations": "13\n", "authors": ["1694"]}
{"title": "Automated semantic grading of programs\n", "abstract": " We present a new method for automatically grading introductory programming assignments. In order to use this method, instructors provide a reference implementation of the assignment, and an error model consisting of potential corrections to errors that students might make. Using this information, the system automatically derives minimal corrections to student\u2019s incorrect solutions, providing them with a quantifiable measure of exactly how incorrect a given solution was, as well as feedback about what they did wrong. We introduce a simple language for describing error models in terms of correction rules, and formally define a rule-directed translation strategy that reduces the problem of finding minimal corrections in an incorrect program to the problem of synthesizing a correct program from a sketch. We have evaluated our system on over 1000 solution attempts by real beginner programmers. Our results show that relatively simple error models can correct on average 73% of fixable fraction of submissions with non-trivial errors. We also show that the error models generalize across different problems from the same category, and our technique scales well for more complex error models and programming assignments such as those found in AP level computer science final examinations.", "num_citations": "13\n", "authors": ["1694"]}
{"title": "Leveraging learned programs for data manipulation\n", "abstract": " Examples of the present disclosure describe leveraging of learned programs for data manipulation. A template associated with information including non-marked up content is detected by applying machine learning processing that compares the information with a plurality of stored templates. The learned program is detected from a learned program pool comprising a plurality of learned programs based on the template detected. Extracted data from the information is manipulated based on application of the learned program. Other examples are also described.", "num_citations": "12\n", "authors": ["1694"]}
{"title": "Extracting relational data from semi-structured spreadsheets\n", "abstract": " Relational data is extracted from spreadsheets. A relational data extraction program is synthesized, where this synthesized program is consistent with examples of relational data associated with a spreadsheet. The synthesized program is executed on the spreadsheet, which extracts a set of tuples therefrom that is consistent with these examples, and generates a table that includes the extracted set of tuples. A program is received that specifies a set of constraints defining relational data to be extracted from a spreadsheet, where this set of constraints includes cell constraints and spatial constraints. The received program is executed on the spreadsheet, which extracts a set of tuples therefrom that is consistent with the set of constraints, and generates a table that includes the extracted set of tuples.", "num_citations": "12\n", "authors": ["1694"]}
{"title": "Bound analysis using backward symbolic execution\n", "abstract": " A fundamental problem that arises frequently in quantitative program analysis (eg, resource usage analysis) is that of computing an upper bound for a given arithmetic expression at a given program location in terms of the procedure inputs. We refer to this problem as bound analysis. The problem is theoretically as well as practically challenging because of variable updates inside loops and presence of virtual methods.Our solution to the bound analysis problem involves an inter-procedural (goal-directed) backward analysis built on top of an SMT solver. The analysis has the advantage of dealing with arbitrary operators that are understood by the underlying SMT solver. The analysis uses novel proof-rule based non-iterative technique to reason about updates inside loops, which makes it quite scalable. It uses user-defined abstract implementations to trace back across virtual methods arising from use of interfaces or extensible types. We have implemented the analysis inside the SPEED tool, which computes symbolic computational complexity bounds for procedures. Our analysis is used to translate bounds on number of loop iterations and cost of method calls to respective bounds in terms of procedure inputs. We have evaluated the precision and scalability of the analysis over 4 .NET assemblies that together contained thousands of methods and resulted in 9152 queries to the analysis. The analysis was able to answer 90% of the queries on an average of 0.23 seconds per query.", "num_citations": "12\n", "authors": ["1694"]}
{"title": "A polynomial-time algorithm for global value numbering\n", "abstract": " We describe a polynomial-time algorithm for global value numbering, which is the problem of discovering equivalences among program sub-expressions. We treat all conditionals as non-deterministic and all program operators as uninterpreted. We show that there are programs for which the set of all equivalences contains terms whose value graph representation requires exponential size. Our algorithm discovers all equivalences among terms of size at most s in time that grows linearly with s. For global value numbering, it suffices to choose s to be the size of the program. Earlier deterministic algorithms for the same problem are either incomplete or take exponential time. We provide a detailed analytical comparison of some of these algorithms.", "num_citations": "12\n", "authors": ["1694"]}
{"title": "Timing analysis of concurrent programs\n", "abstract": " Described are various techniques by which a concurrent program is analyzed with respect to timing. In one aspect, code fragments in a concurrent program are modified and/or instrumented by inserting iteration counters inside loops. Examples of modified fragments include those corresponding to concurrently executing code fragments, non-blocking concurrent code fragments, blocking concurrent code fragments, fragments having a loop that may not terminate, fragments having interlocked operation, or fragments having a timeout. Such fragments are modified and/or flagged so as to provide the summary data. When statically analyzed, the instrumented code provides complexity information regarding each fragment, or combinations of fragments, such as concurrent fragments. Summary data regarding the concurrent program is provided by processing the complexity information into at least one computation graph.", "num_citations": "11\n", "authors": ["1694"]}
{"title": "Path-sensitive analysis for linear arithmetic and uninterpreted functions\n", "abstract": " We describe data structures and algorithms for performing a path-sensitive program analysis to discover equivalences of expressions involving linear arithmetic or uninterpreted functions. We assume that conditionals are abstracted as boolean variables, which may be repeated to reflect equivalent conditionals. We introduce free conditional expression diagrams (FCEDs), which extend binary decision diagrams (BDDs) with internal nodes corresponding to linear arithmetic operators or uninterpreted functions. FCEDs can represent values of expressions in a program involving conditionals and linear arithmetic (or uninterpreted functions). We show how to construct them easily from a program, and give a randomized linear time algorithm (or quadratic time for uninterpreted functions) for comparing FCEDs for equality. FCEDs are compact due to maximal representation sharing for portions of the program with\u00a0\u2026", "num_citations": "11\n", "authors": ["1694"]}
{"title": "A practical framework for constructing structured drawings\n", "abstract": " We describe a novel theoretical framework for modeling structured drawings which contain one or more patterns of repetition in their constituent elements. We then present PatternSketch, a sketch-based drawing tool built using our framework to allow quick construction of structured drawings. PatternSketch can recognize and beautify drawings containing line segments, polylines, arcs, and circles. Users can employ a series of gestures to identify repetitive elements and create new elements based on automatically inferred patterns. PatternSketch leverages the programming-by-example (PBE) paradigm, enabling it to infer non-trivial patterns from a few examples. We show that PatternSketch, with its sketch-based user interface and a unique pattern inference algorithm, enables efficient and natural construction of structured drawings.", "num_citations": "10\n", "authors": ["1694"]}
{"title": "Bounding resource consumption using abstract interpretation\n", "abstract": " Bounding resource consumption of code using abstract interpretation includes a static analysis to estimate a code's resource consumption in terms of units of resources utilized at any point during execution, expressed as a function of its scalar inputs. An instrumentation mechanism and an abstract interpretation mechanism are employed to compute bounds on the code resource consumption. The instrumentation mechanism includes incorporating one or more counter variables in the source code to count the number of loop iterations and recursive procedure call invocations. The abstract interpretation mechanism includes computing invariants on the instrumented counter variables and scalar program variables to obtain bounds on the number of loop iterations and recursive procedure call invocations, which are then composed together to obtain resource bounds for the entire program.", "num_citations": "9\n", "authors": ["1694"]}
{"title": "Bound analysis of imperative programs with the size-change abstraction (extended version)\n", "abstract": " The size-change abstraction (SCA) is an important program abstraction for termination analysis, which has been successfully implemented in many tools for functional and logic programs. In this paper, we demonstrate that SCA is also a highly effective abstract domain for the bound analysis of imperative programs. We have implemented a bound analysis tool based on SCA for imperative programs. We abstract programs in a pathwise and context dependent manner, which enables our tool to analyze real-world programs effectively. Our work shows that SCA captures many of the essential ideas of previous termination and bound analysis and goes beyond in a conceptually simpler framework.", "num_citations": "9\n", "authors": ["1694"]}
{"title": "Sketch beautification and completion of partial structured-drawings\n", "abstract": " A sketch processing system is described herein for assisting a user in producing a drawing. In one implementation, the sketch processing system operates by: receiving ink strokes in response to creation of an original drawing; recognizing components and geometric constraints within the original drawing, to produce a recognized drawing; beautifying the original drawing by modifying at least one aspect of the recognized drawing in accordance with the recognized constraints, to produce a beautified drawing; and recognizing a recurring pattern in the beautified pattern (if any) and using that pattern to produce at least one added component to the beautified drawing.", "num_citations": "8\n", "authors": ["1694"]}
{"title": "Computing a symbolic bound for a procedure\n", "abstract": " A system that facilitates computing a symbolic bound with respect to a procedure that is executable by a processor on a computing device is described herein. The system includes a transition system generator component that receives the procedure and computes a disjunctive transition system for a control location in the procedure. A compute bound component computes a bound for the transition system, wherein the bound is expressed in terms of inputs to the transition system. The system further includes a translator component that translates the bound computed by the compute bound component such that the bound is expressed in terms of inputs to the procedure.", "num_citations": "8\n", "authors": ["1694"]}
{"title": "Programming by demonstration framework applied to procedural math problems\n", "abstract": " K-12 mathematics includes many procedures to be learned, such as addition and subtraction, and there are many \u201cbuggy\u201d or incorrect procedures that students demonstrate during this learning process. Learning such procedures (both correct and incorrect) from demonstration traces has various applications in computer-aided education. We formalize mathematical procedures as spreadsheet programs, involving loops and conditionals over a given set of base operators, and present a novel algorithm for synthesizing such procedures from demonstrations. Our algorithm is based on dynamic programming and leverages ideas from version-space algebras and template-based program synthesis. Our implementation efficiently synthesized programs to solve 20 common math procedures and reproduce 28 different kinds of bugs that were demonstrated by real students across 9 procedures. Our implementation significantly outperforms SKETCH, a state of the art program synthesizer, on these tasks. We also demonstrate the applicability of our generic program synthesis technology to spreadsheet table transformations, an important domain in end-user programming.", "num_citations": "7\n", "authors": ["1694"]}
{"title": "Applications of program synthesis to end-user programming and intelligent tutoring systems\n", "abstract": " Computing devices have become widely available to billions of end users, yet a handful of experts have the needed expertise to program these devices. Automated program synthesis has the potential to revolutionize this landscape, when targeted for the right set of problems and when allowing the right interaction model. The first part of this talk discusses techniques for programming using examples and natural language. These techniques have been applied to various end-user programming domains including data manipulation and smartphone scripting. The second part of this talk presents surprising applications of program synthesis technology to automating various repetitive tasks in Education including problem, solution, and feedback generation for various subject domains such as math and programming. These results advance the state-of-the-art in intelligent tutoring, and can play a significant role in\u00a0\u2026", "num_citations": "6\n", "authors": ["1694"]}
{"title": "Static program reduction for complexity analysis\n", "abstract": " Described is an analysis tool/techniques for determining the computational complexity of a computer program, including when the program includes procedures having nested loops and/or multi-path loops. First, multi-path loops are converted into code-fragments consisting of simpler loops via a transformation called control flow refinement. Progress invariants are determined for appropriate locations in the procedure to represent relationships between a state that can arise at that program location and the previous state at that location. A bound finding mechanism (such as one based on pattern matching) is then used to compute loop bounds from progress invariants. These bounds are then composed appropriately to determine a precise bound for the enclosing procedure.", "num_citations": "6\n", "authors": ["1694"]}
{"title": "Web data extraction using hybrid program synthesis: A combination of top-down and bottom-up inference\n", "abstract": " Automatic synthesis of web data extraction programs has been explored in a variety of settings, but in practice there remain various robustness and usability challenges. In this work we present a novel program synthesis approach which combines the benefits of deductive and enumerative synthesis strategies, yielding a semi-supervised technique with which concise programs expressible in standard languages can be synthesized from very few examples. We demonstrate improvement over existing techniques in terms of overall accuracy, number of examples required, and program complexity. Our method has been deployed as a web extraction feature in the mass market Microsoft Power BI product.", "num_citations": "5\n", "authors": ["1694"]}
{"title": "Join with format modification by example\n", "abstract": " A computing device is provided comprising a processor configured to select at least one pair of elements, including an element in a source column of the first table and an element in a target column of the second table. The processor may detect that the elements are in different formats. For at least one element, the processor may apply a predetermined mapping to a common format. The processor may modify at least one element to have the same format as the other, and may generate an example including the modified pair. The processor may programmatically generate a script that, when performed on the selected elements, produces a value consistent with the example. For the script with output matching the elements of the target column, the processor may convey the output for display, and may join the tables at least in part by performing the script on the source column.", "num_citations": "5\n", "authors": ["1694"]}
{"title": "Program synthesis\n", "abstract": " Program Synthesis is the task of searching for programs over some underlying space that realize user\u2019s intent. There are three key dimensions in program synthesis: expression of user intent, space of programs over which to search, and the search technique. This article illustrates these dimensions while taking an application centric view.The traditional application of program synthesis has been in synthesizing tricky programs such as bitvector algorithms to help software developers or algorithm designers. After an initial discussion of this traditional application, we discuss some recent applications of program synthesis techniques to helping end-users with little or no programming background. In particular, we discuss techniques for automating a variety of simple repetitive tasks in spreadsheets using examples. We then discuss a rather surprising application of synthesis techniques to computer-aided Education including tasks such as problem synthesis, solution synthesis, and feedback synthesis. We illustrate these tasks by means of applications to a variety of subject domains ranging from arithmetic, algebra, geometry, programming, logic, and automata theory.", "num_citations": "5\n", "authors": ["1694"]}
{"title": "Calculating resource bounds of programs manipulating recursive data structures and collections\n", "abstract": " Bounding resource consumption of code that processes recursive data structures and collections includes making use of quantitative functions (based on user input) that are associated with a tuple of data-structures and whose semantics is specified by describing the effect of various data-structure methods on the relevant quantitative functions. Counter variables are incorporated into source code to count loop iterations (and number of recursive procedure call invocations). Relevant quantitative functions are incorporated into the source code to allow computation of invariants (and hence bounds) on the incorporated counter variables in terms of the quantitative functions.", "num_citations": "5\n", "authors": ["1694"]}
{"title": "Randomized algorithms for program analysis and verification\n", "abstract": " Program analysis and verification are provably hard, and we have learned not to expect perfect results. We are accustomed to pay this cost in terms of incompleteness and algorithm complexity. Recently we have started to investigate what benefits we could expect if we are willing to trade off controlled amounts of soundness. This talk describes a number of randomized program analysis algorithms which are simpler, and in many cases have lower computational complexity, than the corresponding deterministic algorithms. The price paid is that such algorithms may, in rare occasions, infer properties that are not true. We describe both the intuitions and the technical arguments that allow us to evaluate and control the probability that an erroneous result is returned, in terms of various parameters of the algorithm. These arguments will also shed light on the limitations of such randomized algorithms.", "num_citations": "5\n", "authors": ["1694"]}
{"title": "Program synthesis for robotic tasks\n", "abstract": " Robotic task program synthesis embodiments are presented that generally synthesize a robotic task program based on received examples of repositioning tasks. In one implementation, the exemplary repositioning tasks are human demonstrations of object manipulation in an actual or displayed robot workspace. A domain specific language (DSL) designed for object repositioning tasks is employed for the robotic control program. In general, candidate robotic task programs are generated from the example tasks. Each candidate program includes instructions for causing the robot to reposition objects, and represents a different permutation of instructions consistent with the received example tasks. The candidate programs are ranked, and whenever the top ranking program accomplishes the repositioning specified in each example task, it is designated as the synthesized robotic task program.", "num_citations": "4\n", "authors": ["1694"]}
{"title": "FlashProfile: Interactive Synthesis of Syntactic Profiles.\n", "abstract": " We address the problem of learning comprehensive syntactic profiles for a set of strings. Real-world datasets, typically curated from multiple sources, often contain data in various formats. Thus any data processing task is preceded by the critical step of data format identification. However, manual inspection of data to identify various formats is infeasible in standard big-data scenarios.We present a technique for generating comprehensive syntactic profiles in terms of user-defined patterns that also allows for interactive refinement. We define a syntactic profile as a set of succinct patterns that describe the entire dataset. Our approach efficiently learns such profiles, and allows refinement by exposing a desired number of patterns. Our implementation, FlashProfile, shows a median profiling time of 0.7 s over 142 tasks on 74 real datasets. We also show that access to the generated data profiles allow for more accurate synthesis of programs, using fewer examples in programming-by-example workflows.", "num_citations": "4\n", "authors": ["1694"]}
{"title": "Automating repetitive tasks for the masses\n", "abstract": " The programming languages (PL) research community has traditionally catered to the needs of professional programmers in the continuously evolving technical industry. However, there is a new opportunity that knocks our doors. The recent IT revolution has resulted in the masses having access to personal computing devices. More than 99% of these computer users are non-programmers and are today limited to being passive consumers of the software that is made available to them. Can we empower these users to more effectively leverage computers for their daily tasks? The formalisms, techniques, and tools developed in the PL and the formal methods research communities can play a pivotal role!", "num_citations": "4\n", "authors": ["1694"]}
{"title": "Approaches and applications of inductive programming (dagstuhl seminar 13502)\n", "abstract": " This report documents the program and the outcomes of Dagstuhl Seminar 13502\" Approaches and Applications of Inductive Programming\". After a short introduction to inductive programming research, an overview of the talks and the outcomes of discussion groups is given.", "num_citations": "4\n", "authors": ["1694"]}
{"title": "Static Analysis of Heap-Manipulating Low-Level So ware\n", "abstract": " This paper describes a static (intraprocedural) analysis for analyzing heap-manipulating programs (in presence of recursive data structures and pointer arithmetic) in languages like C or low-level code. This analysis can be used for checking memory-safety, memory leaks, and user specified assertions. We first propose a rich abstract domain for representing useful invariants about such programs. This abstract domain allows representation of must and may equalities among pointer expressions. The integer variables used in the pointer expressions can be existentially as well as universally quantified and can have constraints over some base domain. We allow quantification of a special form, namely\u2203\u2200 quantification. This choice has been made to balance expressiveness with efficient automated deduction. The existential quantification is over some ghost variables of programs, which are automatically made explicit by our analysis to express useful program invariants. The universal quantifier is used to express properties of collections of memory locations. We then show how to perform sound abstract interpretation over this abstract domain. We give transfer functions for performing join, meet, and postcondition operations over this abstract domain. The basis of all these operations is an abstract interpreter for the quantifier-free base constraint domain (eg., the conjunctive domain of linear arithmetic combined with uninterpreted functions). To our knowledge, this is the first abstract interpreter that can automatically deduce first-order logic invariants in programs (without requiring any explicit predicates).", "num_citations": "4\n", "authors": ["1694"]}
{"title": "Automatic splitting of a column into multiple columns\n", "abstract": " Various technologies described herein pertain to automated data splitting using predictive program synthesis. Input-only examples for splitting an input column of an input data set can be received. The input-only examples can include example entries from the input column of the input data set to be split into multiple output columns without specification of how the example entries are to be split into multiple output columns. Further, a program for splitting the input column of the input data set into the multiple output columns can be synthesized based on the input-only examples. The program can be synthesized, given the input-only examples, in a domain-specific language (DSL) for splitting an entry into a tuple of fields utilizing a predictive program synthesis algorithm. Moreover, the program can be executed on the input data set to split the input column of the input data set into the multiple output columns.", "num_citations": "3\n", "authors": ["1694"]}
{"title": "Program verification and discovery using probabilistic inference\n", "abstract": " In one embodiment, a computer system performs a method for verifying the validity or invalidity of a software routine by learning appropriate invariants at each program point. A computer system chooses an abstract domain that is sufficiently precise to express the appropriate invariants. The computer system associates an inconsistency measure with any two abstract elements of the abstract domain. The computer system searches for a set of local invariants configured to optimize a total inconsistency measure which includes a sum of local inconsistency measures. The computer system optimizes the total inconsistency measure for all input/output pairs of the software routine. In one embodiment, the optimization of total inconsistency is achieved by the computer system which repeatedly replaces a locally inconsistent invariant with a new invariant, randomly selected among the possible invariants which are locally\u00a0\u2026", "num_citations": "3\n", "authors": ["1694"]}
{"title": "Generating tables based upon data extracted from tree-structured documents\n", "abstract": " Various technologies pertaining to extracting data encoded in a tree-structured document and generating a table based upon the extracted data are described herein. In a first embodiment, the table is generated without requiring input from a data cleaner. In a second embodiment, the table is generated based upon examples set forth by a data cleaner.", "num_citations": "2\n", "authors": ["1694"]}
{"title": "Join with predictive merging of multiple columns\n", "abstract": " A computing device is provided, comprising a processor configured to select at least one pair of tuples of columns including a source tuple from a first table and a target tuple from a second table. For each pair, the processor may select one or more rows from the source tuple and elements of the target tuple. For each selected row, the processor may programmatically generate a script that, when performed on the source tuple, produces a value consistent with the target tuple. The processor may apply each script to other rows of the source tuple and determine that an output is in the target tuple. For each column of the target tuple, for the script with output that meets a matching criterion, the processor may convey the output and, in response to a signal accepting the script, join the tables at least in part by performing each accepted script.", "num_citations": "2\n", "authors": ["1694"]}
{"title": "Identifying boundaries of substrings to be extracted from log files\n", "abstract": " Described herein are various technologies pertaining to identifying boundaries of a substring in a log file, wherein the substring is to be extracted from the log file and used to construct a table. An indication is received that a user has selected a beginning boundary of the substring, and the ending boundary of the substring is automatically identified.", "num_citations": "2\n", "authors": ["1694"]}
{"title": "Learning natural programs from a few examples in real-time\n", "abstract": " Programming by examples (PBE) is a rapidly growing subfield of AI, that aims to synthesize user-intended programs using input-output examples from the task. As users can provide only a few I/O examples, capturing user-intent accurately and ranking user-intended programs over other programs is challenging even in the simplest of the domains. Commercially deployed PBE systems often require years of engineering effort and domain expertise to devise ranking heuristics for real-time synthesis of accurate programs. But such heuristics may not cater to new domains, or even to a different segment of users from the same domain. In this work, we develop a novel, real-time, ML-based program ranking algorithm that enables synthesis of natural, user-intended, personalized programs. We make two key technical contributions: 1) a new technique to embed programs in a vector space making them amenable to ML\u00a0\u2026", "num_citations": "2\n", "authors": ["1694"]}
{"title": "Interactive splitting of a column into multiple columns\n", "abstract": " Various technologies described herein pertain to interactive data splitting. A program for splitting an input column of an input data set into multiple output columns can be synthesized based on input-only examples. The program can further be generated based on various user input; thus, the user input can guide the synthesis of the program. Moreover, the program can be executed on the input data set to split the input column of the input data set into the multiple output columns.", "num_citations": "2\n", "authors": ["1694"]}
{"title": "Example management for string transformation\n", "abstract": " A method for transforming strings includes identifying one or more candidate example input strings from a database including a set of input strings. The candidate example input strings are presented for example transformation. For one or more of the candidate example input strings, an example output string corresponding to that example input string is received, where each example input string and its corresponding example output string define a transformation example in an example set. A string transformation program is generated based on transformation examples in the example set.", "num_citations": "2\n", "authors": ["1694"]}
{"title": "Automated feedback and recognition through data mining in code hunt\n", "abstract": " Learning to code has become so popular that it is now almost the default that beginners will encounter coding on a website, along with thousands of others at the same time. Providing feedback and recognition in the face of such increasing numbers is a challenge that can be met by the automated test generation. Through automation and access to massive amounts of data, we show that the frequency, coverage, accuracy and personalization of feedback can be improved over earlier systems. Recognition can also be made automatic by using a gaming model. Based on the Code Hunt programming Game, we have developed and tested a system of test-driven synthesis (TDS) and produced results that show that we can accurately produce sensible feedback. Moreover the feedback increases engagement in continuing with the difficult task of learning to code. We also report on the effect of recognition of progress during the game and during contests.", "num_citations": "2\n", "authors": ["1694"]}
{"title": "Program verification as inference in belief networks\n", "abstract": " In this paper, we propose a new algorithm for proving the validity or invalidity of a pre/postcondition pair for a program. The algorithm is motivated by the success of the algorithms for probabilistic inference developed in the machine learning community for reasoning in graphical models. The validity or invalidity proof consists of providing an invariant at each program point that can be locally verified. The algorithm works by iteratively randomly selecting a program point and updating the current abstract state representation to make it more locally consistent (with respect to the abstractions at the neighboring points). We show that this simple algorithm has some interesting aspects:(a) It brings together the complementary powers of forward and backward analyses;(b) The algorithm has the ability to recover itself from excessive under-approximation or over-approximation that it may make.(Because the algorithm does not\u00a0\u2026", "num_citations": "2\n", "authors": ["1694"]}
{"title": "Probabilistic inference of programs from input/output examples\n", "abstract": " We present a novel algorithm for inferring an imperative program that satisfies examples of given input-output pairs. The algorithm can be used for automatic bug finding and correction from test examples. In addition to providing input-output pairs (which are concrete combinations of states at the beginning and the end of the program), the constraints describing program correctness can also be provided in terms of abstract state representations anywhere in the program. Our approach to solving this set of problems is to describe the program as a graph consisting of instructions and states as potentially unknown variables, connected by constraint nodes. Then, a probabilistic inference technique, known as belief propagation in the machine learning community, is used to infer both the intermediate program states and the instructions that satisfy all the constraints. To illustrate the power of the approach, we show examples of inferring imperative program fragments that execute polynomial computations and list manipulations from small sets of pairs of desired input-output combinations. In addition, we show how a buggy piece of code can be used to initialize the instructions in the graph, after which belief propagation leads to altering the code so as to satisfy the input-output constraints. We believe that the ideas discussed here have many applications in fast software development and debugging.", "num_citations": "2\n", "authors": ["1694"]}
{"title": "A randomized satisfiability procedure for arithmetic and uninterpreted function symbols\n", "abstract": " We present a new randomized algorithm for checking the satisfiability of a conjunction of literals in the combined theory of linear equalities and uninterpreted functions. The key idea of the algorithm is to process the literals incrementally and to maintain at all times a set of random variable assignments that satisfy the literals seen so far. We prove that this algorithm is complete (i.e., it identifies all unsatisfiable conjunctions) and is probabilistically sound (i.e., the probability that it fails to identify satisfiable conjunctions is very small). The algorithm has the ability to retract assumptions incrementally with almost no additional space overhead. The key advantage of the algorithm is its simplicity. We also show experimentally that the randomized algorithm has performance competitive with the existing deterministic symbolic algorithms.", "num_citations": "2\n", "authors": ["1694"]}
{"title": "Record profiling for dataset sampling\n", "abstract": " A method for generating a smaller dataset from a larger dataset, each dataset holding a plurality of records, includes profiling the larger dataset to identify a plurality of patterns, each of which is descriptive of one or more records held in the larger dataset. A plurality of slots of the smaller dataset is filled with records held in the larger dataset. Multiple records held in the larger dataset are individually retrieved, and for each retrieved record it is determined whether to place the retrieved record into a slot of the smaller dataset and evict a record already occupying that slot, or not place the retrieved record into the smaller dataset. This determination is based on a pattern of the retrieved record and a representation status of the pattern in the smaller dataset.", "num_citations": "1\n", "authors": ["1694"]}
{"title": "Automated document content modification\n", "abstract": " Systems and methods may be used to present changes to a document on a user interface. A method may include receiving, on the user interface, a user input including an edit task to a first portion of a document. The method may include determining, using a processor, that a second portion of the document includes text changeable by the edit task. The method may include automatically performing the edit task on the second portion of the document within the user interface based on the determination.", "num_citations": "1\n", "authors": ["1694"]}
{"title": "Behavior feature use in programming by example\n", "abstract": " Technologies for narrowing the choices for programs that each comply with example behaviors provided by a user in programming by example. Even if the user provides insufficient behavior examples to precisely identify a program that should be used, the system still uses program behavior features (along with potentially structure features) of the program in order to identify suitability of each program that would comply with the specific set of behavior examples. A particular program is then selected and enabled for that user so that the particular program performs behaviors exemplified by the one or more program behavior examples. In the case where user assistance is used in selection of the program, the suitability for each possible program may be used to decide which of multiple possible programs should be made selectable by the user. Those higher suitability programs might be visualized to the user for\u00a0\u2026", "num_citations": "1\n", "authors": ["1694"]}
{"title": "Programming-by-example using disjunctive programs\n", "abstract": " Systems, methods, and computer-executable instructions for synthesizing a program for a task. A domain specific language that includes a disjunctive symbol and an input/output example for the task are received. A program for the task is synthesized based on the input/output example and the domain specific language. Sub-programs for an instance of the disjunctive symbol are synthesized, A set of feature calculators and target feature values are determined. The program for the task is returned. The program includes the sub-programs, the set of feature calculators and the target feature values.", "num_citations": "1\n", "authors": ["1694"]}
{"title": "Technical Perspective: Program synthesis using stochastic techniques\n", "abstract": " Program synthesis involves discovering a program from an underlying space of programs that satisfies a given specification using some search technique. 3 It has many applications including algorithm discovery, optimized implementations, programming assistance, 5 and synthesis of small scripts to automate repetitive tasks for end users. 4 Its success relies heavily on efficient search algorithms to navigate the underlying huge state space of programs. The authors of the following paper have developed a stochastic search technique and applied it to program optimization. The impressive results of their implementation STOKE on hard program optimization benchmarks illustrate the promising potential of stochastic search to hard program synthesis problems.The specification for program synthesis can be in the form of a logical declarative relationship between inputs and outputs. Examples or demonstration traces\u00a0\u2026", "num_citations": "1\n", "authors": ["1694"]}
{"title": "Feedback generation for performance problems in introductory programming assignments.\n", "abstract": " Providing feedback on programming assignments manually is a tedious, error prone, and time-consuming task. In this paper, we motivate and address the problem of generating feedback on performance aspects in introductory programming assignments. We studied a large number of functionally correct student solutions to introductory programming assignments and observed:(1) There are different algorithmic strategies, with varying levels of efficiency, for solving a given problem. These different strategies merit different feedback.(2) The same algorithmic strategy can be implemented in countless different ways, which are not relevant for reporting feedback on the student program. We propose a light-weight programming language extension that allows a teacher to define an algorithmic strategy by specifying certain key values that should occur during the execution of an implementation. We describe a dynamic analysis based approach to test whether a student\u2019s program matches a teacher\u2019s specification. Our experimental results illustrate the effectiveness of both our specification language and our dynamic analysis. On one of our benchmarks consisting of 2316 functionally correct implementations to 3 programming problems, we identified 16 strategies that we were able to describe using our specification language (in 95 minutes after inspecting 66, ie, around 3%, implementations). Our dynamic analysis correctly matched each implementation with its corresponding specification, thereby automatically producing the intended feedback.", "num_citations": "1\n", "authors": ["1694"]}
{"title": "Program Synthesis Without Full Specifications for Novel Applications\n", "abstract": " Program synthesis is a family of techniques that generate programs from a description of what the program should do but not how it should do it. By designing a program synthesis algorithm together with the user interaction model we show that by accepting small increases in user effort, it is easier to write the synthesizer and the need for specialization of the synthesizer to a given domain is reduced without losing performance. In this work, we target three tasks to show the breadth of our methodology: code completion, end-user programming-by-example for data transformations, and feedback for introductory programming assignments. For each of these tasks, we develop an interaction model and program synthesis algorithm together to best support the user. In the first, we use partial expressions to allow programmers to express exactly what they don't know and want the completion system to fill in. In the second, we use the sequence of examples to inform building up larger programs iteratively. In the last, we use attempts from other students on the same assignment to mine corrections.", "num_citations": "1\n", "authors": ["1694"]}
{"title": "Automatic generation of starting positions in board games\n", "abstract": " Board games, like Tic-Tac-Toe and CONNECT-4, play an important role not only in development of mathematical and logical skills, but also in emotional and social development. In this paper, we motivate and address the problem of generating interesting start states for such games. Our algorithm generates starting states of varying difficulty level for player 1, given the rules of a board game, the number of steps required for player 1 to win, and the expertise levels of the two players. Our algorithm leverages symbolic methods and iterative simulation to efficiently search the humongous state space. We present experimental results that discover for the first time such interesting states for several games and demonstrate the feasibility of finding them in an offline mode. The presence of such states for a game like Tic-Tac-Toe 4\u00d7 4 that was previously thought to be trivial, opens up new games to be played that have been believed to be useless for ages.", "num_citations": "1\n", "authors": ["1694"]}
{"title": "Set-constraint based Program Analysis: A survey\n", "abstract": " This paper exhaustively surveys the set-constraint based approach to program analysis. The purpose of this paper is to put down the state-of-the-art knowledge in this eld at one place using a common terminology. This paper also serves to make the connection clearer between seemingly disparate program analysis problems which have been using related techniques but dierent terminology.", "num_citations": "1\n", "authors": ["1694"]}
{"title": "An Approach to Accelerated Innovation\n", "abstract": " Background CVP Joseph Sirosh from C&E had approached me after deciding that he didn\u2019t want to go the easy route of buying a relevant start-up. Instead, he would like to risk investing in the superior home-grown technology at MSR to have a shot at putting a significantly better and unique data wrangling product in the market. MSR EVP Harry Shum and CVP Jeannette Wing readily provided an insurance policy:\u201cWhenever you would like to come back, we will roll out a red-carpet welcome for you\u201d. When my then manager Ben Zorn, a staunch supporter of my work, wondered \u201cCan it get better than this?\u201d, it was time for self-reflection.", "num_citations": "1\n", "authors": ["1694"]}
{"title": "Generating random spanning trees\n", "abstract": " CiteSeerX \u2014 Generating Random Spanning Trees Documents Authors Tables Log in Sign up MetaCart DMCA Donate CiteSeerX logo Documents: Advanced Search Include Citations Authors: Advanced Search Include Citations Tables: DMCA Generating Random Spanning Trees Download From IEEE Download from IEEE Download Links [www.cs.berkeley.edu] Other Repositories/Bibliography DBLP Save to List Add to Collection Correct Errors Monitor Changes by Sourav Chatterji , Sumit Gulwani Summary Citations Active Bibliography Co-citation Clustered Documents Version History Share Facebook Twitter Reddit Bibsonomy OpenURL Abstract Keyphrases random spanning tree Powered by: Apache Solr About CiteSeerX Submit and Index Documents Privacy Policy Help Data Source Contact Us Developed at and hosted by The College of Information Sciences and Technology \u00a9 2007-2019 The Pennsylvania \u2026", "num_citations": "1\n", "authors": ["1694"]}