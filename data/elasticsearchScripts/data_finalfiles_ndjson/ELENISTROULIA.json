{"title": "UMLDiff: an algorithm for object-oriented design differencing\n", "abstract": " This paper presents UMLDiff, an algorithm for automatically detecting structural changes between the designs of subsequent versions of object-oriented software. It takes as input two class models of a Java software system, reverse engineered from two corresponding code versions. It produces as output a change tree, ie, a tree of structural changes, that reports the differences between the two design versions in terms of (a) additions, removals, moves, renamings of packages, classes, interfaces, fields and methods,(b) changes to their attributes, and (c) changes of the dependencies among these entities. UMLDiff produces an accurate report of the design evolution of the software system, and enables subsequent design-evolution analyses from multiple perspectives in support of various evolution activities. UMLDiff and the analyses it enables can assist software engineers in their tasks of understanding the rationale\u252c\u00e1\u0393\u00c7\u00aa", "num_citations": "565\n", "authors": ["57"]}
{"title": "Virtual worlds\u0393\u00c7\u00f6past, present, and future: New directions in social computing\n", "abstract": " Virtual worlds, where thousands of people can interact simultaneously within the same three-dimensional environment, represent a frontier in social computing with critical implications for business, education, social sciences, and our society at large. In this paper, we first trace the history of virtual worlds back to its antecedents in electronic gaming and on-line social networking. We then provide an overview of extant virtual worlds, including education-focused, theme-based, community-specific, children-focused, and self-determined worlds \u0393\u00c7\u00f4 and we analyze the relationship among these worlds according to an initial taxonomy for the area. Recognizing the apparent leadership of Second Life among today's self-determined virtual worlds, we present a detailed case study of this environment, including surveys of 138 residents regarding how they perceive and utilize the environment. Lastly, we provide a literature\u252c\u00e1\u0393\u00c7\u00aa", "num_citations": "515\n", "authors": ["57"]}
{"title": "Smart homes and home health monitoring technologies for older adults: A systematic review\n", "abstract": " BackgroundAround the world, populations are aging and there is a growing concern about ways that older adults can maintain their health and well-being while living in their homes.ObjectivesThe aim of this paper was to conduct a systematic literature review to determine: (1) the levels of technology readiness among older adults and, (2) evidence for smart homes and home-based health-monitoring technologies that support aging in place for older adults who have complex needs.ResultsWe identified and analyzed 48 of 1863 relevant papers. Our analyses found that: (1) technology-readiness level for smart homes and home health monitoring technologies is low; (2) the highest level of evidence is 1b (i.e., one randomized controlled trial with a PEDro score \u0393\u00eb\u00d16); smart homes and home health monitoring technologies are used to monitor activities of daily living, cognitive decline and mental health, and heart\u252c\u00e1\u0393\u00c7\u00aa", "num_citations": "389\n", "authors": ["57"]}
{"title": "Structural and semantic matching for assessing web-service similarity\n", "abstract": " The web-services stack of standards is designed to support the reuse and interoperation of software components on the web. A critical step in the process of developing applications based on web services is service discovery, i.e. the identification of existing web services that can potentially be used in the context of a new web application. Discovery through catalog-style browsing (such as supported currently by web-service registries) is clearly insufficient. To support programmatic service discovery, we have developed a suite of methods that assess the similarity between two WSDL (Web Service Description Language) specifications based on the structure of their data types and operations and the semantics of their natural language descriptions and identifiers. Given only a textual description of the desired service, a semantic information-retrieval method can be used to identify and order the most relevant WSDL\u252c\u00e1\u0393\u00c7\u00aa", "num_citations": "220\n", "authors": ["57"]}
{"title": "On the relationship between my avatar and myself\n", "abstract": " What is the relationship between avatars and the people they represent in terms of appearance and behavior? In this paper, we hypothesize that people (balancing motives of self-verification and self-enhancement) customize the image of their avatars to bear similarity to their real selves, but with moderate enhancements. We also hypothesize that virtual-world behavior (due to deindividuation in computer-mediated communication environments) is less restrained by normal inhibitions than real-world behavior. Lastly, we hypothesize that people with more attractive avatars than their real selves will be somewhat more confident and extraverted in virtual worlds than they are in the real world. We examine these issues using data collected from Second Life residents using an in-world intercept method that involved recruiting respondents", "num_citations": "216\n", "authors": ["57"]}
{"title": "Flexible interface matching for web-service discovery\n", "abstract": " The Web-services stack of standards is designed to support the reuse and interoperation of software components on the Web. A critical step, to that end, is service discovery, i.e., the identification of existing Web services that can potentially be used in the context of a new Web application. UDDI, the standard API for publishing Web-services specifications, provides a simple browsing-by-business-category mechanism for developers to review and select published services. In our work, we have developed a flexible service discovery method, for identifying potentially useful services and assessing their relevance to the task at hand. Given a textual description of the desired service, a traditional information-retrieval method is used to identify the most similar service description files, and to order them according to their similarity. Next, given this set of likely candidates and a (potentially partial) specification of the desired\u252c\u00e1\u0393\u00c7\u00aa", "num_citations": "202\n", "authors": ["57"]}
{"title": "Semantic structure matching for assessing web-service similarity\n", "abstract": " The web-services stack of standards is designed to support the reuse and interoperation of software components on the web. A critical step in the process of developing applications based on web services is service discovery, i.e., the identification of existing web services that can potentially be used in the context of a new web application. UDDI, the standard API for publishing web-services specifications, provides a simple browsing-by-business-category mechanism for developers to review and select published services. To support programmatic service discovery, we have developed a suite of methods that utilizes both the semantics of the identifiers of WSDL descriptions and the structure of their operations, messages and data types to assess the similarity of two WSDL files. Given only a textual description of the desired service, a semantic information-retrieval method can be used to identify and order the\u252c\u00e1\u0393\u00c7\u00aa", "num_citations": "180\n", "authors": ["57"]}
{"title": "A typology of virtual worlds: Historical overview and future directions\n", "abstract": " Virtual worlds constitute a growing space for collaborative play, learning, work, and e-commerce. To promote study of this emerging realm of activity, we suggest a typology adapted from C. Porter\u0393\u00c7\u00d6s (2004) typology of virtual communities. The five elements of the proposed typology include (1) purpose (content of interaction),(2) place (location of interaction),(3) platform (design of interaction),(4) population (participants in the interaction), and (5) profit model (return on interaction). We argue that this five-element typology facilitates identification of (a) the historic antecedents of virtual worlds in gaming and social networking,(b) future applications of virtual worlds for society, education, and business; and (c) topics for future research.", "num_citations": "174\n", "authors": ["57"]}
{"title": "A study on the current state of the art in tool-supported UML-based static reverse engineering\n", "abstract": " Today, software-engineering research and industry alike recognize the need for practical tools to support reverse-engineering activities. Most of the well-known CASE tools support reverse engineering in some way. The Unified Modeling Language (UML) has emerged as the de facto standard for graphically representing the design of object-oriented software systems. However, there does not yet exist a standard scheme for representing the reverse-engineered models of these systems. The various CASE tools usually adopt proprietary extensions to UML and, as a result, it is difficult, or even impossible, to ensure that model semantics remains unambiguous when working with different tools at the same time. In this paper, we examine the capabilities of the two most successful industrial-strength CASE-tools in reverse engineering the static structure of software systems and compare them to the results produced by\u252c\u00e1\u0393\u00c7\u00aa", "num_citations": "170\n", "authors": ["57"]}
{"title": "Kritik: An early case-based design system\n", "abstract": " Design is a very common, wide-ranging and open-ended activity. It includes not only the design of physical artifacts but also abstract artifacts, such as software interfaces, and conceptual artifacts, such as causal explanations. It can vary from everyday to specialized, naive to expert, and routine to creative design. Although", "num_citations": "168\n", "authors": ["57"]}
{"title": "API-evolution support with Diff-CatchUp\n", "abstract": " Applications built on reusable component frameworks are subject to two independent, and potentially conflicting, evolution processes. The application evolves in response to the specific requirements and desired qualities of the application's stakeholders. On the other hand, the evolution of the component framework is driven by the need to improve the framework functionality and quality while maintaining its generality. Thus, changes to the component framework frequently change its API on which its client applications rely and, as a result, these applications break. To date, there has been some work aimed at supporting the migration of client applications to newer versions of their underlying frameworks, but it usually requires that the framework developers do additional work for that purpose or that the application developers use the same tools as the framework developers. In this paper, we discuss our approach to\u252c\u00e1\u0393\u00c7\u00aa", "num_citations": "162\n", "authors": ["57"]}
{"title": "Refactoring practice: How it is and how it should be supported-an eclipse case study\n", "abstract": " Refactoring is an important activity in the evolutionary development of object-oriented software systems. Yet, several questions about the practice of refactoring remain unanswered, such as what fraction of code modifications are refactorings and what are the most frequent types of refactorings. To gain some insight in this matter, we conducted a detailed case study on the structural evolution of Eclipse, an integrated-development environment (IDE) and a plugin-based framework. Our study indicates that: 1) about 70% of structural changes may be due to refactorings; 2) for about 60% of these changes, the references to the affected entities in a component-based application can be automatically updated by a refactoring-migration tool if the relevant information of refactored components can be gathered through the refactoring engine; and 3) state-of-the-art IDEs, such as Eclipse, support only a subset of commonly\u252c\u00e1\u0393\u00c7\u00aa", "num_citations": "151\n", "authors": ["57"]}
{"title": "On the personality traits of stackoverflow users\n", "abstract": " In the last decade, developers have been increasingly sharing their questions with each other through Question and Answer (Q&A) websites. As a result, these websites have become valuable knowledge repositories, covering a wealth of topics related to particular programming languages. This knowledge is even more useful as the developer community evaluates both questions and answers through a voting mechanism. As votes accumulate, the developer community recognizes reputed members and further trusts their answers. In this paper, we analyze the community's questions and answers to determine the developers' personality traits, using the Linguistic Inquiry and Word Count (LIWC). We explore the personality traits of Stack Overflow authors by categorizing them into different categories based on their reputation. Through textual analysis of Stack Overflow posts, we found that the top reputed authors are\u252c\u00e1\u0393\u00c7\u00aa", "num_citations": "147\n", "authors": ["57"]}
{"title": "Understanding android fragmentation with topic analysis of vendor-specific bugs\n", "abstract": " The fragmentation of the Android ecosystem causes portability and compatibility issues within the entire Android platform, which increases developer workload, delays application deployment, and ultimately disappoints users. This subject is discussed in the press and in scientific publications but it has yet to be systematically examined. The Android bug reports, as submitted by Android-device users, span across operating-system versions and hardware platforms and can provide interesting evidence about the problem. In this paper, we analyze the bug reports related to two popular vendors, HTC and Motorola. First, we manually label the bug reports. Next, we use Labeled-LDA (Latent Dirichlet Allocation) on the labeled data and LDA on the original data, to infer topics. Finally, by examining the relevance of the top 18 bug topics for each vendor's bug reports over time, we classify topics as common or unique\u252c\u00e1\u0393\u00c7\u00aa", "num_citations": "147\n", "authors": ["57"]}
{"title": "Refactoring detection based on umldiff change-facts queries\n", "abstract": " Refactoring is an important activity in the evolutionary development of object-oriented software systems. Several IDEs today support the automated application of some refactorings; at the same time, there is substantial on-going research aimed at developing support for deciding when and how software should be refactored and for estimating the effect of the refactoring on the quality requirements of the software. On the other hand, understanding the refactorings in the evolutionary history of a software system is essential in understanding its design rationale. Yet, only very limited support exists for detecting refactorings. In this paper, we present our approach for detecting refactorings by analyzing the system evolution at the design level. We evaluate our method with case studies, examining two realistic examples of object-oriented software", "num_citations": "132\n", "authors": ["57"]}
{"title": "A contextual approach towards more accurate duplicate bug report detection\n", "abstract": " Bug-tracking and issue-tracking systems tend to be populated with bugs, issues, or tickets written by a wide variety of bug reporters, with different levels of training and knowledge about the system being discussed. Many bug reporters lack the skills, vocabulary, knowledge, or time to efficiently search the issue tracker for similar issues. As a result, issue trackers are often full of duplicate issues and bugs, and bug triaging is time consuming and error prone. Many researchers have approached the bug-deduplication problem using off-the-shelf information-retrieval tools, such as BM25F used by Sun et al. In our work, we extend the state of the art by investigating how contextual information, relying on our prior knowledge of software quality, software architecture, and system-development (LDA) topics, can be exploited to improve bug-deduplication. We demonstrate the effectiveness of our contextual bug-deduplication\u252c\u00e1\u0393\u00c7\u00aa", "num_citations": "126\n", "authors": ["57"]}
{"title": "An empirical study on web service evolution\n", "abstract": " The service-oriented architecture paradigm prescribes the development of systems through the composition of services, i.e., network-accessible components, specified by (and invoked through) their WSDL interface descriptions. Systems thus developed need to be aware of changes in, and evolve with, their constituent services. Therefore, accurate recognition of changes in the WSDL specification of a service is an essential functionality in the context of the software lifecycle of service-oriented systems. In this work, we present the results of an empirical study on WSDL evolution analysis. In the first part, we empirically study whether VTracker, our algorithm for XML differencing, can precisely recognize changes in WSDL documents by applying it to the task of comparing 18 versions of the Amazon EC2 web service. Second, we analyze the changes that occurred between the subsequent versions of various web\u252c\u00e1\u0393\u00c7\u00aa", "num_citations": "122\n", "authors": ["57"]}
{"title": "Analyzing the evolutionary history of the logical design of object-oriented software\n", "abstract": " Today, most object-oriented software systems are developed using an evolutionary process model. Therefore, understanding the phases that the system's logical design has gone through and the style of their evolution can provide valuable insights in support of consistently maintaining and evolving the system, without compromising the integrity and stability of its architecture. In this paper, we present a method for analyzing the evolution of object-oriented software systems from the point of view of their logical design. This method relies on UMLDiff, a UML-structure differencing algorithm, which, given a sequence of UML class models corresponding to the logical design of a sequence of system code releases, produces a sequence of \"change records\" that describe the design-level changes between subsequent system releases. This change-records sequence is subsequently analyzed from the perspective of each\u252c\u00e1\u0393\u00c7\u00aa", "num_citations": "99\n", "authors": ["57"]}
{"title": "Functional device models and model-based diagnosis in adaptive design\n", "abstract": " We analyze the diagnosis task in the context of adaptive design and redesign of physical devices. We identify three types of diagnosis tasks that differ in the types of information they take as input: the design does not achieve a desired function of the device, the design results in an undesirable behavior, and a specific structural element in the design misbehaves. We describe a model-based approach for solving the diagnosis task in the context of adaptive design and redesign. This approach uses functional models that explicitly represent the device functions and use them to organize teleological and causal knowledge about the device. In particular, we describe a specific kind of functional model called structure\u0393\u00c7\u00f6behavior\u0393\u00c7\u00f6function (SBF) models in which the causal behaviors of the device are specified in terms of flow of substances through components. We illustrate the use of SBF models with three examples from\u252c\u00e1\u0393\u00c7\u00aa", "num_citations": "90\n", "authors": ["57"]}
{"title": "Dynamic analysis for reverse engineering and program understanding\n", "abstract": " The main focus of program understanding and reverse engineering research has been on modeling the structure of a program by examining its code. This has been the result of the nature of the systems investigated and the perceived goals of the reverse engineering activities. The types of systems under investigation have changed, however, and the maintenance objectives have evolved. Many legacy systems today are object-oriented and component-based. One of the most prominent maintenance objectives is system migration to distributed environments, most notably the World Wide Web, for interoperation with other systems. This new maintenance objective has a great impact on the types of models expected as products of reverse engineering. As the traditional static software analysis techniques keep their valuable role in program comprehension, additional techniques, especially those focusing on run-time\u252c\u00e1\u0393\u00c7\u00aa", "num_citations": "87\n", "authors": ["57"]}
{"title": "Functional representation and reasoning for reflective systems\n", "abstract": " Functional models have been extensively investigated in the context of several problemsolving tasks such as device diagnosis and design. In this paper, we view problem solvers themselves as devices, and use structure-behavior-function models to represent how they work. The model representing the functioning of a problem solver explicitly specifies how the knowledge and reasoning of the problem solver result in the achievement of its goals. Then, we employ these models for performance-driven reflective learning. We view performance-driven learning as the task of redesigning the knowledge and reasoning of the problem solver to improve its performance. We use the model of the problem solver to monitor its reasoning. Assign blame when it fails, and appropriately redesign its knowledge and reasoning. This paper focuses on the model-based redesign of a path planner's task structure. It illustrates the\u252c\u00e1\u0393\u00c7\u00aa", "num_citations": "87\n", "authors": ["57"]}
{"title": "Healthcare training enhancement through virtual reality and serious games\n", "abstract": " There has been an increase in the use of immersive 3D virtual environments and serious games, that is, video games that are used for educational purposes, and only recently serious games have been considered for healthcare training. For example, there are a number of commercial surgical simulators which offer great potential for the training of basic skills and techniques, if the tedium of repeated rehearsal can be overcome. It is generally recognized that more abstract problem-solving and knowledge level training needs to be incorporated into simulated scenarios. This chapter explores some examples of what has been developed in terms of teaching models and evaluative methodologies, then discusses the educational theories explaining why virtual simulations and serious games are an important teaching tool, and finally suggests how to assess their value within an educational context. The tasks\u252c\u00e1\u0393\u00c7\u00aa", "num_citations": "80\n", "authors": ["57"]}
{"title": "Differencing logical UML models\n", "abstract": " UMLDiff is a heuristic algorithm for automatically detecting the changes that the logical design of an object-oriented software system has gone through, as the subject system evolved from one version to the next. UMLDiff requires as input two models of the logical design of the system, corresponding to two of its versions. It produces as output a set of change facts, reporting the differences between the two logical-design versions in terms of (a)\u252c\u00e1additions, removals, moves, renamings of model elements, i.e., subsystems, packages, classes, interfaces, attributes and operations, (b)\u252c\u00e1changes to their attributes, and (c)\u252c\u00e1changes to the relations among these model elements. In this paper, we detail the underlying metamodel, the UMLDiff algorithm and its heuristics for establishing lexical and structural similarity. We report on our experimental evaluation of the correctness and robustness of UMLDiff\u252c\u00e1\u0393\u00c7\u00aa", "num_citations": "80\n", "authors": ["57"]}
{"title": "Recognizing contributions in wikis: Authorship categories, algorithms, and visualizations\n", "abstract": " Wikis are designed to support collaborative editing, without focusing on individual contribution, such that it is not straightforward to determine who contributed to a specific page. However, as wikis are increasingly adopted in settings such as business, government, and education, where editors are largely driven by career goals, there is a perceived need to modify wikis so that each editor's contributions are clearly presented. In this paper we introduce an approach for assessing the contributions of wiki editors along several authorship categories, as well as a variety of information glyphs for visualizing this information. We report on three types of analysis: (a) assessing the accuracy of the algorithms, (b) estimating the understandability of the visualizations, and (c) exploring wiki editors' perceptions regarding the extent to which such an approach is likely to change their behavior. Our findings demonstrate that our\u252c\u00e1\u0393\u00c7\u00aa", "num_citations": "79\n", "authors": ["57"]}
{"title": "Reverse engineering legacy interfaces: An interaction-driven approach\n", "abstract": " Legacy systems constitute valuable assets to the organizations that own them. However, due to the development of newer and faster hardware platforms and the invention of novel interface styles, there is a great demand for their migration to new platforms. We present a method for reverse engineering the system interface that consists of two tasks. Based on traces of the users interaction with the system, the \"interface mapping\" task constructs a \"map\" of the system interface, in terms of the individual system screens and the transitions between them. The subsequent \"task and domain modeling\" task uses the interface map and task-specific traces to construct an abstract model of a user's task as an information exchange plan. The task model specifies the screen transition diagram that the user has to traverse in order to accomplish the task in question, and the flow of information that the user exchanges with the system\u252c\u00e1\u0393\u00c7\u00aa", "num_citations": "73\n", "authors": ["57"]}
{"title": "User interface reverse engineering in support of interface migration to the web\n", "abstract": " Legacy systems constitute valuable assets to the organizations that own them, and today, there is an increased demand to make them accessible through the World Wide Web to support e-commerce activities. As a result, the problem of legacy-interface migration is becoming very important. In the context of the CELLEST project, we have developed a new process for migrating legacy user interfaces to web-accessible platforms. Instead of analyzing the application code to extract a model of its structure, the CELLEST process analyzes traces of the system-user interaction to model the behavior of the application's user interface. The produced state-transition model specifies the unique legacy-interface screens (as states) and the possible commands leading from one screen to another (as transitions between the states). The interface screens are identified as clusters of similar-in-appearance snapshots in the\u252c\u00e1\u0393\u00c7\u00aa", "num_citations": "71\n", "authors": ["57"]}
{"title": "Detecting duplicate bug reports with software engineering domain knowledge\n", "abstract": " Bug deduplication, ie, recognizing bug reports that refer to the same problem, is a challenging task in the software\u0393\u00c7\u00c9engineering life cycle. Researchers have proposed several methods primarily relying on information\u0393\u00c7\u00c9retrieval techniques. Our work motivated by the intuition that domain knowledge can provide the relevant context to enhance effectiveness, attempts to improve the use of information retrieval by augmenting with software\u0393\u00c7\u00c9engineering knowledge. In our previous work, we proposed the software\u0393\u00c7\u00c9literature\u0393\u00c7\u00c9context method for using software\u0393\u00c7\u00c9engineering literature as a source of contextual information to detect duplicates. If bug reports relate to similar subjects, they have a better chance of being duplicates. Our method, being largely automated, has a potential to substantially decrease the level of manual effort involved in conventional techniques with a minor trade\u0393\u00c7\u00c9off in accuracy. In this study, we extend\u252c\u00e1\u0393\u00c7\u00aa", "num_citations": "70\n", "authors": ["57"]}
{"title": "Parking-stall vacancy indicator system, based on deep convolutional neural networks\n", "abstract": " Parking-management systems, including services that recognize vacant stalls, can play a valuable role in reducing traffic and energy waste in large cities. Visual methods for detecting vacant parking spots are cost-effective options since they can take advantage of the cameras already available in many parking lots. However, visual-detection methods can be fragile and not easily generalizable. In this paper, we present a robust detection algorithm based on deep convolutional neural networks. We implemented and tested our algorithm on a large baseline dataset, and also tested on video feeds from web-accessible parking-lot cameras. Our detection method improved the state of the art AUC by 8.13%. It also showed robust performance in different testing scenarios including tests on public cameras. We have developed a fully functional system, from server-side image analysis to front-end user interface, to\u252c\u00e1\u0393\u00c7\u00aa", "num_citations": "70\n", "authors": ["57"]}
{"title": "From run-time behavior to usage scenarios: an interaction-pattern mining approach\n", "abstract": " A key challenge facing IT organizations today is their evolution towards adopting e-business practices that gives rise to the need for reengineering their underlying software systems. Any reengineering effort has to be aware of the functional requirements of the subject system, in order not to violate the integrity of its intended uses. However, as software systems get regularly maintained throughout their lifecycle, the documentation of their requirements often become obsolete or get lost. To address this problem of\" software requirements loss\", we have developed an interaction-pattern mining method for the recovery of functional requirements as usage scenarios. Our method analyzes traces of the run-time system-user interaction to discover frequently recurring patterns; these patterns correspond to the functionality currently exercised by the system users, represented as usage scenarios. The discovered scenarios\u252c\u00e1\u0393\u00c7\u00aa", "num_citations": "68\n", "authors": ["57"]}
{"title": "Understanding class evolution in object-oriented software\n", "abstract": " In the context of object-oriented design, software systems model real-world entities abstractly represented in the system classes. As the system evolves through its lifecycle, its class design also evolves. Thus, understanding class evolution is essential in understanding the current design of the system and the rationale behind its evolution. In this paper, we describe a taxonomy of class-evolution profiles, a method for automatically categorizing a system's classes in one (or more) of eight types in the taxonomy, and a data-mining method for eliciting co-evolution relations among them. These methods rely on our UMLDiff algorithm that, given a sequence of UML class models of a system, surfaces the design-level changes over its lifecycle. The recovered knowledge about class evolution facilitates the overall understanding of the system class-design evolution and the identification of the specific classes that should be\u252c\u00e1\u0393\u00c7\u00aa", "num_citations": "67\n", "authors": ["57"]}
{"title": "A multidimensional empirical study on refactoring activity.\n", "abstract": " In this paper we present an empirical study on the refactoring activity in three well-known projects. We have studied five research questions that explore the different types of refactorings applied to different types of sources, the individual contribution of team members on refactoring activities, the alignment of refactoring activity with release dates and testing periods, and the motivation behind the applied refactorings. The studied projects have a history of 12, 7, and 6 years, respectively. We have found that there is very little variation in the types of refactorings applied on test code, since the majority of the refactorings focus on the reorganization and renaming of classes. Additionally, we have identified that the refactoring decision making and application is often performed by individual refactoring \u0393\u00c7\u00a3managers\u0393\u00c7\u00a5. We have found a strong alignment between refactoring activity and release dates. Moreover, we found that the development teams apply a considerable amount of refactorings during testing periods. Finally, we have also found that in addition to code smell resolution the main drivers for applying refactorings are the introduction of extension points, and the resolution of backward compatibility issues.", "num_citations": "66\n", "authors": ["57"]}
{"title": "AskJef: integration of case-based and multimedia technologies for interface design support\n", "abstract": " AskJef is a prototype AI system that helps software engineers in designing human-machine interfaces. It provides a memory of interface design examples, primitive domain objects, and design principles, guidelines, errors and stories. The design examples are represented graphically and decomposed temporally. The different types of knowledge are cross-indexed to enable the designer to navigate through the system\u0393\u00c7\u00d6s memory. AskJef helps software engineers in (1) understanding interface design problems by illustrating and explaining solutions to similar examples, and (2) comprehending the domain of interface design by illustrating and explaining the use of design guidelines. It uses text, graphics, animation and voice to present relevant information to the designer.", "num_citations": "64\n", "authors": ["57"]}
{"title": "Hgrid: A data model for large geospatial data sets in hbase\n", "abstract": " Cloud-based infrastructures enable applications to collect and analyze massive amounts of data. Whether these applications are newly developed or they are being evolved from existing RDBMS-based implementations, NoSQL databases offer an attractive platform with which to address this challenge. However, developers find it difficult to effectively manage data in NoSQL databases, because these platforms do not offer much support for data organization. Since poor data organization may abuse the features of the NoSQL database and result in unsatisfactory performance, developing a systematic method for NoSQL database data-schema design is a timely and important problem. In this paper, we focus on geospatial applications, as a family of big-data systems with distinct data types and usage patterns, in need of scalability. We propose the HGrid data model for HBase, based on a hybrid index structure\u252c\u00e1\u0393\u00c7\u00aa", "num_citations": "63\n", "authors": ["57"]}
{"title": "Latent Dirichlet allocation: extracting topics from software engineering data\n", "abstract": " Topic analysis is a powerful tool that extracts \u0393\u00c7\u00a3topics\u0393\u00c7\u00a5 from document collections. Unlike manual tagging, which is effort intensive and requires expertise in the documents\u0393\u00c7\u00d6 subject matter, topic analysis (in its simplest form) is an automated process. Relying on the assumption that each document in a collection refers to a small number of topics, it extracts bags of words attributable to these topics. These topics can be used to support document retrieval or to relate documents to each other through their associated topics. Given the variety and amount of textual information included in software repositories, in issue reports, in commit and source-code comments, and in other forms of documentation, this method has found many applications in the software-engineering field of mining software repositories.This chapter provides an overview of the theory underlying latent Dirichlet allocation (LDA), the most popular topic\u252c\u00e1\u0393\u00c7\u00aa", "num_citations": "62\n", "authors": ["57"]}
{"title": "A model-based approach to blame-assignment in design\n", "abstract": " We analyze the blame-assignment task in the context of experience-based design and redesign of physical devices. We identify three types of blame-assignment tasks that differ in the types of information they take as input: the design does not achieve a desired behavior of the device, the design results in an undesirable behavior, a specific structural element in the design misbehaves. We then describe a model-based approach for solving the blame-assignment task. This approach uses structure-behavior-function models that capture a designer\u0393\u00c7\u00d6s comprehension of the way a device works in terms of causal explanations of how its structure results in its behaviors. We also address the issue of indexing the models in memory. We discuss how the three types of blame-assignment tasks require different types of indices for accessing the models. Finally we describe the KRITIK2 system that implements and\u252c\u00e1\u0393\u00c7\u00aa", "num_citations": "62\n", "authors": ["57"]}
{"title": "The power of system call traces: predicting the software energy consumption impact of changes.\n", "abstract": " Battery is a critical resource for smartphones. Software developers as the builders and maintainers of applications, are responsible for updating and deploying energy efficient applications to end users. Unfortunately, the impact of software change on energy consumption is still unclear. Estimation based on software metrics has proved difficult. As energy consumption profiling requires special infrastructure, developers have difficulty assessing the impact of their actions on energy consumption. System calls are the interface between applications and the OS kernel and provide insight into how software utilizes hardware and software resources. As profiling system calls requires no specialized infrastructure, unlike energy consumption, it is much easier for the developers to track changes to system calls. Thus we relate software change to energy consumption by tracing the changes in an application\u0393\u00c7\u00d6s pattern of system call invocations. We find that significant changes to system call profiles often induce significant changes in energy consumption.", "num_citations": "60\n", "authors": ["57"]}
{"title": "Mining system-user interaction traces for use case models\n", "abstract": " While code understanding is the primary program comprehension activity, it is quite challenging to recognize the application requirements from code, since they have usually been occluded by a set of layers of later implementation decisions. An alternative source of evidence, especially valuable for understanding the purposes for which the application was built, can be the dynamic behavior of the system, and more specifically the system-user interaction. We have developed a method for modeling the application behavior from the user's perspective in the form of use case models, using recorded traces of system-user interaction. We use data mining and pattern matching methods to mine these traces for frequently occurring user tasks. When interesting patterns are discovered, they are augmented with semantic information and they are used to build use case models. We demonstrate a successful application of this\u252c\u00e1\u0393\u00c7\u00aa", "num_citations": "59\n", "authors": ["57"]}
{"title": "Towards reengineering web sites to web-services providers\n", "abstract": " The Web-services stack of standards is aimed at facilitating the development of Web applications by integrating software components, developed across organizational boundaries. This flexible integration relies on the specification of the components services in terms of an open, XML-based standard, WSDL. A critical step in the process of reusing existing, WSDL-specified components is the availability of a multitude of such components. Automated re-engineering methods for constructing Web services out of functionalities already offered by existing Web sites can therefore play an important role in facilitating the adoption of these standards. In this paper, we describe our work on reverse-engineering the interaction between Web-site servers and client browsers into XML specifications, syntactically and semantically close to WSDL.", "num_citations": "58\n", "authors": ["57"]}
{"title": "A contextual approach towards more accurate duplicate bug report detection and ranking\n", "abstract": " The issue-tracking systems used by software projects contain issues, bugs, or tickets written by a wide variety of bug reporters, with different levels of training and knowledge about the system under development. Typically, reporters lack the skills and/or time to search the issue-tracking system for similar issues already reported. As a result, many reports end up referring to the same issue, which effectively makes the bug-report triaging process time consuming and error prone. Many researchers have approached the bug-deduplication problem using off-the-shelf information-retrieval (IR) tools. In this work, we extend the state of the art by investigating how contextual information about software-quality attributes, software-architecture terms, and system-development topics can be exploited to improve bug deduplication. We demonstrate the effectiveness of our contextual bug-deduplication method at ranking\u252c\u00e1\u0393\u00c7\u00aa", "num_citations": "57\n", "authors": ["57"]}
{"title": "The smart-condo: Optimizing sensor placement for indoor localization\n", "abstract": " The Smart-Condo is a hardware/software platform that aims to support and assist an individual in performing a variety of everyday tasks within his/her living space. The key to achieving this goal is being able to recognize the individual's general activities in real-time, without impeding these activities or compromising privacy. Since location and movement constitute meaningful evidence for many everyday tasks (e.g., presence in the bathroom correlates with personal hygiene activities), we are motivated to develop an efficient, accurate, and noninvasive occupant-localization method. To this end, we propose a methodology for planning the deployment of an array of privacy-respecting binary motion sensors. In particular, given the geometric constraints of the deployment space, we generate a model of indoor mobility patterns typical for a single occupant. We then use this model as the basis for a specific optimization\u252c\u00e1\u0393\u00c7\u00aa", "num_citations": "57\n", "authors": ["57"]}
{"title": "Generic teleological mechanisms and their use in case adaptation\n", "abstract": " In experience-based (or case-based) reasoning, new problems are solved by retrieving and adapting the solutions to similar problems encountered in the past. An important issue in experience-based reasoning is to identify different types of knowledge and reasoning useful for different classes of caseadaptation tasks. In this paper, we examine a class of non-routine case-adaptation tasks that involve patterned insertions of new elements in old solutions. We describe a modelbased method for solving this task in the context of the design of physical devices. The method uses knowledge of generic teleological mechanisms (GTMs) such as cascading. Old designs are adapted to meet new functional specifications by accessing and instantiating the appropriate GTM. The Kritik2 system evaluates the computational feasibility and sufficiency of this method for design adaptation.", "num_citations": "57\n", "authors": ["57"]}
{"title": "Involvement, contribution and influence in GitHub and stack overflow.\n", "abstract": " Software developers are increasingly adopting social-media platforms to contribute to software development, learn and develop a reputation for themselves. GitHub supports version-controlled code sharing and social-networking functionalities and Stack Overflow is a social forum for question answering on programming topics. Motivated by the features\u0393\u00c7\u00d6 overlap of the two networks, we set out to mine and analyze and correlate the members\u0393\u00c7\u00d6 core contributions, editorial activities and influence in the two networks. We aim to better understand the similarities and differences of the members\u0393\u00c7\u00d6 contributions in the two platforms and their evolution over time. In this context, while studying the activities of different user groups, we conducted a three-step investigation of GitHub activity, Stack Overflow activity and inter-network activity over a five-year period. We report our findings on interesting membership and activity patterns within each platform and some relations between the two.", "num_citations": "56\n", "authors": ["57"]}
{"title": "Improved A1C levels in type 1 diabetes with smartphone app use\n", "abstract": " ObjectivesSmartphones are a potentially useful tool in diabetes care. We have developed an application (app) linked to a website, Intelligent Diabetes Management (IDM), which serves as both an insulin bolus calculator and an electronic diabetes diary. We have prospectively studied whether patients using this app improved control of their glucose levels.MethodsPatients with type 1 diabetes were recruited. There was a 4-week observation period, midway during which we offered to review the participants' records. The app was then downloaded and participants' diabetes regimens entered on the synchronized IDM website. At 2, 4, 8, 12 and 16 weeks of the active phase, their records were reviewed online, and feedback was provided electronically. The primary endpoint was change in levels of glycated hemoglobin (A1C).ResultsOf the 31 patients recruited, 18 completed the study. These 18 made 572\u252c\u259298 entries\u252c\u00e1\u0393\u00c7\u00aa", "num_citations": "55\n", "authors": ["57"]}
{"title": "Assessing the maintainability benefits of design restructuring using dependency analysis\n", "abstract": " Software developers and project managers often have to assess the quality of software design. A commonly adopted hypothesis is that a good design should cost less to maintain than a poor design. We propose a model for quantifying the quality of a design from a maintainability perspective. Based on this model, we propose a novel strategy for predicting the \"return on investment\" (ROI) for possible design restructurings using procedure level dependency analysis. We demonstrate this approach with two exploratory Java case studies. Our results show that common low level source code transformations change the system dependency structure in a beneficial way, allowing recovery of the initial refactoring investment over a number of maintenance activities.", "num_citations": "55\n", "authors": ["57"]}
{"title": "Modeling the system-user dialog using interaction traces\n", "abstract": " It is generally the case that some user interface (UI) reverse engineering is needed for every non-trivial reengineering project. Typically, this is done through code analysis, which can be very difficult and/or expensive. When code analysis is not a must, as for wrapping purposes, system-user interaction can be an alternative input for the reverse engineering process. In the CelLEST project, we have developed a prototype, called LeNDI (Legacy Navigation Domain Identifier), to test this idea. LeNDI records traces of the legacy screen snapshots and user actions, while the user interacts with the legacy system. Then, it extracts a set of features for every snapshot and employs artificial intelligence methods to build a model of the legacy UI, called the state-transition graph. LeNDI uses two clustering methods to group similar snapshots together as one system screen modeled by one node on the graph. LeNDI uses the user\u252c\u00e1\u0393\u00c7\u00aa", "num_citations": "53\n", "authors": ["57"]}
{"title": "Metrics of refactoring-based development: An experience report\n", "abstract": " Following a refactorings-based software life-cycle, the nature of the requirements specification and design activities changes drastically. Instead of aiming at identifying the complete set of long-term requirements for the system and designing it in a way that all such foreseen requirements may be accomplished, the system is developed in small increments. To address the system design shortcomings in terms of extensibility, the system is regularly refactored. In this paper, we discuss our experiences with a system, that followed a refactorings-based development and reflect on the trends we have noticed in this project.", "num_citations": "53\n", "authors": ["57"]}
{"title": "Healthcare education with virtual-world simulations\n", "abstract": " Becoming a skilled professional requires the acquisition of theoretical knowledge and the practice of skills under the guidance of an expert. The idea of learning-through-apprenticeship is long accepted in medicine and, more generally, in the health sciences, where practicum courses are an essential part of most curricula. Because of the high cost of apprenticeship programs--mentors can usually supervise few trainees and trainees may need long apprenticeship periods-simulation has long been adopted as a learning-by-doing training method that can supplement apprenticeship in many professional and engineering programs, including the health sciences. In this paper, we describe our experience developing virtual world-based training systems for two healthcare contexts. In one, procedural training was emphasized, while the other focused on teaching communication skills. In each case, we developed a\u252c\u00e1\u0393\u00c7\u00aa", "num_citations": "50\n", "authors": ["57"]}
{"title": "Teaching distributed software engineering with UCOSP: the undergraduate capstone open-source project\n", "abstract": " Software engineering courses in computer-science departments are meant to prepare students for the practice of designing, developing, understanding and maintaining software in the real world. The effectiveness of these courses have potentially a tremendous impact on the software industry, since it is through these courses that students must learn the state-of-the-art process and the tools of their eventual\" trade\", so that they can bring this knowledge to their job and thus advance the actual state of practice. The value of\" learning software engineering\" through project-based courses has long been recognized by educators and practitioners alike. In this paper, we discuss our experience with a distributed project-based course, which infuses the students' learning experience with an increased degree of realism, which, we believe, further improves the quality of their learning and advances their readiness to join the\u252c\u00e1\u0393\u00c7\u00aa", "num_citations": "45\n", "authors": ["57"]}
{"title": "Valuating software service development: integrating COCOMO II and real options theory\n", "abstract": " Our work examines the problem of estimating the potential business value of evolving service-oriented applications, based on the value of the new services this evolution is anticipated to enable and the estimated cost of the development effort. We have adopted COCOMO II as the software-development cost model, as it is designed to account for evolutionary software development. However, it is clear that the model will have to be extended in order to represent the particular idiosyncrasies of this new development style. As it is, it can estimate the cost of adapting source code; however, SOA development also involves developing and adapting declarative composition specifications, which may be a fundamentally different process. Specifically, research into the cost of creating a Web service composition is required. We have also adopted real-option theory for modeling the business services that can be delivered\u252c\u00e1\u0393\u00c7\u00aa", "num_citations": "43\n", "authors": ["57"]}
{"title": "A three-dimensional data model in hbase for large time-series dataset analysis\n", "abstract": " In the transition of applications from the traditional enterprise infrastructures to cloud infrastructures, scalable database management system plays an important role in efficiently managing and analysing unprecedented massive amount of data. Compared to RDBMSs, NoSQL databases, are more attractive in addressing this challenge. However, it is not easy to manage data in NoSQL database effectively for non-expert users because of the rare data-organization support. A poor data organization may accidentally abuse the features of NoSQL database and achieve unsatisfactory performance. Therefore, a systematic method for NoSQL database data-schema design is a timely and important problem for researchers and practitioners. HBase, as a particular NoSQL database offering, relies (a) on HDFS, for its distributed and replicated storage, and (b) on coprocessors, for efficient parallel query processing. To\u252c\u00e1\u0393\u00c7\u00aa", "num_citations": "42\n", "authors": ["57"]}
{"title": "Code convention adherence in evolving software\n", "abstract": " Maintainability is a desired property of software, and a variety of metrics have been proposed for measuring it, focusing on different notions of complexity and code readability. Many practices have been proposed to improve maintainability through code refactorings: improving the cohesion, simplification of interfaces, renamings to improve understandability. Code conventions are a body of advice on lexical and syntactic aspects of code, aiming to standardize low-level code design under the assumption that such a systematic approach will make code easier to read, understand, and maintain. We present the first stage in our examination of code-convention adherence practices as a proxy measurement for maintainability. Based on a preliminary survey of software engineers, we identify a set of coding conventions that most relate to maintainability. Then we devise a \u0393\u00c7\u00a3convention adherence\u0393\u00c7\u00a5 metric, based on the\u252c\u00e1\u0393\u00c7\u00aa", "num_citations": "42\n", "authors": ["57"]}
{"title": "Software engineering for health education and care delivery systems: The Smart Condo project\n", "abstract": " Providing affordable, high-quality healthcare to the elderly while enabling them to live independently longer is of critical importance, as this is an increasing and expensive demographic to treat. Sensor-network technologies are essential to developing assisted living environments. In our Smart Condo project, we have deployed a sensor network with a variety of sensor types in an 850 square-foot condominium. The sensor network records a variety of events and environmental parameters and feeds the related data into our Web-based system. This system is responsible for inferring higher-order information about the activities of the condo's occupant and supporting the visualization of the collected information in a 2D Geographic Information System (GIS) and a 3D virtual world, namely Second Life (SL).", "num_citations": "42\n", "authors": ["57"]}
{"title": "The Smart Condo: Visualizing independent living environments in a virtual world\n", "abstract": " Providing affordable, high-quality healthcare to the elderly while enabling them to live independently longer is of critical importance. In our Smart Condo project, we have deployed a wireless sensor network in an 850-square-foot condominium for assisted living. The sensor network records a variety of events and environmental parameters and feeds the related data into our web-based system. This system is responsible for inferring higher-order information about the activities of the condo's occupant and visualizing the collected information in both a 2D Geographic Information System (GIS) and a 3D virtual world. The architecture is flexible in terms of supported sensor types, analyses, and visualizations through which it communicates this information to its users, including the condo's occupant, their family, and their healthcare providers.", "num_citations": "42\n", "authors": ["57"]}
{"title": "Data-mining in Support of Detecting Class Co-evolution.\n", "abstract": " In an evolving system maintained over a long time period, there exist many non-trivial relationships among system classes, such as class co-evolutions, which usually are not easily perceivable in the source code. However, unfortunately, the continuing evolution of large, long-lived systems leads to lost information about these hidden relationships. In this paper, we propose a method for recovering such lost knowledge by data mining method. This method relies on the UMLDiff algorithm that, given a sequence of UML class models of a system, surfaces the design-level changes over its life span, thus eliminating the need for high quality modification reports and nonintuitive software code-based metrics. We employ Apriori association rule mining algorithm to the transactional database of class modifications, which elicit previously unknown or undocumented co-evolving relations among two or more classes. The recovered knowledge facilitates the overall understanding of system evolution and the planning of future maintaining activities. We report on one real world case study evaluating our approach.", "num_citations": "42\n", "authors": ["57"]}
{"title": "An intelligent-agent architecture for flexible service integration on the web\n", "abstract": " A plethora of information and services is available on the World Wide Web; the challenge has now become to enable the interoperation of these services in the context of high-quality, integrated applications, providing personalized value-added services to the end user. TaMeX is a software framework that supports the development of intelligent multiagent applications, integrating services of existing web applications. The TaMeX applications rely on a set of specifications of the domain model, the integration workflow, their semantic constraints, the end-user profiles, and the services of the existing web applications; all these models are declaratively represented in the XML-based TaMeX integration-specification language. At run-time, the TaMeX agents use these models to flexibly interact with the end users, monitor and control the execution of the underlying applications' services and coordinate the information\u252c\u00e1\u0393\u00c7\u00aa", "num_citations": "42\n", "authors": ["57"]}
{"title": "Greenadvisor: A tool for analyzing the impact of software evolution on energy consumption\n", "abstract": " Change-impact analysis, namely \u0393\u00c7\u00a3identifying the potential consequences of a change\u0393\u00c7\u00a5 is an important and well studied problem in software evolution. Any change may potentially affect an application's behaviour, performance, and energy consumption profile. Our previous work demonstrated that changes to the system-call profile of an application correlated with changes to the application's energy-consumption profile. This paper evaluates and describes GreenAdvisor, a first of its kind tool that systematically records and analyzes an application's system calls to predict whether the energy-consumption profile of an application has changed. The GreenAdvisor tool was distributed to numerous software teams, whose members were surveyed about their experience using GreenAdvisor while developing Android applications to examine the energy-consumption impact of selected commits from the teams' projects\u252c\u00e1\u0393\u00c7\u00aa", "num_citations": "40\n", "authors": ["57"]}
{"title": "Measuring user influence in GitHub: the million follower fallacy\n", "abstract": " Influence in social networks has been extensively studied for collaborative-filtering recommendations and marketing purposes. We are interested in the notion of influence in Software Social Networks (SSNs); more specifically, we want to answer the following questions: 1) What does \u0393\u00c7\u00a3influence\u0393\u00c7\u00a5 mean in SSNs? Given the variety of types of interactions supported in these networks and the abundance of centrality-type metrics, what is the nature of the influence captured by these matrics? 2) Are there silos of influence in these platforms or does influence span across thematic boundaries? To investigate these two questions, we first conducted an in-depth comparison of three influence metrics, number of followers, number of forked projects, and number of projectwatchers in GitHub1 (the largest code-sharing and version control system). Next, we examined how the influence of the most influential software-engineering\u252c\u00e1\u0393\u00c7\u00aa", "num_citations": "38\n", "authors": ["57"]}
{"title": "Constructing XML-speaking wrappers for WEB Applications: Towards an Interoperating WEB\n", "abstract": " We discuss an architecture for integrating WWW applications that offer information and services in the same domain. At the center of this architecture exists a mediator, whose responsibilities are to interact with the user and to effectively exchange information with the underlying applications in order to accomplish the user's task. The integration and interoperation of the existing applications are based on the availability of a common domain model, explicitly represented in XML. More specifically we have developed a general method for constructing wrappers for Web-based applications, so that they exchange data with shared semantics such as defined in the XML domain model. At run-time, the user's requests result in the mediator's XML queries to the application wrappers, which, in turn, invoke appropriate methods on the wrapped applications and extract XML data from their responses to these queries.", "num_citations": "38\n", "authors": ["57"]}
{"title": "Understanding web usage for dynamic web-site adaptation: A case study\n", "abstract": " Every day, new information, products and services are being offered by providers on the World Wide Web. At the same time, the number of consumers and the diversity of their interests is increasing. As a result, providers are seeking ways to infer customers' interests and to adapt their Web sites to make the content of interest more easily accessible. Pattern mining is a promising approach in support of this goal. Assuming that past navigation behavior is an indicator of users' interests, then records of this behavior, kept in the form of Web-server logs, can be mined to infer what users are interested in. On that basis, recommendations can be dynamically generated, to help new Web-site visitors find information of interest faster. In this paper, we discuss our experience with pattern mining for dynamic Web-site adaptation. Our particular approach is tailored to \"focused\" Web sites that offer information on a well-defined\u252c\u00e1\u0393\u00c7\u00aa", "num_citations": "37\n", "authors": ["57"]}
{"title": "Business models in emerging online services\n", "abstract": " Due to advances in technology and the rapid growth of online services, a significant number of new and inventive web-based service models and delivery methods have been introduced. Although online resources and services are having an impact on more traditional service delivery mechanisms, it is not yet clear how these emerging mechanisms for online service delivery will result in profitable business models. In this paper, we consider emerging business models for online services and their implications for how services are delivered, used, and paid for.We demonstrate the changing roles of user / consumer and provider / seller. We also discuss the applicability of different business models for various domains.", "num_citations": "36\n", "authors": ["57"]}
{"title": "An integrated framework for simulation-based training on video and in a virtual world\n", "abstract": " Becoming a skilled professional requires both the acquisition of theoretical knowledge and the practice of skills relevant to one", "num_citations": "35\n", "authors": ["57"]}
{"title": "Understanding phases and styles of object-oriented systems' evolution\n", "abstract": " Understanding the phases and styles of evolution of software systems can provide valuable insight in support of project management. We present a method for studying the evolution of object-oriented software at system/subsystem level and analyzing the underlying factors that drive its unfolding over time. This method relies on analyzing the design-level structural changes between two subsequent software versions to identify additions, removals, moves, renamings and signature-changes of classes, interfaces, and their methods and fields, represented as change trees. A sequence of such change trees constitutes the system's evolution profile. Based on discrete system evolution profiles, three types of analyses: phasic analysis, gamma analysis, and optimal matching analysis, are applied, to abstract an overall sequential pattern and structural properties of system evolution phases and to develop the typology of\u252c\u00e1\u0393\u00c7\u00aa", "num_citations": "35\n", "authors": ["57"]}
{"title": "Failure-driven learning as model-based self-redesign\n", "abstract": " Learning is a competence fundamental to intelligence. Intelligent agents who solve problems in a realistic environment need to learn in order to improve their performance in terms of the quality of the solutions they produce, the efficiency of their problem-solving process, and the class of problems they can solve.", "num_citations": "32\n", "authors": ["57"]}
{"title": "Analysis of Web\u0393\u00c7\u00c9usage behavior for focused Web sites: a case study\n", "abstract": " The number of Web users and the diversity of their interests increase continuously; Web\u0393\u00c7\u00c9content providers seek to infer these interests and to adapt their Web sites to improve accessibility of the offered content. Usage\u0393\u00c7\u00c9pattern mining is a promising approach in support of this goal. Assuming that past navigation behavior is an indicator of the users' interests, then, Web\u0393\u00c7\u00c9server logs can be mined to infer what the users are interested in. On that basis, the Web site may be reorganized to make the interesting content more easily accessible or recommendations can be dynamically generated to help new visitors find information of interest faster. In this paper, we discuss a case study examining the effectiveness of sequential\u0393\u00c7\u00c9pattern mining for understanding the users' navigation behavior in focused Web sites. This study examines the Web site of an undergraduate course, as an example of a focused Web site that offers\u252c\u00e1\u0393\u00c7\u00aa", "num_citations": "31\n", "authors": ["57"]}
{"title": "MULTIPLE PLATFORMS\n", "abstract": " With the proliferation of different computing devices and platforms, it is becoming increasingly important for organizations to migrate their existing software systems to new environments, possibly more than one, with minimum effort and risk. In this paper, we introduce Mathaino, a platform independent, non-invasive tool that can be used to migrate, in a semi-automated manner, text-based legacy interfaces to modern web-centric target platforms, by constructing wrappers as front-ends around the original legacy-system user interface.", "num_citations": "31\n", "authors": ["57"]}
{"title": "A model-based approach to blame assignment: Revising the reasoning steps of problem solvers\n", "abstract": " Blame assignment is a classical problem in learning and adaptation. Given a problem solver that fails to deliver the behaviors desired of it, the blame-assignment task has the goal of identifying the cause (s) of the failure. Broadly categorized, these causes can be knowledge faults (errors in the organization, content, and representation of the problemsolver's domain knowledge) or processing faults (errors in the content, and control of the problem-solving process). Much of AI research on blame assignment has focused on identifying knowledge and control\u0393\u00c7\u00f4of\u0393\u00c7\u00f4processing faults based on the trace of the failed problem-solving episode. In this paper, we describe a blame-assignment method for identifying content\u0393\u00c7\u00f4of\u0393\u00c7\u00f4processing faults, ie, faults in the specification of the problem-solving operators. This method uses a structure\u0393\u00c7\u00f4behavior\u0393\u00c7\u00f4function (SBF) model of the problemsolving process, which captures the functional semantics of the overall task and the operators of the problem solver, the compositional semantics of its problem-solving methods that combine the operators' inferences into the outputs of the overall task, and the \u0393\u00c7\u00a3causal\u0393\u00c7\u00a5 inter-dependencies between its tasks, methods and domain knowledge. We illustrate this model-based blame-assignment method with examples from AUTOGNOSTIC.", "num_citations": "31\n", "authors": ["57"]}
{"title": "Understanding the economics of refactoring\n", "abstract": " In this paper we discuss a novel method for estimating the expected maintenance savings given a refactoring plan. This work is motivated by the increased adoption of refactoring practices as part of new agile methodologies and the lack of any prescriptive theory on when to refactor.", "num_citations": "30\n", "authors": ["57"]}
{"title": "WSDarwin: Studying the Evolution of Web Service Systems\n", "abstract": " The service-oriented architecture paradigm prescribes the development of systems through the composition of services, i.e., network-accessible components, specified by (and invoked through) their interface descriptions. Systems thus developed need to be aware of changes in, and evolve with, their constituent services. Therefore, the accurate recognition of changes in the specification of a service is an essential functionality in supporting the software lifecycle of service-oriented systems. In this chapter, we extend our previous empirical study on the evolution of web-service interfaces and we classify the identified changes according to their impact on client applications. To better understand the evolution of web services, and, more importantly, to facilitate the systematic and automatic maintenance of web-service systems, we introduce WSDarwin, a specialized differencing method for web services. Finally\u252c\u00e1\u0393\u00c7\u00aa", "num_citations": "28\n", "authors": ["57"]}
{"title": "The JDEvAn tool suite in support of object-oriented evolutionary development\n", "abstract": " Object-oriented software is increasingly developed using evolutionary development processes. Systems, in addition to being incrementally (re) designed to fulfill their evolving requirements, have their design continuously improved through behaviorpreserving restructurings, as refactoring has become one of the most important core practices in object-oriented development. As a result, at any point in time, the system design is the product of a sequence of design-evolution decisions, a fact that should be taken into account in subsequent development and maintenance tasks. For example, when building applications that reuse evolving component frameworks, the client-application developers have to understand the nature of component\u0393\u00c7\u00d6s breaking API changes, their plausible replacements and how to use them. In this paper, we present our JDEvAn (Java Design Evolution Analysis) tool suite [2], which consists of\u252c\u00e1\u0393\u00c7\u00aa", "num_citations": "28\n", "authors": ["57"]}
{"title": "Digging the development dust for refactorings\n", "abstract": " Software repositories are rich sources of information about the software development process. Mining the information stored in them has been shown to provide interesting insights into the history of the software development and evolution. Several different types of information have been extracted and analyzed from different points of view. However, these types of information have not been sufficiently cross-examined to understand how they might complement each other. In this paper, we present a systematic analysis of four aspects of the software repository of an open source project - source-code metrics, identifiers, return-on-investment estimates, and design differencing - to collect evidence about refactorings that may have happened during the project development. In the context of this case study, we comparatively examine how informative each piece of information is towards understanding the refactoring\u252c\u00e1\u0393\u00c7\u00aa", "num_citations": "28\n", "authors": ["57"]}
{"title": "Evaluating PSMs in evolutionary design: the A UTOGNOSTIC experiments\n", "abstract": " The specification of generic Problem-Solving Methods has been a fertile research area. A lot of work has been devoted to developing languages for describing PSMs, identifying PSMs, and using their specifications for requirements capture, design and development of knowledge based systems. In our work, we have been investigating another potential use for PSMs, namely, supporting the redesign of systems that fail to exhibit the behaviours desired of them, that is, behaviours similar to, but slightly different from, the ones they were originally designed to exhibit. To this end, we have defined a PSM modeling language and a failure-driven redesign process based on this language, both of which were implemented in the A UTOGNOSTIC system. In this paper, we report on a sequence of experiments performed with A UTOGNOSTIC. Some of them were exploratory and their goal was to enable the precise\u252c\u00e1\u0393\u00c7\u00aa", "num_citations": "28\n", "authors": ["57"]}
{"title": "Office waste cleanup: an application for service robots\n", "abstract": " Waste cleanup is a task which occurs in a great variety of domains and contexts. In spite of the variety of the causes and the types of waste, cleaning it up typically involves dirty, dull, strenuous and sometimes hazardous actions. Thus waste cleanup constitutes a natural task for service robots. In this paper, we describe an office robot, DAVID, who in addition to collecting and delivering mail and stationary, cleans up offices from garbage. We describe, the system's flexible functional architecture and its various components. We identify some functionalities critical in waste-cleanup tasks and describe how they are accomplished in DAVID. The paper closes with the discussion of an experiment which demonstrates the performance of the system, and with a set of conclusions we drew from this work.", "num_citations": "28\n", "authors": ["57"]}
{"title": "Redesigning a problem-solver's operators to improve solution quality\n", "abstract": " The inability of a problem solver to produce solutions of a desired quality often may lie in the incorrect design of its operators. In this paper, we describe a method which, given a problem solver that produces a poor solution for a given problem, and given the desired solution for it, uses a model of the problem-solver's processing and knowledge to identify faults in the specification of its operators and to appropriately redesign them. This method is based on the structure-behavior-function (SBF) model of problem solving that explicitly captures the functional semantics of the problem-solver's tasks, the compositional semantics of its problemsolving methods that combine the operators' inferences into the outputs of the overall task, its domain knowledge, and the\" causal\" interdependencies between its tasks, methods and domain knowledge. We illustrate and evaluate this learning method through AUTOGNOSTIC. ti on of\u252c\u00e1\u0393\u00c7\u00aa", "num_citations": "27\n", "authors": ["57"]}
{"title": "Rapid deployment and evaluation of mobile serious games: A cognitive assessment case study\n", "abstract": " Serious games are proposed as a more efficient and enjoyable way to carry out cognitive assessment. We compare prediction of cognitive ability with a purpose-built serious game and with a similar game built using a game engine. In an experiment conducted with 28 participants, performance on the two games is assessed relative to three cognitive abilities, using two different tablet sizes and two different input methods. The results for the game-engine variant were similar to the purpose-built game, where both games significantly predicted performance on the three cognitive abilities, and were sensitive to the effects of age. Performance on both games was not significantly affected by tablet size or input method. These results support earlier findings that serious games can provide valid cognitive assessment, and they show that game engines can be used to develop serious games for cognitive assessment, cost\u252c\u00e1\u0393\u00c7\u00aa", "num_citations": "26\n", "authors": ["57"]}
{"title": "Analyzing the effects of test driven development in GitHub\n", "abstract": " Testing is an integral part of the software development lifecycle, approached with varying degrees of rigor by different process models. Agile process models recommend Test Driven Development (TDD) as a key practice for reducing costs and improving code quality. The objective of this work is to perform a cost-benefit analysis of this practice. To that end, we have conducted a comparative analysis of GitHub repositories that adopts TDD to a lesser or greater extent, in order to determine how TDD affects software development productivity and software quality. We classified GitHub repositories archived in 2015 in terms of how rigorously they practiced TDD, thus creating a TDD spectrum. We then matched and compared various subsets of these repositories on this TDD spectrum with control sets of equal size. The control sets were samples from all GitHub repositories that matched certain characteristics, and\u252c\u00e1\u0393\u00c7\u00aa", "num_citations": "25\n", "authors": ["57"]}
{"title": "Do the stars align? Multidimensional analysis of Android's layered architecture\n", "abstract": " In this paper we mine the Android bug tracker repository and study the characteristics of the architectural layers of the Android system. We have identified the locality of the Android bugs in the architectural layers of the its infrastructure, and analysed the bug lifetime patterns in each one of them. Additionally, we mined the bug tracker reporters and classified them according to its social centrality in the Android bug tracker community. We report three interesting findings, firstly while some architectural layers have a diverse interaction of people, attracting not only non-central reporters but highly important ones, other layers are mostly captivating for peripheral actors. Second, we exposed that even the bug lifetime is similar across the architectural layers, some of them have higher bug density and differential percentages of unsolved bugs. Finally, comparing the popularity distribution between layers, we have identified\u252c\u00e1\u0393\u00c7\u00aa", "num_citations": "25\n", "authors": ["57"]}
{"title": "Enhancing query support in hbase via an extended coprocessors framework\n", "abstract": " Currently, cloud databases serve as mainstream data storage mechanism for unstructured data, primarily because of their high scalability and ease of availability. However, as yet, they lag behind RDBMs in terms of their support to developers for querying the data. The problem of developing frameworks to support flexible data queries is a very active area of research. In this work we consider HBase, a popular cloud database, inspired by Google\u0393\u00c7\u00d6s BigTable. Relying on the recent Coprocessor feature of HBase, we have developed a framework that developers can use to implement aggregate functions like row count, max, min, etc. We further extended the existing Coprocessor framework to support a Cursor functionality, so that a client can incrementally consume the Coprocessor generated result. We demonstrate the effectiveness of our extension by comparatively evaluating it against the existing Scanner\u252c\u00e1\u0393\u00c7\u00aa", "num_citations": "25\n", "authors": ["57"]}
{"title": "Supporting adaptive web-service orchestration with an agent conversation framework\n", "abstract": " Service-oriented architecture is emerging as a compelling paradigm for developing Web-based software applications. In this style, the functional components of the system are implemented in various programming languages as network-accessible \"services\" declaratively specified (in WSDL) and declaratively composed in workflows (using BPEL4WS). Despite this fundamentally distributed conceptualization of service composition, most current middleware assumes that the specification of the service composition is interpreted at run time by a central middleware node. This implies inflexible composition evolution: all parties must be updated concurrently to avoid interaction failures. This paper introduces an intelligent-agent framework that wraps Web services in a conversation layer and is capable of a simple workflow-adaptation function. The conversation layer implements protocols and consults globally shared\u252c\u00e1\u0393\u00c7\u00aa", "num_citations": "25\n", "authors": ["57"]}
{"title": "Chaintracker, a model-transformation trace analysis tool for code-generation environments\n", "abstract": " Model-driven engineering is advocated as an effective method for developing families of software systems that systematically differ across well defined dimensions. Yet, this software construction paradigm is rather brittle at the face of evolution. Particularly, when building code-generation environments, platform evolution scenarios force developers to modify the generated code of individual generation instances in an ad-hoc manner. Thus violating the systematicity of the original construction process. In order to maintain the code-generation environment synchronized, code refinements have to be traced and backwardly propagated to generation infrastructure, so as to make these changes systematically possible for all systems that can be generated. This paper presents ChainTracker, a general conceptual framework, and model-transformation composition analysis tool, that supports developers when\u252c\u00e1\u0393\u00c7\u00aa", "num_citations": "24\n", "authors": ["57"]}
{"title": "far-play: A framework to develop augmented/alternate reality games\n", "abstract": " Augmented/Alternate Reality Games are a relatively new, yet increasingly interesting, class of social applications. These games are fundamentally intertwined with the players' real life, in that the players' everyday activities generate events that advance the game logic. At the same time, they augment the players' \u0393\u00c7\u00a3regular\u0393\u00c7\u00a5 activities with game-related tasks and challenges and with rich digital content that is communicated to the players through a variety of devices, usually augmenting their mobile-device views. In our work, we have been developing a software framework, fAR-Play, to support the development of educational AARG games, in the treasure-hunt style, using space as the context for communicating information. Our toolkit extends the stereotypical notion of AARGs to include a virtual world in which the players can also interact and play. Our toolkit has been evaluated through (and has evolved based on our\u252c\u00e1\u0393\u00c7\u00aa", "num_citations": "24\n", "authors": ["57"]}
{"title": "Understanding the evolution and co-evolution of classes in object-oriented systems\n", "abstract": " As software systems evolve over a long time, non-trivial and often unintended relationships among system classes arise, which cannot be easily perceived through source-code reading. As a result, the developers' understanding of continuously evolving, large, long-lived systems deteriorates steadily. A most interesting relationship is class co-evolution: because of implicit design dependencies clusters of classes change in \"parallel\" ways and recognizing such co-evolution is crucial in effectively extending and maintaining the system. In this paper, we propose a data-mining method for recovering \"hidden\" co-evolutions of system classes. This method relies on our UML-aware structural differencing algorithm, UMLDiff, which, given a sequence of UML class models of an object-oriented software system, produces a sequence of \"change records\" that describe the design-level changes over its life span. The change\u252c\u00e1\u0393\u00c7\u00aa", "num_citations": "24\n", "authors": ["57"]}
{"title": "Simulating service-oriented systems: A survey and the services-aware simulation framework\n", "abstract": " The service-oriented architecture style supports desirable qualities, including distributed, loosely coupled systems spanning organizational boundaries. Such systems and their configurations are challenging to understand, reason about, and test. Improved understanding of these systems will support activities such as autonomic runtime configuration, application deployment, and development/testing. Simulation is one way to understand and test service systems. This paper describes a literature survey of simulation frameworks for service-oriented systems, examining simulation software, systems, approaches, and frameworks used to simulate service-oriented systems. We identify a set of dimensions for describing the various approaches, considering their modeling methodology, their functionalities, their underlying infrastructure, and their evaluation. We then introduce the services-aware simulation framework\u252c\u00e1\u0393\u00c7\u00aa", "num_citations": "23\n", "authors": ["57"]}
{"title": "A tale of two pricing systems for services\n", "abstract": " Due to advances in technology and the rapid growth of online service offerings, various innovative web-based service models and delivery methods have appeared\u0393\u00c7\u00f6including several free services. It is not always clear whether and how these emerging mechanisms for online service delivery will result in profitable businesses. In this paper, with an eye towards beginning to understand the issues involved, we present an analytical model of rational customer choice between available service plans. In particular, our model predicts how a monopoly service provider should devise its plans, if it understands such customer behavior. We then describe how this model would need to be extended in order to reflect increasingly inexpensive and even free service offerings.", "num_citations": "23\n", "authors": ["57"]}
{"title": "Examining usage protocols for service discovery\n", "abstract": " To date, research on web-service discovery has followed the tradition of signature matching based on the interface description captured in WSDL. WSDL specifications, however, can be information poor, with basic data types, and unintuitive identifiers for data, messages and operations. The nature of the usage of the WSDL component in the context of a BPEL composition can be an extremely useful source of information in the context of service discovery. In this paper, we discuss our method for service discovery based on both interface and usage matching, exploiting the information captured in the WSDL and BPEL specifications. Our approach views both WSDL and BPEL as hierarchical structures and uses tree alignment to compare them. We illustrate our method with an example scenario.", "num_citations": "23\n", "authors": ["57"]}
{"title": "Taking the community's pulse: one blog at a time\n", "abstract": " The blogging phenomenon has caught the on-line world by surprise; the number of blogs doubles regularly and the number of daily blog entries seems to also continuously increase. Even more interestingly, blogs seem to compete with authoritative media outlets as a means for delivering news and opinions. The perceived power of blogs to inform and form, public opinion has given rise to several blog-mining services analyzing the blog entries to infer the reputation of their customers. In this paper, we discuss our work on visualizing and systematically analyzing several blogs in the same domain of interest (movies) in order to assess to what extent the buzz of blogs correlates with public opinion.", "num_citations": "23\n", "authors": ["57"]}
{"title": "Reflections of the extended self: Visual self-representation in avatar-mediated environments\n", "abstract": " We examine the relationship between avatars in virtual environments and the people they represent. We find that people (balancing the motives of self-verification and self-enhancement) design their avatars to be similar to their real selves, but with some enhancements that are more attractive. In particular, users most enhance on physical attributes that they perceive to be weak in real life. We also find that avatar attractiveness affects online behavioral traits such as extroversion and loudness. Lastly, we find support for a hierarchy of physical variation across online roles whereby people retain core identity elements (such as gender and race) across all their avatars, but they change peripheral elements (such as hair and clothing, and even face). We conclude by discussing implications of our findings for business and society.", "num_citations": "22\n", "authors": ["57"]}
{"title": "Linked REST APIs: a middleware for semantic REST API integration\n", "abstract": " Over the last decade, an exponentially increasing number of REST services have been providing a simple and straightforward syntax for accessing rich data resources. To use these services, however, developers have to understand \"information-use contracts\" specified in natural language, and, to build applications that benefit from multiple existing services they have to map the underlying resource schemas in their code. This process is difficult and error-prone, especially as the number and overlap of the underlying services increases, and the mappings become opaque, difficult to maintain, and practically impossible to reuse. The more recent advent of the Linked Data formalisms can offer a solution to the challenge. In this paper, we propose a conceptual framework for REST-service integration based on Linked Data models. In this framework, the data exposed by REST services is mapped to Linked Data\u252c\u00e1\u0393\u00c7\u00aa", "num_citations": "22\n", "authors": ["57"]}
{"title": "Location-based services on a smart campus: A system and a study\n", "abstract": " Knowledge about people's geographical location can be used to infer their possible needs, and to offer relevant services to satisfy these needs. Such targeted approach in service demand identification and service delivery is one of the reasons why Location-Based Services (LBS) are so popular in our days. In this paper, we describe a framework that we developed for offering location-based services, relying on infrastructure typically available in smart campus environments. Our framework includes three user-facing components: 1) an energy-aware Android application for end users to recognize their locations and access the services available to them; 2) a web application, which enables end users to search for services available on the campus as a whole; and 3) a web application for managers to specify what services are available on campus and in which areas. Each of these applications communicates with a\u252c\u00e1\u0393\u00c7\u00aa", "num_citations": "22\n", "authors": ["57"]}
{"title": "Swing2script: Migration of java-swing applications to ajax web applications\n", "abstract": " Platform migration is a core problem in software reengineering, since applications are frequently deemed useful in environments other than the ones in which they were originally implemented. The World-Wide-Web in particular is becoming a target platform of choice because of its pervasiveness, and a substantial class of applications that could benefit from migration to the Web is that of Java graphical user interface (GUI) desktop applications. To that end, we have recently developed Swing2Script, an interaction-reengineering approach for automatically migrating Java-Swing applications to Ajax-enabled Web- based applications. The approach reverse engineers the structure and behavior of Java Swing GUIs, using aspects woven unobtrusively in the original application. Based on the extracted model, it automatically builds an Ajax-enabled front end, which drives the relevant workflows of the original application\u252c\u00e1\u0393\u00c7\u00aa", "num_citations": "22\n", "authors": ["57"]}
{"title": "Legacy Interface Migration: A Task-Centered Approach.\n", "abstract": " Legacy systems constitute repositories of valuable corporate knowledge collected over a long time. However their unintuitive text-based interfaces make them difficult to learn and to use, and as a result the problem of migrating legacy interfaces to GUIs has emerged as one among the most interesting and challenging ones in the software industry (Moore 1996). The approach that we have been investigating in the CelLEST project to the problem of legacy interface migration involves understanding how the system is currently being used, that is how its users interact with it. In this approach, the interaction between the user and the system is recorded, while the user accomplishes her task. Then the recorded interaction trace is abstracted to a specification of the information exchanged between the system and the user. Finally, this specification gives rise to a specific task-oriented GUI design. This approach localizes the reverse-engineering process to these aspects of the legacy system relevant to a specific task, instead of having to deal with the whole body of the system code (Merlo et. al., 1995). Furthermore, it produces an understanding of the information and the logic of the organization\u0393\u00c7\u00d6s current processes as they have actually evolved through the system\u0393\u00c7\u00d6s lifetime. Finally, it enables the development of intuitive, user-friendly graphical interfaces tailored to simplifying the interaction of the user with the system in service of a specific task (Wilson & Johnson 1995, Sanz & Gomez 1995).", "num_citations": "22\n", "authors": ["57"]}
{"title": "Building a game engine: A tale of modern model-driven engineering\n", "abstract": " Game engines enable developers to reuse assets from previously developed games, thus easing the software-engineering challenges around the video-game development experience and making the implementation of games less expensive, less technologically brittle, and more efficient. However, the construction of game engines is challenging in itself, it involves the specification of well defined architectures and typical game play behaviors, flexible enough to enable game designers to implement their vision, while, at the same time, simplifying the implementation through asset and code reuse. In this paper we present a set of lessons learned through the design and construction PhyDSL-2, a game engine for 2D physics-based games. Our experience involves the active use of modern model-driven engineering technologies, to overcome the complexity of the engine design and to systematize its maintenance and\u252c\u00e1\u0393\u00c7\u00aa", "num_citations": "21\n", "authors": ["57"]}
{"title": "Lessons learned managing distributed software engineering courses\n", "abstract": " We have run the Undergraduate Capstone Open Source Projects (UCOSP) program for ten terms over the past six years providing over 400 Canadian students from more than 30 schools the opportunity to be members of distributed software teams. UCOSP aims to provide students with real development experience enabling them to integrate lessons they have learned in the classroom with practical development experience while developing their technical communication skills. The UCOSP program has evolved over time as we have learned how to effectively manage a diverse set of students working on a large number of different projects. The goal of this paper is to provide an overview of the roles of the various stakeholders for distributed software engineering projects and the various lessons we have learned to make UCOSP an effective and positive learning experience.", "num_citations": "21\n", "authors": ["57"]}
{"title": "Web service matching for RESTful web services\n", "abstract": " There is a growing number of web services available on the Internet, providing a wide range of functionalities. This diversity introduces a variety of new challenges in the field of software engineering - service discovery, integration, and composition, all of which require, to some extent, \u0393\u00c7\u00a3service matching\u0393\u00c7\u00a5. Web-service matching (or alignment) is the task of mapping the functionalities of two web services, assuming that these functionalities overlap somewhat. In this paper we propose a novel graph-theoretic approach, called Semantic Flow Matching (SFM), for matching REST web services, specified in WADL (Web Application Description Language). The method builds a heterogeneous network of WADL elements and semantically related terms, and uses this network to match similar functionalities of different web services. The method is implemented in a prototype tool that consists of two modules: a converter and a\u252c\u00e1\u0393\u00c7\u00aa", "num_citations": "21\n", "authors": ["57"]}
{"title": "Reverse Engineering the Process of Small Novice Software Teams.\n", "abstract": " The software-development project success depends on the technical competence of the development team, the quality of its tools and the project-management decisions it makes during the software lifecycle. New requirements, tight delivery schedules and teammember turnaround present the team with challenges. Flexible decision making for effective adaptation to these challenges is an extremely difficult skill to acquire, and even more challenging to teach. Instructors of software-engineering courses involving collaborative project development are often overwhelmed by the task of monitoring the progress of multiple teams and problems in the team\u0393\u00c7\u00d6s process may go unnoticed until it is too late to be fixed. In this paper we describe our work on analyzing the CVS history of a team project repository to extract information about the nature of the collaboration between the members of a team. This analysis can support the instructor in noticing evidence of potential problems who can then use this information to alert the team. It can also be shown to the team members themselves, so that they become more aware of their process. We evaluate our CVS analysis process with a case study, based on an undergraduate softwareengineering course.", "num_citations": "21\n", "authors": ["57"]}
{"title": "VirtualGym: A kinect-based system for seniors exercising at home\n", "abstract": " Serious games are games with a purpose beyond entertainment, and the sub-category of serious games conceived to motivate physical activity are called \u0393\u00c7\u00a3exergames.\u0393\u00c7\u00a5 To date, numerous exergames have been developed to motivate users to exercise regularly and correctly. This objective becomes more challenging when the target user population involves older adults, in which case the specific exercise routine and intuitive interaction are of critical importance. Personalized exercise routines can be an effective means for remaining healthy; however, specifying exercise sessions for an individual user is a complex and effort-intensive task that requires multiple types of expertise.In this paper, we describe our system that supports exercise experts in specify an exercise routine for older adults and generates an exergame in which a coach avatar fluidly guides seniors through a personalized version of this routine\u252c\u00e1\u0393\u00c7\u00aa", "num_citations": "19\n", "authors": ["57"]}
{"title": "From relations to multi-dimensional maps: towards an SQL-to-HBase transformation methodology\n", "abstract": " In this paper, we describe a method for transforming and migrating data schemas developed for RDBMS to HBase. The method consists of a set of HBase-organization guidelines and a four-step data-schema transformation process that HBase application developers may follow during the migration of their application data from RDBMSs to HBase. The method also considers data-access paths extracted from query logs, in order to improve the quality of the transformation and the eventual access efficiency of the HBase repository. We illustrate and validate the method with a case study.", "num_citations": "19\n", "authors": ["57"]}
{"title": "A framework for monitoring instructional environments in a virtual world\n", "abstract": " Virtual worlds are gaining momentum as a platform for delivering simulation\u0393\u00c7\u00c9based educational experiences to students. However, a key aspect of virtual world\u0393\u00c7\u00c9based education that has received little attention is recording and analyzing students' in\u0393\u00c7\u00c9world actions. This capability is essential for assessing what students have learned through their simulation experience, and engaging the students in post\u0393\u00c7\u00c9simulation reflective learning. In this research, we present a framework for recording and analyzing students' actions in a virtual world. This framework is based upon pedagogical theories of exploratory and experiential learning, and is defined in a virtual\u0393\u00c7\u00c9world agnostic manner. The framework consists of two parts: (1) the Avatar Capabilities Model, which defines the educationally relevant actions that a student can take within a virtual world and (2) the Simulation Capture and Analysis toolkit that records and\u252c\u00e1\u0393\u00c7\u00aa", "num_citations": "19\n", "authors": ["57"]}
{"title": "fAARS: a platform for location-aware trans-reality games\n", "abstract": " Users today can easily and intuitively record their real-world experiences through mobile devices, and commodity virtual worlds enable users from around the world to socialize in the context of realistic environments where they simulate real-world activities. This synergy of technological advances makes the design and implementation of trans-reality games, blending the boundaries of the real and virtual worlds, a compelling software-engineering problem. In this paper, we describe fAARS, a platform for developing and deploying trans-reality games that cut across the real and parallel virtual worlds, offering users a range of game-play modalities. We place fAARS in the context of recent related work, and we demonstrate its capabilities by discussing two different games developed on it, one with three different variants.", "num_citations": "19\n", "authors": ["57"]}
{"title": "A remotely programmable smart pillbox for enhancing medication adherence\n", "abstract": " Medication adherence is an important challenge for many patients with chronic conditions, most of them elderly. Technology has an important role to play in this area potentially, with electronic devices equipped with reminder capability and medication intake recording. In this paper, we present a remotely programmable pillbox. This pillbox is equipped with a web application which gives the health professional or caregiver a tool to check and program the pillbox. Also, a mobile application is implemented to establish a connection with the web-application to show pills' daily schedule and pill taking notifications.", "num_citations": "19\n", "authors": ["57"]}
{"title": "Developing interprofessional health competencies in a virtual world\n", "abstract": " Background: Virtual worlds provide a promising means of delivering simulations for developing interprofessional health skills. However, developing and implementing a virtual world simulation is a challenging process, in part because of the novelty of virtual worlds as a simulation platform and also because of the degree of collaboration required among technical and subject experts. Thus, it can be difficult to ensure that the simulation is both technically satisfactory and educationally appropriate.Methods: To address this challenge, we propose the use of de Freitas and Oliver's four-dimensional framework as a means of guiding the development process. We give an overview of the framework and describe how its principles can be applied to the development of virtual world simulations.Results: We present two virtual world simulation pilot projects that adopted this approach, and describe our development experience\u252c\u00e1\u0393\u00c7\u00aa", "num_citations": "18\n", "authors": ["57"]}
{"title": "Wikidev 2.0: discovering clusters of related team artifacts\n", "abstract": " Most software development today is a team activity. Project team members collaboratively work on the tasks necessary to accomplish the various project milestones. The work is usually asynchronous, not orchestrated by any explicit workflow, sometimes geographically distributed, and involves the use of a variety of tools, which do not always interoperate. Version-control repositories are essential in supporting this collaboration but cannot satisfactorily address the problem of traceability of interdependencies among the artifacts produced by the individual tools. In the WikiDev 2.0 collaboration tool, we propose to address these problems by adopting a wiki as the central platform in which to integrate information about the various artifacts of interest, to cluster this information in clusters of relevant artifacts, and to present views on this information that cut across the individual tool boundaries. In this paper, we discuss the\u252c\u00e1\u0393\u00c7\u00aa", "num_citations": "18\n", "authors": ["57"]}
{"title": "Learning problem-solving concepts by reflecting on problem solving\n", "abstract": " Learning and problem solving are intimately related: problem solving determines the knowledge requirements of the reasoner which learning must fulfill, and learning enables improved problem-solving performance. Different models of problem solving, however, recognize different knowledge needs, and, as a result, set up different learning tasks. Some recent models analyze problem solving in terms of generic tasks, methods, and subtasks. These models require the learning of problem-solving concepts such as new tasks and new task decompositions. We view reflection as a core process for learning these problem-solving concepts. In this paper, we identify the learning issues raised by the task-structure framework of problem solving. We view the problem solver as an abstract device, and represent how it works in terms of a structure-behavior-function model which specifies how the knowledge and\u252c\u00e1\u0393\u00c7\u00aa", "num_citations": "18\n", "authors": ["57"]}
{"title": "Sensor-data fusion for multi-person indoor location estimation\n", "abstract": " We consider the problem of estimating the location of people as they move and work in indoor environments. More specifically, we focus on the scenario where one of the persons of interest is unable or unwilling to carry a smartphone, or any other \u0393\u00c7\u00a3wearable\u0393\u00c7\u00a5 device, which frequently arises in caregiver/cared-for situations. We consider the case of indoor spaces populated with anonymous binary sensors (Passive Infrared motion sensors) and eponymous wearable sensors (smartphones interacting with Estimote beacons), and we propose a solution to the resulting sensor-fusion problem. Using a data set with sensor readings collected from one-person and two-person sessions engaged in a variety of activities of daily living, we investigate the relative merits of relying solely on anonymous sensors, solely on eponymous sensors, or on their combination. We examine how the lack of synchronization across different sensing sources impacts the quality of location estimates, and discuss how it could be mitigated without resorting to device-level mechanisms. Finally, we examine the trade-off between the sensors\u0393\u00c7\u00d6 coverage of the monitored space and the quality of the location estimates. View Full-Text", "num_citations": "17\n", "authors": ["57"]}
{"title": "Crowdsourced bug triaging: Leveraging q&a platforms for bug assignment\n", "abstract": " Bug triaging, i.e.,\u252c\u00e1assigning a bug report to the \u0393\u00c7\u00a3best\u0393\u00c7\u00a5 person to address it, involves identifying a list of developers that are qualified to understand and address the bug report, and then ranking them according to their expertise. Most research in this area examines the description of the bug report and the developers\u0393\u00c7\u00d6 prior development and bug-fixing activities. In this paper, we propose a novel method that exploits a new source of evidence for the developers\u0393\u00c7\u00d6 expertise, namely their contributions in Stack Overflow, the popular software Question and Answer (Q&A) platform. The key intuition of our method is that the questions a developer asks and answers in Stack Overflow, or more generally in software Q&A platforms, can potentially be an excellent indicator of his/her expertise. Motivated by this idea, our method uses the bug-report description as a guide for selecting relevant Stack Overflow\u252c\u00e1contributions on\u252c\u00e1\u0393\u00c7\u00aa", "num_citations": "17\n", "authors": ["57"]}
{"title": "Using WADL specifications to develop and maintain REST client applications\n", "abstract": " Service orientation is one of the most popular paradigms for developing modular distributed software systems. In spite of the substantial research effort dedicated to the development of methods and tools to support SOAP-based service-oriented application development, in practice, RESTful services have surpassed SOAP-based services in popularity and adoption, primarily due to the simplicity of their invocation. However, poor adoption of REST specification standards and lack of systematic development tools have given rise to many, more or less compliant, variants of the Restful style constraints, which undermine the evolvability and interoperability of these systems. In this paper, we describe a tool that supports the systematization of RESTful application development, through the use of semi-automatically constructed WADL interface specifications, without compromising the ease of the overall practice. We\u252c\u00e1\u0393\u00c7\u00aa", "num_citations": "17\n", "authors": ["57"]}
{"title": "Computational thinking, code complexity, and prior experience in a videogame-building assignment\n", "abstract": " Computational-thinking skills are an essential intellectual amplifier for all scientific and professional disciplines. Embedding these skills in the K-12 and University curricula is necessary for training the next generation of thinkers. A widely adopted approach to doing so is through simple and visual programming languages like Scratch and engaging assignments like video-game construction. In this work, we report on an empirical study we conducted with senior undergraduate education students aiming to understand how prior experience enables students to better develop their computation-thinking skills through a Scratch-based video-game assignment.", "num_citations": "17\n", "authors": ["57"]}
{"title": "A utility for estimating the relative contributions of wiki authors\n", "abstract": " Wikis were originally designed to hide the association between a wiki page and the authors who have produced it. However, there is evidence suggesting that corporate wiki users require an attribution mechanism that would automatically record (and present) the relative contribution of each author. In this paper we introduce an algorithm for assessing the contributions of wiki authors that is based on the notion of sentence ownership. The results of an empirical evaluation comparing the algorithm\u0393\u00c7\u00d6s output to manual evaluations reveal the type of contributions captured by our algorithm. Implications for research and practice are discussed.", "num_citations": "17\n", "authors": ["57"]}
{"title": "JRefleX: Towards supporting small student software teams\n", "abstract": " The success of a software development project depends on the technical competency of the development team, the quality of the tools they use, and the project-management decisions they make during the software lifecycle. Instructors of software-engineering courses that involve small project teams are often overwhelmed with the task of monitoring the progress of multiple teams. Without adequate monitoring and advice on best practices, problems in the team's process or the developed product may go unnoticed until it is too late to be easily fixed. This paper introduces the JRefleX environment, with components built upon Eclipse, to support the education of small software teams.", "num_citations": "17\n", "authors": ["57"]}
{"title": "Model-based reconfiguration of schema-based reactive control architectures\n", "abstract": " Reactive methods of control get caught in local minima. Fortunately schema-based reactive control systems have built-in redundancy that enables multiple configurations with different modes. We describe a model-based method that exploits this redundancy, and, under certain conditions, reconfigures schema-based reactive control systems trapped in behavioral cycles due to the presence of local minima. The qualitative model specifies the functions and modes of the perceptual and motor schemas, and represents the reactive architecture as a structure-behavior-function model. The model-based method monitors the reactive processing, detects failures in the form of behavioral cycles, analyzes the processing trace, identifies potential modifications, and reconfigures the reactive architecture. We report on experiments with a simulated robot navigating a complex space.", "num_citations": "16\n", "authors": ["57"]}
{"title": "Serious games: Rehabilitation fuzzy grammar for exercise and therapy compliance\n", "abstract": " Serious Games (SG) are advocated as a technology for engaging and motivating a variety of activities, such as learning and exercising. The motivating intuition is that infusing activities with game mechanics should make them more interesting and entertaining, resulting in increased practice time, and consequently, improved performance. In our work we are interested in the role that serious games can play in rehabilitation, relying on affordable, accessible and increasingly precise bio-mechanic sensors, such as the Kinect\u0393\u00e4\u00f3. In this paper, we describe a Kinect\u0393\u00e4\u00f3-based system that guides players through their prescribed rehabilitation-exercise regimen at home, after a sports injury. The system is endowed with a grammar, in terms of which the rehabilitation exercises can be precisely specified by physical therapists, and a fuzzy-logic-based component that discerns in real time, whether the user \"correctly\" follows the\u252c\u00e1\u0393\u00c7\u00aa", "num_citations": "15\n", "authors": ["57"]}
{"title": "Seven challenges to combining human and automated service\n", "abstract": " We introduce this special issue by addressing seven key challenges associated with managing hybrid human\u0393\u00c7\u00c9automated service systems. These consist of the following:  1 What strategic and tactical issues arise when managing hybrid service systems?  2 How should the core \u0393\u00c7\u00a3value proposition\u0393\u00c7\u00a5 be set?  3 What special considerations arise in the design and implementation phases?  4 How can service delivery be managed to identify systemic problems and to address service breakdowns?  5 How can communications with clients improve the functioning of service systems?  6 What performance measures should be used to monitor process, outputs, client perceptions, and financial outcomes?  7 How can we coordinate the various interdisciplinary activities needed to address the previous six issues?    We consider these challenges after first characterizing the historical evolution of service delivery, reviewing some\u252c\u00e1\u0393\u00c7\u00aa", "num_citations": "15\n", "authors": ["57"]}
{"title": "An environment for building, exploring and querying academic social networks\n", "abstract": " Social network analysis aims at uncovering and understanding the structures and patterns resulting from social interactions among individuals and organizations engaged in a common activity. Since the early days of the field, networks are modeled as graphs modeling social actors and the relations between them. The field has become very active with the maturity of computational machinery to handle large-scale graphs, and, more recently, the automated gathering of social data. We introduce ReaSoN: a comprehensive set of tools for visualizing and exploring social networks resulting from academic research. In doing so, ReaSoN contributes to the understanding as well as fostering of the social networks underlying academic research. We describe the infrastructure, visualizations and analysis provided in our system, as well as the process of extracting the social networks which are latent in bibliographic and\u252c\u00e1\u0393\u00c7\u00aa", "num_citations": "15\n", "authors": ["57"]}
{"title": "EduNuggets: an intelligent environment for managing and delivering multimedia education content\n", "abstract": " Todays teaching and learning practices are evolving to leverage the continuously increasing information available on the web, on all conceivable subject matters. This wealth of information presents a great challenge: how to provide an integrated, authoritative, extendible and shareable information collection of related multimedia education materials. In this paper, we describe EduNuggets (http://www. cs. ualberta. ca/~ stroulia/EduNuggets), our intelligent repository for multimedia educational materials.", "num_citations": "15\n", "authors": ["57"]}
{"title": "Reverse engineering interaction plans for legacy interface migration\n", "abstract": " Legacy interface migration is becoming an increasingly important IT activity; many organizations are interested in cost effective and low risk processes for making their legacy systems accessible to new, web-based platforms. Most migration techniques proposed to date require a lot of human expertise. In this paper we discuss Mathaino, an intelligent, multi platform, semi-automated, and low risk solution for migrating legacy user interfaces to the web by wrapping them with web-accessible front-ends.", "num_citations": "15\n", "authors": ["57"]}
{"title": "Detecting Cognitive Ability Changes in Patients With Moderate Dementia Using a Modified \u0393\u00c7\u00a3Whack-a-Mole\u0393\u00c7\u00a5 Game\n", "abstract": " This paper presents the results from a one-year study of 12 patients with moderate dementia in an adult day program who played a novel whack-a-mole game-based measurement instrument for cognitive behavior and performance. The ongoing measurement of cognition and changes associated with dementia is a challenge for healthcare providers. Measurement methods based on a tablet-based instrument are proposed. Partnership with the adult day program greatly eased recruitment: all but 1 eligible participant joined our study, compared to one in five, or lower, for previous studies with similar populations. There are three unique aspects to the design of our game: first, it has two distinct targets requiring different actions, which increases the cognitive processing for the users; second, each level is systematically more difficult; third, it records and analyzes player performance. The results show that the patients'\u252c\u00e1\u0393\u00c7\u00aa", "num_citations": "14\n", "authors": ["57"]}
{"title": "Users\u0393\u00c7\u00d6 attitudes towards personal health records\n", "abstract": " Prevention and management of chronic conditions is a priority for many healthcare systems. Personal health records have been suggested to facilitate implementation of chronic care programs. However, patients\u0393\u00c7\u00d6 attitude towards personal health records (PHRs) can significantly affect the adoption rates and use of PHRs.  to evaluate the attitude of patients with Type II diabetes towards using a PHR to manage their condition.  We used a cross-sectional exploratory pilot study. Fifty-four (54) patients used a PHR to monitor and record their blood glucose levels, diet, and activities for 30 days, and to communicate with their clinicians. At the end of the study, patients responded to a survey based on three constructs borrowed from different technology acceptance frameworks: relative advantage, job fit, and perceived usefulness. A multivariate predictive model was formed using partial least squaring technique (PLS) and the\u252c\u00e1\u0393\u00c7\u00aa", "num_citations": "14\n", "authors": ["57"]}
{"title": "Methods for matching xml documents\n", "abstract": " Methods, systems, and devices related to determining differences between XML documents. Two XML documents to be compared are first each decomposed into ordered labelled trees. Sets of operations which convert one tree into the other tree are then determined and a cost function is applied to each set of operations. The set of operations with the lowest cost is then selected. The cost function uses an affine-cost policy which adjusts a cost of each operation based a context in which the operation is applied.", "num_citations": "14\n", "authors": ["57"]}
{"title": "Sociql: A query language for the socialweb\n", "abstract": " Social-networking sites are becoming increasingly popular with users of all ages. With much of our social activity happening online, these sites are now becoming the subject of scholarly study and research. Unfortunately, despite the fact that they collect similar content and support similar relations and activities, the current generation of these sites are hard to query programmatically, offering limited views of their data, effectively becoming disconnected islands of information. We describe SociQL, a high-level query language, and a corresponding service, to which social-networking sites can subscribe, that supports the integrated representation, querying and exploration of disparate social networks. Unlike generic web query languages, SociQL is designed specifically to support the integration of networks through a common information model for the purpose of examining sociological questions, motivated by\u252c\u00e1\u0393\u00c7\u00aa", "num_citations": "14\n", "authors": ["57"]}
{"title": "The smart condo project: services for independent living\n", "abstract": " Most would agree that older adults want affordable, high-quality healthcare that enables them to live independently longer and in their own homes. To this end, ambient assisted living environments have been developed that are able to non-intrusively monitor the health of people at-home and to provide them with improved care. The authors have designed an environment, the Smart Condo, to support seniors and rehabilitating patients. They have embedded a wireless sensor network into a model living space, which incorporates universal design principles. Information from the sensor network is archived in a server, which supports a range of views via APIs. One such view is a virtual world, which is realistic and intuitive, while remaining non-intrusive. This chapter examines computing technologies for smart healthcare-related environments and the needs of elderly patients. It discusses the Smart Condo architecture\u252c\u00e1\u0393\u00c7\u00aa", "num_citations": "14\n", "authors": ["57"]}
{"title": "Moving text analysis tools to the cloud\n", "abstract": " Text analysis is an important computational task, as unstructured data including text abound and can potentially provide interesting information and knowledge in a variety of areas. In our collaboration with Digital Humanists, we have started to examine the opportunities that the cloud offers to improving the response times of text-analysis tools so that users can comparatively analyze large text corpora across a variety of dimensions. To that end, we have started migrating existing text analysis tools to the cloud, beginning with TAPoR, the Text Analysis Portal for Research. In this paper, we discuss our experience redesigning and re-implementing four basic TAPoR operations on Hadoop and we report on the performance improvements enabled by the migration.", "num_citations": "14\n", "authors": ["57"]}
{"title": "Annoki: a mediawiki-based collaboration platform\n", "abstract": " Communication plays a vital role throughout all the activities of software engineering processes. As Web 2.0 paradigms concentrate on communication, collaboration, and information sharing, it is only natural that these applications should become part of the software engineering toolkit. In this paper, we describe Annoki, our collaboration platform built on top of the popular wiki software MediaWiki. Annoki supports collaboration by improving the organization of, managing access to, assisting in the creation of, and graphically displaying information about content stored on the wiki. We follow our description of Annoki with a discussion of the current users of Annoki, the largest of whom is the Software Engineering Research Lab at the University of Alberta, where it is used to manage research and development software engineering activities on a daily basis.", "num_citations": "14\n", "authors": ["57"]}
{"title": "Rule-based compliance checking and generative design for building interiors using BIM\n", "abstract": " Building Information Modeling (BIM) is becoming an integral part of the design, architecture, and construction process, as it can integrate all building data in an accessible digital representation that can be viewed in a 3D environment prior to construction. This supports the capability of evaluating a model against building codes or design rules to ensure that the building meets the relevant functional and safety requirements for occupants. However, building regulations are typically represented in natural language and, to date, they have not been created with regard to the digital BIM design process. To automate the design evaluation of a building model, this paper describes a simple, yet extendable, domain-specific language for computationally representing building interior design rules and a method for evaluating rules in this language against a BIM model.Furthermore, previous language-based model-checking\u252c\u00e1\u0393\u00c7\u00aa", "num_citations": "13\n", "authors": ["57"]}
{"title": "Phydsl: A code-generation environment for 2d physics-based games\n", "abstract": " Video-game design and development involves a variety of professionals working together to create games with engaging content, and an efficient and flexible software architecture. However, more often than not, video-game development environments are designed for software developers, supporting programming tasks agnostic of the needs of the non-computer experts on the team. Code-generation environments offer an alternative methodology to building families of software systems that systematically differ from each other. They provide highlevel domain-specific languages that express the domain concepts and features of interest, and isolate the low-level implementation concerns, so that even non-programming experts can prototype and efficiently create software systems. In this paper we describe PhyDSL, a code-generation environment for the creation of mobile physics-based games in 2D. We report how we have used PhyDSL for the rapid prototyping of customizable and costeffective games based on physics.", "num_citations": "13\n", "authors": ["57"]}
{"title": "The smart condo: integrating sensor networks and virtual worlds\n", "abstract": " The term\" Smart Home\" refers to a home that has both a set of sensors to observe the environment and a set of actuators to automatically control home devices to improve the occupants' experience. A Smart Home has the potential to provide a variety of services based on information gleaned by data recorded by a multiplicity of sensor types, but also requires a systematic means (a) of abstracting differences among sensor types and (b) of supporting services and their rapid development. In this paper, we describe our approach towards meeting those needs, including a component of sensor adapters and a language for modeling person activities that can guide the development of health-care services.", "num_citations": "13\n", "authors": ["57"]}
{"title": "Toward a simulation-generated knowledge base of service performance\n", "abstract": " The wide adoption of service orientation and the growing complexity of service-oriented applications presents new challenges in configuring and tuning these applications, both at deployment time and at run time. This paper describes our simulation-based approach to addressing this problem. We have developed a general SOA simulation framework, which includes a tool for automatically generating significant portions of the simulator based on the WSDLs of the web services. Our methodology stipulates the systematic exploration of varying SOA deployment configurations in order to collect behavioral profiles. One can use these to examine the trade-offs between configuration cost and performance, ultimately identifying a cost-effective configuration that complies with a Service Level Agreement. The results can also used to identify configurations that allow for more accurate load-balancing and thus better overall\u252c\u00e1\u0393\u00c7\u00aa", "num_citations": "13\n", "authors": ["57"]}
{"title": "Simplicity in RNA Secondary Structure Alignment: Towards biologically plausible alignments\n", "abstract": " Ribonucleic acid (RNA) molecules contain the genetic information that regulates the functions of organisms. Given two different molecules, a preserved function corresponds to a preserved secondary RNA structure. Hence, RNA secondary-structure comparison is essential in predicting the functions of a newly discovered molecule. In this paper, we discuss our SPRC method for RNA structure comparison. In this work, we developed, a novel tree representation of RNA that reflects both its primary and secondary structure and a tree-alignment algorithm, which, given the tree representations of two RNA molecules, produces a sequence of mutations that could transform one RNA molecule to the other. Our SPRC algorithm extends the Zhang-Shasha tree-edit distance calculation algorithm in two ways: first, in addition to the distance, it reports all editing sequences with the same minimum edit cost, and second, it uses a\u252c\u00e1\u0393\u00c7\u00aa", "num_citations": "13\n", "authors": ["57"]}
{"title": "Recognizing refactoring from change tree\n", "abstract": " Refactoring is an essential part of most new lightweight software development processes. In this paper, we describe our work on recovering and analyzing refactorings from change trees that report the structural differences, in terms of class/interface/field/method additions, deletions, moves, and renamings, between two or more versions of an application architecture represented in UML (XMI). We discuss the change-tree data structure, and the refactoring-recovery method, and we report on two case studies evaluating our approach.", "num_citations": "13\n", "authors": ["57"]}
{"title": "A lightweight project-management environment for small novice teams\n", "abstract": " The success of a software-development project depends on the technical competence of the development team, the quality of the tools it uses, and the project-management decisions it makes during the software lifecycle. New requirements, tight delivery schedules and developer turnaround present the team with challenges that need to be addressed with informed development-plan modifications. Project-management skills are especially difficult to teach. When working on a substantially complex project, students often become too involved with coding to recognize the need for management; and when they do, they frequently lack the necessary information to make a good decision, because, more often than not, they do not have a complete overview of their progress.In this paper, we describe a lightweight environment for supporting, monitoring and analyzing activities related to software development. This environment integrates a set of tools, including CVS, newsgroups, code analysis and personalprocess tools, and uses a browser-accessible Wiki-based user interface as a front end to all the underlying tools. We have just deployed this environment in the context of an undergraduate software-engineering course. We believe that the familiar lightweight user interface will encourage students to use the integrated tools and will improve their overall learning experience, especially in the project-management area. At the same time, it will enable the instructors to monitor the teamdevelopment progress and to provide relevant and constructive feedback.", "num_citations": "13\n", "authors": ["57"]}
{"title": "Legacy systems migration in CelLEST\n", "abstract": " Most research on legacy User Interface migration has adopted code understanding as the means for system modeling and reverse engineering. The methodological assumption underlying the CELLEST project is that \u0393\u00c7\u00a3the purpose of system migration is to enable, and possibly optimize, its current uses on a new platform\u0393\u00c7\u00a5. This is why CELLEST uses traces of the system-user interaction to reverse engineer the legacy interface, extract its current uses and generate GUIs on new platforms as wrappers for it.", "num_citations": "13\n", "authors": ["57"]}
{"title": "Home care and technology: A case study\n", "abstract": " Health care aides (HCAs) are the backbone of the home care system and provide a range of services to people who, for various reasons related to chronic conditions and aging, are not able to take care of themselves independently, The demand for HCA services will increase and the current HCA supply will likely not keep up with this increasing demand without fundamental changes in the current environment. Information and communication technology (ICT) can address some of the work\u2229\u00bc\u00e9ow challenges HCAs face. In this project, we conducted an ethnographic study to document and analyse HCAs\u0393\u00c7\u00d6 work\u2229\u00bc\u00e9ows and team interactions. Based on our \u2229\u00bc\u00fcndings, we designed an ICT tool suite, integrating easily available existing and newly developed (by our team) technologies to address these issues. Finally, we simulated the deployment of our technologies, to assess the potential impact of these technological solutions on the work\u2229\u00bc\u00e9ow and productivity of HCAs, their healthcare teams and client care.", "num_citations": "12\n", "authors": ["57"]}
{"title": "Maintainability and source code conventions: An analysis of open source projects\n", "abstract": " Maintainability is a desirable property of software, and a variety of metrics have been proposed for measuring it, all based on different notions of complexity. Although these metrics are useful, complexity is only one factor influencing maintainability. Practical experience in software development has led to a set of best practices and coding conventions that are believed to make source code easier to read, understand and maintain. Based on a survey of software engineers, we identify the relative importance of 71 coding conventions to maintainability. We propose a metric that offers a different perspective on maintenance, namely a \u0393\u00c7\u00a3convention adherence\u0393\u00c7\u00a5 metric based on the number and severity of violations of these coding conventions. We examine the code repositories of four open-source Java projects to measure their adherence to coding conventions over the life of the project, based on both their self-identified conventions and those of the convention-adherence metric. Through our analysis, we discovered several interesting phenomena, including pre-release effort to bring new code in line with desirable conventions, effective usage of automated code convention checkers as part of the build process to improve adherence, variations in adherence over the software lifecycle, and a class of conventions consistently ignored in open source projects.", "num_citations": "12\n", "authors": ["57"]}
{"title": "On coordination tools in the PicOS tuples system\n", "abstract": " In this paper, we discuss the most recent coordination extension to the PicOS-tuples environment, inspired, to a degree, by B-Threads and FACTS. We illustrate the extensions with two design patterns, highly useful in WSN computations, known as regulative superimposition and distributed detection. Those patterns are employed in a debugging protocol that retrieves snapshots of node states. We demonstrate how our new idioms can be propitious for separating concerns in WSN programming using tuples.", "num_citations": "12\n", "authors": ["57"]}
{"title": "Mobile devices for collaborative learning in practicum courses\n", "abstract": " Mobile devices are becoming increasingly powerful and accessible as wireless networks cover most of our daily environment and a variety of software frameworks makes the task of building mobile applications simpler. M-learning applications are a new and interesting breed of mobile applications for supporting a broad range of learning activities on a variety of mobile devices. In this article, we review representative m-learning applications and discuss our own work on MediCol, a tool for supporting the activities of medical students in their surgery rotation.", "num_citations": "12\n", "authors": ["57"]}
{"title": "Use case redocumentation from gui event traces\n", "abstract": " Use case re-documentation is an important maintenance task. The implemented functionality of an application may not reflect original use cases. This discrepancy can create problems in downstream software activities, such as developing documentation and migrating to platforms adopting a service-oriented architecture (SOA). We present a methodology and a toolkit for re-documenting the use cases of interactive Java swing object-oriented applications. Our method collects execution traces of the application while experienced users interact with it. These traces are clustered according to the similarity of the user interface events, to identify families of task-specific execution scenarios. Finally, the traces in each cluster are aligned to produce usage scenarios and visualized.", "num_citations": "12\n", "authors": ["57"]}
{"title": "Task-structure based mediation: The travel-planning assistant example\n", "abstract": " As the number of applications available on the World Wide Web (WEB) increases at a rapid speed, an enormous number of resources become available to the general public. These resources offer information and services in a variety of domains but are often difficult to use due to their idiosyncratic domain and interaction models. In this paper, we discuss a multi-agent architecture for integration of WEB applications within a domain, based on a task-structure approach. The architecture consists of a set of wrapper agents, driving and extracting information from a set of corresponding WEB applications, and a mediator agent, whose task structure drives both its interaction with the users and its communication with the wrappers. We illustrate this architecture with the description of a travel-planning assistant that supports the users in an exploratory, least-commitment search behavior.", "num_citations": "12\n", "authors": ["57"]}
{"title": "Automated acceptance testing of javascript web applications\n", "abstract": " Acceptance testing is an important part of software development and it is performed to ensure that a system delivers its required functionalities. Today, most modern interactive web applications are designed using Web 2.0 technologies, many among them relying on JavaScript. JavaScript enables the development of client-side functionality through the dynamic modification of the web-page's content and structure without calls to the server. This implies that server-side testing frameworks will necessarily fail to test the complete application behaviors. In this paper we present a method for automated acceptance testing of JavaScript web applications to ensure that required functionalities have been implemented. Using an intuitive, human-readable scripting language our method allows users to describe user stories in high level declarative test scripts and to then execute these test scripts on a web application using an\u252c\u00e1\u0393\u00c7\u00aa", "num_citations": "11\n", "authors": ["57"]}
{"title": "Analyzing natural-language artifacts of the software process\n", "abstract": " Software teams, as they communicate throughout the life-cycle of their projects, generate a substantial stream of textual data. Through emails and chats, developers discuss the requirements of their software system, they negotiate the distribution of tasks among them, and they make decisions about the system design, and the internal structure and functionalities of its code modules. The software research community has long recognized the importance and potential usefulness of such textual information. In this paper, we discuss our recent work on systematically analyzing several textual streams collected through our WikiDev2.0 tool. We use two different text-analysis methods to examine five different sources of textual data. We report on our experience using our method on analyzing the communications of a nine-member team over four months.", "num_citations": "11\n", "authors": ["57"]}
{"title": "Smart services across the real and virtual worlds\n", "abstract": " Today, we are witnessing a new level of scale, complexity, and pervasiveness of software systems that are designed to support much more holistically complex processes. Much richer information is becoming available for processing, including raw data, proven facts and people\u0393\u00c7\u00d6s opinions. A multitude of interesting analytics methods is being developed to extract new knowledge from this plethora of data. In this paper, we examine some opportunities for smart service delivery that arise from the integration of sensor networks, service-oriented middleware and virtual worlds.", "num_citations": "11\n", "authors": ["57"]}
{"title": "Accurate and efficient html differencing\n", "abstract": " Recognizing the differences between subsequent versions of HTML documents is an important problem. It is useful for managers of multi-authored Web sites who need to review and approve the changes to their Web-site content. It is also necessary for users who want to be able to easily recognize changes to the pages they visit regularly. Comparing HTML documents at the lexical level, as if they were regular text documents, is neither informative nor intuitive. Instead, their internal tree structure has to be taken into account. In this paper, we discuss VDiff an algorithm we have developed for HTML differencing, based on the Zhang-Shasha tree-edit distance algorithm. Our algorithm reports which nodes in the two compared documents match, have been deleted (inserted) from(in) the original (subsequent) document, or have been, moved in the HTML structure. We have evaluated the accuracy and performance of our\u252c\u00e1\u0393\u00c7\u00aa", "num_citations": "11\n", "authors": ["57"]}
{"title": "Task structures: What to learn\n", "abstract": " Broadly characterized, learning can improve problem-solving performance by increasing its efficiency and effectiveness, and by improving the quality of produced solutions. Traditional AI systems have limited the role of learning to the first two performance-improvement goals. We have developed a reflection process that uses a model of the system\u0393\u00c7\u00d6s functional architecture to monitor its performance, suggest a quite broad range of modifications when it fails, and subsequently perform these modifications to improve its problem-solving mechanism. The modifications suggested and performed by the reflection process may result in performance improvement of all the above types.", "num_citations": "11\n", "authors": ["57"]}
{"title": "BIM sim/3D: multi-agent human activity simulation in indoor spaces\n", "abstract": " Smart buildings are a prevalent example of cyberphysical systems: embedded with sensors, they emit a continuous data stream based on which algorithms are being developed to infer the occupants' activities in order to control the building's ambience to improve the occupants' comfort and safety, and to reduce the building's energy consumption. This type of sensor-fusion-for-occupant-activity-analysis research requires large data sets; however, the security and privacy concerns around sharing data about people's activities impedes the collection, curation, and sharing of such data sets. One solution to this issue would be the creation of a human-activity simulator for generating synthetic, yet realistic, data sets. In this paper, we describe our human-activity simulator as a component in our general framework for evaluating activity-recognition methods for indoor spaces. Our simulator, developed in Unity3D, uses the\u252c\u00e1\u0393\u00c7\u00aa", "num_citations": "10\n", "authors": ["57"]}
{"title": "Serious rehabilitation games with Kinect\n", "abstract": " This demo presents a suite of serious Kinect\u0393\u00e4\u00f3 - based games for rehabilitation. The game embodies three metaphors and corresponding game mechanics, for three exercise movements: elbow flexion and extension (fisherman), shoulder abduction and adduction (moon spaceship), and knee flexion and extension (the trail of the penguin). Conceived to support sport-injury rehabilitation regimens, the games guide the players through their prescribed rehabilitation exercise at home.", "num_citations": "10\n", "authors": ["57"]}
{"title": "How Do Developers Solve Software-engineering Tasks on Model-based Code Generators? An Empirical Study Design.\n", "abstract": " Model-based code-generators are complex in nature; they are built using a variety of tools such as language workbenches, and model-to-model and model-to-text transformation languages. Due to the highly heterogeneous technology ecosystem in which code generators are built, understanding and maintaining their architecture pose numerous cognitive challenges to both novice and expert developers. Most of these challenges are associated with tasks that require to trace and pinpoint generation artifacts given a life-cycle requirement. We argue that such tasks can be classified in three general categories:(a) information discovery,(b) information summarization, and (c) information filtering and isolation. Furthermore, we hypothesize that visualizations that enable the interactive exploration of model-to-model and model-to-text transformation compositions can significantly improve developers\u0393\u00c7\u00d6 performance when reflecting on a code-generation architecture, and its corresponding execution mechanics. In this paper we describe an empirical study conceived (a) to understand the performance of developers (in terms of time and precision) when asked to discover, filter, and summarize information about a model-based code generator, using classic integrated development environments and editors, and (b) to measure and compare the developers\u0393\u00c7\u00d6 effectiveness on the same tasks using state-of-the-art traceability visualizations for model-transformation compositions.", "num_citations": "10\n", "authors": ["57"]}
{"title": "UnderControl an educational serious-game for reproductive health\n", "abstract": " Educational serious games are effective tools to communicate topics of interest to diverse audiences through well defined gameplay designs. In recent years, reproductive health has become an area of special interest for government and health organizations when designing educational programs for teens and young adults. In this paper we present UnderControl, a multi-level mobile serious game that educates players about contraception and STI prevention in an elegant, yet straightforward fashion.", "num_citations": "10\n", "authors": ["57"]}
{"title": "Webdiff: A generic differencing service for software artifacts\n", "abstract": " Software evolution analysis plays an important role in several software engineering activities which are mainly related to maintenance tasks. For this purpose, several approaches and tools have been developed to identify and analyze code changes throughout the history of a software system. However, most existing tools are restricted to a specific type of software artifact, are language-dependent and can only be locally executed on a client machine. To overcome these limitations we propose WebDiff, a web-based generic differencing service for various types of software artifacts including source code and UML diagrams.", "num_citations": "10\n", "authors": ["57"]}
{"title": "Asserting the utility of CO (2) P (3) S using the Cowichan problems.\n", "abstract": " Degree: M. Sc.DegreeYear: 2002Institute: University of Alberta (Canada)Parallel programming is seen as an effective technique to improve the performance of computationally-intensive programs. This is done at the cost of increasing the complexity of the program, since new issues must be addressed for a concurrent application. Parallel programming environments provide a way for users to reap the benefits of concurrent programming while minimizing the effort required to create them. The CO 2 P 3 S parallel programming system is one such tool which uses a pattern-based approach to create parallel programs.", "num_citations": "10\n", "authors": ["57"]}
{"title": "Decentralized access control for smart buildings using metadata and smart contracts\n", "abstract": " Managing the privileges of occupants and visitors of large commercial buildings to access different building areas, control systems and equipment therein is a challenging task. The best practice today involves giving long-term building occupants, for example employees working in the building, access privileges to their organization areas and requiring visitors to be escorted by them. This approach is conservative and inflexible. Ideally, an automated solution is needed to manage access delegations; however, traditional role-based access control models are unwieldy in that they require the specification of all roles and their relative authority, which is a challenge in large buildings home of multiple organizations and numerous visitors. In this paper, we present a methodology based on blockchain smart contracts to describe, grant, and revoke fine-grained permissions for building users in a decentralized fashion. This\u252c\u00e1\u0393\u00c7\u00aa", "num_citations": "9\n", "authors": ["57"]}
{"title": "Detecting Depression from Voice\n", "abstract": " In this paper, we present our exploration of different machine-learning algorithms for detecting depression by analyzing the acoustic features of a person\u0393\u00c7\u00d6s voice. We have conducted our study on benchmark datasets, in order to identify the best framework for the task, in anticipation of deploying it in a future application.", "num_citations": "9\n", "authors": ["57"]}
{"title": "Differencing UML models: a domain-specific vs. a domain-agnostic method\n", "abstract": " Comparing software artifacts to identify their similarities and differences is a task ubiquitous in software engineering. Logical-design comparison is particularly interesting, since it can serve multiple purposes. When comparing the as-intended vs. the as-implemented designs, one can evaluate implementation-to-design conformance. When comparing newer code versions against earlier ones, one may better understand the development process of the system, recognize the refactorings it has gone through and the qualities motivating them, and infer high-order patterns in its history. Given its importance, design differencing has been the subject of much research and a variety of algorithms have been developed to compare different types of software artifacts, in support of a variety of different software-engineering activities. Our team has developed two different algorithms for differencing logical-design models\u252c\u00e1\u0393\u00c7\u00aa", "num_citations": "9\n", "authors": ["57"]}
{"title": "Developing a virtual-world simulation\n", "abstract": " Simulation-based training has been an integral part of health-sciences education for many years, and is becoming increasingly important with the shift towards competency-based education. Virtual worlds have emerged as an effective way to deliver realistic, collaborative training in complex processes, which is consistent with competency-based training and assessment. We have developed MeRiTS, a virtual world-based platform for creating training simulations, to provide students in a wide range of disciplines with this kind of training. Furthermore, through these student training experiences, we will be able to provide a rigorous, comprehensive evaluation of the effectiveness of conducting scenario-based training in virtual worlds.", "num_citations": "9\n", "authors": ["57"]}
{"title": "MeRiTS: simulation-based training for healthcare professionals\n", "abstract": " Simulation-based training has been used in numerous settings for procedural training. In this research, we focus on a method of simulation-based procedural skills training that uses virtual worlds. This method, implemented in our MeRiTS software system, models procedures using executable workflows, which are enacted by the trainee in a virtual world. The workflows may be defined by educators, or demonstrated by experts and then extracted from system logs. To demonstrate the utility of the system, we have created a scenario for training EMTs in patient rescue and transition procedures. We have pilot tested this scenario with students at a polytechnical institute, and will be conducting more rigorous testing with a range of students and institutions in the near future.", "num_citations": "9\n", "authors": ["57"]}
{"title": "2D and 3D visualizations in WikiDev2. 0\n", "abstract": " Several types of 3D software visualizations have been developed to communicate information about the products of a software project and, sometimes, the development process itself. These visualizations have been limited in the degree of interactivity they enabled (primarily panning and zooming) and in their accessibility (since in most cases they assumed a particular client platform). In this paper we discuss our 3D visualization of the data collected and extracted in our collaborative software-development platform WikiDev2.0, developed in the Open Wonderland virtual world. The visualization adopts a city metaphor, similar to earlier work, but advances the state of the art by providing a web-accessible distributed 3D environment where multiple users can explore the same project. In this paper we discuss this visualization, which we call WikiDev3D, and we report on our preliminary findings about its effectiveness\u252c\u00e1\u0393\u00c7\u00aa", "num_citations": "9\n", "authors": ["57"]}
{"title": "Design mentoring based on design evolution analysis\n", "abstract": " Developing and consistently evolving quality software designs requires both theoretical knowledge and practical skills. The former can be communicated in a classroom; the latter has to be acquired with hands-on experience in software development. Our recent work on design evolution has resulted in a framework for analyzing the structural differences of subsequent versions of design artifacts, such as the logical design of OO software and the user-interface design of interactive applications. In this paper, we discuss how design-evolution analysis can be used to assist developers in their tasks of understanding the design rationale of the system at hand and to advise them on how to consistently maintain and evolve it.", "num_citations": "9\n", "authors": ["57"]}
{"title": "Reflective, self-adaptive problem solvers\n", "abstract": " Problem-solving systems, situated in the real world are faced with a great challenge, that is, the dynamic nature of their environment. In any realistic environment the state of the world changes, and therefore, the system's knowledge about the world often becomes incomplete and incorrect. Furthermore, the constraints and the requirements imposed on the system's behavior may also evolve, and as a result, the system's functional architecture may become insufficient to meet the requirements of the evolving task environment. In principle, we would like our systems to be able to adjust themselves in their environments and to sustain quality performance across such environmental changes. To enable a system with the capability of self-adaptation, we have developed a framework for endowing it with the competence of reflection. In this framework, the system's problem-solving behavior is modeled in terms of a\u252c\u00e1\u0393\u00c7\u00aa", "num_citations": "9\n", "authors": ["57"]}
{"title": "Monitoring cognitive ability in patients with moderate dementia using a modified \u0393\u00c7\u00a3whack-a-mole\u0393\u00c7\u00a5\n", "abstract": " This paper presents results from the first 2 months of a 1-year study of 12 moderate dementia patients that participate in a weekly adult day program within a local community-care access center. The 12 patients are using a tablet-based whack-a-mole game, instrumented to record the user's behavior; this record is analyzed to extract indicators, as potential proxies of cognitive ability. Our partnership with the adult day program greatly eased recruitment: all but 1 eligible participant joined our study. The measurements recorded by the game include the detailed user progression through the game levels. There are two unique aspects to the design of our game: first, it includes two distinct targets requiring different actions, which increases the cognitive processing in the tap task for the users; second, each level is systematically more difficult than the last. The results show that the patients' performance within the game\u252c\u00e1\u0393\u00c7\u00aa", "num_citations": "8\n", "authors": ["57"]}
{"title": "Autonomic configuration adaptation based on simulation-generated state-transition models\n", "abstract": " Configuration management is a complex task, even for experienced system administrators, which makes self-managing systems a particularly desirable solution. This paper describes a novel contribution to self-managing systems, including an autonomic configuration self-optimization methodology. Our solution involves a systematic simulation method that develops a state-transition model of the behavior of a service-oriented system in terms of its configuration and performance. At run time, the system's behavior is monitored and classified in one of the model states. If this state may lead to futures that violate service level agreements, the system configuration is changed toward a safer future state. Similarly, a satisfactory state that is over-provisioned may be transitioned to a more economical satisfactory state. Aside from the typical benefits of self-optimization, our approach includes an intuitive, explainable decision\u252c\u00e1\u0393\u00c7\u00aa", "num_citations": "8\n", "authors": ["57"]}
{"title": "Medical education through virtual worlds: the HLTHSIM project\n", "abstract": " Training tools using virtual reality (VR) are becoming more popular and cost-effective to develop and are increasingly adopted; yet there is no systematic means for evaluating their usability and pedagogical effectiveness. There are a wide range of training scenarios that can be scripted, from high level simulations of emergency response systems where participants using their avatars have to make complex decisions and communicate with each other, to low-level sensormotor skills-based trainers where surgeons can practice suturing and cutting. We propose a classification framework for simulator-based training, associating each type of simulation with a specification of the types of skills it is designed to exercise and a corresponding evaluation plan. In this framework, objective measures involving task time and error rates can be formalized at the lower levels, and related subjective and objective measures can be identified at the top. Our framework is being implemented under the auspices of a recently funded New Media project in Canada (GRAND NCE) that spans two health training and simulation facilities (CSTAR and HSERC).", "num_citations": "8\n", "authors": ["57"]}
{"title": "WikiDev 2.0: facilitating software development teams\n", "abstract": " Software development is fundamentally a collaborative task. Developers, sometimes geographically distributed, collectively work on different parts of a project. The challenge of ensuring that their contributions consistently build on one another is a major concern for collaborative development and implies concerns with effective communication, task administration and exchange of documents and information concerning the project. In this demo, we present WikiDev 2.0, a lightweight wiki-based tool suite that enhances collaboration within software development teams. WikiDev 2.0 integrates information from multiple development tools and displays the results through its wikibased front-end. The tool also offers several analysis techniques and visualizations that improve the project-status awareness of the team.", "num_citations": "8\n", "authors": ["57"]}
{"title": "Building highly-interactive, data-intensive, REST applications: the Invenio experience\n", "abstract": " With the explosion of Web 2.0 ideas and technologies such as XML, REST, and RIAs (Rich Internet Applications), developers are now creating\" mashup\" applications that aggregate numerous sources of information and promote rich user interaction. Although many innovative mashups are being created, there has been little research systematically examining which technologies to use and how to design and implement such applications. We describe the features and complexity inherent within a data-intensive, REST-based, RIA entitled, Invenio. Invenio combines a variety of different technologies (Yahoo! Maps, Amazon Associates Web Service, REST, and the Flex framework) to geographically visualize aggregated music chart information. We report on our experiences in designing and authoring Invenio, use Invenio's requirements as a case study to examine relevant technologies and recommend a set of\u252c\u00e1\u0393\u00c7\u00aa", "num_citations": "8\n", "authors": ["57"]}
{"title": "Enwic: Visualizing wiki semantics as topic maps\n", "abstract": " In this paper, we present ENWiC (EduNuggets Wiki Crawler), a framework for intelligent visualization of Wikis. In recent years, e-learning has emerged as an appealing alternative to traditional teaching. The effectiveness of e-Learning is depended upon the sharing of information on the web, which makes the web a vast library of information that students and instructors can utilize for educational purposes. Wiki\u0393\u00c7\u00d6s collaborative authoring nature makes it a very attractive tool to use for e-Learning purposes; however, its text-based navigational structure becomes insufficient as the Wiki grows in size, and this backlash can hinder students from taking full advantage of the information available. ENWiC\u0393\u00c7\u00d6s goal is to provide student with an intelligent interface for navigating Wikis and other similar large-scale websites. ENWiC make use of graphic organizers to visualize the relationships between content pages so that students can gain a cognitional understanding of the content as they navigating through the Wiki pages. We describe ENWiC\u0393\u00c7\u00d6s automated visualization process, and its user interfaces for students to view and navigate the Wiki in a meaningful manner, and for instructors to further enhance the visualization. We also discuss our usability study for evaluating ENWiC\u0393\u00c7\u00d6s effectiveness as a Wiki Interface.", "num_citations": "8\n", "authors": ["57"]}
{"title": "Conversation errors in web service coordination: Run-time detection and repair\n", "abstract": " Organizations that own Web services participating in a workflow composition may evolve their components independently. Service coordination can fail when previously legal messages between independently changing, distributed components become illegal because their respective workflow models are no longer synchronized. This paper presents an intelligent-agent framework that wraps a Web service in a conversation layer and a simple workflow-adaptation function. The conversation layer implements protocols and consults globally shared, declarative policy specifications to resolve interaction failures. The framework allows agents to resolves various model mismatches that cause interaction errors, including changes to required preconditions, partners, and expected message ordering. Implications of this distributed approach to Web service coordination are also discussed.", "num_citations": "8\n", "authors": ["57"]}
{"title": "Towards mentoring object-oriented evolutionary development\n", "abstract": " Object-oriented software is increasingly developed using an evolutionary development process model. Therefore, capturing and understanding the evolution that the system\u0393\u00c7\u00d6s logical design has gone through can provide valuable insights in support of consistently maintaining and evolving the system, without compromising the integrity and stability of its architecture. In this paper, we present a method for capturing and analyzing the design evolution of object-oriented software systems. This method relies on UMLDiff, a heuristic UML-structure differencing algorithm, which, given a sequence of UML class models corresponding to the logical design of a sequence of system code releases, produces a sequence of \u0393\u00c7\u00a3change records\u0393\u00c7\u00a5 that describe the design-level structural changes between subsequent system releases. Various design evolution patterns are then analyzed to reveal the rationale underlying design decisions that may affect the software system. The recovered knowledge about the system\u0393\u00c7\u00d6s logic design evolution enables the overall understanding of system design evolution and provides the basis for mentoring the developers on future maintainance activities. We report on one real world case study evaluating our approach.", "num_citations": "8\n", "authors": ["57"]}
{"title": "Towards Rule-Based Model Checking of Building Information Models\n", "abstract": " Designing a building, so that it adheres to all the relevant applicable constraints imposed by construction codes to cultural preferences to the owners' styles and aesthetics, can be a daunting task, requiring many laborious hours of review and modification. Given the increasing adoption of Building Information Modeling (BIM) in the design process, automated model checking is a pragmatic approach to expeditiously identifying errors that may otherwise cause issues later in the building phase. A variety of methods have been proposed, but they are opaque regarding the rules they consider, and they do not allow users to edit these rules. In this paper, we describe a simple, yet extendible, language for specifying building rules and a method for evaluating these rules in the context of a BIM instance, in order to assess the compliance of the building with these rules.", "num_citations": "7\n", "authors": ["57"]}
{"title": "Augmented reality on building information models\n", "abstract": " Augmented Reality (AR) is emerging as a technology with a multitude of applications in education and entertainment. In this paper, we discuss its potential in visualizing the information captured in Building Information Models (BIMs). To date, BIM-enabled applications have been limited to desktops running proprietary building-design software; cloud platforms, however, enable the usage allows for of BIM models through any device, including mobile ones. Therefore, AR applications can use the geometric information of the BIM models for accurate scene rendering and also for augmenting the scene with additional information relevant to different stakeholders. To demonstrate this concept, we have developed a mobile-application prototype. The application downloads a BIM model from a remote server and superimposes it on the camera feed. To ensure the modeled and real world objects are synced, image tracking\u252c\u00e1\u0393\u00c7\u00aa", "num_citations": "7\n", "authors": ["57"]}
{"title": "Indoor Localization: A Cost-Effectiveness vs. Accuracy Study\n", "abstract": " Recognizing the occupants movement and locations within a home is a basic functionality, underlying a variety of smart-home services, including energy management, ambient environment control, and assistive-living services for seniors and people with disabilities. The outdoor-localization variant of the problem is effectively addressed with the use of GPS; however, GPS does not work well inside buildings, which makes the indoor positioning problem a very active research topic. In this paper, we report on a study of the indoor-localization problem, relying on easy-to-deploy, inexpensive, BLE-enabled stickers and beacons and WiFi access points.", "num_citations": "7\n", "authors": ["57"]}
{"title": "A novel approach to virtual patient simulation using natural language processing.\n", "abstract": " A novel approach to virtual patient simulation using natural language processing. - Abstract - Europe PMC Sign in or create an account https://orcid.org Europe PMC Menu About About Europe PMC Funders Joining Europe PMC Governance Roadmap Outreach Tools Tools overview ORCID article claiming Journal list Grant finder External links service RSS feeds Annotations Annotations submission service Developers Developer resources Articles RESTful API Grants RESTful API API use cases SOAP web service Annotations API OAI service Bulk downloads Developers Forum Help Help using Europe PMC Search syntax reference Contact us Contact us Helpdesk Feedback Twitter Blog Tech blog Developer Forum Europe PMC plus Search worldwide, life-sciences literature Search Advanced Search Recent history Saved searches Abstract Full text References A novel approach to virtual patient simulation using . A, \u0393\u00c7\u00aa", "num_citations": "7\n", "authors": ["57"]}
{"title": "Sensor placement for indoor multi-occupant tracking\n", "abstract": " We consider the problem of localizing and tracking multiple occupants in an indoor space, where the occupants are tagged with RFID tags and the space is embedded with anonymous (Passive Infrared, PIR) motion sensors and identity (RFID reader) sensors. Our localization method uses the RFID readings to disambiguate the occupants' trajectories recognized by the motion sensors. Due to their high cost and generally cumbersome placement requirements, RFID readers must be judiciously placed; in this paper, we study the placement of the readers such that the occupants' trajectory ambiguity is reduced. We rely on a heatmap representing the frequency with which individuals visit locations as they move through the indoor space and on models of coverage for the PIR sensors and RFID readers and develop a heuristic for the RFID reader placement. We demonstrate the effectiveness of our method via simulations.", "num_citations": "7\n", "authors": ["57"]}
{"title": "A hierarchical security-auditing methodology for cloud computing\n", "abstract": " Security concerns are frequently mentioned among the reasons why organizations hesitate to adopt cloud computing. Given the numerous choices of cloud-resource providers, clients often find it difficult to assess their relative advantages and shortcomings with respect to security, which may prevent them from making any choice. In this paper, we describe our methodology for a hierarchical security-audit method for cloud-computing services. Our method examines the overall security of the cloud offering, based on the examination of a comprehensive set of security concerns at the IaaS, PaaS, and SaaS layers. For each layer, relevant evidence regarding its security is collected and subsequently synthesized into an overall security score. We illustrate our method through a case study, examining the relative security merits of the Google Cloud and the Microsoft Azure Cloud.", "num_citations": "7\n", "authors": ["57"]}
{"title": "Chaintracker: Towards a comprehensive tool for building code-generation environments\n", "abstract": " Code-generation environments have emerged as a new mechanism for building software systems in a systematic manner. At their core, model-driven engineering technologies such as model-to-model and model-to-text transformations are effectively used to build generation engines. However, due to the complexity of model-to-model and model-to-text transformation scripts, which is exacerbated as they are composed in complex transformation chains, developers face technical and cognitive challenges when architecting, implementing, and maintaining code-generation environments. In this paper we present Chain Tracker, a visualization and trace analysis tool for model-to-model and model-to-text transformation compositions. Chain Tracker aims to support developers of code-generation environments by making the usage of model-driven engineering technologies more efficient, less error prone, and less\u252c\u00e1\u0393\u00c7\u00aa", "num_citations": "7\n", "authors": ["57"]}
{"title": "Mobili-t: A mobile swallowing-therapy device: An interdisciplinary solution for patients with chronic dysphagia\n", "abstract": " Swallowing impairments, or dysphagia, can lead to serious health problems and psychosocial concerns. Effective treatment can be enhanced with the use of adjuvant visual biofeedback from surface electromyography (sEMG) to monitor muscle movement during intensive swallowing exercises. However, access to this therapy is currently possible only in a clinical setting, and is therefore restricted due to limited clinical capacity and technology costs. In this paper, we describe the concept for a new hardware-and-software mobile system for swallowing therapy: Mobili-T. The system, designed by an interdisciplinary team of biomedical engineers, clinicians, and industrial designers, will help patients with dysphagia go through their rehabilitation regimens at home.", "num_citations": "7\n", "authors": ["57"]}
{"title": "Backward propagation of code refinements on transformational code generation environments\n", "abstract": " Transformational code generation is at the core of generative software development. It advocates the modeling of common and variable features in software-system families with domain-specific languages, and the specification of transformation compositions for successively refining the abstract domain models towards eventually enriching them with execution semantics. Thus, using code-generation environments, families of software systems can be generated, based on models specified in high-level domain languages. The major advantage of this software-construction methodology stems from the fact that it enables the reuse of verified execution semantics, derived from domain models. However, like all software, once an implementation is generated, it is bound to evolve and manually refined to introduce features that were not captured by its original generation environment. This paper describes a conceptual\u252c\u00e1\u0393\u00c7\u00aa", "num_citations": "7\n", "authors": ["57"]}
{"title": "Understanding individual contribution and collaboration in student software teams\n", "abstract": " Software development is an inherently team-based activity, and many software-engineering courses are structured around team projects, in order to provide students with an authentic learning experience. The collaborative-development tools through which student developers define, share and manage their tasks generate a detailed record in the process. Albeit not designed for this purpose, this record can provide the instructor with insights into the students' work, the team's progress over time, and the individual team-member's contributions. In this paper, we describe an analysis and visualization toolkit that enables instructors to interactively explore the trace of the team's collaborative work, to better understand the team dynamics, and the tasks of the individual team developers. We also discuss our grounded-theory analysis of one team's work, based on their email exchanges, questionnaires and interviews. Our\u252c\u00e1\u0393\u00c7\u00aa", "num_citations": "7\n", "authors": ["57"]}
{"title": "Interface-and usage-aware service discovery\n", "abstract": " To date, research on web-service discovery has followed the traditional component-discovery methodology and has examined signature matching, specification matching and information retrieval approaches, based on the interface description and documentation captured in WSDL. WSDL specifications, however, can be information poor, with standard data types, unintuitive identifiers for data, messages and operations and little naturallanguage documentation. The nature of the usage of the WSDL elements in the context of a BPEL composition can be an extremely useful source of information in the context of service discovery. In this paper, we discuss our method for service discovery based on interface and usage matching, exploiting the information captured in the WSDL and BPEL specifications. Our approach views both WSDL and BPEL as hierarchical structures and uses tree alignment to compare them in order to assess their similarity and to recognize the correspondences between their elements. We illustrate our method with two example scenarios.", "num_citations": "7\n", "authors": ["57"]}
{"title": "Supporting the deployment of object-oriented frameworks\n", "abstract": " Although they are intended to support and encourage reuse, Object-Oriented application frameworks are difficult to use. The architecture and implementation details of frameworks, because of their size and complexity, are rarely fully understood by the developers that use them. Instead, developers must somehow learn just enough about the parts of the framework required for their task. Faced with a framework problem, the developer will ask for assistance or muddle through using a trial-and-error approach. In many cases, they will not learn what the framework designer had in mind as the proper solution to their problem, and thus misuse the framework.               This paper is a preliminary look at the kinds of problems faced by framework users, and how the framework developer can assist in mitigating these problems. Our goal is to develop mechanisms for detecting when the framework user has violated the\u252c\u00e1\u0393\u00c7\u00aa", "num_citations": "7\n", "authors": ["57"]}
{"title": "Vocabulary and time based bug\u0393\u00c7\u00c9assignment: A recommender system for open\u0393\u00c7\u00c9source projects\n", "abstract": " Bug\u0393\u00c7\u00c9assignment (BA), the task of ranking developers in terms of the relevance of their expertise to fix a new bug report is time consuming, which is why substantial attention has been paid to developing methods for automating it. In this article, we describe a new BA approach that relies on two key intuitions. Similar to traditional BA methods, our method constructs the expertise profile of project developers, based on the textual elements of the bugs they have fixed in the past; unlike traditional methods, however, our method considers only the programming keywords in these bug descriptions, relying on Stack Overflow\u252c\u00e1as the vocabulary for these keywords. The second key intuition of our method is that recent expertise is more relevant than past expertise, which is why our method weighs the relevance of a developer's expertise based on how recently they have fixed a bug with keywords similar to the bug at hand. We\u252c\u00e1\u0393\u00c7\u00aa", "num_citations": "6\n", "authors": ["57"]}
{"title": "Multi-aspect review-team assignment using latent research areas\n", "abstract": " Reviewer assignment is an important task in many research-related activities, such as conference organization and grant-proposal adjudication. The goal is to assign each submitted artifact to a set of reviewers who can thoroughly evaluate all aspects of the artifact\u0393\u00c7\u00d6s content, while, at the same time, balancing the workload of the reviewers. In this paper, we focus on textual artifacts such as conference papers, where both (aspects of) the submitted papers and (expertise areas of) the reviewers can be described with terms and/or topics extracted from the text. We propose a method for automatically assigning a team of reviewers to each submitted paper, based on the clusters of the reviewers\u0393\u00c7\u00d6 publications as latent research areas. Our method extends the definition of the relevance score between reviewers and papers using the latent research areas information to find a team of reviewers for each paper, such that each\u252c\u00e1\u0393\u00c7\u00aa", "num_citations": "6\n", "authors": ["57"]}
{"title": "End-to-end model-transformation comprehension through fine-grained traceability information\n", "abstract": " The construction and maintenance of model-to-model and model-to-text transformations pose numerous challenges to novice and expert developers. A key challenge involves tracing dependency relationships between artifacts of a transformation ecosystem. This is required to assess the impact of metamodel evolution, to determine metamodel coverage, and to debug complex transformation expressions. This paper presents an empirical study that investigates the performance of developers reflecting on the execution semantics of model-to-model and model-to-text transformations. We measured the accuracy and efficiency of 25 developers completing a variety of traceability-driven tasks in two model-based code generators. We compared the performance of developers using ChainTracker, a traceability analysis environment developed by our team, and that of developers using Eclipse Modeling. We\u252c\u00e1\u0393\u00c7\u00aa", "num_citations": "6\n", "authors": ["57"]}
{"title": "Real-time traffic-based routing, based on open data and open-source software\n", "abstract": " The emergence of cloud computing and the Internet of Things (IoT) have given rise to a wealth of new opportunities for integrating heterogeneous systems and collecting massive data sets, whose analysis may lead to new information, insight, and knowledge. Building a scalable architecture for urban IoT environments is a complex task, primarily because of the massive amounts of data generated by sensor devices, and the variety of data sources. And yet it is a compelling application area, given the number of potential municipal services that can be improved using these technologies. In this paper, we describe our study of how cloud-computing and big-data management technologies can assist decision making for transportation systems in smart cities. More specifically, this paper presents and discusses a proof-of-concept prototype, based on open-source technologies and publicly available data for the city of\u252c\u00e1\u0393\u00c7\u00aa", "num_citations": "6\n", "authors": ["57"]}
{"title": "WSMeta: a meta-model for web services to compare service interfaces\n", "abstract": " With the increasing adoption of the web-services stack of standards, service-oriented architecture has attracted substantial interest from the research community which has produced several languages and methods for describing and reasoning about services. These languages cover many concepts ranging from individual services and their code generation from specifications, service semantics, service compositions and networks, economics and business aspects around service ecosystems etc. However, this abundance of specification languages has also resulted in communication difficulties between stakeholders and hinders tasks such as service composition, discovery and maintenance. The presented work is a step towards the unification of the specifications and different aspects of service systems using Model-Driven Engineering. We propose a generic and abstract web service meta-model called WSMeta\u252c\u00e1\u0393\u00c7\u00aa", "num_citations": "6\n", "authors": ["57"]}
{"title": "Sensors as an evaluative tool for independent living\n", "abstract": " Now more than ever, the design of systems and devices for effective and safe healthcare delivery has taken center stage. And the importance of human factors and ergonomics in achieving this goal can't be ignored. Underlining the utility of research in achieving effective design, Advances in Human Aspects of Healthcare discusses how human factors anABSTRACT", "num_citations": "6\n", "authors": ["57"]}
{"title": "\u0393\u00c7\u00a3Smart Traffic\u0393\u00c7\u00a5: an IoT traffic monitoring system based on open source technologies on the cloud\n", "abstract": " The constantly increasing importance of cloud computing and Internet of Things (IoT) has led to solutions able to integrate heterogenous and diverse systems as well manage big data. This is especially true in Smart City environments with respect to traffic monitoring. Furthermore, cloud computing, and the various technologies around it are quickly becoming a must in the education domain. Unlike traditional education, it promotes the use of computing infrastructures anywhere and at any time, without restrictions. In this paper, we present our experience in using cloud computing technologies for a computing science course on Software Quality, with fourth-year undergraduate students at the University of Alberta, Canada. In particular, the paper illustrates how students have been actively involved in carrying out a real project and coordinated their project work among the class groups thanks to cloud technologies\u252c\u00e1\u0393\u00c7\u00aa", "num_citations": "5\n", "authors": ["57"]}
{"title": "From relations to multi-dimensional maps: A SQL-to-hbase transformation methodology\n", "abstract": " In this paper, we describe a methodology for migrating applications relying on relational databases to HBase backends. Our methodology includes (a) a SQL-to-HBASE data-schema migration step, and (b) a transformation of the application SQL queries to equivalent sequences of HBase API calls. Our data-schema migration method relies on a set of HBase-organization guidelines to drive a four-step data-schema transformation process. Some of these guidelines are query-agnostic: we defined them based on related literature regarding the desired properties of the HBase organization. Other guidelines are query-aware: we formulated them to incorporate data-access paths, extracted from query logs, in order to improve the quality of the transformation and the eventual access efficiency of the HBase repository. Our transformation method maintains a mapping between source and target schema that is used to create\u252c\u00e1\u0393\u00c7\u00aa", "num_citations": "5\n", "authors": ["57"]}
{"title": "A grammar-based framework for rehabilitation exergames\n", "abstract": " Numerous serious exergames advocate the use of engaging avatars to motivate a consistent exercise regimen. However, the process of specifying the prescribed exercise, implementing it as avatar animation, and developing an accurate feedback-providing mechanism is complex and requires a high level of expertise in game engines, control languages, and hardware devices. Furthermore, in the context of rehabilitation exergames, the requirements for accurate assessment and timely and precise feedback can be quite stringent. At the same time, the Kinect\u252c\u00e1motion-capture sensor offers a natural interface to game consoles, and its affordability and wide availability represents a huge opportunity for at-home exergames. In this paper, we describe our work towards a system that envisions to simplify the process of developing rehabilitation exergames with Kinect. The system relies on a language for\u252c\u00e1\u0393\u00c7\u00aa", "num_citations": "5\n", "authors": ["57"]}
{"title": "Federating web-based applications on a hierarchical cloud\n", "abstract": " Cloud-based infrastructures enable applications to collect and analyze massive amounts of data. Sometimes these applications are the product of green-field engineering, but frequently they are the product of the evolution of traditional RDBMS-based implementations. In any case, NoSQL databases, endowed with high availability, elasticity and scalability through their easy deployment on cloud-computing platforms, have become an attractive data-storage solution for these big-data applications. Unfortunately, to date, there is little methodological and tool support for migrating existing applications to these new platforms. In this paper, we describe a hybrid architecture for location-aware applications on hierarchical cloud, a methodology for mapping relational (including spatio-temporal) data to HBase, and a process for migrating legacy applications to the new architecture.", "num_citations": "5\n", "authors": ["57"]}
{"title": "Interactive exploration of collaborative software-development data\n", "abstract": " Modern collaborative software-development tools generate a rich data record, over the lifecycle of the project, which can be analyzed to provide team members and managers with insights into the performance and contributions of individual members and the overall team dynamic. This data can be analyzed from different perspectives, sliced and diced across different dimensions, and visualized in different ways. Frequently the most useful analysis depends on the actual data, which makes the design of single authoritative visualization a challenge. In this paper we describe an analysis and visualization tool that supports the flexible run-time mapping of such a data record to a number of alternative visualizations. We have used our framework to analyze and gain an understanding of how individuals work within their teams and how teams differ in their work on these term projects.", "num_citations": "5\n", "authors": ["57"]}
{"title": "Smart-phone application design for lasting behavioral changes\n", "abstract": " The Smart-Condo interdisciplinary team (including computing science, industrial design, health psychology and occupational therapy) conducts research on putting ICT in the service of health care, focusing on empowering individuals to take control of their health management. This past year, the focus of our activities has been the development of a framework for the design and development of mobile apps to encourage behavioral changes. Grounding our framework the Theory of Planned Behavior and the Intention-Behavior Gap Theory, we explicitly designed all the functions in our applications to influence behavior. From a technical perspective, the applications support personalization, easy data recording and interactive reviewing, and subtle interventions (reminders and personalized information) to help behavior change. The user interface, informed by design theory, is conceived to make the applications\u252c\u00e1\u0393\u00c7\u00aa", "num_citations": "5\n", "authors": ["57"]}
{"title": "Maintaining and evolving service level agreements: Motivation and case study\n", "abstract": " Inter-organization service-oriented compositions are governed by Service Level Agreements (SLAs). While the software is maintained and evolved in response to changing business requirements or technology, the governing SLA and software configuration designed to meet this SLA do not always change in step. SLAs are negotiated and may have legal standing, which makes their maintenance expensive and time consuming. If an SLA is established that meets the requirements of the service consumer, changing the software without updating the configuration and/or the SLA may result in unmet requirements and reduced satisfaction. This paper begins by examining the business perspective on SLAs as a guide and motivation to maintaining SLAs. A simulation-driven approach to updating a configuration in step with ongoing maintenance efforts is presented. The approach is illustrated using a case study, where\u252c\u00e1\u0393\u00c7\u00aa", "num_citations": "5\n", "authors": ["57"]}
{"title": "WikiDev 2.0: Web-based software team collaboration\n", "abstract": " Most software development today is a team activity. Project team members collaboratively work on the tasks necessary to accomplish the various project milestones. The work is usually asynchronous, i.e., not orchestrated by an explicit workflow, some times geographically distributed, and involves the use of a variety of tools which do not always interoperate. Version-control repositories are essential in supporting this collaboration but cannot satisfactorily address the problem of traceability of interdependencies among the artifacts produced by the individual tools. In this demo, we present a new collaboration tool, WikiDev 2.0, that proposes to address these problems by adopting a wiki as the central platform in which to integrate information about the various artifacts of interest and to present views on this information that cut across the individual tool boundaries. We believe that WikiDev 2.0 will advance the degree of\u252c\u00e1\u0393\u00c7\u00aa", "num_citations": "5\n", "authors": ["57"]}
{"title": "Towards experience-based mentoring of evolutionary development\n", "abstract": " Object-oriented software is usually developed through evolutionary processes. To consistently evolve a system, developers have to understand the rationale behind its current design and the evolution trajectory that has led to it. In this paper, we present a method for analyzing the design evolution of object-oriented software systems, for the purpose of providing relevant advice to developers. This method relies on UMLDiff, a heuristic UML-structure differencing algorithm, which, given a sequence of UML class models corresponding to the logical design of a sequence of system code versions, produces a sequence of \"change trees\" that describe the design-level structural changes between subsequent system versions. A set of design-evolution patterns are then analyzed to understand the rationale underlying design decisions that may affect the software system. We demonstrate how the recovered knowledge\u252c\u00e1\u0393\u00c7\u00aa", "num_citations": "5\n", "authors": ["57"]}
{"title": "Advances in Artificial Intelligence: 14th Biennial Conference of the Canadian Society for Computational Studies of Intelligence, AI 2001 Ottawa, Canada, June 7-9, 2001 Proceedings\n", "abstract": " AI 2001 is the 14th in the series of Arti cial Intelligence conferences sponsored by the Canadian Society for Computational Studies of Intelligence/Soci et e-nadienne pour l\u0393\u00c7\u00d6etude de l\u0393\u00c7\u00d6intelligence par ordinateur. As was the case last year too, the conference is being held in conjunction with the annual conferences of two other Canadian societies, Graphics Interface (GI 2001) and Vision Int-face (VI 2001). We believe that the overall experience will be enriched by this conjunction of conferences. This year is the\\silver anniversary\" of the conference: the rst Canadian AI conference was held in 1976 at UBC. During its lifetime, it has attracted Canadian and international papers of high quality from a variety of AI research areas. All papers submitted to the conference received at least three indep-dent reviews. Approximately one third were accepted for plenary presentation at the conference. The best paper of the conference will be invited to appear in Computational Intelligence.", "num_citations": "5\n", "authors": ["57"]}
{"title": "Babel: Application Integration through XML specification of Rules\n", "abstract": " One of the major problems in developing E-commerce services is the divergence between the data and control-ofprocessing models that the existing applications, on which these services are being developed, assume. Even when related applications are aggregated in so-called portals, they usually do not interoperate but are simply linked through a single index web page. It is up to the user of the portal to access different applications, collect information, and then combine this information to access yet other applications.There has already been work on integrating existing data resources, such as MIX [2] and CQ [3]. Both these projects focus on query planning over multiple sources of data to answer complex user\u0393\u00c7\u00d6s questions (in the case of MIX) or to continuously monitor these resources in order to generate alarms of interest to the user (in the case of CQ).", "num_citations": "5\n", "authors": ["57"]}
{"title": "Babel: Representing business rules in XML for application integration\n", "abstract": " In this paper, we discuss Babel, a prototype tool for integrating multiple heterogeneous applications, by wrapping them and by specifying the logic of their interoperation in XML.", "num_citations": "5\n", "authors": ["57"]}
{"title": "Guidelines for evaluating bug\u0393\u00c7\u00c9assignment research\n", "abstract": " Bug assignment is the task of ranking candidate developers in terms of their potential competence to fix a bug report. Numerous methods have been developed to address this task, relying on different methodological assumptions and demonstrating their effectiveness with a variety of empirical studies with numerous data sets and evaluation criteria. Despite the importance of the subject and the attention it has received from researchers, there is still no unanimity on how to validate and comparatively evaluate bug\u0393\u00c7\u00c9assignment methods and, often times, methods reported in the literature are not reproducible. In this paper, we first report on our systematic review of the broad bug\u0393\u00c7\u00c9assignment research field. Next, we focus on a few key empirical studies and review their choices with respect to three important experimental\u0393\u00c7\u00c9design parameters, namely, the evaluation metric(s) they report, their definition of who the real\u252c\u00e1\u0393\u00c7\u00aa", "num_citations": "4\n", "authors": ["57"]}
{"title": "AHL: model-driven engineering of android applications with BLE peripherals\n", "abstract": " Today, an increasing number of \u0393\u00c7\u00a3smart devices\u0393\u00c7\u00a5 are becoming available to consumers, enabling them to quantify their physical activity and health status and to receive updates from their environment and applications. The preferred method of tethering these devices to the Internet is through the BLE (Bluetooth Low Energy) communication protocol connecting them to special-purpose mobile applications. The efficient development of high-quality applications of this type can present challenges to developers who have to familiarize themselves with a number of new technologies and platform-specific architectural patterns. A combination of domain-specific languages and code-generation techniques is a potential solution to this problem.               In this paper, we present (a) a generic reference architecture for Android BLE-enables applications, and (b) our AHL (Android Health Language), a domain-specific\u252c\u00e1\u0393\u00c7\u00aa", "num_citations": "4\n", "authors": ["57"]}
{"title": "Software evolution in web-service ecosystems: A game-theoretic model\n", "abstract": " Service orientation is the prevalent paradigm for modular distributed systems, giving rise to service ecosystems defined by software dependencies, which, at the same time, carry business and economic implications. And as software evolves, so do the business relationships among the ecosystem participants, with corresponding economic impact. Therefore, a more comprehensive model of software evolution is necessary in this context, to support the decision-making processes of the ecosystem participants. In this work, we view the ecosystem as a market environment, with providers offering competing services and developing these services to attract more clients by better satisfying their requirements. Based on an economic model for calculating the costs and values associated with service evolution, we develop a game-theoretic model to capture the interactions between providers and clients and support the\u252c\u00e1\u0393\u00c7\u00aa", "num_citations": "4\n", "authors": ["57"]}
{"title": "Multi\u0393\u00c7\u00f4occupant movement tracking in smart home environments\n", "abstract": " Recognizing the movement and activities of an individual in an indoor space is a key functionality of smart homes, as a prerequisite to providing services in support of the occupant. Focusing on the particular case of smart homes with multiple occupants, we developed a location-and-movement recognition method using many inexpensive passive infrared (PIR) motion sensors and, a small number of, more costly RFID readers. In our method, PIR sensors, placed throughout the space, recognize movement while RFID readers, placed in key locations, recognize tags worn by individuals as they pass through their coverage area. The RFID readings are used to disambiguate the trajectories constructed based on PIR sensor readings. We evaluate through simulations the effectiveness of our method under different occupancy conditions.", "num_citations": "4\n", "authors": ["57"]}
{"title": "WL++: code generation of multi-platform mobile clients to RESTful back-ends\n", "abstract": " With the proliferation of mobile devices and the adoption of mobile applications in most daily-life activities, it is necessary for mobile-application construction to become more efficient and systematic and less costly. In this paper, we describe a code-generation environment, namely WL++, for mobile applications accessing Restful back-ends. Our framework (a) extracts the data models of the to-be-generated application from the back-end APIs or from existing resource schemas, (b) enables developers to extend the application model and annotate it with information regarding the application's user-interaction behavior through a graphical editor, and (c) transforms it into a mobile application, through a template-refinement process, that can be deployed on a variety of platforms.", "num_citations": "4\n", "authors": ["57"]}
{"title": "The WSDarwin Toolkit for Service-Client Evolution\n", "abstract": " As primarily modular and distributed architectures, service-oriented architectures may impose new challenges in software evolution. Since web services evolve independently, this may cause disruptions to the proper function of consuming software. In this paper, we present \\wsd, an Eclipse plug-in to support the evolution of service clients, including (a) identifying the differences between two service versions, (b) automatically adapting the client application to the new version, and (c) testing the client to confirm it functions properly.", "num_citations": "4\n", "authors": ["57"]}
{"title": "Software evolution in the presence of externalities: A game-theoretic approach\n", "abstract": " The architecture of service-oriented systems is defined by the services involved and the network of their usage interdependencies. Changes in an individual service may lead to the evolution of the overall architecture, as (a) different or new interactions may become possible and (b) existing partners may leave the network if their dependency needs are no longer satisfied. Therefore, studying the evolution of a service and the impact it may have on services and business partners that depend on it is essential to studying the evolution of software architecture in the age of service-oriented architecture (SOA). In such an environment with different and possibly independent parties, there may exist conflicting goals. For example, one party may aim for evolution, while another may desire stability. In this chapter, we model the interactions and decision-making process during the evolution of a system using a game-theoretic\u252c\u00e1\u0393\u00c7\u00aa", "num_citations": "4\n", "authors": ["57"]}
{"title": "Feature detection in ajax-enabled web applications\n", "abstract": " In this paper we propose a method for reverse engineering the features of Ajax-enabled web applications. The method first collects instances of the DOM trees underlying the application web pages, using a state-of-the-art crawling framework. Then, it clusters these instances into groups, corresponding to distinct features of the application. The contribution of this paper lies in the novel DOM-tree similarity metric of the clustering step, which makes a distinction between simple and composite structural changes. We have evaluated our method on three real web applications. In all three cases, the proposed distance metric leads to a number of clusters that is closer to the actual number of features and classifies web page instances into these feature-specific clusters more accurately than other traditional distance metrics. We therefore conclude that it is a reliable distance metric for reverse engineering the features of Ajax\u252c\u00e1\u0393\u00c7\u00aa", "num_citations": "4\n", "authors": ["57"]}
{"title": "The Smart-CondoTMInfrastructure and Experience\n", "abstract": " The term \u0393\u00c7\u00a3Smart Home\u0393\u00c7\u00a5 refers to a home equipped with sensors, which observe the environment and the actions of its occupants, and actuators, which automatically control the home ambience and devices. A Smart Home can provide a variety of services to its occupants, based on information gleaned from the data recorded by the sensors and using the automation afforded by the actuators. Our work in the Smart-CondoTM project has been motivated by healthcare concerns: we aim to support people with chronic conditions to live independently longer. To that end, our first objective has been to develop an accurate location- and activity-recognition method. In this paper, we describe the Smart-CondoTM middleware architecture, focusing on its occupant-localization feature. We report on simulation experiments with three sensor placements, one of which was deployed at a recent indoor localization\u252c\u00e1\u0393\u00c7\u00aa", "num_citations": "4\n", "authors": ["57"]}
{"title": "New Directions for Social Computing in Virtual Worlds: Applications for Business and Social Sciences\n", "abstract": " Virtual worlds, where thousands of people can interact simultaneously within the same three-dimensional space, represent a frontier in social computing with critical implications for business, education, social sciences, technological sciences, and our society at large. In this chapter, we first trace the history of virtual worlds back to its antecedents in electronic gaming and social computing. We then provide an overview of many leading virtual worlds, together with a taxonomy of virtual worlds, social computing, and electronic games in the context of virtual communities. As an example of one of the premier virtual worlds, we subsequently develop a detailed case study of Second Life, which includes a survey we conducted of 197 residents. Lastly, we provide a literature review of existing research in business, education, the social sciences, and the humanities, and identify a number of open questions.", "num_citations": "4\n", "authors": ["57"]}
{"title": "Bottom-up design evolution concern discovery and analysis\n", "abstract": " Software system grows in size and complexity as it evolves over time. The fact that object-oriented software is increasingly developed using an evolutionary development process makes the situation even worse. The developers face increasing difficulties in comprehending the system design and its rapid evolution, since the amount of information is overwhelming. Traditional top-down approach to software evolution understanding does not work very well to precisely capture the changes and their underlying motivations. In this paper, we present our bottom-up design-evolution analysis approach, implemented in the JDEvAn tool. The JDEvAn tool has been equipped with a suite of longitudinal and datamining analysis methods and a set of change-pattern detection queries to automatically recover the interesting core evolution concerns, such as sets of co-evolving classes or instances of refactorings, by aggregating elementary design changes into composite concerns. Given the key participants of an evolution concern, the JDEvAn Viewer allows developers to interactively explore the relevant elements, relations, and their changes over time so that they can incrementally build up their knowledge about what has been changed, how and why. We evaluate the effectiveness of JDEvAn with two case studies on realistic open-source objectoriented software, in the context of which we show how JDEvAn help us capture the completely different rationale for two pairs of seemingly similar evolution concerns.", "num_citations": "4\n", "authors": ["57"]}
{"title": "The space station operations control software: A case study in architecture maintenance\n", "abstract": " Software maintenance teams are often faced with the challenge of adapting a system's architecture in response to problem reports as well as new functional requirements. More often than not, these maintenance objectives can be accomplished either through the addition of alternative, \"patching\" components, or by refactoring the original architecture. The latter approach usually results in a simpler, more cohesive design that is more robust, easier to maintain, and therefore should be preferred. This paper presents a case study describing how the Space Station Operations Control Software (OCS) team has handled architectural change after the initial delivery of the system. In particular, the paper analyses two specific examples: the reaction of the maintenance team to a design problem discovered during testing, and the incorporation of a major new feature into the software design.", "num_citations": "4\n", "authors": ["57"]}
{"title": "Functional modeling meets meta-CASE tools for software evolution\n", "abstract": " The development of new software based on reuse and evolution of existing software can potentially save a lot of development effort, assuming that the reused artifact is modified in ways consistent with its original design. In this paper we discuss an on-going project, in which we adopt artificial intelligence formalisms and methods for modeling and redesign towards addressing this problem of software reuse and evolution. More specifically, we discuss the integration of Metaview, a meta-case tool, with Autognostic, an intelligent agent that is able to redesign a system, based on a model of its functional architecture.", "num_citations": "4\n", "authors": ["57"]}
{"title": "City on the river: visualizing temporal collaboration\n", "abstract": " Collaboration is an important component of most work activities. We are interested in understanding how configurations of people come together to create outputs over time. We propose an interactive visualization tool (City on the River) for visualizing collaborations over time. The City on the River (CotR) visualization shows the contributions and artifacts (\u0393\u00c7\u00a3products\u0393\u00c7\u00a5) of a team on a timeline and the individuals on the team who contributed to each product. CotR enables interactive analyses of each of these components for answering questions such as, which people work together on the most products, which products involve the most people, what kinds of products were produced when and by whom, etc. CotR can be used for analyzing diverse domains such as research collaborations, conference participation, email conversations, and software development. In this paper, we present the results of an experiment to assess CotR for analyzing collaboration and outcomes in GitHub projects. We compared the quality of answers, time to answer, and approaches taken to analyze the project collaborations by two groups of people: one group used the GitHub data displayed in a spreadsheet; the other group used the GitHub data displayed using CotR.", "num_citations": "3\n", "authors": ["57"]}
{"title": "Virtual-GymVR: A Virtual Reality Platform for Personalized Exergames\n", "abstract": " Virtual-Gym VR  is a platform for serious exergames in virtual reality. Its purpose is to provide older adults with a fun experience, while, at the same time, encouraging them to complete their personalized exercise sessions. The platform takes as input a description of a prescribed exercise, in terms of a posture-transition grammar, and constructs personalized versions of its games by accordingly configuring the behavior of the interactive objects in these games. The game-configuration process essentially controls the placement and the interaction behavior of the games' objects so that they induce the user to adopt the proper postures, as described by the input exercise specification. At run time, the sequence of game events stimulate the user to move to the prescribed exercise postures and, thus, accomplish their own personalized exercise goals. Given the intended user population of older adults, we have designed\u252c\u00e1\u0393\u00c7\u00aa", "num_citations": "3\n", "authors": ["57"]}
{"title": "Activity classification in independent living environment with JINS MEME Eyewear\n", "abstract": " The population of older adults relative to the total population is rising rapidly worldwide, and this contributes to an increased burden on healthcare systems. Older adults with complex needs are often limited in their ability to perform basic daily activities, and they may require task-specific supports. With continuous health-monitoring systems, the ability to recognize people's activities in their homes can enable automated assisted living systems, caregivers and clinicians to provide suitable adaptive care. With the advent of miniaturized sensing technology, which can be wearable, it is now possible to collect and store data on different aspects of human movement under realistic independent living conditions.In our most recent Smart Condo\u0393\u00e4\u00f3 study, twenty-six participants spent one two-hour session in the one-bedroom living environment, either alone or in pairs, and performed a scripted protocol of activities of daily\u252c\u00e1\u0393\u00c7\u00aa", "num_citations": "3\n", "authors": ["57"]}
{"title": "WL++: a framework to build cross-platform mobile applications and RESTful back-ends\n", "abstract": " About one in two adults and one in four teens own a smart phone in North America and use it to access online information and services. This, ever increasing, demand for mobile applications has given rise to the need for tools and methods to systematically support the design and construction of these applications. Responding to this need, we have developed WL++, a code-generation environment for mobile-application development. Using this tool, developers can create application-specific diagrams of the application's logical model and annotate them with information about the user-interface widgets appropriate for interacting with the model elements. WL++ then produces a relational back-end for storing the model data, a set of RESTful APIs for accessing and updating the back-end, and a multi-platform mobile application that relies on the IBM Worklight framework to render, interact with and store the relevant\u252c\u00e1\u0393\u00c7\u00aa", "num_citations": "3\n", "authors": ["57"]}
{"title": "Kaleidoscope: A cloud-based platform for real-time video-based interaction\n", "abstract": " Mobile video streaming becomes increasingly useful in a variety of contexts (social interaction, education and entertainment) and increasingly feasible with the rapid development of wireless networks and mobile technologies. In this thesis, we develop a platform for multimedia streaming on mobile devices, enhanced with textual and touch-display interactions for a rich user experience. Users (Senders) can use our Kaleidoscope mobile application to set up a streaming channel on the platform server, and invite their contacts (Receivers) to share their real-time video recordings. At the Sender site, the Kaleidoscope app captures the video and shares it with the streaming server. The streaming server saves the multimedia streams into files. At the Receiver site, the Kaleidoscope app replays the video. At both sites, users can send text messages to the connected peers and touch the display to point out interesting video scenes; the Kaleidoscope app shares these interactions with all the peers. The data (audio/video, text, touch events) is stored on the cloud server with timestamps to support feature extraction and analytic services on the cloud. We evaluated the Kaleidoscope system on the SAVI cloud at multiple locations, testing the CPU and memory usage of Kaleidoscope streaming server with different numbers of clients, in different locations. ii", "num_citations": "3\n", "authors": ["57"]}
{"title": "GitHub's big data adaptor: an eclipse plugin\n", "abstract": " The data of GitHub, the most popular code-sharing platform, fits the characteristics of\" big data\"(Volume, Variety and Velocity). To facilitate studies on this huge GitHub data volume, the GHTorrent web-site publishes a MYSQL dump of (some) GitHub data quarterly. Unfortunately, developers using these published data dumps face challenges with respect to the time required to parse and ingest the data, the space required to store it, and the latency of their queries. To help address these challenges, we developed a data adaptor as an Eclipse plugin, which efficiently handles this dump. The plugin offers an interactive interface through which users can explore and select any field in any table. After extracting the data selected by the user, the parser exports it in easy-to-use spreadsheets. We hope that using this plugin will facilitate further studies on the GitHub data as a whole.", "num_citations": "3\n", "authors": ["57"]}
{"title": "Evolutionary analysis of access control models: a formal concept analysis method\n", "abstract": " Access control is an essential feature of most software systems security mechanisms. Role-Based Access Control (RBAC), likely the most popular access control technique, specifies\" user roles\" and associates each role with\" permissions\" to access distinct system data and functionalities. The types of system users, ie, the\" roles\", the sensitive system functionalities accessed through\" permissions\", as well as the roles-permissions assignment rules evolve over time. In this paper, we discuss a methodology for analyzing and understanding the RBAC-evolution process and its relation to the overall evolutionary lifecycle of the system, motivated by the hypothesis that it may impact the overall system security. Our methodology relies on Formal Concept Analysis (FCA). First, we extract the roles-permissions matrix of each system version and we compute the implicit concept lattice. Next, we apply a suite of distance metrics\u252c\u00e1\u0393\u00c7\u00aa", "num_citations": "3\n", "authors": ["57"]}
{"title": "WSDarwin: A web application for the support of REST service evolution\n", "abstract": " REST has become a very popular architectural style for service-oriented systems, primarily due to its ease of use and flexibility. However, the lightweight nature of its syntax does not necessitate the use of systematic methods and tools. In this work, we argue that such tools can greatly facilitate complex engineering tasks, including service discovery and evolution. We present the WSDarwin set of tools to generate WADL interfaces for REST services, to compare service interfaces to identify differences between versions, and to compare service offerings of different vendors to facilitate service discovery and interoperability.", "num_citations": "3\n", "authors": ["57"]}
{"title": "Mapping the responses of RESTful services based on their values\n", "abstract": " The distributed nature of service-oriented architectures imposes some very interesting challenges to the participants of a service system, i.e., the provider and the client. For example, the service may change in a way that no longer satisfies the client's needs, either due to its reduced offered functionality or quality, due to its reduced availability or due to its increased price. In this case, the client may seek to replace the consumed service with another from a competitive provider. The client will also have the challenging task of mapping the elements of the old service to those of the new service, in order to apply the appropriate changes to the client application. In this work, we propose a novel approach to perform this mapping based on the data exchanged by the service and the application (i.e., the values of the input and the output parameters of the service). This technique allows us to avoid any potential ambiguities in\u252c\u00e1\u0393\u00c7\u00aa", "num_citations": "3\n", "authors": ["57"]}
{"title": "WSDARWIN: A Decision-Support Tool for Web-Service Evolution\n", "abstract": " Service-oriented systems are fundamentally distributed in nature, relying on external services accessible through their public interfaces. Distributed ownership and lack of implementation transparency imply special challenges in the evolution of such systems. In order to alleviate the challenge faced by the consumers of their services, providers should, in principle, take into account the impact that service changes may have on the client applications, in addition to considering the potential benefits to be gained from the evolution of these services. In this paper, we present a decision tree to support the provider's service-evolution decision-making process. Using game theory, we construct the tree that makes explicit the value-cost trade-offs involved in considering the potential evolution of services.", "num_citations": "3\n", "authors": ["57"]}
{"title": "Using Simulations to Integrate Technology into Health Care Aides\u0393\u00c7\u00d6 Workflow\n", "abstract": " Health care aides (HCAs) are critical to home care, providing a range of services to people with chronic conditions, aging or are unable to care for themselves independently. The current HCA supply will not keep up with this increasing demand without fundamental changes in their work environment. One possible solution to some of the workflow challenges and workplace stress of HCAs is hand-held tablet technology. In order to introduce the use of tablets with HCAs, simulations were developed. Once an HCA was comfortable with the tablet, a simulated client was introduced. The HCA interacted with the simulated client and used the tablet applications to assist with providing care. After the simulations, the HCAs participated in a focus group. HCAs completed a survey before and after the tablet training and simulation to determine their perception and acceptance of the tablet. Future deployment and\u252c\u00e1\u0393\u00c7\u00aa", "num_citations": "3\n", "authors": ["57"]}
{"title": "Campus mysteries: Serious walking around\n", "abstract": " The Campus Mysteries project developed an augmented reality game platform called fAR-Play and a learning game called Campus Mysteries with the platform. This paper reports on the development of the platform, the development of the game, and a assessment of the playability of the game. We conclude that augmented reality games are a viable model for learning and that the process of development is itself the site of learning.", "num_citations": "3\n", "authors": ["57"]}
{"title": "Communities, artifacts, interaction and contribution on the web\n", "abstract": " Today, most of us are members of multiple online communities, in the context of which we engage in a multitude of personal and professional activities. These communities are supported by different web-based platforms and enable different types of collaborative interactions. Through our experience with the development of and experimentation with three different such platforms in support of collaborative communities, we recognized a few core research problems relevant across all such tools, and we developed SociQL, a language, and a corresponding software framework, to study them.", "num_citations": "3\n", "authors": ["57"]}
{"title": "Migrating a legacy web-based document-analysis application to Hadoop and HBase: An experience report\n", "abstract": " Migrating a legacy application to a more modern computing platform is a recurring software-development activity. This chapter describes the authors\u0393\u00c7\u00d6 experience with a contemporary rendition of this activity, migrating a Web-based system to a service-oriented application on two different cloud software platforms, Hadoop and HBase. Using the case study as a running example, they review the information needed for a successful migration and examine the trade-offs between development/re-design effort and performance/scalability improvements. The two levels of re-design, towards Hadoop and HBase, require notably different levels of effort, and as the authors found through exercising the migrated applications, they achieve different benefits. The authors found that both redesigns led to substantial benefit in performance improvement, and that expending the additional effort required by the more complex migration\u252c\u00e1\u0393\u00c7\u00aa", "num_citations": "3\n", "authors": ["57"]}
{"title": "Incidental Learning and Salience in Virtual Worlds\n", "abstract": " The issue of how students learn in virtual worlds is one that needs to be explored. This study seeks to determine whether or not students can learn incidentally within virtual worlds and whether or not they are better at incidentally learning information that is presented in a salient format, or information presented in a non-salient format. 61 undergraduate students from the University of Alberta enrolled in introductory educational psychology courses participated in the study. Results showed that students were better at incidentally learning information if it was presented in a salient format as opposed to a non-salient format. Based on the findings, it is recommended that those who develop presentations and information for virtual worlds or virtual settings need to consider the manner in which it is presented and displayed.", "num_citations": "3\n", "authors": ["57"]}
{"title": "Automated state-space exploration for configuration management of service-oriented applications\n", "abstract": " Configuration management is a complex task, even for experienced system administrators, which makes self-managing systems a desirable solution. Self-management implies the need for a model based on which configuration changes may be decided. In previous work, we described a method for constructing a state-transition model of application behavior, by observing the application in simulation. This method relied on an expert to manage the (simulated) application in order to collect the necessary observations for constructing the model. However, that method was agnostic about (a) the size of the system space space as implied by the granularity of the observations, and (b) the sufficiency of the actual observations collected for understanding the application in a variety of configurations and environments. In this paper, we replace the (expensive) expert domain knowledge with automatic approaches to\u252c\u00e1\u0393\u00c7\u00aa", "num_citations": "3\n", "authors": ["57"]}
{"title": "Exploring and visualizing academic social networks\n", "abstract": " We demonstrate the ReaSoN portal, consisting of interactive web-based tools for visualizing, exploring, querying, and integrating academic social networks. We describe how these networks are automatically extracted from bibliographic and citation databases, discuss notions of visibility in such networks which enable a rich set of social network analysis, and demonstrate our novel tools for the visualization and exploration of social networks.", "num_citations": "3\n", "authors": ["57"]}
{"title": "Managing virtual world sessions for health science interprofessional education\n", "abstract": " To address the need for interprofessional communications training for health science students, we developed and tested a virtual world (Second Life) for the delivery of a mock patient interview session. Health science students enrolled in an interdisciplinary course were assigned to interprofessional teams drawn from nine different health science disciplines. With the guidance of a facilitator, students planned and enacted a patient admission conference and a discharge conference with a standardized patient and family member. Our best practices session will review \u0393\u00c7\u00a3lessons learned\u0393\u00c7\u00a5 centered around three aspects of the virtual learning context: a) Pre-session and in-session procedures for students, b) Pre-session and in-session procedures for facilitators, and c) Use of technologies and technical support to accomplish key activities within the session.", "num_citations": "3\n", "authors": ["57"]}
{"title": "Picos tuples: easing event based programming in tiny pervasive systems\n", "abstract": " The task of programming sensor-based systems comes with severe constraints on the resources, typically memory, CPU power, and energy. The challenge is usually addressed with techniques that result in poor code understandability and maintainability. In this paper, we report on a data centric language extension based on a tuple-space abstraction, akin to Linda [2], applied to PicOS [5], a programming environment for wireless sensor networks (WSN's). The extension improves state and context management in a multi-tasking environment suffering from severe memory limitations. The solution integrates tuple operations into the model--for networking, event handling, and thread contexts. We demonstrate how tuple constructs improve coding and reduce code overhead. We also show how thread's context-tuples can be used as interface arguments for extension by modular aspect constructs.", "num_citations": "3\n", "authors": ["57"]}
{"title": "SensorGIS-An Integrated Architecture for Information Systems based on Sensor Networks\n", "abstract": " In this paper, we describe SensorGIS, an integrated architecture for WSN applications. SensorGIS provides an integrated service-oriented architecture for collecting, archiving, analyzing, and visualizing sensor network data in a geographic information system (GIS). By using an extendible GIS framework as one of its user views, SensorGIS can contextually communicate the collected data, its trends, and distinct values of interest. In addition, it is designed in the service-oriented style and hence is extendible in terms of the analyses and visualizations. Finally, it integrates an online collaborative forum that enables annotation of the collected data with the users\u0393\u00c7\u00d6 observations and interpretations.", "num_citations": "3\n", "authors": ["57"]}
{"title": "Using interaction models to detect and resolve inconsistencies in evolving service compositions\n", "abstract": " Service-oriented architecture is emerging as a compelling paradigm for developing web-based software applications. According to this architectural style, the functional components of the system are implemented in various programming languages as network-accessible \u0393\u00c7\u00a3services\u0393\u00c7\u00a5 declaratively specified (in WSDL) and hierarchically composed in complex processes (using BPEL4WS). Despite this fundamentally distributed conceptualization of software architecture, most current BPEL4WS execution engines assume that the specification of the process composition is interpreted at run time by a central middleware node. This implies inflexible composition evolution: each time a partner process must be updated, all compositions to which it participates must also be updated to avoid potential failures at run time. This paper presents the WRABBIT project, which associates web services with agents capable of\u252c\u00e1\u0393\u00c7\u00aa", "num_citations": "3\n", "authors": ["57"]}
{"title": "The ViskiMap Toolkit: Extending Mediawiki with Topic Maps\n", "abstract": " In this paper, we present our ViskiMap systems, ENWiC (EduNuggets Wiki Crawler) and Annoki (Annotation wiki), for intelligent visualization of Wikis. In recent years, e-Learning has emerged as an appealing extension to traditional teaching. To some extent, the appeal of e-Learning derives from the great potential of information and knowledge sharing on the web, which has become a de-facto library to be used by students and instructors for educational purposes. Wiki\u0393\u00c7\u00d6s collaborative authoring nature makes it a very attractive tool to use for e-Learning purposes. Unfortunately, the web\u0393\u00c7\u00d6s text-based navigational structure becomes insufficient as the Wiki grows in size, and this backlash can hinder students from taking full advantage of the information available. The objective behind ViskiMap is to provide students with an intelligent interface for navigating Wikis and other similar large-scale websites. ViskiMap\u252c\u00e1\u0393\u00c7\u00aa", "num_citations": "3\n", "authors": ["57"]}
{"title": "Understanding Object-Oriented Architecture Evolution via Change Detection\n", "abstract": " Understanding the software architecture of a system and the process by which it has evolved to its current state is an important task that software developers are often faced with. It becomes relevant when one needs to assess a system for the purpose of adopting it in a new context, or to further develop it to meet new requirements and change requests. In this paper, we describe our work on analyzing and understanding the evolution of an objectoriented application at the class-design level. We introduce a structure-matching algorithm for comparing two or more versions of an architecture represented in UML (XMI). The algorithm produces a\" change tree\" that reports the differences of the compared versions in terms of class/field/method additions, deletions, moves, and renamings. Analysis of a series of change trees corresponding to a series of versions can reveal interesting and useful information about the evolution history of the application architecture, such as evolution styles, class evolution types, change patterns, etc. In this paper, we discuss the algorithm, the change-tree data structure, and the architecture-evolution analysis, and we report on two case studies evaluating our approach.", "num_citations": "3\n", "authors": ["57"]}
{"title": "Reflective collaborative agents for complex service integration\n", "abstract": " With the advent of more and more services available on the Web, a user can have a difficult job of assembling the various pieces of a complex task to arrive at a final solution. Not only would the user need to access each web-based resource through its individual client-side interface, but she would also need to interpret its response to her request, and to manually combine the multiple responses from the different resources to accomplish the complex task. In this paper, we discuss a multiagent, XML-based framework that supports the development of aggregate applications that rely on semantic-based reflective monitoring and collaboration among several agents to complete the user\u0393\u00c7\u00d6s task. Our framework makes use of declarative models of the domain information, the taskspecific information, and the semantic constraints of this information. Each agent uses these models to interact with the user, to coordinate the information exchange with the various web resources, to monitor and control the execution of the applications, and to take action when a failure is detected. When an agent detects a failure, it collaborates with other agents by distributing the tasks to those agents which are capable of completing the task, thus ensuring successful completion of the user\u0393\u00c7\u00d6s request. We illustrate our approach and the architecture of the aggregate applications that it produces using a bookbuying assistant as an example.", "num_citations": "3\n", "authors": ["57"]}
{"title": "Some Experimental Results in Multistrategy Navigation Planning\n", "abstract": " Spatial navigation is a classical problem in AI. In the paper, we examine three specific hypotheses regarding multistrategy navigation planning in visually engineered physical spaces containing discrete pathways: (1) For Hybrid robots capable of both deliberative planning and situated action, qualitative representations of topological knowledge are sufficient for enabling effective spatial navigation; (2) For deliberative planning, the case-based strategy of plan reuse generates plans more efficiently than the model-based strategy of search without any loss in the quality of plans or problem-solving coverage; and (3) For the strategy of model-based search, the \u0393\u00c7\u00a3principle of locality\u0393\u00c7\u00a5 provides a productive basis for partitioning and organizing topological knowledge. We describe the design of a multistrategy navigation planner called Router that provides an experimental testbed for evaluation the three hypotheses. We also describe the embodiment of Router on a mobile robot called Stimpy for testing the first hypothesis. Experiments with Stimpy indicate that this hypothesis apparently is valid for hybrid robots in visually engineered spaces containing discrete pathways such as office buildings. In addition, two different kinds of simulation experiments with Router indicate that the second and the third hypotheses are only partially correct. Finally, we relate the evaluation methods and experimental designs with the research hypotheses.", "num_citations": "3\n", "authors": ["57"]}
{"title": "Learning Language and Acoustic Models for Identifying Alzheimer's Dementia from Speech\n", "abstract": " Alzheimer\u0393\u00c7\u00d6s dementia (AD) is a chronic neurodegenerative illness that manifests in a gradual decline of cognitive function. Early identification of AD is essential for managing the ensuing cognitive deficits, which may lead to a better prognostic outcome. Speech data can serve as a window into cognitive functioning and can be used to screen for early signs of AD. This paper describes methods for learning models using speech samples from the DementiaBank database, for identifying which subjects have Alzheimer\u0393\u00c7\u00d6s dementia. We consider two machine learning tasks: (a)~binary classification to distinguish patients from healthy controls, and (b)~regression to estimate each subject\u0393\u00c7\u00d6s Mini-Mental State Examination (MMSE) score. To develop models that can use acoustic and/or language features, we explore a variety of dimension reduction techniques, training algorithms, and fusion strategies. Our best performing classification model, using language features with dimension reduction and regularized logistic regression, achieves an accuracy of 85.4\\% on a held-out test set. On the regression task, a linear regression model trained on a reduced set of language features achieves an RMSE of 5.62 on the test set. These results demonstrate the promise of using machine learning for detecting cognitive decline from speech in AD patients.", "num_citations": "2\n", "authors": ["57"]}
{"title": "Activity Recognition for Smart-Lighting Automation at Home\n", "abstract": " There is an undeniable movement to blur the line between everyday objects, infrastructure, and technology. We expect our daily interaction to be grounded in an intelligent system that adapts to its environment. Our homes are now becoming smarter through smart devices, such as televisions, speakers, light bulbs, and doors, connected through the Internet of Things, enabling increased home automation. In this paper, we describe a prototype system that analyzes an image of a living space to determine the activities of the occupants to control the lighting accordingly. Most available home-automation techniques require either explicit human control or rely on simple \u0393\u00c7\u00a3if this then that\u0393\u00c7\u00a5 routines, based on basic environmental conditions, such as temperature or time of day. Other home-automation systems use ambient sensors, placed throughout the home to recognize what the user is doing. In this paper, we present a\u252c\u00e1\u0393\u00c7\u00aa", "num_citations": "2\n", "authors": ["57"]}
{"title": "Second annual workshop on data driven knowledge mobilization\n", "abstract": " Knowledge mobilization and translation describes the process of moving knowledge from research and development (R&D) labs into environments where it can be put to use. There is increasing interest in understanding mechanisms for knowledge mobilization, specifically with respect to academia and industry collaborations. At the same time, the number of available datasets and accessible analysis tools is growing.", "num_citations": "2\n", "authors": ["57"]}
{"title": "Data-driven knowledge mobilization\n", "abstract": " Facing disruptions from new technologies, a culture of heavily-involved customers, and global markets, it is critical that knowledge organizations and research and development sites become more effective at innovating, growing new business and building and maintaining partnerships with private and public entities. Furthermore, addressing the complex problems of our time, eg, social, economic, health, and environmental challenges, requires the collaboration of experts from different fields and the merging of diverse knowledge from heterogeneous areas of expertise. Knowledge workers comprise a large proportion of the workforce today employed in the context of large scale expert networks, spanning across different disciplines and organizations.", "num_citations": "2\n", "authors": ["57"]}
{"title": "Service-Oriented Computing: 14th International Conference, ICSOC 2016, Banff, AB, Canada, October 10-13, 2016, Proceedings\n", "abstract": " This book constitutes the proceedings of the 14th International Conference on Service-Oriented Computing, ICSOC 2016, held in Banff, AB, Canada, in October 2016. The 30 full papers presented together with 18 short papers and 8 industrial papers in this volume were carefully reviewed and selected from 137 submissions. The selected papers covered important topics in the area of service-oriented computing, including foundational issues on service discovery and service-systems design, business process modelling and management, economics of service-systems engineering, as well as services on the cloud, social networks, the Internet of Things (IoT), and data analytics.", "num_citations": "2\n", "authors": ["57"]}
{"title": "coDNA: Visualizing peer production processes\n", "abstract": " Our demo for CSCW2015 is an information visualization tool designed to illustrate the temporal evolution of the peer production process. We combine comprehensive data extraction methods (automated, manual, machine learning) with user-friendly visualization techniques. Our visualization tool--coDNA--supports researchers in the development of grounded theory of peer production and allows practitioners to monitor production processes within their online community.", "num_citations": "2\n", "authors": ["57"]}
{"title": "Supporting Maintenance and Evolution of Access Control Models in Web Applications\n", "abstract": " This paper presents an approach to support the maintenance and evolution of Role-Based Access Control (RBAC) models with reverse-engineered Secure UML models. Starting from the Policy Decision Points (PDP) and Policy Enforcement Points (PEP) of an application, our approach statically reverse-engineers the implemented Secure UML model of an application. The secure UML model is then stored in an RDF triple store for easy querying and exploration. In the context of this study, we extracted the Secure UML model of the GRAND Forum, a web-based forum for the members of the GRAND (Graphics, Animation and New Media) NCE (Networks of Centers of Excellence), that is developed and maintained at the University of Alberta. Using three real use-case scenarios, we illustrate how simple queries to the extracted Secure UML can save developers significant amounts of manual work and support them in\u252c\u00e1\u0393\u00c7\u00aa", "num_citations": "2\n", "authors": ["57"]}
{"title": "Creating healthcare training simulations in virtual worlds\n", "abstract": " Virtual worlds offer a rich, flexible platform for creating immersive, interactive training simulations. In this paper, we describe two different platforms that rely on the same virtual world (OpenSim) to deliver different types of simulation-based learning experiences for health professionals.", "num_citations": "2\n", "authors": ["57"]}
{"title": "A framework for collaborative software development analytics\n", "abstract": " In this position paper we describe a conceptual model for analyzing collaborative software development for the purposes of (a) providing to the developers information which can effectively increase their awareness of their project status and support their development tasks, and (b) supporting its more effective management.", "num_citations": "2\n", "authors": ["57"]}
{"title": "Supporting a multidisciplinary digital media research community with GRAND aspirations\n", "abstract": " The challenges of managing a nationwide \u0393\u00c7\u00a3network of centres of excellence\u0393\u00c7\u00a5 (NCE) are being explored by GRAND, a Canadian NCE comprising over 350 researchers from technical disciplines, social sciences, humanities and the arts within 34 interwoven projects focusing on all aspects of digital media. A complex web of relationships with funding agencies, private and public partners, and researchers is being managed using a purpose-built web-based platform (the GRAND Forum) that supports communication and collaboration across communities. The Forum explicitly represents multiple roles of individuals within the organization through formal and informal user-centred workflows that reflect both symmetric (peer-to-peer) and asymmetric (hierarchical) organizational structures. We describe the principles of each.", "num_citations": "2\n", "authors": ["57"]}
{"title": "Video games for teaching and learning: game-building as a teaching tool\n", "abstract": " This presentation describes and showcases an undergraduate course that was designed to teach pre-service teachers to use game-building software in the classroom. The course advocates a constructionist approach to guide pre-service teachers in their use of such software with their own students. The course covers multimedia theory and gaming research in the lectures and uses Scratch, Kodu and OpenSim software for game-building projects.", "num_citations": "2\n", "authors": ["57"]}
{"title": "Configuration decision making using simulation-generated data\n", "abstract": " As service-oriented systems grow larger and more complex, so does the challenge of configuring the underlying hardware infrastructure on which their consitituent services are deployed. With more configuration options (virtualized systems, cloud-based systems, etc.), the challenge grows more difficult. Configuring service-oriented systems involves balancing a competing set of priorities and choosing trade-offs to achieve a satisfactory state. To address this problem, we present a simulation-based methodology for supporting administrators in making these decisions by providing them with relevant information obtained using inexpensive simulation-generated data. Our services-aware simulation framework enables the generation of lengthy simulation traces of the system\u0393\u00c7\u00d6s behavior, characterized by a variety of performance metrics, under different configuration and load conditions. One can design a variety\u252c\u00e1\u0393\u00c7\u00aa", "num_citations": "2\n", "authors": ["57"]}
{"title": "Visualizing relative wiki contributions\n", "abstract": " The past few years have seen a proliferation of collaborative writing and editing projects using wikis, which are a class of online tools designed for fast production and publication of digital text. The word \u0393\u00c7\u00a3wiki\u0393\u00c7\u00a5 is in fact from the Hawaiian word for \u0393\u00c7\u00a3fast.\u0393\u00c7\u00a5 The most well\u0393\u00c7\u00c9known wiki is arguably Wikipedia, but wikis are also widely used in educational and corporate settings (Majchrzak et al. 2006; Giordano 2007; Arazy et al. forthcoming). In these environments, the generally anonymous nature of wikis can be at odds with the requirement for receiving recognition for work, whether in the form of grades (in the context of education) or expert status (in the context of communities of practice).We have therefore been developing and testing a system for automatically determining and presenting the relative contribution of wiki authors (Arazy et al. working paper). A later phase has provided a statistical comparison of a set of manual ratings vs. these automated scores, which shows a good correlation with some interesting complexities. While wikis typically produce born\u0393\u00c7\u00c9digital text, rather than being implicated in the transition from the analog to the digital, they also provide an environment where new affordances for sense\u0393\u00c7\u00c9making can be made available to the author and reader, since the digital text as well as the logging records relating to the collaborative process itself become amenable to analysis and feedback in the form of interactive visualization.", "num_citations": "2\n", "authors": ["57"]}
{"title": "Babel: An XML-based application integration framework\n", "abstract": " One of the major problems in integrating independently developed applications is the divergence between the data and control-of-processing models assumed by these applications. Research on database integration has focused on establishing and maintaining a canonical schema on top of the schemas of the underlying databases. At the same time, web-accessible software systems have been adopting a multi-layer architecture style, with databases in the lowest tier, business logic in the middle tier and user interfaces in the top-most tier. However, as the time-to-market window shrinks, new software is presented with the challenge of reusing and integrating the functionalities of existing whole applications, instead of simply their database back-ends. The Babel framework provides support for specifying existing applications in terms of the functionalities they deliver and the data they manipulate. In addition\u252c\u00e1\u0393\u00c7\u00aa", "num_citations": "2\n", "authors": ["57"]}
{"title": "Compression of XML and JSON API Responses\n", "abstract": " Web services are the de-facto standard for implementing web-based systems today, and comprise message-based interactions involving XML and JSON documents. These formats can be quite verbose, especially XML, and therefore compression of such documents can potentially improve the communication efficiency and performance of service-oriented systems. In this paper, we review the various formulations of XML compression and propose a novel technique for the same, wherein large section of the documents are substituted by numerical representations. The approach is simple yet effective, especially on small documents that constitute the bulk of communicated content in web-based systems. We conduct experiments with several datasets and demonstrate that the proposed technique for XML compression outperforms the existing state-of-the-art techniques.", "num_citations": "1\n", "authors": ["57"]}
{"title": "Recognizing Emotional States With Wearables While Playing a Serious Game\n", "abstract": " In this study, we propose the use of electroencephalography (EEG), electrooculography (EOG), and kinematic motion data captured through wearable sensors to classify emotional states, while individuals are playing a serious computer game (Whack-a-Mole). Twenty-one participants wore an OpenBCI headset and JINS MEME eyewear while playing the Whack-a-Mole game at three levels of difficulty. We used a variety of classifiers [i.e., a support vector machine (SVM), logistic regression (LR), random forest (RF), and ensemble classifier (EC)] to classify the participants\u0393\u00c7\u00d6 emotional states based on their EEG, EOG, and kinematic motion data. The classifiers were trained using the International Affective Picture System (IAPS). The EC and RF showed the best results in terms of their overall performance. Using tenfold cross-validation for all the subjects, the accuracies obtained were 73% for Arousal and 80% for\u252c\u00e1\u0393\u00c7\u00aa", "num_citations": "1\n", "authors": ["57"]}
{"title": "Semantics-based API discovery, matching and composition with linked metadata\n", "abstract": " Web APIs have been adopted as the de facto standard for exchanging data on the Web. However, engineering applications that orchestrate the invocation of multiple APIs and the data flow among them are still mostly manual and labor intensive. In fact, as the number of the potentially relevant APIs increases, compositions become opaque, difficult to maintain, and practically impossible to reuse. The recent advances around linked data formalisms have the potential to provide \u0393\u00c7\u00a3usable\u0393\u00c7\u00a5 semantics, to enable automatic API composition methods. In this paper, we formalize a simplified description model, based on SPARQL graph patterns, for capturing the semantics of Web APIs. Based on this model, we propose a methodology for a fully automated process that produces semantically valid composition chains, using iterative subgraph isomorphism. We have validated the usefulness and accuracy of our approach, using\u252c\u00e1\u0393\u00c7\u00aa", "num_citations": "1\n", "authors": ["57"]}
{"title": "Designing an online interactive and bilingual 3D learning environment for human anatomy education\n", "abstract": " In the last decade, results from neuroscience research have influenced learning theories and, in turn, impacted how we design learning environments. This article presents the process of designing and developing for an interactive learning environment for human anatomy education anchored in neuroscience research. More specifically, and development of the prototype (UDL)(CAST,), anchored in educational theories of learning and enlightened by neuroscience results. The design and development of the prototype focus on a module related to the nervous system that allows learners to understand better pathways taken by information within the complex structure of the nervous system, mainly the brain, to recognize a particular object and act in consequence.(a cross-platform game engine developed by Unity Technologies) and. Studentsenrolled the introductory Human Anatomy course evaluated the's\u252c\u00e1\u0393\u00c7\u00aa", "num_citations": "1\n", "authors": ["57"]}
{"title": "Francopass: A Community-oriented Gamified Web Application for French Learners and Education Students\n", "abstract": " Gamification is commonly defined as \u0393\u00c7\u00a3using game-based mechanics, aesthetics and game thinking to engage people, motivate action, and promote learning\u0393\u00c7\u00a5(Kapp, 2012, p. 10). Gamification strategies have been adopted to design educational tools across a wide variety of disciplines. This article focuses on Francopass, a gamified web application which encourages university students to engage with the local French-speaking community in Edmonton, Alberta. Canada. Although Alberta is not officially a bilingual province, it plays host to a long-established, vibrant, and diverse francophone community. Francopass motivates second language learners by encouraging them to engage with this community. A beta trial of the application took place between September and December 2019. Students taking French courses at the University of Alberta had the option of participating in the study, which included a team\u0393\u00c7\u00d6s competition that was announced to students on October 18, 2019 and closed on December 6, 2019. Feedback to assess the effectiveness of Francopass was obtained using a two-part \u0393\u00c7\u00a3Before\u0393\u00c7\u00a5 and \u0393\u00c7\u00a3After\u0393\u00c7\u00a5 questionnaire. Interestingly, students who identified themselves as less comfortable with French in the \u0393\u00c7\u00a3Before\u0393\u00c7\u00a5 questionnaire had a tendency to score high on Francopass. A relatively small subset of students responded to the \u0393\u00c7\u00a3After\u0393\u00c7\u00a5 questionnaire (n= 12). They indicated that attending events increased their motivation to learn French, that they had learned about francophone culture in Edmonton, and that the application helped them find ways to engage with the francophone community that they would not have known about otherwise. The\u252c\u00e1\u0393\u00c7\u00aa", "num_citations": "1\n", "authors": ["57"]}
{"title": "Generative Interior Design using BIM\n", "abstract": " Computational methods for automatically generating multiple valid alternative solutions to design problems offer the potential for creativity and innovation, by efficiently creating a potentially much larger number of alternatives, among which to select the design that best suits a variety of criteria. In this paper, we present our work on a particular instance of the general generative-design problem, namely the task of generating 3D kitchen layouts, based on a BIM model of the kitchen space, a product catalog of 3D models of kitchen furnishings, and a set of kitchen design rules. Our generative-design method starts with an empty kitchen and implements a heuristic search of the solution space by incrementally selecting and placing a required item and checking the degree to which the resulting model complies with the given kitchen design rules. We have demonstrated the effectiveness of our method by comparing the\u252c\u00e1\u0393\u00c7\u00aa", "num_citations": "1\n", "authors": ["57"]}
{"title": "An effective evolutionary analysis scheme for industrial software access control models\n", "abstract": " Access control is an essential feature of industrial software systems security mechanisms. Role-based access control (RBAC), which is likely the most popular access-control technique, specifies \u0393\u00c7\u00a3user roles\u0393\u00c7\u00a5 and associates each role with \u0393\u00c7\u00a3permissions\u0393\u00c7\u00a5 to access distinct system functionalities. These role-permissions assignment rules, as well as the types of system users and system functionalities, evolve over time. In this paper, we describe a methodology for analyzing and understanding the RBAC-configuration evolution, its relation to the overall evolutionary lifecycle of industrial systems, and its impact on security vulnerabilities from which the system may suffer. Our methodology considers two different sources of information regarding the RBAC-configuration evolution: 1) the role-permissions matrices of subsequent system versions; and 2) the corresponding concept lattices, implied by these matrices. By\u252c\u00e1\u0393\u00c7\u00aa", "num_citations": "1\n", "authors": ["57"]}
{"title": "Simulation-Based deployment configuration of smart indoor spaces\n", "abstract": " Evaluating deployment scenarios for sensor-driven applications in indoor spaces can be a tedious and labour-intensive task. To mitigate the cost of comparatively evaluating sensor deployment configurations and alternatives required by these applications, we present an integrated methodology that enables the modeling, simulation, and evaluation of alternative candidate deployments, as well as, the fine-tuning of the corresponding sensor-driven applications. We illustrate our methodology by applying it to the task of configuring an indoor localization ambient-intelligence application. We explain how our methodology models the real-world environment and the candidate sensor deployment, simulates the occupants' activities and the sensors' run-time behavior, and evaluates, through a variety of metrics, the effectiveness of the application under different deployment configurations. We evaluate our methodology on\u252c\u00e1\u0393\u00c7\u00aa", "num_citations": "1\n", "authors": ["57"]}
{"title": "Sensor-enabled Functional-Mobility Assessment: An Exploratory Investigation\n", "abstract": " The population of adults aged 65 years and older is expected to double by 2050. Healthcare systems must adapt to in order to manage the care of this increasing population. Older adults with complex care needs require a significant amount of additional support from caregivers. To maintain, and possibly improve, their quality of life, it is ideal that they receive this support while continuing to live in their own homes. Recent advances in sensing technologies offer the ability to recognize and collect multiple different types of data around a person's movement and physical ability. This data can subsequently be analyzed in order to inform a person's functional-mobility assessment. In this paper, we present an exploratory feasibility study around the use of Microsoft Kinect\u0393\u00e4\u00f3 and KINVENT's K-FORCE plates for the purpose of assessing balance skills. Our results indicate that the analysis of data streams from these two\u252c\u00e1\u0393\u00c7\u00aa", "num_citations": "1\n", "authors": ["57"]}
{"title": "A T-shaped Measure of Multidisciplinarity in Academic Research Networks: The GRAND Case Study\n", "abstract": " Service-science research has long been studying T-shapedness, arguing that service scientists should be T-shaped individuals, deeply knowledgeable in one field and able to collaborate and communicate across disciplines. The value of multidisciplinarity has also been recognized in academic environments, as funding agencies are committing substantial support to large-scale research initiatives that span across disciplines, organizations, academia and industry, even across national borders, and aim to address the major challenges of our time, from climate change, to energy shortage, to pandemics. New incentives and performance indicators are needed to encourage and reward multidisciplinary collaborative work. In this paper, we introduce a metric for multidisciplinarity, based on the notion of T-shapedness and we report on the application of this measure on data collected over four years from the\u252c\u00e1\u0393\u00c7\u00aa", "num_citations": "1\n", "authors": ["57"]}
{"title": "Third annual workshop on data-driven knowledge mobilization\n", "abstract": " Knowledge mobilization and translation describes the process of moving knowledge from research and development (R&D) labs into environments where it can be put to use. There is increasing interest in understanding mechanisms for knowledge mobilization, specifically with respect to academia and industry collaborations. At the same time, the number of available datasets and accessible analysis tools is growing.", "num_citations": "1\n", "authors": ["57"]}
{"title": "(Semi) automatic construction of access-controlled web data services\n", "abstract": " The widespread adoption of the Internet of Things (IoT) is producing an ever-increasing stream of data that can be mined by multiple stakeholders, in support of different objectives and tasks. In fact, we are witnessing the emergence of data marketplaces that aim to share this data and harness economic value out of these transactions. The advent of data-as-a-service (DaaS) represents a key integrator opportunity that allows for the management of data collections, while providing specific privacy policies to delegated agents. To support DaaS integrations, we develop a model-driven method for creating APIs to deliver DaaS. Our method supports data owners to:(1) automatically abstract the representation of relational database schemas into a visual model and map them to existing ontologies,(2) use the mappings in order to create different role-based access-control views of APIs, and (3) automatically generate API\u252c\u00e1\u0393\u00c7\u00aa", "num_citations": "1\n", "authors": ["57"]}
{"title": "The LRA Workbench for Composing Linked REST APIs\n", "abstract": " The number of Web APIs for accessing information and services is continuously increasing, and yet, no tools exist to automate the process of invoking these APIs and composing their responses, which can be time consuming and error prone. In our previous work, we described LRA (Linked REST APIs) [1], a middleware that enables the automatic composition of REST APIs. Although this automation represents a great opportunity to systematize and improve the quality of the process of using Web APIs, LRA's reliance on SPARQL as the user-interaction model may hinder its adoption. Hence, based upon previous work on Linked Data query systems, in this paper we present a tool that takes advantage of the emergent schema of Web API descriptions, in order to simplify the formulation of LRA-compliant queries.", "num_citations": "1\n", "authors": ["57"]}
{"title": "Effect of Kinect Tai Chi on overall health of dementia clients: A feasibility and usability study\n", "abstract": " The prevalence of dementia is increasing worldwide. Dementia clients experience an increased risk for depression and physical inactivity. Tai Chi can enhance the physical and mental health of healthy older adults, including persons with dementia. However, programs tailored for dementia clients are scarce and barriers, such as transportation and accessibility, further limit participation in Tai Chi. The purpose of this pilot study was to evaluate the usability of a home Kinect-based Tai Chi system (K-TaiChi), and to determine its effect on perceived physical and mental health of dementia clients in preparation for a large-scale study. Using a serious-games methodology, K-TaiChi was developed to guide dementia clients through postures and movements, recognize features of their movement, and provide visual feedback and rewards when movements are performed well. Ten community dwelling individuals with\u252c\u00e1\u0393\u00c7\u00aa", "num_citations": "1\n", "authors": ["57"]}
{"title": "LiveBook: competence assessment with virtual-patient simulations\n", "abstract": " Virtual-patient simulators play an important role in modern medical education. These simulators provide a safe environment for learning, give contextual feedback to learners, and allow the learner to move beyond the time and space constraints of traditional face-to-face medical instruction. In this paper, we present an interactive simulation system, LiveBook. This system places learners in the role of a clinician who investigates the symptoms of a patient, asking questions (and receiving answers) in natural language. Once the learner has completed a case by selecting the most plausible diagnosis, LiveBook provides detailed feedback on the student's performance. The first LiveBook cases are currently being piloted in the area of Pediatrics and the service is available at https://live-book.org. Based on our initial experience with the pilot, we believe that LiveBook can be a valuable addition to the curriculum of future\u252c\u00e1\u0393\u00c7\u00aa", "num_citations": "1\n", "authors": ["57"]}
{"title": "Analyzing test driven development based on GitHub evidence\n", "abstract": " Testing is an integral part of the software development lifecycle, approached with varying degrees of rigor by different process models. Agile process models advocate Test Driven Development (TDD) as one among their key practices for reducing costs and improving code quality. In this paper we comparatively analyze GitHub repositories that adopt TDD against repositories that do not, in order to determine how TDD affects a number of variables related to productivity and developer satisfaction, two aspects that should be considered in a cost-benefit analysis of the paradigm. In this study, we searched through GitHub and found that a relatively small subset of Java-based repositories can be seen to adopt TDD, and an even smaller subset can be confidently identified as rigorously adhering to TDD. For comparison purposes, we created two same-size control sets of repositories. We then compared the repositories in these two sets in terms of number of test files, average commit velocity, number of commits that reference bugs, number of issues recorded, whether they use continuous integration, and the sentiment of their developers\u0393\u00c7\u00d6 commits. We found some interesting and significant differences between the two sets, including higher commit velocity and increased likelihood of continuous integration for TDD repositories.", "num_citations": "1\n", "authors": ["57"]}
{"title": "Reflecting on Model-based Code Generators Using Traceability Information.\n", "abstract": " Model-based code generators use model-to-model and model-to-text transformations to systematize the construction of software systems. They integrate rule-based and templatebased transformation languages to translate high-level specifications into executable code and scripts. Given the complexity and heterogeneity of the underlying transformation languages, flexible traceability tools are needed to collect and visualize information about their architecture and operational mechanics. In this paper, we present ChainTracker, a traceability analysis environment for model-based code generators. ChainTracker helps developers to reflect on the composition of model transformations during the different stages of their construction and maintenance. Furthermore, we describe a family of software-engineering tasks that developers have to complete during the construction of model-based code generators, and how ChainTracker makes the execution of these tasks less error prone and less cognitively challenging.", "num_citations": "1\n", "authors": ["57"]}
{"title": "A lightweight coordination approach for resource-centric collaborations\n", "abstract": " A very common form of collaborative work involves people working on shared resources. Consider for example the process of co-producing a project report, where a content editor writes the text, a librarian cross-references the text against a repository of citations, and an accountant validates the budget line items against applicable rules; or the process of reviewing a loan application where someone examines the credit history of the applicant and co-signatories and a risk-assessment specialist makes the final decisions based on these histories and the bank\u0393\u00c7\u00d6s policies. All these types of collaborative work share a few key properties. The various process steps are partially ordered, based on logical inter-dependencies among them. Although some steps may be automated, the process is driven primarily by people using interactive tools, who somehow notify each other about their progress. Finally, these\u252c\u00e1\u0393\u00c7\u00aa", "num_citations": "1\n", "authors": ["57"]}
{"title": "Towards families of personalized mobile applications\n", "abstract": " In this position paper, we present our early work towards a software architecture for developing product lines of personalized mobile applications.", "num_citations": "1\n", "authors": ["57"]}
{"title": "Technical Challenges and Solutions: Creating Virtual Environments for a Health Science Interprofessional Course\n", "abstract": " Virtual interactive environments such as Second Life are emerging as innovative tools that can support and enhance learning in various educational domains. However, for the educational practitioner new to these environments, developing educational settings and activities in a virtual environment can appear to be technically complex and beyond their area of expertise. This case study describes some of the technical challenges encountered and the solutions derived during the development of a virtual world for the delivery of a health science interprofessional communications course.", "num_citations": "1\n", "authors": ["57"]}
{"title": "Exploring simulation-based configuration decisions\n", "abstract": " As service compositions grow larger and more complex, so does the challenge of configuring the underlying hardware infrastructure on which the component services are deployed. With more configuration options (virtualized systems, cloud-based systems, etc.), the challenge grows more difficult. Configuring service-oriented systems involves balancing a competing set of priorities and choosing trade-offs to achieve high-priority goals. We describe a simulation-based methodology for supporting administrators in making these decisions by providing them with relevant information obtained using inexpensive simulation-generated data. From our existing services-aware simulation framework, we generated millions of performance metrics for a given system in varying configurations. We describe how we structured our simulation experiments to answer specific questions such as optimal service distribution\u252c\u00e1\u0393\u00c7\u00aa", "num_citations": "1\n", "authors": ["57"]}
{"title": "Virtual worlds for modeling complex processes between people and systems\n", "abstract": " Virtual worlds, where thousands of people can interact simultaneously within the same simulated three-dimensional space, represent a frontier in social computing with critical implications for business, education, social sciences, technological sciences, and our society at large. Members participate in virtual worlds through graphical representations of themselves, ie, their avatars. In a virtual world, through their avatars users can engage in rich interactions with each other and with their environment. They can build objects and they can exchange them for in-world money, sometimes exchangeable with real money. They can communicate through voice over a headset and microphone, they can use text chat, and they can communicate non-verbally with their avatars' gestures. They can navigate through the world by walking, running, driving vehicles, flying, and teleporting. All in all, they can\" experience\" the world\u252c\u00e1\u0393\u00c7\u00aa", "num_citations": "1\n", "authors": ["57"]}
{"title": "Valuing software service development in support of business\u0393\u00c7\u00c9to\u0393\u00c7\u00c9consumer services\n", "abstract": " In efforts to innovate, organizations are increasingly offering competitive value\u0393\u00c7\u00c9added services, frequently by evolving their software infrastructure. Business decisions are often motivated by economic trade\u0393\u00c7\u00c9offs related to the development and management of this software. To develop an economic\u0393\u00c7\u00c9modelling framework for the evolutionary development of software\u0393\u00c7\u00c9based services, we examine the problem of estimating the return on a software\u0393\u00c7\u00c9evolution investment. We present methods for estimating both the cost of developing a new service by incrementally modifying existing software and the value generated by introducing the service to the market in terms of revenue generated by the new service and the value of potential future services it may enable. An example case study illustrates the model. Copyright \u252c\u2310 2010 ASAC. Published by John Wiley & Sons, Ltd.", "num_citations": "1\n", "authors": ["57"]}
{"title": "Facilitating a Hierarchy of Engagement: Corporate Education in Virtual Worlds\n", "abstract": " Virtual worlds, where many people can interact simultaneously within the same three-dimensional environment, are productive enabling environments for corporate education. In this chapter, the authors propose a hierarchy of four types of educational engagement, at successively deeper levels of interaction. The authors then show that virtual worlds can be useful platforms for distance corporate education because they can be used to promote engagement at all four levels of the proposed hierarchy. By linking their hierarchy with existing learning theories, they argue that the effectiveness of corporate education can be successfully carried out by using virtual worlds. They also provide an overview of the historical development of virtual worlds, the development of distance education, and a description of technological, institutional, and research challenges needed to be met for distance corporate education to realize\u252c\u00e1\u0393\u00c7\u00aa", "num_citations": "1\n", "authors": ["57"]}
{"title": "Service interaction patterns\n", "abstract": " Enterprises are increasingly adopting Web Services as an enterprise-application development platform, I motivated primarily by the large-scale language and platform interoperability the standards enable and the variety of tools supporting the development of systems of services. However, SOA is underutilized as a distributed-application platform when it is used only to specify service compositions (ie, data and control dependencies among the service operations) in an executable language (such as BPEL), expose them as new complex services and have them orchestrated by an execution engine at runtime. A fundamental innovation of SOA (and Web Services) is that it makes explicit the concept of,\" service choreography\", that is; the coordination of the interactions between two or more independent parties, where no single party can assume complete control of the overall process. Note that in contrast, the concept\u252c\u00e1\u0393\u00c7\u00aa", "num_citations": "1\n", "authors": ["57"]}
{"title": "Using Virtual Environments for an Interprofessional Communications Skills Instructional Program for Health Science Education\n", "abstract": " For health science students, developing appropriate communication skills is important for success in the transition from educational settings to clinical settings. This paper is a description of a new project directed at the development of a virtual environment-based (Second Life) communication skills program for health science students. Within the project, we intend to investigate: a) the learning models that are appropriate as frameworks for VE learning applications, b) the importance of incorporating elements that promote social presence in such programs, and c) the types of scaffolding mechanisms that support learning in VE\u0393\u00c7\u00d6s. From a broader viewpoint, this instructional program is intended to improve patient care at the clinical level through the development of a deeper understanding of how innovative technologies can support and enhance interprofessional health sciences education.", "num_citations": "1\n", "authors": ["57"]}
{"title": "Second Life Gift Registry: Bringing Retail Web Applications into the Metaverse\n", "abstract": " The combination of realistic virtual environments and product information offers a compelling new medium for consumers to shop for products. Specifically, by combining the experience of exploring a virtual house with retail information on items in that house, a consumer can virtually populate a house with desired items. This is particularly appealing for people, such as a couple getting married, who are looking to furnish an entire house with newly-purchased items. The system proposed in this paper provides this combination of realistic, 3D visualization and detailed product information. It uses second life to provide the realistic user interface, and a REST-style Web-based application to create connections between this platform and publicly-available retailer APIs. In cases where a retailer API is unavailable, HTML wrapping may be used to obtain equivalent information. The economic viability of the concept is\u252c\u00e1\u0393\u00c7\u00aa", "num_citations": "1\n", "authors": ["57"]}
{"title": "Some Business Concerns around Service-Oriented Architectures\n", "abstract": " The objective of this paper is to explore the relationship between the engineering of Service-Oriented Applications and some strategic and economic concerns of the organizations that (consider to) adopt this architecture style for the development of their software systems. To that end,(a) we discuss some pragmatic observations regarding the potential role of SOAs in the current economy,(b) we identify some distinct types of applications envisioned to be developed in the SOA style,(c) we correlate some strategic business decisions with different types of SOA evolution scenarios, and (d) we outline a novel model for estimating the ROI of such evolution scenarios. This work rests squarely within the newly articulated area of \u0393\u00c7\u00a3Service Science, Management, and Engineering (SSME)\u0393\u00c7\u00a5[15, 19] as an \u0393\u00c7\u00a3interdisciplinary approach to the study, design, and implementation of service systems, ie, complex systems in which specific arrangements of people and technologies take actions that provide value for others\u0393\u00c7\u00a5.", "num_citations": "1\n", "authors": ["57"]}
{"title": "MediCol: A mobile application for collaborative peer learning in an apprenticeship context\n", "abstract": " In this paper, we discuss MediCol, a JXTA-based P2P application to support the interaction of a cohort of medical students in their surgery rotation. MediCol supports many of the natural interactions occurring among peer students and their rotation supervisors, including note taking, discussion of cases during patient visits, and rotation portfolio management for student evaluation. To date, we have evaluated MediCol\u0393\u00c7\u00f4with promising initial results-to assess its run-time performance with a realistic number of peers. In the near future, we plan an in-situ case study.", "num_citations": "1\n", "authors": ["57"]}
{"title": "User Interface Reverse Engineering in support of Mifgration to the Web\n", "abstract": " Legacy systems constitute valuable assets to the organizations that own them. Nowadays, there is an increased demand to make them accessible through the World-Wide-Web motivated by the need to support e-commerce related activities. As a result, the problem of legacy-interface migration is becoming extremely important. In the context of the CELLEST project, we have developed a novel method for migrating legacy user interfaces to web-accessible platforms. Its novelty lies in that it models the system\u0393\u00c7\u00d6s dynamic behavior based on traces of the users interaction with the system, instead of focusing on the system code structure. Furthermore it proposes a model of the users\u0393\u00c7\u00d6 tasks, in terms of the users\u0393\u00c7\u00d6 navigation of the interface and the information they exchange with the system, as the intermediate abstraction on which the forward engineering phase is based. In this paper, we discuss our interface-migration method, we illustrate it with examples and we discuss the results of our experimentation with it.", "num_citations": "1\n", "authors": ["57"]}
{"title": "Intelligent Integration of Information and Services on the Web\n", "abstract": " The evolution of the World Wide Web from a repository of HTML data to a source of varied distributed services creates exciting opportunities for offering complex, integrated services over the web. The syntactic problems of such integration are being addressed by the advent of the web services stack of standards. 1 However, the promise of service integration will not be delivered unless services can be integrated semantically as well. The 2002 AAAI workshop entitled\" Intelligent Service Integration\" examined this new challenge for the AI community.", "num_citations": "1\n", "authors": ["57"]}
{"title": "Designing Efficient Topic-Driven Web Crawlers\n", "abstract": " Crawlers are essential to web search engines for retrieving high quality web pages automatically and efficiently based on developer defined notions of importance and quality. Due to rapid growth of World-Wide Web and limited resources available to crawlers, developing good crawling strategies and evaluating them are still big challenges. In this paper, we do a comprehensive study of existing and proposed crawling strategies done by other research works. We have developed a topic-driven crawler that uses combinations of two different strategies in evaluating page importance during the crawl.", "num_citations": "1\n", "authors": ["57"]}
{"title": "Towarda A Reference Architecture for Service Integration on the Web\n", "abstract": " Today, due to the proliferation of E-commerce related activities, the interface-migration problem becomes increasingly important. In this paper, we discuss a method we have developed for the migration of existing interfaces to an XML-based representation, executable by multiple devices used to access the World Wide.", "num_citations": "1\n", "authors": ["57"]}
{"title": "3rd International Workshop on Net-Centric Computing (NCC 2001): Theme: Migrating to the Web\n", "abstract": " Enlarged ventricular size and/or asymmetry have been found markers for psychiatric illness, including schizophrenia. However, this morphometric feature is non-specific and occurs in many other brain diseases, and its variability in healthy controls is not sufficiently understood. We studied ventricular size and shape in 3D MRI (N= 20) of monozygotic (N= 5) and dizygotic (N= 5) twin pairs. Left and right lateral, third and fourth ventricles were segmented from high-resolution T1w SPGR MRI using supervised classification and 3D connectivity. Surfaces of binary segmentations of left and right lateral ventricles were parametrized and described by a series expansion using spherical harmonics. Objects were aligned using the intrinsic coordinate system of the ellipsoid described by the first order expansion. The metric for pairwise shape similarity was the mean squared distance (MSD) between object surfaces. Without\u252c\u00e1\u0393\u00c7\u00aa", "num_citations": "1\n", "authors": ["57"]}
{"title": "Towards the \u0393\u00c7\u00a3web-based\u0393\u00c7\u00a5 architectural style\n", "abstract": " These days, a large percentage of software development is on the web and for the web.\u0393\u00c7\u00a3Web services will become the predominant method for making information and applications available programmatically via the Internet in the near future\u0393\u00c7\u00a5[9]. And in that context, one of the most important and resource consuming activities in the e-commerce industry today is the\" webenablement\" of existing software assets and the\" aggregation\" of applications. The intent of these activities is to make services that used to be available only within the corporate LAN accessible to partners and customers on the Web, and to provide complex value-added services, such as comparative shopping, order aggregation, and auctioning, on top of applications offering products or services.This type of software development comes with its own set of distinct problems, which, in turn, have strong architectural implications. In general, these problems are due to three inherent properties of this class of applications: the need for reuse of existing assets, the diversity of the environment in which they are deployed, and the need for special run-time support.", "num_citations": "1\n", "authors": ["57"]}
{"title": "Review of Knowledge Engineering and Management\n", "abstract": " Knowledge Engineering and Management: The CommonKADS Methodology, Guus Schreiber, Hans Akkermans, Anjo Anjewierden, Robert de Hoog, Nigel Shadbolt, Walter Van de Velde, and Bob Wielinga, The MIT Press, 2000, 455 pp., ISBN 0-262-19300-0. This book describes the CommonKADS methodology, the product of a family of knowledge and analysis design support (KADS) projects spanning the past two decades. The last of the book's authors has been involved in this effort since the beginning of 1983. Thus, the book is particularly interesting to those who have been following their work.", "num_citations": "1\n", "authors": ["57"]}
{"title": "Evaluating psms in redesign: The autognostic experiments\n", "abstract": " The specification of generic Problem-Solving Methods has been a fertile research area. A lot of work has been devoted to developing languages for describing PSMs, identifying PSMs, and using their specifications for requirements capture, design and development of knowledgebased systems. In our work, we have been investigating another potential use for PSMs, namely, supporting the redesign of systems that fail to exhibit the behaviors desired of them, that is, behaviors similar to, but slightly different from, the ones they were originally designed to exhibit. To this end, we have defined a PSM modeling language and a failure-driven redesign process based on this language, both of which were implemented in the AUTOGNOSTIC system. In this paper, we report on a sequence of experiments performed with AUTOGNOSTIC. Some of them were exploratory and their goal was to enable the precise characterization of issues relating to the problem of system redesign, while others were designed to evaluate the PSM language and the redesign process implemented in AUTOGNOSTIC.", "num_citations": "1\n", "authors": ["57"]}
{"title": "Reflective reasoning and learning\n", "abstract": " Discussion AUTOGNOSTIC(Stroulia and Goel 1993) is a system that implements and evaluates this theory of reflective reasoning and learning. Given the SBF model of a problem solver, AUTOGNOSTIC monitors its reasoning, and when it fails, assigns blame to some of its elements and redesigns it appropriately. AUTOGNOSTIC presently operates in two widely different task domains: on top of ROUTER, in the domain of navigational planning, and on top of KRITIK~, in the domain of engineering design. Both ROUTER and KRITIK~ are autonomous multistrategy systems developed independently of AUTOGNOSTIC, and since they solve widely different tasks in widely different domains, the success of AUT~ GNOSTIC\u0393\u00c7\u00d6S reflection process suggests that its SBF models of problem solving and reflection process are quite general. AUTOGNOSTIC is capable of identifying and correcting errors1. in the representation scheme of the world knowledge, 2. in the organization of the world knowledge, 3. in the content of the world knowledge itself, 4. in the assumptions on the applicability and utility of different reasoning methods, and5. the role of a subtask in the overall reasoning process.", "num_citations": "1\n", "authors": ["57"]}