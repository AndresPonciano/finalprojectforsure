{"title": "On the reliable detection of concept drift from streaming unlabeled data\n", "abstract": " Classifiers deployed in the real world operate in a dynamic environment, where the data distribution can change over time. These changes, referred to as concept drift, can cause the predictive performance of the classifier to drop over time, thereby making it obsolete. To be of any real use, these classifiers need to detect drifts and be able to adapt to them, over time. Detecting drifts has traditionally been approached as a supervised task, with labeled data constantly being used for validating the learned model. Although effective in detecting drifts, these techniques are impractical, as labeling is a difficult, costly and time consuming activity. On the other hand, unsupervised change detection techniques are unreliable, as they produce a large number of false alarms. The inefficacy of the unsupervised techniques stems from the exclusion of the characteristics of the learned classifier, from the detection process. In this\u00a0\u2026", "num_citations": "115\n", "authors": ["1088"]}
{"title": "A grid density based framework for classifying streaming data in the presence of concept drift\n", "abstract": " Mining data streams is the process of extracting information from non-stopping, rapidly flowing data records to provide knowledge that is reliable and timely. Streaming data algorithms need to be one pass and operate under strict limitations of memory and response time. In addition, the classification of streaming data requires learning in an environment where the data characteristics might change constantly. Many of the classification algorithms presented in literature assume a 100 % labeling rate, which is impractical and expensive when data records are rapidly flowing in. In this paper, a new incremental grid density based learning framework, the GC3 framework, is proposed to perform classification of streaming data with concept drift and limited labeling. The proposed framework uses grid density clustering to detect changes in the input data space. It maintains an evolving ensemble of classifiers to learn\u00a0\u2026", "num_citations": "41\n", "authors": ["1088"]}
{"title": "Data driven exploratory attacks on black box classifiers in adversarial domains\n", "abstract": " While modern day web applications aim to create impact at the civilization level, they have become vulnerable to adversarial activity, where the next cyber-attack can take any shape and can originate from anywhere. The increasing scale and sophistication of attacks, has prompted the need for a data driven solution, with machine learning forming the core of many cybersecurity systems. Machine learning was not designed with security in mind and the essential assumption of stationarity, requiring that the training and testing data follow similar distributions, is violated in an adversarial domain. In this paper, an adversary\u2019s view point of a classification based system, is presented. Based on a formal adversarial model, the Seed-Explore-Exploit framework is presented, for simulating the generation of data driven and reverse engineering attacks on classifiers. Experimental evaluation, on 10 real world datasets and using\u00a0\u2026", "num_citations": "39\n", "authors": ["1088"]}
{"title": "Handling adversarial concept drift in streaming data\n", "abstract": " Classifiers operating in a dynamic, real world environment, are vulnerable to adversarial activity, which causes the data distribution to change over time. These changes are traditionally referred to as concept drift, and several approaches have been developed in literature to deal with the problem of drift detection and handling. However, most concept drift handling techniques approach it as a domain independent task, to make them applicable to a wide gamut of reactive systems. These techniques are developed from an adversarial agnostic perspective, where they naively assume that adversarial activity is like any other change to the data, which can be fixed by retraining the models. However, this is not the case when a malicious agent is trying to evade the deployed classification system. In such an environment, the properties of concept drift are unique, as the drift is intended to degrade the system and at the\u00a0\u2026", "num_citations": "35\n", "authors": ["1088"]}
{"title": "Don\u2019t pay for validation: Detecting drifts from unlabeled data using margin density\n", "abstract": " Validating online stream classifiers has traditionally assumed the availability of labeled samples, which can be monitored over time, to detect concept drift. However, labeling in streaming domains is expensive, time consuming and in certain applications, such as land mine detection, not a possibility at all. In this paper, the Margin Density Drift Detection (MD3) approach is proposed, which can signal change using unlabeled samples and requires labeling only for retraining, in the event of a drift. The MD3 approach when evaluated on 5 synthetic and 5 real world drifting data streams, produced statistically equivalent classification accuracy to that of a fully labeled accuracy tracking drift detector, and required only a third of the samples to be labeled, on average.", "num_citations": "30\n", "authors": ["1088"]}
{"title": "No Free Lunch Theorem for concept drift detection in streaming data classification: A review\n", "abstract": " Many real\u2010world data mining applications have to deal with unlabeled streaming data. They are unlabeled because the sheer volume of the stream makes it impractical to label a significant portion of the data. The data streams can evolve over time and these changes are called concept drifts. Concept drifts have different characteristics, which can be used to categorize them into different types. A trade\u2010off between performance and cost exists among many concept drift detection approaches. On the one hand, high accuracy detection approach usually requires labeled data, possibly involving high cost for labeling. On the other hand, a variety of methods have been devoted to the topic of concept drift detection with unlabeled data, but these approaches often are most suited for only a subset of the concept drift types. The objective of this survey is to present these methods, categorize them and give recommendations\u00a0\u2026", "num_citations": "25\n", "authors": ["1088"]}
{"title": "Monitoring classification blindspots to detect drifts from unlabeled data\n", "abstract": " Machine learning models deployed in real world applications, operate in a dynamic environment where the data distribution can change constantly. These changes, called concept drifts, cause the performance of the learned model to degrade over time. As such it is essential to detect and adapt to changes in the data, for the model to be of any real use. While, model adaptation requires labeled data (for retraining), the detection process does not have to. Labeling data is time consuming and expensive, and if data changes are infrequent, most of the labeling effort, spent on verification, is wasted. In this paper, an ensemble based detection method is proposed, which tracks the number of samples in the critical disagreement regions of the ensemble, to detect concept drift from unlabeled data. The proposed algorithm, is-distribution and model independent, unsupervised and can be used in an online incremental\u00a0\u2026", "num_citations": "15\n", "authors": ["1088"]}
{"title": "\u2018Security theater\u2019: on the vulnerability of classifiers to exploratory attacks\n", "abstract": " The increasing scale and sophistication of cyber-attacks has led to the adoption of machine learning based classification techniques, at the core of cybersecurity systems. These techniques promise scale and accuracy, which traditional rule/signature based methods cannot. However, classifiers operating in adversarial domains are vulnerable to evasion attacks by an adversary, who is capable of learning the behavior of the system by employing intelligently crafted probes. Classification accuracy in such domains provides a false sense of security, as detection can easily be evaded by carefully perturbing the input samples. In this paper, a generic data driven framework is presented, to analyze the vulnerability of classification systems to black box probing based attacks. The framework uses an exploration-exploitation based strategy, to understand an adversary\u2019s point of view of the attack-defense cycle. The\u00a0\u2026", "num_citations": "13\n", "authors": ["1088"]}
{"title": "RLS-A reduced labeled samples approach for streaming imbalanced data with concept drift\n", "abstract": " In the streaming data milieu, the input data distribution is not static and the models generated must be updated when concept drift occurs, to maintain the classification performance. Updating a model requires retraining with the new incoming labeled samples. However, labeling data is a costly and time-consuming process and designing algorithms which do not require all the instances in the stream to be labeled, is needed. In this paper, a new Reduced Labeled Samples (RLS) framework is proposed, which can handle concept drift in imbalanced data streams, by selectively labeling only those set of samples which are the most useful in characterizing the drift, and thereby generating an updated model with fewer labeled samples. Experimental comparison with state of the art imbalanced stream classification algorithms shows that the RLS framework achieves comparable or better performance with requiring only\u00a0\u2026", "num_citations": "12\n", "authors": ["1088"]}
{"title": "CPN-a hybrid model for software cost estimation\n", "abstract": " One of the challenges faced by the managers in the software industry today is the ability to accurately define the requirements of the software projects early in the software development phase. The cost-benefit analysis forms the basis of the planning and decision making throughout the software development lifecycle. As such there is a need for efficient software cost estimation techniques for making any endeavor viable. Software cost estimation is the process of prognosticating the amount of effort required to build a software project. In this paper we have proposed a Particle Swarm Optimization (PSO) technique which operates on data sets clustered using the K-means clustering algorithm. PSO is employed to generate parameters of the COCOMO model for each cluster of data values. The clusters and effort parameters are then trained to a Neural Network by using Back propagation technique, for classification of\u00a0\u2026", "num_citations": "10\n", "authors": ["1088"]}
{"title": "An ensemble classification approach for handling spatio-temporal drifts in partially labeled data streams\n", "abstract": " The classification of streaming data requires learning in an environment where the distribution of the incoming data might change continuously. Stream classification methodologies need to adapt to these changes under limitations of time and memory resources. As such, it is not possible to expect all the samples in the stream to be labeled, as labeling is often time consuming and expensive. In this paper a new ensemble classification approach is proposed, which can handle Spatio-Temporal drifts in streams even when the labeling is limited. The proposed methodology uses a grid density clustering approach to track drifts in the spatial configuration of the data, and maintains a set of classifier models local to each cluster, to track its evolution over time. Structured weighted aggregation of the models across all clusters is performed to produce an overall effective prediction on a new sample. Additionally, a uniform\u00a0\u2026", "num_citations": "8\n", "authors": ["1088"]}
{"title": "Ensemble classifier for imbalanced streaming data using partial labeling\n", "abstract": " The data streams in many applications are characterized by imbalanced class distribution. The pattern in data streams may also change over time and therefore, the classification model should be adjusted to maintain performance. Hence, a new set of labeled samples should be provided which is not an easy task, since labeling is expensive and time consuming. In this paper, we propose Reduced Labeled Samples-Ensemble (RLS-E) which is an ensemble based framework for classification of the imbalanced data stream. It uses partially labeled samples in building the model. The prediction of the labels is obtained in two different approaches: 1) from combined output of all the models in the ensemble 2) from each individual model in the ensemble. The more accurate prediction between 1 and 2 is selected as the final prediction. This method does not rely solely on the ensemble prediction as there could be one\u00a0\u2026", "num_citations": "7\n", "authors": ["1088"]}
{"title": "When good machine learning leads to bad security: Big data (ubiquity symposium)\n", "abstract": " While machine learning has proven to be promising in several application domains, our understanding of its behavior and limitations is still in its nascent stages. One such domain is that of cybersecurity, where machine learning models are replacing traditional rule based systems, owing to their ability to generalize and deal with large scale attacks which are not seen before. However, the naive transfer of machine learning principles to the domain of security needs to be taken with caution. Machine learning was not designed with security in mind and as such is prone to adversarial manipulation and reverse engineering. While most data based learning models rely on a static assumption of the world, the security landscape is one that is especially dynamic, with an ongoing never ending arms race between the system designer and the attackers. Any solution designed for such a domain needs to take into account an\u00a0\u2026", "num_citations": "6\n", "authors": ["1088"]}
{"title": "A dynamic\u2010adversarial mining approach to the security of machine learning\n", "abstract": " Operating in a dynamic real\u2010world environment requires a forward thinking and adversarial aware design for classifiers beyond fitting the model to the training data. In such scenarios, it is necessary to make classifiers such that they are: (a) harder to evade, (b) easier to detect changes in the data distribution over time, and (c) be able to retrain and recover from model degradation. While most works in the security of machine learning have concentrated on the evasion resistance problem (a), there is little work in the areas of reacting to attacks (b) and (c). Additionally, while streaming data research concentrates on the ability to react to changes to the data distribution, they often take an adversarial agnostic view of the security problem. This makes them vulnerable to adversarial activity, which is aimed toward evading the concept drift detection mechanism itself. In this paper, we analyze the security of machine learning\u00a0\u2026", "num_citations": "6\n", "authors": ["1088"]}
{"title": "Selecting samples for labeling in unbalanced streaming data environments\n", "abstract": " In this paper we proposed an alternative approach to random selection for labeling extremely unbalanced stream data sets where one class is only 1-10% of the entire data set. Labeling, especially when human resources are needed, is often time consuming and expensive. In an extremely unbalanced data set, usually a lot of data points need to be labeled to get enough minority class samples. The goal of this research was to reduce the total number of samples needed in the labeling process of training new classification models for updating streaming data ensemble classifier. Our proposed approach is to find minority class clusters using the grid density algorithm, and sample minority class instances inside those regions. The result from the synthetic data set showed that efficiency of our proposed approaches varies with different grid sizes. Results on real world data sets confirmed that observation, and showed\u00a0\u2026", "num_citations": "6\n", "authors": ["1088"]}
{"title": "Cluster analysis & Pso for software cost estimation\n", "abstract": " The modern day software industry has seen an increase in the number of software projects .With the increase in the size and the scale of such projects it has become necessary to perform an accurate requirement analysis early in the project development phase in order to perform a cost benefit analysis. Software cost estimation is the process of gauging the amount of effort required to build a software project. In this paper we have proposed a Particle Swarm Optimization (PSO) technique which operates on data sets which are clustered using the K-means clustering algorithm. The PSO generates the parameter values of the COCOMO model for each of the clusters of data values. As clustering encompasses similar objects under each group PSO tuning is more efficient and hence it generates better results and can be used for large data sets to give accurate results. Here we have tested the model on the\u00a0\u2026", "num_citations": "6\n", "authors": ["1088"]}
{"title": "SEEPC: A toolbox for software effort estimation using soft computing techniques\n", "abstract": " SEEPC: A Toolbox for Software Effort Estimation using Soft Computing Techniques - NASA/ADS Now on home page ads icon ads Enable full ADS view NASA/ADS SEEPC: A Toolbox for Software Effort Estimation using Soft Computing Techniques Hari, Ch. VMK ; Singh Sethi, Tegjyot ; Jagadeesh. M. Abstract Publication: International Journal of Computer Applications Pub Date: October 2011 DOI: 10.5120/3811-5262 Bibcode: 2011IJCA...31d..12H full text sources Publisher | \u00a9 The SAO/NASA Astrophysics Data System adshelp[at]cfa.harvard.edu The ADS is operated by the Smithsonian Astrophysical Observatory under NASA Cooperative Agreement NNX16AC86A NASA logo Smithsonian logo Resources About ADS ADS Help What's New Careers@ADS Social @adsabs ADS Blog Project Switch to full ADS Is ADS down? (or is it just me...) Smithsonian Institution Smithsonian Privacy Notice Smithsonian Terms of \u2026", "num_citations": "5\n", "authors": ["1088"]}
{"title": "Sloppiness mitigation in crowdsourcing: detecting and correcting bias for crowd scoring tasks\n", "abstract": " Due to different expertise levels, personal preference, or fatigue from long working of the crowd workers, the data obtained through crowdsourcing are usually unreliable. One big challenge is to obtain true information from such noisy data. Sloppiness, which represents the phenomena of observed labels which fluctuate around the true labels, is one type of the errors that has rarely been discussed in research. Moreover, most existing approaches try to derive truths in binary labeling tasks. In this paper, we deal with the sloppiness in a crowd scoring task, to obtain high-quality estimated labels. Crowd scoring task consists of ordinal and multiple labels, instead of just two labels. The worker in crowdsourcing can exhibit sloppiness, which can lead to unreliable scoring. We show that sloppy workers with biases, who constantly give higher (or lower) answers compared with true labels, can be effectively utilized to\u00a0\u2026", "num_citations": "4\n", "authors": ["1088"]}
{"title": "The GC3 Framework: Grid Density Based Clustering for Classification of Streaming Data with Concept Drift\n", "abstract": " Data mining is the process of discovering patterns in large sets of data. In recent years there has been a paradigm shift in how the data is viewed. Instead of considering the data as static and available in databases, data is now regarded as a stream as it continuously flows into the system. One of the challenges posed by the stream is its dynamic nature, which leads to a phenomenon known as Concept Drift. This causes a need for stream mining algorithms which are adaptive incremental learners capable of evolving and adjusting to the changes in the stream.", "num_citations": "3\n", "authors": ["1088"]}
{"title": "A partial labeling framework for multi-class imbalanced streaming data\n", "abstract": " Imbalanced data streams are found in many real world applications such as spam email detection, and internet traffic data. The classification of such data is challenging, since data stream usually changes, and the model should be updated to maintain the performance. However, obtaining the true labels of the samples to build a new model is not easy, since labeling is expensive and time consuming. Additionally, existence of the multiple and imbalanced classes may cause to lose performance over one class while trying to gain on another. In this paper, we propose RLS-Multi (Reduced Labeled Samples-Multiple class) which is a classification framework for the multi-class and evolving imbalanced data stream. RLS-Multi handles the data with multiple classes, and it uses a small fraction of the data to update the model. RLS-Multi is compared with McELM, and VWOS-ELM which are two fully labeling approaches for\u00a0\u2026", "num_citations": "2\n", "authors": ["1088"]}