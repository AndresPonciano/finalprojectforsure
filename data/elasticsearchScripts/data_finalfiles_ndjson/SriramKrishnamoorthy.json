{"title": "Scalable work stealing\n", "abstract": " Irregular and dynamic parallel applications pose significant challenges to achieving scalable performance on large-scale multicore clusters. These applications often require ongoing, dynamic load balancing in order to maintain efficiency. Scalable dynamic load balancing on large clusters is a challenging problem which can be addressed with distributed dynamic load balancing systems. Work stealing is a popular approach to distributed dynamic load balancing; however its performance on large-scale clusters is not well understood. Prior work on work stealing has largely focused on shared memory machines. In this work we investigate the design and scalability of work stealing on modern distributed memory systems. We demonstrate high efficiency and low overhead when scaling to 8,192 processors for three benchmark codes: a producer-consumer benchmark, the unbalanced tree search benchmark, and a\u00a0\u2026", "num_citations": "351\n", "authors": ["520"]}
{"title": "Automatic transformations for communication-minimized parallelization and locality optimization in the polyhedral model\n", "abstract": " The polyhedral model provides powerful abstractions to optimize loop nests with regular accesses. Affine transformations in this model capture a complex sequence of execution-reordering loop transformations that can improve performance by parallelization as well as locality enhancement. Although a significant body of research has addressed affine scheduling and partitioning, the problem of automatically finding good affine transforms for communication-optimized coarse-grained parallelization together with locality optimization for the general case of arbitrarily-nested loop sequences remains a challenging problem.               We propose an automatic transformation framework to optimize arbitrarily-nested loop sequences with affine dependences for parallelism and locality simultaneously. The approach finds good tiling hyperplanes by embedding a powerful and versatile cost function into an Integer\u00a0\u2026", "num_citations": "310\n", "authors": ["520"]}
{"title": "A compiler framework for optimization of affine loop nests for GPGPUs\n", "abstract": " GPUs are a class of specialized parallel architectures with tremendous computational power. The new Compute Unified Device Architecture (CUDA) programming model from NVIDIA facilitates programming of general purpose applications on their GPUs. However, manual development of high-performance parallel code for GPUs is still very challenging. In this paper, a number of issues are addressed towards the goal of developing a compiler framework for automatic parallelization and performance optimization of affine loop nests on GPGPUs: 1) approach to program transformation for efficient data access from GPU global memory, using a polyhedral compiler model of data dependence abstraction and program transformation; 2) determination of optimal padding factors for conflict-minimal data access from GPU shared memory; and 3) model-driven empirical search to determine optimal parameters for unrolling\u00a0\u2026", "num_citations": "273\n", "authors": ["520"]}
{"title": "Effective automatic parallelization of stencil computations\n", "abstract": " Performance optimization of stencil computations has been widely studied in the literature, since they occur in many computationally intensive scientific and engineering applications. Compiler frameworks have also been developed that can transform sequential stencil codes for optimization of data locality and parallelism. However, loop skewing is typically required in order to tile stencil codes along the time dimension, resulting in load imbalance in pipelined parallel execution of the tiles. In this paper, we develop an approach for automatic parallelization of stencil codes, that explicitly addresses the issue of load-balanced execution of tiles. Experimental results are provided that demonstrate the effectiveness of the approach.", "num_citations": "273\n", "authors": ["520"]}
{"title": "Synthesis of high-performance parallel programs for a class of ab initio quantum chemistry models\n", "abstract": " This paper provides an overview of a program synthesis system for a class of quantum chemistry computations. These computations are expressible as a set of tensor contractions and arise in electronic structure modeling. The input to the system is a a high-level specification of the computation, from which the system can synthesize high-performance parallel code tailored to the characteristics of the target architecture. Several components of the synthesis system are described, focusing on performance optimization issues that they address.", "num_citations": "240\n", "authors": ["520"]}
{"title": "NWChem\n", "abstract": " Specialized computational chemistry packages have permanently reshaped the landscape of chemical and materials science by providing tools to support and guide experimental efforts and for the prediction of atomistic and electronic properties. In this regard, electronic structure packages have played a special role by using first-principle-driven methodologies to model complex chemical and materials processes. Over the past few decades, the rapid development of computing technologies and the tremendous increase in computational power have offered a unique chance to study complex transformations using sophisticated and predictive many-body techniques that describe correlated behavior of electrons in molecular and condensed phase systems at different levels of theory. In enabling these simulations, novel parallel algorithms have been able to take advantage of computational resources to address the polynomial scaling of electronic structure methods. In this paper, we briefly review the NWChem computational chemistry suite, including its history, design principles, parallel tools, current capabilities, outreach, and outlook.", "num_citations": "210\n", "authors": ["520"]}
{"title": "Dynamic load balancing on single-and multi-GPU systems\n", "abstract": " The computational power provided by many-core graphics processing units (GPUs) has been exploited in many applications. The programming techniques currently employed on these GPUs are not sufficient to address problems exhibiting irregular, and unbalanced workload. The problem is exacerbated when trying to effectively exploit multiple GPUs concurrently, which are commonly available in many modern systems. In this paper, we propose a task-based dynamic load-balancing solution for single-and multi-GPU systems. The solution allows load balancing at a finer granularity than what is supported in current GPU programming APIs, such as NVIDIA's CUDA. We evaluate our approach using both micro-benchmarks and a molecular dynamics application that exhibits significant load imbalance. Experimental results with a single-GPU configuration show that our fine-grained task solution can utilize the\u00a0\u2026", "num_citations": "192\n", "authors": ["520"]}
{"title": "NWChem: Past, present, and future\n", "abstract": " Specialized computational chemistry packages have permanently reshaped the landscape of chemical and materials science by providing tools to support and guide experimental efforts and for the prediction of atomistic and electronic properties. In this regard, electronic structure packages have played a special role by using first-principle-driven methodologies to model complex chemical and materials processes. Over the past few decades, the rapid development of computing technologies and the tremendous increase in computational power have offered a unique chance to study complex transformations using sophisticated and predictive many-body techniques that describe correlated behavior of electrons in molecular and condensed phase systems at different levels of theory. In enabling these simulations, novel parallel algorithms have been able to take advantage of computational resources to address the\u00a0\u2026", "num_citations": "165\n", "authors": ["520"]}
{"title": "Automatic data movement and computation mapping for multi-level parallel architectures with explicitly managed memories\n", "abstract": " Several parallel architectures such as GPUs and the Cell processor have fast explicitly managed on-chip memories, in addition to slow off-chip memory. They also have very high computational power with multiple levels of parallelism. A significant challenge in programming these architectures is to effectively exploit the parallelism available in the architecture and manage the fast memories to maximize performance.", "num_citations": "159\n", "authors": ["520"]}
{"title": "Automatic code generation for many-body electronic structure methods: the tensor contraction engine\n", "abstract": " As both electronic structure methods and the computers on which they are run become increasingly complex, the task of producing robust, reliable, high-performance implementations of methods at a rapid pace becomes increasingly daunting. In this paper we present an overview of the Tensor Contraction Engine (TCE), a unique effort to address issues of both productivity and performance through automatic code generation. The TCE is designed to take equations for many-body methods in a convenient high-level form and acts like an optimizing compiler, producing an implementation tuned to the target computer system and even to the specific chemical problem of interest. We provide examples to illustrate the TCE approach, including the ability to target different parallel programming models, and the effects of particular optimizations.", "num_citations": "149\n", "authors": ["520"]}
{"title": "Lifeline-based global load balancing\n", "abstract": " On shared-memory systems, Cilk-style work-stealing has been used to effectively parallelize irregular task-graph based applications such as Unbalanced Tree Search (UTS). There are two main difficulties in extending this approach to distributed memory. In the shared memory approach, thieves (nodes without work) constantly attempt to asynchronously steal work from randomly chosen victims until they find work. In distributed memory, thieves cannot autonomously steal work from a victim without disrupting its execution. When work is sparse, this results in performance degradation. In essence, a direct extension of traditional work-stealing to distributed memory violates the work-first principle underlying work-stealing. Further, thieves spend useless CPU cycles attacking victims that have no work, resulting in system inefficiencies in multi-programmed contexts. Second, it is non-trivial to detect active distributed\u00a0\u2026", "num_citations": "129\n", "authors": ["520"]}
{"title": "Solving large, irregular graph problems using adaptive work-stealing\n", "abstract": " Solving large, irregular graph problems efficiently is challenging. Current software systems and commodity multiprocessors do not support fine-grained, irregular parallelism well. We present XWS, the X10 work stealing framework, an open-source runtime for the parallel programming language X10 and a library to be used directly by application writers. XWS extends the Cilk work-stealing framework with several features necessary to efficiently implement graph algorithms, viz., support for improperly nested procedures, global termination detection, and phased computation. We also present a strategy to adaptively control the granularity of parallel tasks in the work-stealing scheme, depending on the instantaneous size of the work queue. We compare the performance of the XWS implementations of spanning tree algorithms with that of the hand-written C and Cilk implementations using various graph inputs. We show\u00a0\u2026", "num_citations": "128\n", "authors": ["520"]}
{"title": "Parametric multi-level tiling of imperfectly nested loops\n", "abstract": " Tiling is a crucial loop transformation for generating high performance code on modern architectures. Efficient generation of multi-level tiled code is essential for maximizing data reuse in systems with deep memory hierarchies. Tiled loops with parametric tile sizes (not compile-time constants) facilitate runtime feedback and dynamic optimizations used in iterative compilation and automatic tuning. Previous parametric multi-level tiling approaches have been restricted to perfectly nested loops, where all assignment statements are contained inside the innermost loop of a loop nest. Previous solutions to tiling for imperfect loop nests have only handled fixed tile sizes. In this paper, we present an approach to parametric multi-level tiling of imperfectly nested loops. The tiling technique generates loops that iterate over full rectangular tiles, making them amenable to compiler optimizations such as register tiling. Experimental\u00a0\u2026", "num_citations": "112\n", "authors": ["520"]}
{"title": "Data layout transformation for enhancing data locality on nuca chip multiprocessors\n", "abstract": " With increasing numbers of cores, future CMPs (chip multi-processors) are likely to have a tiled architecture with a portion of shared L2 cache on each tile and a bank-interleaved distribution of the address space. Although such an organization is effective for avoiding access hot-spots, it can cause a significant number of non-local L2 accesses for many commonly occurring regular data access patterns. In this paper we develop a compile-time framework for data locality optimization via data layout transformation. Using a polyhedral model, the program's localizability is determined by analysis of its index set and array reference functions, followed by non-canonical data layout transformation to reduce non-local accesses for localizable computations. Simulation-based results on a 16-core 2D tiled CMP demonstrate the effectiveness of the approach. The developed program transformation technique is also useful in\u00a0\u2026", "num_citations": "98\n", "authors": ["520"]}
{"title": "Scioto: A framework for global-view task parallelism\n", "abstract": " We introduce Scioto, shared collections of task objects, a lightweight framework for providing task management on distributed memory machines under one-sided and global-view parallel programming models. Scioto provides locality aware dynamic load balancing and interoperates with MPI, ARMCI, and global arrays. Additionally, Scioto's task model and programming interface are compatible with many other existing parallel models including UPC, SHMEM, and CAF. Through task parallelism, the Scioto framework provides a solution for overcoming irregularity, load imbalance, and heterogeneity as well as dynamic mapping of computation onto emerging architectures. In this paper, we present the design and implementation of the Scioto framework and demonstrate its effectiveness on the unbalanced tree search (UTS) benchmark and two quantum chemistry codes: the closed shell self-consistent field (SCF\u00a0\u2026", "num_citations": "92\n", "authors": ["520"]}
{"title": "Work stealing and persistence-based load balancers for iterative overdecomposed applications\n", "abstract": " Applications often involve iterative execution of identical or slowly evolving calculations. Such applications require incremental rebalancing to improve load balance across iterations. In this paper, we consider the design and evaluation of two distinct approaches to addressing this challenge: persistence-based load balancing and work stealing. The work to be performed is overdecomposed into tasks, enabling automatic rebalancing by the middleware. We present a hierarchical persistence-based rebalancing algorithm that performs localized incremental rebalancing. We also present an active-message-based retentive work stealing algorithm optimized for iterative applications on distributed memory machines. We demonstrate low overheads and high efficiencies on the full NERSC Hopper (146,400 cores) and ALCF Intrepid systems (163,840 cores), and on up to 128,000 cores on OLCF Titan.", "num_citations": "83\n", "authors": ["520"]}
{"title": "GPU-based implementations of the noniterative regularized-CCSD (T) corrections: applications to strongly correlated systems\n", "abstract": " The details of the graphical processing unit (GPU) implementation of the most computationally intensive (T)-part of the recently introduced regularized CCSD(T) (Reg-CCSD(T)) method [Kowalski, K.; Valiev, M.J. Chem. Phys. 2009, 131, 234107] for calculating electronic energies of strongly correlated systems are discussed. Parallel tests performed for several molecular systems show very good scalability of the triples part of the Reg-CCSD(T) approach. We also discuss the performance of the Reg-CCSD(T) GPU implementation as a function of the parameters defining the partitioning of the spinorbital domain (tiling structure). The accuracy of the Reg-CCSD(T) method is illustrated on three examples: the methyfluoride molecule, dissociation of dodecane, and open-shell Spiro cation (5,5\u2032(4H,4H\u2032)-spirobi[cyclopenta[c]pyrrole] 2,2\u2032,6,6\u2032-tetrahydro cation), which is a frequently used model to study electron transfer\u00a0\u2026", "num_citations": "79\n", "authors": ["520"]}
{"title": "Active-space completely-renormalized equation-of-motion coupled-cluster formalism: Excited-state studies of green fluorescent protein, free-base porphyrin, and oligoporphyrin dimer\n", "abstract": " The completely renormalized equation-of-motion coupled-cluster approach with singles, doubles, and noniterative triples [CR-EOMCCSD(T)] has proven to be a reliable tool in describing vertical excitation energies in small and medium size molecules. In order to reduce the high numerical cost of the genuine CR-EOMCCSD(T) method and make noniterative CR-EOMCCSD(T) approaches applicable to large molecular systems, two active-space variants of this formalism [the CR-EOMCCSd(t)-II and CR-EOMCCSd(t)-III methods], based on two different choices of the subspace of triply excited configurations employed to construct noniterative correction, are introduced. In calculations for green fluorescent protein (GFP) and free-base porphyrin, where the CR-EOMCCSD(T) results are available, we show good agreement between the active-space CR-EOMCCSD(T) (variant II) and full CR-EOMCCSD(T) excitation\u00a0\u2026", "num_citations": "68\n", "authors": ["520"]}
{"title": "An integrated approach to locality-conscious processor allocation and scheduling of mixed-parallel applications\n", "abstract": " Complex parallel applications can often be modeled as directed acyclic graphs of coarse-grained application tasks with dependences. These applications exhibit both task and data parallelism, and combining these two (also called mixed parallelism) has been shown to be an effective model for their execution. In this paper, we present an algorithm to compute the appropriate mix of task and data parallelism required to minimize the parallel completion time (makespan) of these applications. In other words, our algorithm determines the set of tasks that should be run concurrently and the number of processors to be allocated to each task. The processor allocation and scheduling decisions are made in an integrated manner and are based on several factors such as the structure of the task graph, the runtime estimates and scalability characteristics of the tasks, and the intertask data communication volumes. A locality\u00a0\u2026", "num_citations": "57\n", "authors": ["520"]}
{"title": "Supporting the global arrays PGAS model using MPI one-sided communication\n", "abstract": " The industry-standard Message Passing Interface (MPI) provides one-sided communication functionality and is available on virtually every parallel computing system. However, it is believed that MPI's one-sided model is not rich enough to support higher-level global address space parallel programming models. We present the first successful application of MPI one-sided communication as a runtime system for a PGAS model, Global Arrays (GA). This work has an immediate impact on users of GA applications, such as NW Chem, who often must wait several months to a year or more before GA becomes available on a new architecture. We explore challenges present in the application of MPI-2 to PGAS models and motivate new features in the upcoming MPI-3 standard. The performance of our system is evaluated on several popular high-performance computing architectures through communication benchmarking\u00a0\u2026", "num_citations": "56\n", "authors": ["520"]}
{"title": "Scalable implementations of accurate excited-state coupled cluster theories: Application of high-level methods to porphyrin-based systems\n", "abstract": " The development of reliable tools for excited-state simulations is very important for understanding complex processes in the broad class of light harvesting systems and optoelectronic devices. Over the last years we have been developing equation of motion coupled cluster (EOMCC) methods capable of tackling these problems. In this paper we discuss the parallel performance of EOMCC codes which provide accurate description of excited-state correlation effects. Two aspects are discussed in detail:(1) a new algorithm for the iterative EOMCC methods based on improved parallel task scheduling algorithms, and (2) parallel algorithms for the non-iterative methods describing the effect of triply excited configurations. We demonstrate that the most computationally intensive non-iterative part can take advantage of 210,000 cores of the Cray XT5 system at the Oak Ridge Leadership Computing Facility (OLCF), achieving\u00a0\u2026", "num_citations": "47\n", "authors": ["520"]}
{"title": "New-sum: A novel online abft scheme for general iterative methods\n", "abstract": " Emerging high-performance computing platforms, with large component counts and lower power margins, are anticipated to be more susceptible to soft errors in both logic circuits and memory subsystems. We present an online algorithm-based fault tolerance (ABFT) approach to efficiently detect and recover soft errors for general iterative methods. We design a novel checksum-based encoding scheme for matrix-vector multiplication that is resilient to both arithmetic and memory errors. Our design decouples the checksum updating process from the actual computation, and allows adaptive checksum overhead control. Building on this new encoding mechanism, we propose two online ABFT designs that can effectively recover from errors when combined with a checkpoint/rollback scheme. These designs are capable of addressing scenarios under different error rates. Our ABFT approaches apply to a wide range of\u00a0\u2026", "num_citations": "43\n", "authors": ["520"]}
{"title": "Noniterative multireference coupled cluster methods on heterogeneous CPU\u2013GPU systems\n", "abstract": " A novel parallel algorithm for noniterative multireference coupled cluster (MRCC) theories, which merges recently introduced reference-level parallelism (RLP) [Bhaskaran-Nair, K.; Brabec, J.; Apra\u0300, E.; van Dam, H. J. J.; Pittner, J.; Kowalski, K. J. Chem. Phys.2012, 137, 094112] with the possibility of accelerating numerical calculations using graphics processing units (GPUs) is presented. We discuss the performance of this approach applied to the MRCCSD(T) method (iterative singles and doubles and perturbative triples), where the corrections due to triples are added to the diagonal elements of the MRCCSD effective Hamiltonian matrix. The performance of the combined RLP/GPU algorithm is illustrated on the example of the Brillouin\u2013Wigner (BW) and Mukherjee (Mk) state-specific MRCCSD(T) formulations.", "num_citations": "43\n", "authors": ["520"]}
{"title": "Optimizing tensor contraction expressions for hybrid CPU-GPU execution\n", "abstract": " Tensor contractions are generalized multidimensional matrix multiplication operations that widely occur in quantum chemistry. Efficient execution of tensor contractions on Graphics Processing Units (GPUs) requires several challenges to be addressed, including index permutation and small dimension-sizes reducing thread block utilization. Moreover, to apply the same optimizations to various expressions, we need a code generation tool. In this paper, we present our approach to automatically generate CUDA code to execute tensor contractions on GPUs, including management of data movement between CPU and GPU. To evaluate our tool, GPU-enabled code is generated for the most expensive contractions in CCSD(T), a key coupled cluster method, and incorporated into NWChem, a popular computational chemistry suite. For this method, we demonstrate speedup over a factor of 8.4 using one GPU as\u00a0\u2026", "num_citations": "43\n", "authors": ["520"]}
{"title": "Static and dynamic frequency scaling on multicore CPUs\n", "abstract": " Dynamic Voltage and Frequency Scaling (DVFS) typically adapts CPU power consumption by modifying a processor\u2019s operating frequency (and the associated voltage). Typical DVFS approaches include using default strategies such as running at the lowest or the highest frequency or reacting to the CPU\u2019s runtime load to reduce or increase frequency based on the CPU usage. In this article, we argue that a compile-time approach to CPU frequency selection is achievable for affine program regions and can significantly outperform runtime-based approaches. We first propose a lightweight runtime approach that can exploit the properties of the power profile specific to a processor, outperforming classical Linux governors such as powersave or on-demand for computational kernels. We then demonstrate that, for affine kernels in the application, a purely compile-time approach to CPU frequency and core count\u00a0\u2026", "num_citations": "41\n", "authors": ["520"]}
{"title": "Effects of floating-point non-associativity on numerical computations on massively multithreaded systems\n", "abstract": " Floating-point operations, as defined in the IEEE-754 standard, are not associative. The ordering of large numbers of operations (such as summations) that deal with operands of substantially different magnitudes can significantly affect the final result. On massively multi-threaded systems, the non-deterministic nature of how machine floatingpoint operations are interleaved, combined with the fact that intermediate values have to be rounded or truncated to fit in the available precision leads to non-deterministic numerical error propagation. We have investigated on a Cray XMT system the effect of non-deterministic error propagation by observing the convergence rate of a conjugate gradient calculation used as part of a Power State Estimation (PSE) application. As a possible mitigation strategy, we have explored quadruple precision accumulation, as well as a deterministic parallel tree scheme. The tree based approach has consistently outperformed the quadruple precision approach due to an improved convergence rate. As a consequence, we motivate the need for compile time mechanisms that enable enforcement of parallel deterministic operations on the Cray XMT.", "num_citations": "39\n", "authors": ["520"]}
{"title": "An integrated approach for processor allocation and scheduling of mixed-parallel applications\n", "abstract": " Computationally complex applications can often be viewed as a collection of coarse-grained data-parallel tasks with precedence constraints. Researchers have shown that combining task and data parallelism (mixed parallelism) can be an effective approach for executing these applications, as compared to pure task or data parallelism. In this paper, we present an approach to determine the appropriate mix of task and data parallelism, i.e., the set of tasks that should be run concurrently and the number of processors to be allocated to each task. An iterative algorithm is proposed that couples processor allocation and scheduling of mixed-parallel applications on compute clusters so as to minimize the parallel completion time (makespan). Our algorithm iteratively reduces the makespan by increasing the degree of data parallelism of tasks on the critical path that have good scalability and a low degree of potential task\u00a0\u2026", "num_citations": "38\n", "authors": ["520"]}
{"title": "Analytical modeling of cache behavior for affine programs\n", "abstract": " Optimizing compilers implement program transformation strategies aimed at reducing data movement to or from main memory by exploiting the data-cache hierarchy. However, instead of attempting to minimize the number of cache misses, very approximate cost models are used, due to the lack of precise compile-time models for misses for hierarchical caches. The current state of practice for cache miss analysis is based on accurate simulation. However, simulation requires time proportional to the dataset/problem size, as well as the number of distinct cache configurations of interest to be evaluated.   This paper takes a fundamentally different approach, by focusing on polyhedral programs with static control flow. Instead of relying on costly simulation, a closed-form solution for modeling of misses in a set associative cache hierarchy is developed. This solution can enable program transformation choice at compile\u00a0\u2026", "num_citations": "36\n", "authors": ["520"]}
{"title": "Towards effective automatic parallelization for multicore systems\n", "abstract": " The ubiquity of multicore processors in commodity computing systems has raised a significant programming challenge for their effective use. An attractive but challenging approach is automatic parallelization of sequential codes. Although virtually all production C compilers have automatic shared-memory parallelization capability, it is rarely used in practice by application developers because of limited effectiveness. In this paper we describe our recent efforts towards developing an effective automatic parallelization system that uses a polyhedral model for data dependences and program transformations.", "num_citations": "36\n", "authors": ["520"]}
{"title": "Data-driven fault tolerance for work stealing computations\n", "abstract": " Work stealing is a promising technique to dynamically tolerate variations in the execution environment, including faults, system noise, and energy constraints. In this paper, we present fault tolerance mechanisms for task parallel computations, a popular computation idiom, employing work stealing. The computation is organized as a collection of tasks with data in a global address space. The completion of data operations, rather than the actual messages, is tracked to derive an idempotent data store. This information is also used to accurately identify the tasks to be re-executed in the presence of random work stealing. We consider three recovery schemes that present distinct trade-offs---lazy recovery with potentially increased re-execution cost, immediate collective recovery with associated synchronization overheads, and noncollective recovery enabled by additional communication. We employ distributed-memory\u00a0\u2026", "num_citations": "35\n", "authors": ["520"]}
{"title": "Performance characterization of global address space applications: a case study with NWChem\n", "abstract": " The use of global address space languages and one\u2010sided communication for complex applications is gaining attention in the parallel computing community. However, lack of good evaluative methods to observe multiple levels of performance makes it difficult to isolate the cause of performance deficiencies and to understand the fundamental limitations of system and application design for future improvement. NWChem is a popular computational chemistry package, which depends on the Global Arrays/Aggregate Remote Memory Copy Interface suite for partitioned global address space functionality to deliver high\u2010end molecular modeling capabilities. A workload characterization methodology was developed to support NWChem performance engineering on large\u2010scale parallel platforms. The research involved both the integration of performance instrumentation and measurement in the NWChem software, as\u00a0\u2026", "num_citations": "35\n", "authors": ["520"]}
{"title": "Optimizing data locality for fork/join programs using constrained work stealing\n", "abstract": " We present an approach to improving data locality across different phases of fork/join programs scheduled using work stealing. The approach consists of: (1) user-specified and automated approaches to constructing a steal tree, the schedule of steal operations, and (2) constrained work-stealing algorithms that constrain the actions of the scheduler to mirror a given steal tree. These are combined to construct work-stealing schedules that maximize data locality across computation phases while ensuring load balance within each phase. These algorithms are also used to demonstrate dynamic coarsening, an optimization to improve spatial locality and sequential overheads by combining many finer-grained tasks into coarser tasks while ensuring sufficient concurrency for locality-optimized load balance. Implementation and evaluation in Cilk demonstrate performance improvements of up to 2.5x on 80 cores. We also\u00a0\u2026", "num_citations": "34\n", "authors": ["520"]}
{"title": "Fault-tolerant dynamic task graph scheduling\n", "abstract": " In this paper, we present an approach to fault tolerant execution of dynamic task graphs scheduled using work stealing. In particular, we focus on selective and localized recovery of tasks in the presence of soft faults. From users, we elicit the basic task graph structure in terms of successor and predecessor relationships. The work-stealing-based algorithm to schedule such a task graph is augmented to enable recovery when the data and metadata associated with a task get corrupted. We use this redundancy, and knowledge of the task graph structure, to selectively recover from faults with low space and time overheads. We show that the fault tolerant design retains the essential properties of the underlying work stealing-based task scheduling algorithm, and that the fault tolerant execution is asymptotically optimal when task re-execution is taken into account. Experimental evaluation demonstrates the low cost of\u00a0\u2026", "num_citations": "34\n", "authors": ["520"]}
{"title": "Performance Optimization of Tensor Contraction Expressions for Many-Body Methods in Quantum Chemistry\n", "abstract": " Complex tensor contraction expressions arise in accurate electronic structure models in quantum chemistry, such as the coupled cluster method. This paper addresses two complementary aspects of performance optimization of such tensor contraction expressions. Transformations using algebraic properties of commutativity and associativity can be used to significantly decrease the number of arithmetic operations required for evaluation of these expressions. The identification of common subexpressions among a set of tensor contraction expressions can result in a reduction of the total number of operations required to evaluate the tensor contractions. The first part of the paper describes an effective algorithm for operation minimization with common subexpression identification and demonstrates its effectiveness on tensor contraction expressions for coupled cluster equations. The second part of the paper highlights\u00a0\u2026", "num_citations": "34\n", "authors": ["520"]}
{"title": "Efficient execution of recursive programs on commodity vector hardware\n", "abstract": " The pursuit of computational efficiency has led to the proliferation of throughput-oriented hardware, from GPUs to increasingly wide vector units on commodity processors and accelerators. This hardware is designed to efficiently execute data-parallel computations in a vectorized manner. However, many algorithms are more naturally expressed as divide-and-conquer, recursive, task-parallel computations. In the absence of data parallelism, it seems that such algorithms are not well suited to throughput-oriented architectures. This paper presents a set of novel code transformations that expose the data parallelism latent in recursive, task-parallel programs. These transformations facilitate straightforward vectorization of task-parallel programs on commodity hardware. We also present scheduling policies that maintain high utilization of vector resources while limiting space usage. Across several task-parallel\u00a0\u2026", "num_citations": "33\n", "authors": ["520"]}
{"title": "Hypergraph partitioning for automatic memory hierarchy management\n", "abstract": " In this paper, we present a mechanism for automatic management of the memory hierarchy, including secondary storage, in the context of a global address space parallel programming framework. The programmer specifies the parallelism and locality in the computation. The scheduling of the computation into stages, together with the movement of the associated data between secondary storage and global memory, and between global memory and local memory, is automatically managed. A novel formulation of hypergraph partitioning is used to model the optimization problem of minimizing disk I/O. Experimental evaluation of the proposed approach using a sub-computation from the quantum chemistry domain shows a reduction in the disk I/O cost by up to a factor of 11, and a reduction in turnaround time by up to 49%, as compared to alternative approaches used in state-of-the-art quantum chemistry codes.", "num_citations": "33\n", "authors": ["520"]}
{"title": "Noncollective communicator creation in MPI\n", "abstract": " MPI communicators abstract communication operations across application modules, facilitating seamless composition of different libraries. In addition, communicators provide the ability to form groups of processes and establish multiple levels of parallelism. Traditionally, communicators have been collectively created in the context of the parent communicator. The recent thrust toward systems at petascale and beyond has brought forth new application use cases, including fault tolerance and load balancing, that highlight the ability to construct an MPI communicator in the context of its new process group as a key capability. However, it has long been believed that MPI is not capable of allowing the user to form a new communicator in this way. We present a new algorithm that allows the user to create such flexible process groups using only the functionality given in the current MPI standard. We explore\u00a0\u2026", "num_citations": "32\n", "authors": ["520"]}
{"title": "Affine transformations for communication minimal parallelization and locality optimization of arbitrarily nested loop sequences\n", "abstract": " A long running program often spends most of its time in nested loops. The polyhedral model provides powerful abstractions to optimize loop nests with regular accesses for parallel execution. Affine transformations in this model capture a complex sequence of execution-reordering loop transformations that improve performance by parallelization as well as better locality. Although a significant amount of research has addressed affine scheduling and partitioning, the problem of automatically finding good affine transforms for communication-optimized coarse-grained parallelization along with locality optimization for the general case of arbitrarily-nested loop sequences remains a challenging problem-most frameworks do not treat parallelization and locality optimization in an integrated manner, and/or do not optimize across a sequence of producer-consumer loops.In this paper, we develop an approach to communication minimization and locality optimization in tiling of arbitrarily nested loop sequences with affine dependences. We address the minimization of inter-tile communication volume in the processor space, and minimization of reuse distances for local execution at each node. The approach can also fuse across a long sequence of loop nests that have a producer/consumer relationship. Programs requiring one-dimensional versus multi-dimensional time schedules are all handled with the same algorithm. Synchronization-free parallelism, permutable loops or pipelined parallelism, and inner parallel loops can be detected. Examples are provided that demonstrate the power of the framework. The algorithm has been incorporated into a tool\u00a0\u2026", "num_citations": "32\n", "authors": ["520"]}
{"title": "A code generator for high-performance tensor contractions on GPUs\n", "abstract": " Tensor contractions are higher dimensional generalizations of matrix-matrix multiplication. They form the compute-intensive core of many applications in computational science and data science. In this paper, we describe a high-performance GPU code generator for arbitrary tensor contractions. It exploits domain-specific properties about data reuse in tensor contractions to devise an effective code generation schema, coupled with an effective model-driven search, to determine parameters for mapping of computation to threads and staging of data through the GPU memory hierarchy. Experimental evaluation using a set of tensor contraction benchmarks demonstrates performance improvement and/or significantly reduced code generation time over other state-of-the-art tensor contraction libraries and code generators.", "num_citations": "31\n", "authors": ["520"]}
{"title": "A redundant communication approach to scalable fault tolerance in PGAS programming models\n", "abstract": " Recent trends in high-performance computing point toward increasingly large machines with millions of processing, storage, and networking elements. Unfortunately, the reliability of these machines is inversely proportional to their size, resulting in a system-wide mean time between failures (MTBF), ranging from a few days to a few hours. As such, for long-running applications, the ability to efficiently recover from frequent failures is essential. Traditional forms of fault tolerance, such as checkpoint/restart, suffer from performance issues related to limited I/O and memory bandwidth. In this paper, we present a fault-tolerance mechanism that reduces the cost of failure recovery by maintaining shadow data structures and performing redundant remote memory accesses. Results from a computational chemistry application running at scale show that our techniques provide applications with a high degree of fault tolerance\u00a0\u2026", "num_citations": "31\n", "authors": ["520"]}
{"title": "Data locality optimization for synthesis of efficient out-of-core algorithms\n", "abstract": " This paper describes an approach to synthesis of efficient out-of-core code for a class of imperfectly nested loops that represent tensor contraction computations. Tensor contraction expressions arise in many accurate computational models of electronic structure. The developed approach combines loop fusion with loop tiling and uses a performance-model driven approach to loop tiling for the generation of out-of-core code. Experimental measurements are provided that show a good match with model-based predictions and demonstrate the effectiveness of the proposed algorithm.", "num_citations": "31\n", "authors": ["520"]}
{"title": "Downfolding of many-body Hamiltonians using active-space models: Extension of the sub-system embedding sub-algebras approach to unitary coupled cluster formalisms\n", "abstract": " In this paper, we discuss the extension of the recently introduced subsystem embedding subalgebra coupled cluster (SES-CC) formalism to unitary CC formalisms. In analogy to the standard single-reference SES-CC formalism, its unitary CC extension allows one to include the dynamical (outside the active space) correlation effects in an SES induced complete active space (CAS) effective Hamiltonian. In contrast to the standard single-reference SES-CC theory, the unitary CC approach results in a Hermitian form of the effective Hamiltonian. Additionally, for the double unitary CC (DUCC) formalism, the corresponding CAS eigenvalue problem provides a rigorous separation of external cluster amplitudes that describe dynamical correlation effects\u2014used to define the effective Hamiltonian\u2014from those corresponding to the internal (inside the active space) excitations that define the components of eigenvectors\u00a0\u2026", "num_citations": "30\n", "authors": ["520"]}
{"title": "A communication-optimal framework for contracting distributed tensors\n", "abstract": " Tensor contractions are extremely compute intensive generalized matrix multiplication operations encountered in many computational science fields, such as quantum chemistry and nuclear physics. Unlike distributed matrix multiplication, which has been extensively studied, limited work has been done in understanding distributed tensor contractions. In this paper, we characterize distributed tensor contraction algorithms on torus networks. We develop a framework with three fundamental communication operators to generate communication-efficient contraction algorithms for arbitrary tensor contractions. We show that for a given amount of memory per processor, the framework is communication optimal for all tensor contractions. We demonstrate performance and scalability of the framework on up to 262,144 cores on a Blue Gene/Q supercomputer.", "num_citations": "30\n", "authors": ["520"]}
{"title": "Acceleration of streamed tensor contraction expressions on GPGPU-based clusters\n", "abstract": " Tensor contractions are generalized multidimensional matrix multiplication operations that widely occur in quantum chemistry. Efficient execution of tensor contractions on GPUs requires tackling several challenges to be addressed, including index permutation and small dimension-sizes reducing thread block utilization. In this paper, we present our approach to automatically generate CUDA code to execute tensor contractions on GPUs, including management of data movement between CPU and GPU. GPU-enabled code is generated for the most expensive contractions in CCSD(T), a key coupled cluster method, and incorporated into NW Chem, a popular computational chemistry suite. We demonstrate speedup over a factor of 8.4 using one core per node and over 2.6 when utilizing the entire system using hybrid CPU+GPU solution with 2 GPUs and 5 cores. Finally, we analyze the implementation behavior on\u00a0\u2026", "num_citations": "30\n", "authors": ["520"]}
{"title": "Combining analytical and empirical approaches in tuning matrix transposition\n", "abstract": " Matrix transposition is an important kernel used in many applications. Even though its optimization has been the subject of many studies, an optimization procedure that targets the characteristics of current processor architectures has not been developed. In this paper, we develop an integrated optimization framework that addresses a number of issues, including tiling for the memory hierarchy, effective handling of memory misalignment, utilizing memory subsystem characteristics, and the exploitation of the parallelism provided by the vector instruction sets in current processors. A judicious combination of analytical and empirical approaches is used to determine the most appropriate optimizations. The absence of problem information until execution time is handled by generating multiple versions of the code-the best version is chosen at runtime, with assistance from minimal-overhead inspectors. The approach\u00a0\u2026", "num_citations": "30\n", "authors": ["520"]}
{"title": "A framework for load balancing of tensor contraction expressions via dynamic task partitioning\n", "abstract": " In this paper, we introduce the Dynamic Load-balanced Tensor Contractions (DLTC), a domain-specific library for efficient task parallel execution of tensor contraction expressions, a class of computation encountered in quantum chemistry and physics. Our framework decomposes each contraction into smaller unit of tasks, represented by an abstraction referred to as iterators. We exploit an extra level of parallelism by having tasks across independent contractions executed concurrently through a dynamic load balancing runtime. We demonstrate the improved performance, scalability, and flexibility for the computation of tensor contraction expressions on parallel computers using examples from Coupled Cluster (CC) methods.", "num_citations": "29\n", "authors": ["520"]}
{"title": "Effective padding of multidimensional arrays to avoid cache conflict misses\n", "abstract": " Caches are used to significantly improve performance. Even with high degrees of set associativity, the number of accessed data elements mapping to the same set in a cache can easily exceed the degree of associativity. This can cause conflict misses and lower performance, even if the working set is much smaller than cache capacity. Array padding (increasing the size of array dimensions) is a well-known optimization technique that can reduce conflict misses. In this paper, we develop the first algorithms for optimal padding of arrays aimed at a set-associative cache for arbitrary tile sizes. In addition, we develop the first solution to padding for nested tiles and multi-level caches. Experimental results with multiple benchmarks demonstrate a significant performance improvement from padding.", "num_citations": "28\n", "authors": ["520"]}
{"title": "Polycheck: Dynamic verification of iteration space transformations on affine programs\n", "abstract": " High-level compiler transformations, especially loop transformations, are widely recognized as critical optimizations to restructure programs to improve data locality and expose parallelism. Guaranteeing the correctness of program transformations is essential, and to date three main approaches have been developed: proof of equivalence of affine programs, matching the execution traces of programs, and checking bit-by-bit equivalence of program outputs. Each technique suffers from limitations in the kind of transformations supported, space complexity, or the sensitivity to the testing dataset. In this paper, we take a novel approach that addresses all three limitations to provide an automatic bug checker to verify any iteration reordering transformations on affine programs, including non-affine transformations, with space consumption proportional to the original program data and robust to arbitrary datasets of a given\u00a0\u2026", "num_citations": "27\n", "authors": ["520"]}
{"title": "Exascale operating systems and runtime software report\n", "abstract": " Here US Department of Energy (DOE) workshops and reports have identified four key exascale challenges: dramatically improving power efficiency; improving resilience in the presence of increasing faults; enabling efficient data movement across deepening memory hierarchies and new storage technologies; and managing dramatically increased parallelism, especially at the node level. Software solutions that address these challenges must also improve programmability, expanding the community of computational scientists who can use leadership-class platforms. To address these challenges, DOE must develop new techniques, novel designs, and advanced software architectures for next-generation exascale software infrastructure. In this report, we discuss challenges and approaches to exascale operating system and runtime (OS/R) software. The Exascale Operating Systems and Runtime (OS/R) Software Technical Council canvassed hardware architects, application programmers, parallel tool developers, DOE high-performance computing (HPC) facilities, and the vendors that sell and support integrated platforms. After considering the collective requirements of these constituents and examining the future research challenges and current software gaps, the council recommends that DOE invest in targeted advanced computer science research and in specific coordinating activities to enable the effective and successful development of anticipated exascale systems.", "num_citations": "26\n", "authors": ["520"]}
{"title": "Massively parallel implementation of the multireference Brillouin\u2013Wigner CCSD method\n", "abstract": " This Letter reports the parallel implementation of the Multireference Brillouin\u2013Wigner Coupled Cluster method with Single and Double excitations (MR BWCCSD). Preliminary tests for systems composed of 304 and 440 correlated orbitals demonstrate the performance of our implementation across 1000 cores and clearly indicate the advantages of using improved task scheduling. Possible ways for further improvements of the parallel performance are also delineated.", "num_citations": "25\n", "authors": ["520"]}
{"title": "EOMCC, MRPT, and TDDFT studies of charge transfer processes in mixed-valence compounds: Application to the Spiro molecule\n", "abstract": " The proper description of electron transfer (ET) processes in mixed-valence compounds poses a significant challenge for commonly used theoretical approaches. In this paper we analyze the 12A2 and 22A2 potential energy surfaces of the Spiro cation (5,5\u2032(4H,4H\u2032)-spirobi[cyclopenta[c]pyrrole]2,2\u2032,6,6\u2032-tetrahydro cation) which is a frequently used model to study ET processes. We compare and contrast the results obtained with three different methods: multireference perturbation theory, equation-of-motion coupled cluster theory, time-dependent density functional theory. We demonstrate that the proper inclusion of dynamical correlation effects plays a crucial role in the description of an avoided crossing between potential energy surfaces. We also find that proper balancing of the ground- and excited-state correlation effects is especially challenging in the vicinity of the 12A2 and 22A2 avoided crossing region.", "num_citations": "25\n", "authors": ["520"]}
{"title": "Scalable replay with partial-order dependencies for message-logging fault tolerance\n", "abstract": " Deterministic replay of a parallel application is commonly used for discovering bugs or to recover from a hard fault with message-logging fault tolerance. For message passing programs, a major source of overhead during forward execution is recording the order in which messages are sent and received. During replay, this ordering must be used to deterministically reproduce the execution. Previous work in replay algorithms often makes minimal assumptions about the programming model and application to maintain generality. However, in many applications, only a partial order must be recorded due to determinism intrinsic in the program, ordering constraints imposed by the execution model, and events that are commutative (their relative execution order during replay does not need to be reproduced exactly). In this paper, we present a novel algebraic framework for reasoning about the minimum dependencies\u00a0\u2026", "num_citations": "24\n", "authors": ["520"]}
{"title": "Efficient synthesis of out-of-core algorithms using a nonlinear optimization solver\n", "abstract": " Summary form only given. We address the problem of efficient out-of-core code generation for a special class of imperfectly nested loops encoding tensor contractions. These loops operate on arrays too large to fit in physical memory. The problem involves determining optimal tiling and placement of disk I/O statements. This entails a search in an explosively large parameter space. We formulate the problem as a nonlinear optimization problem and use a discrete constraint solver to generate optimized out-of-core code. Measurements on sequential and parallel versions of the generated code demonstrate the effectiveness of the proposed approach.", "num_citations": "24\n", "authors": ["520"]}
{"title": "Towards resiliency evaluation of vector programs\n", "abstract": " The systems resilience research community has developed methods to manually insert additional source-programlevel assertions to trap errors, and also devised tools to conductfault injection studies for scalar program codes. In this work, we contribute the first vector oriented LLVM-level fault injectorVULFI to help study the effects of faults in vector architecturesthat are of growing importance, especially for vectorizing loops. Using VULFI, we conduct a resiliency study of nine real-worldvector benchmarks using Intel's AVX and SSE extensions asthe target vector instruction sets, and offer the first reportedunderstanding of how faults affect vector instruction sets. We takethis work further toward automating the insertion of resilienceassertions during compilation. This is based on our observationthat during intermediate (e.g., LLVM-level) code generation tohandle full and partial vectorization, modern compilers exploit(and\u00a0\u2026", "num_citations": "23\n", "authors": ["520"]}
{"title": "Steal tree: Low-overhead tracing of work stealing schedulers\n", "abstract": " Work stealing is a popular approach to scheduling task-parallel programs. The flexibility inherent in work stealing when dealing with load imbalance results in seemingly irregular computation structures, complicating the study of its runtime behavior. In this paper, we present an approach to efficiently trace async-finish parallel programs scheduled using work stealing. We identify key properties that allow us to trace the execution of tasks with low time and space overheads. We also study the usefulness of the proposed schemes in supporting algorithms for data-race detection and retentive stealing presented in the literature. We demonstrate that the perturbation due to tracing is within the variation in the execution time with 99% confidence and the traces are concise, amounting to a few tens of kilobytes per thread in most cases. We also demonstrate that the traces enable significant reductions in the cost of detecting\u00a0\u2026", "num_citations": "23\n", "authors": ["520"]}
{"title": "Empirical performance model-driven data layout optimization and library call selection for tensor contraction expressions\n", "abstract": " Empirical optimizers like ATLAS have been very effective in optimizing computational kernels in libraries. The best choice of parameters such as tile size and degree of loop unrolling is determined in ATLAS by executing different versions of the computation. In contrast, optimizing compilers use a model-driven approach to program transformation. While the model-driven approach of optimizing compilers is generally orders of magnitude faster than ATLAS-like library generators, its effectiveness can be limited by the accuracy of the performance models used. In this paper, we describe an approach where a class of computations is modeled in terms of constituent operations that are empirically measured, thereby allowing modeling of the overall execution time. The performance model with empirically determined cost components is used to select library calls and choose data layout transformations in the context of the\u00a0\u2026", "num_citations": "23\n", "authors": ["520"]}
{"title": "Role of many-body effects in describing low-lying excited states of \u03c0-conjugated chromophores: High-level equation-of-motion coupled-cluster studies of fused porphyrin systems\n", "abstract": " The unusual photophysical properties of the \u03c0-conjugated chromophores make them potential building blocks of various molecular devices. In particular, significant narrowing of the HOMO\u2013LUMO gaps can be observed as an effect of functionalization chromophores with polycyclic aromatic hydrocarbons (PAHs). In this paper we present equation-of-motion coupled cluster (EOMCC) calculations for vertical excitation energies of several functionalized forms of porphyrins. The results for free-base porphyrin (FBP) clearly demonstrate significant differences between functionalization of FBP with one- (anthracene) and two-dimensional (coronene) structures. We also compare the EOMCC results with the experimentally available results for anthracene fused zinc\u2013porphyrin. The impact of various types of correlation effects is illustrated on several benchmark models, where the comparison with the experiment is possible. In\u00a0\u2026", "num_citations": "22\n", "authors": ["520"]}
{"title": "Localized fault recovery for nested fork-join programs\n", "abstract": " Nested fork-join programs scheduled using work stealing can automatically balance load and adapt to changes in the execution environment. In this paper, we design an approach to efficiently recover from faults encountered by these programs. Specifically, we focus on localized recovery of the task space in the presence of fail-stop failures. We present an approach to efficiently track, under work stealing, the relationships between the work executed by various threads. This information is used to identify and schedule the tasks to be re-executed without interfering with normal task execution. The algorithm precisely computes the work lost, incurs minimal re-execution overhead, and can recover from an arbitrary number of failures. Experimental evaluation demonstrates low overheads in the absence of failures, recovery overheads on the same order as the lost work, and much lower recovery costs than alternative\u00a0\u2026", "num_citations": "21\n", "authors": ["520"]}
{"title": "On fusing recursive traversals of Kd trees\n", "abstract": " Loop fusion is a key program transformation for data locality optimization that is implemented in production compilers. But optimizing compilers for imperative languages currently cannot ex-ploit fusion opportunities across a set of recursive tree traversal computations with producer-consumer relationships. In this paper, we develop a compile-time approach to dependence characterization and program transformation to enable fusion across recursively specified traversals over kd trees. We present the FuseT source-to-source code transformation framework to automatically generate fused composite recursive operators from an input program containing a sequence of primitive recursive operators. We use our framework to implement fused operators for MADNESS, Multi-resolution Adaptive Numerical Environment for Scientific Simulation. We show that locality optimization through fusion can offer significant\u00a0\u2026", "num_citations": "21\n", "authors": ["520"]}
{"title": "Detailed characterization of deep level defects in InGaN Schottky diodes by optical and thermal deep level spectroscopies\n", "abstract": " Schottky diode properties of semitransparent Ag(4 nm)/Au(4 nm) metal stack on In0.2Ga0.8N were investigated and defect characterization was performed using capacitance deep level transient (DLTS) and optical spectroscopy (DLOS). DLTS measurements made on the In0.2Ga0.8N Schottky diodes, which displayed a barrier height of 0.66 eV, revealed the presence of two deep levels located at Ec-0.39 eV and Ec-0.89 eV with nearly identical concentrations of \u223c1.2\u2009\u00d7\u20091015 cm\u22123. Three deeper defect levels were observed by DLOS at Ec-1.45 eV, Ec-1.76 eV, and Ec-2.50 eV with concentrations of 1.3\u2009\u00d7\u20091015cm\u22123, 3.2\u2009\u00d7\u20091015cm\u22123, and 6.1\u2009\u00d7\u20091016 cm\u22123, respectively. The latter, with its high trap concentration and energy position lying 0.4 eV above the valance band, suggests a possible role in compensation of carrier concentration, whereas the mid-gap positions of the other two levels imply that they will\u00a0\u2026", "num_citations": "21\n", "authors": ["520"]}
{"title": "Tolerating correlated failures for generalized cartesian distributions via bipartite matching\n", "abstract": " Faults are expected to play an increasingly important role in how algorithms and applications are designed to run on future extreme-scale systems. Algorithm-based fault tolerance (ABFT) is a promising approach that involves modifications to the algorithm to recover from faults with lower overheads than replicated storage and a significant reduction in lost work compared to checkpoint-restart techniques. Fault-tolerant linear algebra (FTLA) algorithms employ additional processors that store parities along the dimensions of a matrix to tolerate multiple, simultaneous faults. Existing approaches assume regular data distributions (blocked or block-cyclic) with the failures of each data block being independent. To match the characteristics of failures on parallel computers, we extend these approaches to mapping parity blocks in several important ways. First, we handle parity computation for generalized Cartesian data\u00a0\u2026", "num_citations": "21\n", "authors": ["520"]}
{"title": "Identifying cost-effective common subexpressions to reduce operation count in tensor contraction evaluations\n", "abstract": " Complex tensor contraction expressions arise in accurate electronic structure models in quantum chemistry, such as the coupled cluster method. Transformations using algebraic properties of commutativity and associativity can be used to significantly decrease the number of arithmetic operations required for evaluation of these expressions. Operation minimization is an important optimization step for the Tensor Contraction Engine, a tool being developed for the automatic transformation of high-level tensor contraction expressions into efficient programs. The identification of common subexpressions among a set of tensor contraction expressions can result in a reduction of the total number of operations required to evaluate the tensor contractions. In this paper, we develop an effective algorithm for common subexpression identification and demonstrate its effectiveness on tensor contraction expressions for\u00a0\u2026", "num_citations": "21\n", "authors": ["520"]}
{"title": "Efficient parallel out-of-core matrix transposition\n", "abstract": " This paper addresses the problem of parallel transposition of large out-of-core arrays. Although algorithms for out-of-core matrix transposition have been widely studied, previously proposed algorithms have sought to minimize the number of I/O operations and the in-memory permutation time. We propose an algorithm that directly targets the improvement of overall transposition time. The I/O characteristics of the system are used to determine the read, write and communication block sizes such that the total execution time is minimized. We also provide a solution to the array redistribution problem for arrays on disk. The solution to the sequential transposition problem and the parallel array redistribution problem are then combined to obtain an algorithm for the parallel out-of-core transposition problem.", "num_citations": "21\n", "authors": ["520"]}
{"title": "Multi-fault tolerance for cartesian data distributions\n", "abstract": " Faults are expected to play an increasingly important role in how algorithms and applications are designed to run on future extreme-scale systems. Algorithm-based fault tolerance is a promising approach that involves modifications to the algorithm to recover from faults with lower overheads than replicated storage and a significant reduction in lost work compared to checkpoint-restart techniques. Fault-tolerant linear algebra algorithms employ additional processors that store parities along the dimensions of a matrix to tolerate multiple, simultaneous faults. Existing approaches assume regular data distributions (blocked or block-cyclic) with the failures of each data block being independent. To match the characteristics of failures on parallel computers, we extend these approaches to mapping parity blocks in several important ways. First, we handle parity computation for generalized Cartesian data\u00a0\u2026", "num_citations": "18\n", "authors": ["520"]}
{"title": "Global Futures: A multithreaded execution model for Global Arrays-based applications\n", "abstract": " We present Global Futures (GF), an execution model extension to Global Arrays, which is based on a PGAS-compatible active message-based paradigm. We describe the design and implementation of Global Futures and illustrate its use in a computational chemistry application benchmark (Hartree-Fock matrix construction using the Self-Consistent Field method). Our results show how we used GF to increase the scalability of the Hartree-Fock matrix build to 6,144 cores of an Infiniband cluster. We also show how GF's multithreaded execution has comparable performance to the traditional process-based SPMD model.", "num_citations": "18\n", "authors": ["520"]}
{"title": "Design and implementation of a one-sided communication interface for the IBM eServer Blue Gene\u00ae supercomputer\n", "abstract": " This paper discusses the design and implementation of a one-sided communication interface for the IBM Blue Gene/L supercomputer. This interface facilitates ARMCI and the Global Arrays toolkit and can be used by other one-sided communication libraries. New protocols, interrupt driven communication, and compute node kernel enhancements were required to enable these libraries. Three possible methods for enabling ARMCI on the Blue Gene/L software stack are discussed. A detailed look into the development process shows how the implementation of the one-sided communication interface was completed. This was accomplished on a compressed time scale with the collaboration of various organizations within IBM and open source communities. In addition to enabling the one-sided libraries, bandwidth enhancements were made for communication along a diagonal on the Blue Gene/L torus network. The\u00a0\u2026", "num_citations": "18\n", "authors": ["520"]}
{"title": "Task scheduling and file replication for data-intensive jobs with batch-shared I/O\n", "abstract": " This paper addresses the problem of efficient execution of a batch of data-intensive tasks with batch-shared I/O behavior, on coupled storage and compute clusters. Two scheduling schemes are proposed: 1) a 0-1 integer programming (IP) based approach, which couples task scheduling and data replication, and 2) a bi-level hypergraph partitioning based heuristic approach (BiPartition), which decouples task scheduling and data replication. The experimental results show that: 1) the IP scheme achieves the best batch execution time, but has significant scheduling overhead, thereby restricting its application to small scale workloads, and 2) the BiPartition scheme is a better fit for larger workloads and systems - it has very low scheduling overhead and no more than 5-10% degradation in solution quality, when compared with the IP based approach", "num_citations": "18\n", "authors": ["520"]}
{"title": "A domain-specific compiler for a parallel multiresolution adaptive numerical simulation environment\n", "abstract": " This paper describes the design and implementation of a layered domain-specific compiler to support MADNESS-Multiresolution ADaptive Numerical Environment for Scientific Simulation. MADNESS is a high-level software environment for the solution of integral and differential equations in many dimensions, using adaptive and fast harmonic analysis methods with guaranteed precision. MADNESS uses k-d trees to represent spatial functions and implements operators like addition, multiplication, differentiation, and integration on the numerical representation of functions. The MADNESS runtime system provides global namespace support and a task-based execution model including futures. MADNESS is currently deployed on massively parallel supercomputers and has enabled many science advances. Due to the highly irregular and statically unpredictable structure of the k-d trees representing the spatial\u00a0\u2026", "num_citations": "17\n", "authors": ["520"]}
{"title": "Efficient scheduling of recursive control flow on gpus\n", "abstract": " Graphics processing units (GPUs) have rapidly emerged as a very significant player in high performance computing. Single instruction multiple thread (SIMT) pipelines are typically used in GPUs to exploit parallelism and maximize performance. Although support for unstructured control flow has been included in GPUs, efficiently managing thread divergence for arbitrary parallel programs remains a critical challenge. In this paper, we focus on the problem of supporting recursion in modern GPUs. We design and comparatively evaluate various algorithms to manage thread divergence encountered in recursive programs. The results improve upon traditional post-dominator based reconvergence mechanisms designed to handle thread divergence due to control flow within a procedure.", "num_citations": "17\n", "authors": ["520"]}
{"title": "Efficient sparse matrix-matrix multiplication on heterogeneous high performance systems\n", "abstract": " The efficient implementation of sparse matrix-matrix multiplications on high performance parallel machines poses several challenges: large size of input matrices, compressed representation, density of the output matrices, partitioning and load balancing of matrices that present parts with large differences in density and, thus, in computation times. In this paper we show how, starting from the requirements of such application, we developed a framework that allows its efficient implementation on heterogeneous clusters. We introduce a task based programming model and a runtime supported execution model which provides dynamic load balancing on clusters composed by CPUs and GPUs, allowing better utilization of the system while easing the handling of sparse matrices. The results show that our solution, which co-designs the application together with the programming model and the runtime system, is able to\u00a0\u2026", "num_citations": "17\n", "authors": ["520"]}
{"title": "A work stealing based approach for enabling scalable optimal sequence homology detection\n", "abstract": " Sequence homology detection is central to a number of bioinformatics applications including genome sequencing and protein family characterization. Given millions of sequences, the goal is to identify all pairs of sequences that are highly similar (or \u201chomologous\u201d) on the basis of alignment criteria. While there are optimal alignment algorithms to compute pairwise homology, their deployment for large-scale is currently not feasible; instead, heuristic methods are used at the expense of quality. Here, we present the design and evaluation of a parallel implementation for conducting optimal homology detection on distributed memory supercomputers. Our approach uses a combination of techniques from asynchronous load balancing (viz. work stealing, dynamic task counters), data replication, and exact-matching filters to achieve homology detection at scale. Results for 2.56 M sequences on up to 8K cores show parallel\u00a0\u2026", "num_citations": "16\n", "authors": ["520"]}
{"title": "Selective recovery from failures in a task parallel programming model\n", "abstract": " We present a fault tolerant task pool execution environment that is capable of performing fine-grain selective restart using a lightweight, distributed task completion tracking mechanism. Compared with conventional checkpoint/restart techniques, this system offers a recovery penalty that is proportional to the degree of failure rather than the system size. We evaluate this system using the Self Consistent Field (SCF) kernel which forms an important component in ab initio methods for computational chemistry. Experimental results indicate that fault tolerant task pools are robust in the presence of an arbitrary number of failures and that they offer low overhead in the absence of faults.", "num_citations": "16\n", "authors": ["520"]}
{"title": "Exploiting vector and multicore parallelism for recursive, data-and task-parallel programs\n", "abstract": " Modern hardware contains parallel execution resources that are well-suited for data-parallelism-vector units-and task parallelism-multicores. However, most work on parallel scheduling focuses on one type of hardware or the other. In this work, we present a scheduling framework that allows for a unified treatment of task-and data-parallelism. Our key insight is an abstraction, task blocks, that uniformly handles data-parallel iterations and task-parallel tasks, allowing them to be scheduled on vector units or executed independently as multicores. Our framework allows us to define schedulers that can dynamically select between executing task-blocks on vector units or multicores. We show that these schedulers are asymptotically optimal, and deliver the maximum amount of parallelism available in computation trees. To evaluate our schedulers, we develop program transformations that can convert mixed data-and task\u00a0\u2026", "num_citations": "15\n", "authors": ["520"]}
{"title": "Scalable communication trace compression\n", "abstract": " Characterizing the communication behavior of parallel programs through tracing can help understand an application's characteristics, model its performance, and predict behavior on future systems. However, lossless communication traces can get prohibitively large, causing programmers to resort to variety of other techniques. In this paper, we present a novel approach to lossless communication trace compression. We augment the sequitur compression algorithm to employ it in communication trace compression of parallel programs. We present optimizations to reduce the memory overhead, reduce size of the trace files generated, and enable compression across multiple processes in a parallel program. The evaluation shows improved compression and reduced overhead over other approaches, with up to 3 orders of magnitude improvement for the NAS MG benchmark. We also observe that, unlike existing\u00a0\u2026", "num_citations": "15\n", "authors": ["520"]}
{"title": "Qasmbench: A low-level qasm benchmark suite for nisq evaluation and simulation\n", "abstract": " The rapid development of quantum computing (QC) in the NISQ era urgently demands a low-level benchmark suite and insightful evaluation metrics for characterizing the properties of prototype NISQ devices, the efficiency of QC programming compilers, schedulers and assemblers, and the capability of quantum simulators in a classical computer. In this work, we fill this gap by proposing a low-level, easy-to-use benchmark suite called QASMBench based on the OpenQASM assembly representation. It consolidates commonly used quantum routines and kernels from a variety of domains including chemistry, simulation, linear algebra, searching, optimization, arithmetic, machine learning, fault tolerance, cryptography, etc., trading-off between generality and usability. To analyze these kernels in terms of NISQ device execution, in addition to circuit width and depth, we propose four circuit metrics including gate density, retention lifespan, measurement density, and entanglement variance, to extract more insights about the execution efficiency, the susceptibility to NISQ error, and the potential gain from machine-specific optimizations. Most of the QASMBench application code can be launched and verified in IBM-Q directly. With the help from q-convert, QASMBench can be evaluated on various platforms and simulation environments. QASMBench is released at: http://github.com/pnnl/QASMBench.", "num_citations": "14\n", "authors": ["520"]}
{"title": "Toward a general theory of optimal checkpoint placement\n", "abstract": " Checkpoint/restart has been widely used to cope with fail-stop errors. The checkpointing frequency is most often optimized by assuming an exponential failure distribution. However, field studies show that most often failures do not follow a constant failure rate exponential distribution. Therefore, the optimal checkpointing frequency should be computed and tuned considering the different distributions that failures follow. Moreover, due to operating system and input/output jitter and hybrid solutions that combine checkpointing with other techniques, such as data compression, checkpointing time can no longer be assumed constant. Thus, time varying checkpointing time should be accounted for to realistically model the application execution.In this study, we develop a mathematical theory and model to optimize the checkpointing frequency with respect to arbitrary failure distributions while capturing time-dependent non\u00a0\u2026", "num_citations": "14\n", "authors": ["520"]}
{"title": "Framework for distributed contractions of tensors with symmetry\n", "abstract": " Tensor contractions represent the most computeintensive core kernels in ab initio computational quantum chemistry and nuclear physics. In this paper we develop a comprehensive framework for distributed tensor contractions on a torus network. The contraction algorithms are constructed using three basic data movement operations: Rotation, Recursive Broadcast and Reduction. A characterization is developed that classifies all possible mappings of the tensor elements and the computational iteration space onto processors, associating each mapping with the requisite data movement primitives. A cost model enables the selection of the algorithm with minimal communication overhead.We then develop an efficient approach to contract symmetric tensors. We introduce a novel approach that avoids data redistribution in contracting symmetric tensors while avoiding redundant storage and maintaining load balance. We present experimental results on two parallel supercomputers, for several symmetric contractions that appear in the CCSD coupled cluster quantum chemistry method.", "num_citations": "14\n", "authors": ["520"]}
{"title": "Primetile: A parametric multi-level tiler for imperfect loop nests\n", "abstract": " Tiling is a crucial loop transformation for generating high performance code on modern architectures. Efficient generation of multi-level tiled code is essential for maximizing data reuse in systems with deep memory hierarchies. Tiled loops with parametric tile sizes (not compile-time constants) facilitate runtime feedback and dynamic optimizations used in iterative compilation and automatic tuning. Previous parametric multi-level tiling approaches have been restricted to perfectly nested loops, where all assignment statements are contained inside the innermost loop of a loop nest. Previous solutions to tiling for imperfect loop nests have only handled fixed tile sizes. In this paper, we present an approach to parametric multi-level tiling of imperfectly nested loops. The tiling technique generates loops that iterate over full rectangular tiles, making them amenable to compiler optimizations such as register tiling. Experimental results using a number of computational benchmarks demonstrate the effectiveness of the developed tiling approach.", "num_citations": "14\n", "authors": ["520"]}
{"title": "Global trees: a framework for linked data structures on distributed memory parallel systems\n", "abstract": " This paper describes the Global Trees (GT) system that provides a multi-layered interface to a global address space view of distributed tree data structures, while providing scalable performance on distributed memory systems. The Global Trees system utilizes coarse-grained data movement to enhance locality and communication efficiency. We describe the design and implementation of GT, illustrate its use in the context of a gravitational simulation application, and provide experimental results that demonstrate the effectiveness of the approach. The key benefits of using this system include efficient shared-memory style programming of distributed trees, tree-specific optimizations for data access and computation, and the ability to customize many aspects of GT to optimize application performance.", "num_citations": "14\n", "authors": ["520"]}
{"title": "Efficient Search-Space Pruning for Integrated Fusion and Tiling Transformations\n", "abstract": " Compile\u2010time optimizations involve a number of transformations such as loop permutation, fusion, tiling, array contraction etc. The selection of the appropriate transformation to minimize the execution time is a challenging task. We address this problem in the context of tensor contraction expressions involving arrays too large to fit in main memory. Domain\u2010specific features of the computation are exploited to develop an integrated framework that facilitates the exploration of the entire search space of optimizations. In this paper, we discuss the exploration of the space of loop fusion and tiling transformations in order to minimize the disk I/O cost. These two transformations are integrated and pruning strategies are presented that significantly reduce the number of loop structures to be evaluated for subsequent transformations. The evaluation of the framework using representative contraction expressions from quantum\u00a0\u2026", "num_citations": "14\n", "authors": ["520"]}
{"title": "Cache locality optimization for recursive programs\n", "abstract": " We present an approach to optimize the cache locality for recursive programs by dynamically splicing---recursively interleaving---the execution of distinct function invocations. By utilizing data effect annotations, we identify concurrency and data reuse opportunities across function invocations and interleave them to reduce reuse distance. We present algorithms that efficiently track effects in recursive programs, detect interference and dependencies, and interleave execution of function invocations using user-level (non-kernel) lightweight threads. To enable multi-core execution, a program is parallelized using a nested fork/join programming model. Our cache optimization strategy is designed to work in the context of a random work stealing scheduler. We present an implementation using the MIT Cilk framework that demonstrates significant improvements in sequential and parallel performance, competitive with a state\u00a0\u2026", "num_citations": "13\n", "authors": ["520"]}
{"title": "Compiler-assisted detection of transient memory errors\n", "abstract": " The probability of bit flips in hardware memory systems is projected to increase significantly as memory systems continue to scale in size and complexity. Effective hardware-based error detection and correction require that the complete data path, involving all parts of the memory system, be protected with sufficient redundancy. First, this may be costly to employ on commodity computing platforms, and second, even on high-end systems, protection against multi-bit errors may be lacking. Therefore, augmenting hardware error detection schemes with software techniques is of considerable interest.", "num_citations": "13\n", "authors": ["520"]}
{"title": "Locality conscious processor allocation and scheduling for mixed parallel applications\n", "abstract": " Complex applications can often be viewed as a collection of coarse-grained data-parallel application components with precedence constraints. It has been shown that combining task and data parallelism (mixed parallelism) can be an effective execution paradigm for these applications. In this paper, we present an algorithm to compute the appropriate mix of task and data parallelism based on the scalability characteristics of the tasks as well as the intertask data communication costs, such that the parallel completion time (makespan) is minimized. The algorithm iteratively reduces the makespan by increasing the degree of data parallelism of tasks on the critical path that have good scalability and a low degree of potential task parallelism. Data communication costs along the critical path are minimized by exploiting parallel transfer mechanisms and use of a locality conscious backfill scheduler. Evaluation using\u00a0\u2026", "num_citations": "13\n", "authors": ["520"]}
{"title": "Integrated loop optimizations for data locality enhancement of tensor contraction expressions\n", "abstract": " A very challenging issue for optimizing compilers is the phase ordering problem: In what order should a collection of compiler optimizations be performed? We address this problem in the context of optimizing a sequence of tensor contractions. The pertinent loop transformations are loop permutation, tiling, and fusion; in addition, the placement of disk I/O statements crucially affects performance. The space of possible combinations is exponentially large. We develop novel pruning strategies whereby a search problem in a larger space is replaced by a large number of searches in a much smaller space, to determine the optimal permutation, fusion, tiling and placement of disk I/O statements. Experimental results show that we obtain an improvement in I/O cost by a factor of up to 2.6 over an equi-tile-size approach.", "num_citations": "13\n", "authors": ["520"]}
{"title": "The global arrays user manual\n", "abstract": " The Global Arrays (GA) toolkit provides a shared memory style programming environment in the context of distributed array data structures (called \u201cglobal arrays\u201d). From the user perspective, a global array can be used as if it was stored in shared memory. All details of the data distribution, addressing, and data access are encapsulated in the global array objects. Information about the actual data distribution and locality can be easily obtained and taken advantage of whenever data locality is important. The primary target architectures for which GA was developed are massively-parallel distributed-memory and scalable shared-memory systems.GA divides logically shared data structures into \u201clocal\u201d and \u201cremote\u201d portions. It recognizes variable data transfer costs required to access the data depending on the proximity attributes. A local portion of the shared memory is assumed to be faster to access and the remainder (remote portion) is considered slower to access. These differences do not hinder the ease-of-use since the library provides uniform access mechanisms for all the shared data regardless where the referenced data is located. In addition, any processes can access a local portion of the shared data directly/in-place like any other data in process local memory. Access to other portions of the shared data must be done through the GA library calls.", "num_citations": "12\n", "authors": ["520"]}
{"title": "An efficient mixed-mode representation of sparse tensors\n", "abstract": " The Compressed Sparse Fiber (CSF) representation for sparse tensors is a generalization of the Compressed Sparse Row (CSR) format for sparse matrices. For a tensor with d modes, typical tensor methods such as CANDECOMP/PARAFAC decomposition (CPD) require a sequence of d tensor computations, where efficient memory access with respect to different modes is required for each of them. The straightforward solution is to use d distinct representations of the tensor, with each one being efficient for one of the d computations. However, a d-fold space overhead is often unacceptable in practice, especially with memory-constrained GPUs. In this paper, we present a mixed-mode tensor representation that partitions the tensor's nonzero elements into disjoint sections, each of which is compressed to create fibers along a different mode. Experimental results demonstrate that better performance can be achieved\u00a0\u2026", "num_citations": "11\n", "authors": ["520"]}
{"title": "Load balancing of dynamical nucleation theory Monte Carlo simulations through resource sharing barriers\n", "abstract": " The dynamical nucleation theory Monte Carlo (DNTMC) application from the NW Chem computational chemistry suite utilizes a Markov chain Monte Carlo, two-level parallel structure, with periodic synchronization points that assemble the results of independent finer-grained calculations. Like many such applications, the existing code employs a static partitioning of processes into groups and assigns each group a piece of the finer-grained parallel calculation. A significant cause of performance degradation is load imbalance among groups since the time requirements of the inner-parallel calculation varies widely with the input problem and as a result of the Monte Carlo simulation. We present a novel approach to load balancing such calculations with minimal changes to the application. We introduce the concept of a resource sharing barrier (RSB) - a barrier that allows process groups waiting on other processes'\u00a0\u2026", "num_citations": "11\n", "authors": ["520"]}
{"title": "Density matrix quantum circuit simulation via the BSP machine on modern GPU clusters\n", "abstract": " As quantum computers evolve, simulations of quantum programs on classical computers will be essential in validating quantum algorithms, understanding the effect of system noise, and designing applications for future quantum computers. In this paper, we first propose a new multi-GPU programming methodology called MG-BSP which constructs a virtual BSP machine on top of modern multi-GPU platforms, and apply this methodology to build a multi-GPU density matrix quantum simulator called DM-Sim. We propose a new formulation that can significantly reduce communication overhead, and show that this formula transformation can conserve the semantics despite noise being introduced. We build the tool-chain for the simulator to run open standard quantum assembly code, execute synthesized quantum circuits, and perform ultra-deep and largescale simulations. We evaluated DM-Sim on several state-of\u00a0\u2026", "num_citations": "10\n", "authors": ["520"]}
{"title": "Q# and NWChem: tools for scalable quantum chemistry on quantum computers\n", "abstract": " Fault-tolerant quantum computation promises to solve outstanding problems in quantum chemistry within the next decade. Realizing this promise requires scalable tools that allow users to translate descriptions of electronic structure problems to optimized quantum gate sequences executed on physical hardware, without requiring specialized quantum computing knowledge. To this end, we present a quantum chemistry library, under the open-source MIT license, that implements and enables straightforward use of state-of-art quantum simulation algorithms. The library is implemented in Q#, a language designed to express quantum algorithms at scale, and interfaces with NWChem, a leading electronic structure package. We define a standardized schema for this interface, Broombridge, that describes second-quantized Hamiltonians, along with metadata required for effective quantum simulation, such as trial wavefunction ansatzes. This schema is generated for arbitrary molecules by NWChem, conveniently accessible, for instance, through Docker containers and a recently developed web interface EMSL Arrows. We illustrate use of the library with various examples, including ground- and excited-state calculations for LiH, H, and C with an active-space simplification, and automatically obtain resource estimates for classically intractable examples.", "num_citations": "10\n", "authors": ["520"]}
{"title": "Optimizing tensor contractions in ccsd (t) for efficient execution on gpus\n", "abstract": " Tensor contractions are higher dimensional analogs of matrix multiplications, used in many computational contexts such as high order models in quantum chemistry, deep learning, finite element methods etc. In contrast to the wide availability of high-performance libraries for matrix multiplication on GPUs, the same is not true for tensor contractions. In this paper, we address the optimization of a set of symmetrized tensor contractions that form the computational bottleneck in the CCSD (T) coupled-cluster method in computational chemistry suites like NWChem. Some of the challenges in optimizing tensor contractions that arise in practice from the variety of dimensionalities and shapes for tensors include effective mapping of the high-dimensional iteration space to threads, choice of data buffering in shared-memory and registers, and tile sizes for multi-level tiling. Furthermore, in the case of symmetrized tensor\u00a0\u2026", "num_citations": "10\n", "authors": ["520"]}
{"title": "Numa-caffe: Numa-aware deep learning neural networks\n", "abstract": " Convolution Neural Networks (CNNs), a special subcategory of Deep Learning Neural Networks (DNNs), have become increasingly popular in industry and academia for their powerful capability in pattern classification, image processing, and speech recognition. Recently, they have been widely adopted in High Performance Computing (HPC) environments for solving complex problems related to modeling, runtime prediction, and big data analysis. Current state-of-the-art designs for DNNs on modern multi- and many-core CPU architectures, such as variants of Caffe, have reported promising performance in speedup and scalability, comparable with the GPU implementations. However, modern CPU architectures employ Non-Uniform Memory Access (NUMA) technique to integrate multiple sockets, which incurs unique challenges for designing highly efficient CNN frameworks. Without a careful design, DNN\u00a0\u2026", "num_citations": "10\n", "authors": ["520"]}
{"title": "On the use of term rewriting for performance optimization of legacy HPC applications\n", "abstract": " Preparing codes for next generation supercomputer systems is anticipated to require significant changes to the optimization strategies employed in established HPC applications. In this paper, we present our experience in applying term rewriting transformations for the optimization of such applications. We have designed application-specific term rewriting transformations to improve the scalability, enhance locality and reduce the communication overhead of the Self-Consistent Field computational chemistry benchmark. We present the rationale for the use of term rewriting in this manner, the design of our transformations, and the much enhanced performance of the resulting code.", "num_citations": "10\n", "authors": ["520"]}
{"title": "On efficient out-of-core matrix transposition\n", "abstract": " This paper addresses the problem of transposition of large out-of-core arrays. Although algorithms for out-of-core matrix transposition have been widely studied, previously proposed algorithms have sought to minimize the number of I/O operations and the in-memory permu-tation time. We propose an algorithm that directly targets the improvement of overall transpo-sition time. The algorithm proposed decouples the algorithm from the matrix dimensions and associates it with the I/O characteristics of the system. The I/O characteristics of the system are used to determine the read and write block sizes. These I/O block sizes are chosen in order to optimize the total execution time. Experimental results are provided that demonstrate the", "num_citations": "10\n", "authors": ["520"]}
{"title": "Scalable yet rigorous floating-point error analysis\n", "abstract": " Automated techniques for rigorous floating-point round-off error analysis are a prerequisite to placing important activities in HPC such as precision allocation, verification, and code optimization on a formal footing. Yet existing techniques cannot provide tight bounds for expressions beyond a few dozen operators\u2013barely enough for HPC. In this work, we offer an approach embedded in a new tool called SATIHE that scales error analysis by four orders of magnitude compared to today\u2019s best-of-class tools. We explain how three key ideas underlying SATIHE helps it attain such scale: path strength reduction, bound optimization, and abstraction. SATIHE provides tight bounds and rigorous guarantees on significantly larger expressions with well over a hundred thousand operators, covering important examples including FFT, matrix multiplication, and PDE stencils.", "num_citations": "9\n", "authors": ["520"]}
{"title": "Gpu code optimization using abstract kernel emulation and sensitivity analysis\n", "abstract": " In this paper, we develop an approach to GPU kernel optimization by focusing on identification of bottleneck resources and determining optimization parameters that can alleviate the bottleneck. Performance modeling for GPUs is done by abstract kernel emulation along with latency/gap modeling of resources. Sensitivity analysis with respect to resource latency/gap parameters is used to predict the bottleneck resource for a given kernel's execution. The utility of the bottleneck analysis is demonstrated in two contexts: 1) Coupling the new bottleneck-driven optimization strategy with the OpenTuner auto-tuner: experimental results on all kernels from the Rodinia suite and GPU tensor contraction kernels from the NWChem computational chemistry suite demonstrate effectiveness. 2) Manual code optimization: two case studies illustrate the use of the bottleneck analysis to iteratively improve the performance of code from\u00a0\u2026", "num_citations": "9\n", "authors": ["520"]}
{"title": "Application-specific fault tolerance via data access characterization\n", "abstract": " Recent trends in semiconductor technology and supercomputer design predict an increasing probability of faults during an application\u2019s execution. Designing an application that is resilient to system failures requires careful evaluation of the impact of various approaches on preserving key application state. In this paper, we present our experiences in an ongoing effort to make a large computational chemistry application fault tolerant. We construct the data access signatures of key application modules to evaluate alternative fault tolerance approaches. We present the instrumentation methodology, characterization of the application modules, and evaluation of fault tolerance techniques using the information collected. The application signatures developed capture application characteristics not traditionally revealed by performance tools. We believe these can be used in the design and evaluation of runtimes\u00a0\u2026", "num_citations": "9\n", "authors": ["520"]}
{"title": "Efficient search\u2010space pruning for integrated fusion and tiling transformations\n", "abstract": " Compile\u2010time optimizations involve a number of transformations such as loop permutation, fusion, tiling, array contraction etc. The selection of the appropriate transformation to minimize the execution time is a challenging task. We address this problem in the context of tensor contraction expressions involving arrays too large to fit in main memory. Domain\u2010specific features of the computation are exploited to develop an integrated framework that facilitates the exploration of the entire search space of optimizations. In this paper, we discuss the exploration of the space of loop fusion and tiling transformations in order to minimize the disk I/O cost. These two transformations are integrated and pruning strategies are presented that significantly reduce the number of loop structures to be evaluated for subsequent transformations. The evaluation of the framework using representative contraction expressions from quantum\u00a0\u2026", "num_citations": "9\n", "authors": ["520"]}
{"title": "From NWChem to NWChemEx: Evolving with the computational chemistry landscape\n", "abstract": " Since the advent of the first computers, chemists have been at the forefront of using computers to understand and solve complex chemical problems. As the hardware and software have evolved, so have the theoretical and computational chemistry methods and algorithms. Parallel computers clearly changed the common computing paradigm in the late 1970s and 80s, and the field has again seen a paradigm shift with the advent of graphical processing units. This review explores the challenges and some of the solutions in transforming software from the terascale to the petascale and now to the upcoming exascale computers. While discussing the field in general, NWChem and its redesign, NWChemEx, will be highlighted as one of the early codesign projects to take advantage of massively parallel computers and emerging software standards to enable large scientific challenges to be tackled.", "num_citations": "8\n", "authors": ["520"]}
{"title": "Toward generalized tensor algebra for ab initio quantum chemistry methods\n", "abstract": " The widespread use of tensor operations in describing electronic structure calculations has motivated the design of software frameworks for productive development of scalable optimized tensor-based electronic structure methods. Whereas prior work focused on Cartesian abstractions for dense tensors, we present an algebra to specify and perform tensor operations on a larger class of block-sparse tensors. We illustrate the use of this framework in expressing real-world computational chemistry calculations beyond the reach of existing frameworks.", "num_citations": "8\n", "authors": ["520"]}
{"title": "Approximate computing techniques for iterative graph algorithms\n", "abstract": " Approximate computing enables processing of large-scale graphs by trading off quality for performance. Approximate computing techniques have become critical not only due to the emergence of parallel architectures but also due to the availability of large scale datasets enabling data-driven discovery. Using two prototypical graph algorithms, PageRank and community detection, we present several approximate computing heuristics to scale the performance with minimal loss of accuracy. We present several heuristics including loop perforation, data caching, incomplete graph coloring and synchronization, and evaluate their efficiency. We demonstrate performance improvements of up to 83% for PageRank and up to 450x for community detection, with low impact on accuracy for both the algorithms. We expect the proposed approximate techniques will enable scalable graph analytics on data of importance to\u00a0\u2026", "num_citations": "8\n", "authors": ["520"]}
{"title": "Scalable transparent checkpoint-restart of global address space applications on virtual machines over Infiniband\n", "abstract": " Checkpoint-Restart is one of the most used software approaches to achieve fault-tolerance in high-end clusters. While standard techniques typically focus on user-level solutions, the advent of virtualization software has enabled efficient and transparent system-level approaches. In this paper, we present a scalable transparent system-level solution to address fault-tolerance for applications based on global address space (GAS) programming models on Infiniband clusters. In addition to handling communication, the solution addresses transparent checkpoint of user-generated files. We exploit the support for the Infiniband network in the Xen virtual machine environment. We have developed a version of the Aggregate Remote Memory Copy Interface (ARMCI) one-sided communication library capable of suspending and resuming applications. We present efficient and scalable mechanisms to distribute checkpoint\u00a0\u2026", "num_citations": "8\n", "authors": ["520"]}
{"title": "An extensible global address space framework with decoupled task and data abstractions\n", "abstract": " Although message passing using MPI is the dominant model for parallel programming today, the significant effort required to develop high-performance MPI applications has prompted the development of several parallel programming models that are more convenient. Programming models such as Co-Array Fortran, Global Arrays, Titanium, and UPC provide a more convenient global view of the data, but face significant challenges in delivering high performance over a range of applications. It is particularly challenging to achieve high performance using global-address-space languages for unstructured applications with irregular data structures. In this paper, we describe a global-address-space parallel programming framework with decoupled task and data abstractions. The framework centers around the use of task pools, where tasks specify operands in a distributed, globally addressable pool of data chunks. The\u00a0\u2026", "num_citations": "8\n", "authors": ["520"]}
{"title": "Characterization of the impact of soft errors on iterative methods\n", "abstract": " Soft errors caused by transient bit flips have the potential to significantly impact an application's behavior. This has motivated the design of an array of techniques to detect, isolate, and correct soft errors using microarchitectural, architectural, compilation-based, or application-level techniques to minimize their impact on the executing application. The first step toward the design of good error detection/correction techniques involves an understanding of an application's vulnerability to soft errors. In this paper, we present the first comprehensive characterization of the impact of soft errors on the convergence characteristics of six iterative methods using application-level fault injection. In particular, we consider the use of iterative methods to incrementally solve a linear system of equations, which constitute the core kernel in many scientific applications. We analyze the impact of soft errors in terms of the type of error (single\u00a0\u2026", "num_citations": "7\n", "authors": ["520"]}
{"title": "TTLG-an efficient tensor transposition library for gpus\n", "abstract": " This paper presents a Tensor Transposition Library for GPUs (TTLG). A distinguishing feature of TTLG is that it also includes a performance prediction model, which can be used by higher level optimizers that use tensor transposition. For example, tensor contractions are often implemented by using the TTGT (Transpose-Transpose-GEMM-Transpose) approach - transpose input tensors to a suitable layout and then use high-performance matrix multiplication followed by transposition of the result. The performance model is also used internally by TTLG for choosing among alternative kernels and/or slicing/blocking parameters for the transposition. TTLG is compared with current state-of-the-art alternatives for GPUs. Comparable or better transposition times for the \"repeated-use\" scenario and considerably better \"single-use\" performance are observed.", "num_citations": "7\n", "authors": ["520"]}
{"title": "Comparative analysis of soft-error detection strategies: A case study with iterative methods\n", "abstract": " Undetected soft errors caused by transient bit flips can lead to silent data corruption (SDC), an undesirable outcome where invalid results pass for valid ones. This has motivated the design of soft error detectors to minimize SDCs. However, the detectors have been studied under different contexts, making comparative evaluation difficult. In this paper, we present the first comprehensive evaluation of four online soft error detection techniques in detecting the adverse impact of soft errors on iterative methods. We observe that, across five iterative methods, the detectors studied achieve high but not perfect detection rates. To understand the potential for improved detection, we evaluate a machine-learning based detector that takes as features that are the runtime features observed by the individual detectors to arrive at their conclusions. Our evaluation demonstrates improved but still far from perfect detection accuracy for\u00a0\u2026", "num_citations": "7\n", "authors": ["520"]}
{"title": "CAST: Contraction algorithm for symmetric tensors\n", "abstract": " Tensor contractions represent the most compute- intensive core kernels in ab initio computational quantum chemistry and nuclear physics. Symmetries in these tensor contractions make them difficult to load balance and scale to large distributed systems. In this paper, we develop an efficient and scalable algorithm to contract symmetric tensors. We introduce a novel approach that avoids data redistribution during contraction of symmetric tensors while also bypassing redundant storage and maintaining load balance. We present experimental results on two parallel supercomputers for several symmetric contractions that appear in the coupled cluster singles and doubles (CCSD) quantum chemistry method. We also present a novel approach to tensor redistribution that can take advantage of parallel hyperplanes when the initial distribution has replicated dimensions, and use collective broadcast when the final\u00a0\u2026", "num_citations": "7\n", "authors": ["520"]}
{"title": "A scalable infrastructure for the performance analysis of passive target synchronization\n", "abstract": " Partitioned global address space (PGAS) languages combine the convenient abstraction of shared memory with the notion of affinity, extending multi-threaded programming to large-scale systems with physically distributed memory. However, in spite of their obvious advantages, PGAS languages still lack appropriate tool support for performance analysis, one of the reasons why their adoption is still in its infancy. Some of the performance problems for which tool support is needed occur at the level of the underlying one-sided communication substrate, such as the Aggregate Remote Memory Copy Interface (ARMCI). One such example is the waiting time in situations where asynchronous data transfers cannot be completed without software intervention at the target side. This is not uncommon on systems with reduced operating-system kernels such as IBM Blue Gene/P where the use of progress threads would double\u00a0\u2026", "num_citations": "7\n", "authors": ["520"]}
{"title": "Practical loop transformations for tensor contraction expressions on multi-level memory hierarchies\n", "abstract": " Modern architectures are characterized by deeper levels of memory hierarchy, often explicitly addressable. Optimizing applications for such architectures requires careful management of the data movement across all these levels. In this paper, we focus on the problem of mapping tensor contractions to memory hierarchies with more than two levels, specifically addressing placement of memory allocation and data movement statements, choice of loop fusions, and tile size selection. Existing algorithms to find an integrated solution to this problem even for two-level memory hierarchies have been shown to be expensive. We improve upon this work by focusing on the first-order cost components, simplifying the analysis required and reducing the number of candidates to be evaluated. We have evaluated our framework on a cluster of GPUs. Using five candidate tensor contraction expressions, we show that\u00a0\u2026", "num_citations": "7\n", "authors": ["520"]}
{"title": "PRESAGE: Protecting structured address generation against soft errors\n", "abstract": " Modern computer scaling trends in pursuit of larger component counts and power efficiency have, unfortunately, lead to less reliable hardware and consequently soft errors escaping into application data (\"silent data corruptions\"). Techniques to enhance system resilience hinge on the availability of efficient error detectors that have high detection rates, low false positive rates, and lower computational overhead. Unfortunately, efficient detectors to detect faults during address generation have not been widely researched (especially in the context of indexing large arrays). We present a novel lightweight compiler-driven technique called PRESAGE for detecting bit-flips affecting structured address computations. A key insight underlying PRESAGE is that any address computation scheme that propagates an already incurred error is better than a scheme that corrupts one particular array access but otherwise (falsely\u00a0\u2026", "num_citations": "6\n", "authors": ["520"]}
{"title": "Work stealing for GPU\u2010accelerated parallel programs in a global address space framework\n", "abstract": " Task parallelism is an attractive approach to automatically load balance the computation in a parallel system and adapt to dynamism exhibited by parallel systems. Exploiting task parallelism through work stealing has been extensively studied in shared and distributed\u2010memory contexts. In this paper, we study the design of a system that uses work stealing for dynamic load balancing of task\u2010parallel programs executed on hybrid distributed\u2010memory CPU\u2010graphics processing unit (GPU) systems in a global\u2010address space framework. We take into account the unique nature of the accelerator model employed by GPUs, the significant performance difference between GPU and CPU execution as a function of problem size, and the distinct CPU and GPU memory domains. We consider various alternatives in designing a distributed work stealing algorithm for CPU\u2010GPU systems, while taking into account the impact of task\u00a0\u2026", "num_citations": "6\n", "authors": ["520"]}
{"title": "Towards scalable optimal sequence homology detection\n", "abstract": " The field of bioinformatics and computational biology is experiencing a data revolution - experimental techniques to procure data have increased in throughput improved in accuracy and reduced in costs. This has spurred an array of high profile sequencing and data generation projects. While the data repositories represent untapped reservoirs of rich information critical for scientific breakthroughs the analytical software tools that are needed to analyze large volumes of such sequence data have significantly lagged behind in their capacity to scale. In this paper we address homology detection which is a fundamental problem in large-scale sequence analysis with numerous applications. We present a scalable framework to conduct large-scale optimal homology detection on massively parallel super-computing platforms. Our approach employs distributed memory work stealing to effectively parallelize optimal\u00a0\u2026", "num_citations": "6\n", "authors": ["520"]}
{"title": "Parameterized micro-benchmarking: An auto-tuning approach for complex applications\n", "abstract": " Auto-tuning has emerged as an important practical method for creating highly optimized implementations of key computational kernels and applications. However, the growing complexity of architectures and applications is creating new challenges for auto-tuning. Complex applications can involve a prohibitively large search space that precludes empirical auto-tuning. Similarly, architectures are getting more complicated, making it hard to model performance.", "num_citations": "6\n", "authors": ["520"]}
{"title": "Fault oblivious eXascale whitepaper\n", "abstract": " Exascale computing systems will provide a thousand-fold increase in parallelism and a proportional increase in failure rate relative to today's machines [3]. Future systems are expected to feature billions of threads and 10s of millions of CPUs. The nodes and networks of these systems will be hierarchical, and ignoring this hardware hierarchy will lead to poor utilization. Failure will be a constant companion, and it is unlikely that checkpointing the entire system, with its petabytes of memory, will be practical. Systems software for exascale machines must provide the infrastructure to support existing applications while simultaneously enabling efficient execution of new programming models that naturally express dynamic, adaptive, irregular computation; coupled simulations; and massive data analysis.", "num_citations": "6\n", "authors": ["520"]}
{"title": "Layout transformation support for the disk resident arrays framework\n", "abstract": " The Global Arrays (GA) toolkit provides a shared-memory programming model in which data locality is explicitly managed by the programmer. It inter-operates with MPI and supports a variety of language bindings. The Disk Resident Arrays (DRA) model extends the GA programming model to secondary storage. GA and DRA together provide a convenient programming model that encourages locality-aware programming by the user, while presenting a high-level abstraction. High performance depends on the appropriate distribution of the data in the disk-resident arrays. In this paper, we discuss the addition of layout transformation support to DRA. The implementation of an efficient parallel layout transformation algorithm is done on top of existing GA/DRA functions; thus GA/DRA is itself used in implementing the enhanced DRA functionality. Experimental performance data is provided that demonstrates the\u00a0\u2026", "num_citations": "6\n", "authors": ["520"]}
{"title": "Green\u2019s function coupled cluster simulation of the near-valence ionizations of DNA-fragments\n", "abstract": " Accurate description of the ionization process in DNA is crucial to the understanding of the DNA damage under exposure to ionizing radiation and the exploration of the potential application of DNA strands in nanoelectronics. In this work, by employing our recently developed Green\u2019s function coupled-cluster library on supercomputing facilities, we have studied the spectral functions of several guanine\u2013cytosine (G\u2013C) base pair structures ([G\u2013C]n, n = 1\u20133) for the first time in a relatively broad near-valence regime ([\u221225.0, \u22125.0] eV) in the coupled-cluster with singles and doubles level. Our focus is to give a preliminary many-body coupled-cluster understanding and guideline of the vertical ionization energy (VIE), spectral profile, and ionization feature changes of these systems as the system size expands in this near-valence regime. The results show that, as the system size expands, even though the lowest VIEs keep\u00a0\u2026", "num_citations": "5\n", "authors": ["520"]}
{"title": "Extracting SIMD parallelism from recursive task-parallel programs\n", "abstract": " The pursuit of computational efficiency has led to the proliferation of throughput-oriented hardware, from GPUs to increasingly wide vector units on commodity processors and accelerators. This hardware is designed to execute data-parallel computations in a vectorized manner efficiently. However, many algorithms are more naturally expressed as divide-and-conquer, recursive, task-parallel computations. In the absence of data parallelism, it seems that such algorithms are not well suited to throughput-oriented architectures. This article presents a set of novel code transformations that expose the data parallelism latent in recursive, task-parallel programs. These transformations facilitate straightforward vectorization of task-parallel programs on commodity hardware. We also present scheduling policies that maintain high utilization of vector resources while limiting space usage. Across several task-parallel\u00a0\u2026", "num_citations": "5\n", "authors": ["520"]}
{"title": "NoC-enabled software/hardware co-design framework for accelerating k-mer counting\n", "abstract": " Counting k-mers (substrings of fixed length k) in DNA and protein sequences generate non-uniform and irregular memory access patterns. Processing-in-Memory (PIM) architectures have the potential to significantly reduce the overheads associated with such frequent and irregular memory accesses. However, existing k-mer counting algorithms are not designed to exploit the advantages of PIM architectures. Furthermore, owing to thermal constraints, the allowable power budget is limited in conventional PIM designs. Moreover, k-mer counting generates unbalanced and long-range traffic patterns that need to be handled by an efficient Network-on-Chip (NoC). In this paper, we present an NoC-enabled software/hardware co-design framework to implement high-performance k-mer counting. The proposed architecture enables more computational power, efficient communication between cores/memory-all without\u00a0\u2026", "num_citations": "5\n", "authors": ["520"]}
{"title": "Bonvoision: Leveraging spatial data smoothness for recovery from memory soft errors\n", "abstract": " Detectable but Uncorrectable Errors (DUEs) in the memory subsystem are becoming increasingly frequent. Today, upon encountering a DUE, applications crash, and the recovery methods used incur significant performance, storage, and energy overheads. To mitigate the impact of these errors, we start from two high-level observations that apply to some classes of HPC applications (eg, stencil computations on regular grids or irregular meshes): first, these applications, display a property we dub spatial data smoothness: ie, data items that are nearby in the application's logical space are relatively similar. Second, since these data items are generally used together, programmers go to great lengths to place them in nearby memory locations to improve application's performance by improving access locality. Based on these observations we explore the feasibility of a roll-forward recovery scheme that leverages spatial\u00a0\u2026", "num_citations": "5\n", "authors": ["520"]}
{"title": "A gaussian process approach for effective soft error detection\n", "abstract": " In this paper, we present a non-parametric dataanalytic soft-error detector. Our detector uses the key properties of Gaussian process regression. First, because Gaussian process regression provides confidence on the prediction, this confidence can be used to automatize construction of the detection range. Second, because the correlation model of a Gaussian process captures the similarity among neighboring point values, only one-time online training is needed. This leads to very low online performance overheads. Finally, Gaussian process regression localizes the detection range computation, thereby avoiding communication costs. We compare our detector with the adaptive impact-driven (AID) and spatial supportvector- machine (SSD) detectors, two effective detectors based on observation of the temporal and spatial evolution of data, respectively. Experiments with five failure distributions and six real-world\u00a0\u2026", "num_citations": "5\n", "authors": ["520"]}
{"title": "Global transformations for legacy parallel applications via structural analysis and rewriting\n", "abstract": " Performance and scalability optimization of large HPC applications is currently a labor-intensive, manual process with very low productivity. Major difficulties come from the disaggregated environment for HPC application development: the compiler is only involved in local decisions (core or multithreaded domain), while a library-based, communication-oriented programming model realizes whole-machine parallelism. Realizing any major global change in such a disaggregated environment is very difficult and involves changing large portions of the source code. We present semi-automated techniques, based on structural analysis and rewriting, for performing global transformations on an HPC application source code. We present two case studies using the Self-Consistent Field (SCF) standalone benchmark as well as the Coupled Cluster (CCSD) module (2.9 million lines of Fortran code), a key module of the\u00a0\u2026", "num_citations": "5\n", "authors": ["520"]}
{"title": "Enabling structured exploration of workflow performance variability in extreme-scale environments\n", "abstract": " Workflows are taking an Workflows are taking an increasingly important role in orchestrating complex scientific processes in extreme scale and highly heterogeneous environments. However, to date we cannot reliably predict, understand, and optimize workflow performance. Sources of performance variability and in particular the interdependencies of workflow design, execution environment and system architecture are not well understood. While there is a rich portfolio of tools for performance analysis, modeling and prediction for single applications in homogenous computing environments, these are not applicable to workflows, due to the number and heterogeneity of the involved workflow and system components and their strong interdependencies. In this paper, we investigate workflow performance goals and identify factors that could have a relevant impact. Based on our analysis, we propose a new workflow performance provenance ontology, the Open Provenance Model-based WorkFlow Performance Provenance, or OPM-WFPP, that will enable the empirical study of workflow performance characteristics and variability including complex source attribution.", "num_citations": "5\n", "authors": ["520"]}
{"title": "COMET: A Domain-Specific Compilation of High-Performance Computational Chemistry\n", "abstract": " The computational power increases over the past decades havegreatly enhanced the ability to simulate chemical reactions andunderstand ever more complex transformations. Tensor contractions are the fundamental computational building block of these simulations. These simulations have often been tied to one platform and restricted in generality by the interface provided to the user. The expanding prevalence of accelerators and researcher demands necessitate a more general approach which is not tied to specific hardware or requires contortion of algorithms to specific hardware platforms. In this paper we present COMET, a domain-specific programming language and compiler infrastructure for tensor contractions targeting heterogeneous accelerators. We present a system of progressive lowering through multiple layers of abstraction and optimization that achieves up to 1.98X speedup for 30 tensor contractions commonly used in computational chemistry and beyond.", "num_citations": "4\n", "authors": ["520"]}
{"title": "Ground-truth prediction to accelerate soft-error impact analysis for iterative methods\n", "abstract": " Understanding the impact of soft errors on applications can be expensive. Often, it requires an extensive error injection campaign involving numerous runs of the full application in the presence of errors. In this paper, we present a novel approach to arriving at the ground truth-the true impact of an error on the final output-for iterative methods by observing a small number of iterations to learn deviations between normal and error-impacted execution. We develop a machine learning based predictor for three iterative methods to generate ground-truth results without running them to completion for every error injected. We demonstrate that this approach achieves greater accuracy than alternative prediction strategies, including three existing soft error detection strategies. We demonstrate the effectiveness of the ground truth prediction model in evaluating vulnerability and the effectiveness of soft error detection strategies\u00a0\u2026", "num_citations": "4\n", "authors": ["520"]}
{"title": "PaKman: Scalable assembly of large genomes on distributed memory machines\n", "abstract": " De novo genome assembly is a fundamental problem in the field of bioinformatics, that aims to assemble the DNA sequence of an unknown genome from numerous short DNA fragments (aka reads) obtained from it. With the advent of high-throughput sequencing technologies, billions of reads can be generated in a matter of hours, necessitating efficient parallelization of the assembly process. While multiple parallel solutions have been proposed in the past, conducting a large-scale assembly at scale remains a challenging problem because of the inherent complexities associated with data movement, and irregular access footprints of memory and I/O operations. In this paper, we present a novel algorithm, called PaKman, to address the problem of performing large-scale genome assemblies on a distributed memory parallel computer. Our approach focuses on improving performance through a combination of novel\u00a0\u2026", "num_citations": "4\n", "authors": ["520"]}
{"title": "Lightweight detection of cache conflicts\n", "abstract": " In memory hierarchies, caches perform an important role in reducing average memory access latency. Minimizing cache misses can yield significant performance gains. As set-associative caches are widely used in modern architectures, capacity and conflict cache misses co-exist. These two types of cache misses require different optimization strategies. While cache misses are commonly studied using cache simulators, state-of-the-art simulators usually incur hundreds to thousands of times a program's execution runtime. Moreover, a simulator has difficulty in simulating complex real hardware. To overcome these limitations, measurement methods are proposed to directly monitor program execution on real hardware via performance monitoring units. However, existing measurement-based tools either focus on capacity cache misses or do not distinguish capacity and conflict cache misses. In this paper, we design\u00a0\u2026", "num_citations": "4\n", "authors": ["520"]}
{"title": "Automatic risk-based selective redundancy for fault-tolerant task-parallel hpc applications\n", "abstract": " Silent data corruption (SDC) and fail-stop errors are the most hazardous error types in high-performance computing (HPC) systems. In this study, we present an automatic, efficient and lightweight redundancy mechanism to mitigate both error types. We propose partial task-replication and checkpointing for task-parallel HPC applications to mitigate silent and fail-stop errors. To avoid the prohibitive costs of complete replication, we introduce a lightweight selective replication mechanism. Using a fully automatic and transparent heuristics, we identify and selectively replicate only the reliability-critical tasks based on a risk metric. Our approach detects and corrects around 70% of silent errors with only 5% average performance overhead. Additionally, the performance overhead of the heuristic itself is negligible.", "num_citations": "4\n", "authors": ["520"]}
{"title": "Locality-aware dynamic task graph scheduling\n", "abstract": " Dynamic task graph schedulers automatically balance work across processor cores by scheduling tasks among available threads while preserving dependences. In this paper, we design NABBITC, a provably efficient dynamic task graph scheduler that accounts for data locality on NUMA systems. NABBITC allows users to assign a color to each task representing the location (e.g., a processor core) that has the most efficient access to data needed during that node's execution. NABBITC then automatically adjusts the scheduling so as to preferentially execute each node at the location that matches its color-leading to better locality because the node is likely to make local rather than remote accesses. At the same time, NABBITC tries to optimize load balance and not add too much overhead compared to the vanilla NABBIT scheduler that does not consider locality. We provide a theoretical analysis that shows that\u00a0\u2026", "num_citations": "4\n", "authors": ["520"]}
{"title": "Non-collective parallel i/o for global address space programming models\n", "abstract": " Achieving high performance for out-of-core applications typically involves explicit management of the movement of data between the disk and the physical memory. We are developing a programming environment in which the different levels of the memory hierarchy are handled efficiently in a unified transparent framework. In this paper, we present our experiences with implementing efficient non-collective I/O (GPCIO) as part of this framework. As a generalization of the remote procedure call (RPC) that was used as a foundation for the Sun NFS system, we developed a global procedure call (GPC) to invoke procedures on a remote node to handle non-collective I/O. We consider alternative approaches that can be employed in implementing this functionality. The approaches are evaluated using a representative computation from quantum chemistry. The results demonstrate that GPC-IO achieves better absolute\u00a0\u2026", "num_citations": "4\n", "authors": ["520"]}
{"title": "Afne transformations for communication minimal parallelization and locality optimization of arbitrarily nested loop sequences\n", "abstract": " The polytope model provides powerful abstractions to optimize loop nests with regular accesses for parallel execution. Affine transformations in the polytope model encompass compositions of loop permutation, skewing, reversal, relative shifting, and fusion. Though significant amount of research has dealt with affine scheduling and partitioning, the problem of finding good affine transforms for communication-minimal coarse-grained parallelization as well as locality optimization for the general case of arbitrarily-nested loop sequences has not been addressed. Also, many frameworks do not treat parallelization and locality optimization in an integrated manner, and/or optimize across a sequence of producer/consumer loops. In this paper, we develop an algorithm for communication minimal and locality optimal tiling of arbitrarily nested loop sequences. The transformed loop nests are a hierarchy of fully permutable loop nest sets such that tiling those leads to minimal communication in the processor space as well as minimal reuse distances for local execution at each node. The approach also finds maximal fusion structures across a sequence of loop nests that have a producer/consumer relationship. Programs with one-dimensional and multi-dimensional schedules are all handled with the same algorithm. Synchronization-free parallelism, permutable loops or pipelined par-allelism, and inner parallel loops can be detected. Examples are provided that demonstrate the effectiveness of the approach. The algorithm has been implemented into a tool to generate transformations from C/Fortran code in a fully automatic fashion. 1", "num_citations": "4\n", "authors": ["520"]}
{"title": "Design and Implementation of a One-Sided Communication Interface for the IBM eServer Blue Gene\n", "abstract": " This paper discusses the design and implementation of a one-sided communication interface for the IBM Blue Gene/L supercomputer. This interface facilitates ARMCI and the Global Arrays toolkit and can be used by other one-sided communication libraries. New protocols, interrupt driven communication, and compute node kernel enhancements were required to enable these libraries. Three possible methods for enabling ARMCI on the Blue Gene/L software stack are discussed. A detailed look into the development process shows how the implementation of the one-sided communication interface was completed. This was accomplished on a compressed time scale with the collaboration of various organizations within IBM and open source communities. In addition to enabling the one-sided libraries, bandwidth enhancements were made for communication along a diagonal on the Blue Gene/L torus network. The\u00a0\u2026", "num_citations": "4\n", "authors": ["520"]}
{"title": "An approach to locality-conscious load balancing and transparent memory hierarchy management with a global-address-space parallel programming model\n", "abstract": " The development of efficient parallel out-of-core applications is often tedious, because of the need to explicitly manage the movement of data between files and data structures of the parallel program. Several large-scale applications require multiple passes of processing over data too large to fit in memory, where significant concurrency exists within each pass. This paper describes a global-address-space framework for the convenient specification and efficient execution of parallel out-of-core applications operating on block-sparse data. The programming model provides a global view of block-sparse matrices and a mechanism for the expression of parallel tasks that operate on block-sparse data. The tasks are automatically partitioned into phases that operate on memory-resident data, and mapped onto processors to optimize load balance and data locality. Experimental results are presented that demonstrate the\u00a0\u2026", "num_citations": "4\n", "authors": ["520"]}
{"title": "Data and computation abstractions for dynamic and irregular computations\n", "abstract": " Effective data distribution and parallelization of computations involving irregular data structures is a challenging task. We address the twin-problems in the context of computations involving block-sparse matrices. The programming model provides a global view of a distributed block-sparse matrix. Abstractions are provided for the user to express the parallel tasks in the computation. The tasks are mapped onto processors to ensure load balance and locality. The abstractions are based on the Aggregate Remote Memory Copy Interface, and are interoperable with the Global Arrays programming suite and MPI. Results are presented that demonstrate the utility of the approach.", "num_citations": "4\n", "authors": ["520"]}
{"title": "Cache miss characterization and data locality optimization for imperfectly nested loops on shared memory multiprocessors\n", "abstract": " This paper develops an algorithm to accurately characterize the number of cache misses for a class of compute-intensive calculations encountered in accurate quantum chemistry models of electronic structure. The proposed approach can handle imperfectly nested loop structures, symbolic loop bounds, and non-constant dependences for a constrained class of array references. It is proposed in the context of tensor contraction computations, and extends previous work on \"stack distances\" by Almasi et al. (2002) and Cascaval et al. (2003). We illustrate the application of the approach for determination of effective tile sizes and parallelization on shared-memory parallel systems.", "num_citations": "4\n", "authors": ["520"]}
{"title": "Empirical performance-model driven data layout optimization\n", "abstract": " Empirical optimizers like ATLAS have been very effective in optimizing computational kernels in libraries. The best choice of parameters such as tile size and degree of loop unrolling is determined by executing different versions of the computation. In contrast, optimizing compilers use a model-driven approach to program transformation. While the model-driven approach of optimizing compilers is generally orders of magnitude faster than ATLAS-like library generators, its effectiveness can be limited by the accuracy of the performance models used. In this paper, we describe an approach where a class of computations is modeled in terms of constituent operations that are empirically measured, thereby allowing modeling of the overall execution time. The performance model with empirically determined cost components is used to perform data layout optimization in the context of the Tensor Contraction Engine\u00a0\u2026", "num_citations": "4\n", "authors": ["520"]}
{"title": "Characterizing the impact of soft errors affecting floating-point ALUs using RTL-Ievel fault injection\n", "abstract": " Strategies to detect, correct, or mitigate the impact of soft errors rely on errors injection experiments. For efficient evaluation, these experiments typically inject errors in software by sampling errors from a candidate distribution. Most often, these strategies randomly select and flip one bit in the output of an instruction. While single-bit flips may constitute a meaningful model for errors affecting hardware, the appropriateness of this model for software-based errors has not been studied. In this paper, we examine the manifestation of errors in the output registers due to errors affecting candidate instructions executed by floating-point arithmetic logic units (ALUs). We inject single-bit flips into the register-transfer level descriptions of floating-point ALUs and analyze the differences between anticipated and observed outputs when executing floating-point addition, subtraction, multiplication, and division. We choose the operands\u00a0\u2026", "num_citations": "3\n", "authors": ["520"]}
{"title": "Understanding scale-dependent soft-error behavior of scientific applications\n", "abstract": " Analyzing application fault behavior on large-scale systems is time-consuming and resource-demanding. Currently, researchers need to perform fault injection campaigns at full scale to understand the effects of soft errors on applications and whether these faults result in silent data corruption. Both time and resource requirements greatly limit the scope of the resilience studies that can be currently performed. In this work, we propose a methodology to model application fault behavior at large scale based on a reduced set of experiments performed at small scale. We employ machine learning techniques to accurately model application fault behavior using a set of experiments that can be executed in parallel at small scale. Our methodology drastically reduces the set and the scale of the fault injection experiments to be performed and provides a validated methodology to study application fault behavior at large scale\u00a0\u2026", "num_citations": "3\n", "authors": ["520"]}
{"title": "Efficient cache simulation for affine computations\n", "abstract": " Trace based cache simulation are common techniques in design space exploration. In this paper, we develop an efficient strategy to simulate cache behavior for affine computations. Our framework exploits the regularity of polyhedral programs to implement a cache set partition transformation to parallelize both trace generation and simulation. We demonstrate that our framework accurately models the cache behavior of polyhedral programs while achieving significant improvements in simulation time. Extensive evaluations show that our proposed framework systematically outperforms the time-partition based parallel cache simulation.", "num_citations": "3\n", "authors": ["520"]}
{"title": "Point and Extended Defects in Ultra Wide Band Gap \u03b2-Ga2O3 Interfaces\n", "abstract": " //static.cambridge.org/content/id/urn%3Acambridge.org%3Aid%3Aarticle%3AS1431927617007930/resource/name/firstPage-S1431927617007930a.jpg", "num_citations": "3\n", "authors": ["520"]}
{"title": "Optimizing the four-index integral transform using data movement lower bounds analysis\n", "abstract": " The four-index integral transform is a fundamental and computationally demanding calculation used in many computational chemistry suites such as NWChem. It transforms a four-dimensional tensor from one basis to another. This transformation is most efficiently implemented as a sequence of four tensor contractions that each contract a four- dimensional tensor with a two-dimensional transformation matrix. Differing degrees of permutation symmetry in the intermediate and final tensors in the sequence of contractions cause intermediate tensors to be much larger than the final tensor and limit the number of electronic states in the modeled systems. Loop fusion, in conjunction with tiling, can be very effective in reducing the total space requirement, as well as data movement. However, the large number of possible choices for loop fusion and tiling, and data/computation distribution across a parallel system, make it\u00a0\u2026", "num_citations": "3\n", "authors": ["520"]}
{"title": "Cilkspec: optimistic concurrency for cilk\n", "abstract": " Recursive parallel programming models such as Cilk strive to simplify the task of parallel programming by enabling a simple divide-and-conquer programming model. This model is effective in recursively partitioning work into smaller parts and combining their results. However, recursive work partitioning can impose additional constraints on concurrency than is implied by the true dependencies in a program. In this paper, we present a speculation-based approach to alleviate the concurrency constraints imposed by such recursive parallel programs. We design a runtime infrastructure that supports speculative execution and a predictor to accurately learn and identify opportunities to relax extraneous concurrency constraints. Experimental evaluation demonstrates that speculative relaxation of concurrency constraints can deliver gains of up to 1.6x on 30 cores over baseline Cilk.", "num_citations": "3\n", "authors": ["520"]}
{"title": "High performance molecular dynamic simulation on single and multi-GPU systems\n", "abstract": " The computational power provided by many-core graphics processing units (GPUs) has been exploited in many applications. The programming techniques supported and employed on these GPUs and Multi-GPUs systems are not sufficient to address problems exhibiting irregular, and unbalanced workload such as Molecular Dynamic (MD) simulations of systems with non-uniform densities. In this paper, we propose a task-based dynamic load-balancing solution to employ on MD simulations for single- and multi-GPU systems. The solution allows load balancing at a finer granularity than what is supported in existing APIs such as NVIDIA's CUDA. Experimental results with a single-GPU configuration show that our fine-grained task solution can utilize the hardware more efficiently than the CUDA scheduler. On multi-GPU systems, our solution achieves near-linear speedup, load balance, and significant performance\u00a0\u2026", "num_citations": "3\n", "authors": ["520"]}
{"title": "Integrated data and task management for scientific applications\n", "abstract": " Several emerging application areas require intelligent management of distributed data and tasks that encapsulate execution units for collection of processors or processor groups. This paper describes an integration of data and task parallelism to address the needs of such applications in context of the Global Array (GA) programming model. GA provides programming interfaces for managing shared arrays based on non-partitioned global address space programming model concepts. Compatibility with MPI enables the scientific programmer to benefit from performance and productivity advantages of these high level programming abstractions using standard programming languages and compilers.", "num_citations": "3\n", "authors": ["520"]}
{"title": "A compiler framework for optimization of affine loop nests for GPGPUs\n", "abstract": " GPUs are a class of specialized parallel architectures with tremendous computational power. The new Compute Unified Device Architecture (CUDA) programming model from NVIDIA facilitates programming of general purpose applications on their GPUs. However, manual development of high-performance parallel code for GPUs is still very challenging. In this paper, a number of issues are addressed towards the goal of developing a compiler framework for automatic parallelization and performance optimization of affine loop nests on GPGPUs: 1) approach to program transformation for efficient data access from GPU global memory, using a polyhedral compiler model of data dependence abstraction and program transformation; 2) determination of optimal padding factors for conflict-minimal data access from GPU shared memory; and 3) model-driven empirical search to determine optimal parameters for unrolling and tiling. Experimental results on a number of kernels demonstrate the effectiveness of the compiler optimization approaches developed.", "num_citations": "3\n", "authors": ["520"]}
{"title": "Efficient layout transformation for disk-based multidimensional arrays\n", "abstract": " I/O libraries such as PANDA and DRA use blocked layouts for efficient access to disk-resident multi-dimensional arrays, with the shape of the blocks being chosen to match the expected access pattern of the array. Sometimes, different applications, or different phases of the same application, have very different access patterns for an array. In such situations, an array\u2019s blocked layout representation must be transformed for efficient access. In this paper, we describe a new approach to solve the layout transformation problem and demonstrate its effectiveness in the context of the Disk Resident Arrays (DRA) library. The approach handles re-blocking and permutation of dimensions. Results are provided that demonstrate the performance benefit as compared to currently available mechanisms.", "num_citations": "3\n", "authors": ["520"]}
{"title": "GFCCLib: Scalable and efficient coupled-cluster Green's function library for accurately tackling many-body electronic structure problems\n", "abstract": " Coupled-cluster Green's function (GFCC) calculation has drawn much attention in the recent years for targeting the molecular and material electronic structure problems from a many-body perspective in a systematically improvable way. However, GFCC calculations on scientific computing clusters usually suffer from expensive higher dimensional tensor contractions in the complex space, expensive inter-process communication, and severe load imbalance, which limits it's use for tackling electronic structure problems. Here we present a numerical library prototype that is specifically designed for large-scale GFCC calculations. The design of the library is focused on a systematically optimal computing strategy to improve its scalability and efficiency. The performance of the library is demonstrated by the relevant profiling analysis of running GFCC calculations on remote giant computing clusters. The capability of the\u00a0\u2026", "num_citations": "2\n", "authors": ["520"]}
{"title": "Reliability Analysis for Unreliable FSM Computations\n", "abstract": " Finite State Machines (FSMs) are fundamental in both hardware design and software development. However, the reliability of FSM computations remains poorly understood. Existing reliability analyses are mainly designed for generic computations and are unaware of the special error tolerance characteristics in FSM computations. This work introduces RelyFSM -- a state-level reliability analysis framework for FSM computations. By modeling the behaviors of unreliable FSM executions and qualitatively reasoning about the transition structures, RelyFSM can precisely capture the inherent error tolerance in FSM computations. Our evaluation with real-world FSM benchmarks confirms both the accuracy and efficiency of RelyFSM.", "num_citations": "2\n", "authors": ["520"]}
{"title": "Accelerating the Global Arrays ComEx Runtime Using Multiple Progress Ranks\n", "abstract": " Partitioned Global Address Space (PGAS) models are a part of system software that is being designed to support communication runtimes for exascale applications. MPI has been shown to be a viable option to develop a scalable PGAS communication subsystem and has the advantages of its standardization and higher performance. We used MPI two-sided semantics with a combination of automatic and user defined splitting of MPI communicators to achieve asynchronous progress. Our implementation can make use of multiple asynchronous progress ranks (PR) per node that can be mapped to the computing architecture of a node in a distributed cluster. We are able to show significant speed up of over 2.0X and scaling of a communication bound computational chemistry application distributed over 1024 nodes of state-of-the-art HPC clusters. Our results show that while running a communication bound\u00a0\u2026", "num_citations": "2\n", "authors": ["520"]}
{"title": "Towards Predicting the Impact of Roll-Forward Failure Recovery for HPC Applications\n", "abstract": " The roll-forward recovery schemes on HPC systems implicitly trade off faster time to solution for higher risk: as it usually performs a probabilistic repair, this may cause further failures such as SDCs. It is essential for users to be able to reason about the impact of a particular repair exercised by the scheme. Towards this goal, we identify two research questions aiming to determine the outcome of a repair either at the failure point or at the end of the execution. For the former, we propose a promising hybrid approach that combines machine learning and error propagation analysis techniques.", "num_citations": "2\n", "authors": ["520"]}
{"title": "Performance modeling for gpus using abstract kernel emulation\n", "abstract": " Performance modeling of GPU kernels is a significant challenge. In this paper, we develop a novel approach to performance modeling for GPUs through abstract kernel emulation along with latency/gap modeling of resources. Experimental results on all benchmarks from the Rodinia suite demonstrate good accuracy in predicting execution time on multiple GPU platforms.", "num_citations": "2\n", "authors": ["520"]}
{"title": "User-assisted store recycling for dynamic task graph schedulers\n", "abstract": " The emergence of the multi-core era has led to increased interest in designing effective yet practical parallel programming models. Models based on task graphs that operate on single-assignment data are attractive in several ways. Notably, they can support dynamic applications and precisely represent the available concurrency. However, for efficient execution, they also require nuanced algorithms for scheduling and memory management. In this article, we consider memory-efficient dynamic scheduling of task graphs. Specifically, we present a novel approach for dynamically recycling the memory locations assigned to data items as they are produced by tasks. We develop algorithms to identify memory-efficient store recycling functions by systematically evaluating the validity of a set of user-provided or automatically generated alternatives. Because recycling functions can be input data-dependent, we have also\u00a0\u2026", "num_citations": "2\n", "authors": ["520"]}
{"title": "Toward Quantum Computing for High-Energy Excited States in Molecular Systems: Quantum Phase Estimations of Core-Level States\n", "abstract": " This paper explores the utility of the quantum phase estimation (QPE) algorithm in calculating high-energy excited states characterized by the promotion of electrons occupying core-level shells. These states have been intensively studied over the last few decades, especially in supporting the experimental effort at light sources. Results obtained with QPE are compared with various high-accuracy many-body techniques developed to describe core-level states. The feasibility of the quantum phase estimator in identifying classes of challenging shake-up states characterized by the presence of higher-order excitation effects is discussed. We also demonstrate the utility of the QPE algorithm in targeting excitations from specific centers in a molecule. Lastly, we discuss how the lowest-order Trotter formula can be applied to reducing the complexity of the ansatz without affecting the error.", "num_citations": "1\n", "authors": ["520"]}
{"title": "FPDetect Efficient Reasoning About Stencil Programs Using Selective Direct Evaluation\n", "abstract": " We present FPDetect, a low-overhead approach for detecting logical errors and soft errors affecting stencil computations without generating false positives. We develop an offline analysis that tightly estimates the number of floating-point bits preserved across stencil applications. This estimate rigorously bounds the values expected in the data space of the computation. Violations of this bound can be attributed with certainty to errors. FPDetect helps synthesize error detectors customized for user-specified levels of accuracy and coverage. FPDetect also enables overhead reduction techniques based on deploying these detectors coarsely in space and time. Experimental evaluations demonstrate the practicality of our approach.", "num_citations": "1\n", "authors": ["520"]}
{"title": "NWChemEx\u2013computational chemistry for the exascale era\n", "abstract": " NWChemEx is an ECP project for computational chemistry that builds on the success of NWChem. NWChem is an early co-design project started in 1992, to address distributed memory parallel computers. The code's modular design, the Global Arrays for distributed data handling, and code generation using the Tensor Contraction Engine, provided a platform for building scalable chemistry capabilities. Key capabilities of the code are MD, DFT methods, and coupled cluster.The science challenges targeted by the NWChemEx are accurate simulations of catalytic reactions and biomolecular complexes. Such calculations require next generation computers that are very different from those NWChem was designed for. Hence, NWChemEx re-engineered the concepts, models and implementations for future computers. We focus on overcoming the limitations of NWChem\u2019s design. This involves platform enhancements\u00a0\u2026", "num_citations": "1\n", "authors": ["520"]}
{"title": "HPC Software Verification in Action: A Case Study with Tensor Transposition\n", "abstract": " As HPC platforms get increasingly complex, the complexity of software optimized for these platforms has also increased. There is a pressing need to ensure correctness of scientific applications to enhance our confidence in the results they produce. In this paper, we focus on checking the functional equivalence of libraries providing a small but important functionality---tensor transposition---used in computational chemistry applications. While several correctness tools have been developed and deployed, there are several practical challenges in using them to check correctness of production HPC software. We present our experiences using two tools---CIVL and CodeThorn---in checking the functional equivalence of two index permutation libraries. We observe that, with some effort, the tools we evaluated can handle kernels from production codes. We present observations that will aid library writers to write code that\u00a0\u2026", "num_citations": "1\n", "authors": ["520"]}
{"title": "On the theory of speculative checkpointing: Time and energy considerations\n", "abstract": " Collective checkpoint/rollback is the most popular approach for dealing with fail-stop errors on high-performance computing platforms. Prior work has focused on choosing checkpoint intervals that minimize the total cost of checkpoint/rollback. This work introduces the notion of speculative checkpointing, where we probabilistically skip some checkpoints. The careful selection of checkpoints either to be taken or skipped has the potential to reduce the total checkpoint/rollback overhead. We mathematically formulate the overall checkpoint/rollback cost in the presence of speculation. We consider the choice of speculation as a fixed probability or a probability distribution. We formulate two criteria to be minimized: total execution time and approximate total energy. We derive the criteria for beneficial speculative checkpointing for exponential and arbitrary failure distributions. Furthermore, we analyze the joint optimization of\u00a0\u2026", "num_citations": "1\n", "authors": ["520"]}
{"title": "On the impact of widening vector registers on sequence alignment\n", "abstract": " Vector extensions, such as SSE, have been part of the x86 since the 1990s, with applications in graphics, signal processing, and scientific applications. Although many algorithms and applications can naturally benefit from automatic vectorization techniques, there are still many that are difficult to vectorize due to their dependence on irregular data structures, dense branch operations, or data dependencies. Sequence alignment, one of the most widely used operations in bioinformatics workflows, has a computational footprint that features complex data dependencies. In this paper, we demonstrate that the trend of widening vector registers adversely affects the state-of-the-art sequence alignment algorithm based on striped data layouts. We present a practically efficient SIMD implementation of a parallel scan based sequence alignment algorithm that can better exploit wider SIMD units. We conduct comprehensive\u00a0\u2026", "num_citations": "1\n", "authors": ["520"]}
{"title": "Final Project Report. Scalable fault tolerance runtime technology for petascale computers\n", "abstract": " With the massive number of components comprising the forthcoming petascale computer systems, hardware failures will be routinely encountered during execution of large-scale applications. Due to the multidisciplinary, multiresolution, and multiscale nature of scientific problems that drive the demand for high end systems, applications place increasingly differing demands on the system resources: disk, network, memory, and CPU. In addition to MPI, future applications are expected to use advanced programming models such as those developed under the DARPA HPCS program as well as existing global address space programming models such as Global Arrays, UPC, and Co-Array Fortran. While there has been a considerable amount of work in fault tolerant MPI with a number of strategies and extensions for fault tolerance proposed, virtually none of advanced models proposed for emerging petascale systems is currently fault aware. To achieve fault tolerance, development of underlying runtime and OS technologies able to scale to petascale level is needed. This project has evaluated range of runtime techniques for fault tolerance for advanced programming models.", "num_citations": "1\n", "authors": ["520"]}
{"title": "On the Impact of Execution Models: A Case Study in Computational Chemistry\n", "abstract": " Efficient utilization of high-performance computing (HPC) platforms is an important and complex problem. Execution models, abstract descriptions of the dynamic runtime behavior of the execution stack, have significant impact on the utilization of HPC systems. Using a computational chemistry kernel as a case study and a wide variety of execution models combined with load balancing techniques, we explore the impact of execution models on the utilization of an HPC system. We demonstrate a 50 percent improvement in performance by using work stealing relative to a more traditional static scheduling approach. We also use a novel semi-matching technique for load balancing that has comparable performance to a traditional hyper graph-based partitioning implementation, which is computationally expensive. Using this study, we found that execution model design choices and assumptions can limit critical\u00a0\u2026", "num_citations": "1\n", "authors": ["520"]}
{"title": "SCaLeM: a framework for characterizing and analyzing execution models\n", "abstract": " As scalable parallel systems evolve towards more complex nodes with many-core architectures and larger trans-petascale & upcoming exascale deployments, there is a need to understand, characterize and quantify the underlying execution models being used on such systems. Execution models are a conceptual layer between applications & algorithms and the underlying parallel hardware and systems software on which those applications run.", "num_citations": "1\n", "authors": ["520"]}
{"title": "Domain-Specific Languages and High-Level Frameworks for High-Performance Computing\n", "abstract": " Sauf mention contraire ci-dessus, le contenu de cette notice bibliographique peut \u00eatre utilis\u00e9 dans le cadre d\u2019une licence CC BY 4.0 Inist-CNRS/Unless otherwise stated above, the content of this bibliographic record may be used under a CC BY 4.0 licence by Inist-CNRS/A menos que se haya se\u00f1alado antes, el contenido de este registro bibliogr\u00e1fico puede ser utilizado al amparo de una licencia CC BY 4.0 Inist-CNRS", "num_citations": "1\n", "authors": ["520"]}
{"title": "Poster: FOX: a fault-oblivious extreme scale execution environment\n", "abstract": " Exascale computing systems will provide a thousand-fold increase in parallelism and a proportional increase in failure rate relative to today's machines. Systems software for exascale machines must provide the infrastructure to support existing applications while simultaneously enabling efficient execution of new programming models that naturally express dynamic, adaptive, irregular computation; coupled simulations; and massive data analysis in a highly unreliable hardware environment with billions of threads of execution. Further, these systems must be designed with failure in mind. FOX is a new system for the exascale that will support distributed data objects as first class objects in the operating system itself. This memory-based data store will be named and accessed as part of the file system name space of the application. We can build many types of objects with this data store, including data-driven work\u00a0\u2026", "num_citations": "1\n", "authors": ["520"]}
{"title": "Locality-aware Load Balancing for Dynamic and Irregular Computations\n", "abstract": " Development of scalable application codes is a challenging task. It requires an understanding of system architecture, programming model, and ability to identify and express parallelism in the underlying problem. Design patterns can help programmers by presenting a set of recipes for expressing and implementing parallelism in the context of a particular programming model and classes of algorithms. In the current paper, we consider the Global Arrays shared memory programming model. In particular, we focus on a relatively common design pattern associated with implementations of dynamic load balancing in GA programs. Dynamic load balancing is often used in dynamic and irregular problems that have been parallelized using GA, in different application areas such as the electronic structure, molecular dynamics, or computational physics based on adaptive mesh refinement. The global/shared view of data and efficient one-sided communication offered by the GA toolkit facilitate a relatively straightforward implementation of dynamic load balancing, as compared to MPI. In particular, the programmer can take advantage of atomic operations such as fetch-and-add to schedule the execution of parallel tasks and rely on one-sided access to shared data to implement communication involved in executing individual tasks, regardless of the data ownership. For example, a common design pattern used in several computational chemistry algorithms uses an atomic update of a shared variable that corresponds to the current task index, pointing to either an explicit or implicit task list: a get for accessing the required sections of global arrays, followed by\u00a0\u2026", "num_citations": "1\n", "authors": ["520"]}
{"title": "Web Service Pipelining\n", "abstract": " Web servers provide information that can be accessed in the form of web services. Integrating these services often involves getting the result from one web service and sending it to the next. Traditionally, the client gets the result from one web service and sends it to the next. This paper proposes a model called Web Service Pipelining to improve the performance of web service access in such situations.", "num_citations": "1\n", "authors": ["520"]}