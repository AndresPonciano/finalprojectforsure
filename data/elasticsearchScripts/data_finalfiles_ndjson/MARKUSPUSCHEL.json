{"title": "SPIRAL: Code generation for DSP transforms\n", "abstract": " Fast changing, increasingly complex, and diverse computing platforms pose central problems in scientific computing: How to achieve, with reasonable effort, portable optimal performance? We present SPIRAL, which considers this problem for the performance-critical domain of linear digital signal processing (DSP) transforms. For a specified transform, SPIRAL automatically generates high-performance code that is tuned to the given platform. SPIRAL formulates the tuning as an optimization problem and exploits the domain-specific mathematical structure of transform algorithms to implement a feedback-driven optimizer. Similar to a human expert, for a specified transform, SPIRAL \"intelligently\" generates and explores algorithmic and implementation choices to find the best match to the computer's microarchitecture. The \"intelligence\" is provided by search and learning techniques that exploit the structure of the\u00a0\u2026", "num_citations": "990\n", "authors": ["275"]}
{"title": "Multiplierless multiple constant multiplication\n", "abstract": " A variable can be multiplied by a given set of fixed-point constants using a multiplier block that consists exclusively of additions, subtractions, and shifts. The generation of a multiplier block from the set of constants is known as the multiple constant multiplication (MCM) problem. Finding the optimal solution, namely, the one with the fewest number of additions and subtractions, is known to be NP-complete. We propose a new algorithm for the MCM problem, which produces solutions that require up to 20% less additions and subtractions than the best previously known algorithm. At the same time our algorithm, in contrast to the closest competing algorithm, is not limited by the constant bitwidths. We present our algorithm using a unifying formal framework for the best, graph-based MCM algorithms and provide a detailed runtime analysis and experimental evaluation. We show that our algorithm can handle problem\u00a0\u2026", "num_citations": "506\n", "authors": ["275"]}
{"title": "D-ADMM: A communication-efficient distributed algorithm for separable optimization\n", "abstract": " We propose a distributed algorithm, named Distributed Alternating Direction Method of Multipliers (D-ADMM), for solving separable optimization problems in networks of interconnected nodes or agents. In a separable optimization problem there is a private cost function and a private constraint set at each node. The goal is to minimize the sum of all the cost functions, constraining the solution to be in the intersection of all the constraint sets. D-ADMM is proven to converge when the network is bipartite or when all the functions are strongly convex, although in practice, convergence is observed even when these conditions are not met. We use D-ADMM to solve the following problems from signal processing and control: average consensus, compressed sensing, and support vector machines. Our simulations show that D-ADMM requires less communications than state-of-the-art algorithms to achieve a given accuracy\u00a0\u2026", "num_citations": "352\n", "authors": ["275"]}
{"title": "An abstract domain for certifying neural networks\n", "abstract": " We present a novel method for scalable and precise certification of deep neural networks. The key technical insight behind our approach is a new abstract domain which combines floating point polyhedra with intervals and is equipped with abstract transformers specifically tailored to the setting of neural networks. Concretely, we introduce new transformers for affine transforms, the rectified linear unit (ReLU), sigmoid, tanh, and maxpool functions.   We implemented our method in a system called DeepPoly and evaluated it extensively on a range of datasets, neural architectures (including defended networks), and specifications. Our experimental results indicate that DeepPoly is more precise than prior work while scaling to large networks.   We also show how to combine DeepPoly with a form of abstraction refinement based on trace partitioning. This enables us to prove, for the first time, the robustness of the network\u00a0\u2026", "num_citations": "262\n", "authors": ["275"]}
{"title": "Spiral: A generator for platform-adapted libraries of signal processing algorithms\n", "abstract": " SPIRAL is a generator for libraries of fast software implementations of linear signal                processing transforms. These libraries are adapted to the computing platform and can                be re-optimized as the hardware is upgraded or replaced. This paper describes the                main components of SPIRAL: the mathematical framework that concisely describes                signal transforms and their fast algorithms; the formula generator that captures at                the algorithmic level the degrees of freedom in expressing a particular signal                processing transform; the formula translator that encapsulates the compilation                degrees of freedom when translating a specific algorithm into an actual code                implementation; and, finally, an intelligent search engine that finds within the                large space of alternative formulas and implementations the                \u201cbest\u201d match to the given computing platform. We\u00a0\u2026", "num_citations": "258\n", "authors": ["275"]}
{"title": "Fast and effective robustness certification\n", "abstract": " We present a new method and system, called DeepZ, for certifying neural network robustness based on abstract interpretation. Compared to state-of-the-art automated verifiers for neural networks, DeepZ:(i) handles ReLU, Tanh and Sigmoid activation functions,(ii) supports feedforward and convolutional architectures,(iii) is significantly more scalable and precise, and (iv) and is sound with respect to floating point arithmetic. These benefits are due to carefully designed approximations tailored to the setting of neural networks. As an example, DeepZ achieves a verification accuracy of 97% on a large network with 88,500 hidden units under  attack with  with an average runtime of 133 seconds.", "num_citations": "247\n", "authors": ["275"]}
{"title": "Distributed basis pursuit\n", "abstract": " We propose a distributed algorithm for solving the optimization problem Basis Pursuit (BP). BP finds the least \u2113 1 -norm solution of the underdetermined linear system Ax = b and is used, for example, in compressed sensing for reconstruction. Our algorithm solves BP on a distributed platform such as a sensor network, and is designed to minimize the communication between nodes. The algorithm only requires the network to be connected, has no notion of a central processing node, and no node has access to the entire matrix A at any time. We consider two scenarios in which either the columns or the rows of A are distributed among the compute nodes. Our algorithm, named D-ADMM, is a decentralized implementation of the alternating direction method of multi- pliers. We show through numerical simulation that our algorithm requires considerably less communications between the nodes than the state-of-the-art\u00a0\u2026", "num_citations": "212\n", "authors": ["275"]}
{"title": "Algebraic signal processing theory: Foundation and 1-D time\n", "abstract": " This paper introduces a general and axiomatic approach to  linear  signal processing (SP) that we refer to as the algebraic signal processing theory (ASP). Basic to ASP is the  linear   signal   model  defined as a triple ( A , M ,Phi) where familiar concepts like the filter space and the signal space are cast as an algebra  A  and a module  M , respectively. The mapping Phi generalizes the concept of a  z -transform to bijective linear mappings from a vector space of signal samples into the module  M . Common concepts like filtering, spectrum, or Fourier transform have their equivalent counterparts in ASP. Once these concepts and their properties are defined and understood in the context of ASP, they remain true and apply to specific instantiations of the ASP signal model. For example, to develop signal processing theories for infinite and finite discrete time signals, for infinite or finite discrete space signals, or for\u00a0\u2026", "num_citations": "156\n", "authors": ["275"]}
{"title": "Computer generation of hardware for linear digital signal processing transforms\n", "abstract": " Linear signal transforms such as the discrete Fourier transform (DFT) are very widely used in digital signal processing and other domains. Due to high performance or efficiency requirements, these transforms are often implemented in hardware. This implementation is challenging due to the large number of algorithmic options (e.g., fast Fourier transform algorithms or FFTs), the variety of ways that a fixed algorithm can be mapped to a sequential datapath, and the design of the components of this datapath. The best choices depend heavily on the resource budget and the performance goals of the target application. Thus, it is difficult for a designer to determine which set of options will best meet a given set of requirements. In this article we introduce the Spiral hardware generation framework and system for linear transforms. The system takes a problem specification as input as well as directives that define\u00a0\u2026", "num_citations": "137\n", "authors": ["275"]}
{"title": "Active learning for multi-objective optimization\n", "abstract": " In many fields one encounters the challenge of identifying, out of a pool of possible designs, those that simultaneously optimize multiple objectives. This means that usually there is not one optimal design but an entire set of Pareto-optimal ones with optimal tradeoffs in the objectives. In many applications, evaluating one design is expensive; thus, an exhaustive search for the Pareto-optimal set is unfeasible. To address this challenge, we propose the Pareto Active Learning (PAL) algorithm, which intelligently samples the design space to predict the Pareto-optimal set. Key features of PAL include (1) modeling the objectives as samples from a Gaussian process distribution to capture structure and accommodate noisy evaluation;(2) a method to carefully choose the next design to evaluate to maximize progress; and (3) the ability to control prediction accuracy and sampling cost. We provide theoretical bounds on PAL\u2019s sampling cost required to achieve a desired accuracy. Further, we show an experimental evaluation on three real-world data sets. The results show PAL\u2019s effectiveness; in particular it improves significantly over a state-of-the-art evolutionary algorithm, saving in many cases about 33%.", "num_citations": "135\n", "authors": ["275"]}
{"title": "The algebraic approach to the discrete cosine and sine transforms and their fast algorithms\n", "abstract": " It is known that the discrete Fourier transform (DFT) used in digital signal processing can be characterized in the framework of the representation theory of algebras, namely, as the decomposition matrix for the regular module . This characterization provides deep insight into the DFT and can be used to derive and understand the structure of its fast algorithms. In this paper we present an algebraic characterization of the important class of discrete cosine and sine transforms as decomposition matrices of certain regular modules associated with four series of Chebyshev polynomials. Then we derive most of their known algorithms by pure algebraic means. We identify the mathematical principle behind each algorithm and give insight into its structure. Our results show that the connection between algebra and digital signal processing is stronger than previously understood.", "num_citations": "121\n", "authors": ["275"]}
{"title": "Discrete Fourier transform on multicore\n", "abstract": " This article gives an overview on the techniques needed to implement the discrete Fourier transform (DFT) efficiently on current multicore systems. The focus is on Intel-compatible multicores, but we also discuss the IBM Cell and, briefly, graphics processing units (GPUs). The performance optimization is broken down into three key challenges: parallelization, vectorization, and memory hierarchy optimization. In each case, we use the Kronecker product formalism to formally derive the necessary algorithmic transformations based on a few hardware parameters. Further code-level optimizations are discussed. The rigorous nature of this framework enables the complete automation of the implementation task as shown by the program generator Spiral. Finally, we show and analyze DFT benchmarks of the fastest libraries available for the considered platforms.", "num_citations": "120\n", "authors": ["275"]}
{"title": "Algebraic signal processing theory: Cooley\u2013Tukey type algorithms for DCTs and DSTs\n", "abstract": " This paper presents a systematic methodology to derive and classify fast algorithms for linear transforms. The approach is based on the algebraic signal processing theory. This means that the algorithms are not derived by manipulating the entries of transform matrices, but by a stepwise decomposition of the associated signal models, or polynomial algebras. This decomposition is based on two generic methods or algebraic principles that generalize the well-known Cooley-Tukey fast Fourier transform (FFT) and make the algorithms' derivations concise and transparent. Application to the 16 discrete cosine and sine transforms yields a large class of fast general radix algorithms, many of which have not been found before.", "num_citations": "116\n", "authors": ["275"]}
{"title": "Toward efficient static analysis of finite-precision effects in DSP applications via affine arithmetic modeling\n", "abstract": " We introduce a static error analysis technique, based on smart interval methods from affine arithmetic, to help designers translate DSP codes from full-precision floating-point to smaller finite-precision formats. The technique gives results for numerical error estimation comparable to detailed simulation, but achieves speedups of three orders of magnitude by avoiding actual bit-level simulation. We show results for experiments mapping common DSP transform algorithms to implementations using small custom floating point formats.", "num_citations": "109\n", "authors": ["275"]}
{"title": "FFT program generation for shared memory: SMP and multicore\n", "abstract": " The chip maker's response to the approaching end of CPU frequency scaling are multicore systems, which offer the same programming paradigm as traditional shared memory platforms but have different performance characteristics. This situation considerably increases the burden on library developers and strengthens the case for automatic performance tuning frameworks like Spiral, a program generator and optimizer for linear transforms such as the discrete Fourier transform (DFT). We present a shared memory extension of Spiral. The extension within Spiral consists of a rewriting system that manipulates the structure of transform algorithms to achieve load balancing and avoids false sharing, and of a backend to generate multithreaded code. Application to the DFT produces a novel class of algorithms suitable for multicore systems as validated by experimental results: we demonstrate a parallelization speed-up\u00a0\u2026", "num_citations": "106\n", "authors": ["275"]}
{"title": "Algebraic signal processing theory: 1-D space\n", "abstract": " In our paper titled \u201cAlgebraic Signal ProcessingTheory: Foundation and 1-D Time\u201d appearing in this issue of the IEEE TRANSACTIONS ON SIGNAL PROCESSING, we presented the algebraic signal processing theory, an axiomatic and general framework for linear signal processing. The basic concept in this theory is the signal model defined as the triple (8), where is a chosen algebra of filters, an associated-module of signals, and 8 is a generalization of the-transform. Each signal model has its own associated set of basic SP concepts, including filtering, spectrum, and Fourier transform. Examples include infinite and finite discrete time where these notions take their well-known forms. In this paper, we use the algebraic theory to develop infinite and finite space signal models. These models are based on a symmetric space shift operator, which is distinct from the standard time shift. We present the space signal processing concepts of filtering or convolution,\u201c-transform,\u201d spectrum, and Fourier transform. For finite length space signals, we obtain 16 variants of space models, which have the 16 discrete cosine and sine transforms (DCTs/DSTs) as Fourier transforms. Using this novel derivation, we provide missing signal processing concepts associated with the DCTs/DSTs, establish them as precise analogs to the DFT, get deep insight into their origin, and enable the easy derivation of many of their properties including their fast algorithms.", "num_citations": "104\n", "authors": ["275"]}
{"title": "Real, tight frames with maximal robustness to erasures\n", "abstract": " Motivated by the use of frames for robust transmission over the Internet, we present a first systematic construction of real tight frames with maximum robustness to erasures. We approach the problem in steps: we first construct maximally robust frames by using polynomial transforms. We then add tightness as an additional property with the help of orthogonal polynomials. Finally, we impose the last requirement of equal norm and construct, to our best knowledge, the first real, tight, equal-norm frames maximally robust to erasures.", "num_citations": "102\n", "authors": ["275"]}
{"title": "Applying the roofline model\n", "abstract": " The recently introduced roofline model plots the performance of executed code against its operational intensity (operations count divided by memory traffic). It also includes two platform-specific performance ceilings: the processor's peak performance and a ceiling derived from the memory bandwidth, which is relevant for code with low operational intensity. The model thus makes more precise the notions of memory- and compute-bound and, despite its simplicity, can provide an insightful visualization of bottlenecks. As such it can be valuable to guide manual code optimization as well as in education. Unfortunately, to date the model has been used almost exclusively with back-of-the-envelope calculations and not with measured data. In this paper we show how to produce roofline plots with measured data on recent generations of Intel platforms. We show how to accurately measure the necessary quantities for a\u00a0\u2026", "num_citations": "100\n", "authors": ["275"]}
{"title": "In search of the optimal Walsh-Hadamard transform\n", "abstract": " This paper describes an approach to implementing and optimizing fast signal transforms. Algorithms for computing signal transforms are expressed by symbolic expressions, which can be automatically generated and translated into programs. Optimizing an implementation involves searching for the fastest program obtained from one of the possible expressions. We apply this methodology to the implementation of the Walsh-Hadamard transform. An environment, accessible from MATLAB, is provided for generating and timing WHT algorithms. These tools are used to search for the fastest WHT algorithm. The fastest algorithm found is substantially faster than standard approaches to implementing the WHT. The work reported in this paper is part of the SPIRAL project. An ongoing project whose goal is to automate the implementation and optimization of signal processing algorithms.", "num_citations": "96\n", "authors": ["275"]}
{"title": "Time-multiplexed multiple-constant multiplication\n", "abstract": " This paper studies area-efficient arithmetic circuits to multiply a fixed-point input value selectively by one of several preset fixed-point constants. We present an algorithm that generates a class of solutions to this time-multiplexed multiple-constant multiplication problem by ldquofusingrdquo single-constant multiplication circuits for the required constants. Our evaluation compares our solution against a baseline implementation style that employs a full multiplier and a lookup table for the constants. The evaluation shows that we gain a significant area advantage, at the price of increased latency, for problem sizes (in terms of the number of constants) up to a threshold dependent on the bit-widths of the input and the constants. Our evaluation further shows that our solution is better suited for standard-cell application-specific integrated circuits than prior works on reconfigurable multiplier blocks.", "num_citations": "95\n", "authors": ["275"]}
{"title": "Boosting robustness certification of neural networks\n", "abstract": " We present a novel approach for the certification of neural networks against adversarial perturbations which combines scalable overapproximation methods with precise (mixed integer) linear programming. This results in significantly better precision than state-of-the-art verifiers on challenging feedforward and convolutional neural networks with piecewise linear activation functions.", "num_citations": "93\n", "authors": ["275"]}
{"title": "Automatic generation of customized discrete Fourier transform IPs\n", "abstract": " This paper presents a parameterized soft core generator for the discrete Fourier transform (DFT). Reusable IPs of digital signal processing (DSP) kernels are important time-saving resources in DSP hardware development. Unfortunately, reusable IPs, however optimized, can introduce inefficiencies because they cannot fit the exact requirements of every application context. Given the well-understood and regular computation in DSP kernels, an automatic tool can generate high-quality ready-to-use IPs customized to user-specified cost/performance tradeoffs (beyond basic parameters such as input size and data format). The paper shows that the generated DFT cores can match closely the performance and cost of DFT cores from the Xilinx LogiCore library. Furthermore, the generator can yield DFT cores over a range of different performance/cost tradeoff points that are not available from the library.", "num_citations": "88\n", "authors": ["275"]}
{"title": "Distributed optimization with local domains: Applications in MPC and network flows\n", "abstract": " We consider a network where each node has exclusive access to a local cost function. Our contribution is a communication-efficient distributed algorithm that finds a vector x* minimizing the sum of all the functions. We make the additional assumption that the functions have intersecting local domains, i.e., each function depends only on some components of the variable. Consequently, each node is interested in knowing only some components of x*, not the entire vector. This allows improving communication-efficiency. We apply our algorithm to distributed model predictive control (D-MPC) and to network flow problems and show, through experiments on large networks, that the proposed algorithm requires less communications to converge than prior state-of-the-art algorithms.", "num_citations": "86\n", "authors": ["275"]}
{"title": "Spiral\n", "abstract": " Spiral Presentation Template Page 1 Carnegie Mellon This work was supported by DARPA, NSF-NGS/ITR,ACR,CPA, Intel, Mercury, National Instruments Markus P\u00fcschel With: Srinivas Chellappa Fr\u00e9d\u00e9ric de Mesmay Franz Franchetti Daniel McFarlin Yevgen Voronenko Electrical and Computer Engineering Carnegie Mellon University \u2026 and the Spiral team (only part shown) Spiral Automating Library Development Page 2 Carnegie Mellon Positions and Thoughts \u25a0 Autotuning definition \u25aa Search over space of alternatives and \u25aa Parameter-based tuning are very important \u25aa but fails to address some key problems; we need to think about \u25a0 Raising the level of abstraction: Enables \u25aa Use of domain knowledge \u25aa Difficult optimizations: parallelization, vectorization, etc. \u25aa Faster porting to new platforms and platform paradigms \u25aa Possibly automatic software development \u25a0 We need coarse platform abstractions \u25a0 We need \u25aa /\u2026", "num_citations": "86\n", "authors": ["275"]}
{"title": "Formal loop merging for signal transforms\n", "abstract": " A critical optimization in the domain of linear signal transforms, such as the discrete Fourier transform (DFT), is loop merging, which increases data locality and reuse and thus performance. In particular, this includes the conversion of shuffle operations into array reindexings. To date, loop merging is well understood only for the DFT, and only for Cooley-Tukey FFT based algorithms, which excludes DFT sizes divisible by large primes. In this paper, we present a formal loop merging framework for general signal transforms and its implementation within the SPIRAL code generator. The framework consists of \u0395-SPL, a mathematical language to express loops and index mappings; a rewriting system to merge loops in \u0395-SPL and a compiler that translates \u0395-SPL into code. We apply the framework to DFT sizes that cannot be handled using only the Cooley-Tukey FFT and compare our method to FFTW 3.0. 1 and the vendor\u00a0\u2026", "num_citations": "82\n", "authors": ["275"]}
{"title": "Generation of optical OFDM signals using 21.4 GS/s real time digital signal processing\n", "abstract": " We demonstrate a field programmable gate array (FPGA) based optical orthogonal frequency division multiplexing (OFDM) transmitter implementing real time digital signal processing at a sample rate of \u202821.4 GS/s. The QPSK-OFDM signal is generated using an 8 bit, 128 point inverse fast Fourier transform (IFFT) core, performing one transform per clock cycle at a clock speed of 167.2 MHz and can be deployed with either a direct-detection or a coherent receiver. The hardware design and the main digital signal processing functions are described, and we show that the main performance limitation is due to the low (4-bit) resolution of the digital-to-analog converter (DAC) and the 8-bit resolution of the IFFT core used. We analyze the back-to-back performance of the transmitter generating an 8.36 Gb/s optical single sideband (SSB) OFDM signal using digital up-conversion, suitable for direct-detection. Additionally, we\u00a0\u2026", "num_citations": "81\n", "authors": ["275"]}
{"title": "A basic linear algebra compiler\n", "abstract": " Many applications in media processing, control, graphics, and other domains require efficient small-scale linear algebra computations. However, most existing high performance libraries for linear algebra, such as ATLAS or Intel MKL are more geared towards large-scale problems (matrix sizes in the hundreds and larger) and towards specific interfaces (eg, BLAS). In this paper we present LGen: a compiler for small-scale, basic linear algebra computations. The input to LGen is a fixed-size linear algebra expression; the output is a corresponding C function optionally including intrinsics to efficiently use SIMD vector extensions. LGen generates code using two levels of mathematical domain-specific languages (DSLs). The DSLs are used to perform tiling, loop fusion, and vectorization at a high level of abstraction, before the final code is generated. In addition, search is used to select among alternative generated\u00a0\u2026", "num_citations": "79\n", "authors": ["275"]}
{"title": "Efficient compression of QRS complexes using Hermite expansion\n", "abstract": " We propose a novel algorithm for the compression of ECG signals, in particular QRS complexes. The algorithm is based on the expansion of signals with compact support into a basis of discrete Hermite functions. These functions can be constructed by sampling continuous Hermite functions at specific sampling points. They form an orthogonal basis in the underlying signal space. The proposed algorithm relies on the theory of signal models based on orthogonal polynomials. We demonstrate that the constructed discrete Hermite functions have important ad- vantages compared to continuous Hermite functions, which have previously been suggested for the compression of QRS complexes. Our algorithm achieves higher compression ratios compared with previously reported algorithms based on continuous Hermite functions, discrete Fourier, cosine, or wavelet transforms.", "num_citations": "79\n", "authors": ["275"]}
{"title": "Fast polyhedra abstract domain\n", "abstract": " Numerical abstract domains are an important ingredient of modern static analyzers used for verifying critical program properties (eg, absence of buffer overflow or memory safety). Among the many numerical domains introduced over the years, Polyhedra is the most expressive one, but also the most expensive: it has worst-case exponential space and time complexity. As a consequence, static analysis with the Polyhedra domain is thought to be impractical when applied to large scale, real world programs.", "num_citations": "78\n", "authors": ["275"]}
{"title": "A SIMD vectorizing compiler for digital signal processing algorithms\n", "abstract": " Short vector SIMD instructions on recent microprocessors, such as SSE on Pentium III and 4, speed up code but are a major challenge to software developers. We present a compiler that automatically generates C code enhanced with short vector instructions for digital signal processing (DSP) transforms, such as the fast Fourier transform (FFT). The input to our compiler is a concise mathematical description of a DSP algorithm in the language SPL. SPL is used in the SPIRAL system (http://wwwece.cmu.edu/~spira/) to generate highly optimized architecture adapted implementations of DSP transforms. Interfacing our compiler with SPIRAL yields speed-ups of more than a factor of 2 in several important cases including the FFT and the discrete cosine transform (DCT) used in the JPEG compression standard. For the FFT our automatically generated code is competitive with the hand-coded Intel Math Kernel Library.", "num_citations": "77\n", "authors": ["275"]}
{"title": "Spiral in Scala: Towards the systematic construction of generators for performance libraries\n", "abstract": " Program generators for high performance libraries are an appealing solution to the recurring problem of porting and optimizing code with every new processor generation, but only few such generators exist to date. This is due to not only the difficulty of the design, but also of the actual implementation, which often results in an ad-hoc collection of standalone programs and scripts that are hard to extend, maintain, or reuse. In this paper we ask whether and which programming language concepts and features are needed to enable a more systematic construction of such generators. The systematic approach we advocate extrapolates from existing generators: a) describing the problem and algorithmic knowledge using one, or several, domain-specific languages (DSLs), b) expressing optimizations and choices as rewrite rules on DSL programs, c) designing data structures that can be configured to control the type of\u00a0\u2026", "num_citations": "74\n", "authors": ["275"]}
{"title": "Distributed ADMM for model predictive control and congestion control\n", "abstract": " Many problems in control can be modeled as an optimization problem over a network of nodes. Solving them with distributed algorithms provides advantages over centralized solutions, such as privacy and the ability to process data locally. In this paper, we solve optimization problems in networks where each node requires only partial knowledge of the problem's solution. We explore this feature to design a decentralized algorithm that allows a significant reduction in the total number of communications. Our algorithm is based on the Alternating Direction of Multipliers (ADMM), and we apply it to distributed Model Predictive Control (MPC) and TCP/IP congestion control. Simulation results show that the proposed algorithm requires less communications than previous work for the same solution accuracy.", "num_citations": "73\n", "authors": ["275"]}
{"title": "Bandit-based optimization on graphs with application to library performance tuning\n", "abstract": " The problem of choosing fast implementations for a class of recursive algorithms such as the fast Fourier transforms can be formulated as an optimization problem over the language generated by a suitably defined grammar. We propose a novel algorithm that solves this problem by reducing it to maximizing an objective function over the sinks of a directed acyclic graph. This algorithm valuates nodes using Monte-Carlo and grows a subgraph in the most promising directions by considering local maximum k-armed bandits. When used inside an adaptive linear transform library, it cuts down the search time by an order of magnitude compared to the existing algorithm. In some cases, the performance of the implementations found is also increased by up to 10% which is of considerable practical importance since it consequently improves the performance of all applications using the library.", "num_citations": "70\n", "authors": ["275"]}
{"title": "Beyond the single neuron convex barrier for neural network certification\n", "abstract": " We propose a new parametric approach, called k-ReLU, for computing precise convex relaxations used in robustness certification of neural networks. The key idea is to approximate the output of multiple ReLUs in a layer jointly instead of separately. This joint relaxation captures dependencies between the inputs to different ReLUs in a layer, which were previously ignored by the commonly used triangle relaxation and its approximations. The method is parametric in the number of k ReLUs it considers jointly and can be naturally combined with existing abstraction techniques so to improve their precision. Indeed, our experimental results demonstrate that the k-ReLU technique enables significantly better precision than existing state-of-the-art verifiers while preserving their scalability.", "num_citations": "68\n", "authors": ["275"]}
{"title": "Formal datapath representation and manipulation for implementing DSP transforms\n", "abstract": " We present a domain-specific approach to representing datapaths for hardware implementations of linear signal transform algorithms. We extend the tensor structure for describing linear transform algorithms, adding the ability to explicitly characterize two important dimensions of datapath architecture. This representation allows both algorithm and datapath to be specified within a single formula and gives the designer the ability to easily consider a wide space of possible datapaths at a high level of abstraction. We have constructed a formula manipulation system based on this representation and have written a compiler that can translate a formula into a hardware implementation. This enables an automatic \"push button\" compilation flow that produces a register transfer level hardware description from high-level datapath directives and an algorithm (written as a formula). In our experimental results, we demonstrate\u00a0\u2026", "num_citations": "65\n", "authors": ["275"]}
{"title": "Operator language: A program generation framework for fast kernels\n", "abstract": " We present the Operator Language (OL), a framework to automatically generate fast numerical kernels. OL provides the structure to extend the program generation system Spiral beyond the transform domain. Using OL, we show how to automatically generate library functionality for the fast Fourier transform and multiple non-transform kernels, including matrix-matrix multiplication, synthetic aperture radar (SAR), circular convolution, sorting networks, and Viterbi decoding. The control flow of the kernels is data-independent, which allows us to cast their algorithms as operator expressions. Using rewriting systems, a structural architecture model and empirical search, we automatically generate very fast C implementations for state-of-the-art multicore CPUs that rival hand-tuned implementations.", "num_citations": "63\n", "authors": ["275"]}
{"title": "SPIRAL: Extreme performance portability\n", "abstract": " In this paper, we address the question of how to automatically map computational kernels to highly efficient code for a wide range of computing platforms and establish the correctness of the synthesized code. More specifically, we focus on two fundamental problems that software developers are faced with: performance portability across the ever-changing landscape of parallel platforms and correctness guarantees for sophisticated floating-point code. The problem is approached as follows: We develop a formal framework to capture computational algorithms, computing platforms, and program transformations of interest, using a unifying mathematical formalism we call operator language (OL). Then we cast the problem of synthesizing highly optimized computational kernels for a given machine as a strongly constrained optimization problem that is solved by search and a multistage rewriting system. Since all rewrite\u00a0\u2026", "num_citations": "60\n", "authors": ["275"]}
{"title": "Fast quantum Fourier transforms for a class of non-abelian groups\n", "abstract": " An algorithm is presented allowing the construction of fast Fourier transforms for any solvable group on a classical computer. The special structure of the recursion formula being the core of this algorithm makes it a good starting point to obtain systematically fast Fourier transforms for solvable groups on a quantum computer. The inherent structure of the Hilbert space imposed by the qubit architecture suggests to consider groups of order 2                   n                  first (where n is the number of qubits). As an example, fast quantum Fourier transforms for all 4 classes of nonabelian 2-groups with cyclic normal subgroup of index 2 are explicitly constructed in terms of quantum circuits. The (quantum) complexity of the Fourier transform for these groups of size 2                   n                  is O(                   n                                          2) in all cases.", "num_citations": "58\n", "authors": ["275"]}
{"title": "Permuting streaming data using RAMs\n", "abstract": " This article presents a method for constructing hardware structures that perform a fixed permutation on streaming data. The method applies to permutations that can be represented as linear mappings on the bit-level representation of the data locations. This subclass includes many important permutations such as stride permutations (corner turn, perfect shuffle, etc.), the bit reversal, the Hadamard reordering, and the Gray code reordering. The datapath for performing the streaming permutation consists of several independent banks of memory and two interconnection networks. These structures are built for a given streaming width (i.e., number of inputs and outputs per cycle) and operate at full throughput for this streaming width. We provide an algorithm that completely specifies the datapath and control logic given the desired permutation and streaming width. Further, we provide lower bounds on the achievable cost\u00a0\u2026", "num_citations": "57\n", "authors": ["275"]}
{"title": "Program generation for the all-pairs shortest path problem\n", "abstract": " A recent trend in computing are domain-specific program generators, designed to alleviate the effort of porting and re-optimizing libraries for fast-changing and increasingly complex computing platforms. Examples include ATLAS, SPIRAL, and the codelet generator in FFTW. Each of these generators produces highly optimized source code directly from a problem specification. In this paper, we extend this list by a program generator for the well-known Floyd-Warshall (FW) algorithm that solves the all-pairs shortest path problem, which is important in a wide range of engineering applications. As the first contribution, we derive variants of the FW algorithm that make it possible to apply many of the optimization techniques developed for matrix-matrix multiplication. The second contribution is the actual program generator, which uses tiling, loop unrolling, and SIMD vectorization combined with a hill climbing search to\u00a0\u2026", "num_citations": "57\n", "authors": ["275"]}
{"title": "A rewriting system for the vectorization of signal transforms\n", "abstract": " We present a rewriting system that automatically vectorizes signal transform algorithms at a high level of abstraction. The input to the system is a transform algorithm given as a formula in the well-known Kronecker product formalism. The output is a \u201cvectorized\u201d formula, which means it consists exclusively of constructs that can be directly mapped into short vector code. This approach obviates compiler vectorization, which is known to be limited in this domain. We included the formula vectorization into the Spiral program generator for signal transforms, which enables us to generate vectorized code and further optimize for the memory hierarchy through search over alternative algorithms. Benchmarks for the discrete Fourier transform (DFT) show that our generated floating-point code is competitive with and that our fixed-point code clearly outperforms the best available libraries.", "num_citations": "57\n", "authors": ["275"]}
{"title": "Optical OFDM for the data center\n", "abstract": " We investigate the use of orthogonal frequency division multiplexing (OFDM) to increase the capacity of multimode fiber (MMF)-based optical interconnects for data center applications. This approach provides a solution to modulation bandwidth limitations of the lasers, and to the intermodal dispersion of the MMF which leads to frequency-dependent attenuation. Recent studies on adaptively modulated OFDM are reviewed, and new simulation results assessing the capacity of such links for lengths of up to 300 m are presented, assuming the use of 50/125 \u03bcm graded-index MMF at a wavelength of 850 nm. The use of coded OFDM as an approach to deal with intermodal dispersion is also discussed.", "num_citations": "54\n", "authors": ["275"]}
{"title": "Algebraic signal processing theory: Cooley\u2013Tukey type algorithms for real DFTs\n", "abstract": " In this paper, we systematically derive a large class of fast general-radix algorithms for various types of real discrete Fourier transforms (real DFTs) including the discrete Hartley transform (DHT) based on the algebraic signal processing theory. This means that instead of manipulating the transform definition, we derive algorithms by manipulating the polynomial algebras underlying the transforms using one general method. The same method yields the well-known Cooley-Tukey fast Fourier transform (FFT) as well as general radix discrete cosine and sine transform algorithms. The algebraic approach makes the derivation concise, unifies and classifies many existing algorithms, yields new variants, enables structural optimization, and naturally produces a human-readable structural algorithm representation based on the Kronecker product formalism. We show, for the first time, that the general-radix Cooley-Tukey and\u00a0\u2026", "num_citations": "54\n", "authors": ["275"]}
{"title": "Short vector code generation for the discrete Fourier transform\n", "abstract": " In this paper we use a mathematical approach to automatically generate high performance short vector code for the discrete Fourier transform (DFT). We represent the well-known Cooley-Tukey fast Fourier transform in a mathematical notation and formally derive a \"short vector variant\". Using this recursion we generate for a given DFT a large number of different algorithms, represented as formulas, and translate them into short vector code. Then we present a vector code specific dynamic programming method that searches in the space of different implementations for the fastest on the given architecture. We implemented this approach as part of the SPIRAL library generator On Pentium III and 4, our automatically generated SSE and SSE2 vector code compares favorably with the hand-tuned Intel vendor library.", "num_citations": "54\n", "authors": ["275"]}
{"title": "\u03b5-Pal: An active learning approach to the multi-objective optimization problem\n", "abstract": " In many fields one encounters the challenge of identifying out of a pool of possible designs those that simultaneously optimize multiple objectives. In many applications an exhaustive search for the Pareto-optimal set is infeasible. To address this challenge, we propose the \u03f5-Pareto Active Learning (\u03f5-PAL) algorithm which adaptively samples the design space to predict a set of Pareto-optimal solutions that cover the true Pareto front of the design space with some granularity regulated by a parameter \u03f5. Key features of \u03f5-PAL include (1) modeling the objectives as draws from a Gaussian process distribution to capture structure and accommodate noisy evaluation;(2) a method to carefully choose the next design to evaluate to maximize progress; and (3) the ability to control prediction accuracy and sampling cost. We provide theoretical bounds on \u03f5-PAL\u2019s sampling cost required to achieve a desired accuracy. Further, we perform an experimental evaluation on three real-world data sets that demonstrate \u03f5-PAL\u2019s effectiveness; in comparison to the state-of-the-art active learning algorithm PAL, \u03f5-PAL reduces the amount of computations and the number of samples from the design space required to meet the user\u2019s desired level of accuracy. In addition, we show that \u03f5-PAL improves significantly over a state-of-the-art multi-objective optimization method, saving in most cases 30% to 70% evaluations to achieve the same accuracy.", "num_citations": "53\n", "authors": ["275"]}
{"title": "Automatic generation of fast discrete signal transforms\n", "abstract": " This paper presents an algorithm that derives fast versions for a broad class of discrete signal transforms symbolically. The class includes but is not limited to the discrete Fourier and the discrete trigonometric transforms. This is achieved by finding fast sparse matrix factorizations for the matrix representations of these transforms. Unlike previous methods, the algorithm is entirely automatic and uses the defining matrix as its sole input. The sparse matrix factorization algorithm consists of two steps: first, the \"symmetry\" of the matrix is computed in the form of a pair of group representations; second, the representations are stepwise decomposed, giving rise to a sparse factorization of the original transform matrix. We have successfully demonstrated the method by computing automatically efficient transforms in several important cases: for the DFT, we obtain the Cooley-Tukey (1965) FFT; for a class of transforms including\u00a0\u2026", "num_citations": "53\n", "authors": ["275"]}
{"title": "Computer generation of streaming sorting networks\n", "abstract": " Sorting networks offer great performance but become prohibitively expensive for large data sets. We present a domain-specific language and compiler to automatically generate hardware implementations of sorting networks with reduced area and optimized for latency or throughput. Our results show that the generator produces a wide range of Pareto-optimal solutions that both compete with and outperform prior sorting hardware.", "num_citations": "51\n", "authors": ["275"]}
{"title": "A proof of convergence for the alternating direction method of multipliers applied to polyhedral-constrained functions\n", "abstract": " We give a general proof of convergence for the Alternating Direction Method of Multipliers (ADMM). ADMM is an optimization algorithm that has recently become very popular due to its capabilities to solve large-scale and/or distributed problems. We prove that the sequence generated by ADMM converges to an optimal primal-dual optimal solution. We assume the functions f and g, defining the cost f(x) + g(y), are real-valued, but constrained to lie on polyhedral sets X and Y. Our proof is an extension of the proofs from [Bertsekas97, Boyd11].", "num_citations": "51\n", "authors": ["275"]}
{"title": "Computer generation of general size linear transform libraries\n", "abstract": " The development of high-performance libraries has become extraordinarily difficult due to multiple processor cores, vector instruction sets, and deep memory hierarchies. Often, the library has to be reimplemented and reoptimized, when a new platform is released. In this paper we show how to automatically generate general input-size libraries for the domain of linear transforms. The input to our generator is a formal specification of the transform and the recursive algorithms the library should use; the output is a library that supports general input size, is vectorized and multithreaded, provides an adaptation mechanism for the memory hierarchy, and has excellent performance, comparable to or better than the best human-written libraries. Further, we show that our library generator enables various customizations; one example is the generation of Java libraries.", "num_citations": "51\n", "authors": ["275"]}
{"title": "How to write fast numerical code: A small introduction\n", "abstract": " The complexity of modern computing platforms has made it extremely difficult to write numerical code that achieves the best possible performance. Straightforward implementations based on algorithms that minimize the operations count often fall short in performance by at least one order of magnitude. This tutorial introduces the reader to a set of general techniques to improve the performance of numerical code, focusing on optimizations for the computer\u2019s memory hierarchy. Further, program generators are discussed as a way to reduce the implementation and optimization effort. Two running examples are used to demonstrate these techniques: matrix-matrix multiplication and the discrete Fourier transform.", "num_citations": "51\n", "authors": ["275"]}
{"title": "Algebraic signal processing theory\n", "abstract": " This paper presents an algebraic theory of linear signal processing. At the core of algebraic signal processing is the concept of a linear signal model defined as a triple (A, M, phi), where familiar concepts like the filter space and the signal space are cast as an algebra A and a module M, respectively, and phi generalizes the concept of the z-transform to bijective linear mappings from a vector space of, e.g., signal samples, into the module M. A signal model provides the structure for a particular linear signal processing application, such as infinite and finite discrete time, or infinite or finite discrete space, or the various forms of multidimensional linear signal processing. As soon as a signal model is chosen, basic ingredients follow, including the associated notions of filtering, spectrum, and Fourier transform. The shift operator is a key concept in the algebraic theory: it is the generator of the algebra of filters A. Once the shift is chosen, a well-defined methodology leads to the associated signal model. Different shifts correspond to infinite and finite time models with associated infinite and finite z-transforms, and to infinite and finite space models with associated infinite and finite C-transforms (that we introduce). In particular, we show that the 16 discrete cosine and sine transforms are Fourier transforms for the finite space models. Other definitions of the shift naturally lead to new signal models and to new transforms as associated Fourier transforms in one and higher dimensions, separable and non-separable. We explain in algebraic terms shift-invariance (the algebra of filters A is commutative), the role of boundary conditions and signal extensions, the\u00a0\u2026", "num_citations": "51\n", "authors": ["275"]}
{"title": "A basic linear algebra compiler for structured matrices\n", "abstract": " Many problems in science and engineering are in practice modeled and solved through matrix computations. Often, the matrices involved have structure such as symmetric or triangular, which reduces the operations count needed to perform the computation. For example, dense linear systems of equations are solved by first converting to triangular form and optimization problems may yield matrices with any kind of structure. The well-known BLAS (basic linear algebra subroutine) interface provides a small set of structured matrix computations, chosen to serve a certain set of higher level functions (LAPACK). However, if a user encounters a computation or structure that is not supported, she loses the benefits of the structure and chooses a generic library. In this paper, we address this problem by providing a compiler that translates a given basic linear algebra computation on structured matrices into optimized C code\u00a0\u2026", "num_citations": "45\n", "authors": ["275"]}
{"title": "Making numerical program analysis fast\n", "abstract": " Numerical abstract domains are a fundamental component in modern static program analysis and are used in a wide range of scenarios (e.g. computing array bounds, disjointness, etc). However, analysis with these domains can be very expensive, deeply affecting the scalability and practical applicability of the static analysis. Hence, it is critical to ensure that these domains are made highly efficient. In this work, we present a complete approach for optimizing the performance of the Octagon numerical abstract domain, a domain shown to be particularly effective in practice. Our optimization approach is based on two key insights: i) the ability to perform online decomposition of the octagons leading to a massive reduction in operation counts, and ii) leveraging classic performance optimizations from linear algebra such as vectorization, locality of reference, scalar replacement and others, for improving the key\u00a0\u2026", "num_citations": "44\n", "authors": ["275"]}
{"title": "Automatic SIMD vectorization of fast Fourier transforms for the Larrabee and AVX instruction sets\n", "abstract": " The well-known shift to parallelism in CPUs is often associated with multicores. However another trend is equally salient: the increasing parallelism in per-core single-instruction multiple-date (SIMD) vector units. Intel's SSE and IBM's VMX (compatible to AltiVec) both offer 4-way (single precision) floating point, but the recent Intel instruction sets AVX and Larrabee (LRB) offer 8-way and 16-way, respectively. Compilation and optimization for vector extensions is hard, and often the achievable speed-up by using vectorizing compilers is small compared to hand-optimization using intrinsic function interfaces. Unfortunately, the complexity of these intrinsics interfaces increases considerably with the vector length, making hand-optimization a nightmare. In this paper, we present a peephole-based vectorization system that takes as input the vector instruction semantics and outputs a library of basic data reorganization\u00a0\u2026", "num_citations": "44\n", "authors": ["275"]}
{"title": "Generating FPGA-accelerated DFT libraries\n", "abstract": " We present a domain-specific approach to generate high-performance hardware-software partitioned implementations of the discrete Fourier transform (DFT) in fixed point precision. The partitioning strategy is a heuristic based on the DFT's divide-and-conquer algorithmic structure and fine tuned by the feedback-driven exploration of candidate designs. We have integrated this approach in the Spiral linear-transform code-generation framework to support push-button automatic implementation. We present evaluations of hardware-software DFT implementations running on the embedded PowerPC processor and the reconfigurable fabric of the Xilinx Virtex-II Pro FPGA. In our experiments, the 1D and 2D DFT's FPGA-accelerated libraries exhibit between 2 and 7.5 times higher performance (operations per second) and up to 2.5 times better energy efficiency (operations per Joule) than the software-only version.", "num_citations": "41\n", "authors": ["275"]}
{"title": "High-performance sparse fast Fourier transforms\n", "abstract": " The sparse fast Fourier transform (SFFT) is a recent novel algorithm to compute discrete Fourier transforms on signals with a sparse frequency domain with an improved asymptotic runtime. Reference implementations exist for different variants of the algorithm and were already shown to be faster than state-of-the-art FFT implementations in cases of sufficient sparsity. However, to date the SFFT has not been carefully optimized for modern processors. In this paper, we first analyze the performance of the existing SFFT implementations and discuss possible improvements. Then we present an optimized implementation. We achieve a speedup of 2-5 compared to the existing code and an efficiency that is competitive to highperformance FFT libraries.", "num_citations": "40\n", "authors": ["275"]}
{"title": "Smart design space sampling to predict Pareto-optimal solutions\n", "abstract": " Many high-level synthesis tools offer degrees of freedom in mapping high-level specifications to Register-Transfer Level descriptions. These choices do not affect the functional behavior but span a design space of different cost-performance tradeoffs. In this paper we present a novel machine learning-based approach that efficiently determines the Pareto-optimal designs while only sampling and synthesizing a fraction of the design space. The approach combines three key components:(1) A regression model based on Gaussian processes to predict area and throughput based on synthesis training data.(2) A\" smart\" sampling strategy, GP-PUCB, to iteratively refine the model by carefully selecting the next design to synthesize to maximize progress.(3) A stopping criterion based on assessing the accuracy of the model without access to complete synthesis data. We demonstrate the effectiveness of our approach using\u00a0\u2026", "num_citations": "40\n", "authors": ["275"]}
{"title": "Fast automatic generation of DSP algorithms\n", "abstract": " SPIRAL is a generator of optimized, platform-adapted libraries for digital signal processing algorithms. SPIRAL\u2019s strategy translates the implementation task into a search in an expanded space of alternatives. These result from the many degrees of freedom in the DSP algorithm itself and in the various coding choices. This paper describes the framework to represent and generate efficiently these alternatives: the formula generator module in SPIRAL. We also address the search module that works in tandem with the formula generator in a feedback loop to find optimal implementations. These modules are implemented using the computer algebra system GAP/AREP.", "num_citations": "40\n", "authors": ["275"]}
{"title": "Cooley-Tukey FFT like algorithms for the DCT\n", "abstract": " The Cooley-Tukey FFT algorithm decomposes a discrete Fourier transform (DFT) of size n = km into smaller DFT of size k and m. In this paper we present a theorem that decomposes a polynomial transform into smaller polynomial transforms, and show that the FFT is obtained as a special case. Then we use this theorem to derive a new class of recursive algorithms for the discrete cosine transforms (DCT) of type II and type III. In contrast to other approaches, we manipulate polynomial algebras instead of transform matrix entries, which makes the derivation transparent, concise, and gives insight into the algorithms' structure. The derived algorithms have a regular structure and, for 2-power size, minimal arithmetic cost (among known DCT algorithms).", "num_citations": "39\n", "authors": ["275"]}
{"title": "Generating SIMD vectorized permutations\n", "abstract": " This paper introduces a method to generate efficient vectorized implementations of small stride permutations using only vector load and vector shuffle instructions. These permutations are crucial for high-performance numerical kernels including the fast Fourier transform. Our generator takes as input only the specification of the target platform\u2019s SIMD vector ISA and the desired permutation. The basic idea underlying our generator is to model vector instructions as matrices and sequences of vector instructions as matrix formulas using the Kronecker product formalism. We design a rewriting system and a search mechanism that applies matrix identities to generate those matrix formulas that have vector structure and minimize a cost measure that we define. The formula is then translated into the actual vector program for the specified permutation. For three important classes of permutations, we show that our\u00a0\u2026", "num_citations": "36\n", "authors": ["275"]}
{"title": "Fast and accurate resource estimation of automatically generated custom DFT IP cores\n", "abstract": " This paper presents an equation-based resource utilization model for automatically generated discrete Fourier transform (DFT) soft core IPs. The parameterized DFT IP generator allows a user to make customized tradeoffs between cost and performance and between utilization of different resource classes. The equation-based resource model permits immediate and accurate estimation of resource requirements as the user considers the different generator options. Furthermore, the fast turnaround of the model allows it to be combined with a search algorithm such that the user could query automatically for an optimal design within the stated performance and resource constraints. Following a brief review of the DFT IP generator, this paper presents the development of the equation-based models for estimating slice and hard macro utilizations in the Xilinx Virtex-II Pro FPGA family. The evaluation section shows that an\u00a0\u2026", "num_citations": "36\n", "authors": ["275"]}
{"title": "Algebraic Signal Processing Theory: 1-D Nearest Neighbor Models\n", "abstract": " We present a signal processing framework for the analysis of discrete signals represented as linear combinations of orthogonal polynomials. We demonstrate that this representation implicitly changes the associated shift operation from the standard time shift to the nearest neighbor shift introduced in this paper. Using the algebraic signal processing theory, we construct signal models based on this shift and derive their corresponding signal processing concepts, including the proper notions of signal and filter spaces, z-transform, convolution, spectrum, and Fourier transform. The presented results extend the algebraic signal processing theory and provide a general theoretical framework for signal analysis using orthogonal polynomials.", "num_citations": "33\n", "authors": ["275"]}
{"title": "Automatic tuning of discrete fourier transforms driven by analytical modeling\n", "abstract": " Analytical models have been used to estimate optimal values for parameters such as tile sizes in the context of loop nests. However, important algorithms such as fast Fourier transforms (FFTs) present a far more complex search space consisting of many thousands of different implementations with very different complex access patterns and nesting and code structures. As a results, some of the best available FFT implementations use heuristic search based on runtime measurements. In this paper we present the first analytical model that can successfully replace the measurement in this search on modern platforms. The model includes many details of the platform's memory system including the TLBs, and, for the first time, physically addressed caches and hardware prefetching. The effect, as we show, is a dramatically reduced search time to find the best FFT without significant loss in performance. Even though our\u00a0\u2026", "num_citations": "31\n", "authors": ["275"]}
{"title": "Algebraic signal processing theory: 2-D spatial hexagonal lattice\n", "abstract": " We develop the framework for signal processing on a spatial, or undirected, 2-D hexagonal lattice for both an infinite and a finite array of signal samples. This framework includes the proper notions of z-transform, boundary conditions, filtering or convolution, spectrum, frequency response, and Fourier transform. In the finite case, the Fourier transform is called discrete triangle transform. Like the hexagonal lattice, this transform is nonseparable. The derivation of the framework makes it a natural extension of the algebraic signal processing theory that we recently introduced. Namely, we construct the proper signal models, given by polynomial algebras, bottom-up from a suitable definition of hexagonal space shifts using a procedure provided by the algebraic theory. These signal models, in turn, then provide all the basic signal processing concepts. The framework developed in this paper is related to Mersereau's early\u00a0\u2026", "num_citations": "30\n", "authors": ["275"]}
{"title": "Symmetry-based matrix factorization\n", "abstract": " We present a method for factoring a given matrix M into a short product of sparse matrices, provided that M has a suitable \u201csymmetry\u201d. This sparse factorization represents a fast algorithm for the matrix\u2013vector multiplication with M. The factorization method consists of two essential steps. First, a combinatorial search is used to compute a suitable symmetry of M in the form of a pair of group representations. Second, the group representations are decomposed stepwise, which yields factorized decomposition matrices and determines a sparse factorization of M. The focus of this article is the first step, finding the symmetries. All algorithms described have been implemented in the library AREP. We present examples for automatically generated sparse factorizations\u2014and hence fast algorithms\u2014for a class of matrices corresponding to digital signal processing transforms including the discrete Fourier, cosine, Hartley, and\u00a0\u2026", "num_citations": "30\n", "authors": ["275"]}
{"title": "Fast numerical program analysis with reinforcement learning\n", "abstract": " We show how to leverage reinforcement learning (RL) in order to speed up static program analysis. The key insight is to establish a correspondence between concepts in RL and those in analysis: a state in RL maps to an abstract program state in analysis, an action maps to an abstract transformer, and at every state, we have a set of sound transformers (actions) that represent different trade-offs between precision and performance. At each iteration, the agent (analysis) uses a policy learned offline by RL to decide on the transformer which minimizes loss of precision at fixpoint while improving analysis performance. Our approach leverages the idea of online decomposition (applicable to popular numerical abstract domains) to define a space of new approximate transformers with varying degrees of precision and performance. Using a suitably designed set of features that capture key properties of abstract\u00a0\u2026", "num_citations": "29\n", "authors": ["275"]}
{"title": "Program generation for small-scale linear algebra applications\n", "abstract": " We present SLinGen, a program generation system for linear algebra. The input to SLinGen is an application expressed mathematically in a linear-algebra-inspired language (LA) that we define. LA provides basic scalar/vector/matrix additions/multiplications and higher level operations including linear systems solvers, Cholesky and LU factorizations. The output of SLinGen is performance-optimized single-source C code, optionally vectorized with intrinsics. The target of SLinGen are small-scale computations on fixed-size operands, for which a straightforward implementation using optimized libraries (eg, BLAS or LAPACK) is known to yield suboptimal performance (besides increasing code size and introducing dependencies), but which are crucial in control, signal processing, computer vision, and other domains. Internally, SLinGen uses synthesis and DSL-based techniques to optimize at a high level of\u00a0\u2026", "num_citations": "29\n", "authors": ["275"]}
{"title": "Extending the roofline model: Bottleneck analysis with microarchitectural constraints\n", "abstract": " Software, even if carefully optimized, rarely reaches the peak performance of a processor. Understanding which hardware resource is the bottleneck is difficult but important as it can help with both further optimizing the code or deciding which hardware component to upgrade for higher performance. If the bottleneck is the memory bandwidth, the roofline model provides a simple but instructive analysis and visualization. In this paper, we take the roofline analysis further by including additional performance-relevant hardware features such as latency, throughput, capacity information for a multilevel cache hierarchy and out-of-order execution buffers. Two key ideas underlie our analysis. First, we estimate performance based on a scheduling of the computation DAG on a high-level model of a microarchitecture and extract data including utilization of resources and overlaps from a cycle-by-cycle analysis of the schedule\u00a0\u2026", "num_citations": "29\n", "authors": ["275"]}
{"title": "Offline library adaptation using automatically generated heuristics\n", "abstract": " Automatic tuning has emerged as a solution to provide high-performance libraries for fast changing, increasingly complex computer architectures. We distinguish offline adaptation (e.g., in ATLAS) that is performed during installation without the full problem description from online adaptation (e.g., in FFTW) that is performed at runtime. Offline adaptive libraries are simpler to use, but, unfortunately, writing the adaptation heuristics that power them is a daunting task. The overhead of online adaptive libraries, on the other hand, makes them unsuitable for a number of applications. In this paper, we propose to automatically generate heuristics in the form of decision trees using a statistical classifier, effectively converting an online adaptive library into an offline one. As testbed we use Spiral-generated adaptive transform libraries for current multicores with vector extensions. We show that replacing the online search with\u00a0\u2026", "num_citations": "29\n", "authors": ["275"]}
{"title": "Computer generation of fast Fourier transforms for the cell broadband engine\n", "abstract": " The Cell BE is a multicore processor with eight vector accelerators (called SPEs) that implement explicit cache management through direct memory access engines. While the Cell has an impressive floating point peak performance, programming and optimizing for it is difficult as it requires explicit memory management, multithreading, streaming, and vectorization. We address this problem for the discrete Fourier transform (DFT) by extending Spiral, a program generation system, to automatically generate highly optimized implementations for the Cell. The extensions include multi-SPE parallelization and explicit memory streaming, both performed at a high abstraction level using rewriting systems operating on Spiral's internal domain-specific language. Further, we support latency and throughput optimizations, single and double precision, and different data formats. The performance of Spiral's computer generated\u00a0\u2026", "num_citations": "29\n", "authors": ["275"]}
{"title": "Basis pursuit in sensor networks\n", "abstract": " Basis Pursuit (BP) finds a minimum \u2113 1 -norm vector z that satisfies the underdetermined linear system Mz = b, where the matrix M and vector b are given. Lately, BP has attracted attention because of its application in compressed sensing, where it is used to reconstruct signals by finding the sparsest solutions of linear systems. In this paper, we propose a distributed algorithm to solve BP. This means no central node is used for the processing and no node has access to all the data: the rows of M and the vector b are distributed over a set of interconnected compute nodes. A typical scenario is a sensor network. The novelty of our method is in using an optimal first-order method to solve an augmented Lagrangian-based reformulation of BP. We implemented our algorithm in a computer cluster, and show that it can solve problems that are too large to be stored in and processed by a single node.", "num_citations": "28\n", "authors": ["275"]}
{"title": "Compression of QRS complexes using Hermite expansion\n", "abstract": " We propose an algorithm for the compression of ECG signals, in particular QRS complexes, based on the expansion of signals with compact support into a basis of discrete Hermite functions. These functions are obtained by sampling continuous Hermite functions, previously used for the compression of ECG signals. Our algorithm uses the theory of signal models based on orthogonal polynomials, and achieves higher compression ratios compared with previously reported algorithms, both those using Hermite functions, as well as those using the discrete Fourier and discrete cosine transforms.", "num_citations": "28\n", "authors": ["275"]}
{"title": "Generating high performance pruned FFT implementations\n", "abstract": " We derive a recursive general-radix pruned Cooley-Tukey fast Fourier transform (FFT) algorithm in Kronecker product notation. The algorithm is compatible with vectorization and parallelization required on state-of-the-art multicore CPUs. We include the pruned FFT algorithm into the program generation system Spiral, and automatically generate optimized implementations of the pruned FFT for the Intel Core2Duo multicore processor. Experimental results show that using the pruned FFT can indeed speed up the fastest available FFT implementations by up to 30% when the problem size and the pattern of unused inputs and outputs are known in advance.", "num_citations": "28\n", "authors": ["275"]}
{"title": "Automatic performance optimization of the discrete Fourier transform on distributed memory computers\n", "abstract": " This paper introduces a formal framework for automatically generating performance optimized implementations of the discrete Fourier transform (DFT) for distributed memory computers. The framework is implemented as part of the program generation and optimization system Spiral. DFT algorithms are represented as mathematical formulas in Spiral\u2019s internal language SPL. Using a tagging mechanism and formula rewriting, we extend Spiral to automatically generate parallelized formulas. Using the same mechanism, we enable the generation of rescaling DFT algorithms, which redistribute the data in intermediate steps to fewer processors to reduce communication overhead. It is a novel feature of these methods that the redistribution steps are merged with the communication steps of the algorithm to avoid additional communication overhead. Among the possible alternative algorithms, Spiral\u2019s search\u00a0\u2026", "num_citations": "28\n", "authors": ["275"]}
{"title": "A practical construction for decomposing numerical abstract domains\n", "abstract": " Numerical abstract domains such as Polyhedra, Octahedron, Octagon, Interval, and others are an essential component of static program analysis. The choice of domain offers a performance/precision tradeoff ranging from cheap and imprecise (Interval) to expensive and precise (Polyhedra). Recently, significant speedups were achieved for Octagon and Polyhedra by manually decomposing their transformers to work with the Cartesian product of projections associated with partitions of the variable set. While practically useful, this manual process is time consuming, error-prone, and has to be applied from scratch for every domain.   In this paper, we present a generic approach for decomposing the transformers of sub-polyhedra domains along with conditions for checking whether the decomposed transformers lose precision with respect to the original transformers. These conditions are satisfied by most practical\u00a0\u2026", "num_citations": "27\n", "authors": ["275"]}
{"title": "Automatic generation of streaming datapaths for arbitrary fixed permutations\n", "abstract": " This paper presents a technique to perform arbitrary fixed permutations on streaming data. We describe a parameterized architecture that takes as input n data points streamed at a rate of w per cycle, performs a permutation over all n points, and outputs the result in the same streaming format. We describe the system and its requirements mathematically and use this mathematical description to show that the datapaths resulting from our technique can sustain a full throughput of w words per cycle without stalling. Additionally, we provide an algorithm to configure the datapath for a given permutation and streaming width. Using this technique, we have constructed a full synthesis system that takes as input a permutation and a streaming width and outputs a register-transfer level Verilog description of the datapath. We present an evaluation of our generated designs over varying problem sizes and streaming widths\u00a0\u2026", "num_citations": "27\n", "authors": ["275"]}
{"title": "21.4 GS/s real-time DSP-based optical OFDM signal generation and transmission over 1600 km of uncompensated fibre\n", "abstract": " We report a real-time optical OFDM transmitter with the highest sampling rate to date. Generation and transmission of an 8.36Gb/s digitally up-converted single sideband OFDM signal over 1600km of uncompensated fiber with a BER\u226a10 \u22123  was achieved.", "num_citations": "25\n", "authors": ["275"]}
{"title": "Streaming sorting networks\n", "abstract": " Sorting is a fundamental problem in computer science and has been studied extensively. Thus, a large variety of sorting methods exist for both software and hardware implementations. For the latter, there is a trade-off between the throughput achieved and the cost (i.e., the logic and storage invested to sort n elements). Two popular solutions are bitonic sorting networks with O(nlog 2n) logic and storage, which sort n elements per cycle, and linear sorters with O(n) logic and storage, which sort n elements per n cycles. In this article, we present new hardware structures that we call streaming sorting networks, which we derive through a mathematical formalism that we introduce, and an accompanying domain-specific hardware generator that translates our formal mathematical description into synthesizable RTL Verilog. With the new networks, we achieve novel and improved cost-performance trade-offs. For example\u00a0\u2026", "num_citations": "24\n", "authors": ["275"]}
{"title": "Decomposing monomial representations of solvable groups\n", "abstract": " We present an efficient algorithm that decomposes a monomial representation of a solvable groupG into its irreducible components. In contradistinction to other approaches, we also compute the decomposition matrixA in the form of a product of highly structured, sparse matrices. This factorization provides a fast algorithm for the multiplication with A. In the special case of a regular representation, we hence obtain a fast Fourier transform forG . Our algorithm is based on a constructive representation theory that we develop. The term \u201cconstructive\" signifies that concrete matrix representations are considered and manipulated, rather than equivalence classes of representations as it is done in approaches that are based on characters. Thus, we present well-known theorems in a constructively refined form and derive new results on decomposition matrices of representations. Our decomposition algorithm has been\u00a0\u2026", "num_citations": "24\n", "authors": ["275"]}
{"title": "Real-time digital signal processing for the generation of optical orthogonal frequency-division-multiplexed signals\n", "abstract": " In this paper, we investigate the design of a field-programmable-gate-array (FPGA) based optical orthogonal frequency-division multiplexing (OFDM) transmitter implementing real-time digital signal processing at 21.4 GSample/s. The transmitter was utilized to generate 8.34 Gb/s QPSK-OFDM signals for direct detection. We study the impact of the finite resolutions of the inverse fast Fourier transform cores and the digital-to-analog converters on the system performance. Furthermore, we describe a transmission experiment over 800 and 1600 km of uncompensated standard fiber with negligible optical SNR penalties and bit error rate <; 10 -3 .", "num_citations": "22\n", "authors": ["275"]}
{"title": "Design studies for an ASIC implementation of an optical OFDM transceiver\n", "abstract": " We designed at the register-transfer-level the DSP circuits for a 21.8 Gb/s QPSK-OFDM transceiver, and carried out synthesis and simulations assessing performance, power consumption and chip area, to determine their suitability for low-cost optical interconnects.", "num_citations": "21\n", "authors": ["275"]}
{"title": "Performance analysis of the filtered backprojection image reconstruction algorithms\n", "abstract": " We investigate performance tradeoffs for a class of filtered backprojection (FBP) image reconstruction algorithms. The recently developed fast hierarchical backprojection asymptotically achieves the same O(N/sup 2/ log N) cost as Fourier-based methods while retaining many advantages of the FBP technique. In this paper, we provide a detailed cost and performance analysis of the algorithm on a general purpose platform. Based on carefully tuned implementations of both the direct and the hierarchical backprojection, we explore the tradeoffs between distortion and runtime by varying several algorithm and implementation choices. Experimental results show that, given the desired performance, the choice of algorithm parameters is not obvious and largely depends on the image properties and the underlying computer platform.", "num_citations": "21\n", "authors": ["275"]}
{"title": "SIMD intrinsics on managed language runtimes\n", "abstract": " Managed language runtimes such as the Java Virtual Machine (JVM) provide adequate performance for a wide range of applications, but at the same time, they lack much of the low-level control that performance-minded programmers appreciate in languages like< pre> C/C++. One important example is the intrinsics interface that exposes instructions of SIMD (Single Instruction Multiple Data) vector ISAs (Instruction Set Architectures). In this paper we present an automatic approach for including native intrinsics in the runtime of a managed language. Our implementation consists of two parts. First, for each vector ISA, we automatically generate the intrinsics API from the vendor-provided XML specification. Second, we employ a metaprogramming approach that enables programmers to generate and load native code at runtime. In this setting, programmers can use the entire high-level language as a kind of macro\u00a0\u2026", "num_citations": "20\n", "authors": ["275"]}
{"title": "Algebraic signal processing theory: Cooley\u2013Tukey-type algorithms for polynomial transforms based on induction\n", "abstract": " A polynomial transform is the multiplication of an input vector  by a matrix  whose th element is defined as  for polynomials  from a list  and sample points  from a list . Such transforms find applications in the areas of signal processing, data compression, and function interpolation. An important example includes the discrete Fourier transform. In this paper we introduce a novel technique to derive fast algorithms for polynomial transforms. The technique uses the relationship between polynomial transforms and the representation theory of polynomial algebras. Specifically, we derive algorithms by decomposing the regular modules of these algebras as a stepwise induction. As an application, we derive novel  general-radix algorithms for the discrete Fourier transform and the discrete cosine transform of type 4.", "num_citations": "19\n", "authors": ["275"]}
{"title": "Domain-specific library generation for parallel software and hardware platforms\n", "abstract": " We overview a library generation framework called Spiral. For the domain of linear transforms, Spiral automatically generates implementations for parallel platforms including SIMD vector extensions, multicore processors, field-programmable gate arrays (FPGAs) and FPGA accelerated processors. The performance of the generated code is competitive with the best available hand-written libraries.", "num_citations": "19\n", "authors": ["275"]}
{"title": "Special issue on program generation, optimization, and platform adaptation\n", "abstract": " The fast evolution, increasing complexity, and increasing diversity of today\u2019s computing platforms pose a major challenge to developers of high-performance applications: software development has become an interdisciplinary task that requires the programmer to have specialized knowledge in algorithms, programming languages, and computer architectures. Furthermore, tuning even simple programs tends to be expensive because it requires an intense and sustained effort\u2014which can stretch over a period of weeks or months, if not years\u2014from the technically best expert programmers. But the manual tuning or adaptation of software implementations to a particular platform also leads to a vicious cycle: the code developer invests tremendous energy tinkering with the implementation to exploit in the best way the computing resources available, simply to realize that the hardware infrastructure has become obsolete\u00a0\u2026", "num_citations": "19\n", "authors": ["275"]}
{"title": "Computer generation of efficient software Viterbi decoders\n", "abstract": " This paper presents a program generator for fast software Viterbi decoders for arbitrary convolutional codes. The input to the generator is a specification of the code and a single-instruction multiple-data (SIMD) vector length. The output is an optimized C implementation of the decoder that uses explicit Intel SSE vector instructions. At the heart of the generator is a small domain-specific language called VL to express the structure of the forward pass. Vectorization is done by rewriting VL expressions, which a compiler then translates into actual code in addition to performing further optimizations specific to the vector instruction set. Benchmarks show that the generated decoders match the performance of available expert hand-tuned implementations, while spanning the entire space of convolutional codes. An online interface to the generator is provided at www.spiral.net.", "num_citations": "18\n", "authors": ["275"]}
{"title": "High-performance synthetic aperture radar image formation on commodity multicore architectures\n", "abstract": " Synthetic Aperture Radar (SAR) image processing platforms have to process increasingly large datasets under and hard real-time deadlines. Upgrading these platforms is expensive. An attractive solution to this problem is to couple high performance, general-purpose Commercial-Off-The-Shelf (COTS) architectures such as IBM's Cell BE and Intel's Core with software implementations of SAR algorithms. While this approach provides great flexibility, achieving the requisite performance is difficult and time-consuming. The reason is the highly parallel nature and general complexity of modern COTS microarchitectures. To achieve the best performance, developers have to interweave of various complex optimizations including multithreading, the use of SIMD vector extensions, and careful tuning to the memory hierarchy. In this paper, we demonstrate the computer generation of high performance code for SAR\u00a0\u2026", "num_citations": "18\n", "authors": ["275"]}
{"title": "Automatic cost minimization for multiplierless implementations of discrete signal transforms\n", "abstract": " The computation of linear DSP transforms consists entirely of additions and multiplications by constants, which, in a hardware realization, can be implemented as a network of wired shifts and additions. Thus, a light weight fixed point implementation that approximates an exact transform can be built from only adders. The paper presents an automatic approach for minimizing the number of additions required for a given transform under the constraint of a particular quality measure. We present an evaluation of our approach. For example, one experiment shows that the IMDCT transform within an MP3 decoder can be reduced from 572 additions to 260 additions while maintaining limited accuracy as defined by the MP3 ISO standard.", "num_citations": "18\n", "authors": ["275"]}
{"title": "Automatic generation of implementations for DSP transforms on fused multiply-add architectures\n", "abstract": " Many modern computer architectures feature fused multiply-add (FMA) instructions, which offer potentially faster performance for numerical applications. For DSP transforms, compilers can only generate FMA code to a very limited extent because optimal use of FMAs requires modifying the chosen algorithm. In this paper, we present a framework for automatically generating FMA code for every linear DSP transform, which we implemented as an extension to the SPIRAL code generation system. We show that for many transforms and transform sizes, our generated FMA code matches the best-known hand-derived FMA algorithms in terms of arithmetic cost. Further, we present actual runtime results that show the speed-up obtained by using FMA instructions.", "num_citations": "18\n", "authors": ["275"]}
{"title": "Optimal circuits for streamed linear permutations using RAM\n", "abstract": " We propose a method to automatically derive hardware structures that perform a fixed linear permutation on streaming data. Linear permutations are permutations that map linearly the bit representation of the elements addresses. This set contains many of the most important permutations in media processing, communication, and other applications and includes perfect shuffles, stride permutations, and the bit reversal. Streaming means that the data to be permuted arrive as a sequence of chunks over several cycles. We solve this problem by mathematically decomposing a given permutation into a sequence of three permutations that are either temporal or spatial. The former are implemented as banks of RAM, the latter as switching networks. We prove optimality of our solution in terms of the number of switches in these networks.", "num_citations": "17\n", "authors": ["275"]}
{"title": "Staging for generic programming in space and time\n", "abstract": " Metaprogramming is among the most promising candidates to solve the abstraction vs performance trade-off that plagues software engineering through specialization. Metaprogramming has been used to enable low-overhead generic programming for a long time, with C++ templates being one of the most prominent examples. But often a single, fixed pattern of specialization is not enough, and more flexibility is needed. Hence, this paper seeks to apply generic programming techniques to challenges in metaprogramming, in particular to abstract over the execution stage of individual program expressions. We thus extend the scope of generic programming into the dimension of time. The resulting notion of stage polymorphism enables novel abstractions in the design of program generators, which we develop and explore in this paper. We present one possible implementation, in Scala using the lightweight modular\u00a0\u2026", "num_citations": "16\n", "authors": ["275"]}
{"title": "Design studies for ASIC implementations of 28 GS/s optical QPSK-and 16-QAM-OFDM transceivers\n", "abstract": " We designed at the register-transfer-level digital signal processing (DSP) circuits for 21.8 Gb/s and 43.7 Gb/s QPSK- and 16-QAM-encoded optical orthogonal frequency division multiplexing (OFDM) transceivers, and carried out synthesis and simulations assessing performance, power consumption and chip area. The aim of the study is to determine the suitability of OFDM technology for low-cost optical interconnects. Power calculations based on synthesis for a 65nm standard-cell library showed that the DSP components of the transceiver (FFTs, equalisation, (de)mapping and clipping/scaling circuits) consume 18.2 mW/Gb/s and 12.8 mW/Gb/s in the case of QPSK and 16-QAM respectively.", "num_citations": "16\n", "authors": ["275"]}
{"title": "Fast Fourier Transform\n", "abstract": " The discrete Fourier transform (DFT) is a ubiquitous tool in science and engineering including in digital signal processing, communication, and high-performance computing. Applications include spectral analysis, image compression, interpolation, solving partial differential equations, and many other tasks. Given n real or complex inputs x0,..., xn\u2212 1, the DFT is defined as yk=\u22110\u2264 \u2113< n \u03c9k\u2113 n x\u2113, 0\u2264 k< n,(1) with \u03c9n= exp (\u2212 2\u03c0i/n), i=", "num_citations": "16\n", "authors": ["275"]}
{"title": "Discrete Fourier transform compiler: From mathematical representation to efficient hardware\n", "abstract": " A wide range of hardware implementations are pos-sible for the discrete Fourier transform (DFT), offering different tradeoffs in throughput, latency and cost. The well-understood structure of DFT algorithms makes possible a fully automatic synthesis framework that can span the viable interesting design choices. In this paper, we present such a synthesis framework that starts from formal mathematical formulas of a general class of fast DFT algorithms and produces performance and cost efficient sequential hardware implementations, making design decisions and tradeoffs according to user specified high-level preferences. We present evaluations to demonstrate the variety of supported implementations and the cost/performance tradeoffs they allow.", "num_citations": "16\n", "authors": ["275"]}
{"title": "Custom-optimized multiplierless implementations of DSP algorithms\n", "abstract": " Linear DSP kernels such as transforms and filters are comprised exclusively of additions and multiplications by constants. These multiplications may be realized as networks of additions and wired shifts in hardware. The cost of such a \"multiplierless\" implementation is determined by the number of additions, which in turn depends on the value and precision of these constants. For a given transform or filter, the set of constants and their required precision is affected by algorithmic and implementation choices and hence provides a degree of freedom for optimization. In This work we present an automated method to generate, for a given linear transform, a minimum addition multiplierless implementation that satisfies a given quality constraint. The method combines automatic algorithm selection to improve numerical robustness and automatic search methods to minimize constant precisions in a chosen algorithm. We\u00a0\u2026", "num_citations": "16\n", "authors": ["275"]}
{"title": "A basic linear algebra compiler for embedded processors\n", "abstract": " Many applications in signal processing, control, and graphics on embedded devices require efficient linear algebra computations. On general-purpose computers, program generators have proven useful to produce such code, or important building blocks, automatically. An example is LGen, a compiler for basic linear algebra computations of fixed size. In this work, we extend LGen towards the embedded domain using as example targets Intel Atom, ARM Cortex-A8, ARM Cortex-A9, and ARM1176 (Raspberry Pi). To efficiently support these processors we introduce support for the NEON vector ISA and a methodology for domain-specific load/store optimizations. Our experimental evaluation shows that the new version of LGen produces code that performs in many cases considerably better than well-established, commercial and non-commercial libraries (Intel MKL and IPP), software generators (Eigen and ATLAS\u00a0\u2026", "num_citations": "15\n", "authors": ["275"]}
{"title": "D-ADMM: A distributed algorithm for compressed sensing and other separable optimization problems\n", "abstract": " We propose a distributed, decentralized algorithm for solving separable optimization problems over a connected network of compute nodes. In a separable problem, each node has its own private function and its own private constraint set. Private means that no other node has access to it. The goal is to minimize the sum of all nodes' private functions, constraining the solution to be in the intersection of all the private sets. Our algorithm is based on the alternating direction method of multipliers (ADMM) and requires a coloring of the network to be available beforehand. We perform numerical experiments of the algorithm, applying it to compressed sensing problems. These show that the proposed algorithm requires in general less iterations, and hence less communication between nodes, than previous algorithms to achieve a given accuracy.", "num_citations": "15\n", "authors": ["275"]}
{"title": "An adaptive multiresolution approach to fingerprint recognition\n", "abstract": " We propose an adaptive multiresolution (MR) approach to the classification of fingerprint images. The system adds MR decomposition in front of a generic classifier consisting of feature computation and classification in each MR subspace, yielding local decisions, which are then combined into a global decision using a weighting algorithm. In our previous work on classification of protein subcellular location images, we showed that the space-frequency localized information in the MR subspaces adds significantly to the discriminative power of the system. Here, we go one step farther; We develop a new weighting method which allows for the discriminative power of each subband to be expressed and examined within each class. This, in turn, allows us to evaluate the importance of the information contained within a specific subband. Moreover, we develop a pruning procedure to eliminate the subbands that do not\u00a0\u2026", "num_citations": "15\n", "authors": ["275"]}
{"title": "Automatic derivation and implementation of signal processing algorithms\n", "abstract": " We present a computer algebra framework to automatically derive and implement algorithms for digital signal processing. The two main parts of the framework are AREP, a library for symbolic manipulation of group representations and structured matrices, and SPL, a compiler turning matrix expressions into efficient imperative-style numerical programs.", "num_citations": "15\n", "authors": ["275"]}
{"title": "Improving fixed-point accuracy of FFT cores in O-OFDM systems\n", "abstract": " Optical OFDM communication systems operating at data rates in the 40Gb/s (and higher) range require high-throughput/highly parallel fast Fourier transform (FFT) implementations. These consume a significant amount of chip resources; we aim to reduce costs by improving the system's accuracy per chip-area. For OFDM signals, we characterize the growth of data within the FFT and explore several cost-conscious methods for improving the fixed-point format. Using ASIC synthesis and hardware accurate simulations, we evaluate the corresponding system error and stability of these methods. We introduce Directive Scaling, which provides an average increase in overall accuracy without additional runtime-adaptive mechanisms. ASIC synthesis results show minimal overhead, and we explicitly evaluate and explain the inherent tradeoffs. When applied to an 8-bit IFFT design, our technique improves precision by\u00a0\u2026", "num_citations": "14\n", "authors": ["275"]}
{"title": "Hardware implementation of the discrete fourier transform with non-power-of-two problem size\n", "abstract": " In this paper, we examine several algorithms suitable for the hardware implementation of the discrete Fourier transform (DFT) with non-power-of two problem size. We incorporate these algorithms into Spiral, a tool capable of automatically generating corresponding hardware implementations. We discuss how each algorithm can be used to generate different types of hardware structures, and we demonstrate that our tool is able to produce hardware implementations of non-power-of-two sized DFTs over a wide range of cost/performance tradeoff points.", "num_citations": "14\n", "authors": ["275"]}
{"title": "Fourier transform for the spatial quincunx lattice\n", "abstract": " We derive a new, two-dimensional nonseparable signal transform for computing the spectrum of spatial signals residing on a finite quincunx lattice. The derivation uses the connection between transforms and polynomial algebras, which has long been known for the discrete Fourier transform (DFT), and was extended to other transforms in recent research. We also show that the new transform can be computed with O(n/sup 2/ log(n)) operations, which puts it in the same complexity class as its separable counterparts.", "num_citations": "14\n", "authors": ["275"]}
{"title": "Fourier transform for the directed quincunx lattice\n", "abstract": " We introduce a new signal transform for computing the spectrum of a signal given on a two-dimensional directional quincunx lattice. The transform is non-separable, but closely related to a two-dimensional (separable) discrete Fourier transform. We derive the transform using recently discovered connections between signal transforms and polynomial algebras. These connections also yield several important properties of the new transform.", "num_citations": "14\n", "authors": ["275"]}
{"title": "Powerset convolutional neural networks\n", "abstract": " We present a novel class of convolutional neural networks (CNNs) for set functions, i.e., data indexed with the powerset of a finite set. The convolutions are derived as linear, shift-equivariant functions for various notions of shifts on set functions. The framework is fundamentally different from graph convolutions based on the Laplacian, as it provides not one but several basic shifts, one for each element in the ground set. Prototypical experiments with several set function classification tasks on synthetic datasets and on datasets derived from real-world hypergraphs demonstrate the potential of our new powerset CNNs.", "num_citations": "13\n", "authors": ["275"]}
{"title": "Robustness certification with refinement\n", "abstract": " We present a novel approach for the certification of neural networks against adversarial perturbations which combines scalable overapproximation methods with precise (mixed integer) linear programming. This results in significantly better precision than state-of-the-art verifiers on challenging feedforward and convolutional neural networks with piecewise linear activation functions.", "num_citations": "13\n", "authors": ["275"]}
{"title": "ADMM for consensus on colored networks\n", "abstract": " We propose a novel distributed algorithm for one of the most fundamental problems in networks: the average consensus. We view the average consensus as an optimization problem, which allows us to use recent techniques and results from the optimization area. Based on the assumption that a coloring scheme of the network is available, we derive a decentralized, asynchronous, and communication-efficient algorithm that is based on the Alternating Direction Method of Multipliers (ADMM). Our simulations with other state-of-the-art consensus algorithms show that the proposed algorithm is the one exhibiting the most stable performance across several network models.", "num_citations": "13\n", "authors": ["275"]}
{"title": "Real-time software implementation of an IEEE 802.11 a baseband receiver on Intel multicore\n", "abstract": " We present a software-only implementation of an IEEE 802.11a (WiFi) receiver optimized for Intel multicore platforms. The receiver is about 50 times faster than a straightforward C implementation, i.e., an implementation that has the same functionality, but leaves optimization completely to the compiler. Our hand-optimized implementation achieves real-time for all data rates up to the maximum of 54 Mbit/s on a Core i7, clocked at 3.3 GHz, and for up to 12 Mbit/s on an Atom, clocked at 1.6 GHz, using two cores in both cases. To achieve this performance we use up to two threads, up to 16-way vectorization using Intel's SSE, and various other optimizations.", "num_citations": "13\n", "authors": ["275"]}
{"title": "Algebraic signal processing theory: Sampling for infinite and finite 1-D space\n", "abstract": " We derive a signal processing framework, called space signal processing, that parallels time signal processing. As such, it comes in four versions (continuous/discrete, infinite/finite), each with its own notion of convolution and Fourier transform. As in time, these versions are connected by sampling theorems that we derive. In contrast to time, however, space signal processing is based on a different notion of shift, called space shift, which operates symmetrically. Our work rigorously connects known and novel concepts into a coherent framework; most importantly, it shows that the sixteen discrete cosine and sine transforms are the space equivalent of the discrete Fourier transform, and hence can be derived by sampling. The platform for our work is the algebraic signal processing theory, an axiomatic approach and generalization of linear signal processing that we recently introduced.", "num_citations": "13\n", "authors": ["275"]}
{"title": "The discrete triangle transform\n", "abstract": " We introduce the discrete triangle transform (DTT), a non-separable transform for signal processing on a two-dimensional equispaced triangular grid. The DTT is, in a strict mathematical sense, a generalization of the DCT, type III, to two dimensions, since the DTT is built from Chebyshev polynomials in two variables in the same way as the DCT, type III, is built from Chebyshev polynomials in one variable. We provide boundary conditions, signal extension, and diagonalization properties for the DTT. Finally, we give evidence that the DTT has Cooley-Tukey FFT like algorithms that enable its efficient computation.", "num_citations": "13\n", "authors": ["275"]}
{"title": "Fast automatic software implementations of FIR filters\n", "abstract": " SPIRAL is a generator for platform-adapted libraries of DSP transform algorithms. SPIRAL represents and automatically generates fast algorithms as mathematical formulas and translates them into programs. Adaptation is achieved by searching in the space of algorithmic and coding alternatives for the fastest implementation. We extend SPIRAL to generate platform-adapted implementations of FIR filters. First, we present various filter algorithms and introduce the mathematical constructs needed to include them into SPIRAL's architecture. Then we use SPIRAL to find fast filter implementations. The results show runtime improvements to a standard loop implementation of up to 70% using different blocking techniques. Further, we show that the usefulness of frequency-domain methods is not determined by the number of operations.", "num_citations": "13\n", "authors": ["275"]}
{"title": "Short vector code generation and adaptation for DSP algorithms\n", "abstract": " Most recent general purpose processors feature short vector SIMD instructions, like SSE on Pentium III/4. We automatically generate platform-adapted short vector code for DSP transform algorithms using SPIRAL. SPIRAL represents and generates fast algorithms as mathematical formulas, and translates them into code. Adaptation is achieved by searching in the space of algorithmic and coding alternatives for the fastest implementation on the given platform. We explain the mathematical foundation that relates formula constructs to vector code, and overview the vector code generator within SPIRAL. Experimental results show excellent speed-ups compared to ordinary C code for a variety of transforms and computing platforms. For the DFT on Pentium 4, our automatically generated code compares favorably with the hand-tuned Intel MKL vendor library.", "num_citations": "13\n", "authors": ["275"]}
{"title": "Solving puzzles related to permutation groups\n", "abstract": " Physical puzzles that can be solved with methods for permutation groups are considered and classified according to a number of abstract properties. The approach for solution is based on word stabilizer chains (the transversal elements are factored in words in a given list of generators). New methods are presented to construct word stabilizer chains that take advantage of the special structures present in physical puzzles. In many cases the methods are successful in avoiding the exponential growth of word length that plagues stabilizer chain methods to construct transversal elements. Finally, a classification scheme for puzzles is presented which helps with finding the permutation group related to the puzzle.", "num_citations": "13\n", "authors": ["275"]}
{"title": "Learning fast and precise numerical analysis\n", "abstract": " Numerical abstract domains are a key component of modern static analyzers. Despite recent advances, precise analysis with highly expressive domains remains too costly for many real-world programs. To address this challenge, we introduce a new data-driven method, called LAIT, that produces a faster and more scalable numerical analysis without significant loss of precision. Our approach is based on the key insight that sequences of abstract elements produced by the analyzer contain redundancy which can be exploited to increase performance without compromising precision significantly. Concretely, we present an iterative learning algorithm that learns a neural policy that identifies and removes redundant constraints at various points in the sequence. We believe that our method is generic and can be applied to various numerical domains.", "num_citations": "12\n", "authors": ["275"]}
{"title": "A discrete signal processing framework for meet/join lattices with applications to hypergraphs and trees\n", "abstract": " We introduce a novel discrete signal processing framework, called discrete-lattice SP, for signals indexed by a finite lattice. A lattice is a partially ordered set that supports a meet (or join) operation that returns the greatest element below two given elements. Discrete-lattice SP chooses the meet as shift operation and derives associated notion of (meet-invariant) convolution, Fourier transform, frequency response, and a convolution theorem. Examples of lattices include sets of sets that are closed under intersection and trees. Thus our framework is applicable to certain sparse set functions, signals on sparse hypergraphs, and signals on trees. Another view on discrete-lattice SP is as an SP framework for a certain class of directed graphs. However, it is fundamentally different from the prior graph SP as it is based on more than one basic shift and all shifts are always simultaneously diagonalizable.", "num_citations": "12\n", "authors": ["275"]}
{"title": "A discrete signal processing framework for set functions\n", "abstract": " A set function associates a real (or complex) value with every subset of a given finite set S. In this paper, we derive a novel discrete signal processing (DSP) framework for such functions. This means we define and derive suitable notions of basic DSP concepts including shift, filtering, frequency response, Fourier transform, and convolution theorems. At the heart is the definition of the shift on subsets for which we consider the two most natural choices, i.e., those most analogous to the time shift in standard DSP. Set functions naturally occur in many contexts associated with probability distributions, graph cuts, sensor placements, mutual information, entropy of sets of random variables, and others. Our work offers a new set of tools for their processing.", "num_citations": "12\n", "authors": ["275"]}
{"title": "Scaling Polyhedral Neural Network Verification on GPUs\n", "abstract": " Certifying the robustness of neural networks against adversarial attacks is critical to their reliable adoption in realworld systems including autonomous driving and medical diagnosis. Unfortunately, state-of-the-art verifiers either do not scale to larger networks or are too imprecise to prove robustness, which limits their practical adoption.In this work, we introduce GPUPoly, a scalable verifier that can prove the robustness of significantly larger deep neural networks than possible with prior work. The key insight behind GPUPoly is the design of custom, sound polyhedra algorithms for neural network verification on a GPU. Our algorithms leverage the available GPU parallelism and the inherent sparsity of the underlying neural network verification task. GPUPoly scales to very large networks: for example, it can prove the robustness of a 1M neuron, 34-layer deep residual network in about 1 minute. We believe GPUPoly is a promising step towards the practical verification of large real-world networks.", "num_citations": "11\n", "authors": ["275"]}
{"title": "Algebraic signal processing theory: Cooley\u2013Tukey type algorithms on the 2-D hexagonal spatial lattice\n", "abstract": " Recently, we introduced the framework for signal processing on a nonseparable 2-D hexagonal spatial lattice including the associated notion of Fourier transform called discrete triangle transform (DTT). Spatial means that the lattice is undirected in contrast to earlier work by Mersereau introducing hexagonal discrete Fourier transforms. In this paper we derive a general-radix algorithm for the DTT of an n \u00d7 n 2-D signal, focusing on the radix-2 \u00d7 2 case. The runtime of the algorithm is O(n                         2 log(n)), which is the same as for commonly used separable 2-D transforms. The DTT algorithm derivation is based on the algebraic signal processing theory. This means that instead of manipulating transform coefficients, the algorithm is derived through a stepwise decomposition of its underlying polynomial algebra based on a general theorem that we introduce. The theorem shows that the obtained DTT\u00a0\u2026", "num_citations": "11\n", "authors": ["275"]}
{"title": "SIMD vectorization of non-two-power sized FFTs\n", "abstract": " SIMD (single instruction multiple data) vector instructions, such as Intel's SSE family, are available on most architectures, but are difficult to exploit for speed-up. In many cases, such as the fast Fourier transform (FFT), signal processing algorithms have to undergo major transformations to map efficiently. Using the Kronecker product formalism, we rigorously derive a novel variant of the general-radix Cooley-Tukey FFT that is structured to map efficiently for any vector length v and radix. Then, we include the new FFT into the program generator spiral to generate actual C implementations. Benchmarks on Intel's SSE show that the new algorithms perform better on practically all sizes than the best available libraries Intel's MKL and FFTW.", "num_citations": "11\n", "authors": ["275"]}
{"title": "Cooley-Tukey FFT like algorithm for the discrete triangle transform\n", "abstract": " The discrete triangle transform (DTT) was recently introduced (Pu/spl uml/schel, M. and Ro/spl uml/tteler, M., Proc. ICASSP, 2004) as an example of a non-separable transform for signal processing on a two-dimensional triangular grid. The DTT is built from Chebyshev polynomials in two variables in the same way as the DCT, type III, is built from Chebyshev polynomials in one variable. We show that, as a consequence, the DTT has, like the type III DCT, a Cooley-Tukey FFT type fast algorithm. We derive this algorithm and an upper bound for the number of complex operations it requires. Similar to most separable two-dimensional transforms, the operations count of this algorithm is O(n/sup 2/ log(n)) for an input of size n/spl times/n.", "num_citations": "11\n", "authors": ["275"]}
{"title": "RandIR: differential testing for embedded compilers\n", "abstract": " This paper describes RandIR, a tool for differential testing of compilers using random instances of a given intermediate representation (IR). RandIR assumes no fixed target language but instead supports extensible IR-definitions through an internal IR-independent representation of operations. This makes it particularly well suited to test embedded compilers for multi-stage programming, which is our main use case. The ideas underlying our work, however, are more generally applicable.", "num_citations": "10\n", "authors": ["275"]}
{"title": "FFT Compiler: from math to efficient hardware HLDVT invited short paper\n", "abstract": " This paper presents a high-level compiler that generates hardware implementations of the discrete Fourier transform (DFT) from mathematical specifications. The matrix formula input language captures not only the DFT calculation but also the implementation options at the algorithmic and architectural levels. By selecting the appropriate formula, the resulting hardware implementations (described in a synthesizable Verilog description) can achieve a wide range of tradeoffs between implementation cost and performance. The compiler is also parameterized for a set of technology-specific optimizations, to allow it to target specific implementation platforms. This paper gives a brief overview of the system and presents synthesis results.", "num_citations": "10\n", "authors": ["275"]}
{"title": "Mechanical Derivation of Fused Multiply\u2013Add Algorithms for Linear Transforms\n", "abstract": " Several computer architectures offer fused multiply-add (FMA), also called multiply-and-accumulate (MAC) instructions, that are as fast as a single addition or multiplication. For the efficient implementation of linear transforms, such as the discrete Fourier transform or discrete cosine transforms, this poses a challenge to algorithm developers as standard transform algorithms have to be manipulated into FMA algorithms that make optimal use of FMA instructions. We present a general method to convert any transform algorithm into an FMA algorithm. The method works with both algorithms given as directed acyclic graphs (DAGs) and algorithms given as structured matrix factorizations. We prove bounds on the efficiency of the method. In particular, we show that it removes all single multiplications except at most as many as the transform has outputs. We implemented the DAG-based version of the method and show that\u00a0\u2026", "num_citations": "10\n", "authors": ["275"]}
{"title": "Abstracting vector architectures in library generators: Case study convolution filters\n", "abstract": " We present FGen, a program generator for high performance convolution operations (finite-impulse-response filters). The generator uses an internal mathematical DSL to enable structural optimization at a high level of abstraction. We use FGen as a testbed to demonstrate how to provide modular and extensible support for modern SIMD vector architectures in a DSL-based generator. Specifically, we show how to combine staging and generic programming with type classes to abstract over both the data type (real or complex) and the target architecture (eg, SSE or AVX) when mapping DSL expressions to C code with explicit vector intrinsics. Benchmarks shows that the generated code is highly competitive with commercial libraries.", "num_citations": "9\n", "authors": ["275"]}
{"title": "Systematic construction of real lapped tight frame transforms\n", "abstract": " We present a constructive algorithm for the design of real lapped equal-norm tight frame transforms. These transforms can be efficiently implemented through filter banks and have recently been proposed as a redundant counterpart to lapped orthogonal transforms, as well as an infinite-dimensional counterpart to harmonic tight frames. The proposed construction consists of two parts: First, we design a large class of new real lapped orthogonal transforms derived from submatrices of the discrete Fourier transform. Then, we seed these to obtain real lapped tight frame transforms corresponding to tight, equal-norm frames. We identify those frames that are maximally robust to erasures, and show that our construction leads to a large class of new lapped orthogonal transforms as well as new lapped tight frame transforms.", "num_citations": "9\n", "authors": ["275"]}
{"title": "Performance/energy optimization of DSP transforms on the XScale processor\n", "abstract": " The XScale processor family provides user-controllable independent configuration of CPU, bus, and memory frequencies. This feature introduces another handle for the code optimization with respect to energy consumption or runtime performance. We quantify the effect of frequency configurations on both performance and energy for three signal processing transforms: the discrete Fourier transform (DFT), finite impulse response (FIR) filters, and the Walsh-Hadamard Transform (WHT).               To do this, we use SPIRAL, a program generation and optimization system for signal processing transforms. For a given transform to be implemented, SPIRAL searches over different algorithms to find the best match to the given platform with respect to the chosen performance metric (usually runtime). In this paper we use SPIRAL to generate implementations for different frequency configurations and optimize for\u00a0\u2026", "num_citations": "9\n", "authors": ["275"]}
{"title": "Multiple constant multiplication by time-multiplexed mapping of addition chains\n", "abstract": " An important primitive in the hardware implementations of linear DSP transforms is a circuit that can multiply an input value by one of several different preset constants. We propose a novel implementation of this circuit based on combining the addition chains of the constituent constants. We present an algorithm to automatically generate such a circuit for a given set of constants. The quality of the resulting circuits is evaluated after synthesis for a commercial 0.18 um standard cell library. We compare the area and latency efficiency of this addition chain based approach against a straightforward approach based on a constant table and a full multiplier.", "num_citations": "9\n", "authors": ["275"]}
{"title": "Short vector SIMD code generation for DSP algorithms\n", "abstract": " Viewgraphs of presentation on short vector SIMD code generation for digital signal processing algorithms.Descriptors:", "num_citations": "9\n", "authors": ["275"]}
{"title": "Generalizing block LU factorization: A lower\u2013upper\u2013lower block triangular decomposition with minimal off-diagonal ranks\n", "abstract": " We propose a novel factorization of a non-singular matrix P, viewed as a 2\u00d7 2-blocked matrix. The factorization decomposes P into a product of three matrices that are lower block-unitriangular, upper block-triangular, and lower block-unitriangular, respectively. Our goal is to make this factorization \u201cas block-diagonal as possible\u201d by minimizing the ranks of the off-diagonal blocks. We give lower bounds on these ranks and show that they are sharp by providing an algorithm that computes an optimal solution. The proposed decomposition can be viewed as a generalization of the well-known Block LU factorization using the Schur complement. Finally, we briefly explain one application of this factorization: the design of optimal circuits for a certain class of streaming permutations.", "num_citations": "8\n", "authors": ["275"]}
{"title": "Computer generation of platform-adapted physical layer software\n", "abstract": " In this paper, we describe a program generator for physical layer (PHY) baseband processing in a software-defined radio implementation. The input of the generator is a very highlevel platform-independent description of the transmitter and receiver PHY functionality, represented in a domain-specific declarative language called Operator Language (OL). The output is performance-optimized and platform-tuned C code with single-instruction multiple-data (SIMD) vector intrinsics and threading directives. The generator performs these optimizations by restructuring the algorithms for the individual components at the OL level before mapping to code. This way known compiler limitation are overcome. Further platform tuning is achieved by a feedback-directed search that determines the fastest solution among a space of candidates. We demonstrate the approach and the excellent performance of the generated code on on the IEEE 802.11a (WiFi) receiver and transmitter for all transmission modes.", "num_citations": "8\n", "authors": ["275"]}
{"title": "FFT program generation for the Cell BE\n", "abstract": " The complexity of the Cell BE\u2019s architecture makes it difficult and time consuming to develop multithreaded, vectorized, high-performance numerical libraries. Our approach to solving this problem is to use Spiral, a program generation system, to automatically generate and optimize linear transform libraries for the Cell. To extend the Spiral framework to support the Cell architecture, we first show how to automatically generate high-performance discrete Fourier transform kernels that run on a single SPE. The performance of our kernels is comparable to hand tuned code, and reaches 16\u201320 Gflop/s on a single SPE for input vectors resident in the local memories. We then show how to produce optimized multithreaded code that runs on multiple SPEs.", "num_citations": "8\n", "authors": ["275"]}
{"title": "Fast signal transforms for quantum computers\n", "abstract": " We present the discrete Fourier transform as a basic primitive in the treatment of controlled quantum systems. Based on the complexity model for quantum circuits the Fourier transform of size 2 n surprisingly can be realised with O (n\u00b2) elementary operations which is an exponential speedup compared to the classical case. This is the reason for its presence in almost all known quantum algorithms among which Shor's algorithm for factoring is the most prominent example. We show how recent results in the theory of signal processing (for a classical computer) can be applied to obtain fast quantum algorithms for various discrete signal transforms. As an example we derive a quantum circuit implementing the discrete cosine transform DCTIV (8) efficiently.", "num_citations": "8\n", "authors": ["275"]}
{"title": "Decomposing a permutation into a conjugated tensor product\n", "abstract": " The problem of decomposing a single permutation into a conjugated tensor product of smaller permutations is solved. Iu general, the decomposition is not uniquely determined. An algorithm is presented which enumerates all solutions. In particular, it is possible to decide considerably fast if a permutation is tensor-indecomposable.", "num_citations": "8\n", "authors": ["275"]}
{"title": "A DSL-based FFT hardware generator in Scala\n", "abstract": " We present a generator for fast Fourier transforms (FFTs) on hardware. The input of the generator is a high-level description of an FFT algorithm; the output is a token-based, synchronized design in the form of RTL-Verilog. Building on prior work, the generator uses several layers of domain-specific languages (DSLs) to represent and optimize at different levels of abstraction to produce a RAM-and area-efficient hardware implementation. Two of these layers and DSLs are novel. The first one allows the use and domain-specific optimization of state-of-the-art streaming permutations. The second DSL enables the automatic pipelining of a streaming hardware dataflow and the synchronization of its data-independent control signals. The generator including the DSLs are implemented in Scala, leveraging its type system, and uses concepts from lightweight modular staging (LMS) to handle the constraints of streaming\u00a0\u2026", "num_citations": "7\n", "authors": ["275"]}
{"title": "Generating high-performance general size linear transform libraries using Spiral\n", "abstract": " For example, a typical input to the library generator is Developing numerical libraries that achieve highest performance on modern computer architectures became an extremely difficult task due to the increasingly complicated microarchitectures,", "num_citations": "7\n", "authors": ["275"]}
{"title": "Algebraic derivation of general radix Cooley-Tukey algorithms for the real discrete Fourier transform\n", "abstract": " We first show that the real version of the discrete Fourier transform (called RDFT) can be characterized in the framework of polynomial algebras just as the DFT and the discrete cosine and sine transforms. Then, we use this connection to algebraically derive a general radix Cooley-Tukey type algorithm for the RDFT The algorithm has a similar structure as its complex counterpart, but there are also important differences, which are exhibited by our Kronecker product style presentation. In particular, the RDFT is decomposed into smaller RDFTs but also other auxiliary transforms, which we then decompose by their own Cooley-Tukey type algorithms to obtain a full recursive algorithm for the RDFT", "num_citations": "7\n", "authors": ["275"]}
{"title": "Generation of custom DSP transform IP cores: Case study Walsh-Hadamard transform\n", "abstract": " Presentation of a case study on the generation of custom digital signal processing transform information processing cores.Descriptors:", "num_citations": "7\n", "authors": ["275"]}
{"title": "Sampling signals on meet/join lattices\n", "abstract": " We present a novel sampling theorem, and prototypical applications, for Fourier-sparse lattice signals, i.e., data indexed by a finite semilattice. A semilattice is a partially ordered set endowed with a meet (or join) operation that returns the greatest lower bound (smallest upper bound) of two elements. Semilattices can be viewed as a special class of directed graphs with a strictly triangular adjacency matrix, which thus cannot be diagonalized. Our work does not build on prior graph signal processing (GSP) frameworks but on the recently introduced discrete-lattice signal processing (DLSP), which uses the meet as shift operator to derive convolution and Fourier transform. DLSP is fundamentally different from GSP in that it requires several generating shifts that capture the partial-order- rather than the adjacency-structure, and a diagonalizing Fourier transform is always guaranteed by algebraic lattice theory. We apply\u00a0\u2026", "num_citations": "6\n", "authors": ["275"]}
{"title": "How to write fast numerical code\n", "abstract": " Method Int (add/mult) Float (add/mult) combine4 2.2 10.0 5.0 7.0 bound 1.0 1.0 2.0 2.0", "num_citations": "6\n", "authors": ["275"]}
{"title": "Distributed algorithms for basis pursuit\n", "abstract": " The Basis Pursuit (BP) problem consists in finding a least `1 norm solution of the underdetermined linear system Ax = b. It arises in many areas of electrical engineering and applied mathematics. Applications include signal compression and modeling, estimation, fitting, and compressed sensing. In this paper, we explore methods for solving the BP in a distributed environment, i.e., when the computational resources and the matrix A are distributed over several interconnected nodes. Special instances of this distributed framework include sensor networks and distributed memory and/or processor platforms. We consider two distribution paradigms: either the columns or the rows of A are distributed across the nodes. The several algorithms that we present impose distinct requirements on the degree of connectivity of the network and the per-node computational complexity.", "num_citations": "6\n", "authors": ["275"]}
{"title": "The algebraic structure in signal processing: time and space\n", "abstract": " The assumptions underlying linear signal processing (SP) produce more structure than vector spaces. We capture this structure by describing the space of filters as an algebra and the space of signals as the associated module. We formulate an algebraic approach to SP that is axiomatically based on the concept of a signal model. Signal models for time are visualized as directed graphs. We construct corresponding models for undirected graphs, which we hence call space models, and show that, in particular, the 16 DCTs and DSTs are Fourier transforms for these finite space models. Finally, we discuss the extension of our theory to separable and nonseparable 2-DSP", "num_citations": "6\n", "authors": ["275"]}
{"title": "Accelerating blocked matrix-matrix multiplication using a software-managed memory hierarchy with DMA\n", "abstract": " The optimization of matrix-matrix multiplication (MMM) performance has been well studied on general-purpose desktop and server processors. Classic solutions exploit common microarchitectural features including superscalar execution and the cache and TLB hierarchy to achieve near-peak performance. Typical digital signal processors (DSPs) do not have these features, and instead use in-order execution, configurable memory hierarchies, and programmable I/O interfaces.We investigate the methods needed to achieve high performance MMM on the Texas Instruments C6713 floatingpoint DSP. This processor has two components that can be used to accelerate MMM: a software-managed memory hierarchy, and a direct memory access (DMA) engine that can perform block copies from main memory to into the memory hierarchy. Our MMM implementation overlaps computation with DMA block transfers. For matrices larger than the data caches, we observed a 46% performance increase over a blocked MMM implementation, and a 190% increase over the Texas Instruments DSP library.", "num_citations": "6\n", "authors": ["275"]}
{"title": "The discrete trigonometric transforms and their fast algorithms: An algebraic symmetry perspective\n", "abstract": " It is well-known that the discrete Fourier transform (DFT) can be characterized as decomposition matrix for the polynomial algebra /spl Copf/[x]/(x/sup n/ - 1). This property gives deep insight into the DFT and can be used to explain and derive its fast algorithms. In this paper we present the polynomial algebras associated to the 16 discrete cosine and sine transforms. Then we derive important algorithms by manipulating algebras rather than matrix entries. This makes the derivation more transparent and explains their structure. Our results show that the relationship between signal processing and algebra is stronger than previously understood.", "num_citations": "6\n", "authors": ["275"]}
{"title": "Discrete Signal Processing with Set Functions\n", "abstract": " Set functions are functions (or signals) indexed by the powerset (set of all subsets) of a finite set N. They are fundamental and ubiquitous in many application domains and have been used, for example, to formally describe or quantify loss functions for semantic image segmentation, the informativeness of sensors in sensor networks the utility of sets of items in recommender systems, cooperative games in game theory, or bidders in combinatorial auctions. In particular, the subclass of submodular functions occurs in many optimization and machine learning problems. In this paper, we derive discrete-set signal processing (SP), a novel shift-invariant linear signal processing framework for set functions. Discrete-set SP considers different notions of shift obtained from set union and difference operations. For each shift it provides associated notions of shift-invariant filters, convolution, Fourier transform, and frequency\u00a0\u2026", "num_citations": "5\n", "authors": ["275"]}
{"title": "Linear transforms: From math to efficient hardware\n", "abstract": " Introduction. Linear transforms (such as the discrete Fourier transform) are widely used building blocks in signal processing applications. The domain of linear transforms and their algorithms is well understood mathematically. In this work, we utilize this math-level knowledge to construct a formula driven domain specific high-level synthesis tool. This tool is able to generate efficient register transfer level designs from a mathematical description of the problem. The tool\u2019s flexibility allows its generated designs to span a wide cost/performance tradeoff space. Formula Framework. A linear transform is defined as the matrix-vector multiplication y= An\u00b7 x, where x and y are (respectively) the n point input and output vectors, and An is an n\u00d7 n matrix that defines the transform. Computing a transform by definition requires O (n2) operations. So-called \u201cfast\u201d algorithms for linear transforms reduce the cost to O (n log n) operations\u00a0\u2026", "num_citations": "5\n", "authors": ["275"]}
{"title": "Parallelism in Spiral\n", "abstract": " Spiral is a program generator for linear transforms such as the discrete Fourier transform. Spiral generates highly optimized code directly from a problem specification using a combination of techniques including optimization at a high level of abstraction using rewriting of mathematical expressions and heuristic search for platform adaptation. In this paper, we overview the generation of parallel programs using Spiral. This includes programs for vector architectures and programs for shared or distributed memory platforms.", "num_citations": "5\n", "authors": ["275"]}
{"title": "Fourier analysis-based iterative combinatorial auctions\n", "abstract": " Recent advances in Fourier analysis have brought new tools to efficiently represent and learn set functions. In this paper, we bring the power of Fourier analysis to the design of iterative combinatorial auctions. The key idea is to approximate the bidders' value functions using Fourier-sparse set functions, which can be computed using a relatively small number of queries. Since this number is still too large for real-world auctions, we propose a novel hybrid auction design: we first use neural networks to learn bidders' values and then apply Fourier analysis to those learned representations. On a technical level, we formulate a Fourier transform-based winner determination problem and derive its mixed integer program formulation. Based on this, we devise an iterative mechanism that asks Fourier-based queries. Our experimental evaluation shows that our hybrid auction leads to a fairer distribution of social welfare among bidders and significantly reduces runtime, while matching the economic efficiency of state-of-the-art auction designs. With this paper, we are the first to leverage Fourier analysis in combinatorial auction design and lay the foundation for future work in this area.", "num_citations": "4\n", "authors": ["275"]}
{"title": "Diagonalizable shift and filters for directed graphs based on the Jordan-Chevalley decomposition\n", "abstract": " Graph signal processing on directed graphs poses theoretical challenges since an eigendecomposition of filters is in general not available. Instead, Fourier analysis requires a Jordan decomposition and the frequency response is given by the Jordan normal form, whose computation is numerically unstable for large sizes. In this paper, we propose to replace a given adjacency shift A by a diagonalizable shift A D  obtained via the Jordan-Chevalley decomposition. This means, as we show, that A D  generates the subalgebra of all diagonalizable filters and is itself a polynomial in A (i.e., a filter). For several synthetic and real-world graphs, we show how A D  adds and removes edges compared to A.", "num_citations": "4\n", "authors": ["275"]}
{"title": "Fast quantized arithmetic on x86: Trading compute for data movement\n", "abstract": " We introduce Clover, a new library for efficient computation using low-precision data, providing mathematical routines required by fundamental methods in optimization and sparse recovery. Our library faithfully implements variants of stochastic quantization that guarantee convergence at low precision, and supports data formats from 4-bit quantized to 32-bit IEEE-754 on current Intel processors. In particular, we show that 4-bit can be implemented efficiently using Intel AVX despite the lack of native support for this data format. Experimental results with dot product, matrix-vector multiplication (MVM), gradient descent (GD), and iterative hard thresholding (IHT) demonstrate that the attainable speedups are in many cases close to linear with respect to the reduction of precision due to reduced data movement. Finally, for GD and IHT, we show examples of absolute speedup achieved by 4-bit versus 32-bit, by iterating until\u00a0\u2026", "num_citations": "4\n", "authors": ["275"]}
{"title": "Program generation with Spiral: Beyond transforms\n", "abstract": " In this paper we extend the program generation system Spiral [5, 6] beyond its problem domain. Spiral was originally developed to automate the optimization of software libraries for linear transforms like the discrete Fourier transform (DFT), filters, wavelets, and others. In previous work we enabled Spiral to generate high-performance libraries for state-of-the-art and emerging platforms, including multicore CPUs with SIMD vector instruction sets, graphics processors (GPUs), field-programmable gate arrays (FPGAs), or a CPU with FPGA acceleration [2].Beyond transforms. In this paper we take Spiral a first step beyond the domain of linear transforms. We extend Spiral to generate parallel and/or vectorized libraries for 1) Viterbi decoding, 2) the EBCOT encoder used in JPEG2000, 3) an SAR imaging algorithm, and 4) matrixmatrix-multiplication (MMM) for small matrices. This is work in progress: our automatically generated Viterbi decoder libraries and small-size SGEMM MMM libraries are competitive with or outperform the best available hand-tuned libraries for the same functionality. For the EBCOT encoder and SAR imaging, Spiral automatically generates fast implementations but these are not yet competitive with the best available software.", "num_citations": "4\n", "authors": ["275"]}
{"title": "Sampling theorem associated with the discrete cosine transform\n", "abstract": " One way of deriving the discrete Fourier transform (DFT) is by equispaced sampling of periodic signals or signals on a circle. In this paper, we show that an analogous derivation can be used to obtain the DCT (type 2). To achieve this goal, we replace the circle by a line graph with symmetric boundary conditions, and define signal space, filter space, and filtering operation appropriately. Further, we derive the corresponding sampling theorem including the proper notions of \"bandlimited\" and \"sine function.\" The results show that, in a rigorous sense, the DCT is closely related to the DFT, and can be introduced without concepts from statistical signal processing as is the current practice", "num_citations": "4\n", "authors": ["275"]}
{"title": "Automatically optimized FFT codes for the BlueGene/L supercomputer\n", "abstract": " IBM\u2019s upcoming 360 Tflop/s supercomputer BlueGene/L featuring 65,536 processors is supposed to lead the Top 500 list when being installed in 2005. This paper presents one of the first numerical codes actually run on a small prototype of this machine. Formal vectorization techniques, the Vienna MAP vectorizer (both developed for generic short vector SIMD extensions), and the automatic performance tuning approach provided by Spiral are combined to generate automatically optimized FFT codes for the BlueGene/L machine targeting its two-way short vector SIMD \u201cdouble\u201d floating-point unit. The resulting FFT codes are 40% faster than the best scalar Spiral generated code and 5 times faster than the mixed-radix FFT implementation provided by the Gnu scientific library GSL.", "num_citations": "4\n", "authors": ["275"]}
{"title": "Spiral\n", "abstract": " Computer Generation of Performance Libraries Page 1 Carnegie Mellon Spiral Computer Generation of Performance Libraries Jos\u00e9 MF Moura Markus P\u00fcschel Franz Franchetti & the Spiral Team Applications Platforms Performance Page 2 Carnegie Mellon What is Spiral? Traditionally Spiral Approach High performance library optimized for given platform Spiral High performance library optimized for given platform Comparable performance Page 3 Carnegie Mellon Main Idea: Program Generation \u03bd p \u03bc Architectural parameter: Vector length, #processors, \u2026 rewriting defines Kernel: problem size, algorithm choice pick search abstraction abstraction Model: common abstraction = spaces of matching formulas architecture space algorithm space optimization Page 4 Carnegie Mellon How Spiral Works Algorithm Generation Algorithm Optimization Implementation Code Optimization Compilation Compiler Optimizations (\u201c\u201d /\u2026", "num_citations": "4\n", "authors": ["275"]}
{"title": "Generation and manipulation of DSP transform algorithms\n", "abstract": " SPIRAL generates automatically high quality implementations for a variety of DSP signal transforms. The generated code is adapted to the machine configuration and architecture. SPIRAL achieves this through an intelligent search in the Cartesian product of the space of algorithms and the space of coding variants. This paper describes the mathematical framework that SPIRAL uses to represent, generate, and manipulate transform algorithms.", "num_citations": "4\n", "authors": ["275"]}
{"title": "Discrete signal processing on meet/join lattices\n", "abstract": " A lattice is a partially ordered set supporting a meet (join) operation that returns the largest lower bound (smallest upper bound) of two elements. Just like graphs, lattices are a fundamental structure that occurs across domains including social data analysis, natural language processing, computational chemistry and biology, and database theory. In this paper we introduce discrete-lattice signal processing (DLSP), an SP framework for data, or signals, indexed by such lattices. We use the meet (or join) to define a shift operation and derive associated notions of filtering, Fourier basis and transform, and frequency response. We show that the spectrum of a lattice signal inherits the lattice structure of the signal domain and derive a sampling theorem. Finally, we show two prototypical applications: spectral analysis of formal concept lattices in social science and sampling and Wiener filtering on multiset lattices in\u00a0\u2026", "num_citations": "3\n", "authors": ["275"]}
{"title": "PRIMA: Precise and General Neural Network Certification via Multi-Neuron Convex Relaxations\n", "abstract": " Formal verification of neural networks is critical for their safe and secure adoption in real-world applications. However, designing a precise and scalable verifier which can handle different activation functions, realistic network architectures and relevant specifications remains an open and difficult challenge. In this paper, we take a major step in addressing this challenge and present a new verification framework, called PRIMA. PRIMA is both (i) general: it handles any non-linear activation function, and (ii) precise: it computes precise convex approximations involving multiple neurons via novel convex hull approximation algorithms that leverage concepts from computational geometry. The algorithms have polynomial complexity, yield fewer constraints, and minimize precision loss. We evaluate the effectiveness of PRIMA on a variety of challenging image classifiers from prior work. Our results show that PRIMA is significantly more precise than state-of-the-art, verifying robustness for up to 14%, 30%, and 34% more images than existing work on ReLU-, Sigmoid-, and Tanh-based networks, respectively. Further, PRIMA enables, for the first time, precise verification of a realistic neural network for autonomous driving within a few minutes.", "num_citations": "3\n", "authors": ["275"]}
{"title": "DSL-Based Hardware Generation with Scala: Example Fast Fourier Transforms and Sorting Networks\n", "abstract": " We present a hardware generator for computations with regular structure including the fast Fourier transform (FFT), sorting networks, and others. The input of the generator is a high-level description of the algorithm; the output is a token-based, synchronized design in the form of RTL-Verilog. Building on prior work, the generator uses several layers of domain-specific languages (DSLs) to represent and optimize at different levels of abstraction to produce a RAM- and area-efficient hardware implementation. Two of these layers and DSLs are novel. The first one allows the use and domain-specific optimization of state-of-the-art streaming permutations. The second DSL enables the automatic pipelining of a streaming hardware dataflow and the synchronization of its data-independent control signals. The generator including the DSLs are implemented in Scala, leveraging its type system, and uses concepts from\u00a0\u2026", "num_citations": "3\n", "authors": ["275"]}
{"title": "Memory-efficient fast Fourier transform on streaming data by fusing permutations\n", "abstract": " We propose a novel FFT datapath that reduces the memory requirement compared to state-of-the-art RAM-based implementations by up to a factor of two. The novelty is in a technique to fuse the datapaths for the required perfect shuffle and bit reversal and is applicable to an entire design space of FFT implementations with varying degrees of reuse and number of input ports. We implemented a tool to generate this FFT design space for a given input size and to benchmark against prior work. The results show a reduction of half the RAM banks and/or half the logic complexity used for the permutations. The technique for fusing permutations is more generally applicable beyond the FFT.", "num_citations": "3\n", "authors": ["275"]}
{"title": "Real-time DSP-based optical OFDM transmission\n", "abstract": " We present the design of a field programmable gate array (FPGA) based optical orthogonal frequency division multiplexing (OFDM) transmitter operating at 21.4 GS/s and an experimental assessment of its performance in a directly-detected 8.34 Gbit/s QPSK-OFDM configuration over 1600 km of uncompensated standard fiber. We also discuss the suitability of OFDM technology for low-cost, low-power optical interconnects.", "num_citations": "3\n", "authors": ["275"]}
{"title": "Small guide to making nice tables\n", "abstract": " Background\u25a0 Up to 2005, I had been writing technical publications for 8 years, creating roughly 35 fully reviewed papers, 2 theses, 20 proposals, and many other pages of technical writing", "num_citations": "3\n", "authors": ["275"]}
{"title": "Automatic Generation of Vectorized Fast Fourier Transform Libraries for the Larrabee and AVX Instruction Set Extension\n", "abstract": " The discrete Fourier transform (DFT) and its fast algorithms (fast Fourier transforms or FFTs) are among the most important computational building blocks in signal processing and scientific computing. Consequently, there is a number of high performance DFT libraries available including Intel\u2019s Integrated Performance Primitives (IPP), FFTW [6], and libraries generated by Spiral [9, 10]. When optimizing a DFT library, all the latest performance-enhancing processor features have to be used.Since the introduction of Intel\u2019s SSE and AltiVec/VMX on PowerPCs, DFT libraries have to be tuned for single instruction multiple data (SIMD) vector instructions. These instructions pack multiple smaller data words (for instance, four 32-bit floating-point numbers) into wide registers (in our example 128-bit wide). While these instructions provide the potential for tremendous speed-up, using them is challenging: vector instructions impose many restrictions and must be carefully selected to provide actual speed-up. Unavoidable overhead due to data alignment and reorganization often diminishes the performance gains and sometimes make vector code uncompetitive.", "num_citations": "3\n", "authors": ["275"]}
{"title": "System demonstration of Spiral: Generator for high-performance linear transform libraries\n", "abstract": " We demonstrate Spiral, a domain-specific library generation system. Spiral generates high performance source code for linear transforms (such as the discrete Fourier transform and many others) directly from a problem specification. The key idea underlying Spiral is to perform automatic reasoning and optimizations at a high abstraction level using the mathematical, declarative domain-specific languages SPL and \u03a3-SPL and a rigorous rewriting framework. Optimization includes various forms of parallelization. Even though Spiral provides complete automation, its generated libraries often run faster than any existing hand-written code.", "num_citations": "3\n", "authors": ["275"]}
{"title": "Alternatives to the discrete Fourier transform\n", "abstract": " It is well-known that the discrete Fourier transform (DFT) of a finite length discrete-time signal samples the discrete-time Fourier transform (DTFT) of the same signal at equidistant points on the unit circle. Hence, as the signal length goes to infinity, the DFT approaches the DTFT. Associated with the DFT are circular convolution and a periodic signal extension. In this paper we identify a large class of alternatives to the DFT using the theory of polynomial algebras. Each of these transforms approaches the DTFT just as the DFT does, but has its own signal extension and own notion of convolution. Further, these transforms have Vandermonde structure, which enables their fast computation. We provide a few experimental examples that confirm our theoretical results.", "num_citations": "3\n", "authors": ["275"]}
{"title": "Algebraic signal processing theory: An overview\n", "abstract": " We give an overview of the algebraic signal processing theory, a recently proposed generalization of linear signal processing (SP). Algebraic SP (ASP) is built axiomatically on top of the concept of a signal model, which is a triple (A, M, Phi), where A is a chosen algebra of filters, M an associated A-module of signals, and Phi generalizes the idea of a z-transform. ASP encompasses standard time SP (continuous and discrete, infinite and finite duration), but goes beyond it, for example, by defining meaningful notions of space SP in one and higher dimensions, separable and non-separable. ASP identifies many known transforms as Fourier transforms for a suitably chosen signal model and provides the means to derive and explain existing and novel transform algorithms. As one example, the discrete cosine transform is in ASP the Fourier transform for the finite space model and possesses general radix Cooley-Tukey\u00a0\u2026", "num_citations": "3\n", "authors": ["275"]}
{"title": "Automatically tuned fFTs for blueGene/L\u2019s double FPU\n", "abstract": " IBM is currently developing the new line of BlueGene/L supercomputers. The top-of-the-line installation is planned to be a 65,536 processors system featuring a peak performance of 360 Tflop/s. This system is supposed to lead the Top 500 list when being installed in 2005 at the Lawrence Livermore National Laboratory. This paper presents one of the first numerical kernels run on a prototype BlueGene/L machine. We tuned our formal vectorization approach as well as the Vienna MAP vectorizer to support BlueGene/L\u2019s custom two-way short vector SIMD \u201cdouble\u201d floating-point unit and connected the resulting methods to the automatic performance tuning systems Spiral and Fftw. Our approach produces automatically tuned high-performance FFT kernels for BlueGene/L that are up to 45% faster than the best scalar spiral generated code and up to 75% faster than Fftw when run on a single BlueGene/L\u00a0\u2026", "num_citations": "3\n", "authors": ["275"]}
{"title": "Automatically generated high-performance code for discrete wavelet transforms\n", "abstract": " A growing number of performance-critical DSP applications use the discrete wavelet transform (DWT), thus prompting the need for highly efficient DWT software implementations. Unfortunately, the rapid evolution of computing platforms and compiler technology makes carefully hand-tuned code obsolete almost as fast as it is written. In this paper, we describe our work on the automatic generation of DWT implementations that are tuned to a given platform. Our approach captures the various DWT algorithms in a concise mathematical framework that enables the integration of DWTs into the SPIRAL code generation system. Experiments show the quality of our automatically generated code and provide interesting insights; for example, the fastest code differs between platforms and is usually based on a non-obvious combination of DWT algorithms.", "num_citations": "3\n", "authors": ["275"]}
{"title": "Precise Multi-Neuron Abstractions for Neural Network Certification\n", "abstract": " Formal verification of neural networks is critical for their safe adoption in real-world applications. However, designing a verifier which can handle realistic networks in a precise manner remains an open and difficult challenge. In this paper, we take a major step in addressing this challenge and present a new framework, called PRIMA, that computes precise convex approximations of arbitrary non-linear activations. PRIMA is based on novel approximation algorithms that compute the convex hull of polytopes, leveraging concepts from computational geometry. The algorithms have polynomial complexity, yield fewer constraints, and minimize precision loss. We evaluate the effectiveness of PRIMA on challenging neural networks with ReLU, Sigmoid, and Tanh activations. Our results show that PRIMA is significantly more precise than the state-of-the-art, verifying robustness for up to 16%, 30%, and 34% more images\u00a0\u2026", "num_citations": "2\n", "authors": ["275"]}
{"title": "Learning set functions that are sparse in non-orthogonal Fourier bases\n", "abstract": " Many applications of machine learning on discrete domains, such as learning preference functions in recommender systems or auctions, can be reduced to estimating a set function that is sparse in the Fourier domain. In this work, we present a new family of algorithms for learning Fourier-sparse set functions. They require at most nk\u2212 k log2 k+ k queries (set function evaluations), under mild conditions on the Fourier coefficients, where n is the size of the ground set and k the number of non-zero Fourier coefficients. In contrast to other work that focused on the orthogonal Walsh-Hadamard transform (WHT), our novel algorithms operate with recently introduced nonorthogonal Fourier transforms that offer different notions of Fourier-sparsity. These naturally arise when modeling, eg, sets of items forming substitutes and complements. We demonstrate effectiveness on several real-world applications.", "num_citations": "2\n", "authors": ["275"]}
{"title": "A stage-polymorphic IR for compiling MATLAB-style dynamic tensor expressions\n", "abstract": " We propose a novel approach for compiling MATLAB and similar languages that are characterized by tensors with dynamic shapes and types. We stage an evaluator for a subset of MATLAB using the Lightweight Modular Staging (LMS) framework to produce a compiler that generates C code. But the first Futamura projection alone does not lead to efficient code: we need to refine the rigid stage distinction based on type and shape inference to remove costly runtime checks.", "num_citations": "2\n", "authors": ["275"]}
{"title": "Characterizing and enumerating Walsh-Hadamard transform algorithms\n", "abstract": " We propose a way of characterizing the algorithms computing a Walsh-Hadamard transform that consist of a sequence of arrays of butterflies () interleaved by linear permutations. Linear permutations are those that map linearly the binary representation of its element indices. We also propose a method to enumerate these algorithms.", "num_citations": "2\n", "authors": ["275"]}
{"title": "Automatic locality-friendly interface extension of numerical functions\n", "abstract": " Raising the level of abstraction is a key concern of software engineering, and libraries (either used directly or as a target of a program generation system) are a successful technique to raise programmer productivity and to improve software quality. Unfortunately successful libraries may contain functions that may not be general enough. For example, many numeric performance libraries contain functions that work on one-or higher-dimensional arrays. A problem arises if a program wants to invoke such a function on a non-contiguous subarray (eg, in C the column of a matrix or a subarray of an image). If the library developer did not foresee this scenario, the client program must include explicit copy steps before and after the library function call, incurring a possibly high performance penalty. A better solution would be an enhanced library function that allows for the desired access pattern. Exposing the access pattern\u00a0\u2026", "num_citations": "2\n", "authors": ["275"]}
{"title": "Automatic refactoring: Locality friendly interface enhancements for numerical functions\n", "abstract": " Recent improvements in processor architectures such as multiple cores and larger single-instruction multiple-data (SIMD) vector units increased the discrepancy between processing speed and memory bandwidth. Today, the memory bandwidth has become the biggest bottleneck in high performance domains. Numerical functions are often target to heavy optimizations to get as much performance as possible. These functions presume a specific data layout and have a fixed domain and range. Adjusting unsuitable data according to these requirements can take up a significant amount of the runtime due to heavy memory operations. By integrating layout, domain and range adjustments into numerical functions, memory bandwidth is saved as the adjustments happen inplace during execution of the function.Four transformations are provided by the developed tool to refactor the most common adjustments into numerical functions. Restrictions on the to transformed function ensure the correctness of the transformations. These transformations enable the function to directly work on previously incompatible data which makes the manual adjustments superfluous and saves memory bandwidth by not needing to adjust the data manually before calling the function. The runtime of the transformed function is highly dependent on the used function and transformation type, ranging from 50% slower to up to 5 times faster compared to applying the adjustments manually before or after the function.", "num_citations": "2\n", "authors": ["275"]}
{"title": "System and method for designing architecture for specified permutation and datapath circuits for permutation\n", "abstract": " Computer-implemented systems and methods that provide an efficient technique for performing a large class of permutations on data vectors of length 2 n, n> 1, implemented with streaming width 2 k (where 1\u2266 k\u2266 n\u2212 1). The technique applies to any permutation Q on 2 n datawords that can be specified as a linear transform, ie, as an n\u00d7 n bit matrix (a matrix containing only 1s and 0s) P on the bit level. The relationship between Q and P is as follows: If Q maps (dataword) i to (dataword) j, then the bit representation of j is the bit-matrix-vector product of P with the bit representation of i. Given such a permutation specified by the matrix P and given the streaming width (k), an architectural framework (or datapath) is calculated to implement the permutation.", "num_citations": "2\n", "authors": ["275"]}
{"title": "Automatic Generation of FFT Libraries for GPUs\n", "abstract": " Automatic Generation of FFT Libraries for GPUs Page 1 Automatic Generation of FFT Libraries for GPUs GPUs and Programmability GPU Architecture Model Results on the GTX 480 Forward Problem: Match Algorithm to Architecture Philosophy Itera,on of this process to search for the fastest Architecture \u25aa 15 Multiprocessors \u25aa 32 cores per multiprocessor \u25aa 32 K registers per multiprocessor \u25aa 48 KB of shared memory \u25aa 16 KB of L1 cache \u25aa 768 KB of L2 cache \u25aa 1.5 GB of GPU Memory Restrictions \u25aa Banked Shared Memory \u27a2 32 banks Within one warp resolve bank conflicts Every thread in the warp Reads/Writes at different bank 32 threads in a warp to 32 banks \u25aa Register pressure Max registers per MP = 32K/# of threads per MP \u25aa Uncommon Architectural Model \u27a2 Size of registers > Size of caches \u25aa Global Memory \u27a2 Only block transfers, using caches \u27a2 Double buffering Algorithm & Program Generation Future Work This : '\u2026", "num_citations": "2\n", "authors": ["275"]}
{"title": "High performance linear transform program generation for the Cell BE\n", "abstract": " The Cell BE is among a new generation of multicore processors including the Intel Larrabee and the Tilera TILE64 that provide an impressive peak fixed or floating point performance for scientific, signal processing, visualization, and other engineering applications. As shown in Fig. 1, the Cell uses simple in-order cores designed specifically for numerical computing, and requires explicit memory management to achieve maximal performance, which make programming and optimizing a challenge. In this paper, we extend Spiral [7], a program generation system, to generate highly optimized linear transform programs for the Cell BE. In doing so, as presented in [2], we extend Spiral\u2019s architectural paradigms to include support for distributed memory architectures like the Cell that allow hiding memory costs using multibuffering techniques.We focus on fixed-size code for the 1D complex discrete Fourier transform (DFT), but also generate code for variants including transforms that work on real input, 2D input, and for other transforms including the discrete Cosine and Sine transforms. We generate code for various usage scenarios, including latency optimized and throughput optimized code, and our system can handle various complex data formats and data distribution formats. The performance of Spiral generated code for the Cell is comparable to, and in many cases better than existing implementations, where available. Spiral. Spiral automates the generation of platform adapted high-performance libraries with a focus on the domain of linear transforms. Spiral provides a range of functionality difficult to match with hand written libraries, with generated\u00a0\u2026", "num_citations": "2\n", "authors": ["275"]}
{"title": "Can we teach computers to write fast libraries?\n", "abstract": " \u25a0 ConclusionMarkus P\u00fcschel, Jos\u00e9 MF Moura, Jeremy Johnson, David Padua, Manuela Veloso, Bryan Singer, Jianxin Xiong, Franz Franchetti, Aca Gacic, Yevgen Voronenko, Kang Chen, Robert W.", "num_citations": "2\n", "authors": ["275"]}
{"title": "Adaptive mapping of linear DSP algorithms to fixed-point arithmetic\n", "abstract": " Embedded DSP digital signal processing applications are typically implemented using fixed point arithmetic--in hardware to reduce area requirements and increase throughput, but also in software since most embedded processors do not provide floating point arithmetic. Consequently, the developer is confronted with the difficult task of deciding on the fixed point format, ie, the number of integer and fractional bits to avoid overflow and ensure sufficient accuracy. For software implementations, the entire bitwidth is fixed, typically at 32, which means that increasing the representable range number of integer bits reduces the available accuracy number of fractional bits and vice-versa. In this paper we present a compiler that translates a floating point C implementation of a linear DSP kernel, such as a discrete Fourier or wavelet transform, into a high accuracy fixed point C implementation. The inputs to the compiler are a floating point arithmetic C program and the range of the input vector elements. First, the compiler statically analyzes the program in a single pass using a recently developed tool that uses affine arithmetic modeling. Then, in the global mode, the compiler determines the global fixed point format with the least number of integer bits and thus the highest accuracy that guarantees to avoid overflow and outputs the corresponding code. More interesting is the local mode, in which the compiler determines the best format independently for each variable, thus further pushing the possible accuracy. The compiler is currently limited to straightline code an extension to loop code is in development.Descriptors:", "num_citations": "2\n", "authors": ["275"]}
{"title": "High-Performance Code Generation for FIR Filters and the Discrete Wavelet Transform Using SPIRAL\n", "abstract": " High-Performance Code Generation for FIR Filters and the Discrete Wavelet Transform Using SPIRAL Page 1 Carnegie Mellon High-Performance Code Generation for FIR Filters and the Discrete Wavelet Transform Using SPIRAL Aca Gacic Markus P\u00fcschel Jos\u00e9 MF Moura SPIRAL project http://www.spiral.net Electrical and Computer Engineering Department Carnegie Mellon University Page 2 Carnegie Mellon Motivation \u270dChoose Fast Algorithm \u270d Arithmetic cost \u2013 only a rough estimate of performance \u270d Many algorithms with similar cost \u2013 which one? \u270dDesign Efficient Code \u270d Architecture conscious \u2013 machine dependent \u270d Obsolete when platform is changed/upgraded \u270dBest implementation Best implementation: Algorithm + Machine + Compiler \u270d Requires experts in algorithms and computer architecture \u270d Frequent re-implementation Better way: automatic performance tuning \u270dFIR filters - image enhancement, , , \u2026", "num_citations": "2\n", "authors": ["275"]}
{"title": "Wiener Filter on Meet/Join Lattices\n", "abstract": " Recent work introduced a framework for signal processing (SP) on meet/join lattices. Such a lattice is partially ordered and supports a meet (or join) operation that returns the greatest lower bound and the smallest upper bound of two elements, respectively. Lattices appear in various domains and can be used, for example, to express rankings in social choice theory or multisets in combinatorial auctions. Discrete lattice SP (DLSP) uses the meet operation as shift and derives associated notions of convolution and Fourier transform for signals indexed by lattices. In this paper we extend DLSP with Wiener filtering for denoising and demonstrate it on two prototypical applications.", "num_citations": "1\n", "authors": ["275"]}
{"title": "An Interval Compiler for Sound Floating-Point Computations\n", "abstract": " Floating-point arithmetic is widely used by software developers but is unsound, i.e., there is no guarantee on the accuracy obtained, which can be imperative in safety-critical applications. We present IGen, a source-to-source compiler that translates a given C function using floating-point into an equivalent sound C function that uses interval arithmetic. IGen supports Intel SIMD intrinsics in the input function using a specially designed code generator and can produce SIMD-optimized output. To mitigate a possible loss of accuracy due to the increase of interval sizes, IGen can compile to double-double precision, again SIMD-optimized. Finally, IGen implements an accuracy optimization for the common reduction pattern. We benchmark our compiler on high-performance code in the domain of linear algebra and signal processing. The results show that the generated code delivers sound double precision results at high\u00a0\u2026", "num_citations": "1\n", "authors": ["275"]}
{"title": "Digraph signal processing with generalized boundary conditions\n", "abstract": " Signal processing on directed graphs (digraphs) is problematic, since the graph shift, and thus associated filters, are in general not diagonalizable. Furthermore, the Fourier transform in this case is now obtained from the Jordan decomposition, which may not be computable at all for larger graphs. We propose a novel and general solution for this problem based on matrix perturbation theory: We design an algorithm that adds a small number of edges to a given digraph to destroy nontrivial Jordan blocks. The obtained digraph is then diagonalizable and yields, as we show, an approximate eigenbasis and Fourier transform for the original digraph. We explain why and how this construction can be viewed as generalized form of boundary conditions, a common practice in signal processing. Our experiments with random and real world graphs show that we can scale to graphs with a few thousands nodes, and obtain\u00a0\u2026", "num_citations": "1\n", "authors": ["275"]}
{"title": "On linear learning with manycore processors\n", "abstract": " A new generation of manycore processors is on the rise that offers dozens and more cores on a chip and, in a sense, fuses host processor and accelerator. In this paper we target the efficient training of generalized linear models on these machines. We propose a novel approach for achieving parallelism which we call Heterogeneous Tasks on Homogeneous Cores (HTHC). It divides the problem into multiple fundamentally different tasks, which themselves are parallelized. For evaluation, we design a detailed, architecture-cognizant implementation of our scheme on a recent 72-core Knights Landing processor that is adaptive to the cache, memory, and core structure. Our library efficiently supports dense and sparse datasets as well as 4-bit quantized data for further possible gains in performance. We show benchmarks for Lasso and SVM with different data sets against straightforward parallel implementations and\u00a0\u2026", "num_citations": "1\n", "authors": ["275"]}
{"title": "In search of the optimal Walsh-Hadamard transform for streamed parallel processing\n", "abstract": " The Walsh-Hadamard transform (WHT) is computed using a network of butterflies, similar to the fast Fourier transform. The network is not unique but can be modified in exponentially many ways by properly changing the permutations between butterfly stages. Our first contribution is the exact char-acterization of all possible WHT networks. Then we aim to find the optimal networks for streaming implementations. In such an implementation the input is fed in chunks over several cycles and the hardware cost is thus reduced in proportion. To find the optimal network we smartly search through all possibilities for small sizes and discover novel networks that are thus proven optimal. The results can be used to extrapolate the optimal hardware cost for all sizes but the associated algorithms still remain elusive.", "num_citations": "1\n", "authors": ["275"]}
{"title": "Optimal streamed linear permutations\n", "abstract": " We give an overview on optimal circuits to implement linear permutations on FPGAs using only RAM banks and switches. Linear means that the permutation maps linearly the bit representation of the indices, as it is the case with most permutations arising in digital signal processing algorithms including those in fast Fourier transforms, Viterbi decoders, and sorting networks. Additionally, we assume that the data to be permuted is streamed, i.e., input in chunks over several cycles. The circuits are obtained from a suitable factorization of the bit matrix representing the permutation and achieve the minimal number of switches possible.", "num_citations": "1\n", "authors": ["275"]}
{"title": "Building program generators for high-performance: Spiral on Scala\n", "abstract": " The development of high performance libraries on modern hardware is extremely di cult and often requires reimplementation or retuning with every new processor generation. Program generators that produce such libraries automatically from a high level description are an appealing solution but only few exist to date. The di culty is in both the design of the generator but also its actual implementation, which often results in an ad-hoc collection of standalone programs and scripts that are hard to extend, maintain, or reuse. In this paper we ask whether there is a programming language environment suitable for building such generators. We argue in two steps that Scala with lightweight modular staging (LMS) is such an environment. First, we extract from existing generators the requirements that a suitable environment should fulfill. The list includes elegant support for internal DSLs, DSL rewriting, performance transformations like unrolling with scalar replacement, selective precomputation, and specialization, and support for multiple data representations. Inside Scala with LMS, we then implement a subset of the Spiral program generator, chosen to cover these requirements. For each requirement, we then identify the supporting language features. Finally, we benchmark against FFTW to show the quality of the generated code.", "num_citations": "1\n", "authors": ["275"]}
{"title": "Distributed compressed sensing algorithms: Completing the puzzle\n", "abstract": " Reconstructing compressed sensing signals involves solving an optimization problem. An example is Basis Pursuit (BP) [1], which is applicable only in noise-free scenarios. In noisy scenarios, either the Basis Pursuit Denoising (BPDN) [1] or the Noise-Aware BP (NABP) [2] can be used. Consider a distributed scenario where the dictionary matrix and the vector of observations are spread over the nodes of a network. We solve the following open problem: design distributed algorithms that solve BPDN with a column partition, i.e., when each node knows only some columns of the dictionary matrix, and that solve NABP with a row partition, i.e., when each node knows only some rows of the dictionary matrix and the corresponding observations. Our approach manipulates these problems so that a recent general-purpose algorithm for distributed optimization can be applied.", "num_citations": "1\n", "authors": ["275"]}
{"title": "A unified algorithmic approach to distributed optimization\n", "abstract": " We address general optimization problems formulated on networks. Each node in the network has a function, and the goal is to find a vector x \u2208 \u211d n  that minimizes the sum of all the functions. We assume that each function depends on a set of components of x, not necessarily on all of them. This creates additional structure in the problem, which can be captured by the classification scheme we develop. This scheme not only to enables us to design an algorithm that solves very general distributed optimization problems, but also allows us to categorize prior algorithms and applications. Our general-purpose algorithm shows a performance superior to prior algorithms, including algorithms that are application-specific.", "num_citations": "1\n", "authors": ["275"]}
{"title": "Compiling math to fast code\n", "abstract": " Extracting optimal performance from modern computing platforms has become increasingly difficult over the last few years. The effect is particularly noticeable in computations that are of mathematical nature such as those needed in multimedia processing, communication, control, graphics, and scientific simulations: a straightforward implementation, eg, in C, is often one or two orders of magnitude slower than the best possible code. The reason is in optimizations that are known to be difficult and often impossible for compilers: parallelization, vectorization, and locality optimizations.", "num_citations": "1\n", "authors": ["275"]}
{"title": "Program Composition and Optimization: An Introduction\n", "abstract": " Software composition connects separately defined software artifacts. Such connection may be in program structure (such as inheritance), data flow (such as message passing) and/or control flow (such as function calls or loop control).", "num_citations": "1\n", "authors": ["275"]}
{"title": "FPGA-based optical transmitters for electronic predistortion and advanced signal format generation\n", "abstract": " We describe an optical transmitter, based on field programmable gate arrays, carrying out real-time DSP at 21.4 GSa/s. We implemented electronic predistortion at 10.7 Gb/s, and 8.35 Gb/s optical orthogonal frequency division multiplexed (OFDM) signal generation.", "num_citations": "1\n", "authors": ["275"]}
{"title": "A new class of seeded real lapped tight frame transforms\n", "abstract": " We propose a design procedure for the real, equal-norm, lapped tight frame transforms (LTFTs). These transforms have been recently proposed as both a redundant counterpart to lapped orthogonal transforms and an infinite-dimensional counterpart to harmonic tight frames. In addition, LTFTs can be efficiently implemented with filter banks. The procedure consists of two steps. First, we construct new lapped orthogonal transforms designed from submatrices of the DFT matrix. Then we specify the seeding procedure that yields real equal-norm LTFTs. Among them we identify the subclass of maximally robust to erasures LTFTs.", "num_citations": "1\n", "authors": ["275"]}
{"title": "Haar filter banks for 1-D space signals\n", "abstract": " We derive the Haar filter bank for 1-D space signals, based on our recently introduced framework for 1-D space signal processing, termed this way since it is built on a symmetric space shift operation in contrast to the directed time shift operation. The framework includes the proper notions of signal and filter spaces, \"z-transform,\" convolution, and Fourier transform, each of which is different from their time equivalents. In this paper, we extend this framework by deriving the proper notions of a Haar filter bank for space signal processing, and show that it has a similar yet different form compared to the time case. Our derivation also sheds light on the nature of filter banks and makes a case for viewing them as projections on subspaces rather than as based on filters.", "num_citations": "1\n", "authors": ["275"]}
{"title": "Spiral: Generating Signal Processing Kernels for New Commodity Architectures\n", "abstract": " Programmers in charge of developing high performance libraries for new commodity architectures are confronted with the difficult task of optimizing for deep memory hierarchies, extracting the fine-grain parallelism for vector instruction sets, and producing multithreaded code for tightly coupled processors. This scenario strengthens the case for recent efforts on automatic performance tuning, program generation, and adaptive library frameworks that can offer high performance with greatly reduced development time. Examples include ATLAS [7] for linear algebra, FFTW [5] for the discrete Fourier transform, and Spiral [6] for general linear transforms.", "num_citations": "1\n", "authors": ["275"]}
{"title": "Automatic Generation of SIMD DSP Code\n", "abstract": " Short vector SIMD instructions on recent microprocessors, such as SSE on Pentium III and 4, speed up code but are a major challenge to software developers. This report introduces a compiler that automatically generates C code enhanced with short vector instructions for digital signal processing (DSP) transforms, such as the fast Fourier transform (FFT).", "num_citations": "1\n", "authors": ["275"]}
{"title": "Constant Multiplication Methods\n", "abstract": " An important primitive in the hardware implementations of linear DSP transforms like the discrete Fourier transform or discrete cosine transforms is a circuit that multiplies an input value by one out of a set of several different constants. Up to now standard multiplication units were mainly used for that purpose.", "num_citations": "1\n", "authors": ["275"]}