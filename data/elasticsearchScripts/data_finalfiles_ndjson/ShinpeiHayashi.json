{"title": "ATTED-II: a database of co-expressed genes and cis elements for identifying co-regulated gene groups in Arabidopsis\n", "abstract": " Publicly available database of co-expressed gene sets would be a valuable tool for a wide variety of experimental designs, including targeting of genes for functional identification or for regulatory investigation. Here, we report the construction of an Arabidopsis thaliana trans-factor and cis-element prediction database (ATTED-II) that provides co-regulated gene relationships based on co-expressed genes deduced from microarray data and the predicted cis elements. ATTED-II () includes the following features: (i) lists and networks of co-expressed genes calculated from 58 publicly available experimental series, which are composed of 1388 GeneChip data in A.thaliana; (ii) prediction of cis-regulatory elements in the 200 bp region upstream of the transcription start site to predict co-regulated genes amongst the co-expressed genes; and (iii) visual representation of expression patterns for individual genes. ATTED\u00a0\u2026", "num_citations": "426\n", "authors": ["794"]}
{"title": "ATTED-II provides coexpressed gene networks for Arabidopsis\n", "abstract": " ATTED-II (http://atted.jp) is a database of gene coexpression in Arabidopsis that can be used to design a wide variety of experiments, including the prioritization of genes for functional identification or for studies of regulatory relationships. Here, we report updates of ATTED-II that focus especially on functionalities for constructing gene networks with regard to the following points: (i) introducing a new measure of gene coexpression to retrieve functionally related genes more accurately, (ii) implementing clickable maps for all gene networks for step-by-step navigation, (iii) applying Google Maps API to create a single map for a large network, (iv) including information about protein\u2013protein interactions, (v) identifying conserved patterns of coexpression and (vi) showing and connecting KEGG pathway information to identify functional modules. With these enhanced functions for gene network representation, ATTED-II\u00a0\u2026", "num_citations": "395\n", "authors": ["794"]}
{"title": "COXPRESdb: a database of coexpressed gene networks in mammals\n", "abstract": " A database of coexpressed gene sets can provide valuable information for a wide variety of experimental designs, such as targeting of genes for functional identification, gene regulation and/or protein\u2013protein interactions. Coexpressed gene databases derived from publicly available GeneChip data are widely used in Arabidopsis research, but platforms that examine coexpression for higher mammals are rather limited. Therefore, we have constructed a new database, COXPRESdb ( co e xpres sed gene d ata b ase) ( http://coxpresdb.hgc.jp ), for coexpressed gene lists and networks in human and mouse. Coexpression data could be calculated for 19 777 and 21 036 genes in human and mouse, respectively, by using the GeneChip data in NCBI GEO. COXPRESdb enables analysis of the four types of coexpression networks: (i) highly coexpressed genes for every gene, (ii) genes with the same GO annotation, (iii\u00a0\u2026", "num_citations": "164\n", "authors": ["794"]}
{"title": "Refactoring edit history of source code\n", "abstract": " This paper proposes a concept for refactoring an edit history of source code and a technique for its automation. The aim of our history refactoring is to improve the clarity and usefulness of the history without changing its overall effect. We have defined primitive history refactorings including their preconditions and procedures, and large refactorings composed of these primitives. Moreover, we have implemented a supporting tool that automates the application of history refactorings in the middle of a source code editing process. Our tool enables developers to pursue some useful applications using history refactorings such as task level commit from an entangled edit history and selective undo of past edit operations.", "num_citations": "36\n", "authors": ["794"]}
{"title": "Supporting refactoring activities using histories of program modification\n", "abstract": " Refactoring is one of the promising techniques for improving program design by means of program transformation with preserving behavior, and is widely applied in practice. However, it is difficult for engineers to identify how and where to refactor programs, because proper knowledge and skills of a high order are required of them. In this paper, we propose the technique to instruct how and where to refactor a program by using a sequence of its modifications. We consider that the histories of program modifications reflect developers' intentions, and focusing on them allows us to provide suitable refactoring guides. Our technique can be automated by storing the correspondence of modification patterns to suitable refactoring operations. By implementing an automated supporting tool, we show its feasibility. The tool is implemented as a plug-in for Eclipse IDE. It selects refactoring operations by matching between a\u00a0\u2026", "num_citations": "33\n", "authors": ["794"]}
{"title": "Design pattern detection by using meta patterns\n", "abstract": " One of the approaches to improve program understanding is to extract what kinds of design pattern are used in existing object-oriented software. This paper proposes a technique for efficiently and accurately detecting occurrences of design patterns included in source codes. We use both static and dynamic analyses to achieve the detection with high accuracy. Moreover, to reduce computation and maintenance costs, detection conditions are hierarchically specified based on Pree's meta patterns as common structures of design patterns. The usage of Prolog to represent the detection conditions enables us to easily add and modify them. Finally, we have implemented an automated tool as an Eclipse plug-in and conducted experiments with Java programs. The experimental results show the effectiveness of our approach.", "num_citations": "29\n", "authors": ["794"]}
{"title": "Recording finer-grained software evolution with IDE: An annotation-based approach\n", "abstract": " This paper proposes a formalized technique for generating finer-grained source code deltas according to a developer's editing intentions. Using the technique, the developer classifies edit operations of source code by annotating the time series of the edit history with the switching information of their editing intentions. Based on the classification, the history is sorted and converted automatically to appropriate source code deltas to be committed separately to a version repository. This paper also presents algorithms for automating the generation process and a prototyping tool to implement them.", "num_citations": "28\n", "authors": ["794"]}
{"title": "A tool for attributed goal-oriented requirements analysis\n", "abstract": " This paper presents an integrated supporting tool for Attributed Goal-Oriented Requirements Analysis (AGORA), which is an extended version of goal-oriented analysis. Our tool assists seamlessly requirements analysts and stakeholders in their activities throughout AGORA steps including constructing goal graphs with group work, prioritizing goals, and version control of goal graphs.", "num_citations": "27\n", "authors": ["794"]}
{"title": "Context-based code smells prioritization for prefactoring\n", "abstract": " To find opportunities for applying prefactoring, several techniques for detecting bad smells in source code have been proposed. Existing smell detectors are often unsuitable for developers who have a specific context because these detectors do not consider their current context and output the results that are mixed with both smells that are and are not related to such context. Consequently, the developers must spend a considerable amount of time identifying relevant smells. As described in this paper, we propose a technique to prioritize bad code smells using developers' context. The explicit data of the context are obtained using a list of issues extracted from an issue tracking system. We applied impact analysis to the list of issues and used the results to specify which smells are associated with the context. Consequently, our approach can provide developers with a list of prioritized bad code smells related to their\u00a0\u2026", "num_citations": "26\n", "authors": ["794"]}
{"title": "Slicing and replaying code change history\n", "abstract": " Change-aware development environments have recently become feasible and reasonable. These environments can automatically record fine-grained code changes on a program and allow programmers to replay the recorded changes in chronological order. However, they do not always need to replay all the code changes to investigate how a particular entity of the program has been changed. Therefore, they often skip several code changes of no interest. This skipping action is an obstacle that makes many programmers hesitate in using existing replaying tools. This paper proposes a slicing mechanism that can extract only code changes necessary to construct a particular class member of a Java program from the whole history of past code changes. In this mechanism, fine-grained code changes are represented by edit operations recorded on source code of a program. The paper also presents a running tool\u00a0\u2026", "num_citations": "26\n", "authors": ["794"]}
{"title": "Sentence-to-code traceability recovery with domain ontologies\n", "abstract": " We propose an ontology-based technique for recovering trace ability links between a natural language sentence specifying features of a software product and the source code of the product. Some software products have been released without detailed documentation. To automatically detect code fragments associated with sentences describing a feature, the relations between source code structures and problem domains are important. We model the knowledge of the problem domains as domain ontologies having concepts of the domains and their relations. Using semantic relations on the ontologies in addition to method invocation relations and the similarity between an identifier on the code and words in the sentences, we locate the code fragments corresponding to the given sentences. Additionally, our prioritization mechanism which orders the located results of code fragments based on the ontologies\u00a0\u2026", "num_citations": "24\n", "authors": ["794"]}
{"title": "Enhancing goal-oriented security requirements analysis using common criteria-based knowledge\n", "abstract": " Goal-oriented requirements analysis (GORA) is one of the promising techniques to elicit software requirements, and it is natural to consider its application to security requirements analysis. In this paper, we proposed a method for goal-oriented security requirements analysis using security knowledge which is derived from several security targets (STs) compliant to Common Criteria (CC, ISO/IEC 15408). We call such knowledge security ontology for an application domain (SOAD). Three aspects of security such as confidentiality, integrity and availability are included in the scope of our method because the CC addresses these three aspects. We extract security-related concepts such as assets, threats, countermeasures and their relationships from STs, and utilize these concepts and relationships for security goal elicitation and refinement in GORA. The usage of certificated STs as knowledge source allows us to reuse\u00a0\u2026", "num_citations": "21\n", "authors": ["794"]}
{"title": "Context\u2010based approach to prioritize code smells for prefactoring\n", "abstract": " Existing techniques for detecting code smells (indicators of source code problems) do not consider the current context, which renders them unsuitable for developers who have a specific context, such as modules within their focus. Consequently, the developers must spend time identifying relevant smells. We propose a technique to prioritize code smells using the developers' context. Explicit data of the context are obtained using a list of issues extracted from an issue tracking system. We applied impact analysis to the list of issues and used the results to specify the context\u2010relevant smells. Results show that our approach can provide developers with a list of prioritized code smells related to their current context. We conducted several empirical studies to investigate the characteristics of our technique and factors that might affect the ranking quality. Additionally, we conducted a controlled experiment with professional\u00a0\u2026", "num_citations": "20\n", "authors": ["794"]}
{"title": "Recovering traceability links between a simple natural language sentence and source code using domain ontologies\n", "abstract": " This paper proposes an ontology-based technique for recovering traceability links between a natural language sentence specifying features of a software product and the source code of the product. Some software products have been released without detailed documentation. To automatically detect code fragments associated with the functional descriptions written in the form of simple sentences, the relationships between source code structures and problem domains are important. In our approach, we model the knowledge of the problem domains as domain ontologies. By using semantic relationships of the ontologies in addition to method invocation relationships and the similarity between an identifier on the code and words in the sentences, we can detect code fragments corresponding to the sentences. A case study within a domain of painting software shows that we obtained results of higher quality than\u00a0\u2026", "num_citations": "18\n", "authors": ["794"]}
{"title": "Constructing feature models using goal-oriented analysis\n", "abstract": " This paper proposes a systematic approach to derive feature models required in a software product line development. In our approach, we use goal graphs constructed by goal-oriented requirements analysis. We merge multiple goal graphs into a graph, and then regarding the leaves of the merged graph as the candidates of features, identify their commonality and variability based on the achievability of product goals. Through a case study of a portable music player domain, we obtained a feature model with high quality.", "num_citations": "17\n", "authors": ["794"]}
{"title": "Historef: A tool for edit history refactoring\n", "abstract": " This paper presents Historef, a tool for automating edit history refactoring on Eclipse IDE for Java programs. The aim of our history refactorings is to improve the understandability and/or usability of the history without changing its whole effect. Historef enables us to apply history refactorings to the recorded edit history in the middle of the source code editing process by a developer. By using our integrated tool, developers can commit the refactored edits into underlying SCM repository after applying edit history refactorings so that they are easy to manage their changes based on the performed edits.", "num_citations": "16\n", "authors": ["794"]}
{"title": "Understanding source code differences by separating refactoring effects\n", "abstract": " Comparing and understanding differences between old and new versions of source code are necessary in various software development situations. However, if refactoring is applied between those versions, then the source code differences are more complicated, and understanding them becomes more difficult. Although many techniques for extracting refactoring effects from the differences have been studied, it is necessary to exclude the extracted refactorings' effects and reconstruct the differences for meaningful and understandable ones with no refactoring effect. As described in this paper, we propose a novel technique to address this difficulty. Using our technique, we extract the refactoring effects and then apply them to the old version of source code to produce the differences without refactoring effects. We also implemented a support tool that helps separate refactorings automatically. An evaluation of open\u00a0\u2026", "num_citations": "16\n", "authors": ["794"]}
{"title": "Modeling security threat patterns to derive negative scenarios\n", "abstract": " The elicitation of security requirements is a crucial issue to develop secure business processes and information systems of higher quality. Although we have several methods to elicit security requirements, most of them do not provide sufficient supports to identify security threats. Since threats do not occur so frequently, like exceptional events, it is much more difficult to determine the potentials of threats exhaustively rather than identifying normal behavior of a business process. To reduce this difficulty, accumulated knowledge of threats obtained from practical setting is necessary. In this paper, we present the technique to model knowledge of threats as patterns by deriving the negative scenarios that realize threats and to utilize them during business process modeling. The knowledge is extracted from Security Target documents, based on the international Common Criteria Standard, and the patterns are described\u00a0\u2026", "num_citations": "15\n", "authors": ["794"]}
{"title": "Generating assertion code from OCL: A transformational approach based on similarities of implementation languages\n", "abstract": " The Object Constraint Language (OCL) carries a platform independent characteristic allowing it to be decoupled from implementation details, and therefore it is widely applied in model transformations used by model-driven development techniques. However, OCL can be found tremendously useful in the implementation phase aiding assertion code generation and allowing system verification. Yet, taking full advantage of OCL without destroying its platform independence is a difficult task. This paper proposes an approach for generating assertion code from OCL constraints by using a model transformation technique to abstract language specific details away from OCL high-level concepts, showing wide applicability of model transformation techniques. We take advantage of structural similarities of implementation languages to describe a rewriting framework, which is used to easily and flexibly reformulate\u00a0\u2026", "num_citations": "15\n", "authors": ["794"]}
{"title": "How do developers select and prioritize code smells? A preliminary study\n", "abstract": " Code smells are considered to be indicators of design flaws or problems in source code. Various tools and techniques have been proposed for detecting code smells. The number of code smells detected by these tools is generally large, so approaches have also been developed for prioritizing and filtering code smells. However, the lack of empirical data regarding how developers select and prioritize code smells hinders improvements to these approaches. In this study, we investigated professional developers to determine the factors they use for selecting and prioritizing code smells. We found that Task relevance and Smell severity were most commonly considered during code smell selection, while Module importance and Task relevance were employed most often for code smell prioritization. These results may facilitate further research into code smell detection, prioritization, and filtration to better focus on the\u00a0\u2026", "num_citations": "14\n", "authors": ["794"]}
{"title": "Incremental feature location and identification in source code\n", "abstract": " Feature location (FL) in source code is an important task for program understanding. Existing dynamic FL techniques depend on sufficient scenarios for exercising the features to be located. However, it is difficult to prepare such scenarios because it involves a correct understanding of the features. This paper proposes an incremental technique for refining the identification of features integrated with the existing FL technique using formal concept analysis. In our technique, we classify the differences of static and dynamic dependencies of method invocations based on their relevance to the identified features. According to the classification, the technique suggests method invocations to exercise unexplored part of the features. An application example indicates the effectiveness of the approach.", "num_citations": "13\n", "authors": ["794"]}
{"title": "Supporting design model refactoring for improving class responsibility assignment\n", "abstract": " Although a responsibility driven approach in object oriented analysis and design methodologies is promising, the assignment of the identified responsibilities to classes (simply, class responsibility assignment: CRA) is a crucial issue to achieve design of higher quality. The GRASP by Larman is a guideline for CRA and is being put into practice. However, since it is described in an informal way using a natural language, its successful usage greatly relies on designers\u2019 skills. This paper proposes a technique to represent GRASP formally and to automate appropriate CRA based on them. Our computerized tool automatically detects inappropriate CRA and suggests alternatives of appropriate CRAs to designers so that they can improve a CRA based on the suggested alternatives. We made preliminary experiments to show the usefulness of our tool.", "num_citations": "13\n", "authors": ["794"]}
{"title": "A preliminary study on using code smells to improve bug localization\n", "abstract": " Bug localization is a technique that has been proposed to support the process of identifying the locations of bugs specified in a bug report. A traditional approach such as information retrieval (IR)-based bug localization calculates the similarity between the bug description and the source code and suggests locations that are likely to contain the bug. However, while many approaches have been proposed to improve the accuracy, the likelihood of each module having a bug is often overlooked or they are treated equally, whereas this may not be the case. For example, modules having code smells have been found to be more prone to changes and faults. Therefore, in this paper, we explore a first step toward leveraging code smells to improve bug localization. By combining the code smell severity with the textual similarity from IR-based bug localization, we can identify the modules that are not only similar to the bug\u00a0\u2026", "num_citations": "12\n", "authors": ["794"]}
{"title": "Search-based refactoring detection from source code revisions\n", "abstract": " This paper proposes a technique for detecting the occurrences of refactoring from source code revisions. In a real software development process, a refactoring operation may sometimes be performed together with other modifications at the same revision. This means that detecting refactorings from the differences between two versions stored in a software version archive is not usually an easy process. In order to detect these impure refactorings, we model the detection within a graph search. Our technique considers a version of a program as a state and a refactoring as a transition between two states. It then searches for the path that approaches from the initial to the final state. To improve the efficiency of the search, we use the source code differences between the current and the final state for choosing the candidates of refactoring to be applied next and estimating the heuristic distance to the final state. Through\u00a0\u2026", "num_citations": "12\n", "authors": ["794"]}
{"title": "Hierarchical categorization of edit operations for separately committing large refactoring results\n", "abstract": " In software configuration management using a version control system, developers have to follow the commit policy of the project. However, preparing changes according to the policy are sometimes cumbersome and time-consuming, in particular when applying large refactoring consisting of multiple primitive refactoring instances. In this paper, we propose a technique for re-organizing changes by recording editing operations of source code. Editing operations including refactoring operations are hierarchically managed based on their types provided by an integrated development environment. Using the obtained hierarchy, developers can easily configure the granularity of changes and obtain the resulting changes based on the configured granularity. We confirmed the feasibility of the technique by applying it to the recorded changes in a large refactoring process.", "num_citations": "11\n", "authors": ["794"]}
{"title": "A survey on methods of recording fine-grained operations on integrated development environments and their applications\n", "abstract": " This paper presents a survey on techniques to record and utilize developers\u2019 operations on integrated development environments (IDEs). Especially, we let techniques treating fine-grained code changes be targets of this survey for reference in software evolution research. We created a three-tiered model to represent the relationships among IDEs, recording techniques, and application techniques. This paper also presents common features of the techniques and their details.", "num_citations": "11\n", "authors": ["794"]}
{"title": "A visualization tool recording historical data of program comprehension tasks\n", "abstract": " Software visualization has become a major technique in program comprehension. Although many tools visualize the structure, behavior, and evolution of a program, they have no concern with how a tool user has understood it. Moreover, they miss the stuff the user has left through trial-and-error processes of his/her program comprehension task. This paper presents a source code visualization tool called CodeForest. It uses a forest metaphor to depict source code of Java programs. Each tree represents a class within the program and the collection of trees constitutes a three-dimensional forest. CodeForest helps a user to try a large number of combinations of mapping of software metrics on visual parameters. Moreover, it provides two new types of support: leaving notes that memorize the current understanding and insight along with visualized objects, and automatically recording a user's actions under\u00a0\u2026", "num_citations": "11\n", "authors": ["794"]}
{"title": "iFL: An interactive environment for understanding feature implementations\n", "abstract": " We propose iFL, an interactive environment that is useful for effectively understanding feature implementation by application of feature location (FL). With iFL, the inputs for FL are improved incrementally by interactions between users and the FL system. By understanding a code fragment obtained using FL, users can find more appropriate queries from the identifiers in the fragment. Furthermore, the relevance feedback obtained by partially judging whether or not a fragment is relevant improves the evaluation score of FL. Users can then obtain more accurate results. Case studies with iFL show that our interactive approach is feasible and that it can reduce the understanding cost more effectively than the non-interactive approach.", "num_citations": "11\n", "authors": ["794"]}
{"title": "Slicing fine-grained code change history\n", "abstract": " Change-aware development environments can automatically record fine-grained code changes on a program and allow programmers to replay the recorded changes in chronological order. However, since they do not always need to replay all the code changes to investigate how a particular entity of the program has been changed, they often eliminate several code changes of no interest by manually skipping them in replaying. This skipping action is an obstacle that makes many programmers hesitate when they use existing replaying tools. This paper proposes a slicing mechanism that automatically removes manually skipped code changes from the whole history of past code changes and extracts only those necessary to build a particular class member of a Java program. In this mechanism, fine-grained code changes are represented by edit operations recorded on the source code of a program and\u00a0\u2026", "num_citations": "10\n", "authors": ["794"]}
{"title": "Extracting and visualizing implementation structure of features\n", "abstract": " Feature location is an activity to identify correspondence between features in a system and program elements in source code. After a feature is located, developers need to understand implementation structure around the location from static and/or behavioral points of view. This paper proposes a semi-automatic technique both for locating features and exposing their implementation structures in source code, using a combination of dynamic analysis and two data analysis techniques, sequential pattern mining and formal concept analysis. We have implemented our technique in a supporting tool and applied it to an example of a web application. The result shows that the proposed technique is not only feasible but helpful to understand implementation of features just after they are located.", "num_citations": "10\n", "authors": ["794"]}
{"title": "Impact analysis on an attributed goal graph\n", "abstract": " Requirements changes frequently occur at any time of a software development process, and their management is a crucial issue to develop software of high quality. Meanwhile, goal-oriented analysis techniques are being put into practice to elicit requirements. In this situation, the change management of goal graphs and its support are necessary. This paper presents a technique related to the change management of goal graphs, realizing impact analysis on a goal graph when its modifications occur. Our impact analysis detects conflicts that arise when a new goal is added, and investigates the achievability of the other goals when an existing goal is deleted. We have implemented a supporting tool for automating the analysis. Two case studies suggested the efficiency of the proposed approach.", "num_citations": "10\n", "authors": ["794"]}
{"title": "Detecting occurrences of refactoring with heuristic search\n", "abstract": " This paper proposes a novel technique to detect the occurrences of refactoring from a version archive, in order to reduce the effort spent in understanding what modifications have been applied. In a real software development process, a refactoring operation may sometimes be performed together with other modifications at the same revision. This means that understanding the differences between two versions stored in the archive is not usually an easily process. In order to detect these impure refactorings, we model the detection within a graph search. Our technique considers a version of a program as a state and a refactoring as a transition. It then searches for the path that approaches from the initial to the final state. To improve the efficiency of the search, we use the source code differences between the current and the final state for choosing the candidates of refactoring to be applied next and estimating the\u00a0\u2026", "num_citations": "9\n", "authors": ["794"]}
{"title": "An investigative study on how developers filter and prioritize code smells\n", "abstract": " Code smells are indicators of design flaws or problems in the source code. Various tools and techniques have been proposed for detecting code smells. These tools generally detect a large number of code smells, so approaches have also been developed for prioritizing and filtering code smells. However, lack of empirical data detailing how developers filter and prioritize code smells hinders improvements to these approaches. In this study, we investigated ten professional developers to determine the factors they use for filtering and prioritizing code smells in an open source project under the condition that they complete a list of five tasks. In total, we obtained 69 responses for code smell filtration and 50 responses for code smell prioritization from the ten professional developers. We found that Task relevance and Smell severity were most commonly considered during code smell filtration, while Module importance\u00a0\u2026", "num_citations": "8\n", "authors": ["794"]}
{"title": "Visualizing a tangled change for supporting its decomposition and commit construction\n", "abstract": " Developers often save multiple kinds of source code edits into a commit in a version control system, producing a tangled change, which is difficult to understand and revert. However, its separation using an existing sequence-based change representation is tough. We propose a new visualization technique to show the details of a tangled change and align its component edits in a tree structure for expressing multiple groups of changes. Our technique is combined with utilizing refactoring detection and change relevance calculation techniques for constructing the structural tree. Our combination allows us to divide the change into several associations. We have implemented a tool and conducted a controlled experiment with industrial developers to confirm its usefulness and efficiency. Results show that by using our tool with tree visualization, the subjects could understand and decompose tangled changes easier\u00a0\u2026", "num_citations": "7\n", "authors": ["794"]}
{"title": "Early requirements analysis for a socio-technical system based on goal dependencies\n", "abstract": " A socio-technical system (STS) consists of many different actors such as people, organizations, software applications and infrastructures. We call actors except both people and organizations machines. Machines should be carefully introduced into the STS because the machines are beneficial to some people or organization but harmful to others. We thus propose a goal-oriented requirements modelling language called GDMA based on i* so that machines with the following characteristics can be systematically specified. First, machines make the goals of each people be achieved more and better than ever. Second, machines make people achieve goals fewer and easier than ever. We also propose analysis techniques of GDMA to judge whether or not the introduction of machines are appropriate or not. Several machines are introduced into an as-is model of GDMA locally with the help of model transformation\u00a0\u2026", "num_citations": "7\n", "authors": ["794"]}
{"title": "Terminology matching of requirements specification documents and regulations for compliance checking\n", "abstract": " To check the consistency between requirements specification documents and regulations by using a model checking technique, requirements analysts generate inputs to the model checker, i.e., state transition machines from the documents and logical formulas from the regulatory statements to be verified as properties. During these generation processes, to make the logical formulas semantically correspond to the state transition machine, analysts should take terminology matching where they look for the words in the requirements document having the same meaning as the words in the regulatory statements and unify the semantically same words. In this paper, by using case grammar approach, we propose an automated technique to reason the meaning of words in requirements specification documents by means of co-occurrence constraints on words in case frames, and to generate from regulatory statements\u00a0\u2026", "num_citations": "7\n", "authors": ["794"]}
{"title": "REdiffs: Refactoring-aware difference viewer for java\n", "abstract": " Comparing and understanding differences between old and new versions of source code are necessary in various software development situations. However, if changes are tangled with refactorings in a single revision, then the resulting source code differences are more complicated. We propose an interactive difference viewer which enables us to separate refactoring effects from source code differences for improving the understandability of the differences.", "num_citations": "7\n", "authors": ["794"]}
{"title": "Feature location for multi-layer system based on formal concept analysis\n", "abstract": " Locating features in software composed of multiple layers is a challenging problem because we have to find program elements distributed over layers, which still work together to constitute a feature. This paper proposes a semi-automatic technique to extract correspondence between features and program elements among layers. By merging execution traces of each layer to feed into formal concept analysis, collaborative program elements are grouped into formal concepts and tied with a set of execution scenarios. We applied our technique to an example of web application composed of three layers. The result indicates that our technique is not only feasible but promising to promote program understanding in a more realistic context.", "num_citations": "7\n", "authors": ["794"]}
{"title": "ChangeMacroRecorder: Recording fine-grained textual changes of source code\n", "abstract": " Recording code changes comes to be well recognized as an effective means for understanding the evolution of existing programs and making their future changes efficient. Although fine-grained textual changes of source code are worth leveraging in various situations, there is no satisfactory tool that records such changes. This paper proposes a yet another tool, called ChangeMacroRecorder, which automatically records all textual changes of source code while a programmer writes and modifies it on the Eclipse's Java editor. Its capability has been improved with respect to both the accuracy of its recording and the convenience for its use. Tool developers can easily and cheaply create their new applications that utilize recorded changes by embedding our proposed recording tool into them.", "num_citations": "6\n", "authors": ["794"]}
{"title": "Revisiting context-based code smells prioritization: On supporting referred context\n", "abstract": " Because numerous code smells are revealed by code smell detectors, many attempts have been undertaken to mitigate related problems by prioritizing and filtering code smells. We earlier proposed a technique to prioritize code smells by leveraging the context of the developers, ie, the modules that the developers plan to implement. Our empirical studies revealed that the results of code smells prioritized using our technique are useful to support developers' implementation on the modules they intend to change. Nonetheless, in software change processes, developers often navigate through many modules and refer to them before making actual changes. Such modules are important when considering the developers' context. Therefore, it is essential to ascertain whether our technique can also support developers on modules to which they are going to refer to make changes. We conducted an empirical study of an\u00a0\u2026", "num_citations": "5\n", "authors": ["794"]}
{"title": "Facilitating Business Improvement by Information Systems using Model Transformation and Metrics.\n", "abstract": " We propose a method to explore how to improve business by introducing information systems. We use a meta-modeling technique to specify the business itself and its metrics. The metrics are defined based on the structural information of the business model, so that they can help us to identify whether the business is good or not with respect to several different aspects. We also use a model transformation technique to specify an idea of the business improvement. The metrics help us to predict whether the improvement idea makes the business better or not. We use strategic dependency (SD) models in i* to specify the business, and attributed graph grammar (AGG) for the model transformation.", "num_citations": "5\n", "authors": ["794"]}
{"title": "Visualizing stakeholder concerns with anchored map\n", "abstract": " Software development is a cooperative work by stakeholders. It is important for project managers and analysts to understand stakeholder concerns and to identify potential problems such as imbalance of stakeholders or lack of stakeholders. This paper presents a tool which visualizes the strength of stakeholders\u2019 interest of concern on two dimensional screens. The proposed tool generates an anchored map from an attributed goal graph by AGORA, which is an extended version of goal-oriented analysis methods. It has information on stakeholders\u2019 interest to concerns and its degree as the attributes of goals. Results from the case study are that (1) some concerns are not connected to any stakeholders and (2) a type of stakeholders is interested in different concerns each other. The results suggest that lack of stakeholders for the unconnected concerns and need that a type of stakeholders had better to unify\u00a0\u2026", "num_citations": "5\n", "authors": ["794"]}
{"title": "An Integrated Support for Attributed Goal-Oriented Requirements Analysis Method and its Implementation\n", "abstract": " This paper presents an integrated supporting tool for Attributed Goal-Oriented Requirements Analysis (AGORA), which is an extended version of goal-oriented analysis. Our tool assists seamlessly requirements analysts and stakeholders in their activities throughout AGORA steps including constructing goal graphs with group work, utilizing domain ontologies for goal graph construction, detecting various types of conflicts among goals, prioritizing goals, analyzing impacts when modifying a goal graph, and version control of goal graphs.", "num_citations": "5\n", "authors": ["794"]}
{"title": "Changebeadsthreader: An interactive environment for tailoring automatically untangled changes\n", "abstract": " To improve the usability of a revision history, change untangling, which reconstructs the history to ensure that changes in each commit belong to one intentional task, is important. Although there are several untangling approaches based on the clustering of fine-grained editing operations of source code, they often produce unsuitable result for a developer, and manual tailoring of the result is necessary. In this paper, we propose ChangeBeadsThreader (CBT), an interactive environment for splitting and merging change clusters to support the manual tailoring of untangled changes. CBT provides two features: 1) a two-dimensional space where fine-grained change history is visualized to help users find the clusters to be merged and 2) an augmented diff view that enables users to confirm the consistency of the changes in a specific cluster for finding those to be split. These features allow users to easily tailor\u00a0\u2026", "num_citations": "4\n", "authors": ["794"]}
{"title": "Toward proactive refactoring: An exploratory study on decaying modules\n", "abstract": " Source code quality is often measured using code smell, which is an indicator of design flaw or problem in the source code. Code smells can be detected using tools such as static analyzer that detects code smells based on source code metrics. Further, developers perform refactoring activities based on the result of such detection tools to improve source code quality. However, such approach can be considered as reactive refactoring, i.e., developers react to code smells after they occur. This means that developers first suffer the effects of low quality source code (e.g., low readability and understandability) before they start solving code smells. In this study, we focus on proactive refactoring, i.e., refactoring source code before it becomes smelly. This approach would allow developers to maintain source code quality without having to suffer the impact of code smells. To support the proactive refactoring process, we\u00a0\u2026", "num_citations": "4\n", "authors": ["794"]}
{"title": "Establishing regulatory compliance in goal-oriented requirements analysis\n", "abstract": " To develop with lower costs information systems that do not violate regulations, it is necessary to elicit requirements compliant to the regulations. Automated supports allow us to avoid missing requirements necessary to comply with regulations and to exclude functional requirements against the regulations. In this paper, we propose a technique to detect goals relevant to regulations in a goal model and to add goals so that the resulting goal model can be compliant to the regulations. In this approach, we obtain the goals relevant to regulations by semantically matching goal descriptions to regulatory statements. We use Case Grammar approach to deal with the meaning of goal descriptions and regulatory statements, i.e., both are transformed to case frames as their semantic representations, and we check if their case frames can be unified. After detecting the relevant goals, based on the modality of matched\u00a0\u2026", "num_citations": "4\n", "authors": ["794"]}
{"title": "A tool supporting postponable refactoring\n", "abstract": " Failures of precondition checking when attempting to apply automated refactorings often discourage programmers from attempting to use these refactorings in the future. To alleviate this situation, the postponement of the failed refactoring instead its cancellation is beneficial. This poster paper proposes a new concept of postponable refactoring and a prototype tool that implements postponable Extract Method as an Eclipse plug-in. We believe that this refactoring tool inspires a new field of reconciliation automated and manual refactoring.", "num_citations": "4\n", "authors": ["794"]}
{"title": "Multi-dimensional goal refinement in goal-oriented requirements engineering\n", "abstract": " In this paper, we propose a multi-dimensional extension of goal graphs in goal-oriented requirements engineering in order to support the understanding the relations between goals, i.e., goal refinements. Goals specify multiple concerns such as functions, strategies, and non-functions, and they are refined into sub goals from mixed views of these concerns. This intermixture of concerns in goals makes it difficult for a requirements analyst to understand and maintain goal graphs. In our approach, a goal graph is put in a multi-dimensional space, a concern corresponds to a coordinate axis in this space, and goals are refined into sub goals referring to the coordinates. Thus, the meaning of a goal refinement is explicitly provided by means of the coordinates used for the refinement. By tracing and focusing on the coordinates of goals, requirements analysts can understand goal refinements and modify unsuitable ones. We\u00a0\u2026", "num_citations": "4\n", "authors": ["794"]}
{"title": "On the effectiveness of accuracy of automated feature location technique\n", "abstract": " Automated feature location techniques have been proposed to extract program elements that are likely to be relevant to a given feature. A more accurate result is expected to enable developers to perform more accurate feature location. However, several experiments assessing traceability recovery have shown that analysts cannot utilize an accurate traceability matrix for their tasks. Because feature location deals with a certain type of traceability links, it is an important question whether the same phenomena are visible in feature location or not. To answer that question, we have conducted a controlled experiment. We have asked 20 subjects to locate features using lists of methods of which the accuracy is controlled artificially. The result differs from the traceability recovery experiments. Subjects given an accurate list would be able to locate a feature more accurately. However, subjects could not locate the complete\u00a0\u2026", "num_citations": "4\n", "authors": ["794"]}
{"title": "Model transformation patterns for introducing suitable information systems\n", "abstract": " When information systems are introduced in a social setting such as a business, the systems will give bad and good impacts on stakeholders in the setting. Requirements analysts have to predict such impacts in advance because stakeholders cannot decide whether the systems are really suitable for them without such prediction. In this paper, we propose a method based on model transformation patterns for introducing suitable information systems. We use metrics of a model to predict whether a system introduction is suitable for a social setting. Through a case study, we show our method can avoid an introduction of a system, which was actually bad for some stakeholders. In the case study, we use a strategic dependency model in i* to specify the model of systems and stakeholders, and attributed graph grammar for model transformation. We focus on the responsibility and the satisfaction of stakeholders as the\u00a0\u2026", "num_citations": "4\n", "authors": ["794"]}
{"title": "Detecting Bad Smells in Use Case Descriptions\n", "abstract": " Use case modeling is very popular to represent the functionality of the system to be developed, and it consists of two parts: use case diagram and use case description. Use case descriptions are written in structured natural language (NL), and the usage of NL can lead to poor descriptions such as ambiguous, inconsistent and/or incomplete descriptions, etc. Poor descriptions lead to missing requirements and eliciting incorrect requirements as well as less comprehensiveness of produced use case models. This paper proposes a technique to automate detecting bad smells of use case descriptions, symptoms of poor descriptions. At first, to clarify bad smells, we analyzed existing use case models to discover poor use case descriptions concretely and developed the list of bad smells, i.e., a catalogue of bad smells. Some of the bad smells can be refined into measures using the Goal-Question-Metric paradigm to\u00a0\u2026", "num_citations": "3\n", "authors": ["794"]}
{"title": "Detecting bad smells of refinement in goal-oriented requirements analysis\n", "abstract": " Goal refinement is a crucial step in goal-oriented requirements analysis to create a goal model of high quality. Poor goal refinement leads to missing requirements and eliciting incorrect requirements as well as less comprehensiveness of produced goal models. This paper proposes a technique to automate detecting bad smells of goal refinement, symptoms of poor goal refinement. Based on the classification of poor refinement, we defined four types of bad smells of goal refinement and developed two types of measures to detect them: measures on the graph structure of a goal model and semantic similarity of goal descriptions. We have implemented a support tool to detect bad smells and assessed its usefulness by an experiment.", "num_citations": "3\n", "authors": ["794"]}
{"title": "Guiding identification of missing scenarios for dynamic feature location\n", "abstract": " Feature location (FL) is an important activity for finding correspondence between software features and modules in source code. Although dynamic FL techniques are effective, the quality of their results depends on analysts to prepare sufficient scenarios for exercising the features. In this paper, we propose a technique for guiding identification of missing scenarios using the prior FL result. After applying FL, unexplored call dependencies are extracted by comparing the results of static and dynamic analyses, and analysts are advised to investigate them for finding missing scenarios. We propose several metrics that measure the potential impact of unexplored dependencies to help analysts sort out them. Through a preliminary evaluation using an example web application, we showed our technique was effective for recommending the clues to find missing scenarios.", "num_citations": "3\n", "authors": ["794"]}
{"title": "Annotating goals with concerns in goal-oriented requirements engineering\n", "abstract": " In goal-oriented requirements analysis, goals specify multiple concerns such as functions, strategies, and non-functions, and they are refined into sub goals from mixed views of these concerns. This intermixture of concerns in goals makes it difficult for a requirements analyst to understand and maintain goal refinements. Separating concerns and specifying them explicitly is one of the useful approaches to improve the understandability of goal refinements, i.e., the relations between goals and their sub goals. In this paper, we propose a technique to annotate goals with the concerns they have in order to support the understanding of goal refinement. In our approach, goals are refined into sub goals referring to the annotated concerns, and these concerns annotated to a goal and its sub goals provide the meaning of its goal refinement. By tracing and focusing on the annotated concerns, requirements analysts\u00a0\u2026", "num_citations": "3\n", "authors": ["794"]}
{"title": "Class responsibility assignment as fuzzy constraint satisfaction\n", "abstract": " We formulate the class responsibility assignment (CRA) problem as the fuzzy constraint satisfaction problem (FCSP) for automating CRA of high quality. Responsibilities are contracts or obligations of objects that they should assume, by aligning them to classes appropriately, quality designs realize. Typical conditions of a desirable design are having a low coupling between highly cohesive classes. However, because of a trade-off among such conditions, solutions that satisfy the conditions moderately are desired, and computer assistance is needed. Additionally, if we have an initial assignment, the improved one by our technique should keep the original assignment as much as possible because it involves with the intention of human designers. We represent such conditions as fuzzy constraints, and formulate CRA as FCSP. That enables us to apply common FCSP solvers to the problem and to derive solution\u00a0\u2026", "num_citations": "3\n", "authors": ["794"]}
{"title": "Toward structured location of features\n", "abstract": " This paper proposes structured location, a semiautomatic technique and its supporting tool both for locating features and exposing their structures in source code, using a combination of dynamic analysis, sequential pattern mining and formal concept analysis.", "num_citations": "3\n", "authors": ["794"]}
{"title": "An extensive study on smell-aware bug localization\n", "abstract": " Bug localization is an important aspect of software maintenance because it can locate modules that should be changed to fix a specific bug. Our previous study showed that the accuracy of the information retrieval\u00a0(IR)-based bug localization technique improved when used in combination with code smell information. Although this technique showed promise, the study showed limited usefulness because of the small number of: (1) projects in the dataset, (2) types of smell information, and (3) baseline bug localization techniques used for assessment. This paper presents an extension of our previous experiments on Bench4BL, the largest bug localization benchmark dataset available for bug localization. In addition, we generalized the smell-aware bug localization technique to allow different configurations of smell information, which were combined with various bug localization techniques. Our results confirmed that\u00a0\u2026", "num_citations": "2\n", "authors": ["794"]}
{"title": "Can Automated Impact Analysis Techniques Help Predict Decaying Modules?\n", "abstract": " A decaying module refers to a module whose quality is getting worse and is likely to become smelly in the future. The concept has been proposed to mitigate the problem that developers cannot track the progression of code smells and prevent them from occurring. To support developers in proactive refactoring process to prevent code smells, a prediction approach has been proposed to detect modules that are likely to become decaying modules in the next milestone. Our prior study has shown that modules that developers will modify as an estimation of developers' context can be used to improve the performance of the prediction model significantly. Nevertheless, it requires the developer who has perfect knowledge of locations of changes to manually specify such information to the system. To this end, in this study, we explore the use of automated impact analysis techniques to estimate the developers' context\u00a0\u2026", "num_citations": "2\n", "authors": ["794"]}
{"title": "The impact of systematic edits in history slicing\n", "abstract": " While extracting a subset of a commit history, specifying the necessary portion is a time-consuming task for developers. Several commit-based history slicing techniques have been proposed to identify dependencies between commits and to extract a related set of commits using a specific commit as a slicing criterion. However, the resulting subset of commits become large if commits for systematic edits whose changes do not depend on each other exist. We empirically investigated the impact of systematic edits on history slicing. In this study, commits in which systematic edits were detected are split between each file so that unnecessary dependencies between commits are eliminated. In several histories of open source systems, the size of history slices was reduced by 13.3-57.2% on average after splitting the commits for systematic edits.", "num_citations": "2\n", "authors": ["794"]}
{"title": "Detecting Architectural Violations Using Responsibility and Dependency Constraints of Components\n", "abstract": " Utilizing software architecture patterns is important for reducing maintenance costs. However, maintaining code according to the constraints defined by the architecture patterns is time-consuming work. As described herein, we propose a technique to detect code fragments that are incompliant to the architecture as fine-grained architectural violations. For this technique, the dependence graph among code fragments extracted from the source code and the inference rules according to the architecture are the inputs. A set of candidate components to which a code fragment can be affiliated is attached to each node of the graph and is updated step-by-step. The inference rules express the components' responsibilities and dependency constraints. They remove candidate components of each node that do not satisfy the constraints from the current estimated state of the surrounding code fragment. If the inferred role of a\u00a0\u2026", "num_citations": "2\n", "authors": ["794"]}
{"title": "Goal-oriented requirements analysis meets a creativity technique\n", "abstract": " Goal-oriented requirements analysis (GORA) has been growing in the area of requirement engineering. It is one of the approaches that elicits and analyzes stakeholders\u2019 requirements as goals to be achieved, and develops an AND-OR graph, called a goal graph, as a result of requirements elicitation. However, although it is important to involve stakeholders\u2019 ideas and viewpoints during requirements elicitation, GORA still has a problem that their processes lack the deeper participation of stakeholders. Regarding stakeholders\u2019 participation, creativity techniques have also become popular in requirements engineering. They aim to create novel and appropriate requirements by involving stakeholders. One of these techniques, the KJ-method is a method which organizes and associates novel ideas generated by Brainstorming. In this paper, we present an approach to support stakeholders\u2019 participation during\u00a0\u2026", "num_citations": "2\n", "authors": ["794"]}
{"title": "Inference-based Detection of Architectural Violations in MVC2.\n", "abstract": " Utilizing software architecture patterns is important for reducing maintenance costs. However, maintaining code according to the constraints defined by the architecture patterns is time-consuming work. As described herein, we propose a technique to detect code fragments that are incompliant to the architecture as finegrained architectural violations. For this technique, the dependence graph among code fragments extracted from the source code and the inference rules according to the architecture are the inputs. A set of candidate components to which a code fragment can be affiliated is attached to each node of the graph and is updated step-by-step. The inference rules express the components\u2019 responsibilities and dependency constraints. They remove candidate components of each node that do not satisfy the constraints from the current estimated state of the surrounding code fragment. If the current result does not include the current component, then it is detected as a violation. By defining inference rules for MVC2 architecture and applying the technique to web applications using Play Framework, we obtained accurate detection results.", "num_citations": "2\n", "authors": ["794"]}
{"title": "Modeling and Utilizing Security Knowledge for Eliciting Security Requirements\n", "abstract": " In order to develop secure information systems with less development cost, it is important to elicit the requirements to security functions (simply security requirements) as early in their development process as possible. To achieve it, accumulated knowledge of threats and their objectives obtained from practical experiences is useful, and the technique to support the elicitation of security requirements utilizing this knowledge should be developed. In this paper, we present the technique for security requirements elicitation using practical knowledge of threats, their objectives and security functions realizing the objectives, which is extracted from Security Target documents compliant to the standard Common Criteria. We show the usefulness of our approach with several case studies.", "num_citations": "2\n", "authors": ["794"]}
{"title": "Using hierarchical transformation to generate assertion code from OCL constraints\n", "abstract": " Object Constraint Language (OCL) is frequently applied in software development for stipulating formal constraints on software models. Its platform-independent characteristic allows for wide usage during the design phase. However, application in platform-specific processes, such as coding, is less obvious because it requires usage of bespoke tools for that platform. In this paper we propose an approach to generate assertion code for OCL constraints for multiple platform specific languages, using a unified framework based on structural similarities of programming languages. We have succeeded in automating the process of assertion code generation for four different languages using our tool. To show effectiveness of our approach in terms of development effort, an experiment was carried out and summarised.", "num_citations": "2\n", "authors": ["794"]}
{"title": "Recent researches for supporting software construction and maintenance with data mining\n", "abstract": " \u91cd\u8907\u7cfb\u5217\u306e\u767a\u751f\u30d1\u30bf\u30fc\u30f3\u306b\u95a2\u3059\u308b\u6642\u7cfb\u5217\u30de\u30a4\u30cb\u30f3\u30b0\u3068\u305d\u306e\u533b\u7642\u5fdc\u7528 (< \u7279\u96c6> \u7cfb\u5217\u30d1\u30bf\u30fc\u30f3\u30de\u30a4\u30cb\u30f3\u30b0\u306e\u6700\u8fd1\u306e\u52d5\u5411)", "num_citations": "2\n", "authors": ["794"]}
{"title": "\u5c5e\u6027\u3064\u304d\u30b4\u30fc\u30eb\u6307\u5411\u8981\u6c42\u5206\u6790\u6cd5\u306e\u652f\u63f4\u306e\u305f\u3081\u306e\u7d71\u5408\u30c4\u30fc\u30eb\n", "abstract": " \u8457\u8005\u3089\u304c\u958b\u767a\u3057\u305f\u5c5e\u6027\u3092\u4ed8\u52a0\u3057\u305f\u30b4\u30fc\u30eb\u30b0\u30e9\u30d5\u306b\u57fa\u3065\u304f\u8981\u6c42\u5206\u6790\u6cd5\u3092\u652f\u63f4\u3059\u308b\u30c4\u30fc\u30eb\u306b\u3064\u3044\u3066\u8ff0\u3079\u308b. \u3053\u306e\u30c4\u30fc\u30eb\u306f\u8981\u6c42\u7372\u5f97\u304b\u3089\u8981\u6c42\u7ba1\u7406\u307e\u3067\u306e\u30d7\u30ed\u30bb\u30b9\u3092\u7d99\u304e\u76ee\u306a\u304f\u652f\u63f4\u3059\u308b.", "num_citations": "2\n", "authors": ["794"]}
{"title": "An Improvement on Data Interoperability with Large-Scale Conceptual Model and Its Application in Industry.\n", "abstract": " In the world of the Internet of Things, heterogeneous systems and devices need to be connected. A key issue for systems and devices is data interoperability such as automatic data exchange and interpretation. A wellknown approach to solve the interoperability problem is building a conceptual model (CM). Regarding CM in industrial domains, there are often a large number of entities defined in one CM. How data interoperability with such a largescale CM can be supported is a critical issue when applying CM into industrial domains. In this paper, evolved from our previous work, a meta-model equipped with new concepts of \u201cPropertyRelationship\u201d and \u201cCategory\u201d is proposed, and a tool called FSCM supporting the automatic generation of property relationships and categories is developed. A case study in an industrial domain shows that the proposed approach effectively improves the data interoperability of large-scale CMs.", "num_citations": "1\n", "authors": ["794"]}
{"title": "Supporting Prefactoring Using Feature Location Results\n", "abstract": " (in English) In order to find the opportunities for applying refactoring, several techniques for detecting bad smells in source code have been proposed. However, existing smell detectors are not suitable for developers who are trying to implement a specific feature because the detectors detect too many smells from the whole source code. In this paper, we propose a technique to detect bad smells specific to the focused feature for supporting prefactoring to improve the extendibility of the program before implementing the feature. In order to estimate the effect of the feature introduction before implementing it, dummy code imitating the deterioration of the design quality is inserted to the modules obtained using the result of a feature location technique. Comparing the detected smells in source code before and after inserting dummy code, we can specify which smells are strongly related to the target feature. Several\u00a0\u2026", "num_citations": "1\n", "authors": ["794"]}
{"title": "Cutting a method call graph for supporting feature location\n", "abstract": " This paper proposes a technique for locating the implementation of features by combining techniques of a graph cut and a formal concept analysis based on methods and scenarios.", "num_citations": "1\n", "authors": ["794"]}
{"title": "\u30b4\u30fc\u30eb\u30b0\u30e9\u30d5\u306e\u54c1\u8cea\u5411\u4e0a\u652f\u63f4\u30c4\u30fc\u30eb\u3068\u305d\u306e\u8a55\u4fa1\n", "abstract": " \u6284\u9332 (\u548c) \u672c\u7a3f\u3067\u306f, \u5c5e\u6027\u3064\u304d\u30b4\u30fc\u30eb\u30b0\u30e9\u30d5\u306e\u54c1\u8cea\u5411\u4e0a\u3092\u652f\u63f4\u3059\u308b\u30c4\u30fc\u30eb\u3092\u63d0\u6848\u3057, \u3053\u306e\u30c4\u30fc\u30eb\u306e\u6709\u52b9\u6027\u3092\u793a\u3059\u5b9f\u9a13\u306b\u3064\u3044\u3066\u8ff0\u3079\u308b. \u30b4\u30fc\u30eb\u306b\u5bfe\u3059\u308b\u54c1\u8cea\u7279\u6027\u3092, IEEE Std 830 \u306b\u8a18\u3055\u308c\u305f\u8981\u6c42\u4ed5\u69d8\u66f8\u304c\u5099\u3048\u308b\u3079\u304d\u54c1\u8cea\u7279\u6027\u306b\u6e96\u3058\u3066, \u5b9a\u7fa9\u3057\u305f. \u652f\u63f4\u30c4\u30fc\u30eb\u3067\u306f, \u3053\u308c\u3089\u306e\u54c1\u8cea\u7279\u6027\u3092\u6e80\u305f\u3055\u306a\u3044\u30b4\u30fc\u30eb\u3092\u30e6\u30fc\u30b6\u306b\u63d0\u793a\u3059\u308b. \u691c\u8a3c\u5b9f\u9a13\u306b\u3088\u308a, \u30e6\u30fc\u30b6\u304c\u8003\u616e\u3059\u3079\u304d\u7bc4\u56f2\u306e\u3057\u307c\u308a\u8fbc\u307f\u304c\u77ed\u6642\u9593\u3067\u884c\u306a\u3048\u308b\u305f\u3081, \u52b9\u7387\u7684\u306b\u4f5c\u696d\u304c\u884c\u306a\u3048\u308b\u3053\u3068\u304c\u5206\u304b\u308a, \u30c4\u30fc\u30eb\u306e\u6709\u52b9\u6027\u3092\u793a\u3059\u3053\u3068\u304c\u3067\u304d\u305f.(\u82f1) In this article, a supporting tool to develop high-quality goal graphs is proposed and the result of an experiment is described. The tool highlights the goals which do not satisfy quality properties. The quality properties are defined based on IEEE Std 830. The result of an experiment shows that users can modify goal graphs rapidly because they can focus on parts that were not satisfy the quality properties.", "num_citations": "1\n", "authors": ["794"]}
{"title": "\u30e1\u30c8\u30ea\u30af\u30b9\u5024\u306e\u5909\u5316\u306e\u53ef\u8996\u5316\u306b\u3088\u308b\u30d7\u30ed\u30b0\u30e9\u30e0\u5909\u66f4\u306e\u652f\u63f4\n", "abstract": " \u8ad6\u6587\u6284\u9332\u672c\u7a3f\u3067\u306f, \u30bd\u30d5\u30c8\u30a6\u30a7\u30a2\u30e1\u30c8\u30ea\u30af\u30b9\u306e\u5024\u306e\u5909\u5316\u3092\u30b3\u30fc\u30c9\u30a8\u30c7\u30a3\u30bf\u4e0a\u306b\u53ef\u8996\u5316\u3059\u308b\u3053\u3068\u306b\u3088\u308a, \u958b\u767a\u8005\u306e\u30d7\u30ed\u30b0\u30e9\u30e0\u5909\u66f4\u3092\u652f\u63f4\u3059\u308b\u624b\u6cd5\u3092\u63d0\u6848\u3059\u308b. \u30d7\u30ed\u30b0\u30e9\u30e0\u306e\u4fdd\u5b88\u54c1\u8cea\u3092\u9ad8\u304f\u4fdd\u3064\u305f\u3081\u306b\u306f, \u30d7\u30ed\u30b0\u30e9\u30e0\u5909\u66f4\u6642\u306b\u305d\u308c\u3092\u4f4e\u4e0b\u3055\u305b\u306a\u3044\u3053\u3068\u304c\u671b\u307e\u3057\u3044. \u63d0\u6848\u624b\u6cd5\u3067\u306f, \u958b\u767a\u8005\u304c\u5bfe\u8c61\u30d7\u30ed\u30b0\u30e9\u30e0\u306b\u5bfe\u3057\u3066\u884c\u3063\u305f\u5909\u66f4\u3092, \u305d\u308c\u306b\u3088\u3063\u3066\u751f\u3058\u305f\u5bfe\u8c61\u30d7\u30ed\u30b0\u30e9\u30e0\u3067\u306e\u30e1\u30c8\u30ea\u30af\u30b9\u5024\u306e\u5909\u5316\u3067\u8a55\u4fa1\u3059\u308b. \u8a55\u4fa1\u5024\u3092\u30b3\u30fc\u30c9\u30a8\u30c7\u30a3\u30bf\u306a\u3069\u306e\u30bd\u30d5\u30c8\u30a6\u30a7\u30a2\u958b\u767a\u74b0\u5883\u4e0a\u306b\u53ef\u8996\u5316\u3059\u308b\u3053\u3068\u306b\u3088\u308a, \u958b\u767a\u8005\u306f\u4e0d\u9069\u5207\u306a\u5909\u66f4\u3092\u65e9\u671f\u306b\u8a8d\u8b58\u3057, \u6539\u5584\u3059\u308b\u3053\u3068\u304c\u3067\u304d\u308b. \u30e1\u30c8\u30ea\u30af\u30b9\u5024\u306e\u5909\u5316\u306e\u8a55\u4fa1\u306e\u969b\u306b\u306f, \u305d\u306e\u57fa\u6e96\u3092\u5bfe\u8c61\u30d7\u30ed\u30b0\u30e9\u30e0\u306e\u904e\u53bb\u306e\u5909\u66f4\u5c65\u6b74\u3092\u8003\u616e\u3057\u3066\u4e0e\u3048\u308b\u3053\u3068\u306b\u3088\u308a\u53ef\u8996\u5316\u3059\u3079\u304d\u5bfe\u8c61\u306e\u30d7\u30ed\u30b0\u30e9\u30e0\u7247\u3092\u5236\u9650\u3057, \u53ef\u8996\u5316\u304c\u958b\u767a\u8005\u306e\u30b3\u30fc\u30c7\u30a3\u30f3\u30b0\u4f5c\u696d\u306b\u4e0e\u3048\u308b\u8ca0\u306e\u5f71\u97ff\u3092\u6291\u5236\u3059\u308b.", "num_citations": "1\n", "authors": ["794"]}
{"title": "Extracting prehistories of software refactorings from version archives\n", "abstract": " This paper proposes an automated technique to extract prehistories of software refactorings from existing software version archives, which in turn a technique to discover knowledge for finding refactoring opportunities. We focus on two types of knowledge to extract: characteristic modification histories, and fluctuations of the values of complexity measures. First, we extract modified fragments of code by calculating the difference of the Abstract Syntax Trees in the programs picked up from an existing software repository. We also extract past cases of refactorings, and then we create traces of program elements by associating modified fragments with cases of refactorings for finding the structures that frequently occur. Extracted traces help us identify how and where to refactor programs, and it leads to improve the program design.", "num_citations": "1\n", "authors": ["794"]}
{"title": "A Technique for Supporting Refactoring Based on Program Modification\n", "abstract": " and is widely taken into practice. But it isn't easy that identifying where to apply which refactoring because it requires proper knowledges and experiences. In this paper, we propose the technique to suggesting refactoring using a sequence of program modifications. Our technique could suggest which refactoring is suitable by considering developer's intentions. It is done by efficiently and automatically. We illustrate the feasibility of our approach with the development of system which selects refactoring by matching between a sequence of modifications and modification patterns.", "num_citations": "1\n", "authors": ["794"]}