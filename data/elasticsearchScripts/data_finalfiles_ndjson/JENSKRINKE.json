{"title": "Identifying similar code with program dependence graphs\n", "abstract": " We present an approach to identifying similar code in programs based on finding similar subgraphs in attributed directed graphs. This approach is used on program dependence graphs and therefore considers not only the syntactic structure of programs but also the data flow within (as an abstraction of the semantics). As a result, there is no tradeoff between precision and recall; our approach is very good in both. An evaluation of our prototype implementation shows that the approach is feasible and gives very good results despite the non polynomial complexity of the problem.", "num_citations": "847\n", "authors": ["289"]}
{"title": "A study of consistent and inconsistent changes to code clones\n", "abstract": " Code cloning is regarded as a threat to software maintenance, because it is generally assumed that a change to a code clone usually has to be applied to the other clones of the clone group as well. However, there exists little empirical data that supports this assumption. This paper presents a study on the changes applied to code clones in open source software systems based on the changes between versions of the system. It is analyzed if changes to code clones are consistent to all code clones of a clone group or not. The results show that usually half of the changes to code clone groups are inconsistent changes. Moreover, the study observes that when there are inconsistent changes to a code clone group in a near version, it is rarely the case that there are additional changes in later versions such that the code clone group then has only consistent changes.", "num_citations": "255\n", "authors": ["289"]}
{"title": "Static slicing of threaded programs\n", "abstract": " Static program slicing is an established method for analyzing sequential programs, especially for program understanding, debugging and testing. Until now, there was no slicing method for threaded programs which handles interference correctly. We present such a method which also calculates more precise static slices. This paper extends the well known structures of the control flow graph and the program dependencc graph for threaded programs with interference. This new technique does not require serialization of threaded programs.", "num_citations": "219\n", "authors": ["289"]}
{"title": "Aspect mining using event traces\n", "abstract": " Aspect mining tries to identify crosscutting concerns in existing systems and thus supports the adaption to an aspect-oriented design. This work describes the first aspect mining approach that detects crosscutting concerns in legacy systems based on dynamic analysis. The analysis uses program traces that are generated in different program executions as underlying data pool. These traces are then investigated for recurring execution patterns based on different constraints, such as the requirement that the patterns have to exist in different calling contexts in the program trace. The implemented approach was evaluated in several case studies over systems with more than 80 kLoC. The tool was able to identify automatically both existing and seeded crosscutting concerns.", "num_citations": "206\n", "authors": ["289"]}
{"title": "Is cloned code more stable than non-cloned code?\n", "abstract": " This paper presents a study on the stability of cloned code. The results from an analysis of 200 weeks of evolution of five software system show that the stability as measured by changes to the system is dominated by the deletion of code clones. It can also be observed that additions to a systems are more often additions to non-cloned code than additions to cloned code. If the dominating factor of deletions is eliminated, it can generally be concluded that cloned code is more stable than non-cloned code.", "num_citations": "194\n", "authors": ["289"]}
{"title": "Efficient path conditions in dependence graphs for software safety analysis\n", "abstract": " A new method for software safety analysis is presented which uses program slicing and constraint solving to construct and analyze path conditions, conditions defined on a program's input variables which must hold for information flow between two points in a program. Path conditions are constructed from subgraphs of a program's dependence graph, specifically, slices and chops. The article describes how constraint solvers can be used to determine if a path condition is satisfiable and, if so, to construct a witness for a safety violation, such as an information flow from a program point at one security level to another program point at a different security level. Such a witness can prove useful in legal matters.The article reviews previous research on path conditions in program dependence graphs; presents new extensions of path conditions for arrays, pointers, abstract data types, and multithreaded programs; presents\u00a0\u2026", "num_citations": "158\n", "authors": ["289"]}
{"title": "Context-sensitive slicing of concurrent programs\n", "abstract": " Program slicing is a technique to identify statements that may influence the computations at other statements. Precise slicing has been shown to be undecidable for concurrent programs. This work presents the first context-sensitive approach to slice concurrent programs accurately. It extends the well known structures of the control flow graph and the (interprocedural) program dependence graph for concurrent programs with interference. This new technique does not require serialization or inlining.", "num_citations": "139\n", "authors": ["289"]}
{"title": "Dynamic path conditions in dependence graphs\n", "abstract": " We present a new approach combining dynamic slicing with path conditions in dependence graphs enhanced by dynamic information collected in a program trace. While dynamic slicing can only reveal that certain dependences have been holding during program execution, the combination with dynamic path conditions reveals why, as well. The approach described here has been implemented for full ANSI-C. It uses the static dependence graph to produce a fine-grained variable and dependence trace of an executing program. This information is used for dynamic slicing, yielding significantly smaller sets of statements than static slices, as well as for increasing precision of the path condition between two statements. Such a dynamic path condition contains explicit information about if and how one statement influenced the other. Dynamic path conditions work even when tracing information is incomplete or corrupted\u00a0\u2026", "num_citations": "127\n", "authors": ["289"]}
{"title": "Advanced slicing of sequential and concurrent programs\n", "abstract": " Program slicing is a technique to identify statements that may influence the computations in other statements. Despite the ongoing research of almost 25 years, program slicing still has problems that prevent a widespread use: Sometimes, slices are too big to understand and too expensive and complicated to be computed for real-life programs. The presented thesis shows solutions to these problems: It contains various approaches which help the user to understand a slice more easily by making it more focused on the user's problem. All of these approaches have been implemented in the VALSOFT system and thorough evaluations of the proposed algorithms are presented. The underlying data structures used for slicing are program dependence graphs. They can also be used for different purposes: A new approach to clone detection based on identifying similar subgraphs in program dependence graphs is\u00a0\u2026", "num_citations": "114\n", "authors": ["289"]}
{"title": "Is cloned code older than non-cloned code?\n", "abstract": " It is still a debated question whether cloned code causes increased maintenance efforts. If cloned code is more stable than non-cloned code, ie it is changed less often, it will require less maintenance efforts. The more stable cloned code is, the longer it will not have been changed, so the stability can be estimated through the code's age. This paper presents a study on the average age of cloned code. For three large open source systems, the age of every line of source code is computed as the date of the last change in that line. In addition, every line is categorized whether it belongs to cloned code as detected by a clone detector. The study shows that on average, cloned code is older than non-cloned code. Moreover, if a file has cloned code, the average age of the cloned code of the file is lower than the average age of the non-cloned code in the same file. The results support the previous findings that cloned code\u00a0\u2026", "num_citations": "90\n", "authors": ["289"]}
{"title": "A Comparison of Code Similarity Analysers\n", "abstract": " Copying and pasting of source code is a common activity in software engineering. Often, the code is not copied as it is and it may be modified for various purposes; e.g. refactoring, bug fixing, or even software plagiarism. These code modifications could affect the performance of code similarity analysers including code clone and plagiarism detectors to some certain degree. We are interested in two types of code modification in this study: pervasive modifications, i.e. transformations that may have a global effect, and local modifications, i.e. code changes that are contained in a single method or code block. We evaluate 30 code similarity detection techniques and tools using five experimental scenarios for Java source code. These are (1) pervasively modified code, created with tools for source code and bytecode obfuscation, and boiler-plate code, (2) source code normalisation through compilation and\u00a0\u2026", "num_citations": "72\n", "authors": ["289"]}
{"title": "Interference analysis for AspectJ\n", "abstract": " AspectJ is a language implementing aspect-oriented programming on top of Java. Besides modification of program flow and state using advice, AspectJ offers language elements to statically modify existing classes by changing their position in the inheritance hierarchy or introducing new members. This can lead to binding interference, ie the dynamic lookup of method calls not affected directly by the aspect might change.", "num_citations": "71\n", "authors": ["289"]}
{"title": "Evaluating context-sensitive slicing and chopping\n", "abstract": " We present an empirical evaluation of three context-sensitive slicing algorithms and five context-sensitive chopping algorithms, and compare them to context-insensitive methods. Besides the algorithms by Reps et al. (1994, 1995) and Agrawal (2001) we investigate six new algorithms based on variations of k-limited call strings and approximative chopping based on summary information. It turns out that chopping based on summary information may have a prohibitive complexity, and that approximate algorithms are almost as precise and much faster.", "num_citations": "56\n", "authors": ["289"]}
{"title": "Validation of measurement software as an application of slicing and constraint solving\n", "abstract": " We show how to combine program slicing and constraint solving in order to obtain better slice accuracy. The method is used in the VALSOFT slicing system. One particular application is the validation of computer-controlled measurement systems. VALSOFT will be used by the Physikalisch-Technische-Bundesanstalt for verification of legally required calibration standards.The article describes the VALSOFT slicing system. In particular, we describe how to generate and simplify path conditions based on program slices. A case study shows that the technique can indeed increase slice precision and reveal manipulations of the so-called calibration path.", "num_citations": "52\n", "authors": ["289"]}
{"title": "EzUnit: A Framework for Associating Failed Unit Tests with Potential Programming Errors\n", "abstract": " Unit testing is essential in the agile context. A unit test case written long ago may uncover an error introduced only recently, at a time at which awareness of the test and the requirement it expresses may have long vanished. Popular unit testing frameworks such as JUnit may then detect the error at little more cost than the run of a static program checker (compiler). However, unlike such checkers current unit testing frameworks can only detect the presence of errors, they cannot locate them. With EzUnit, we present an extension to the JUnit                 Eclipse plug-in that serves to narrow down error locations, and that marks these locations in the source code in very much the same way syntactic and typing errors are displayed. Because EzUnit is itself designed as a framework, it can be extended by algorithms further narrowing down error locations.", "num_citations": "51\n", "authors": ["289"]}
{"title": "Visualization of program dependence and slices\n", "abstract": " The program dependence graph (PDG) itself and the computed slices within the program dependence graph are results that should be presented to the user in a comprehensible form, if not used in subsequent analyses. A graphical presentation would be preferred as it is usually more intuitive than textual ones. This work describes how a layout for the PDGs can be generated to enable an appealing presentation. However, experience shows that the graphical presentation is less helpful than expected and a textual presentation is superior. Therefore, this work contains an approach to textually present slices of PDGs in source code. The innovation of this approach is the fine-grained visualization of arbitrary node sets based on tokens and not on complete lines like in other approaches. Furthermore, a major obstacle in visualization and comprehension of slices is the loss of locality. Thus, this work presents a simple\u00a0\u2026", "num_citations": "50\n", "authors": ["289"]}
{"title": "Slicing, chopping, and path conditions with barriers\n", "abstract": " One of the critiques on program slicing is that slices presented to the user are hard to understand. This is mainly related to the problem that slicing \u2018dumps\u2019 the results onto the user without any explanation. This work will present an approach that can be used to \u2018filter\u2019 slices. This approach basically introduces \u2018barriers\u2019 which are not allowed to be passed during slice computation. An earlier filtering approach is chopping which is also extended to obey such a barrier. The barrier variants of slicing and chopping provide filtering possibilities for smaller slices and better comprehensibility. The concept of barriers is then applied to path conditions, which provide necessary conditions under which an influence between the source and target criterion exists. Barriers make those conditions more precise.", "num_citations": "45\n", "authors": ["289"]}
{"title": "How Double-Fetch Situations turn into Double-Fetch Vulnerabilities: A Study of Double Fetches in the Linux Kernel\n", "abstract": " We present the first static approach that systematically detects potential double-fetch vulnerabilities in the Linux kernel. Using a pattern-based analysis, we identified 90 double fetches in the Linux kernel. 57 of these occur in drivers, which previous dynamic approaches were unable to detect without access to the corresponding hardware. We manually investigated the 90 occurrences, and inferred three typical scenarios in which double fetches occur. We discuss each of them in detail. We further developed a static analysis, based on the Coccinelle matching engine, that detects double-fetch situations which can cause kernel vulnerabilities. When applied to the Linux, FreeBSD, and Android kernels, our approach found six previously unknown double-fetch bugs, four of them in drivers, three of which are exploitable double-fetch vulnerabilities. All of the identified bugs and vulnerabilities have been confirmed and patched by maintainers. Our approach has been adopted by the Coccinelle team and is currently being integrated into the Linux kernel patch vetting. Based on our study, we also provide practical solutions for anticipating double-fetch bugs and vulnerabilities. We also provide a solution to automatically patch detected double-fetch bugs.", "num_citations": "44\n", "authors": ["289"]}
{"title": "Control-flow-graph-based aspect mining\n", "abstract": " Aspect mining tries to identify crosscutting concerns in existing systems and thus supports the adaption to an aspect-oriented design. This paper describes an automatic static aspect mining approach, where the control flow graphs of a program are investigated for recurring execution patterns based on different constraints, such as the requirement that the patterns have to exist in different calling contexts. A case study done with the implemented tool shows that most discovered crosscutting candidates are most often perfectly good style.", "num_citations": "43\n", "authors": ["289"]}
{"title": "Barrier slicing and chopping\n", "abstract": " One of the critiques on program slicing is that slices presented to the user are hard to understand. This is partly due to bad user interfaces, but mainly related to the problem that slicing 'dumps' the results onto the user without any explanation. We present an approach that can be used to 'filter' slices. This approach basically introduces 'barriers' which are not allowed to be passed during slice computation. An earlier filtering approach is chopping which is also extended to obey such a barrier. The barrier variants of slicing and chopping provide filtering possibilities for smaller slices and better comprehensibility.", "num_citations": "42\n", "authors": ["289"]}
{"title": "Are Developers Aware of the Architectural Impact of Their Changes?\n", "abstract": " Although considered one of the most important decisions in a software development lifecycle, empirical evidence on how developers perform and perceive architectural changes is still scarce. Given the large implications of architectural decisions, we do not know whether developers are aware of their changes' impact on the software's architecture, whether awareness leads to better changes, and whether automatically making developers aware would prevent degradation. Therefore, we use code review data of 4 open source systems to investigate the intent and awareness of developers when performing changes. We extracted 8,900 reviews for which the commits are available. 2,152 of the commits have changes in their computed architectural metrics, and 338 present significant changes to the architecture. We manually inspected all reviews for commits with significant changes and found that only in 38% of the\u00a0\u2026", "num_citations": "40\n", "authors": ["289"]}
{"title": "Mining control flow graphs for crosscutting concerns\n", "abstract": " Aspect mining tries to identify crosscutting concerns in existing systems and thus supports the adoption to an aspect-oriented design. This paper describes an automatic static aspect mining approach, where the control flow graphs of a program are investigated for recurring execution patterns based on different constraints, such as the requirement that the patterns have to exist in different calling contexts. A case study done with the implemented tool shows that most discovered crosscutting candidates are instances of crosscutting delegation and should not be refactored into aspects", "num_citations": "40\n", "authors": ["289"]}
{"title": "Aspect Mining Using Dynamic Analysis\n", "abstract": " Concerns express a specific interest in some topic regarding a particular system of interest. Separation of concerns (originally invented by Dijkstra) is essential in the software development process: It is an important paradigm in software engineering to cope with the increasing number of special purpose concerns in today\u2019s applications. To deal with that increasing complexity, several new approaches like Composition Filters, Hyperslices and last but not least Aspect-Oriented Programming [3](including programming languages like AspectJ) have been proposed. But what about legacy systems, where separation of concerns could only be applied in a restricted way within the object-oriented paradigm? It is possible to find aspects and to encapsulate them without changing software behavior, improving maintainability and re-usability, reducing tangled and scattered code. This is illustrated in the following sections.", "num_citations": "40\n", "authors": ["289"]}
{"title": "Similarity of Source Code in the Presence of Pervasive Modifications\n", "abstract": " Source code analysis to detect code cloning, code plagiarism, and code reuse suffers from the problem of pervasive code modifications, i.e. transformations that may have a global effect. We compare 30 similarity detection techniques and tools against pervasive code modifications. We evaluate the tools using two experimental scenarios for Java source code. These are (1) pervasive modifications created with tools for source code and bytecode obfuscation and (2) source code normalisation through compilation and decompilation using different decompilers. Our experimental results show that highly specialised source code similarity detection techniques and tools can perform better than more general, textual similarity measures. Our study strongly validates the use of compilation/decompilation as a normalisation technique. Its use reduced false classifications to zero for six of the tools. This broad, thorough study is\u00a0\u2026", "num_citations": "35\n", "authors": ["289"]}
{"title": "Software engineering projects in distant teaching\n", "abstract": " Software engineering education is most often complemented by a software engineering project where a team of students has to develop a large software system. At a distance teaching university such projects challenge the students in communication, coordination, and collaboration, because team members work in different places, many miles away from each other. We present an ECLIPSE-based unified platform that leverages available tools and solutions and discuss the problems involved. Besides using plug-ins that support the students during implementation, our platform integrates a collaborative distant education environment and a software project management system that eases the students' collaboration in the software engineering project", "num_citations": "34\n", "authors": ["289"]}
{"title": "Trace analysis for aspect application\n", "abstract": " AspectJ is a language implementing aspect oriented programming on top of Java. Usually aspect application influences not only observable behavior but changes program flow internally. To test if an aspect works as intended, we suggest trace analysis to capture these internal changes. We demonstrate how trace analysis can be used for impact analysis. It can also be used to validate that refactorings which replaced scattered code by an aspect did not change system behavior.", "num_citations": "34\n", "authors": ["289"]}
{"title": "Effects of context on program slicing\n", "abstract": " Whether context-sensitive program analysis is more effective than context-insensitive analysis is an ongoing discussion. There is evidence that context-sensitivity matters in complex analyses like pointer analysis or program slicing. Empirical data shows that context-sensitive program slicing is more precise and under some circumstances even faster than context-insensitive program slicing. This article will add to the discussion by examining if the context itself matters, i.e. if a given context leads to more precise slices for that context. Based on some experiments, we will show that this is strongly dependent on the structure of the programs.The presented experiments require backward slices to return to call sites specified by an abstract call stack. Such call stacks can be seen as a poor man\u2019s dynamic slicing: For a concrete execution, the call stack is captured, and static slices are restricted to the captured stack. The\u00a0\u2026", "num_citations": "33\n", "authors": ["289"]}
{"title": "Intransitive Noninterference in Dependence Graphs\n", "abstract": " In classic information flow control (IFC), noninterference guarantees that no information flows from secret input channels to public output channels. However, this notion turned out to be overly restrictive as many intuitively secure programs do allow some release. In this paper we define a static analysis that allows intransitive noninterference in combination with context- sensitive analysis for Java bytecode programs. In contrast to type systems that annotate variables, our approach annotates information sources and sinks. To the best of our knowledge this is the first IFC technique which is flow-, context-, and object- sensitive. It allows IFC for realistic languages like Java or C and offers a mechanism for declassification to accommodate some information leakage for cases where traditional noninterference is too restrictive.", "num_citations": "33\n", "authors": ["289"]}
{"title": "Siamese: scalable and incremental code clone search via multiple code representations\n", "abstract": " This paper presents a novel code clone search technique that is accurate, incremental, and scalable to hundreds of million lines of code. Our technique incorporates multiple code representations (i.e., a technique to transform code into various representations to capture different types of clones), query reduction (i.e., a technique to select clone search keywords based on their uniqueness), and a customised ranking function (i.e., a technique to allow a specific clone type to be ranked on top of the search results) to improve clone search performance. We implemented the technique in a clone search tool, called Siamese, and evaluated its search accuracy and scalability on three established clone data sets. Siamese offers the highest mean average precision of 95% and 99% on two clone benchmarks compared to seven state-of-the-art clone detection tools, and reported the largest number of Type-3 clones\u00a0\u2026", "num_citations": "29\n", "authors": ["289"]}
{"title": "Program slicing\n", "abstract": " Program slicing is a technique to identify statements that may influence the computations of other statements. The original goal was to aid program understanding and debugging. Program slicing is now used as a base technique in other applications. Researchers in several areas of software engineering have suggested applications in program comprehension, software maintenance, reverse engineering and evolution, testing, and even verification. The following will give an overview of program slicing, including recent developments. This overview covers static as well as dynamic slicing. It contains a discussion of applications and basic approaches to compute slices, shows problems and their solutions, together with refinements of slicing.", "num_citations": "26\n", "authors": ["289"]}
{"title": "Using Compilation/Decompilation to Enhance Clone Detection\n", "abstract": " We study effects of compilation and decompilation to code clone detection in Java. Compilation/decompilation canonicalise syntactic changes made to source code and can be used as source code normalisation. We used NiCad to detect clones before and after decompilation in three open source software systems, JUnit, JFreeChart, and Tomcat. We filtered and compared the clones in the original and decompiled clone set and found that 1,201 clone pairs (78.7%) are common between the two sets while 326 pairs (21.3%) are only in one of the sets. A manual investigation identified 325 out of the 326 pairs as true clones. The 252 original-only clone pairs contain a single false positive while the 74 decompiled-only clone pairs are all true positives. Many clones in the original source code that are detected only after decompilation are type-3 clones that are dicult to detect due to added or deleted statements, keywords\u00a0\u2026", "num_citations": "21\n", "authors": ["289"]}
{"title": "A picture is worth a thousand words: Code clone detection based on image similarity\n", "abstract": " This paper introduces a new code clone detection technique based on image similarity. The technique captures visual perception of code seen by humans in an IDE by applying syntax highlighting and images conversion on raw source code text. We compared two similarity measures, Jaccard and earth mover's distance (EMD) for our image-based code clone detection technique. Jaccard similarity offered better detection performance than EMD. The F1 score of our technique on detecting Java clones with pervasive code modifications is comparable to five well-known code clone detectors: CCFinderX, Deckard, iClones, NiCad, and Simian. A Gaussian blur filter is chosen as a normalisation technique for type-2 and type-3 clones. We found that blurring code images before similarity computation resulted in higher precision and recall. The detection performance after including the blur filter increased by 1 to 6 percent\u00a0\u2026", "num_citations": "20\n", "authors": ["289"]}
{"title": "Context-sensitivity matters, but context does not\n", "abstract": " Whether context-sensitive program analysis is more effective than context-insensitive analysis is an ongoing discussion. There is evidence that context-sensitivity matters in complex analyses like pointer analysis or program slicing. One might think that the context itself matters, because empirical data shows that context-sensitive program slicing is more precise and under some circumstances even faster than context-insensitive program slicing. Based on some experiments, we will show that this is not the case. The experiment requires backward slices to return to call sites specified by an abstract call stack. Such call stacks can be seen as a poor man's dynamic slicing: for a concrete execution, the call stack is captured, and static slices are restricted to the captured stack. The experiment shows that there is no significant increase in precision of the restricted form of slicing compared to the unrestricted traditional slicing\u00a0\u2026", "num_citations": "16\n", "authors": ["289"]}
{"title": "The impact of code review on architectural changes\n", "abstract": " Although considered one of the most important decisions in the software development lifecycle, empirical evidence on how developers perform and perceive architectural changes remains scarce. Architectural decisions have far-reaching consequences yet, we know relatively little about the level of developers' awareness of their changes' impact on the software's architecture. We also know little about whether architecture-related discussions between developers lead to better architectural changes. To provide a better understanding of these questions, we use the code review data from 7 open source systems to investigate developers' intent and awareness when performing changes alongside the evolution of the changes during the reviewing process. We extracted the code base of 18,400 reviews and 51,889 revisions. 4,171 of the reviews have changes in their computed architectural metrics, and 731 present\u00a0\u2026", "num_citations": "13\n", "authors": ["289"]}
{"title": "Statement-level cohesion metrics and their visualization\n", "abstract": " Slice-based metrics for cohesion have been defined and examined for years. However, if a module with low cohesion has been identified, the metrics cannot help the maintainer to restructure the module to improve the cohesion. This work presents statement-level cohesion metrics based on slices and chops. When visualized, the statement-level cohesion metrics can show which parts of a module have a low cohesion and thus help the maintainer to identify the parts that should be restructured.", "num_citations": "13\n", "authors": ["289"]}
{"title": "Information flow control and taint analysis with dependence graphs\n", "abstract": " Ensuring that the integrity of critical computation is not violated by untrusted code or the confidential data is protected is a complex problem for current software systems. We can observe two main directions to approach the problems:", "num_citations": "11\n", "authors": ["289"]}
{"title": "Using Eclipse in distant teaching of software engineering\n", "abstract": " Software engineering education is most often complemented by a software engineering project where a team of students has to develop a large software system. At a distance teaching university such projects challenge the students in communication and collaboration, because team members work in different places, many miles away from each other. We present an ECLIPSE-based unified platform that leverages available tools and solutions and discuss the problems involved. Besides using plug-ins that support the students during implementation, our platform integrates a collaborative distant education environment and a software project management system that will ease th\u00e9 students' collaboration in the software engineering project.", "num_citations": "11\n", "authors": ["289"]}
{"title": "Establishing Multilevel Test-to-Code Traceability Links\n", "abstract": " Test-to-code traceability links model the relationships between test artefacts and code artefacts. When utilised during the development process, these links help developers to keep test code in sync with tested code, reducing the rate of test failures and missed faults. Test-to-code traceability links can also help developers to maintain an accurate mental model of the system, reducing the risk of architectural degradation when making changes. However, establishing and maintaining these links manually places an extra burden on developers and is error-prone. This paper presents TCtracer, an approach and implementation for the automatic establishment of test-to-code traceability links. Unlike existing work, TCtracer operates at both the method level and the class level, allowing us to establish links between tests and functions, as well as between test classes and tested classes. We improve over existing techniques\u00a0\u2026", "num_citations": "9\n", "authors": ["289"]}
{"title": "Essential Open Source Toolset\n", "abstract": " Market_Desc:\u00b7 Programmers working on Linux/Unix platforms Special Features:\u00b7 Covers newest and best open source tools: Ant, Doxygen, Junit, Valgrind, and Bugzilla\u00b7 Includes a whole chapter on Eclipse, which is thecoolest programming environment ever seen'\u00b7 Covers classic tools with modern tutorials About The Book: Programmers increasingly rely on tools and there are some excellent new, often freely available tools available under Linux/Unix. The book presents all those tools and environments which should form the basic toolset for any programmer working in a Unix-like environment. It shows how to use both those tools now considered, as well as a newer range of exciting plug-ins and extras which make a programmers life so much easier and more productive.", "num_citations": "9\n", "authors": ["289"]}
{"title": "Searching for configurations in clone evaluation\u2013a replication study\n", "abstract": " Clone detection is the process of finding duplicated code within a software code base in an automated manner. It is useful in several areas of software development such as code quality analysis, bug detection, and program understanding. We replicate a study of a genetic-algorithm based framework that optimises parameters for clone agreement (EvaClone). We apply the framework to 14 releases of Mockito, a Java mocking framework. We observe that the optimised parameters outperform the tools\u2019 default parameters in term of clone agreement by 19.91\u00a0% to 66.43\u00a0%. However, the framework gives undesirable results in term of clone quality. EvaClone either maximises or minimises a number of clones in order to achieve the highest agreement resulting in more false positives or false negatives introduced consequently.", "num_citations": "6\n", "authors": ["289"]}
{"title": "Cloning in Max/MSP patches\n", "abstract": " Max/MSP is widely used for developing applications in music and art yet less attention has been given to supporting developers working in this language than for more traditional languages such as Java. Technologies such as code-completion, reuse support, and refactoring may be helpful but are largely unexplored. Such methods rely on detecting similarities between language elements. This paper presents a method for detecting similarities between Max/MSP patches (and subpatches) based on clone detection techniques. The method has been implemented and a proof-of-concept evaluation has been undertaken by applying it to the set of Max tutorial patches supplied with Max/MSP 5. The results show that significant cloning takes place both within and outwith an individual patch and that, as clone constraints are relaxed, the number of clone pairs increases.", "num_citations": "6\n", "authors": ["289"]}
{"title": "Python coding style compliance on stack overflow\n", "abstract": " Software developers all over the world use Stack Overflow (SO) to interact and exchange code snippets. Research also uses SO to harvest code snippets for use with recommendation systems. However, previous work has shown that code on SO may have quality issues, such as security or license problems. We analyse Python code on SO to determine its coding style compliance. From 1,962,535 code snippets tagged with 'python', we extracted 407,097 snippets of at least 6 statements of Python code. Surprisingly, 93.87% of the extracted snippets contain style violations, with an average of 0.7 violations per statement and a huge number of snippets with a considerably higher ratio. Researchers and developers should, therefore, be aware that code snippets on SO may not representative of good coding style. Furthermore, while user reputation seems to be unrelated to coding style compliance, for posts with vote\u00a0\u2026", "num_citations": "5\n", "authors": ["289"]}
{"title": "No Good Reason to Remove Features\n", "abstract": " Application sandboxes are an essential security mechanism to contain malware, but are seldom used on desktops. To understand why this is the case, we interviewed 13 expert users about app appropriation decisions they made on their desktop computers. We collected 201 statements about app appropriation decisions. Our value-sensitive empirical analysis of the interviews revealed that (a) security played a very minor role in app appropriation; (b) users valued plugins that support their productivity; (c) users may abandon apps that remove a feature \u2013 especially when a feature was blocked for security reasons. Our expert desktop users valued a stable user experience and flexibility, and are unwilling to sacrifice those for better security. We conclude that sandboxing \u2013 as currently implemented \u2013 is unlikely to be voluntarily adopted, especially by expert users. For sandboxing to become a desirable security\u00a0\u2026", "num_citations": "5\n", "authors": ["289"]}
{"title": "Mining execution relations for crosscutting concerns\n", "abstract": " Aspect mining tries to identify crosscutting concerns in the code of existing systems and thus supports their adaption to an aspect-oriented design. A semi-automatic static aspect mining approach is described, where the program's control flow graphs are investigated for recurring execution patterns based on different constraints, such as the requirement that the patterns have to exist in different calling contexts. Two case studies done with the implemented tool show that many discovered candidates for crosscutting concerns are instances of delegation and should not be refactored into aspects. More generally, it is shown that aspect mining techniques need a way to distinguish between delegation and superimposed behaviour.", "num_citations": "5\n", "authors": ["289"]}
{"title": "Aspect mining based on control-flow\n", "abstract": " Aspect mining tries to identify crosscutting concerns in existing systems and thus supports the adaption to an aspectoriented design. This paper describes an automatic static aspect mining approach, where the control flow graphs of a program are investigated for recurring execution patterns based on different constraints, such as the requirement that the patterns have to exist in different calling contexts. A case study done with the implemented tool shows that most discovered crosscutting candidates are most often perfectly good style.", "num_citations": "5\n", "authors": ["289"]}
{"title": "AVPredictor: Comprehensive prediction and detection of atomicity violations\n", "abstract": " Concurrency bugs, such as atomicity\u2010violation bugs, are difficult to detect due to the uncertainty of thread\u2010scheduling. It is particularly difficult to conduct a thorough bug fix when an atomicity\u2010violation bug can be triggered by different buggy interleavings. This paper proposes a prediction\u2010based approach to comprehensively detect atomicity\u2010violation bugs. A bug fix can be incomplete when the developer cannot have all the buggy interleavings. Based on the candidate interleavings, this approach can predict unmanifested atomicity\u2010violation bugs from a non\u2010buggy execution and comprehensively display all the buggy interleavings for the same bug to assist a thorough fix. We use a monitored execution to record execution traces and predict potential buggy interleavings based on the candidate interleavings identified from the trace. Then, we use controlled executions to verify the predicted buggy interleavings by\u00a0\u2026", "num_citations": "3\n", "authors": ["289"]}
{"title": "Testnmt: Function-to-test neural machine translation\n", "abstract": " Test generation can have a large impact on the software engineering process by decreasing the amount of time and effort required to maintain a high level of test coverage. This increases the quality of the resultant software while decreasing the associated effort. In this paper, we present TestNMT, an experimental approach to test generation using neural machine translation. TestNMT aims to learn to translate from functions to tests, allowing a developer to generate an approximate test for a given function, which can then be adapted to produce the final desired test.", "num_citations": "3\n", "authors": ["289"]}
{"title": "A platform for teaching distributed software engineering\n", "abstract": " Many problems in distributed software engineering (DSE) arise, because the participants of a team are not trained in DSE. We present an integrated development environment which supports collaborative working. To introduce such a system in the teaching of software engineering provides for a higher educational standard and for a better awareness of students for the problems involved in distributed software development. We present the necessary tools to accomplish the development of such an IDE based on Eclipse and discuss the problems involved.", "num_citations": "3\n", "authors": ["289"]}
{"title": "Software-Sicherheitspr\u00fcfung mit VALSOFT\n", "abstract": " Die Physikalisch-Technische Bundesanstalt mu\u00df alle eichpflichtigen Me\u00dfger\u00e4te pr\u00fcfen. Da heute fast jedes Me\u00dfger\u00e4t durch Software gesteuert wird, mu\u00df sichergestellt werden, da\u00df der Datenpfad vom Sensoreingang zur Anzeige (Eichpfad) nicht durch externe Faktoren beeinflu\u00dft werden kann. Das VALSOFT-Werkzeug erkennt, analysiert und visualisiert Beeinflussungen der Eichpfade. Grundlage der Analyse sind Program-Slicing und Constraint-Solving. Zu beliebigen Programmpunkten (z. B. Me\u00dfwertausgaben) k\u00f6nnen diejenigen Anweisungen bestimmt werden, die diesen Punkt beeinflussen (sog. Slice). Zus\u00e4tzlich k\u00f6nnen genaue Bedingungen berechnet werden, unter denen verd\u00e4chtige Datenfl\u00fcsse stattfinden (sog. Pfadbedingungen). Anwendungen in anderen sicherheitskritischen Bereichen sind ohne weiteres m\u00f6glich.", "num_citations": "3\n", "authors": ["289"]}
{"title": "Reassert: Deep learning for assert generation\n", "abstract": " The automated generation of test code can reduce the time and effort required to build software while increasing its correctness and robustness. In this paper, we present RE-ASSERT, an approach for the automated generation of JUnit test asserts which produces more accurate asserts than previous work with fewer constraints. This is achieved by targeting projects individually, using precise code-to-test traceability for learning and by generating assert statements from the method-under-test directly without the need to write an assert-less test first. We also utilise Reformer, a state-of-the-art deep learning model, along with two models from previous work to evaluate ReAssert and an existing approach, known as ATLAS, using lexical accuracy,uniqueness, and dynamic analysis. Our evaluation of ReAssert shows up to 44% of generated asserts for a single project match exactly with the ground truth, increasing to 51% for generated asserts that compile. We also improve on the ATLAS results through our use of Reformer with 28% of generated asserts matching exactly with the ground truth. Reformer also produces the greatest proportion of unique asserts (71%), giving further evidence that Reformer produces the most useful asserts.", "num_citations": "2\n", "authors": ["289"]}
{"title": "Who\u2019s this? Developer identification using IDE event data\n", "abstract": " This paper presents a technique to identify a developer based on their IDE event data. We exploited the KaVE data set which recorded IDE activities from 85 developers with 11M events. We found that using an SVM with a linear kernel on raw event count outperformed k-NN in identifying developers with an accuracy of 0.52. Moreover, after setting the optimal number of events and sessions to train the classifier, we achieved a higher accuracy of 0.69 and 0.71 respectively. The findings shows that we can identify developers based on their IDE event data. The technique can be expanded further to group similar developers for IDE feature recommendations.", "num_citations": "2\n", "authors": ["289"]}
{"title": "Eine Plattform f\u00fcr die Softwaretechnik-Fernlehre\n", "abstract": " Softwaretechnik-Lehre ist ohne entsprechende Praktika und Projekte nicht sinnvoll. An der FernUniversit\u00e4t in Hagen ist die Softwaretechnik-Lehre auch immer entfernte Lehre und die Anforderungen an die Softwaretechnik-Praktika sind somit h\u00f6her. Wir beschreiben eine integrierte Entwicklungsumgebung, die auf Eclipse basiert und alle Werkzeuge, die f\u00fcr die entfernte Softwaretechnik-Lehre n\u00f6tig sind, unter einer einzigen, in sich geschlossenen Oberfl\u00e4che vereint.", "num_citations": "2\n", "authors": ["289"]}
{"title": "Using program analysis infrastructure for software maintenance\n", "abstract": " Enabling the reuse of available techniques and tools for software maintenance is a major topic. However, research focuses mostly on two topics: parsing and tool interoperability. In the future, more sophisticated approaches to maintenance will be needed and dataflow analysis has to be used. As building dataflow analyzers for real languages is expensive, we must start to provide reusable dataflow analysis infrastructures for software maintenance. This paper first reports on our experience in building program analysis based maintenance tools. From that perspective, we formulate specific requirements for reusable program analysis infrastructures and then take a look at some program analysis infrastructures from compiler optimization research to evaluate if they are (re) usable for software maintenance tools.", "num_citations": "2\n", "authors": ["289"]}
{"title": "Erfahrungen mit dem Open-Access-Journal \u201celeed (e-learning and education)\u201d\n", "abstract": " Im Rahmen der Open Access Initiative \u201eDigital Peer Publishing NRW \u201cgibt die Fern-Universit\u00e4t in Hagen in Kooperation mit der Initiative CampusSource seit 2005 das eJournal \u201eeleed (e-learning and education)\u201cheraus. eleed ist ein elektronisches Journal, bei dem alle Ver\u00f6ffentlichungen unter eine Open Access Lizenz gestellt werden. Ein Redaktionstridem, bestehend aus Fachwissenschaftlern sowie Vertretern der Universit\u00e4tsbibliothek und CampusSource akquiriert und bewertet wissenschaftliche Aufs\u00e4tze, Projektberichte und Buchbesprechungen. Dieser Artikel beschreibt, welche Erfahrungen mit diesem Journal gemacht wurden.", "num_citations": "1\n", "authors": ["289"]}
{"title": "Kombination von Slicing mit Constraint-Solving fur Software-Reengineering\n", "abstract": " Um sicherheitsrelevante Software zu \u00fcberpr\u00fcfen, reichen herk\u00f6mmliche Softwareanalyse-Verfahren nicht aus. Unser Softwareanalyse-System ValSoft setzt Datenflu\u00dfanalysen und deduktive Verfahren ein, um Beeinflussungen von relevanten Informationspfaden innerhalb von Programmen zu erkennen und zu analysieren. Die Grundlage der Analyse bilden sog. Programmabh\u00e4ngigkeitsgraphen. Mit deren Hilfe berechnen wir konservativ approximierte Pfadbedingungen: diese geben die Umst\u00e4nde an, unter denen es eine Abh\u00e4ngigkeit zwischen interessierenden Punkten im Programm geben kann.", "num_citations": "1\n", "authors": ["289"]}