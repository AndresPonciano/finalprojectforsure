{"title": "Techniques for verifying superscalar microprocessors\n", "abstract": " J.R. Burch and D.L. Dill (1994) described an automatic method for verifying a pipelined processor against its instruction set architecture (ISA). We describe three techniques for improving this method. We show how the combination of these techniques allows for the automatic verification of the control logic of a pipelined, superscalar implementation of a subset of the DLX architecture.", "num_citations": "158\n", "authors": ["1792"]}
{"title": "Efficient validity checking for processor verification\n", "abstract": " We describe an efficient validity checker for the quantifier-free logic of equality with uninterpreted functions. This logic is well suited for verifying microprocessor control circuitry since it allows the abstraction of datapath values and operations. Our validity checker uses special data structures to speed up case splitting, and powerful heuristics to reduce the number of case splits needed. In addition, we present experimental results and show that this implementation has enabled the automatic verification of an actual high-level microprocessor description.", "num_citations": "139\n", "authors": ["1792"]}
{"title": "Tight integration of combinational verification methods\n", "abstract": " Combinational verification is an important piece of most equivalence checking tools. In the recent past, many combinational verification algorithms have appeared in the literature. Previous results show that these algorithms are able to exploit circuit similarity to successfully verify large designs. However, none of these strategies seems to work when the two input designs are not equivalent. We present our combinational verification algorithm, with evidence, that is designed to be robust for both the positive and the negative problem instances. We also show that a tight integration of different verification techniques, as opposed to a coarse integration of different algorithm, is more effective at solving hard instances.", "num_citations": "124\n", "authors": ["1792"]}
{"title": "Efficient Boolean function matching\n", "abstract": " Efficient algorithms for performing the matching step in technology mapping are proposed. The main result is an algorithm for matching under input negations that takes time polynomial in the size of the BDDs representing the functions to be matched. This algorithm is the basis for efficient methods for matching under permutations, bridging and constant inputs. A simple mapper based on the algorithms was implemented and tested on a suite of combinational circuits. Using the Actel type 1 mother cell, the mapper required an average of 8.5% fewer cells than mispga. When integrated into a more sophisticated technology mapper, the matching algorithms could provide even better performance.< >", "num_citations": "96\n", "authors": ["1792"]}
{"title": "Using BDDs to verify multipliers\n", "abstract": " Bryant\u2019s Binary Decision Diagrams(BDDs)[6] have been successfully used for verifying combinational circuits [12, 18]. However, multiplier circuits are difficult to verify using BDDs since the size of the BDD representing multiplication grows exponentially in the number of input bits [6, 7]. This paper presents a method for using BDDs to verify multipliers that avoids this exponential complexity. The method has been used to verify a 16 by 16 bit combhtational multiplier, the C6288 circuit from the ISCAS85 benchmarks [5]. This is the only IS CAS85 benchmark circuit that could not be verified using the techniques described by Fujita et al.[12] and Malik et al.[18].", "num_citations": "95\n", "authors": ["1792"]}
{"title": "Safe BDD minimization using don't cares\n", "abstract": " In many computer-aided design tools, binary decision diagrams (BDDs) are used to represent Boolean functions. To increase theefficiency and capability of these tools, many algorithms have beendeveloped to reduce the size of BDDs. This paper presents heuristicalgorithms that minimize the size of BDDs representing incompletelyspecified functions by intelligently assigning don't cares tobinary values. The traditional algorithm, restrict [Verification of Synchronous Sequential Machines Based on Symbolic Execution], is often effectivein BDD minimization, but can increase the BDD size. We proposenew algorithms based on restrict which are guaranteed neverto increase the size of the BDD, thereby significantly reducing peakmemory requirements. Experimental results show that our techniquestypically yield significantly smaller BDDs than restrict.", "num_citations": "91\n", "authors": ["1792"]}
{"title": "Trace algebra for automatic verification of real-time concurrent systems\n", "abstract": " Verification methodologies for real-time systems can be classified according to whether they are based on a continuous time model or a discrete time model. Continuous time often provides a more accurate model of physical reality, while discrete time can be more efficient to implement in an automatic verifier based on state exploration techniques. Choosing a model appears to require a compromise between efficiency and accuracy. We avoid this compromise by constructing discrete time models that are conservative approximations of appropriate continuous time models. Thus, if a system is verified to be correct in discrete time, then it is guaranteed to also be correct in continuous time. We also show that models with explicit simultaneity can be conservatively approximated by models with interleaving semantics.Descriptors:", "num_citations": "91\n", "authors": ["1792"]}
{"title": "Using simulation and satisfiability to compute flexibilities in Boolean networks\n", "abstract": " Simulation and Boolean satisfiability (SAT) checking are common techniques used in logic verification. This paper shows how simulation and satisfiability (S&S) can be tightly integrated to efficiently compute flexibilities in a multilevel Boolean network, including the following: 1) complete \"don't cares\" (CDCs); 2) sets of pairs of functions to be distinguished (SPFDs); and 3) sets of candidate nodes for resubstitution. These flexibilities can be used in network optimization to change the network structure while preserving its functionality. In the first two applications, simulation quickly enumerates most of the solutions while SAT detects the remaining solutions. In the last application, simulation efficiently filters out most of the infeasible solutions while SAT checks the remaining candidates. The experimental results confirm that the combination of simulation and SAT offers a computation engine that outperforms binary\u00a0\u2026", "num_citations": "71\n", "authors": ["1792"]}
{"title": "Overcoming heterophobia: Modeling concurrency in heterogeneous systems\n", "abstract": " System level design is complex. One source of this complexity is that systems are often heterogeneous: different models of computation (e.g., dataflow, FSMs) are used to describe different components of a system. Existing formal methods for concurrent systems are typically based on one particular model of computation, so it is difficult to formalize the interaction between heterogeneous components. In this paper, we develop a framework for formalizing the relationships between different models of computation.", "num_citations": "55\n", "authors": ["1792"]}
{"title": "Mechanically checking a lemma used in an automatic verification tool\n", "abstract": " Automatic formal verification methods sometimes depend on lemmas for decomposing proofs into parts. The decomposition simplifies the verification task for automatic tools, such as model checkers. Typically the lemmas are proven by hand, and apply to all instances where the automatic tool is applied. Mechanically verifying these lemmas using a theorem prover provides greater assurance that the decomposition is correct and can provide insight into possible simplifications and generalizations. This paper gives an example of such an exercise, proving a theorem used by Burch [Bur96] in the verification of a super-scalar processor model.", "num_citations": "49\n", "authors": ["1792"]}
{"title": "Constraints specification at higher levels of abstraction\n", "abstract": " We are proposing a formalism to express performance constraints at a high level of abstraction. The formalism allows specifying design performance constraints even before all low level details necessary to evaluate them are known. It is based on a solid mathematical foundation, to remove any ambiguity in its interpretation, and yet it allows quite simple and natural specification of many typical constraints. Once the design details are known, the satisfaction of constraints can be checked either by simulation, or by formal techniques like theorem proving, and, in some cases, by automatic model checking.", "num_citations": "46\n", "authors": ["1792"]}
{"title": "Robust latch mapping for combinational equivalence checking\n", "abstract": " Existing literature on combinational equivalence checking concentrates on comparing combinational blocks and assumes that a latch mapping (register mapping) has already been constructed. We describe an algorithm for automatically constructing a latch mapping. It is based on the functionality of the circuits being compared rather than on heuristics. As a result, if two circuits are combinationally equivalent, then our algorithm is guaranteed to find a latch mapping. Our empirical results show that the method is practical on large circuits.", "num_citations": "46\n", "authors": ["1792"]}
{"title": "Modeling hierarchical combinational circuits\n", "abstract": " Hierarchical descriptions of combinational circuits often contain apparent loops. Since it may be difficult to distinguish apparent loops from actual loops, it is useful to construct models of combinational circuits that can handle cyclic dependencies. We show that Boolean relations are inadequate for this purpose, and define a ternary model that solves the problem. We use the model to characterize exact solutions to a broad class of substitution and rectification problems. The theory cleanly handles network transformations that might introduce cyclic dependencies.", "num_citations": "41\n", "authors": ["1792"]}
{"title": "Method and system for combinational verification having tight integration of verification techniques\n", "abstract": " A method and system for combinational verification tightly integrates multiple verification methods. The present invention performs random simulation on the inputs of two combinational netlists. The nets within the netlists are described as BDDs and divided into classes of cutpoint candidates based upon the signatures produced by the random simulation. Cutpoint candidates within each class are resolved to determine whether the candidates are equivalent. If the nets are likely to be equivalent, BDD composition is performed on the nets. Otherwise, SAT-based analysis is performed on the nets. If either method fails to resolve the cutpoints within an allocated amount of time or resources, then the other method is invoked and information learned by the first method is passed to the second method to assist in the resolution. This process repeats until the cutpoint candidates are resolved. If the cutpoint resolution\u00a0\u2026", "num_citations": "37\n", "authors": ["1792"]}
{"title": "Combining CTL, trace theory and timing models\n", "abstract": " A system that combines CTL model checking and trace theory for verifying speed-independent asynchronous circuits is described. This system is able to verify a large and useful class of liveness and fairness properties, and is able to find safety violations after examining only a small fraction of the circuit's state space in many cases. An extension has been implemented that allows the verification of circuits that are not speed-independent, but instead rely on assumptions about the relative delays of their components for correct operation. This greatly expands the class of circuits that can be automatically verified, making the verifier a more useful tool in the design of asynchronous circuits. The system is demonstrated on several fair mutual exclusion circuits, including a speed-independent version that is verified correct. It is also shown that given quite weak assumptions about the relative delays of components\u00a0\u2026", "num_citations": "36\n", "authors": ["1792"]}
{"title": "Using multiple levels of abstractions in embedded software design\n", "abstract": " The methodologies that are in use today for software development rely on representations and techniques appropriate for the applications (compilers, business applications, CAD, etc.) that have been traditionally implemented on programmable processors. Embedded software is different: by virtue of being embedded in a surrounding system, the software must be able to continuously react to stimula in the desired way. Verifying the correctness of the system requires that the model of the software be transformed to include (refine) or exclude (abstract) information to retain only what is relevant to the task at hand. In this paper, we outline a framework that we inted to use for studying the problems of abstraction and refinement in the context of embedded software for hybrid systems.", "num_citations": "32\n", "authors": ["1792"]}
{"title": "Modelling timing assumption with trace theory\n", "abstract": " An extension of trace theory is described that allows for the verification of asynchronous circuits that are not speed-independent, but instead rely on assumptions about the delays of their components for correct operation. The theory has been implemented in an automatic verifier that checks whether a circuit satisfies a given formal specification in time linear in the number of states of both the specification and the circuit. The ability of the verifier to model timing assumptions greatly expands the class of circuits that can be automatically verified, making the verifier a more useful tool in the design of asynchronous circuits. The verifier is demonstrated on a self-timed queue element.<>", "num_citations": "32\n", "authors": ["1792"]}
{"title": "Sibling-substitution-based BDD minimization using don't cares\n", "abstract": " In many computer-aided design tools, binary decision diagrams (BDDs) are used to represent Boolean functions. To increase the efficiency and capability of these tools, many algorithms have been developed to reduce the size of the BDDs. This paper presents heuristic algorithms to minimize the size of the BDDs representing incompletely specified functions by intelligently assigning don't cares to binary values. Experimental results show that new algorithms yield significantly smaller BDDs compared with existing algorithms yet still require manageable run-times. These algorithms are particularly useful for synthesis application where the structure of the hardware/software is derived from the BDD representation of the function to implement because the minimization quality is more critical than the minimization speed in these applications.", "num_citations": "28\n", "authors": ["1792"]}
{"title": "Efficient verification of determinate speed-independent circuits\n", "abstract": " We present sufficient conditions for the correctness of speed-independent circuits with respect to their state graph (SG) specification, which can be tested in linear-time with respect to the size of the SG. Our correctness conditions consist of one safety condition and one progress condition. The progress condition detects deadlock conditions that are not present in the specification. The SG specifications considered are determinate, allowing input choice (conditionals) but not output choice (arbitration). The circuits considered are a network of basic gates; arbiters and mutual-exclusion elements are not allowed. We present an efficient algorithm to test the correctness conditions, in which false positives are not possible, but false negatives are possible. We have implemented the algorithm and present a table of run-time comparisons between our verification tool and the tool AVER by D. Dill on a large benchmark of\u00a0\u2026", "num_citations": "28\n", "authors": ["1792"]}
{"title": "Delay models for verifying speed-dependent asynchronous circuits\n", "abstract": " It is demonstrated that the binary inertial delay model can lead to false positive results when used in the verification of speed-dependent asynchronous circuits. A delay model called the binary chaos delay model solves this problem in many cases. The two timing models are compared by using them in the verification of a FIFO controller circuit. The models can be viewed as two extremes of a more general, parameterized model.<>", "num_citations": "28\n", "authors": ["1792"]}
{"title": "Method and system of latch mapping for combinational equivalence checking\n", "abstract": " A method and system of latch mapping for performing combinational equivalence checking on a specification and an implementation of a circuit that does not depend on signal names or circuit structure to determine the latch mapping. First, every latch is mapped to every other latch. Then, the resulting mapping is refined until it is semi-inductive. The refinement is performed by randomly producing a state that satisfies the mapping and applying a random input vector to the circuits. The resulting mappings are iteratively compared and new input vectors are applied to the circuits until the greatest fixed point of the refinement is found. Then, it is determined whether the greatest fixed point of refinement forces output equality. If the greatest fixed point does not force output equality, then a bug in a combinational block of the implementation is localized through an interactive procedure. If the greatest fixed point does force\u00a0\u2026", "num_citations": "19\n", "authors": ["1792"]}
{"title": "Memory modeling in ESL-RTL equivalence checking\n", "abstract": " When designers create RTL models from a system-level specification, arrays in the system-level model are often implemented as memories in the RTL. Knowing the correspondence between ESL arrays and RTL memories can significantly reduce the complexity of a formal equivalence check between the ESL model and the RTL. In practice, however, handling memory mappings in ESL-RTL equivalence checking is non-trivial for the following reasons: first, because of a lack of bit-accurate data-types in the system-level language, the information stored in an array location may be stored in a compressed form in the RTL. Second, a single array in the ESL model may be implemented by multiple memories in the RTL and/or corresponding data items may be stored in different locations. And last but not least, due to timing differences between the ESL model and the RTL, the correspondence between arrays and\u00a0\u2026", "num_citations": "18\n", "authors": ["1792"]}
{"title": "Sufficient conditions for correct gate-level speed-independent circuits\n", "abstract": " We describe sufficient conditions for the correctness of speed-independent asynchronous circuits. The circuit specifications considered are determinate, allowing input choice but not output choice (arbitration). The circuit implementations considered are networks of single-output basic gates. A circuit is defined to be correct if it is hazard-free and complex-gate equivalent to its specification. We show that a circuit is hazard-free if and only if all of its signals are monotonic and acknowledged. This result provides a useful tool for formal reasoning about the correctness of circuits and synthesis techniques. Cubes that approximate sets of reachable circuit states can be used to give sufficient conditions for monotonicity and acknowledgement. These sufficient conditions are the basis of efficient synthesis and verification algorithms.", "num_citations": "17\n", "authors": ["1792"]}
{"title": "Formally proving the functional equivalence of pipelined designs containing memories\n", "abstract": " One embodiment of the present invention provides a system that formally proves the functional equivalence of pipelined designs. First, the system receives a specification for a first pipelined design, which includes a first memory system, and a specification for a second pipelined design, which includes a second memory system. Next, the system determines a correspondence between operations on the first memory system and corresponding operations on the second memory system. This correspondence enables memory operations to be represented in a combinational form based on design inputs, thereby allowing both memory systems to be logically abstracted out of their respective designs. After the memory systems have been abstracted out, the system compares the combinational outputs of the first pipelined design and the combinational outputs of the second pipelined design to verify that the designs are\u00a0\u2026", "num_citations": "16\n", "authors": ["1792"]}
{"title": "Symbolic model checking\n", "abstract": " In immer mehr Gegenst anden des allt aglichen Gebrauchs werden immer komplizierte elektronische Schaltungen eingebaut. Damit steigt auch die Abh angigkeit vom fehlerlosen Verhalten dieser Ger ate, da zB bei Insulinpumpen daran Menschenleben h angen. Aber auch bei weniger kritischen Anwendungen, zB elektronische T urschl osser, k onnte ein Versagen fatale Folgen haben. Um Fehler zu nden, werden die Schaltungen getestet. Leider k onnen sich auch nach intensivsten Testreihen noch Fehler im Produkt be nden, wie der verwandte Software-Markt zeigt. Eine M oglichkeit, formal zu veri zieren, da eine Schaltung sich entsprechend ihrer Spezikation verh alt, ist Model-Checking. Beim Model-Checking wird uberpr uft, ob in jedem m oglichen Zustands ubergang die Nebenbedingungen gelten. Die Menge aller m oglichen Zust ande eines Systems hei t Zustandsraum. Seine Gr oeh angt von der Anzahl\u00a0\u2026", "num_citations": "16\n", "authors": ["1792"]}
{"title": "Generalized symmetries in boolean functions: Fast computation and application to boolean matching\n", "abstract": " In recent years, the notion of symmetry has been extended from classical symmetries to also include constant cofactor symmetries, single variable symmetries and Kronecker symmetries. All these symmetries form a generalized symmetry scheme. Existing methods to detect generalized symmetries require computing the cofactors for each pair of variables to check certain relationships between the cofactors. In this paper, we present a new algorithm that detects all pairs of symmetric variables in one pass over a multi-output BDD. Experiments on the MCNC benchmarks are encouraging. We also propose a potential application of generalized symmetries in Boolean matching. Keywords: Kronecker symmetries, generalized symmetries, Boolean matching.", "num_citations": "15\n", "authors": ["1792"]}
{"title": "Refinement preserving approximations for the design and verification of heterogeneous systems\n", "abstract": " Embedded systems are electronic devices that function in the context of a real environment, by sensing and reacting to a set of stimuli. Because of their close interaction with the environment, and to simplify their design, different parts of an embedded system are best described using different notations and different techniques. In this case, we say that the system is heterogeneous. We informally refer to the notation and the rules that are used to specify and verify the elements of heterogeneous systems and their collective behavior as a model of computation. In this paper, we consider different classes of relationships between models of computation and discuss their preservation properties with respect to the model's refinement relation and composition operator. In particular, we focus on abstraction and refinement relationships in the form of abstract interpretations and introduce the notion of conservative\u00a0\u2026", "num_citations": "14\n", "authors": ["1792"]}
{"title": "Fair mutual exclusion with unfair P and V operations\n", "abstract": " The semantics of P and V operations can be described by two axioms, called the boundedness and progress axioms. For a given pair of P and V operations on semaphore s, let cPs and cVs be the number of completed P and V operations on s respectively, and let qPs be the number of currently suspended P operations.", "num_citations": "14\n", "authors": ["1792"]}
{"title": "Checking combinational equivalence of speed-independent circuits\n", "abstract": " We introduce the notion of combinational equivalence to relate two speed-independent asynchronous (sequential) circuits: a \u201cgolden\u201d hazard-free circuit C 1 and a \u201ctarget\u201d circuit C 2 that can be derived from C 1 through only combinational decomposition and extraction. Both circuits are assumed to be networks of single-output basic gates; multiple output gates such as arbiters, toggles, and dual-rail function blocks are not considered. We say that the circuits are combinationally equivalent if the decomposition and extraction preserves the essential functionality of the combinational blocks in the circuit and does not introduce hazards. The paper's focus is the bottleneck of the verification procedure, checking whether C 2 is hazard-free. We show that C 2 is hazard-free if and only if all of its signals are monotonic and acknowledged . We then show how cubes that approximate sets of reachable circuit states can\u00a0\u2026", "num_citations": "12\n", "authors": ["1792"]}
{"title": "Linear cofactor relationships in Boolean functions\n", "abstract": " This paper describes linear cofactor relationships (LCRs), which are defined as the exclusive sums of cofactors with respect to a pair of variables in Boolean functions. These relationships subsume classical symmetries and single-variable symmetries. The paper proposes an efficient algorithm to detect LCRs and discusses their potential applications in Boolean matching, minimization of decision diagrams, synthesis of regular layout-friendly logic circuits, and detection of support-reducing bound sets", "num_citations": "11\n", "authors": ["1792"]}
{"title": "Verifying liveness properties by verifying safety properties\n", "abstract": " Conventional techniques for automatically verifying liveness properties of circuits involve explicitly modeling infinite behaviors with either infinite paths through a Kripke structure or with strings in an \u03c9-regular language. This paper describes how timed trace structures [2, 3] can be used to convert liveness properties (including unbounded liveness properties such as strong fairness) to safety properties. Such properties can then be modeled and verified using only finite traces. No new algorithms are needed. All that is required is a new interpretation of what behaviors are represented by the finite traces. A mapping is defined between timed trace structures and complete trace structures [5], which contain infinite traces, to show that this new interpretation makes sense. The method is demonstrated on a fair mutual exclusion circuit.", "num_citations": "9\n", "authors": ["1792"]}
{"title": "Modeling techniques in design-by-refinement methodologies\n", "abstract": " Embedded system design methodologies that are based on the effective use of multiple levels of abstraction hold promise for substantial productivity gains. Starting the design process at a high level of abstraction improves control over the design and facilitates verification and synthesis. In particular, if we use a rigorous approach to link the levels of abstraction, we can establish properties of lower levels from analysis at higher levels. This process goes by the name of \u201cdesign by refinement\u201d. To maximize its benefit, design by refinement requires a formal semantic foundation that supports a wide range of levels of abstraction. We introduce such a semantic foundation and describe how it can integrate several models for reactive systems.", "num_citations": "8\n", "authors": ["1792"]}
{"title": "Conservative approximations for heterogeneous design\n", "abstract": " Embedded systems are electronic devices that function in the context of a real environment, by sensing and reacting to a set of stimuli. Because of their close interaction with the environment, and to simplify their design, different parts of an embedded system are best described using different notations and different techniques. In this case, we say that the system is heterogeneous. We informally refer to the notation and the rules that are used to specify and verify the elements of heterogeneous system and their collective behavior as a model of computation. In this paper, we focus in particular on abstraction and refinement relationships in the form of conservative approximations. We do so by constructing a framework, called Agent Algebra, where the different models reside and share a common algebraic structure. We compare our techniques to the well established notion of abstract interpretation. We show that\u00a0\u2026", "num_citations": "6\n", "authors": ["1792"]}
{"title": "Notes on agent algebras\n", "abstract": " We introduce Agent Algebra as a general framework that can be used to include a wide variety of models for concurrent systems. We introduce an ordering in the algebra to represent refinement in the model, and study its relationships with respect to the operators of the algebra. In particular, we study the problem of compositionality and provide an extension of the notion of monotonic function to the case of partial functions. We then characterize the order in terms of a substitutability relation that we call conformance. We relate the conformance order for each agent to its maximally compatible agent, called the mirror. Given models for a plant, a controller and a specification, we often want to determine whether the specification is satisfied by the composition of the plant and the controller. It is also common, given a plant and a specification, to try to characterize all of the controllers that meet the above requirement. We give sufficient conditions for constructing such characterizations in the framework of Agent Algebra, including conditions to be met by the definitions of system composition and system refinement in the models.", "num_citations": "6\n", "authors": ["1792"]}
{"title": "Detecting support-reducing bound sets using two-cofactor symmetries\n", "abstract": " Detecting support-reducing bound sets is an important step in Boolean decomposition. It affects both the quality and the runtime of several applications in technology mapping and re-synthesis. This paper presents an efficient heuristic method for detecting support-reducing bound sets using two-cofactor symmetries. Experiments on the MCNC and ITC benchmarks show an average 40x speedup over the published exhaustive method for bound set construction.", "num_citations": "5\n", "authors": ["1792"]}
{"title": "Symbolic model checking: lo2\u2019states and beyond\n", "abstract": " Many different methods have been devised for automatically verifying finite state systems by examining state-graph models of system behavior. These methods all depend on decision procedures that explicitly represent a state space, using a list or a table that grows in proportion to the number of states. We describe a general method that represents the state space symbolically instead of explicitly. The generality of our method comes from using a dialect of the Mu-Calculus as the primary specification language. We describe a model checking algorithm for Mu-Calculus formulas which uses Bryant\u2019s", "num_citations": "5\n", "authors": ["1792"]}
{"title": "A comparison of strict and non-strict semantics for lists\n", "abstract": " Implementations of functional programming languages can be classi\ufb01ed according to whether they apply eager-evaluation or lazy-evaluation. Eager-evaluation gives rise to strict semantics while lazy-evaluation gives rise to non-strict semantics. In this paper we de\ufb01ne the syntax of a simple functional programming language, and specify strict and non-strict denotational semantics for that language. These semantics are speci\ufb01ed by giving axioms for the domains and semantic functions involved. The axioms for the two different semantics are very similar, differing only in the speci\ufb01cation of cans. However, this small diiference results in the domains for the two semantics being quite different. Giving axioms, rather than just postulating particular domains and semantic functions, makes more explicit the similiarities of the strict and the non-strict semantics. We give a model of the axioms of the non-strict semantics in order\u00a0\u2026", "num_citations": "1\n", "authors": ["1792"]}