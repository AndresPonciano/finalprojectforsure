{"title": "Timed automata: Semantics, algorithms and tools\n", "abstract": " This chapter is to provide a tutorial and pointers to results and related work on timed automata with a focus on semantical and algorithmic aspects of verification tools. We present the concrete and abstract semantics of timed automata (based on transition rules, regions and zones), decision problems, and algorithms for verification. A detailed description on DBM (Difference Bound Matrices) is included, which is the central data structure behind several verification tools for timed systems. As an example, we give a brief introduction to the tool Uppaal.", "num_citations": "1073\n", "authors": ["1873"]}
{"title": "CCS+ time= an interleaving model for real time systems\n", "abstract": " This paper shows how to put time into Milner's CCS to model real time systems. In particular, we will develop an expansion theorem for real time concurrency, which is an extension of the expansion theorem of CCS. The essential step made in this work is that a more general form of action prefix, \u03bc@t.P is introduced, where t is a time variable. Intuitively, \u03bc@t.P is an agent which may perform \u03bc and become P[d/t] in doing so, where t is replaced by d, the time delay before \u03bc is actually performed. The original form \u03bc.P of action prefix of CCS is just a simple case of \u03bc@t.P when t does not occur free in P \u2014 P does not depend on the time at which \u03bc is performed.", "num_citations": "287\n", "authors": ["1873"]}
{"title": "Real-time behaviour of asynchronous agents\n", "abstract": " In this paper, we present a calculus for real-time communicating systems. The calculus is an extension of Milner's CCS with explicit time. In SCCS,                                                                      means that if P exists at time r, it will proceed to Q at time r + 1. The time delay is exactly one unit. We extend this idea to asynchronous agents by allowing arbitrary delays. We write                                                                      to mean that aftert units of time, P will become Q, where \u03b5 stands for idling. Based on the notion of bisimulation, two equivalence relations over agents are defined. It has been shown that the strong equivalence is a congruence and the weak one is preserved by all operators except summation and recursion [W90]. Various examples are given to illustrate the approach.", "num_citations": "252\n", "authors": ["1873"]}
{"title": "Efficient verification of real-time systems: Compact data structure and state-space reduction\n", "abstract": " During the past few years, a number of verification tools have been developed for real-time systems in the framework of timed automata (e.g. KRONOS and UPPAAL). One of the major problems in applying these tools to industrial-size systems is the huge memory-usage for the exploration of the state-space of a network (or product) of timed automata, as the model-checkers must keep information on not only the control structure of the automata but also the clock values specified by clock constraints. In this paper, we present a compact data structure for representing clock constraints. The data structure is based on an O(n/sup 3/) algorithm which, given a constraint system over real-valued variables consisting of bounds on differences, constructs an equivalent system with a minimal number of constraints. In addition, we have developed an on-the-fly, reduction technique to minimize the space-usage. Based on static\u00a0\u2026", "num_citations": "204\n", "authors": ["1873"]}
{"title": "New response time bounds for fixed priority multiprocessor scheduling\n", "abstract": " Recently, there have been several promising techniques developed for schedulability analysis and response time analysis for multiprocessor systems based on over-approximation. This paper contains two contributions. First, to improve the analysis precision, we apply Baruah's window analysis framework to response time analysis for poradic tasks on multiprocessor systems where the deadlines of tasks are within their periods. The crucial observation is that for global fixed priority scheduling, a response time bound of each task can be efficiently estimated by fixed-point computation without enumerating all the busy window sizes as in for schedulability analysis. The technique is proven to dominate theoretically state-of-the-art techniques for response time analysis for multiprocessor systems. Our experiments also show that the technique results in significant performance improvement compared with several existing\u00a0\u2026", "num_citations": "200\n", "authors": ["1873"]}
{"title": "Compositional and Symbolic Model Checking of Real-time System\n", "abstract": " Efficient automatic model-checking algorithms for real-time systems have been obtained in recent years based on the state-region graph technique of Alur, Courcoubetis and Dill (1990). However, these algorithms are faced with two potential types of explosion arising from parallel composition: explosion in the space of control nodes, and explosion in the region space over clock-variables. In this paper we attack these explosion problems by developing and combining compositional and symbolic model-checking techniques. The presented techniques provide the foundation for a new automatic verification tool UPPAAL. Experimental results indicate that UPPAAL performs time- and space-wise favorably compared with other real-time verification tools.", "num_citations": "186\n", "authors": ["1873"]}
{"title": "Efficient timed reachability analysis using clock difference diagrams\n", "abstract": " One of the major problems in applying automatic verification tools to industrial-size systems is the excessive amount of memory required during the state-space exploration of a model. In the setting of real-time, this problem of state-explosion requires extra attention as information must be kept not only on the discrete control structure but also on the values of continuous clock variables.               In this paper, we exploit Clock Difference Diagrams, CDD\u2019s, a BDD-like data-structure for representing and effectively manipulating certain non- convex subsets of the Euclidean space, notably those encountered during verification of timed automata.               A version of the real-time verification tool Uppaal using CDD\u2019s as a compact data-structure for storing explored symbolic states has been implemented. Our experimental results demonstrate significant spacesavings: for eight industrial examples, the savings are in\u00a0\u2026", "num_citations": "176\n", "authors": ["1873"]}
{"title": "Probabilistic extensions of process algebras\n", "abstract": " In this chapter, we adopt Probabilistic Transition Systems as a basic model for probabilistic processes, in which probabilistic and nondeterministic choices are independent concepts. The model is essentially a nondeterministic version of Markov decision processes or probabilistic automata of Rabin. We develop a general framework to define probabilistic process languages to describe probabilistic transition systems. In particular, we show how operators for nonprobabilistic process algebras can be lifted to probabilistic process algebras in a uniform way similar to de Simone format. To establish a notion of refinement, we present a family of preorders including probabilistic bisimulation and simulation, and probabilistic testing pre-orders as well as their logical or denotational characterization. These preorders are shown to be precongruences with respect to the algebraic operators that can be defined in our general\u00a0\u2026", "num_citations": "173\n", "authors": ["1873"]}
{"title": "TIMES \u2014A Tool for Modelling and Implementation of Embedded Systems\n", "abstract": " T imes is a modelling and schedulability analysis tool for embedded real-time systems, developed at Uppsala University in 2001. It is appropriate for systems that can be described as a set of preemptive or non-preemptive tasks which are triggered periodically or sporadically by time or external events. It provides a graphical interface for editing and simulation, and an engine for schedulability analysis. The main features of Times are: A graphical editor for timed automata extended with tasks [1], which allows the user to model a system and the abstract behaviour of its environment In addition the user may specify a set of preemptive or non-preemtive tasks with parameters such as (relative) deadline, execution time, priority, etc. A simulator, in which the user can validate the dynamic behaviour of the system and see how the tasks execute according to the task parameters and a given scheduling policy. The simulator\u00a0\u2026", "num_citations": "170\n", "authors": ["1873"]}
{"title": "Partial order reductions for timed systems\n", "abstract": " In this paper, we present a partial-order reduction method for timed systems based on a local-time semantics for networks of timed automata. The main idea is to remove the implicit clock synchronization between processes in a network by letting local clocks in each process advance independently of clocks in other processes, and by requiring that two processes resynchronize their local time scales whenever they communicate. A symbolic version of this new semantics is developed in terms of predicate transformers, which enjoys the desired property that two predicate transformers are independent if they correspond to disjoint transitions in different processes. Thus we can apply standard partial order reduction techniques to the problem of checking reachability for timed systems, which avoid exploration of unnecessary interleavings of independent transitions. The price is that we must introduce extra\u00a0\u2026", "num_citations": "169\n", "authors": ["1873"]}
{"title": "Testing probabilistic and nondeterministic processes\n", "abstract": " In this paper, we extend Milner's CCS with a binary stochastic choice operator,\u2295 p indexed with a probability p\u2208] 0, 1 [to model probabilistic and nondeterministic processes. Intuitively, P\u2295 p Q may move to P immediately with probability p, written P\u2297 p Q\u27f6 e p P,, or to Q with probability 1\u2013p. Based on de Nicola and Hennessy's testing [NH84], a theory of testing is proposed. Given a process P and a test T, we define a notion of P can pass T with a set of probabilities \u03c6 (P, T). For non-probabilistic processes and tests (eg written in CCS), it turns out that P must satisfy T when inf {\u03c6 (P, T)}= 1 and P may satisfy T when sup {\u03c6 (P, T)}= 1, where may satisfy and must satisfy are the two satisfaction relations between processes and tests due to de Nicola and Hennessy. In terms of \u03c6 (P, T), three testing preorders are defined, which in turn generalize Nicola-Hennessy's may, must and test preorders to probabilistic and\u00a0\u2026", "num_citations": "168\n", "authors": ["1873"]}
{"title": "Cache-aware scheduling and analysis for multicores\n", "abstract": " The major obstacle to use multicores for real-time applications is that we may not predict and provide any guarantee on real-time properties of embedded software on such platforms; the way of handling the on-chip shared resources such as L2 cache may have a significant impact on the timing predictability. In this paper, we propose to use cache space isolation techniques to avoid cache contention for hard real-time tasks running on multicores with shared caches. We present a scheduling strategy for real-time tasks with both timing and cache space constraints, which allows each task to use a fixed number of cache partitions, and makes sure that at any time a cache partition is occupied by at most one running task. In this way, the cache spaces of tasks are isolated at run-time.", "num_citations": "164\n", "authors": ["1873"]}
{"title": "The digraph real-time task model\n", "abstract": " Models for real-time systems have to balance the inherently contradicting goals of expressiveness and analysis efficiency. Current task models with tractable feasibility tests have limited expressiveness, restricting their ability to model many systems accurately. In particular, they are all recurrent, preventing the modeling of structures like mode switches, local loops, etc. In this paper, we advance the state-of-the-art with a model that is free from these constraints. Our proposed task model is based on arbitrary directed graphs (digraphs) for job releases. We show that the feasibility problem on preemptive uniprocessors for our model remains tractable. This even holds in the case of task systems with arbitrary deadlines.", "num_citations": "160\n", "authors": ["1873"]}
{"title": "Timed automata as task models for event-driven systems\n", "abstract": " We extend the classic model of timed automata with a notion of real-time tasks. The main idea is to associate each discrete transition in a timed automaton with a task (an executable program). Intuitively, a discrete transition in an extended timed automaton denotes an event releasing a task and the guard on the transition specifies all the possible arrival times of the event (instead of the so-called minimal inter-arrival time). This yields a general model for hard real-time systems in which tasks may be periodic or non-periodic. We show that the schedulability problem for the extended model can be transformed into a reachability problem for standard timed automata, and thus it is decidable. This allows us to apply model-checking tools for timed automata to schedulability analysis for event-driven systems. In addition, based on the same model of a system, we may use the tools to verify other properties of the system (e.g\u00a0\u2026", "num_citations": "146\n", "authors": ["1873"]}
{"title": "Outstanding paper award: Bounding and shaping the demand of mixed-criticality sporadic tasks\n", "abstract": " We derive demand-bound functions for mixed-criticality sporadic tasks, and use these to determine EDF-schedulability. Tasks have different demand-bound functions for each criticality mode. We show how to shift execution demand from high-to low-criticality mode by tuning the relative deadlines. This allows us to shape the demand characteristics of each task. We propose an efficient algorithm for tuning all relative deadlines of a task set in order to shape the total demand to the available supply of the computing platform. Experiments indicate that this approach is significantly more powerful than previous approaches to mixed-criticality scheduling. This new approach has the added benefit of supporting hierarchical scheduling frameworks.", "num_citations": "140\n", "authors": ["1873"]}
{"title": "Combining abstract interpretation with model checking for timing analysis of multicore software\n", "abstract": " It is predicted that multicores will be increasingly used in future embedded real-time systems for high performance and low energy consumption. The major obstacle is that we may not predict and provide any guarantee on real-time properties of software on such platforms. The shared memory bus is among the most critical resources, which severely degrade the timing predictability of multicore software due to the access contention between cores. In this paper, we study a multicore architecture where each core has a local L1 cache and all cores use a shared bus to access the off-chip memory. We use Abstract Interpretation (AI) to analyze the local cache behavior of a program running on a dedicated core. Based on the cache analysis, we construct a Timed Automaton (TA) to model when the programs access the memory bus. Then we model the shared bus also using timed automata. The TA models for the bus and\u00a0\u2026", "num_citations": "136\n", "authors": ["1873"]}
{"title": "Building timing predictable embedded systems\n", "abstract": " A large class of embedded systems is distinguished from general-purpose computing systems by the need to satisfy strict requirements on timing, often under constraints on available resources. Predictable system design is concerned with the challenge of building systems for which timing requirements can be guaranteed a priori. Perhaps paradoxically, this problem has become more difficult by the introduction of performance-enhancing architectural elements, such as caches, pipelines, and multithreading, which introduce a large degree of uncertainty and make guarantees harder to provide. The intention of this article is to summarize the current state of the art in research concerning how to build predictable yet performant systems. We suggest precise definitions for the concept of \u201cpredictability\u201d, and present predictability concerns at different abstraction levels in embedded system design. First, we consider timing\u00a0\u2026", "num_citations": "133\n", "authors": ["1873"]}
{"title": "Fixed-priority multiprocessor scheduling with liu and layland's utilization bound\n", "abstract": " Liu and Layland discovered the famous utilization bound for fixed-priority scheduling on single processor systems in the 1970's. Since then, it has been a long standing open problem to find fixed-priority scheduling algorithms with the same bound for multiprocessor systems. In this paper, we present a partitioning-based fixed-priority multiprocessor scheduling algorithm with Liu and Layland's utilization bound.", "num_citations": "126\n", "authors": ["1873"]}
{"title": "Effective and efficient scheduling of certifiable mixed-criticality sporadic task systems\n", "abstract": " An increasing trend in embedded system design is to integrate components with different levels of criticality into a shared hardware platform for better cost and power efficiency. Such mixed-criticality systems are subject to certifications at different levels of rigorousness, for validating the correctness of different subsystems on various confidence levels. The real-time scheduling of certifiable mixed-criticality systems has been recognized to be a challenging problem, where using traditional scheduling techniques may result in unacceptable resource waste. In this paper we present an algorithm called PLRS to schedule certifiable mixed-criticality sporadic tasks systems. PLRS uses fixed-job-priority scheduling, and assigns job priorities by exploring and balancing the asymmetric effects between the workload on different criticality levels. Comparing with the state-of-the-art algorithm by Li and Baruah for such systems\u00a0\u2026", "num_citations": "122\n", "authors": ["1873"]}
{"title": "Clock difference diagrams\n", "abstract": " In this paper, we present Clock Di erence Diagrams, a new BDD-like data-structure for e ective representation and manipulation of certain non-convex subsets of the Euclidean space, notably those encountered in veri cation of timed automata.It is shown that all set-theoretic operations including inclusion checking may be carried out e ciently on Clock Di erence Diagrams. Other central operations needed for analysing timed automata (eg future-and reset-operations), are readily de ned using an e ectively obtained, relative normal form.", "num_citations": "117\n", "authors": ["1873"]}
{"title": "A calculus of real time systems\n", "abstract": " CiNii \u8ad6\u6587 - A Calculus of Real Time Systems CiNii \u56fd\u7acb\u60c5\u5831\u5b66\u7814\u7a76\u6240 \u5b66\u8853\u60c5\u5831\u30ca\u30d3\u30b2\u30fc\u30bf[\u30b5\u30a4\u30cb\u30a3 ] \u65e5\u672c\u306e\u8ad6\u6587\u3092\u3055\u304c\u3059 \u5927\u5b66\u56f3\u66f8\u9928\u306e\u672c\u3092\u3055\u304c\u3059 \u65e5\u672c\u306e\u535a\u58eb\u8ad6\u6587\u3092\u3055\u304c\u3059 \u65b0\u898f\u767b\u9332 \u30ed\u30b0\u30a4\u30f3 English \u691c\u7d22 \u3059\u3079\u3066 \u672c\u6587\u3042\u308a \u3059\u3079\u3066 \u672c\u6587\u3042\u308a \u9589\u3058\u308b \u30bf\u30a4\u30c8\u30eb \u8457\u8005\u540d \u8457\u8005ID \u8457\u8005\u6240\u5c5e \u520a\u884c\u7269\u540d ISSN \u5dfb\u53f7 \u30da\u30fc\u30b8 \u51fa\u7248\u8005 \u53c2\u8003\u6587\u732e \u51fa\u7248\u5e74 \u5e74\u304b\u3089 \u5e74\u307e\u3067 \u691c\u7d22 \u691c\u7d22 \u691c\u7d22 A Calculus of Real Time Systems YI W. \u88ab\u5f15\u7528\u6587\u732e: 1\u4ef6 \u8457\u8005 YI W. \u53ce\u9332\u520a\u884c\u7269 Ph. D. Thesis, Chalmers University of Technology Ph. D. Thesis, Chalmers University of Technology, 1991 \u88ab\u5f15\u7528\u6587\u732e: 1\u4ef6\u4e2d 1-1\u4ef6\u3092 \u8868\u793a 1 \u6642\u9593\u4ed8\u304d\u03c0\u8a08\u7b97\u306b\u3088\u308b\u30ea\u30a2\u30eb\u30bf\u30a4\u30e0\u30aa\u30d6\u30b8\u30a7\u30af\u30c8\u6307\u5411\u8a00\u8a9e\u306e\u5f62\u5f0f\u7684\u8a18\u8ff0 \u6851\u539f \u5bdb\u660e , \u7d50\u7e01\u7965\u6cbb , \u963f\u8349 \u6e05\u6ecb \u60c5\u5831\u51e6\u7406\u5b66\u4f1a\u8ad6\u6587\u8a8c 45(6), 1498-1507, 2004-06-15 \u53c2\u8003\u6587\u732e13\u4ef6 \u88ab\u5f15\u7528\u6587\u732e2\u4ef6 Tweet \u5404\u7a2e\u30b3\u30fc\u30c9 NII\u8ad6\u6587ID(NAID) 10013116357 \u8cc7\u6599\u7a2e\u5225 \u305d\u306e\u4ed6 \u30c7\u30fc\u30bf\u63d0\u4f9b\u5143 CJP\u5f15\u7528 \u66f8\u304d\u51fa\u3057 RefWorks\u306b\u66f8\u304d\u51fa\u3057 EndNote\u306b\u66f8\u304d\u51fa\u3057 Mendeley\u306b\u66f8\u304d\u51fa\u3057 Refer/BiblX\u3067\u8868\u793a RIS\u3067\u8868\u793a \u2026", "num_citations": "112\n", "authors": ["1873"]}
{"title": "Bounding and shaping the demand of generalized mixed-criticality sporadic task systems\n", "abstract": " We generalize the commonly used mixed-criticality sporadic task model to let all task parameters (execution-time, deadline and period) change between criticality modes. In addition, new tasks may be added in higher criticality modes and the modes may be arranged using any directed acyclic graph, where the nodes represent the different criticality modes and the edges the possible mode switches. We formulate demand bound functions for mixed-criticality sporadic tasks and use these to determine EDF-schedulability. Tasks have different demand bound functions for each criticality mode. We show how to shift execution demand between different criticality modes by tuning the relative deadlines. This allows us to shape the demand characteristics of each task. We propose efficient algorithms for tuning all relative deadlines of a task set in order to shape the total demand to the available supply of the\u00a0\u2026", "num_citations": "107\n", "authors": ["1873"]}
{"title": "Autodietary: A wearable acoustic sensor system for food intake recognition in daily life\n", "abstract": " Nutrition-related diseases are nowadays a main threat to human health and pose great challenges to medical care. A crucial step to solve the problems is to monitor the daily food intake of a person precisely and conveniently. For this purpose, we present AutoDietary, a wearable system to monitor and recognize food intakes in daily life. An embedded hardware prototype is developed to collect food intake sensor data, which is highlighted by a high-fidelity microphone worn on the subject's neck to precisely record acoustic signals during eating in a noninvasive manner. The acoustic data are preprocessed and then sent to a smartphone via Bluetooth, where food types are recognized. In particular, we use hidden Markov models to identify chewing or swallowing events, which are then processed to extract their time/frequency-domain and nonlinear features. A lightweight decision-tree-based algorithm is adopted to\u00a0\u2026", "num_citations": "102\n", "authors": ["1873"]}
{"title": "Time abstracted bisimulation: Implicit specifications and decidability\n", "abstract": " In the last few years a number of real-time process calculi have emerged with the purpose of capturing important quantitative aspects of real-time systems. In addition, a number of process equivalences sensitive to time-quantities have been proposed, among these the notion of timed (bisimulation) equivalence in [RR86, DS89, HR91, BB89, NRSV90, MT90, Wan91b].             In this paper, we introduce a time-abstracting (bisimulation) equivalence, and investigate its properties with respect to the real-time process calculus of [Wan90]. Seemingly, such an equivalence would yield very little information (if any) about the timing properties of a process. However, time-abstracted reasoning about a composite process may yield important information about the relative timing-properties of the components of the system. In fact, we show as a main theorem that such implicit reasoning will reveal all timing aspects of a\u00a0\u2026", "num_citations": "89\n", "authors": ["1873"]}
{"title": "Energy-efficient scheduling of real-time tasks on cluster-based multicores\n", "abstract": " While much work has addressed the energy-efficient scheduling problem for uniprocessor or multiprocessor systems, little has been done for multicore systems. We study the multicore architecture with a fixed number of cores partitioned into clusters (or islands), on each of which all cores operate at a common frequency. We develop algorithms to determine a schedule for real-time tasks to minimize the energy consumption under the timing and operating frequency constraints. As technical contributions, we first show that the optimal frequencies resulting in the minimum energy consumption for each island is not dependent on the workload mapped but the number of cores and leakage power on the island, when not considering the timing constraint. Then for systems with timing constraints, we present a polynomial algorithm which derives the minimum energy consumption for a given task partition. Finally, we\u00a0\u2026", "num_citations": "80\n", "authors": ["1873"]}
{"title": "Uppaal\n", "abstract": " Verifikation af realtids systemer i UPPAAL Page 1 UCb Verifikation af realtids systemer i UPPAAL Kim G. Larsen BRICS@Aalborg Page 2 2 MII\u2019\u20192001 Kim G. Larsen UCb Research Profile Distributed Systems & Semantics Unit Semantic Models concurrency, mobility, objects real-time, hybrid systems Validation & Verification algorithms & tools Construction real-time & network systems Page 3 3 MII\u2019\u20192001 Kim G. Larsen UCb BRICS Machine Basic Research in Computer Science 30+40+40 Millkr 100 100 Aalborg Aarhus Tools Other revelvant projects UPPAAL, VHS, VVS, WOODDES Page 4 4 MII\u2019\u20192001 Kim G. Larsen UCb Tools and BRICS Logic \u2022 Temporal Logic \u2022 Modal Logic \u2022 MSOL \u2022 \u2022 Algorithmic \u2022 (Timed) Automata Theory \u2022 Graph Theory \u2022 BDDs \u2022 Polyhedra Manipulation \u2022 \u2022 Semantics \u2022 Concurrency Theory \u2022 Abstract Interpretation \u2022 Compositionality \u2022 Models for real-time & hybrid systems \u2022 \u2022 HOL TLP Applications \u2026", "num_citations": "79\n", "authors": ["1873"]}
{"title": "Compositional testing preorders for probabilistic processes\n", "abstract": " Transitions systems are well established as a semantic model for distributed systems. There are widely accepted preorders that serve as criteria for refinement of a more abstract transition system to a more concrete one. To reason about probabilistic phenomena such as failure rates, we need to extend models and methods that have proven successful for nonprobabilistic systems to a probabilistic setting. We consider a model of probabilistic transition systems, containing probabilistic choice and nondeterministic choice as independent concepts. We present a notion of testing for these systems. Our main contributions are denotational characterizations of the testing preorders. The characterizations are given in terms of chains for may testing and refusal chains for must testing, that are analogous to traces and failures in denotational models of CSP. Refinement corresponds to inclusion between chains and refusal\u00a0\u2026", "num_citations": "77\n", "authors": ["1873"]}
{"title": "Testing preorders for probabilistic processes can be characterized by simulations\n", "abstract": " Transition systems are well established as a semantic model for distributed systems. There are several preorders that serve as criteria for refinement of an abstract transition system to a more concrete one. To reason about probabilistic phenomena such as failures and randomization, we need to extend models and methods that have proven successful for nonprobabilistic systems to a probabilistic setting. In this paper, we develop a refinement preorder for a probabilistic extension of the transition systems model. The preorder is based on a notion of testing, where refinement corresponds to an improvement in the \u201cworst-case\u201d behavior of a process. The main result of the paper is that this preorder can be described by a notion of probabilistic simulation, which generalizes the standard simulation preorder for ordinary transition system. To our knowledge, this simulation preorder has not been previously described in the\u00a0\u2026", "num_citations": "75\n", "authors": ["1873"]}
{"title": "Timed vs. time-triggered automata\n", "abstract": " To establish a semantic foundation for the synthesis of executable programs from timed models, we study in what sense the timed language (i.e. sequences of events with real-valued time-stamps) of a timed automaton is recognized by a digital machine. Based on the non-instant observability of events, we propose an alternative semantics for timed automata. We show that the new semantics gives rise to a natural notion of digitalization for timed languages. As a model for digital machines we use time-triggered automata \u2013 a subclass of timed automata with simplified syntax accepting digitalized timed languages. A time-triggered automaton is essentially a time table for a digital machine (or a digital controller), describing what the machine should do at a given time point, and it can be easily transformed to an executable program. Finally, we present a method to check whether a time-triggered automaton\u00a0\u2026", "num_citations": "68\n", "authors": ["1873"]}
{"title": "Decidable and undecidable problems in schedulability analysis using timed automata\n", "abstract": " We study schedulability problems of timed systems with non-uniformly recurring computation tasks. Assume a set of real time tasks whose best and worst execution times, and deadlines are known. We use timed automata to describe the arrival patterns (and release times) of tasks. From the literature, it is known that the schedulability problem for a large class of such systems is decidable and can be checked efficiently.               In this paper, we provide a summary on what is decidable and what is undecidable in schedulability analysis using timed automata. Our main technical contribution is that the schedulability problem will be undecidable if these three conditions hold: (1) the execution times of tasks are intervals, (2) a task can announce its completion time, and (3) a task can preempt another task. We show that if one of the above three conditions is dropped, the problem will be decidable. Thus our result\u00a0\u2026", "num_citations": "68\n", "authors": ["1873"]}
{"title": "New schedulability test conditions for non-preemptive scheduling on multiprocessor platforms\n", "abstract": " We study the schedulability analysis problem for nonpreemptive scheduling algorithms on multiprocessors. To our best knowledge, the only known work on this problem is the test condition proposed by Baruah for non-preemptive EDF scheduling, which will reject a task set with arbitrarily low utilization if it contains a task whose execution time is equal or greater than the minimal relative deadline among all tasks. In this paper, we firstly derive a linear-time test condition which avoids the problem mentioned above, by building upon previous work for preemptive multiprocessor scheduling. This test condition works on not only non-preemptive EDF, but also any other work-conserving non-preemptive scheduling algorithms. Then we improve the analysis and present test conditions of pseudo-polynomial time-complexity for Non-preemptive Earliest Deadline First scheduling and Non-preemptive Fixed Priority scheduling\u00a0\u2026", "num_citations": "66\n", "authors": ["1873"]}
{"title": "Cyclic dependencies in modular performance analysis\n", "abstract": " The Modular Performance Analysis based on Real-Time Calculus (MPA-RTC), developed by Thiele et al., is an abstraction for the analysis of component-based real-time systems. The formalism uses an abstract stream model to characterize both workload and availability of computation and communication resources. Components can then be viewed as stream transformers. The Real-Time Calculus has been used successfully on systems where dependencies between components, via either workload or resource streams, are acyclic. For systems with cyclic dependencies the foundations and performance of the formalism are less well understood.", "num_citations": "64\n", "authors": ["1873"]}
{"title": "Time-abstracted bisimulation: Implicit specifications and decidability\n", "abstract": " In the last few years a number of real-time process calculi have emerged with the purpose of capturing important quantitative aspects of real-time systems. In addition, a number of process equivalences sensitive to time-quantities have been proposed, among these the notion of timed (bisimulation) equivalence. In this paper, we introduce atime-abstracting(bisimulation) equivalence and investigate its properties with respect to the real-time process calculus of Wang (Real-time behaviour of asynchronous agents,in\u201cProceedings of CONCUR90,\u201d Lecture Notes in Computer Science, Vol. 458, Springer-Verlag, Berlin/New York, 1990). Seemingly, such an equivalence would yield very little information (if any) about the timing properties of a process. However, time-abstracted reasoning about a composite process may yield important information about the relative timing-properties of the components of the system. In fact\u00a0\u2026", "num_citations": "62\n", "authors": ["1873"]}
{"title": "Noninvasive and continuous blood pressure monitoring using wearable body sensor networks\n", "abstract": " Hypertension is a major health risk that influences the quality of life for many people. The importance of monitoring hypertension in a continuous and noninvasive manner increases as more people experience raised blood pressure (BP). The authors present a smartphone-centric body sensor network to measure the pulse transit time (PTT) in real time. Their robust method for calculating BP uses PPT information that considers the baroreflex mechanism, which reflects the relationship between BP and the heart rate. To evaluate the performance of their proposed method, they collected 300 groups of data from six subjects before and after exercise. Experimental results show that their proposed method can estimate BP values in real time with good precision.", "num_citations": "61\n", "authors": ["1873"]}
{"title": "Model-based validation of QoS properties of biomedical sensor networks\n", "abstract": " A Biomedical Sensor Network (BSN) is a small-size sensor network for medical applications, that may contain tens of sensor nodes. In this paper, we present a formal model for BSNs using timed automata, where the sensor nodes communicate using the Chipcon CC2420 transceiver (developed by Texas Instruments) according to the IEEE 802.15. 4 standard. Based on the model, we have used UPPAAL to validate and tune the temporal configuration parameters of a BSN in order to meet desired QoS requirements on network connectivity, packet delivery ratio and end-to-end delay. The network studied allows dynamic reconfigurations of the network topology due to the temporally switching of sensor nodes to power-down mode for energy-saving or their physical movements. Both the simulator and model-checker of UPPAAL are used to analyze the average-case and worst-case behaviors. To enhance the\u00a0\u2026", "num_citations": "60\n", "authors": ["1873"]}
{"title": "A survey on static cache analysis for real-time systems\n", "abstract": " Real-time systems are reactive computer systems that must produce their reaction to a stimulus within given time bounds. A vital verification requirement is to estimate the Worst-Case Execution Time (WCET) of programs. These estimates are then used to predict the timing behavior of the overall system. The execution time of a program heavily depends on the underlying hardware, among which cache has the biggest influence. Analyzing cache behavior is very challenging due to the versatile cache features and complex execution environment. This article provides a survey on static cache analysis for real-time systems. We first present the challenges and static analysis techniques for independent programs with respect to different cache features. Then, the discussion is extended to cache analysis in complex execution environment, followed by a survey of existing tools based on static techniques for cache analysis. An outlook for future research is provided at last.", "num_citations": "59\n", "authors": ["1873"]}
{"title": "Graph-based models for real-time workload: a survey\n", "abstract": " This paper provides a survey on task models to characterize real-time workloads at different levels of abstraction for the design and analysis of real-time systems. It covers the classic periodic and sporadic models by Liu and Layland et al., their extensions to describe recurring and branching structures as well as general graph- and automata-based models to allow modeling of complex structures such as mode switches, local loops and also global timing constraints. The focus is on the precise semantics of the various models and on the solutions and complexity results of the respective feasibilty and schedulability analysis problems for preemptable uniprocessors.", "num_citations": "57\n", "authors": ["1873"]}
{"title": "Semi-federated scheduling of parallel real-time tasks on multiprocessors\n", "abstract": " Federated scheduling is a promising approach to schedule parallel real-time tasks on multi-cores, where each heavy task exclusively executes on a number of dedicated processors, while light tasks are treated as sequential sporadic tasks and share the remaining processors. However, federated scheduling suffers resource waste since a heavy task with processing capacity requirement x+epsilon (where x is an integer and 0 epsilon 1) needs x+1 dedicated processors. In the extreme case, almost half of the processing capacity is wasted. In this paper we propose the semi-federate scheduling approach, which only grants x dedicated processors to a heavy task with processing capacity requirement x+epsilon, and schedules the remaining epsilon part together with light tasks on shared processors. Experiments with randomly generated task sets show the semi-federated scheduling approach significantly outperforms\u00a0\u2026", "num_citations": "54\n", "authors": ["1873"]}
{"title": "EDF-VD scheduling of mixed-criticality systems with degraded quality guarantees\n", "abstract": " This paper studies real-time scheduling of mixed-criticality systems where low-criticality tasks are still guaranteed some service in the high-criticality mode, with reduced execution budgets. First, we present a utilization-based schedulability test for such systems under EDF-VD scheduling. Second, we quantify the suboptimality of EDF-VD (with our test condition) in terms of speedup factors. In general, the speedup factor is a function with respect to the ratio between the amount of resource required by different types of tasks in different criticality modes, and reaches 4/3 in the worst case. Furthermore, we show that the proposed utilization-based schedulability test and speedup factor results apply to the elastic mixed-criticality model as well. Experiments show effectiveness of our proposed method and confirm the theoretical suboptimality results.", "num_citations": "54\n", "authors": ["1873"]}
{"title": "Schedulability analysis for non-preemptive fixed-priority multiprocessor scheduling\n", "abstract": " Non-preemptive scheduling is usually considered inferior to preemptive scheduling for time critical systems, because the non-preemptive block would lead to poor task responsiveness. Although this is true in single-processor scheduling, we found by empirical simulation experiments that it is not necessarily the case in multiprocessor scheduling. Additionally, non-preemptive scheduling enjoys other benefits like lower implementation complexity and run-time overhead. So non-preemptive scheduling may be a better alternative compared to preemptive scheduling for a considerable part of real-time applications on multiprocessor/multi-core platforms.As the technical contribution, we study the schedulability analysis problem of global non-preemptive fixed-priority scheduling (NP-FP) on multiprocessors. We propose schedulability test conditions for NP-FP, building upon the \u201cproblem window analysis\u201d by Baruah [8] for\u00a0\u2026", "num_citations": "53\n", "authors": ["1873"]}
{"title": "WCET analysis with MRU cache: challenging LRU for predictability\n", "abstract": " Most previous work on cache analysis for WCET estimation assumes a particular replacement policy called LRU. In contrast, much less work has been done for non-LRU policies, since they are generally considered to be very unpredictable. However, most commercial processors are actually equipped with these non-LRU policies, since they are more efficient in terms of hardware cost, power consumption and thermal output, while still maintaining almost as good average-case performance as LRU. In this work, we study the analysis of MRU, a non-LRU replacement policy employed in mainstream processor architectures like Intel Nehalem. Our work shows that the predictability of MRU has been significantly underestimated before, mainly because the existing cache analysis techniques and metrics do not match MRU well. As our main technical contribution, we propose a new cache hit/miss classification, k-Miss, to\u00a0\u2026", "num_citations": "48\n", "authors": ["1873"]}
{"title": "Deciding properties of regular real timed processes\n", "abstract": " We discuss the decidability problem associated with verifying properties of processes expressed in the real time process calculus TCCS of [W90], A regular subcalculus TC of TCCS is considered. Two operational semantics, and associated timed notions of bisimulation, are given: a standard infinite semantics, and a symbolic finite semantics. The consistency between the two semantics is proved. We show that both the equivalences are decidable for regular processes relative to comparisons between real numbers.             As an alternative specification formalism, we present a timed modal logic. It turns out that this logic characterises timed bisimulation equivalence in the sense that equivalent processes enjoy exactly the same properties expressed within the logic. Moreover, we prove that the problem of deciding whether a given regular real timed process satisfies a given property of the logic is decidable\u00a0\u2026", "num_citations": "47\n", "authors": ["1873"]}
{"title": "Processing moving k NN queries using influential neighbor sets\n", "abstract": " The moving k nearest neighbor query, which computes one's k nearest neighbor set and maintains it while at move, is gaining importance due to the prevalent use of smart mobile devices such as smart phones. Safe region is a popular technique in processing the moving k nearest neighbor query. It is a region where the movement of the query object does not cause the current k nearest neighbor set to change. Processing a moving k nearest neighbor query is a continuing process of checking the validity of the safe region and recomputing it if invalidated. The size of the safe region largely decides the frequency of safe region recomputation and hence query processing efficiency. Existing moving k nearest neighbor algorithms lack efficiency due to either computing small safe regions and have to recompute frequently or computing large safe regions (i.e., an order-k Voronoi cell) with a high cost. In this paper, we take\u00a0\u2026", "num_citations": "43\n", "authors": ["1873"]}
{"title": "On clock difference constraints and termination in reachability analysis of timed automata\n", "abstract": " The key step to guarantee termination of reachability analysis for timed automata is the normalisation algorithms for clock constraints i.e. zones represented as DBM\u2019s (Difference Bound Matrices). It transforms DBM\u2019s which may contain arbitrarily large integers (the source of non-termination) into their equivalent according to the maximal constants of clocks appearing in the input timed automaton to be analysed. Surprisingly, though the zones of a timed automaton are essentially difference constraints in the form of x-y~n, as shown in this paper, it is a non-trivial task to normalise the zones of timed automata that allows difference constraints in the enabling conditions (i.e. guards) on transitions. In fact, the existing normalisation algorithms implemented in tools such as Kronos and Uppaal can only handle timed automata (as input) allowing simple constraints in the form of x~n. For a long time, this has been a\u00a0\u2026", "num_citations": "42\n", "authors": ["1873"]}
{"title": "Combinatorial abstraction refinement for feasibility analysis\n", "abstract": " The traditional periodic workload model for hard real-time systems has been extended by more expressive models in recent years. These models based on different classes of directed graphs allow modeling of structures like frames, branching and loops. With more expressiveness comes higher complexity of the associated analysis problems. Feasibility of digraph-based models with dynamic priority schedulers has been shown to be tractable via pseudo-polynomial algorithms. However, the problem was shown to be intractable for static priority scheduling since it is strongly coNP-hard already for the relatively simple class of cyclic digraphs. The core of this problem is an inherent combinatorial explosion caused by combining different behaviors of the participating tasks, lacking local worst cases. We introduce a novel iterative approach to efficiently cope with this combinatorial explosion, called combinatorial\u00a0\u2026", "num_citations": "37\n", "authors": ["1873"]}
{"title": "Communicating timed automata: the more synchronous, the more difficult to verify\n", "abstract": " We study channel systems whose behaviour (sending and receiving messages via unbounded FIFO channels) must follow given timing constraints specifying the execution speeds of the local components. We propose Communicating Timed Automata (CTA) to model such systems. The goal is to study the borderline between decidable and undecidable classes of channel systems in the timed setting. Our technical results include: (1) CTA with one channel without shared states in the form (A                         1,A                         2, c                         1,2) is equivalent to one-counter machine, implying that verification problems such as checking state reachability and channel boundedness are decidable, and (2) CTA with two channels without sharing states in the form (A                         1,A                         2,A                         3, c                         1,2,c                         2,3) has the power of Turing machines. Note that in the untimed\u00a0\u2026", "num_citations": "37\n", "authors": ["1873"]}
{"title": "Multi-feature fusion for thermal face recognition\n", "abstract": " Human face recognition has been researched for the last three decades. Face recognition with thermal images now attracts significant attention since they can be used in low/none illuminated environment. However, thermal face recognition performance is still insufficient for practical applications. One main reason is that most existing work leverage only single feature to characterize a face in a thermal image. To solve the problem, we propose multi-feature fusion, a technique that combines multiple features in thermal face characterization and recognition. In this work, we designed a systematical way to combine four features, including Local binary pattern, Gabor jet descriptor, Weber local descriptor and Down-sampling feature. Experimental results show that our approach outperforms methods that leverage only a single feature and is robust to noise, occlusion, expression, low resolution and different l 1\u00a0\u2026", "num_citations": "35\n", "authors": ["1873"]}
{"title": "Fifo cache analysis for wcet estimation: A quantitative approach\n", "abstract": " Although most previous work in cache analysis for WCET estimation assumes the LRU replacement policy, in practise more processors use simpler non-LRU policies for lower cost, power consumption and thermal output. This paper focuses on the analysis of FIFO, one of the most widely used cache replacement policies. Previous analysis techniques for FIFO caches are based on the same framework as for LRU caches using qualitative always-hit/always-miss classifications. This approach, though works well for LRU caches, is not suitable to analyze FIFO and usually leads to poor WCET estimation quality. In this paper, we propose a quantitative approach for FIFO cache analysis. Roughly speaking, the proposed quantitative analysis derives an upper bound on the \u201cmiss ratio\u201d of an instruction (set), which can better capture the FIFO cache behavior and support more accurate WCET estimations. Experiments with\u00a0\u2026", "num_citations": "35\n", "authors": ["1873"]}
{"title": "Real-time scheduling and analysis of OpenMP task systems with tied tasks\n", "abstract": " OpenMP is a promising framework for developing parallel real-time software on multi-cores. Although similar to the DAG task model, OpenMP task systems are significantly more difficult to analyze due to constraints posed by the OpenMP specification. An important feature in OpenMP is tied tasks, which must execute on the same thread during the whole life cycle. Although tied tasks enjoy benefits in simplicity and efficiency, it was considered to be not suitable to real-time systems due to its complex behavior. In this paper, we study the realtime scheduling and analysis of OpenMP task systems with tied tasks. First, we show that under the existing scheduling algorithms in OpenMP, tied tasks indeed may lead to extremely bad timing behaviors where the parallel workload is sequentially executed completely. To solve this problem, we proposed a new scheduling algorithm and developed two response time bounds for it\u00a0\u2026", "num_citations": "34\n", "authors": ["1873"]}
{"title": "Partitioned mixed-criticality scheduling on multiprocessor platforms\n", "abstract": " Scheduling mixed-criticality systems that integrate multiple functionalities with different criticality levels into a shared platform appears to be a challenging problem, even on single-processor platforms. Multi-core processors are more and more widely used in embedded systems, which provide great computing capacities for such mixed-criticality systems. In this paper, we propose a partitioned scheduling algorithm MPVD to extend the state-of-the-art single-processor mixed-criticality scheduling algorithm EY to multiprocessor platforms. The key idea of MPVD is to evenly allocate tasks with different criticality levels to different processors, in order to better explore the asymmetry between different criticality levels and improve the system schedulability. Then we propose two enhancements to further improve the schedulability of MPVD. Experiments with randomly generated task sets show significant performance\u00a0\u2026", "num_citations": "34\n", "authors": ["1873"]}
{"title": "On the tractability of digraph-based task models\n", "abstract": " In formal analysis of real-time systems, a major concern is the analysis efficiency. As the expressiveness of models grows, so grows the complexity of their analysis. A recently proposed model, the digraph real-time task model (DRT), offers high expressiveness well beyond traditional periodic task models. Still, the associated feasibility problem on preemptive uniprocessors remains tractable. It is an open question to what extent the expressiveness of the model can be further increased before the feasibility problem becomes intractable. In this paper, we study that tractability border. We show that system models with the need for global timing constraints make feasibility analysis intractable. However, our second technical result shows that it remains tractable if the number of global constraints is bounded by a constant. Thus, this paper establishes a precise borderline between tractability and intractability.", "num_citations": "34\n", "authors": ["1873"]}
{"title": "On the consensus mechanisms of blockchain/dlt for internet of things\n", "abstract": " Internet of Things (IoT) has been experiencing exponential growth in recent years, but still faces many serious challenges. The distributed ledger technology (DLT), e.g., Blockchain, not only appears to be promising to address these technical challenges, but also brings tremendous opportunities for new application and business models. However, the convergence of IoT and DLT is yet a goal far beyond our reach today. Among many problems that have not been sufficiently understood, a fundamental one is how to design appropriate consensus mechanisms for DLT applied to IoT, which is the theme of this paper. We first discuss the potential benefits of applying DLT to IoT, and identify major challenges posed to DLT by IoT. Then we make a survey of existing DLT consensus mechanisms, to summarize major principles and discuss their pros and cons when applied in IoT.", "num_citations": "33\n", "authors": ["1873"]}
{"title": "Improving the response time analysis of global fixed-priority multiprocessor scheduling\n", "abstract": " In this paper we address the problem of schedulability analysis for a set of sporadic tasks with arbitrary deadlines running on a multiprocessor system with global fixed-priority preemptive scheduling. We prove the existence of a class of critical instants for releasing a task, one of which results in the worst-case response time of that task. Then, we propose a new analysis that improves over current state-of-the-art Response Time Analysis (RTA) by reducing its pessimism. We also observe that, in the case of unconstrained deadlines, the current RTA may underestimate the carry-in workload, and we propose a new formulation that corrects the problem. Finally, we evaluate the performance improvement of our new response time analysis method by empirical experiments with randomly generated task sets. Experimental results show that our new analysis method can successfully accept a considerable amount of task\u00a0\u2026", "num_citations": "33\n", "authors": ["1873"]}
{"title": "Multi-processor schedulability analysis of preemptive real-time tasks with variable execution times\n", "abstract": " In this paper, we study schedulability analysis problems for multi-processor real-time systems. Assume a set of real-time tasks whose execution times and deadlines are known. We use timed automata to describe the non-deterministic arrival times of tasks. The schedulability problem is to check whether the released task instances can be executed within their given deadlines on a multi-processor platform where each processor has a task queue to buffer task instances scheduled to run on the processor. On the positive side, we show that the problem is decidable for systems with non-preemptive schedulers or tasks with fixed execution times. A surprising negative result is that for multi-processor systems with variable task execution times and a preemptive scheduler, the schedulability analysis problem is undecidable, which is still an open problem in the single-processor setting.", "num_citations": "32\n", "authors": ["1873"]}
{"title": "Hardness results for static priority real-time scheduling\n", "abstract": " Real-time systems are often modeled as a collection of tasks, describing the structure of the processor's workload. In the literature, task-models of different expressiveness have been developed, ranging from the traditional periodic task model to highly expressive graph-based models. For dynamic priority schedulers, it has been shown that the schedulability problem can be solved efficiently, even for graph-based models. However, the situation is less clear for the case of static priority schedulers. It has been believed that the problem can be solved in pseudo-polynomial time for the generalized multiframe model (GMF). The GMF model constitutes a compromise in expressiveness by allowing cycling through a static list of behaviors, but disallowing branching. Further, the problem complexity for more expressive models has been unknown so far. In this paper, we show that previous results claiming that a precise and\u00a0\u2026", "num_citations": "26\n", "authors": ["1873"]}
{"title": "Utilization-based scheduling of flexible mixed-criticality real-time tasks\n", "abstract": " Mixed-criticality models are an emerging paradigm for the design of real-time systems because of their significantly improved resource efficiency. However, formal mixed-criticality models have traditionally been characterized by two impractical assumptions: once any high-criticality task overruns, all low-criticality tasks are suspended and all other high-criticality tasks are assumed to exhibit high-criticality behaviors at the same time. In this paper, we propose a more realistic mixed-criticality model, called the flexible mixed-criticality (FMC) model, in which these two issues are addressed in a combined manner. In this new model, only the overrun task itself is assumed to exhibit high-criticality behavior, while other high-criticality tasks remain in the same mode as before. The guaranteed service levels of low-criticality tasks are gracefully degraded with the overruns of high-criticality tasks. We derive a utilization-based\u00a0\u2026", "num_citations": "24\n", "authors": ["1873"]}
{"title": "Finitary real-time calculus: Efficient performance analysis of distributed embedded systems\n", "abstract": " Real-Time Calculus (RTC) is a powerful framework to analyze real-time performance of distributed embedded systems. However, RTC may run into serious analysis efficiency problems when applied to systems of large scale and/or with complex timing parameter characteristics. The main reason is that many RTC operations generate curves with periods equal to the hyper-period of the input curves. Therefore, the analysis in RTC has exponential complexity. In practise the curve periods may explode rapidly when several components are serially connected, which leads to low analysis efficiency. In this work, we propose Finitary RTC to solve the above problem. Finitary RTC only maintains and operates on a limited part of each curve that is relevant to the final analysis results, which results in pseudo-polynomial computational complexity. Experiments show that Finitary RTC can drastically improve the analysis\u00a0\u2026", "num_citations": "23\n", "authors": ["1873"]}
{"title": "Minimizing multi-resource energy for real-time systems with discrete operation modes\n", "abstract": " Energy conservation is an important issue in the design of embedded systems. Dynamic Voltage Scaling (DVS) and Dynamic Power Management (DPM) are two widely used techniques for saving energy in such systems. In this paper, we address the problem of minimizing multi-resource energy consumption concerning both CPU and devices. A system is assumed to contain a fixed number of real-time tasks scheduled to run on a DVS-enabled processor, and a fixed number of off-chip devices used by the tasks during their executions. We will study the non-trivial time and energy overhead of device state transitions between active and sleep states. Our goal is to find optimal schedules providing not only the execution order and CPU frequencies of tasks, but also the time points for device state transitions. We adopt the frame-based real-time task model, and develop optimization algorithms based on 0-1 Integer Non\u00a0\u2026", "num_citations": "23\n", "authors": ["1873"]}
{"title": "Combinatorial abstraction refinement for feasibility analysis of static priorities\n", "abstract": " Combinatorial explosion is a challenge for many analysis problems in the theory of hard real-time systems. One of these problems is static priority schedulability of workload models which are more expressive than the traditional periodic task model. Different classes of directed graphs have been proposed in recent years to model structures like frames, branching and loops. In contrast to dynamic priority schedulers with pseudo-polynomial time analysis methods, static priority schedulability has been shown to be intractable since it is strongly coNP-hard already for the relatively simple class of cyclic digraphs. The core of this problem is the necessity to combine different behaviors of the participating tasks.               We introduce a novel iterative approach to efficiently cope with this combinatorial explosion, called combinatorial abstraction refinement. In combination with other techniques it significantly reduces\u00a0\u2026", "num_citations": "22\n", "authors": ["1873"]}
{"title": "Uniprocessor feasibility of sporadic tasks with constrained deadlines is strongly coNP-Complete\n", "abstract": " Deciding the feasibility of a sporadic task system on a preemptive uniprocessor is a central problem in real-time scheduling theory. The computational complexity of this problem has been a long-standing open question. We show that it is coNP-complete in the strong sense, even when deadlines are constrained. This is achieved by means of a pseudo-polynomial transformation from the strongly NP-hard Simultaneous Congruences Problem to the complement of the feasibility problem.", "num_citations": "21\n", "authors": ["1873"]}
{"title": "General and efficient response time analysis for EDF scheduling\n", "abstract": " Response Time Analysis (RTA) is one of the key problems in real-time system design. This paper proposes new RTA methods for EDF scheduling, with general system models where workload and resource availability are represented by request/demand bound functions and supply bound functions. The main idea is to derive response time upper bounds by lower-bounding the slack times. We first present a simple over-approximate RTA method, which lower bounds the slack time by measuring the \u201chorizontal distance\u201d between the demand bound function and the supply bound function. Then we present an exact RTA method based on the above idea but eliminating the pessimism in the first analysis. This new exact RTA method, not only allows to precisely analyze more general system models than existing EDF RTA techniques, but also significantly improves analysis efficiency. Experiments are conducted to show\u00a0\u2026", "num_citations": "20\n", "authors": ["1873"]}
{"title": "Refinement of workload models for engine controllers by state space partitioning\n", "abstract": " We study an engine control application where the behavior of engine controllers depends on the engine's rotational speed. For efficient and precise timing analysis, we use the Digraph Real-Time (DRT) task model to specify the workload of control tasks where we employ optimal control theory to faithfully calculate the respective minimum inter-release times. We show how DRT models can be refined by finer grained partitioning of the state space of the engine up to a model which enables an exact timing analysis. Compared to previously proposed methods which are either unsafe or pessimistic, our work provides both abstract and tight characterizations of the corresponding workload.", "num_citations": "19\n", "authors": ["1873"]}
{"title": "Schedulability analysis of synchronous digraph real-time tasks\n", "abstract": " Real-time task models have evolved from periodic models to more sophisticated graph-based ones like the Digraph Real Time task model (DRT) to specify branching and loop structures of real-time embedded software. For independent DRT tasks, efficient techniques for schedulability analysis have been developed in previous work. In this paper, we extend the DRT model to specify inter-task synchronization through a rendezvous mechanism. We present an abstraction technique for static priority schedulability analysis of the corresponding tasks. Our experiments show that, despite the high computational complexity of the problem, the proposed technique scales very well for large sets of dependent tasks.", "num_citations": "19\n", "authors": ["1873"]}
{"title": "Feasibility of fork-join real-time task graph models: Hardness and algorithms\n", "abstract": " In the formal analysis of real-time systems, modeling of branching codes and modeling of intratask parallelism structures are two of the most important research topics. These two real-time properties are combined, resulting in the fork-join real-time task (FJRT) model, which extends the digraph-based task model with forking and joining semantics. We prove that the EDF schedulability problem on a preemptive uniprocessor for the FJRT model is coNP-hard in the strong sense, even if the utilization of the task system is bounded by a constant strictly less than 1. Then, we show that the problem becomes tractable with some slight structural restrictions on parallel sections, for which we propose an exact schedulability test with pseudo-polynomial time complexity. Our results thus establish a borderline between the tractable and intractable FJRT models.", "num_citations": "19\n", "authors": ["1873"]}
{"title": "Schedulability analysis of a graph-based task model for mixed-criticality systems\n", "abstract": " We present a new graph-based real-time task model that can specify complex job arrival patterns and global state-based mode switching. The mode switching is of a mixed-criticality style, meaning that it allows immediate changes to the parameters of active jobs upon mode switches. The resulting task model generalizes previously proposed task graph models as well as mixed-criticality (sporadic) task models; the merging of these mutually incomparable modeling paradigms allows formulation of new types of tasks. A sufficient schedulability analysis for EDF on preemptive uniprocessors is developed for the proposed model.", "num_citations": "19\n", "authors": ["1873"]}
{"title": "Approximate response time analysis of real-time task graphs\n", "abstract": " The response time analysis problem is intractable for most existing real-time task models, except the simplest ones. Exact solutions for this problem in general have exponential complexity, and may run into scalability problems for large-scale task systems. In this paper, we study approximate analysis for static-priority scheduling of the Digraph Real-Time task model, which is a generalization of most existing graph-based real-time task models. We present two approximate analysis methods RBF and IBF, both of which have pseudo-polynomial complexity. We quantitatively evaluate their analysis precision using the metric speedup factor. We prove that RBF has a speedup factor of 2, and this is tight even for dual-task systems. The speedup factor of IBF is an increasing function with respect to k, the number of interfering tasks. This function converges to 2 as k approaches infinity and equals 1 when k = 1, implying that\u00a0\u2026", "num_citations": "19\n", "authors": ["1873"]}
{"title": "Algebraic reasoning for real-time probabilistic processes with uncertain information\n", "abstract": " In this paper, we study behaviour descriptions with uncertain information such as \u201cthe probability of a system failure within a given time period is less than or equal to 0.3\u201d in terms of process algebras. Typical systems that may show such behaviours include communicating systems with unreliable components, e.g. faulty medium. We present a process model for such behaviours, in which uncertain information is described by means of intervals of probabilities. In particular, we introduce a stochastic choice operator                                                                      [\u03a6 i] E i, where \u03a6 i's are intervals of probabilities. Roughly speaking, it is a process which may become E i in one unit of time with a probability within the interval \u03a6 i. Such a process is considered as a specification specifying a set of processes with less uncertain information. We develop a notion of probabilistic simulation to order specifications in terms of the\u00a0\u2026", "num_citations": "19\n", "authors": ["1873"]}
{"title": "Scheduling analysis of imprecise mixed-criticality real-time tasks\n", "abstract": " In this paper, we study the scheduling problem of the imprecise mixed-criticality model (IMC) under earliest deadline first with virtual deadline (EDF-VD) scheduling upon uniprocessor systems. Two schedulability tests are presented. The first test is a concise utilization-based test which can be applied to the implicit deadline IMC task set. The suboptimality of the proposed utilization-based test is evaluated via a widely-used scheduling metric, speedup factors. The second test is a more effective test but with higher complexity which is based on the concept of demand bound function (DBF). The proposed DBF-based test is more generic and can apply to constrained deadline IMC task set. Moreover, in order to address the high time cost of the existing deadline tuning algorithm, we propose a novel algorithm which significantly improve the efficiency of the deadline tuning procedure. Experimental results show the\u00a0\u2026", "num_citations": "18\n", "authors": ["1873"]}
{"title": "Efficient drone hijacking detection using onboard motion sensors\n", "abstract": " The fast growth of civil drones raises significant security challenges. A legitimate drone may be hijacked by GPS spoofing for illegal activities, such as terrorist attacks. The target of this paper is to develop techniques to let drones detect whether they have been hijacked using onboard motion sensors (accelerometers and gyroscopes). Ideally, the linear acceleration and angular velocity measured by motion sensors can be used to estimate the position of a drone, which can be compared with the position reported by GPS to detect whether the drone has been hijacked. However, the position estimation by motion sensors is very inaccurate due to the significant error accumulation over time. In this paper, we propose a novel method to detect hijacking based on motion sensors measurements and GPS, which overcomes the accumulative error problem. The computational complexity of our method is very low, and thus is\u00a0\u2026", "num_citations": "18\n", "authors": ["1873"]}
{"title": "Horn clauses for communicating timed systems\n", "abstract": " Languages based on the theory of timed automata are a well established approach for modelling and analysing real-time systems, with many applications both in industrial and academic context. Model checking for timed automata has been studied extensively during the last two decades; however, even now industrial-grade model checkers are available only for few timed automata dialects (in particular Uppaal timed automata), exhibit limited scalability for systems with large discrete state space, or cannot handle parametrised systems. We explore the use of Horn constraints and off-the-shelf model checkers for analysis of networks of timed automata. The resulting analysis method is fully symbolic and applicable to systems with large or infinite discrete state space, and can be extended to include various language features, for instance Uppaal-style communication/broadcast channels and BIP-style interactions, and systems with infinite parallelism. Experiments demonstrate the feasibility of the method.", "num_citations": "18\n", "authors": ["1873"]}
{"title": "Fixed-priority multiprocessor scheduling: Critical instant, response time and utilization bound\n", "abstract": " The rapid development of multi-core processors leads to a constantly increasing trend of deploying real-time systems on multi-core platforms, to satisfy the dramatically increasing high-performance and low-power requirements. This trend demands effective and efficient multiprocessor real-time scheduling techniques. The uniprocessor scheduling problem has been well studied during the last 40 years. However the multiprocessor scheduling problem to map tasks onto parallel architectures is a much harder challenge. In this work, we study several fundamental problems in multiprocessor scheduling, namely the critical instant, bounded responsiveness, and utilization bound.", "num_citations": "18\n", "authors": ["1873"]}
{"title": "Resource sharing protocols for real-time task graph systems\n", "abstract": " Previous works on real-time task graph models have ignored the crucial resource sharing problem. Due to the non-deterministic branching behavior, resource sharing in graph-based task models is significantly more difficult than in the simple periodic or sporadic task models. In this work we address this problem with several different scheduling strategies, and quantitatively evaluate their performance. We first show that a direct application of the well-known EDF+SRP strategy to graph-based task models leads to an unbounded speedup factor. By slightly modifying EDF+SRP, we obtain a new scheduling strategy, called EDF+saSRP, which has a speedup factor of 2. Then we propose a novel resource sharing protocol, called ACP, to better manage resource sharing in the presence of branching structures. The scheduling strategy EDF+ACP, which applies ACP to EDF, can achieve a speedup factor of 1.618, the\u00a0\u2026", "num_citations": "18\n", "authors": ["1873"]}
{"title": "Reducing memory usage in symbolic state-space exploration for timed systems\n", "abstract": " One of the major problems to scale up model checking techniques to the size of industrial systems is the large memory consumption. This report address the problem in the context of verifiers for timed systems and present a number of techniques that reduce the amount memory used for state space exploration in such a tool. The methods are evaluated and compared by reallife examples and their strengths and weaknesses are described. In particular we adress the memory consumption problem on two fronts, first by reducing the size of each symbolic state by means of compression and second by reducing the size of the stored state space by early inclusion checking and probabilistic methods.", "num_citations": "18\n", "authors": ["1873"]}
{"title": "Refinement-based exact response-time analysis\n", "abstract": " A recent trend in the theory of real-time scheduling is to consider generalizations of the classical periodic task model. Work on the associated schedulability and feasibility problems has resulted in algorithms that run efficiently and provide exact results. While these analyses give black-and-white answers about whether timing constraints are being met or not, response-time analysis adds a quantitative dimension. This brings new challenges for models more expressive than the classical periodic task model. An exact quantification of response time is difficult because of non-deterministic task behavior and a lack of combinable task-local worst cases. Therefore, previous approaches all make a trade-off between efficiency and precision, resulting in either prohibitively slow analysis run-times or imprecise over-approximate results. In this paper, we show that analysis can be both exact and efficient at the same time. We\u00a0\u2026", "num_citations": "17\n", "authors": ["1873"]}
{"title": "Wcet analysis of the mc/os-ii real-time kernel\n", "abstract": " Worst-case execution time (WCET) analysis is one of the major tasks in timing validation of hard real-time systems. In complex systems with real-time operating systems (RTOS), the timing properties of the system are decided by both the applications and the RTOS. Traditionally, WCET analysis mainly deals with application programs, while it is crucial to know whether the RTOS also behaves in a timely predictable manner. In this paper, we present a case study where static analysis is used to predict the WCET of the system calls of the uC/OS-II real-time kernel. To our knowledge, this paper is the first to present quantitative results on the real-time performance of uC/OS-II. The precision of applying existing WCET analysis techniques on RTOS code is evaluated, and the practical difficulties in using static methods in timing analysis of RTOS are also reported.", "num_citations": "17\n", "authors": ["1873"]}
{"title": "Benchmarking OpenMP programs for real-time scheduling\n", "abstract": " Real-time systems are shifting from single-core to multi-core processors. Software must be parallelized to fully utilize the computation power of multi-core architecture. OpenMP is a popular parallel programming framework in general and high-performance computing, and recently has drawn a lot of interests in embedded and real-time computing. Much recent work has been done on real-time scheduling of OpenMP-based parallel workload. However, these studies conduct evaluations with randomly generated task systems, which cannot well represent the structure features of OpenMP workload. This paper presents a benchmark suite, ompTGB, to support research on real-time scheduling of OpenMP-based parallel tasks. ompTGB does not only collect realistic OpenMP programs, but also models them into task graphs so that the real-time scheduling researchers can easily understand and use them. We also present\u00a0\u2026", "num_citations": "16\n", "authors": ["1873"]}
{"title": "Generalized finitary real-time calculus\n", "abstract": " Real-time Calculus (RTC) is a non-stochastic queuing theory to the worst-case performance analysis of distributed real-time systems. Workload as well as resources are modelled as piece-wise linear, pseudo-periodic curves and the system under investigation is modelled as a sequence of algebraic operations over these curves. The memory footprint of computed curves increases exponentially with the sequence of operations and RTC may become computationally infeasible fast. Recently, Finitary RTC has been proposed to counteract this problem. Finitary RTC restricts curves to finite input domains and thereby counteracts the memory demand explosion seen with pseudo periodic curves of common RTC implementations. However, the proof to the correctness of Finitary RTC specifically exploits the operational semantic of the greed processing component (GPC) model and is tied to the maximum busy window\u00a0\u2026", "num_citations": "16\n", "authors": ["1873"]}
{"title": "Dynamic budgeting for settling dram contention of co-running hard and soft real-time tasks\n", "abstract": " In modern non-customized multicore architectures, computing cores commonly share large parts of the memory hierarchy. This paper presents a scheme for controlling the sharing of main memory among cores, respectively the concurrently executing real-time tasks. This is important for the following: concurrent memory accesses are served sequentially by the memory controller. As task execution stalls until memory fetches are served, the latter significantly contributes to the execution time of the tasks. With multiple real-time tasks concurrently competing for the access to the memory, the main memory can easily become the Achilles heel for the timing correctness of the tasks. To provide hard timing guarantees, release of access requests issued to the main memory has therefore to be controlled. Run-time budgeting is a well accepted technique for controlling and coordinating the use of a shared resource, particularly\u00a0\u2026", "num_citations": "16\n", "authors": ["1873"]}
{"title": "Parametric utilization bounds for fixed-priority multiprocessor scheduling\n", "abstract": " Future embedded real-time systems will be deployed on multi-core processors to meet the dramatically increasing high-performance and low-power requirements. This trend appeals to generalize established results on uniprocessor scheduling, particularly the various utilization bounds for schedulability test used in system design, to the multiprocessor setting. Recently, this has been achieved for the famous Liu and Lay land utilization bound by applying novel task splitting techniques. However, parametric utilization bounds that can guarantee higher utilizations (up to 100%) for common classes of systems are not yet known to be generalizable to multiprocessors as well. In this paper, we solve this problem for most parametric utilization bounds by proposing new task partitioning algorithms based on exact response time analysis. In addition to the worst-case guarantees, as the exact response time analysis is used\u00a0\u2026", "num_citations": "16\n", "authors": ["1873"]}
{"title": "An efficient uav hijacking detection method using onboard inertial measurement unit\n", "abstract": " With the fast growth of civil drones, their security problems meet significant challenges. A commercial drone may be hijacked by a GPS-spoofing attack for illegal activities, such as terrorist attacks. The target of this article is to develop a technique that only uses onboard gyroscopes to determine whether a drone has been hijacked. Ideally, GPS data and the angular velocities measured by gyroscopes can be used to estimate the acceleration of a drone, which can be further compared with the measurement of the accelerometer to detect whether a drone has been hijacked. However, the detection results may not always be accurate due to some calculation and measurement errors, especially when no hijacking occurs in curve trajectory situations. To overcome this, in this article, we propose a novel and simple method to detect hijacking only based on gyroscopes\u2019 measurements and GPS data, without using any\u00a0\u2026", "num_citations": "15\n", "authors": ["1873"]}
{"title": "An optimal resource sharing protocol for generalized multiframe tasks\n", "abstract": " Many different task models of varying expressiveness have been proposed to capture the timing constraints of real-time workloads. However, techniques for optimal scheduling and exact feasibility analysis of systems with mutually-exclusive shared resources have been available only for relatively simple task models, such as the sporadic task model. We consider sharing of mutually-exclusive resources in task models that are more expressive in terms of the job-release patterns that can be modeled. We propose a new scheduling algorithm and show that it is optimal for scheduling generalized multiframe tasks with shared resources on uniprocessor systems. We also present an efficient feasibility test for such systems, and show that it is both sufficient and necessary.", "num_citations": "15\n", "authors": ["1873"]}
{"title": "On the analysis of EDF-VD scheduled mixed-criticality real-time systems\n", "abstract": " Real-time embedded systems usually integrate multiple functionalities of different criticality levels on a shared hardware platform. For these mixed-criticality real-time systems it is a challenging problem to efficiently utilize system resource to satisfy all the timing constraints on different criticality levels. A simple yet efficient algorithm EDF-VD has recently been proposed to schedule mixed-criticality real-time systems, and shown promising real-time performance. However, the competency of EDF-VD has not been fully exploited due to the imprecise underlying analysis techniques. In this paper, we develop new schedulability analysis methods for EDF-VD. Different from previous analysis methods that separate the analysis on each individual criticality level, our new analysis looks into system behavior crossing multiple criticality levels to obtain more precisely analysis results. Experiments show that our new analysis\u00a0\u2026", "num_citations": "15\n", "authors": ["1873"]}
{"title": "Improving the scheduling of certifiable mixed-criticality sporadic task systems\n", "abstract": " An increasing trend in embedded system design is to integrate components with different levels of criticality into a shared hardware platform for better cost and power efficiency. Such mixed-criticality systems are subject to certifications at different levels of rigorousness, for validating the correctness of different subsystems on various confidence levels. The realtime scheduling of certifiable mixed-criticality systems has been recognized to be a challenging problem, where using traditional scheduling techniques may result in unacceptable resource waste. In this paper we present an algorithm called PLRS to schedule certifiable mixed-criticality sporadic tasks systems. PLRS uses fixed-job-priority scheduling, and assigns job priorities by exploring and balancing the asymmetric effects between the workload on different criticality levels. Comparing with the state-of-the-art algorithm by Li and Baruah for such systems, which we refer to as LB, PLRS is both more effective and more efficient:(i) The schedulability test of PLRS not only theoretically dominates, but also on average significantly outperforms LB\u2019s.(ii) The run-time complexity of PLRS is polynomial (quadratic in the number of tasks), which is much more efficient than the pseudo-polynomial run-time complexity of LB.", "num_citations": "15\n", "authors": ["1873"]}
{"title": "Axiomatising timed automata\n", "abstract": " Timed automata has been developed as a basic semantic model for real time systems. Its algorithmic aspects for automated analysis have been well studied. But so far there is still no satisfactory algebraic theory to allow the derivation of semantical equivalence of automata by purely syntactical manipulation. The aim of this paper is to provide such a theory. We present an inference system of timed bisimulation equivalence for timed automata based on a CCS-style regular language for describing timed automata. It consists of the standard monoid laws for bisimulation and a set of inference rules. The judgments of the proof system are conditional equations of the form  $\\phi \\rhd t = u$ where   is a clock constraint and t,u are terms denoting timed automata. The inference system is shown to be sound and complete for timed bisimulation. The proof of the completeness result relies on the notion of symbolic\u00a0\u2026", "num_citations": "15\n", "authors": ["1873"]}
{"title": "Bounding carry-in interference to improve fixed-priority global multiprocessor scheduling analysis\n", "abstract": " The analysis of global multiprocessor scheduling is more difficult than its uniprocessor counterpart. Due to the unknown critical instant, existing techniques use over-approximations of task interference for efficient yet pessimistic analysis. In this paper, we proposed a new technique to improve the precision of interference estimation. The key is to identify and resolve contradicting assumptions made in the analysis procedure. The resulting new analysis method improves the analysis precision at the price of a higher complexity. Then we introduce techniques to optimize the new method for better efficiency. Experiments with randomly generated task sets are conducted to evaluate both the precision and efficiency of the proposed new method.", "num_citations": "14\n", "authors": ["1873"]}
{"title": "Improving OCBP-based scheduling for mixed-criticality sporadic task systems\n", "abstract": " Scheduling mixed-criticality systems is a challenging problem. Recently a number of new techniques are developed to schedule such systems, among which an approach called OCBP has shown interesting properties and drawn considerable attentions. OCBP explores the job-level priority order in a very flexible manner to drastically improve the system schedulability. However, the job priority exploration in OCBP involves nontrivial overheads. In this work, we propose a new algorithm LPA (Lazy Priority Adjustment) based on the OCBP approach, which improves the state-of-the-art OCBP-based scheduling algorithm PLRS in both schedulability and run-time efficiency. Firstly, while the time-complexity of PLRS' online priority management is quadratic, our new algorithm LPA has linear time-complexity at run-time. Secondly, we present an approach to calculate tighter upper bounds of the busy period size, and thereby\u00a0\u2026", "num_citations": "14\n", "authors": ["1873"]}
{"title": "Fixed-priority schedulability of sporadic tasks on uniprocessors is np-hard\n", "abstract": " We study the computational complexity of the FP-schedulability problem for sporadic or synchronous periodic tasks on a preemptive uniprocessor. We show that this problem is (weakly) NP-hard, even when restricted to either (i) task sets with implicit deadlines and rate-monotonic priority ordering, or (ii) task sets with constrained deadlines, deadline-monotonic priority ordering and utilization bounded by any constant c, such that 0 <; c <; 1.", "num_citations": "13\n", "authors": ["1873"]}
{"title": "Speed planning for solar-powered electric vehicles\n", "abstract": " Electric vehicles (EVs) are the trend for future transportation. The major obstacle is range anxiety due to poor availability of charging stations and long charging time. Solar-powered EVs, which mostly rely on solar energy, are free of charging limitations. However, the range anxiety problem is more severe due to the availability of sun light. For example, shadings of buildings or trees may cause a solar-powered EV to stop halfway in a trip. In this paper, we show that by optimally planning the speed on different road segments and thus balancing energy harvesting and consumption, we can enable a solar-powered EV to successfully reach the destination using the shortest travel time. The speed planning problem is essentially a constrained non-linear programming problem, which is generally difficult to solve. We have identified an optimality property that allows us to compute an optimal speed assignment for a partition\u00a0\u2026", "num_citations": "12\n", "authors": ["1873"]}
{"title": "Uniprocessor feasibility of sporadic tasks remains coNP-complete under bounded utilization\n", "abstract": " A central problem in real-time scheduling theory is to decide whether a sporadic task system with constrained deadlines is feasible on a preemptive uniprocessor. It is known that this problem is strongly coNP-complete in the general case, but also that there exists a pseudo-polynomial time solution for instances with utilization bounded from above by any constant c, where 0 <; c <; 1. For a long time it has been unknown whether the bounded case also has a polynomial-time solution. We show that for any choice of the constant c, such that 0 <; c <; 1, the bounded feasibility problem is (weakly) coNP-complete, and thus that no polynomial-time solution exists for it, unless P = NP.", "num_citations": "12\n", "authors": ["1873"]}
{"title": "Efficient instruction cache analysis with model checking\n", "abstract": " Cache analysis is one of the major tasks of static timing analysis. There are very efficient techniques based on abstract interpretation for the analysis of the cache replacement policy LRU. It is known that these techniques can not deal with cache replacement polices such as PLRU and FIFO with satisfactory precision. On the other hand, model checking technique may provide precise analysis results for these polices, but it doesn\u2019t scale due to the search space of the analysis problem. In this paper, we identify a class of programs for which are able to reduce the branching structure of the programs without changing their WCET. The reduction technique allows to significantly reduce the state space of a program and thus model checking technique can be used for efficient WCET analysis with adequate precision. As an example, we focus on the FIFO replacement policy, but the technique can be extended to handle the\u00a0\u2026", "num_citations": "12\n", "authors": ["1873"]}
{"title": "Modeling and analysis of thread-pools in an industrial communication platform\n", "abstract": " Thread pools are often used as a pattern to increase the throughput and responsiveness of software systems. Implementations of thread pools may differ considerably from each other, which urges the need to analyze these differences in a formal manner. We use an object-oriented paradigm to model different thread pools in the context of the ASK system, an industrial communication platform. We use behavioral interfaces, high-level behavioral specifications for the objects, as a starting-point for analysis. Based on these behavioral interfaces, functional aspects are modeled in Creol, a high-level modeling language for concurrent objects. We use Uppaal to create real-time models and to perform schedulability analysis with respect to the behavioral interfaces. We finally check conformance between the real-time and Creol models using test-cases generated from the behavioral interfaces.", "num_citations": "12\n", "authors": ["1873"]}
{"title": "Improving scalability of model-checking for minimizing buffer requirements of synchronous dataflow graphs\n", "abstract": " Synchronous dataflow (SDF) is a well-known model of computation for dataflow-oriented applications such as embedded systems for signal processing and multimedia. It is important to minimize the buffer size requirements of applications generated from SDF graphs, since memory space is often a scarce resource in these systems due to cost or power consumption constraints. Some authors have proposed to use model-checking for finding the minimum buffer size requirements, but the scalability of model-checking is limited by state space explosion. In this paper, we present several techniques for reducing state space size and improving scalability of model-checking by exploiting problem-specific properties of SDF graphs.", "num_citations": "12\n", "authors": ["1873"]}
{"title": "An optimal approach to hardware/software partitioning for synchronous model\n", "abstract": " Computer aided hardware/software partitioning is one of the key challenges in hardware/software co-design. This paper describes a new approach to hardware/software partitioning for synchronous communication model. We transform the partitioning into a reachability problem of timed automata. By means of an optimal reachability algorithm, an optimal solution can be obtained in terms of limited resources in hardware. To relax the initial condition of the partitioning for optimization, two algorithms are designed to explore the dependency relations among processes in the sequential specification. Moreover, we propose a scheduling algorithm to improve the synchronous communication efficiency further after partitioning stage. Some experiments are conducted with model checker UPPAAL to show our approach is both effective and efficient.", "num_citations": "12\n", "authors": ["1873"]}
{"title": "Energy-efficient scheduling for parallel real-time tasks based on level-packing\n", "abstract": " While much work has addressed energy-efficient scheduling for sequential tasks where each task can run on only one processor at a time, little work has been done for parallel tasks where an individual task can be executed by multiple processors simultaneously. In this paper, we develop energy minimizing algorithms for parallel task systems with timing guarantees. For parallel tasks executed by a fixed number of processors, we first propose several heuristic algorithms based on level-packing for task scheduling, and then present a polynomial-time complexity energy minimizing algorithm which is optimal for any given level-packed task schedule. For parallel tasks that can run on a variable number of processors, we propose another polynomial-time complexity algorithm to determine the number of processors executing each task, task schedule and frequency assignment. To the best of our knowledge, this is the\u00a0\u2026", "num_citations": "11\n", "authors": ["1873"]}
{"title": "A tool for compositional analysis of timed systems by abstraction\n", "abstract": " We present a tool for compositional timing and performance analysis of real-time systems modeled using timed automata and the real-time calculus [5]. It is based on an (over-) approximation technique in which a timed automaton is abstracted as a transducer of abstract streams described by arrival curves from network calculus [2]. As the main feature, the tool can be used to check the schedulability of a system and to estimate the best and worst case response times of its computation tasks. The tool is available for evaluation at www. timestool. com/cats.", "num_citations": "11\n", "authors": ["1873"]}
{"title": "Verifying temporal constraints on data in multi-rate transactions using timed automata\n", "abstract": " Transactions involving multiple tasks, possibly with different period times, are common constructs used in the design of real-time systems. Data flowing through a transaction is usually subject to temporal constraints, such as maximum time from input to output or a maximum time difference between inputs. Such constraints are of great importance to guarantee the correct functioning of the designed system, but normally they cannot be checked using the traditional approach to schedulability analysis. We describe how to use timed automata and reachability analysis to verify such temporal constraints on data in transactions. By making a timed automaton model of the data dependencies in a transaction, we enable automatic verification of timing constraints such as end-to-end latency. The model can handle different computational models and any non-preemptive execution order of the tasks in the transaction. Our\u00a0\u2026", "num_citations": "11\n", "authors": ["1873"]}
{"title": "A capacity augmentation bound for real-time constrained-deadline parallel tasks under gedf\n", "abstract": " Capacity augmentation bound is a widely used quantitative metric in theoretical studies of schedulability analysis for directed acyclic graph (DAG) parallel real-time tasks, which not only quantifies the suboptimality of the scheduling algorithms, but also serves as a simple linear-time schedulability test. Earlier studies on capacity augmentation bounds of the sporadic DAG task model were either restricted to a single DAG task or a set of tasks with implicit deadlines. In this paper, we consider parallel tasks with constrained deadlines under global earliest deadline first policy. We first show that it is impossible to obtain a constant bound for our problem setting, and derive both lower and upper bounds of the capacity augmentation bound as a function with respect to the maximum ratio of task period to deadline. Our upper bound is at most 1.47 times larger than the optimal one. We conduct experiments to compare the\u00a0\u2026", "num_citations": "10\n", "authors": ["1873"]}
{"title": "Pervasive eating habits monitoring and recognition through a wearable acoustic sensor\n", "abstract": " Eating habits provide clinical diagnosis evidences of lifestyle related diseases, such as dysphagia and indigestion. However, it is costly to obtain eating habit information of common people in terms of both time and expenses. This paper presents a pervasive approach for eating habit monitoring and recognition by a necklace-like device and a smartphone communicating via bluetooth. The necklace-like device acquires acoustic signals from the throat, and the data are processed in the smartphone to recognize important features. With complex acoustic signals collected from the throat, our method comprehensively analyzes and recognizes different events including chewing, swallowing, and breathing in the smartphone. Experiments show that the proposed approach can recognize different acoustic events effectively, and the recognition accuracy with K-Nearest Neighbor (KNN) and Support Vector Machine (SVM) is\u00a0\u2026", "num_citations": "10\n", "authors": ["1873"]}
{"title": "McAiT\u2013A Timing Analyzer for Multicore Real-Time Software\n", "abstract": " We present McAiT, a tool for estimating the Worst-Case Execution Times (WCET) of programs running on multicore processors. The highlight of McAiT is that it leverages timed automata to model both the timing behaviors of the programs\u2019 interaction with its environment (based on the results of local cache analysis by abstract interpretation) and a broad range of on-chip shared resources, such as shared buses and shared caches. McAiT also allows for modeling complex task models, such as synchronization, jitter, etc. High analysis precision is achieved by the McAiT approach, which is demonstrated by extensive experiments. The tool also supports the classical Implicit Path Enumeration Technique (IPET) combined with worst-case shared resource access delay for WCET estimation, to provide the users with the flexibility to trade analysis precision for efficiency.", "num_citations": "10\n", "authors": ["1873"]}
{"title": "Worst-case cause-effect reaction latency in systems with non-blocking communication\n", "abstract": " In real-time embedded systems, a system functionality is often implemented using a data-flow chain over a set of communicating tasks. A critical non-functional requirement in such systems is to restrict the amount of time, i.e. cause-effect latency, for an input to impact its corresponding output. The problem of estimating the worst-case cause-effect latency is well-studied in the context of blocking inter-task communication. Recent research results show that non-blocking communication preserving functional semantics is critical for the model-based design of dynamically updatable systems. In this paper, we study the worst-case cause-effect reaction latency estimation problem in the context of non-blocking inter-task communication. We present a computationally efficient algorithm that tightly over-approximates the exact worst-case reaction latency in cause-effect data-flow chains.", "num_citations": "9\n", "authors": ["1873"]}
{"title": "Start time configuration for strictly periodic real-time task systems\n", "abstract": " In many digital control systems, it is required to perform computation in a strictly periodic fashion to provide high control performance. System designers need to assign time slots that are infinitely repeated given a strict period for each task such that the time slots of different tasks do not overlap. While previous work has studied how to decide if a system is schedulable with a certain time slot assignment, it is still an unexplored area of how to select time slots for strictly periodic tasks to make them schedulable. In this paper, we propose an efficient method to solve the above problem. Our method explores the relations among task periods to improve the possibility of finding feasible start time configurations. Finally, we conduct experiments with randomly generated workload to evaluate the performance of the proposed method.", "num_citations": "9\n", "authors": ["1873"]}
{"title": "Understanding the dynamic caches on intel processors: Methods and applications\n", "abstract": " The design and implementation of caches on a given platform has significant impacts to many areas in computer system design. On chip-multiprocessors (CMP), new cache architectures are proposed to meet the rapidly increasing performance requirements. However, the cache architectures are usually not well-documented for commercial processors. This raises difficulties for people to precisely understand the working principle of many components of the processors, not only the cache itself, but also the related components like the whole memory subsystem. This paper aims at disclosing the working principle of the last level cache of Intel Ivy Bridge processors. First, we identify the address translation logic on this cache. Second, we disclose the replacement policy of the cache. This is a dynamic insertion replacement policy, which is very different from the widely used LRU policy and its variants. Although this\u00a0\u2026", "num_citations": "9\n", "authors": ["1873"]}
{"title": "Implementation and empirical comparison of partitioning-based multi-core scheduling\n", "abstract": " Recent theoretical studies have shown that partitioning-based scheduling has better real-time performance than other scheduling paradigms like global scheduling on multi-cores. Especially, a class of partitioning-based scheduling algorithms (called semi-partitioned scheduling), which allow to split a small number of tasks among different cores, offer very high resource utilization. The major concern about the semi-partitioned scheduling is that due to the task splitting, some tasks will migrate from one core to another at run time, which incurs higher context switch overhead. So one would suspect whether the extra overhead caused by task splitting would counteract the theoretical performance gain of semi-partitioned scheduling. In this work, we implement a semi-partitioned scheduler in the Linux operating system, and run experiments on an Intel Core-i7 4-cores machine to measure the real overhead in both\u00a0\u2026", "num_citations": "9\n", "authors": ["1873"]}
{"title": "Sampled universality of timed automata\n", "abstract": " Timed automata can be studied in not only a dense-time setting but also a discrete-time setting. The most common example of discrete-time semantics is the so called sampled semantics (i.e., discrete semantics with a fixed time granularity \u03b5). In the real-time setting, the universality problem is known to be undecidable for timed automata. In this work, we study the universality question for the languages accepted by timed automata with sampled semantics. On the negative side, we show that deciding whether for all sampling periods \u03b5 a timed automaton accepts all timed words in \u03b5-sampled semantics is as hard as in the real-time case, i.e., undecidable. On the positive side, we show that checking whether there is a sampling period such that a timed automaton accepts all untimed words in \u03b5-sampled semantics is decidable. Our proof uses clock difference relations, developed to characterize the reachability\u00a0\u2026", "num_citations": "9\n", "authors": ["1873"]}
{"title": "Leaking your engine speed by spectrum analysis of real-Time scheduling sequences\n", "abstract": " This paper identifies and studies a new security/privacy issue for automobile vehicles. Specifically, attackers can infer the engine speed of a vehicle by observing and analyzing the real-time scheduling sequences on the Engine Control Unit (ECU). First, we present the problem model of engine-triggered task executed on ECU. And then, we introduce two Engine-triggered Task Period Tracing methods (DFT-based ETPT and FRSP-based ETPT) to infer the period variation of engine-triggered task. Finally, simulation experiments are conducted to demonstrate the effect of this new timing side-channel information leakage with our proposed methods.", "num_citations": "8\n", "authors": ["1873"]}
{"title": "On fixed-priority schedulability analysis of sporadic tasks with self-suspension\n", "abstract": " We consider the schedulability analysis problem of a set of sporadic tasks which are subject to self-suspension, using a fixed-priority scheduler on a preemptive uniprocessor. We show that this problem is coNP-hard in the strong sense even in the simple case when only the lowest-priority task is self-suspending. Also, it is shown that the problem is weakly coNP-hard even if that self-suspending task has only a single suspension interval. In addition, we propose an efficient method for schedulability analysis of self-suspending tasks that are subject to interference from higher-priority tasks without self-suspension. The method works on the basis of an iterative approach which begins with an abstraction of the task set and improves the analysis results by refinement steps as needed. Our evaluation shows that this method significantly improves the scalability of the existing approaches.", "num_citations": "8\n", "authors": ["1873"]}
{"title": "A proof system for timed automata\n", "abstract": " A proof system for timed automata is presented, based on a CCS-style language for describing timed automata. It consists of the standard monoid laws for bisimulation and a set of inference rules. The judgments of the proof system are conditional equations of the form \u03c6 \u22b3 t = u where \u03c6 is a clock constraint and t, u are terms denoting timed automata. It is proved that the proof system is complete for timed bisimulation over the recursion-free subset of the language. The completeness proof relies on the notion of symbolic timed bisimulation. The axiomatisation is also extended to handle an important variation of timed automata where each node is associated with an invariant constraint.", "num_citations": "8\n", "authors": ["1873"]}
{"title": "Decidability of timed language-inclusion for networks of real-time communicating sequential processes\n", "abstract": " An important verification problem for concurrent systems in general is that of establishing whether one system is a correct implementation, or refinement, of another system. For untimed systems, trace inclusion (or variants such as failure inclusion) is often used as a criterion of refinement. The natural extension of this criterion to timed systems is timed trace-inclusion. Unfortunately, this problem is undecidable for the commonly used model of timed automata (i.e. finite-state automata extended with clocks) due to the expressive power of the model. This is a serious obstacle to the application of automatic verification methods to timed automata. In this paper, we show that the problem of timed trace-inclusion is decidable for a large and natural class of processes in Reed and Roscoe's Timed CSP [RR86]. Essentially, this class includes static networks of processes with finite-control structure and real-valued clocks\u00a0\u2026", "num_citations": "8\n", "authors": ["1873"]}
{"title": "Fault-tolerant real-time tasks scheduling with dynamic fault handling\n", "abstract": " Predictable performance when coping with transient failures is of paramount importance in safety-critical real-time systems. Various software fault-tolerant techniques are employed towards this goal among which check-pointing is a relatively cost-effective scheme. In this paper, we propose an efficient fault-tolerant scheduling framework with run-time fault handling protocol, where criticality levels can be adaptively inserted for fault handling according to run-time fault workload. In contrast to prior works which apply with task re-execution strategy, the proposed framework adaptively determines on-demand re-executions only on the faulty checkpoint segments, rather than on the whole job. Towards this, a unified overrun handling protocol is developed to handle fault recovery adaptively to avoid over-provisioning of resources. In addition, we develop an off-line schedulability analysis technique for the proposed\u00a0\u2026", "num_citations": "7\n", "authors": ["1873"]}
{"title": "Towards customizable cps: Composability, efficiency and predictability\n", "abstract": " Today, many industrial products are defined by software, and therefore customizable by installing new applications on demand - their functionalities are implemented by software and can be modified and extended by software updates. This trend towards customizable products is extending into all domains of IT, including Cyber-Physical Systems (CPS) such as cars, robotics, and medical devices. However, these systems are often highly safety-critical. The current state-of-practice allows hardly any modifications once safety-critical systems are put in operation. This is due to the lack of techniques to preserve crucial safety conditions for the modified system, which severely restricts the benefits of software.                 This work aims at new paradigms and technologies for the design and safe software updates of CPS at operation-time \u2013 subject to stringent timing constraints, dynamic workloads, and limited\u00a0\u2026", "num_citations": "7\n", "authors": ["1873"]}
{"title": "Scalable timing analysis with refinement\n", "abstract": " Traditional timing analysis techniques rely on composing system-level worst-case behavior with local worst-case behaviors of individual components. In many complex real-time systems, no single local worst-case behavior exists for each component and it generally requires to enumerate all the combinations of individual local behaviors to find the global worst case. This paper presents a scalable timing analysis technique based on abstraction refinement, which provides effective guidance to significantly prune away state space and quickly verify the desired timing properties. We first establish the general framework of the method, and then apply it to solve the analysis problem for several different real-time task models.", "num_citations": "7\n", "authors": ["1873"]}
{"title": "The fork-join real-time task model\n", "abstract": " Hard real-time task models have evolved from periodic models to more sophisticated graph-based ones like the Digraph Real-Time Task Model (DRT) [1]. These models have in common that tasks are sequential in nature and do not allow for forking structures, modeling job releases that occur in parallel within the same task. To capture these, we present a task model that extends the DRT model with the possibility of forking and joining release paths. We are developing an exact schedulability test for EDF on uniprocessor systems with a pseudo-polynomial bound of its runtime.", "num_citations": "7\n", "authors": ["1873"]}
{"title": "On the analysis of parallel real-time tasks with spin locks\n", "abstract": " Locking protocol is an essential component in resource management of real-time systems, which coordinates mutually exclusive accesses to shared resources from different tasks. Although the design and analysis of locking protocols have been intensively studied for sequential real-time tasks, there has been a little work on this topic for parallel real-time tasks. In this article, we study the analysis of parallel real-time tasks using spin locks to protect accesses to shared resources in three commonly used request serving orders (unordered, FIFO-order, and priority-order). A remarkable feature making our analysis method more accurate is to systematically analyze the blocking time which may delay a task's finishing time, where the impact to the total workload and the longest path length is jointly considered, rather than analyzing them separately and counting all blocking time as the workload that delays a task's finishing\u00a0\u2026", "num_citations": "6\n", "authors": ["1873"]}
{"title": "Efficient drone hijacking detection using two-step GA-XGBoost\n", "abstract": " With the fast growth of civilian drones, their security problems meet significant challenges. A commercial drone may be hijacked by Global Positioning System (GPS)-spoofing attacks for illegal activities, such as terrorist attacks. Ideally, comparing positions respectively estimated by GPS and Inertial Navigation System (INS) can detect such attacks, while the results may always get fault because of the accumulated errors over time in INS. Therefore, in this paper, we propose a two-step GA-XGBoost method to detect GPS-spoofing attacks that just uses GPS and Inertial Measurement Unit (IMU) data. However, tunning the proper values of XGBoost parameters directly on the drone to achieve high prediction results consumes lots of resources which would influence the real-time performance of the drone. The proposed method separates the training phase into offboard step and onboard step. In offboard step, model is\u00a0\u2026", "num_citations": "6\n", "authors": ["1873"]}
{"title": "EDF-VD scheduling of flexible mixed-criticality system with multiple-shot transitions\n", "abstract": " The existing mixed-criticality (MC) real-time task models assume that once any high-criticality task overruns, all high-criticality jobs execute up to their most pessimistic WCET estimations simultaneously in a one-shot manner. This is very pessimistic in the sense of unnecessary resource overbooking. In this paper, we propose a more generalized mixed-critical real-time task model, called flexible MC model with multiple-shot transitions (FMC-MST), to address this problem. In FMC-MST, high-criticality tasks can transit multiple intermediate levels to handle less pessimistic overruns independently and to nonuniformly scale the deadline on each level. We develop a run-time schedulability analysis for FMC-MST under EDF-VD scheduling, in which a better tradeoff between the penalties of low-criticality tasks and the overruns of high-criticality tasks is achieved to improve the service quality of low-criticality tasks. We also\u00a0\u2026", "num_citations": "6\n", "authors": ["1873"]}
{"title": "Effect of pre-stressed cable on pre-stressed mega-braced steel frame\n", "abstract": " This study addresses the effect of pre-stressed cables on a pre-stressed mega-braced steel frame through employing static analysis and pushover analysis. The performances of a pre-stressed mega-braced steel frame and a pure steel frame without mega-braces are compared in terms of base shear, ductility, and failure mode. The influence of the cable parameters is also analyzed. Numerical results show that cable braces can effectively improve the lateral stiffness of a pure frame. However, it reduces structural ductility and degenerates structural pre-failure lateral stiffness greatly. Furthermore, it is found that 20% fluctuation in the cable pretension has little effect on structural ultimate bearing capacity and lateral stiffness. As comparison, 20% fluctuation in the cable diameter has much greater impact.", "num_citations": "6\n", "authors": ["1873"]}
{"title": "Performance isolation for real-time systems with Xen hypervisor on multi-cores\n", "abstract": " Virtualization techniques are gaining significant interests in embedded real-time system design. However, existing virtualization platforms lack strong performance isolation among virtual machines. In this work we propose a method to monitor and control the shared memory accesses of individual virtual machines on multi-core processors with Xen hypervisor, to enhance the performance isolation among virtual machines and improve the timing predictability of real-time applications. Experiments with the SPEC2006 benchmark programs are conducted to validate the proposed method.", "num_citations": "6\n", "authors": ["1873"]}
{"title": "Maximizing lifetime of three-dimensional corona-based wireless sensor networks\n", "abstract": " In a wireless sensor network (WSN), the energy of nodes closer to the sink node is usually exhausted sooner than others. This is known as the energy hole problem, which heavily affects the lifetime of the network. In this work, we study the lifetime maximization problem of a three-dimensional corona-based WSN with uniformly distributed sensor nodes and data transmission workload. We first derive the optimal configuration of the first layer of the corona to maximize the lifetime of the network. Then, we propose two strategies to configure nodes outside the first layer: the equal energy strategy (EES) which minimizes the number of hops to transmit data from sensor nodes to the sink and the local optimal energy (LOE) which stands for the fact that under this strategy each individual layer reaches its minimal energy consumption. Furthermore, the optimal equal distance strategy (OEDS) which is a simple deployment\u00a0\u2026", "num_citations": "6\n", "authors": ["1873"]}
{"title": "Towards the Implementation and Evaluation of Semi-Partitioned Multi-Core Scheduling\n", "abstract": " Recent theoretical studies have shown that partitioning-based scheduling has better real-time performance than other scheduling paradigms like global scheduling on multi-cores. Especially, a class of partitioning-based scheduling algorithms (called semi-partitioned scheduling), which allow to split a small number of tasks among different cores, offer very high resource utilization, and appear to be a promising solution for scheduling real-time systems on multi-cores. The major concern about the semi-partitioned scheduling is that due to the task splitting, some tasks will migrate from one core to another at run time, and might incur higher context switch overhead than partitioned scheduling. So one would suspect whether the extra overhead caused by task splitting would counteract the theoretical performance gain of semi-partitioned scheduling. In this work, we implement a semi-partitioned scheduler in the Linux operating system, and run experiments on a Intel Core-i7 4-cores machine to measure the real overhead in both partitioned scheduling and semi-partitioned scheduling. Then we integrate the obtained overhead into the state-of-the-art partitioned scheduling and semi-partitioned scheduling algorithms, and conduct empirical comparison of their real-time performance. Our results show that the extra overhead caused by task splitting in semi-partitioned scheduling is very low, and its effect on the system schedulability is very small. Semi-partitioned scheduling indeed outperforms partitioned scheduling in realistic systems.", "num_citations": "6\n", "authors": ["1873"]}
{"title": "On-line placement of real-time tasks on 2D partially run-time reconfigurable FPGAs\n", "abstract": " Partially Runtime-Reconfigurable (PRTR) FPGAs allow hardware tasks to be placed and removed dynamically at runtime in multi-tasking systems. Such systems need to not only support sharing of the resources in space, but also guarantee timely execution of the tasks. We present a novel online task placement algorithm under real-time constraints. The proposed algorithm uses a new metric to allocate tasks that makes tasks be placed densely, thereby, larger continuous free area remains. Simulation experiments indicate that our approach gives better results and sometimes has lower algorithm complexity than existingtechniques.", "num_citations": "6\n", "authors": ["1873"]}
{"title": "Schedulability analysis and software synthesis for graph-based task models with resource sharing\n", "abstract": " Currently the main approaches to model-based design of embedded software rely on the synchronous paradigm where the executions of software components are either statically ordered or enforced using predefined orderings e.g. Simulink diagrams. However, these approaches may result in resource over provisioning and inflexibility e.g. adding a new function block may require re-designing the whole system. To overcome these drawbacks, we use a dynamic approach allowing multi-tasking implementation of software components using real-time tasks. The challenge is run-time scheduling and schedulability analysis of real-time tasks with inter-task communication (i.e. resource sharing). In this paper, we use a graph-based task model (DRT developed in previous work) to describe software components as a system of real-time tasks sharing not only a uniprocessor but also non-preemptive resources e.g\u00a0\u2026", "num_citations": "5\n", "authors": ["1873"]}
{"title": "Revisiting GPC and AND connector in real-time calculus\n", "abstract": " Real-Time Calculus (RTC) is a powerful framework for modeling and worst-case performance analysis of networked systems. GPC and AND are two fundamental components in RTC, which model priority-based resource arbitration and synchronization operations, respectively. In this paper, we revisit GPC and AND. For GPC, we develop tighter output arrival curves to more precisely characterize the output event streams. For AND, we first identify a problem in the existing analysis method that may lead to negative values in the output curves, and present corrections to the problem. Then we generalize AND to synchronize more than two input event streams. We implement our new theoretical results and conduct experiments to evaluate their performance. Experiment results show significant improvement of our new methods in analysis precision and efficiency.", "num_citations": "5\n", "authors": ["1873"]}
{"title": "Synthesis of Ada code from graph-based task models\n", "abstract": " Software for safety-critical applications must provide high-confidence behavior through predictable timely executions. The Synchronous Digraph Real-Time (SDRT) task model is a graph-based model for safety-critical software, for which efficient timing analysis techniques exist. In this work, we present a software synthesis method to generate Ada source code from SDRT models verified by timing analysis. We also explore how the expressiveness of SDRT can be utilized in synthesizing real-time simulation code of systems with complex behavior through a heart/pacemaker case study.", "num_citations": "5\n", "authors": ["1873"]}
{"title": "Modeling and analysis of data flow graphs using the digraph real-time task model\n", "abstract": " Data flow graphs are widely used for modeling and analysis of real-time streaming applications in which having a predictable and reliable implementation is an essential requirement. In this paper, we consider scheduling a set of data flow graphs such that liveness and boundedness properties are guaranteed, which leads to a predictable and correct behavior of the application. A formal translation method is proposed to map a given set of data flow graphs to a set of graph-based real-time tasks. Additionally, sufficient conditions are derived under which the obtained task set provides a semantically correct implementation of the given data flow graphs. It is shown that the proposed approach provides a higher level of design flexibility compared to the existing methods which use a simpler, i.e. periodic, task model.", "num_citations": "5\n", "authors": ["1873"]}
{"title": "Memory access aware mapping for networks-on-chip\n", "abstract": " Networks-on-Chip (NoC) has been introduced to offer high on-chip communication bandwidth for large scale multi-core systems. However, the communication bandwidth between NoC chips and off-chip memories is relatively low, which seriously limits the overall system performance. So optimizing the off-chip memory communication efficiency is a crucial issue in the NoC system design flow. In this paper, we present a memory access aware mapping algorithm for NoC, which explores SDRAM access parallelization in order to offer higher off-chip memory communication efficiency, and eventually achieve higher overall system performance. To the best of our knowledge, this is the first work to consider off-chip memory communication efficiency in application mapping on NoC. Experimental results showed that, comparing with classical NoC mapping algorithms, our algorithm can significantly improve the memory\u00a0\u2026", "num_citations": "5\n", "authors": ["1873"]}
{"title": "Multicore embedded systems: the timing problem and possible solutions\n", "abstract": " Today\u2019s processor chips contain often multiple CPUs i.e. processor cores each of which may support several hardware threads working in parallel. They are known as multicore or many-core processors. As a consequence of the broad introduction of multicore into computing, almost all software must exploit parallelism to make the most efficient use of on-chip resources including processor cores, caches and memory bandwidth. For embedded applications, it is predicted that multicores will be increasingly used in future embedded systems for high performance and low energy consumption. The major obstacle is that due to on-chip resource contention, the prediction of system performance, latencies, and resource utilization in multicore systems becomes a much harder task than that for single-core systems. With the current technology we may not predict and provide any guarantee on real-time properties of\u00a0\u2026", "num_citations": "5\n", "authors": ["1873"]}
{"title": "Fixed-priority multiprocessor scheduling: Beyond Liu & Layland utilization bound\n", "abstract": " The increasing interests in multicores raise the question whether utilization bounds for uni-processor scheduling can be generalized to the multiprocessor setting. Recently, this has been shown for the famous Liu and Layland utilization bound by applying novel task splitting techniques. However, parametric utilization bounds that can guarantee higher utilizations (up to 100%) for common classes of systems are not yet known to be generalizable to multiprocessors as well. In this paper, we solve this open problem for most parametric utilization bounds by proposing new partitioning-based scheduling algorithms.", "num_citations": "5\n", "authors": ["1873"]}
{"title": "An optimal approach to hardware/software partitioning for synchronous model\n", "abstract": " Computer aided hardware/software partitioning is one of the key challenges in hardware/software co-design. This paper describes a new approach to hardware/software partitioning for synchronous communication model. We transform the partitioning into a reachability problem of timed automata. By means of an optimal reachability algorithm, an optimal solution can be obtained in terms of limited resources in hardware. To relax the initial condition of the partitioning for optimization, two algorithms are designed to explore the dependency relations among processes in the initial specification. Moreover, we propose a scheduling algorithm to improve the synchronous communication efficiency further after partitioning stage. Some experiments are conducted with model checker UPPAAL to show our approach is both effective and efficient.", "num_citations": "5\n", "authors": ["1873"]}
{"title": "Fully abstract characterization of probabilistic may testing\n", "abstract": " In this paper, to develop a refinement relation for probabilistic and nondeterministic systems, we study a notion of probabilistic testing, that extends the testing framework of de Nicola and Hennessy for nondeterministic processes to the probabilistic setting. We present a model of probabilistic computation trees, which corresponds to the classic trace model for non-probabilistic systems. Our main contribution is a fully abstract characterization of the may-testing preorder which is essential for the probabilistic setting. The characterization is given based on convex closures of probabilistic computation trees.", "num_citations": "5\n", "authors": ["1873"]}
{"title": "Optimizing the locations and sizes of solar assisted electric vehicle charging stations in an urban area\n", "abstract": " With the wide-spread adoption of electric vehicles (EVs), introducing solar energy in building EV charging stations is promising as it can reduce carbon emissions and improve air quality. The main challenges are how to decide where to build solar assisted charging stations in a city and how to size the charging stations, as the decision is affected by a broad range of factors, such as construction cost, solar energy fluctuation, and user requirements. This paper proposed an approach to efficiently decide the locations and sizes of solar energy assisted charging stations for an urban area. Experiments are conducted on real EV history data from 297 users of an EV leasing company. The results show that the proposed method can produce high quality decisions within reasonable computation time. The work of this paper will provide important information for decision makers to integrate solar energy into the EV charging\u00a0\u2026", "num_citations": "4\n", "authors": ["1873"]}
{"title": "Real-Time Scheduling and Analysis of OpenMP DAG Tasks Supporting Nested Parallelism\n", "abstract": " OpenMP is a promising framework to develop parallel real-time software on multi-cores. Although similar to the DAG task model, OpenMP task systems are significantly more difficult to analyze due to constraints posed by OpenMP specifications. One of the most interesting features in OpenMP is the support for nested parallelism, enjoying benefits in enhancing performance transparency of parallel libraries and promoting reuse of black-box code. Previous researches on DAG task scheduling mainly restrict to only one level of parallelism. The problem whether OpenMP tasks with multiple levels of parallelism are suitable to real-time systems remains open. In this paper, we study the real-time scheduling and analysis of OpenMP task systems supporting nested parallelism. First, we show that under existing scheduling algorithms in OpenMP implementations, nested parallelism indeed may lead to extremely bad timing\u00a0\u2026", "num_citations": "4\n", "authors": ["1873"]}
{"title": "A note on some open problems in mixed-criticality scheduling\n", "abstract": " In this note we list a few open problems that, despite being foundational for mixed-criticality (MC) scheduling theory, have received little or no attention in the existing literature. We also present a couple of (unpublished) claims related to the listed problems. The latter should, of course, be viewed with a healthy dose of skepticism. We mainly consider the MC sporadic task model that is commonly used in the literature (sometimes called the \u201cVestal model\u201d), see, eg,[3] for a concise description of its semantics. To the best of our knowledge, all the listed problems remain open for all common variations of the system model. For example, they are open regardless of whether we assume (i) implicit, constrained or arbitrary deadlines,(ii) K criticality levels for any constant or nonconstant K\u2a7e 2,(iii) a uniprocessor or multiprocessor platform,(iv) preemptive or non-preemptive scheduling, or (v) any common subclass such as task sets with harmonic periods. In the remainder of this note we assume a system with constrained deadlines, two criticality levels (called lo and hi) and a preemptive uniprocessor. It is also assumed that all schedulers are online (ie, non-clairvoyant), like any real scheduler must be. In particular, a scheduler cannot know the actual execution time of a job except by executing it until completion, and it cannot know the exact release patterns of the sporadic tasks beforehand (it only knows about the minimum release separations). Let a job sequence be a static sequence of unbounded length that specifies all the release times of jobs in one execution of the system. While the release times are fixed in a given job sequence, execution times are still\u00a0\u2026", "num_citations": "4\n", "authors": ["1873"]}
{"title": "Response Time Analysis and Priority Assignment of Processing Chains on ROS2 Executors\n", "abstract": " ROS (Robot Operating System) is currently the most popular robotic software development framework. Robotic software in safe-critical domain are usually subject to hard real-time constraints, so designers must formally model and analyze their timing behaviors to guarantee that real-time constraints are always honored at runtime. This paper studies real-time scheduling and analysis of processing chains in ROS2, the second-generation ROS with a major consideration of real-time capability. First, we study response time analysis of processing chains on ROS2 executors. We show that the only existing result of this problem is both optimistic and pessimistic, and develop new techniques to address these problems and significantly improve the analysis precision. Second, we reveal that the response time of a processing chain on an executor only depends on its last scheduling entity (callback), which provides useful\u00a0\u2026", "num_citations": "3\n", "authors": ["1873"]}
{"title": "Scope-aware data cache analysis for OpenMP programs on multi-core processors\n", "abstract": " OpenMP is the de facto standard parallel programming framework on shared memory architectures, which is not only widely used in general and high-performance computing but also draws increasing interests for real-time embedded systems. Choosing the appropriate assignment of loop iterations to threads is one of the most critical decisions when parallelizing loops, especially considering the large impact by caches behaviors to the program execution time. In this paper, we study data cache analysis for OpenMP programs with parallel loops. We first present a method considering the impact of the schedule clause in OpenMP programs on cache behavior. We capture the dynamic behavior of memory access by computing its temporal scope (the loop iterations where a given memory block is accessed for a given data reference) during address analysis. Based on the ACS representation, we present a temporal\u00a0\u2026", "num_citations": "3\n", "authors": ["1873"]}
{"title": "Towards a tool: times-pro for modeling, analysis, simulation and implementation of cyber-physical systems\n", "abstract": " We consider a Cyber-Physical System (CPS) as a network of components that are either physical plants with continuous behaviors or discrete controllers. To build CPS\u2019s in a systematic manner, the TIMES-Pro tool is designed to support modeling, analysis and code generation for real-time simulation and final deployment. In this paper, we present our decisions in designing the modeling language, the tool architecture and features of TIMES-Pro, and also a case study to demonstrate its applicability.", "num_citations": "3\n", "authors": ["1873"]}
{"title": "Modular performance analysis of energy-harvesting real-time networked systems\n", "abstract": " This paper studies the performance analysis problem of energy-harvesting real-time network systems in the Real-Time Calculus (RTC) framework. The behavior of an energy-harvesting node turns out to be a generalization of two known components in RTC: it behaves like an AND connector if the capacitor used to temporally store surplus energy has unlimited capacity and there is no energy loss, while it behaves like a greedy processing component (GPC) if the size of the capacitor is zero and thus surplus energy is lost or passed to other nodes immediately. In this paper, methods are developed to analyze the worst-case performance, in terms of delay and backlog, of energy-harvesting nodes as well as compute upper/lower bounds of their data and energy outputs. Moreover, with the proposed analysis methods, we disclose some interesting properties of the worst-case behaviors of energy-harvesting systems\u00a0\u2026", "num_citations": "3\n", "authors": ["1873"]}
{"title": "Proper running posture guide: a wearable biomechanics capture system\n", "abstract": " Running is a popular exercise for all age groups. It helps heart and lung functions, enhances muscle strength and control weight. Nevertheless, excessive fatigue and severe injury resulting from inappropriate running poses might reduce the benefits brought by this exercise and stop people from keeping running regularly. In this paper, we design a system that can monitor the running biomechanics, infer running poses, analyze running patterns, and provide both real-time and off-line feedbacks to reduce unnecessary fatigue and unwanted injuries. Common inappropriate running patterns, over-striding, over-pronating and out-sync, are identified and analyzed with the continuous wearable sensor data streams. Two types of correctional feedbacks are designed to provide users appropriate adjustment guidance: vibrating the areas of user body where improper poses are detected and visualizing running video with\u00a0\u2026", "num_citations": "3\n", "authors": ["1873"]}
{"title": "Partitioning-Based Scheduling of OpenMP Task Systems With Tied Tasks\n", "abstract": " OpenMP is a popular programming framework in both general and high-performance computing and has recently drawn much interest in embedded and real-time computing. Although the execution semantics of OpenMP are similar to the DAG task model, the constraints posed by the OpenMP specification make them significantly more challenging to analyze. A  tied  task is an important feature in OpenMP that must execute on the same thread throughout its entire life cycle. A previous work    succeeded in analyzing the real-time scheduling of  tied  tasks by modifying the Task Scheduling Constraints (TSCs) in OpenMP specification. In this article, we also study the real-time scheduling of OpenMP task systems with  tied  tasks but without changing the original TSCs. In particular, we propose a partitioning-based algorithm, P-EDF-omp, by which the  tied  constraint can be automatically guaranteed as long as an\u00a0\u2026", "num_citations": "2\n", "authors": ["1873"]}
{"title": "On computing exact WCRT for DAG tasks\n", "abstract": " Most current real-time parallel applications can be modeled as a directed acyclic graph (DAG) task. Existing worst-case response time (WCRT) bounds (e.g., Graham's bound) derived for DAGs may be very pessimistic. No one precisely knows the gap between the WCRT bound and the actual WCRT. In this paper, we aim to derive the exact WCRT of a DAG task under the list scheduling upon multi-core platforms. We encode the WCRT analysis problem into a satisfaction modular theoretical (SMT) formulation based on insights into the list scheduling algorithm, and prove that our SMT program can solve the WCRT precisely, providing an accurate baseline to measure the tightness of the existing WCRT bounds. Experiments show that our method significantly improves the tightness of the WCRT bound, and is practically quite efficient, e.g., it can analyze DAGs with more than 40 vertices in a few seconds.", "num_citations": "2\n", "authors": ["1873"]}
{"title": "Efficient and Effective Dimension Control in Automotive Applications\n", "abstract": " In automotive industry, the production line for assembling mechanical parts of vehicles must place and weld hundreds of components on the right positions of the platform. The accuracy of deploying the components has great impact on the quality and performance of the produced vehicle. To ensure the assembly accuracy, a critical task in the production process is the so-called dimension quality control. The current state of practice in automotive industries is mainly based on a manual process where experienced engineers use production data to identify accuracy problems and suggest solutions for corrections on fixture adjustment in the assembly line. It is an extremely inefficient process, which typically takes the engineers around ten days for one batch of vehicles and a year to achieve the required assembly accuracy for final production. In this article, we present an automatic technique for dimension control. We\u00a0\u2026", "num_citations": "2\n", "authors": ["1873"]}
{"title": "Integrating cyber-attack defense techniques into real-time cyber-physical systems\n", "abstract": " With the rapid deployment of Cyber-Physical Systems (CPS), security has become a more critical problem than ever before, as such devices are interconnected and have access to a broad range of critical data. A well-known attack is ReturnOriented Programming (ROP) which can diverge the control flow of a program by exploiting the buffer overflow vulnerability. To protect a program from ROP attacks, a useful method is to instrument code into the protected program to do runtime control flow checking (known as Control Flow Integrity, CFI). However, instrumented code brings extra execution time, which has to be properly handled, as most CPS systems need to behave in a real-time manner. In this paper, we present a technique to efficiently compute an execution plan, which maximizes the number of executions of instrumented code to achieve maximal defense effect, and at the same time guarantees real-time\u00a0\u2026", "num_citations": "2\n", "authors": ["1873"]}
{"title": "ompTG: From OpenMP Programs to Task Graphs\n", "abstract": " I. MOTIVATION Real-time systems are shifting from single-core processors to multi-core processors. Software must be parallelized to fully utilize the additional computation power of multi-core processors. OpenMP [1] is a parallel programming framework widely used in general and high-performance computing. Recently, there have been rapidly increasing interests to use OpenMP in development of parallel real-time software [2],[3]. An essential problem in real-time systems is scheduling the workload to satisfy the timing constraints. Parallel software systems can usually be represented as graph-based task models, and there have been much work in the area of real-time scheduling with graph-based models. The current version of OpenMP supports task structures, and its execution semantics are closely related to graph-based task models, which motivates many recent work in this direction [2]\u2013[7]. However, each of these work focuses on a small subset of the OpenMP features, and it lacks a holistic view of what new features are introduced by OpenMP and how would they affect the underlying real-time scheduling and analysis problems. The ompTG project aims to support researchers in the realtime scheduling area to better understand OpenMP-based software and study their scheduling and analysis problems. The core of this project is a tool to transform OpenMP programs into graph-based models, which are easier to understand and use by real-time scheduling researchers. Building up on this transformation tool, we will provide various supports that are important to study the real-time scheduling of OpenMP-based software, including simulator\u00a0\u2026", "num_citations": "2\n", "authors": ["1873"]}
{"title": "Universality of R-automata with Value Copying\n", "abstract": " R-automata are finite state machines extended with counters which can be incremented or reset to zero along the transitions. The universality question asks whether there is a constant D such that all words are accepted by some run along which no counter exceeds D. It has been shown in [Parosh Abdulla, Pavel Krcal, and Wang Yi. R-automata. In Proc. of CONCUR'08., volume 5201 of LNCS, pages 67\u201381. Springer, 2008] that this question is decidable. In this paper, we add one more operation to R-automata, namely the operation which can copy the value of a counter into another one. The result of this paper is a reduction of the universality problem for R-automata with value copying to universality of R-automata, thus rendering the problem decidable. The reduction replaces copy operations by non-deterministic resets together with a mechanism ensuring that the number of such replacements is bounded between\u00a0\u2026", "num_citations": "2\n", "authors": ["1873"]}
{"title": "Integrating timed automata into tabu algorithm for HW-SW partitioning\n", "abstract": " Hardware/software (HW-SW) partitioning is a key problem in codesign of embedded systems, studied extensively in the past. This paper describes a new approach to hardware/software partitioning for synchronous model. We formalize the partitioning problem using timed automata, which captures the key elements of the partitioning. Then the tabu algorithm is applied to timed automata model to search for the solution efficiently. An industrial experiment is conducted to show our approach can handle large applications with hundreds of nodes in task graph effectively", "num_citations": "2\n", "authors": ["1873"]}
{"title": "Exploring optimal solution to hardware/software partitioning for synchronous model\n", "abstract": " Computer aided hardware/software partitioning is one of the key challenges in hardware/software co-design. This paper describes a new approach to hardware/software partitioning for a synchronous communication model including multiple hardware devices. We transform the partitioning into a reachability problem of timed automata. By means of an optimal reachability algorithm, the optimal solution can be obtained with limited resources in hardware. To relax the initial condition of the partitioning for optimization, two algorithms are designed to explore the dependency relations among processes in the sequential specification. Moreover, we propose a scheduling algorithm to improve the synchronous communication efficiency further after partitioning stage. Some experiments are conducted with the model checker UPPAAL to show our approach is both effective and efficient.", "num_citations": "2\n", "authors": ["1873"]}
{"title": "An approach to hardware/software partitioning for multiple hardware devices model\n", "abstract": " Computer aided hardware/software partitioning is one of the key challenges in hardware/software co-design. This paper describes a new approach to hardware/software partitioning for multiple hardware-devices model. The partitioning is transformed into a reachability problem of timed automata, and the optimal solution can be obtained by means of an optimal reachibility algorithm. To relax the initial condition of partitioning for optimization, two algorithms are designed to explore the dependency relations among processes in the sequential specification. Some experiments are conducted with model checker UPPAAL to show our approach is both effective and efficient.", "num_citations": "2\n", "authors": ["1873"]}
{"title": "A complete axiomatisation for timed automata\n", "abstract": " In this paper we present a complete proof system for timed automata. It extends our previous axiomatisation of timed bisimulation for the class of loop-free timed automata with unique fixpoint induction. To our knowledge, this is the first algebraic theory for the whole class of timed automata with a completeness result, thus fills a gap in the theory of timed automata. The proof of the completeness result relies on the notion of symbolic timed bisimulation, adapted from the work on value-passing processes.", "num_citations": "2\n", "authors": ["1873"]}
{"title": "Reasoning about uncertain information compositionally\n", "abstract": " In this paper, we study behaviour descriptions with uncertain information such as\\the probability of a system failure within a given time period is less than or equal to 0: 3\" in terms of process algebras. Typical systems that may show such behaviours include communicating systems with unreliable components, eg faulty medium. We present a process model for such behaviours, in which uncertain information is described by means of intervals of probabilities. In particular, we introduce a stochastic choice operator", "num_citations": "2\n", "authors": ["1873"]}
{"title": "Response Time Analysis of Lazy Round Robin\n", "abstract": " The Round Robin scheduling policy is used in many real-time embedded systems because of its simplicity and low overhead. In this paper, we study a variation of Round Robin used in practical systems, named Lazy Round Robin, which is simpler to implement and has lower runtime overhead than ordinary Round Robin. The key difference between Round Robin and Lazy Round Robin lies in when the scheduler reacts to newly released task instances. The Round Robin scheduler checks whether a newly released task instance is eligible for execution in the remaining part of the current round, while the Lazy Round Robin scheduler does not react to any task release until the end of the current round. This paper develops techniques to calculate upper bounds of response time of tasks scheduled by Lazy Round Robin. Experiments are conducted to evaluate our analysis techniques and compare the real-time\u00a0\u2026", "num_citations": "1\n", "authors": ["1873"]}
{"title": "Cause-effect reaction latency in real-time systems\n", "abstract": " In embedded real-time systems, a functionality is often implemented as a dataflow chain over a set of communicating tasks. An important requirement in such systems is to restrict the amount of time an input data requires to impact its corresponding output. Such temporal requirements over dataflow chains also known as the end-to-end latency constraints, are well-studied in the context of lock-based blocking inter-task communication. However, lock-based communication does not preserve the functional semantics and complicates latency calculation due to its reliance on response times of the communicating tasks. We propose to use non-blocking inter-task communications to preserve the functional semantics. Unfortunately a naive method to compute the reaction latency by adding worst-case delays between each write-read pair is unsafe for systems with non-blocking communication. In this paper, we study a non\u00a0\u2026", "num_citations": "1\n", "authors": ["1873"]}
{"title": "Task parameters analysis in schedule-based timing side-channel attack\n", "abstract": " Recent work has shown that the timing behavior of a real-time system can be utilized by attackers for various adverse purposes via schedule-based timing side-channel attacks. An important assumption in this type of attacks is the prior knowledge of attackers about the task parameter information, including the number of tasks in the system and the period and execution time of each task. The attackers can use such information, together with the execution sequence of the task system, to reconstruct the exact schedule of the tasks and perform various subsequent attacks. In this paper, we show that the schedule-based timing side channel attacks can actually be performed even without knowing the task parameter information in prior. We develop methods to infer the number of tasks in the system and the period and execution time of each task directly from the execution sequence. This removes the task parameter prior\u00a0\u2026", "num_citations": "1\n", "authors": ["1873"]}
{"title": "MINITEE\u2014A Lightweight TrustZone-Assisted TEE for Real-Time Systems\n", "abstract": " While trusted execution environments (TEEs) provide industry standard security and isolation, TEE requests through secure monitor calls (SMCs) attribute to large time overhead and weakened temporal predictability. Moreover, as current available TEE solutions are designed for Linux and/or Android initially, it will encounter many constraints (eg, driver libraries incompatible, large memory footprint, etc.) when integrating with low-end Real-Time Operating Systems, RTOSs. In this paper, we present M ini TEE to understand, evaluate and discuss the benefits and limitations when integrating TrustZone-assisted TEEs with RTOSs. We demonstrate how M ini TEE can be adequately exploited for meeting the real-time needs, while presenting a low performance overhead to the rich OSs (ie, low-end RTOSs). View Full-Text", "num_citations": "1\n", "authors": ["1873"]}
{"title": "Capacity Augmentation Function for Real-Time Parallel Tasks With Constrained Deadlines Under GEDF Scheduling\n", "abstract": " Capacity augmentation bound (CAB) is a widely used quantitative metric in theoretical analysis for directed acyclic graph (DAG) parallel real-time tasks, which reveals the key factors the schedulability of DAG tasks heavily depending on: the normalized utilization (the ratio of the total utilization to the core numbers) and the tensity (the maximum ratio of task\u2019s longest path length to task\u2019s deadline). However, CAB requires both factors of a schedulable task system to be capped by the same threshold. A task system with a normalized utilization slightly larger than that threshold but very small tensity, or very smaller normalized utilization but slightly larger than that threshold has good chance to be scheduled are both denied by CAB. To this end, we propose a new concept called capacity augmentation function (CAF) to better characterize the schedulability of parallel real-time tasks, which provides a more loose and\u00a0\u2026", "num_citations": "1\n", "authors": ["1873"]}
{"title": "Design and Dynamic Update of Real-Time Systems\n", "abstract": " Technology solutions are becoming utterly dependent on software. Today, the functionality of most industrial systems and products such as cars, smart phones, and medical devices is implemented by software as embedded real-time system. The reliability of these systems is fundamental to the functioning of our society, as evidenced by accidents reported in recent years, e.g., involving self-driving Tesla cars controlled by software. The current trend is that today's mostly closed and single purpose embedded real-time systems will become open platforms. They will allow integration of an expanding number of software components over their life-time e.g., in order to enhance and customize their functionality according to the varying needs of individual users, and to defend against upcoming security threats. To enable this, we must have systems that support dynamic updates on-demand, but still retain their safety\u00a0\u2026", "num_citations": "1\n", "authors": ["1873"]}
{"title": "Marking method of cell rotational motion under micro-nano scale vision\n", "abstract": " Cell manipulation in drug research and development, physiology and other biomedical research plays an important role. In high-precision micro environment, especially when the measurement accuracy reaches the nanometer level, it will be subject to light diffraction, scattering and other issues of interference. Cell images in different target is characterized by high similarity, and the movement of cells in some specific conditions is extremely fast, especially in the rotation of the movement is difficult to use the traditional macro-visual algorithm to identify the measurement. In this paper, the SURF feature of the extracted image is selected, its feature registration algorithm is improved for the high-speed motion characteristics of the nanometer visual image are further marked. It mainly includes three parts: feature point detection, feature point description, feature registration and labeling. The rotational speed of the cells was\u00a0\u2026", "num_citations": "1\n", "authors": ["1873"]}
{"title": "Dynamic exerciser template weighting in x86 processor verification\n", "abstract": " Modern digital designs are becoming increasingly complex, which makes their verification a harder process. In modern processors, Random ISA level verification is used to run many diverse stimulus programs to verify a wide variety of desired properties. Random verification uses Exercisers to randomly generate functional ISA level stimulus using predefined templates. The number of simulation slots that are assigned to each template is determined by their assigned weights which reflect the importance of the template, and is currently determined by expert engineers. In this paper, we present a tool to dynamically assign a proper weight to each template based on its ability to successfully generate stimulus programs and its potential of capturing defects in the current phase of the design. The tool is integrated to the verification of a state of the art x86 processor and it was able to hit four new and unique bugs, as well\u00a0\u2026", "num_citations": "1\n", "authors": ["1873"]}
{"title": "An executable semantics for synchronous task graphs: From sdrt to ada\n", "abstract": " We study a graph-based real-time task model in which inter-task synchronization can be specified through a rendezvous mechanism. Previously, efficient methods have been proposed for timing analysis of the corresponding task sets. In this paper, we first formally specify an operational semantics for the model. Next, we describe a method for Ada code generation for a set of such task graphs. We also specify extensions of the approach to cover a notion of broadcasting, as well as global inter-release separation time of real-time jobs. We have implemented the proposed method in a graphical tool which facilitates a model-based design and implementation of real-time software.", "num_citations": "1\n", "authors": ["1873"]}
{"title": "Transforming real-time task graphs to improve schedulability\n", "abstract": " Real-time task graphs are used to describe complex real-time systems with non-cyclic timing behaviors. The workload of such systems are typically bursty, which may degrade their schedulability even with sufficient resource in the long term. In this paper, we propose to use task graph transformation to improve system schedulability. The idea is to insert artificial delays to the release times of certain vertices of a task graph to get a new graph with a smoother workload, while still meeting the timing constraints of the original task graph. Delaying the release time of a vertex may smoothen the workload of some paths of the task graph, but at the same time make the workload of other paths even more bursty. We developed efficient techniques to search for an appropriate release time delay for each vertex. Experiments with randomly generated task systems show that the proposed transformation method can make a\u00a0\u2026", "num_citations": "1\n", "authors": ["1873"]}
{"title": "Improving performance by monitoring while maintaining worst-case guarantees\n", "abstract": " With real-time systems, feasibility analysis is based on worst-case scenarios. At run-time, worst-case situations are often very unlikely to occur. With the system being dimensioned for the worst-case, one faces low resource utilization and implicit loss in performance at run-time. We propose to use run-time monitoring for evaluating the deviation of job releases from their worst-case release bound. This allows us to compute a conservative bound on the future workload. Based on this, we design a scheme for reclaiming computation time, which has been originally allocated for jobs which are now known to be absent. By organizing the consumption of extra computing time in a dynamic and time-safe manner, we improve the run-time performance of applications and provably maintain the worst-case guarantees for their response times. We evaluate the usefulness of the presented approach by using randomly generated\u00a0\u2026", "num_citations": "1\n", "authors": ["1873"]}
{"title": "Delay analysis of structural real-time workload\n", "abstract": " In many complex embedded systems, real-time workload is generated conforming certain structural constraints. In this paper we study how to analyze the delay of real-time workloads of which the generation pattern can be modeled by task graph models. We first show that directly combining path abstraction technique (PAT) in real-time scheduling theory and real-time calculus (RTC) can provide safe delay bounds, but the results are typically over-pessimistic. Then we propose new algorithms to efficiently and precisely solve the delay analysis problem. Experiments with randomly generated task systems are conducted to evaluate the performance of the proposed methods.", "num_citations": "1\n", "authors": ["1873"]}
{"title": "Building timing predictable embedded systems\n", "abstract": " A large class of embedded systems is distinguished from general purpose computing systems by the need to satisfy strict requirements on timing, often under constraints on available resources. Predictable system design is concerned with the challenge of building systems for which timing requirements can be guaranteed a priori. Perhaps paradoxically, this problem has become more difficult by the introduction of performanceenhancing architectural elements, such as caches, pipelines, and multithreading, which introduce a large degree of nondeterminism and make guarantees harder to provide. The intention of this paper is to summarize current state-of-the-art in research concerning how to build predictable yet performant systems. We consider how processor architectures, and programming languages can be devised for predictability. We also consider the integration of compilation and timing analysis, as well as strategies for predictability on multicores.", "num_citations": "1\n", "authors": ["1873"]}
{"title": "New Fixed-Priority Multiprocessor Scheduling Algorithms with Liu & Layland\u2019s Utilization Bound\n", "abstract": " In a recent work [11], we have developed an algorithm generalizing the famous Liu and Layland\u2019s utilization bound to multiprocessor scheduling. The algorithm has the best worst-case utilization bound compared with existing algorithms. However, its average-case performance is not satisfactory as the workload of each processor is limited by Liu and Layland\u2019s bound. In this paper, we present a new algorithm to improve the averagecase performance while keeping the best worst-case utilization bound. To determine the maximal workload assigned to each processor, we use the exact analysis ie Response Time Analysis (RTA) instead of the worst-case utilization threshold as in [11]. Similar to the known fact on single processors for ratemonotonic scheduling that the exact analysis RTA results in much higher average-case utilization than the worst-case bound (88% vs 69%), our algorithm has significantly improved average-case performance. The technical challenge is to derive the worst-case utilization bound for the new algorithm which adopts the flexible partitioning strategy with RTA. We provide a non-trivial proof showing that the algorithm guarantees also Liu and Layland\u2019s utilization bound. Thus it dominates theoretically the state-of-the-art fixed priority scheduling algorithms for multiprocessor systems in terms of worst-case utilization bound. We have also conducted extensive experiments with randomly generated task sets to study the average-case performance of the algorithm. The experiments demonstrate that our algorithm also outperforms other existing algorithms trading lower worst-case utilization bounds for higher average utilization.", "num_citations": "1\n", "authors": ["1873"]}
{"title": "Tools and Algorithms for the Construction and Analysis of Systems: 7th International Conference, TACAS 2001 Held as Part of the Joint European Conferences on Theory and\u00a0\u2026\n", "abstract": " This book constitutes the refereed proceedings of the 7th International Conference on Tools and Algorithms for the Construction and Analysis of Systems, TACAS 2001. The 36 revised full papers presented together with an invited contribution were carefully reviewed and selected from a total of 125 submissions. The papers are organized in sections on symbolic verification, infinite state systems-deduction and abstraction, application of model checking techniques, timed and probabilistic systems, hardware-design and verification, software verification, testing-techniques and tools, implementation techniques, semantics and compositional verification, logics and model checking, and ETAPS tool demonstration.", "num_citations": "1\n", "authors": ["1873"]}
{"title": "Structure and magnetic properties of compounds\n", "abstract": " In the present work, the influence of substitution of V for Mn on the structure and magnetic properties of compounds has been investigated. The lattice constants, the Curie and spin-reorientation temperatures, the anisotropy field and the saturation magnetization have been determined as a function of the V content.", "num_citations": "1\n", "authors": ["1873"]}
{"title": "UPPAAL: a Tool Suite for Validation and Verification of Real {Time Systems\n", "abstract": " The purpose of this document is to provide a complete description of Uppaal, including its theoretical basis and user guide. Uppaal is a tool suite for simulation and veri cation of real-time systems modeled as networks of automata with clock and data variables. It consists of a graphical interface, a simulator and a model {checker (or analyzer). The graphical interface supports graphical and textual representations of system descriptions (ie networks of automata extended with clock and data variables), and automatic transformation from graphical representations to textual format. It also provides a compiler that transforms a certain class of linear hybrid systems to networks of automata. The simulator enables a grphical visualisation of possible dynamic behaviours (execution traces) of a system description allowing for inexpenseive fault detection at an early stage before actual veri cation is attempted. The model {checker allows automatic veri cation of safety and bounded {liveness properties, based on constraint {solving techniques. The model {checker also provides diagnostic information in case veri cation of a particular real-time system fails; the diagnostic o ered may be graphically visualised through the simulator.", "num_citations": "1\n", "authors": ["1873"]}