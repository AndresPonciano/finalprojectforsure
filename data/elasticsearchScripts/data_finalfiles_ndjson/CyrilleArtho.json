{"title": "Memory deduplication as a threat to the guest OS\n", "abstract": " Memory deduplication shares same-content memory pages and reduces the consumption of physical memory. It is effective on environments that run many virtual machines with the same operating system. Memory deduplication, however, is vulnerable to memory disclosure attacks, which reveal the existence of an application or file on another virtual machine. Such an attack takes advantage of a difference in write access times on deduplicated memory pages that are re-created by Copy-On-Write. In our experience on KSM (kernel samepage merging) with the KVM virtual machine, the attack could detect the existence of sshd and apache2 on Linux, and IE6 and Firefox on WindowsXP. It also could detect a downloaded file on the Firefox browser. We describe the attack mechanism in this paper, and also mention countermeasures against this attack.", "num_citations": "157\n", "authors": ["687"]}
{"title": "GRT: Program-analysis-guided random testing\n", "abstract": " We propose Guided Random Testing (GRT), which uses static and dynamic analysis to include information on program types, data, and dependencies in various stages of automated test generation. Static analysis extracts knowledge from the system under test. Test coverage is further improved through state fuzzing and continuous coverage analysis. We evaluated GRT on 32 real-world projects and found that GRT outperforms major peer techniques in terms of code coverage (by 13 %) and mutation score (by 9 %). On the four studied benchmarks of Defects4J, which contain 224 real faults, GRT also shows better fault detection capability than peer techniques, finding 147 faults (66 %). Furthermore, in an in-depth evaluation on the latest versions of ten popular real-world projects, GRT successfully detects over 20 unknown defects that were confirmed by developers.", "num_citations": "68\n", "authors": ["687"]}
{"title": "Finding faults in multi-threaded programs\n", "abstract": " Multi-threaded programming creates the fundamental problem that the execution of a program is no longer deterministic, because the thread schedule is not controlled by the application. This causes traditional testing methods to be rather ineffective. Trilogy, producing many multi-threaded server programs, also has to deal with the limitations of regression testing. New approaches to this problem\u2013static and extended dynamic checking\u2013promise to ameliorate the situation. Many tools are in development that try to find faults in multi-threaded programs in new ways. The first part of this report describes a detailed evaluation of a wide variety of dynamic and static checkers. That comparison always had the applicability to industrial software in mind. While none of the checking tools was a clear winner, certain tools are more useful in practice than others.Because simple cases are the most common ones in practice, the decision was made to extend Jlint, a simple, fast static Java program checker. The new Jlint can now also check for deadlocks in synchronized blocks in Java, which results in improved faultfinding capabilities. The extensions and their usefulness in an industrial environment are described in the second part of the report. Jlint has been applied to many core packages of Trilogy, and also a few other software packages, and shown various degrees of success.", "num_citations": "58\n", "authors": ["687"]}
{"title": "Iterative delta debugging\n", "abstract": " Automated debugging attempts to locate the reason for a failure. Delta debugging minimizes the difference between two inputs, where one input is processed correctly while the other input causes a failure, using a series of test runs to determine the outcome of applied changes. Delta debugging is applicable to inputs or to the program itself, as long as a correct version of the program exists. However, complex errors are often masked by other program defects, making it impossible to obtain a correct version of the program through delta debugging in such cases. Iterative delta debugging extends delta debugging and removes a series of defects step by step, until the originally unresolved defect is isolated. The method is automated and managed to localize a bug in some real-life examples.", "num_citations": "54\n", "authors": ["687"]}
{"title": "Accurate centralization for applying model checking on networked applications\n", "abstract": " Software model checkers can be applied directly to single-process programs, which typically are multithreaded. Multi-process applications cannot be model checked directly. While multiple processes can be merged manually into a single one, this process is very labor-intensive and a major obstacle towards model checking of client-server applications. Previous work has automated the merging of multiple applications but mostly omitted network communication. Remote procedure calls were simply mined, creating similar results for simple cases while removing much of the inherent complexities involved. Our goal is a fully transparent replacement of network communication. Other language features were also modeled more precisely than in previous work, resulting in a program that is much closer to the original. This makes our approach suitable for testing, debugging, and software model checking. Due to the\u00a0\u2026", "num_citations": "51\n", "authors": ["687"]}
{"title": "Visualization of concurrent program executions\n", "abstract": " Various program analysis techniques are efficient at discovering failures and properties. However, it is often difficult to evaluate results, such as program traces. This calls for abstraction and visualization tools. We propose an approach based on UML sequence diagrams, addressing shortcomings of such diagrams for concurrency. The resulting visualization is expressive and provides all the necessary information at a glance.", "num_citations": "43\n", "authors": ["687"]}
{"title": "Efficient model checking of networked applications\n", "abstract": " Most applications today communicate with other processes over a network. Such applications are often multi-threaded. The non-determinism in the thread and communication schedules makes it desirable to model check such applications. When model checking such a networked application, a simple state space exploration scheme is not applicable, as the process being model checked would repeat communication operations when revisiting a given state after backtracking. We propose a solution that encapsulates such operations in a caching layer that is capable of hiding redundant communication operations from the environment. This approach is both more portable and more scalable than other approaches, as only a single process executes inside the model checker.", "num_citations": "38\n", "authors": ["687"]}
{"title": "Software side channel attack on memory deduplication\n", "abstract": " Memory deduplication merges same-content memory pages and reduces the consumption of physical memory. It is effective on environments that run many virtual machines with the same operating system. However, memory deduplication is subject to software side channel attacks, which discloses memory contents. It can be used to reveal the existence of an application or file on another virtual machine. Such an attack takes advantage of a difference in write access times on deduplicated memory pages that are re-created by Copy-On-Write [4]. Previously published exploits were immature. In this work we show untouched problems and refined exploits. Furthermore we show new applications of this technique, which enables secret communication between virtual machines on a processor. A secret marker on memory is used to detect the existence of a VM on a processor in a multi-tenant cloud computing environment.", "num_citations": "33\n", "authors": ["687"]}
{"title": "Model-based API testing of Apache Zookeeper\n", "abstract": " Apache ZooKeeper is a distributed data storage that is highly concurrent and asynchronous due to network communication, testing such a system is very challenging. Our solution using the tool \"Modbat\" generates test cases for concurrent client sessions, and processes results from synchronous and asynchronous callbacks. We use an embedded model checker to compute the test oracle for non-deterministic outcomes, the oracle model evolves dynamically with each new test step. Our work has detected multiple previously unknown defects in ZooKeeper. Finally, a thorough coverage evaluation of the core classes show how code and branch coverage strongly relate to feature coverage in the model, and hence modeling effort.", "num_citations": "30\n", "authors": ["687"]}
{"title": "Modular software model checking for distributed systems\n", "abstract": " Distributed systems are complex, being usually composed of several subsystems running in parallel. Concurrent execution and inter-process communication in these systems are prone to errors that are difficult to detect by traditional testing, which does not cover every possible program execution. Unlike testing, model checking can detect such faults in a concurrent system by exploring every possible state of the system. However, most model-checking techniques require that a system be described in a modeling language. Although this simplifies verification, faults may be introduced in the implementation. Recently, some model checkers verify program code at runtime but tend to be limited to stand-alone programs. This paper proposes cache-based model checking, which relaxes this limitation to some extent by verifying one process at a time and running other processes in another execution environment. This\u00a0\u2026", "num_citations": "30\n", "authors": ["687"]}
{"title": "Cache-based model checking of networked applications: From linear to branching time\n", "abstract": " Many applications are concurrent and communicate over a network. The non-determinism in the thread and communication schedules makes it desirable to model check such systems. However, a simple state space exploration scheme is not applicable, as backtracking results in repeated communication operations. A cache-based approach solves this problem by hiding redundant communication operations from the environment. In this work, we propose a change from a linear-time to a branching-time cache, allowing us to relax restrictions in previous work regarding communication traces that differ between schedules. We successfully applied the new algorithm to real-life programs where a previous solution is not applicable.", "num_citations": "29\n", "authors": ["687"]}
{"title": "Software model checking for distributed systems with selector-based, non-blocking communication\n", "abstract": " Many modern software systems are implemented as client/server architectures, where a server handles multiple clients concurrently. Testing does not cover the outcomes of all possible thread and communication schedules reliably. Software model checking, on the other hand, covers all possible outcomes but is often limited to subsets of commonly used protocols and libraries. Earlier work in cache-based software model checking handles implementations using socket-based TCP/IP networking, with one thread per client connection using blocking input/output. Recently, servers using non-blocking, selector-based input/output have become prevalent. This paper describes our work extending the Java PathFinder extension net-iocache to such software, and the application of our tool to modern server software.", "num_citations": "26\n", "authors": ["687"]}
{"title": "Implementation of a memory disclosure attack on memory deduplication of virtual machines\n", "abstract": " Memory deduplication improves the utilization of physical memory by sharing identical blocks of data. Although memory deduplication is most effective when many virtual machines with same operating systems run on a CPU, cross-user memory deduplication is a covert channel and causes serious memory disclosure attack. It reveals the existence of an application or file on another virtual machine. The covert channel is a difference in write access time on deduplicated memory pages that are re-created by Copy-On-Write, but it has some interferences caused by execution environments. This paper indicates that the attack includes implementation issues caused by memory alignment, self-reflection between page cache and heap, and run-time modification (swap-out, anonymous pages, ASLR, preloading mechanism, and self-modification code). However, these problems are avoidable with some techniques. In our\u00a0\u2026", "num_citations": "17\n", "authors": ["687"]}
{"title": "GRT at the SBST 2015 tool competition\n", "abstract": " GRT (Guided Random Testing) is an automatic test generation tool for Java code, which leverages static and dynamic program analysis to guide run-time test generation. In this paper, we summarize competition results and experiences of GRT in participating in SBST 2015, where GRT ranked first with a score of 203.73 points over 63 Java classes from 10 packages of 9 open-source software projects.", "num_citations": "16\n", "authors": ["687"]}
{"title": "Moving from Logical Sharing of Guest OS to Physical Sharing of Deduplication on Virtual Machine.\n", "abstract": " Current OSes include many logical sharing techniques (shared library, symbolic link, etc.) on memory and storage. Unfortunately they cause security and management problems which come from the dynamic management of logical sharing; eg, search path replacement attack, GOT (Global Offset Table) overwrite attack, Dependency Hell, etc. This paper proposes that self-contained binaries eliminate the problems caused by logical sharing. The memory and storage overheads caused by self-contained binaries are mitigated by physical sharing (memory and disk deduplication). The effect of deduplication was investigated on the KVM virtual machine with KSM (Kernel Samepage Merging) and LBCAS (Loopback Content Addressable Storage).", "num_citations": "16\n", "authors": ["687"]}
{"title": "Model checking networked programs in the presence of transmission failures\n", "abstract": " Software model checkers work directly on single-process programs, but not on multiple processes. Conversion of processes into threads, combined with a network model, allows for model checking distributed applications, but does not cover potential communication failures. This paper contributes a fault model for model checking networked programs. If a naive fault model is used, spurious deadlocks may appear, because certain processes are terminated before they can complete a necessary action. Such spurious deadlocks have to be suppressed, as implemented in our model checker extension. Our approach found several faults in existing applications, and scales well because exceptions generated by our tool can be checked individually.", "num_citations": "15\n", "authors": ["687"]}
{"title": "Applying Jlint to space exploration software\n", "abstract": " Java is a very successful programming language which is also becoming widespread in embedded systems, where software correctness is critical. Jlint is a simple but highly efficient static analyzer that checks a Java program for several common errors, such as null pointer exceptions, and overflow errors. It also includes checks for multi-threading problems, such as deadlocks and data races. The case study described here shows the effectiveness of Jlint in finding certain faults, including multi-threading problems. Analyzing the reasons for false positives in the multi-threading warnings gives an insight into design patterns commonly used in multi-threaded code. The results show that a few analysis techniques are sufficient to avoid almost all false positives. These techniques include investigating all possible callers and a few code idioms. Verifying the correct application of these patterns is still crucial\u00a0\u2026", "num_citations": "15\n", "authors": ["687"]}
{"title": "Software model checking of UDP-based distributed applications\n", "abstract": " We extend exhaustive verification of networked applications to applications using the User Datagram Protocol (UDP). UDP maximizes performance by omitting flow control and connection handling. High-performance services often offer a UDP mode in which they handle connections internally for optimal throughput. However, because UDP is unreliable (packets are subject to loss, duplication, and reordering), verification of UDP-based applications becomes an issue. Even though unreliable behavior occurs only rarely during testing, it often appears in a production environment due to a larger number of concurrent network accesses. Our tool systematically tests UDP-based applications by producing packet loss, duplication, and reordering for each packet. It is built on top of net-Rio cache for the Java Path Finder model checker. We have evaluated the performance of our tool in a multi-threaded client/server\u00a0\u2026", "num_citations": "13\n", "authors": ["687"]}
{"title": "Effects of memory randomization, sanitization and page cache on memory deduplication\n", "abstract": " Memory deduplication merges same-content memory pages and reduces the consumption of physical memory. It is a desirable feature for virtual machines on IaaS (Infrastructure as a Service) type cloud computing, because IaaS hosts many guest OSes which are expected to include many identical memory pages. However, some security capabilities of the guest OS modify memory contents for each execution (eg, ASLR: Address Space Layout Randomization) or uniformly set inactive memory contents to zero (Memory Sanitization). These capabilities have positive or negative impacts on memory deduplication. The severity of the impact depends on the size of the memory (ie, the number of virtual machines) and update frequency, because most memory deduplications scan and merge the memory at runtime at regular intervals. We evaluated the effects of ASLR, Memory Sanitization, and their related security capabilities (Position Independent Executables, page cache flushing, and dirty page flushing) of the Linux guest operating system on the KVM virtual machine with KSM (Kernel Samepage Merging) memory deduplication. The results indicate ASLR increases physical memory consumption by more than 18% on 4 virtual machines with memory deduplication. The combination of memory sanitization and page cache flushing reduce physical memory consumption about 20-35% at a stable state.", "num_citations": "13\n", "authors": ["687"]}
{"title": "Trace server: A tool for storing, querying and analyzing execution traces\n", "abstract": " Various techniques for software verification are in use today, including testing and software model checking. Each of them has certain limitations, imposed by limited memory and computation time. This limits the types of properties that can be analyzed during one execution on a given computer. By carrying out additional analysis of program traces outside the execution of the program, one can extend the scope of the analysis. This paper presents the Trace Server, a solution for collecting, storing, querying and processing data describing program execution traces. The work is implemented as an extension of the Java PathFinder model checking tool. The collected data can be saved in a database for further processing, or be processed during the operation of the system. Data can also be sent to a remote server. The tool defines the interface for creating data analyzers and includes examples of its use, providing a deadlock analyzer and an analyzer of executed methods. A developer using our tool can create new reports or supplement existing data.", "num_citations": "13\n", "authors": ["687"]}
{"title": "Combining Static and Dynamic Analysis to Find Multi-threading Faults Beyond Data Races\n", "abstract": " Multi-threaded programming is very difficult, and can result in errors that cannot be found through testing as is the case with sequential programs. Due to its scalability, the use of general-purpose rules to verify the locking and data access discipline of a program is more promising than systematic exploration of the entire program space. It is difficult to find such rules, but once found, they can be applied to any program using only a single program trace and detect errors that cannot usually be found through testing. JNuke contains a virtual machine for Java bytecode that can execute Java programs and monitor such general-purpose rules. Furthermore, it is capable of utilizing the same analysis algorithm statically,\u201cat compile-time\u201d, and dynamically, at run-time. This allows for new combinations and comparisons of the two techniques. JNuke also offers modelchecking capabilities, in order to explore the full program state space when run-time verification is not sufficient.", "num_citations": "13\n", "authors": ["687"]}
{"title": "Domain-specific languages with Scala\n", "abstract": " Domain-Specific Languages (DSLs) are often classified into external and internal DSLs. An external DSL is a stand-alone language with its own parser. An internal DSL is an extension of an existing programming language, the host language, offering the user of the DSL domain-specific constructs as well as the constructs of the host language, thus providing a richer language than the DSL itself. In this paper we report on experiences implementing external as well as internal formal modeling DSLs with the Scala programming language, known in particular for its support for defining DSLs. The modeling languages include monitoring logics, a testing language, and a general purpose SysML inspired modeling language. We present a systematic overview of advantages and disadvantages of each option.", "num_citations": "12\n", "authors": ["687"]}
{"title": "Combinatorial testing for tree-structured test models with constraints\n", "abstract": " In this paper, we develop a combinatorial testing technique for tree-structured test models. First, we generalize our previous test models for combinatorial testing based on AND-XOR trees with constraints limited to a syntactic subset of propositional logic, to allow for constraints in full propositional logic. We prove that the generalized test models are strictly more expressive than the limited ones. Then we develop an algorithm for combinatorial testing for the generalized models, and show its correctness and computational complexity. We apply a tool based on our algorithm to an actual ticket gate system that is used by several large transportation companies in Japan. Experimental results show that our technique outperforms existing techniques.", "num_citations": "12\n", "authors": ["687"]}
{"title": "Priority integration for weighted combinatorial testing\n", "abstract": " Priorities (weights) for parameter values can improve the effectiveness of combinatorial testing. Previous approaches have employed weights to derive high-priority test cases either earlier or more frequently. Our approach integrates these order-focused and frequency-focused prioritizations. We show that our priority integration realizes a small test suite providing high-priority test cases early and frequently in a good balance. We also propose two algorithms that apply our priority integration to existing combinatorial test generation algorithms. Experimental results using numerous test models show that our approach improves the existing approaches w.r.t. Order-focused and frequency-focused metrics, while overheads in the size and generation time of test suites are small.", "num_citations": "12\n", "authors": ["687"]}
{"title": "Analyzing distributed Java applications by automatic centralization\n", "abstract": " The verification and analysis of distributed applications are difficult. They involve large combinational states, interactive network communication between peers, and concurrency. Some dynamic analysis tools can analyze the runtime behavior of a single-process application. However, they do not support the analysis of a whole distributed application, where multiple processes run simultaneously. Centralization is a general solution, which transforms multi-process applications into a single-process one that can be directly analyzed by such existing tools. In this paper, we adopt centralization as a general framework for analyzing distributed applications. We propose and solve the essential issue of a class version conflict during centralization. We also propose a clean solution for the shutdown semantics. We implement and apply our centralization tool to some network benchmarks. Experiments, where existing tools are\u00a0\u2026", "num_citations": "12\n", "authors": ["687"]}
{"title": "Model checking distributed systems by combining caching and process checkpointing\n", "abstract": " Verification of distributed software systems by model checking is not a straightforward task due to inter-process communication. Many software model checkers only explore the state space of a single multi-threaded process. Recent work proposes a technique that applies a cache to capture communication between the main process and its peers, and allows the model checker to complete state-space exploration. Although previous work handles non-deterministic output in the main process, any peer program is required to produce deterministic output. This paper introduces a process checkpointing tool. The combination of caching and process checkpointing makes it possible to handle non-determinism on both sides of communication. Peer states are saved as checkpoints and restored when the model checker backtracks and produces a request not available in the cache. We also introduce the concept of\u00a0\u2026", "num_citations": "12\n", "authors": ["687"]}
{"title": "Oracle-supported dynamic exploit generation for smart contracts\n", "abstract": " Despite the high stakes involved in smart contracts, they are often developed in an undisciplined manner, leaving the security and reliability of blockchain transactions at risk. In this paper, we introduce ContraMaster an oracle-supported dynamic exploit generation framework for smart contracts. Existing approaches mutate only single transactions; ContraMaster exceeds these by mutating the transaction sequences. ContraMaster uses data-flow, control-flow, and the dynamic contract state to guide its mutations. It then monitors the executions of target contract programs, and validates the results against a general-purpose semantic test oracle to discover vulnerabilities. Being a dynamic technique, it guarantees that each discovered vulnerability is a violation of the test oracle and is able to generate the attack script to exploit this vulnerability. In contrast to rule-based approaches, ContraMaster has not shown any false\u00a0\u2026", "num_citations": "11\n", "authors": ["687"]}
{"title": "Using checkpointing and virtualization for fault injection\n", "abstract": " The program monitoring and control mechanisms of virtualization tools are becoming increasingly standardized and advanced. Together with checkpointing, these can be used for general program analysis tools. We explore this idea with an architecture we call Checkpoint-based Fault Injection (CFI), and two concrete implementations using different existing virtualization tools: DMTCP and SBUML. The implementations show interesting trade-offs in versatility and performance as well as the generality of the architecture.", "num_citations": "11\n", "authors": ["687"]}
{"title": "Test effectiveness evaluation of prioritized combinatorial testing: A case study\n", "abstract": " Combinatorial testing is a widely-used technique to detect system interaction failures. To improve test effectiveness with given priority weights of parameter values in a system under test, prioritized combinatorial testing constructs test suites where highly weighted parameter values appear earlier or more frequently. Such order-focused and frequency-focused combinatorial test generation algorithms have been evaluated using metrics called weight coverage and KL divergence but not sufficiently with fault detection effectiveness so far. We evaluate the fault detection effectiveness on a collection of open source utilities, applying prioritized combinatorial test generation and investigating its correlation with weight coverage and KL divergence.", "num_citations": "10\n", "authors": ["687"]}
{"title": "Specification and verification of synchronization with condition variables\n", "abstract": " This paper proposes a technique to specify and verify the correct synchronization of concurrent programs with condition variables. We define correctness of synchronization as the liveness property: \u201cevery thread synchronizing under a set of condition variables eventually exits the synchronization block\u201d, under the assumption that every such thread eventually reaches its synchronization block. Our technique does not avoid the combinatorial explosion of interleavings of thread behaviours. Instead, we alleviate it by abstracting away all details that are irrelevant to the synchronization behaviour of the program, which is typically significantly smaller than its overall behaviour. First, we introduce SyncTask, a simple imperative language to specify parallel computations that synchronize via condition variables. We consider a SyncTask program to have a correct synchronization iff it terminates. Further, to relieve the\u00a0\u2026", "num_citations": "9\n", "authors": ["687"]}
{"title": "Runtime monitoring for concurrent systems\n", "abstract": " Most existing specification languages for runtime verification describe the properties of the entire system in a top-down manner, and lack constructs to describe concurrency in the specification directly.  is a runtime-monitoring framework based on Hoare\u2019s Communicating Sequential Processes (CSP) that captures concurrency in the specification directly. In this paper, we define the syntax of  and its formal semantics. In comparison to quantified event automata (QEA), as an example,  describes a specification for a concurrent system in a bottom-up manner, whereas QEA lends itself to a top-down manner. We also present an implementation of , which supports full  without optimization. When comparing its performance to that of QEA, our implementation of  requires slightly more than twice the time required by QEA; we consider this overhead to be acceptable. Finally, we\u00a0\u2026", "num_citations": "9\n", "authors": ["687"]}
{"title": "Tools and techniques for model checking networked programs\n", "abstract": " For software executing several threads in parallel, testing is unreliable, as it cannot cover all thread schedules. Model checking, however, can cover all possible thread interleavings. Software model checkers can directly verify an implementation, but typically cannot handle network input/output operations, which most programs require. This shortcoming can be addressed by a special model checker designed for multiple processes, or by different kinds of extensions and preprocessors for existing model checkers. This paper surveys currently existing approaches and tools.", "num_citations": "8\n", "authors": ["687"]}
{"title": "Optimal test suite generation for Modified Condition Decision Coverage using SAT solving\n", "abstract": " Boolean expressions occur frequently in descriptions of computer systems, but they tend to be complex and error-prone in complex systems. The modified condition decision coverage (MCDC) criterion in system testing is an important testing technique for Boolean expression, as its usage mandated by safety standards such as DO-178 [1] (avionics) and ISO26262 [2] (automotive). In this paper, we develop an algorithm to generate optimal MCDC test suites for Boolean expressions. Our algorithm is based on SAT solving and generates minimal MCDC test suites. Experiments on a real-world avionics system confirm that the technique can construct minimal MCDC test suites within reasonable times, and improves significantly upon prior techniques.", "num_citations": "7\n", "authors": ["687"]}
{"title": "Distance-integrated combinatorial testing\n", "abstract": " This paper proposes a novel approach to combinatorial test generation, which achieves an increase of not only the number of new combinations but also the distance between test cases. We applied our distance-integrated approach to a state-of-the-art greedy algorithm for traditional combinatorial test generation by using two distance metrics, Hamming distance, and a modified chi-square distance. Experimental results using numerous benchmark models show that combinatorial test suites generated by our approach using both distance metrics can improve interaction coverage for higher interaction strengths with low computational overhead.", "num_citations": "7\n", "authors": ["687"]}
{"title": "Java Pathfinder on Android Devices\n", "abstract": " Because Android apps are written in Java and executed on a virtual machine (VM), there is an opportunity to employ Java Pathfinder (JPF) for their verification. There already exist two JPF extensions, jpf-android and jpf-pathdroid. The former executes Java bytecode on the Java VM, while the latter executes Android applications in their original format. Both do not support native methods, and thus depend on a model of the Android environment. This paper introduces an alternative approach: we run JPF as an Android application that executes Java bytecode, which gives us direct access to the Android environment. This approach allows us to verify rich Android apps that rely on native calls", "num_citations": "6\n", "authors": ["687"]}
{"title": "Verifying nested lock priority inheritance in RTEMS with java pathfinder\n", "abstract": " Scheduling and synchronization algorithms for uniprocessor real-time systems benefit from the rich theory of schedulability analysis, and yet translating these algorithms to practical implementations can be challenging. This paper presents a Java model of the priority inheritance protocol for mutual exclusion, as implemented in the RTEMS open-source real-time operating system. We verified this model using Java Pathfinder to detect potential data races, deadlocks, and priority inversions. JPF detected a known bug in the RTEMS implementation, which we modified along with the Java model. Verification of the modified model showed the absence of data races, deadlocks, and established nine protocol-specific correctness properties.", "num_citations": "6\n", "authors": ["687"]}
{"title": "Efficient testing of software product lines via centralization (short paper)\n", "abstract": " Software product line~(SPL) engineering manages families of software products that share common features. However, cost-effective test case generation for an SPL is challenging. Applying existing test case generation techniques to each product variant separately may test common code in a redundant way. Moreover, it is difficult to share the test results among multiple product variants. In this paper, we propose the use of centralization, which combines multiple product variants from the same SPL and generates test cases for the entire system. By taking into account all variants, our technique generally avoids generating redundant test cases for common software components. Our case study on three SPLs shows that compared with testing each variant independently, our technique is more efficient and achieves higher test coverage.", "num_citations": "6\n", "authors": ["687"]}
{"title": "Jlint manual\n", "abstract": " Jlint will check your Java code and find bugs, inconsistencies and synchronization problems by doing data flow analysis and building lock graph.Jlint consists of two separate programs performing syntax and semantic verification. As far as Java mostly inherits C/C++ syntax and so inherits most of the problems caused by C syntax, the idea was to create common syntax verifier for all C-family languages: C, C++, Objective C and Java. This program was named AntiC, because it fixes problems with C grammar, which can cause dangerous programmer\u2019s bugs, undetected by compiler. By using hand-written scanner and simple top-down parser, AntiC is able to detect such bugs as suspicious use of operators priorities, absence of break in switch code, wrong assumption about constructions bodies...", "num_citations": "6\n", "authors": ["687"]}
{"title": "Visual analytics for concurrent Java executions\n", "abstract": " Analyzing executions of concurrent software is very difficult. Even if a trace is available, such traces are very hard to read and interpret. A textual trace contains a lot of data, most of which is not relevant to the issue at hand. Past visualization attempts either do not show concurrent behavior, or result in a view that is overwhelming for the user. We provide a visual analytics tool, VA4JVM, for error traces produced by either the Java Virtual Machine, or by Java Pathfinder. Its key features are a layout that spatially associates events with threads, a zoom function, and the ability to filter event data in various ways. We show in examples how filtering and zooming in can highlight a problem without having to read lengthy textual data.", "num_citations": "5\n", "authors": ["687"]}
{"title": "Design of prioritized N-wise testing\n", "abstract": " wise testing is a widely used technique for combinatorial interaction testing. Prioritizing testing reorders test cases by relevance, testing important aspects more thoroughly. We propose a novel technique for-wise test case generation to satisfy the three distinct prioritization criteria of interaction coverage, weight coverage, and KL divergence. The proposed technique generates small-wise test cases, where high-priority test cases appear early and frequently. Our early evaluation confirms that the proposed technique improves on existing techniques based on the three prioritization criteria.", "num_citations": "5\n", "authors": ["687"]}
{"title": "Separation of transitions, actions, and exceptions in model-based testing\n", "abstract": " Model-based testing generates test cases from a high-level model. Current models employ extensions to finite-state machines. This work proposes a separation of transitions in the model and their corresponding actions in the target implementation, and also includes special treatment of exceptional states.", "num_citations": "5\n", "authors": ["687"]}
{"title": "Visualization and abstractions for execution paths in model-based software testing\n", "abstract": " This paper presents a technique to measure and visualize execution-path coverage of test cases in the context of model-based software systems testing. Our technique provides visual feedback of the tests, their coverage, and their diversity. We provide two types of visualizations for path coverage based on so-called state-based graphs and path-based graphs. Our approach is implemented by extending the Modbat tool for model-based testing and experimentally evaluated on a collection of examples, including the ZooKeeper distributed coordination service. Our experimental results show that the state-based visualization is good at relating the tests to the model structure, while the path-based visualization shows distinct paths well, in particular linearly independent paths. Furthermore, our graph abstractions retain the characteristics of distinct execution paths, while removing some of the complexity of the graph.", "num_citations": "4\n", "authors": ["687"]}
{"title": "Model checking of concurrent algorithms: From Java to C\n", "abstract": " Concurrent software is difficult to verify. Because the thread schedule is not controlled by the application, testing may miss defects that occur under specific thread schedules. This problem gave rise to software model checking, where the outcome of all possible thread schedules is analyzed.               Among existing software model checkers for multi-threaded programs, Java PathFinder for Java bytecode is probably the most flexible one. We argue that compared to C programs, the virtual machine architecture of Java, combined with the absence of direct low-level memory access, lends itself to software model checking using a virtual machine approach. C model checkers, on the other hand, often use a stateless approach, where it is harder to avoid redundancy in the analysis.               Because of this, we found it beneficial to prototype a concurrent algorithm in Java, and use the richer feature set of a Java\u00a0\u2026", "num_citations": "4\n", "authors": ["687"]}
{"title": "Verifying networked programs using a model checker extension\n", "abstract": " Model checking finds failures in software by exploring every possible execution schedule. Until recently it has been mainly applied to stand-alone applications. This paper presents the I/O-cache, an extension for a Java model checker to support networked programs. It contains a cache module, which captures data streams between a target process and its peer processes. This demonstration also shows how we found a defect in a WebDAV client with a model checker and our extension.", "num_citations": "4\n", "authors": ["687"]}
{"title": "Teaching software model checking\n", "abstract": " The use of formal methods has become commonplace in hardware design, and is becoming increasingly widespread in software engineering. While formal methods have repeatedly been applied in safety-critical projects, their technologies and tools are not widely known, due to lack of in-depth education in current curricula. In this paper, we introduce the curriculum design of software model checking, which is part of a larger education program that addresses several issues in software engineering and formal methods in general. We will also touch upon the necessity of a formal methods body of knowledge (FMBOK) for the guidance of formal methods education.", "num_citations": "4\n", "authors": ["687"]}
{"title": "Model-based Network Fault Injection for IoT Protocols.\n", "abstract": " IoT devices operate in environments where networks may be unstable. They rely on transport protocols to deliver data with given quality-of-service settings. To test an implementation of the popular MQTT protocol thoroughly, we extend the model-based test framework \u201cModbat\u201d to simulate unstable networks by taking into account delays and transmission failures. Our proxy-based technology requires no changes to the IoT software, while the model allows the user to define stateless or stateful types or fault patterns. We evaluate our methods on a client-server library for MQTT, a transport protocol designed for IoT.", "num_citations": "3\n", "authors": ["687"]}
{"title": "Model-based Testing of the Java network API\n", "abstract": " Testing networked systems is challenging. The client or server side cannot be tested by itself. We present a solution using tool \"Modbat\" that generates test cases for Java's network library java.nio, where we test both blocking and non-blocking network functions. Our test model can dynamically simulate actions in multiple worker and client threads, thanks to a carefully orchestrated design that covers non-determinism while ensuring progress.", "num_citations": "3\n", "authors": ["687"]}
{"title": "Automated dataset construction from web resources with tool Kayur\n", "abstract": " Many text mining tools cannot be applied directly to documents available on web pages. There are tools for fetching and preprocessing of textual data, but combining them in one working tool chain can be time consuming. The preprocessing task is even more labor-intensive if documents are located on multiple remote sources with different storage formats. In this paper we propose the simplification of data preparation process for cases when data come from wide range of web resources. We developed an open-sourced tool, called Kayur, that greatly minimizes time and effort required for routine data preprocessing steps, allowing to quickly proceed to the main task of data analysis. The datasets generated by the tool are ready to be loaded into a data mining workbench, such as WEKA or Carrot2, to perform classification, feature prediction, and other data mining tasks.", "num_citations": "3\n", "authors": ["687"]}
{"title": "Analysis of disk access patterns on file systems for content addressable storage\n", "abstract": " CAS (Content Addressable Storage) is virtual disk with deduplication, which merges same-content chunks and reduces the consumption of physical storage. The performance of CAS depends on the allocation strategy of the individual file system and its access patterns (size, frequency, and locality of reference) since the effect of merging depends on the size of a chunk (access unit) used in deduplication.We propose a method to evaluate the affinity between file system and CAS, which compares the degree of deduplication by storing many same-contents files throughout a file system. The results show the affinity and semantic gap between the file systems (ext3, ext4, XFS, JFS, ReiserFS (they are bootable file systems), NILFS, btrfs, FAT32 and NTFS, and CAS.", "num_citations": "3\n", "authors": ["687"]}
{"title": "Multi-objective Search for Model-based Testing\n", "abstract": " This paper presents a search-based approach relying on multi-objective reinforcement learning and optimization for test case generation in model-based software testing. Our approach considers test case generation as an exploration versus exploitation dilemma, and we address this dilemma by implementing a particular strategy of multi-objective multi-armed bandits with multiple rewards. After optimizing our strategy using the jMetal multi-objective optimization framework, the resulting parameter setting is then used by an extended version of the Modbat tool for model-based testing. We experimentally evaluate our search-based approach on a collection of examples, such as the ZooKeeper distributed service and PostgreSQL database system, by comparing it to the use of random search for test case generation. Our results show that test cases generated using our search-based approach can obtain more\u00a0\u2026", "num_citations": "2\n", "authors": ["687"]}
{"title": "Classification tree method with parameter shielding\n", "abstract": " The Classification Tree Method (CTM) is a structured and diagrammatic modeling technique for combinatorial testing. CTM can express the notion of \u201cparameter shielding\u201d, the phenomenon that some system parameters become invalidated depending on another system parameter. The current form of CTM, however, is limited in its expressiveness: it can only express parameter shielding that depends on a single parameter. In this paper, we extend CTM with parameter shielding that depends on multiple parameters, proposing CTM. We evaluate the proposed extension on several industrial systems. The evaluation finds that parameter shielding often depends on multiple parameters in real systems, and the effectiveness of the extension.", "num_citations": "2\n", "authors": ["687"]}
{"title": "Classification of randomly generated test cases\n", "abstract": " Random test case generation produces relatively diverse test sequences, but the validity of the test verdict is always uncertain. Because tests are generated without taking the specification and documentation into account, many tests are invalid. To understand the prevalent types of successful and invalid tests, we present a classification of 56 issues that were derived from 208 failed, randomly generated test cases. While the existing workflow successfully eliminated more than half of the tests as irrelevant, half of the remaining failed tests are false positives. We show that the new @NonNull annotation of Java 8 has the potential to eliminate most of the false positives, highlighting the importance of machine-readable documentation.", "num_citations": "2\n", "authors": ["687"]}
{"title": "Formal Techniques for Safety-Critical Systems: Second International Workshop, FTSCS 2013, Queenstown, New Zealand, October 29--30, 2013. Revised Selected Papers\n", "abstract": " This book constitutes the refereed proceedings of the Second International Workshop, FTSCS 2013, held in Queenstown, New Zealand, in October 2013. The 17 revised full papers presented together with an invited talk were carefully reviewed and selected from 32 submissions. The papers address various topics related to the application of formal and semi-formal methods to improve the quality of safety-critical computer systems.", "num_citations": "2\n", "authors": ["687"]}
{"title": "Project centralization based on graph coloring\n", "abstract": " Version conflicts are common in a component-based system, where each component is developed and managed independently. Changes during the life-cycle of components require multiple versions to coexist. This creates a challenge in representing multiple versions for program analysis tools and execution platforms that are designed to handle only one version. In this paper, a project centralization approach is proposed to manage the version conflict problem. Our technique shares common code whenever possible while keeping the version space of each component separate. We formalize and transform the project centralization into a graph coloring problem. A corresponding algorithm is also presented. Experiments on real world software projects demonstrate the effectiveness of our technique.", "num_citations": "2\n", "authors": ["687"]}
{"title": "The quest for precision: A layered approach for data race detection in static analysis\n", "abstract": " Low level data-races in multi-threaded software are hard to detect, especially when requiring exhaustiveness, speed and precision. In this work, we combine ideas from run-time verification, static analysis and model checking to balance the above requirements. In particular, we adopt a well-known dynamic race detection algorithm based on calculating lock sets to static program analysis for achieving exhaustiveness. The resulting data race candidates are in a further step investigated by model checking with respect to a formal threading model to achieve precision. Moreover, we demonstrate the effectiveness of the combined approach by a case study on the open-source TFTP server OpenTFTP, which shows the trade-off between speed and precision in our two-stage analysis.", "num_citations": "2\n", "authors": ["687"]}
{"title": "Impact on Chunk Size on Deduplication and Disk Prefetch\n", "abstract": " CAS (Content Addressable Storage) systems reduce total volume of virtual disk with deduplication technique. The effects of deduplication has been evaluated and confirmed in some papers. Most evaluations, however, were achieved by small chunk size (4KB-8KB) and did not care about I/O optimization (disk prefetch) on a real usage. Effective disk prefetch is larger than the chunk size and causes many CAS operations. Furthermore, previous evaluations did not care about ratio of effective data in a chunk. The ratio is improved by block reallocation of file system, which considers access profile. Chunk size should be decided by considering these effects on a real usage. This paper evaluates effectiveness of deduplication on a large chunk of CAS system which considers the optimization for disk prefetch and effective data in a chunk. The optimization was achieved for boot procedure, because it was a\u00a0\u2026", "num_citations": "2\n", "authors": ["687"]}
{"title": "Introduction of virtualization technology to multi-process model checking\n", "abstract": " Model checkers find failures in software by exploring every possible execution schedule. Java PathFinder (JPF), a Java model checker, has been extended recently to cover networked applications by caching data transferred in a communication channel. A target process is executed by JPF, whereas its peer process runs on a regular virtual machine outside. However, non-deterministic target programs may produce different output data in each schedule, causing the cache to restart the peer process to handle the different set of data. Virtualization tools could help us restore previous states of peers, eliminating peer restart. This paper proposes the application of virtualization technology to networked model checking, concentrating on JPF.", "num_citations": "2\n", "authors": ["687"]}
{"title": "Architecture-aware Partial Order Reduction to Accelerate Model Checking of Networked Programs\n", "abstract": " Testing cannot cover all execution schedules in concurrent software. Model checking, however, is capable of verifying the outcome of all possible executions. It has been applied successfully to networked software, with all processes being analyzed in conjunction. Unfortunately, this approach does not scale very well. This paper presents a partial-order reduction through which a performance gain of up to 70% was achieved.", "num_citations": "2\n", "authors": ["687"]}
{"title": "AOP-based automated unit test classification of large benchmarks\n", "abstract": " Despite the availability of a variety of program analysis tools, evaluation of these tools is difficult, as only few benchmark suites exist. Existing benchmark suites lack the uniformity needed for automation of experiments. We introduce the design of a uniform build/installation platform, which constitutes an important part of the solution. This platform is used to manage the build and test process, which is enhanced by a tool that analyzes the structure of unit tests. Benchmark applications lack detailed information about unit tests. Such knowledge is useful: For analysis algorithms that target specific program features, it is desirable to analyze only relevant tests. Using aspect-oriented programming, we wrap test execution and implement a tool providing coverage data of individual unit tests. Furthermore, the wrapper provides a front-end for the selection of subsets of a test suite. We successfully applied our tool to several\u00a0\u2026", "num_citations": "2\n", "authors": ["687"]}
{"title": "Method summaries for JPF\n", "abstract": " Java Path nder (JPF) is a virtual machine executing Java byte- code that is able to perform model checking using backtracking execution. Due to backtracking, parts of a program may be ex- ecuted multiple times during model checking. Hence, we explore whether method summaries can be used to make JPF's model checking more efficient. We present the design and implementa- tion of dynamically generated summaries as an extension of JPF. While our summaries incur an overhead that outweighs the bene- ts in most cases, the approach shows promise in certain cases, in particular when stateless model checking is used. We also provide some results related to cases when our summaries are applicable that could provide guidance for future work within this eld.", "num_citations": "1\n", "authors": ["687"]}
{"title": "Dynamic Vulnerability Detection on Smart Contracts Using Machine Learning\n", "abstract": " In this work we propose Dynamit, a monitoring framework to detect reentrancy vulnerabilities in Ethereum smart contracts. The novelty of our framework is that it relies only on transaction metadata and balance data from the blockchain system; our approach requires no domain knowledge, code instrumentation, or special execution environment. Dynamit extracts features from transaction data and uses a machine learning model to classify transactions as benign or harmful. Therefore, not only can we find the contracts that are vulnerable to reentrancy attacks, but we also get an execution trace that reproduces the attack. Using a random forest classifier, our model achieved more than 90 percent accuracy on 105 transactions, showing the potential of our technique.", "num_citations": "1\n", "authors": ["687"]}
{"title": "Model\u2010based testing of Apache ZooKeeper: Fundamental API usage and watchers\n", "abstract": " In this paper, we extend work on model\u2010based testing for Apache ZooKeeper, to handle watchers (triggers) and improve scalability. In a distributed asynchronous shared storage like ZooKeeper, watchers deliver notifications on state changes. They are difficult to test because watcher notifications involve an initial action that sets the watcher, followed by another action that changes the previously seen state. We show how to generate test cases for concurrent client sessions executing against ZooKeeper with the tool Modbat. The tests are verified against an oracle that takes into account all possible timings of network communication. The oracle has to verify that there exists a chain of events that triggers both the initial callback and the subsequent watcher notification. We show in detail how the oracle computes whether watch triggers are correct and how the model was adapted and improved to handle these features\u00a0\u2026", "num_citations": "1\n", "authors": ["687"]}
{"title": "Formal Techniques for Safety-Critical Systems (FTSCS 2014)\n", "abstract": " Formal Techniques for Safety-Critical Systems (FTSCS 2014) \u00d7 Close The Infona portal uses cookies, ie strings of text saved by a browser on the user's device. The portal can access those files and use them to remember the user's data, such as their chosen settings (screen view, interface language, etc.), or their login data. By using the Infona portal the user accepts automatic saving and using this information for portal operation purposes. More information on the subject can be found in the Privacy Policy and Terms of Service. By closing this window the user confirms that they have read the information on cookie usage, and they accept the privacy policy and the way cookies are used by the portal. You can change the cookie settings in your browser. I accept Polski English Login or register account remember me Password recovery INFONA - science communication portal INFONA Search advanced search Browse \u2026", "num_citations": "1\n", "authors": ["687"]}
{"title": "Precondition coverage in software testing\n", "abstract": " Preconditions indicate when it is permitted to use a given function. However, it is not always the case that both outcomes of a precondition are observed during testing. A precondition that is always false makes a function unusable, a precondition that is always true may turn out to be actually an invariant. In model-based testing, preconditions describes when a transition may be executed from a given state. If no outgoing transition is enabled in a given state because all preconditions of all outgoing transitions are false, the test model may be flawed. Experiments show a low test coverage of preconditions in the Scala library. We also investigate preconditions in Modbat models for model-based testing, in that case, a certain number of test cases is needed to produce sufficient coverage, but remaining cases of low coverage indeed point to legitimate flaws in test models or code.", "num_citations": "1\n", "authors": ["687"]}
{"title": "Automated technology for verification and analysis\n", "abstract": " This volume contains the papers presented at ATVA 2016, the 14th International Symposium on Automated Technology for Verification and Analysis held during October 17\u201320 in Chiba, Japan. The purpose of ATVA is to promote research on theoretical and practical aspects of automated analysis, verification, and synthesis by providing an international forum for interaction among researchers in academia and industry.ATVA attracted 82 submissions in response to the call for papers. Each submission was assigned to at least four reviewers of the Program Committee. The Program Committee discussed the submissions electronically, judging them on their perceived importance, originality, clarity, and appropriateness to the expected audience. The Program Committee selected 31 papers for presentation, leading to an acceptance rate of 38%.", "num_citations": "1\n", "authors": ["687"]}
{"title": "Guiding random test generation with program analysis\n", "abstract": " Random test generation is effective in creating method sequences for exercising the software under test. However, black-box approaches for random testing are known to suffer from low code coverage and limited defect detection ability. Analyzing the software under test and using the extracted knowledge to guide test generation can help to overcome these limitations. We developed a random test case generator augmented by a combination of six static and dynamic program analysis techniques. Our tool GRT (Guided Random Testing) has been evaluated on realworld software systems as well as Defects4J benchmarks. It outperformed related approaches in terms of code coverage, mutation score and detected faults. The results show a considerable improvement potential of random test generation when combined with advanced analysis techniques.", "num_citations": "1\n", "authors": ["687"]}
{"title": "Formal Techniques for Safety-Critical Systems\n", "abstract": " This volume contains the proceedings of the Second International Workshop of Formal Techniques for Safety-Critical Systems (FTSCS 2013), held in scenic Queenstown, New Zealand, during October 29\u201330, 2013, as a satellite event of the ICFEM conference.The aim of FTSCS is to bring together researchers and engineers who are interested in the application of formal and semi-formal methods to improve the quality of safetycritical computer systems. FTSCS strives to promote research and development of formal methods and tools for industrial applications, and is particularly interested in industrial applications of formal methods. Specific topics of the workshop include, but are not limited to:", "num_citations": "1\n", "authors": ["687"]}
{"title": "Improving automatic centralization by version separation\n", "abstract": " With today\u2019s importance of distributed applications, their verification and analysis are still challenging. They involve large combinational states, interactive network communications between peers, and concurrency. Although there are some dynamic analysis tools for analyzing the runtime behavior of a single-process application, they do not provide methods to analyze distributed applications as a whole, where multiple processes run simultaneously. Centralization is a general solution which transforms multi-process applications into a single-process one that can be directly analyzed by existing tools. In this paper, we improve the accuracy of centralization. Moreover, we extend it as a general framework for analyzing distributed applications with multiple versions. First, we formalize the version conflict problem and present a simple solution, and further propose an optimized solution to resolving class version conflicts during centralization. Our techniques enable sharing common code whenever possible while keeping the version space of each component application separate. Centralization issues like startup semantics and static field transformation are improved and discussed. We implement and apply our centralization tool to some network benchmarks. Experiments, where existing tools are used on the centralized application, prove the usefulness of our automatic centralization tool, showing that centralization enables these tools to analyze distributed applications with multiple versions.", "num_citations": "1\n", "authors": ["687"]}
{"title": "Run-time verification of networked software\n", "abstract": " Most applications that are in use today inter-operate with other applications, so-called peers, over a network. The analysis of such distributed applications requires that the effect of the communication with peers is included. This can be achieved by writing or generating stubs of peers, or by including all processes in the execution environment. The latter approach also requires special treatment of network communication primitives.               We also present an alternative approach, which analyzes a networked application by recording and caching its communication with peers. Caching becomes useful when several traces of the application are analyzed. It dispenses with the need of generating a new peer application execution for each different execution of the main application. Such a caching framework for input/output has been implemented on the Java PathFinder platform, which can be used to verify\u00a0\u2026", "num_citations": "1\n", "authors": ["687"]}