{"title": "Model-integrated computing\n", "abstract": " Computers now control many critical systems in our lives, from the brakes on our cars to the avionics control systems on planes. Such computers wed physical systems to software, tightly integrating the two and generating complex component interactions unknown in earlier systems. Thus, it is imperative that we construct software and its associated physical system so they can evolve together. The paper discusses one approach that accomplishes this called model-integrated computing. This works by extending the scope and use of models. It starts by defining the computational processes that a system must perform and develops models that become the backbone for the development of computer-based systems. In this approach, integrated, multiple-view models capture information relevant to the system under design. The paper considers the Multigraph Architecture framework for model-integrated computing\u00a0\u2026", "num_citations": "681\n", "authors": ["572"]}
{"title": "Model-integrated development of embedded software\n", "abstract": " The paper describes a model-integrated approach for embedded software development that is based on domain-specific, multiple-view models used in all phases of the development process. Models explicitly represent the embedded software and the environment it operates in, and capture the requirements and the design of the application, simultaneously. Models are descriptive , in the sense that they allow the formal analysis, verification, and validation of the embedded system at design time. Models are also generative, in the sense that they carry enough information for automatically generating embedded systems using the techniques of program generators. Because of the widely varying nature of embedded systems, a single modeling language may not be suitable for all domains; thus, modeling languages are often domain-specific. To decrease the cost of defining and integrating domain-specific modeling\u00a0\u2026", "num_citations": "606\n", "authors": ["572"]}
{"title": "Toward a science of cyber\u2013physical system integration\n", "abstract": " System integration is the elephant in the china store of large-scale cyber-physical system (CPS) design. It would be hard to find any other technology that is more undervalued scientifically and at the same time has bigger impact on the presence and future of engineered systems. The unique challenges in CPS integration emerge from the heterogeneity of components and interactions. This heterogeneity drives the need for modeling and analyzing cross-domain interactions among physical and computational/networking domains and demands deep understanding of the effects of heterogeneous abstraction layers in the design flow. To address the challenges of CPS integration, significant progress needs to be made toward a new science and technology foundation that is model based, precise, and predictable. This paper presents a theory of composition for heterogeneous systems focusing on stability. Specifically\u00a0\u2026", "num_citations": "343\n", "authors": ["572"]}
{"title": "Developing applications using model-driven design environments\n", "abstract": " Historically, software development methodologies have focused more on improving tools for system development than on developing tools that assist with system composition and integration. Component-based middleware like Enterprise Java-Beans (EJB), Microsoft .NET, and the CORBA Component Model (CCM) have helped improve software reusability through component abstraction. However, as developers have adopted these commercial off-the-shelf technologies, a wide gap has emerged between the availability and sophistication of standard software development tools like compilers and debuggers, and the tools that developers use to compose, analyze, and test a complete system or system of systems. As a result, developers continue to accomplish system integration using ad hoc methods without the support of automated tools. Model-driven development is an emerging paradigm that solves numerous\u00a0\u2026", "num_citations": "295\n", "authors": ["572"]}
{"title": "Artificial neural networks applied to arc welding process modeling and control\n", "abstract": " Artificial neural networks have been studied to determine their applicability to modeling and control of physical processes. Some basic concepts relating to neural networks and how they can be used to model weld-bead geometry in terms of the equipment parameters selected to produce the weld are explained. Approaches to utilizing neural networks in process control are discussed. The need for modeling transient as well as static characteristics of physical systems for closed-loop control is pointed out, and an approach to achieving this is presented. The performance of neural networks for modeling is evaluated using actual welding data. It is concluded that the accuracy of neural network modeling is fully comparable with the accuracy achieved by more traditional modeling schemes.< >", "num_citations": "254\n", "authors": ["572"]}
{"title": "Design guidelines for domain specific languages\n", "abstract": " Designing a new domain specific language is as any other complex task sometimes error-prone and usually time consuming, especially if the language shall be of high-quality and comfortably usable. Existing tool support focuses on the simplification of technical aspects but lacks support for an enforcement of principles for a good language design. In this paper we investigate guidelines that are useful for designing domain specific languages, largely based on our experience in developing languages as well as relying on existing guidelines on general purpose (GPLs) and modeling languages. We defined guidelines to support a DSL developer to achieve better quality of the language design and a better acceptance among its users.", "num_citations": "246\n", "authors": ["572"]}
{"title": "Metamodeling-rapid design and evolution of domain-specific modeling environments\n", "abstract": " Model integrated computing (MIC) is gaining increased attention as an effective and efficient method for developing, maintaining, and evolving large-scale, domain-specific software applications for computer-based systems. MIC is a model-based approach to software development, allowing the synthesis of application programs from models created using customized, domain-specific model integrated program synthesis (MIPS) environments. Until now, these MIPS environments have been handcrafted. Analysis has shown that it is possible to \"model the modeling environment\" by creating a metamodel that specifies both the syntactic and semantic behavior of the desired domain-specific MIPS environment (DSME). Such a metamodel could then be used to synthesize the DSME itself allowing the entire design environment to safely and efficiently evolve in the face of changing domain requirements. This paper\u00a0\u2026", "num_citations": "238\n", "authors": ["572"]}
{"title": "Semantic translation of simulink/stateflow models to hybrid automata using graph transformations\n", "abstract": " Embedded systems are often modeled using Matlab's Simulink and Stateflow (MSS), to simulate plant and controller behavior but these models lack support for formal verification. On the other hand verification techniques and tools do exist for models based on the notion of Hybrid Automata (HA) but there are no tools that can convert Simulink/Stateflow models into their semantically equivalent Hybrid Automata models. This paper describes a translation algorithm that converts a well-defined subset of the MSS modeling language into an equivalent hybrid automata. The translation has been specified and implemented using a metamodel-based graph transformation tool. The translation process allows semantic interoperability between the industry-standard MSS tools and the new verification tools developed in the research community.", "num_citations": "202\n", "authors": ["572"]}
{"title": "The graph rewriting and transformation language: GReAT\n", "abstract": " In this paper, we describe the language and features of our graph transformation tool, GReAT. We begin with a brief introduction and motivation, followed by an overview of the actual language, the modeling framework, and the tools that were written to support transformations. Finally, we compare GReAT to other similar tools, discuss additional functionality we are currently implementing, and describe some of our experiences with the tool thus far.", "num_citations": "176\n", "authors": ["572"]}
{"title": "Constraint-based design-space exploration and model synthesis\n", "abstract": " An important bottleneck in model-based design of embedded systems is the cost of constructing models. This cost can be significantly decreased by increasing the reuse of existing model components in the design process. This paper describes a tool suite, which has been developed for component-based model synthesis. The DESERT tool suite can be interfaced to existing modeling and analysis environments and can be inserted in various, domain specific design flows. The modeling component of DESERT supports the modeling of design spaces and the automated search for designs that meet structural requirements. DESERT has been introduced in automotive applications and proved to be useful in increasing design productivity.", "num_citations": "162\n", "authors": ["572"]}
{"title": "The design of a language for model transformations\n", "abstract": " Model-driven development of software systems envisions transformations applied in various stages of the development process. Similarly, the use of domain-specific languages also necessitates transformations that map domain-specific constructs into the constructs of an underlying programming language. Thus, in these cases, the writing of transformation tools becomes a first-class activity of the software engineer. This paper introduces a language that was designed to support implementing highly efficient transformation programs that perform model-to-model or model-to-code translations. The language uses the concepts of graph transformations and metamodeling, and is supported by a suite of tools that allow the rapid prototyping and realization of transformation tools.", "num_citations": "149\n", "authors": ["572"]}
{"title": "Graph transformations on domain-specific models\n", "abstract": " In model driven development, model transformations play a crucial role. This paper introduces a new, UML-based approach for the specification and implementation of model transformations. The technique is based on graph transformations, where the transformations are a set of explicitly sequenced elementary rewriting operations. UML class diagrams are used to represent the graph grammars for the input and output graphs. The paper\u2019s main contributions are the visual language designed for the representation of transformation programs and the graph transformation execution engine which implements the semantics of the language.", "num_citations": "138\n", "authors": ["572"]}
{"title": "Composition and cloning in modeling and meta-modeling\n", "abstract": " The Generic Modeling Environment (GME) is a configurable tool suite that facilitates the rapid creation of domain-specific model-integrated program synthesis environments. There are three characteristics of the GME that make it a valuable tool for the construction of domain-specific modeling environments. First, the GME provides generic modeling primitives that assist an environment designer in the specification of new graphical modeling environments. Second, these generic primitives are specialized to create the domain-specific modeling concepts through meta-modeling. The meta-models explicitly support composition enabling the creation of composite modeling languages supporting multiple paradigms. Third, several ideas from prototype-based programming languages have been integrated with the inherent model containment hierarchy, which gives the domain expert the ability to clone graphical models\u00a0\u2026", "num_citations": "126\n", "authors": ["572"]}
{"title": "An end-to-end domain-driven software development framework\n", "abstract": " This paper presents a comprehensive, domain-driven framework for software development. It consists of a meta-programmable domain-specific modeling environment and a model transformation generator toolset based on graph transformations. The framework allows the creation of custom, domain-oriented programming environments that support end-user programmability. In addition, the framework could be considered an early, end-to-end implementation of the concepts advocated by the OMG's Model Driven Architecture initiative.", "num_citations": "122\n", "authors": ["572"]}
{"title": "Real-time fault diagnostics\n", "abstract": " The intelligent process control system (IPCS), an integrated environment for developing complex process control and automation systems is discussed, focusing on its real-time fault diagnostics capability. IPCS has been used to build a supervisory monitoring and diagnostics system for a cogenerator plant. The requirements and problems specific to such systems are examined. The key concepts involved in fault modeling in IPCS are explicated. The IPCS reasoning technique is described in some detail. The IPCS tool kit is also described. IPCS's performance in the cogenerator plant application is reported.< >", "num_citations": "112\n", "authors": ["572"]}
{"title": "Multiple aspect operator interface for displaying fault diagnostics results in intelligent process control systems\n", "abstract": " In a fault diagnostic system, an operator interface simultaneously displays an operations hierarchy and a components hierarchy in two separate windows. The display system is used with a model-based diagnostic system that monitors operational parameters of an industrial process. The diagnostic system identifies possible failure source components in the industrial process and the display system uses these diagnostics to display the most interesting portions of the operations hierarchy and the components hierarchy. The most interesting node, to be displayed with its subtree, is defined as the node at the lowest level of the hierarchy that is both a fault source and that has more children than than other fault sources at that level.", "num_citations": "111\n", "authors": ["572"]}
{"title": "On metamodel composition\n", "abstract": " Computer-based systems (CBS) development integrates various disciplines, such as hardware design, software engineering, and performance modeling, as well as the \"base\" engineering discipline in which the CBS will operate. As such, use of a \"non-native\" modeling language is not acceptable when performing CBS design, and rapid specification and development of domain-specific modeling languages (DSMLs) is necessary. We advocate a UML-based metamodeling technique to DSML specification and generation. A key feature of our approach is the composition of new metamodels from existing metamodels through the use of three newly defined UML operators-equivalence, implementation inheritance, and interface inheritance. The paper describes the development of these new operators, details how they are used in metamodel composition, and presents examples of metamodel composition.", "num_citations": "110\n", "authors": ["572"]}
{"title": "A testbed for secure and robust SCADA systems\n", "abstract": " The Supervisory Control and Data Acquisition System (SCADA) monitor and control real-time systems. SCADA systems are the backbone of the critical infrastructure, and any compromise in their security can have grave consequences. Therefore, there is a need to have a SCADA testbed for checking vulnerabilities and validating security solutions. In this paper we develop such a SCADA testbed.", "num_citations": "103\n", "authors": ["572"]}
{"title": "A model-based approach to self-adaptive software\n", "abstract": " The authors' model based approach to self adaptive software systems uses domain specific models and components to restore flexibility and adaptability to software systems running in dynamic environments. The model-integrated approach to self adaptive software, decomposes the problem into two major issues: the issues of representation and that of the reconfiguration mechanism. The goal of the work is to facilitate a performance/spl rarr/evolution/spl rarr/architecture modification/spl rarr/modified performance cycle in which the application's performance is continuously monitored, with the results used to modify the architectural model. The modification is then followed by a partial or complete regeneration of the executable system. We have implemented and tested some aspects of our approach in applications; other aspects are part of our ongoing investigation in various research projects.", "num_citations": "103\n", "authors": ["572"]}
{"title": "Towards verifying model transformations\n", "abstract": " In model-based software development, a complete design and analysis process involves designing the system using the design language, converting it into the analysis language, and performing the verification and analysis on the analysis model. Graph transformation is increasingly being used to automate this conversion. In such a scenario, it is very important that the conversion preserves the semantics of the design model. This paper discusses an approach to verify this semantic equivalence for each transformation. We will show how to check whether a particular transformation resulted in an output model that preserves the semantics of the input model with respect to a particular property.", "num_citations": "100\n", "authors": ["572"]}
{"title": "Generative programming via graph transformations in the model-driven architecture\n", "abstract": " The Model-Driven Architecture of OMG envisions a development paradigm where designers create a Platform-Independent Model (PIM) of the design, which is then refined into a Platform-Specific Model (PSM). This paper argues that this approach lends itself well to generative programming techniques, and that tools are needed to support this transformation. The paper shows how a technique based on graph transformations could be applied to automate the process, as well as make it user-extendible.", "num_citations": "96\n", "authors": ["572"]}
{"title": "MULTIGRAPH: An architecture for model-integrated computing\n", "abstract": " The design, implementation and deployment of computer applications tightly integrated with complex, changing environments is a difficult task. This paper presents the Multigraph Architecture (MGA) developed for building complex embedded systems. The MGA is a meta-level architecture which includes tools and methods to create domain specific model integrated program synthesis environments. These environments support the integrated modeling of systems independently from their implementation, include tools for model analysis and application specific model interpreters for the synthesis of executable programs.", "num_citations": "96\n", "authors": ["572"]}
{"title": "Self-adaptive software for signal processing\n", "abstract": " The design of DSP systems is based on the available a priori information about the signal source and the noise in the environment. Necessarily, the performance of the target system largely depends on the environmental conditions as well as additional factors, such as the computational resources available to the task. In conventional design approaches, these conditions are typically set at design time by introducing various constraints, simplifications, and assumptions. The critical issue in this methodology is: What happens if the design time assumptions do not hold? Stabilization of the environment is impossible in many applications. For example, in turbine engine testing, the deterioration of sensors is unavoidable. Changes in analysis objectives demand dramatic changes in computational strategies. The goal of designing a single, sufficiently robust DSP algorithm able to tolerate all possible changes in the\u00a0\u2026", "num_citations": "94\n", "authors": ["572"]}
{"title": "A robust method for hybrid diagnosis of complex systems\n", "abstract": " The AI model-based diagnosis community has developed qualitative reasoning mechanisms for fault isolation in dynamic systems. Their emphasis has been on the fault isolation algorithms, and little attention has been paid to robust online detection and symbol generation that are essential components of a complete diagnostic solution. This paper discusses a robust diagnosis methodology for hybrid systems that combines fault detection with a combined qualitative and quantitative fault isolation scheme. We focus on fault detection, symbol generation, and parameter estimation, and illustrate the effectiveness of this method by running experiments on the fuel transfer system of aircraft", "num_citations": "93\n", "authors": ["572"]}
{"title": "Model-integrated development of cyber-physical systems\n", "abstract": " Cyber-physical systems represent a new class of systems that integrate physics with computation. Their correct design is frequently of great importance as they are applied in safety- or business-critical contexts. This paper introduces a model-integrated development approach that addresses the development needs of such systems through the pervasive use of models. A complete model-based view is proposed that covers all aspects of the hardware and software components, as well as their interactions. Early experiments and work in progress are also reported.", "num_citations": "92\n", "authors": ["572"]}
{"title": "Design patterns for open tool integration\n", "abstract": " Design tool integration is a highly relevant area of software engineering that can greatly improve the efficiency of development processes. Design patterns have been widely recognized as important contributors to the success of software systems. This paper describes and compares two large-grain, architectural design patterns that solve specific design tool integration problems. Both patterns have been implemented and used in real-life engineering processes.", "num_citations": "92\n", "authors": ["572"]}
{"title": "Model-based integration platform for FMI co-simulation and heterogeneous simulations of cyber-physical systems\n", "abstract": " Virtual evaluation of complex Cyber-Physical Systems (CPS)[1] with a number of tightly integrated domains such as physical, mechanical, electrical, thermal, cyber, etc. demand the use of heterogeneous simulation environments. Our previous effort with C2 Wind Tunnel (C2WT)[2][3] attempted to solve the challenges of evaluating these complex systems as-a-whole, by integrating multiple simulation platforms with varying semantics and integrating and managing different simulation models and their interactions. Recently, a great interest has developed to use Functional Mockup Interface (FMI)[4] for a variety of dynamics simulation packages, particularly in the automotive industry. Leveraging the C2WT effort on effective integration of different simulation engines with different Models of Computation (MoCs), we propose, in this paper, to use the proven methods of High-Level Architecture (HLA)-based model and system integration. We identify the challenges of integrating Functional Mockup Unit for Co-Simulation (FMU-CS) in general and via HLA [5] and present a novel model-based approach to rapidly synthesize an effective integration. The approach presented provides a unique opportunity to integrate readily available FMU-CS components with various specialized simulation packages to rapidly synthesize HLA-based integrated simulations for the overall composed Cyber-Physical Systems.", "num_citations": "90\n", "authors": ["572"]}
{"title": "Model reuse with metamodel-based transformations\n", "abstract": " Metamodel-based transformations permit descriptions of mappings between models created using different concepts from possibly overlapping domains. This paper describes the basic algorithms used in matching metamodel constructs, and how this match is to be applied. The transformation process facilitates the reuse of models specified in one domain-specific modeling language in another context: another domain-specific modeling language. UML class diagrams are used as the language of the metamodels. The focus of the paper is on the matching and firing of transformation rules, and on finding efficient and generic algorithms. An illustrative case study is provided.", "num_citations": "88\n", "authors": ["572"]}
{"title": "Rapid synthesis of high-level architecture-based heterogeneous simulation: a model-based integration approach\n", "abstract": " Virtual evaluation of complex command and control concepts demands the use of heterogeneous simulation environments. Development challenges include how to integrate multiple simulation engines with varying semantics and how to integrate simulation models and manage the complex interactions between them. While existing simulation frameworks may provide many of the required run-time services needed to coordinate among multiple simulation engines, they lack an overarching integration approach that connects and relates the interoperability of heterogeneous domain models and their interactions. This paper outlines some of the challenges encountered in developing a command and control simulation environment and discusses our use of the Generic Modeling Environment tool suite to create a model-based integration approach that allows for rapid synthesis of complex high-level architecture\u00a0\u2026", "num_citations": "85\n", "authors": ["572"]}
{"title": "Automatic domain model migration to manage metamodel evolution\n", "abstract": " Metamodel evolution is a significant problem in domain specific software development for several reasons. Domain-specific modeling languages (DSMLs) are likely to evolve much more frequently than programming languages and commonly used software formalisms, often resulting in a large number of valuable instance models that are no longer compliant with the metamodel. In this paper, we present the Model Change Language (MCL), aimed at satisfying these requirements.", "num_citations": "84\n", "authors": ["572"]}
{"title": "An approach to self-adaptive software based on supervisory control\n", "abstract": " Self-adaptive software systems use observations of their own behavior, and that of their environment, to select and enact adaptations in accordance with some objective(s). This adaptation is a higher-level system function that performs optimizations, manages faults, or otherwise supports achieving an objective via changes in the running system. In this paper, we show how this capability can be realized using techniques found in hierarchical control systems, and we discuss interrelated issues of stability, assurance, and implementation.", "num_citations": "82\n", "authors": ["572"]}
{"title": "A component model for hard real\u2010time systems: CCM with ARINC\u2010653\n", "abstract": " The size and complexity of software in safety\u2010critical systems is increasing at a rapid pace. One technology that can be used to mitigate this complexity is component\u2010based software development. However, in spite of the apparent benefits of a component\u2010based approach to development, little work has been done in applying these concepts to hard real\u2010time systems. This paper improves the state of the art by making three contributions: (1) we present a component model for hard real\u2010time systems and define the semantics of different types of component interactions; (2) we present an implementation of a middleware that supports this component model. This middleware combines an open\u2010source CORBA Component Model (CCM) implementation (MICO) with ARINC\u2010653: a state\u2010of\u2010the\u2010art real\u2010time operating systems (RTOS) standard, (3) finally; we describe a modeling environment that enables design, analysis\u00a0\u2026", "num_citations": "80\n", "authors": ["572"]}
{"title": "Simulation of network attacks on SCADA systems\n", "abstract": " It is essential to model and simulate communication networks to study mission critical situations SCADA system is composed of units in domains like dynamic systems, networks and physical environments Each of these units can be modeled using a variety of available simulators and/or emulators", "num_citations": "77\n", "authors": ["572"]}
{"title": "Introducing embedded software and systems education and advanced learning technology in an engineering curriculum\n", "abstract": " Embedded software and systems are at the intersection of electrical engineering, computer engineering, and computer science, with, increasing importance, in mechanical engineering. Despite the clear need for knowledge of systems modeling and analysis (covered in electrical and other engineering disciplines) and analysis of computational processes (covered in computer science), few academic programs have integrated the two disciplines into a cohesive program of study. This paper describes the efforts conducted at Vanderbilt University to establish a curriculum that addresses the needs of embedded software and systems. Given the compartmentalized nature of traditional engineering schools, where each discipline has an independent program of study, we have had to devise innovative ways to bring together the two disciplines. The paper also describes our current efforts in using learning technology to\u00a0\u2026", "num_citations": "77\n", "authors": ["572"]}
{"title": "A configurable visual programming environment: A tool for domain-specific programming\n", "abstract": " Visual programming is an appealing technique, which many environments support. It can be applied in a system development process that nonsoftware engineers can perform. The key is to use visual domain specific models. Because there are many different domains, it is economical to develop a generic and configurable visual programming environment (VPE) that can be customized for the domains and paradigms. The author discusses a generic VPE's requirements, design, and implementation, and illustrates its use in a system, the Intelligent Process-Control System (IPCS), for the process control domain. This VPE and the IPCS have been developed in a multiyear research effort. Different versions of the VPE are used at many companies, including Boeing, DuPont, and NASA, and the IPCS has been commercialized by the Osaka Gas Information Systems Research Institute (Osaka, Japan).< >", "num_citations": "77\n", "authors": ["572"]}
{"title": "Model-based software synthesis\n", "abstract": " The knowledge-representation and compilation techniques used in a model-based, automatic software synthesis environment are discussed. The environment was used to build Caddmus, a system with more than 250 cooperating processes. The real-time execution environment automatically generates a macro-dataflow computation from declarative models. Central to the approach is the Multigraph Architecture, which provides the framework for model-based synthesis in real-time, parallel-computing environments. Application of Caddmus to analysis of all data related to testing new and redesigned turbine engines is described.< >", "num_citations": "76\n", "authors": ["572"]}
{"title": "Generative programming for embedded systems\n", "abstract": " Embedded systems represent fundamentally new challenges for software design, which render conventional approaches to software composition ineffective. Starting with the unique challenges of building embedded systems, this paper discusses key issues of model-based technology for embedded systems. The discussion uses Model-Integrated Computing (MIC) as an example for model-based software development. In MIC, domain-specific, multiple view models are used in all phases of the development process. Models explicitly represent the embedded software and the environment it operates in, and capture the requirements of the application, simultaneously. Models are descriptive, in the sense that they allow the formal analysis, verification and validation of the embedded system at design time. Models are also generative, in the sense that they carry enough information for automatically generating\u00a0\u2026", "num_citations": "71\n", "authors": ["572"]}
{"title": "A UML-based graph transformation approach for implementing domain-specific model transformations\n", "abstract": " This paper introduces a UML-based approach for specifying model transformations. The technique is based on graph transformations, where UML class diagrams are used to represent the graph grammars of the input and the output of the transformations, and the transformations are represented as explicitly sequenced elementary rewriting operations. The paper discusses the visual language designed for the representation of transformation programs and the graph transformation execution engine which implements the semantics of the language.", "num_citations": "67\n", "authors": ["572"]}
{"title": "Riaps: Resilient information architecture platform for decentralized smart systems\n", "abstract": " The emerging Fog Computing paradigm provides an additional computational layer that enables new capabilities in real-time data-driven applications. This is especially interesting in the domain of Smart Grid as the boundaries between traditional generation, distribution, and consumer roles are blurring. This is a reflection of the ongoing trend of intelligence distribution in Smart Systems. In this paper, we briefly describe a component-based decentralized software platform called Resilient Information Architecture Platform for Smart Systems (RIAPS) which provides an infrastructure for such systems. We briefly describe some initial applications built using this platform. Then, we focus on the design and integration choices for a resilient Discovery Manager service that is a critical component of this infrastructure. The service allows applications to discover each other, work collaboratively, and ensure the stability of the\u00a0\u2026", "num_citations": "62\n", "authors": ["572"]}
{"title": "Practical implementation of diagnosis systems using timed failure propagation graph models\n", "abstract": " Timed failure propagation graphs (TFPGs) are causal models that capture the temporal aspects of failure propagation in typical engineering systems. In this paper, we present several practical modeling and reasoning considerations that have been addressed based on experience with complex real-time vehicle subsystems. These include handling intermittent faults, reasoning over dynamically commanded test sequences, dealing with the constraints of limited computational resources, and providing automated model verification. We finally present a vehicle subsystem case study.", "num_citations": "61\n", "authors": ["572"]}
{"title": "Reusable idioms and patterns in graph transformation languages\n", "abstract": " Software engineering tools based on Graph Transformation techniques are becoming available, but their practical applicability is somewhat reduced by the lack of idioms and design patterns. Idioms and design patterns provide prototypical solutions for recurring design problems in software engineering, but their use can be easily extended into software development using graph transformation systems. In this paper we briefly present a simple graph transformation language: GReAT, and show how typical design problems that arise in the context of model transformations can be solved using its constructs. These solutions are similar to software design patterns, and intend to serve as the starting point for a more complete collection.", "num_citations": "59\n", "authors": ["572"]}
{"title": "SURE: A modeling and simulation integration platform for evaluation of secure and resilient cyber\u2013physical systems\n", "abstract": " The exponential growth of information and communication technologies have caused a profound shift in the way humans engineer systems leading to the emergence of closed-loop systems involving strong integration and coordination of physical and cyber components, often referred to as cyber-physical systems (CPSs). Because of these disruptive changes, physical systems can now be attacked through cyberspace and cyberspace can be attacked through physical means. The paper considers security and resilience as system properties emerging from the intersection of system dynamics and the computing architecture. A modeling and simulation integration platform for experimentation and evaluation of resilient CPSs is presented using smart transportation systems as the application domain. Evaluation of resilience is based on attacker-defender games using simulations of sufficient fidelity. The platform\u00a0\u2026", "num_citations": "58\n", "authors": ["572"]}
{"title": "MDE-based approach for generalizing design space exploration\n", "abstract": " Design Space Exploration (DSE) is the exploration of design alternatives before the implementation. Existing DSE frameworks are domain-specific where the representation, evaluation method as well as exploration algorithm are tightly coupled with domain-dependent assumptions. Although the tasks involved in DSE are similar, the inflexibility of the existing frameworks restricts their reuse for solving DSE problems from other domains.               This paper presents an MDE-based approach for generalizing DSE techniques. The framework supports a reconfigurable representation of a design space, which is decoupled from exploration algorithm. The framework can be configured to solve DSE problems from different domains and enables the designer to experiment with different approaches to solve the same problem with minimum effort. The main contributions of this framework are: (1) rapid modeling of\u00a0\u2026", "num_citations": "57\n", "authors": ["572"]}
{"title": "A novel approach to semi-automated evolution of dsml model transformation\n", "abstract": " In the industrial applications of Model-Based Development, the evolution of modeling languages is an inevitable issue. The migration to the new language involves the reuse of the existing artifacts created for the original language, such as models and model transformations. This paper is devoted to an evolution method for model transformations as well as the related algorithms. The change description is assumed to be available in a modeling language specific to the evolution. Based on the change description, our method is able to automate certain parts of the evolution. When automation is not possible, our algorithms automatically alert the user about the missing semantic information, which can then be provided manually after the automatic part of the interpreter evolution. The algorithms have been implemented and tested in an industrial environment. The results indicate that the semi-automated\u00a0\u2026", "num_citations": "57\n", "authors": ["572"]}
{"title": "An examination of DSLs for concisely representing model traversals and transformations\n", "abstract": " A key advantage for the use of a domain-specific language (DSL) is the leverage that can be captured from a concise representation of a programmer's intention. This paper reports on three different DSLs that were developed for two different projects. Two of the DSLs assisted in the specification of various modeling tool ontologies, and the integration of models across these tools. On another project, a different DSL has been applied as a language to assist in aspect-oriented modeling. Each of these three languages was converted to C++ using different code generators. These DSLs were concerned with issues of traversing a model and performing transformations. The paper also provides quantitative data on the relative sizes of the intention (as expressed in the DSL) and the generated C++ code. Observations are made regarding the nature of the benefits and the manner in which the conciseness of the DSL is\u00a0\u2026", "num_citations": "57\n", "authors": ["572"]}
{"title": "Simultaneous data-driven and demand-driven computational model for dynamically configured systems\n", "abstract": " In a model-based dynamically configured system, various processing components are created dynamically, interfaced to each other, and scheduled upon demand. A combination of data driven and demand-driven scheduling techniques are used to enhance the effectiveness of the dynamically configured system.", "num_citations": "57\n", "authors": ["572"]}
{"title": "Udm: An infrastructure for implementing domain-specific modeling languages\n", "abstract": " Domain-specific modeling languages amortize the cost of the development of a language over all the software products they can be used for. This paper describes an infrastructure for developing DSMLs and using them in a systematic manner. The infrastructure consists of a modeling language (UML class diagrams), a modeling tool, a code generator, and a number of generic libraries that provide support for object performance in several forms.", "num_citations": "56\n", "authors": ["572"]}
{"title": "Model-driven architecture for embedded software: A synopsis and an example\n", "abstract": " MDA proposes a new paradigm for software development in general. We claim that MDA could be beneficial for embedded software development, especially if it is extended to address the special needs of embedded systems. The paper consists of two sections: the first is a brief synopsis on how MDA ought to be extended to handle embedded software development, while the second illustrates the concepts in practice using a prototype modeling language and tool chain designed for developing mission computing software.", "num_citations": "54\n", "authors": ["572"]}
{"title": "Model-based software health management for real-time systems\n", "abstract": " Complexity of software systems has reached the point where we need run-time mechanisms that can be used to provide fault management services. Testing and verification may not cover all possible scenarios that a system will encounter, hence a simpler, yet formally specified run-time monitoring, diagnosis, and fault mitigation architecture is needed to increase the software system's dependability. The approach described in this paper borrows concepts and principles from the field of \u201cSystems Health Management\u201d for complex systems and implements a two level health management strategy that can be applied through a model-based software development process. The Component-level Health Manager (CLHM) for software components provides a localized and limited functionality for managing the health of a component locally. It also reports to the higher-level System Health Manager (SHM) which manages the\u00a0\u2026", "num_citations": "52\n", "authors": ["572"]}
{"title": "Model based analysis and test generation for flight software\n", "abstract": " We describe a framework for model-based analysis and test case generation in the context of a heterogeneous model-based development paradigm that uses and combines MathWorks and UML 2.0 models and the associated code generation tools. This paradigm poses novel challenges to analysis and test case generation that, to the best of our knowledge, have not been addressed before. The framework is based on a common intermediate representation for different modeling formalisms and leverages and extends model checking and symbolic execution tools for model analysis and test case generation, respectively. We discuss the application of our framework to software models for a NASA flight mission.", "num_citations": "52\n", "authors": ["572"]}
{"title": "Specifying graphical modeling systems using constraint-based meta models\n", "abstract": " Embedded computer-based systems are becoming highly complex and difficult to implement due to the large number of concerns designers must address. These systems are tightly coupled to their environments, requiring an integrated view that encompasses both the information system and its physical surroundings. Mathematical analysis of such systems requires formal modeling of both \"sides\", including their interaction. There exist a number of suitable modeling techniques for describing both the information system component and physical environment, but the best choice changes from domain to domain. We propose a two-level approach to modeling that introduces a meta-level representation. Meta-level models define modeling languages, but they can also be used to capture subtle interactions between domain level models. We show how the two-level approach can be supported with computational tools\u00a0\u2026", "num_citations": "51\n", "authors": ["572"]}
{"title": "Automatic test generation for model-based real-time fault diagnostic systems\n", "abstract": " In a real-time diagnostic system, an alarm sequence generator is used to test the correctness of a fault model. The fault model describes an industrial process being monitored. The alarm sequence generator reads the fault model and generates a user interface, from which specific components can be selected for failure at specified times. The alarm sequence generator assembles all alarms that are causally downstream from the selected set of faulty components and determines which alarms should be turned on based on probabilistic and temporal information in the fault model. The timed alarm sequence can be used by an expert to measure the correctness of a particular model, or can be used as input into a diagnostic system to measure the correctness of the diagnostic system.", "num_citations": "51\n", "authors": ["572"]}
{"title": "A co-simulation framework for design of time-triggered automotive cyber physical systems\n", "abstract": " Designing cyber-physical systems (CPS) is challenging due to the tight interactions between software, network/platform, and physical components. Automotive control system is a typical CPS example and often designed based on a time-triggered paradigm. In this paper, a co-simulation framework that considers interacting CPS components for assisting time-triggered automotive CPS design is proposed. Virtual prototyping of automotive vehicles is the core of this framework, which uses SystemC to model the cyber components and integrates CarSim to model the vehicle dynamics. A network/platform model in SystemC forms the backbone of the virtual prototyping. The network/platform model consists of processing elements abstracted by real-time operating systems, communication systems, sensors, and actuators. The framework is also integrated with a model-based design tool to enable rapid prototyping. The\u00a0\u2026", "num_citations": "50\n", "authors": ["572"]}
{"title": "A software platform for fractionated spacecraft\n", "abstract": " A fractionated spacecraft is a cluster of independent modules that interact wirelessly to maintain cluster flight and realize the functions usually performed by a monolithic satellite. This spacecraft architecture poses novel software challenges because the hardware platform is inherently distributed, with highly fluctuating connectivity among the modules. It is critical for mission success to support autonomous fault management and to satisfy real-time performance requirements. It is also both critical and challenging to support multiple organizations and users whose diverse software applications have changing demands for computational and communication resources, while operating on different levels and in separate domains of security. The solution proposed in this paper is based on a layered architecture consisting of a novel operating system, a middleware layer, and component-structured applications. The\u00a0\u2026", "num_citations": "50\n", "authors": ["572"]}
{"title": "The multigraph and structural adaptivity\n", "abstract": " Structurally adaptive and dynamically reconfigurable systems are presented as important ingredients in the design and development of robust large-scale signal processing systems for operation in complex nonstationary environments. The multigraph programming and execution environment (MPEE) simplifies the design and implementation of such systems because of its graph-based computational model, support for dynamic scheduling, multiprocessor programming capabilities, model-based approach to system design, and graphic editors. The use of MPEE is illustrated by a structurally adaptive system example that highlights both the capabilities of the MPEE and the nature of structurally adaptive and dynamically reconfigurable systems. This example, a signal extraction system, also shows how to deal with transients produced by abrupt changes in filter characteristics of filters during run-time.< >", "num_citations": "50\n", "authors": ["572"]}
{"title": "Model-based control design and integration of cyberphysical systems: an adaptive cruise control case study\n", "abstract": " The systematic design of automotive control applications is a challenging problem due to lack of understanding of the complex and tight interactions that often manifest during the integration of components from the control design phase with the components from software generation and deployment on actual platform/network. In order to address this challenge, we present a systematic methodology and a toolchain using well-defined models to integrate components from various design phases with specific emphasis on restricting the complex interactions that manifest during integration such as timing, deployment, and quantization. We present an experimental platform for the evaluation and testing of the design process. The approach is applied to the development of an adaptive cruise control, and we present experimental results that demonstrate the efficacy of the approach.", "num_citations": "49\n", "authors": ["572"]}
{"title": "Building observers to address fault isolation and control problems in hybrid dynamic systems\n", "abstract": " Model based approaches to diagnosis for dynamic systems have been based on continuous and discrete event models. Systems that combine continuous and discrete behaviors, i.e., hybrid systems have been typically abstracted into discrete event models or approximated by continuous models with steep slopes so that existing algorithms can be applied for fault isolation tasks. This approach runs into problems when both discrete events and continuous behaviors provide vital diagnostic information. We propose a diagnostic methodology that uses hybrid models of the system to perform diagnosis.", "num_citations": "49\n", "authors": ["572"]}
{"title": "Application of software health management techniques\n", "abstract": " The growing complexity of software used in large-scale, safety critical cyber-physical systems makes it increasingly difficult to expose and hence correct all potential defects. There is a need to augment the existing fault tolerance methodologies with new approaches that address latent software defects exposed at runtime. This paper describes an approach that borrows and adapts traditional'System Health Management'techniques to improve software dependability through simple formal specification of runtime monitoring, diagnosis, and mitigation strategies. The two-level approach to health management at the component and system level is demonstrated on a simulated case study of an Air Data Inertial Reference Unit (ADIRU). An ADIRU was categorized as the primary failure source for the in-flight upset caused in the Malaysian Air flight 124 over Perth, Australia in 2005.", "num_citations": "48\n", "authors": ["572"]}
{"title": "Model-Based Engineering of Embedded Real-Time Systems: International Dagstuhl Workshop, Dagstuhl Castle, Germany, November 4-9, 2007. Revised Selected Papers\n", "abstract": " Thetopicof \u201cModel-BasedEngineeringofReal-TimeEmbeddedSystems\u201d brings together a challenging problem domain (real-time embedded systems) and a-lution domain (model-based engineering). It is also at the forefrontof integrated software and systems engineering, as software in this problem domain is an essential tool for system implementation and integration. Today, real-time-bedded software plays a crucial role in most advanced technical systems such as airplanes, mobile phones, and cars, and has become the main driver and-cilitator for innovation. Development, evolution, veri? cation, con? guration, and maintenance of embedded and distributed software nowadays are often serious challenges as drastic increases in complexity can be observed in practice. Model-based engineering in general, and model-based software development in particular, advocates the notion of using models throughout the development and life-cycle of an engineered system. Model-based software engineering re-forces this notion by promoting models not only as the tool of abstraction, but also as the tool for veri? cation, implementation, testing, and maintenance. The application of such model-based engineering techniques to embedded real-time systems appears to be a good candidate to tackle some of the problems arising in the problem domain.", "num_citations": "47\n", "authors": ["572"]}
{"title": "Verifying model transformations by structural correspondence\n", "abstract": " Model transformations play a significant role in model based software development, and the correctness of the transformation is crucial to the success of the development effort. We have previously shown how we can use bisimulation to verify the preservation of certain behavioral properties across a transformation. However, transformations are often used to construct structurally different models, and we might wish to ensure that there is some structural correspondence to the original model. It may be possible to verify such transformations without having to explicitly specify the dynamic semantics of the source and target languages. In this paper, we present a technique to verify such transformations, by first specifying certain structural correspondence rules between the source and target languages, and extending the transformation so that these rules can be easily evaluated on the instance models. This will allow us to conclude if the output model has the expected structure. The verification is performed at the instance level, meaning that each execution of the transformation is verified. We will also look at some examples using this technique.", "num_citations": "46\n", "authors": ["572"]}
{"title": "Graph transformations in OMG\u2019s model-driven architecture\n", "abstract": " The Model-Driven Architecture (MDA) vision of the Object Management Group offers a\u00a0unique opportunity for introducing Graph Transformation (GT) technology to the software industry. The paper proposes a\u00a0domain-specific refinement of MDA, and describes a\u00a0practical manifestation of MDA called Model-Integrated Computing (MIC). MIC extends MDA towards domain-specific modeling languages, and it is well supported by various generic tools that include model transformation tools based on graph transformations. The MIC tools are metaprogrammable, i.e. they can be tailored for specific domains using metamodels that include metamodels of transformations. The paper describes the development process and the supporting tools of MIC, and it raises a\u00a0number of issues for future research on GT in MDA.", "num_citations": "45\n", "authors": ["572"]}
{"title": "Metaprogrammable toolkit for model-integrated computing\n", "abstract": " Model-integrated computing, specifically model-integrated program synthesis (MIPS) environments that include visual model building, constraint management, and automatic program synthesis components, are well suited for the design and implementation of complex computer based systems. However, building such an environment from scratch for each new domain can be cost-prohibitive. This paper presents a toolkit that makes the rapid creation of MIPS environments possible through metaprogramming.", "num_citations": "44\n", "authors": ["572"]}
{"title": "Polyglot: modeling and analysis for multiple statechart formalisms\n", "abstract": " In large programs such as NASA Exploration, multiple systems that interact via safety-critical protocols are already designed with different Statechart variants. To verify these safety-critical systems, a unified framework is needed based on a formal semantics that captures the variants of Statecharts. We describe Polyglot, a unified framework for the analysis of models described using multiple State-chart formalisms. In this framework, Statechart models are translated into Java and analyzed using pluggable semantics for different variants operating in a polymorphic execution environment. The framework has been built on the basis of a parametric formal semantics that captures the common core of Statecharts with extensions for different variants, and addresses previous limitations. Polyglot has been integrated with the Java Pathfinder verification tool-set, providing analysis and test-case generation capabilities. We\u00a0\u2026", "num_citations": "43\n", "authors": ["572"]}
{"title": "The model-integrated computing toolsuite: Metaprogrammable tools for embedded control system design\n", "abstract": " Model-Integrated Computing is a development approach that advocates the use of Domain-Specific Modeling throughout the system development process and lifecycle. This paper describes and summarizes the generic and reusable software tools that support MIC and which can be tailored to solve a wide variety of modeling, analysis, and generation problems in an engineering process.", "num_citations": "43\n", "authors": ["572"]}
{"title": "Integrating security modeling into embedded system design\n", "abstract": " There is an ever increasing concern about security threats as embedded systems are moving towards networked applications. Model based approaches have proven to be effective techniques for embedded systems design. However, existing modeling tools were not designed to meet the current and future security challenges of networked embedded systems. In this paper, we propose a framework to incorporate security modeling into embedded system design. We've developed a security analysis tool that can easily integrate with existing tool chains to create co-design environments that addresses security, functionality and system architecture aspects of embedded systems concurrently", "num_citations": "42\n", "authors": ["572"]}
{"title": "A consistency-based robust diagnosis approach for temporal causal systems\n", "abstract": " In this paper we present a consistency-based robust diagnosis approach for a class of temporal causal systems modeled as timed failure propagation graphs. Timed failure propagation graphs are causal models that capture the temporal characteristics of failure propagation in dynamic systems. In this paper, we define the problem of robust diagnosis for this class of systems and introduce an optimal diagnosis algorithm that is robust with respect to sensor faults. The paper outlines the proof for the correctness and optimality of the proposed algorithm.", "num_citations": "42\n", "authors": ["572"]}
{"title": "Co-simulation framework for design of time-triggered cyber physical systems\n", "abstract": " Designing cyber-physical systems (CPS) is challenging due to the tight interactions between software, network/platform, and physical components. A co-simulation method is valuable to enable early system evaluation. In this paper, a co-simulation framework that considers interacting CPS components for design of time-triggered (TT) CPS is proposed. Virtual prototyping of CPS is the core of the proposed framework. A network/platform model in SystemC forms the backbone of the virtual prototyping, which bridges control software and physical environment. The network/platform model consists of processing elements abstracted by realtime operating systems, communication systems, sensors, and actuators. The framework is also integrated with a model-based design tool to enable rapid prototyping. The framework is validated by comparing simulation results with the results from a hardware-in-the-loop automotive\u00a0\u2026", "num_citations": "40\n", "authors": ["572"]}
{"title": "Guest editorial: Special issue on computer automated multi-paradigm modeling\n", "abstract": " Modeling and simulation are becoming increasingly important enablers for the analysis and design of complex systems. To tackle problems of ever growing complexity, the focus of modeling and simulation research is shifting from simulation techniques to modeling methodology and technology. This trend is also visible in the software engineering community. Most noticeable is the shift from programming to modeling. Examples include the use of the Unified Modeling Language (UML) in the context of the Model Driven Architecture (MDA) and of (domain specific) tools to automatically generate prototype and even production quality code from high-level models.In this special issue, the emerging field of Computer Automated Multi-Paradigm Modeling (CAMPaM) is presented. Because of the heterogeneous nature of embedded systems and the many implementation technologies, multiparadigm modeling is a critical\u00a0\u2026", "num_citations": "39\n", "authors": ["572"]}
{"title": "F6com: A component model for resource-constrained and dynamic space-based computing environments\n", "abstract": " Component-based programming models are well-suited to the design of large-scale, distributed applications because of the ease with which distributed functionality can be developed, deployed, and validated using the models' compositional properties. Existing component models supported by standardized technologies, such as the OMG's CORBA Component Model (CCM), however, incur a number of limitations in the context of cyber physical systems (CPS) that operate in highly dynamic, resource-constrained, and uncertain environments, such as space environments, yet require multiple quality of service (QoS) assurances, such as timeliness, reliability, and security. To overcome these limitations, this paper presents the design of a novel component model called F6COM that is developed for applications operating in the context of a cluster of fractionated spacecraft. Although F6COM leverages the\u00a0\u2026", "num_citations": "38\n", "authors": ["572"]}
{"title": "Component-oriented modeling of hybrid dynamic systems using the Generic Modeling Environment\n", "abstract": " This paper presents a component oriented modeling environment for building hybrid dynamic models of physical system. The modeling environment is created using the generic modeling environment (GME), a meta programmable visual modeling application developed at the Institute for Software Integrated Systems (ISIS). The core of the modeling language itself is a hybrid extension of the bond graph modeling language. The advantages of an object-oriented approach to physical system modeling combined with the advanced features of GME for managing model complexity are illustrated by building a library of hydraulic system components. A simulation model can be automatically generated from the physical system model using a model translator. As an example application we use the component library to build the model of a coupled multi-tank system with controlled and autonomous hybrid behaviors, and\u00a0\u2026", "num_citations": "37\n", "authors": ["572"]}
{"title": "Design tool integration: an exercise in semantic interoperability\n", "abstract": " The integration of software tools used in an engineering process is a problem that arises frequently in large-scale engineering projects. Traditional approaches are insufficient for complex engineering tools and processes. The solution must also account for the evolution of the system, as tools and processes change over time. This paper shows a new approach to the problem, describes the supporting infrastructure, and discusses the background model-integrated generation technology.", "num_citations": "37\n", "authors": ["572"]}
{"title": "System diagnosis using hybrid failure propagation graphs\n", "abstract": " This paper presents an approach for robust diagnosis of a general class of dynamic systems based on a temporal failure propagation model. The proposed approach can be applied to a general class of systems with both time and event driven dynamics such as hybrid and discrete event systems. The paper presents the syntax and semantics of the proposed model and introduces the diagnosis approach.", "num_citations": "36\n", "authors": ["572"]}
{"title": "Towards fault-adaptive control of complex dynamic systems\n", "abstract": " Today\u2019s complex systems, like high-performance aircraft require sophisticated control techniques to support all aspects of operation: from flight controls through mission management to environmental controls, just to give a few examples. All this, of course, is done using a multitude of computer systems, all of which rely heavily on software technology. Software systems now play a dual role. Not only do they implement system functionalities, but they are also becoming the primary vehicle for system integration. One of the main goals of software is to implement control functions: open-and closed-loop control, from low-level regulation to high-level supervisory control. However, software enables new capabilities in control. It offers a framework that provides great flexibility for developing novel algorithms that significantly improve the performance of the system. Furthermore, brand new functionalities can be created that\u00a0\u2026", "num_citations": "36\n", "authors": ["572"]}
{"title": "TRANSAX: A blockchain-based decentralized forward-trading energy exchanged for transactive microgrids\n", "abstract": " Power grids are undergoing major changes due to rapid growth in renewable energy and improvements in battery technology. Prompted by the increasing complexity of power systems, decentralized IoT solutions are emerging, which arrange local communities into transactive microgrids. The core functionality of these solutions is to provide mechanisms for matching producers with consumers while ensuring system safety. However, there are multiple challenges that these solutions still face: privacy, trust, and resilience. The privacy challenge arises because the time series of production and consumption data for each participant is sensitive and may be used to infer personal information. Trust is an issue because a producer or consumer can renege on the promised energy transfer. Providing resilience is challenging due to the possibility of failures in the infrastructure that is required to support these market based\u00a0\u2026", "num_citations": "35\n", "authors": ["572"]}
{"title": "An evolvable tri-reasoner ivhm system\n", "abstract": " Meeting the challenges of decreasing operational costs and increasing operational readiness for future aircraft will require a systemic approach to integrated vehicle health management (IVHM). Realizing such an approach will involve synergistic deployments of component health monitoring technologies, as well as integrated, model-based reasoning capabilities for the interpretation of the monitor outputs. Further, it will involve the introduction of learning technologies to support the continuous improvement of the knowledge enabling these reasoning capabilities. Finally, it will involve organizing these elements into an architecture that governs integration and interoperation-within the VHM system, between its on-board elements and their ground-based support functions, and between the VHM system and external maintenance and operations functions. We present and discuss the architecture for an evolvable tri\u00a0\u2026", "num_citations": "35\n", "authors": ["572"]}
{"title": "Model-based intelligent process control for cogenerator plants\n", "abstract": " This paper describes a new approach for the design and implementation of an intelligent monitoring and diagnostic system for a complex, practical system: a cogenerator plant. The methodology is based on multiple aspect modeling and model interpretation, which is used for instantiating a run-time system based on a graph-model of computation. Sensory input signals from the plant are processed and interpreted in the context of various models of the cogenerator system in real-time. The system demonstrated that the model-based approach has a significant impact not only on the functional performance of the control system, but dramatically reduces development time as well.", "num_citations": "35\n", "authors": ["572"]}
{"title": "Synthesis of self-adaptive software\n", "abstract": " Embedded applications are constantly being pushed toward achieving autonomy, allowing them to function reliably in all circumstances and under extreme design constraints. Our approach to embedded systems introduces a feedback loop characterizing adaptive systems: the adaptation mechanism monitors system performance and changes the structure accordingly to optimize performance. These self-adaptive systems can be designed and implemented using model-integrated computing. To represent dynamic software architectures, the system is modeled in a generative manner. Here, the components of the architecture are prepared, but their number and connectivity patterns are not fully defined at design time. Instead, an algorithmic description and architectural parameters are provided that specify how the architecture could be generated \"on-the-fly\". These design-time models are then embedded in the run\u00a0\u2026", "num_citations": "34\n", "authors": ["572"]}
{"title": "A modeling language and its supporting tools for avionics systems\n", "abstract": " Practical experience with the object-oriented development of complex reusable avionics application software has led to the recognition that domain-specific model-based approaches to software component and system configuration are not only viable, but also essential to success in terms of productivity, assurance, and quality. This technology requires a domain-specific modeling approach as it is closely related to the model of computation utilized in the underlying integration platform, and must be designed to support analysis and synthesis activities as well for fullest benefit. The modeling approach goes beyond the current capabilities of standard tools, like UML, and is specialized for the needs of the application domain. In this paper, we present a modeling language, the Embedded System Modeling Language (ESML), which supports the architectural modeling of avionics systems built using the Boeing Bold\u00a0\u2026", "num_citations": "33\n", "authors": ["572"]}
{"title": "Component generation technology for semantic tool integration\n", "abstract": " The problem of tool integration often occurs in the design and implementation of large computer-based systems that rely on software-based engineering tools. Each specialized tool contributes to a crucial step in the engineering process. It would be beneficial to capture the information in the context of one tool and use it in a different tool. However, differences in file formats and variations in the method of user interaction can make the integration of tools a formidable challenge. This paper presents a new approach to the tool integration problem and describes the framework and process that has been used to successfully integrate the data models of several tools. The technique is centered on generators that create \"componentized\" semantic translators.", "num_citations": "33\n", "authors": ["572"]}
{"title": "Resilient information architecture platform for the smart grid: A novel open-source platform for microgrid control\n", "abstract": " Microgrids are seen as an effective way to achieve reliable, resilient, and efficient operation of the power distribution system. Core functions of the microgrid control system are defined by the IEEE Standard 2030.7; however, the algorithms that realize these functions are not standardized, and are a topic of research. Furthermore, the corresponding controller hardware, operating system, and communication system to implement these functions vary significantly from one implementation to the next. In this article, we introduce an open-source platform, resilient information architecture platform for the smart grid (RIAPS), ideally suited for implementing and deploying distributed microgrid control algorithms. RIAPS provides a design-time tool suite for development and deployment of distributed microgrid control algorithms. With support from a number of run-time platform services, developed algorithms can be easily\u00a0\u2026", "num_citations": "32\n", "authors": ["572"]}
{"title": "Barista: Efficient and scalable serverless serving system for deep learning prediction services\n", "abstract": " Pre-trained deep learning models are increasingly being used to offer a variety of compute-intensive predictive analytics services such as fitness tracking, speech, and image recognition. The stateless and highly parallelizable nature of deep learning models makes them well-suited for serverless computing paradigm. However, making effective resource management decisions for these services is a hard problem due to the dynamic workloads and diverse set of available resource configurations that have different deployment and management costs. To address these challenges, we present a distributed and scalable deep-learning prediction serving system called Barista and make the following contributions. First, we present a fast and effective methodology for forecasting workloads by identifying various trends. Second, we formulate an optimization problem to minimize the total cost incurred while ensuring\u00a0\u2026", "num_citations": "32\n", "authors": ["572"]}
{"title": "Distributed real-time managed systems: A model-driven distributed secure information architecture platform for managed embedded systems\n", "abstract": " Architecting software for a cloud computing platform built from mobile embedded devices incurs many challenges that aren't present in traditional cloud computing. Both effectively managing constrained resources and isolating applications without adverse performance effects are needed. A practical design- and runtime solution incorporates modern software development practices and technologies along with novel approaches to address these challenges. The patterns and principles manifested in this system can potentially serve as guidelines for current and future practitioners in this field.", "num_citations": "32\n", "authors": ["572"]}
{"title": "Online safety control of a class of hybrid systems\n", "abstract": " In this paper we outline a supervisor synthesis procedure for safety control of a class of hybrid systems. The procedure is conducted online based on a limited exploration of the state space. We establish feasibility conditions for online controllability with respect to the safety specifications, and provide an upper limit for the accuracy error of the online controller.", "num_citations": "32\n", "authors": ["572"]}
{"title": "Automatic verification of component-based real-time corba applications\n", "abstract": " Distributed real-time embedded (DRB) systems often need to satisfy various time, resource and fault-tolerance constraints. To manage the complexity of scheduling these systems many methods use rate monotonic scheduling assuming a time-triggered architecture. This paper presents a method that captures the reactive behavior of complex time- and event-driven systems, can provide simulation runs and can provide exact characterization of timed properties of component-based DRE applications that use the publisher/subscriber communication pattern. We demonstrate our approach on real-time CORBA avionics applications.", "num_citations": "31\n", "authors": ["572"]}
{"title": "Using semantic anchoring to verify behavior preservation in graph transformations\n", "abstract": " Graph transformation is often used to transform domain models from one domain specific language (DSML) to another. In some cases, the DSMLs are based on a formalism that has many implementation variants, such as Statecharts. For instance, it could be necessary to transform iLogix Statechart models into Matlab Stateflow models. The preservation of behavior of the models is crucial in such transformations. Bisimulation has previously been demonstrated as an approach to verifying behavior preservation, and semantic anchoring is an approach to specifying the dynamic semantics of DSMLs. We propose a method to verify behavior preservation, using bisimulation in conjunction with semantic anchoring. We will consider two hypothetical variants of the Statecharts formalism, and specify the operational semantics of each variant by semantic anchoring, using Abstract State Machines as a common semantic framework. We then establish bisimulation properties to verify if the behavior models of the source and target Statechart models are equivalent for a particular execution of the transformation.", "num_citations": "30\n", "authors": ["572"]}
{"title": "Towards model-based integration of tools and techniques for embedded control system design, verification, and implementation\n", "abstract": " While design automation for hardware systems is quite advanced, this is not the case for practical embedded systems. The current state-of-the-art is to use a software modeling environment and integrated development environment for code development and debugging, but these rarely include the sort of automatic synthesis and verification capabilities available in the VLSI domain. We present a model-based integration environment which uses a graphical architecture description language (EsMoL) to pull together control design, code and configuration generation, platform-specific simulation, and a number of other features useful for taming the heterogeneity inherent in safety-critical embedded control system designs. We describe concepts, elements, and development status for this suite of tools.", "num_citations": "29\n", "authors": ["572"]}
{"title": "Diagnostic technology evaluation report for on-board crew launch vehicle\n", "abstract": " 1.1 PurposeTo evaluate the state-of-the-practice in embedded fault detection and diagnosis technologies, for requirements development for the Crew Launch Vehicle (CLV).", "num_citations": "29\n", "authors": ["572"]}
{"title": "Development of a controller hardware-in-the-loop platform for microgrid distributed control applications\n", "abstract": " Microgrids (MGs) are ideally suited for distributed control solutions. However, implementation and validation of the developed distributed control algorithms are quite challenging. In this paper we propose a Controller Hardware-in-the-Loop (CHIL) platform for MG distributed control applications that satisfy the requirements of IEEE Std. 2030.7 for MG control systems. We describe two main features of the proposed platform: 1) a software platform that enables the implementation of control algorithms that have been developed analytically and 2) a real-time MG testbed that replicates practical MG operation environment by using real-time communication network and grid solutions. Implementation and validation of a distributed MG synchronization operation control strategy are used to demonstrate the performance of the proposed CHIL platform.", "num_citations": "28\n", "authors": ["572"]}
{"title": "Time synchronization services for low-cost fog computing applications\n", "abstract": " This paper presents the time synchronization infrastructure for a low-cost run-time platform and application framework specifically targeting Smart Grid applications. Such distributed applications require the execution of reliable and accurate time-coordinated actions and observations both within islands of deployments and across geographically distant nodes. The time synchronization infrastructure is built on well-established technologies: GPS, NTP, PTP, PPS and Linux with real-time extensions, running on low-cost BeagleBone Black hardware nodes. We describe the architecture, implementation, instrumentation approach, performance results and present an example from the application domain. Also, we discuss an important finding on the effect of the Linux RT_PREEMPT real-time patch on the accuracy of the PPS subsystem and its use for GPS-based time references.", "num_citations": "28\n", "authors": ["572"]}
{"title": "Towards a generic design space exploration framework\n", "abstract": " The set of all possible design alternatives for a system is referred to as a design-space, and design-space exploration (DSE) is the systematic exploration of the elements in a design-space. Various DSE techniques have been used for hardware/software co-design, configuration of software product lines and real-time software synthesis. Although at an abstract level DSE steps performed in these domains are similar, most of the current research is focused on domain specific frameworks which are tightly coupled with tools that evaluate point designs and use domain specific knowledge. There is a need for a generic tool that can be easily configured to model exploration problems from different domains as well on different levels of abstraction. In this paper we present Generic Design Space Exploration (GDSE) framework for domain independent DSE. This framework supports generic modeling of DSE problems from\u00a0\u2026", "num_citations": "27\n", "authors": ["572"]}
{"title": "Platform Modeling and Model Transformations for Analysis.\n", "abstract": " The model-based approach to the development of embedded systems relies on the use of explicit models in the design process. If these models faithfully represent the components of the system with respect to their properties as well as their interactions, then they can be used to predict the dynamic behavior of the system under construction. In this paper we argue for modeling the execution platform that facilitates the component interactions, and show how models of the application and the knowledge of the platform can be used to translate system configurations into another abstract formalism (timed automata, in our case) that allows system verification through model checking.", "num_citations": "27\n", "authors": ["572"]}
{"title": "Model-integrated program synthesis environment\n", "abstract": " The paper describes a model-integrated program synthesis environment for computer-based system applications. In model-integrated program synthesis (MIPS), domain-specific, multiple-view models represent the software, its environment and their relationships. Model interpreters translate the models into the input languages of static and dynamic analysis tools, and application specific model interpreters synthesize software applications. The components of the system are built in the framework of the layered multigraph architecture, which separates the generic and domain/application specific components, and defines interfaces for expandability.", "num_citations": "27\n", "authors": ["572"]}
{"title": "Achieving resilience in distributed software systems via self-reconfiguration\n", "abstract": " Improvements in mobile networking combined with the ubiquitous availability and adoption of low-cost development boards have enabled the vision of mobile platforms of Cyber-Physical Systems (CPS), such as fractionated spacecraft and UAV swarms. Computation and communication resources, sensors, and actuators that are shared among different applications characterize these systems. The cyber-physical nature of these systems means that physical environments can affect both the resource availability and software applications that depend on resource availability. While many application development and management challenges associated with such systems have been described in existing literature, resilient operation and execution have received less attention. This paper describes our work on improving runtime support for resilience in mobile CPS, with a special focus on our runtime infrastructure that\u00a0\u2026", "num_citations": "25\n", "authors": ["572"]}
{"title": "Design space exploration and manipulation for cyber physical systems\n", "abstract": " Cyber-Physical Systems (CPS)[1] are engineered systems that require tight interaction between physical and computational components. Designing a CPS is highly challenging [2] because these systems are inherently complex, need significant effort to describe and evaluate a vast set of crossdisciplinary interactions, and require seamless meshing of physical elements with corresponding software artifacts. Moreover, a large set of architectural and composable alternatives must be systematically explored and evaluated in the context of a highly constrained design space. The constraints imposed on the selection of alternatives are derived from the system\u2019s functional, performance, dimensional, physical, and economical objectives. Furthermore, the design process of these systems is highly iterative and requires continuous integration of design generation with design selection and manipulation supported by design analyses. Existing computer-aided design tools are not well-suited for this method of design. To facilitate the iterative design process for CPS-s, we have developed a design toolchain, OpenMETA [4][9], built around a Domain-Specific Modeling Language (DSML)[3], called the Cyber-Physical Modeling Language (CyPhyML). In this paper, we present parts OpenMETA that address the requirements of Design Space Exploration and Manipulation (DSEM) for CPS-s.", "num_citations": "25\n", "authors": ["572"]}
{"title": "A real-time component framework: experience with CCM and ARINC-653\n", "abstract": " The complexity of software in systems like aerospace vehicles has reached the point where new techniques are needed to ensure system dependability while improving the productivity of developers. One possible approach is to use precisely defined software execution platforms that (1) enable the system to be composed from separate components, (2) restrict component interactions and prevent fault propagation, and (3) whose compositional properties are well-known. In this paper we describe the initial steps towards building a platform that combines component-based software construction with hard real-time operating system services. Specifically, the paper discusses how the CORBA Component Model (CCM) could be combined with the ARINC-653 platform services and the lessons learned from this experiment. The results point towards both extending the CCM as well as revising the ARINC-653.", "num_citations": "25\n", "authors": ["572"]}
{"title": "Model-integrated program synthesis environment for parallel/real-time image processing\n", "abstract": " In this paper, it is shown that, through the use of model- integrated program synthesis (MIPS), parallel real-time implementations of image processing data flows can be synthesized from high level graphical specifications. The complex details in inherent to parallel and real-time software development become transparent to the programmer, enabling the cost-effective exploitation of parallel hardware for building more flexible and powerful real-time imaging systems. The model integrated real-time image processing system (MIRTIS) is presented as an example. MIRTIS employs the multigraph architecture (MGA), a framework and set of tools for building MIPS systems, to generate parallel real-time image processing software which runs under the control of a parallel run-time kernel on a network of Texas Instruments TMS320C40 DSPs (C40s). The MIRTIS models contain graphical declarations of the image processing\u00a0\u2026", "num_citations": "25\n", "authors": ["572"]}
{"title": "Specifying the correctness properties of model transformations\n", "abstract": " The correctness of a model transformation is central to the success of a model-driven software development process. A transformation can be said to have executed correctly if it resulted in the desired output model, but this requires a specification of what constitutes a desirably correct output. If we have this specification, and a framework to verify that it holds on a specific execution of the transformation, then that execution instance may be\" certified correct\". In this paper, we explore a technique to specify such a correctness, using a language framework that can easily be incorporated into a variety of domains. We will also see how these correctness criteria can be verified on instance models.", "num_citations": "23\n", "authors": ["572"]}
{"title": "Tool integration patterns\n", "abstract": " Design patterns have been widely recognized as important contributors to the success of software systems. This paper introduces and compares two patterns that solve specific design tool integration problems. Both patterns have been implemented and used in real-life engineering processes.", "num_citations": "23\n", "authors": ["572"]}
{"title": "A practical method for creating plant diagnostics applications\n", "abstract": " Making manufacturing systems more robust (ie, able to carry out their function under the presence of faults) is an issue of paramount importance: It involves on-line and real-time detection of faults, diagnosis of faults, and recovery from the faults. In this paper, we present a system that is able to generate practical and efficient solutions for these problem. This approach we present is available as part of IPCS (Intelligent Process Control System), which is a model-based environment for generating monitoring, control, simulation, and diagnostics applications for large-scale, continuous process plants. IPCS has been used to generate practical real-time diagnostic and recovery applications in chemical and cogenerator plants.", "num_citations": "23\n", "authors": ["572"]}
{"title": "Compensating for timing jitter in computing systems with general-purpose operating systems\n", "abstract": " Fault-tolerant frameworks for large scale computing clusters require sensor programs, which are executed periodically to facilitate performance and fault management. By construction, these clusters use general purpose operating systems such as Linux that are built for best average case performance and do not provide deterministic scheduling guarantees. Consequently, periodic applications show jitter in execution times relative to the expected execution time. Obtaining a deterministic schedule for periodic tasks in general purpose operating systems is difficult without using kernel-level modifications such as RTAI and RTLinux. However, due to performance and administrative issues kernel modification cannot be used in all scenarios. In this paper, we address the problem of jitter compensation for periodic tasks that cannot rely on modifying the operating system kernel. ; Towards that, (a) we present motivating\u00a0\u2026", "num_citations": "22\n", "authors": ["572"]}
{"title": "Practical considerations in systems diagnosis using timed failure propagation graph models\n", "abstract": " Timed failure propagation graphs (TFPG) are causal models that capture the temporal aspects of failure propagation in dynamic systems. In this paper we present several practical modeling and reasoning considerations that have been addressed based on experience with avionics systems. These include the problem of intermittent faults, handling test alarms, dealing with limited computational resources, and model reduction for large scale systems.", "num_citations": "22\n", "authors": ["572"]}
{"title": "Towards a verifiable real-time, autonomic, fault mitigation framework for large scale real-time systems\n", "abstract": " Designing autonomic fault responses is difficult, particularly in large-scale systems, as there is no single \u2018perfect\u2019 fault mitigation response to a given failure. The design of appropriate mitigation actions depend upon the goals and state of the application and environment. Strict time deadlines in real-time systems further exacerbate this problem. Any autonomic behavior in such systems must not only be functionally correct but should also conform to properties of liveness, safety and bounded time responsiveness. This paper details a real-time fault-tolerant framework, which uses a reflex and healing architecture to provide fault mitigation capabilities for large-scale real-time systems. At the heart of this architecture is a real-time reflex engine, which has a state-based failure management logic that can respond to both event- and time-based triggers. We also present a semantic domain for verifying properties of\u00a0\u2026", "num_citations": "22\n", "authors": ["572"]}
{"title": "Notions of diagnosability for timed failure propagation graphs\n", "abstract": " Timed failure propagation graphs (TFPG) are causal models that capture the temporal aspects of failure propagation in dynamic systems. This paper presents several notions of diagnosability for timed failure propagation models. Diagnosability characteristics of TFPG models are defined based on three metrics; failure detectability, distinguishability, and predictability. The paper identifies the modeling and run-time parameters of the diagnosability metrics. The application of diagnosability analysis to the problem of alarm allocation is discussed.", "num_citations": "22\n", "authors": ["572"]}
{"title": "Evolution of the Hungarian economy 1848-1998\n", "abstract": " The books in this series deal with peoples whose homelands lie between the Germans to the west, the Russians, Ukrainians and Belorussians to the east and north, and the Mediterranean and Adriatic seas to the south. They constitute a particular civilization, one that is at once an integral part of Europe, yet substantially dif-ferent from the West. The area is characterized by a rich diversity of languages, religions and governments. The study of this complex area demands a multidisciplinary approach, and, accordingly, our contributors to the series represent several academic disciplines. They have been drawn from universities and other scholarly insti-tutions in the United States and Western Europe, as well as East and Central Europe.The editor-in-chief is responsible for ensuring the comprehensiveness, cohesion, internal balance, and scholarly quality of the series he has launched. He cheerfully accept this responsibility and intend this work to be neither justification nor condemnation of the policies, attitudes, and activities of any person involved. At the same time, because the contributors represent so many different", "num_citations": "22\n", "authors": ["572"]}
{"title": "Model-integrated system development: Models, architecture, and process\n", "abstract": " Many large software systems are tightly integrated with their physical environments and must be adapted when their environment changes. Typically, software development methodologies do not place a great emphasis on modeling the system's environment, and hence environmental changes may lead to significant and complicated changes in the software. We argue that (1) the modeling of the environment should be an integral part of the process, and (2) to support software evolution, wherever possible, the software should be automatically generated. We present a model-integrated development approach that is capable of supporting cost effective system evolution in accordance with changes in the system's environment. The approach is supported by a \"meta-architecture\" that provides a framework for building model-based systems. This framework has been successfully used in various projects. One of these\u00a0\u2026", "num_citations": "22\n", "authors": ["572"]}
{"title": "A model-integrated information system for increasing throughput in discrete manufacturing\n", "abstract": " The use of information systems (IS) has been increasingly playing a critical role towards enhancing productivity and throughput in manufacturing enterprises. The primary drivers are efficiency and quality increase through automation, facilitation of better business processes and improved decision making. Many problems and issues relating to the design, development, integration, evolution and maintenance of ISs in large-scale and complex plants have become apparent which are not adequately addressed by the traditional Process Monitoring and Control (PM&C) systems. Model-Integrated Computing (MIC) offers a feasible approach towards providing cost-effective development, integration, evolution and maintenance of ISs through the extensive use of plant models. This paper describes an application of MIC in providing a problem-solving environment and decision support tool in the context of discrete\u00a0\u2026", "num_citations": "22\n", "authors": ["572"]}
{"title": "ROSMOD: a toolsuite for modeling, generating, deploying, and managing distributed real-time component-based software using ROS\n", "abstract": " This paper presents the Robot Operating System Model-driven development tool suite,(ROSMOD) an integrated development environment for rapid prototyping component-based software for the Robot Operating System (ROS) middleware. ROSMOD is well suited for the design, development and deployment of large-scale distributed applications on embedded devices. We present the various features of ROSMOD including the modeling language, the graphical user interface, code generators, and deployment infrastructure. We demonstrate the utility of this tool with a real-world case study: an Autonomous Ground Support Equipment (AGSE) robot that was designed and prototyped using ROSMOD for the NASA Student Launch competition, 2014\u20132015. View Full-Text", "num_citations": "20\n", "authors": ["572"]}
{"title": "Distributed and managed: Research challenges and opportunities of the next generation cyber-physical systems\n", "abstract": " Cyber-physical systems increasingly rely on distributed computing platforms where sensing, computing, actuation, and communication resources are shared by a multitude of applications. Such 'cyber-physical cloud computing platforms' present novel challenges because the system is built from mobile embedded devices, is inherently distributed, and typically suffers from highly fluctuating connectivity among the modules. Architecting software for these systems raises many challenges not present in traditional cloud computing. Effective management of constrained resources and application isolation without adversely affecting performance are necessary. Autonomous fault management and real-time performance requirements must be met in a verifiable manner. It is also both critical and challenging to support multiple end-users whose diverse software applications have changing demands for computational and\u00a0\u2026", "num_citations": "20\n", "authors": ["572"]}
{"title": "A passivity-based framework for resilient cyber physical systems\n", "abstract": " Resilient control systems play a special role in the area of cyber-physical systems, where the design must address the question how complex dynamic plants are to be controlled safely and reliably when a control system is under a cyber attack. In this paper we describe a control theoretical framework based on the concept of passivity for designing a control network which can tolerate, for instance, denial-of-service attacks on networks used in the closed loop. In particular, we demonstrate how the resilient power junction structure could be applied, and provide simulated results.", "num_citations": "20\n", "authors": ["572"]}
{"title": "The Design of a simple language for graph transformations\n", "abstract": " Model-driven development of software systems envisions transformations applied in various stages of the development process. Similarly, the use of domain-specific languages also necessitates transformations that map domain-specific constructs into the constructs of an underlying programming language. Thus, in these cases, the writing of transformation tools becomes a first-class activity of the software engineer. This paper introduces a simple language that was designed to support implementing highly efficient transformation programs that perform model-to-model or model-to-code translations. The language uses the concepts of graph transformations and metamodeling, and is supported by a suite of tools that allow the rapid prototyping and realization of transformation tools.", "num_citations": "20\n", "authors": ["572"]}
{"title": "A testbed to simulate and analyze resilient cyber-physical systems\n", "abstract": " This paper describes a testbed for development, deployment, testing, and analysis of Cyber-Physical Systems (CPS) applications. The testbed incorporates smart network hardware, allowing high-fidelity emulation of CPS network characteristics, and CPS simulation environments to enable high-frequency sensor reading, actuator control and physical environmental changes. We discuss the architecture of this testbed and present the types of experiments and applications which can be run to study hardware and software fault tolerance, software reconfiguration, and system stability characteristics in distributed real-time embedded systems. We also describe the scalability, limitations, and potential extensions to this testbed.", "num_citations": "19\n", "authors": ["572"]}
{"title": "On the correctness of model transformations in the development of embedded systems\n", "abstract": " Model based techniques have become very popular in the development of software for embedded systems, with a variety of tools for design, simulation and analysis of model based systems being available (such as Matlab\u2019s Simulink [20], the model checking tool NuSMV [4] etc.). Model transformations usually play a critical role in such model based development approaches. While the available tools are geared to verify properties about individual models, the correctness of model transformations is generally not verified. However, errors in the transformation could present serious problems. Proving a property for a certain source model becomes irrelevant if an erroneous transformation produces an incorrect target model. One way to provide assurance about a transformation would be to prove that it preserves certain properties of the source model (such as reachability) in the target model. In this paper, we\u00a0\u2026", "num_citations": "19\n", "authors": ["572"]}
{"title": "A metamodel-driven MDA process and its tools\n", "abstract": " A domain-specific refinement of MDA, called DS-MDA is introduced, and a practical manifestation of it called MIC (for Model-Integrated Computing) is described. MIC extends MDA in the direction of domain-specific modeling languages. The MIC tools are metaprogrammable, ie are tailored for specific domains using meta-models. Meta-models capture the domain\u2019s and the target platform\u2019s general properties, as well as the transformation between the two. The paper introduces the tools and process that supports single domains, and proposes an extension towards multi-model processes.", "num_citations": "19\n", "authors": ["572"]}
{"title": "Structured specification of model interpreters\n", "abstract": " Model interpreters play an essential role in model integrated systems: they transform domain-specific models into executable models. The state-of-the-art of model interpreter writing needs to be advanced to enhance the reusability and maintainability of this software. This paper presents an approach which makes this possible through the use of structured specifications. These specifications let the programmer express traversal strategies and visitation actions in very high-level terms. From these specifications efficient traversal code can be automatically generated.", "num_citations": "19\n", "authors": ["572"]}
{"title": "Neural network methods for the modeling and control of welding processes\n", "abstract": " While welding processes are of great importance in manufacturing, their modeling and control is still subject of research. The highly nonlinear, strongly coupled, and multivariable nature of these processes renders the use of analytical tools practically impossible. In this article a novel approach is presented which employs networks of simple nonlinear units: a neural network. A widely used welding process, the Gas Tungsten Arc Welding is presented and the problem of its modeling and control is exhibited. A very brief introduction to neural networks is followed by presenting the experimental results for modeling the static and dynamic behavior of the process, as well as some practical recommendations regarding the use of the neural network techniques for controlling these processes.", "num_citations": "19\n", "authors": ["572"]}
{"title": "A game-theoretic approach for power systems defense against dynamic cyber-attacks\n", "abstract": " Technological advancements in today\u2019s electrical grids give rise to new vulnerabilities and increase the potential attack surface for cyber-attacks that can severely affect the resilience of the grid. Cyber-attacks are increasing both in number as well as sophistication and these attacks can be strategically organized in chronological order (dynamic attacks), where they can be instantiated at different time instants. The chronological order of attacks enables us to uncover those attack combinations that can cause severe system damage but this concept remained unexplored due to the lack of dynamic attack models. Motivated by the idea, we consider a game-theoretic approach to design a new attacker-defender model for power systems. Here, the attacker can strategically identify the chronological order in which the critical substations and their protection assemblies can be attacked in order to maximize the overall\u00a0\u2026", "num_citations": "18\n", "authors": ["572"]}
{"title": "Implementation of a distributed microgrid controller on the resilient information architecture platform for smart systems (riaps)\n", "abstract": " Formation of microgrids have been proposed as a solution to improve grid reliability, and enable smoother integration of renewables into the grid. Microgrids are sections of the grid that can operate in isolation from the main power system. Maintaining power balance within an islanded microgrid is a challenging task, due to the low system inertia, which requires complex control to maintain stable and optimized operation. Many studies have demonstrated feasible distributed microgrid controllers that can maintain microgrid stability in grid connected and islanded modes. However, there is little emphasis on how to implement these distributed algorithms on a computational platform that allows for fast and seamless deployment. This paper introduces a decentralized software platform called Resilient Information Architecture Platform for Smart Systems (RIAPS) that runs on processors embedded with the microgrid\u00a0\u2026", "num_citations": "18\n", "authors": ["572"]}
{"title": "A CubeSat-payload radiation-reliability assurance case using goal structuring notation\n", "abstract": " CubeSats have become an attractive platform for universities, industry, and government space missions because they are cheaper and quicker to develop than full-scale satellites. One way CubeSats keep costs low is by using commercial off-the-shelf parts (COTS) instead of space-qualified parts. Space-qualified parts are often costlier, larger, and consume more power than their commercial counterparts precluding their use within the CubeSat form-factor. Given typical power budgets, monetary budgets, and timelines for CubeSat missions, conventional radiation hardness assurance, like the use of space-qualified parts and radiation testing campaigns of COTS parts, is not practical. Instead, a system-level approach to radiation effects mitigation is needed. In this paper an assurance case for a system-level approach to mitigate radiation effects of a CubeSat science experiment is expressed using Goal Structuring\u00a0\u2026", "num_citations": "18\n", "authors": ["572"]}
{"title": "Range-finding sensor degradation in gamma radiation environments\n", "abstract": " The effects of gamma radiation on common sensors used in robots intended for nuclear remediation scenarios are examined. Commercial rangefinders are chosen as an exemplar of the impact of gamma radiation on sensors and systems. This paper illustrates sensor radiation degradation not only in operational failure, but also in changes in the sensor transfer function. Three types of commercial range-finding sensors are considered [infrared (IR) triangulation using a position sensitive detector, sonar using time of flight, and laser rangefinder using triangulation and a CMOS camera]. Experimental results show significant changes in the IR sensor's static sensitivity with dose, abrupt failure of the laser range finder at low dose, and degradation and abrupt failure for the sonar detector. The input-output relationship of the IR sensor showed further variation after a period of room-temperature annealing. Significant part-to\u00a0\u2026", "num_citations": "18\n", "authors": ["572"]}
{"title": "An experimental model-based rapid prototyping environment for high-confidence embedded software\n", "abstract": " The development of embedded software for high confidence systems is a challenging task that must be supported by a deep integration of control theoretical and computational aspects. Model-based development of embedded software has been practiced for more than a decade now,but very few integrated approaches have emerged to provide end-to-end support for the process, and integrate platform aspects as well as verification. The paper describes an early version of a model-based prototyping tool chain that provides such support and covers most engineering steps.The tool chain is coupled with a hardware-in-the-loop simulation system, allowing quick experimental evaluation of designs.", "num_citations": "18\n", "authors": ["572"]}
{"title": "Towards verification of model transformations via goal-directed certification\n", "abstract": " Embedded software is widely used in automotive applications, often in critical situations where reliability of the system is extremely important. Such systems often use model based development approaches. Model transformation is an important step in such scenarios. This includes generating code from models, transforming design models into analysis models, or transforming a model between variants of a formalism (such as variants of Statecharts). It becomes important to verify that the transformation was correct, and the transformed model or code preserved the semantics of the design model. In this paper, we will look at a technique called \u201cgoal-directed certification\u201d that provides a pragmatic solution to the verification problem. We will see how we can use concepts of bisimulation to verify whether a certain transformation instance preserved certain properties. We will then extend this idea using weak\u00a0\u2026", "num_citations": "18\n", "authors": ["572"]}
{"title": "Embedded software: Challenges and opportunities\n", "abstract": " This paper discusses challenges and opportunities in embedded system and software design. The key thesis of the paper is that embedded computing applications create fundamentally new challenges for software technology that require new ideas and approaches. The paper reviews two of the new challenges, physicality and its effects on change management. The discussion on the impacts of these challenges focuses on key components of integrated development environments, representation, synthesis and analysis, and generator technology.", "num_citations": "18\n", "authors": ["572"]}
{"title": "A meta-framework for design space exploration\n", "abstract": " Complex software systems have a large number of choices in terms of selection of software components and hardware architectures for implementation. These design choices create a large space of possible design solutions called the design space. The design process requires exploring through this design space to find valid design solutions before the actual implementation. Design space exploration (DSE) is the process of searching through the design space to find feasible and optimal design solutions. The main challenge in DSE is to deal with an exponential number of design alternatives, which is further complicated by the various conflicting requirements. Thus, there is a clear need for tool support to automate DSE. Over the years domain-experts have frequently relied on different search techniques (mathematical programming, constraint techniques, heuristics) to automate DSE. Different approaches can be\u00a0\u2026", "num_citations": "17\n", "authors": ["572"]}
{"title": "Model based integration and experimentation of information fusion and c2 systems\n", "abstract": " Modern Network Centric Operations drive the complexity of information fusion and command and control (C2) systems. Driving this complexity further is the interplay dynamics of the human element, information systems, and communication networks. The lack of low-cost realistic experimental context limits the testing, evaluation, and further development of fusion systems to small-scale localized experiments. A Model-based Integration and Experimentation Framework is proposed. This framework is built on C2 Wind Tunnel - a robust multi-model simulation framework for integrating simulations to drive fusion experiments. The second component of the framework is a model-based system of systems integration tool-suite that allows modeling, synthesis, and deployment of networked system of systems. This component enables researchers to embed their research algorithm into the networked C2 systems. The C2\u00a0\u2026", "num_citations": "17\n", "authors": ["572"]}
{"title": "A model-based front-end to TAO/ACE: the embedded system modeling language\n", "abstract": " The development of embedded systems necessitates the use of models throughout the engineering process that allow both the analysis and synthesis of the system. This paper introduces a system-level modeling language, which uses a specific, well-defined component model and model of computation, supported by an existing run-time infrastructure. The language allows component modeling, interaction modeling, and configuration modeling. The language is presented using the UML class diagram formalism, and is supported by a visual modeling environment. Formally specified, explicit constraints force the designer to create correct-by-construction models. The language and its supporting environment operate in conjunction with UML tools, synthesis tools that generate system configurations, and analysis tools that provide immediate feedback for the designer. The target platform of the modeling language is TAO/ACE as defined and used in the Bold Stroke architecture.", "num_citations": "17\n", "authors": ["572"]}
{"title": "Graph model\u2010based approach to the representation, interpretation, and execution of signal processing systems\n", "abstract": " In a large class of intelligent machines, one of the tasks of the knowledge\u2010based system components is to configure real\u2010time signal processing systems. These systems implement low\u2010level sensory or control algorithms according to the model of the system to be observed or controlled. If a change in the state of the model is detected, or the goal of the operation is modified, the real\u2010time signal processing schemes have to be dynamically restructured. This article describes a system which has been developed for the knowledge\u2010based generation and restructuring of real\u2010time signal processing systems in parallel computing environments. the system is based on the integration of a hierarchical representation technique, the corresponding interpretation method, and an execution environment, which includes a graph model of computations.", "num_citations": "17\n", "authors": ["572"]}
{"title": "Device access abstractions for resilient information architecture platform for smart grid\n", "abstract": " This letter presents an overview of design mechanisms to abstract device access protocols in the resilient information architecture platform for smart grid, a middleware for developing distributed smart grid applications. These mechanisms are required to decouple the application functionality from the specifics of the device mechanisms built by the device vendors.", "num_citations": "16\n", "authors": ["572"]}
{"title": "A semi-formal description of migrating domain-specific models with evolving domains\n", "abstract": " One of the main advantages of defining a domain-specific modeling language (DSML) is the flexibility to adjust the language definition to changing requirements or in response to a deeper understanding of the domain. With the industrial applications of domain-specific modeling environments, models are valuable investments. If the modeling language evolves, these models must be seamlessly migrated to the evolved DSML. Although the changes stemming from the language evolution are not abrupt in nature, migrating existing models to a new language is still a challenging task. Our solution is the Model Change Language (MCL) tool set, which defines a DSML to describe the migration rules and then performs the model migration automatically. In this paper, we describe the precise semantics of MCL and its execution, along with the confluence of the migration.", "num_citations": "16\n", "authors": ["572"]}
{"title": "Towards a time-triggered schedule calculation tool to support model-based embedded software design\n", "abstract": " Time-triggered architectures (TTA) provide replica determinism in safety-critical distributed embedded software designs. TTA has become a crucial part of many high-confidence embedded paradigms, as it decouples functional concerns from platform timing concerns in system designs. Complex embedded software development workflows for safety-critical applications are increasingly managed by model-based design tools, in order to support automated verification and reconcile conflicts between functional and non-functional concerns in designs. We present a prototype scheduling tool (ESched) which calculates cyclic schedules for time-triggered networks. ESched supports the model-based workflow of the ESMoL modeling language and tool suite. Using ESMoL, designers can rapidly iterate through simulating a control design, capturing platform effects in models, generating a schedule (if feasible), and re\u00a0\u2026", "num_citations": "16\n", "authors": ["572"]}
{"title": "A subgraph operator for graph transformation languages\n", "abstract": " In practical applications of graph transformation techniques to model transformations one often has the need for copying, deleting, or moving entire subgraphs that match a certain graph pattern. While this can be done using elementary node and edge operations, the transformation is rather cumbersome to write. To simplify the transformation, we have recently developed a novel approach that allows selecting subgraphs from the matched portion of the host graph, applying a filter condition to the selection, and performing a delete, move, or copy operation on the filtered result in the context of a transformation rule. The approach has been implemented in the GReAT language and tested on examples that show the practical efficacy of the technique. The paper describes the technique in detail and illustrates its use on a real-life example.", "num_citations": "16\n", "authors": ["572"]}
{"title": "Model-based software tools for integrated vehicle health management\n", "abstract": " Present day IVHM systems are often constructed using hand-written code that is hard to produce and difficult to verify and maintain. In this paper we introduce a suite of model-based tools that allow for the construction of embeddable IVHM applications using a model-based approach. Reusable (and potentially validated) reasoners are used in conjunction with executable code that is generated from models, thus allowing the integration of the reasoner as a component into a larger on-board system. This paper describes the toolsuite, the modeling approach used, the runtime environment, and some of the applications where the tools were used", "num_citations": "16\n", "authors": ["572"]}
{"title": "Model-based fault-adaptive control of complex dynamic systems\n", "abstract": " Complex control applications require capabilities for accommodating faults in the controlled plant. Fault accommodation involves the detection and isolation of faults, and then taking appropriate control actions to mitigate the fault effects and maintain control. This requires the integration of fault diagnostics with control in a feedback loop. This paper discusses a generic framework for building fault-adaptive control systems using a modelbased approach, with special emphasis on the modeling schemes that describe different aspects of the system at different levels of abstraction and granularity. The concepts are illustrated by a fault adaptive notional fuel system control example.", "num_citations": "16\n", "authors": ["572"]}
{"title": "Metamodel composition in the generic modeling environment\n", "abstract": " Domain-Specific Design Environments (DSDE) capture specifications and automatically generate or configure the target applications in particular engineering fields. Well known examples include Matlab/Simulink for signal processing [1] and LabView for instrumentation [2], among others. The success of DSDEs in a wide variety of applications in diverse fields is well documented. Their merit lies in the natural interface they provide to the designer. While the output of a DSDE is typically software in some shape or form, the user does not have to be a software engineer. In fact, a DSDE is specifically targeted at the domain engineers who want to keep using the standard notations and diagrams that are natural in their field.The main advantage of DSDEs is the automatic generation of the target application (software, hardware, configuration files, input to analysis tools, etc.) from specifications in the domain language. This has enormous productivity and system lifecycle cost implications. The alternative, the traditional approach, is to have the specifications provided by the domain engineers translated into code by a software. Clearly, development cost, turnaround time, productivity, maintenance cost and time, and necessary manpower would compare unfavorably to a DSDE. Why are then the use of DSDEs not more widespread?", "num_citations": "16\n", "authors": ["572"]}
{"title": "URMILA: Dynamically trading-off fog and edge resources for performance and mobility-aware IoT services\n", "abstract": " The fog/edge computing paradigm is increasingly being adopted to support a range of latency-sensitive IoT services due to its ability to assure the latency requirements of these services while supporting the elastic properties of cloud computing. IoT services that cater to user mobility, however, face a number of challenges in this context. First, since user mobility can incur wireless connectivity issues, executing these services entirely on edge resources, such as smartphones, will result in a rapid drain in the battery charge. In contrast, executing these services entirely on fog resources, such as cloudlets or micro data centers, will incur higher communication costs and increased latencies in the face of fluctuating wireless connectivity and signal strength. Second, a high degree of multi-tenancy on fog resources involving different IoT services can lead to performance interference issues due to resource contention. In\u00a0\u2026", "num_citations": "15\n", "authors": ["572"]}
{"title": "Deliberative, search-based mitigation strategies for model-based software health management\n", "abstract": " Rising software complexity in aerospace systems makes them very difficult to analyze and prepare for all possible fault scenarios at design time; therefore, classical run-time fault tolerance techniques such as self-checking pairs and triple modular redundancy are used. However, several recent incidents have made it clear that existing software fault tolerance techniques alone are not sufficient. To improve system dependability, simpler, yet formally specified and verified run-time monitoring, diagnosis, and fault mitigation capabilities are needed. Such architectures are already in use for managing the health of vehicles and systems. Software health management is the application of these techniques to software systems. In this paper, we briefly describe the software health management techniques and architecture developed by our research group. The foundation of the architecture is a real-time component\u00a0\u2026", "num_citations": "15\n", "authors": ["572"]}
{"title": "Real-time fault tolerant deployment and configuration framework for cyber physical systems\n", "abstract": " This paper describes ongoing work on making the deployment and configuration functionality for cyber physical systems reliable and tolerant to failures, while also supporting predictable and incremental online redeployment and reconfiguration of application functionality. Our work is currently designed and evaluated in the context of a system of fractionated spacecrafts, which is a representative CPS system.", "num_citations": "15\n", "authors": ["572"]}
{"title": "Polyglot: systematic analysis for multiple statechart formalisms\n", "abstract": " Polyglot is a tool for the systematic analysis of systems integrated from components built using multiple Statechart formalisms. In Polyglot, Statechart models are translated into a common Java representation with pluggable semantics for different Statechart variants. Polyglot is tightly integrated with the Java Pathfinder verification tool-set, providing analysis and test-case generation capabilities. The tool has been applied in the context of safety-critical software systems whose interacting components were modeled using multiple Statechart formalisms.", "num_citations": "15\n", "authors": ["572"]}
{"title": "Computer automated multi-paradigm modeling\n", "abstract": " Modeling and simulation are quickly becoming the primary enablers for complex system design. They allow the representation of intricate knowledge at various levels of abstraction and allow automated analysis as well as synthesis. The heterogeneity of the design process as much as of the system itself, however, requires a manifold of formalisms tailored to the specific task at hand. Efficient design approaches aim to combine different models of a system under study and maximally utilize the knowledge captured in them. Computer Automated Multi-Paradigm Modeling (CAMPaM) is the emerging field that addresses the issues involved and formulates a domain-independent framework along three dimensions:(i) multiple levels of abstraction,(ii) multi-formalism modeling, and (iii) meta-modeling. This article presents an overview of the CAMPaM field and shows how transformations assume a central place. These transformation are, in turn, explicitly modeled themselves by graph grammars.", "num_citations": "15\n", "authors": ["572"]}
{"title": "Towards specification of program synthesis in model-integrated computing\n", "abstract": " Model-integrated computing offers unique benefits for building computer-based systems. The tight integration of physical and information processess typical in CBSs is naturally addressed using this approach. However, the creation of model-integrated programming environments is a non-trivial task, which requires various skills on behalf of the system implementor. This paper addresses one particular issue of these environments: the specification and generation of model interpreters that are the tools responsible for translating models into components of the executable system.", "num_citations": "15\n", "authors": ["572"]}
{"title": "Optimization method for adaptive sensor reading scheduling and delayed alarm evaluation in real-time diagnostic systems\n", "abstract": " An optimization method is used in a real-time diagnostic system that monitors alarm sources and detects possible sources of failure in an industrial process. When the diagnostic system detects one or more alarms, it determines which components are likely sources of failure. The system determines the level of criticality of certain other, currently off-line, alarms sources and schedules the off-line alarms for evaluation according to their levels of criticality. The system refines its analysis of likely sources of failure by evaluating the status of the previously off-line alarm sources Those previously off-line alarm sources are added to the grouping of possible sources of failure prior to repeating the evaluation process. The evaluation process is repeated, with the analysis of likely causes of failure being continually refined.", "num_citations": "15\n", "authors": ["572"]}
{"title": "GReAT user manual\n", "abstract": " The GReAT tool suite has been designed for the rapid specification and implementation of model to model transformations. These transformations are required in many domains. A few use case scenarios of this tools suite are:\u25aa Developing model interpreters that convert gme models (conforming to a metamodel) to XML files conforming to a particular dtd.\u25aa Developing model interpreters that convert gme models (conforming to a metamodel) to a set of secondary data structures. A visitor can then be written to convert the secondary models to text.", "num_citations": "14\n", "authors": ["572"]}
{"title": "Real-time fault diagnostics with multiple aspect models\n", "abstract": " A real-time fault diagnostics system that is applicable for diagnosing large-scale plants is described. It uses a multiple aspect model of the plant including the hierarchical process model, the hierarchical component model, and the hierarchical fault model (HFM). HFM represents the spatial and temporal aspects of faulty behavior in the form of a hierarchical fault propagation digraph. The reasoning algorithm is based on the structural and temporal constraint enforcement, and is migrated to lower levels of HFM hierarchy. It is able to guarantee response times, perform nonmonotonic and temporal reasoning, operate continuously, accept asynchronous data, generate requests, perform time and diagnostic resolution tradeoffs, and diagnose single and most multiple fault cases.<>", "num_citations": "14\n", "authors": ["572"]}
{"title": "Dynamic modeling and control of nonlinear processes using neural network techniques\n", "abstract": " An adaptive network architecture of nonlinear elements and delay lines is proposed, which can be taught to model the time responses of a nonlinear, multivariable system. The structure has been applied to the modeling and control of a highly coupled multivariable process, namely, gas tungsten arc (GTA) welding. The authors present the architecture, learning algorithm, and experiments which showed the feasibility of the approach, and propose a controller architecture that can regulate a nonlinear, multivariable plant such as GTA welding.< >", "num_citations": "14\n", "authors": ["572"]}
{"title": "Declarative programming techniques for engineering problems.\n", "abstract": " Degree: Ph. D.DegreeYear: 1988Institute: Vanderbilt UniversityAdviser: Janos Sztipanovits.Declarative programming, which is based on the software technologies developed in the field of Artificial Intelligence research, is a suitable programming paradigm for engineering problems. In this thesis a novel definition is given for\" declarative programming\": programs written in declarative languages should deal with the architectural complexity issues of a system, while the algorithmic complexity should be addressed by using traditional, procedural languages. The purpose of the thesis is the analysis of this idea in the context of various implementations.", "num_citations": "14\n", "authors": ["572"]}
{"title": "Practical causal models for cyber-physical systems\n", "abstract": " Unlike faults in classical systems, faults in Cyber-Physical Systems will often be caused by the system\u2019s interaction with its physical environment and social context, rendering these faults harder to diagnose. To complicate matters further, knowledge about the behavior and failure modes of a system are often collected in different models. We show how three of those models, namely attack trees, fault trees, and timed failure propagation graphs can be converted into Halpern-Pearl causal models, combined into a single holistic causal model, and analyzed with actual causality reasoning to detect and explain unwanted events. Halpern-Pearl models have several advantages over their source models, particularly that they allow for modeling preemption, consider the non-occurrence of events, and can incorporate additional domain knowledge. Furthermore, such holistic models allow for analysis across model\u00a0\u2026", "num_citations": "13\n", "authors": ["572"]}
{"title": "Drems ml: A wide spectrum architecture design language for distributed computing platforms\n", "abstract": " Complex sensing, processing and control applications running on distributed platforms are difficult to design, develop, analyze, integrate, deploy and operate, especially if resource constraints, fault tolerance and security issues are to be addressed. While technology exists today for engineering distributed, real-time component-based applications, many problems remain unsolved by existing tools. Model-driven development techniques are powerful, but there are very few existing and complete tool chains that offer an end-to-end solution to developers, from design to deployment. There is a need for an integrated model-driven development environment that addresses all phases of application lifecycle including design, development, verification, analysis, integration, deployment, operation and maintenance, with supporting automation in every phase. Arguably, a centerpiece of such a model-driven environment is\u00a0\u2026", "num_citations": "13\n", "authors": ["572"]}
{"title": "Managing the quality of software product line architectures through reusable model transformations\n", "abstract": " In model-driven engineering of applications, the quality of the software architecture is realized and preserved in the successive stages of its lifecycle through model transformations. However, limited support for reuse in contemporary model transformation techniques forces developers of product line architectures to reinvent transformation rules for every variant of the product line, which can adversely impact developer productivity and in turn degrade the quality of the resulting software architecture for the variant. To overcome these challenges, this paper presents the MTS (Model-transformation Templatization and Specialization generative transformation process, which promotes reuse in model transformations through parameterization and specialization of transformation rules. MTS defines two higher order transformations to capture the variability in transformation rules and to specialize them across product\u00a0\u2026", "num_citations": "13\n", "authors": ["572"]}
{"title": "Rapid synthesis of multi-model simulations for computational experiments in c2\n", "abstract": " Virtual evaluation of complex command and control concepts demands the use of heterogeneous simulation environments. Development challenges include how to integrate multiple simulation platforms with varying semantics and how to integrate simulation models and the complex interactions between them. While existing simulation frameworks may provide many of the required services needed to coordinate among multiple simulation platforms, they lack an overarching integration approach that connects and relates the semantics of heterogeneous domain models and their interactions. This paper outlines some of the challenges encountered in developing a command and control simulation environment and discusses our use of the GME meta-modeling tool-suite to create a model-based integration approach that allows for rapid synthesis of complex HLA-based simulation environments.", "num_citations": "13\n", "authors": ["572"]}
{"title": "Model transformations in the model-based development of real-time systems\n", "abstract": " In this paper we argue for UML-based metamodeling and pattern-based graph transformation techniques in computer-based systems development through an illustrative example from the domain of embedded systems. We present a tool that uses advanced graph-rewriting techniques to generate a schedule that satisfies hard real-time constraints for multi-modal systems. The input is a time-triggered system specification (using the Giotto language); the output is an instruction sequence for the E-machine: a virtual machine for hard real-time embedded systems. The resulting model may be refined into a) system implementations (E-code programs) through a trivial synthesis process and b) development-time analysis models expressing the properties of the system implemented over different execution platforms. Furthermore, we identify the next steps to be taken towards generating analysis models using explicit\u00a0\u2026", "num_citations": "13\n", "authors": ["572"]}
{"title": "Fault-adaptive control: a CBS application\n", "abstract": " Complex control applications require a capability for accommodating faults in the controlled plant. Fault accommodation involves the detection and isolation of faults, and taking an appropriate control action that mitigates the effect of the faults and maintains control. This requires the integration of fault diagnostics with control, in a feedback loop. The paper discusses how a generic framework for building fault-adaptive control systems can be created using a model based approach. Instances of the framework are examples of complex CBSs (computer based systems) that have novel capabilities.", "num_citations": "13\n", "authors": ["572"]}
{"title": "Learning to control: some practical experiments with neural networks\n", "abstract": " The author reports on a series of experiments for controlling a nonlinear industrial plant using various neural network controller architectures. The architectures studied include copying an existing controller, inverse dynamics control, and feedback linearizable learning control. These experiments have shown the capabilities and potentials of using neural networks for control. In addition, some shortcomings of the approach were revealed, such as the need to estimate the order of the plant.< >", "num_citations": "13\n", "authors": ["572"]}
{"title": "Knowledge-based techniques in instrumentation\n", "abstract": " Opportunities for the application of knowledge-based techniques in Fourier transform infrared (FTIR) spectrometry are examined. Three issues are considered: (1) the new functionalities that can be implemented by artificial intelligence (AI) techniques; (2) the kind of AI techniques that can be used in this specific problem; and (3) how to merge AI techniques with existing, relatively small instruments, such as FTIR systems. The ADVICE facility developed to support the experiment design phase of the FTIR operation is described. Spectrum interpretation is discussed.< >", "num_citations": "13\n", "authors": ["572"]}
{"title": "Integrated simulation testbed for security and resilience of CPS\n", "abstract": " Owing 1 to an immense growth of internet-connected and learning-enabled cyber-physical systems (CPSs)[1], several new types of attack vectors have emerged. Analyzing security and resilience of these complex CPSs is difficult as it requires evaluating many subsystems and factors in an integrated manner. Integrated simulation of physical systems and communication network can provide an underlying framework for creating a reusable and configurable testbed for such analyses. Using a model-based integration approach and the IEEE High-Level Architecture (HLA)[2] based distributed simulation software; we have created a testbed for integrated evaluation of large-scale CPS systems. Our tested supports web-based collaborative metamodeling and modeling of CPS system and experiments and a cloud computing environment for executing integrated networked co-simulations. A modular and extensible cyber\u00a0\u2026", "num_citations": "12\n", "authors": ["572"]}
{"title": "Abstractions for modeling complex systems\n", "abstract": " The ever increasing popularity of model-based system- and software engineering has resulted in more and more systems\u2014and more and more complex systems\u2014being modeled. Hence, the problem of managing the complexity of the models themselves has gained importance. This paper introduces three abstractions that are specifically targeted at improving the scalability of the modeling process and the system models themselves.", "num_citations": "12\n", "authors": ["572"]}
{"title": "Embedded control systems language for distributed processing\n", "abstract": " Embedded Automotive systems are becoming increasingly complex, and as such difficult to design and develop. Model-based approaches are gaining foothold in this area, and increasingly the system design and development is being conducted with model-based tools, most notably Matlab\u00ae Simulink\u00ae and Stateflow\u00ae from Mathworks Inc., among others. However, these tools are addressing only a limited aspect of the system design. Moreover, there is a lack of integration between these tools, which makes overall system design and development cumbersome and error-prone. Motivated by these shortcomings we have developed an approach, based on Model-Integrated Computing, a technology matured over a decade of research at ISIS, Vanderbilt University. The center-piece of this approach is a graphical modeling language, Embedded Control Systems Language for Distributed Processing. A suite of translators and tools have been developed that facilitate the integration of ECSL-DP with industry standard Simulink and Stateflow tools, and open the possibility for integration of other tools, by providing convenient and extensible interfaces. A code generator has been developed that synthesizes implementation code, configuration and firmware gluecode from models. The approach has been prototyped and evaluated with a medium scale example. The results demonstrate the promise of the approach, and points to interesting directions for further research.", "num_citations": "12\n", "authors": ["572"]}
{"title": "Design-space construction and exploration in platform-based design\n", "abstract": " A fundamental requirement for achieving rapid turn-round and short timeto-market in embedded software and system development is to achieve high level of reuse. Platform-based design offers a systematic way to make tradeoff between the conflicting requirements of flexibility and reuse. This paper describes a modelintegrated approach in controlling and exploiting flexibility via the disciplined construction and automated exploration of large design-spaces on hardware/software platforms.", "num_citations": "12\n", "authors": ["572"]}
{"title": "Towards Two-Level Formal Modeling of Computer-Based Systems\n", "abstract": " Embedded Computer-based Systems are becoming highly complex and hard to implement because of the large number of concerns the designers have to address. These systems are tightly coupled to their environments and this requires an integrated view that encompasses both the information system and its physical surroundings. Therefore, mathematical analysis of these systems necessitates formal modeling of both\u201d sides\u201d and their interaction. There exist a number of suitable modeling techniques for describing the information system component and the physical environment, but the best choice changes from domain to domain. In this paper, we propose a two-level approach to modeling that introduces a meta-level representation. Meta-level models define modeling languages, but they can also be used to capture subtle interactions between domain level models. We will show how the twolevel approach\u00a0\u2026", "num_citations": "12\n", "authors": ["572"]}
{"title": "Metalevel extension of the multigraph architecture\n", "abstract": " Domain-specific model integrated program synthesis (MIPS) environments are created according to a modeling paradigm\u2013a description of the class of models that can be created using the system. Just as model integrated computing applications are executable instances of domain models, domain models can be viewed as instances of meta-models. Desired modeling environment characteristics are selected from a library of model composition constraints and combined with domain-specific modeling concepts and constraints to create a meta model. This meta model is then translated and used to automatically generate the actual MIPS environment. Advantages include support for formal specifications of domain-specific modeling paradigms and model interpreters, fast adaptation of applications through the automatic re-synthesis of running applications from models, evolution of applications through model modification, and slow evolution through incremental modification of the MIPS environment components.", "num_citations": "12\n", "authors": ["572"]}
{"title": "Model-integrated development of complex applications\n", "abstract": " Many large distributed applications are tightly integrated with their physical environments and must be adapted when their environment changes. Typically, software development methodologies do not place a large emphasis on modeling the system's environment, and hence environmental changes may lead to significant discrepancies in the software. The authors argue that (1) the modeling of the environment should be an integral part of the process, and (2) to support software evolution, wherever possible, the software should be automatically generated. They present a model-integrated development approach that is capable of supporting cost effective system evolution in accordance with changes in the system's environment. The approach is supported by a \"meta-architecture\" that provides a framework for building complex software systems using COTS and custom developed software components. This\u00a0\u2026", "num_citations": "12\n", "authors": ["572"]}
{"title": "Modelling paradigm for parallel signal processing\n", "abstract": " CiNii \u8ad6\u6587 - Modelling paradigm for parallel signal processing CiNii \u56fd\u7acb\u60c5\u5831\u5b66\u7814\u7a76\u6240 \u5b66\u8853 \u60c5\u5831\u30ca\u30d3\u30b2\u30fc\u30bf[\u30b5\u30a4\u30cb\u30a3] \u65e5\u672c\u306e\u8ad6\u6587\u3092\u3055\u304c\u3059 \u5927\u5b66\u56f3\u66f8\u9928\u306e\u672c\u3092\u3055\u304c\u3059 \u65e5\u672c\u306e\u535a\u58eb\u8ad6\u6587\u3092\u3055\u304c\u3059 \u65b0\u898f\u767b\u9332 \u30ed\u30b0\u30a4\u30f3 English \u691c\u7d22 \u3059\u3079\u3066 \u672c\u6587\u3042\u308a \u3059\u3079\u3066 \u672c\u6587\u3042\u308a \u9589\u3058\u308b \u30bf\u30a4\u30c8\u30eb \u8457\u8005\u540d \u8457\u8005ID \u8457\u8005\u6240\u5c5e \u520a\u884c\u7269\u540d ISSN \u5dfb\u53f7\u30da\u30fc\u30b8 \u51fa\u7248\u8005 \u53c2\u8003\u6587\u732e \u51fa\u7248\u5e74 \u5e74\u304b\u3089 \u5e74\u307e\u3067 \u691c\u7d22 \u691c\u7d22 \u691c\u7d22 CiNii\u306e\u30b5\u30fc\u30d3\u30b9\u306b\u95a2\u3059\u308b\u30a2\u30f3\u30b1\u30fc\u30c8\u3092\u5b9f\u65bd\u4e2d\u3067\u3059\uff0811/11(\u6c34)-12/23(\u6c34)\uff09 Modelling paradigm for parallel signal processing LENDECZI A. \u88ab\u5f15\u7528\u6587\u732e: 1\u4ef6 \u8457\u8005 LENDECZI A. \u53ce\u9332\u520a\u884c\u7269 The Australian Computer Jour. The Australian Computer Jour. 27(3), 92-102, 1995 \u88ab\u5f15\u7528\u6587\u732e: 1\u4ef6\u4e2d 1-1\u4ef6\u3092 \u8868\u793a 1 \u30de\u30eb\u30c1\u30e1\u30c7\u30a3\u30a2\u4fe1\u53f7\u51e6\u7406\u4ed5\u69d8\u304b\u3089\u306e\u30c7\u30fc\u30bf\u99c6\u52d5\u30d7\u30ed\u30b0\u30e9\u30e0\u306e\u76f4\u63a5\u751f\u6210\u624b\u6cd5 \u5510\u6fa4 \u572d , \u5ca9\u7530 \u8aa0 , \u5bfa\u7530 \u6d69\u8a54 \u96fb\u5b50\u60c5\u5831\u901a\u4fe1\u5b66\u4f1a\u8ad6\u6587\u8a8c. D-1, \u60c5\u5831\u30fb\u30b7\u30b9\u30c6\u30e0 1-\u60c5\u5831\u51e6\u7406 00082(00005), 603-612, 1999-05 \u53c2\u8003\u6587\u732e17\u4ef6 CiNii\u5229\u7528\u8005\u30a2\u30f3\u30b1\u30fc\u30c8 Tweet \u5404\u7a2e\u30b3\u30fc\u30c9 NII\u8ad6\u6587ID(NAID) \u2026", "num_citations": "12\n", "authors": ["572"]}
{"title": "Model-based design for cps with learning-enabled components\n", "abstract": " Recent advances in machine learning led to the appearance of Learning-Enabled Components (LECs) in Cyber-Physical Systems. LECs are being evaluated and used for various, complex functions including perception and control. However, very little tool support is available for design automation in such systems. This paper introduces an integrated toolchain that supports the architectural modeling of CPS with LECs, but also has extensive support for the engineering and integration of LECs, including support for training data collection, LEC training, LEC evaluation and verification, and system software deployment. Additionally, the toolsuite supports the modeling and analysis of safety cases-a critical part of the engineering process for mission and safety critical systems.", "num_citations": "11\n", "authors": ["572"]}
{"title": "Resilience at the edge in cyber-physical systems\n", "abstract": " As the number of low cost computing devices at the edge of communication network increase, there are greater opportunities to enable innovative capabilities, especially in cyber-physical systems. For example, micro-grid power systems can make use of computing capabilities at the edge of a Smart Grid to provide more robust and decentralized control. However, the downside to distributing intelligence to the edge away from the controlled environment of the data centers is the increased risk of failures. The paper introduces a framework for handling these challenges. The contribution of this framework is to support strategies to (a) tolerate the transient faults as they appear due to network fluctuations or node failures, and to (b) systematically reconfigure the application if the faults persist.", "num_citations": "11\n", "authors": ["572"]}
{"title": "Using temporal causal models to isolate failures in power system protection devices\n", "abstract": " We introduced the modeling paradigm of Temporal Causal Diagrams (TCD) in this paper. TCDs capture fault propagation and behavior (nominal and faulty) of system components. An example model for the power transmission systems was also described. This TCD model was then used to develop an executable simulation model in Simulink/ Stateflow. Though this translation of TCD to an executable model is currently done manually, we are developing model templates and tools to automate this process. Simulations results (i.e., event traces) for a couple of single and multi-fault scenarios were also presented. As part of our future work, we wish to test and study the scalability of this approach towards a larger power transmission system taking into account a far richer set of protection elements. Further, we wish to consider more realistic event traces from the fault scenarios including missing, inconsistent and out-of\u00a0\u2026", "num_citations": "11\n", "authors": ["572"]}
{"title": "A case study on the model-based design and integration of automotive cyber-physical systems\n", "abstract": " Cyber-physical systems (CPS), such as automotive systems, are very difficult to design due to the tight interactions between the physical dynamics, computational dynamics and communication networks. In addition, the evaluation of these systems at the early design stages is very crucial and challenging. Model-based design (MBD) approaches have been applied in order to manage the complexities due interactions. In this paper, we present a case study to demonstrate the systematic design, analysis and evaluation of an integrated automotive control system. The system is composed of two independently designed controllers, a lane keeping controller and an adaptive cruise controller, which interact as a result of the integration. The integrated system is deployed on a hardware-in-the-loop simulator for evaluation under realistic scenarios. We present experimental results that demonstrate the effectiveness of the\u00a0\u2026", "num_citations": "11\n", "authors": ["572"]}
{"title": "Reliable distributed real-time and embedded systems through safe middleware adaptation\n", "abstract": " Distributed real-time and embedded (DRE) systems are a class of real-time systems formed through a composition of predominantly legacy, closed and statically scheduled real-time subsystems, which comprise over-provisioned resources to deal with worst-case failure scenarios. The formation of the system-of-systems leads to a new range of faults that manifest at different granularities for which no statically defined fault tolerance scheme applies. Thus, dynamic and adaptive fault tolerance mechanisms are needed which must execute within the available resources without compromising the safety and timeliness of existing real-time tasks in the individual subsystems. To address these requirements, this paper describes a middleware solution called Safe Middleware Adaptation for Real-Time Fault Tolerance (SafeMAT), which opportunistically leverages the available slack in the over-provisioned resources of\u00a0\u2026", "num_citations": "11\n", "authors": ["572"]}
{"title": "The inertial measurement unit example: A software health management case study\n", "abstract": " This report captures in detail a Two-level Software Health Management strategy on a real-life example of an Inertial Measurement Unit subsystem. We describe in detail the design of the component and system level health management strategy. Results are expressed as relevant portions of the detailed logs that shows the successful adaptation of the monitor/detect/diagnose/mitigate approach to Software Health Management.", "num_citations": "11\n", "authors": ["572"]}
{"title": "Distributed diagnosis of complex systems using timed failure propagation graph models\n", "abstract": " Timed failure propagation graph (TFPG) is a directed graph model that represents temporal progression of failure effects in physical systems. In this paper, a distributed diagnosis approach for complex systems is introduced based on the TFPG model settings. In this approach, the system is partitioned into a set of local subsystems each represented by a subgraph of the global system TFPG model. Information flow between subsystems is achieved through special input and output nodes. A high level diagnoser integrates the diagnosis results of the local subsystems using an abstract high level model to obtain a globally consistent diagnosis of the system.", "num_citations": "11\n", "authors": ["572"]}
{"title": "A transformation instance-based approach to traceability\n", "abstract": " Although traceability is often a suggested requirement for general software development, there are areas such as airborne systems, where traceability is a compulsory part of the development process. This paper describes a tool chain that is able to generate and to follow traceability links across model-to-model and model-to-code transformations, and capable of providing navigability support along these traceability links. We elaborate on the conceptual design of our tool chain and provide details on its realization in a DSML environment underpinned by graph rewriting-based model transformation.", "num_citations": "11\n", "authors": ["572"]}
{"title": "Towards a real-time component framework for software health management\n", "abstract": " 1 The complexity of software in systems like aerospace vehicles has reached the point where new techniques are needed to ensure system dependability. Such techniques include a novel direction called \u2018Software Health Management\u2019(SHM) that extends classic software fault tolerance with techniques borrowed from System Health Management. In this paper the initial steps towards building a SHM approach are described that combine component-based software construction with hard real-time operating system platforms. Specifically, the paper discusses how the CORBA Component Model could be combined with the ARINC-653 platform services and the lessons learned from this experiment. The results point towards both extending the CCM as well as revising the ARINC-653.", "num_citations": "11\n", "authors": ["572"]}
{"title": "A visually-specified code generator for simulink/stateflow\n", "abstract": " Visual modeling languages are often used today in engineering domains, Mathworks' Simulink/Stateflow for simulation, signal processing and controls being the prime example. However, they are also becoming suitable for implementing other computational tasks, like model transformations. In this paper we briefly introduce GReAT: a visual language with simple, yet powerful semantics for implementing transformations on attributed, typed hypergraphs with the help of explicitly sequenced graph transformation rules. The main contribution of the paper is a Simulink/Stateflow code generator that generates executable code (running on a distributed platform) from the visual input models. The paper provides an overview of the algorithms used and their realization in GReAT.", "num_citations": "11\n", "authors": ["572"]}
{"title": "Integrated diagnosis and control for hybrid dynamic systems\n", "abstract": " In this paper we present an approach for combined fault diagnosis and reconfigurable control structure for a general class of hybrid systems. In this approach a plant is modeled using an extended version of bond graphs, namely hybrid bond graph, where discrete mode transitions are represented as binary switch junctions. A hybrid observer has been developed that uses this model to track the system behavior within and across modes. Two complementary approaches are used for fault detection and isolation. The first diagnoser is based on hybrid models and uses the hybrid observer, qualitative reasoning techniques, and real-time parameter estimation. The other diagnoser is based an abstracted discrete event model of the system that shows the causal and temporal relation between failure modes and corresponding abstract observations. To accommodate detected failure a new controller can be selected for a\u00a0\u2026", "num_citations": "11\n", "authors": ["572"]}
{"title": "Model-integrated on-line problem-solving in chemical engineering\n", "abstract": " Complex chemical plants need various custom monitoring, control, simulation and diagnostic software codes that necessitate the integration of models into the problem-solving process. This paper describes a system and its practical applications that support this process. The work described here is based on the Multigraph Architecture: a generic framework for building model-based systems. The paper discusses the modeling paradigm and techniques used, how the applications are generated, and some practical, existing applications.", "num_citations": "11\n", "authors": ["572"]}
{"title": "Model-embedded on-line problem solving environment for chemical engineering\n", "abstract": " The building of custom monitoring, control, simulation and diagnostics applications for complex chemical plants necessitates the integration of models into the problem solving process. This paper describes a system and its practical applications that supports this activity. It is based on the Multigraph Architecture, which is a generic framework for building these model-based systems. The paper discusses the modeling paradigms used, how the applications are generated, and some practical, existing applications.", "num_citations": "11\n", "authors": ["572"]}
{"title": "Neuromorphic learning of continuous-valued mappings in the presence of noise: Application to real-time adaptive control\n", "abstract": " The ability of feed-forward neural net architectures to learn continuous-valued mappings in the presence of noise is demonstrated in relation to parameter identification and realtime adaptive control applications. Factors and parameters influencing the learning performance of such nets in the presence of noise are identified. Their effects are discussed through a computer simulation of the Back-Error-Propagation algorithm by taking the example of the cart-pole system controlled by a non-linear control law. Adequate sampling of the state space is found to be essential for canceling the effect of the statistical fluctuations and allowing learning to take place.", "num_citations": "11\n", "authors": ["572"]}
{"title": "Vulnerability analysis of power systems based on cyber-attack and defense models\n", "abstract": " Reliable operation of power systems is a primary challenge for the system operators. With the advancement in technology and grid automation, power systems are becoming more vulnerable to cyber-attacks. The main goal of adversaries is to take advantage of these vulnerabilities and destabilize the system. This paper describes a game-theoretic approach to attacker / defender modeling in power systems. In our models, the attacker can strategically identify the subset of substations that maximize damage when compromised. However, the defender can identify the critical subset of substations to protect in order to minimize the damage when an attacker launches a cyber-attack. The algorithms for these models are applied to the standard IEEE-14, 39, and 57 bus examples to identify the critical set of substations given an attacker and a defender budget.", "num_citations": "10\n", "authors": ["572"]}
{"title": "Transactive energy demo with RIAPS platform\n", "abstract": " This work presents a platform for decentralized distributed computing called Resilient Information Architecture for the Smart Grid (RIAPS) through a transactional energy and a traffic application.", "num_citations": "10\n", "authors": ["572"]}
{"title": "A rapid testing framework for a mobile cloud\n", "abstract": " Mobile clouds such as network-connected vehicles and satellite clusters are an emerging class of systems that are extensions to traditional real-time embedded systems: they provide long-term mission platforms made up of dynamic clusters of heterogeneous hardware nodes communicating over ad hoc wireless networks. Besides the inherent complexities entailed by a distributed architecture, developing software and testing these systems is difficult due to a number of other reasons, including the mobile nature of such systems, which can require a model of the physical dynamics of the system for accurate simulation and testing. This paper describes a rapid development and testing framework for a distributed satellite system. Our solutions include a modeling language for configuring and specifying an application's interaction with the middleware layer, a physics simulator integrated with hardware in the loop to\u00a0\u2026", "num_citations": "10\n", "authors": ["572"]}
{"title": "Establishing secure interactions across distributed applications in satellite clusters\n", "abstract": " Recent developments in small satellites have led to an increasing interest in building satellite clusters as open systems that provide a \"cluster-as-a-service\" in space. Since applications with different security classification levels must be supported in these open systems, the system must provide strict information partitioning such that only applications with matching security classifications interact with each other. The anonymous publish/subscribe communication pattern is a powerful interaction abstraction that has enjoyed great success in previous space software architectures, such as NASA's Core Flight Executive. However, the difficulty is that existing solutions that support anonymous publish/subscribe communication, such as the OMG Data Distribution Service (DDS), do not support information partitioning based on security classifications, which is a key requirement for some systems. This paper makes two\u00a0\u2026", "num_citations": "10\n", "authors": ["572"]}
{"title": "Analysis, verification, and management toolsuite for cyber-physical applications on time-varying networks\n", "abstract": " Cyber-Physical Systems (CPS) are increasingly utilizing advances in wireless mesh networking among computing nodes to facilitate communication and control for distributed applications. Factors such as interference or node mobility cause such wireless networks to experience changes in both topology and link capacities. These dynamic networks pose a reliability concern for high-criticality or mixed-criticality systems which require strict guarantees about system performance and robustness prior to deployment. To address the design-and run-time verification and reliability concerns created by these dynamic networks, we are developing an integrated modeling, analysis, and run-time toolsuite which provides (1) network profiles that model the dynamics of system network resources and application network requirements over time,(2) design-time verification of application performance on dynamic networks, and (3\u00a0\u2026", "num_citations": "10\n", "authors": ["572"]}
{"title": "Colored Petri Net-based Modeling and Formal Analysis of Component-based Applications.\n", "abstract": " Distributed Real-Time Embedded (DRE) Systems that address safety and mission-critical system requirements are applied in a variety of domains today. Complex, integrated systems like managed satellite clusters expose heterogeneous concerns such as strict timing requirements, complexity in system integration, deployment, and repair; and resilience to faults. Integrating appropriate modeling and analysis techniques into the design of such systems helps ensure predictable, dependable and safe operation upon deployment. This paper describes how we can model and analyze applications for these systems in order to verify system properties such as lack of deadline violations. Our approach is based on (1) formalizing the component operation scheduling using Colored Petri nets (CPN),(2) modeling the abstract temporal behavior of application components, and (3) integrating the business logic and the component operation scheduling models into a concrete CPN, which is then analyzed. This model-driven approach enables a verification-driven workflow wherein the application model can be refined and restructured before actual code development.", "num_citations": "10\n", "authors": ["572"]}
{"title": "Component-based modeling of dynamic systems using heterogeneous composition\n", "abstract": " Cyber-Physical Systems (CPS) are composed of computational and physical components, which includes various types of physical phenomena such as electrical and mechanical domains. Many modeling paradigms exist to model the static properties and dynamic behavior of such components. However, there is no unified modeling framework to compose components that use different paradigms and/or tools. In this paper, we present the syntax and semantics of such an integration language and its component-based design, where components can embed models from different tools, formalisms, and paradigms such as Bond Graphs and Modelica models. Our framework is built around common set of interface concepts to support heterogeneous composition and interchangeability among modeling paradigms.", "num_citations": "10\n", "authors": ["572"]}
{"title": "A deliberative reasoner for model-based software health management\n", "abstract": " While traditional design-time and off-line approaches to testing and verification contribute significantly to improving and ensuring high dependability of software, they may not cover all possible fault scenarios that a system could encounter at runtime. Thus, runtime \u2018health management\u2019of complex embedded software systems is needed to improve their dependability. Our approach to Software Health Management uses concepts from the field of \u2018Systems Health Management\u2019: detection, diagnosis and mitigation. In earlier work we had shown how to use a reactive mitigation strategy specified using a timed state machine model for system health manager. This paper describes the algorithm and key concepts for an alternative approach to system mitigation using a deliberative strategy, which relies on a function-allocation model to identify alternative component-assembly configurations that can restore the functions needed for the goals of the system.", "num_citations": "10\n", "authors": ["572"]}
{"title": "Discrete abstraction and supervisory control of switching systems\n", "abstract": " In this paper we propose a method to create discrete abstraction of state space behavior for continuous-time systems based on gradient analysis of the system dynamics. Then we describe how to use such a discrete model to design a supervisory controller for a given safety specification for the system. Finally we provide an entropy measure of nondeterminism, which can be used to evaluate the quality of the result discrete model as the degree of nondeterminism in that model.", "num_citations": "10\n", "authors": ["572"]}
{"title": "Tool Support for Design Patterns\n", "abstract": " Design patterns have been widely recognized as important contributors to the success of software systems, yet there is little tool support for their application. In this paper an approach is presented that outlines how graph rewriting techniques can be used to build tool support for design patterns. The paper considers design patterns as graph rewriting rules to be applied in class diagram, and it presents an example for its application.", "num_citations": "10\n", "authors": ["572"]}
{"title": "Why XML is not suitable for semantic translation\n", "abstract": " Recently, XML [XML] has been extended with a capability, called XSLT,[XSL] for translating XML data compliant with one DTD into XML compliant with another DTD. This approach has been hailed as the general solution for data transformation in database systems that can solve any and all data integration problems by providing a simple way for transforming data. In this note I will briefly review the XSLT approach and contrast it with another approach developed for tool integration.", "num_citations": "10\n", "authors": ["572"]}
{"title": "A simulation testbed for cascade analysis\n", "abstract": " Electrical power systems are heavily instrumented with protection assemblies (relays and breakers) that detect anomalies and arrest failure propagation. However, failures in these discrete protection devices could have inadvertent consequences, including cascading failures resulting in blackouts. This paper aims to model the behavior of these discrete protection devices in nominal and faulty conditions and apply it towards simulation and contingency analysis of cascading failures in power transmission systems. The behavior under fault conditions are used to identify and explain conditions for blackout evolution which are not otherwise obvious. The results are demonstrated using a standard IEEE-14 Bus System.", "num_citations": "9\n", "authors": ["572"]}
{"title": "Enabling self-management by using model-based design space exploration\n", "abstract": " Reconfiguration and self-management are important properties for systems that operate in hazardous and uncontrolled environments, such as inter-planetary space. These systems need a reconfiguration mechanism that provides recovery from individual component failures as well as the ability to dynamically adapt to evolving mission goals. One way to provide this functionality is to define a model of alternative system configurations and allow the system to choose the current configuration based on its current state, including environmental parameters and goals. The primary difficulties with this approach are (1) the state space of configurations can grow very large, which can make explicit enumeration infeasible, and (2) the component failures and evolving system goals must be somehow encoded in the system configuration model. This paper describes an online reconfiguration method based on model-based\u00a0\u2026", "num_citations": "9\n", "authors": ["572"]}
{"title": "Lessons learned from building a graph transformation system\n", "abstract": " Model-driven software development is a language- and transformation-based paradigm, where the various development tasks of engineers are cast in this framework. During the past decade we have developed, evolved, and applied in practical projects a manifestation of this principle through a suite of tools we call the Model-Integrated Computing suite. Graph transformations are fundamental to this environment and tools for constructing model translators, for the specification of the semantics of languages, for the evolution of modeling languages, models, and their transformations have been built. Designing and building these tools have taught us interesting lessons about graph transformation techniques, language engineering, scalability and abstractions, pragmatic semantics, verification, and evolutionary changes in tools and designs. In the paper we briefly summarize the techniques and tools we have\u00a0\u2026", "num_citations": "9\n", "authors": ["572"]}
{"title": "Model-based adaptation of flight-critical systems\n", "abstract": " In this paper we describe our experience applying the Producible Adaptive Model-based Software (PAMS) technology to the development of safety critical flight control software. PAMS is based on the state of the art Model Integrated Computing (MIC) environment from Vanderbilt University and represents a highly evolvable model-based software development methodology and tool suite that is revolutionary in its ability to address software adaptation. In particular, PAMS is an adaptation framework that introduces support for model transformations, co-evolution of models and modeling tools, and self-adaptation of systems. Analogous to delayed binding in compiler technology, PAMS enables binding software updates statically at design-time, on a configuration basis at load-time, and dynamically at run-time. The focus of this paper will be the application of PAMS to designtime evolution.", "num_citations": "9\n", "authors": ["572"]}
{"title": "Recent advances in multi-paradigm modeling\n", "abstract": " Model-Based Design of complex software systems is an activity that requires the use of different modeling formalisms, with different perspectives of the system, to cover all relevant aspects of the system, to avoid over-design, to employ manageable models and to support system integration. The comprehensive use of models in design has created a set of challenges beyond those of supporting one isolated design task. In particular, the need to combine, couple, and integrate models at different levels of abstraction and in different formalisms is posing a set of specific problems that must be tackled. Multi-Paradigm Modeling is precisely the research field to focus on developing an appropriate set of concepts and tools to address the challenge of integrating models of different aspects of a software system specified using different formalisms and eventually at different levels of abstraction. This paper summarizes\u00a0\u2026", "num_citations": "9\n", "authors": ["572"]}
{"title": "A model transformation for automated concrete syntax definitions of metamodeled visual languages\n", "abstract": " Metamodeling techniques are popular in describing the rules of special domains, but these techniques do not support defining presentation for these domains, namely the concrete syntax. The aim of our research is to provide a method to create the concrete syntax for metamodeling systems in a flexible, efficient way. Several domain-specific languages have been created that support defining the concrete syntax, ie the visualization. The main concern of this paper is to present a model transformation method that processes our presentation definitions and transforms them automatically into source code. The source code implements a plug-in capable of editing the models. A termination analysis for the presented method is also provided.", "num_citations": "9\n", "authors": ["572"]}
{"title": "Implementation of reconfiguration management in fault-adaptive control systems\n", "abstract": " Fault adaptive systems must adapt and reconfigure themselves to the changes in the environment or the system itself, and have to maintain operation even in case of system failures. In order to avoid performance degradation due to system reconfigurations, adequate reconfiguration management is necessary. This paper describes a fault-adaptive control system with multilayer control and a reconfiguration management system.", "num_citations": "9\n", "authors": ["572"]}
{"title": "Hybrid modeling and diagnosis in the real world: A case study\n", "abstract": " Applying model-based diagnosis techniques to systems that exhibit hybrid behavior presents an interesting set of challenges that mostly revolve around interactions of the continuous and discrete components of the system. In many real world systems, the overall physical plant is inherently continuous, but system control is performed by a supervisory controller that imposes discrete switching behaviors by reconfiguring the system components, or switching controllers. In this paper, we present a case study of an aircraft fuel system, and discuss methodologies for building system models for online tracking of system behavior and performing fault isolation and identification. Empirical studies are performed on detection and isolation for a set of pump and pipe failures.Descriptors:", "num_citations": "9\n", "authors": ["572"]}
{"title": "Integrated approach to diagnosis of complex hybrid systems\n", "abstract": " This paper presents a model-based approach to diagnosis of hybrid systems. We have developed a combined qualitative-quantitative diagnosis scheme that uses hybrid models of the system and a model of the supervisory controller. By applying the supervisory controller model to diagnostic analysis we significantly cut down on the complexity in tracking behaviors, and in generating and refining hypotheses across discrete mode changes in the system behavior. We present the algorithms for hybrid diagnosis: hypotheses generation by back propagation, and hypotheses refinement by forward propagation and parameter estimation. Example scenarios demonstrate the effectiveness of this approach.", "num_citations": "9\n", "authors": ["572"]}
{"title": "Model integrated computing-based software design and evolution\n", "abstract": " Among the most significant technological developments of the past 20 years are computer-based systems (CBSs), where functional, performance, and reliability requirements demand the tight integration of physical processes and information processing. Because complex component interactions exist in these systems, we must construct the software and its associated hardware such that they can evolve together.Model integrated computing (MIC) is an effective and efficient method for developing, maintaining, and evolving large-scale, domain-specific CBS applications. MIC is modelbased, allowing the synthesis of application programs from models created using customized, domain-specific, multi-aspect model integrated program synthesis (MIPS) environments. Integrated models explicitly represent dependencies and constraints among various design views. Because engineers can input design information at appropriate levels in the design hierarchy, and are freed from low-level implementation details, true end-user programmability is achieved.", "num_citations": "9\n", "authors": ["572"]}
{"title": "Integrated Analysis Environment for High Impact Systems\n", "abstract": " Modeling and analysis of high consequence, high assurance systems requires special modeling considerations. System safety and reliability information must be captured in the models. Previously, high consequence systems were modeled using separate, disjoint models for safety, reliability, and security. The MultiGraph Architecture facilitates the implementation of a model integrated system for modeling and analysis of high assurance systems. Model integrated computing allows an integrated modeling technique to be applied to high consequence systems. Among the tools used for analyzing safety and reliability are a behavioral simulator and an automatic fault tree generation and analysis tool. Symbolic model checking techniques are used to efficiently investigate the system models. A method for converting finite state machine models to ordered binary decision diagrams allows the application of symbolic model checking routines to the integrated system models. This integrated approach to modeling and analysis of high consequence systems ensures consistency between the models and the different analysis tools.", "num_citations": "9\n", "authors": ["572"]}
{"title": "Model-based programming for parallel image processing\n", "abstract": " We describe a programming environment which is being developed for the automatic generation of parallel image processing applications. Through the use of model-based software synthesis, we transparently create large grained data parallel applications which can be executed on arbitrary processor networks. The high-level abstractions provided by the modeling paradigm isolates the user from the complexity of the underlying implementation, allowing developers with little or no experience in parallel programming to rapidly create parallel applications. The data parallel modeling facilities perform the same tasks as the data alignment and distribution compiler directives of High Performance Fortran and the aggregate objects of pC++. However, we have found that by introducing the parallelism on the system level, instead of in the algorithm, we can use traditional compilers and leave the application specific code\u00a0\u2026", "num_citations": "9\n", "authors": ["572"]}
{"title": "Distributed microgrid synchronization strategy using a novel information architecture platform\n", "abstract": " To seamlessly reconnect an islanded microgrid to the main grid, voltage phasors on both sides of the point of common coupling need to be synchronized before the main relay closes. In this paper, a distributed control strategy is proposed for microgrid synchronization operation. The proposed controller design utilizes pinning-based consensus algorithm to avoid system single point of failure. It is able to actively track the main grid frequency, provide a good coordination between frequency and phase regulation and ensure all distributed generations in the system proportionally share the load. Implementation of such distributed algorithm in practice is difficult because it requires mitigation of both distributed computing and power system engineering challenges. In this paper, a novel software platform called RIAPS platform is presented that helps implementing the proposed distributed synchronization strategy in\u00a0\u2026", "num_citations": "8\n", "authors": ["572"]}
{"title": "An adaptive interleaving algorithm for multi-converter systems\n", "abstract": " To integrate DC distributed generation (DG) with micro-source into the existing AC grid, a DC distribution bus can be used to couple on-site photovoltaics (PV), battery energy storage systems (BESS), and DC loads. If the converters connected to the DC bus are interleaved, the DC bus capacitor size could be minimized. In this paper, we propose an interleaving algorithm for multi-converter systems to minimize the current harmonics at switching frequency on the DC bus. The proposed algorithm is implemented using Resilient Information Architecture Platform for Smart Grid (RIAPS) platform. Hardware-in-the-Loop (HIL) simulation results based on Opal- RT are presented to validate its performance. The influence of synchronization frequency on the proposed algorithm are also considered.", "num_citations": "8\n", "authors": ["572"]}
{"title": "Temporal causal diagrams for diagnosing failures in cyber physical systems\n", "abstract": " Resilient and reliable operation of cyber physical systems of societal importance such as Smart Electric Grids is one of the top national priorities. Due to their critical nature, these systems are equipped with fast-acting, local protection mechanisms. However, commonly misguided protection actions together with system dynamics can lead to unintentional cascading effects. This paper describes the ongoing work usingTemporal Causal Diagrams TCD, a refinement of the Timed Failure Propagation Graphs TFPG, to diagnose problems associated with the power transmission lines protected by a combination of relays and breakers. The TCD models represent the faults and their propagationas TFPG, the nominal and faulty behavior of components including local, discrete controllers and protection devices as Timed Discrete Event Systems TDES, and capture the cumulative and cascading effects of these interactions. TheTCD diagnosis engine includes an extended TFPG-like reasonerwhich in addition to observing the alarms and mode changes as the TFPG, monitors the event traces that correspond to the behavioral aspects of the model to generate hypotheses that consistently explain all the observations. In this paper, we show the results of applying the TCD to a segment of a power transmission system that is protected by distance relays and breakers.Descriptors:", "num_citations": "8\n", "authors": ["572"]}
{"title": "An FMI-based tool for robust design of dynamical systems\n", "abstract": " Concepts from quality sciences, such as robust design, six-sigma, and design-of-experiments have had a large impact on product development in industry. These concepts are increasingly used in a model-based engineering context where data is gathered from simulation models rather than laboratory setups or prototypes.This paper presents a framework to apply such ideas to analysis of dynamical systems. A set of tools that can be used for uncertainty analysis of dynamical Modelica models is presented. These tools are made available in the FMI Toolbox for MATLAB. The workflow and tools are demonstrated on a cooling loop design problem.", "num_citations": "8\n", "authors": ["572"]}
{"title": "Towards a self-adaptive deployment and configuration infrastructure for cyber-physical systems\n", "abstract": " Multi-module Cyber-Physical Systems (CPSs), such as satellite clusters, swarms of Unmanned Aerial Vehicles (UAV), and fleets of Unmanned Underwater Vehicles (UUV) are examples of managed distributed real-time systems where mission-critical applications, such as sensor fusion or coordinated flight control, are hosted. These systems are dynamic and reconfigurable, and provide a \u201cCPS cluster-as-a-service\u201d for mission-specific scientific applications that can benefit from the elasticity of the cluster membership and heterogeneity of the cluster members. Distributed and remote nature of these systems often necessitates the use of Deployment and Configuration (D&C) services to manage lifecycle of software applications. Fluctuating resources, volatile cluster membership and changing environmental conditions require resilience. However, due to the dynamic nature of the system, human intervention is often infeasible. This necessitates a self-adaptive D&C infrastructure that supports autonomous resilience. Such an infrastructure must have the ability to adapt existing applications on the fly in order to provide application resilience and must itself be able to adapt to account for changes in the system as well as tolerate failures. This paper describes the design and architectural considerations to realize a self-adaptive, D&C infrastructure for CPSs. Previous efforts in this area have resulted in D&C infrastructures that support application adaptation via dynamic re-deployment and re-configuration mechanisms. Our work, presented in this paper, improves upon these past efforts by implementing a selfadaptive D&C infrastructure which itself is resilient\u00a0\u2026", "num_citations": "8\n", "authors": ["572"]}
{"title": "A model-driven software component framework for fractionated spacecraft\n", "abstract": " Fractionated spacecraft is a novel space architecture that uses a cluster of small spacecraft modules (with their own attitude control and propulsion systems) connected via wireless links to accomplish complex missions. Resources, such as sensors, persistent storage space, processing power, and downlink bandwidth can be shared among the members of the cluster thanks to the networking. Such spacecraft can serve as a cost effective, highly adaptable, and fault tolerant platform for running various distributed mission software applications that collect, process, and downlink data. Naturally, a key component in such a system is the software platform: the distributed operating system and software infrastructure that makes such applications possible. Existing operating systems are insufficient, and newer technologies like component frameworks do not address all the requirements of such flexible space architectures. The high degree of flexibility and the need for thorough planning and analysis of the resource management necessitates the use of advanced development techniques. This paper describes the core principles and design of a software component framework for fractionated spacecraft that is a special case of a distributed real-time embedded system. Additionally we describe how a model-driven development environment helps with the design and engineering of complex applications for this platform.", "num_citations": "8\n", "authors": ["572"]}
{"title": "Fault-adaptivity in hard real-time component-based software systems\n", "abstract": " Complexity in embedded software systems has reached the point where we need run-time mechanisms that provide fault management services. Testing and verification may not cover all possible scenarios that a system encounters, hence a simpler, yet formally specified run-time monitoring, diagnosis, and fault mitigation architecture is needed to increase the software system\u2019s dependability. The approach described in this paper borrows concepts and principles from the field of \u2018Systems Health Management\u2019 for complex aerospace systems and implements a novel two level health management architecture that can be applied in the context of a model-based software development process.               At the first level, the Component-level Health Manager (CLHM) provides localized and limited service for managing the health of individual software components. A higher-level System-level Health Manager\u00a0\u2026", "num_citations": "8\n", "authors": ["572"]}
{"title": "Model-based tools and techniques for real-time system and software health management\n", "abstract": " 9.3. 4.1 Overview 302 9.3. 4.2 Extensions to the TFPG Model 302 9.3. 4.3 Extensions to the Reasoner 304 9.3. 4.4 Synchronous Event Processing 305 9.3. 4.5 Asynchronous Event Processing 306 9.3. 5 Distributed TFPG Examples 307 9.3. 5.1 Discussion 310 9.4 Application of TFPG for Diagnosing Software Failures 311 9.4. 1 ARINC Component Framework 312 9.4. 2 Health Management in ACM 314 9.4. 2.1 Component-Level Health Management 314 9.4. 2.2 System-Level Health Manager 314 9.4. 2.3 Component-Level Detection 314 9.4. 2.4 Component-Level Mitigation 316 9.4. 3 Software Fault Propagation Model 317 9.4. 3.1 Complexity of the Generated Model 322 9.4. 4 The Diagnosis Process 323 9.5 Application of TFPG for Prognostics of Impending Faults 326 9.5. 1 Failure Criticality 326", "num_citations": "8\n", "authors": ["572"]}
{"title": "Rapid property specification and checking for model-based formalisms\n", "abstract": " In model-based development, verification techniques can be used to check whether an abstract model satisfies a set of properties. Ideally, implementation code generated from these models can also be verified against similar properties. However, the distance between the property specification languages and the implementation makes verifying such generated code difficult. Optimizations and renamings can blur the correspondence between the two, further increasing the difficulty of specifying verification properties on the generated code. This paper describes methods for specifying verification properties on abstract models that are then checked on implementation level code. These properties are translated by an extended code generator into implementation code and special annotations that are used by a software model checker.", "num_citations": "8\n", "authors": ["572"]}
{"title": "Failure prognosis using timed failure propagation graphs\n", "abstract": " Timed failure propagation graph (TFPG) is a causal model that captures the causal and temporal aspects of failure propagation in a wide variety of engineering systems. In this paper we investigate the problem of failure prognosis within the TFPG model settings. The paper introduces a formal definition for system reliability based on measures of failure criticality, proximity between alarm observations, and plausibility of the estimated current system condition. An algorithm to compute the time to reach a given criticality level of the system, referred to as time to criticality, based on the current conditions of the system is introduced. The time to criticality, also known as the system\u2019s Remaining Useful Life (RUL), can be used as a measure for system reliability at any given time in the future.", "num_citations": "8\n", "authors": ["572"]}
{"title": "Model based software engineering, graph grammars and graph transformations\n", "abstract": " The evolution of programming languages shows a clear direction towards higher levels of abstraction. This evolution started from assembly languages, went on to procedural languages, then to object oriented languages and now the state of the art is component oriented languages and frameworks. In the same timeframe top down approaches classified as Model Based Software Engineering [6] attempted to bridge large semantic gaps between very-high-level semantic models and programming languages, and failed. This community found success in more rigorous domain-specific fields such as embedded systems where formal and graphical models were already in use. An example of such a success is Matlab\u2019s Simulink/Stateflow [36] modeling language. With the advent of Unified Modeling Language (UML) and Model Driven Architecture (MDA) that advocate the use of models in software development, the communities were brought together and are producing promising results.For textual languages and compiler design there is a vast literature in textual grammars, parsers, parser generators and other formal methods to specify and implement textual languages and compilers. Theory and formal methods equivalent to that of textual grammars can be of tremendous help to the modeling community. Graph grammars and transformations have been studied for over the 30 years and have produced many theoretical results. However, these results haven\u2019t been applied to the development of methodologies or tools that facilitate the development of modeling languages.", "num_citations": "8\n", "authors": ["572"]}
{"title": "Embedded control systems language for distributed processing (ECSL-DP)\n", "abstract": " Embedded Automotive systems are becoming increasingly complex, and as such difficult to design and develop. Model-based approaches are gaining foothold in this area, and increasingly the system design and development is being conducted with model-based tools, most notably Matlab\u00ae Simulink\u00ae and Stateflow\u00ae from Mathworks Inc., among others. However, these tools are addressing only a limited aspect of the system design. Moreover, there is a lack of integration between these tools, which makes overall system design and development cumbersome and error-prone. Motivated by these shortcomings we have developed an approach, based on Model-Integrated Computing, a technology matured over a decade of research at ISIS, Vanderbilt University. The center-piece of this approach is a graphical modeling language, Embedded Control Systems Language for Distributed Processing. A suite of translators and tools have been developed that facilitate the integration of ECSL-DP with industry standard Simulink and Stateflow tools, and open the possibility for integration of other tools, by providing convenient and extensible interfaces. A code generator has been developed that synthesizes implementation code, configuration and firmware gluecode from models. The approach has been prototyped and evaluated with a medium scale example. The results demonstrate the promise of the approach, and points to interesting directions for further research.", "num_citations": "8\n", "authors": ["572"]}
{"title": "Intelligent supervisory controller for gas distribution system\n", "abstract": " This paper describes the application of artificial intelligence techniques in the supervisory controller of a gas distribution network. The main idea was to use symbolic models of the distribution network in the knowledge-based system components. The symbolic models represented various quantitative and qualitative features of the process which made it possible to support the monitoring, diagnostic and intervention planning procedures with high-level tools. The spectrum of Al techniques used in the system architecture included associative databases, object-oriented programming and planning techniques. The system has been implemented in a distributed computing environment.", "num_citations": "8\n", "authors": ["572"]}
{"title": "Dynamic-weighted simplex strategy for learning enabled cyber physical systems\n", "abstract": " Cyber Physical Systems (CPS) have increasingly started using Learning Enabled Components (LECs) for performing perception-based control tasks. The simple design approach, and their capability to continuously learn has led to their widespread use in different autonomous applications. Despite their simplicity and impressive capabilities, these components are difficult to assure, which makes their use challenging. The problem of assuring CPS with untrusted controllers has been achieved using the Simplex Architecture. This architecture integrates the system to be assured with a safe controller and provides a decision logic to switch between the decisions of these controllers. However, the key challenges in using the Simplex Architecture are: (1) designing an effective decision logic, and (2) sudden transitions between controller decisions lead to inconsistent system performance. To address these research\u00a0\u2026", "num_citations": "7\n", "authors": ["572"]}
{"title": "Augmenting learning components for safety in resource constrained autonomous robots\n", "abstract": " Learning enabled components (LECs) trained using data-driven algorithms are increasingly being used in autonomous robots commonly found in factories, hospitals, and educational laboratories. However, these LECs do not provide any safety guarantees, and testing them is challenging. In this paper, we introduce a framework that performs weighted simplex strategy based supervised safety control, resource management and confidence estimation of autonomous robots. Specifically, we describe two weighted simplex strategies: (a) simple weighted simplex strategy (SW-Simplex) that computes a weighted controller output by comparing the decisions between a safety supervisor and an LEC, and (b) a context-sensitive weighted simplex strategy (CSW-Simplex) that computes a context-aware weighted controller output. We use reinforcement learning to learn the contextual weights. We also introduce a system\u00a0\u2026", "num_citations": "7\n", "authors": ["572"]}
{"title": "A hardware-in-the-loop real-time testbed for microgrid hierarchical control\n", "abstract": " To maintain a stable, flexible and economic operation of a microgrid, hierarchical control architecture consisting of primary, secondary and tertiary control is proposed. However, the differences in dynamics of microgrid, bandwidths of control levels and speed of communication channels make it difficult to comprehensively validate the performance of the hierarchical control schemes. In this paper we propose a hardware-in-the-loop real-time testbed for microgrid hierarchical control. The proposed testbed can be used to validate control performance under different microgrid operating modes (grid-tied or islanded), different primary control schemes (current or voltage mode) and different secondary control approaches (centralized or distributed). The integration of industry-grade hardware that runs primary and secondary control into the testbed allows for complete emulation of microgrid operation, and facilitates the\u00a0\u2026", "num_citations": "7\n", "authors": ["572"]}
{"title": "Triggering RowHammer hardware faults on ARM: A revisit\n", "abstract": " The rowhammer bug belongs to software-induced hardware faults, and has posed great security challenges to numerous systems. On x86, many approaches to triggering the rowhammer bug have been found; yet, due to several different reasons, the number of discovered approaches on ARM is limited. In this paper, we revisit the problem of how to trigger the rowhammer bug on ARM-based devices by carefully investigating whether it is possible to translate the original x86-oriented rowhammer approaches to ARM. We provide a thorough study of the unprivileged ARMv8-A cache maintenance instructions and give two previously overlooked reasons to support their use in rowhammer attacks. Moreover, we present a previously undiscovered instruction that can be exploited to trigger the rowhammer bug on many ARM-based devices. A potential approach to quickly evicting ARM CPU caches is also discussed, and\u00a0\u2026", "num_citations": "7\n", "authors": ["572"]}
{"title": "Demo abstract: RIAPS\u2014A resilient information architecture platform for edge computing\n", "abstract": " The emerging CPS/IoT ecosystem platforms such as Beaglebone Black, Raspberry Pi, Intel Edison and other edge devices such as SCALE, Paradrop are providing new capabilities for data collection, analysis and processing at the edge (also referred to as Fog Computing). This allows the dynamic composition of computing and communication networks that can be used to monitor and control the physical phenomena closer to the physical system. However, there are still a number of challenges that exist and must be resolved before we see wider applicability of these platforms for applications in safety-critical application domains such as Smart Grid and Traffic Control.", "num_citations": "7\n", "authors": ["572"]}
{"title": "SURE: An experimentation and evaluation testbed for CPS security and resilience: Demo abstract\n", "abstract": " In-depth consideration and evaluation of security and resilience is necessary for developing the scientific foundations and technology of Cyber-Physical Systems (CPS). In this demonstration, we present SURE [1], a CPS experimentation and evaluation testbed for security and resilience focusing on transportation networks. The testbed includes (1) a heterogeneous modeling and simulation integration platform,(2) a Web-based tool for modeling CPS in adversarial environments, and (3) a framework for evaluating resilience using attacker-defender games. Users such as CPS designers and operators can interact with the testbed to evaluate monitoring and control schemes that include sensor placement and traffic signal configuration.", "num_citations": "7\n", "authors": ["572"]}
{"title": "Integrated analysis of temporal behavior of component-based distributed real-time embedded systems\n", "abstract": " Integrated analysis of temporal behavior for distributed real-time embedded (DRE) systems is an important design-time step needed to verify safe and predictable system operation at run-time. In earlier work, we have shown a Colored Petri Net-based (CPN) approach to modeling and analyzing component-based DRE systems. In this paper, we present new CPN-based modeling approaches and advanced state space methods that improve on the scalability and efficiency of the analysis. The generality of the modeling principles used show the applicability of this approach to a wide range of systems.", "num_citations": "7\n", "authors": ["572"]}
{"title": "Architecting health management into software component assemblies: Lessons learned from the arinc-653 component mode\n", "abstract": " Complex real-time software systems require an active fault management capability. While testing, verification and validation schemes and their constant evolution help improve the dependability of these systems, an active fault management strategy is essential to potentially mitigate the unacceptable behaviors at run-time. In our work we have applied the experience gained from the field of Systems Health Management towards component-based software systems. The software components interact via well-defined concurrency patterns and are executed on a real-time component framework built upon ARINC-653 platform services. In this paper, we present the lessons learned in architecting and applying a two-level health management strategy to assemblies of software components.", "num_citations": "7\n", "authors": ["572"]}
{"title": "SOAMANET: A tool for evaluating service-oriented architectures on mobile ad-hoc networks\n", "abstract": " Service-Oriented Architectures (SOAs) are increasingly being used for designing and building large-scale networked and distributed systems. Catering to the complex and dynamically varying needs of business applications/clients, these systems must usually be realized by dynamically composing a variety of network-available services. Evaluation of large-scale SOAs, particularly on dynamic network platforms, such as Mobile Ad-hoc Networks (MANETs), is a non-trivial problem that requires not only a correct modeling of SOAs and the network platform, but also their relationships. This paper describes a new tool - SOAMANET - to design and rapidly synthesize simulations for the experimental evaluation of SOAs on MANET platforms. With its modeling techniques and analysis capabilities, SOAMANET allows simulation-based and system execution-based analysis of dynamic SOA and/or MANET designs and\u00a0\u2026", "num_citations": "7\n", "authors": ["572"]}
{"title": "Discrete-time IDA-passivity based control of coupled tank processes subject to actuator saturation\n", "abstract": " Interconnection damping assignment passivity based control (IDA-PBC) is an emerging control design method which allows an engineer to systematically design an advanced controller for complex non-linear systems. As a result specific gain ranges can be determined which can prevent an operator (adversary) from accidentally (maliciously) setting control gains which could potentially destabilize the system. However in order to generate the controller the engineer will have to resort to using symbolic numerical solvers in order to complete the design. This can be both a cumbersome and error-prone task which can be automated. We present initial results of a tool which simplifies IDA-PBC. In addition many fluid control problems posses tight operating regions in which pumps degrade over time. As a result actuator saturation may occur for given set-point profiles which will lead to integrator wind-up and more\u00a0\u2026", "num_citations": "7\n", "authors": ["572"]}
{"title": "An active pattern infrastructure for domain-specific languages\n", "abstract": " Tool support for design patterns is a critically important area of computeraided software engineering. With the proliferation of Domain-Specific Modeling Languages (DSMLs), the adaptation of the notion of design patterns appears to be a promising direction of research. This paper introduces a new approach to DSML patterns, namely, the Active Model Pattern infrastructure. In this framework, not only the traditional insertion of predefined partial models is supported, but interactive, localized design-time manipulation of models. Optionally, the infrastructure can be adapted to handling transactional tracing information as well as transactional undo and redo operations. Possible realizations of the framework are also discussed and compared.", "num_citations": "7\n", "authors": ["572"]}
{"title": "Evaluating the Correctness and Effectiveness of a Middleware QoS Configuration Process in Distributed Real-time and Embedded Systems\n", "abstract": " Recent advances in software processes and artifacts for automating middleware configurations in distributed realtime and embedded (DRE) systems are starting to address the complexities faced by system developers in dealing with the flexibility and configurability provided by contemporary middleware. Despite the benefits of these new processes, there remain significant challenges in verifying their correctness, and validating their effectiveness in meeting the end-to-end quality of service (QoS) requirements of DRE systems. This paper addresses this problem by describing how model-checking and structural correspondence can be used to verify the correctness of a middleware QoS configuration process that uses model-based graph transformations at its core. Next, it provides empirical proof to validate the effectiveness of our technique to meet the end-to-end QoS requirements in the context of a representative\u00a0\u2026", "num_citations": "7\n", "authors": ["572"]}
{"title": "Towards a model-based autonomic reliability framework for computing clusters\n", "abstract": " One of the primary problems with computing clusters is to ensure that they maintain a reliable working state most of the time to justify economics of operation. In this paper, we introduce a model-based hierarchical reliability framework that enables periodic monitoring of vital health parameters across the cluster and provides for autonomic fault mitigation. We also discuss some of the challenges faced by autonomic reliability frameworks in cluster environments such as non-determinism in task scheduling in standard operating systems such as Linux and need for synchronized execution of monitoring sensors across the cluster. Additionally, we present a solution to these problems in the context of our framework, which utilizes a feedback controller based approach to compensate for the scheduling jitter in non real-time operating systems. Finally, we present experimental data that illustrates the effectiveness of our\u00a0\u2026", "num_citations": "7\n", "authors": ["572"]}
{"title": "Automotive software: A challenge and opportunity for model-based software development\n", "abstract": " Embedded software development for automotive applications is widely considered as a significant source of innovation and improvements in cars. However, software development processes do not address well the needs of large-scale distributed real-time systems, like the ones automobiles do (or soon will) contain. The paper introduces a vision for the model-based development of embedded software, which is based on the broad-spectrum modeling of the applications in the context of a larger system, formal (and computer-supported) analysis of models, and automatic synthesis of the application(s). The paper also describes some initial steps taken to build the infrastructure for supporting such a process in the form of modeling and model transformation tools. The paper concludes with a list of challenging research problems.", "num_citations": "7\n", "authors": ["572"]}
{"title": "Software for automotive systems: Model-integrated computing\n", "abstract": " Embedded Automotive systems are becoming increasingly complex, and as such difficult to design and develop. Model-based approaches are gaining foothold in this area, and increasingly the system design and development is being conducted with model-based tools, most notably Matlab\u00ae Simulink\u00ae and Stateflow\u00ae from Mathworks Inc., among others. However, these tools are addressing only a limited aspect of the system design. Moreover, there is a lack of integration between these tools, which makes overall system design and development cumbersome and error-prone. Motivated by these shortcomings we have developed an approach, based on Model-Integrated Computing, a technology matured over a decade of research at ISIS, Vanderbilt University. The center-piece of this approach is a graphical modeling language, Embedded Control Systems Language for Distributed Processing (ECSL-DP\u00a0\u2026", "num_citations": "7\n", "authors": ["572"]}
{"title": "Intelligent monitoring and diagnostics for plant automation\n", "abstract": " A approach is proposed for the design and implementation of an intelligent monitoring and diagnostic system for a cogenerator plant. The approach is based on multiple-aspect modeling and model interpretation: sensory input signals from the plant are processed and interpreted in the context of various models of the cogenerator system. Experiences obtained during the development and the field test of the system have proved that the approach is viable even in real-time applications and results in considerable improvement in software technology.< >", "num_citations": "7\n", "authors": ["572"]}
{"title": "The multigraph approach to parallel, distributed, structurally adaptive signal processing\n", "abstract": " Structurally adaptive and dynamically reconfigurable systems are presented as important ingredients in the design and development of robust large-scale signal-processing systems for operation in complex nonstationary environments. The multigraph programming and execution environment (MPEE) is a complete, parallel, fully integrated programming and execution environment for structurally adaptive signal-processing systems. It provides a user-friendly environment for designing, programming, and executing such a signal-processing system. The MPEE is shown to have many advantages, due to graph-based processing, dynamic scheduling, multiprocessor programming capabilities, a hierarchical approach to system design, and graphic editors.< >", "num_citations": "7\n", "authors": ["572"]}
{"title": "Knowledge-based approach to real-time supervisory control\n", "abstract": " Increasing complexity of industrial plants necessitates the usage of advanced programming techniques in process control. Artificial Intelligence programming offers new opportunities in constructing complex software systems. This paper describes an approach which has been used to build Intelligent Process Control System (IPCS). IPCS expand the conventional process control systems with an additional, \"knowledge-based layer\", where declarative programming methods are used extensively. The knowledge-based components represent a model of the process from multiple viewpoints and the simulator, monitor, control, diagnostics and operator interface subsystems are coupled to a symbolic process database. A special architecture, the Multigraph Architecture has been used as a general framework for integrating symbolic and numeric programming techniques in a distributed environment. The knowledge\u00a0\u2026", "num_citations": "7\n", "authors": ["572"]}
{"title": "Resilient information architecture platform for smart systems (RIAPS): Case study for distributed apparent power control\n", "abstract": " Maintaining voltage and frequency stability in an islanded microgrid is challenging, due to the low system inertia. In addition, islanded microgrids have limited generation capability, requiring that all DGs contribute proportionally to meet the system power consumption. This paper proposes a distributed control algorithm for optimal apparent power utilization in islanded microgrids. The developed algorithm improves system apparent power utilization by maintaining proportional power sharing among DGs. A decentralized platform called Resilient Information Architecture Platform for Smart Systems (RIAPS) is introduced that runs on processors embedded within the DGs. The proposed algorithm is fully implemented in RIAPS platform and validated on a real-time microgrid testbed.", "num_citations": "6\n", "authors": ["572"]}
{"title": "Design Considerations for a Variable Autonomy Exeuctive for UAS in the NAS\n", "abstract": " The Autonomy Operating System (AOS) is an open flight software platform for smart UAVs. AOS has as its foundations NASA\u2019s core flight executive and core flight software (cFE/cFS). Core flight software is an open source middleware package that originates in NASA\u2019s small spacecraft flight software community, providing the capability for interoperation of reusable apps [1]. In that regard, it is similar to Apple\u2019s IOS for smartphones. Typical reusable apps for small spacecraft flight software include command and data handling, thermal management, attitude pointing, and electrical power management. The AOS project has determined that cFE/cFS can be ported to the UAS domain and serve as a robust and certifiable platform for UAS flight software.A small business, Windhover Labs, is developing a UAS flight software product line based on cFE/cFS suitable for visual and beyond visual line of sight applications such as\u00a0\u2026", "num_citations": "6\n", "authors": ["572"]}
{"title": "Model-Based Assurance for Satellites with Commercial Parts in Radiation Environments\n", "abstract": " Small satellite projects often do not have the budget or schedule to incorporate radiation-hardened parts or extensive radiation test campaigns into their schedule. Yet a case must be made that the spacecraft will function as intended in orbit, with radiation, temperature and vacuum affecting part performance. The Vanderbilt Institute for Space and Defense Electronics, with support from NASA HQ, NASA NEPP, and NASA JPL, has developed a platform for making a safety case for systems with commercial (non-hardened) parts, called the Systems Engineering Assurance and Modeling (SEAM) platform. The platform has three elements: goal structuring notation (GSN), systems engineering models (SysML and our extensions), and Bayesian networks (BN). The GSN is a visual argument structure that presents an argument that the system meets specifications based on goals, strategies, and evidence. The systems engineering model is a high-level descriptive language that captures the spacecraft design and system architecture through various diagrams. We extend the SysML diagram set to include fault propagation diagrams, which map the environment, failure manifestations, anomalies, failure effects and responses (mitigation measures) of components and systems. The SEAM platform provides a low-cost alternative to conventional radiation hardening assurance paradigms.", "num_citations": "6\n", "authors": ["572"]}
{"title": "Heuristics-based approach for identifying critical N\u2014k contingencies in power systems\n", "abstract": " Reliable operation of electrical power systems in the presence of multiple critical N - k contingencies is an important challenge for the system operators. Identifying all the possible N - k critical contingencies to design effective mitigation strategies is computationally infeasible due to the combinatorial explosion of the search space. This paper describes two heuristic algorithms based on the iterative pruning of the candidate contingency set to effectively and efficiently identify all the critical N - k contingencies resulting in system failure. These algorithms are applied to the standard IEEE-14 bus system, IEEE-39 bus system, and IEEE-57 bus system to identify multiple critical N - k contingencies. The algorithms are able to capture all the possible critical N - k contingencies (where 1 \u2264 k \u2264 9) without missing any dangerous contingency.", "num_citations": "6\n", "authors": ["572"]}
{"title": "Radiation response and adaptive control-based degradation mitigation of MEMS accelerometers in ionizing dose environments\n", "abstract": " This paper investigates the effects of gamma radiation on the operation of commercially available capacitive microelectromechanical accelerometers intended for use in robotic systems deployed for nuclear disaster remediation. Radiation-induced accelerometer degradation is examined in terms of its effects on the input-output relationship of ADXL325 accelerometers (Analog Devices, Inc., Norwood, Massachusetts, USA) prior to sensor failure. Results show a moderate increase in sensor nonlinearity as well as significant, non-monotonic changes to accelerometer axis sensitivity and zero-g bias. Both part-to-part variation and axis-to-axis variation within individual accelerometers are observed. The effects of the observed accelerometer degradation on the performance of a simple robotic manipulator that relies on acceleration feedback are evaluated in simulation. Additionally, using tools derived from adaptive\u00a0\u2026", "num_citations": "6\n", "authors": ["572"]}
{"title": "A domain-specific language for model composition and verification of multidisciplinary models\n", "abstract": " Complex, engineered products and manufacturing processes often necessitate integrated analysis that cuts across physical domains and engineering disciplines. When the domain-specific models that contribute to the overall analysis process are available then the problem can be addressed by composing them into an analysis workflow which then can be executed using some execution platform. Such a composition and integrated analysis is essentially a systems engineering approach applied to an engineering process. In this paper we describe a model integration language that allows the rapid composition of models, the verification of the composition and the generation of executable code and other engineering artifacts that are needed for model execution on a software platform. The language is based on OpenMDAO, a widely-used model execution framework, and it improves the engineering process by checking composition constraints that must be satisfied by the integrated model and by automatically generating executable code that facilitates the run-time integration of the models. This paper describes the design of the language, illustrates its use through a running example and outlines future work.\u00a9 2016 Amogh Kulkarni, Daniel Balasubramanian, Gabor Karsai, Anantha Narayanan", "num_citations": "6\n", "authors": ["572"]}
{"title": "Bayesian inference modeling of total ionizing dose effects on system performance\n", "abstract": " A probabilistic Bayesian modeling method for determining the effects of radiation-induced component-level parameter shifts on system-level performance is described. The modeling method incorporates information about the system design and component-level degradation into a Bayesian network and performs inference on the constructed network using Markov chain Monte Carlo approaches, producing distributions for the range of component responses. Deterministic simulations use the results of the Bayesian inference to determine the combined impact of multiple degraded components on system performance quantities. The goal of the modeling approach is to turn uncertain information into actionable knowledge. The utility of this approach is demonstrated using a case study based on total ionizing dose degradation of line-sensor components in a simple line-tracking robot system.", "num_citations": "6\n", "authors": ["572"]}
{"title": "Next-generation command and control wind tunnel for courses of action simulation\n", "abstract": " The quantitative analysis and evaluation of COAs is a daunting problem. Given the complexity of the operational environment in which the Air Force conducts operations, commanders need the capability to consider multiple alternative courses of actions and assess their expected effects in light of the resources needed for their execution. An additional complication is the challenge of integrated C2 in which the selected COA must work synergistically with the COAs produced by other component commanders. Cyber security considerations will also affect the choice of COA.The results of the work summarized in this report address the challenge of developing an integrated, easily composable modeling and simulation environment to create realistic cyber warfare operational scenarios for course of action (COA) exploration. The approach is based on a new generation C2 Wind Tunnel by enhancing the already existing C2 Wind Tunnel (developed under AFOSR funding) through the addition of several software tools and a modeling language for operational sequences.", "num_citations": "6\n", "authors": ["572"]}
{"title": "Towards a product line of heterogeneous distributed applications\n", "abstract": " Next generation large-scale distributed systems\u2013such as smart cities\u2013are dynamic, heterogeneous and multi-domain in nature. The same is true for applications hosted on these systems. Application heterogeneity stems from their Unit of Composition (UoC); some applications might be coarse-grained and composed from processes or actors, whereas others might be fine-grained and composed from software components. Software components can further amplify heterogeneity since there exists different component models for different domains. Lifecycle management of such distributed, heterogeneous applications is a considerable challenge.In this paper, we solve this problem by reasoning about these systems as a Software Product Line (SPL) where individual dimensions of heterogeneity can be considered as product variants. To enable such reasoning, first, we present UMRELA (Universal feature-Model for distRibutEd appLicAtions), a conceptual feature model that identifies commonalities and variability points for capturing and representing distributed applications and their target system. This results in a product line of a family of distributed applications. UMRELA facilitates representation of initial configuration point, and the configuration space of the system. The latter represents all possible states the system can reach and is used as an implicit encoding to calculate new configuration points at runtime. Second, we present a prototype Application Management Framework (AMF) as a proof of concept configuration management tool that uses UMRELA to manage heterogeneous distributed applications.", "num_citations": "6\n", "authors": ["572"]}
{"title": "Unification or Integration? The Challenge of Semantics in Heterogeneous Modeling Languages.\n", "abstract": " Model-driven software development and systems engineering rely on modeling languages that provide e cient, domain-specific abstractions for design, analysis, and implementation. Models are essential for communicating ideas across the engineering team, but also key to the analysis of the system. No single model or modeling language can cover all aspects of a system, and even for particular aspects multiple modeling languages are used in the same system. Thus engineers face the dilemma of either defining a unifying semantics for all models, or finding a solution to the model integration problem. The talk will elaborate these problems, and show two, potential solutions: one using a model integration language (for the engineering design domain) and another one using explicit and executable semantics (for the domain of distributed reactive controllers).", "num_citations": "6\n", "authors": ["572"]}
{"title": "Automated synthesis of time-triggered architecture-based TrueTime models for platform effects simulation and analysis\n", "abstract": " The TrueTime toolbox simulates real-time control systems, including platform-specific details like process scheduling, task execution and network communications. Analysis using these models provides insight into platform-induced timing effects, such as jitter and delay. For safety-critical applications, the Time-Triggered Architecture (TTA) has been shown to provide the necessary services to create robust, fault-tolerant control systems. Communication induced timing effects still need to be simulated and analyzed even for TTA-compliant models. The process of adapting time-invariant control system models, through the inclusion of platform specifics, into TTA-based TrueTime models requires significant manual effort and detailed knowledge of the desired platform's execution semantics. In this paper, we present an extension of the Embedded Systems Modeling Language (ESMoL) tool chain that automatically\u00a0\u2026", "num_citations": "6\n", "authors": ["572"]}
{"title": "Reusing model transformations while preserving properties\n", "abstract": " Model transformations are indispensable to model-based development (MBD) where they act as translators between domain-specific languages (DSLs). As a result, transformations must be verified to ensure they behave as desired. Simultaneously, transformations may be reused as requirements evolve. In this paper we present novel algorithms to determine if a reused transformation preserves the same properties as the original, without expensive re-verification. We define a type of behavioral equivalence, called lifting equivalence, relating an original transformation to its reused version. A reused transformation that is equivalent to the original will preserve all compatible universally quantified properties. We describe efficient algorithms for verifying lifting equivalence, which we have implemented in our FORMULA [1, 2] framework.", "num_citations": "6\n", "authors": ["572"]}
{"title": "Templatized model transformations: enabling reuse in model transformations\n", "abstract": " Model transformations are a key element of model-based software development processes. Despite their importance, contemporary model transformation tools have limited or no support for reuse, particularly, when model transformations are applied in the context of development of a family of application variants, such as product lines. This forces developers to reinvent the transformation rules thereby adversely impacting their productivity and increasing maintenance costs. This paper presents MTS (Model transformation Templatization and Specialization), which overcomes these limitations by enabling developers to write reusable, templatized model transformations. MTS defines two higher order transformations to capture the variability and specialize the transformations across variants of an application family. MTS can be realized within existing model transformation tools without requiring any modifications to them. The results from applying our approach to two representative case studies indicate reduction in development effort of upto 90% when compared with the nontemplatized approach.", "num_citations": "6\n", "authors": ["572"]}
{"title": "Applying a grouping operator in model transformations\n", "abstract": " The usability of model transformation languages depends on the level of abstractions one can work with in rules to perform complex operations on models. Recently, we have introduced a novel operator for our model transformation language GReAT that allows the concise specification of complex model (graph) rewriting operations that manipulate entire subgraphs. In this paper we show how the new operator can be used to implement non-trivial model manipulations with fewer and simpler rules, while maintaining efficiency. The examples were motivated by problems encountered in real-life model transformations.", "num_citations": "6\n", "authors": ["572"]}
{"title": "Improving the usability of a graph transformation language\n", "abstract": " Model transformation tools implemented using graph transformation techniques are often expected to provide high performance. For this reason, in the Graph Rewriting and Transformation (GReAT) language we have supported two techniques: pre-binding of selected pattern variables and explicit sequencing of transformation steps to improve the performance of the transformation engine. When applied to practical situations, we recognized three shortcomings in our approach: (1) no support for the convenient reuse of results of one rewriting step in another, distant step, (2) lack of a sorting capability for ordering the results of the pattern matching, and (3) absence of support for the distinguished merging of results of multiple pattern matches. In this paper we briefly highlight the relevant features of GReAT, describe three motivating examples that illustrate the problems, introduce our solutions: new extensions to the\u00a0\u2026", "num_citations": "6\n", "authors": ["572"]}
{"title": "Finite-state temporal automata modeling for fault diagnosis\n", "abstract": " The paper discusses a modeling paradigm defined for the model-based diagnosis of large-scale, heterogeneous systems. The complexity of the models is managed by the introduction of hierarchical representation and the separation of the functional and physical structure. Uncertainty in the behavior of the system under fault conditions is expressed by approximating the operation with a finite-state temporal automaton model (FSTM). In this formalism, the dynamic system is represented as a discrete, hierarchical automaton, in which the states correspond to regions of the discretized input, output, parameter and skate spaces, and transitions to the propagation of disturbances in the dynamic system.", "num_citations": "6\n", "authors": ["572"]}
{"title": "Intelligent test integration system\n", "abstract": " A new test technology is described which was developed for space system integration. The ultimate purpose of the system is to support the automatic generation of test systems in real time, distributed computing environments. The Intelligent Test Integration System (ITIS) is a knowledge based layer above the traditional test system components which can generate complex test configurations from the specification of test scenarios.", "num_citations": "6\n", "authors": ["572"]}
{"title": "Towards an architecture for evaluating and analyzing decentralized Fog applications\n", "abstract": " As the number of low cost computing devices at the edge of network increases, there are greater opportunities to enable novel, innovative capabilities, especially in decentralized cyber-physical systems. For example, in an urban setting, a set of networked, collaborating processors at the edge can be used to dynamically detect traffic densities via image processing and then use those densities to control the traffic flow by coordinating traffic light sequences, in a decentralized architecture. In this paper we describe a testbed and an application framework for such applications.", "num_citations": "5\n", "authors": ["572"]}
{"title": "Goal Structuring Notation in a Radiation Hardening Assurance Case for COTS-Based Spacecraft\n", "abstract": " A systematic approach is presented to constructing a radiation assurance case using Goal Structuring Notation (GSN) for spacecraft containing commercial-off-the-shelf (COTS) parts. The GSN paradigm is applied to an SRAM single-event upset experiment board designed to fly on a CubeSat November 2016. Construction of a radiation assurance case without use of hardened parts or extensive radiation testing is discussed.", "num_citations": "5\n", "authors": ["572"]}
{"title": "Towards an analysis-driven rapid design process for cyber-physical systems\n", "abstract": " System design typically involves the specification of requirements and evaluation of the design with respect to those requirements. The requirements describe and quantify the desired physical and software properties of the system. Evaluating requirements often involves performing domain-specific analysis. Domain-specific analyses are spread across a wide range of domains and tools, e.g., geometric properties vs. dynamics behavior of the system. Different analysis types require different tools, where each tool targets a narrow range of domains or a single domain. For large system designs, the requirements could be too complex to be evaluated by a single analysis tool. In such cases, the coupling of multiple domains and analysis tools is inevitable, and managing these interactions can prove to be difficult, often leading to wasted efforts. In this paper we present an analysis-driven rapid design process for Cyber\u00a0\u2026", "num_citations": "5\n", "authors": ["572"]}
{"title": "System health awareness in total-ionizing dose environments\n", "abstract": " Understanding the relationship between the impact of radiation at the component and system levels is challenging. This paper discusses a hierarchical approach, based on Bayesian theory, to establish a mechanism for determining system health based on the status of, and interactions between, the radiation response of component parts. When the Bayesian network is trained with a combination of experimental data, data from similar parts, simulations, and expert estimates, a quantitative estimate of the Total-Ionizing Dose (TID) response of a system can be obtained. Bayesian networks enable inference about system-level functional performance, the dose exposure, and the sensitivity of different components to TID, thus providing a framework for TID awareness in design and operation of systems. A case study of a robotic system consisting of commercial components is presented.", "num_citations": "5\n", "authors": ["572"]}
{"title": "Modeling network medium access protocols for network quality of service analysis\n", "abstract": " Design-time analysis and verification of distributed real-time embedded systems necessitates the modeling of the time-varying performance of the network and comparing that to application requirements. Earlier work has shown how to build a system network model that abstracted away the network's physical medium and protocols which govern its access and multiplexing. In this work we show how to apply a network medium channel access protocol, such as Time-Division Multiple Access (TDMA), to our network analysis methods and use the results to show that the abstracted model without the explicit model of the protocol is valid.", "num_citations": "5\n", "authors": ["572"]}
{"title": "Taming Multi-Paradigm Integration in a Software Architecture Description Language.\n", "abstract": " Software architecture description languages offer a convenient way of describing the high-level structure of a software system. Such descriptions facilitate rapid prototyping, code generation and automated analysis. One of the big challenges facing the software community is the design of architecture description languages that are general enough to describe a wide-range of systems, yet detailed enough to capture domain-specific properties and provide a high level of tool automation. This paper presents the multi-paradigm challenges we faced and solutions we built when creating a domain-specific modeling language for software architectures of distributed real-time systems.", "num_citations": "5\n", "authors": ["572"]}
{"title": "Embedded systems security co-design\n", "abstract": " There is an ever increasing concern about security threats as embedded systems are moving towards networked applications. Model based approaches have proven to be effective techniques for embedded systems design. However, existing modeling tools were not designed to meet the current and future security challenges of networked embedded systems. In this paper, we propose a framework to incorporate security modeling into embedded system design. We\u2019ve developed a security analysis tool that can easily integrate with existing tool chains to create co-design environments that addresses security, functionality and system architecture aspects of embedded systems concurrently.", "num_citations": "5\n", "authors": ["572"]}
{"title": "Synthesis of robust task schedules for minimum disruption repair\n", "abstract": " An off-line scheduling algorithm considers resource, precedence, and synchronization requirements of a task graph, and generates a schedule guaranteeing its timing requirements. This schedule must, however, be executed in a dynamic and unpredictable operating environment where resources may fail and tasks may execute longer than expected. To accommodate such execution uncertainties, this paper addresses the synthesis of robust task schedules using a slack-based approach and proposes a solution using integer linear programming (ILP). An ILP model, whose solution maximizes the temporal flexibility of the overall task schedule, is formulated. Two different ILP solvers are used to solve this model and their performance compared. For large task graphs, an efficient approximate method is presented and its performance evaluated.", "num_citations": "5\n", "authors": ["572"]}
{"title": "Model-integrated computing and integration of globally distributed manufacturing enterprises: Issues and challenges\n", "abstract": " The advances in Information System (IS) technology in recent years have allowed manufacturing enterprises to use and apply increasingly, sophisticated computer based systems to run their business and to achieve a competitive advantage. However, these systems mostly exist in isolation with minimal (and expensive) integration. Of late, primarily due to emergent competitive global enterprises and markets, the need to be able to integrate the global enterprise has become more urgent. There are many dimensions to the integration problem that relate to IS: integration across geographically distributed enterprises and offices of an enterprise, integration with suppliers and customers, integration of various domains of activities, integration of different tools, collaborative design, etc. In this paper we will identify the different layers and dimensions of the integration problem, the issues and the challenges involved. We will\u00a0\u2026", "num_citations": "5\n", "authors": ["572"]}
{"title": "Integrated modeling for planning, simulation and diagnosis\n", "abstract": " An intelligent planning system was developed to automatically generate plans for maintenance and repair activity aboard manned spacecraft integrating crew activities, a robot possessing integrated sensors, and a graphical robotic simulator. The authors have established a robust approach to modeling plan constraints that allows one to create plans for a variety of agents from a single plan source. A model-based monitoring and diagnostic system was developed and integrated into the planning system to simulate and detect anomalous situations in the domain workspace. An existing robotic simulation program was enhanced to verify safe operation of a robot, planning path movement for task execution while avoiding collision with other workspace objects. Hierarchical models of human users and constraints allowed system explanations to be given in varying levels of detail, depending on the needs of the user.< >", "num_citations": "5\n", "authors": ["572"]}
{"title": "A Novel Approach Toward Relationships Between Process Variables and Weld Geometry\n", "abstract": " Neural networks and their applications for modeling the geometric parameters of gas tungsten arc weld (GTAW) pool dimensions are presented. Some basic concepts relating to neural nets and the various approaches used for weld modeling are reviewed. Neural networks are trained to predict the dimensions of GTA welds and their modeling performances are evaluated. It is concluded that neural networks do not replace traditional modeling methods, but they provide attractive, and fairly accurate, alternatives. Graphs. 16 ref.--AA", "num_citations": "5\n", "authors": ["572"]}
{"title": "Programming model for distributed intelligent systems\n", "abstract": " A programming model and architecture which was developed for the design and implementation of complex, heterogeneous measurement and control systems is described. The Multigraph Architecture integrates artificial intelligence techniques with conventional software technologies, offers a unified framework for distributed and shared memory based parallel computational models and supports multiple programming paradigms. The system can be implemented on different hardware architectures and can be adapted to strongly different applications.", "num_citations": "5\n", "authors": ["572"]}
{"title": "Designing a decentralized fault-tolerant software framework for smart grids and its applications\n", "abstract": " The vision of the \u2018Smart Grid\u2019 anticipates a distributed real-time embedded system that implements various monitoring and control functions. As the reliability of the power grid is critical to modern society, the software supporting the grid must support fault tolerance and resilience of the resulting cyber-physical system. This paper describes the fault-tolerance features of a software framework called Resilient Information Architecture Platform for Smart Grid (RIAPS). The framework supports various mechanisms for fault detection and mitigation and works in concert with the applications that implement the grid-specific functions. The paper discusses the design philosophy for and the implementation of the fault tolerance features and presents an application example to show how it can be used to build highly resilient systems.", "num_citations": "4\n", "authors": ["572"]}
{"title": "Automatic Fault Tree Generation from Radiation-Induced Fault Models\n", "abstract": " The space environment raises several unique reliability issues for non-optical-based electronic systems for surviving radiation from cosmic rays, our Sun, or the trapped radiation belts. These radiation categories are total ionizing dose (TID), a cumulative degradation mechanism that may eventually lead to component failure, and single-event effects (SEE), random events in time that are either recoverable or permanent failures. Fault effects and degradation caused by these mechanisms can propagate through the system and cause system failure, even mission failure when not accounted for and mitigated.", "num_citations": "4\n", "authors": ["572"]}
{"title": "CPS Design with Learning-Enabled Components: A Case Study\n", "abstract": " Cyber-Physical Systems (CPS) are used in many applications where they must perform complex tasks with a high degree of autonomy in uncertain environments. Traditional design flows based on domain knowledge and analytical models are often impractical for tasks such as perception, planning in uncertain environments, control with ill-defined objectives, etc. Machine learning based techniques have demonstrated good performance for such difficult tasks, leading to the introduction of Learning-Enabled Components (LEC) in CPS. Model based design techniques have been successful in the development of traditional CPS, and toolchains which apply these techniques to CPS with LECs are being actively developed. As LECs are critically dependent on training and data, one of the key challenges is to build design automation for them. In this paper, we examine the development of an autonomous Unmanned\u00a0\u2026", "num_citations": "4\n", "authors": ["572"]}
{"title": "Model-based System Health Management and Contingency Planning for Autonomous UAS\n", "abstract": " S autonomous operations of an Unmanned Aerial System (UAS) requires that the UAS is, during flight, aware of its health status and environment, and can react accordingly. On a manned aircraft, the pilot is in charge of detecting and identifying faults as well as trying to find their root causes. Only with a detailed knowledge about the current state of the aircraft, the pilot can plan any contingency activity that can mitigate the failures or provide means to safely end the flight by, for example, landing at a nearby airport. Fault identification and planning for a contingency requires that the pilot has substantial knowledge and experience, and that he is able to plan ahead and to mentally play through several alternatives to address the current situation.An autonomous UAS must essentially perform the same actions in real time, without the help of a ground station or a human in the loop. Modern UASs have numerous sensors\u00a0\u2026", "num_citations": "4\n", "authors": ["572"]}
{"title": "An analytical framework for smart manufacturing\n", "abstract": " Smart manufacturing is an emerging paradigm for the next generation of manufacturing systems. One key to the success of smart manufacturing is the ability to use the production data for defining predictive and descriptive models and their analyses. However, the development and refinement of such models is a labor- and knowledgeintensive activity that involves acquiring data, selecting and refining an analytical method and validating results. This paper presents an analytical framework that facilitates these activities by allowing ad-hoc analyses to be rapidly specified and performed. The proposed framework uses a domain-specific language to allow manufacturing experts to specify analysis models in familiar terms and includes code generators that automatically generate the lower-level artifacts needed for performing the analysis. We also describe the use of our framework with an example problem.", "num_citations": "4\n", "authors": ["572"]}
{"title": "A modeling framework to integrate exogenous tools for identifying critical components in power systems\n", "abstract": " Cascading failures in electrical power systems are one of the major causes of concern for the modem society as it results in huge socio-economic loss. Tools for analyzing these failures while considering different aspects of the system are typically very expensive. Thus, researchers tend to use multiple tools to perform various types of analysis on the same system model in order to understand the reasons for these failures in detail. Modeling a simple system in multiple platforms is a tedious, error prone and time consuming process. This paper describes a domain specific modeling language (DSML) for power systems. It identifies and captures the right abstractions for modeling components in different analysis tools. A framework is proposed that deals with system modeling using the developed DSML, identifying the type of analysis to be performed, choosing the appropriate tool(s) needed for the analysis from the tool\u00a0\u2026", "num_citations": "4\n", "authors": ["572"]}
{"title": "WiP abstract: Transactive energy demo with RIAPS platform\n", "abstract": " This work presents a platform for decentralized distributed computing called Resilient Information Architecture for the Smart Grid (RIAPS) through a transactional energy and a traffic application.", "num_citations": "4\n", "authors": ["572"]}
{"title": "Autonomy Operatng System for UAVs: Pilot-in-a-Box\n", "abstract": " The Autonomy Operating System (AOS) is an open flight software platform with Artificial Intelligence for smart UAVs. It is built to be extendable with new apps, similar to smartphones, to enable an expanding set of missions and capabilities. AOS has as its foundations NASA\u2019s core flight executive and core flight software (cFE/cFS). Pilot-in-a-Box (PIB) is an expanding collection of interacting AOS apps that provide the knowledge and intelligence onboard a UAV to safely and autonomously fly in the National Air Space, eventually without a remote human ground crew. Longer-term, the goal of PIB is to provide the capability for pilotless air vehicles such as air taxis that will be key for new transportation concepts such as mobility-on-demand. PIB provides the procedural knowledge, situational awareness, and anticipatory planning (\u2018thinking ahead of the plane\u2019) that comprises pilot competencies. These competencies\u00a0\u2026", "num_citations": "4\n", "authors": ["572"]}
{"title": "Total-ionizing-dose induced timing window violations in CMOS microcontrollers\n", "abstract": " The total-ionizing-dose robustness of low power microcontrollers is investigated. Experiments reveal that with increasing total ionizing dose (TID), the \u201cTiming Window Violations,\u201di.e., inability of the instruction set to execute within the clock-cycle(s) lead to failures in microcontroller operations. Clock frequency and supply voltage of the microcontroller are varied to determine the maximum clock frequency at which the microcontroller can execute software subroutines without failure. Low power microcontrollers from two different manufacturers were tested. The maximum clock frequency decreases with increasing TID for both parts. A model for the degradation based on analysis of circuit level timing models is presented. The microcontroller robustness implications for system designers and ASIC designers are discussed.", "num_citations": "4\n", "authors": ["572"]}
{"title": "A tool chain for the V&V of NASA cryogenic fuel loading health management\n", "abstract": " Complex machinery like spacecraft, aircraft, or chemical plants are equipped with fault detection and diagnosis systems. Due to their safety-critical nature, such diagnosis systems have to undergo rigorous Verification and Validation (V&V). In this paper, we present a tool suite to facilitate V&V of the deployed diagnostic system. The V&V relies on the paradigms of cross validation (to compare the diagnosis results of the deployed reasoner against those of other, more advanced reasoners), automatic fault scenario generation (to support extensive testing and coverage analysis), and parametric model analysis (to enrich test sets and for robustness and sensitivity analysis). We present the application of this tool architecture towards the V&V of the diagnosis system based on the TEAMS tool suite towards a subsystem in the NASA cryogenic fuel loading facility.", "num_citations": "4\n", "authors": ["572"]}
{"title": "A model-based integration of network emulation with HLA-based heterogeneous simulation environments\n", "abstract": " Evaluation of Command and Control (C2) concepts requires a sophisticated modeling, simulation and experiment infrastructure. This requires the integration of existing simulation tools, system prototypes and experiment platforms that can interact in a coordinated way. This paper presents our work on integrating the network experiment platform into the HLA-based simulation environment as a solution to this problem. Network emulation environments allow the use of real network devices, components and systems, thus providing greater realism in the network experiment. Integrating network emulation into the C2W system, however, is a challenging issue due to (1) the different time domains that the simulation and the real network platform operate on and (2) the need to controlling the communication overhead between the simulation and the emulation environment, while still ensuring the accuracy of the experiment\u00a0\u2026", "num_citations": "4\n", "authors": ["572"]}
{"title": "Continuous migration support for domain-specific languages\n", "abstract": " Metamodel evolution is becoming an inevitable part of software projects that use domain-specific modeling. Domainspecific modeling languages (DSMLs) evolve more frequently than traditional programming languages, resulting in a large number of invalid instance models that are no longer compliant with the metamodel. The key to addressing this problem is to provide a solution that focuses on the specification of typical metamodel changes and automatically deduces the corresponding instance model migration. Additionally, a solution must be usable by domain experts not familiar with low level programming issues. This paper presents the Model Change Language (MCL), a language and supporting framework aimed at fulfilling these requirements.", "num_citations": "4\n", "authors": ["572"]}
{"title": "20 The Model-Integrated Computing Tool Suite\n", "abstract": " Embedded system software development is challenging, owing to a tight integration of the software and its physical environment, profoundly impacting the software technology that can be applied for constructing embedded systems. Modeling and model-based design are central to capture all essential aspects of embedded systems. Vanderbilt University\u2019s Model Integrated Computing tool suite, driven by the recognition of the need for integrated systems and software modeling, provides a reusable infrastructure for model-based design of embedded systems. The suite includes metaprogrammable model-builder (GME), model-transformation engine (UDM/GReAT), tool-integration framework (OTIF), and design space exploration tool (DESERT). The application of the MIC tool suite in constructing a tool chain for Automotive Embedded System (VCP) is presented.", "num_citations": "4\n", "authors": ["572"]}
{"title": "An Examination of Criticality-Sensitive Approaches to Coordination.\n", "abstract": " In this work, we address the problem of coordinating the distributed execution of plans and schedules by multiple agents subject to a number of different execution uncertainties. The coordination of multi-agent teams in uncertain, dynamic domains is a challenging problem requiring the fusion of techniques from many disciplines. We describe an approach based on the dynamic and selective use of a family of different problem-solving strategies that combine stochastic state estimation with repair-based and heuristic-guided planning and scheduling techniques. This approach is implemented as a cognitive problem-solving architecture that combines (i) a deliberative scheduler, which performs partially-centralized solution repair,(ii) an opportunistic scheduler, which locally optimizes resource utilization for plan enhancement, and (iii) a downgrader, which proactively guides the execution into regions of higher likelihood of success. This paper characterizes the complexity of the problem through examples and experiments, and discusses the advantages and effectiveness of the implemented solution.", "num_citations": "4\n", "authors": ["572"]}
{"title": "Architecture analysis in software factories\n", "abstract": " In this paper, we argue for the incorporation of architecture analysis techniques in Software Factories. While software factories often rely on a domain-specific (or product-line specific) architecture, frequently there are some architectural alternatives left open. In these situations, architectural analysis, static or dynamic is essential. The paper elaborates these concepts and shows an example from the domain of avionics systems how this can be accomplished.", "num_citations": "4\n", "authors": ["572"]}
{"title": "Experimental platform for studying distributed embedded control applications\n", "abstract": " Networked embedded systems are highly distributed systems with limited resources and communication capabilities tightly coupled to physical processes with sensors and actuators. These constraints do not allow the deployment of existing heavyweight middleware layers to support the distributed control algorithms in the different application domains of these systems. The paper describes a simulation framework that enables the timing accurate simulation of these systems including the physical system, the computing nodes and the communication network. The tool serves two distinct purposes by 1) allowing experimentation with different application domains and distributed control algorithms in the presence of communication delays, clock drift and faults and 2) providing a platform for distributed middleware research.", "num_citations": "4\n", "authors": ["572"]}
{"title": "The BTeV DAQ and trigger system-some throughput, usability and fault tolerance aspects\n", "abstract": " As presented at the last CHEP conference, the BTeV triggering and data collection pose a significant challenge in construction and operation, generating 1.5 Terabytes/second of raw data from over 30 million detector channels. We report on facets of the DAQ and trigger farms. We report on the current design of the DAQ, especially its partitioning features to support commissioning of the detector. We are exploring collaborations with computer science groups experienced in fault tolerant and dynamic real-time and embedded systems to develop a system to provide the extreme flexibility and high availability required of the heterogeneous trigger farm ({approximately} ten thousand DSPs and commodity processors). We describe directions in the following areas: system modeling and analysis using the Model Integrated Computing approach to assist in the creation of domain-specific modeling, analysis, and program synthesis environments for building complex, large-scale computer-based systems; System Configuration Management to include compilable design specifications for configurable hardware components, schedules, and communication maps; Runtime Environment and Hierarchical Fault Detection/Management--a system-wide infrastructure for rapidly detecting, isolating, filtering, and reporting faults which will be encapsulated in intelligent active entities (agents) to run on DSPs, L2/3 processors, and other supporting processors throughout the system.", "num_citations": "4\n", "authors": ["572"]}
{"title": "Automating human based negotiation processes for autonomic logistics\n", "abstract": " Affordability and responsiveness are two key requirements for the next generation of aircraft support systems. Aircraft have to be repaired with minimum downtime and the support process has to be economical and efficient. The vision of autonomic logistics (AL) entails a maintenance and support system that can autonomously respond to \"events\", e.g. problems detected on-board the aircraft. The response includes identifying the source of the problem, acquiring the correct parts and tools, locating and scheduling the right maintenance personnel. Currently, software tools and packages are available that can provide functional components for an AL system, but the integration of these does not exist yet. The paper discusses how agent technology in general and negotiation processes in particular can be applied to build an AL system. We envision a system where existing, \"legacy\" packages are integrated via an agent\u00a0\u2026", "num_citations": "4\n", "authors": ["572"]}
{"title": "The integration of anomaly, prognostics, and diagnostics reasoners to optimize overall vehicle health management goals\n", "abstract": " The challenge is to economically field complex systems in safety critical applications over a service life of at least twenty years. Traditional solutions have included a variety of approaches to implementing diagnostic systems. Just as the health of human beings cannot be maintained entirely through diagnostics, complex safety critical systems cannot either. Diagnoses provide feedback on failure events only after they have occurred. The next major challenge to designing automatic health maintenance systems is to prognose failure events before they occur. The prognostic and diagnostic systems must be integrated into an overall system whose primary customers are the maintainer and the vehicle operator. In this paper we categorize a failure event into three classes: (1) an anomaly, (2) an impending failure, or (3) an active failure. Using the definitions of these three failure classes we develop a reasoner architecture\u00a0\u2026", "num_citations": "4\n", "authors": ["572"]}
{"title": "A generic and symbolic model-based diagnostic reasoner with highly scalable properties\n", "abstract": " Modern computing technologies-hardware, software, and algorithmic-have enabled the deployment of more exacting diagnostic reasoning (DR) systems than has heretofore been possible. Compromises in algorithm and modeling paradigm complexity, due to computational throughput and state-space explosion constraints, have historically dominated practical applications of such systems. This paper describes approaches that have been shown to be applicable in a wide set of domains. The algorithms used are highly scaleable and support a symbolic modeling formalism for analyzing the properties of the complex, dynamic systems. Moreover, analysis of simultaneous failures occurs as a natural byproduct of this formalism.", "num_citations": "4\n", "authors": ["572"]}
{"title": "Neural networks in GTA weld modeling and control\n", "abstract": " Solutions to modeling the Gas Tungsten Arc(GTA) Welding process using a non-conventional technique is presented here. This approach is a non-linear modeling technique employing neural networks which has exhibited the potential to learn to model the time response of a non-linear, multivariable system. This paper examines the feasibility of this approach an alternative to existing techniques Potential problems with this approach are also discussed. A control architecture using a second neural network is also suggested.", "num_citations": "4\n", "authors": ["572"]}
{"title": "Graphic Simulation Test Bed for Robotics Applications in a Workstation Environment\n", "abstract": " Graphical simulation is a cost-effective solution for developing and testing robots and their control systems. The availability of various high-performance workstations makes these systems feasible in everyday practice. Simulation offers preliminary testing of systems before their actual realizations, and it provides a framework for developing new control and planning algorithms. On the other hand, these simulation systems have to have the capability of incorporating various knowledge-based system components, e. 9. task planners, representation formalisms, etc. They also should have an appropriate user interface, which makes possible the creation and control of simulation models.ROBOSIM was developed jointly by MSFC and Vanderbilt University, first in a VAX environment. Recently, the system has been ported to an HP-9000 workstation equipped with an SRX graphics accelerator. The user interface of the system now contains a menu-and icon-based facility, as well as the original ROBOSIM language. The system is also coupled to a symbolic computing system based on Common Lisp, where knowledge-based functionalities are implemented. The knowledge-based layer uses various representation and reasoning facilities for programming and testing the control systems of robots.", "num_citations": "4\n", "authors": ["572"]}
{"title": "Model-based approach for intelligent control\n", "abstract": " The paper discusses a comprehensive, model-based approach for the design and implementation of intelligent controllers. The system has been implemented in the framework of the Multigraph Architecture. The Multigraph Architecture is a layered system, which includes a parallel, graph computation model, the corresponding execution environment, and software tools supporting the interactive, graphical building of knowledge-bases.", "num_citations": "4\n", "authors": ["572"]}
{"title": "Gas tungsten arc weld modeling using a mapping network\n", "abstract": " An accurate model of the characteristics of a welding pool is relevant for realtime control of the welding process. Traditionally tile weld models have been based on physical laws believed to describe the process. In practice such models have frequently needed\" fine tuning\" of one or more\" empirical parameters\" to achieve accurate compliance with real welds. By using a mapping neural network a radically different approach is taken in modeling the weld pool. The weld modeling problem can be formulated as follows: Known parameters are the arc voltage, current and electrode travel speed while the unknowns are the geometrical attributes of the weld. For practical purposes tables have been compiled through experimentation, which contain the corresponding data sets of parameter values. Thus the problem can be considered as a mapping problem, where a mapping 7~ m~-,\"/'dn is known only for certain points in\u00a0\u2026", "num_citations": "4\n", "authors": ["572"]}
{"title": "Towards model-based intent-driven adaptive software\n", "abstract": " Model-based software engineering plays an increasing role in system development. The abstractions offered by models provide a basis for tasks such as analysis, synthesis, and automated reasoning. However, like traditional software engineering, model-based engineering must also deal with challenges that arise during system evolution, including requirement changes and platform updates. This paper describes our vision for a model-based workflow for adaptive software that reduces the burden caused by evolution. Our vision includes a modeling paradigm centered around the concepts of objectives, intents, and constraints, which define, respectively, (1) what the system must do in terms of domain-specific abstractions, (2) the concretization choices made to refine a model into implementation, and (3) the system requirements not expressed in terms of domain-specific abstractions. We also discuss a\u00a0\u2026", "num_citations": "3\n", "authors": ["572"]}
{"title": "ReSonAte: A Runtime Risk Assessment Framework for Autonomous Systems\n", "abstract": " Autonomous CPSs are often required to handle uncertainties and self-manage the system operation in response to problems and increasing risk in the operating paradigm. This risk may arise due to distribution shifts, environmental context, or failure of software or hardware components. Traditional techniques for risk assessment focus on design-time techniques such as hazard analysis, risk reduction, and assurance cases among others. However, these static, design-time techniques do not consider the dynamic contexts and failures the systems face at runtime. We hypothesize that this requires a dynamic assurance approach that computes the likelihood of unsafe conditions or system failures considering the safety requirements, assumptions made at design time, past failures in a given operating context, and the likelihood of system component failures. We introduce the ReSonAte dynamic risk estimation framework for autonomous systems. ReSonAte reasons over Bow-Tie Diagrams (BTDs) which capture information about hazard propagation paths and control strategies. Our innovation is the extension of the BTD formalism with attributes for modeling the conditional relationships with the state of the system and environment. We also describe a technique for estimating these conditional relationships and equations for estimating risk based on the state of the system and environment. To help with this process, we provide a scenario modeling procedure that can use the prior distributions of the scenes and threat conditions to generate the data required for estimating the conditional relationships. To improve scalability and reduce the amount of\u00a0\u2026", "num_citations": "3\n", "authors": ["572"]}
{"title": "Science of design for societal-scale cyber-physical systems: challenges and opportunities\n", "abstract": " Emerging industrial platforms such as the Internet of Things (IoT), Industrial Internet (II) in the US and Industrie 4.0 in Europe have tremendously accelerated the development of new generations of Cyber-Physical Systems (CPS) that integrate humans and human organizations (H-CPS) with physical and computation processes and extend to societal-scale systems such as traffic networks, electric grids, or networks of autonomous systems where control is dynamically shifted between humans and machines. Although such societal-scale CPS can potentially affect many aspect of our lives, significant societal strains have emerged about the new technology trends and their impact on how we live. Emerging tensions extend to regulations, certification, insurance, and other societal constructs that are necessary for the widespread adoption of new technologies. If these systems evolve independently in different parts of the\u00a0\u2026", "num_citations": "3\n", "authors": ["572"]}
{"title": "Simulation of transistor-level radiation effects on system-level performance parameters\n", "abstract": " A simulation paradigm is proposed to examine the effects of transistor-level degradation produced by total ionizing dose (TID) on top-level system performance parameters. The approach is demonstrated on a command and data handling (C&DH) board for deep-space CubeSats. Simulation and postirradiation measurements of a temperature control loop show that TID degradation changes temperature regulation significantly.", "num_citations": "3\n", "authors": ["572"]}
{"title": "Towards operational use of unit manufacturing process models\n", "abstract": " Unit Manufacturing Processes (UMP) are models that capture succinct definitions of individual manufacturing steps in a manufacturing system. They are used to facilitate model composition and reuse. However, mainly due to their textual nature, they are difficult to use in conjunction with other types of computational models and in subsequent analysis activities such as optimization. This paper describes our method that allows UMP models (conforming to the ASTM E3012 standard) to be combined with other types of manufacturing system models (such as analytical, data-driven, and simulation models). This is done through an interface between a tool used to create UMP models (in the ASTM E3012 standard) and an analytical framework for the composition and analysis of manufacturing process models. Additionally, we present an example showing how the combination of the two tools can be used in practice.", "num_citations": "3\n", "authors": ["572"]}
{"title": "Transportation networks\n", "abstract": " A transportation network is a critical component of a Smart City (considered in the preceding chapter), and therefore it is fitting that a distinguishing element of this chapter is the resilience analysis of transportation networks. The chapter highlights the importance of humans in most cyber-physical systems and uses the term Human Cyber-Physical System (H-CPS). It further argues that H-CPS design processes should use five fundamentally different abstraction layers: the physical layer, the three \u201ccyber\u201d layers: network, service platform, and application layers, and the human layer. It then describes the Cyber-Physical Systems Wind Tunnel (CPSWT), a simulation integration architecture tool kit, and proceeds to illustrate a simulation-based resilience analysis using a transportation network example.", "num_citations": "3\n", "authors": ["572"]}
{"title": "DREMS-OS: An operating system for managed distributed real-time embedded systems\n", "abstract": " Distributed real-time and embedded (DRE) systems executing mixed criticality task sets are increasingly being deployed in mobile and embedded cloud computing platforms, including space applications. These DRE systems must not only operate over a range of temporal and spatial scales, but also require stringent assurances for secure interactions between the system's tasks without violating their individual timing constraints. To address these challenges, this paper describes a novel distributed operating system focusing on the scheduler design to support the mixed criticality task sets. Empirical results from experiments involving a case study of a cluster of satellites emulated in a laboratory testbed validate our claims.", "num_citations": "3\n", "authors": ["572"]}
{"title": "Diagnostics and prognostics using temporal causal models for cyber physical energy systems\n", "abstract": " Reliable operation of cyber-physical systems such as Power Transmission and Distribution Systems is critical for the seamless functioning of a vibrant economy. These systems consist of tightly coupled physical (energy sources, transmission and distribution lines, and loads) and computational components (protection devices, energy management systems, etc). The protection devices such as distance relays help in preventing failure propagation by isolating faulty physical components. However, these devices rely on hard thresholds and local information, often ignoring system-level effects introduced by the distributed control algorithms. This leads to scenarios wherein a local mitigation in a subsystem could trigger a larger fault cascade, possibly resulting in a blackout. Efficient models and tool that curtail such systematic failures by performing fault diagnosis and prognosis are therefore necessary.", "num_citations": "3\n", "authors": ["572"]}
{"title": "Towards diagnosing cascading outages in cyber physical energy systems using temporal causal models\n", "abstract": " Cascading failures in critical cyber physical systems such as power systems are rare but lead to huge social and economic implications. Timely diagnosis of faults in these systems is a challenging task due to inherent heterogeneity and scale of the system. In the past, we have successfully demonstrated a robust technique for diagnosing independent component faults using Temporal Causal Diagrams (TCD) at sub-system level. In this paper, we present a systematic approach of using the sub-system level fault models to auto-generate a systemlevel fault model that helps in diagnosing cascading failures. We show the time complexity of our model generation algorithm using industry standard Power Transmission networks. Further, we describe the updates to the existing TCD reasoner algorithms and report the TCD diagnosis results for simulated multi fault scenario on a standard power system.", "num_citations": "3\n", "authors": ["572"]}
{"title": "Demo abstract: SURE: An experimentation and evaluation testbed for CPS security and resilience\n", "abstract": " In-depth consideration and evaluation of security and resilience is necessary for developing the scientific foundations and technology of Cyber-Physical Systems (CPS). In this demonstration, we present SURE [1], a CPS experimentation and evaluation testbed for security and resilience focusing on transportation networks. The testbed includes (1) a heterogeneous modeling and simulation integration platform, (2) a Web-based tool for modeling CPS in adversarial environments, and (3) a framework for evaluating resilience using attacker-defender games. Users such as CPS designers and operators can interact with the testbed to evaluate monitoring and control schemes that include sensor placement and traffic signal configuration.", "num_citations": "3\n", "authors": ["572"]}
{"title": "A component-based approach for modeling failure propagations in power systems\n", "abstract": " Resiliency and reliability is of paramount impor- tance for energy cyber physical systems. Electrical protection systems including detection elements such as Distance Relays and actuation elements such as Breakers are designed to protect the system from abnormal operations and arrest failure propagation by rapidly isolating the faulty components. However, failure in the protection devices themselves can and do lead to major system events and fault cascades, often leading to blackouts. This paper augments our past work on Temporal Causal Diagrams (TCD), a modeling formalism designed to help reason about the failure progressions by (a) describing a way to generate the TCD model from the system specification, and (b) understand the system failure dynamics for TCD reasoners by configuring simulation models.", "num_citations": "3\n", "authors": ["572"]}
{"title": "Key Considerations for a Resilient and Autonomous Deployment and Configuration Infrastructure for Cyber-Physical Systems\n", "abstract": " Multi-module Cyber-Physical Systems (CPSs), such as satellite clusters, swarms of Unmanned Aerial Vehicles (UAV), and fleets of Unmanned Underwater Vehicles (UUV) are examples of managed distributed real-time systems where mission-critical applications, such as sensor fusion or coordinated flight control, are hosted. These systems are dynamic and reconfigurable, and provide a \u201cCPS cluster-as-a-service\u201d for mission-specific scientific applications that can benefit from the elasticity of the cluster membership and heterogeneity of the cluster members. The distributed and remote nature of these systems often necessitates the use of Deployment and Configuration (D&C) services to manage the lifecycle of software applications. Fluctuating resources, volatile cluster membership and changing environmental conditions require resilient D&C services. However, the dynamic nature of the system often precludes human intervention during the D&C activities, which motivates the need for a self-adaptive D&C infrastructure that supports autonomous resilience. Such an infrastructure must have the ability to adapt existing applications on-the-fly in order to provide application resilience and must itself be able to adapt to account for changes in the system as well as tolerate failures. This paper makes two contributions towards addressing these needed. First, we identify the key challenges in achieving such a self-adaptive D&C infrastructure. Second, we present our ideas on resolving these challenges and realizing a self-adaptive D&C infrastructure.", "num_citations": "3\n", "authors": ["572"]}
{"title": "A resilient and secure software platform and architecture for distributed spacecraft\n", "abstract": " A distributed spacecraft is a cluster of independent satellite modules flying in formation that communicate via ad-hoc wireless networks. This system in space is a cloud platform that facilitates sharing sensors and other computing and communication resources across multiple applications, potentially developed and maintained by different organizations. Effectively, such architecture can realize the functions of monolithic satellites at a reduced cost and with improved adaptivity and robustness. Openness of these architectures pose special challenges because the distributed software platform has to support applications from different security domains and organizations, and where information flows have to be carefully managed and compartmentalized. If the platform is used as a robust shared resource its management, configuration, and resilience becomes a challenge in itself. We have designed and prototyped a\u00a0\u2026", "num_citations": "3\n", "authors": ["572"]}
{"title": "Deliberative reasoning in software health management\n", "abstract": " Rising software complexity in aerospace systems makes them very difficult to analyze and prepare for all possible fault scenarios at design-time. Therefore, classical run-time fault-tolerance techniques, such as self-checking pairs and triple modular redundancy are used. However, several recent incidents have made it clear that existing software fault tolerance techniques alone are not sufficient. To improve system dependability, simpler, yet formally specified and verified run-time monitoring, diagnosis, and fault mitigation are needed. Such architectures are already in use for managing the health of vehicles and systems. Software health management is the application of adapting and applying these techniques to software. In this paper, we briefly describe the software health management technique and architecture developed by our research group. The foundation of the architecture is a real-time component framework (built upon ARINC-653 platform services) that defines a model of computation for software components. Dedicated architectural elements: the Component Level Health Manager (CLHM) and System Level Health Manager (SLHM) are providing health management services: anomaly detection, fault source isolation, and fault mitigation. The SLHM includes a diagnosis engine that uses a Timed Failure Propagation (TFPG) model derived from the component assembly model, and it reasons about cascading fault effects in the system and isolates the fault source component (s). Thereafter, the appropriate system level mitigation action is taken. The main focus of this article is the description of the fault mitigation architecture that uses\u00a0\u2026", "num_citations": "3\n", "authors": ["572"]}
{"title": "Web-based Metaprogrammable Frontend for Molecular Dynamics Simulations.\n", "abstract": " Molecular dynamics simulators are indispensable tools in the arsenal of chemical engineers and material scientists. However, they are often difficult to use and require programming skills as well as deep knowledge of both the given scientific domain and the simulation software itself. In this paper, we describe a metaprogramming approach where simulator experts can create a library of simulation components and templates of frequently used simulations. Domain experts, in turn, can build and customize their own simulations and the required input for the various supported simulators is automatically synthesized. The web-based environment also supports setting up a suite of simulation jobs, for example, to carry out automated parameter optimization, via a visual programming environment. The entire simulation setup\u2013including the various parameters, the version of tools utilized and the results\u2013is stored in a database to support searching and browsing of existing simulation outputs and facilitating the reproducibility of scientific results.", "num_citations": "3\n", "authors": ["572"]}
{"title": "Formalization of a component model for real-time systems\n", "abstract": " Component-based software development for real-time systems necessitates a well-defined \u2018component model\u2019that allows compositional analysis and reasoning about systems. Such a model defines what a component is, how it works, and how it interacts with other components. It is especially important for real-time systems to have such a component model, as many problems in these systems arise from poorly understood and analyzed component interactions. In this paper we describe a component model for hard real-time systems that relies on the services of an ARINC-653 compliant real-time operating system platform. The model provides high-level abstractions of component interactions, both for the synchronous and asynchronous case. We present a formalization of the component model in the form of timed transition traces. Such formalization is necessary to be able to derive interesting system level properties such as fault propagation graphs from models of component assemblies. We provide a brief discussion about such system level fault propagation templates for this component model.", "num_citations": "3\n", "authors": ["572"]}
{"title": "A case study on the application of software health management techniques\n", "abstract": " Ever increasing complexity of software used in largescale, safety critical cyber-physical systems makes it increasingly difficult to expose and thence correct all potential bugs. There is a need to augment the existing fault tolerance methodologies with new approaches that address latent software bugs exposed at runtime. This paper describes an approach that borrows and adapts traditional \u2018Systems Health Management\u2019techniques to improve software dependability through simple formal specification of runtime monitoring, diagnosis and mitigation strategies. The two-level approach of Health Management at Component and System level is demonstrated on a simulated case study of an Air Data Inertial Reference Unit (ADIRU). That subsystem was categorized as the primary failure source for the in-flight upset caused in the Malaysian Air flight 124 over Perth, Australia in August 2005.", "num_citations": "3\n", "authors": ["572"]}
{"title": "Online stability validation using sector analysis\n", "abstract": " Our previous work has explored the use of compositional stabilization techniques for embedded flight control software [9] based on passivity properties of controller components and systems. Zames [21] presented a compositional behavior-bounding technique for evaluating stability of nonlinear systems based on real intervals representing cones (sectors) that bound possible component behaviors. Many innovations in control theory have developed from his insights. We present a novel use of his sector bound theory to validate the stability of embedded control implementations online. The sector analysis can be implemented as a computationally efficient check of stability for different parts of a control design. The advantage of the online application of this technique is that it takes into account software platform effects that impact stability, such as time delays, quantization, and data integrity.", "num_citations": "3\n", "authors": ["572"]}
{"title": "Towards a model-based toolchain for the high-confidence design of embedded systems\n", "abstract": " While design automation for hardware systems is quite advanced, this is not the case for practical embedded systems. The current state-of-the-art is to use a software modeling environment and integrated development environment for code development and debugging, but these rarely include the sort of automatic synthesis and verification capabilities available in the VLSI domain. This paper introduces concepts, elements, and some early prototypes for an envisioned suite of tools for the development of embedded software that integrates verification steps into the overall process.", "num_citations": "3\n", "authors": ["572"]}
{"title": "Evolving paradigms and models in multi-paradigm modeling\n", "abstract": " The essence of model based software development for domain specific appli-cations is in the definition of a meta-model that captures the key aspects of the domain. However, the meta-model rarely defines the domain completely, and must often be modified to reflect our improved understanding of the domain dur-ing the course of development and subsequent use of domain specific software. The modification of the meta-model creates a versioning problem, whereby ex-isting models may no longer conform to the modified meta-model. This report describes the Universal Model Migrator, a tool that allows domain designers to declaratively specify incremental modifications to their meta-models, in order to facilitate the automatic evolution of domain models to remain conformant to the latest version of the meta-model. 1", "num_citations": "3\n", "authors": ["572"]}
{"title": "Transparent Collaborative haptic simulation\n", "abstract": " This paper deals with the problem of transparency (or fidelity) in force feedback systems or more particularly for haptics simulation under time delay transmission. The haptics rendering transparency is all the more difficult in distributed collaboration between distant users because it is necessary also to make feel faithfully the mutual interactions. The idea suggested in this article gives an original solution to overcome this lack of transparency in haptic shared collaborations on the network using a principle called the \u201cLatency Envelope\u201d (LE). One advantage of this implementation is the anticipation of the contact between users and virtual objects. The delay can then be partially or completely compensated from the open perception point of view. Also it does not affect at all the stability of haptics simulation (carried out using well known control laws).", "num_citations": "3\n", "authors": ["572"]}
{"title": "Robust diagnosis of switching systems\n", "abstract": " This paper presents an approach for robust diagnosis of switching systems based on an extended version of the timed failure propagation graph model. The extended failure propagation graph model is a labeled graph used for the representation of failure conditions and their propagation modeled as causal relations with timing properties for a general class of systems with both timebased and event-driven dynamics such as hybrid and discrete event systems. We introduce the extended model and describe the structure and main components of the failure detection and isolation system based on the proposed model.", "num_citations": "3\n", "authors": ["572"]}
{"title": "Realization and Real-time Properties of Reconfiguration and Transient Management Methods\n", "abstract": " System reconfigurations are of major concern in embedded control applications, where the effects of internal or external changes may ask for drastic modifications within the architecture and the operation of the controllers. In dynamic systems, these kinds of modifications are followed by transient phenomena resulting in possibly unacceptable side effects. For this very reason, reconfiguration methods should include also some measures concerning transient behavior. These measures are referred to as transient management. In this report some possible realization schemes of certain reconfiguration methods including transient management are investigated. The primary aim of this work is to give aspects of performance characterization of system reconfigurations, and to provide a conceptual framework to support their development and design.The problem to be solved here is how to move a real-time system from its actual configuration to a new one with predictably low magnitude and short time transient response. There are several activities, which might influence significantly this reconfiguration procedure. To provide a proper design of this procedure we must be aware of the complete system as much as possible both in design-time and also in run-time. The complete system in our case includes both the plant and the controller, or equivalently the complete physical environment and the embedded computational system. Changes, ie, intentional or unintentional reconfigurations might occur in any part of the overall system. Therefore, during operation an ongoing real-time identification might be required to detect these changes, and decision\u00a0\u2026", "num_citations": "3\n", "authors": ["572"]}
{"title": "An Integrated Multi-Domain Analysis Environment For High Consequence Systems\n", "abstract": " Modeling and analysis of high consequence, high assurance systems requires special modeling considerations. System safety and reliability information must be captured in the models. Previously, high consequence systems were modeled using separate, disjoint models for safety, reliability, and security. The MultiGraph Architecture facilitates the implementation of a model-integrated system for modeling and analysis of high assurance systems. Among the tools used for analyzing safety and reliability are a behavioral simulator and an automatic fault tree generation and analysis tool. Symbolic model checking techniques are used to efficiently investigate the system models. A method for converting finite state machine models to ordered binary decision diagrams allows the application of symbolic model checking routines to the system models. This integrated approach to modeling and analysis of high\u00a0\u2026", "num_citations": "3\n", "authors": ["572"]}
{"title": "A graphical programming environment for simulation of control and signal processing systems\n", "abstract": " The authors have developed a graphical programming library for control and signal processing applications. The library covers a wide range starting from basic primitives such as simple arithmetic and Boolean functions to complicated units like generalized neural networks. The user gets access to these units in the form of icons. By making connections to and from these icons, a user generates different block diagrams, which are the programs in the graphical environment. The library is described from the user's point of view. Different features of the graphical programming environment and the library are discussed. The use of the library is illustrated with a simple graphical programming example. Some of the implementation details are discussed.< >", "num_citations": "3\n", "authors": ["572"]}
{"title": "Al, Automation And The Flight Telerobotic Servicer\n", "abstract": " NASA has recently completed a study for the preliminary definition of a teleoperated robotic device. The Flight Telerobotic Servicer (FTS) will be used to assist astronauts in many of the on-board tasks of assembly, maintenance, servicing and inspection of the Space Station. This paper makes an assessment of the role that Artificial Intelligence (AI) may have in furthering the automation capabilities of the FTS and, hence, extending the FTS capacity for growth and evolution. Relevant system engineering issues are identified, and an approach for insertion of AI technology is presented in terms of the NASA/NBS Standard Reference Model (NASREM) control architecture.", "num_citations": "3\n", "authors": ["572"]}
{"title": "Programming Model For Coupled Intelligent Systems In Distributed Execution Environments\n", "abstract": " This paper discusses the requirements for integrating artificial intelligence (AI) techniques with traditional real-time computing in distributed computing environments, and describes an architecture and high-level programming model developed for this purpose. The Multigraph Architecture is a multilayered system, which includes a parallel computation model, the corresponding execution environment and various software tools. The components of the high-level programming model are tailored to the specific properties of the distri-buted computing system, and are centered around the concept of autonomous, communicating objects. The programming model consists of special object types that offer high-level support for the design of complex system components, such as procedural networks, or rule-based systems.", "num_citations": "3\n", "authors": ["572"]}
{"title": "Qualitative Fault Modeling in Safety Critical Cyber Physical Systems\n", "abstract": " One of the key requirements for designing safety critical cyber physical systems (CPS) is to ensure resiliency. Typically, the cyber sub-system in a CPS is empowered with protection devices that quickly detect and isolate faulty components to avoid failures. However, these protection devices can have internal faults that can cause cascading failures, leading to system collapse. Thus, to guarantee the resiliency of the system, it is necessary to identify the root cause (s) of a given system disturbance to take appropriate control actions. Correct failure diagnosis in such systems depends upon an integrated fault model of the system that captures the effect of faults in CPS as well as nominal and faulty operation of protection devices, sensors, and actuators.", "num_citations": "2\n", "authors": ["572"]}
{"title": "Deep-Edge: An Efficient Framework for Deep Learning Model Update on Heterogeneous Edge\n", "abstract": " Deep Learning (DL) model-based AI services are increasingly offered in a variety of predictive analytics services such as computer vision, natural language processing, speech recognition. However, the quality of the DL models can degrade over time due to changes in the input data distribution, thereby requiring periodic model updates. Although cloud data-centers can meet the computational requirements of the resource-intensive and time-consuming model update task, transferring data from the edge devices to the cloud incurs a significant cost in terms of network bandwidth and are prone to data privacy issues. With the advent of GPU-enabled edge devices, the DL model update can be performed at the edge in a distributed manner using multiple connected edge devices. However, efficiently utilizing the edge resources for the model update is a hard problem due to the heterogeneity among the edge devices\u00a0\u2026", "num_citations": "2\n", "authors": ["572"]}
{"title": "Development of a Flight-Program-Ready Radiation Model-Based Assurance Platform\n", "abstract": " This work describes one step towards automating the development of assurance cases for systems in radiation environments. The Systems Engineering Assurance and Modeling Platform (SEAM) developed by Vanderbilt and NASA is extended to automatically cross-reference faults, fault paths, and mitigation functions in the system description with assurance arguments in the Goal Structuring Notation (GSN) format. This automatic coverage check considerably enhances the capability of the platform to facilitate systematic radiation hardness evaluations of complex spacecraft systems.", "num_citations": "2\n", "authors": ["572"]}
{"title": "Model-Based On-Board Decision Making for Autonomous Aircraft\n", "abstract": " Powerful, small and lightweight sensors in combination with advanced failure detection, diagnosis, and prognostics techniques provide up-to-date data on the health status of an Unmanned Aerial System (UAS) or autonomously piloted vehicle. This information must be used for automatic planning and execution of contingency actions to keep the UAS safe in adverse conditions. We present DM (Decision Maker), a software component which uses model-based reasoning and backtracking search to iteratively construct contingency plans that are safe for the UAS to execute and pose minimal interruption to the mission goals. The DM is a discrete decision making system has been developed within the NASA Autonomous Operating System (AOS) project and fills the gap between Prognostics and Health Management and autonomous flight operations. In this paper, we describe DM and its reasoning algorithm and present the supporting modeling framework for the construction of system and fault models. Flights with a DJI S1000+ octocopter with fault injection will be used as our case study.", "num_citations": "2\n", "authors": ["572"]}
{"title": "Enabling strong isolation for distributed real-time applications in edge computing scenarios\n", "abstract": " Distributed coexisting applications found in the military and space domains, which operate over managed but shared computing resources at the edge require strong isolation from each other. The state of the art for computation sharing at the edge is traditionally based on Docker and similar pseudovirtualization features. Our team has been working on an end-to-end architecture that provides strong spatial and temporal isolation similar to what has become standard in avionics communities. In this paper, we describe an open-source extension to Linux that we have designed and implemented for our distributed real-time embedded managed systems (DREMS) architecture. The key concepts are the partitioning scheduler, strong security design, and a health management interface.", "num_citations": "2\n", "authors": ["572"]}
{"title": "On the Design of Fault-Tolerance in a Decentralized Software Platform for Power Systems\n", "abstract": " The vision of the `Smart Grid' assumes a distributed real-time embedded system that implements various monitoring and control functions. As the reliability of the power grid is critical to modern society, the software supporting the grid must support fault tolerance and resilience in the resulting cyber-physical system. This paper describes the fault-tolerance features of a software framework called Resilient Information Architecture Platform for Smart Grid (RIAPS). The framework supports various mechanisms for fault detection and mitigation and works in concert with the applications that implement the grid-specific functions. The paper discusses the design philosophy for and the implementation of the fault tolerance features and presents an application example to show how it can be used to build highly resilient systems.", "num_citations": "2\n", "authors": ["572"]}
{"title": "From modeling to model-based programming\n", "abstract": " Modeling is a fundamental, analytical tool for engineering design. Programming is the synthesis (i.e. construction) of \u2018machines\u2019 that do something useful. Advances made during the past three decades showed how these activities are intertwined in systems development and cannot be separated. Arguably, the future of engineered systems shall encompass both, especially considering the design of cyber-physical systems where the computational is in continuous interaction with the physical. State-of-the-art industrial practice appears to focus on \u2018model-based programming\u2019 \u2013 programming with higher-level abstractions. In this paper we outline a broader picture for integrating modeling and programming, and what it means for engineering processes and engineering education.", "num_citations": "2\n", "authors": ["572"]}
{"title": "Hierarchical reasoning about faults in cyber-physical energy systems using temporal causal diagrams\n", "abstract": " fault management systems that observe the state of the system, decide if there is an anomaly and then take automated actions to isolate faults. For example, in electrical networks relays and breaks isolate faults in order to arrest failure propagation and protect the healthy parts of the system. However, due to the limited situational awareness and hidden failures the protection devices themselves, through their operation (or mis-operation) may cause overloading and the disconnection of parts of an otherwise healthy system. Additionally, often there can be faults in the management system itself leading to situations where it is difficult to isolate failures. Our work presented in this paper is geared towards solution of this problem by describing the formalism of Temporal Causal Diagrams (TCD-s) that augment the failure models for the physical systems with discrete time models of protection elements, accounting for the complex interactions between the protection devices and the physical plants. We use the case study of the standard Western System Coordinating Council (WSCC) 9 bus system to describe four different fault scenarios and illustrate how our approach can help isolate these failures. Though, we use power networks as exemplars in this paper our approach can be applied to other distributed cyberphysical systems, for example water networks.", "num_citations": "2\n", "authors": ["572"]}
{"title": "Bayesian modeling of COTS power MOSFET ionizing dose impact on circuit response\n", "abstract": " Threshold voltage variation with ionizing dose was measured for a commercial power MOSFET. Variation of radiation response was captured using a Bayesian linear model, which enabled a Monte Carlo simulation of variation in circuit performance.", "num_citations": "2\n", "authors": ["572"]}
{"title": "A dependable, prognostics-incorporated, ns modular battery reconfiguration scheme with an application to electric aircraft\n", "abstract": " The design of dependable systems, such as electric aircraft, necessitates reliable battery system management to help ensure that in addition to power demands being met in the present, they can be met in the future with a low probability of failure. The development of rules concerning battery discharge can minimize the possibility of faults leading to failures due to extreme operating conditions such as exposure to excessive heat or deep discharge. Fault mitigation methods of battery system management can also include switching mechanisms that reconfigure the battery system to exclude faulty batteries. In our work, we propose a dynamic battery reconfiguration scheme for systems that contain battery packs. The battery reconfiguration scheme was designed with the motivation to be both dependable and capable of having a longer discharge time when compared to a static configuration. The contributions of the\u00a0\u2026", "num_citations": "2\n", "authors": ["572"]}
{"title": "Janalyzer: A static analysis tool for java bytecode\n", "abstract": " Static analysis attempts to discover program properties and answer questions about a program\u2019s potential behavior without actually running the program. Example properties include things such as loop bounds, reachability and taint analysis. Even though there is a vast body of literature describing program various program analysis techniques and algorithms, implementing these algorithms can be challenging. Understanding how to make the techniques scale to real-world programs is an additional challenge. This technical report describes our work implementing several static analysis techniques on Java bytecode in a tool we call the Janalyzer. We describe the algorithms we used along with the trade-offs we made in terms of scalability and precision.", "num_citations": "2\n", "authors": ["572"]}
{"title": "Software health management\n", "abstract": " Software health management is defined as a technology that applies the principles and techniques of system health management to software systems. It is motivated by the apparent gap between the importance and complexity of software in today\u2019s cyber-physical systems and the rare, but undoubtedly present occurrence of software malfunctions in those systems. While engineers strive to create dependable systems unforeseen environmental conditions or faults in the hardware can trigger latent defects in the software with potentially negative consequences. The goal of software health management is to maintain system function and performance, even when software fails in unexpected ways. System health management is a well-established discipline in aerospace systems: many air and space vehicles today have quite elaborate health management systems on board. Software fault tolerance techniques are also\u00a0\u2026", "num_citations": "2\n", "authors": ["572"]}
{"title": "Towards a resilient deployment and configuration infrastructure for fractionated spacecraft\n", "abstract": " Fractionated spacecraft are clusters of small, independent modules that interact wirelessly to realize the functionality of a traditional monolithic spacecraft. System F6 (F6 stands for Future, Fast, Flexible, Fractionated, Free-Flying spacecraft) is a DARPA program for fractionated spacecraft. Software applications in F6 are implemented in the context of the F6 Information Architecture Platform (IAP), which provides component-based abstractions for composing distributed applications. The lifecycle of these distributed applications must be managed autonomously by a deployment and configuration (D&C) infrastructure, which can redeploy and reconfigure the running applications in response to faults and other anomalies that may occur during system operation. Addressing these D&C requirements is hard due to the significant fluctuation in resource availabilities, constraints on resources, and safety and security concerns\u00a0\u2026", "num_citations": "2\n", "authors": ["572"]}
{"title": "Integrating statechart components in Polyglot\n", "abstract": " Statecharts is a model-based formalism for simulating and analyzing reactive systems. In our previous work, we developed Polyglot, a unified framework for analyzing different semantic variants of Statechart models. However, for systems containing communicating, asynchronous components deployed on a distributed platform, additional features not inherent to the basic Statecharts paradigm are needed. These include a connector mechanism for communication, a scheduling framework for sequencing the execution of individual components, and a method for specifying verification properties spanning multiple components. This paper describes the addition of these features to Polyglot, along with an example NASA case study using these new features. Furthermore, the paper describes on-going work on modeling Plexil execution plans with Polyglot, which enables the study of interaction issues for future\u00a0\u2026", "num_citations": "2\n", "authors": ["572"]}
{"title": "Csc: Criticality-sensitive coordination\n", "abstract": " Our Criticality-Sensitive Coordination (CSC) agents are designed to enhance the performance of a human-team working together in uncertain and dynamic settings by monitoring and adapting their plans as dictated by the evolution of the environment. Such situations model military scenarios such as a coordinated joint operations or enterprise settings such as multiple-project management. Among the many challenges in these situations are the large space of possible states due to uncertainty, the distributed/partial knowledge of current state and plan among the agents and the need to react in a timely manner to events that may not be in the original model. In fact, reaction alone is often insufficient as in environments where success depends on completing sequences of coupled actions, one needs to anticipate future difficulties and enable contingencies to alleviate potential hazards.", "num_citations": "2\n", "authors": ["572"]}
{"title": "Component-oriented modeling of hybrid dynamic systems using the Generic Modeling Environment\n", "abstract": " This paper presents a component oriented modeling environment for building hybrid dynamic models of physical system. The modeling environment is created using the Generic Modeling Environment (GME), a metaprogrammable visual modeling application developed at the Institute for Software Integrated Systems (ISIS). The core of the modeling language itself is a hybrid extension of the bond graph modeling language. The advantages of an object-oriented approach to physical system modeling combined with the advanced features of GME for managing model complexity are illustrated by building a library of hydraulic system components. A simulation model can be automatically generated from the physical system model using a model translator. As an example application we use the component library to build the model of a coupled multi-tank system with controlled and autonomous hybrid behaviors, and illustrate this with a simulation example. 1.", "num_citations": "2\n", "authors": ["572"]}
{"title": "Robust state-based supervisory control of discrete event systems\n", "abstract": " In this paper, we present an approach for robust supervisory control of discrete event systems. In the proposed approach, we assume that the current state is known only to be within a nonempty subset of the system states. We extend the definition of discrete event system controllability to take into account such uncertainty about the current state. We show that if the system behavior can be traced within the uncertainty set then an optimal non-blocking supervisor can be constructed for the system based on the optimal supervisor under full observation", "num_citations": "2\n", "authors": ["572"]}
{"title": "Self-Adaptive Software for Fault-Adaptive Control\n", "abstract": " Self-adaptive software is a technology that allows building fault-adaptive control systems: control software that can survive faults in the system under control, and in the control software itself. This form of self-adaptive software requires capabilities for the detection and isolation of faults when the system is in operation, and then taking appropriate control actions to mitigate the fault effects and maintain system operation in the best way possible. This paper discusses heterogeneous model-based approach for building fault-adaptive control software, with special emphasis on the modeling schemes that describe different aspects of the system functionality and behavior at different levels of granularity. The computational architecture is applied to design and run experiments on a fault-adaptive control software of an airplane fuel system.", "num_citations": "2\n", "authors": ["572"]}
{"title": "Interpreter Writing Using Graph Transformations\n", "abstract": " This paper introduces a UML-based approach for specifying model transformations. The technique is based on graph transformations, where UML class diagrams are used to represent the graph grammars of the input and the output of the transformations, and the transformations are represented as explicitly sequenced elementary rewriting operations. The paper discusses the visual language designed for the representation of transformation programs and the graph transformation execution engine which implements the semantics of the language.", "num_citations": "2\n", "authors": ["572"]}
{"title": "Online diagnostics makes manufacturing more robust-Part 1\n", "abstract": " An online system to detect, diagnose and recovery from equipment failures can be a boon in minimizing unnecessary downtime. A practical and efficient method in chemical process plants and power stations to diagnose and overcome potential process upsets is presented. The overall methodology is part of a software program called Intelligent Process Control System (IPCS). IPCS is a model-based programming system for developing complex monitoring, control, simulation, diagnostics and recovery applications. The software has an easy-to-use graphical user interface that enables engineers with minimal programming experience to create their own applications. This real-time system uses generic models of a plant and its processes, allowing the basic IPCS system to be used and re-used in different applications. Generic models also simplify maintenance tasks, such as testing, validation, upgrades and\u00a0\u2026", "num_citations": "2\n", "authors": ["572"]}
{"title": "Models and model building in intelligent process control systems\n", "abstract": " A novel approach to the intelligent control of cogeneration plants comprising multiple-aspect modeling and model interpretation is presented. The most important characteristics of this approach are the following: (1) models represent the plant as well as the control system; (2) the control system is derived from this representation; (3) processing of sensory input signals is done in the context of the models; (4) control actions are determined based on the basis of the actual state of the plant and the models. This system has demonstrated that not only are the capabilities of the control system enhanced, but the system development efforts are reduced dramatically as well.< >", "num_citations": "2\n", "authors": ["572"]}
{"title": "Model Based Techniques for Intelligent Process Control\n", "abstract": " This paper describes a new approach in the design and implementation of an intelligent monitoring and diagnostic system for a co-generator plant. The methodology is based on multiple aspect modelling and model interpretation. Sensory input signals from the plant are processed and interpreted in the context of various models of the co-generator system. It is shown that the model based approach has a large impact not only on the functional performance of the system, but dramatically reduces system development time as well. The system has undergone field test and has been in experimental use since May 1989.", "num_citations": "2\n", "authors": ["572"]}
{"title": "Modeling, model interpretation and intelligent control\n", "abstract": " The authors analyze the abstract properties of system architectures supporting structural adaptivity and describe a programming and execution environment (the Multigraph architecture) developed for this system category. The main focus of the Multigraph environment is to facilitate the modeling process on different application domains, such as instrumentation, process control, simulation, and robotics. It is shown that the problems in modeling, model interpretation, and execution environment are closely related in intelligent controllers.<>", "num_citations": "2\n", "authors": ["572"]}
{"title": "SYSTEMS ENGINEERING AND ASSURANCE MODELING (SEAM): A WEB-BASED SOLUTION FOR INTEGRATED MISSION ASSURANCE\n", "abstract": " We present an overview of the Systems Engineering and Assurance Modeling (SEAM) platform, a web-browser-based tool which is designed to help engineers evaluate the radiation vulnerabilities and develop an assurance approach for electronic parts in space systems. The SEAM framework consists of three interconnected modeling tools, a SysML compatible system description tool, a Goal Structuring Notation (GSN) visual argument tool, and Bayesian Net and Fault Tree extraction and export tools. The SysML and GSN sections also have a coverage check application that ensures that every radiation fault identified on the SysML side is also addressed in the assurance case in GSN. The SEAM platform works on space systems of any degree of radiation hardness but is especially helpful for assessing radiation performance in systems with commercial-off-the-shelf (COTS) electronic components.", "num_citations": "1\n", "authors": ["572"]}
{"title": "An LSTM-Based Online Prediction Method for Building Electric Load During COVID-19\n", "abstract": " Accurate prediction of electric load is critical to optimally controlling and operating buildings. It provides the opportunities to reduce building energy consumption and to implement advanced functionalities such as demand response in the context of smart grid. However, buildings are nonstationary and it is important to consider the underlying concept changes that will affect the load pattern. In this paper we present an online learning method for predicting building electric load during concept changes such as COVID-19. The proposed methods is based on online Long Short-Term Memory (LSTM) recurrent neural network. To speed up the learning process during concept changes and improve prediction accuracy, an ensemble of multiple models with different learning rates is used. The learning rates are updated in realtime to best adapt to the new concept while maintaining the learned information for the prediction.", "num_citations": "1\n", "authors": ["572"]}
{"title": "A Binary Decision Diagram Based Cascade Prognostics Scheme For Power Systems\n", "abstract": " Cascading outages in power systems is a rare, but important phenomenon with huge social and economic implications. Due to the inherent complexity and heterogeneity of components in power system, analysis and prediction of the current and future states of the system is a challenging task. In this paper, we address prognosis of cascading outages in power systems by employing a novel approach based on reduced ordered binary decision diagrams. We present a systemic way of synthesizing these decision diagrams based on a simple cascade model. We also describe a workflow for finding the emergency load curtailment actions as a part of the mitigation strategy. In the end, we show the applicability of our approach using the standard IEEE 14 bus system.", "num_citations": "1\n", "authors": ["572"]}
{"title": "An integrated cyber-physical fault management approach\n", "abstract": " Fault-tolerance in distributed cyber-physical systems involves a close interplay between the physical system: the 'plant' to be controlled and the distributed computing layer that controls it. In this paper, a systematic approach for designing resilient decentralized control applications is presented that considers both the cyber and physical faults and how they affect each other (if at all). It establishes a formal methodology for system design and then illustrates its use in an example application related to the power grid.", "num_citations": "1\n", "authors": ["572"]}
{"title": "DeepECO: Applying deep learning for occupancy detection from energy consumption data\n", "abstract": " Occupancy identification using Electricity Consumption data has been shown as an effective, non-intrusive strategy aiding the design of efficient Energy Management solutions. This paper introduces DeepECO, a Deep Learning framework for the Occupancy Classification task. It studies the impact of different feature selection algorithms, namely Principal Component Analysis (PCA) and a new game-theoretic approach called SHapley Additive exPlanation (SHAP) on the network performance. Three different metrics- Classification Accuracy, Mathew's Correlation Coefficient and F2 score are used for evaluation and comparison between the mentioned algorithms. The results obtained serve as a comprehensive evaluation of different feature selection methods for deep CNNs and their effectiveness in addressing the given problem.", "num_citations": "1\n", "authors": ["572"]}
{"title": "Deepnncar: A testbed for deploying and testing middleware frameworks for autonomous robots\n", "abstract": " This demo showcases the features of an adaptive middleware framework for resource constrained autonomous robots like DeepNNCar (Figure 1). These robots use Learning Enabled Components (LECs), trained with deep learning models to perform control actions. However, these LECs do not provide any safety guarantees and testing them is challenging. To overcome these challenges, we have developed an adaptive middleware framework that (1) augments the LEC with safety controllers that can use different weighted simplex strategies to improve the systems safety guarantees, and (2) includes a resource manager to monitor the resource parameters (temperature, CPU Utilization), and offload tasks at runtime. Using DeepNNCar we will demonstrate the framework and its capability to adaptively switch between the controllers and strategies based on its safety and speed performance.", "num_citations": "1\n", "authors": ["572"]}
{"title": "Dynamic symbolic execution for the analysis of web server applications in Java\n", "abstract": " Symbolic execution is a well-known program analysis technique that explores multiple program paths simultaneously. Among other things, it is used to uncover subtle bugs and corner cases in programs, as well as to produce high-coverage test suites. Even though symbolic execution has seen successful use in practice, there remain challenges in applying it to programs like web servers that use features such as multithreading and callbacks. This paper describes our dynamic symbolic execution framework for Java that was designed with these types of features in mind. Our framework uses bytecode instrumentation combined with a run-time agent to perform the symbolic execution. We give a detailed description of the challenges we faced along with our design choices. We also present benchmark results on various examples including programs that use web server frameworks.", "num_citations": "1\n", "authors": ["572"]}
{"title": "Resilient Information Architecture Platform for the Smart Grid\n", "abstract": " \u2013All app-level communications are protected by the CurveCP (elliptic curve encryption) on the messaging layer: ZeroMQ. All communications are protected via public/private keypairs, that are generated dynamically when the app is deployed. Keys are installed whenever an app-level network connection is established, and they are part of the deployment package, stored in a certificate store on the target nodes.", "num_citations": "1\n", "authors": ["572"]}
{"title": "Diagnosis in Cyber-Physical Systems with Fault Protection Assemblies\n", "abstract": " Fault Protection Assemblies are used in cyber-physical systems for automated fault-isolation. These devices alter the mode of the system using locally available information in order to stop fault propagation. For example, in electrical networks relays and breakers isolate faults in order to arrest failure propagation and protect the healthy parts of the system. However, these assemblies themselves can have faults, which may inadvertently induce secondary failures. Often these secondary failures lead to cascade effects, which then lead to total system collapse. This behavior is often seen in electrical transmission systems where failures of relays and breakers may cause overloading and the disconnection of parts of an otherwise healthy system. In the past, we had developed a consistency based diagnosis approach for physical systems based on the temporal failure propagation graph. We now describe an\u00a0\u2026", "num_citations": "1\n", "authors": ["572"]}
{"title": "SAFE AND SECURE CYBER  PHYSICAL SYSTEMS\n", "abstract": " Table of contents Page 1 9 Safety and Security in Cyber Physical Systems and Internet-ofThings Systems By M. Wolf and D. Serpanos |INVITED PAPER| This paper identifies key issues in the safety and security of CPSs and Internet-of-Things (IoT) systems as well as design-time and runtime approaches to handle safety and security. 21 System-on-Chip Platform Security Assurance: Architecture and Validation By S. Ray, E. Peeters, MM Tehranipoor, and S. Bhunia |INVITED PAPER| This paper surveys the security of VLSI systems-on-chip, identifies potential concerns, and proposes new approaches. 38 Wireless Communication and Security Issues for Cyber Physical Systems and the Internet-of-Things By A. Burg, A. Chattopadhyay, and K.-Y. Lam |INVITED PAPER| This paper looks at wireless communication used for CPS and IoT; the authors identify gaps between the vulnerabilities posed by cyber\u2013physical and \u2026", "num_citations": "1\n", "authors": ["572"]}
{"title": "Timing analysis of a middleware-based system\n", "abstract": " Component-based systems are often constructed with the help of a middleware layer that provides execution semantics for the components. If the implementations of the components use only the middleware services for concurrency, synchronization, and interactions then the analysis of the timing properties of such systems becomes feasible. In this paper we describe a particular middleware (the cFE/cFS from NASA) and introduce a model-based method for the end-to-end, stimulus-to-response timing analysis for systems built using it. The method is based on a timing model that uses Colored Petri Net to model the behavior of applications and the framework. The model is constructed based on the architecture of the application system and the behavior of the components and is analyzed using a state-space analysis tool. The paper gives illustrative examples for the feasibility and scalability of the approach.", "num_citations": "1\n", "authors": ["572"]}
{"title": "A systematic approach of identifying optimal load control actions for arresting cascading failures in power systems\n", "abstract": " Cascading outages in power networks cause blackouts which lead to huge economic and social consequences. The traditional form of load shedding is avoidable in many cases by identifying optimal load control actions. However, if there is a change in the system topology (adding or removing loads, lines etc), the calculations have to be performed again. This paper addresses this problem by providing a workflow that 1) generates system models from IEEE CDF specifications, 2) identifies a collection of blackout causing contingencies, 3) dynamically sets up an optimization problem, and 4) generates a table of mitigation strategies in terms of minimal load curtailment. We demonstrate the applicability of our proposed methodology by finding load curtailment actions for Nk contingencies (k= 1, 2, 3) in IEEE 14 Bus system.", "num_citations": "1\n", "authors": ["572"]}
{"title": "A domain-specific language for model composition and verification of multidisciplinary models\n", "abstract": " Complex, engineered products and manufacturing processes often necessitate integrated analysis that cuts across physical domains and engineering disciplines. When the domain-specific models that contribute to the overall analysis process are available then the problem can be addressed by composing them into an analysis workflow which then can be executed using some execution platform. Such a composition and integrated analysis is essentially a systems engineering approach applied to an engineering process. In this paper we describe a model integration language that allows the rapid composition of models, the verification of the composition and the generation of executable code and other engineering artifacts that are needed for model execution on a software platform. The language is based on OpenMDAO, a widely-used model execution framework, and it improves the engineering process by\u00a0\u2026", "num_citations": "1\n", "authors": ["572"]}
{"title": "Goal structured notation in a radiation hardening safety case for COTS-based spacecraft\n", "abstract": " A systematic approach is presented to constructing a radiation assurance case using Goal Structured Notation (GSN) for spacecraft containing COTS parts. The GSN paradigm is applied to an SRAM single-event upset experiment board designed to fly on a CubeSat November 2016. Construction of a radiation assurance case without use of hardened parts or extensive radiation testing is discussed.", "num_citations": "1\n", "authors": ["572"]}
{"title": "DVER: A tool chain for cross-validation and perfection of discrete model-based diagnostic systems\n", "abstract": " The safe and reliable operation of complex aerospace vehicles requires rapid and accurate detection and identification of system faults. Discrete model-based fault diagnostic systems (FDS) are often used when rapid real-time fault detection is needed. Given a vector of current discretized sensor readings, such a diagnostic algorithm produces fault hypotheses as its output. In this paper, we present DVER (Diagnostic VERification), a tool set to support the automation of validation and improvement of the central FDS components - the discrete model and associated sensor data processing capabilities. We present the results of applying the DVER tool chain to a modelbased FDS for the NASA Advanced Diagnostic and Prognostic Testbed (ADAPT) system, a testbed for a redundant electrical power distribution system.", "num_citations": "1\n", "authors": ["572"]}
{"title": "From system modeling to formal verification\n", "abstract": " Due to increasing design complexity, modern systems are modeled at a high level of abstraction. SystemC is widely accepted as a system level language for modeling complex embedded systems. Verification of these SystemC designs nullifies the chances of error propagation down to the hardware. Due to lack of formal semantics of SystemC, the verification of such designs is done mostly in an unsystematic manner. This paper provides a new modeling environment that enables the designer to simulate and formally verify the designs by generating SystemC code. The generated SystemC code is automatically translated to timed automata for formal analysis.", "num_citations": "1\n", "authors": ["572"]}
{"title": "Understanding Failure Dynamics in the Smart Electric Grid\n", "abstract": " Resilient and reliable operation of cyber-physical systems (CPS) of societal importance such as Smart Electric Grids is one of the top national priorities. Recent blackouts and hurricane Sandy in 2012 demonstrated grid vulnerability and gave reasons to look at existing defense mechanisms more closely. A recent study by North Electric Reliability Corporation (NERC) 1 states that relay or automatic control misoperations can account for nearly all major system events. Effect of failures in protection system components, protection settings, software tools, and human decisions impacting power system physical components are not captured either. In the absence of a system-wide integrated fault model, faults are identified by directly observing the associated anomaly or a set of anomalies as part of a pattern. However, this technique fails when a large number of alarms occur within a short time period. It has been noted\u00a0\u2026", "num_citations": "1\n", "authors": ["572"]}
{"title": "Drems: A toolchain and platform for the rapid application development, integration, and deployment of managed distributed real-time embedded systems\n", "abstract": " The DREMS1 toolsuite is a software infrastructure for designing, implementing, configuring, deploying, operating, and managing distributed real-time embedded systems. It consists of two major subsystems:(1) a design-time environment for modeling, analysis, synthesis, implementation, debugging, testing, and maintenance of application software built from reusable components, and (2) a run-time software platform for deploying, managing, and operating application software on a network of computing nodes. The platform is tailored towards a managed network of computers and distributed software applications running on that network: such as a cluster of networked nodes such as fractionated satellites or a group of smartphones deployed in a coordinated fashion to provide adhoc distributed services that can be used in disaster relief.It is a complete, end-to-end solution for software development: from modeling tools to code to deployed applications. Open and extensible, it relies on open industry (OMG) standards, well-tested functionality, and high-performance tools. It supports a model-based paradigm of software development for distributed, real-time, embedded systems where modeling tools and generators automate the tedious parts of software development and also provide a design-time framework for the analysis of the system. The run-time software platform reduces complexity and increases reliability of software applications by providing reusable technological building blocks: an operating system, middleware, and application management services.", "num_citations": "1\n", "authors": ["572"]}
{"title": "Component, Context, and Manufacturing Model Library (C2M2L)\n", "abstract": " Manufacturing process models are developed to describe manufacturing and assembly processes for an infantry fighting vehicle drivetrain in support of the first manufacturing challenge of the Defense Advanced Research Projects Agency DARPA Adaptive Vehicle Make AVM program. Machine and tool resources are characterized for manufacturing processes to provide a broad characterization of manufacturing process coverage in a hypothetical final assembly factory for infantry fighting vehicles. A sample population of manufacturing process parameters and resources is collected and incorporated into a manufacturing capability and process model library.Descriptors:", "num_citations": "1\n", "authors": ["572"]}
{"title": "The GDSE framework: a meta-tool for automated design space exploration\n", "abstract": " Existing Design Space Exploration (DSE) frameworks are tailored specifically to a particular problem domain and cannot be easily re-used between domains. Typically these frameworks translate the DSE problem to a single formulation of the problem (eg ILP or CSP) and then solve it to retrieve satisfying alternatives. In order to compare the efficiency of different formulations/techniques on a given problem, the domain-expert has to manually reformulate the problem in another constraint language, which is time-consuming. In order to overcome this lack of reusability and flexibility in the current frameworks, we present here the Generic Design Space Exploration (GDSE) framework that allows the designer to solve DSE problems from different domains. Rather than using one strict formulation of the design problem, the framework supports a higher level formulation that can be mapped to different low level encodings\u00a0\u2026", "num_citations": "1\n", "authors": ["572"]}
{"title": "Simulation of Network Security Attacks on SCADA Systems\n", "abstract": " Security is a major issue affecting SCADA systems, designed and deployed in the last decade. Simulation of network attacks on a SCADA system presents certain challenges, since even a simple SCADA system is composed of models in heterogenous domains and simulation environments. Here, we simulate a chemical plant and its controller, communicating through an ethernet network. We simulate and observe the effects of a common network attack on the availability of the system.", "num_citations": "1\n", "authors": ["572"]}
{"title": "Using Runtime Verification to Design a Reliable Execution Framework for Scientific Workflows\n", "abstract": " In this paper, we describe the design of a scientific workflow execution framework that integrates runtime verification to monitor its execution and checking it against the formal specifications. For controlling workflow execution, this framework provides for data provenance, execution tracking and online monitoring of each work flow task, also referred to as participants. The sequence of participants is described in an abstract parameterized view, which is used to generate concrete data dependency based sequence of participants with defined arguments. As participants belonging to a workflow are mapped onto machines and executed, periodic and on-demand monitoring of vital health parameters on allocated nodes is enabled according to pre-specified invariant conditions with actions to be taken upon violation of invariants.", "num_citations": "1\n", "authors": ["572"]}
{"title": "Third international workshop on graph and model transformations\n", "abstract": " Model transformation is an emerging paradigm used in model-driven software development. Graph transformations deal with rewriting operations on graphs, and as such can serve as a foundation for constructing model transformation language, tools, and systems. This workshop, the 3rd in a series, investigates the connection between graph and model transformations and intends to bring together interested researchers and practitioners from the two fields.", "num_citations": "1\n", "authors": ["572"]}
{"title": "High precision automatic scheduling of periodic task sets for microcontrollers\n", "abstract": " In low-end microcontroller systems task scheduling is often not done, or using very ad-hoc methods, or using a high-overhead RTOS. In this paper we offer an alternative: the design-time generation of high-precision schedules which are then executed using a minimal scheduler on a microcontroller. The schedules are derived from a simple task modeling language that allows the specification of properties of tasks, constraints on task execution, as well as worst-case interrupt rates and interrupt service execution times. An off-line scheduling algorithm then computes a schedule for the tasks specified which is then compiled and linked with a simple execution kernel that performs the scheduling. The paper describes the modeling language, the schedule computation approach used, the run-time kernel, as well as experimental results.", "num_citations": "1\n", "authors": ["572"]}
{"title": "Web-Based Open Tool Integration Framework\n", "abstract": " The OTIF project described in this report addressed the problem of building integrated design tool chains for embedded system development. The project has developed, implemented, and applied an open tool integration framework that provides a software infrastructure for building specific tool integration solutions. The framework is based on reusable components and industry-standard protocols, and uses metamodeling and model transformation technology to facilitate the tool integration task. The report summarizes the technological contributions of the project, and the actual prototype tool chains constructed.Descriptors:", "num_citations": "1\n", "authors": ["572"]}
{"title": "Distributed middleware services composition and synthesis technology\n", "abstract": " The highly distributed and resource constrained nature of computing in Networked Embedded Systems necessitates an application specific middleware\u2014a kind of distributed operating system that provides global services for the application. We propose to automatically synthesize the middleware from abstract, platform-independent algorithm models. The modeling language captures the temporal and computational aspects of the distributed algorithms in a programming language-independent and platform-neutral way. It supports the specification, composition and verification of middleware components, and allows the integration of existing platform-specific components. We have implemented a proof-of-concept prototype modeling environment, and used it to model and generate the middleware for a structural vibration damping application running on an I/O automata-based Java simulator, and for a cooperative acoustic tracking application running on TinyOS. The proposed formalism allows the creation of a platform-independent library of middleware services that can be used to build and synthesize various application-specific middleware instances.", "num_citations": "1\n", "authors": ["572"]}
{"title": "Fault tolerant issues in the BTeV trigger\n", "abstract": " The BTeV trigger performs sophisticated computations using large ensembles of FPGAs, DSPs, and conventional microprocessors. This system will have between 5,000 and 10,000 computing elements and many networks and data switches. While much attention has been devoted to developing efficient algorithms, the need for fault-tolerant, fault-adaptive, and flexible techniques and software to manage this huge computing platform has been identified as one of the most challenging aspects of this project. They describe the problem and offer an approach to solving it based on a distributed, hierarchical fault management system.", "num_citations": "1\n", "authors": ["572"]}
{"title": "Model-integrated computing environment\n", "abstract": " Model-Integrated Computing MIC was developed for building embedded software systems. The key element of this approach is the extension of the scope and usage of models such that they form the backbone of a model-integrated system development process. In Model-Integrated Computing models play the following central roles 1 Models can explicitly represent the designers understanding of the entire system, including the information processing architecture, the physical architecture, and the environment it operates in. 2 Integrated modeling allows the explicit representations of dependencies and constraints among the different modeling views. 3 Tools analyze different, but interdependent characteristics of systems such as performance, safety, reliability, etc.. Tool-specific model interpreters translate the information in the models to the input languages of analysis tools. Using MIC technology one can capture the requirements actual architecture, and the environment of a system in the form of high-level models. The requirement models allow the explicit representation of desired functionalities andor non-functional properties. The architecture models represent the actual structure of the system to be built, while the environment models capture what the outside world of the system looks like. These models act as a repository of information that is needed for analyzing and generating the system.Descriptors:", "num_citations": "1\n", "authors": ["572"]}
{"title": "On generators for embedded information systems\n", "abstract": " The sophisticated services provided by modern measurement systems and complex instruments are implemented almost exclusively in software. In fact, these instruments are embedded information systems where software components implement complex functions and act as the system integrator. The development of these software systems is crucial for achieving the desired quality and precision in a measurement system. In this paper, we present an approach to the development of complex embedded software systems through the use of generators. Software generators are software engineering tools that translate high-level, domain-specific models into executable systems. The key elements of this technology are domain modeling and automatic code generation resulting in the ability to reuse design solutions.", "num_citations": "1\n", "authors": ["572"]}
{"title": "An Approach to Self-adaptive Software Based on Supervisory Control\n", "abstract": " Self-adaptive software systems use observations of their own behav-ior, and that of their environment, to select and enact adaptations in accordance with some objective (s). This adaptation is a higher-level system function that performs optimizations, manages faults, or otherwise supports achieving an ob-jective via changes in the running system. In this paper, we show how this capability can be realized using techniques found in hierarchical control systems, and we discuss interrelated issues of stability, assurance, and implementation.", "num_citations": "1\n", "authors": ["572"]}
{"title": "Integration of Design Tools and Semantic Interoperability\n", "abstract": " The integration of software tools used in an engineering process is a problem that arises frequently in large-scale projects. Simple solutions for integration are insufficient in the case of complex engineering tools and processes. The integration solution must also account for the evolution of the system, as tools and processes change over time. This paper shows a new approach to the problem, describes the supporting infrastructure, and discusses the background model-integrated generation technology.", "num_citations": "1\n", "authors": ["572"]}
{"title": "Models, Patterns, and Generators for Embedded Systems\n", "abstract": " Model-based development of embedded information systems necessitates the use of generative techniques. Models determine and configure computations, but they also lend themselves to design-time analysis. This paper discusses why generative techniques are important for embedded systems, outlines how a general-purpose generator technology can be built to help the engineering of complex applications. However, a number of technical problems have to be solved before generators will become an everyday tool in embedded software development, related to the construction, verification, and usability of generators.", "num_citations": "1\n", "authors": ["572"]}
{"title": "Parallel DSP system integration\n", "abstract": " Heterogeneous parallel computer architectures with flexible topology, such as transputer or TMS320C40 networks with special purpose coprocessors, are ideal hardware candidates for many signal processing and instrumentation applications. The management of the hardware complexity of large systems, however, presents serious problems. This paper describes a model-based approach to deal with them. The novel features of this method include hierarchical modelling, dual (graphical and declarative) model representation and automatic model analysis. The merits of the approach include the formal representation of the system design, intelligent hardware diagnostic support and fast message routing map and network loader information generation.", "num_citations": "1\n", "authors": ["572"]}
{"title": "Model-based programming tools for integrated monitoring, simulation, diagnosis and control\n", "abstract": " This paper presents a software technique which is useful for building the monitoring, simulation, diagnosis and control software for complex systems, like the ones found in aerospace systems. The technique is based on the extensive use of models, which include description of the equipment as well as the software configuration itself. The system has been successfully used in various practical applications, and it is being evaluated by various sites.The development of complex automation systems, like the ones in aerospace systems, is a formidable task. People implementing these systems must have training both in the methods of the domain engineering, as well as in software engineering. The two fields are not separable, because almost all of the monitoring and control systems are now computer-based which means\" implemented in software\".", "num_citations": "1\n", "authors": ["572"]}
{"title": "INDICES: Applying DDDAS Principles for Performance Interference-aware Cloud-to-Fog Application Migration\n", "abstract": " An increasing number of interactive applications and services, such as online gaming and cognitive assistance, are being hosted in the cloud because of its elastic properties and cost benefits. Despite these benefits, the longer and often unpredictable end-to-end network latencies between the end user and the cloud can be detrimental to the response time requirements of the applications. Although technology enablers, such as Cloudlets or Micro Data Centers (MDCs), are increasingly being leveraged by cloud infrastructure providers to address the network latency concerns, existing efforts in re-provisioning services from the cloud to the MDCs seldom focus on ensuring that the performance properties of the migrated services are met. This chapter demonstrates the application of DDDAS principles to address these limitations by:(a) determining when to re-provision;(b) identifying the appropriate MDC and a suitable host within that MDC that meets the performance considerations of the applications; and (c) ensuring that the cloud service provider continues to meet customer service-level objectives while keeping its operational", "num_citations": "1\n", "authors": ["572"]}
{"title": "A rapid testing framework for a mobile cloud infrastructure\n", "abstract": " Mobile clouds such as network-connected vehicles and satellite clusters are an emerging class of systems that are extensions to traditional real-time embedded systems: they provide long-term mission platforms made up of dynamic clusters of heterogeneous hardware nodes communicating over ad hoc wireless networks. Besides the inherent complexities entailed by a distributed architecture, developing software and testing these systems is difficult due to a number of other reasons, including the mobile nature of such systems, which can require a model of the physical dynamics of the system for accurate simulation and testing. This paper describes a rapid development and testing framework for a distributed satellite system. Our solutions include a modeling language for configuring and specifying an application\u2019s interaction with the middleware layer, a physics simulator integrated with hardware in the loop to provide the system\u2019s physical dynamics and the integration of a network traffic tool to dynamically vary the network bandwidth based on the physical dynamics.", "num_citations": "1\n", "authors": ["572"]}
{"title": "The ESMoL language and tools for high-confidence distributed control systems design. Part 1: Design language, modeling framework, and analysis\n", "abstract": " Consider the general class of control system designs for use in a flight control system. Sensors, actuators, and data networks are designed redundantly to mitigate faults. The underlying platform implements a variant of the time-triggered architecture (TTA)[1], which provides precise timing and reliability guarantees. Safetycritical tasks and messages execute according to strict precomputed schedules to ensure synchronization between replicated components and provide fault mitigation and management. Deployed software implementations of the control functions must pass strict certification requirements which impose constraints on the software as well as on the development process. The additional burden of design analysis required to establish safety increases cost and schedule, decreasing the flexibility of the development process. In modern embedded control system designs, graphical modeling and simulation tools (eg Mathworks\u2019 Simulink/Stateflow) represent physical systems and engineering designs using block diagram notations. Design work revolves around simulation and test cases, with code generated from models when the design team reaches particular schedule milestones. Control designs often ignore software design constraints and issues arising from embedded platform choices. At early stages of the design, platforms may be vaguely specified to engineers as sets of trade offs [2].Software development uses Unified Modeling Language Computer-Aided Software Engineering (UML CASE) tools to capture concepts such as types, components, interfaces, interactions, timing, fault handling, and deployment. Software\u00a0\u2026", "num_citations": "1\n", "authors": ["572"]}