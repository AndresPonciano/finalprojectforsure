{"title": "Model evolution by run-time parameter adaptation\n", "abstract": " Models can help software engineers to reason about design-time decisions before implementing a system. This paper focuses on models that deal with non-functional properties, such as reliability and performance. To build such models, one must rely on numerical estimates of various parameters provided by domain experts or extracted by other similar systems. Unfortunately, estimates are seldom correct. In addition, in dynamic environments, the value of parameters may change over time. We discuss an approach that addresses these issues by keeping models alive at run time and feeding a Bayesian estimator with data collected from the running system, which produces updated parameters. The updated model provides an increasingly better representation of the system. By analyzing the updated model at run time, it is possible to detect or predict if a desired property is, or will be, violated by the running\u00a0\u2026", "num_citations": "339\n", "authors": ["634"]}
{"title": "Self-adaptive software needs quantitative verification at runtime\n", "abstract": " Continually verify self-adaptation decisions taken by critical software in response to changes in the operating environment.", "num_citations": "328\n", "authors": ["634"]}
{"title": "Moses: A framework for qos driven runtime adaptation of service-oriented systems\n", "abstract": " Architecting software systems according to the service-oriented paradigm and designing runtime self-adaptable systems are two relevant research areas in today's software engineering. In this paper, we address issues that lie at the intersection of these two important fields. First, we present a characterization of the problem space of self-adaptation for service-oriented systems, thus providing a frame of reference where our and other approaches can be classified. Then, we present MOSES, a methodology and a software tool implementing it to support QoS-driven adaptation of a service-oriented system. It works in a specific region of the identified problem space, corresponding to the scenario where a service-oriented system architected as a composite service needs to sustain a traffic of requests generated by several users. MOSES integrates within a unified framework different adaptation mechanisms. In this way it\u00a0\u2026", "num_citations": "226\n", "authors": ["634"]}
{"title": "Qos-driven runtime adaptation of service oriented architectures\n", "abstract": " Runtime adaptation is recognized as a viable way for a service-oriented system to meet QoS requirements in its volatile operating environment. In this paper we propose a methodology to drive the adaptation of such a system, that integrates within a unified framework different adaptation mechanisms, to achieve a greater flexibility in facing different operating environments and the possibly conflicting QoS requirements of several concurrent users. To determine the most suitable adaptation action (s), the methodology is based on the formulation and solution of a linear programming problem, which is derived from a behavioral model of the system updated at runtime by a monitoring activity. Numerical experiments show the effectiveness of our approach. Besides the methodology, we also present a prototype tool that implements it.", "num_citations": "172\n", "authors": ["634"]}
{"title": "Filling the gap between design and performance/reliability models of component-based systems: A model-driven approach\n", "abstract": " To facilitate the use of non-functional analysis results in the selection and assembly of components for component-based systems, automatic prediction tools should be devised, to predict some overall quality attribute of the application without requiring extensive knowledge of analysis methodologies to the application designer. To achieve this goal, a key idea is to define a model transformation that takes as input some \u201cdesign-oriented\u201d model of the component assembly and produces as a result an \u201canalysis-oriented\u201d model that lends itself to the application of some analysis methodology. However, to actually devise such a transformation, we must face both the heterogeneous design level notations for component-based systems, and the variety of non-functional attributes and related analysis methodologies we could be interested in. To tackle these problems, we define a model-driven transformation framework\u00a0\u2026", "num_citations": "132\n", "authors": ["634"]}
{"title": "Quality prediction of service compositions through probabilistic model checking\n", "abstract": " The problem of composing services to deliver integrated business solutions has been widely studied in the last years. Besides addressing functional requirements, services compositions should also provide agreed service levels. Our goal is to support model-based analysis of service compositions, with a focus on the assessment of non-functional quality attributes, namely performance and reliability. We propose a model-driven approach, which automatically transforms a design model of service composition into an analysis model, which then feeds a probabilistic model checker for quality prediction. To bring this approach to fruition, we developed a prototype tool called ATOP, and we demonstrate its use on a simple case study.", "num_citations": "123\n", "authors": ["634"]}
{"title": "From design to analysis models: a kernel language for performance and reliability analysis of component-based systems\n", "abstract": " To facilitate the use of non-functional analysis results in the selection and assembly of components for component-based systems, automatic prediction tools should be devised, to predict some overall quality attribute of the application without requiring extensive knowledge of analysis methodologies to the application designer. To achieve this goal, a key idea is to define a model transformation that takes as input some\" design-oriented\" model of the component assembly and produces as a result an\" analysis-oriented\" model that lends itself to the application of some analysis methodology. However, to actually devise such a transformation, we must face both the heterogeneous design level notations for component-based systems, and the variety of non-functional attributes and related analysis methodologies we could be interested in. In this perspective, we define a kernel language whose aim is to capture the\u00a0\u2026", "num_citations": "115\n", "authors": ["634"]}
{"title": "Per-flow optimal service selection for web services based processes\n", "abstract": " With the development of the Service-Oriented Computing (SOC) paradigm, flexible business processes can be defined from independently developed services. Multiple services corresponding to the same functionality but characterized by different Quality of Service (QoS) attributes can be offered by different service providers and the best set of Web services can be selected at run-time in order to maximize the QoS for end users.In the literature many approaches have been proposed for the optimal service selection which is usually performed on a per-request basis, i.e., considering a single process invocation. In this paper we propose a broker-based framework which solves the optimal service selection on a per-flow basis. Multiple applications, defined as different BPEL processes are considered at the same time and multiple requests to the same process are optimized concurrently.Service selection is formulated\u00a0\u2026", "num_citations": "81\n", "authors": ["634"]}
{"title": "Performance prediction of web service workflows\n", "abstract": " Web Services play an important role in the SOA paradigm, as they allow services to be selected on-the-fly to build applications out of existing components. In this scenario, the BPEL notation can be used as an orchestration language which allows the user to describe interactions with Web Services in a standard way. The performance of a BPEL workflow is a very important factor for deciding which components must be selected, or to choose whether a given sequence of interactions can provide the requested quality of service. Due to its very dynamic nature, workflow performance evaluation can not be accomplished using traditional, heavy-weight techniques. In this paper we present a multi-view approach for the performance prediction of service-based applications encompassing both users and service provider(s) perspectives. As a first step towards the realization of this integrated framework we present\u00a0\u2026", "num_citations": "80\n", "authors": ["634"]}
{"title": "Reliability analysis of component-based systems with multiple failure modes\n", "abstract": " This paper presents a novel approach to the reliability modeling and analysis of a component-based system that allows dealing with multiple failure modes and studying the error propagation among components. The proposed model permits to specify the components attitude to produce, propagate, transform or mask different failure modes. These component-level reliability specifications together with information about systems global structure allow precise estimation of reliability properties by means of analytical closed formulas, probabilistic model-checking or simulation methods. To support the rapid identification of components that could heavily affect systems reliability, we also show how our modeling approach easily support the automated estimation of the system sensitivity to variations in the reliability properties of its components. The results of this analysis allow system designers and developers to\u00a0\u2026", "num_citations": "76\n", "authors": ["634"]}
{"title": "Rethinking the use of models in software architecture\n", "abstract": " Models play a central role in software engineering. They may be used to reason about requirements, to identify possible missing parts or conflicts. They may be used at design time to analyze the effects and trade-offs of different architectural choices before starting an implementation, anticipating the discovery of possible defects that might be uncovered at later stages, when they might be difficult or very expensive to remove. They may also be used at run time to support continuous monitoring of compliance of the running system with respect to the desired model. This paper focuses on models that support reasoning about non-functional system properties \u2014 namely, performance and reliability. It provides a taxonomy, which tries to capture the main facets that are needed to understand, choose, and use models appropriately in the various phases of software development and operation. The paper also\u00a0\u2026", "num_citations": "67\n", "authors": ["634"]}
{"title": "A UML profile to model mobile systems\n", "abstract": " The introduction of adaptation features in the design of applications that operate in a mobile computing environment has been suggested as a viable solution to cope with the high heterogeneity and variability of this environment. Mobile code paradigms can be used to this purpose, since they allow to dynamically modify the load of the hosting nodes and the internode traffic, to adapt to the resources available in the nodes and to the condition of the (often wireless) network link. In this paper we propose a UML profile to deal with all the relevant issues of a mobile system, concerning the mobility of both physical (e.g. computing nodes) and logical (e.g. software components) entities. The profile is defined as a lightweight customization of the UML 2.0 metamodel, so remaining fully compliant with it. In the definition of this profile, the underlying idea has been to model mobility (in both physical and logical sense\u00a0\u2026", "num_citations": "63\n", "authors": ["634"]}
{"title": "KLAPER: An Intermediate Language for Model-Driven Predictive Analysis of Performance and Reliability\n", "abstract": " Automatic prediction tools play a key role in enabling the application of non-functional analysis to the selection and the assembly of components for component-based systems, without requiring extensive knowledge of analysis methodologies to the application designer. A key idea to achieve this goal is to define a model transformation that takes as input some \u201cdesign-oriented\u201d model of the component assembly and produces as a result an \u201canalysis-oriented\u201d model that lends itself to the application of some analysis methodology. For this purpose, we define a model-driven transformation framework, centered around a kernel language whose aim is to capture the relevant information for the analysis of non-functional attributes of component-based systems, with a focus on performance and reliability. Using this kernel language as a bridge between design-oriented and analysis-oriented notations we reduce\u00a0\u2026", "num_citations": "49\n", "authors": ["634"]}
{"title": "A framework for optimal service selection in broker-based architectures with multiple QoS classes\n", "abstract": " Service composition is one of the most promising advantages of the service-oriented paradigm. In a service market scenario, given a functional description of a service, different providers may offer diverse service implementations that match such a functional description but differ for some QoS attributes. A key point for the construction of a suitable composition is the selection of the services that best meet the QoS requirements of the composite service users. In this paper, we consider a broker-based architecture for service composition, focusing on the service selection problem and assuming that the broker supports different QoS classes. We formulate the service selection as a constrained optimization problem, where each QoS class is modeled by suitable constraints. Differently from most of the existing approaches to service selection, in our approach the broker optimizes the overall QoS of a flow of requests rather\u00a0\u2026", "num_citations": "49\n", "authors": ["634"]}
{"title": "A model-driven approach to performability analysis of dynamically reconfigurable component-based systems\n", "abstract": " Dynamic reconfiguration techniques appear promising to build component-based (CB) systems for application domains that have strong adaptability requirements, like the mobile and the service-oriented computing domains. However, introducing dynamic reconfiguration features into a CB application makes even more challenging the design and verification of functional and non functional requirements. Our goal is to support the model-based analysis of the effectiveness of reconfigurable CB applications, with a focus on the assessment of the non-functional performance and reliability attributes. As a first step towards this end, we address the issue of selecting suitable analysis models for reconfigurable systems, suggesting to this end the use of joint performance and reliability (performability) models. Furthermore, we propose a model-driven approach to automatically transform a design model into an analysis\u00a0\u2026", "num_citations": "48\n", "authors": ["634"]}
{"title": "Klapersuite: An integrated model-driven environment for reliability and performance analysis of component-based systems\n", "abstract": " Automatic prediction tools play a key role in enabling the application of non-functional requirements analysis to selection and assembly of components for Component-Based Systems, reducing the need for strong mathematical skills to software designers. Exploiting the paradigm of Model Driven Engineering (MDE), it is possible to automate transformations from design models to analytical models, enabling for formal property verification. MDE is the core paradigm of KlaperSuite presented in this paper, which exploits the KLAPER pivot language to fill the gap between Design and Analysis of Component-Based Systems for reliability and performance properties. KlaperSuite is a family of tools empowering designers with the ability to capture and analyze QoS views of their systems by building a one-click bridge towards a number of established verification instruments.", "num_citations": "43\n", "authors": ["634"]}
{"title": "Adaptation space exploration for service-oriented applications\n", "abstract": " Service-oriented applications may require adaptation to tackle changing user needs, system intrusions or faults, changing operational environment, resource variability, etc. In order to achieve the right trade off among the functional requirements, software qualities (such as performance and reliability) and the adaptation cost itself, the adaptation decisions should involve the (a priori) evaluation of new alternatives to the current application design. However, the generation and evaluation of design alternatives is often time-consuming, it can be error-prone and can lead to suboptimal design decisions, especially if carried out manually by system maintainers.This article proposes an automatic optimization process for adaptation space exploration of service-oriented applications based on trade-offs between functional and extra-functional requirements. The proposed method combines the use of metaheuristic search\u00a0\u2026", "num_citations": "41\n", "authors": ["634"]}
{"title": "Towards self-adaptation for dependable service-oriented systems\n", "abstract": " Increasingly complex information systems operating in dynamic environments ask for management policies able to deal intelligently and autonomously with problems and tasks. An attempt to deal with these aspects can be found in the Service-Oriented Architecture (SOA) paradigm that foresees the creation of business applications from independently developed services, where services and applications build up complex dependencies. Therefore the dependability of SOA systems strongly depends on their ability to self-manage and adapt themselves to cope with changes in the operating conditions and to meet the required dependability with a minimum of resources. In this paper we propose a model-based approach to the realization of self-adaptable SOA systems, aimed at the fulfillment of dependability requirements. Specifically, we provide a methodology driving the system adaptation and we discuss\u00a0\u2026", "num_citations": "40\n", "authors": ["634"]}
{"title": "Model-driven assessment of qos-aware self-adaptation\n", "abstract": " One of the main goals of a self-adaptable software system is to meet the required Quality of Service (QoS) by autonomously modifying its structure/behavior in response to changes in the supporting infrastructure and surrounding physical environment. A key issue in the design and development of such system is the assessment of their effectiveness, both in terms of their ability to meet the required QoS under different operating conditions, and in terms of the costs involved by the reconfiguration process, which could outweigh the benefit of the reconfiguration. This paper introduces an approach to support this assessment, with a focus on performance and dependability attributes. Our approach is based on the idea of defining a model transformation chain that maps a \u201cdesign oriented\u201d model of the system to an \u201canalysis oriented\u201d model that lends itself to the application of a suitable analysis methodology. We\u00a0\u2026", "num_citations": "40\n", "authors": ["634"]}
{"title": "PRIMAmob-UML: a methodology for performance analysis of mobile software architectures\n", "abstract": " Different paradigms (client-server, mobility based, etc.) have been suggested and adopted to cope with the complexity of designing the software architecture of distributed applications for wide area environments, and selecting the\" best\" paradigm is a typical choice to be made in the very early software design phases. Several factors should drive this choice, one of them being the impact of the adopted paradigm on the application performance. Within this framework our contribution is as follows: we apply an extension of UML to better modelling the possible adoption of mobility-based paradigms in the software architecture of an application; we extend classical models, like queueing networks models and execution graphs, to cope with mobile architectures; we introduce a complete methodology that, starting from a software architecture described using this extended notation, generates a performance model (namely\u00a0\u2026", "num_citations": "38\n", "authors": ["634"]}
{"title": "A method for the prediction of software reliability\n", "abstract": " This paper deals with the reliability assessment of component-based software to predict the software product reliability at the early stage. The proposed approach transforms a specification written in a semi-formal language into a stochastic model to be used for reliability evaluation. The paper assumes an UML-based system specification and introduces a method to map the specification onto a failure model.The method enables software designers with no specific knowledge of reliability theory to predict at design time the reliability of the final product, thus introducing lifecycle reliability prediction into their development best practices. The method is illustrated by use of an application case study that deals with the development of distributed software.", "num_citations": "36\n", "authors": ["634"]}
{"title": "QoS-driven web services selection in autonomic grid environments\n", "abstract": " In the Service Oriented Architecture (SOA) complex applications can be described as business processes from independently developed services that can be selected at run time on the basis of the provided Quality of Service (QoS). However, QoS requirements are difficult to satisfy especially for the high variability of Internet application workloads. Autonomic grid architectures, which provide basic mechanisms to dynamically re-configure service center infrastructures, can be be exploited to fullfill varying QoS requirements. We tackle the problem of selection of Web services that assure the optimum mapping between each abstract Web service of a business process and a Web service which implements the abstract description, such that the overall quality of service perceived by the user is maximized. The proposed solution guarantees the fulfillment of global constraints, considers variable quality of service\u00a0\u2026", "num_citations": "32\n", "authors": ["634"]}
{"title": "A quality driven extension to the QVT-relations transformation language\n", "abstract": " An emerging approach to software development is Model Driven Software Development     (MDSD). It shifts the focus from source code to models, aims at cost reduction, risk     mitigation, and eases the engineering of complex applications. System models can be     used in the early development stages to verify certain relevant properties, such as     performance, before source code is available and problems become hard and costly to     solve. The present status of Model Driven Engineering (MDE) is still far from this     ideal situation. A well-known problem is feedback provisioning, which arises when     different solutions for the same design problem exist. An approach for feedback     provisioning automation leverages model transformations, which glue together models     in an MDSD setting, encapsulate the design rationale, and promote knowledge reuse     and solutions otherwise available only to\u00a0\u2026", "num_citations": "29\n", "authors": ["634"]}
{"title": "An online learning model based on episode mining for workload prediction in cloud\n", "abstract": " The resource provisioning is one of the challenging problems in the cloud environment. The resources should be allocated dynamically according to the demand changes of the applications. Over-provisioning increases energy wasting and costs. On the other hand, under-provisioning causes Service Level Agreements (SLA) violation and Quality of Service (QoS) dropping. Therefore the allocated resources should be close to the current demand of applications as much as possible. Thus, the prediction of the future workload of applications is an essential step before the resource provisioning. In our previous work, we proposed a Prediction mOdel based on SequentIal paTtern mINinG (POSITING), which considers the correlation between different resources and extracts behavioural patterns of applications independently of the fixed pattern length explicitly. Although POSITING provides reliable results, it is not able to\u00a0\u2026", "num_citations": "26\n", "authors": ["634"]}
{"title": "Towards quality driven exploration of model transformation spaces\n", "abstract": " Verifying that a software system has certain non-functional properties is a primary concern in many engineering fields. Although several model-driven approaches exist to predict quality attributes from system models, they still lack the proper level of automation envisioned by Model Driven Software Development. When a potential issue concerning non-functional properties is discovered, the identification of a solution is still entirely up to the engineer and to his/her experience. This paper presents QVT-Rational, our multi-modeling solution to automate the detection-solution loop. We leverage and extend existing model transformation techniques with constructs to elicit the space of the alternative solutions and to bind quality properties to them. Our framework is highly customizable, it supports the definition of non-functional requirements and provides an engine to automatically explore the solution space. We\u00a0\u2026", "num_citations": "26\n", "authors": ["634"]}
{"title": "Efficient performance models in component-based software engineering\n", "abstract": " Performance evaluation of component-based software systems should be performed as early as possible during the software development life cycle. Unfortunately, a detailed quantitative analysis is often not possible during such stages, as only the system outline is available, with very little quantitative knowledge. In this paper we propose an approach based on queueing network analysis for performance evaluation of component-based software systems at the software architectural level. Our approach provides performance bounds which can be efficiently computed. Starting from annotated UML diagrams we compute bounds on the system throughput and response time without explicitly deriving or solving the underlying multichain and multiclass queueing network model. We illustrate with an example how the technique can be applied to answer many performance-related questions which may arise during the\u00a0\u2026", "num_citations": "26\n", "authors": ["634"]}
{"title": "Model driven qos analyses of composed web services\n", "abstract": " The problem of composing services to deliver integrated business solutions has been widely studied in the last years. Besides addressing functional requirements, services compositions should also provide agreed service levels. Our goal is to support model-based analysis of service compositions, with a focus on the assessment of non-functional quality attributes, namely performance and reliability. We propose a model-driven approach, which automatically selects the set of available services, transforms a design model of service composition into an analysis model, which then feeds a probabilistic model checker for quality prediction. To bring this approach to fruition, we developed a prototype tool and we show the results which can be achieved with a simple example.", "num_citations": "25\n", "authors": ["634"]}
{"title": "A model transformation approach for the early performance and reliability analysis of component-based systems\n", "abstract": " The adoption of a \u201chigh level\u201d perspective in the design of a component-based application, without considering the specific features of some underlying supporting platform, has the advantage of focusingon the relevant architectural aspects and reasoning about them in a platform independent way, omitting unnecessary details that could even not be known at the earliest development stages.On the other hand, many of the details that are typically neglected in this high-level perspective must necessarily be taken into account to obtain a meaningful evaluation of different architectural choices in terms of extra-functional quality attributes, like performance or reliability. Toward the reconciliation of these two contrasting needs, we propose a model-based approach whose goal is to support the derivation of sufficiently detailed prediction models from high level models of component-based systems, focusing on the\u00a0\u2026", "num_citations": "25\n", "authors": ["634"]}
{"title": "UML based modeling and performance analysis of mobile systems\n", "abstract": " The high heterogeneity and variability of mobile computing environments can adversely affect the performance of applications running in these environments. To tackle this problem, adaptation techniques can be exploited. Adaptation based on code mobility is a possible solution, as it allows to dynamically modify the load of the hosting nodes and the internode traffic, to adapt to the changing characteristics of computing nodes and network links. In this paper we propose a modeling framework to analyze the performance effectiveness of code mobility based adaptation in a mobile computing environment. A distinguishing feature of our framework is the modeling of both physical and logical mobility as something that can be\" plugged\" into a pre-existing architecture model, to ease the analysis of the performance impact of both different physical mobility scenarios, and of different adaptation strategies based on code\u00a0\u2026", "num_citations": "25\n", "authors": ["634"]}
{"title": "Towards automatic compositional performance analysis of component-based systems\n", "abstract": " To make predictive analysis an effective tool for component-based software development (CBSD), it should be, as much as possible: compositional, to allow the re-use of known information about the properties of existing components, and automatic, to keep the pace with the timeliness and cost-effectiveness promises of CBSD. Towards this end, focusing on the predictive analysis of performance properties, we define a simple language, based on an abstract component model, to describe a component assembly, outlining which information should be included in it to support compositional performance analysis. Moreover, we outline a mapping of the constructs of the proposed language to elements of the RT-UML Profile, to give them a precisely defined \"performance semantics\", and to get a starting point for the exploitation of proposed UML-based methodologies and algorithms for performance analysis.", "num_citations": "25\n", "authors": ["634"]}
{"title": "A sequential pattern mining model for application workload prediction in cloud environment\n", "abstract": " The resource provisioning is one of the challenging problems in the cloud environment. The resources should be allocated dynamically according to the demand changes of the applications. Over-provisioning increases energy wasting and costs. On the other hand, under-provisioning causes Service Level Agreements (SLA) violation and Quality of Service (QoS) dropping. Therefore the allocated resources should be close to the current demand of applications as much as possible. For this purpose, the future demand of applications should be determined. Thus, the prediction of the future workload of applications is an essential step before the resource provisioning. To the best of our knowledge, for the first time, this paper proposes a novel Prediction mOdel based on SequentIal paTtern mINinG (POSITING) that considers correlation between different resources and extracts behavioural patterns of applications\u00a0\u2026", "num_citations": "24\n", "authors": ["634"]}
{"title": "GoPrime: A Fully Decentralized Middleware for Utility-Aware Service Assembly\n", "abstract": " Modern applications, e.g., for pervasive computing scenarios, are increasingly reliant on systems built from multiple distributed components, which must be suitably composed to meet some specified functional and non-functional requirements. A key challenge is how to efficiently and effectively manage such complex systems. The use of self-management capabilities has been suggested as a possible way to address this challenge. To cope with the scalability and robustness issues of large distributed systems, self-management should ideally be architected in a decentralized way, where the overall system behavior emerges from local decisions and interactions. Within this context, we propose GOPRIME, a fully decentralized middleware solution for the adaptive self-assembly of distributed services. The GOPRIME goal is to build and maintain an assembly of services that, besides functional requirements, fulfils also\u00a0\u2026", "num_citations": "24\n", "authors": ["634"]}
{"title": "A reliability model for service component architectures\n", "abstract": " Service-oriented applications are dynamically built by assembling existing, loosely coupled, distributed, and heterogeneous services. Predicting their reliability is very important to appropriately drive the selection and assembly of services, to evaluate design feasibility, to compare design alternatives, to identify potential failure areas and to maintain an acceptable reliability level under environmental extremes.This article presents a model for predicting reliability of a service-oriented application based on its architecture specification in the lightweight formal language SCA-ASM. The SCA-ASM component model is based on the OASIS standard Service Component Architecture for heterogeneous service assembly and on the formal method Abstract State Machines for modeling service behavior, interactions, and orchestration in an abstract but executable way.The proposed method provides an automatic and\u00a0\u2026", "num_citations": "21\n", "authors": ["634"]}
{"title": "MANTra: Towards model transformation testing\n", "abstract": " Model-driven development is gaining importance in software engineering practice. This increasing usage asks for a new generation of testing tools to verify correctness and suitability of model transformations. This paper presents a novel approach to unit testing QVT Operational (QVTO) transformations, which overcomes limitations of currently available tools. Our proposal, called MANTra (Model transformation Testing), allows software developers to design test cases directly within the QVTO language and verify them without moving from the transformation environment.", "num_citations": "20\n", "authors": ["634"]}
{"title": "Run-time resource management in SOA virtualized environments\n", "abstract": " Service Oriented Architecture (SOA) and virtualization of physical resources are key emerging technologies which are driving the interest of research both from industry and academia. The combination of the two is leading to a new paradigm-the Service Oriented Infrastructure-(SOI) whose goal is to provide a flexible solution for accessing component based service applications on demand.", "num_citations": "20\n", "authors": ["634"]}
{"title": "Derivation of markov models for effectiveness analysis of adaptable software architectures for mobile computing\n", "abstract": " Adaptable software architectures (SA) have been suggested as a viable solution for the design of distributed applications that operate in a mobile computing environment to cope with the high heterogeneity and variability of this environment. Mobile code techniques can be used to implement this kind of SA since they allow us to dynamically modify the load of the hosting nodes and the internode traffic to adapt to the resources available in the nodes and to the condition of the (often wireless) network link. However, moving code among nodes has a cost (e.g., in terms of network traffic and consumed energy for mobile nodes), so designing an adaptable SA based on mobile code techniques requires a careful analysis to determine its effectiveness from the early design stages. In this respect, our main contribution consists of a methodology, called ASAP (adaptable software architectures performance), to automatically\u00a0\u2026", "num_citations": "20\n", "authors": ["634"]}
{"title": "UML modelling and performance analysis of mobile software architectures\n", "abstract": " Modern distributed software applications generally operate in complex and heterogeneous computing environments (like the World Wide Web). Different paradigms (client-server, mobility based, etc.) have been suggested and adopted to cope with the complexity of designing the software architecture of distributed applications for such environments, and deciding the \u201cbest\u201d paradigm is a typical choice to be made in the very early software design phases. Several factors should drive this choice, one of them being the impact of the adopted paradigm on the application performance. Within this framework, the contribute of this paper is twofold: we suggest an extension of UML to best modeling the possible adoption of mobility-based paradigms in the software architecture of an application; we introduce a complete methodology that, starting from a software architecture described using this extended notation\u00a0\u2026", "num_citations": "20\n", "authors": ["634"]}
{"title": "Reinforcement learning techniques for decentralized self-adaptive service assembly\n", "abstract": " This paper proposes a self-organizing fully decentralized solution for the service assembly problem, whose goal is to guarantee a good overall quality for the delivered services, ensuring at the same time fairness among the participating peers. The main features of our solution are: (i) the use of a gossip protocol to support decentralized information dissemination and decision making, and (ii) the use of a reinforcement learning approach to make each peer able to learn from its experience the service selection rule to be followed, thus overcoming the lack of global knowledge. Besides, we explicitly take into account load-dependent quality attributes, which lead to the definition of a service selection rule that drives the system away from overloading conditions that could adversely affect quality and fairness. Simulation experiments show that our solution self-adapts to occurring variations by quickly converging\u00a0\u2026", "num_citations": "19\n", "authors": ["634"]}
{"title": "Qos analysis for web service applications: a survey of performance-oriented approaches from an architectural viewpoint\n", "abstract": " Building applications from independently developed services is one of the current trends in software development. In this context, the quality\u2013and specifically performance\u2013of a composition of services is a crucial factor for deciding which components must be selected, or to choose whether a given sequence of interactions can provide the requested quality of service. To achieve this goal, different methods and tools to capture and analyze the performance of web services have been developed. These methods and tools aim at helping Web service providers and consumers to understand design trade-offs, optimize the system by identifying performance bottlenecks, or analyze the system performance within a specified deployment environment. The goal of this paper to propose an initial taxonomy for analyzing the existing performance prediction and analysis methods for the development of service-based systems. Then, we use this taxonomy to discuss the strengths and weaknesses of different performance prediction approaches, trying to establish a basis to select an appropriate prediction method and to provide recommendations for future research activities.", "num_citations": "18\n", "authors": ["634"]}
{"title": "Model transformation in software performance engineering\n", "abstract": " Nowadays it is widely recognized the crucial role played in the software development process by the analysis of extra-functional properties (and especially performance) at the architectural level. To foster this kind of quantitative analysis we envisage the need to transform the performance model generation and analysis into a rigorous and sound discipline. To this end we intend to exploit the knowledge (acquired by other disciplines) in the area of model transformation, and import both reasoning and methodologies in the software performance engineering. In this paper we investigate the area of performance model derivation and analysis focusing on model transformation; we propose an initial taxonomy for the area of performance analysis at software architecture level and we delineate our suggestions towards a software performance model driven engineering.", "num_citations": "18\n", "authors": ["634"]}
{"title": "Dynamic power management for QoS-aware applications\n", "abstract": " Reducing the power requirement of large IT infrastructures is becoming a major concern. Energy savings can be achieved with hardware and/or software solutions; in particular, modern CPUs can operate at different power levels that can be selected by software: low power modes reduce energy consumption at the cost of lowering also the CPU processing rate. In this paper we address the problem of reducing energy consumption of a large-scale distributed application subject to Service Level Agreements requiring a maximum allowed response time. Specifically, we propose Energy Aware reconfiguration of software SYstems (EASY), an on-line algorithm for dynamically adjusting the processing speed of individual devices such that the average system response time is kept below a predefined threshold, and the total power consumption is minimized. EASY uses a queueing networks performance model to\u00a0\u2026", "num_citations": "17\n", "authors": ["634"]}
{"title": "Qos-aware fully decentralized service assembly\n", "abstract": " Large distributed software systems are increasingly common in today geographically distributed IT infrastructures. A key challenge for the software engineering community is how to efficiently and effectively manage such complex systems. Extending software services with autonomic capabilities has been suggested as a possible way to address this challenge. Ideally, self-management capabilities should be based on fully distributed, peer-to-peer (P2P) architectures in order to try to overcome the scalability and robustness problems of centralized solutions. Within this context, we propose an approach for the adaptive self-assembly of distributed services, based on a simple epidemic protocol. Our approach is based on the three-layer reference model for adaptive systems, and is centered on the use of a gossip protocol to achieve decentralized information dissemination and decision making. The goal of our system is\u00a0\u2026", "num_citations": "17\n", "authors": ["634"]}
{"title": "A QoS-based framework for the adaptation of service-based systems\n", "abstract": " Since a system may require dynamic adaptation for several reasons (eg, a new version may be available and a new functionality or a different level of quality of service) it should be possible to dynamically adapt a service-based system in an automated manner. In this paper we give a general overview of the main components of a framework, based on an optimization model, that dynamically adapts a service based system (ie, both the structural and behavioral software and hardware architecture) while minimizing the adaptation costs and guaranteeing a required level of the system qualities. Adaptation actions can be triggered both by a user request and/or automatically after the runtime violation of system quality constraints, or the appearing/disappearing of services into the environment. In this paper we provide also a deeper discussion of the optimization model that is the core of the framework by providing an example of instantiation of the model together with a first experimentation.", "num_citations": "17\n", "authors": ["634"]}
{"title": "MOSES: a platform for experimenting with QoS-driven self-adaptation policies for service oriented systems\n", "abstract": " Architecting software systems according to the service-oriented paradigm, and designing runtime self-adaptable systems are two relevant research areas in\u00a0today\u2019s software engineering. In this chapter we present MOSES, a software platform supporting QoS-driven adaptation of service-oriented systems. It has been conceived for service-oriented systems architected as composite services that receive requests generated by different classes of users. MOSES integrates within a unified framework different adaptation mechanisms. In this way it achieves a greater flexibility in facing various operating environments and the possibly conflicting QoS requirements of several concurrent users. Besides providing its own self-adaptation functionalities, MOSES lends itself to the experimentation of alternative approaches to QoS-driven adaptation of service-oriented systems thanks to its modular architecture.", "num_citations": "14\n", "authors": ["634"]}
{"title": "Building autonomic components: the SelfLets approach\n", "abstract": " Autonomic computing is an emergent field aiming at the development of large-scale, self-managing, distributed component-based systems. This paper presents the model and the architecture of an autonomic computing element called SelfLet, which is a building component that can be used to create autonomic systems. SelfLets can be defined by specifying their goal, behaviors, services they need to use and/or provide, and autonomic policies guiding their self-management. The SelfLet architecture has been implemented in Java and offers programming abstractions suitable to implement an application-specific logic as well as autonomic policies. As a case study we have implemented a pervasive autonomic system that manages electrical power balancing in intelligent cooperating buildings.", "num_citations": "14\n", "authors": ["634"]}
{"title": "Software performance validation strategies\n", "abstract": " Software performance validation strategies | System performance evaluation ACM Digital Library home ACM home Google, Inc. (search) Advanced Search Browse About Sign in Register Advanced Search Journals Magazines Proceedings Books SIGs Conferences People More Search ACM Digital Library SearchSearch Advanced Search Browse Browse Digital Library Collections More HomeBrowse by TitleBooksSystem performance evaluation: methodologies and applicationsSoftware performance validation strategies chapter Software performance validation strategies Share on Authors: Giuseppe Iazeolla View Profile , Andrea D'Ambrogio View Profile , Raffaela Mirandola View Profile Authors Info & Affiliations Publication: System performance evaluation: methodologies and applicationsJune 2000 Pages 365\u2013381 3citation", "num_citations": "14\n", "authors": ["634"]}
{"title": "Self-adaptation of service based systems based on cost/quality attributes tradeoffs\n", "abstract": " An application should be self-adaptive in order to automatically and autonomously adapt its behavior for several reasons, such as service evolution (e.g. a new version may be available), hardware volatility (e.g. network quality changes) and varying users demands with new requirements (e.g. a new functionality or a different level of quality of service). In this paper we introduce a framework, based on an optimization model, that dynamically adapts a service based system (i.e. both the structural and behavioral software and hardware architecture) while minimizing the adaptation costs and guaranteeing a required level of the system qualities. Adaptation actions can be triggered both by an user request and/or automatically after the runtime violation of system quality constraints, or the appearing/disappearing of services into the environment. In particular, in this paper we give a general overview of the main\u00a0\u2026", "num_citations": "13\n", "authors": ["634"]}
{"title": "An infrastructure for autonomic system development: the selflet approach\n", "abstract": " Autonomic computing is an emergent field for the development of large-scale, self-managing, complex distributed computer-based systems. This paper aims to be a practical approach to Autonomic Computing, by defining and implementing a generic model for autonomic systems, allowing software developers to create autonomic applications using a common and comprehensive infrastructure. In particular, this paper defines a simple but complete model andarchitecture of an autonomic computing element called SelfLet, which could be the building components used to create autonomic systems. SelfLets can be defined by specifying their behaviour, the abilities and goals they need to use and/or provide, and a high-level policy guiding their self-management.", "num_citations": "13\n", "authors": ["634"]}
{"title": "A deep investigation for qos-based feedback at design time and runtime\n", "abstract": " Complex software systems are regularly required to work more, faster and on a broader scale, to adapt dynamically to changing workloads, scenarios and objectives, and to achieve guaranteed levels of Quality of Service (QoS). Satisfying such demanding requirements at design time is a not trivial task, since at runtime the presence of the variability, eterogeneity and non-linear behaviour that characterize complex software systems makes the whole process harder for software designers. Feedback strategies must be introduced to keep track of the QoS status of software systems with the purpose of identifying if such status meets the current requirements and of suggesting, if necessary, the most suitable reconfigurations. In this paper we propose a deep investigation for QoS-based Feedback that makes use of design and runtime knowledge thus to provide a methodology to manage the data over time, while the\u00a0\u2026", "num_citations": "12\n", "authors": ["634"]}
{"title": "A compositional method for reliability analysis of workflows affected by multiple failure modes\n", "abstract": " We focus on reliability analysis for systems designed as workflow based compositions of components. Components are characterized by their failure profiles, which take into account possible multiple failure modes. A compositional calculus is provided to evaluate the failure profile of a composite system, given failure profiles of the components. The calculus is described as a syntax-driven procedure that synthesizes a workflow's failure profile. The method is viewed as a design-time aid that can help software engineers reason about system's reliability in the early stage of development. A simple case study is presented to illustrate the proposed approach.", "num_citations": "12\n", "authors": ["634"]}
{"title": "Multi-modeling approach to performance engineering of cyber-physical systems design\n", "abstract": " The modeling and analysis of Cyber Physical Systems (CPS) is inevitably challenging due to the intrinsic problem of merging the specification of different ensembles that indicate hardware, software and physical aspects of such systems. This intrinsic complexity is exacerbated in performance engineering since multiple models need to co-exist in order to get meaningful performance indicators. In this paper we introduce a guided process called IMPACt (multI Modelling PerformAnce Cps),which helps architects during the design phase, to better understand the behavior of the system under development and the design choices they made, through performance analysis on results obtained by runnable models derived from system high-level specification.", "num_citations": "11\n", "authors": ["634"]}
{"title": "Proceedings of the 30th Annual ACM Symposium on Applied Computing, SAC 2015; Salamanca; Spain; 13 April 2015 through 17 April 2015\n", "abstract": " Proceedings of the 30th Annual ACM Symposium on Applied Computing, SAC 2015; Salamanca; Spain; 13 April 2015 through 17 April 2015 IRIS nascondi/visualizza icone a destra nascondi/visualizza menu in alto IRIS Scorri Scorri Titoli Autori Unibg per data di pubblicazione per data di archiviazione per tipo di contenuto (ricerca) per tipo di contenuto (didattica) Centri di ricerca Corsi e Scuole di dottorato Login IRIS Aisberg 1. Prodotti della ricerca - Research output 1.6 Curatele - Editorships 1.6.Curatele - Edited books Proceedings of the 30th Annual ACM Symposium on Applied Computing, SAC 2015; Salamanca; Spain; 13 April 2015 through 17 April 2015 Italiano Italiano Italiano Italiano English English (2015). Proceedings of the 30th Annual ACM Symposium on Applied Computing, SAC 2015; Salamanca; Spain; 13 April 2015 through 17 April 2015 [edited proceedings - curatela di Atti di convegno]. Retrieved \u2026", "num_citations": "11\n", "authors": ["634"]}
{"title": "A Model-Driven Approach to Predictive Non-Functional Analysis of Component-Based Systems\n", "abstract": " We present an approach to the predictive analysis of non functional properties of component-based software systems. According to a model-driven perspective, the construction of a model that supports some specific analysis methodology is seen as the result of a sequence of refinement steps, where earlier steps can be generally shared among different analysis methodologies. We focus in particular on a path leading to the construction of a stochastic model for the compositional performance analysis, but we also outline some relationships with different refinement paths.", "num_citations": "11\n", "authors": ["634"]}
{"title": "Decentralized learning for self-adaptive qos-aware service assembly\n", "abstract": " The highly dynamic nature of future computing systems, where applications dynamically emerge as opportunistic aggregation of autonomous and independent resources available at any given time, requires a radical shift in the adopted computing paradigms. Indeed, they should fully reflect the decentralized perspective of the execution environment and consider QoS, scalability and resilience as key objectives. In this context, the everything-as-a-service (XaaS) paradigm, which envisions the creation of new services as an assembly of independent services available within the environment, can greatly help in tackling the challenges of developing future applications. However, in order to be effective, XaaS paradigm requires self-adaptive service assembly solutions able to cope with the unpredictable variability and scalability of the execution environment, the lack of global knowledge, and the QoS requirements of\u00a0\u2026", "num_citations": "10\n", "authors": ["634"]}
{"title": "A decentralized approach to network-aware service composition\n", "abstract": " Dynamic service composition represents a key feature for service-based applications operating in dynamic and large scale network environments, as it allows leveraging the variety of offered services, and to cope with their volatility. However, the high number of services and the lack of central control pose a significant challenge for the scalability and effectiveness of the composition process. We address this problem by proposing a fully decentralized approach to service composition, based on the use of a gossip protocol to support information dissemination and decision making. The proposed system builds and maintains a composition of services that fulfills both functional and non functional requirements. For the latter, we focus in particular on requirements concerning the composite service completion time, taking into account both the response time and the impact of network latency. Simulation\u00a0\u2026", "num_citations": "10\n", "authors": ["634"]}
{"title": "Introducing SCRUM into a distributed software development course\n", "abstract": " The growing enactment of Global Software Engineering in industry has triggered educational institutions to perceive the importance of preparing students for distributed software development. During the last twelve years we have disclosed advantages and pitfalls of GSE to our students through our Distributed Software Development course. After running the projects according to the iterative process model for eleven years, we decided to shift to an agile development model, SCRUM. This decision was due to the growing industrial adoption of agile methods, but more importantly to increase proactiveness, sense of responsibility, and to balance the workload among the project team members. In this paper we describe the process and outcomes of our first attempt at introducing SCRUM in our distributed course.", "num_citations": "10\n", "authors": ["634"]}
{"title": "Dependability assessment of web service orchestrations\n", "abstract": " In this paper, we focus on the reliability and availability analysis of Web service (WS) compositions, orchestrated via the Business Process Execution Language (BPEL). Starting from the failure profiles of the services being composed, which take into account multiple possible failure modes, latent errors, and propagation effects, and from a BPEL process description, we provide an analytical technique for evaluating the composite process' reliability-availability metrics. This technique also takes into account BPEL's advanced composition features, including fault, compensation, termination, and event handling. The method is a design-time aid that can help users and third party providers reason, in the early stages of development, and in particular during WS selection, about a process' reliability and availability. A non-trivial case study in the area of travel management is used to illustrate the applicability and\u00a0\u2026", "num_citations": "10\n", "authors": ["634"]}
{"title": "Performance aware reconfiguration of software systems\n", "abstract": " In this paper we address the problem of building a scalable component-based system by means of dynamic reconfiguration. Specifically, we consider the system response time as the performance metric; we assume that the system components can be dynamically reconfigured to provide a degraded service with lower response time. Each component operating at one of the available quality levels is assigned a utility. Higher quality levels are associated to higher utility. We propose an approach for performance-aware reconfiguration of degradable software systems called PARSY (Performance Aware Reconfiguration of software SYstems). PARSY tunes individual components in order to maximize the system utility with the constraint of keeping the system response time below a pre defined threshold. PARSY uses a closed Queueing Network model to select the components to upgrade or degrade.", "num_citations": "10\n", "authors": ["634"]}
{"title": "Overlay self-organization for traffic reduction in multi-broker publish-subscribe systems\n", "abstract": " In this work we propose a heuristic-based strategy to modify the broker overlay of a multi-broker publish-subscribe system for optimizing the message flow. The approach we adopt is inspired by self-organization in biology and makes the broker overlay behave as an autonomic distributed system. We define our approach in the case of a topic-based publish-subscribe system, and show experimentally that it is able to reduce the overall network traffic in a faster way when compared to similar approaches.", "num_citations": "9\n", "authors": ["634"]}
{"title": "MSL: A pattern language for engineering self-adaptive systems\n", "abstract": " In architecture-based self-adaptation of decentralized systems, design patterns have been introduced to ease the design of complex adaptation solutions that usually require the interaction of different MAPE-K (Monitor-Analyze-Plan-Execute over a shared Knowledge) control loops, each dealing with an adaptation concern of the managed system. Such MAPE patterns have been proposed by means of a graphical notation, but without a well-defined way to document them and to express the semantics of components interactions.In this paper, we propose an approach to overcome these limitations. We present a domain-specific language, called MSL for MAPE Specification Language, to define and instantiate MAPE patterns and to give semantics to some semantic variation points of the equivalent graphical notation for MAPE pattern. We also provide a formal semantics of the language by means of self-adaptive\u00a0\u2026", "num_citations": "8\n", "authors": ["634"]}
{"title": "QVTR2: A Rational and Performance-Aware Extension to the Relations Language.\n", "abstract": " Model transformations glue together models in an MDE process and represent the rationale behind it. It is however likely that in a design/development process different solutions (or alternatives) for the same problem are available. When alternatives are encountered, engineers need to make a choice by relying on past experience and on quality metrics. Several languages exist to specify transformations, but all of them bury deep inside source code rational information about performance and alternatives, and none of them is capable of providing feedback to select between the different solutions. In this paper we present QVT-Relations Rational (QVTR2), an extension to the Relations language to help engineers in keeping information about the design rationale in declarative transformations, and to guide them in the alternatives selection process by using performance engineering techniques to evaluate candidate solutions. We demonstrate the effectiveness of our approach by using our QVTR2 prototype engine on a modified version of the common UML-to-RDBMS example transformation, and by guiding the engineer in the selection of the most reasonable and performing solution.", "num_citations": "8\n", "authors": ["634"]}
{"title": "A pattern-oriented design framework for self-adaptive software systems\n", "abstract": " Multiple interacting MAPE-K loops, structured according to specific interaction patterns, have been introduced to design the adaptation logic in case of decentralized self-adaptive software systems. Designing such complex systems requires the availability of tools where MAPE patterns can be easily instantiated to provide fast architectural solutions, and the encoding towards specific domains is facilitated by automatic mapping of such pattern instantiations in domain-specific languages; validation and verification must be also supported to assure correct development of reliable systems. In this paper, we present a pattern-oriented framework, based on the MSL (MAPE Specification Language) modeling language, for the design of self-adaptive systems. The framework supports: (i) explicit modeling of the adaptation logic in terms of patterns of interactive MAPE-K loops; (ii) ability to tailor MSL models for a specific\u00a0\u2026", "num_citations": "7\n", "authors": ["634"]}
{"title": "A DSL for MAPE patterns representation in self-adapting systems\n", "abstract": " In architecture-based self-adaptation, the adaptation logic is usually structured in terms of MAPE-K (Monitor-Analyze-Plan-Execute over a shared Knowledge) control loops dealing with the adaptation concerns of the managed system. In case of large, complex and decentralized systems, multiple interacting MAPE loops are introduced. Some common design patterns of interactive MAPE components have been proposed in the literature; however, a well-defined way to document them and to express the semantics of their interactions is still missing.                 This paper presents a domain-specific language, MAPE Specification Language (MSL), as modeling front-end to define and instantiate common patterns of interacting MAPE components when architecting the adaptation logic of a self-adaptive system. We also provide a semantic mapping (implemented by a model generator) to transform MSL\u00a0\u2026", "num_citations": "7\n", "authors": ["634"]}
{"title": "Conquering complexity via seamless integration of design-time and run-time verification\n", "abstract": " The complexity of modern software systems has grown enormously in the past years with users always demanding for new features and better quality of service. Software applications evolved not only in terms of size, but also in the criticality of the services supported. At the same time, software artifacts changed from being monolithic and centralized to modular, distributed, and dynamic. Systems are now composed of heterogeneous components and infrastructures on which software is configured and deployed. Interactions with the external environment and the structure of the application, in terms of components and interconnections, are often required to change dynamically. All these causes challenge our ability to achieve acceptable levels of dependability. To guarantee system dependability, it is necessary to combine off-line (development-time) analysis techniques with run-time mechanisms for\u00a0\u2026", "num_citations": "7\n", "authors": ["634"]}
{"title": "A new approach to performance modelling of Client/Server distributed data base architectures\n", "abstract": " The recent technological advances in the field of computer and communication lead to distributed data base (DDB) architectures based on the Client/Server paradigm. Available DDB performance prediction methodologies are not sufficiently adequate being too expensive both in the model definition and in the model analysis because of the structural complexity and the large system dimension.This paper concentrates on a new approach to performance modeling of DDB systems called \u201cindependent modelling approach\u201d. This approach separates the DDB software model from the DDB machinery model, and models from solution techniques. This way the aspects related to data contention can be analysed as a pure software characteristic and separated from resource contention, considered as a machinery characteristic. Furthermore, it is possible to analytically model some system aspects (e.g., the software only, or\u00a0\u2026", "num_citations": "7\n", "authors": ["634"]}
{"title": "Qos-based feedback for service compositions\n", "abstract": " The Service Oriented Architecture is boosting a fast move from developing applications as stand-alone systems, to developing applications as composition of autonomous and heterogeneous services. Service compositions are required to adapt dynamically to changing workloads, scenarios and objectives, and to achieve a certain Quality of Service (QoS). Guaranteeing such requirements is not a trivial task, since run-time variability makes the process of devising service compositions challenging for software designers. In this paper, we exploit the QoS analysis at run time to support software design, highlighting service compositions where QoS predictions are not reliable enough. To this end, we propose a QoS-based feedback framework that makes use of design-time and run-time knowledge to manage QoS data over time, and support software architect while devising a service composition that best fits QoS\u00a0\u2026", "num_citations": "6\n", "authors": ["634"]}
{"title": "Multi-dimensional assessment of risks in a distributed software development course\n", "abstract": " The organizational shift from local to global settings in many software development initiatives has triggered the need for entailing it when educating the future software engineers. Several educational institutions have embraced this need and started collaborating for the provision of global software engineering courses. The rather complex nature of such courses results in a wider range of risks, in comparison to standard software engineering courses, that arise in different dimensions, ranging from course-to result-related, and for different reasons. In this work we provide an assessment of such a variety of risks as well as their causes, and we give a hint on how they may affect each other based on our 10-year-long experience with a tightly integrated GSD course.", "num_citations": "6\n", "authors": ["634"]}
{"title": "An XML-based language to support performance and reliability modeling and analysis in software architectures\n", "abstract": " In recent years, the focus of software development has progressively shifted upward, in the direction of the abstract level of architecture specification. However, while the functional properties of the systems have been extensively dealt with in the literature, relatively less attention has been given until recently to the specification and analysis at the architectural level of quality attributes such as performance and reliability. The contribution of this paper is twofold: first we discuss the type of information that should be provided at the architectural level in order to successfully address the problem of performance and reliability modeling and analysis of software systems; based on this discussion, we define an extension of the xADL architectural language that enables the support for stochastic modeling and analysis of performance and reliability in software architectures.", "num_citations": "6\n", "authors": ["634"]}
{"title": "Smart home platform supporting decentralized adaptive automation control\n", "abstract": " Smart Home is an exemplar application domain of the Internet of Things (IoT). In particular, smart home automation processes that manage the interactions with the home devices and integrate all their (possibly interfering) services, introduce new challenges and call for modern engineering practices, software platforms, and computational intelligence. A key example is the need to achieve a more efficient integration between design and runtime aspects in the automation process, taking into account that unanticipated situations can occur in the home environment and require a smart home system to deal with them at runtime. In this paper, using an application example, we foresee how to architect future smart home systems in order to endow them with self-adaptation capabilities allowing decentralized control and device interconnection. Namely, we propose to exploit feedback control loop architectures (eg\u00a0\u2026", "num_citations": "5\n", "authors": ["634"]}
{"title": "Resilience of distributed student teams to stress factors: A longitudinal case-study\n", "abstract": " Context: Teaching global software engineering is continuously evolving and improving to prepare future software engineers adequately. Geographically distributed work in project-oriented software development courses is both demanding and rewarding for student teams, who are susceptible to various risks stemming from different internal and external factors, being the sources of stress and impacting team performance.Objective: In this paper, we analyze the resilience of teams of students working in a geographically fully distributed setting. Resilience is analyzed in relation to two representative stress factors: non-contributing team members and changes to customer project requirements. We also reason on team collaboration patterns and analyze potential dependencies among these collaboration patterns, team resilience and stress factors.Method: We conduct a longitudinal case-study over five years on our\u00a0\u2026", "num_citations": "5\n", "authors": ["634"]}
{"title": "A case study to elicit challenges for performance engineering of cyber physical systems\n", "abstract": " Cyber-physical Systems (CPS) are engineered systems that are built from, and depend upon, the seamless integration of computational algorithms and physical components. Therefore, the engineering of CPS is inherently collaborative, demanding cooperation between diverse disciplines. Besides, it requires attention to not only the functional aspects, such as behaviour and correctness, but also to performance characteristics, such as timing constraints of the entire system. In this paper we exploit an existing simulation environment to model and analyze a robotic system, and some preliminary performance analysis results are shown. This illustrative case study aims to bring upfront the challenges for performance engineering of CPS.", "num_citations": "5\n", "authors": ["634"]}
{"title": "A reliability prediction method for abstract state machines\n", "abstract": " According to the vision of Design for Reliability, software reliability has to be considered in all the activities within the software development life cycle. In particular, writing formal specifications, like other activities in software development, is error-prone, especially for large-scale systems. This paper presents a reliability prediction method for Abstract State Machines specifications. The method considers the internal structure of an ASM by computing its reliability based on the reliabilities calculated inductively along the call tree of the ASM rules and the structure of the rule bodies.", "num_citations": "5\n", "authors": ["634"]}
{"title": "Engineering cyber\u2010physical systems through performance\u2010based modelling and analysis: A case study experience report\n", "abstract": " The process of engineering cyber\u2010physical systems (CPS) is inevitably challenging because of the intrinsic problem of merging the specification of different ensembles that indicate hardware, software, and physical aspects of such systems. This intrinsic complexity is exacerbated when modelling and analysing the performance characteristics of CPS since multiple models need to coexist in order to get meaningful performance indicators. In this paper, we present a case study, a delivery robots system, whose experience is exploited towards building a guided process for engineering CPS through performance\u2010based modelling and analysis. Model\u2010based performance results are provided while analysing different design alternatives, thus to support architects in the process of better understanding the performance characteristics of CPS under development.", "num_citations": "4\n", "authors": ["634"]}
{"title": "An optimization process for adaptation space exploration of service-oriented applications\n", "abstract": " This paper proposes an automatic optimization process for adaptation space exploration of service-oriented applications based on trade-offs between functional and extra-functional requirements. The optimization method combines both meta-heuristic search techniques and the use of functional/extra-functional patterns (i.e., architectural design patterns and tactics). Moreover, the proposed approach relies on the standard Service-oriented Component Architecture (SCA) for heterogeneous service assembly and its runtime platforms.", "num_citations": "4\n", "authors": ["634"]}
{"title": "Web services composition in autonomic grid environments\n", "abstract": " To cope with the competitiveness of the market place, e-business applications should be developed exploiting the flexibility of service oriented paradigm and the challenges of the grid computing technologies and should guarantee the fulfillment of quality requirements. In this paper we present a reference framework to support the execution of Web services based e-business applications in autonomic grid environments. Specifically, we tackle the problem of selection of Web services that assure the optimum mapping between each abstract Web service of a business process and a Web service which implements the abstract description, such that the overall quality of service perceived by the user is maximized. The proposed solution guarantees the fulfillment of global constraints, considers variable quality of service profile of component Web services and the long term process execution.", "num_citations": "4\n", "authors": ["634"]}
{"title": "Building design\u2010time and run\u2010time knowledge for QoS\u2010based component assembly\n", "abstract": " Modern software systems are required to dynamically adapt to changing workloads, scenarios, and objectives and to achieve a certain Quality of Service (QoS). Guaranteeing QoS requirements is not trivial, as run\u2010time uncertainty might invalidate the design\u2010time rationale, where software components have been selected by means of off\u2010line analysis. In this work, we propose a QoS\u2010based feedback approach that makes a combined use of design\u2010time predictions and run\u2010time measurements to manage QoS data over time and support software architects while selecting software components that best fit QoS requirements. We illustrate the feasibility and efficacy of the approach on a case study, where the quantitative evaluation shows how the analysis effectively identifies the sources of QoS violations and indicates possible solutions to achieve QoS requirements.", "num_citations": "3\n", "authors": ["634"]}
{"title": "Continuous rearchitecting of qos models: Collaborative analysis for uncertainty reduction\n", "abstract": " Architecting high quality software systems is not trivial, in fact to know whether a certain quality attribute has been achieved, it has to be continuously analysed. Reasoning about multiple quality attributes (e.g., performance, availability) of software systems is even more difficult since it is necessary to jointly analyze multiple and heterogeneous Quality-of-Service (QoS) models. The goal of this paper is to investigate the combined use of different QoS models and continuously re-architecting them since the acquired knowledge of a specific QoS model may affect another model, thus to put in place a collaborative analysis process that reduces the overall uncertainty. Starting from an example of interaction among two different QoS models, i.e., a Bayesian Network for availability and a Queueing Network for performance, we demonstrate that the collaborative analysis brings benefits to the overall process since\u00a0\u2026", "num_citations": "3\n", "authors": ["634"]}
{"title": "Testing operational transformations in model-driven engineering\n", "abstract": " Model-driven development is gaining importance in software engineering practice. This increasing usage asks for a new generation of testing tools to verify correctness and suitability of model transformations. This paper presents a novel approach to unit testing QVT operational (QVTO) transformations, which overcomes limitations of currently available tools. Our proposal, called MANTra (Model trANsformation Testing), allows software developers to design test cases directly within the QVTO language and verify them without moving from the transformation environment. MANTra is also available as an eclipse feature that can be easily integrated into established development practice.", "num_citations": "3\n", "authors": ["634"]}
{"title": "A Framework for QoS-aware Execution of Workflows over the Cloud\n", "abstract": " The Cloud Computing paradigm is providing system architects with a new powerful tool for building scalable applications. Clouds allow allocation of resources on a \"pay-as-you-go\" model, so that additional resources can be requested during peak loads and released after that. However, this flexibility asks for appropriate dynamic reconfiguration strategies. In this paper we describe SAVER (qoS-Aware workflows oVER the Cloud), a QoS-aware algorithm for executing workflows involving Web Services hosted in a Cloud environment. SAVER allows execution of arbitrary workflows subject to response time constraints. SAVER uses a passive monitor to identify workload fluctuations based on the observed system response time. The information collected by the monitor is used by a planner component to identify the minimum number of instances of each Web Service which should be allocated in order to satisfy the response time constraint. SAVER uses a simple Queueing Network (QN) model to identify the optimal resource allocation. Specifically, the QN model is used to identify bottlenecks, and predict the system performance as Cloud resources are allocated or released. The parameters used to evaluate the model are those collected by the monitor, which means that SAVER does not require any particular knowledge of the Web Services and workflows being executed. Our approach has been validated through numerical simulations, whose results are reported in this paper.", "num_citations": "3\n", "authors": ["634"]}
{"title": "Model-Based Testing for MAPE-K adaptation control loops\n", "abstract": " Self-adaptation is an effective solution for complex systems that need to adapt themselves to external changes while keeping internal goals; it can be realized in terms of MAPE-K feedback control loops, organized according to specific MAPE patterns in case of decentralized and distributed control. The MSL-centric framework allows the definition of the structure of MAPE-K loops using the MAPE Specification Language (MSL), and the description of its adaptation logic in terms of self-adaptive Abstract State Machines (ASMs). These models can be tested by exploiting classical model-based testing for ASMs that allows structural coverage of ASM models, but which is not adequate to test executions that are peculiar of the structure of MAPE-K loops. To overcome this limitation, in this paper, we propose a MAPE-based testing approach, which generates, from the MSL model, test goals specifying requirements on the\u00a0\u2026", "num_citations": "2\n", "authors": ["634"]}
{"title": "Decentralized architecture for energy-aware service assembly\n", "abstract": " Contemporary application domains make more and more appealing the vision of applications built as a dynamic and opportunistic assembly of autonomous and independent resources. However, the adoption of such paradigm is challenged by: (i) the openness and scalability needs of the operating environment, which rule out approaches based on centralized architectures and, (ii) the increasing concern for sustainability issues, which makes particularly relevant, in addition to QoS constraints, the goal of reducing the application energy footprint. In this context, we contribute by proposing a decentralized architecture to build a fully functional assembly of distributed services, able to optimize its energy consumption, paying also attention to issues concerning the delivered quality of service. We suggest suitable indexes to measure from different perspectives the energy efficiency of the resulting assembly, and\u00a0\u2026", "num_citations": "2\n", "authors": ["634"]}
{"title": "To what extent formal methods are applicable for performance analysis of smart cyber-physical systems?\n", "abstract": " The dynamic nature of complex Cyber-Physical Systems (CPS) introduces new research challenges since they need to smartly deal with changing situations in their environment. This triggers the usage of methodologies that keep track of changes and raise alarms whether extra-functional requirements (eg, safety, reliability, performance) are violated. In this context, we investigate the usage of formal methods as support to provide a model-based performance evaluation of smart CPS. The main goal is to understand to what extent well-known performance models, specifically Queueing Networks, are suitable to represent these dynamic scenarios.", "num_citations": "2\n", "authors": ["634"]}
{"title": "Gender balance in computer science and engineering in Italian universities\n", "abstract": " Multiple studies have shown that gender balance in the fields of Science, Technology, Engineering and Maths-and in particular in ICT-is still far to be achieved. Several initiatives have been recently taken to increase the women participation, but it is difficult, at present, to evaluate their impact and their potential of changing the situation. This paper contributes to the discussion by presenting a descriptive analysis of the gender balance in Computer Science and Computer Engineering in Italian Universities.", "num_citations": "2\n", "authors": ["634"]}
{"title": "A scalable approach to QoS-aware self-adaption in service-oriented architectures\n", "abstract": " In this paper we consider a provider that offers a SOA application implemented as a composite service to several users with different Qos requirements. For such a system, we present a scalable framework to the QoS-aware self-adaptation based on a two layer reference architecture. The first layer addresses the adaptation at the provisioning level: operating at a slower time scale, its role is to identify the set of candidate services to implement the system functionality at the required user QoS. The second layer addresses the adaptation at the service selection level: operating on a faster time scale, its role is to determine at running time the actual services which are bound to each user request while meeting both provider and user QoS. We formulate the adaptation strategy of both layers as suitable optimization problems which can be efficiently solved using standard techniques. Numerical experiments show\u00a0\u2026", "num_citations": "2\n", "authors": ["634"]}
{"title": "The Common Component Modeling Example: Comparing Software Component Models [result from the Dagstuhl research seminar for CoCoME, August 1-3, 2007]\n", "abstract": " La presente simulazione \u00e8 stata realizzata sulla base delle regole riportate nel DM 598/2018 e allegata Tabella A. Cineca non si assume alcuna responsabilit\u00e0 in merito all\u2019uso che il diretto interessato o terzi faranno della simulazione. Si specifica inoltre che la simulazione contiene calcoli effettuati con dati e algoritmi di pubblico dominio e deve quindi essere considerata come un mero ausilio al calcolo svolgibile manualmente o con strumenti equivalenti. Informazioni sui dati: vengono considerati tutti i prodotti in stato definitivo. Per i prodotti indicizzati wos/scopus, l\u2019anno di riferimento e la tipologia sono quelli riportati in banca-dati.", "num_citations": "2\n", "authors": ["634"]}
{"title": "CoCoTA\u2013Common Component Task\n", "abstract": " This chapter overviews the scope, goals and timeline of the modeling contest CoCoME. It also describes the input the competing teams received and, furthermore, explains how the peer reviewing process went ahead, and how the evaluation criteria were set with the aim to balance the inherently heterogeneous modeling and expressive power of different component models.", "num_citations": "2\n", "authors": ["634"]}
{"title": "Collaborative IV&V by SPEED: a tool-kit for the performance IV&V of critical software\n", "abstract": " Software performance engineering is a software engineering methodology whose scope is continuing performance IV&V during the life cycle. SPEED (Software Performance Evaluation and Modeling) is a toolkit for software performance IV&V according to performance engineering criteria. It is in course of development at the Laboratory for Computer Science, and CERTIA Research Center University of Rome at TorVergata. In its present version, it generates and evaluates the Master Model of the product, a performance analysis model that continuously evolves with the product design, and that includes the software workload model and the abstract machine model, or model of the executing environment. Conventional analytical and hybrid simulation techniques can then be applied to the MM to obtain performance predictions for the product under design. The paper gives a description of the SPEED philosophy and\u00a0\u2026", "num_citations": "2\n", "authors": ["634"]}
{"title": "A new efficient approach for extracting the closed episodes for workload prediction in cloud\n", "abstract": " The prediction of the future workload of applications is an essential step guiding resource provisioning in cloud environments. In our previous works, we proposed two prediction models based on pattern mining. This paper builds on our previous experience and focuses on the issue of time and space complexities of the prediction model. Specifically, it presents a general approach to improve the efficiency of the pattern mining engine, which leads to improving the efficiency of the predictors. The approach is composed of two steps: (1) Firstly, to improve space complexity, redundant occurrences of patterns are defined and algorithms are suggested to identify and omit them. (2) To improve time complexity, a new data structure, called closed pattern backward tree, is presented for mining closed patterns directly. The approach not only improves the efficiency of our predictors, but also can be employed in different fields\u00a0\u2026", "num_citations": "1\n", "authors": ["634"]}
{"title": "Towards a Continuous Model-Based Engineering Process for QoS-Aware Self-adaptive Systems\n", "abstract": " Modern information systems connecting software, physical systems, and people, are usually characterized by high dynamism. These dynamics introduce uncertainties, which in turn may harm the quality of service and lead to incomplete, inaccurate, and unreliable results. In this context, self-adaptation is considered as an effective approach for managing run-time uncertainty. However, classical approaches for quality engineering are not suitable to deal with run-time adaptation, as they are mainly used to derive the steady-state solutions of a system at design-time. In this paper, we envision a Continuous Model-based Engineering Process that makes use of architectural analysis in conjunction with experimentation to have a wider understanding of the system under development. These two activities are performed incrementally, and jointly used in a feedback loop to provide insights about the quality of the\u00a0\u2026", "num_citations": "1\n", "authors": ["634"]}
{"title": "Self-accounting in architecture-based self-adaptation\n", "abstract": " This paper proposes a work-in-progress approach regarding qualities of the managing layer in architecture-based self-adaptation. In particular, we establish the notion of self-accounting as self-* property and we present an inductive method, based on the structure of the MAPE pattern of the adaptation layer, to evaluate the cost of the adaptation logic in terms of latency time and availability of the managing system. We also show how the MSL (MAPE Specification Language), a language for modeling the adaptation layer in terms of MAPE patterns, has been extended to annotate MAPE components with values for these quality properties, so allowing the computation of the cost function and endowing an adaptation layer with a value for its self-accounting property.", "num_citations": "1\n", "authors": ["634"]}
{"title": "Hierarchical performance modeling of computer communication systems\n", "abstract": " Performance analysis has a relevant role in network-architecture design, protocol selection and network tuning by providing estimates of network behavior in terms of throughput, response time and network utilization. This chapter focuses on the use of modeling methods and techniques in computer-networks performance evaluation. It discusses communication-system models defined by using the queueing formalism. The chapter presents the Hierarchical Modeling (HM) approach both in the definition of a system\u2019s model and in the model solution phase. It describes the use of hierarchical modeling and hybrid simulation in a general setting, and provides their use in computer-network analysis in a case study. HM can be used to define a system model through a top-down stepwise refinement technique. The system is represented by a succession of models, each defined at a different level of detail. The chapter aims\u00a0\u2026", "num_citations": "1\n", "authors": ["634"]}
{"title": "Formal reliability models for web services\n", "abstract": " In Web services (WS), software applications are dynamically built by assembling over a network existing, loosely coupled, distributed, and heterogeneous services. Reliability is one of the most important quality dimensions for Web services, since predicting their reliability is fundamental to appropriately drive the selection and the assembly of services. This chapter presents two approaches to predict the reliability of a Web service architecture. The first one is based on the Business Process Execution Language (BPEL), the de facto standard executable language for specifying actions within business processes with Web services. The second one is based on the SCA-ASM, a lightweight formal language for modeling service-oriented applications, which is based on the OASIS (Organization for the Advancement of Structured Information Standards) standard Service Component Architecture for heterogeneous\u00a0\u2026", "num_citations": "1\n", "authors": ["634"]}
{"title": "A framework for adapting service-oriented applications based on functional/extra-functional requirements tradeoffs: the Stock Trading System case study\n", "abstract": " This report presents the model parameters and experimental results for adapting a sample service-oriented application from a Stock Trading System. In particular, the followed adaptation strategy combines the metaheuristic steepestascent hill-climbing with some tactics (ie extra-functional adaptation patterns) to increase the system availability and performance.", "num_citations": "1\n", "authors": ["634"]}
{"title": "A Framework for Adapting Service-oriented Applications based on Functional/Extra-functional Requirements Tradeoffs\n", "abstract": " This paper introduces an adaptation framework for service-oriented applications based on trade-offs between functional and extra-functional (eg, availability, performance, and adaptation cost) requirements. The framework relies on an optimization method for adaptation space exploration based on the combined use of meta-heuristic search techniques and of functional and extra-functional patterns (eg, architectural design patterns and tactics). A formal service-oriented component model, called SCA-ASM, is also adopted for the specification and functional analysis of service-oriented applications. Through a sample application, we exemplify the methodology with emphasis on the use of extra-functional patterns.", "num_citations": "1\n", "authors": ["634"]}
{"title": "An optimization process for adaptation space exploration of service-oriented applications: the stock trading system case study\n", "abstract": " We propose an automatic optimization process for adaptation space exploration of service-oriented applications based on trade-offs between functional and extra-functional requirements. The optimization method combines both metaheuristic search techniques and functional/extra-functional patterns (ie, architectural design patterns and tactics). Moreover, the proposed methodology relies also on the standard Serviceoriented Component Architecture (SCA) for heterogeneous ser-vice assembly and related tools/running infrastructures in order to process architectural models (of the application to adapt) that are directly tight to the real assembled components implementations and their deployment. As a proof-of-concepts, this report provides an example of instantiation of the proposed process together with an experimentation on a stock trading application.", "num_citations": "1\n", "authors": ["634"]}