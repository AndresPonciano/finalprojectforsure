{"title": "The pains and gains of microservices: A systematic grey literature review\n", "abstract": " The design, development, and operation of microservices are picking up more and more momentum in the IT industry. At the same time, academic work on the topic is at an early stage, and still on the way to distilling the actual \u201cPains & Gains\u201d of microservices as an architectural style. Having witnessed this gap, we set forth to systematically analyze the industrial grey literature on microservices, to identify the technical/operational pains and gains of the microservice-based architectural style. We conclude by discussing research directions stemming out from our analysis.", "num_citations": "210\n", "authors": ["2279"]}
{"title": "Devops: introducing infrastructure-as-code\n", "abstract": " DevOps entails a series of software engineering tactics aimed at shortening the actionable operation of software design changes. One of these tactics is to harness infrastructure-as-code, that is, writing a blueprint that contains deployment specifications ready for orchestration in the cloud. This abstract briefly discusses all necessary elements and abstractions in writing and maintaining that blueprint, revolving around a key standard for its expression, namely, the OASIS \"Topology and Orchestration Specification for Cloud Applications\" (TOSCA) industrial standard adopted by as many as 60+ big industrial players worldwide.", "num_citations": "82\n", "authors": ["2279"]}
{"title": "Towards a model-driven design tool for big data architectures\n", "abstract": " Big Data technologies are rapidly becoming a key enabler for modern industries. However, the entry costs inherent to\" going Big\" are considerable, ranging from learning curve, renting/buying infrastructure, etc. A key component of these costs is the time spent on learning about and designing with the many big data frameworks (eg, Spark, Storm, HadoopMR, etc.) on the market. To reduce said costs while decreasing time-to-market we advocate the usage of Model-Driven Engineering (MDE), ie, software engineering by means of models and their automated manipulation. This paper outlines a tool architecture to support MDE for big data applications, illustrating with a case-study.", "num_citations": "45\n", "authors": ["2279"]}
{"title": "Design principles for the General Data Protection Regulation (GDPR): A formal concept analysis and its evaluation\n", "abstract": " Data and software are nowadays one and the same: for this very reason, the European Union (EU) and other governments introduce frameworks for data protection \u2014 a key example being the General Data Protection Regulation (GDPR). However, GDPR compliance is not straightforward: its text is not written by software or information engineers but rather, by lawyers and policy-makers. As a design aid to information engineers aiming for GDPR compliance, as well as an aid to software users\u2019 understanding of the regulation, this article offers a systematic synthesis and discussion of it, distilled by the mathematical analysis method known as Formal Concept Analysis (FCA). By its principles, GDPR is synthesised as a concept lattice, that is, a formal summary of the regulation, featuring 144372 records \u2014 its uses are manifold. For example, the lattice captures so-called attribute implications, the implicit logical relations\u00a0\u2026", "num_citations": "41\n", "authors": ["2279"]}
{"title": "Model-driven continuous deployment for quality devops\n", "abstract": " DevOps entails a series of software engineering strategies and tools that promise to deliver quality and speed at the same time with little or no additional expense. In our work we strived to enable a DevOps way of working, combining Model-Driven Engineering tenets with the challenges of delivering a model-driven continuous deployment tool that allows quick (re-) deployment of cloud applications for the purpose of continuous improvement. This paper illustrates the DICER tool and elaborates on how it can bring about the DevOps promise and enable the quality-awareness.", "num_citations": "38\n", "authors": ["2279"]}
{"title": "A software architecture framework for quality-aware DevOps\n", "abstract": " DevOps is an emerging software engineering strategy entailing the joined efforts of development and operations people, their concerns and best practices with the purpose of realising a coherent working group for increased software development and operations speed. To allow software architecture practitioners to enrich and properly elaborate their architecture specifications in a manner which is consistent with DevOps, we surveyed a number of DevOps stakeholders. We studied concerns and challenges to be tackled with respect to preparing a software architecture which is DevOps-ready, ie, described in all details needed to enact DevOps scenarios. Subsequently, we introduce SQUID, that stands for Specification Quality In DevOps. SQUID is a software architecture framework that supports the model-based documentation of software architectures and their quality properties in DevOps scenarios with the goal of\u00a0\u2026", "num_citations": "34\n", "authors": ["2279"]}
{"title": "Blockchains: a systematic multivocal literature review\n", "abstract": " Blockchain technology has gained tremendous popularity both in practice and academia. The goal of this article is to develop a coherent overview of the state of the art in blockchain technology, using a systematic (i.e., protocol-based, replicable), multivocal (i.e., featuring both white and grey literature alike) literature review to (1) define blockchain technology, (2) elaborate on its architecture options and (3) tradeoffs, as well as to understand (4) the current applications and challenges, as evident from the state of the art. We derive a systematic definition of blockchain technology, based on a formal concept analysis. Further, we flesh out an overview of blockchain technology elaborated by means of Grounded-Theory.", "num_citations": "30\n", "authors": ["2279"]}
{"title": "Tosca solves big problems in the cloud and beyond!\n", "abstract": " TOSCA, the Topology and Orchestration Specification for Cloud Applications offers an OASIS-recognized, open standard domain-specific language (DSL) that enables portability and automated management of applications, services, and resources regardless of underlying cloud platform, software defined environment, or infrastructure. With a growing, interoperable eco-system of open source projects, solutions from leading cloud platform and service providers, and research, TOSCA empowers the definition and modeling of applications and their services (microservices or traditional services) across their entire lifecycle by describing their components, relationships, dependencies, requirements, and capabilities for orchestrating software in the context of associated operational policies. The authors introduce important TOSCA concepts and benefits in the context of commonly understood cloud use cases as a\u00a0\u2026", "num_citations": "29\n", "authors": ["2279"]}
{"title": "Towards a UML profile for data intensive applications\n", "abstract": " Data intensive applications that leverage Big Data technologies are rapidly gaining market trend. However, their design and quality assurance are far from satisfying software engineers needs. In fact, a CapGemini research shows that only 13% of organizations have achieved full-scale production for their Big Data implementations. We aim at addressing an early design and a quality evaluation of data intensive applications, being our goal to help software engineers on assessing quality metrics, such as the response time of theapplication. We address this goal by means of a quality analysis tool-chain. At the core of the tool, we are developing a Profile that converts the Unified Modeling Language into a domain specific modeling language for quality evaluation of data intensive applications.", "num_citations": "28\n", "authors": ["2279"]}
{"title": "Four-Dimensional Sustainable E-Services.\n", "abstract": " E-services are not sustainable, unless specifically designed for sustainability along four dimensions (4D): economical, technical, environmental, and social. Designing 4D-sustainable eservices is very complex, mainly due to the many challenges in communicating and assessing sustainability. This paper proposes a conceptual model that identifies the core elements of 4D-sustainable e-services. Our goal is to enhance the shared understanding amongst sustainability stakeholders, while easing sustainability assessment and negotiation. We illustrate the value of the conceptual model using a real-life case study featuring an airport baggage handling system2.", "num_citations": "23\n", "authors": ["2279"]}
{"title": "When software architecture leads to social debt\n", "abstract": " Social and technical debt both represent the state of software development organizations as a result of accumulated decisions. In the case of social debt, decisions (and connected debt) weigh on people and their socio-technical interactions/characteristics. Digging deeper into social debt with an industrial case-study, we found that software architecture, the prince of development artefacts, plays a major role in causing social debt. This paper discusses a key circumstance wherefore social debt is connected to software architectures and what can be done and measured in response, as observed in our case-study. Also, we introduce DAHLIA, that is \"Debt-Aimed Architecture-Level Incommunicability Analysis\" - a framework to elicit some of the causes behind social debt for further analysis.", "num_citations": "22\n", "authors": ["2279"]}
{"title": "Microcloud: A container-based solution for efficient resource management in the cloud\n", "abstract": " Cloud-based applications require dynamic resource allocation to cope with changing workloads and unexpected request spikes. The use of container technology increases manageability, portability, and scalability, but changes how the applications are provisioned and maintained. This paper presents MicroCloud, a novel architecture for providing multiple containerized applications with fine-grained resource allocation. MicroCloud consists of a TOSCA library, for specifying the topology of containerized applications and of their infrastructure, and a meta-workflow, for automatically adapting resource allocation in a coordinated, multi-level, and topology-aware way. MicroClouds's implementation is based on ECoWare, our framework for the management of self-adaptive, cloud-based applications. We evaluated MicroCloud using two applications deployed on Amazon EC2. The experiments focused on guaranteeing\u00a0\u2026", "num_citations": "19\n", "authors": ["2279"]}
{"title": "Continuous Architecting of Stream-Based Systems\n", "abstract": " Big data architectures have been gaining momentum in recent years. For instance, Twitter uses stream processing frameworks like Storm to analyse billions of tweets per minute and learn the trending topics. However, architectures that process big data involve many different components interconnected via semantically different connectors making it a difficult task for software architects to refactor the initial designs. As an aid to designers and developers, we developed OSTIA (On-the-fly Static Topology Inference Analysis) that allows: (a) visualising big data architectures for the purpose of design-time refactoring while maintaining constraints that would only be evaluated at later stages such as deployment and run-time, (b) detecting the occurrence of common anti-patterns across big data architectures, (c) exploiting software verification techniques on the elicited architectural models. This paper illustrates OSTIA and\u00a0\u2026", "num_citations": "19\n", "authors": ["2279"]}
{"title": "Towards self-evolving context-aware services\n", "abstract": " The introduction of new communication infrastructures such as Beyond 3rd Generation (B3G) and the widespread usage of small computing devices are rapidly changing the way we use and interact with technology to perform everyday tasks. Ubiquitous networking empowered by B3G networking makes it possible for mobile users to access networked software services across continuously changing heterogeneous infrastructures by resource-constrained devices. Heterogeneity and devices\u2019 limitedness, create serious problems for the development and dynamic deployment of mobile applications that are able to run properly on the execution context and consume services matching with the users\u2019 expectations. Furthermore, the everchanging B3G environment calls for applications that self-evolve according to context changes. Out of these problems, self-evolving adaptable applications are increasingly emerging in the software community. In this paper we describe how CHAMELEON, a declarative framework for tailoring adaptable applications, is being used for tackling adaptation and self-evolution within the IST PLASTIC project.", "num_citations": "18\n", "authors": ["2279"]}
{"title": "General methods for software architecture recovery: a potential approach and its evaluation\n", "abstract": " Software architecture is a critical artefact in the software lifecycle. It is a system blueprint for construction, it aids in planning teaming and division of work, and it aids in reasoning about system properties. But architecture documentation is seldom created and, even when it is initially created, it is seldom maintained. For these reasons organisations often feel the need to recover legacy architectures, for example, as part of planning for evolution or cloud migration. But there is no existing general architecture recovery approach nor tool that can be applied to any type of system, under any condition. We will show that one way of achieving such generality is to apply systematic code inspection following a Grounded Theory (GT) approach. Though relatively costly and human-intensive, a GT-based approach has several merits, for example: (a) it is general by design; (b) it can be partially automated; (c) it yields\u00a0\u2026", "num_citations": "14\n", "authors": ["2279"]}
{"title": "Towards omnia: A monitoring factory for quality-aware devops\n", "abstract": " Modern DevOps pipelines entail extreme automation and speed as paramount assets for continuous application improvement. Likewise, monitoring is required to assess the quality of service and user-experience such that applications can continuously evolve towards use-centric excellence. In this scenario however, it is increasingly difficult to pull up and maintain efficient monitoring infrastructures which are frictionless, ie, they do not introduce any slowdown neither in the DevOps pipeline nor in the DevOps organizational and social structure comprising multiple roles and responsibilities. Using an experimental prototype, this paper elaborates Omnia an approach for structured monitoring configuration and rollout based around a monitoring factory, ie, a re-interpretation of the factory design-pattern for building and managing ad-hoc monitoring platforms. Comparing with practitioner surveys and the state of the art\u00a0\u2026", "num_citations": "14\n", "authors": ["2279"]}
{"title": "Sustainable MLOps: Trends and Challenges\n", "abstract": " Even simply through a GoogleTrends search it becomes clear that Machine-Learning Operations-or MLOps, for short-are climbing in interest from both a scientific and practical perspective. On the one hand, software components and middleware are proliferating to support all manners of MLOps, from AutoML (i.e., software which enables developers with limited machine-learning expertise to train high-quality models specific to their domain or data) to feature-specific ML engineering, e.g., Explainability and Interpretability. On the other hand, the more these platforms penetrate the day-to-day activities of software operations, the more the risk for AI Software becoming unsustainable from a social, technical, or organisational perspective. This paper offers a concise definition of MLOps and AI Software Sustainability and outlines key challenges in its pursuit.", "num_citations": "12\n", "authors": ["2279"]}
{"title": "Providing big data applications with fault-tolerant data migration across heterogeneous NoSQL databases\n", "abstract": " The recent growing interest on highly-available data-intensive applications sparked the need for flexible and portable storage technologies, e.g., NoSQL databases. Unfortunately, the lack of standard interfaces and architectures for NoSQLs makes it difficult and expensive to create portable applications, which results in vendor lock-in. Building on previous work, we aim at providing guaranteed fault-tolerant techniques and supporting architectures to port or migrate data to and across heterogeneous NoSQL technology. To prove the effectiveness of our approach we evaluate it on an industrial case-study. We conclude that our method and supporting architecture offer an efficient and fault-tolerant mechanism for NoSQL portability and interoperation.", "num_citations": "12\n", "authors": ["2279"]}
{"title": "Defining, enforcing and checking privacy policies in data-intensive applications\n", "abstract": " The rise of Big Data is leading to an increasing demand for large-scale data-intensive applications (DIAs), which have to analyse massive amounts of personal data (eg customers' location, cars' speed, people heartbeat, etc.), some of which can be sensitive, meaning that its confidentiality has to be protected. In this context, DIA providers are responsible for enforcing privacy policies that account for the privacy preferences of data subjects as well as for general privacy regulations. This is the case, for instance, of data brokers, ie companies that continuously collect and analyse data in order to provide useful analytics to their clients. Unfortunately, the enforcement of privacy policies in modern DIAs tends to become cumbersome because (i) the number of policies can easily explode, depending on the number of data subjects,(ii) policy enforcement has to autonomously adapt to the application context, thus, requiring\u00a0\u2026", "num_citations": "11\n", "authors": ["2279"]}
{"title": "Cybercrime Threat Intelligence: a Systematic Multi-Vocal Literature Review\n", "abstract": " Significant cybersecurity and threat intelligence analysts agree that online criminal activity is increasing exponentially. To offer an overview of the techniques and indicators to perform cyber crime detection by means of more complex machine- and deep-learning investigations as well as similar threat intelligence and engineering activities over multiple analysis levels (i.e., surface, deep, and darknets), we systematically analyze state of the art in such techniques. First, to aid the engineering and management of such intelligence solutions. We provide (i) a taxonomy of existing methods mapped to (ii) an overview of detectable criminal activities as well as (iii) an overview of the indicators and risk parameters that can be used for such detection. Second, to find the major engineering and management challenges and variables to be addressed. We apply a Topic Modelling Analysis to identify and analyze the most\u00a0\u2026", "num_citations": "10\n", "authors": ["2279"]}
{"title": "Refactoring Community Smells in the Wild: The Practitioner\u2019s Field Manual\n", "abstract": " Community smells have been defined as sub-optimal organizational structures that may lead to social debt. Previous studies have shown that they are highly diffused in both open-and closed-source projects, are perceived as harmful by practitioners, and can even lead to the introduction of technical debt in source code. Despite the presence of this body of research, little is known on the practitioners' perceived prominence of community smells in practice as well as on the strategies adopted to deal with them. This paper aims at bridging this gap by proposing an empirical study in which 76 software practitioners are inquired on (i) the prominence of four well-known community smells, ie, Organizational Silo, Black Cloud, Lone Wolf, and Radio Silence, in their contexts and (ii) the methods they adopted to\" refactor\" them. Our results first reveal that community smells frequently manifest themselves in software projects\u00a0\u2026", "num_citations": "10\n", "authors": ["2279"]}
{"title": "Cloud applications monitoring: An industrial study\n", "abstract": " ContextModern software systems employ large IT infrastructures hosted in on-premise clouds or using \u201crented\u201d cloud resources from specific vendors. The unifying force across any cloud strategy is incremental product and application improvement against conservation of those resources. This is where monitoring of cloud applications becomes a key assetObjectiveTo shed light over the status of monitoring practices in industry, we study: (a) monitoring practices and tools adoption in industry; (b) size and complexity of industrial monitoring problems; (c) the role of software architecture and software process with respect to monitoring strategies.MethodWe conduct mixed-methods empirical research featuring interviews and a web survey featuring 140+ practitioners from over 70 different organizations.ResultsEven if the market makes available a significant set of monitoring tools, our results show a rather unappealing\u00a0\u2026", "num_citations": "9\n", "authors": ["2279"]}
{"title": "Simulating awareness in global software engineering: a comparative analysis of scrum and agile service networks\n", "abstract": " Global software engineering (GSE) is a business strategy to realize a business idea (i.e. the development project) faster, through round-the-clock productivity. However, GSE creates a volatile and unstable process in which many actors interact together against unpredictable premises (e.g. cultural or time differences), often producing unexpected outcomes (e.g. compacting effects of distance and time). So far, Scrum has been used extensively for embarking in global software engineering, but many of the problems in Scrum-based GSE could still benefit from the usage of ad-hoc supporting tools (e.g. information continuity between timezones, cultural differences, developers awareness, etc.). Agile Service Networks (ASNs) are networks of service oriented applications (nodes) that collaborate adaptively towards a common goal. ASNs offer a way to represent GSE professionals through service-oriented \u201csocial\u201d nodes\u00a0\u2026", "num_citations": "8\n", "authors": ["2279"]}
{"title": "Going Global With Agile Service Networks\n", "abstract": " ASNs are emergent networks of service-based applications (nodes) which collaborate through agile (i.e. adaptable) transactions. GSE comprises the management of project teams distanced in both space and time, collaborating in the same development effort. The GSE condition poses challenges both technical (e.g. geolocalization of resources, information continuity between timezones, etc.) and social (e.g. collaboration between different cultures, fear of competition, etc.). ASNs can be used to build an adaptable social network (ASN GSE ) supporting the collaborations (edges of ASN GSE ) of GSE teams (nodes of ASN GSE ).", "num_citations": "8\n", "authors": ["2279"]}
{"title": "Towards semantic detection of smells in cloud infrastructure code\n", "abstract": " Automated deployment and management of Cloud applications relies on descriptions of their deployment topologies, often referred to as Infrastructure Code. As the complexity of applications and their deployment models increases, developers inadvertently introduce software smells to such code specifications, for instance, violations of good coding practices, modular structure, and more. This paper presents a knowledge-driven approach enabling developers to identify the aforementioned smells in deployment descriptions. We detect smells with SPARQL-based rules over pattern-based OWL 2 knowledge graphs capturing deployment models. We show the feasibility of our approach with a prototype and three case studies.", "num_citations": "7\n", "authors": ["2279"]}
{"title": "Software architecture social debt: Managing the incommunicability factor\n", "abstract": " Architectural technical debt is the additional project cost connected to technical issues nested in software architectures. Similarly, many practitioners have already experienced that there exists within software architectures a form of social debt, that is, the additional project cost connected to sociotechnical and organizational issues evident in or related to software architectures. This paper illustrates four recurrent antipatterns or community smells connected to such architectural social debt and outlines a means to measure the additional project cost connected to their underlying cause: decision incommunicability. Evaluating the results in multiple focus groups, this paper concludes that studying social debt and community smells at the architecture level may prove vital to rid software development communities of critical organizational flaws incurring considerable additional cost.", "num_citations": "7\n", "authors": ["2279"]}
{"title": "TOSCA-based Intent modelling: goal-modelling for infrastructure-as-code\n", "abstract": " DevOps entails a set of practices that speed up the time needed to rollout software product changes. One such practice is automating deployment and delivery with infrastructure-as-code, i.e., automated scripts that ideally carry out 1-click deployment. Providing effective infrastructure-as-code poses the tricky issue in determining the modelling and information representation paradigm (e.g., Imperative, Declarative, etc.) most compatible with specifying infrastructural code. The OASIS TOSCA standard (\u201cTopology and Orchestration Specification for Cloud Applications\u201d) is the de-facto and de-iure standard language for infrastructure-as-code, and adopts an innovative take called \u201cintent modelling\u201d. This paper articulates the foundations of this modelling approach incorporating the most related modelling paradigm, that is, goal-modelling. We elaborate on it with a real but simple industrial sample featuring the\u00a0\u2026", "num_citations": "6\n", "authors": ["2279"]}
{"title": "Model-driven ML-Ops for intelligent enterprise applications: vision, approaches and challenges\n", "abstract": " This paper explores a novel vision for the disciplined, repeatable, and transparent model-driven development and Machine-Learning operations (ML-Ops) of intelligent enterprise applications. The proposed framework treats model abstractions of AI/ML models (named AI/ML Blueprints) as first-class citizens and promotes end-to-end transparency and portability from raw data detection- to model verification, and, policy-driven model management. This framework is grounded on the intelligent Application Architecture (iA2) and entails a first attempt to incorporate requirements stemming from (more) intelligent enterprise applications into a logically-structured architecture. The logical separation is grounded on the need to enact MLOps and logically separate basic data manipulation requirements (data-processing layer), from more advanced functionality needed to instrument applications with intelligence (data\u00a0\u2026", "num_citations": "5\n", "authors": ["2279"]}
{"title": "Verifying big data topologies by-design: a semi-automated approach\n", "abstract": " Big data architectures have been gaining momentum in recent years. For instance, Twitter uses stream processing frameworks like Apache Storm to analyse billions of tweets per minute and learn the trending topics. However, architectures that process big data involve many different components interconnected via semantically different connectors. Such complex architectures make possible refactoring of the applications a difficult task for software architects, as applications might be very different with respect to the initial designs. As an aid to designers and developers, we developed OSTIA (Ordinary Static Topology Inference Analysis) that allows detecting the occurrence of common anti-patterns across big data architectures and exploiting software verification techniques on the elicited architectural models. This paper illustrates OSTIA and evaluates its uses and benefits on three industrial-scale case-studies.", "num_citations": "4\n", "authors": ["2279"]}
{"title": "Splicing community and software architecture smells in agile teams: an industrial study\n", "abstract": " Software engineering nowadays largely relies on agile methods to carry out software development. In often highly distributed organizations, agile teams can develop organisational and socio-technical issues loosely defined as community smells, which reflect sub-optimal organisational configurations that bear additional project cost, a phenomenon called social debt. In this paper we look into the co-occurrence of such nasty organisational phenomena\u2014community smells\u2014with software architecture smells\u2014indicators that software architectures may exhibit sub-optimal modularization structures, with consequent additional cost. We conclude that community smells can serve as a guide to steer the qualities of software architectures within agile teams.", "num_citations": "4\n", "authors": ["2279"]}
{"title": "Quality Assurance of Heterogeneous Applications: The SODALITE Approach\n", "abstract": " A key focus of the SODALITE project is to assure the quality and performance of the deployments of applications over heterogeneous Cloud and HPC environments. It offers a set of tools to detect and correct errors, smells, and bugs in the deployment models and their provisioning workflows, and a framework to monitor and refactor deployment model instances at runtime. This paper presents objectives, designs, early results of the quality assurance framework and the refactoring framework.", "num_citations": "3\n", "authors": ["2279"]}
{"title": "Auto-scaling Using TOSCA Infrastructure as Code\n", "abstract": " Autoscaling cloud infrastructures still remains a challenging endeavour during orchestration, given the many possible risks, options, and connected costs. In this paper we discuss the options for defining and enacting autoscaling using TOSCA standard templates and its own policy definition specifications. The goal is to define infrastructure blueprints to be self-contained, executable by an orchestrator that can take over autonomously all scaling tasks while maintaining acceptable structural and non-functional quality levels.", "num_citations": "3\n", "authors": ["2279"]}
{"title": "Varying defect prediction approaches during project evolution: A preliminary investigation\n", "abstract": " Defect prediction approaches use various features of software product or process to prioritize testing, analysis and general quality assurance activities. Such approaches require the availability of project's historical data, making them inapplicable in early phase. To cope with this problem, researchers have proposed cross-project and even cross-company prediction models, which use training material from other projects to build the model. Despite such advances, there is limited knowledge of how, as the project evolves, it would be convenient to still keep using data from other projects, and when, instead, it might become convenient to switch towards a local prediction model. This paper empirically investigates, using historical data from four open source projects, on how the performance of various kinds of defect prediction approaches - within-project prediction, local and global cross-project prediction, and mixed\u00a0\u2026", "num_citations": "3\n", "authors": ["2279"]}
{"title": "\u201cThe Canary in the Coal Mine...\u201d A Cautionary Tale from the Decline of SourceForge\n", "abstract": " Forges are online collaborative platforms to support the development of distributed open source software. While once mighty keepers of open source vitality, software forges are rapidly becoming less and less relevant. For example, of the top 10 forges in 2011, only one survives today\u2014SourceForge\u2014the biggest of them all, but its numbers are dropping and its community is tenuous at best. Through mixed\u2010methods research, this article chronicles and analyze the software practice and experiences of the project's history\u2014in particular its architectural and community/organizational decisions. We discovered a number of suboptimal social and architectural decisions and circumstances that, may have led to SourceForge's demise. In addition, we found evidence suggesting that the impact of such decisions could have been monitored, reduced, and possibly avoided altogether. The use of sociotechnical insights needs to\u00a0\u2026", "num_citations": "2\n", "authors": ["2279"]}
{"title": "Autonomic Decentralized Microservices: The Gru Approach and Its Evaluation\n", "abstract": " Cloud applications are more and more featuring microservices as a design pattern, using related technologies (containerization, orchestration, continuous deployment, integration, and more) to speed up design, development, and operation. However, microservices are not bullet-proof: they increase design and management issues in the cloud adding to the mix all the intrinsic complexities of highly distributed systems. This addition can render ineffective all centralized management technologies like Docker or clustering systems like Swarm and Kubernetes. Conversely, autonomic and decentralized microservices management is still largely unexplored. We address this problem with Gru, an approach based on multiagent systems that adds an autonomic adaptation layer for microservice applications focusing on Docker, the de facto market leader in container technology. Gru is designed to support fully decentralized\u00a0\u2026", "num_citations": "2\n", "authors": ["2279"]}
{"title": "Fallacies and pitfalls on the road to DevOps: a longitudinal industrial study\n", "abstract": " DevOps has come into play to help companies in improving their product delivery. This paper offers an overview of the fallacies and pitfalls faced in this context by engineers and operators in an industrial case-study. We reveal a total of 8 key fallacies and pitfalls that span the organisational structure, technical structures, as well as software process and delivery mechanisms in the target case-study. Practitioners can use these challenges as references for diagnosing their own scenario while planning their own potential DevOps process migration strategy.", "num_citations": "2\n", "authors": ["2279"]}
{"title": "Cognitive distance and research output in computing education: a case-study\n", "abstract": " Contribution: This paper quantifies the phenomenon of more versus better research output in computing research education and elaborates on how the organizational variable known as cognitive distance plays a fundamental role in mediating such more versus better research output relation. Background: To improve the current educational system, investigation and quantification is needed of the \u201csilos.\u201d Cognitive distance-a measure of the differences in background, culture, and expertise between collaborators-may be a factor influencing the lack of quality and variety in research outputs. Addressing this is a key enabler for fruitful collaboration. Research Question: Does collaboration with similarly expert researchers yield better research? Methodology: A quantitative survey provides baseline data for cognitive distance while publication data allowed creation of a co-authorship network between 123 researchers in a\u00a0\u2026", "num_citations": "2\n", "authors": ["2279"]}
{"title": "DevOps Quality Engineering\n", "abstract": " DevOps is recently emerging as a disruptive series of principles and practices that reduce the amount of time between software refactoring and operationally deploying changes. Our theme issue proposal will host top papers accepted for the QUATIC 2018 track on DevOps Quality Engineering-the track in question seeks to shed light over the synergies and challenges in DevOps quality engineering, both from a process and technical perspective. Copyright c 2018 John Wiley & Sons, Ltd.", "num_citations": "2\n", "authors": ["2279"]}
{"title": "Towards DevOps for Privacy-by-Design in Data-Intensive Applications: A Research Roadmap\n", "abstract": " With the onset of Big Data and Data-Intensive Applications (DIAs) exploiting such big data, the problem of offering privacy guarantees to data owners becomes crucial, even more so with the emergence of DevOps development strategies where speed is paramount. This paper outlines this complex scenario and the challenges therein. On one hand, we outline a tool prototype that addresses the key challenge we found in industry, more specifically, assisting the process of continuous DIA architecting for the purpose of offering privacy-by-design guarantees. On the other hand we define a research roadmap in pursuit of a more correct and complete solution for ensured privacy-by-design in the context of Big Data DevOps.", "num_citations": "2\n", "authors": ["2279"]}
{"title": "Fathoming software evangelists with the D-index\n", "abstract": " The increased importance represented by open-source and crowd-sourced software developers and software development in general, inspired us to consider the following dilemma: can we \"compute\" virtuous software developers? The D-Index is our preliminary attempt. Essentially, the D-Index meaningfully equates several indicators for the virtues of a developer, such as, contributed code, its quality, mentoring in online learning communities, community engagement. Our preliminary evaluation of the index suggests that establishing the virtues for certain developers eases the identification of software \"evangelists\", key success enablers for software communities.", "num_citations": "2\n", "authors": ["2279"]}
{"title": "Automated Mapping of Vulnerability Advisories onto their Fix Commits in Open Source Repositories\n", "abstract": " The lack of comprehensive sources of accurate vulnerability data represents a critical obstacle to studying and understanding software vulnerabilities (and their corrections). In this paper, we present an approach that combines heuristics stemming from practical experience and machine-learning (ML) - specifically, natural language processing (NLP) - to address this problem. Our method consists of three phases. First, an advisory record containing key information about a vulnerability is extracted from an advisory (expressed in natural language). Second, using heuristics, a subset of candidate fix commits is obtained from the source code repository of the affected project by filtering out commits that are known to be irrelevant for the task at hand. Finally, for each such candidate commit, our method builds a numerical feature vector reflecting the characteristics of the commit that are relevant to predicting its match with the advisory at hand. The feature vectors are then exploited for building a final ranked list of candidate fixing commits. The score attributed by the ML model to each feature is kept visible to the users, allowing them to interpret of the predictions. We evaluated our approach using a prototype implementation named Prospector on a manually curated data set that comprises 2,391 known fix commits corresponding to 1,248 public vulnerability advisories. When considering the top-10 commits in the ranked results, our implementation could successfully identify at least one fix commit for up to 84.03% of the vulnerabilities (with a fix commit on the first position for 65.06% of the vulnerabilities). In conclusion, our method reduces considerably the\u00a0\u2026", "num_citations": "1\n", "authors": ["2279"]}
{"title": "DataOps for Societal Intelligence: a Data Pipeline for Labor Market Skills Extraction and Matching\n", "abstract": " Big Data analytics supported by AI algorithms enable skills localization and retrieval, in the context of a labor market intelligence problem. We formulate and solve this problem through specific DataOps models, blending data sources from administrative and technical partners in several countries into cooperation, creating shared knowledge to support policy and decision-making. We then focus on the critical task of skills extraction from resumes and vacancies featuring state-of-the-art machine learning models. We showcase preliminary results with applied machine learning on real data from the employment agencies of the Netherlands and the Flemish region in Belgium. The final goal is to match these skills to standard ontologies of skills, jobs and occupations.", "num_citations": "1\n", "authors": ["2279"]}
{"title": "Business-Savvy Blockchains with Gamification: A Framework for Collaborative Problem Solving.\n", "abstract": " This paper proposes a design pattern that combines gamification dynamics along with blockchains for the purpose of using blockchain technology in a business-savvy fashion as support to a framework for collaborative problem solving, ie, leveraging gamification to incentivize people to produce efficient, freely available and easily accessible solutions in the optimisation research and the potentiality of blockchain technology to safekeep the intellectual property on such solutions, marking the progress of problem solving as intellectual capital. The proposed gamification design pattern is then instantiated in the context of optimisation.", "num_citations": "1\n", "authors": ["2279"]}
{"title": "Towards A Model-Driven Design Tool for Big Data Architectures\n", "abstract": " Big Data technologies are rapidly becoming a key enabler for modern industries. However, the entry costs inherent to \u201cgoing Big\u201d are considerable, ranging from learning curve, renting/buying infrastructure, etc. A key component of these costs is the time spent on learning about and designing with the many big data frameworks (eg, Spark, Storm, HadoopMR, etc.) on the market. To reduce said costs while decreasing time-to-market we advocate the usage of Model-Driven Engineering (MDE), ie, software engineering by means of models and their automated manipulation. This paper outlines a tool architecture to support MDE for big data applications, illustrating with a case-study.", "num_citations": "1\n", "authors": ["2279"]}
{"title": "Supporting Networked Software Development\n", "abstract": " Supporting Networked Software Development (2014) | www.narcis.nl KNAW KNAW Narcis Back to search results VU University Amsterdam Publication Supporting Networked Software Development (2014) Open access . Pagina-navigatie: Main Save publication Save as MODS Export to Mendeley Save as EndNote Export to RefWorks Title Supporting Networked Software Development Author Tamburri, DA Thesis advisor van Vliet, JC; Lago, Patricia Publisher Information Management and Software Engineering; Network Institute; Software & Services; Software Engineering Date issued 2014 Access Open Access Language English Type Doctoral Thesis Publication https://research.vu.nl/en/publications/2745d01e-9462-4b1a-b5... Persistent Identifiers NBN urn:nbn:nl:ui:31-1871/50557 Handle 1871/50557 Metadata XML Source VU University Amsterdam Go to Website Navigation: Home about narcis login Nederlands \u2026", "num_citations": "1\n", "authors": ["2279"]}
{"title": "Round Trip Engineering for Legacy Space Data Systems Based on a Model Driven Architecture Approach\n", "abstract": " HE European Space Agency, ESA, is currently carrying out an ambitious program under the umbrella name of ESA Ground Operation System, EGOS, which shall standardize the infrastructure used throughout the ESA ground segments with the goal of improving the reliability, cost effectiveness and the interoperability of the ground systems.", "num_citations": "1\n", "authors": ["2279"]}