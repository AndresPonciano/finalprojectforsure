{"title": "The evolution of sentiment analysis\u0393\u00c7\u00f6A review of research topics, venues, and top cited papers\n", "abstract": " Sentiment analysis is one of the fastest growing research areas in computer science, making it challenging to keep track of all the activities in the area. We present a computer-assisted literature review, where we utilize both text mining and qualitative coding, and analyze 6996 papers from Scopus. We find that the roots of sentiment analysis are in the studies on public opinion analysis at the beginning of 20th century and in the text subjectivity analysis performed by the computational linguistics community in 1990\u0393\u00c7\u00d6s. However, the outbreak of computer-based sentiment analysis only occurred with the availability of subjective texts on the Web. Consequently, 99% of the papers have been published after 2004. Sentiment analysis papers are scattered to multiple publication venues, and the combined number of papers in the top-15 venues only represent ca. 30% of the papers in total. We present the top-20 cited papers\u252c\u00e1\u0393\u00c7\u00aa", "num_citations": "396\n", "authors": ["62"]}
{"title": "Guidelines for including grey literature and conducting multivocal literature reviews in software engineering\n", "abstract": " ContextA Multivocal Literature Review (MLR) is a form of a Systematic Literature Review (SLR) which includes the grey literature (e.g., blog posts, videos and white papers) in addition to the published (formal) literature (e.g., journal and conference papers). MLRs are useful for both researchers and practitioners since they provide summaries both the state-of-the art and \u0393\u00c7\u00f4practice in a given area. MLRs are popular in other fields and have recently started to appear in software engineering (SE). As more MLR studies are conducted and reported, it is important to have a set of guidelines to ensure high quality of MLR processes and their results.ObjectiveThere are several guidelines to conduct SLR studies in SE. However, several phases of MLRs differ from those of traditional SLRs, for instance with respect to the search process and source quality assessment. Therefore, SLR guidelines are only partially useful for\u252c\u00e1\u0393\u00c7\u00aa", "num_citations": "266\n", "authors": ["62"]}
{"title": "Benefits and Limitations of Automated Software Testing: Systematic Literature Review and Practitioner Survey\n", "abstract": " There is a documented gap between academic and practitioner views on software testing. This paper tries to close the gap by investigating both views regarding the benefits and limits of test automation. The academic views are studied with a systematic literature review while the practitioners views are assessed with a survey, where we received responses from 115 software professionals. The results of the systematic literature review show that the source of evidence regarding benefits and limitations is quite shallow as only 25 papers provide the evidence. Furthermore, it was found that benefits often originated from stronger sources of evidence (experiments and case studies), while limitations often originated from experience reports. We believe that this is caused by publication bias of positive results. The survey showed that benefits of test automation were related to test reusability, repeatability, test coverage and\u252c\u00e1\u0393\u00c7\u00aa", "num_citations": "262\n", "authors": ["62"]}
{"title": "Comparing and experimenting machine learning techniques for code smell detection\n", "abstract": " Several code smell detection tools have been developed providing different results, because smells can be subjectively interpreted, and hence detected, in different ways. In this paper, we perform the largest experiment of applying machine learning algorithms to code smells to the best of our knowledge. We experiment 16 different machine-learning algorithms on four code smells (Data Class, Large Class, Feature Envy, Long Method) and 74 software systems, with 1986 manually validated code smell samples. We found that all algorithms achieved high performances in the cross-validation data set, yet the highest performances were obtained by J48 and Random Forest, while the worst performance were achieved by support vector machines. However, the lower prevalence of code smells, i.e., imbalanced data, in the entire data set caused varying performances that need to be addressed in the future\u252c\u00e1\u0393\u00c7\u00aa", "num_citations": "232\n", "authors": ["62"]}
{"title": "What types of defects are really discovered in code reviews?\n", "abstract": " Research on code reviews has often focused on defect counts instead of defect types, which offers an imperfect view of code review benefits. In this paper, we classified the defects of nine industrial (C/C++) and 23 student (Java) code reviews, detecting 388 and 371 defects, respectively. First, we discovered that 75 percent of defects found during the review do not affect the visible functionality of the software. Instead, these defects improved software evolvability by making it easier to understand and modify. Second, we created a defect classification consisting of functional and evolvability defects. The evolvability defect classification is based on the defect types found in this study, but, for the functional defects, we studied and compared existing functional defect classifications. The classification can be useful for assigning code review roles, creating checklists, assessing software evolvability, and building software\u252c\u00e1\u0393\u00c7\u00aa", "num_citations": "216\n", "authors": ["62"]}
{"title": "Using metrics in Agile and Lean Software Development\u0393\u00c7\u00f4A systematic literature review of industrial studies\n", "abstract": " ContextSoftware industry has widely adopted Agile software development methods. Agile literature proposes a few key metrics but little is known of the actual metrics use in Agile teams.ObjectiveThe objective of this paper is to increase knowledge of the reasons for and effects of using metrics in industrial Agile development. We focus on the metrics that Agile teams use, rather than the ones used from outside by software engineering researchers. In addition, we analyse the influence of the used metrics.MethodThis paper presents a systematic literature review (SLR) on using metrics in industrial Agile software development. We identified 774 papers, which we reduced to 30 primary studies through our paper selection process.ResultsThe results indicate that the reasons for and the effects of using metrics are focused on the following areas: sprint planning, progress tracking, software quality measurement, fixing\u252c\u00e1\u0393\u00c7\u00aa", "num_citations": "210\n", "authors": ["62"]}
{"title": "Subjective evaluation of software evolvability using code smells: An empirical study\n", "abstract": " This paper presents the results of an empirical study on the subjective evaluation of code smells that identify poorly evolvable structures in software. We propose use of the term software evolvability to describe the ease of further developing a piece of software and outline the research area based on four different viewpoints. Furthermore, we describe the differences between human evaluations and automatic program analysis based on software evolvability metrics. The empirical component is based on a case study in a Finnish software product company, in which we studied two topics. First, we looked at the effect of the evaluator when subjectively evaluating the existence of smells in code modules. We found that the use of smells for code evaluation purposes can be difficult due to conflicting perceptions of different evaluators. However, the demographics of the evaluators partly explain the variation\u252c\u00e1\u0393\u00c7\u00aa", "num_citations": "177\n", "authors": ["62"]}
{"title": "The highways and country roads to continuous deployment\n", "abstract": " As part of a Finnish research program, researchers interviewed 15 information and communications technology companies to determine the extent to which the companies adopted continuous deployment. They also aimed to find out why continuous deployment is considered beneficial and what the obstacles are to its full adoption. The benefits mentioned the most often were the ability to get faster feedback, the ability to deploy more often to keep customers satisfied, and improved quality and productivity. Despite understanding the benefits, none of the companies adopted a fully automatic deployment pipeline. The companies also had higher continuous-deployment capability than what they practiced. In many cases, they consciously chose to not aim for full continuous deployment. Obstacles to full adoption included domain-imposed restrictions, resistance to change, customer desires, and developers' skill and\u252c\u00e1\u0393\u00c7\u00aa", "num_citations": "174\n", "authors": ["62"]}
{"title": "Perceived Causes of Software Project Failures\u0393\u00c7\u00f4An Analysis of their Relationships\n", "abstract": " ContextSoftware project failures are common. Even though the reasons for failures have been widely studied, the analysis of their causal relationships is lacking. This creates an illusion that the causes of project failures are unrelated.ObjectiveThe aim of this study is to conduct in-depth analysis of software project failures in four software product companies in order to understand the causes of failures and their relationships. For each failure, we want to understand which causes, so called bridge causes, interconnect different process areas, and which causes were perceived as the most promising targets for process improvement.MethodThe causes of failures were detected by conducting root cause analysis. For each cause, we classified its type, process area, and interconnectedness to other causes. We quantitatively analyzed which type, process area, and interconnectedness categories (bridge, local) were\u252c\u00e1\u0393\u00c7\u00aa", "num_citations": "173\n", "authors": ["62"]}
{"title": "The need for multivocal literature reviews in software engineering: complementing systematic literature reviews with grey literature\n", "abstract": " Systematic Literature Reviews (SLR) may not provide insight into the\" state of the practice\" in SE, as they do not typically include the\" grey\"(non-published) literature. A Multivocal Literature Review (MLR) is a form of a SLR which includes grey literature in addition to the published (formal) literature. Only a few MLRs have been published in SE so far. We aim at raising the awareness for MLRs in SE by addressing two research questions (RQs):(1) What types of knowledge are missed when a SLR does not include the multivocal literature in a SE field? and (2) What do we, as a community, gain when we include the multivocal literature and conduct MLRs? To answer these RQs, we sample a few example SLRs and MLRs and identify the missing and the gained knowledge due to excluding or including the grey literature. We find that (1) grey literature can give substantial benefits in certain areas of SE, and that (2) the\u252c\u00e1\u0393\u00c7\u00aa", "num_citations": "171\n", "authors": ["62"]}
{"title": "When and what to automate in software testing? A multi-vocal literature review\n", "abstract": " ContextMany organizations see software test automation as a solution to decrease testing costs and to reduce cycle time in software development. However, establishment of automated testing may fail if test automation is not applied in the right time, right context and with the appropriate approach.ObjectiveThe decisions on when and what to automate is important since wrong decisions can lead to disappointments and major wrong expenditures (resources and efforts). To support decision making on when and what to automate, researchers and practitioners have proposed various guidelines, heuristics and factors since the early days of test automation technologies. As the number of such sources has increased, it is important to systematically categorize the current state-of-the-art and -practice, and to provide a synthesized overview.MethodTo achieve the above objective, we have performed a Multivocal Literature\u252c\u00e1\u0393\u00c7\u00aa", "num_citations": "151\n", "authors": ["62"]}
{"title": "Bad smells\u0393\u00c7\u00f6humans as code critics\n", "abstract": " This work presents the results of an initial empirical study on the subjective evaluation of bad code smells, which identify poor structures in software. Based on a case study in a Finnish software product company, we make two contributions. First, we studied the evaluator effect when subjectively evaluating the existence of smells in code modules. We found that the use of smells for code evaluation purposes is hard due to conflicting perceptions of different evaluators. Second, we applied source code metrics for identifying three smells and compared these results to the subjective evaluations. Surprisingly, the metrics and smell evaluations did not correlate.", "num_citations": "126\n", "authors": ["62"]}
{"title": "Defect detection efficiency: Test case based vs. exploratory testing\n", "abstract": " This paper presents a controlled experiment comparing the defect detection efficiency of exploratory testing (ET) and test case based testing (TCT). While traditional testing literature emphasizes test cases, ET stresses the individual tester's skills during test execution and does not rely upon predesigned test cases. In the experiment, 79 advanced software engineering students performed manual functional testing on an open-source application with actual and seeded defects. Each student participated in two 90-minute controlled sessions, using ET in one and TCT in the other. We found no significant differences in defect detection efficiency between TCT and ET. The distributions of detected defects did not differ significantly regarding technical type, detection difficulty, or severity. However, TCT produced significantly more false defect reports than ET. Surprisingly, our results show no benefit of using predesigned test\u252c\u00e1\u0393\u00c7\u00aa", "num_citations": "110\n", "authors": ["62"]}
{"title": "Bad smells in software-a taxonomy and an empirical study\n", "abstract": " This study also compares the results of the smell survey to the source code metrics collected with automatic tools. The results show that developers\u0393\u00c7\u00d6 evaluations of the bad code smells do not correlate with the actual source code metrics. This means that the smell evaluations from developers are not very reliable and that there is a need for automatic smell measurement.", "num_citations": "105\n", "authors": ["62"]}
{"title": "The Role of the Tester's Knowledge in Exploratory Software Testing\n", "abstract": " We present a field study on how testers use knowledge while performing exploratory software testing (ET) in industrial settings. We video recorded 12 testing sessions in four industrial organizations, having our subjects think aloud while performing their usual functional testing work. Using applied grounded theory, we analyzed how the subjects performed tests and what type of knowledge they utilized. We discuss how testers recognize failures based on their personal knowledge without detailed test case descriptions. The knowledge is classified under the categories of domain knowledge, system knowledge, and general software engineering knowledge. We found that testers applied their knowledge either as a test oracle to determine whether a result was correct or not, or for test design, to guide them in selecting objects for test and designing tests. Interestingly, a large number of failures, windfall failures, were\u252c\u00e1\u0393\u00c7\u00aa", "num_citations": "102\n", "authors": ["62"]}
{"title": "A systematic literature review of literature reviews in software testing\n", "abstract": " ContextAny newcomer or industrial practitioner is likely to experience difficulties in digesting large volumes of knowledge in software testing. In an ideal world, all knowledge used in industry, education and research should be based on high-quality evidence. Since no decision should be made based on a single study, secondary studies become essential in presenting the evidence. According to our search, over 101 secondary studies have been published in the area of software testing since 1994. With this high number of secondary studies, it is important to conduct a review in this area to provide an overview of the research landscape in this area.ObjectiveThe goal of this study is to systematically map (classify) the secondary studies in software testing. We propose that tertiary studies can serve as summarizing indexes which facilitate finding the most relevant information from secondary studies and thus supporting\u252c\u00e1\u0393\u00c7\u00aa", "num_citations": "98\n", "authors": ["62"]}
{"title": "How do testers do it? An exploratory study on manual testing practices\n", "abstract": " We present the results of a qualitative observation study on the manual testing practices in four software development companies. Manual testing practices are seldom studied, and based on the literature we conjecture that they have a strong effect on the effectiveness of manual testing. We observed testing sessions of 11 software professionals performing system level functional testing. As a result we identified 22 manual testing practices that we classified into 9 test session strategies and 13 detailed test execution techniques. Many of the identified techniques were based on similar ideas as traditional test case design techniques. However, the subjects applied these techniques during manual testing without separate test design phase. The results indicate that software professionals use a wide set of strategies and techniques when performing manual testing. Testers seem to need and use techniques even if\u252c\u00e1\u0393\u00c7\u00aa", "num_citations": "96\n", "authors": ["62"]}
{"title": "Citations, research topics and active countries in software engineering: A bibliometrics study\n", "abstract": " Context: An enormous number of papers (more than 70,000) have been published in the area of Software Engineering (SE) since its inception in 1968. To better characterize and understand this massive research literature, there is a need for comprehensive bibliometrics assessments in this vibrant field.Objective: The objective of this study is to utilize automated citation and topic analysis to characterize the software engineering research literature over the years. While a few bibliometrics studies have appeared in the field of SE, this article aims to be the most comprehensive bibliometrics assessments in this vibrant field.Method: To achieve the above objective, we report in this paper a bibliometrics study with data collected from Scopus database consisting of over 70,000 articles. For thematic analysis, we used topic modeling to automatically generate the most probable topic distributions given the data.Results: We\u252c\u00e1\u0393\u00c7\u00aa", "num_citations": "84\n", "authors": ["62"]}
{"title": "Drivers for software refactoring decisions\n", "abstract": " This paper presents an empirical study of drivers for software refactoring decisions. We studied the refactoring decisions made by 37 students evaluating ten methods of a purposefully constructed Java program. The decision rationales reported by the evaluators were coded to identify the drivers behind the decisions. The identified drivers were categorized into Structure, Documentation, Visual Representation, and General drivers. The evaluators had conflicting opinions both regarding the internal quality of the methods and refactoring decisions. Complex code problems were detected only by experienced evaluators. Using regression analysis, we looked at the predictive value of drivers explaining the refactoring decisions. The most salient driver leading to a favourable refactoring decision was method size. This study provides information of the refactoring decisions and helps form a basis for creating code problem\u252c\u00e1\u0393\u00c7\u00aa", "num_citations": "66\n", "authors": ["62"]}
{"title": "A benchmark study on the effectiveness of search-based data selection and feature selection for cross project defect prediction\n", "abstract": " Context Previous studies have shown that steered training data or dataset selection can lead to better performance for cross project defect prediction (CPDP). On the other hand, feature selection and data quality are issues to consider in CPDP. Objective We aim at utilizing the Nearest Neighbor (NN)-Filter, embedded in genetic algorithm to produce validation sets for generating evolving training datasets to tackle CPDP while accounting for potential noise in defect labels. We also investigate the impact of using different feature sets. Method We extend our proposed approach, Genetic Instance Selection (GIS), by incorporating feature selection in its setting. We use 41 releases of 11 multi-version projects to assess the performance GIS in comparison with benchmark CPDP (NN-filter and Naive-CPDP) and within project (Cross-Validation (CV) and Previous Releases (PR)). To assess the impact of feature sets, we use\u252c\u00e1\u0393\u00c7\u00aa", "num_citations": "65\n", "authors": ["62"]}
{"title": "Analyzing an Automotive Testing Process with Evidence-Based Software Engineering\n", "abstract": " ContextEvidence-based software engineering (EBSE) provides a process for solving practical problems based on a rigorous research approach. The primary focus so far was on mapping and aggregating evidence through systematic reviews.ObjectivesWe extend existing work on evidence-based software engineering by using the EBSE process in an industrial case to help an organization to improve its automotive testing process. With this we contribute in (1) providing experiences on using evidence based processes to analyze a real world automotive test process and (2) provide evidence of challenges and related solutions for automotive software testing processes.MethodsIn this study we perform an in-depth investigation of an automotive test process using an extended EBSE process including case study research (gain an understanding of practical questions to define a research scope), systematic literature\u252c\u00e1\u0393\u00c7\u00aa", "num_citations": "62\n", "authors": ["62"]}
{"title": "Are test cases needed? Replicated comparison between exploratory and test-case-based software testing\n", "abstract": " Manual software testing is a widely practiced verification and validation method that is unlikely to fade away despite the advances in test automation. In the domain of manual testing, many practitioners advocate exploratory testing (ET), i.e., creative, experience-based testing without predesigned test cases, and they claim that it is more efficient than testing with detailed test cases. This paper reports a replicated experiment comparing effectiveness, efficiency, and perceived differences between ET and test-case-based testing (TCT) using 51 students as subjects, who performed manual functional testing on the jEdit text editor. Our results confirm the findings of the original study: 1) there is no difference in the defect detection effectiveness between ET and TCT, 2) ET is more efficient by requiring less design effort, and 3) TCT produces more false-positive defect reports than ET. Based on the small differences in\u252c\u00e1\u0393\u00c7\u00aa", "num_citations": "61\n", "authors": ["62"]}
{"title": "Development and evaluation of a lightweight root cause analysis method (ARCA method) - Field studies at four software companies\n", "abstract": " ContextThe key for effective problem prevention is detecting the causes of a problem that has occurred. Root cause analysis (RCA) is a structured investigation of the problem to identify which underlying causes need to be fixed. The RCA method consists of three steps: target problem detection, root cause detection, and corrective action innovation. Its results can help with process improvement.ObjectiveThis paper presents a lightweight RCA method, named the ARCA method, and its empirical evaluation. In the ARCA method, the target problem detection is based on a focus group meeting. This is in contrast to prior RCA methods, where the target problem detection is based on problem sampling, requiring heavy startup investments.MethodThe ARCA method was created with the framework of design science. We evaluated it through field studies at four medium-sized software companies using interviews and query\u252c\u00e1\u0393\u00c7\u00aa", "num_citations": "61\n", "authors": ["62"]}
{"title": "An experiment on subjective evolvability evaluation of object-oriented software: explaining factors and interrater agreement\n", "abstract": " Recent trends in software development have emphasized the importance of refactoring in preserving software evolvability. We performed two experiments on software evolvability evaluation, i.e. evaluating the existence of certain code problems called code smells and the refactoring decision. We studied the agreement of the evaluators. Interrater agreement was high for simple code smells and low for the refactoring decision. Furthermore, we analyzed evaluators' demographics and source code metrics as factors explaining the evaluations. The code metrics explained over 70% of the variation regarding the simple code smell evaluations, but only about 30% of the refactoring decision. Surprisingly, the demographics were not useful predictors neither for evaluating code smells nor the refactoring decision. The low agreement for the refactoring decisions may indicate difficulty in building tool support simulating real\u252c\u00e1\u0393\u00c7\u00aa", "num_citations": "50\n", "authors": ["62"]}
{"title": "More Testers\u0393\u00c7\u00f4The Effect of Crowd Size and Time Restriction in Software Testing\n", "abstract": " ContextThe questions of how many individuals and how much time to use for a single testing task are critical in software verification and validation. In software review and usability evaluation contexts, positive effects of using multiple individuals for a task have been found, but software testing has not been studied from this viewpoint.ObjectiveWe study how adding individuals and imposing time pressure affects the effectiveness and efficiency of manual testing tasks. We applied the group productivity theory from social psychology to characterize the type of software testing tasks.MethodWe conducted an experiment where 130 students performed manual testing under two conditions, one with a time restriction and pressure, i.e., a 2-h fixed slot, and another where the individuals could use as much time as they needed.ResultsWe found evidence that manual software testing is an additive task with a ceiling effect, like\u252c\u00e1\u0393\u00c7\u00aa", "num_citations": "49\n", "authors": ["62"]}
{"title": "Who tested my software? Testing as an organizationally cross-cutting activity\n", "abstract": " There is a recognized disconnect between testing research and industry practice, and more studies are needed on understanding how testing is conducted in real-world circumstances instead of demonstrating the superiority of specific methods. Recent literature indicates that testing is a cross-cutting activity that involves various organizational roles rather than the sole involvement of specialized testers. This research empirically investigates how testing involves employees in varying organizational roles in software product companies. We studied the organization and values of testing using an exploratory case study methodology through interviews, defect database analysis, workshops, analyses of documentation, and informal communications at three software product companies. We analyzed which employee groups test software in the case companies, and how many defects they find. Two companies\u252c\u00e1\u0393\u00c7\u00aa", "num_citations": "48\n", "authors": ["62"]}
{"title": "Prioritizing manual test cases in traditional and rapid release environments\n", "abstract": " Test case prioritization is one of the most practically useful activities in testing, specially for large scale systems. The goal is ranking the existing test cases in a way that they detect faults as soon as possible, so that any partial execution of the test suite detects maximum number of defects for the given budget. Test prioritization becomes even more important when the test execution is time consuming, e.g., manual system tests vs. automated unit tests. Most existing test case prioritization techniques are based on code coverage, which requires access to source code. However, manual testing is mainly done in a black- box manner (manual testers do not have access to the source code). Therefore, in this paper, we first examine the existing test case prioritization techniques and modify them to be applicable on manual black-box system testing. We specifically study a coverage- based, a diversity-based, and a risk driven\u252c\u00e1\u0393\u00c7\u00aa", "num_citations": "47\n", "authors": ["62"]}
{"title": "Advances in using agile and lean processes for software development\n", "abstract": " Software development processes have evolved according to market needs. Fast changing conditions that characterize current software markets have favored methods advocating speed and flexibility. Agile and Lean software development are in the forefront of these methods. This chapter presents a unified view of Agile software development, Lean software development, and most recent advances toward rapid releases. First, we introduce the area and explain the reasons why the software development industry begun to move into this direction in the late 1990s. Section 2 characterizes the research trends on Agile software development. This section helps understand the relevance of Agile software development in the research literature. Section 3 provides a walk through the roots of Agile and Lean thinking, as they originally emerged in manufacturing. Section 4 develops into Agile and Lean for software\u252c\u00e1\u0393\u00c7\u00aa", "num_citations": "45\n", "authors": ["62"]}
{"title": "Choosing the right test automation tool: a grey literature review of practitioner sources\n", "abstract": " Background: Choosing the right software test automation tool is not trivial, and recent industrial surveys indicate lack of right tools as the main obstacle to test automation. Aim: In this paper, we study how practitioners tackle the problem of choosing the right test automation tool. Method: We synthesize the\" voice\" of the practitioners with a grey literature review originating from 53 different companies. The industry experts behind the sources had roles such as\" Software Test Automation Architect\", and\" Principal Software Engineer\". Results: Common consensus about the important criteria exists but those are not applied systematically. We summarize the scattered steps from individual sources by presenting a comprehensive process for tool evaluation with 12 steps and a total of 14 different criteria for choosing the right tool. Conclusions: The practitioners tend to have general interest in and be influenced by related grey\u252c\u00e1\u0393\u00c7\u00aa", "num_citations": "43\n", "authors": ["62"]}
{"title": "Survey reproduction of defect reporting in industrial software development\n", "abstract": " Context: Defect reporting is an important part of software development in-vivo, but previous work from open source context suggests that defect reports often have insufficient information for defect fixing. Objective: Our goal was to reproduce and partially replicate one of those open source studies in industrial context to see how well the results could be generalized. Method: We surveyed developers from six industrial software development organizations about the defect report information, from three viewpoints: concerning quality, usefulness and automation possibilities of the information. Seventy-four developers out of 142 completed our survey. Results: Our reproduction confirms the results of the prior study in that \"steps to reproduce\" and \"observed behaviour\" are highly important defect information. Our results extend the results of the prior study as we found that \"part of the application\", \"configuration of the\u252c\u00e1\u0393\u00c7\u00aa", "num_citations": "36\n", "authors": ["62"]}
{"title": "Why are industrial agile teams using metrics and how do they use them?\n", "abstract": " Agile development methods are increasing in popularity, yet there are limited studies on the reasons and use of metrics in industrial agile development. This paper presents preliminary results from a systematic literature review. Based on our study, metrics and their use are focused to the following areas: Iteration planning, Iteration tracking, Motivating and improving, Identifying process problems, Pre-release quality, Post-release quality and Changes in processes or tools. The findings are mapped against agile principles and it seems that the use of metrics supports the principles with some deviations. Surprisingly, we find little evidence of the use of code metrics. Also, we note that there is a lot of evidence on the use of planning and tracking metrics. Finally, the use of metrics to motivate and enforce process improvements as well as applicable quality metrics can be interesting future research topics.", "num_citations": "32\n", "authors": ["62"]}
{"title": "Time pressure: a controlled experiment of test case development and requirements review\n", "abstract": " Time pressure is prevalent in the software industry in which shorter and shorter deadlines and high customer demands lead to increasingly tight deadlines. However, the effects of time pressure have received little attention in software engineering research. We performed a controlled experiment on time pressure with 97 observations from 54 subjects. Using a two-by-two crossover design, our subjects performed requirements review and test case development tasks. We found statistically significant evidence that time pressure increases efficiency in test case development (high effect size Cohen\u0393\u00c7\u00d6sd= 1.279) and in requirements review (medium effect size Cohen\u0393\u00c7\u00d6sd= 0.650). However, we found no statistically significant evidence that time pressure would decrease effectiveness or cause adverse effects on motivation, frustration or perceived performance. We also investigated the role of knowledge but found no\u252c\u00e1\u0393\u00c7\u00aa", "num_citations": "32\n", "authors": ["62"]}
{"title": "How is exploratory testing used? A state-of-the-practice survey\n", "abstract": " Context: Exploratory Testing has experienced a rise in popularity in the industry with the emergence of agile development practices, yet it remains unclear, in which domains and how it is used in practice.Goal: To study how software engineers understand and apply the principles of exploratory testing, as well as the specific advantages and difficulties they experience.Method: We conducted an online survey in the period June to August 2013 among Estonian and Finnish software developers and testers.Results: Our main findings are that the majority of testers, developers, and test managers using ET,(1) apply ET to usability-critical, performance-critical, security-critical and safety-critical software to a high degree;(2) use ET very flexibly in all types of test levels, activities, and phases;(3) perceive ET as an approach that supports creativity during testing and that is effective and efficient; and (4) find that ET is not easy to\u252c\u00e1\u0393\u00c7\u00aa", "num_citations": "30\n", "authors": ["62"]}
{"title": "Search based training data selection for cross project defect prediction\n", "abstract": " Context: Previous studies have shown that steered training data or dataset selection can lead to better performance for cross project defect prediction (CPDP). On the other hand, data quality is an issue to consider in CPDP.Aim: We aim at utilising the Nearest Neighbor (NN)-Filter, embedded in a genetic algorithm, for generating evolving training datasets to tackle CPDP, while accounting for potential noise in defect labels.Method: We propose a new search based training data (ie, instance) selection approach for CPDP called GIS (Genetic Instance Selection) that looks for solutions to optimize a combined measure of F-Measure and GMean, on a validation set generated by (NN)-filter. The genetic operations consider the similarities in features and address possible noise in assigned defect labels. We use 13 datasets from PROMISE repository in order to compare the performance of GIS with benchmark CPDP\u252c\u00e1\u0393\u00c7\u00aa", "num_citations": "29\n", "authors": ["62"]}
{"title": "Testing highly complex system of systems: an industrial case study\n", "abstract": " Context: Systems of systems (SoS) are highly complex and are integrated on multiple levels (unit, component, system, system of systems). Many of the characteristics of SoS (such as operational and managerial independence, integration of system into system of systems, SoS comprised of complex systems) make their development and testing challenging. Contribution: This paper provides an understanding of SoS testing in large-scale industry settings with respect to challenges and how to address them. Method: The research method used is case study research. As data collection methods we used interviews, documentation, and fault slippage data. Results: We identified challenges related to SoS with respect to fault slippage, test turn-around time, and test maintainability. We also classified the testing challenges to general testing challenges, challenges amplified by SoS, and challenges that are SoS specific\u252c\u00e1\u0393\u00c7\u00aa", "num_citations": "29\n", "authors": ["62"]}
{"title": "Measuring LDA topic stability from clusters of replicated runs\n", "abstract": " Background: Unstructured and textual data is increasing rapidly and Latent Dirichlet Allocation (LDA) topic modeling is a popular data analysis methods for it. Past work suggests that instability of LDA topics may lead to systematic errors. Aim: We propose a method that relies on replicated LDA runs, clustering, and providing a stability metric for the topics. Method: We generate k LDA topics and replicate this process n times resulting in n* k topics. Then we use K-medioids to cluster the n* k topics to k clusters. The k clusters now represent the original LDA topics and we present them like normal LDA topics showing the ten most probable words. For the clusters, we try multiple stability metrics, out of which we recommend Rank-Biased Overlap, showing the stability of the topics inside the clusters. Results: We provide an initial validation where our method is used for 270,000 Mozilla Firefox commit messages with k= 20\u252c\u00e1\u0393\u00c7\u00aa", "num_citations": "26\n", "authors": ["62"]}
{"title": "Test prioritization in continuous integration environments\n", "abstract": " Two heuristics namely diversity-based (DBTP) and history-based test prioritization (HBTP) have been separately proposed in the literature. Yet, their combination has not been widely studied in continuous integration (CI) environments. The objective of this study is to catch regression faults earlier, allowing developers to integrate and verify their changes more frequently and continuously. To achieve this, we investigated six open-source projects, each of which included several builds over a large time period. Findings indicate that previous failure knowledge seems to have strong predictive power in CI environments and can be used to effectively prioritize tests. HBTP does not necessarily need to have large data, and its effectiveness improves to a certain degree with larger history interval. DBTP can be used effectively during the early stages, when no historical data is available, and also combined with HBTP to\u252c\u00e1\u0393\u00c7\u00aa", "num_citations": "23\n", "authors": ["62"]}
{"title": "Lightweight elicitation and analysis of software product quality goals: A multiple industrial case study\n", "abstract": " We developed and used a method that gathers relevant stakeholders to elicit, prioritize, and elaborate the quality goals of a software product. It is designed to be lightweight and easy to learn compared to methods for a more comprehensive analysis of non-functional requirements. The method and the resulting quality goals are meant especially for improving the software product management process. We used it in four software product companies, and report lessons learned and evaluation of the method based on practitioners' comments. We found it better to set the goals first for the product in general before discussing a specific release project. In addition to identifying goals that needed improvement, the practitioners considered identifying already achieved goals relevant, but they were neg- lected unless explicitly considered. Using ISO 9126 as a checklist after brainstorming did not add many goals. Prioritization\u252c\u00e1\u0393\u00c7\u00aa", "num_citations": "23\n", "authors": ["62"]}
{"title": "Time pressure in software engineering: A systematic review\n", "abstract": " ContextLarge project overruns and overtime work have been reported in the software industry, resulting in additional expense for companies and personal issues for developers. Experiments and case studies have investigated the relationship between time pressure and software quality and productivity.ObjectiveThe present work aims to provide an overview of studies related to time pressure in software engineering; specifically, existing definitions, possible causes, and metrics relevant to time pressure were collected, and a mapping of the studies to software processes and approaches was performed. Moreover, we synthesize results of existing quantitative studies on the effects of time pressure on software development, and offer practical takeaways for practitioners and researchers, based on empirical evidence.MethodOur search strategy examined 5414 sources, found through repository searches and\u252c\u00e1\u0393\u00c7\u00aa", "num_citations": "22\n", "authors": ["62"]}
{"title": "A replicated study on duplicate detection: Using Apache Lucene to search among Android defects\n", "abstract": " Context: Duplicate detection is a fundamental part of issue management. Systems able to predict whether a new defect report will be closed as a duplicate, may decrease costs by limiting rework and collecting related pieces of information. Goal: Our work explores using Apache Lucene for large-scale duplicate detection based on textual content. Also, we evaluate the previous claim that results are improved if the title is weighted as more important than the description. Method: We conduct a conceptual replication of a well-cited study conducted at Sony Ericsson, using Lucene for searching in the public Android defect repository. In line with the original study, we explore how varying the weighting of the title and the description affects the accuracy. Results: We show that Lucene obtains the best results when the defect report title is weighted three times higher than the description, a bigger difference than has been\u252c\u00e1\u0393\u00c7\u00aa", "num_citations": "22\n", "authors": ["62"]}
{"title": "Software deployment activities and challenges-a case study of four software product companies\n", "abstract": " Software deployment, including both clean installs and updates, is a crucial activity for all software vendors. It starts with a customer's order of a new release and incorporates all steps taken until the customer is satisfied with the deployed product. Using interviews as the main data collection method, we conducted a case study of four companies to discover their software deployment activities and challenges. The studied products were more complicated than pure COTS products. We noticed three product characteristics that make deployment more challenging: 1) the product is tightly integrated to other customer systems, 2) the product offers various configuration options to support different ways of working, and 3) the product requires a pre-created, complex, real-world data model to be usable. We also noticed that software deployment is multifaceted, involving activities related to customer interaction, making\u252c\u00e1\u0393\u00c7\u00aa", "num_citations": "21\n", "authors": ["62"]}
{"title": "Industry-academia collaborations in software engineering: An empirical analysis of challenges, patterns and anti-patterns in research projects\n", "abstract": " Research collaboration between industry and academia supports improvement and innovation in industry and helps to ensure industrial relevance in academic research. However, many researchers and practitioners believe that the level of joint industry-academia collaboration (IAC) in software engineering (SE) research is still relatively low, compared to the amount of activity in each of the two communities. The goal of the empirical study reported in this paper is to exploratory characterize the state of IAC with respect to a set of challenges, patterns and anti-patterns identified by a recent Systematic Literature Review study. To address the above goal, we gathered the opinions of researchers and practitioners wrt their experiences in IAC projects. Our dataset includes 47 opinion data points related to a large set of projects conducted in 10 different countries. We aim to contribute to the body of evidence in the area of\u252c\u00e1\u0393\u00c7\u00aa", "num_citations": "17\n", "authors": ["62"]}
{"title": "Gamification of software testing-an MLR\n", "abstract": " This paper presents an initial multi-vocal literature review that extracts ideas for gamification of software testing. We surveyed the type of testing, system under test, role of individuals, gamification elements, challenges and drawbacks, support constructs and tools, and empirical evidence from academic sources and grey literature. Ideas were given to both automated unit-testing, and end-user related testing done by exploratory testers and beta testers. The most frequent gamification elements were points (13 sources), awards (4), stories (4), badges (3), rankings (3), levels (3) and time-pressure (3).", "num_citations": "17\n", "authors": ["62"]}
{"title": "A tool supporting root cause analysis for synchronous retrospectives in distributed software teams\n", "abstract": " ContextRoot cause analysis (RCA) is a useful practice for software project retrospectives, and is typically carried out in synchronous collocated face-to-face meetings. Conducting RCA with distributed teams is challenging, as face-to-face meetings are infeasible. Lack of adequate real-time tool support exacerbates this problem. Furthermore, there are no empirical studies on using RCA in synchronous retrospectives of geographically distributed teams.ObjectiveThis paper presents a real-time cloud-based software tool (ARCA-tool) we developed to support RCA in distributed teams and its initial empirical evaluation. The feasibility of using RCA with distributed teams is also evaluated.MethodWe compared our tool with 35 existing RCA software tools. We conducted field studies of four distributed agile software teams at two international software product companies. The teams conducted RCA collaboratively in\u252c\u00e1\u0393\u00c7\u00aa", "num_citations": "17\n", "authors": ["62"]}
{"title": "Benefitting from the grey literature in software engineering research\n", "abstract": " Researchers generally place the most trust in peer-reviewed, published information, such as journals and conference papers. By contrast, software engineering (SE) practitioners typically do not have the time, access, or expertise to review and benefit from such publications. As a result, practitioners are more likely to turn to other sources of information that they trust, e.g., trade magazines, online blog posts, survey results, or technical reports, collectively referred to as grey literature (GL). Furthermore, practitioners also share their ideas and experiences as GL, which can serve as a valuable data source for research. While GL itself is not a new topic in SE, using, benefitting, and synthesizing knowledge from the GL in SE is a contemporary topic in empirical SE research and we are seeing that researchers are increasingly benefitting from the knowledge available within GL. The goal of this chapter is to provide an\u252c\u00e1\u0393\u00c7\u00aa", "num_citations": "14\n", "authors": ["62"]}
{"title": "Citation and Topic Analysis of the ESEM papers\n", "abstract": " Context: The pool of papers published in ESEM. Objective: To utilize citation analysis and automated topic analysis to characterize the SE research literature over the years focusing on those papers published in ESEM. Method: We collected data from Scopus database consisting of 513 ESEM papers. For thematic analysis, we used topic modeling to automatically generate the most probable topic distributions given the data. Results: Nearly 42% of the papers have not been cited at all but the effect seems to wear off as time passes. Using text mining of article titles and abstracts, we found that currently the most popular research topics in the ESEM community are: systematic reviews, testing, defects, cost estimation, and team work. Conclusions: While this study analyzes the paper pool of the ESEM symposium, the approach can easily be applied to any other sub-set of SE papers to conduct large scale studies. Due to\u252c\u00e1\u0393\u00c7\u00aa", "num_citations": "14\n", "authors": ["62"]}
{"title": "How are software defects found? The role of implicit defect detection, individual responsibility, documents, and knowledge\n", "abstract": " ContextPrior research has focused heavily on explicit defect detection, such as formal testing and reviews. However, in reality, humans find software defects in various activities. Implicit defect detection activities, such as preparing a product demonstration or updating a user manual, are not designed for defect detection, yet through such activities defects are discovered. In addition, the type of documentation, and knowledge used, in defect detection is diverse.ObjectiveTo understand how defect detection is affected by the perspectives of responsibility, activity, knowledge, and document use. To provide illustrative numbers concerning the multidimensionality of defect detection in an industrial context.MethodThe data were collected with a survey on four software development organizations in three different companies. We designed the survey based on our prior extensive work with these companies.ResultsWe found\u252c\u00e1\u0393\u00c7\u00aa", "num_citations": "14\n", "authors": ["62"]}
{"title": "Characterizing industry-academia collaborations in software engineering: evidence from 101 projects\n", "abstract": " Research collaboration between industry and academia supports improvement and innovation in industry and helps ensure the industrial relevance of academic research. However, many researchers and practitioners in the community believe that the level of joint industry-academia collaboration (IAC) projects in Software Engineering (SE) research is relatively low, creating a barrier between research and practice. The goal of the empirical study reported in this paper is to explore and characterize the state of IAC with respect to industrial needs, developed solutions, impacts of the projects and also a set of challenges, patterns and anti-patterns identified by a recent Systematic Literature Review (SLR) study. To address the above goal, we conducted an opinion survey among researchers and practitioners with respect to their experience in IAC. Our dataset includes 101 data points from IAC projects\u252c\u00e1\u0393\u00c7\u00aa", "num_citations": "13\n", "authors": ["62"]}
{"title": "Using surveys and web-scraping to select tools for software testing consultancy\n", "abstract": " We analyzed findings from data collected utilizing surveys and Web-scraping, to support Knowit Oy, a software testing consultation company, in the process of selecting the right tools for software testing & test automation. We conducted two surveys (2013 & 2016) among (mostly Finnish) software professionals to acquire criteria and a list of tools used for software testing in industry. Considering all our data sources Selenium was the most popular pure tool, while Robot Framework was the most referenced tool (latter survey). According to the surveys Jenkins and Sikuli have the highest increase in popularity (or familiarity). Top referred criteria for selection were usability, functionality, maintainability and available support for a tool. While Knowit considers it best to utilize traditional surveys, Web-scraping is seen as cost effective support for such instruments. To get comprehensive picture and to gain knowledge\u252c\u00e1\u0393\u00c7\u00aa", "num_citations": "13\n", "authors": ["62"]}
{"title": "What are Problem Causes of Software Projects? Data of Root Cause Analysis at Four Software Companies\n", "abstract": " Root cause analysis (RCA) is a structured investigation of a problem to detect the causes that need to be prevented. We applied ARCA, an RCA method, to target problems of four medium-sized software companies and collected 648 causes of software engineering problems. Thereafter, we applied grounded theory to the causes to study their types and related process areas. We detected 14 types of causes in 6 process areas. Our results indicate that development work and software testing are the most common process areas, whereas lack of instructions and experiences, insufficient work practices, low quality task output, task difficulty, and challenging existing product are the most common types of the causes. As the types of causes are evenly distributed between the cases, we hypothesize that the distributions could be generalizable. Finally, we found that only 2.5% of the causes are related to software\u252c\u00e1\u0393\u00c7\u00aa", "num_citations": "13\n", "authors": ["62"]}
{"title": "Characteristics of high performing testers: a case study\n", "abstract": " Objective: We studied what are the characteristics of high performing software testers in the industry. Method: We conducted an exploratory case study, collecting data through recorded interviews of one development manager and three testers in each of the three companies, analysis of the defect database, and informal communication within our research partnership with the companies. Results: We found that experience, reflection, motivation and personal characteristics were the top level themes. Experience related to the domain, eg processes of the customer, and on the other hand, specialized technical skills, eg performance testing, were seen more important than skills of test case design and test planning.", "num_citations": "13\n", "authors": ["62"]}
{"title": "Natural language or not (nlon) a package for software engineering text analysis pipeline\n", "abstract": " The use of natural language processing (NLP) is gaining popularity in software engineering. In order to correctly perform NLP, we must pre-process the textual information to separate natural language from other information, such as log messages, that are often part of the communication in software engineering. We present a simple approach for classifying whether some textual input is natural language or not. Although our NLoN package relies on only 11 language features and character tri-grams, we are able to achieve an area under the ROC curve performances between 0.976-0.987 on three different data sources, with Lasso regression from Glmnet as our learner and two human raters for providing ground truth. Cross-source prediction performance is lower and has more fluctuation with top ROC performances from 0.913 to 0.980. Compared with prior work, our approach offers similar performance but is\u252c\u00e1\u0393\u00c7\u00aa", "num_citations": "12\n", "authors": ["62"]}
{"title": "TestAWARE: a laboratory-oriented testing tool for mobile context-aware applications\n", "abstract": " Although mobile context instrumentation frameworks have simplified the development of mobile context-aware applications, it remains challenging to test such applications. In this paper, we present TestAWARE that enables developers to systematically test context-aware applications in laboratory settings. To achieve this, TestAWARE is able to download, replay and emulate contextual data on either physical devices or emulators. To support both white -box and black-box testing, TestAWARE has been implemented as a novel structure with a mobile client and code library. In blackbox testing scenarios, developers can manage data replay through the mobile client, without writing testing scripts or modifying the source code of the targeted application. In white-box testing scenarios, developers can manage data replay and test functional/non-functional properties of the targeted application by writing testing scripts\u252c\u00e1\u0393\u00c7\u00aa", "num_citations": "12\n", "authors": ["62"]}
{"title": "Build Waiting Time in Continuous Integration--An Initial Interdisciplinary Literature Review\n", "abstract": " In this position paper, we present and demonstrate the idea of using an interdisciplinary literature review to accelerate the research on continuous integration practice. A common suggestion has been that build waiting time in continuous integration cycle should be less than 10 minutes. This guideline is based on practitioners' opinion and has not been further investigated. The objective of this study is to understand the effects of build waiting time in software engineering and to get input from waiting time research in other disciplines. The objective is met by performing two literature reviews, first on build waiting time and second on waiting times in the contexts of service operation, web use and computer use. The found effects of build waiting time were categorized into continuous integration specific, cognitive and emotional. Two minute build waiting time was considered optimal, but under 10 minutes was considered\u252c\u00e1\u0393\u00c7\u00aa", "num_citations": "11\n", "authors": ["62"]}
{"title": "Developing new approaches for software design quality improvement based on subjective evaluations\n", "abstract": " This research abstract presents two approaches for utilizing the developers' subjective design quality evaluations during the software lifecycle. In process-based approach developers study and improve their system's structure at fixed intervals. Tool-based approach uses subjective evaluations as input to tool analysis. These approaches or their combination are expected to improve software design and promote organizational learning about software design.", "num_citations": "11\n", "authors": ["62"]}
{"title": "The Effect of Team Exploratory Testing--Experience Report from F-Secure\n", "abstract": " Practitioners have found exploratory testing (ET) to be cost effective in detecting defects. The team exploratory testing (TET) approach scales exploratory testing to team level. This paper reports the effectiveness of (TET), and the experiences of the participants of TET sessions. The research was carried at F-Secure Corporation, where two projects were investigated. The results show that the TET sessions have good effectiveness and higher efficiency than other testing methods in the company measured in number of defects detected. Furthermore, the TET sessions found more usability defects that other methods. The session participants saw benefits in especially in the joint discussion and learning of the target application. However, with respect to test effectiveness and efficiency we should be cautions as further studies are needed to compensate the limitations of this work.", "num_citations": "10\n", "authors": ["62"]}
{"title": "Supporting regression test scoping with visual analytics\n", "abstract": " Background: Test managers have to repeatedly select test cases for test activities during evolution of large software systems. Researchers have widely studied automated test scoping, but have not fully investigated decision support with human interaction. We previously proposed the introduction of visual analytics for this purpose. Aim: In this empirical study we investigate how to design such decision support. Method: We explored the use of visual analytics using heat maps of historical test data for test scoping support by letting test managers evaluate prototype visualizations in three focus groups with in total nine industrial test experts. Results: All test managers in the study found the visual analytics useful for supporting test planning. However, our results show that different tasks and contexts require different types of visualizations. Conclusion: Important properties for test planning support are: ability to overview\u252c\u00e1\u0393\u00c7\u00aa", "num_citations": "10\n", "authors": ["62"]}
{"title": "Empirical software evolvability-code smells and human evaluations\n", "abstract": " Low software evolvability may increase costs of software development for over 30%. In practice, human evaluations and discoveries of software evolvability dictate the actions taken to improve the software evolvability, but the human side has often been ignored in prior research. This dissertation synopsis proposes a new group of code smells called the solution approach, which is based on a study of 563 evolvability issues found in industrial and student code reviews. Solution approach issues require re-thinking of the existing implementation rather than just reorganizing the code through refactoring. This work also contributes to the body of knowledge about software quality assurance practices by confirming that 75% of defects found in code reviews affect software evolvability rather than functionality. We also found evidence indicating that context-specific demographics, i.e., role in organization and code\u252c\u00e1\u0393\u00c7\u00aa", "num_citations": "10\n", "authors": ["62"]}
{"title": "Rethinking replication in software engineering: Can we see the forest for the trees\n", "abstract": " In this paper, we argue that the concept of replication of empirical studies in software engineering should be understood more broadly than it currently is. In particular, the replication of case studies and surveys as a way of validating and extending theories should be incorporated in the mainstream view of replication, which at present is mostly focused on controlled experiments. A small-sample study of papers in IEEE Transactions on Software Engineering shows that about 10% of studies published in 2009 can be considered replications. However, none of these was self-labeled as replication. We think that the authors believed that labeling their work as replication might decrease its value in the eyes of reviewers and editors. We conclude that there is no acute shortage of replication studies in software engineering if taking a broader viewpoint to replication, but the definition and valuation of \u0393\u00c7\u00ffreplication studies\u0393\u00c7\u00d6 need to be re-evaluated in the software engineering community.", "num_citations": "9\n", "authors": ["62"]}
{"title": "Practitioner evaluations on software testing tools\n", "abstract": " In software engineering practice, evaluating and selecting the software testing tools that best fit the project at hand is an important and challenging task. In scientific studies of software engineering, practitioner evaluations and beliefs have recently gained interest, and some studies suggest that practitioners find beliefs of peers more credible than empirical evidence. To study how software practitioners evaluate testing tools, we applied online opinion surveys (n= 89). We analyzed the reliability of the opinions utilizing Krippendorff's alpha, intra-class correlation coefficient (ICC), and coefficients of variation (CV). Negative binomial regression was used to evaluate the effect of demographics. We find that opinions towards a specific tool can be conflicting. We show how increasing the number of respondents improves the reliability of the estimates measured with ICC. Our results indicate that on average, opinions from\u252c\u00e1\u0393\u00c7\u00aa", "num_citations": "8\n", "authors": ["62"]}
{"title": "On the use of emoticons in open source software development\n", "abstract": " Background: Using sentiment analysis to study software developers' behavior comes with challenges such as the presence of a large amount of technical discussion unlikely to express any positive or negative sentiment. However, emoticons provide information about developer sentiments that can easily be extracted from software repositories. Aim: We investigate how software developers use emoticons differently in issue trackers in order to better understand the differences between developers and determine to which extent emoticons can be used as in place of sentiment analysis. Method: We extract emoticons from 1.3 M comments from Apache's issue tracker and 4.5 M from Mozilla's issue tracker using regular expressions built from a list of emoticons used by SentiStrength and Wikipedia. We check for statistical differences using Mann-Whitney U tests and determine the effect size with Cliff's \u256c\u2524. Results: Overall\u252c\u00e1\u0393\u00c7\u00aa", "num_citations": "8\n", "authors": ["62"]}
{"title": "Reviewing literature on time pressure in software engineering and related professions: computer assisted interdisciplinary literature review\n", "abstract": " During the past few years, psychological diseases related to unhealthy work environments, such as burnouts, have drawn more and more public attention. One of the known causes of these affective problems is time pressure. In order to form a theoretical background for time pressure detection in software repositories, this paper combines interdisciplinary knowledge by analyzing 1270 papers found on Scopus database and containing terms related to time pressure. By clustering those papers based on their abstract, we show that time pressure has been widely studied across different fields, but relatively little in software engineering. From a literature review of the most relevant papers, we infer a list of testable hypotheses that we want to verify in future studies in order to assess the impact of time pressures on software developers' mental health.", "num_citations": "8\n", "authors": ["62"]}
{"title": "How to validate mobile crowdsourcing design? leveraging data integration in prototype testing\n", "abstract": " Mobile crowdsourcing applications often run in dynamic environments. Due to limited time and budget, developers of mobile crowdsourcing applications sometimes cannot completely test their prototypes in real world situations. We describe a data integration technique for developers to validate their design in prototype testing. Our approach constructs the intended context by combining real-time, historical and simulated data. With correct context-aware design, mobile crowdsourcing applications presenting crowdsourcing questions in relevant context to users are likely to obtain high response quality.", "num_citations": "8\n", "authors": ["62"]}
{"title": "Daily questionnaire to assess self-reported well-being during a software development project\n", "abstract": " According to authors best knowledge, this workshop paper makes two novel extensions to software engineering research. First, we create and execute a daily questionnaire monitoring the work well-being of software developers through a period of eight months. Second, we utilize statistical methods developed for discovering psychological dynamics to analyze this data. Our questionnaire includes elements from job satisfaction surveys and one software development specific element. The data were collected every day for a period of 8 months in a single software development project producing 526 answers from eight developers. The preliminary analysis shows the strongest correlations between hurry and interruptions. Additionally, we constructed temporal and contemporaneous network models used for discovering psychological dynamics from the questionnaire responses. In the future, we will try to establish\u252c\u00e1\u0393\u00c7\u00aa", "num_citations": "7\n", "authors": ["62"]}
{"title": "Diagrams or structural lists in software project retrospectives\u0393\u00c7\u00f4an experimental comparison\n", "abstract": " Root cause analysis (RCA) is a recommended practice in retrospectives and cause\u0393\u00c7\u00f4effect diagram (CED) is a commonly recommended technique for RCA. Our objective is to evaluate whether CED improves the outcome and perceived utility of RCA. We conducted a controlled experiment with 11 student software project teams by using a single factor paired design resulting in a total of 22 experimental units. Two visualization techniques of underlying causes were compared: CED and a structural list of causes. We used the output of RCA, questionnaires, and group interviews to compare the two techniques. In our results, CED increased the total number of detected causes. CED also increased the links between causes, thus, suggesting more structured analysis of problems. Furthermore, the participants perceived that CED improved organizing and outlining the detected causes. The implication of our results is that\u252c\u00e1\u0393\u00c7\u00aa", "num_citations": "7\n", "authors": ["62"]}
{"title": "A systematic mapping study of empirical studies on the use of pair programming in industry\n", "abstract": " Previous systematic literature reviews on pair programming (PP) lack in their coverage of industrial PP data as well as certain factors of PP such as infrastructure. Therefore, we conducted a systematic mapping study on empirical, industrial PP research. Based on 154 research papers, we built a new PP framework containing 18 factors. We analyzed the previous research on each factor through several research properties. The most thoroughly studied factors in industry are communication, knowledge of work, productivity and quality. Many other factors largely lack comparative data, let alone data from reliable data collection methods such as measurement. Based on these gaps in research further studies would be most valuable for development process, targets of PP, developers\u0393\u00c7\u00d6 characteristics, and feelings of work. We propose how they could be studied better. If the gaps had been commonly known, they could\u252c\u00e1\u0393\u00c7\u00aa", "num_citations": "7\n", "authors": ["62"]}
{"title": "Pacing software product development: a framework and practical implementation guidelines\n", "abstract": " Pacing Software Product Development: A Framework and Practical Implementation Guidelines \u0393\u00c7\u00f6 Aalto University's research portal Skip to main navigation Skip to search Skip to main content Aalto University's research portal Logo Accessibility statement English Suomi Home Profiles Research output Datasets Projects Prizes Activities Press / Media Infrastructure Research Units Impacts Search by expertise, name or affiliation Pacing Software Product Development: A Framework and Practical Implementation Guidelines Kristian Rautiainen, Casper Lassenius, Juha Itkonen, Mika V. M\u251c\u00f1ntyl\u251c\u00f1, Mikko Rusama, Jari Vanhanen, Jarno V\u251c\u00f1h\u251c\u00f1niitty Research output: Book/Report \u0393\u00c7\u2551 Book \u0393\u00c7\u2551 Professional Overview Original language English Place of Publication Espoo Publisher Helsinki University of Technology, Software Business and Engineering Institute ISBN (Electronic) 951-22-8382-4 ISBN (Print) 951-22-7069-2 Publication - , :\u0393\u00c7\u00aa", "num_citations": "7\n", "authors": ["62"]}
{"title": "6G White Paper on Validation and Trials for Verticals towards 2030's\n", "abstract": " This white paper discusses the different business verticals that are expected to gain productivity enhancements with the introduction of B5G/6G wireless services. It is evident that wireless offers benefits when the use case exhibits mobility, requires nomadic behavior or flexibility and in some situation, cost may be favoring wireless solutions (eg retrofitting). In many cases, however, fiber optic solution is still a viable approach. Based on revenue expansion potential as well as most opportunity rich verticals, we have chosen seven vertical businesses and future software based testing to be singled out for discussion. These include industry4. 0, future mobility, eHealth, energy, finance and banking, public safety and agribusiness. We describe drivers in the respective verticals and the change expected. We also highlight the features within verticals that may require 6G capabilities and make a very first attempt to provide some key performance and value indicators for vertical businesses highlighting the divergence in requirements to be experienced in the 2030\u0393\u00c7\u00d6s. We conclude the discussion with proposing some guidelines for trialing and validation activities within verticals to agree golden references that give a reference baseline against which any system provider can test their solutions. Out of the white paper, we have finally formulated critical research questions to be answered during this decade to provide the vertical specific solutions foreseen.", "num_citations": "6\n", "authors": ["62"]}
{"title": "Towards automatically identifying paid open source developers\n", "abstract": " Open source development contains contributions from both hired and volunteer software developers. Identification of this status is important when we consider the transferability of research results to the closed source software industry, as they include no volunteer developers. While many studies have taken the employment status of developers into account, this information is often gathered manually due to the lack of accurate automatic methods. In this paper, we present an initial step towards predicting paid and unpaid open source development using machine learning and compare our results with automatic techniques used in prior work. By relying on code source repository meta-data from Mozilla, and manually collected employment status, we built a dataset of the most active developers, both volunteer and hired by Mozilla. We define a set of metrics based on developers' usual commit time pattern and use\u252c\u00e1\u0393\u00c7\u00aa", "num_citations": "6\n", "authors": ["62"]}
{"title": "Software Evolvability\u0393\u00c7\u00f4Empirically Discovered Evolvability Issues and Human Evaluations\n", "abstract": " Evolution of a software system can take decades and can cost up to several billion Euros. Software evolvability refers to how easily software is understood, modified, adapted, corrected, and developed. It has been estimated that software evolvability can explain 25% to 38% of the costs of software evolution. Prior research has presented software evolvability criteria and quantified the criteria utilizing source code metrics. However, the empirical observations of software evolvability issues and human evaluations of them have largely been ignored.   This dissertation empirically studies human evaluations and observations of software evolvability issues. This work utilizes both qualitative and quantitative research methods. Empirical data was collected from controlled experiments with student subjects, and by observing issues that were discovered in real industrial settings.   This dissertation presents a new classification for software evolvability issues. The information provided by the classification is extended by the detailed analysis of evolvability issues that have been discovered in code reviews and their distributions to different issue types. Furthermore, this work studies human evaluations of software evolvability; more specifically, it focuses on the interrater agreement of the evaluations, the affect of demographics, the evolvability issues that humans find to be most significant, as well as the relationship between human evaluation and source code metrics based evaluations.   The results show that code review that is performed after light functional testing reveals three times as many evolvability issues as functional defects. We also discovered a new\u252c\u00e1\u0393\u00c7\u00aa", "num_citations": "6\n", "authors": ["62"]}
{"title": "Guest editorial for special section on success and failure in software engineering\n", "abstract": " Many papers investigate success and failure of software projects from diverse perspectives, leading to a myriad of antecedents, causes, correlates, factors and predictors of success and failure. This body of research has not yet produced a solid, empirically grounded body of evidence enabling actionable practices for increasing success and avoiding failure in software projects. The need for more evidence motivates this special issue, which includes four articles that contribute to our understanding of how software project success and failure relate to topics such as: requirements engineering, user satisfaction, start-up pivots and retrospective discussions. We moreover present a brief systematic review to both situate the accepted articles in existing literature and to explore enduring methodological and conceptual challenges in this area, including developing sound instruments for measuring success\u252c\u00e1\u0393\u00c7\u00aa", "num_citations": "5\n", "authors": ["62"]}
{"title": "Prevalence, contents and automatic detection of KL-SATD\n", "abstract": " When developers use different keywords such as TODO and FIXME in source code comments to describe self-admitted technical debt (SATD), we refer it as Keyword-Labeled SATD (KL-SATD). We study KL-SATD from 33 software repositories with 13,588 KL-SATD comments. We find that the median percentage of KL-SATD comments among all comments is only 1,52%. We find that KL-SATD comment contents include words expressing code changes and uncertainty, such as remove, fix, maybe and probably. This makes them different compared to other comments. KL-SATD comment contents are similar to manually labeled SATD comments of prior work. Our machine learning classifier using logistic Lasso regression has good performance in detecting KL-SATD comments (AUC-ROC 0.88). Finally, we demonstrate that using machine learning we can identify comments that are currently missing but which should\u252c\u00e1\u0393\u00c7\u00aa", "num_citations": "4\n", "authors": ["62"]}
{"title": "20-MAD: 20 Years of Issues and Commits of Mozilla and Apache Development\n", "abstract": " Data of long-lived and high profile projects is valuable for research on successful software engineering in the wild. Having a dataset with different linked software repositories of such projects, enables deeper diving investigations. This paper presents 20-MAD, a dataset linking the commit and issue data of Mozilla and Apache projects. It includes over 20 years of information about 765 projects, 3.4 M commits, 2.3 M issues, and 17.3 M issue comments, and its compressed size is over 6 GB. The data contains all the typical information about source code commits (eg, lines added and removed, message and commit time) and issues (status, severity, votes, and summary). The issue comments have been pre-processed for natural language processing and sentiment analysis. This includes emoticons and valence and arousal scores. Linking code repository and issue tracker information, allows studying individuals in two\u252c\u00e1\u0393\u00c7\u00aa", "num_citations": "4\n", "authors": ["62"]}
{"title": "A self-assessment instrument for assessing test automation maturity\n", "abstract": " Test automation is important in the software industry but self-assessment instruments for assessing its maturity are not sufficient. The two objectives of this study are to synthesize what an organization should focus to assess its test automation; develop a self-assessment instrument (a survey) for assessing test automation maturity and scientifically evaluate it. We carried out the study in four stages. First, a literature review of 25 sources was conducted. Second, the initial instrument was developed. Third, seven experts from five companies evaluated the initial instrument. Content Validity Index and Cognitive Interview methods were used. Fourth, we revised the developed instrument. Our contributions are as follows:(a) we collected practices mapped into 15 key areas that indicate where an organization should focus to assess its test automation;(b) we developed and evaluated a self-assessment instrument for\u252c\u00e1\u0393\u00c7\u00aa", "num_citations": "4\n", "authors": ["62"]}
{"title": "Benchmarking web-testing-selenium versus watir and the choice of programming language and browser\n", "abstract": " Context: Selenium is claimed to be the most popular software test automation tool. Past academic works have mainly neglected testing tools in favor of more methodological topics. Objective: We investigated the performance of web-testing tools, to provide empirical evidence supporting choices in software test tool selection and configuration. Method: We used 4*5 factorial design to study 20 different configurations for testing a web-store. We studied 5 programming language bindings (C#, Java, Python, and Ruby for Selenium, while Watir supports Ruby only) and 4 browsers (Google Chrome, Internet Explorer, Mozilla Firefox and Opera). Performance was measured with execution time, memory usage, length of the test scripts and stability of the tests. Results: Considering all measures the best configuration was Selenium with Python language binding for Chrome. Selenium with Python bindings was the best option for all browsers. The effect size of the difference between the slowest and fastest configuration was very high (Cohens d=41.5, 91% increase in execution time). Overall Internet Explorer was the fastest browser while having the worst results in the stability. Conclusions: We recommend benchmarking tools before adopting them. Weighting of factors, e.g. how much test stability is one willing to sacrifice for faster performance, affects the decision.", "num_citations": "4\n", "authors": ["62"]}
{"title": "Experiences on applying refactoring\n", "abstract": " Refactoring is controlled way to improve the quality of the programs\u0393\u00c7\u00d6 source code without changing the programs\u0393\u00c7\u00d6 behavior. Programs with high source code quality are easier to understand and also making changes to these programs is easier. Refactoring should be considered as programmers\u0393\u00c7\u00d6 daily task in a same way as developing new features. In more detail programmers should consider whether code refactoring is needed every time they add features or fix bugs. The reason for this is that in some cases adding feature or fixing bug will be easier after some refactoring is performed.Extreme Program (XP) that is one of the agile methodologies [Beck et al., 2001] has adopted refactoring as one of its practices. XP like all agile methodologies value \u0393\u00c7\u00a3Responding to change over following a plan\u0393\u00c7\u00a5. In XP refactoring is one way to cope with changes. Refactoring is also the main way how the code quality is kept high on XP, which does not put much value on designing the programs.", "num_citations": "4\n", "authors": ["62"]}
{"title": "Chat activity is a better predictor than chat sentiment on software developers productivity\n", "abstract": " Recent works have proposed that software developers' positive emotion has a positive impact on software developers' productivity. In this paper we investigate two data sources: developers chat messages (from Slack and Hipchat) and source code commits of a single co-located Agile team over 200 working days. Our regression analysis shows that the number of chat messages is the best predictor and predicts productivity measured both in the number of commits and lines of code with R2 of 0.33 and 0.27 respectively. We then add sentiment analysis variables until AIC of our model no longer improves and gets R2 values of 0.37 (commits) and 0.30 (lines of code). Thus, analyzing chat sentiment improves productivity prediction over chat activity alone but the difference is not massive. This work supports the idea that emotional state and productivity are linked in software development. We find that three positive\u252c\u00e1\u0393\u00c7\u00aa", "num_citations": "3\n", "authors": ["62"]}
{"title": "How Many Individuals to Use in a QA Task with Fixed Total Effort?\n", "abstract": " Increasing the number of persons working on quality assurance (QA) tasks, e.g., reviews and testing, increases the number of defects detected - but it also increases the total effort unless effort is controlled with fixed effort budgets. Our research investigates how QA tasks should be configured regarding two parameters, i.e., time and number of people. We define an optimization problem to answer this question. As a core element of the optimization problem we discuss and describe how defect detection probability should be modeled as a function of time. We apply the formulas used in the definition of the optimization problem to empirical defect data of an experiment previously conducted with university students. The results show that the optimal choice of the number of persons depends on the actual defect detection probabilities of the individual defects over time, but also on the size of the effort budget. Future work\u252c\u00e1\u0393\u00c7\u00aa", "num_citations": "3\n", "authors": ["62"]}
{"title": "Citations in Software Engineering--Paper-related, Journal-related, and Author-related Factors\n", "abstract": " Many factors could affect the number of citations to a paper. Citations have an important role in research policy and in measuring the excellence of research and researchers. This work is the first study in software engineering (SE) to assess multiple factors affecting the number of citations to SE papers. We use (a) negative binomial regression and (b) quantile regression to study arithmetic mean and median expected citations of a paper. Our dataset includes all the 25,113 papers which have been published in a set of 16 main SE journals, between 1970 and 2018. Our results indicate that publication venue, author team's past citations, paper length, the number of references, and the recency of references are the most influential factors on the number of citations to SE papers. From our empirical findings, we present several implications and advice to researchers for getting higher citations on their papers, which are in addition to the obvious case of conducting high-quality technical research, e.g. (1) Aim for high-profile venues, (2) Build a high-quality author team with highly cited past papers, and (3) Aim for high-quality work that has comprehensive content (thus longer paper length and reference list).", "num_citations": "2\n", "authors": ["62"]}
{"title": "Test case prioritization using test similarities\n", "abstract": " A classical heuristic in software testing is to reward diversity, which implies that a higher priority must be assigned to test cases that differ the most from those already prioritized. This approach is commonly known as similarity-based test prioritization (SBTP) and can be realized using a variety of techniques. The objective of our study is to investigate whether SBTP is more effective at finding defects than random permutation, as well as determine which SBTP implementations lead to better results. To achieve our objective, we implemented five different techniques from the literature and conducted an experiment using the defects4j dataset, which contains 395 real faults from six real-world open-source Java programs. Findings indicate that running the most dissimilar test cases early in the process is largely more effective than random permutation (Vargha\u0393\u00c7\u00f4Delaney A [VDA]: 0.76\u0393\u00c7\u00f40.99 observed using\u252c\u00e1\u0393\u00c7\u00aa", "num_citations": "2\n", "authors": ["62"]}
{"title": "Development and evaluation of a lightweight root cause analysis method in software project retrospectives\n", "abstract": " Software projects are famous for their problems. The most common problems include low software quality and schedule and cost overruns. According to the theory of causality, prob-lems escalate from the causal relationships of mutually exclusive events. The consequences of the problems motivate software companies to improve their work practices. Improvement of work practices is based on the detection of occurred problems and the ana-lyses of their underlying causes. \"Retrospective\" is a term that refers to post-project activities where the occurred problems are considered in order to make improvements. Software project retrospectives include the detection of the occurred problems, reasoning their causes, and developing corrective actions. There are many retrospective methods that follow these three phases. Root cause analysis (RCA) is a structured investigation of problems to detect their under-lying causes. This dissertation considers the applicability of RCA in the retrospectives of small- and medium-sized software product organizations. The research focuses on three research problems. The first problem is to explain how to conduct RCA in collocated and distributed software project retrospectives. The second problem is to study whether RCA is perceived as efficient and easy to use. The third problem is to consider whether the outcome of RCA indica-tes how the causes of project failures are interconnected. In this dissertation, an RCA method (ARCA) is developed. Thereafter, it is evaluated in a to-tal of six industrial cases and in one controlled student experiment. Additionally, a software tool, called ARCA-tool, for improving the ARCA\u252c\u00e1\u0393\u00c7\u00aa", "num_citations": "2\n", "authors": ["62"]}
{"title": "Defect Bash-Literature Review\n", "abstract": " Defect bash is a co-located testing session performed by a group of people. We performed a systematic review of the academic and grey literature, ie informally published writings, of the defect bash. Altogether, we found 44 items (17 academic and 27 grey literature sources) that were identified useful for the review. Based on the review the definition of defect bash is presented, benefits and limitations of using defect bash are given. Finally, the process of doing defect bash is outlined. This review provides initial understanding on how defect bash could be useful in achieving the software quality and lays foundation for further academic studies of this topic.", "num_citations": "2\n", "authors": ["62"]}
{"title": "Detecting Anomalies in Software Execution Logs with Siamese Network\n", "abstract": " Logs are semi-structured text files that represent software's execution paths and states during its run-time. Therefore, detecting anomalies in software logs reflect anomalies in the software's execution path or state. So, it has become a notable concern in software engineering. We use LSTM like many prior works, and on top of LSTM, we propose a novel anomaly detection approach based on the Siamese network. This paper also provides an authentic validation of the approach on the Hadoop Distributed File System (HDFS) log dataset. To the best of our knowledge, the proposed approach outperforms other methods on the same dataset at the F1 score of 0.996, resulting in a new state-of-the-art performance on the dataset. Along with the primary method, we introduce a novel training pair generation algorithm that reduces generated training pairs by the factor of 3000 while maintaining the F1 score, merely a modest decay from 0.996 to 0.995. Additionally, we propose a hybrid model by combining the Siamese network with a traditional feedforward neural network to make end-to-end training possible, reducing engineering effort in setting up a deep-learning-based log anomaly detector. Furthermore, we examine our method's robustness to log evolutions by evaluating the model on synthetically evolved log sequences; we got the F1 score of 0.95 at the noise ratio of 20%. Finally, we dive deep into some of the side benefits of the Siamese network. Accordingly, we introduce a method of monitoring the evolutions of logs without label requirements at run-time. Additionally, we present a visualization technique that facilitates human administrations of\u252c\u00e1\u0393\u00c7\u00aa", "num_citations": "1\n", "authors": ["62"]}
{"title": "Predicting technical debt from commit contents: reproduction and extension with automated feature selection\n", "abstract": " Self-admitted technical debt refers to sub-optimal development solutions that are expressed in written code comments or commits. We reproduce and improve on a prior work by Yan et al. (2018) on detecting commits that introduce self-admitted technical debt. We use multiple natural language processing methods: Bag-of-Words, topic modeling, and word embedding vectors. We study 5 open-source projects. Our NLP approach uses logistic Lasso regression from Glmnet to automatically select best predictor words. A manually labeled dataset from prior work that identified self-admitted technical debt from code level commits serves as ground truth. Our approach achieves +\u0393\u00c7\u00eb0.15 better area under the ROC curve performance than a prior work, when comparing only commit message features, and +\u0393\u00c7\u00eb0.03 better result overall when replacing manually selected features with automatically selected words. In\u252c\u00e1\u0393\u00c7\u00aa", "num_citations": "1\n", "authors": ["62"]}
{"title": "Test automation process improvement in a DevOps team: experience report\n", "abstract": " How to successfully conduct test automation process improvement (TAPI) for continuous development, consisting of iterative software development, continuous testing, and delivery, is the challenge faced by many software organizations. In this paper, we present an experience report on TAPI in one DevOps team in F-Secure (a Finnish software company). The team builds Windows application software and exists in F-Secure's TAPI culture. The team self-reports high satisfaction and maturity in test automation for continuous development. To study their TAPI, we reviewed a collection of experience notes, team reflection reports and telemetry result reports. Then several meetings were held to discuss the details. We found that based on the understanding of the team, test automation maturity for continuous development is defined as a set of indicators, e.g., the increasing speed to release, improving the productivity of\u252c\u00e1\u0393\u00c7\u00aa", "num_citations": "1\n", "authors": ["62"]}
{"title": "we must keep going i guess\n", "abstract": " Towards identifying paid open source developers-a case study with mozilla developers Open source development contains contributions from both hired and volunteer software developers. Identification of this status is important when we consider the transferability of research results to the closed source software industry, as they include no volunteer developers. While many studies have taken the employment status of developers into account, this information is often gathered manually due to the lack of accurate automatic methods. In this paper, we present an initial step towards predicting paid and unpaid open source development using machine learning and compare our results with automatic techniques used in prior work. By relying on code source repository meta-data from Mozilla, and manually collected employment status, we built a dataset of the most active developers, both volunteer and hired by Mozilla. We define a set of metrics based on developers' usual commit time pattern and use different classification methods (logistic regression, classification tree, and random forest). The results show that our proposed method identify paid and unpaid commits with an AUC of 0.75 using random forest, which is higher than the AUC of 0.64 obtained with the best of the previously used automatic methods.", "num_citations": "1\n", "authors": ["62"]}
{"title": "What Are Problem Causes of Software Projects?\n", "abstract": " Root cause analysis (RCA) is a structured investigation of a problem to detect the causes that need to be prevented. We applied ARCA, an RCA method, to target problems of four medium-sized software companies and collected 648 causes of software engineering problems. Thereafter, we applied grounded theory to the causes to study their types and related process areas. We detected 14 types of causes in 6 process areas. Our results indicate that development work and software testing are the most common process areas, whereas lack of instructions and experiences, insufficient work practices, low quality task output, task difficulty, and challenging existing product are the most common types of the causes. As the types of causes are evenly distributed between the cases, we hypothesize that the distributions could be generalizable. Finally, we found that only 2.5% of the causes are related to software development tools that are widely investigated in software engineering research.", "num_citations": "1\n", "authors": ["62"]}
{"title": "Smart card payment and risk scenarios\n", "abstract": " Current payment methods, that are based on cash and magnetic strip cards, are either expensive to use, or they do not offer enough security for payments. Smart card based payment systems offer several benefits over currently used cash and magnetic strip cards. Building and delivering smart card based payments systems is not an easy task. It includes several risks and some of them are addressed in this paper. We conclude that worst risks in delivering smart card systems are the lacking knowledge of merchants and card users needs and the cost of building wide-scale payment system.", "num_citations": "1\n", "authors": ["62"]}