{"title": "Comments on \"Researcher Bias: The Use of Machine Learning in Software Defect Prediction\"\n", "abstract": " Shepperd et al. find that the reported performance of a defect prediction model shares a strong relationship with the group of researchers who construct the models. In this paper, we perform an alternative investigation of Shepperd et al.'s data. We observe that (a) research group shares a strong association with other explanatory variables (i.e., the dataset and metric families that are used to build a model); (b) the strong association among these explanatory variables makes it difficult to discern the impact of the research group on model performance; and (c) after mitigating the impact of this strong association, we find that the research group has a smaller impact than the metric family. These observations lead us to conclude that the relationship between the research group and the performance of a defect prediction model are more likely due to the tendency of researchers to reuse experimental components (e.g\u00a0\u2026", "num_citations": "51\n", "authors": ["231"]}
{"title": "Towards a better understanding of the impact of experimental components on defect prediction modelling\n", "abstract": " Defect prediction models are used to pinpoint risky software modules and understand past pitfalls that lead to defective modules. The predictions and insights that are derived from defect prediction models may not be accurate and reliable if researchers do not consider the impact of experimental components (eg, datasets, metrics, and classifiers) of defect prediction modelling. Therefore, a lack of awareness and practical guidelines from previous research can lead to invalid predictions and unreliable insights. In this thesis, we investigate the impact that experimental components have on the predictions and insights of defect prediction models. Through case studies of systems that span both proprietary and open-source domains, we find that (1) noise in defect datasets;(2) parameter settings of classification techniques; and (3) model validation techniques have a large impact on the predictions and insights of defect\u00a0\u2026", "num_citations": "21\n", "authors": ["231"]}
{"title": "Predicting Defective Lines Using a Model-Agnostic Technique\n", "abstract": " Defect prediction models are proposed to help a team prioritize source code areas files that need Software QualityAssurance (SQA) based on the likelihood of having defects. However, developers may waste their unnecessary effort on the whole filewhile only a small fraction of its source code lines are defective. Indeed, we find that as little as 1%-3% of lines of a file are defective. Hence, in this work, we propose a novel framework (called LINE-DP) to identify defective lines using a model-agnostic technique, i.e., an Explainable AI technique that provides information why the model makes such a prediction. Broadly speaking, our LINE-DP first builds a file-level defect model using code token features. Then, our LINE-DP uses a state-of-the-art model-agnostic technique (i.e.,LIME) to identify risky tokens, i.e., code tokens that lead the file-level defect model to predict that the file will be defective. Then, the lines that contain risky tokens are predicted as defective lines. Through a case study of 32 releases of nine Java open source systems, our evaluation results show that our LINE-DP achieves an average recall of 0.61, a false alarm rate of 0.47, a top 20%LOC recall of0.27, and an initial false alarm of 16, which are statistically better than six baseline approaches. Our evaluation shows that our LINE-DP requires an average computation time of 10 seconds including model construction and defective line identification time. In addition, we find that 63% of defective lines that can be identified by our LINE-DP are related to common defects (e.g., argument change, condition change). These results suggest that our LINE-DP can effectively identify defective lines\u00a0\u2026", "num_citations": "13\n", "authors": ["231"]}
{"title": "JITLine: A Simpler, Better, Faster, Finer-grained Just-In-Time Defect Prediction\n", "abstract": " A Just-In-Time (JIT) defect prediction model is a classifier to predict if a commit is defect-introducing. Recently, CC2Vec -- a deep learning approach for Just-In-Time defect prediction -- has been proposed. However, CC2Vec requires the whole dataset (i.e., training + testing) for model training, assuming that all unlabelled testing datasets would be available beforehand, which does not follow the key principles of just-in-time defect predictions. Our replication study shows that, after excluding the testing dataset for model training, the F-measure of CC2Vec is decreased by 38.5% for OpenStack and 45.7% for Qt, highlighting the negative impact of excluding the testing dataset for Just-In-Time defect prediction. In addition, CC2Vec cannot perform fine-grained predictions at the line level (i.e., which lines are most risky for a given commit). In this paper, we propose JITLine -- a Just-In-Time defect prediction approach for predicting defect-introducing commits and identifying lines that are associated with that defect-introducing commit (i.e., defective lines). Through a case study of 37,524 commits from OpenStack and Qt, we find that our JITLine approach is at least 26%-38% more accurate (F-measure), 17%-51% more cost-effective (PCI@20%LOC), 70-100 times faster than the state-of-the-art approaches (i.e., CC2Vec and DeepJIT) and the fine-grained predictions at the line level by our approach are 133%-150% more accurate (Top-10 Accuracy) than the baseline NLP approach. Therefore, our JITLine approach may help practitioners to better prioritize defect-introducing commits and better identify defective lines.", "num_citations": "11\n", "authors": ["231"]}
{"title": "Deep Learning for Android Malware Defenses: a Systematic Literature Review\n", "abstract": " Malicious applications (especially in the Android platform) are a serious threat to developers and end-users. Many research efforts have hence been devoted to developing effective approaches to defend Android malware. However, with the explosive growth of Android malware and the continuous advancement of malicious evasion technologies like obfuscation and reflection, android malware defenses based on manual rules or traditional machine learning may not be effective due to limited apriori knowledge. In recent years, a dominant research field of deep learning (DL) with the powerful feature abstraction ability has demonstrated a compelling and promising performance in various fields, like Nature Language processing and image processing. To this end, employing deep learning techniques to thwart the attack of Android malware has recently gained considerable research attention. Yet, there exists no systematic literature review that focuses on deep learning approaches for Android Malware defenses. In this paper, we conducted a systematic literature review to search and analyze how deep learning approaches have been applied in the context of malware defenses in the Android environment. As a result, a total of 104 studies were identified over the period 2014-2020. The results of our investigation show that even though most of these studies still mainly consider DL-based on Android malware detection, 35 primary studies (33.7\\%) design the defenses approaches based on other scenarios. This review also describes research trends, research focuses, challenges, and future research directions in DL-based Android malware defenses.", "num_citations": "4\n", "authors": ["231"]}
{"title": "Workload-aware reviewer recommendation using a multi-objective search-based approach\n", "abstract": " Reviewer recommendation approaches have been proposed to provide automated support in finding suitable reviewers to review a given patch. However, they mainly focused on reviewer experience, and did not take into account the review workload, which is another important factor for a reviewer to decide if they will accept a review invitation. We set out to empirically investigate the feasibility of automatically recommending reviewers while considering the review workload amongst other factors. We develop a novel approach that leverages a multi-objective meta-heuristic algorithm to search for reviewers guided by two objectives, ie,(1) maximizing the chance of participating in a review, and (2) minimizing the skewness of the review workload distribution among reviewers. Through an empirical study of 230,090 patches with 7,431 reviewers spread across four open source projects, we find that our approach can\u00a0\u2026", "num_citations": "2\n", "authors": ["231"]}
{"title": "Towards a Better Understanding of the Impact of Experimental Components on Defect Prediction Models\n", "abstract": " Software Quality Assurance (SQA) teams play a critical role in the software development process to ensure the absence of software defects. It is not feasible to perform exhaustive SQA tasks (ie, software testing and code review) on a large software product given the limited SQA resources that are available. Thus, the prioritization of SQA efforts is an essential step in all SQA efforts. Defect prediction models are used to prioritize risky software modules and understand the impact of software metrics on the defect-proneness of software modules. The predictions and insights that are derived from defect prediction models can help software teams allocate their limited SQA resources to the modules that are most likely to be defective and avoid common past pitfalls that are associated with the defective modules of the past. However, the predictions and insights that are derived from defect prediction models may be inaccurate and unreliable if practitioners do not control for the impact of experimental components (eg, datasets, metrics, and classifiers) on defect prediction models, which could lead to erroneous decision-making in practice.", "num_citations": "2\n", "authors": ["231"]}
{"title": "Assessing the Students' Understanding and their Mistakes in Code Review Checklists\n", "abstract": " Code review is a widely-used practice in software development companies to identify defects. Hence, code review has been included in many software engineering curricula at universities worldwide. However, teaching code review is still a challenging task because the code review effectiveness depends on the code reading and analytical skills of a reviewer. While several studies have investigated the code reading techniques that students should use to find defects during code review, little has focused on a learning activity that involves analytical skills. Indeed, developing a code review checklist should stimulate students to develop their analytical skills to anticipate potential issues (ie, software defects). Yet, it is unclear whether students can anticipate potential issues given their limited experience in software development (programming, testing, etc.). We perform a qualitative analysis to investigate whether\u00a0\u2026", "num_citations": "1\n", "authors": ["231"]}
{"title": "Knowledge Discovery in Web Traffic Log: A Case Study of Facebook Usage in Kasetsart University\n", "abstract": " Recognizing and understanding knowledge flow between user interactions in social networks are valuable for sociology, economy, political science, and marketing. In this paper, we present a methodology in order to extract information and discover knowledge from a web traffic log. Our study is based on traffic and login history logs of Kasetsart University's network during a 7-days period from March 1-7, 2011. The summarized HTTP sessions show 39,046 distinct users together with 25,894 IP addresses. We conduct a pattern analysis in six aspects: The Origin of HTTP Requests, Distribution of HTTP Requests at the level of hostname, Time spent communicating online, Overall Traffic Workload Analysis, Facebook Traffic Workload Analysis and Web Access Patterns. The results reveal many interesting patterns and knowledge from raw data.", "num_citations": "1\n", "authors": ["231"]}
{"title": "A Tool for Collaborative Guitar Chords Creation based on The Concept of The Distributed Version Control\n", "abstract": " The distributed version control system has become very popular in software development process for years. Many software projects, which are developed by a large group of programmers have been using it to manage their source code. We study on another aspect of applying a distributed version control to keep track the version of other artifacts instead of using just for tracking source code. An application for sharing and creating guitar chords is used in our case study. We apply distributed version control concept in order to interoperate musical ideas from multiple users and preserve the versions of guitar chords with their music styles introduced to the community. The results show how distributed version control system can help guitarists to collaborate on creating guitar chords and also reduce the redundancy of derivative versions. This study has approved that distributed version control system can be applied to any projects that need to keep track the version of their artifacts.", "num_citations": "1\n", "authors": ["231"]}