{"title": "Alpha shapes: definition and software\n", "abstract": " The concept of an a-shape of a finite set of points with weights in R\" is defined and illustrated. It is a polytope uniquely determined by the points, their weights, and a parameter a that controls the desired level of detail. Software that computes such shapes in dimensions 2 and 3 is available via anonymous ftp at ftp. ncsa. uiuc. edu.", "num_citations": "134\n", "authors": ["685"]}
{"title": "The internet operating system: Middleware for adaptive distributed computing\n", "abstract": " Large-scale, dynamic, and heterogeneous networks of computational resources (a.k.a.                 grids) promise to provide high performance and scalability to                 computationally intesive applications. To fulfill this promise, grid environments                 require complex resource management. We propose decetralized middleware-triggered                 dynamic reconfiguration straegies to enable application adaptation to the constantly                 changing resource availability of Internet-scale shared coputational grids. As a                 proof of concept, we present a sofware framework for dynamically reconfigurable                 distributed applications. The Internet Operating System (IOS) is a middleware                 infrastructure which aims at freeing appliction developers from dealing with                 non-functional concerns while seeking to optimize application performance and glbal                 resource utilization. IOS consists\u00a0\u2026", "num_citations": "67\n", "authors": ["685"]}
{"title": "Transactors: a programming model for maintaining globally consistent distributed state in unreliable environments\n", "abstract": " We introduce transactors, a fault-tolerant programming model for composing loosely-coupled distributed components running in an unreliable environment such as the internet into systems that reliably maintain globally consistent distributed state. The transactor model incorporates certain elements of traditional transaction processing, but allows these elements to be composed in different ways without the need for central coordination, thus facilitating the study of distributed fault-tolerance from a semantic point of view. We formalize our approach via the \u03c4-calculus, an extended lambda-calculus based on the actor model, and illustrate its usage through a number of examples. The \u03c4-calculus incorporates constructs which distributed processes can use to create globally-consistent checkpoints. We provide an operational semantics for the \u03c4-calculus, and formalize the following safety and liveness properties: first, we\u00a0\u2026", "num_citations": "65\n", "authors": ["685"]}
{"title": "Dynamic malleability in iterative MPI applications\n", "abstract": " Malleability enables a parallel application's execution system to split or merge processes modifying granularity. While process migration is widely used to adapt applications to dynamic execution environments, it is limited by the granularity of the application's processes. Malleability empowers process migration by allowing the application's processes to expand or shrink following the availability of resources. We have implemented malleability as an extension to the PCM (process checkpointing and migration) library, a user-level library for iterative MPI applications. PCM is integrated with the Internet operating system (IOS), a framework for middleware-driven dynamic application reconfiguration. Our approach requires minimal code modifications and enables transparent middleware- triggered reconfiguration. Experimental results using a two-dimensional data parallel program that has a regular communication\u00a0\u2026", "num_citations": "62\n", "authors": ["685"]}
{"title": "Elastic scalable cloud computing using application-level migration\n", "abstract": " We present the Cloud Operating System (COS), a middleware framework to support autonomous workload elasticity and scalability based on application-level migration as a reconfiguration strategy. While other scalable frameworks (e.g., MapReduce or Google App Engine) force application developers to write programs following specific APIs, COS provides scalability in a general-purpose programming framework based on an actor-oriented programming language. When all executing VMs are highly utilized, COS scales a workload up by migrating mobile actors over to newly dynamically created VMs. When VM utilization drops, COS scales the workload down by consolidating actors and terminating idle VMs. Application-level migration is advantageous compared to VM migration especially in hybrid clouds in which migration costs over the Internet are critical to scale out the workloads. We demonstrate the\u00a0\u2026", "num_citations": "60\n", "authors": ["685"]}
{"title": "Malleable applications for scalable high performance computing\n", "abstract": " Iterative applications are known to run as slow as their slowest computational component. This paper introduces malleability, a new dynamic reconfiguration strategy to overcome this limitation. Malleability is the ability to dynamically change the data size and number of computational entities in an application. Malleability can be used by middleware to autonomously reconfigure an application in response to dynamic changes in resource availability in an architecture-aware manner, allowing applications to optimize the use of multiple processors and diverse memory hierarchies in heterogeneous environments.                 The modular Internet Operating System (IOS) was extended to reconfigure applications autonomously using malleability. Two different iterative applications were made malleable. The first is used in astronomical modeling, and representative of maximum-likelihood applications was made\u00a0\u2026", "num_citations": "49\n", "authors": ["685"]}
{"title": "Airplane flight safety using error-tolerant data stream processing\n", "abstract": " Ubiquitous sensing is pervasive in society for such applications as biometrics for health care, smart grids for power delivery, and avionics for transportation safety [1]. As society continues to rely ever more on sensors for various applications, there is a need to address the accuracy of sensor readings for health maintenance, signal identification, and control [2]. While there have been advances in information fusion [3] for avionics control [4] and user warnings [5], there is still a need for further research in methods that allow for fault detection and recovery techniques to be easily realized and implemented with minimal risk of software errors.", "num_citations": "48\n", "authors": ["685"]}
{"title": "An analysis of massively distributed evolutionary algorithms\n", "abstract": " Computational science is placing new demands on optimization algorithms as the size of data sets and the computational complexity of scientific models continue to increase. As these complex models have many local minima, evolutionary algorithms (EAs) are very useful for quickly finding optimal solutions in these challenging search spaces. In addition to the complex search spaces involved, calculating the objective function can be extremely demanding computationally. Because of this, distributed computation is a necessity. In order to address these computational demands, top-end distributed computing systems are surpassing hundreds of thousands of computing hosts; and as in the case of Internet based volunteer computing systems, they can also be highly heterogeneous and faulty. This work examines asynchronous strategies for distributed EAs using simulated computing environments. Results show that\u00a0\u2026", "num_citations": "48\n", "authors": ["685"]}
{"title": "An architecture for reconfigurable iterative MPI applications in dynamic environments\n", "abstract": " With the proliferation of large scale dynamic execution environments such as grids, the need for providing efficient and scalable application adaptation strategies for long running parallel and distributed applications has emerged. Message passing interfaces have been initially designed with a traditional machine model in mind which assumes homogeneous and static environments. It is inevitable that long running message passing applications will require support for dynamic reconfiguration to maintain high performance under varying load conditions. In this paper we describe a framework that provides iterative MPI applications with reconfiguration capabilities. Our approach is based on integrating MPI applications with a middleware that supports process migration and large scale distributed application reconfiguration. We present our architecture for reconfiguring MPI applications, and verify our design\u00a0\u2026", "num_citations": "47\n", "authors": ["685"]}
{"title": "Maximum likelihood fitting of tidal streams with application to the sagittarius dwarf tidal tails\n", "abstract": " We present a maximum likelihood method for determining the spatial properties of tidal debris and of the Galactic spheroid. With this method we characterize Sagittarius debris using stars with the colors of blue F turnoff stars in SDSS stripe 82. The debris is located at (\u03b1, \u03b4, R)=(31.37\u00b10.26, 0.0, 29.22\u00b10.20 kpc), with a (spatial) direction given by the unit vector (\u2212 0.991\u00b10.007 kpc, 0.042\u00b10.033 kpc, 0.127\u00b10.046 kpc), in galactocentric Cartesian coordinates, and with FWHM= 6.74\u00b10.06 kpc. This 2.5 wide stripe contains 0.9% as many F turnoff stars as the current Sagittarius dwarf galaxy. Over small spatial extent, the debris is modeled as a cylinder with a density that falls off as a Gaussian with distance from the axis, while the smooth component of the spheroid is modeled with a Hernquist profile. We assume that the absolute magnitude of F turnoff stars is distributed as a Gaussian, which is an improvement over previous\u00a0\u2026", "num_citations": "39\n", "authors": ["685"]}
{"title": "Malleable iterative MPI applications\n", "abstract": " Malleability enables a parallel application's execution system to split or merge processes modifying granularity. While process migration is widely used to adapt applications to dynamic execution environments, it is limited by the granularity of the application's processes. Malleability empowers process migration by allowing the application's processes to expand or shrink following the availability of resources. We have implemented malleability as an extension to the process checkpointing and migration (PCM) library, a user\u2010level library for iterative message passing interface (MPI) applications. PCM is integrated with the Internet Operating System, a framework for middleware\u2010driven dynamic application reconfiguration. Our approach requires minimal code modifications and enables transparent middleware\u2010triggered reconfiguration. Experimental results using a two\u2010dimensional data parallel program that has a\u00a0\u2026", "num_citations": "38\n", "authors": ["685"]}
{"title": "Load Balancing of Autonomous Actors over Dynamic Networks.\n", "abstract": " The Internet is constantly growing as a ubiquitous platform for high-performance distributed computing. In this paper, we propose a new software framework for distributed computing over large scale dynamic and heterogeneous systems. Our framework wraps computation into autonomous actors, self organizing computing entities, which freely roam over the network to find their optimal target execution environments.We introduce the architecture of our worldwide computing framework, which consists of an actor-oriented programming language (SALSA), a distributed run time environment (WWC), and a middleware infrastructure for autonomous reconfiguration and load balancing (IO). Load balancing is completely transparent to application programmers. The middleware triggers actor migration based on profiling resources in a completely decentralized manner. Our infrastructure also allows for the dynamic addition and removal of nodes from the computation, while continuously balancing the load given the changing resources. To balance computational load, we introduce three variations of random work stealing: load-sensitive (RS), actor topology-sensitive (ARS), and network topology-sensitive (NRS) random stealing. We evaluated RS and ARS with several actor interconnection topologies in a local area network. While RS performed worse than static round-robin (RR) actor placement, ARS outperformed both RS and RR in the sparse connectivity and hypercube connectivity tests, by a full order of magnitude.", "num_citations": "37\n", "authors": ["685"]}
{"title": "Impact of cloud computing virtualization strategies on workloads' performance\n", "abstract": " Cloud computing brings significant benefits for service providers and users because of its characteristics: \\emph{e.g.}, on demand, pay for use, scalable computing. Virtualization management is a critical task to accomplish effective sharing of physical resources and scalability. Existing research focuses on live Virtual Machine (VM) migration as a workload consolidation strategy. However, the impact of other virtual network configuration strategies, such as optimizing total number of VMs for a given workload, the number of virtual CPUs (vCPUs) per VM, and the memory size of each VM has been less studied. This paper presents specific performance patterns on different workloads for various virtual network configuration strategies. For loosely coupled CPU-intensive workloads, on an 8-CPU machine, with memory size varying from 512MB to 4096MB and vCPUs ranging from 1 to 16 per VM, 1, 2, 4, 8 and 16VMs\u00a0\u2026", "num_citations": "36\n", "authors": ["685"]}
{"title": "Impact of virtual machine granularity on cloud computing workloads performance\n", "abstract": " This paper studies the impact of VM granularity on workload performance in cloud computing environments. We use HPL as a representative tightly coupled computational workload and a web server providing content to customers as a representative loosely coupled network intensive workload. The performance evaluation demonstrates VM granularity has a significant impact on the performance of the computational workload. On an 8-CPU machine, the performance obtained from utilizing 8VMs is more than 4 times higher than that given by 4 or 16 VMs for HPL of problem size 4096; whereas on two machines with a total of 12 CPUs 24 VMs gives the best performance for HPL of problem sizes from 256 to 1024. Our results also indicate that the effect of VM granularity on the performance of the web system is not critical. The largest standard deviation of the transaction rates obtained from varying VM granularity is\u00a0\u2026", "num_citations": "33\n", "authors": ["685"]}
{"title": "Zelig: schema-based generation of soft WWW database applications\n", "abstract": " The World\u2212 Wide Web brings a global information universe into existence using available technology [Berners\u2212 Lee et al. 1992]. In order to fully realize the benefits of this information system, methodologies need to be developed for the creation of scripts that query existing databases and produce effective user interfaces. Present practice falls short of this goal in two areas; first, interface changes require direct modification of the scripts, and second, user interfaces are hard, in the sense that they don\u2019t adapt to database usage.We present Zelig, a schema\u2212 based approach to HTML document generation that addresses both these problems. First, Zelig uses ZHTML schemata, which are HTML documents commented with directives for document generation. And second, Zelig contains an expert module which gives advice regarding the underlying data structures and interface design issues. This approach allows soft or evolving database applications that keep track of usage and self\u2212 adapt to increase database efficiency and to improve human\u2212 computer interaction. As an example, we have used this approach to automatically generate four different WWW interfaces to the CCSO phone nameserver database software.", "num_citations": "32\n", "authors": ["685"]}
{"title": "Accurate resource prediction for hybrid IaaS clouds using workload-tailored elastic compute units\n", "abstract": " Cloud computing's pay-per-use model greatly reduces upfront cost and also enables on-demand scalability as service demand grows or shrinks. Hybrid clouds are an attractive option in terms of cost benefit, however, without proper elastic resource management, computational resources could be over-provisioned or under-provisioned, resulting in wasting money or failing to satisfy service demand. In this paper, to accomplish accurate performance prediction and cost-optimal resource management for hybrid clouds, we introduce Workload-tailored Elastic Compute Units (WECU) as a measure of computing resources analogous to Amazon EC2's ECUs, but customized for a specific workload. We present a dynamic programming-based scheduling algorithm to select a combination of private and public resources which satisfy a desired throughput. Using a loosely-coupled benchmark, we confirmed WECUs have 24\u00a0\u2026", "num_citations": "31\n", "authors": ["685"]}
{"title": "Distributed garbage collection for mobile actor systems: The pseudo root approach\n", "abstract": " Automatic distributed garbage collection (GC) gives abstraction to grid application development, promoting code quality and improving resource management. Unreachability of active objects or actors from the root set is not a sufficient condition to collect actor garbage, making passive object GC algorithms unsafe when directly used on actor systems. In practical actor languages, all actors have references to the root set since they can interact with users, e.g., through standard input or output streams. Based on this observation, we introduce pseudo roots: a dynamic set of actors that can be viewed as the root set. Pseudo roots use protected (undeletable) references to ensure that no actors are erroneously collected even with messages in transit. Following this idea, we introduce a new direction of actor GC, and demonstrate it by developing a distributed GC framework. The framework can thus be used for\u00a0\u2026", "num_citations": "30\n", "authors": ["685"]}
{"title": "Towards a middleware framework for dynamically reconfigurable scietific computing\n", "abstract": " Computational grids are appealing platforms for the execution of large scale applications among the scientific and engineering communities. However, designing new applications and deploying existing ones with the capability of exploiting this potential still remains a challenge. Computational grids are characterized by their dynamic, non-dedicted, and heterogeneous nature. Novel application-level and middleware-level techniques are needed to allow applications to reconfigure themselves and adapt automatically to their underlying execution environments. In this paper, we introduce a new software framework that enhances the performance of Message Passing Interface (MPI) applications through an adaptive middleware for load balancing that includes process checkpointing and migration. Fields as diverse as fluid dynamics, materials science, biomechanics, and ecology make use of parallel adaptive\u00a0\u2026", "num_citations": "28\n", "authors": ["685"]}
{"title": "An asynchronous hybrid genetic-simplex search for modeling the milky way galaxy using volunteer computing\n", "abstract": " This paper examines the use of a probabilistic simplex operator for asynchronous genetic search on the BOINC volunteer computing framework. This algorithm is used to optimize a computationally intensive function with a continuous parameter space: finding the optimal fit of an astronomical model of the Milky Way galaxy to observed stars. The asynchronous search using a BOINC community of over 1,000 users is shown to be comparable to a synchronous continuously updated genetic search on a 1,024 processor partition of an IBM BlueGene/L supercomputer. The probabilistic simplex operator is also shown to be highly effective and the results demonstrate that increasing the parents used to generate offspring improves the convergence rate of the search. Additionally, it is shown that there is potential for improvement by refining the range of the probabilistic operator, adding more parents, and generating\u00a0\u2026", "num_citations": "27\n", "authors": ["685"]}
{"title": "Accelerating the milkyway@ home volunteer computing project with gpus\n", "abstract": " General-Purpose computing on Graphics Processing Units (GPGPU) is an emerging field of research which allows software developers to utilize the significant amount of computing resources GPUs provide for a wider range of applications. While traditional high performance computing environments such as clusters, grids and supercomputers require significant architectural modifications to incorporate GPUs, volunteer computing grids already have these resources available as most personal computers have GPUs available for recreational use. Additionally, volunteer computing grids are gradually upgraded by the volunteers as they upgrade their hardware, whereas clusters, grids and supercomputers are typically upgraded only when replaced by newer hardware. As such, MilkyWay@Home\u2019s volunteer computing system is an excellent testbed for measuring the potential of large scale distributed GPGPU\u00a0\u2026", "num_citations": "26\n", "authors": ["685"]}
{"title": "Maximum sustainable throughput prediction for data stream processing over public clouds\n", "abstract": " In cloud-based stream processing services, the maximum sustainable throughput (MST) is defined as the maximum throughput that a system composed of a fixed number of virtual machines (VMs) can ingest indefinitely. If the incoming data rate exceeds the system's MST, unprocessed data accumulates, eventually making the system inoperable. Thus, it is important for the service provider to keep the MST always larger than the incoming data rate by dynamically changing the number of VMs used by the system. In this paper, we identify a common data processing environment used by modern data stream processing systems, and we propose MST prediction models for this environment. We train the models using linear regression with samples obtained from a few VMs and predict MST for a larger number of VMs. To minimize the time and cost for model training, we statistically determine a set of training samples\u00a0\u2026", "num_citations": "24\n", "authors": ["685"]}
{"title": "Light-weight adaptive task offloading from smartphones to nearby computational resources\n", "abstract": " Applications on smartphones are extremely popular as users can download and install them very easily from a service provider's application repository. Most of the applications are thoroughly tested and verified on a target smartphone platform; however, some applications could be very computationally intensive and overload the smartphone's resource capability. In this paper, we describe a method to predict the total processing time when offloading part of an application from smartphones to nearby servers. In our method, if an application developercan (1) define a basic model of the problem (eg, f (x)= ax+ b) and (2) implement an algorithm to update the model (eg, least squares method), the application quickly adjusts the parameters of the model and minimizes the difference between predicted and measured performance adaptively. This accurate prediction helps dynamically determine whether or not it is worth\u00a0\u2026", "num_citations": "24\n", "authors": ["685"]}
{"title": "A spatial characterization of the Sagittarius dwarf galaxy tidal tails\n", "abstract": " We measure the spatial density of F turnoff stars in the Sagittarius dwarf tidal stream, from Sloan Digital Sky Survey data, using statistical photometric parallax. We find a set of continuous, consistent parameters that describe the leading Sgr stream's position, direction, and width for 15 stripes in the north Galactic cap, and three stripes in the south Galactic cap. We produce a catalog of stars that has the density characteristics of the dominant leading Sgr tidal stream that can be compared with simulations. We find that the width of the leading (north) tidal tail is consistent with recent triaxial and axisymmetric halo model simulations. The density along the stream is roughly consistent with common disruption models in the north, but possibly not in the south. We explore the possibility that one or more of the dominant Sgr streams has been misidentified, and that one or more of the\" bifurcated\" pieces is the real Sgr tidal tail\u00a0\u2026", "num_citations": "23\n", "authors": ["685"]}
{"title": "Worldwide computing: Adaptive middleware and programming technology for dynamic Grid environments\n", "abstract": " Future-generations cyber-infrastructure must enable the dynamic coordinated composition of computing and information services. Resulting applications need to provide high-performance distributed computing to end users in a scalable, reliable and secure manner. This pervasive and ubiquitous grid computing infrastructure will view physical devices and computational agents uniformly, enabling radical improvement of existing applications, and opening the door for applications in entirely new domains. For example, wireless sensoractuator networks deployed in buildings and bridges can semi-automatically and cooperatively react to natural or man-made disasters in order to prevent human losses. Temperature, pressure, and stress-sensing devices can inform authorities about the probability of structural damage leading to collapse, can automatically activate fire extinguishing equipment, can help locate survivors and devise exit strategies, and can deviate traffic on emergency situations in semi-automated ways. Another example is virtual surgical planning, in which a surgeon simulates several surgery plans on a detailed computational model of a patient\u2019s body. The surgeon can interactively analyze the effect of different plans on the patient\u2019s body fluid dynamics. Another example is a distributed camera network coordinated by a real-time data mining component for airport surveillance and security. Unusual irregular patterns of human behavior can be detected and communicated promptly to authorities. A final example is a manned and unmanned aerial vehicle network that can exchange sensed information and plans of action, and combine\u00a0\u2026", "num_citations": "23\n", "authors": ["685"]}
{"title": "Browsing object-oriented databases over the web\n", "abstract": " In this paper, we present critical issues that arise when users browse object-oriented databases over the World Wide Web, and performance results for the Database Browser (DB) implementation. Initially, given the statelessness of HTTP, we introduced a dispatcher-script architecture. In this architecture, a CGI script communicates with an intermediate data server connected to the database application, which keeps the database open for faster future transactions. Second, we used ODL, a standard object-definition language, and defined a simple intermediate data format for moving database objects across the network. Lastly, we defined generic hypertext interfaces for five distinct purposes: a database schema, a class definition, a class query form, a class extent, and a set of class instances. Our implementation used ObjectStore and two database applications: university registration and electronic mailboxes. The DB architecture provided dramatic improvements in performance.", "num_citations": "23\n", "authors": ["685"]}
{"title": "A programming model for spatio-temporal data streaming applications\n", "abstract": " In this paper, we describe a programming model to enable reasoning about spatio-temporal data streams. A spatio-temporal data stream is one where each datum is related to a point in space and time. For example, sensors in a plane record airspeeds (va) during a given flight. Similarly, GPS units record an airplane\u2019s flight path over the ground including ground speeds (vg) at different locations. An aircraft\u2019s airspeed and ground speed are related by the following mathematical formula: vg=", "num_citations": "22\n", "authors": ["685"]}
{"title": "Use of run time predictions for automatic co-allocation of multi-cluster resources for iterative parallel applications\n", "abstract": " Metaschedulers co-allocate resources by requesting a fixed number of processors and usage time for each cluster. These static requests, defined by users, limit the initial scheduling and prevent rescheduling of applications to other resource sets. It is also difficult for users to estimate application execution times, especially on heterogeneous environments. To overcome these problems, metaschedulers can use performance predictions for automatic resource selection. This paper proposes a resource co-allocation technique with rescheduling support based on performance predictions for multi-cluster iterative parallel applications. Iterative applications have been used to solve a variety of problems in science and engineering, including large-scale computations based on the asynchronous model more recently. We performed experiments using an iterative parallel application, which consists of benchmark\u00a0\u2026", "num_citations": "22\n", "authors": ["685"]}
{"title": "Evolutionary algorithms on volunteer computing platforms: The milkyway@ home project\n", "abstract": " Introduction             Evolutionary algorithms (EAs) require large scale computing resources when tackling real world problems. Such computational requirement is derived from inherently complex fitness evaluation functions, large numbers of individuals per generation, and the number of iterations required by EAs to converge to a satisfactory solution. Therefore, any source of computing power can significantly benefit researchers using evolutionary algorithms. We present the use of volunteer computing (VC) as a platform for harnessing the computing resources of commodity machines that are nowadays present at homes, companies and institutions. Taking into account that currently desktop machines feature significant computing resources (dual cores, gigabytes of memory, gigabit network connections, etc.), VC has become a cost-effective platform for running time consuming evolutionary algorithms in order to\u00a0\u2026", "num_citations": "22\n", "authors": ["685"]}
{"title": "Flight trajectory planning for fixed-wing aircraft in loss of thrust emergencies\n", "abstract": " Loss of thrust emergencies-e.g., induced by bird/drone strikes or fuel exhaustion-create the need for dynamic data-driven flight trajectory planning to advise pilots or control UAVs. While total loss of thrust trajectories to nearby airports can be pre-computed for all initial points in a 3D flight plan, dynamic aspects such as partial power and airplane surface damage must be considered for accuracy. In this paper, we propose a new Dynamic Data-Driven Avionics Software (DDDAS) approach which during flight updates a damaged aircraft performance model, used in turn to generate plausible flight trajectories to a safe landing site. Our damaged aircraft model is parameterized on a baseline glide ratio for a clean aircraft configuration assuming best gliding airspeed on straight flight. The model predicts purely geometric criteria for flight trajectory generation, namely, glide ratio and turn radius for different bank angles and drag configurations. Given actual aircraft performance data, we dynamically infer the baseline glide ratio to update the damaged aircraft model. Our new flight trajectory generation algorithm thus can significantly improve upon prior Dubins based trajectory generation work by considering these data-driven geometric criteria. We further introduce a trajectory utility function to rank trajectories for safety. As a use case, we consider the Hudson River ditching of US Airways 1549 in January 2009 using a flight simulator to evaluate our trajectories and to get sensor data. In this case, a baseline glide ratio of 17.25:1 enabled us to generate trajectories up to 28 seconds after the birds strike, whereas, a 19:1 baseline glide ratio enabled us to\u00a0\u2026", "num_citations": "21\n", "authors": ["685"]}
{"title": "Validating evolutionary algorithms on volunteer computing grids\n", "abstract": " Computational science is placing new demands on distributed computing systems as the rate of data acquisition is far outpacing the improvements in processor speed. Evolutionary algorithms provide efficient means of optimizing the increasingly complex models required by different scientific projects, which can have very complex search spaces with many local minima. This work describes different validation strategies used by MilkyWay@Home, a volunteer computing project created to address the extreme computational demands of 3-dimensionally modeling the Milky Way galaxy, which currently consists of over 27,000 highly heterogeneous and volatile computing hosts, which provide a combined computing power of over 1.55 petaflops. The validation strategies presented form a foundation for efficiently validating evolutionary algorithms on unreliable or even partially malicious computing systems, and\u00a0\u2026", "num_citations": "21\n", "authors": ["685"]}
{"title": "Autonomous data error detection and recovery in streaming applications\n", "abstract": " Detecting and recovering from errors in data streams is paramount to developing successful autonomous real-time streaming applications. In this paper, we devise a multi-modal data error detection and recovery architecture to enable automated recovery from data errors in streaming applications based on available redundancy. We formally define error signatures as a way to identify classes of abnormal conditions and mode likelihood vectors as a quantitative discriminator of data stream condition modes. Finally, we design an extension to our own declarative programming language, PILOTS, to include error correction code. We define performance metrics for our approach, and evaluate the impact of monitored data window size and mode likelihood change threshold on the accuracy and responsiveness of our data-driven multi-modal error detection and correction software. Tragic accidents\u2014such as Air France's\u00a0\u2026", "num_citations": "20\n", "authors": ["685"]}
{"title": "Dynamic data-driven avionics systems: Inferring failure modes from data streams\n", "abstract": " Dynamic Data-Driven Avionics Systems (DDDAS) embody ideas from the Dynamic Data- Driven Application Systems paradigm by creating a data-driven feedback loop that analyzes spatio-temporal data streams coming from aircraft sensors and instruments, looks for errors in the data signaling potential failure modes, and corrects for erroneous data when possible. In case of emergency, DDDAS need to provide enough information about the failure to pilots to support their decision making in real-time. We have developed the PILOTS system, which supports data-error tolerant spatio-temporal stream processing, as an initial step to realize the concept of DDDAS. In this paper, we apply the PILOTS system to actual data from the Tuninter 1153 (TU1153) flight accident in August 2005, where the installation of an incorrect fuel sensor led to a fatal accident. The underweight condition suggesting an incorrect fuel\u00a0\u2026", "num_citations": "19\n", "authors": ["685"]}
{"title": "Adaptive computation over dynamic and heterogeneous networks\n", "abstract": " Over the last two decades, efficient message passing libraries have been developed for parallel scientific computation. Concurrently, programming languages have been created supporting dynamically reconfigurable distributed systems over the heterogeneous Internet. In this paper, we introduce SALSA-MPI, an actor programming language approach to scientific computing that extends MPI with a checkpointing and migration API and a runtime system that manages both periodic checkpoints and process or application migration. The goal is to enable dynamic network reconfiguration and load balancing without sacrificing application performance or requiring extensive code modifications. As driving technology for this effort of unifying parallel and distributed computing, we plan to use adaptive solvers of partial differential equations. Fields as diverse as fluid dynamics, material science, biomechanics, and\u00a0\u2026", "num_citations": "17\n", "authors": ["685"]}
{"title": "Towards learning spatio-temporal data stream relationships for failure detection in avionics\n", "abstract": " Spatio-temporal data streams are often related in complex ways, for example, while the airspeed that an aircraft attains in cruise phase depends on the weight it carries, it also depends on many other factors. Some of these factors are controllable such as engine inputs or the airframe\u2019s angle of attack, while others contextual, such as air density, or turbulence. It is therefore critical to develop failure models that can help recognize errors in the data, such as an incorrect fuel quantity, a malfunctioning pitot-static system, or other abnormal flight conditions. In this paper, we extend our PILOTS programming language [1] to support machine learning techniques that will help data scientists: (1) create parameterized failure models from data and (2) continuously train a statistical model as new evidence (data) arrives. The linear regression approach learns parameters of a linear model to minimize least squares error for\u00a0\u2026", "num_citations": "15\n", "authors": ["685"]}
{"title": "Self-healing spatio-temporal data streams using error signatures\n", "abstract": " Self-healing spatio-temporal data streaming systems enable error detection and data correction based on error signatures. Error signatures are mathematical function patterns with constraints and are used to identify and categorize errors in redundant spatio-temporal data streams. In this paper, we apply these methods to real data from a private Cessna flight and from the Air France AF447 accident in June 2009. For the private Cessna flight, three error scenarios are simulated: pitot tube failure, GPS failure, and simultaneous pitot tube and GPS failures. The error detection accuracy is approximately 93% and the response time to correct data is at most 5 seconds. For the AF447 flight, 162 seconds of available flight data including the pitot tubes failure is collected from the accident report. The pitot tube failure of the AF447 flight is successfully detected and corrected after 5 seconds from the beginning of the failure\u00a0\u2026", "num_citations": "15\n", "authors": ["685"]}
{"title": "Programming spatio-temporal data streaming applications with high-level specifications\n", "abstract": " In this paper, we describe the design and implementation of PILOTS, a ProgrammIng Language for spatiO-Temporal data Streaming applications. Using PILOTS, application developers can easily program an application that handles spatio-temporal data streams by writing a high-level declarative program specification.", "num_citations": "15\n", "authors": ["685"]}
{"title": "Robust asynchronous optimization for volunteer computing grids\n", "abstract": " Volunteer computing grids offer significant computing power at relatively low cost to researchers, while at the same time generating public interest in different scientific projects. However, in order to be used effectively, their heterogeneity, volatility and restrictive computing models must be overcome. As these computing grids are open, incorrect or malicious results must also be handled. This paper examines extending the BOINC volunteer computing framework to allow for asynchronous global optimization as applied to scientific computing problems. The asynchronous optimization method used is resilient to faults and the heterogeneous nature of volunteer computing grids, while allowing scalability to tens of thousands of hosts. A work verification strategy that does not require the validation of every result is presented. This is shown to be able to effectively reduce the need for verification done to less than 30% of the\u00a0\u2026", "num_citations": "15\n", "authors": ["685"]}
{"title": "Asynchronous genetic search for scientific modeling on large-scale heterogeneous environments\n", "abstract": " Use of large-scale heterogeneous computing environments such as computational grids and the Internet has become of high interest to scientific researchers. This is because the increasing complexity of their scientific models and data sets is drastically outpacing the increases in processor speed while the cost of supercomputing environments remains relatively high. However, the heterogeneity and unreliability of these environments, especially the Internet, make scalable and fault tolerant search methods indispensable to effective scientific model verification. The paper introduces two versions of asynchronous master-worker genetic search and evaluates their convergence and performance rates in comparison to traditional synchronous genetic search on both a IBM BlueGene supercomputer and using the MilkyWay@HOME BOINC Internet computing project  1 . The asynchronous searches not only perform\u00a0\u2026", "num_citations": "15\n", "authors": ["685"]}
{"title": "Distributed and generic maximum likelihood evaluation\n", "abstract": " This paper presents GMLE  1 , a generic and distributed framework for maximum likelihood evaluation. GMLE is currently being applied to astroinformatics for determining the shape of star streams in the Milky Way galaxy, and to particle physics in a search for theory-predicted but yet unobserved sub-atomic particles. GMLE is designed to enable parallel and distributed executions on platforms ranging from supercomputers and high-performance homogeneous computing clusters to more heterogeneous Grid and Internet computing environments. GMLE's modular implementation seperates concerns of developers into the distributed evaluation frameworks, scientific models, and search methods, which interact through a simple API. This allows us to compare the benefits and drawbacks of different scientific models using different search methods on different computing environments. We describe and compare the\u00a0\u2026", "num_citations": "15\n", "authors": ["685"]}
{"title": "Salsa lite: A hash-based actor runtime for efficient local concurrency\n", "abstract": " As modern computer processors continue becoming more parallel, the actor model plays an increasingly important role in helping develop correct concurrent systems. In this paper, we consider efficient runtime strategies for non-distributed actor programming languages. While the focus is on a non-distributed implementation, it serves as a platform for a future efficient distributed implementation. Actors extend the object model by combining state and behavior with a thread of control, which can significantly simplify concurrent programming. Further, with asynchronous communication, no shared memory, and the fact an actor only processes one message at a time, it is possible to easily implement transparent distributed message passing and actor mobility. This paper discusses SALSA Lite, a completely re-designed actor runtime system engineered to maximize performance. The new runtime consists of a\u00a0\u2026", "num_citations": "14\n", "authors": ["685"]}
{"title": "OverView: A framework for generic online visualization of distributed systems\n", "abstract": " Visualizing, testing and debugging distributed systems is a challenging task that is not well ad- dressed by conventional software tools. OverView, an event-based Eclipse plug-in that provides runtime visualization of systems running on distributed Java virtual machines is presented. In the same way that the coding and debugging tools in Eclipse make writing software more accessible by visually representing both a program's static components: packages, classes, and interfaces, as well as a program's dynamic components: objects, threads, and invocation stacks; OverView in- tends to make distributed systems more accessible to programmers by creating an analogous visual workspace with appropriate abstractions for distributed component naming, state, location, remote communication, and migration. Overview is a generic visualization framework that uses an Entity Specification Language (ESL) to enable\u00a0\u2026", "num_citations": "14\n", "authors": ["685"]}
{"title": "The effects of heterogeneity on asynchronous panmictic genetic search\n", "abstract": " Research scientists increasingly turn to large-scale heterogeneous environments such as computational grids and the Internet based facilities to satisfy their rapidly growing computational needs. The increasing complexity of the scientific models and rapid collection of new data are drastically outpacing the advances in processor speed while the cost of supercomputing environments remains relatively high. However, the heterogeneity and unreliability of these environments, especially the Internet, make scalable and fault tolerant search methods indispensable to effective scientific model verification. An effective search method for these types of environments is asynchronous genetic search, where a population continuously evolves based on asynchronously generated and received results. However, it is unclear what effect heterogeneity has on this type of search. For example, results received from slower\u00a0\u2026", "num_citations": "13\n", "authors": ["685"]}
{"title": "Malleable components for scalable high performance computing\n", "abstract": " This paper describes a modular decentralized mid-dleware framework for dynamic application reconfiguration in large scale heterogeneous environments. Component malleability is presented as a dynamic reconfiguration strategy. Dynamic component granularity enables improved load balancing by component migration, and most importantly, it enables applications to scale up to arbitrarily large numbers of processing nodes in a relatively transparent way. Preliminary experimental results show that without significant overhead, malleable components can improve applications performance and distributed resource utilization.", "num_citations": "12\n", "authors": ["685"]}
{"title": "Dynamic data-driven learning for self-healing avionics\n", "abstract": " In sensor-based systems, spatio-temporal data streams are often related in non-trivial ways. For example in avionics, while the airspeed that an aircraft attains in cruise phase depends on the weight it carries, it also depends on many other factors such as engine inputs, angle of attack, and air density. It is therefore a challenge to develop failure models that can help recognize errors in the data, such as an incorrect fuel quantity or an incorrect airspeed. In this paper, we present a highly-declarative programming framework that facilitates the development of self-healing avionics applications, which can detect and recover from data errors. Our programming framework enables specifying expert-created failure models using error signatures, as well as learning failure models from data. To account for unanticipated failure modes, we propose a new dynamic Bayes classifier, that detects outliers and upgrades them\u00a0\u2026", "num_citations": "11\n", "authors": ["685"]}
{"title": "Fault tolerant distributed computing using asynchronous local checkpointing\n", "abstract": " The transactor model, an extension to the actor model, specifies an operational semantics to model concurrent systems with globally consistent distributed state. The semantics formalizes tracks dependencies among loosely coupled distributed components to ensure fault tolerance through a two-phase commit protocol and to issue rollbacks in the presence of failures or state inconsistency. In this paper, we introduce the design of a transactor language as an extension of an existing actor language and highlight the capabilities of this programming model. We developed our transactor language using SALSA, an actor language developed as a dialect of Java. We first develop a basic transactor SALSA/Java library, which implements the fundamental semantics of the transactor model following the operational semantics' transition rules. We then illustrate two example programs written using this library. Furthermore, we\u00a0\u2026", "num_citations": "11\n", "authors": ["685"]}
{"title": "Structured reasoning about actor systems\n", "abstract": " The actor model of distributed computing imposes important restrictions on concurrent computations in order to be valid. In particular, an actor language implementation must provide fairness, the property that if a system transition is infinitely often enabled, the transition must eventually happen. Fairness is fundamental to proving progress properties. We show that many properties of actor computation can be expressed and proved at an abstract level, independently of the details of a particular system of actors. As in abstract algebra, we formulate and prove theorems at the most abstract level possible, so that they can be applied at all more refined levels of the theory hierarchy. Our most useful abstract-level theorems concern persistence of actors, conditional persistence of messages, preservation of unique actor identifiers, monotonicity properties of actor local states, guaranteed message delivery, and general\u00a0\u2026", "num_citations": "11\n", "authors": ["685"]}
{"title": "Cost-efficient high-performance internet-scale data analytics over multi-cloud environments\n", "abstract": " To analyze data distributed across the world, one can use distributed computing power to take advantage of data locality and achieve higher throughput. The multi-cloud model, a composition of multiple clouds, can provide cost-effective computing resources to process such distributed data. As multicolour becomes more and more accessible from cloud users, the use of MapReduce/Hadoop over multi-cloud is emerging, however, existing work has two issues in principle. First, it mainly focuses on maximizing throughput by improving data locality, but the perspective of cost optimization is missing. Second, conventional centralized optimization methods would not be able to scale well in multi-cloud environments due to its highly dynamic nature. We plan to solve the first issue by formalizing an optimization framework for MapReduce over multi-cloud including virtual machine and data transfer costs, and then the\u00a0\u2026", "num_citations": "10\n", "authors": ["685"]}
{"title": "Actor garbage collection using vertex-preserving actor-to-object graph transformations\n", "abstract": " Large-scale distributed computing applications require concurrent programming models that support modular and compositional software development. The actor model supports the development of independent software components with its asynchronous message-passing communication and state encapsulation properties. Automatic actor garbage collection is necessary for high-level actor-oriented programming, but identifying live actors is not as intuitive and easy as identifying live passive objects in a reference graph. However, a transformation method can turn an actor reference graph into a passive object reference graph, which enables the use of passive object garbage collection algorithms and simplifies the problem of actor garbage collection. In this paper, we formally define potential communication by introducing two binary relations - the may-talk-to and the may-transitively-talk-to relations\u00a0\u2026", "num_citations": "10\n", "authors": ["685"]}
{"title": "Towards proving runtime properties of data-driven systems using safety envelopes\n", "abstract": " Dynamic data-driven application systems [1, 2](DDDAS) allow for unprecedented self-healing and self-diagnostic behavior across a broad swathe of domains. The usefulness of these systems is offset against their inherent complexity, and therefore fragility to specification or implementation error. Further, DDDAS techniques are often applied in safety-critical domains, where correctness is paramount. Formal methods facilitate the development of correctness proofs about software systems, which provide stronger behavioral guarantees than non-exhaustive unit tests. While unit testing can validate that a system behaves correctly in some finite number of configurations, formal methods enable us to prove correctness in an infinite subset of the configuration space, which is often needed in cyber-physical systems involving continuous mechanics. Although the efficacy of formal methods is traditionally offset by significantly\u00a0\u2026", "num_citations": "9\n", "authors": ["685"]}
{"title": "Evolving n-body simulations to determine the origin and structure of the milky way galaxy's halo using volunteer computing\n", "abstract": " This work describes research done by the MilkyWay@Home project to use N-Body simulations to model the formation of the Milky Way Galaxy's halo. While there have been previous efforts to use N-Body simulations to perform astronomical modeling, to our knowledge this is the first to use evolutionary algorithms to discover the initial parameters to the N-Body simulations so that they accurately model astronomical data. Performing a single 32,000 body simulation can take up to 200 hours on a typical processor, with an average of 15 hours. As optimizing the input parameters to these N-Body simulations typically takes at least 30,000 or more simulations, this work is made possible by utilizing the computing power of the 35,000 volunteered hosts at the MilkyWay@Home project, which are currently providing around 800 teraFLOPS. This work also describes improvements to an open-source framework for generic\u00a0\u2026", "num_citations": "9\n", "authors": ["685"]}
{"title": "Wind-aware trajectory planning for fixed-wing aircraft in loss of thrust emergencies\n", "abstract": " Loss of thrust (LOT) emergencies create the need for quickly providing pilots with valid trajectories for safely landing the aircraft. It is easy to pre-compute total lost of thrust trajectories for every possible initial point in a 3D flight plan, but it is impossible to predict variables like the availability of partial power, wing surface damage, and wind aloft in advance. Availability of partial power can affect the glide ratio of an aircraft while the presence of wind can significantly affect the trajectory of a gliding aircraft with respect to the ground, e.g. - a tailwind or a headwind can aid or hinder straight line glide by increasing or decreasing the ground speed. Wind can also change the shape of turns from circular to trochoidal, moving an aircraft away from its intended position. In this paper, we present a robust trajectory generation system that can take these dynamic factors into consideration. Our approach outputs valid trajectories to a\u00a0\u2026", "num_citations": "8\n", "authors": ["685"]}
{"title": "Uncertainty-aware elastic virtual machine scheduling for stream processing systems\n", "abstract": " Stream processing systems deployed on the cloud need to be elastic to effectively accommodate workload variations over time. Performance models can predict maximum sustainable throughput (MST) as a function of the number of VMs allocated. We present a scheduling framework that incorporates three statistical techniques to improve Quality of Service (QoS) of cloud stream processing systems: (i) uncertainty quantification to consider variance in the MST model; (ii) online learning to update MST model as new performance metrics are gathered; and (iii) workload models to predict input data stream rates assuming regular patterns occur over time. Our framework can be parameterized by a QoS satisfaction target that statistically finds the best performance/cost tradeoff. Our results illustrate that each of the three techniques alone significantly improves QoS, from 52% to 73-81% QoS satisfaction rates on average\u00a0\u2026", "num_citations": "8\n", "authors": ["685"]}
{"title": "Cost-efficient elastic stream processing using application-agnostic performance prediction\n", "abstract": " Cloud computing adds great on-demand scalability to stream processing systems with its pay-per-use cost model. However, to promise service level agreements to users while keeping resource allocation cost low is a challenging task due to uncertainties coming from various sources, such as the target application's scalability, future computational demand, and the target cloud infrastructure's performance variability. To deal with these uncertainties, it is essential to create accurate application performance prediction models. In cloud computing, the current state of the art in performance modelling remains application-specific. We propose an application-agnostic performance modeling that is applicable to a wide range of applications. We also propose an extension to probabilistic performance prediction. This paper reports the progress we have made so far.", "num_citations": "8\n", "authors": ["685"]}
{"title": "Elastic virtual machine scheduling for continuous air traffic optimization\n", "abstract": " As we are facing ever increasing air traffic demand, it is critical to enhance air traffic capacity and alleviate humancontrollers' workload by viewing air traffic optimization as acontinuous/online streaming problem. Air traffic optimizationis commonly formulated as an integer linear programming(ILP) problem. Since ILP is NP-hard, it is computationallyintractable. Moreover, a fluctuating number of flights changescomputational demand dynamically. In this paper, we presentan elastic middleware framework that is specifically designedto solve ILP problems generated from continuous air trafficstreams. Experiments show that our VM scheduling algorithmwith time-series prediction can achieve similar performanceto a static schedule while using 49% fewer VM hours for arealistic air traffic pattern.", "num_citations": "8\n", "authors": ["685"]}
{"title": "Toward a programming model for building reliable systems with distributed state\n", "abstract": " We present the preliminary design of a programming model for building reliable systems with distributed state from collections of potentially unreliable components. Our transactor model provides constructs for maintaining consistency among the states of distributed components. Our intention is that transactors should support key aspects of both traditional distributed transactions, e.g., for electronic commerce, and systems with weaker consistency requirements, e.g., peer-to-peer file- and process-sharing systems. In this paper, we motivate the need for language support for maintenance of distributed state, describe the design goals for the transactor model, provide an operational semantics for a simple transactor calculus, and provide several examples of applications of the transactor model in a higher-level language.The authors would like to thank James Leifer for detailed comments on previous drafts of this paper\u00a0\u2026", "num_citations": "8\n", "authors": ["685"]}
{"title": "A performance study of geo-distributed IoT data aggregation for fog computing\n", "abstract": " We investigate MapReduce-based data aggregation for Internet-of-Things data in a multi-tier, geo-distributed datacenter architecture. Specifically, we consider 1) end-to-end hierarchical data aggregation and 2) query response for aggregated data requests made by geo-distributed clients. We first develop a realistic performance model based on previous empirical studies. We then study application performance for various deployment architectures, ranging from a purely cloud-based approach to a geo-distributed architecture that combines cloud, fog, and edge resources. From simulations created based on U.S. Census data, we characterize the trade-off between end-to-end data aggregation time and query response time. Our experiments show that for data aggregation, a purely-cloud based deployment is 53% faster than a deployment with edge resources; however, for query response, the edge approach is 46\u00a0\u2026", "num_citations": "7\n", "authors": ["685"]}
{"title": "Dynamically reconfigurable scientific computing on large-scale heterogeneous grids\n", "abstract": " Many scientific applications require computational capabilities not easily supported by current computing environments. We propose a scalable computing environment based on autonomous actors. In this approach, a wide range of computational resources, ranging from clusters to desktops and laptops, can run an application programmed using actors as program components in an actor language: SALSA. SALSA actors have the ability to execute autonomously in dynamically reconfigurable computing environments. We develop the corresponding \u201cInternet Operating system\u201d (IO) to address run-time middleware issues such as permanent storage for results produced by actors, inter-actor communication and synchronization, and fault-tolerance in a manner transparent to the end-user. We are using this worldwide computing software infrastructure to solve a long outstanding problem in particle physics: the\u00a0\u2026", "num_citations": "7\n", "authors": ["685"]}
{"title": "Skedulix: Hybrid Cloud Scheduling for Cost-Efficient Execution of Serverless Applications\n", "abstract": " We present a framework for scheduling multifunction serverless applications over a hybrid public-private cloud. A set of serverless jobs is input as a batch, and the objective is to schedule function executions over the hybrid platform to minimize the cost of public cloud use, while completing all jobs by a specified deadline. As this scheduling problem is NP-Hard, we propose a greedy algorithm that dynamically determines both the order and placement of each function execution using predictive models of function execution time and network latencies. We present a prototype implementation of our framework that uses AWS Lambda and OpenFaaS, for the public and private cloud, respectively. We evaluate our prototype in live experiments using a mixture of compute and I/O heavy serverless applications. Our results show that our framework can achieve a speedup in batch processing of up to 1.92 times that of an\u00a0\u2026", "num_citations": "6\n", "authors": ["685"]}
{"title": "Global snapshot of a distributed system running on virtual machines\n", "abstract": " Recently, a new concept called desktop cloud emerged, which was developed to offer cloud computing services on non-dedicated resources. Similarly to cloud computing, desktop clouds are based on virtualization, and like other computational systems, may experience faults at any time. As a consequence, reliability has become a concern for researchers. Fault-tolerance strategies focused on independent virtual machines include snapshots (checkpoints) to resume the execution from a healthy state of a virtual machine on the same or another host, which is trivial because hypervisors provide this function. However, it is not trivial to obtain a global snapshot of a distributed system formed by applications that communicate among them because the concept of global clock does not exist, so it can not be guaranteed that snapshots of each VM will be taken at the same time. Therefore, some protocol is needed to\u00a0\u2026", "num_citations": "6\n", "authors": ["685"]}
{"title": "A middleware framework for maximum likelihood evaluation over dynamic grids\n", "abstract": " We have designed a maximum likelihood fitter using the actor model to distribute the computation over a heterogeneous network. The prototype implementation uses the SALSA programming language and the Internet Operating System middleware. We have used our fitter to perform a partial wave analysis of particle physics data. Preliminary measurements have shown good performance and scalability. We expect our approach to be applicable to other scientific domains, such as biology and astronomy, where maximum likelihood evaluation is an important technique. We also expect our performance results to scale to Internet-wide runtime infrastructures, given the high adaptability of our software framework.", "num_citations": "6\n", "authors": ["685"]}
{"title": "An electronic marketplace: Agent-based coordination models for online auctions\n", "abstract": " Different coordination models exist for managing concurrency in complex distributed systems, for example, direct interaction, tuple spaces, hierarchical structures, and publish-and-subscribe mechanisms. Online auctions are complex distributed systems, where the choice of coordination model can significantly impact the performance of multiple software agents, acting on behalf of human buyers and sellers. In this paper, we evaluate analytically and experimentally different auction types and coordination models in an electronic marketplace. Three important metrics are: the number of software agents, the number of messages exchanged between these agents, and the number of migrations performed by the agents. We conclude that dynamically choosing the number of agents and the coordination model can improve quality of service in electronic commerce applications. Furthermore, in online auctions where there is a lot of interaction between software agents, migration of agents to virtual stores and local bidding is more fair and efficient than using remote interaction. This observation has the potential to significantly improve and redefine existing online auction systems such as eBay.", "num_citations": "6\n", "authors": ["685"]}
{"title": "Network sensitive reconfiguration of distributed applications\n", "abstract": " Large-scale, dynamic, and heterogeneous networks of computational resources promise to provide high performance and scalability to computationally intensive applications, but these environments also introduce the need for complex resource management strategies. This paper introduces actor-based programming abstractions and a middleware framework to relieve developers from considering non-functional concerns while allowing middleware layers to optimize application performance and global resource utilization. The Internet Operating System (IOS) consists of a peer-to-peer virtual network of middleware agents that trigger application component reconfiguration based on changes in the underlying physical network and based on the application communication patterns and resource consumption. IOS middleware agents are highly customizable to account for different resource profiling, load balancing, and peer-to-peer interconnection policies. Despite the lack of global coordination and information management, IOS exhibited the ability to reconfigure distributed applications effectively improving their performance over highly dynamic networks. Diverse application communication topologies were tested on Internet-like and Grid-like environments using two middleware agent interconnection topologies: peer-to-peer (p2p) and cluster-tocluster (c2c). In most cases, p2p agent topologies outperformed c2c agent topologies for Internet-like environments; while c2c agent topologies outperformed p2p agent topologies for Grid-like environments. Our empirical results show also that using group migration of application components to perform\u00a0\u2026", "num_citations": "6\n", "authors": ["685"]}
{"title": "Data-driven state awareness for fly-by-feel aerial vehicles via adaptive time series and gaussian process regression models\n", "abstract": " This work presents the investigation and critical assessment, within the framework of Dynamic Data Driven Applications Systems (DDDAS), of two probabilistic state awareness approaches for fly-by-feel aerial vehicles based on (i) stochastic adaptive time-dependent time series models and (ii) Bayesian learning via homoscedastic and heteroscedastic Gaussian process regression models (GPRMs). Stochastic time-dependent autoregressive (TAR) time series models with adaptive parameters are estimated via a recursive maximum likelihood (RML) scheme and used to represent the dynamic response of a self-sensing composite wing under varying flight states. Bayesian learning based on homoscedastic and heteroscedastic versions of GPRM is assessed via the ability to represent the nonlinear mapping between the flight state and the vibration signal energy of the wing. The experimental assessment is\u00a0\u2026", "num_citations": "5\n", "authors": ["685"]}
{"title": "Conflict-aware flight planning for avoiding near mid-air collisions\n", "abstract": " We present a novel conflict-aware flight planning approach that avoids the possibility of near mid-air collisions (NMACs) in the flight planning stage. Our algorithm computes a valid flight-plan for an aircraft (ownship) based on a starting time, a set of discrete way-points in 3D space, discrete values of ground speed, and a set of available flight-plans for traffic aircraft. A valid solution is one that avoids loss of standard separation with available traffic flight-plans. Solutions are restricted to permutations of constant ground speed and constant vertical speed for the ownship between consecutive way-points. Since the course between two consecutive way-points is not changed, this strategy can be used in situations where vertical or lateral constraints due to terrain or weather may restrict deviations from the original flight-plan. This makes our approach particularly suitable for unmanned aerial systems (UAS) integration into\u00a0\u2026", "num_citations": "5\n", "authors": ["685"]}
{"title": "MilkyWay@ home: Harnessing volunteer computers to constrain dark matter in the Milky Way\n", "abstract": " MilkyWay@home is a volunteer computing project that allows people from every country in the world to volunteer their otherwise idle processors to Milky Way research. Currently, more than 25,000 people (150,000 since November 9, 2007) contribute about half a PetaFLOPS of computing power to our project. We currently run two types of applications: one application fits the spatial density profile of tidal streams using statistical photometric parallax, and the other application finds the N-body simulation parameters that produce tidal streams that best match the measured density profile of known tidal streams. The stream fitting application is well developed and is producing published results. The Sagittarius dwarf leading tidal tail has been fit, and the algorithm is currently running on the trailing tidal tail and bifurcated pieces. We will soon have a self-consistent model for the density of the smooth component of the\u00a0\u2026", "num_citations": "4\n", "authors": ["685"]}
{"title": "Enabling computational steering with an asynchronous-iterative computation framework\n", "abstract": " In this paper, we present a framework that enables scientists to steer computations executing over large-scale grid computing environments. By using computational steering, users can dynamically control their simulations or computations to reach expected results more efficiently. The framework supports steerable applications by introducing an asynchronous iterative MapReduce programming model that is deployed using Hadoop over a set of virtual machines executing on a multi-cluster grid. To tolerate the heterogeneity between different sites, results are collected asynchronously and users can dynamically interact with their computations to adjust the area of interest. According to users' dynamic interaction, the framework can redistribute the computational overload between the heterogeneous sites and explore the user's interest area by using more powerful sites when possible. With our framework, the\u00a0\u2026", "num_citations": "4\n", "authors": ["685"]}
{"title": "Distributed garbage collection for large-scale mobile actor systems\n", "abstract": " 1.1 An actor is a reactive entity which communicates with others by asynchronous messages in a non-blocking manner. In response to an incoming message, it can use its thread of control to 1) modify its internal state, 2) send messages to other actors, 3) create actors, or 4) migrate to another computing node......................... 3", "num_citations": "4\n", "authors": ["685"]}
{"title": "A non-blocking snapshot algorithm for distributed garbage collection of mobile active objects\n", "abstract": " Distributed actor garbage collection differs from distributed object garbage collection in that it needs to consider in-transit message detection, unordered message reception, and actor migration. In this paper, we propose a new snapshot-based distributed actor garbage collection algorithm. The algorithm does not require First-In-First-Out or blocking communication, nor message logging. Furthermore, actor migration is allowed while capturing global snapshots and partial snapshots can be safely used to collect garbage, therefore not requiring comprehensive cooperation among all computing nodes. These features make it unique in the area of distributed garbage collection. We formally prove the following safety and conditional liveness properties of the algorithm: 1) the garbage in a global snapshot, created by composing several local snapshots, remains the same from the beginning to the end of the global snapshot algorithm, and 2) garbage is eventually collected if the global garbage collection algorithm is periodically activated and every blocked actor is always captured before a global garbage collection phase is triggered.", "num_citations": "4\n", "authors": ["685"]}
{"title": "Approaches to architecture-aware parallel scientific computation\n", "abstract": " Modern parallel scientific computation is being performed in a wide variety of computational environments that include clusters, large-scale supercomputers, grid environments, and metacomputing environments. This presents challenges for application and library developers, who must develop architecture-aware software if they wish to utilize several computing platforms efficiently. Architecture-aware computation can be beneficial in single-processor environments. It takes the form of something as common as an optimizing compiler, which will optimize software for a target computer. Application and library developers may adjust data structures or memory management techniques to improve cache utilization on a particular system [21]. Parallel computation introduces more variety and, with that, more need and opportunity for architecture-specific optimizations. Heterogeneous processor speeds at first seem easy to\u00a0\u2026", "num_citations": "4\n", "authors": ["685"]}
{"title": "Mobility and security in worldwide computing\n", "abstract": " Modern distributed computing requires a secure framework capable of free code mobility. In this paper, we present a simple lambda-based actor language with extensions for mobility and security, as well as the operational semantics to reason about these topics in distributed systems. Finally, we describe our preliminary implementation results.", "num_citations": "4\n", "authors": ["685"]}
{"title": "ACCORDANT: A domain specific-model and DevOps approach for big data analytics architectures\n", "abstract": " Big data analytics (BDA) applications use machine learning algorithms to extract valuable insights from large, fast, and heterogeneous data sources. New software engineering challenges for BDA applications include ensuring performance levels of data-driven algorithms even in the presence of large data volume, velocity, and variety (3Vs). BDA software complexity frequently leads to delayed deployments, longer development cycles, and challenging performance assessment. This paper proposes a Domain-Specific Model (DSM), and DevOps practices to design, deploy, and monitor performance metrics in BDA applications. Our proposal includes a design process, and a framework to define architectural inputs, software components, and deployment strategies through integrated high-level abstractions to enable QS monitoring. We evaluate our approach with four use cases from different domains to demonstrate\u00a0\u2026", "num_citations": "3\n", "authors": ["685"]}
{"title": "Collaborative situational awareness for conflict-aware flight planning\n", "abstract": " In autonomous air-traffic management scenarios of the future, manned and unmanned aircraft will be able to safely navigate through the National Airspace System, independent of centralized air-traffic controllers. They will do this by sharing critical data necessary for maintaining standard separation with each other. Under such conditions, every aircraft must have sufficient knowledge about other aircraft sharing the airspace to operate safely. In this paper, we specify a safe state of knowledge that is necessary for aircraft to operate safely in the absence of a centralized air-traffic controller and present a distributed knowledge propagation protocol to attain this safe state. This protocol can be used by network-connected aircraft to achieve collaborative situational awareness for cooperative flight planning. We identify certain system conditions necessary to guarantee two correctness properties for our protocol \u2013 safety and\u00a0\u2026", "num_citations": "3\n", "authors": ["685"]}
{"title": "Dynamic data-driven formal progress envelopes for distributed algorithms\n", "abstract": " This work presents formal progress envelopes applied to flight systems for distinctly classifying a system\u2019s state space into regions where a formal proof of progress for a distributed algorithm holds or does not hold. It also presents an approach for runtime integration of formal methods in the dynamic data-driven applications systems (DDDAS) architecture using parameterized proofs. Finally, it showcases the development of reusable parameterized proof libraries for high-level statistical and stochastic reasoning in the Athena proof assistant and demonstrates their use with a progress proof for the Paxos distributed consensus protocol.", "num_citations": "3\n", "authors": ["685"]}
{"title": "Self-healing data streams using multiple models of analytical redundancy\n", "abstract": " We have created a highly declarative programming language called PILOTS that enables error detection and estimation of correct data streams based on analytical redundancy (i.e., algebraic relationship between data streams). Data scientists are able to express their analytical redundancy models with the domain specific grammar of PILOTS and test their models with erroneous data streams. PILOTS has the ability to express a single analytical redundancy, and it has been successfully applied to data from aircraft accidents such as Air France flight 447 and Tuninter flight 1153 where only one simultaneous sensor type failure was observed. In this work, we extend PILOTS to support multiple models of analytical redundancy and improve situational awareness for multiple simultaneous sensor type failures. Motivated by the two recent accidents involving the Boeing 737 Max 8, which was potentially caused by a faulty\u00a0\u2026", "num_citations": "3\n", "authors": ["685"]}
{"title": "Developing elastic software for the cloud\n", "abstract": " Developing standalone applications running on a single computer is very different from developing scalable applications running on the cloud, such as data analytics applications that process terabytes of data, Web applications that receive thousands of requests per second, or distributed computing applications where components run simultaneously across many computers. Cloud computing service providers help facilitate the development of these complex applications through their cloud programming frameworks. A cloud programming framework is a software platform to develop applications in the cloud that takes care of nonfunctional concerns, such as scalability, elasticity, fault tolerance, and load balancing. Using cloud programming frameworks, application developers can focus on the functional aspects of their applications and benefit from the power of cloud computing.In this chapter, we will show how to\u00a0\u2026", "num_citations": "3\n", "authors": ["685"]}
{"title": "A performance and scalability analysis of actor message passing and migration in SALSA Lite\n", "abstract": " IncomingTheaterConnectionActors are spawned by the theater when a connection is established on it's listening port. They repeatedly receive messages (and actors in the case of migration) and forward them on the the appropriate stage to be processed by their target. OutgoingTheaterConnectionActors connect to outgoing theaters and then send messages to remote actors over the connection to their corresponding IncomingTheaterConnectionActor.", "num_citations": "3\n", "authors": ["685"]}
{"title": "Ethical Reasoning for Autonomous Agents Under Uncertainty\n", "abstract": " Autonomous (and partially autonomous) agents are beginning to play significant roles in safetycritical and privacy-critical domains, such as driving and healthcare. When humans operate in these spaces, not only are there regulations and laws dictating proper behavior, but crucially, neurobiologically normal humans can be expected to comprehend how to reason with certain principles to ensure that their actions are legally/ethically/prudentially correct (whether or not these humans choose to abide by the principles in question). It seems reasonable that we should hold autonomous agents to, minimally, the same standard we hold humans to. In this paper, we present a framework for autonomous aircraft piloting agents to reason about ethical problems in the context of emergency landings. In particular, we are concerned with ethical problems in which every option is equally unethical with regard to the ethical principles the options violate; and the only distinguishing factor is the likelihood that a plan will violate an ethical principle. We conclude by discussing why, in general, we find an inference-theoretic approach to ethical reasoning to be superior to the model-theoretic approach of prior work.", "num_citations": "2\n", "authors": ["685"]}
{"title": "Dynamic data driven analytics for multi-domain environments\n", "abstract": " Recent trends in artificial intelligence and machine learning (AI/ML), dynamic data driven application systems (DDDAS), and cloud computing provide opportunities for enhancing multidomain systems performance. The DDDAS framework utilizes models, measurements, and computation to enhance real-time sensing, performance, and analysis. One example the represents a multi-domain scenario is \u201cfly-by-feel\u201d avionics systems that can support autonomous operations. A \"fly-by-feel\" system measures the aerodynamic forces (wind, pressure, temperature) for physics-based adaptive flight control to increase maneuverability, safety and fuel efficiency. This paper presents a multidomain approach that identifies safe flight operation platform position needs from which models, data, and information are invoked for effective multidomain control. Concepts are presented to demonstrate the DDDAS approach for enhanced\u00a0\u2026", "num_citations": "2\n", "authors": ["685"]}
{"title": "Augmenting performance for distributed cloud storage\n", "abstract": " The device people use to capture multimedia has changed over the years with the rise of smart phones. Smart phones are readily available, easy to use, and capture multimedia with high quality. While consumers capture all of this media, the storage requirements are not changing significantly. Therefore, people look towards cloud storage solutions. The typical consumer stores files within a single provider. They want a solution that is quick to access, reliable, and secure. Using multiple providers can reduce cost and improve overall performance. We present a middleware framework called Distributed Indexed Storage in the Cloud (DISC) to improve all aspects a user expects in a cloud provider. The process of uploading and downloading is essentially transparent to the user. The upload and download performance happens simultaneously by distributing a subset of the file across multiple cloud providers that it\u00a0\u2026", "num_citations": "2\n", "authors": ["685"]}
{"title": "Modular visualization of distributed systems\n", "abstract": " Effective visualization is critical to developing, analyzing, and optimizing distributed systems. We have developed OverView, a tool for online/offline distributed systems visualization, that enables modular layout mechanisms, so that different distributed system high-level programming abstractions such as actors or processes can be visualized in intuitive ways. OverView uses by default a hierarchical concentric layout that distinguishes entities from containers allowing migration patterns triggered by adaptive middleware to be visualized. In this paper, we develop a force-directed layout strategy that connects entities according to their communication patterns in order to directly exhibit the application communication topologies. In force-directed visualization, entities\u2019 locations are encoded with different colors to illustrate load balancing. We compare these layouts using quantitative metrics including communication to entity ratio, applied on common distributed application topologies. We conclude that modular visualization is necessary to effectively visualize distributed systems since no one layout is best for all applications.", "num_citations": "2\n", "authors": ["685"]}
{"title": "Advances in Grid and Pervasive Computing: 4th International Conference, GPC 2009, Geneva, Switzerland, May 4-8, 2009, Proceedings\n", "abstract": " Grid and Pervasive Computing (GPC) is an annual international conference devoted to the promotion and advancement of all aspects of grid and pervasive computing. The objective of this conference is to provide a forum for researchers and engineers to present their latest research in the? elds of grid and pervasive computing. Previous editions of the Grid and Pervasive Computing conference were held in: Kunming (China) May 25-28, 2008, Paris (France) May 2-4, 2007, and Taichung (Taiwan) May 3-5, 2006. The fourth edition took place in Geneva, Switzerland during May 4-8, 2009. It was organized by members of the University of Applied Sciences Western Switzerland (Haute Ecole de Paysage, d\u2019Ing \u0301 enierie et d\u2019Architecture-hepia), in collaboration with colleagues from various places around the world. The conference spanned a full week, including a three-day technical program where the papers contained in these proceedings were presented. The conf-ence was followed by two tutorial days where attendants had the opportunity to discuss a variety of topics related to the? elds covered at the conference, at both introductory and advanced levels. The technical program also included an industrial session, with contributions illustrating challenges faced and so-tions devised by industry. Furthermore, the conference o? ered an opportunity for vendors and researchers to present their products and projects at an ex-bition (Grid Village) where solutions supporting the development of grid and pervasive computing were displayed.", "num_citations": "2\n", "authors": ["685"]}
{"title": "Tracing the sagittarius tidal stream with maximum likelihood\n", "abstract": " Large scale surveys are providing vast amounts of data that can help us understand and study tidal debris more easily and accurately. A maximum likelihood method for determining the spatial properties of this tidal debris and the stellar Galactic spheroid has been developed to take advantage of these huge datasets. We present the results of studying the Sagittarius dwarf tidal stream in two SDSS stripes taken in the southern Galactic Cap using this method. This study was done using stars with the colors of blue F turnoff stars in SDSS. We detected Sagittarius debris at the positions (l,b,R)\u2009=\u2009(163.311\u00b0,\u221248.400\u00b0,30.23\u2009kpc) and (l,b,R)\u2009=\u2009(34.775\u00b0,\u221272.342\u00b0,26.08\u2009kpc). These debris pieces were found to have a FWHM of 6.53\u00b10.54\u2009kpc and 5.71\u00b10.26\u2009kpc and also to contain \u22489,500 and \u224816,700 F turnoff stars, respectively. The debris pieces were also found to have (spatial) directions of (X\u0302,\u0176,\u1e90)\u2009=\u2009(0.758,0\u00a0\u2026", "num_citations": "2\n", "authors": ["685"]}
{"title": "OverView-Dynamic Visualization of Java-Based Highly Reconfigurable Distributed Systems\n", "abstract": " Online visualization enables developers to test, debug, and monitor the behavior of distributed systems, while they are running. While important in software development, online visualization of distributed systems is largely unaddressed by conventional tools. Distributed systems are often programmed using high-level abstractions that facilitate reasoning about them, eg, actors, processes, sessions, or ambients. OverView is an entity specification language-driven Eclipse plug-in for visualization of distributed systems that preserves the high level of abstraction, and enables online visualization of critical distributed system properties such as component naming, location, remote communication, and migration. OverView\u2019s architecture is generic in that different abstractions can reuse the visualization module requiring changes only in the entity specifications that drive the visualization process.", "num_citations": "2\n", "authors": ["685"]}
{"title": "The Effects of Heterogeneity on Asynchronous Panmictic Genetic Search\n", "abstract": " Research scientists increasingly turn to large-scale heterogeneous environments such as computational grids and the Internet based facilities to satisfy their rapidly growing computational needs. The increasing complexity of the scientific models and rapid collection of new data are drastically outpacing the advances in processor speed while the cost of supercomputing environments remains relatively high. However, the heterogeneity and unreliability of these environments, especially the Internet, make scalable and fault tolerant search methods indispensable to effective scientific model verification. An effective search method for these types of environments is asynchronous genetic search, where a population continuously evolves based on asynchronously generated and received results. However, it is unclear what effect heterogeneity has on this type of search. For example, results received from slower workers may turn out to be obsolete or less beneficial than results calculated by faster workers. This paper examines the effect of heterogeneity on asynchronous panmictic (single population) genetic search for two different scientific applications, one used by astronomers to model the Milky Way galaxy and another by particle physicists to determine the existence of theory predicted, yet unobserved particles such as missing baryons. Results show that for both applications results received from slower workers while overall less beneficial are still useful. Additionally, a modification of asynchronous genetic search shows that different parameter generation strategies change their effectiveness over the course of the search 1.", "num_citations": "2\n", "authors": ["685"]}
{"title": "Towards Provably Correct Probabilistic Flight Systems\n", "abstract": " Safety envelopes are meant to determine under which conditions and state space regions a probabilistic property of a data-driven system can be asserted with high confidence. Dynamic data-driven applications systems (DDDAS) can make use of safety envelopes to be cognizant of the formal warranties derived from their models and assumptions. An example of safety envelopes is presented as the intersection of two simpler concepts: -predictability and -confidence; which correspond to state estimation and classification, respectively. To illustrate safety envelopes, stall detection from signal energy is shown with data gathered by piezo-electric sensors in a composite wing inside a wind tunnel under varying angles of attack and airspeed configuration. A formalization of these safety envelopes is presented in the Agda proof assistant, from which formally proven sentinel code can be generated.", "num_citations": "1\n", "authors": ["685"]}
{"title": "Measuring performance quality scenarios in big data analytics applications: a DevOps and domain-specific model approach\n", "abstract": " Big data analytics (BDA) applications use advanced analysis algorithms to extract valuable insights from large, fast, and heterogeneous data sources. These complex BDA applications require software design, development, and deployment strategies to deal with volume, velocity, and variety (3vs) while sustaining expected performance levels. BDA software complexity frequently leads to delayed deployments, longer development cycles and challenging performance monitoring. This paper proposes a DevOps and Domain Specific Model (DSM) approach to design, deploy, and monitor performance Quality Scenarios (QS) in BDA applications. This approach uses high-level abstractions to describe deployment strategies and QS enabling performance monitoring. Our experimentation compares the effort of development, deployment and QS monitoring of BDA applications with two use cases of near mid-air collisions\u00a0\u2026", "num_citations": "1\n", "authors": ["685"]}
{"title": "Stochastic Quantitative Reasoning for Autonomous Mission Planning\n", "abstract": " In research performed with funding from this grant, PI Varela has developed mathematical concepts and software to automatically detect and correct for errors in spatio-temporal data streams. Varela and his group invented and formalized the notions of error signatures and mode likelihood vectors, and developed the PILOTS programming language v0. 2.3. An important application of this work was to demonstrate that the Air France flight 447 accident from June 2009 could have been avoided by using these techniques applied on air speed, ground speed, and wind speed data streams.Descriptors:", "num_citations": "1\n", "authors": ["685"]}
{"title": "Enabling computational steering with an asynchronous-iterative computation framework\n", "abstract": " In this paper, we present a framework that enables scientists to steer computations executing over large-scale grid computing environments. By using computational steering, users can dynamically control their simulations or computations to reach expected results more efficiently. The framework supports steerable applications by introducing an asynchronous iterative MapReduce programming model that is deployed using Hadoop over a set of virtual machines executing on a multi-cluster grid. To tolerate the heterogeneity between different sites, results are collected asynchronously and users can dynamically interact with their computations to adjust the area of interest. According to users dynamic interaction, the framework can redistribute the computational overload between the heterogeneous sites and explore the user's interest area by using more powerful sites when possible. With our framework, the\u00a0\u2026", "num_citations": "1\n", "authors": ["685"]}
{"title": "The SALSA Programming Language 2.0. 0alpha Release Tutorial\n", "abstract": " With the emergence of Internet and mobile computing, a wide range of Internet applications have introduced new demands for openness, portability, highly dynamic reconfiguration, and the ability to adapt quickly to changing execution environments. Current programming languages and systems lack support for dynamic reconfiguration of applications, where application entities get moved to different processing nodes at run-time.Java has provided support for dynamic web content through applets, network class loading, bytecode verification, security, and multi-platform compatibility. Moreover, Java is a good framework for distributed Internet programming because of its standardized representation of objects and serialization support. Some of the important libraries that provide support for Internet computing are: java. rmi for remote method invocation, java. reflection for run-time introspection, java. io for serialization, and java. net for sockets, datagrams, and URLs. SALSA (Simple Actor Language, System and Architecture)[3] is an actororiented programming language designed and implemented to introduce the benefits of the actor model while keeping the advantages of object-oriented programming. Abstractions include active objects, asynchronous message passing, universal naming, migration, and advanced coordination constructs for concurrency. SALSA is pre-processed into Java and preserves many of Java\u2019s useful object oriented conceptsmainly, encapsulation, inheritance, and polymorphism. SALSA abstractions enable the development of dynamically reconfigurable applications. A SALSA program consists of universal actors that can be\u00a0\u2026", "num_citations": "1\n", "authors": ["685"]}
{"title": "Organic and hierarchical concentric layouts for distributed system visualization\n", "abstract": " Distributed systems, due to their inherent complexity and nondeterministic nature, are programmed using high-level abstractions, such as processes, actors, ambients, agents, or services. There is a need to provide tools which allow developers to better understand, test, and debug distributed systems. OverView is a software toolkit which allows online and offline visualization of distributed systems through the concepts of entities and containers, which preserve the abstractions used at the programming level and display important dynamic properties, such as temporal (that is, when entities are created and deleted), spatial (that is, entity location and migration events) and relational (that is, entity containment or communication patterns). In this paper, we introduce two general layout mechanisms to visualize distributed systems: a hierarchical concentric layout that places containers and entities in a ring of rings, and an organic layout that uses the dynamic properties of the system to co-locate entities. We define visualization quality metrics such as intuitiveness, scalability, and genericity, and use them to evaluate the visualization layouts for several application communication topologies including linked lists, trees, hypercubes, and topologies arising from structured overlay networks such as Chord rings.", "num_citations": "1\n", "authors": ["685"]}
{"title": "Making Maximally Ethical Decisions via Cognitive Likelihood & Formal Planning\n", "abstract": " This chapter attempts to give an answer to the following question: Given an obligation and a set of potentially-inconsistent, ethically-charged beliefs, how can an artificially-intelligent agent ensure that its actions maximize the likelihood that the obligation is satisfied? Our approach to answering this question is in the intersection of several areas of research, including automated planning, reasoning with uncertainty, and argumentation. We exemplify our reasoning framework in a case study based on the famous, heroic ditching of US Airways Flight 1549, an event colloquially known as the \u201cMiracle on the Hudson.\u201d", "num_citations": "1\n", "authors": ["685"]}