{"title": "Approximating the true evolutionary distance between two genomes\n", "abstract": " As more and more genomes are sequenced, evolutionary biologists are becoming increasingly interested in evolution at the level of whole genomes, in scenarios in which the genome evolves through insertions, duplications, deletions, and movements of genes along its chromosomes. In the mathematical model pioneered by Sankoff and others, a unichromosomal genome is represented by a signed permutation of a multiset of genes; Hannenhalli and Pevzner showed that the edit distance between two signed permutations of the same set can be computed in polynomial time when all operations are inversions. El-Mabrouk extended that result to allow deletions and a limited form of insertions (which forbids duplications); in turn we extended it to compute a nearly optimal edit sequence between an arbitrary genome and the identity permutation. In this paper we generalize our approach to compute distances\u00a0\u2026", "num_citations": "102\n", "authors": ["1721"]}
{"title": "Time travel debugging for browser components\n", "abstract": " Various technologies described herein pertain to performing time travel debugging. A computer-executable program can be executed. The computer-executable program can be executable under control of a virtual machine. The virtual machine can interact with a browser system during execution of the computer-executable program. Moreover, nondeterministic events can be logged via an interrogative virtual machine interface (VMI) during the execution of the computer-executable program. The nondeterministic events can be logged as part of event logs. Moreover, the interrogative VMI is between the virtual machine and the browser system. Further, snapshots of the virtual machine can be captured during the execution of the computer-executable program. The snapshots can be captured via the interrogative VMI. At least a portion of the execution of the computer-executable program can be replayed based at\u00a0\u2026", "num_citations": "80\n", "authors": ["1721"]}
{"title": "Genomic distances under deletions and insertions\n", "abstract": " As more and more genomes are sequenced, evolutionary biologists are becoming increasingly interested in evolution at the level of whole genomes, in scenarios in which the genome evolves through insertions, deletions, and movements of genes along its chromosomes. In the mathematical model pioneered by Sankoff and others, a unichromosomal genome is represented by a signed permutation of a multiset of genes; Hannenhalli and Pevzner showed that the edit distance between two signed permutations of the same set can be computed in polynomial time when all operations are inversions. El-Mabrouk extended that result to allow deletions (or conversely, a limited form of insertions which forbids duplications). In this paper, we extend El-Mabrouk's work to handle duplications as well as insertions and present an alternate framework for computing (near) minimal edit sequences involving insertions, deletions\u00a0\u2026", "num_citations": "70\n", "authors": ["1721"]}
{"title": "Time travel debugging in managed runtime\n", "abstract": " Various technologies described herein pertain to time travel debugging in a managed runtime system. The managed runtime system can include an execution component that executes a managed program component. Moreover, the managed runtime system can include a time travel debugger component. The time travel debugger component can be configured to record a sequence of live-object snapshots of program states during execution of the managed program component. A live-object snapshot can include live objects from a heap in memory at a given time during the execution. Moreover, the time travel debugger component can be configured to replay at least a portion of the execution of the managed program component based upon the live-object snapshots.", "num_citations": "62\n", "authors": ["1721"]}
{"title": "Tardis: Affordable time-travel debugging in managed runtimes\n", "abstract": " Developers who set a breakpoint a few statements too late or who are trying to diagnose a subtle bug from a single core dump often wish for a time-traveling debugger. The ability to rewind time to see the exact sequence of statements and program values leading to an error has great intuitive appeal but, due to large time and space overheads, time traveling debuggers have seen limited adoption. A managed runtime, such as the Java JVM or a JavaScript engine, has already paid much of the cost of providing core features - type safety, memory management, and virtual IO - that can be reused to implement a low overhead time-traveling debugger. We leverage this insight to design and build affordable time-traveling debuggers for managed languages. Tardis realizes our design: it provides affordable time-travel with an average overhead of only 7% during normal execution, a rate of 0.6MB/s of history logging, and a\u00a0\u2026", "num_citations": "42\n", "authors": ["1721"]}
{"title": "Genomic distances under deletions and insertions\n", "abstract": " As more and more genomes are sequenced, evolutionary biologists are becoming increasingly interested in evolution at the level of whole genomes, in scenarios in which the genome evolves through insertions, deletions, and movements of genes along its chromosomes. In the mathematical model pioneered by Sankoff and others, a unichromosomal genome is represented by a signed permutation of a multi-set of genes; Hannenhalli and Pevzner showed that the edit distance between two signed permutations of the same set can be computed in polynomial time when all operations are inversions. El-Mabrouk extended that result to allow deletions and a limited form of insertions (which forbids duplications). In this paper we extend El-Mabrouk\u2019s work to handle duplications as well as insertions and present an alternate framework for computing (near) minimal edit sequences involving insertions, deletions\u00a0\u2026", "num_citations": "39\n", "authors": ["1721"]}
{"title": "Semantics of asynchronous JavaScript\n", "abstract": " JavaScript code running in the Node. js runtime is a major platform for developers building cloud, mobile, or IoT applications. A fundamental concept in Node. js programming is the use of asynchronous callbacks and event loops to provide highly responsive applications. While conceptually simple, this programming model contains numerous subtleties and behaviors that are defined implicitly by the current Node. js implementation. This paper presents the first comprehensive formalization of the Node. js asynchronous execution model and defines a high-level notion of async-contexts to formalize fundamental relationships between asynchronous executions in an application. These formalizations provide a foundation for the construction of static or dynamic program analysis tools, support the exploration of alternative Node. js event loop implementations, and provide a high-level conceptual framework for reasoning\u00a0\u2026", "num_citations": "31\n", "authors": ["1721"]}
{"title": "Time-travel debugging for javascript/node. js\n", "abstract": " Time-traveling in the execution history of a program during debugging enables a developer to precisely track and understand the sequence of statements and program values leading to an error. To provide this functionality to real world developers, we embarked on a two year journey to create a production quality time-traveling debugger in Microsoft's open-source ChakraCore JavaScript engine and the popular Node. js application framework.", "num_citations": "31\n", "authors": ["1721"]}
{"title": "Collecting a Heap of Shapes\n", "abstract": " The program heap is fundamentally a simple mathematical concept---a set of objects and a connectivity relation on them. However, a large gap exists between the set of heap structures that could be constructed and those that programmers actually build. To understand this gap, we empirically study heap structures and sharing relations in large object-oriented programs. To scale and make sense of real world heaps, any analysis must employ abstraction; our abstraction groups sets of objects by role and the aliasing present in pointer sets. We find that the heaps of real-world programs are, in practice, fundamentally simple structures that are largely constructed from a small number of simple structures and sharing idioms, such as the sharing of immutable or unique (eg, singleton) objects. For instance, we find that, under our abstraction, 53--75% of pointers build tree structures and we classify all but 7--18% of\u00a0\u2026", "num_citations": "18\n", "authors": ["1721"]}
{"title": "Modeling the heap: A practical approach\n", "abstract": " The ability to accurately model the evolution of the program heap during the execution of a program is critical for many types of program optimization and verification techniques. Past work on the topic of heap analysis has identified a number of important heap properties (connectivity, shape, heap based dependence information, and region identification) that are used in many client applications (parallelization, scheduling, memory management) and has explored a range of approaches for computing this information. However, past work has been unable to compute this information with the required level of accuracy and/or has not been computationally efficient enough to make the analysis practical. The inability to compute the required heap information has limited the scope or effectiveness of many branches of research (the inability to compute the required heap information made the optimization technique\u00a0\u2026", "num_citations": "6\n", "authors": ["1721"]}
{"title": "Log++ logging for a cloud-native world\n", "abstract": " Logging is a fundamental part of the software development and deployment lifecycle but logging support is often provided as an afterthought via limited library APIs or third-party modules. Given the critical nature of logging in modern cloud, mobile, and IoT development workflows, the unique needs of the APIs involved, and the opportunities for optimization using semantic knowledge, we argue logging should be included as a central part of the language and runtime designs. This paper presents a rethinking of the logger for modern cloud-native workflows.   Based on a set of design principles for modern logging we build a logging system, that supports near zero-cost for disabled log statements, low cost lazy-copying for enabled log statements, selective persistence of logging output, unified control of logging output across different libraries, and DevOps integration for use with modern cloud-based deployments. To\u00a0\u2026", "num_citations": "5\n", "authors": ["1721"]}
{"title": "Techniques to identify idiomatic code in a code base\n", "abstract": " Techniques to identify idiomatic code in a code base are described. Embodiments of such techniques are configured with idiom information corresponding to idiomatic code representations of computer code of which each idiomatic code representation comprises information corresponding to a control structure and variable usage. These techniques are operative to compare the idiomatic code representations to computer code fragments in the code base and identify one or more code fragments matching at least one of the idiomatic code representations. These techniques may identify functional operators for replacing the code fragments in the code base. Other embodiments are described and claimed.", "num_citations": "4\n", "authors": ["1721"]}
{"title": "A gray box approach for high-fidelity, high-speed time-travel debugging\n", "abstract": " Time-travel debugging (TTD) lets developers step backward as well as forward through a program\u2019s execution. TTD is a powerful mechanism for diagnosing bugs, but previous approaches suffer from poor performance due to checkpoint and logging overhead, or poor fidelity because important information like GUI state is not tracked. In this paper, we describe how to provide highperformance and high-fidelity TTD to programs written in managed languages. Previous high-performance debuggers treat components external to the program like the GUI as black boxes, but that is not sufficient for highfidelity time-travel. Instead, we advocate for a gray-box approach that keeps these components live and in sync with the program during time-travel. The key insight is that managed runtime APIs expose most of the functionality required to do this; where it does not, we extend the runtime with a small number of non-intrusive interrogative interfaces. To demonstrate the power of our gray-box approach, we implement REJS, a time-traveling debugger for web applications. REJS imposes imperceptible tracing overhead, and its logs typically grow less than 1 KB/s. As a result, REJS is performant enough to be deployed in the wild; real client machines can ship buggy execution traces across the wide area to developer-side machines for debugging.", "num_citations": "3\n", "authors": ["1721"]}
{"title": "Mining semantic loop idioms from Big Code\n", "abstract": " During maintenance, developers spend a lot of time transforming existing code: refactoring, optimizing, and adding checks to make it more robust. Much of this work is the drudgery of identifying and replacing specific patterns, yet it resists automation, because of meaningful patterns are hard to automatically find. We present a technique for mining loop idioms, surprisingly probable semantic patterns that occur in loops, from big code to find meaningful patterns. First, we show that automatically identifiable patterns exist, in great numbers, with a large scale empirical study of loop over 25 MLOC. We find that loops in this corpus are simple and predictable: 90% of them have fewer than 15LOC and 90% have no nesting and very simple control structure. Encouraged by this result, we coil loops to abstract away syntactic diversity to define information rich loop idioms. We show that only 50 loop idioms cover 50% of the concrete loops. We show how loop idioms can help a tool developers identify and prioritize refactorings. We also show how our framework opens the door to data-driven tool and language design discovering opportunities to introduce new API calls and language constructs: loop idioms show that LINQ would benefit from an Enumerate operator, a result confirmed by the fact that precisely this feature is one of the most requested features on StackOverflow with 197 votes and 95k views.", "num_citations": "3\n", "authors": ["1721"]}
{"title": "Programming paradigm driven heap analysis\n", "abstract": " The computational cost and precision of a shape style heap analysis is highly dependent on the way method calls are handled. This paper introduces a new approach to analyzing method calls that leverages the fundamental object-oriented programming concepts of encapsulation and invariants. The analysis consists of a novel partial context-sensitivity heuristic and a new take on cutpoints that, in practice, provide large improvements in interprocedural analysis performance while having minimal impacts on the precision of the results.               The interprocedural analysis has been implemented for .Net bytecode and an existing abstract heap model. Using this implementation we evaluate both the runtime cost and the precision of the results on a number of well known benchmarks and real-world programs. Our experimental evaluations show that, despite the use of partial context sensitivity heuristics, the\u00a0\u2026", "num_citations": "3\n", "authors": ["1721"]}
{"title": "Heap analysis design: An empirical approach\n", "abstract": " Despite extensive work on the subject, the construction of a precise, accurate, and scalable static heap analysis for object-oriented programs remains an open problem. This paper argues that much of this difficulty is the result of inappropriate, and empirically unvalidated, design decisions. We examine three them and show that in practice:(1) strong updates are not necessary for obtaining accurate results (2) fixed naming schemes for defining abstract memory locations are fundamentally limiting and are not required for efficiency, and (3) shape/sharing in the heap is generally simple and can be described using a simple abstract heap model. Using these results we construct a new heap analysis and experimentally demonstrate that it is both precise and accurate, enabling program optimizations that are not possible with existing points-to analyses, and scalable, allowing the analysis of programs outside the scope of existing shape analyses.", "num_citations": "2\n", "authors": ["1721"]}
{"title": "Single-core performance is still relevant in the multi-core era\n", "abstract": " Problem: Underutilized Hardware. Software rarely uses all the potential performance available in a modern microprocessor. For example, on an Intel Core 2 class workstation\u2014a microprocessor capable of executing 4 instructions per cycle\u2014the average instructions per cycle for the single-threaded DaCapo benchmark suite is 0.98. In other words, even in the multi-core era, there is still enormous potential to increase single-core program performance. Recent work in PLDI has focused on multi-core performance: by our count PLDI\u201910 has around 6 papers on multi-core optimizations and PLDI\u201911 has 6 papers as well. We believe this aggressive focus on multi-core may miss a critical trend in computing environments: power, or performance per watt. The issues of power consumption and thermal dissipation are now major limiting factors in performance, even in environments with unconstrained power and cooling systems (eg, desktops or servers). However, power consumption and performance per watt are even more critical in mobile computing (eg, phones or tablets) and data centers, which are increasingly important computing environments. We argue that, while research on multi-core optimizations is valuable, improvements in single-core performance via improved resource utilization are key to increasing performance and doing so with minimal impact on power consumption.", "num_citations": "2\n", "authors": ["1721"]}
{"title": "SafeStrings: Representing Strings as Structured Data\n", "abstract": " Strings are ubiquitous in code. Not all strings are created equal, some contain structure that makes them incompatible with other strings. CSS units are an obvious example. Worse, type checkers cannot see this structure: this is the latent structure problem. We introduce SafeStrings to solve this problem and expose latent structure in strings. Once visible, operations can leverage this structure to efficiently manipulate it; further, SafeStrings permit the establishment of closure properties. SafeStringsharness the subtyping and inheritance mechanics of their host language to create a natural hierarchy of string subtypes. SafeStrings define an elegant programming model over strings: the front end use of a SafeString is clear and uncluttered, with complexity confined inside the definition of a particular SafeString. They are lightweight, language-agnostic and deployable, as we demonstrate by implementing SafeStrings in TypeScript. SafeStrings reduce the surface area for cross-site scripting, argument selection defects, and they can facilitate fuzzing and analysis.", "num_citations": "1\n", "authors": ["1721"]}
{"title": "McFly: Time-Travel Debugging for the Web\n", "abstract": " Time-traveling debuggers offer the promise of simplifying debugging by letting developers freely step forwards and backwards through a program's execution. However, web applications present multiple challenges that make time-travel debugging especially difficult. A time-traveling debugger for web applications must accurately reproduce all network interactions, asynchronous events, and visual states observed during the original execution, both while stepping forwards and backwards. This must all be done in the context of a complex and highly multithreaded browser runtime. At the same time, to be practical, a time-traveling debugger must maintain interactive speeds. This paper presents McFly, the first time-traveling debugger for web applications. McFly departs from previous approaches by operating on a high-level representation of the browser's internal state. This approach lets McFly provide accurate time-travel debugging - maintaining JavaScript and visual state in sync at all times - at interactive speeds. McFly's architecture is browser-agnostic, building on web standards supported by all major browsers. We have implemented McFly as an extension to the Microsoft Edge web browser, and core parts of McFly have been integrated into a time-traveling debugger product from Microsoft.", "num_citations": "1\n", "authors": ["1721"]}
{"title": "Call-site heuristics for scalable context-sensitive interprocedural analysis\n", "abstract": " When analyzing a program via an abstract interpretation (dataflow analysis) framework we would like to examine the program in a context-sensitive interprocedural manner. Analyzing the entire program in a manner that precisely considers interprocedural flow can lead to much more accurate results than local or context insensitive analyses (particularly for heap based analyses such as shape analysis). However, the computational cost (both time and memory consumption) associated with context-sensitive interprocedural analysis techniques makes them infeasible for all but very small programs or simple domains.This paper presents several novel heuristics based on exploiting structure in the program that is fundamental to the design and implementation of object-oriented programs (pre/post conditions for method calls). We also define a hybrid call-context technique that precisely captures call-context information that is central to the final result of the analysis while efficiently eliminating callcontext information that is merely an artifact of the iterative fixpoint process. We present both theoretical justification, based on fundamental properties of software design and the semantics of iterative dataflow analysis, and experimental justification, which shows both excellent scalability and high precision, for the effectiveness of these techniques.", "num_citations": "1\n", "authors": ["1721"]}