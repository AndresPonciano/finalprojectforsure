{"title": "Defence standard 00-56 issue 4: Towards evidence-based safety standards\n", "abstract": " Defence Standard 00-56 Issue 4 is goal-based, and requires system developers to demonstrate how they have achieved safety. To this end, evidence is used to support claims relating to software safety. One of the most subtle questions when constructing a safety argument is the determination of whether the evidence presented is sufficient to assure the safety of the system to the level required. This paper presents a framework for assessing the assurance of evidence and claims. We also present a vocabulary for discussing factors which influence assurance. This framework and vocabulary together enable us to construct and discuss safety arguments for software. Using this framework and vocabulary, we present some sample discussions which demonstrate how the factors influencing assurance can interact.", "num_citations": "37\n", "authors": ["1487"]}
{"title": "Defining a formal coalgebraic semantics for the rosetta specification language\n", "abstract": " Rosetta is a systems level design language that allows algebraic specification of systems through facets. The usual approach to formally describe a specification is to define an algebra that satisfies the specification. Although it is possible to formally describe Rosetta facets with the use of algebras, we choose to use the dual of algebra, ie coalgebra, to do so. Coalgebras are particularly suited for describing statebased systems. This makes formally defining state-based Rosetta quite straightforward. For non-state-based Rosetta, the formalization is not as direct, but can still be done with coalgebras by focusing on the behaviors of systems specified. We use denotational semantics to map Rosetta syntactic constructs into a language understood by the coalgebras.", "num_citations": "10\n", "authors": ["1487"]}
{"title": "Interpreting ALARP\n", "abstract": " This paper explores some of the common difficulties in interpreting the ALARP principle, and traces the potential effects of these difficulties on system risk. We introduce two categories of risk reduction approach which permit us to characterise the risk profile of a system in more detail and discuss their application to Systems of Systems (SoS).", "num_citations": "9\n", "authors": ["1487"]}
{"title": "Eliciting software safety requirements in complex systems\n", "abstract": " We present a discussion of the issues involved with eliciting and managing safety requirements in complex systems. We show how safety case architectures present a modular view of a safety case which is consistent with the modular structure of a system of systems. These architectures can also be used to allocate responsibility for safety analysis across contractual boundaries. This paper discusses how these architectures can be used to address the technical and engineering management challenges associated with safety analysis in complex systems.", "num_citations": "7\n", "authors": ["1487"]}
{"title": "Issues and considerations for a modular safety certification approach in a Service-Oriented Architecture\n", "abstract": " Service Oriented Architecture is an architectural style that is being adopted by many of the major military organisations such as the United States Department of Defense, The North Alliance Treaty Organization and the UK's Ministry of Defence, as a means to realise increased agility and reduced long term cost of ownership. SOA has emerged and matured predominately within the commercial sectors and as well as maturing further to overcome current challenges in these sectors, must address specific challenges when employed in a military context. This paper provides an introduction to the topic and identifies the issues and a potential methodology by which safety arguments can be constructed, based on experience from the military aviation domain. This is proposed as a means to support the flexible compositional characteristics of SOA whilst facilitating the Safety Certification and Accreditation of SOA-style\u00a0\u2026", "num_citations": "6\n", "authors": ["1487"]}
{"title": "A Safety-Case Approach to Ethical Considerations for Autonomous Vehicles\n", "abstract": " Ethical considerations for autonomous vehicles (AVs) go beyond the \u201ctrolley problem\u201d to include such aspects as risk/benefit trade-offs, informed consent, risk responsibility and risk mitigation within a system of systems. In this paper we present a methodology for arguing that the behaviour of a given AV meets desired ethical characteristics. We identify some of the ethical imperatives surrounding the introduction of AVs and consider how decisions made during development can impact the ethics of the AV's behaviour.", "num_citations": "5\n", "authors": ["1487"]}
{"title": "Managing safety requirements across supply chains\n", "abstract": " This paper presents a discussion of some of the common issues encountered when attempting to express software safety requirements across complex supply chains. Many of these issues originate from un-stated expectations or unjustified assumptions on the part of the varied stakeholders, primarily relating to the expected stakeholder relationships and communication. We present a taxonomy of archetypal problems which can arise from the presence of such assumptions, and discuss how these might be addressed. (6 pages)", "num_citations": "5\n", "authors": ["1487"]}
{"title": "Towards a semantic basis for Rosetta\n", "abstract": " Rosetta is a specification language for designing hardware and software systems with a view to being able to consider multiple system perspectives concurrently (such as functional correctness, performance constraints, and physical constraints). It also provides the capability to integrate components from heterogeneous domains, such as software and reconfigurable systems and digital and analog hardware.This paper explores a semantic framework for Rosetta in terms of category theory. We outline how a specification can be equated with a theory, and the different components which satisfy a specification can be equated with the algebras which satisfy this theory. From this, we define a category consisting of all legal specifications in a given language, and then show how the notions of extension and interaction of specifications can be modelled by means of colimits within this category. This requires a consideration of the different notions of equivalence of specifications, including behavioural equivalence, axiom abstraction and signature abstraction. Finally, we briefly outline how information hiding might be included in the construction of objects within the category of theories.", "num_citations": "5\n", "authors": ["1487"]}
{"title": "How a Robot\u2019s Social Credibility Affects Safety Performance\n", "abstract": " This paper connects the two domains of Human-Robot Interaction (HRI) and safety engineering to ensure that the design of interactive robots considers the effect of social behaviours on safety functionality. We conducted a preliminary user study with a social robot that alerts participants during a puzzle-solving task to a safety hazard. Our study findings show an indicative trend where users who were interrupted by a socially credible robot were more likely to act to mitigate the hazard than users interrupted by a robot lacking social credibility.", "num_citations": "4\n", "authors": ["1487"]}
{"title": "Ethics and the safety of autonomous systems\n", "abstract": " The ethical landscape surrounding the introduction of autonomous vehicles is complex, and there are real concerns over whether the operational safety of these systems can be adequately demonstrated. In this paper we focus on the ethical factors relevant to the design and safety justification of autonomous systems, considering issues such as risk transfer, ALARP considerations, capability vs risk trade-offs and emergent behaviours. We look beyond the \"trolley problem\u201d to consider how design decisions can reflect a wider ethical framework. We also look at the wider landscape around the emergence of autonomous systems, with a particular focus on the driving social factors which encourage early adoption of new technologies in this domain. We present some arguments for encouraging an explicit discussion of social and ethical factors within the safety framework for autonomous systems.", "num_citations": "4\n", "authors": ["1487"]}
{"title": "Goal-based safety standards and COTS software selection\n", "abstract": " In this paper we examine some of the challenges associated with adequately demonstrating the safety of COTS products as required by goal-based safety standards. The safety evidence available for COTS products - if any - is sometimes of questionable quality and applicability. This paper introduces a framework for assessing the applicability of the available evidence when selecting a COTS product for purchase. Use of this framework enables the purchase of a particular COTS product to be justified from a safety perspective, as well as identifying where further post-purchase analysis of the software will be required to support a safety argument.", "num_citations": "4\n", "authors": ["1487"]}
{"title": "A safety-case approach to the ethics of autonomous vehicles\n", "abstract": " Autonomous Vehicles (AVs) have significant ethical and safety implications. Questions of informed consent and risk acceptance are of primary importance, as is an explicit identification of the ethical principles underlying these decisions. In this paper we present a process framework for producing an ethics assurance case, which can be used to translate ethical imperatives into design decisions and safety management practices. The process and resultant assurance case integrate ethical considerations into the wider engineering lifecycle, providing a tool to demonstrate that design and safety management decisions reflect an identified ethical position.", "num_citations": "3\n", "authors": ["1487"]}
{"title": "Safety assurance objectives for autonomous systems\n", "abstract": " Safety Assurance Objectives for Autonomous Systems Page 1 This is a repository copy of Safety Assurance Objectives for Autonomous Systems. White Rose Research Online URL for this paper: http://eprints.whiterose.ac.uk/157598/ Version: Published Version Book: Alexander, Rob orcid.org/0000-0003-3818-0310, Asgari, Hamid, Ashmore, Rob et al. (15 more authors) (2020) Safety Assurance Objectives for Autonomous Systems. Safety Critical Systems Club , (112pp). eprints@whiterose.ac.uk https://eprints.whiterose.ac.uk/ Reuse This article is distributed under the terms of the Creative Commons Attribution (CC BY) licence. This licence allows you to distribute, remix, tweak, and build upon the work, even commercially, as long as you credit the authors for the original work. More information and the full terms of the licence here: https://creativecommons.org/licenses/ Takedown If you consider content in White Rose \u2026", "num_citations": "2\n", "authors": ["1487"]}
{"title": "An Overview of the SoBP for Software in the Context of DS 00-56 Issue 4\n", "abstract": " Defence Standard 00-56 Issue 4 is the current contractual safety standard for UK MOD projects. It requires the production of a structured argument, supported by diverse evidence, to show that a system is safe for a defined purpose within a defined environment. This paper introduces a Standard of Best Practice which has been produced by the Software Systems Engineering Initiative to provide guidance for software compliance with Defence Standard 00-56 Issue 4.", "num_citations": "2\n", "authors": ["1487"]}
{"title": "Inconsistency management and view updates\n", "abstract": " Inconsistency management in component-based languages is the identification and resolution of conflicting constraints or expectations between the different components which make up a system. Here we present a category theoretical framework for detecting and classifying those inconsistencies which can arise throughout a simulation. In addition, the framework permits us to apply techniques developed for defining database view updates. With these, we can analyse the set of traces of a system with respect to a particular behaviour in a subsystem.", "num_citations": "2\n", "authors": ["1487"]}
{"title": "Analysis and Implementation of Threat Agents Profiles in Semi-Automated Manner for a Network Traffic in Real-Time Information Environment\n", "abstract": " Threat assessment is the continuous process of monitoring the threats identified in the network of the real-time informational environment of an organisation and the business of the companies. The sagacity and security assurance for the system of an organisation and company\u2019s business seem to need that information security exercise to unambiguously and effectively handle the threat agent\u2019s attacks. How is this unambiguous and effective way in the present-day state of information security practice working? Given the prevalence of threats in the modern information environment, it is essential to guarantee the security of national information infrastructure. However, the existing models and methodology are not addressing the attributes of threats like motivation, opportunity, and capability (C, M, O), and the critical threat intelligence (CTI) feed to the threat agents during the penetration process is ineffective, due to which security assurance arises for an organisation and the business of companies. This paper proposes a semi-automatic information security model, which can deal with situational awareness data, strategies prevailing information security activities, and protocols monitoring specific types of the network next to the real-time information environment. This paper looks over analyses and implements the threat assessment of network traffic in one particular real-time informational environment. To achieve this, we determined various unique attributes of threat agents from the Packet Capture Application Programming Interface (PCAP files/DataStream) collected from the network between the years 2012 and 2019. We used hypothetical and real\u00a0\u2026", "num_citations": "1\n", "authors": ["1487"]}
{"title": "Does A Loss of Social Credibility Impact Robot Safety?\n", "abstract": " This position paper discusses the safety-related functions performed by assistive robots and explores the relationship between trust and effective safety risk mitigation. We identify a measure of the robot\u2019s social effectiveness, termed social credibility, and present a discussion of how social credibility may be gained and lost. This paper\u2019s contribution is the identification of a link between social credibility and safety-related performance. Accordingly, we draw on analyses of existing systems to demonstrate how an assistive robot\u2019s safety-critical functionality can be impaired by a loss of social credibility. In addition, we present a discussion of some of the consequences of prioritising either safety-related functionality or social engagement. We propose the identification of a mixed-criticality scheduling algorithm in order to maximise both safety-related performance and social engagement.", "num_citations": "1\n", "authors": ["1487"]}