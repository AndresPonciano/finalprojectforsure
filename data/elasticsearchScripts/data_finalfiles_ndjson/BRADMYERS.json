{"title": "Past, present, and future of user interface software tools\n", "abstract": " A user interface software tool helps developers design and implement the user interface. Research on past tools has had enormous impact on today's developers\u0393\u00c7\u00f6virtually all applications today are built using some form of user interface tool. In this article, we consider cases of both success and failure in past user interface tools. From these cases we extract a set of themes which can serve as lessons for future work. Using these themes, past tools can be characterized by what aspects of the user interface they addressed, their threshold and ceiling, what path of least resistance they offer, how predictable they are to use, and whether they addressed a target that became irrelevant. We believe the lessons of these past themes are particularly important now, because increasingly  rapid technological changes are likely to significantly change user interfaces. We are at the dawn of an era where user interfaces are about\u252c\u00e1\u0393\u00c7\u00aa", "num_citations": "1013\n", "authors": ["25"]}
{"title": "A brief history of human-computer interaction technology\n", "abstract": " Figure 1 shows the time span for some of the technologies discussed in this article. including when they were introduced. Of course, a deeper analysis would reveal significant interaction among the university, corporate research, and commercial activity lines. It is important to appreciate that years of research are involved in creating and making these technologies ready for widespread use. The same will be true for the HCI technologies currently being developed that will provide the interfaces of tomorrow. Clearly it is impossible to list every system and source in a paper of this scope, but I have tried to represent the earliest and most influential systems. Further information can be found in other surveys of HCI topics (see, for example,[1, 11, 36, 41]). Another useful resource is the video All The Widgets, which shows the historical progression of a number of user interface ideas [27]. The technologies discussed in this\u252c\u00e1\u0393\u00c7\u00aa", "num_citations": "881\n", "authors": ["25"]}
{"title": "A study in two-handed input\n", "abstract": " Two experiments were run to investigate two-handed input. The experimental tasks were representative of those found in CAD and office information systems. Experiment one involved the performance of a compound selection/positioning task. The two sub-tasks were performed by different hands using separate transducers. Without prompting, novice subjects adopted strategies that involved performing the two sub-tasks simultaneously. We interpret this as a demonstration that, in the appropriate context, users are capable of simultaneously providing continuous data from two hands without significant overhead. The results also show that the speed of performing the task was strongly correlated to the degree of parallelism employed. Experiment two involved the performance of a compound navigation/selection task. It compared a one-handed versus two-handed method for finding and selecting words in a document\u252c\u00e1\u0393\u00c7\u00aa", "num_citations": "786\n", "authors": ["25"]}
{"title": "Taxonomies of visual programming and program visualization\n", "abstract": " There has been great interest recently in systems that use graphics to aid in the programming, debugging, and understanding of computer systems. The terms \u0393\u00c7\u00ffVisual Programming\u0393\u00c7\u00d6 and \u0393\u00c7\u00ffProgram Visualization\u0393\u00c7\u00d6 have been applied to these systems. This paper attempts to provide more meaning to these terms by giving precise definitions, and then surveys a number of systems that can be classified as providing Visual Programming or Program Visualization. These systems are organized by classifying them into three different taxonomies.", "num_citations": "731\n", "authors": ["25"]}
{"title": "Survey on user interface programming\n", "abstract": " This paper reports on the results of a survey of user interface programming. The survey was widely distributed, and we received 74 responses. The results show that in today's applications, an average of 48% of the code is devoted to the user interface portion. The average time spent on the user interface portion is 45% during the design phase, 50% during the implementation phase, and 37% during the maintenance phase. 34% of the systems were implemented using a toolkit, 27% used a UIMS, 14% used an interface builder, and 26% used no tools. This appears to be because the toolkit systems had more sophisticated user interfaces. The projects using UIMSs or interface builders spent the least percent of time and code on the user interface (around 41%) suggesting that these tools are effective. In general, people were happy with the tools they used, especially the graphical interface builders. The most common\u252c\u00e1\u0393\u00c7\u00aa", "num_citations": "690\n", "authors": ["25"]}
{"title": "An exploratory study of how developers seek, relate, and collect relevant information during software maintenance tasks\n", "abstract": " Much of software developers' time is spent understanding unfamiliar code. To better understand how developers gain this understanding and how software development environments might be involved, a study was performed in which developers were given an unfamiliar program and asked to work on two debugging tasks and three enhancement tasks for 70 minutes. The study found that developers interleaved three activities. They began by searching for relevant code both manually and using search tools; however, they based their searches on limited and misrepresentative cues in the code, environment, and executing program, often leading to failed searches. When developers found relevant code, they followed its incoming and outgoing dependencies, often returning to it and navigating its other dependencies; while doing so, however, Eclipse's navigational tools caused significant overhead. Developers\u252c\u00e1\u0393\u00c7\u00aa", "num_citations": "685\n", "authors": ["25"]}
{"title": "Sketching interfaces: Toward more human interface design\n", "abstract": " Researchers at University of California, Berkeley and Carnegie Mellon University have designed, implemented, and evaluated SILK (Sketching Interfaces Like Krazy), an informal sketching tool that combines many of the benefits of paper-based sketching with the merits of current electronic tools. With SILK, designers can quickly sketch an interface using an electronic pad and stylus, and SILK recognizes widgets and other interface elements as the designer draws them. Unlike paper-based sketching, however, designers can exercise these elements in their sketchy state. For example, a sketched scroll-bar is likely to contain an elevator or thumbnail, the small rectangle a user drags with a mouse. In a paper sketch, the elevator would just sit there, but in a SILK sketch, designers can drag it up and down, which lets them test component or widget behavior. SILK also supports the creation of storyboards-the arrangement\u252c\u00e1\u0393\u00c7\u00aa", "num_citations": "674\n", "authors": ["25"]}
{"title": "GARNET comprehensive support for graphical, highly interactive user interfaces\n", "abstract": " Publisher SummaryThis chapter presents an overview of Garnet research project which attempts to create a comprehensive support for graphical, highly interactive user interfaces. User interface software is difficult and expensive to implement. Highly interactive interfaces are among the hardest to create, because they must handle at least two asynchronous input devices, real time feedback, multiple windows, and elaborate dynamic graphics. The Garnet research project is creating a set of tools to aid the design and implementation of highly interactive, graphical, direct manipulation user interfaces. Garnet also helps designers rapidly prototype different interfaces and explore various user interface metaphors during early product design. A number of features differentiate Garnet from other user interface tools, including an emphasis on handling objects' runtime behavior and on handling all visual aspects of a program\u252c\u00e1\u0393\u00c7\u00aa", "num_citations": "664\n", "authors": ["25"]}
{"title": "Interactive sketching for the early stages of user interface design\n", "abstract": " Current interactive user interface construction tools are often more of a hindrance than a benefit during the early stages of user interface design. These tools take too much time to use and force designers to specify more of the design details than they wish at this early stage. Most interface designers, especially those who have a background in graphic design, prefer to sketch early interface ideas on paper or on a whiteboard. We are developing an interactive tool called SILK that allows designers to quickly sketch an interface using an electronic pad and stylus. SILK preserves the important properties of pencil and paper: a rough drawing can be produced very quickly and the medium is very flexible. However, unlike a paper sketch, this electronic sketch is interactive and can easily be modified. In addition, our system allows designers to examine, annotate, and edit a complete history of the design. When the designer\u252c\u00e1\u0393\u00c7\u00aa", "num_citations": "651\n", "authors": ["25"]}
{"title": "Collaboration using multiple PDAs connected to a PC\n", "abstract": " The Pebbles project is creating applications to connmt multiple Personal DigiM Assistants &DAs) to a main computer such as a PC We are cmenfly using 3Com Pd@ Ilots b-use they are popdar and widespread. We created the \u0393\u00c7\u00ffRemote Comrnandefl application to dow users to take turns sending input from their PahnPiiots to the PC as if they were using the PCS mouse and keyboard.\u0393\u00c7\u00ff. PebblesDraw\u0393\u00c7\u00a5 is a shared whiteboard application we btit that allows dl of tie users to send input simtdtaneously while sharing the same PC display. We are investigating the use of these applications in various contexts, such as colocated mmtings.", "num_citations": "514\n", "authors": ["25"]}
{"title": "Six learning barriers in end-user programming systems\n", "abstract": " As programming skills increase in demand and utility, the learnability of end-user programming systems is of utmost importance. However, research on learning barriers in programming systems has primarily focused on languages, overlooking potential barriers in the environment and accompanying libraries. To address this, a study of beginning programmers learning Visual Basic.NET was performed. This identified six types of barriers: design, selection, coordination, use, understanding, and information. These barriers inspire a new metaphor of computation, which provides a more learner-centric view of programming system design", "num_citations": "511\n", "authors": ["25"]}
{"title": "User interface software tools\n", "abstract": " Almost as long as there have been user interfaces, there have been special software systems and tools to help design and implement the user interface software. Many of these tools have demonstrated significant productivity gains for programmers, and have become important commercial products. Others have proven less successful at supporting the kinds of user interfaces people want to build. This article discusses the different kinds of user interface software tools, and investigates why some approaches have worked and others have not. Many examples of commercial and research systems are included. Finally, current research directions and open issues in the field are discussed.", "num_citations": "503\n", "authors": ["25"]}
{"title": "Visual programming, programming by example, and program visualization: a taxonomy\n", "abstract": " There has been a great interest recently in systems that use graphics to aid in the programming, debugging, and understanding of computer programs. The terms \u0393\u00c7\u00a3Visual Programming\u0393\u00c7\u00a5 and \u0393\u00c7\u00a3Program Visualization\u0393\u00c7\u00a5 have been applied to these systems. Also, there has been a renewed interest in using examples to help alleviate the complexity of programming. This technique is called \u0393\u00c7\u00a3Programming by Example.\u0393\u00c7\u00a5 This paper attempts to provide more meaning to these terms by giving precise definitions, and then uses these definitions to classify existing systems into a taxonomy. A number of common unsolved problems with most of these systems are also listed.", "num_citations": "479\n", "authors": ["25"]}
{"title": "Estimating the numbers of end users and end user programmers\n", "abstract": " In 1995, Boehm predicted that by 2005, there would be \"55 million performers\" of \"end user programming\" in the United States. The original context and method which generated this number had two weaknesses, both of which we address. First, it relies on undocumented, judgment-based factors to estimate the number of end user programmers based on the total number of end users; we address this weakness by identifying specific end user sub-populations and then estimating their sizes. Second, Boehm's estimate relies on additional undocumented, judgment-based factors to adjust for rising computer usage rates; we address this weakness by integrating fresh Bureau of Labor Statistics (BLS) data and projections as well as a richer estimation method. With these improvements to Boehm's method, we estimate that in 2012 there will be 90 million end users in American workplaces. Of these, we anticipate that over\u252c\u00e1\u0393\u00c7\u00aa", "num_citations": "457\n", "authors": ["25"]}
{"title": "EdgeWrite: a stylus-based text entry method designed for high accuracy and stability of motion\n", "abstract": " EdgeWrite is a new unistroke text entry method for handheld devices designed to provide high accuracy and stability of motion for people with motor impairments. It is also effective for able-bodied people. An EdgeWrite user enters text by traversing the edges and diagonals of a square hole imposed over the usual text input area. Gesture recognition is accomplished not through pattern recognition but through the sequence of corners that are hit. This means that the full stroke path is unimportant and recognition is highly deterministic, enabling better accuracy than other gestural alphabets such as Graffiti. A study of able-bodied users showed subjects with no prior experience were 18% more accurate during text entry with Edge Write than with Graffiti (p>. 05), with no significant difference in speed. A study of 4 subjects with motor impairments revealed that some of them were unable to do Graffiti, but all of them could\u252c\u00e1\u0393\u00c7\u00aa", "num_citations": "408\n", "authors": ["25"]}
{"title": "Designing the whyline: a debugging interface for asking questions about program behavior\n", "abstract": " Debugging is still among the most common and costly of programming activities. One reason is that current debugging tools do not directly support the inquisitive nature of the activity. Interrogative Debugging is a new debugging paradigm in which programmers can ask why did and even why didn't questions directly about their program's runtime failures. The Whyline is a prototype Interrogative Debugging interface for the Alice programming environment that visualizes answers in terms of runtime events directly relevant to a programmer's question. Comparisons of identical debugging scenarios from user tests with and without the Whyline showed that the Whyline reduced debugging time by nearly a factor of 8, and helped programmers complete 40% more tasks.", "num_citations": "395\n", "authors": ["25"]}
{"title": "Generating remote control interfaces for complex appliances\n", "abstract": " The personal universal controller (PUC) is an approach for improving the interfaces to complex appliances by introducing an intermediary graphical or speech interface. A PUC engages in two-way communication with everyday appliances, first downloading a specification of the appliance's functions, and then automatically creating an interface for controlling that appliance. The specification of each appliance includes a high-level description of every function, a hierarchical grouping of those functions, and dependency information, which relates the availability of each function to the appliance's state. Dependency information makes it easier for designers to create specifications and helps the automatic interface generators produce a higher quality result. We describe the architecture that supports the PUC, and the interface generators that use our specification language to build high-quality graphical and speech\u252c\u00e1\u0393\u00c7\u00aa", "num_citations": "390\n", "authors": ["25"]}
{"title": "Creating user interfaces by demonstration\n", "abstract": " Peridot is a new experimental tool for creating visual user interfaces without programming. The interface designer draws the screen that the user will see, performs sample user actions, and gives examples of typical values. Peridot infers how the constructed parts will interact, checks these inferences with the designer to be sure they are valid, and produces parametrized procedures that can be called from application programs. The program is implemented in Interlisp-D on a Xerox 1109, and Myers has used it to duplicate many of the interaction techniques found in the Macintosh Toolbox. The work, as documented in this outstanding book, makes major research contributions to the evolving area of user interface management systems (UIMSs). Though based on doctoral work done over several years at the University of Toronto, this book provides depth of insight, quality of design, and explanatory value far beyond\u252c\u00e1\u0393\u00c7\u00aa", "num_citations": "365\n", "authors": ["25"]}
{"title": "Using handhelds and PCs together\n", "abstract": " THE AGE OF UBIqUITOUS AND NOMADIC COMPUTING is at hand, with computing devices reflecting a spectrum of shapes and sizes being used in offices, homes, classrooms, even in our pockets. Many environments contain embedded computers and data projectors, including offices, meeting rooms, classrooms [1], and homes. One relatively unstudied aspect of these environments is how personal handheld computers interoperate with desktop and built-in computers seamlessly in real time. More and more people carry around programmable computers in the form of personal digital assistants (PDAs), including PalmOS organizers and Pocket PCs (also called Windows CE devices). Mobile phones and even watches also increasingly participate in our computing and information environments. In a project called Pebbles, or PDAs for Entry of Both Bytes and Locations from External Sources, begun in 1997 at\u252c\u00e1\u0393\u00c7\u00aa", "num_citations": "360\n", "authors": ["25"]}
{"title": "Computer science handbook\n", "abstract": " When you think about how far and fast computer science has progressed in recent years, it's not hard to conclude that a seven-year old handbook may fall a little short of the kind of reference today's computer scientists, software engineers, and IT professionals need. With a broadened scope, more emphasis on applied computing, and more than 70 chap", "num_citations": "354\n", "authors": ["25"]}
{"title": "Maximizing the guessability of symbolic input\n", "abstract": " Guessability is essential for symbolic input, in which users enter gestures or keywords to indicate characters or commands, or rely on labels or icons to access features. We present a unified approach to both maximizing and evaluating the guessability of symbolic input. This approach can be used by anyone wishing to design a symbol set with high guessability, or to evaluate the guessability of an existing symbol set. We also present formulae for quantifying guessability and agreement among guesses. An example is offered in which the guessability of the EdgeWrite unistroke alphabet was improved by users from 51.0% to 80.1% without designer intervention. The original and improved alphabets were then tested for their immediate usability with the procedure used by MacKenzie and Zhang (1997). Users entered the original alphabet with 78.8% and 90.2% accuracy after 1 and 5 minutes of learning, respectively\u252c\u00e1\u0393\u00c7\u00aa", "num_citations": "348\n", "authors": ["25"]}
{"title": "Studying the language and structure in non-programmers' solutions to programming problems\n", "abstract": " Programming may be more difficult than necessary because it requires solutions to be expressed in ways that are not familiar or natural for beginners. To identify what is natural, this article examines the ways that non-programmers express solutions to problems that were chosen to be representative of common programming tasks. The vocabulary and structure in these solutions is compared with the vocabulary and structure in modern programming languages, to identify the features and paradigms that seem to match these natural tendencies as well as those that do not. This information can be used by the designers of future programming languages to guide the selection and generation of language features. This design technique can result in languages that are easier to learn and use, because the languages will better match beginners' existing problem-solving abilities.", "num_citations": "343\n", "authors": ["25"]}
{"title": "User-interface tools: Introduction and survey\n", "abstract": " An overview is given of user-interface development systems (UIDS). Systems are classified by how they let the programmer specify the interfaces, and examples of each type are given. The three types are language-based, graphical, and automatic creation interfaces. Shortcomings of UIDS and user-interface toolkits are discussed.< >", "num_citations": "340\n", "authors": ["25"]}
{"title": "Debugging reinvented\n", "abstract": " When software developers want to understand the reason for a program's behavior, they must translate their questions about the behavior into a series of questions about code, speculating about the causes in the process. The Whyline is a new kind of debugging tool that avoids such speculation by instead enabling developers to select a question about program output from a set of why did and why didn't questions derived from the program's code and execution. The tool then finds one or more possible explanations for the output in question, using a combination of static and dynamic slicing, precise call graphs, and new algorithms for determining potential sources of values and explanations for why a line of code was not reached. Evaluations of the tool on one task showed that novice programmers with the Whyline were twice as fast as expert programmers without it. The tool has the potential to simplify debugging\u252c\u00e1\u0393\u00c7\u00aa", "num_citations": "327\n", "authors": ["25"]}
{"title": "Creativity support tools: Report from a US National Science Foundation sponsored workshop\n", "abstract": " Creativity support tools is a research topic with high risk but potentially very high payoff. The goal is to develop improved software and user interfaces that empower users to be not only more productive but also more innovative. Potential users include software and other engineers, diverse scientists, product and graphic designers, architects, educators, students, and many others. Enhanced interfaces could enable more effective searching of intellectual resources, improved collaboration among teams, and more rapid discovery processes. These advanced interfaces should also provide potent support in hypothesis formation, speedier evaluation of alternatives, improved understanding through visualization, and better dissemination of results. For creative endeavors that require composition of novel artifacts (e.g., computer programs, scientific papers, engineering diagrams, symphonies, artwork), enhanced interfaces\u252c\u00e1\u0393\u00c7\u00aa", "num_citations": "286\n", "authors": ["25"]}
{"title": "Strategic directions in human-computer interaction\n", "abstract": " Human-computer interaction (HCI) is the study of how people design, implement, and use interactive computer systems and how computers affect individuals, organizations, and society. This encompasses not only ease of use but also new interaction techniques for supporting user tasks, providing better access to information, and creating more powerful forms of communication. It involves input and output devices and the interaction techniques that use them; how information is presented and requested; how the computer\u0393\u00c7\u00d6s actions are controlled and monitored; all forms of help, documentation, and training; the tools used to design, build, test, and evaluate user interfaces; and the processes that developers follow when creating interfaces.", "num_citations": "286\n", "authors": ["25"]}
{"title": "Mica: A web-search tool for finding api components and examples\n", "abstract": " Because software libraries are numerous and large, learning how to use them is a common and problematic task for experienced programmers and novices alike. Internet search engines such as Google have emerged as important resources to help programmers successfully use APIs. However, observations of programmers using Web search have revealed problems and inefficiencies in their use. We present a new prototype search tool called Mica that augments standard Web search results to help programmers find the right API classes and methods given a description of the desired functionality, and help programmers find examples when they already know which methods to use. Mica works by using the Google Web APIs to find relevant pages, and then analyzing the content of those pages to extract the most relevant programming terms and to classify the type of each result", "num_citations": "267\n", "authors": ["25"]}
{"title": "The importance of percent-done progress indicators for computer-human interfaces\n", "abstract": " A \u0393\u00c7\u00a3percent-done progress indicator\u0393\u00c7\u00a5 is a graphical technique which allows the user to monitor the progress through the processing of a task. Progress indicators can be displayed on almost all types of output devices, and can be used with many different kinds of programs. Practical experience and formal experiments show that prograss indicators are an important and useful user-interface tool, and that they enhance the attractiveness and effectiveness of programs that incorporate them. This paper discusses why progress indicators are important. It includes the results of a formal experiment with progress indicators. One part of the experiment demonstrates that people prefer to have progress indicators. Another part attempted to replicate earlier findings to show that people prefer constant to variable response time in general, and then to show that this effect is reversed with progress indicators, but the results were not\u252c\u00e1\u0393\u00c7\u00aa", "num_citations": "265\n", "authors": ["25"]}
{"title": "Design principles for tools to support creative thinking\n", "abstract": " We have developed a set of \u0393\u00c7\u00a3design principles\u0393\u00c7\u00a5 to guide the development of new creativity support tools\u0393\u00c7\u00f4that is, tools that enable people to express themselves creatively and to develop as creative thinkers. Our goal is to develop improved software and user interfaces that empower users to be not only more productive, but more innovative. Potential users of these interfaces include software and other engineers, diverse scientists, product and graphic designers, architects, educators, students, and many others. Enhanced interfaces could enable more effective searching of intellectual resources, improved collaboration among teams, and more rapid discovery processes. These advanced interfaces should also provide potent support in hypothesis formation, speedier evaluation of alternatives, improved understanding through visualization, and better dissemination of results. For creative endeavors that require composition of novel artifacts (eg, computer programs, scientific papers, engineering diagrams, symphonies, artwork), enhanced interfaces could facilitate exploration of alternatives, prevent unproductive choices, and enable easy backtracking.Some of these design principles have appeared previously [Myers 2000][Shneiderman 2000][Resnick 2005][Yamamoto 2005][Hewett 2005][Selker 2005]. These principles have emerged through collaborations with a large number of colleagues, in the development of many different creativity support tools, both for children and adults. Some of the principles are also relevant to tools for creating software in general, often called \u0393\u00c7\u00a3User Interface Software Tools,\u0393\u00c7\u00a5 but targeting tools specifically for creativity\u252c\u00e1\u0393\u00c7\u00aa", "num_citations": "258\n", "authors": ["25"]}
{"title": "Incense: A system for displaying data structures\n", "abstract": " Many modern computer languages allow the programmer to define and use a variety of data types. Few programming systems, however, allow the programmer similar flexibility when displaying the data structures for debugging, monitoring and documenting programs. Incense is a working prototype system that allows the programmer to interactively investigate data structures in actual programs. The desired displays can be specified by the programmer or a default can be used. The default displays provided by Incense present the standard form for literals of the basic types, the actual names for scalar types, stacked boxes for records and arrays, and curved lines with arrowheads for pointers. In addition to displaying data structures, Incense also allows the user to select, move, erase and redimension the resulting displays. These interactions are provided in a uniform, natural manner using a pointing device (mouse\u252c\u00e1\u0393\u00c7\u00aa", "num_citations": "258\n", "authors": ["25"]}
{"title": "Multimodal error correction for speech user interfaces\n", "abstract": " Although commercial dictation systems and speech-enabled telephone voice user interfaces have become readily available, speech recognition errors remain a serious problem in the design and implementation of speech user interfaces. Previous work hypothesized that switching modality could speed up interactive correction of recognition errors. This article presents multimodal error correction methods that allow the user to correct recognition errors efficiently without keyboard input. Correction accuracy is maximized by novel recognition algorithms that use context information for recognizing correction input. Multimodal error correction is evaluated in the context of a prototype multimodal dictation system. The study shows that unimodal repair is less accurate than multimodal error  correction. On a dictation task, multimodal correction is faster than unimodal correction by respeaking. The study also provides\u252c\u00e1\u0393\u00c7\u00aa", "num_citations": "244\n", "authors": ["25"]}
{"title": "A new model for handling input\n", "abstract": " Although there has been important progress in models and packages for the output of graphics to computer screens, there has been little change in the way that input from the mouse, keyboard, and other input devices is handled. New graphics standards are still using a fifteen-year-old model even though it is widely accepted as inadequate, and most modern window managers simply return a stream of low-level, device-dependent input events. This paper presents a new model that handles input devices for highly interactive, direct manipulation, graphical user interfaces, which could be used in future toolkits, window managers, and graphics standards. This model encapsulates interactive behaviors into a few \u0393\u00c7\u00a3Interactor\u0393\u00c7\u00a5 object types. Application  programs can then create instances of these Interactor objects which hide the details of the underlying window manager events. In addition, Interactors allow a clean\u252c\u00e1\u0393\u00c7\u00aa", "num_citations": "243\n", "authors": ["25"]}
{"title": "Eliciting design requirements for maintenance-oriented ides: a detailed study of corrective and perfective maintenance tasks\n", "abstract": " Recently, several innovative tools have found their way into mainstream use in modern development environments. However, most of these tools have focused on creating and modifying code, despite evidence that most of programmers' time is spent understanding code as part of maintenance tasks. If new tools were designed to directly support these maintenance tasks, what types would be most helpful? To find out, a study of expert Java programmers using Eclipse was performed. The study suggests that maintenance work consists of three activities:(1) forming a working set of task-relevant code fragments;(2) navigating the dependencies within this working set; and (3) repairing or creating the necessary code. The study identified several trends in these activities, as well as many opportunities for new tools that could save programmers up to 35% of the time they currently spend on maintenance tasks.", "num_citations": "242\n", "authors": ["25"]}
{"title": "Usability issues in the design of novice programming systems\n", "abstract": " This report reviews and organizes research about novice programmers. Over the past two decades, many aspects of novice programming have been investigated, resulting in the discovery of important facts and tradeoffs about what makes programming difficult to learn, and about the effectiveness of existing languages, environments, and methods of instruction. However, because this research is dispersed throughout the literature, it is difficult for designers of new programming systems to consider all of the issues collectively. The result is that most new systems are built primarily around technical objectives, perhaps considering only a subset of the usability issues summarized here. In addition to providing a checklist of issues that should be considered in the design of future systems, this report can be used to help researchers identify fruitful topics of future novice programming research.Descriptors:", "num_citations": "239\n", "authors": ["25"]}
{"title": "Natural programming languages and environments\n", "abstract": " Over the last six years, we have been working to create programming languages and environments that are more natural, or closer to the way people think about their tasks. Our goal is to make it possible for people to express their ideas in the same way they think about them. To achieve this, we have performed various studies about how people think about programming tasks, both when trying to create a new program and when trying to find and fix bugs in existing programs. We then use this knowledge to develop new tools for programming and debugging. Our user studies have shown the resulting systems provide significant benefits to users.", "num_citations": "234\n", "authors": ["25"]}
{"title": "User-centered design and interactive health technologies for patients\n", "abstract": " Despite recommendations that patients be involved in the design and testing of health technologies, few reports describe how to involve patients in systematic and meaningful ways to ensure that applications are customized to meet their needs. User-centered design (UCD) is an approach that involves end-users throughout the development process so that technology support tasks, are easy to operate, and are of value to users. In this paper we provide an overview of UCD and use the development of Pocket Personal Assistant for Tracking Health (Pocket PATH), to illustrate how these principles and techniques were applied to involve patients in the development of this interactive health technology. Involving patient-users in the design and testing ensured functionality and usability, therefore increasing the likelihood of promoting the intended health outcomes.", "num_citations": "233\n", "authors": ["25"]}
{"title": "Why do people tag? Motivations for photo tagging\n", "abstract": " Introduction Tagging, or using keywords to add metadata to shared content, is gaining much popularity in recent years. Tags are used to annotate various types of content, including images, videos, bookmarks, and blogs, through web-based systems such as Flickr, YouTube, del.icio.us, and Technorati, respectively. The popularity of tagging is attributed, at least in part, to the benefits users gain from effective sharing and from organization of very large amounts of information. As tagging receives increasing attention in both research and business communities, studies have found that users vary substantially in their tag usage, and suggested several factors that motivate user tagging. However, to date no quantitative study has assessed the strength of the effects of each motivation on levels of tag usage. This is surprising, since user participation is critical to the sustainability of content sharing communities, and a\u252c\u00e1\u0393\u00c7\u00aa", "num_citations": "221\n", "authors": ["25"]}
{"title": "The factory pattern in API design: A usability evaluation\n", "abstract": " The usability of software APIs is an important and infrequently researched topic. A user study comparing the usability of the factory pattern and constructors in API designs found highly significant results indicating that factories are detrimental to API usability in several varied situations. The results showed that users require significantly more time (p = 0.005) to construct an object with a factory than with a constructor while performing both context-sensitive and context- free tasks. These results suggest that the use of factories can and should be avoided in many cases where other techniques, such as constructors or class clusters, can be used instead.", "num_citations": "216\n", "authors": ["25"]}
{"title": "A framework and methodology for studying the causes of software errors in programming systems\n", "abstract": " An essential aspect of programmers\u0393\u00c7\u00d6 work is the correctness of their code. This makes current HCI techniques ill-suited to analyze and design the programming systems that programmers use everyday, since these techniques focus more on problems with learnability and efficiency of use, and less on error-proneness. We propose a framework and methodology that focuses specifically on errors by supporting the description and identification of the causes of software errors in terms of chains of cognitive breakdowns. The framework is based on both old and new studies of programming, as well as general research on the mechanisms of human error. Our experiences using the framework and methodology to study the Alice programming system have directly inspired the design of several new programming tools and interfaces. This includes the Whyline debugging interface, which we have shown to reduce debugging\u252c\u00e1\u0393\u00c7\u00aa", "num_citations": "204\n", "authors": ["25"]}
{"title": "A linguistic analysis of how people describe software problems\n", "abstract": " There is little understanding of how people describe software problems, but a variety of tools solicit, manage, and analyze these descriptions in order to streamline software development. To inform the design of these tools and generate ideas for new ones, an study of nearly 200,000 bug report titles was performed. The titles of the reports generally described a software entity or behavior, its inadequacy, and an execution context, suggesting new designs for more structured report forms. About 95% of noun phrases referred to visible software entities, physical devices, or user actions, suggesting the feasibility of allowing users to select these entities in debuggers and other tools. Also, the structure of the titles exhibited sufficient regularity to parse with an accuracy of 89%, enabling a number of new automated analyses. These findings and others have many implications for tool design and software engineering", "num_citations": "200\n", "authors": ["25"]}
{"title": "A taxonomy of window manager user interfaces\n", "abstract": " A taxonomy for the user-visible parts of window managers is presented. It is noted that there are actually very few significant differences, and the differences can be classified in a taxonomy with fairly limited branching. This taxonomy should be useful in evaluating various window managers, and it will also serve as a guide for the issues that need to be addressed by designers if future window-manager user interfaces. The advantages and disadvantages of the various options are presented.< >", "num_citations": "195\n", "authors": ["25"]}
{"title": "Creating highly-interactive and graphical user interfaces by demonstration\n", "abstract": " It is very time-consuming and expensive to create the graphical, highly-interactive styles of user interfaces that are increasingly common. User Interface Management Systems (UIMSs) attempt to make the creation of user interfaces easier, but most existing UIMSs cannot create the low-level interaction techniques (pop-up pull-down and fixed menus, on-screen \"light buttons\", scroll-bars, elaborate feedback mechanisms and animations, etc.) that are frequently used. This paper describes Peridot, a system that automatically creates the code for these user interfaces while the designer demonstrates to the system how the interface should look and work. Peridot uses rule-based inferencing so no programming by the designer is required, and Direct Manipulation techniques are used to create Direct Manipulation interfaces, which can make full use of a mouse and other input devices. This allows extremely rapid\u252c\u00e1\u0393\u00c7\u00aa", "num_citations": "184\n", "authors": ["25"]}
{"title": "Improving API usability\n", "abstract": " Human-centered design can make application programming interfaces easier for developers to use.", "num_citations": "181\n", "authors": ["25"]}
{"title": "Creating charts and visualizations by demonstration\n", "abstract": " A system and method to automatically produce a display chart from example graphics and data values. New or existing example graphics are drawn with a programmable data processing system, and the drawn graphical elements within the chart are identified. A data value is then associated with at least one of the graphical elements, and a list of heuristics are applied to determine the visualization characteristics for the graphical elements. The display chart is then produced incorporating the visualization characteristics for the graphical elements.", "num_citations": "181\n", "authors": ["25"]}
{"title": "Separating application code from toolkits: Eliminating the spaghetti of call-backs\n", "abstract": " Conventional toolkits today require the programmer to attach call-back procedures to most buttons, scroll bars, menu items, and other widgets in the interface. These procedures are called by the system when the user operates the widget in order to notify the application of the user\u0393\u00c7\u00d6s actions. Unfortunately, real interfaces contain hundreds or thousands of widgets, and therefore many call-back procedures, most of which perform trivial tasks, resulting in a maintenance nightmare. This paper describes a system that allows the majority of these procedures to be eliminated. The user interface designer can specify by demonstration many of the desired actions and connections among the widgets, so call-backs are only needed for the most significant application actions. In addition, the callbacks that remain are completely insulated from the widgets, so that the application code is better separated from the user interface.", "num_citations": "177\n", "authors": ["25"]}
{"title": "Using edges and corners for character input\n", "abstract": " BACKGROUNDThis invention relates to methods and systems for entering characters into a handheld or wearable computerized device, Such as a handheld computer also called a \u0393\u00c7\u00a3personal digital assistant, a cellphone, a watch, a computer game console, or the like.Text input is difficult on handheld and wearable comput erized devices. Handheld devices include cell phones, two way pagers, game console controllers, and\" Personal Digital Assistants\u0393\u00c7\u00a5(PDAs), including those made by Palm, Inc. and the devices which run Microsoft's WindowsCE operating system. In the future, we expect that wearable devices such as wristwatches and other small computerized devices will need good text entry methods. Today, PDAs and two-way pagers primarily use on-screen \u0393\u00c7\u00a3soft keyboards, handwriting rec ognition, tiny physical keyboards used with the thumbs, or special gestural alphabets such as Graffiti from Palm, Inc. or Jot\u252c\u00e1\u0393\u00c7\u00aa", "num_citations": "176\n", "authors": ["25"]}
{"title": "Why are human-computer interfaces difficult to design and implement\n", "abstract": " Everyone knows that designing and implementing human-computer interface is difficult and time-consuming. However, there is little discussion of why this is true. Should we expect that a new method is around the corner that will make the design easier Will the next generation of user interface toolkits make the implementation trivial No. This article discusses reasons why user interface design and implementation are inherently difficult tasks and will remain so for the foreseeable future.Descriptors:", "num_citations": "175\n", "authors": ["25"]}
{"title": "WebThumb: interaction techniques for small-screen browsers\n", "abstract": " The proliferation of wireless handheld devices is placing the World Wide Web in the palms of users, but this convenience comes at a high interactive cost. The Web that came of age on the desktop is ill-suited for use on the small displays of handhelds. Today, handheld browsing often feels like browsing on a PC with a shrunken desktop. Overreliance on scrolling is a big problem in current handheld browsing. Users confined to viewing a small portion of each page often lack a sense of the overall context---they may feel lost in a large page and be forced to remember the locations of items as those items scroll out of view. In this paper, we present a synthesis of interaction techniques to address these problems. We implemented these techniques in a prototype, WebThumb, that can browse the live Web.", "num_citations": "171\n", "authors": ["25"]}
{"title": "The performance of hand postures in front-and back-of-device interaction for mobile computing\n", "abstract": " Three studies of different mobile-device hand postures are presented. The first study measures the performance of postures in Fitts\u0393\u00c7\u00d6 law tasks using one and two hands, thumbs and index fingers, horizontal and vertical movements, and front- and back-of-device interaction. Results indicate that the index finger performs well on both the front and the back of the device, and that thumb performance on the front of the device is generally worse. Fitts\u0393\u00c7\u00d6 law models are created and serve as a basis for comparisons. The second study examines the orientation of shapes on the front and back of a mobile device. It shows that participants\u0393\u00c7\u00d6 expectations of visual feedback for finger movements on the back of a device reverse the direction of their finger movements to favor a \u0393\u00c7\u00a3transparent device\u0393\u00c7\u00a5 orientation. The third study examines letter-like gestures made on the front and back of a device. It confirms the performance of the index\u252c\u00e1\u0393\u00c7\u00aa", "num_citations": "168\n", "authors": ["25"]}
{"title": "Developers ask reachability questions\n", "abstract": " A reachability question is a search across feasible paths through a program for target statements matching search criteria. In three separate studies, we found that reachability questions are common and often time consuming to answer. In the first study, we observed 13 developers in the lab and found that half of the bugs developers inserted were associated with reachability questions. In the second study, 460 professional software developers reported asking questions that may be answered using reachability questions more than 9 times a day, and 82% rated one or more as at least somewhat hard to answer. In the third study, we observed 17 developers in the field and found that 9 of the 10 longest activities were associated with reachability questions. These findings suggest that answering reachability questions is an important source of difficulty understanding large, complex codebases.", "num_citations": "165\n", "authors": ["25"]}
{"title": "How designers design and program interactive behaviors\n", "abstract": " Designers are skilled at sketching and prototyping the look of interfaces, but to explore various behaviors (what the interface does in response to input) typically requires programming using Javascript, ActionScript for Flash, or other languages. In our survey of 259 designers, 86% reported that the behavior is more difficult to prototype than the appearance. Often (78% of the time), designing the behavior requires collaborating with developers, but 76% of designers reported that communicatin1g the behavior to developers was more difficult than the appearance. Other results include that annotations such as arrows and paragraphs of text are used on top of sketches and storyboards to explain behaviors, and designers want to explore multiple versions of behaviors, but todaypsilas tools make this difficult. The results provide new ideas for future tools.", "num_citations": "159\n", "authors": ["25"]}
{"title": "Demonstrational interfaces: A step beyond direct manipulation\n", "abstract": " Demonstrational interfaces, interfaces that let the user perform actions on concrete example objects while constructing an abstract program, thus letting the user create parameterized procedures and objects without learning a programming language, are discussed. The motivations for and problems associated with demonstrational interfaces are presented. A survey of the various types of interfaces is also presented. Areas that would benefit from demonstrational technology, including general-purpose programming, visualization, macros for direct-manipulation interfaces, drawing packages, text editing and formatting, and user interface development environments, are discussed. Research issues involving demonstrational interfaces are reviewed.< >", "num_citations": "159\n", "authors": ["25"]}
{"title": "Analyzing the input stream for character-level errors in unconstrained text entry evaluations\n", "abstract": " Recent improvements in text entry error rate measurement have enabled the running of text entry experiments in which subjects are free to correct errors (or not) as they transcribe a presented string. In these \u0393\u00c7\u00a3unconstrained\u0393\u00c7\u00a5 experiments, it is no longer necessary to force subjects to unnaturally maintain synchronicity with presented text for the sake of performing overall error rate calculations. However, the calculation of character-level error rates, which can be trivial in artificially constrained evaluations, is far more complicated in unconstrained text entry evaluations because it is difficult to infer a subject's intention at every character. For this reason, prior character-level error analyses for unconstrained experiments have only compared presented and transcribed strings, not input streams. But input streams are rich sources of character-level error information, since they contain all of the text entered (and erased) by a\u252c\u00e1\u0393\u00c7\u00aa", "num_citations": "156\n", "authors": ["25"]}
{"title": "A user interface toolkit based on graphical objects and constraints\n", "abstract": " One of the most difficult aspects of creating graphical, direct manipulation user interfaces is managing the relationships between the graphical objects on the screen and the application data structures that they represent. Coral (Constraint-based Object-oriented Relations And Language) is a new user interface toolkit under development that uses efficiently-implemented constraints to support these relationships. Using Coral, user interface designers can construct interaction techniques such as menus and scroll bars. More importantly, Coral makes it easy to construct direct-manipulation user interfaces specialized to particular applications. Unlike previous constraint-based toolkits, Coral supports defining constraints in the abstract, and then applying them to different object instances. In addition, it provides iteration constructs where lists of items (such as those used in menus) can be constrained as a group. Coral has\u252c\u00e1\u0393\u00c7\u00aa", "num_citations": "156\n", "authors": ["25"]}
{"title": "Hard-to-answer questions about code\n", "abstract": " To build new tools and programming languages that make it easier for professional software developers to create, debug, and understand code, it is helpful to better understand the questions that developers ask during coding activities. We surveyed professional software developers and asked them to list hard-to-answer questions that they had recently asked about code. 179 respondents reported 371 questions. We then clustered these questions into 21 categories and 94 distinct questions. The most frequently reported categories dealt with intent and rationale--what does this code do, what is it intended to do, and why was it done this way? Many questions described very specific situations--eg, what does the code do when an error occurs, how to refactor without breaking callers, or the implications of a specific change on security. These questions revealed opportunities for both existing research tools to help\u252c\u00e1\u0393\u00c7\u00aa", "num_citations": "144\n", "authors": ["25"]}
{"title": "Challenges of HCI design and implementation\n", "abstract": " BRAD MYERS is a Senior Research Computer Scientist at Carnegie Mellon University, where he is the principal investigator for the Garnet User Intdace Development Environment and the Demonstrational Intdaces Projtzt. entail.* bam@ cr. cmu. edu etting the user interface right is becoming critical to the success of products, and everyone knows that designing and implementing human-computer interfaces is difficult and time-consuming. But why is this true? Should we expect that a new method is around the corner that will make the design significantly easier? Will the next generation of user interface toolkits make the implementation trivial? No. This article discusses reasons why a focus on the user interface is important, and why user interface design and implementation are inherently difficult tasks and will remain so for the foreseeable future.", "num_citations": "143\n", "authors": ["25"]}
{"title": "Invited research overview: end-user programming\n", "abstract": " In the past few decades there has been considerable work on empowering end users to be able to write their own programs, and as a result, users are indeed doing so. In fact, we estimate that over 12 million people in American workplaces would say that they\" do programming\" at work, and almost 50 million people use spreadsheets or databases (and therefore may potentially program), compared to only 3 million professional programmers. The\" programming\" systems used by these end users include spreadsheet systems, web authoring tools, business process authoring tools such as Visual Basic, graphical languages for demonstrating the desired behavior of educational simulations, and even professional languages such as Java. The motivation for end-user programming is to have the computer be useful for each person's specific individual needs. While the empirical study of programming has been an HCI\u252c\u00e1\u0393\u00c7\u00aa", "num_citations": "142\n", "authors": ["25"]}
{"title": "Using HCI techniques to design a more usable programming system\n", "abstract": " A programming system is the user interface between the programmer and the computer. Programming is a notoriously difficult activity, and some of this difficulty can be attributed to the user interface as opposed to other factors. Historically, the designs of programming languages and tools have not emphasized usability. This paper describes the process we used to design HANDS, a new programming system for children that focuses on usability, where HCI knowledge, principles, and methods guided all design decisions. The features of HANDS are presented along with their motivations from prior empirical research on programmers and new studies conducted by the authors. HANDS is an event-based language that features a concrete model for computation, provides operators that match the way non-programmers express problem solutions, and includes domain-specific features for the creation of interactive\u252c\u00e1\u0393\u00c7\u00aa", "num_citations": "141\n", "authors": ["25"]}
{"title": "Finding causes of program output with the Java Whyline\n", "abstract": " Debugging and diagnostic tools are some of the most important software development tools, but most expect developers choose the right code to inspect. Unfortunately, this rarely occurs. A new tool called the Whyline is described which avoids such speculation by allowing developers to select questions about a program's output. The tool then helps developers work backwards from output to its causes. The prototype, which supports Java programs, was evaluated in an experiment in which participants investigated two real bug reports from an open source project using either the Whyline or a breakpoint debugger. Whyline users were successful about three times as often and about twice as fast compared to the control group, and were extremely positive about the tool's ability to simplify diagnostic tasks in software development work.", "num_citations": "139\n", "authors": ["25"]}
{"title": "Interaction styles and input/output devices\n", "abstract": " Abstract", "num_citations": "139\n", "authors": ["25"]}
{"title": "Graphical techniques in a spreadsheet for specifying user interfaces\n", "abstract": " Many modem user interface development environments use constraints to connect graphical objects. Constraints are relationships that are de&red once and then maintained by the system. Often, systems provide graphical, iconic, or demonstrational techniques for specifying some constraints, but these are incapable of expressing all desired relationships, and it is always necessary to allow the user interface designer to write code to specify complex constraints. The spreadsheet interface described here, called C32, provides the programmer with the full power of writing constraint code in the underlying programming language, but it is significantly easier to use. Unlike other spreadsheets tools for gmphics, C32 automatically generates appropriate object references from mouse clicks in graphics windows and usesinferencing and demonstrational techniques to make constructing and copying constraints easier. In\u252c\u00e1\u0393\u00c7\u00aa", "num_citations": "132\n", "authors": ["25"]}
{"title": "Simplifying video editing using metadata\n", "abstract": " Digital video is becoming increasingly ubiquitous. However, editing video remains difficult for several reasons: it is a time-based medium, it has dual tracks of audio and video, and current tools force users to work at the smallest level of detail. Based on interviews with professional video editors, we developed a video editor, called Silver, that uses metadata to make digital video editing more accessible to novices. To help users visualize video, Silver provides multiple views with different semantic content and at different levels of abstraction, including storyboard, editable transcript, and timeline views. Silver offers smart editing operations that help users resolve the inconsistencies that arise because of the different boundaries in audio and video. We conducted a preliminary user study to investigate the effectiveness of the Silver smart editing. Participants successfully edited video after only a short tutorial, both with and\u252c\u00e1\u0393\u00c7\u00aa", "num_citations": "129\n", "authors": ["25"]}
{"title": "Automatic, look-and-feel independent dialog creation for graphical user interfaces\n", "abstract": " Jade is a new interactive tool that automatically creates graphical input dialogs such as dialog boxes and menus. Application programmers write a textual specification of a dialog's contents. This specification contains absolutely no graphical information and thus is look-and-feel independent. The graphic artist uses a direct manipulation graphical editor to define the rules, graphical objects, interaction techniques, and decorations that will govern the dialog's look-and-feel, and stores the results in a look and feel database. Jade combines the application programmer's specification with the look-and-feel database to automatically generate a graphical dialog. If necessary, the graphic artist can then edit the resulting dialog using a graphical editor and these edits will be remembered by Jade, even if the original textual specification is modified. By eliminating all graphical references from the dialog's content specification\u252c\u00e1\u0393\u00c7\u00aa", "num_citations": "129\n", "authors": ["25"]}
{"title": "Reusable hierarchical command objects\n", "abstract": " The Amulet user interface development environment uses hierarchical command objects to support the creation of highly-interactive graphical user interfaces. When input arrives or a widget is operated by the user, instead of invoking a call-back procedure as in most other toolkits, Amulet allocates a command object and calls its", "num_citations": "125\n", "authors": ["25"]}
{"title": "The implications of method placement on API learnability\n", "abstract": " To better understand what makes Application Programming Interfaces (APIs) hard to use and how to improve them, recent research has begun studying programmers' strategies and use of APIs. It was found that method placement---on which class or classes a method is placed---can have large usability impact in object-oriented APIs. This was because programmers often start their exploration of an API from one\" main\" object, and were slower finding other objects that were not referenced in the methods of the main object. For example, while mailServer. send (mailMessage) might make sense, if programmers often begin their API explorations from the MailMessage class, then this makes it harder to find the MailServer class than the alternative mailMessage. send (mailServer). This is interesting because many real APIs place methods essential to common objects on other, helper objects. Alternate versions of three\u252c\u00e1\u0393\u00c7\u00aa", "num_citations": "118\n", "authors": ["25"]}
{"title": "Creating user interfaces using programming by example, visual programming, and constraints\n", "abstract": " Peridot is an experimental tool that allows designers to create user interface components without conventional programming. The designer draws pictures of what the interface should look like and then uses the mouse and other input devices to demonstrate how the interface should operate. Peridot generalizes from these example pictures and actions to create parameterized procedures, such as those found in conventional user interface libraries such as the Macintosh Toolbox. Peridot uses visual programming, programming by example, constraints, and plausible inferencing to allow nonprogrammers to create menus, buttons, scroll bars, and many other interaction techniques easily and quickly. Peridot created its own interface and can create almost all of the interaction techniques in the Macintosh Toolbox. Therefore, Peridot demonstrates that it is possible to provide sophisticated programming capabilities to\u252c\u00e1\u0393\u00c7\u00aa", "num_citations": "113\n", "authors": ["25"]}
{"title": "Text entry from power wheelchairs: EdgeWrite for joysticks and touchpads\n", "abstract": " Power wheelchair joysticks have been used to control a mouse cursor on desktop computers, but they offer no integrated text entry solution, confining users to point-and-click or point-and-dwell with on-screen keyboards. But on-screen keyboards reduce useful screen real-estate, exacerbate the need for frequent window management, and impose a second focus of attention. By contrast, we present two integrated gestural text entry methods designed for use from power wheelchairs: one for joysticks and the other for touchpads. Both techniques are adaptations of EdgeWrite, originally a stylus-based unistroke method designed for people with tremor. In a preliminary study of 7 power wheelchair users, we found that touchpad EdgeWrite was faster than joystick WiVik, and joystick EdgeWrite was only slightly slower after minimal practice. These findings reflect\" walk up and use\"-ability and warrant further investigation\u252c\u00e1\u0393\u00c7\u00aa", "num_citations": "111\n", "authors": ["25"]}
{"title": "Marquise: Creating complete user interfaces by demonstration\n", "abstract": " Marquise is a new interactive tool that allows virtually all of the user interfaces of graphical editors to be created by demonstration without programming. A \u0393\u00c7\u00a3graphical editor\u0393\u00c7\u00a5 allows the user to create and manipulate graphical objects with a mouse. This is a very large class of programs and includes drawing programs like MacDraw, graph layout editors like MacProject, visual language editors, and many CAD/CAM programs. The primary innovation in Marquise is to allow the designer to demonstrate the overall behavior of the interface. To implement this, the Marquise framework contains knowledge about palettes for creating and specifying properties of objects, and about operations such as selecting, moving, and deleting objects. The interactive tool uses the framework to allow the designer to demonstrate most of the end user's actions without programming, which means that Marquise can be used by non\u252c\u00e1\u0393\u00c7\u00aa", "num_citations": "110\n", "authors": ["25"]}
{"title": "Sketching storyboards to illustrate interface behaviors\n", "abstract": " Current user interface construction tools make it difficult for a user interface designer to illustrate the behavior of an interface. These tools focus on specifying widgets and manipulating details such as colors. They can show what the interface will look like, but make it hard to show what it will do. For these reasons, designers prefer to sketch early interface ideas on paper. We have developed a tool called SILK that allows designers to quickly sketch an interface electronically. Unlike paper sketches, this electronic sketch is interactive. The designer can illustrate behaviors by sketching storyboards, which specify how the screen should change in response to user actions.", "num_citations": "104\n", "authors": ["25"]}
{"title": "Creating graphical interactive application objects by demonstration\n", "abstract": " The Lapidary user interface tool allows all pictorial aspects of programs to be specified graphically. In addition, the behavior of these objects at run-time can be specified using dialogue boxes and by demonstration. In particular, Lapidary allows the designer to draw pictures of application-specific graphical objects which will be created and maintained at run-time by the application. This includes the graphical entities that the end user will manipulate (such as the components of the picture), the feedback that shows which objects are selected (such as small boxes on the sides and corners of an object), and the dynamic feedback objects (such as hair-line boxes to show where an object is being dragged). In addition, Lapidary supports the construction and use of \u0393\u00c7\u00a3widgets\u0393\u00c7\u00a5(sometimes called interaction techniques or gadgets) such as menus, scroll bars, buttons and icons. Lapidary therefore supports using a pre-defined\u252c\u00e1\u0393\u00c7\u00aa", "num_citations": "104\n", "authors": ["25"]}
{"title": "Controlling home and office appliances with smart phones\n", "abstract": " The personal universal controller system lets users interact with their appliances through automatically generated remote control interfaces on their smart phone devices. In this article, we present a framework for automatically generating appliance interfaces from abstract specifications of appliances' functions. These interfaces control each appliance's full functionality and are consistent with the phone's other interfaces. Our interfaces are also fully interactive, which incrementally adjust the appliance's features, such as volume, in real time. Our work demonstrates the feasibility of automatically generating high-quality interfaces for a wide range of appliances on a smart phone device", "num_citations": "102\n", "authors": ["25"]}
{"title": "The story in the notebook: Exploratory data science using a literate programming tool\n", "abstract": " Literate programming tools are used by millions of programmers today, and are intended to facilitate presenting data analyses in the form of a narrative. We interviewed 21 data scientists to study coding behaviors in a literate programming environment and how data scientists kept track of variants they explored. For participants who tried to keep a detailed history of their experimentation, both informal and formal versioning attempts led to problems, such as reduced notebook readability. During iteration, participants actively curated their notebooks into narratives, although primarily through cell structure rather than markdown explanations. Next, we surveyed 45 data scientists and asked them to envision how they might use their past history in an future version control system. Based on these results, we give design guidance for future literate programming tools, such as providing history search based on how\u252c\u00e1\u0393\u00c7\u00aa", "num_citations": "101\n", "authors": ["25"]}
{"title": "User Interfaces That Span Hand-Held and Fixed Devices\n", "abstract": " The Pebbles research project (http://www. pebbles. cs. cmu. edu/) has been studying the use of hand-held devices at the same time as other computing devices. As people move about the world, they will be entering and leaving spaces where there are embedded or desktop computers, such as offices, conference rooms, classrooms, and even\" smart homes.\" We are exploring the many issues surrounding how to have the user interface, functionality, and information spread across multiple devices that are used simultaneously. For example, there are many ways that a personal digital assistant (PDA), such as a Palm Pilot or PocketPC device, can serve as a useful adjunct to a personal computer to enhance interactions with existing desktop applications for individuals or groups. Applications may distribute their user interfaces across multiple devices so the user can choose the appropriate device for each part of the interaction. A key focus of our research is that the hand-held computers are used both as output devices and as input devices to control the activities on the other computers. The following scenarios illustrate some of the capabilities we are already investigating:\u0393\u00c7\u00f3 The presenter of a talk has a laptop whose display is projected onto a large screen. The laptop's powerful processor is needed to control the animations and external applications that are part of the presentation.(Or similarly, the meeting room has a built-in computer with a data projector to control the presentation.) The presenter walks in with a hand-held PDA. The laptop communicates with the PDA, and the PDA displays the current slide's notes. Gestures on the PDA cause the\u252c\u00e1\u0393\u00c7\u00aa", "num_citations": "100\n", "authors": ["25"]}
{"title": "Answering why and why not questions in user interfaces\n", "abstract": " Modern applications such as Microsoft Word have many automatic features and hidden dependencies that are frequently helpful but can be mysterious to both novice and expert users. The\"\" Crystal\"\" application framework provides an architecture and interaction techniques that allow programmers to create applications that let the user ask a wide variety of questions about why things did and did not happen, and how to use the related features of the application without using natural language. A user can point to an object or a blank space and get a popup list of questions about it, or the user can ask about recent actions from a temporal list. Parts of a text editor were implemented to show that these techniques are feasible, and a user test suggests that they are helpful and well-liked.", "num_citations": "99\n", "authors": ["25"]}
{"title": "State of the art in user interface software tools\n", "abstract": " Publisher SummaryThis chapter discusses why user interface software is so difficult to create, and what kinds of tools have been created to help with this process. The user interface of a computer program is the part that handles the output to the display and the input from the person using the program. The rest of the program is called the application or the application semantics. User interface tools have been called various names over the years, with the most popular being user interface management systems (UIMS). Other terms like toolkits, user interface development environments, interface builders, and application frameworks are also used. This chapter tries to define these terms more specifically, and use the general term user interface tool for all software aimed to help create user interfaces.", "num_citations": "97\n", "authors": ["25"]}
{"title": "What to do when search fails: finding information by association\n", "abstract": " Sometimes people cannot remember the names or locations of things on their computer, but they can remember what other things are associated with them. We created Feldspar, the first system that fully supports this associative retrieval of personal information on the computer. Feldspar's contributions include (1) an intuitive user interface that allows users to find information by interactively and incrementally specifying multiple levels of associations as retrieval queries, such as:\" find the file from the person who I met at an event in May\"; and (2) algorithms for collecting the association information and for providing answers to associative queries in real-time. A user study showed that Feldspar is easy to use, and suggested that it might be faster than conventional browsing and searching for these kinds of retrieval tasks. Feldspar could be an important addition to search and browsing tools.", "num_citations": "95\n", "authors": ["25"]}
{"title": "Development and evaluation of a model of programming errors\n", "abstract": " Models of programming and debugging suggest many causes of errors, and many classifications of error types exist. Yet, there has been no attempt to link causes of errors to these classifications, nor is there a common vocabulary for reasoning about such causal links. This makes it difficult to compare the abilities of programming styles, languages, and environments to prevent errors. To address this issue, this paper presents a model of programming errors based on past studies of errors. The model was evaluated with two observational of Alice, an event-based programming system, revealing that most errors were due to attentional and strategic problems in implementing algorithms, language constructs, and uses of libraries. In general, the model can support theoretical, design, and educational programming research.", "num_citations": "95\n", "authors": ["25"]}
{"title": "Model-based and empirical evaluation of multimodal interactive error correction\n", "abstract": " Our research addresses the problem of error correction in speech user interfaces. Previous work hypothesized that switching modality could speed up interactive correction of recognition errors (so-called multimodal error correction). We present a user study that compares, on a dictation task, multimodal error correction with conventional interactive correction, such as speaking again, choosing Tom a list, and keyboard input. Results show that multimodal correction is faster than conventional correction without keyboard input, but slower than correction by typing for users with good typing skills. Furthermore, while users initially prefer speech, they learn to avoid ineffective correction modalities with experience. To extrapolate results from this user study we developed a performance model of multimodal interaction that predicts input speed including time needed for error correction. We apply the model to estimate the\u252c\u00e1\u0393\u00c7\u00aa", "num_citations": "95\n", "authors": ["25"]}
{"title": "SUGILITE: creating multimodal smartphone automation by demonstration\n", "abstract": " SUGILITE is a new programming-by-demonstration (PBD) system that enables users to create automation on smartphones. SUGILITE uses Android's accessibility API to support automating arbitrary tasks in any Android app (or even across multiple apps). When the user gives verbal commands that SUGILITE does not know how to execute, the user can demonstrate by directly manipulating the regular apps' user interface. By leveraging the verbal instructions, the demonstrated procedures, and the apps? UI hierarchy structures, SUGILITE can automatically generalize the script from the recorded actions, so SUGILITE learns how to perform tasks with different variations and parameters from a single demonstration. Extensive error handling and context checking support forking the script when new situations are encountered, and provide robustness if the apps change their user interface. Our lab study suggests that\u252c\u00e1\u0393\u00c7\u00aa", "num_citations": "93\n", "authors": ["25"]}
{"title": "Active code completion\n", "abstract": " Code completion menus have replaced standalone API browsers for most developers because they are more tightly integrated into the development workflow. Refinements to the code completion menu that incorporate additional sources of information have similarly been shown to be valuable, even relative to standalone counterparts offering similar functionality. In this paper, we describe active code completion, an architecture that allows library developers to introduce interactive and highly-specialized code generation interfaces, called palettes, directly into the editor. Using several empirical methods, we examine the contexts in which such a system could be useful, describe the design constraints governing the system architecture as well as particular code completion interfaces, and design one such system, named Graphite, for the Eclipse Java development environment. Using Graphite, we implement a palette\u252c\u00e1\u0393\u00c7\u00aa", "num_citations": "93\n", "authors": ["25"]}
{"title": "UNIFORM: automatically generating consistent remote control user interfaces\n", "abstract": " A problem with many of today's appliance interfaces is that they are inconsistent. For example, the procedure for setting the time on alarm clocks and VCRs differs, even among different models made by the same manufacturer. Finding particular functions can also be a challenge, because appliances often organize their features differently. This paper presents a system, called Uniform, which approaches this problem by automatically generating remote control interfaces that take into account previous interfaces that the user has seen during the generation process. Uniform is able to automatically identify similarities between different devices and users may specify additional similarities. The similarity information allows the interface generator to use the same type of controls for similar functions, place similar functions so that they can be found with the same navigation steps, and create interfaces that have a similar\u252c\u00e1\u0393\u00c7\u00aa", "num_citations": "93\n", "authors": ["25"]}
{"title": "Handheld computing\n", "abstract": " Because handhelds are inexpensive compared to other types of computers, users can possess more than one of these devices, each having a specialized user interface. Although handhelds can be used in isolation, they also can interoperate with other devices through wireless networks including WiFi and Bluetooth. Further, by using inexpensive components, developers can integrate different technologies into one device, leading to one of the fastest-growing markets for handhelds. Worldwide, about 30 million PDAs are in use, but this pales in comparison to the 1.3 billion mobile phone devices currently being used (www. cellular. co. za/stats/stats-main. htm). Increasingly, these mobile smart phones offer PDA-like capabilities. Analysts predict that in 2003 smart phone sales will reach 4 million units in Europe, for the first time outpacing sales of PDAs (http://search. internet. com/www. rimroad. com). In the US, predictions indicate that the smart phone segment of the phone market will increase from 8.5 percent in 2003 to 35 percent in 2007, while PDA sales will increase from 6.9 million to 17.1 million in the same period (www. wirelessdevnet. com/news/2003/169/news7. html).", "num_citations": "91\n", "authors": ["25"]}
{"title": "Getting more out of programming-by-demonstration\n", "abstract": " Programming-by-demonstration (PBD) can be used to create tools and methods that eliminate the need to learn difficult computer languages. Gamut is a PBD tool that nonprogrammers can use to create a broader range of interactive software, including games, simulations, and educational software, than they can with other PBD tools. To do this, Gamut provides advanced interaction techniques that make it easier for a developer to express all aspects of an application. These techniques include a simplified way to demonstrate new examples, called nudges, and a way to highlight objects to show they are important. Also, Gamut includes new objects and metaphors like the deck-of-cards metaphor for demonstrating collections of objects and randomness, guide objects for demonstrating relationships that the system would find too difficult to guess, and temporal ghosts which simplify showing relationships with the\u252c\u00e1\u0393\u00c7\u00aa", "num_citations": "91\n", "authors": ["25"]}
{"title": "Improving API documentation using API usage information\n", "abstract": " Jadeite is a new Javadoc-like API documentation system that takes advantage of multiple users' aggregate experience to reduce difficulties that programmers have learning new APIs. Previous studies have shown that programmers often guessed that certain classes or methods should exist, and looked for these in the API. Jadeite's ldquoplaceholdersrdquo let users add new ldquopretendrdquo classes or methods that are displayed in the actual API documentation, and can be annotated with the appropriate APIs to use instead. Since studies showed that programmers had difficulty finding the right classes from long lists in documentation, Jadeite takes advantage of usage statistics to display commonly used classes more prominently. Programmers had difficulty discovering how to instantiate objects, so Jadeite uses a large corpus of sample code to automatically the most common ways to construct an instance of\u252c\u00e1\u0393\u00c7\u00aa", "num_citations": "90\n", "authors": ["25"]}
{"title": "Trackball text entry for people with motor impairments\n", "abstract": " We present a new gestural text entry method for trackballs. The method uses the mouse cursor and relies on crossing instead of pointing. A user writes in fluid Roman-like unistrokes by\"\" pulsing\"\" the trackball in desired letter patterns. We examine this method both theoretically using the Steering Law and empirically in two studies. Our studies show that able-bodied users who were unfamiliar with trackballs could write at about 10 wpm with< 4% total errors after 45 minutes. In eight sessions, a motor-impaired trackball user peaked at 7.11 wpm with 0% uncorrected errors, compared to 5.95 wpm with 0% uncorrected errors with an on-screen keyboard. Over sessions, his speeds were significantly faster with our gestural method than with an on-screen keyboard. A former 15-year veteran of on-screen keyboards, he now uses our gestural method instead.", "num_citations": "90\n", "authors": ["25"]}
{"title": "A multi-view intelligent editor for digital video libraries\n", "abstract": " Silver is an authoring tool that aims to allow novice users to edit di gital video. The goal is to make editing of digital video as easy as text editing. Silver provides multiple coordinated views, including project, source, outline, subject, storyboard, textual transcript and timeline views. Selections and edits in any view are synchronized with all other views. A variety of recognition algorithms are applied to the video and audio content and then are used to aid in the editing tasks. The Informedia Digital Library supplies the recognition algorithms and metadata used to support intelligent editing, and Informedia also provides search and a repository. The metadata includes shot boundaries and a time-synchronized transcript, which are used to support intelligent selection and intelligent cut/copy/paste.", "num_citations": "90\n", "authors": ["25"]}
{"title": "Variolite: Supporting Exploratory Programming by Data Scientists.\n", "abstract": " How do people ideate through code? Using semi-structured interviews and a survey, we studied data scientists who program, often with small scripts, to experiment with data. These studies show that data scientists frequently code new analysis ideas by building off of their code from a previous idea. They often rely on informal versioning interactions like copying code, keeping unused code, and commenting out code to repurpose older analysis code while attempting to keep those older analyses intact. Unlike conventional version control, these informal practices allow for fast versioning of any size code snippet, and quick comparisons by interchanging which versions are run. However, data scientists must maintain a strong mental map of their code in order to distinguish versions, leading to errors and confusion. We explore the needs for improving version control tools for exploratory tasks, and demonstrate a tool for lightweight local versioning, called Variolite, which programmers found usable and desirable in a preliminary usability study.", "num_citations": "88\n", "authors": ["25"]}
{"title": "Improving automatic interface generation with smart templates\n", "abstract": " One of the challenges of using mobile devices for ubiquitous remote control is the creation of the user interface. If automatically generated designs are used, then they must be close in quality to hand-designed interfaces. Automatically generated interfaces can be dramatically improved if they use standard conventions to which users are accustomed, such as the arrangement of buttons on a telephone dial-pad or the conventional play, stop, and pause icons on a media player. Unfortunately, it can be difficult for a system to determine where to apply design conventions because each appliance may represent its functionality differently. Smart Templates is a technique that uses parameterized templates in the appliance model to specify when such conventions might be automatically applied in the user interface. Our templates easily adapt to existing appliance models, and interface generators on different platforms can\u252c\u00e1\u0393\u00c7\u00aa", "num_citations": "88\n", "authors": ["25"]}
{"title": "Capturing and analyzing low-level events from the code editor\n", "abstract": " In this paper, we present FLUORITE, a publicly available event logging plug-in for Eclipse which captures all of the low-level events when using the Eclipse code editor. FLUORITE captures not only what types of events occurred in the code editor, but also more detailed information such as the inserted and deleted text and the specific parameters for each command. This enables the detection of many usage patterns that could otherwise not be recognized, such as\" typo correction\" that requires knowing that the entered text is immediately deleted and replaced. Moreover, the snapshots of each source code file that has been opened during the session can be completely reproduced using the collected information. We also provide analysis and visualization tools which report various statistics about usage patterns, and we provide the logs in an XML format so others can write their own analyzers. FLUORITE can be\u252c\u00e1\u0393\u00c7\u00aa", "num_citations": "87\n", "authors": ["25"]}
{"title": "Languages for developing user interfaces\n", "abstract": " This book brings together a number of researchers and developers from industry and academia who report on their work. It is of interest to language designers and the creators of toolkits, UIMSs, and other user interface tools.", "num_citations": "87\n", "authors": ["25"]}
{"title": "Creating dynamic interaction techniques by demonstration\n", "abstract": " When creating highly-interactive, Direct Manipulation interfaces, one of the most difficult design and implementation tasks is handling the mouse and other input devices. Peridot, a new User Interface Management System, addresses this problem by allowing the user interface designer to demonstrate how the input devices should be handled by giving an example of the interface in action. The designer uses sample values for parameters, and the system automatically infers the general operation and creates the code. After an interaction is specified, it can immediately be executed and edited. This promotes extremely rapid prototyping since it is very easy to design, implement and modify mouse-based interfaces. Peridot also supports additional input devices such as touch tablets, as well as multiple input devices operating in parallel (such as one in each hand) in a natural, easy to specify manner. This is\u252c\u00e1\u0393\u00c7\u00aa", "num_citations": "87\n", "authors": ["25"]}
{"title": "Huddle: automatically generating interfaces for systems of multiple connected appliances\n", "abstract": " Systems of connected appliances, such as home theaters and presentation rooms, are becoming commonplace in our homes and workplaces. These systems are often difficult to use, in part because users must determine how to split the tasks they wish to perform into sub-tasks for each appliance and then find the particular functions of each appliance to complete their sub-tasks. This paper describes Huddle, a new system that automatically generates task-based interfaces for a system of multiple appliances based on models of the content flow within the multi-appliance system.", "num_citations": "85\n", "authors": ["25"]}
{"title": "Declarative programming in a prototype-instance system: object-oriented programming without writing methods\n", "abstract": " Over the last three years of using the Garnet system to create dozens of large-scale user interfaces, we have observed that the style of programming in Garnet is quite different from that in conventional objectoriented systems. In Garnet, programmers combine pre-defined objects into collections, use constraints to define the relationships among them, and then attach pre-defined \u0393\u00c7\u00a3Interactor\u0393\u00c7\u00a5 objects to cause the objects to respond to input. The result is a declarative style of programming where the programmer rarely writes methods. Furthermore, the interface to objects is usually through direct accessing and setting of data values, rather than through methods.", "num_citations": "85\n", "authors": ["25"]}
{"title": "Visualizing call graphs\n", "abstract": " Developers navigate and reason about call graphs throughout investigation and debugging activities. This is often difficult: developers can spend tens of minutes answering a single question, get lost and disoriented, and erroneously make assumptions, causing bugs. To address these problems, we designed a new form of interactive call graph visualization - REACHER. Instead of leaving developers to manually traverse the call graph, REACHER lets developers search along control flow. The interactive call graph visualization encodes a number of properties that help developers answer questions about causality, ordering, type membership, repetition, choice, and other relationships. And developers remain oriented while navigating. To evaluate REACHER'S benefits, we conducted a lab study in which 12 participants answered control flow questions. Compared to an existing IDE, participants with REACHER were\u252c\u00e1\u0393\u00c7\u00aa", "num_citations": "84\n", "authors": ["25"]}
{"title": "FireCrystal: Understanding interactive behaviors in dynamic web pages\n", "abstract": " For developers debugging their own code, augmenting the code of others, or trying to learn the implementation details of interactive behaviors, understanding how web pages work is a fundamental problem. FireCrystal is a new Firefox extension that allows developers to indicate interactive behaviors of interest, and shows the specific code (Javascript, CSS, and HTML) that is responsible for those behaviors. FireCrystal provides an execution timeline that users can scrub back and forth, and the ability to select items of interest in the actual web page UI to see the associated code. FireCrystal may be especially useful for developers who are trying to learn the implementation details of interactive behaviors, so they can reuse these behaviors in their own web site.", "num_citations": "84\n", "authors": ["25"]}
{"title": "Evaluation of a hand\u0393\u00c7\u00c9held, computer\u0393\u00c7\u00c9based intervention to promote early self\u0393\u00c7\u00c9care behaviors after lung transplant\n", "abstract": " Abstract:\u0393\u00c7\u00e9 Background:\u0393\u00c7\u00e9 Lung transplant recipients are expected to perform self\u0393\u00c7\u00c9care behaviors to maximize transplant\u0393\u00c7\u00c9related health outcomes. Despite high non\u0393\u00c7\u00c9adherence rates in performing these self\u0393\u00c7\u00c9care behaviors, and the dire clinical consequences of such non\u0393\u00c7\u00c9adherence, interventions are lacking. Pocket Personal Assistant for Tracking Health (Pocket PATH) is a hand\u0393\u00c7\u00c9held device developed for patients to record health data, review data trends, and report condition changes to the transplant team. Methods:\u0393\u00c7\u00e9 A pilot trial was conducted to compare self\u0393\u00c7\u00c9care agency, self\u0393\u00c7\u00c9care behaviors, and health\u0393\u00c7\u00c9related quality of life (HRQOL) between recipients randomized to use Pocket PATH (n\u0393\u00c7\u00e2=\u0393\u00c7\u00e215) vs. standard care (n\u0393\u00c7\u00e2=\u0393\u00c7\u00e215) for the first two months following hospital discharge after lung transplantation. Results:\u0393\u00c7\u00e9 Baseline characteristics were equivalent across groups. Patients in the Pocket PATH group showed\u252c\u00e1\u0393\u00c7\u00aa", "num_citations": "82\n", "authors": ["25"]}
{"title": "Mapping the space of API design decisions\n", "abstract": " When creating new application programming interfaces (APIs), designers must make many decisions. These decisions affect the quality of the resulting APIs in terms of performance (such as speed and memory usage), power (expressiveness, extensibility and evolvability) and usability (leamability, productivity and error prevention). Experienced API designers have written recommendations on how to design APIs, offering their opinions on various API design decisions. Additionally, empirical research has begun to measure the usability tradeoffs of specific design decisions. While previous work has offered specific suggestions, there has not been a clear description of the design space of all possible API design decisions, or the quality attributes that these decisions affect. This paper puts existing API design recommendations into context by mapping out the space of API design decisions and API quality attributes.", "num_citations": "81\n", "authors": ["25"]}
{"title": "Encapsulating interactive behaviors\n", "abstract": " Although there has been important progress in models and packages for the output of graphics to computer screens, there has been little change in the way that input from the mouse, keyboard and other input devices is handled. New graphics standards are still using a ten year old model even though it is widely accepted as inadequate, and most modern window managers simply return a stream of device-dependent input events. This paper presents a new model for how input devices can be handled for highly-interactive, direct manipulation, graphical user interfaces. This model encapsulates interactive behaviors into a few \u0393\u00c7\u00a3interactor\u0393\u00c7\u00a5 object types. Application programs can then create instances of these interactor objects, and the details of the handling of the input devices are separated from the application and from the output graphics.", "num_citations": "81\n", "authors": ["25"]}
{"title": "A randomized controlled trial of a mobile health intervention to promote self\u0393\u00c7\u00c9management after lung transplantation\n", "abstract": " Lung transplant recipients are encouraged to perform self\u0393\u00c7\u00c9management behaviors, including (i) monitoring health indicators, (ii) adhering to their regimen, and (iii) reporting abnormal health indicators to the transplant coordinator, yet performance is suboptimal. When hospital discharge was imminent, this two\u0393\u00c7\u00c9group trial randomized 201 recipients to use either the mobile health (mHealth) intervention (n = 99) or usual care (n = 102), to compare efficacy for promoting self\u0393\u00c7\u00c9management behaviors (primary outcomes) and self\u0393\u00c7\u00c9care agency, rehospitalization, and mortality (secondary outcomes) at home during the first year after transplantation. The mHealth intervention group performed self\u0393\u00c7\u00c9monitoring (odds ratio [OR] 5.11, 95% confidence interval [CI] 2.95\u0393\u00c7\u00f48.87, p < 0.001), adhered to medical regimen (OR 1.64, 95% CI 1.01\u0393\u00c7\u00f42.66, p = 0.046), and reported abnormal health indicators (OR 8.9, 95% CI 3.60\u0393\u00c7\u00f421.99, p < 0\u252c\u00e1\u0393\u00c7\u00aa", "num_citations": "80\n", "authors": ["25"]}
{"title": "Citrine: providing intelligent copy-and-paste\n", "abstract": " We present Citrine, a system that extends the widespread copy-and-paste interaction technique with intelligent transformations, making it useful in more situations. Citrine uses text parsing to find the structure in copied text and allows users to paste the structured information, which might have many pieces, in a single paste operation. For example, using Citrine, a user can copy the text of a meeting request and add it to the Outlook calendar with a single paste. In applications such as Excel, users can teach Citrine by example how to copy and paste data by showing it which fields go into which columns, and can use this to copy or paste many items at a time in a user-defined manner. Citrine can be used with a wide variety of applications and types of data and can be easily extended to work with more. It currently includes parsers that recognize contact information, calendar appointments and bibliographic citations. It\u252c\u00e1\u0393\u00c7\u00aa", "num_citations": "80\n", "authors": ["25"]}
{"title": "Visualization of fine-grained code change history\n", "abstract": " Conventional version control systems save code changes at each check-in. Recently, some development environments retain more fine-grain changes. However, providing tools for developers to use those histories is not a trivial task, due to the difficulties in visualizing the history. We present two visualizations of fine-grained code change history, which actively interact with the code editor: a timeline visualization, and a code history diff view. Our timeline and filtering options allow developers to navigate through the history and easily focus on the information they need. The code history diff view shows the history of any particular code fragment, allowing developers to move through the history simply by dragging the marker back and forth through the timeline to instantly see the code that was in the snippet at any point in the past. We augment the usefulness of these visualizations with richer editor commands including\u252c\u00e1\u0393\u00c7\u00aa", "num_citations": "79\n", "authors": ["25"]}
{"title": "Usability challenges for enterprise service-oriented architecture APIs\n", "abstract": " An important part of many programming tasks is the use of libraries and other forms of application programming interfaces (APIs). Programming via Web services using a service-oriented architecture (SOA) is an emerging form of API usage. Web services in a business context (called enterprise SOA or E-SOA) add additional complexity in terms of the number of the services, the variety of internal data structures, and service interdependencies. After altering existing human-computer interaction (HCI) methodologies to address the unique context of software development for SOA, we evaluated a large E-SOA API and identified many usability challenges. Prominent results include difficulties developers encountered while assembling data structures in Web service parameters, cycles of errors due to unclear control parameters within data structures, and difficulties with understanding long identifier names. We\u252c\u00e1\u0393\u00c7\u00aa", "num_citations": "79\n", "authors": ["25"]}
{"title": "Future of end-user software engineering: beyond the silos\n", "abstract": " End-user software engineering (EUSE) is a research area that aims to invent new kinds of technologies that collaborate with end users to improve the quality of their software. The practice that EUSE research aims to support is end users using new tools and methods to improve the quality of the software that they and other end users have created. There is a need for this outcome because research shows both that the number of end users creating their own software greatly exceeds the number of professional software developers, and that the software they create is riddled with errors. In this paper, we describe the present state of EUSE, and challenges in moving forward toward a bright future. We show how the future of EUSE may become over-siloed, restricting future researchers' vision of what can be achieved. We then show that focusing on the in-the-moment intents of end-user developers can be used to derive\u252c\u00e1\u0393\u00c7\u00aa", "num_citations": "77\n", "authors": ["25"]}
{"title": "Programmers are users too: Human-centered methods for improving programming tools\n", "abstract": " Human-centered methods can help researchers better understand and meet programmers' needs. Because programming is a human activity, many of these methods can be used without change. However, some programmer needs require new methods, which can also be applied to domains other than software engineering. This article features five Web extras. The video at https://youtu.be/4PH9-qi-yTQ demonstrates Azurite, an Eclipse plug-in with a selective undo feature that lets programmers more easily backtrack their code. The video at https://youtu.be/gOSlR62-rd8 describes Graphite, an Eclipse plug-in offering active code completion, a simple but powerful technique that integrates useful code-generation tools directly into the editor. The video at https://youtu.be/zyrqcYxqDtI describes HANDS, a new programming system that emphasizes usability by building on children's and beginning programmers' natural\u252c\u00e1\u0393\u00c7\u00aa", "num_citations": "75\n", "authors": ["25"]}
{"title": "Automatic data visualization for novice Pascal programmers.\n", "abstract": " Previous work has demonstrated that presenting the data structures from programs in a graphical manner can significantly help programmers understand and debug their programs. In most previous systems, however, the graphical displays, called data visualizations, had to be laboriously hand created. The Amethyst system, which runs on Apple Macintosh computers, provides attractive and appropriate default displays for data structures. The default displays include the appropriate forms for literals of the simple types inside type-specific shapes, and stacked boxes for records and arrays. In the near future, we plan to develop rules for layout of simple dynamic data structures (like linked lists and binary trees), and simple mechanisms for creating customized displays. The visualizations are integrated into an advanced programming environment which is used to teach programming methodology at the introductory level.", "num_citations": "75\n", "authors": ["25"]}
{"title": "Eyes on the road, hands on the wheel: thumb-based interaction techniques for input on steering wheels\n", "abstract": " The increasing quantity and complexity of in-vehicle systems creates a demand for user interfaces which are suited to driving. The steering wheel is a common location for the placement of buttons to control navigation, entertainment, and environmental systems, but what about a small touchpad? To investigate this question, we embedded a Synaptics StampPad in a computer game steering wheel and evaluated seven methods for selecting from a list of over 3000 street names. Selection speed was measured while stationary and while driving a simulator. Results show that the EdgeWrite gestural text entry method is about 20% to 50% faster than selection-based text entry or direct list-selection methods. They also show that methods with slower selection speeds generally resulted in faster driving speeds. However, with EdgeWrite, participants were able to maintain their speed and avoid incidents while selecting and\u252c\u00e1\u0393\u00c7\u00aa", "num_citations": "74\n", "authors": ["25"]}
{"title": "Barista: An implementation framework for enabling new tools, interaction techniques and views in code editors\n", "abstract": " Recent advances in programming environments have focused on improving programmer productivity by utilizing the inherent structure in computer programs. However, because these environments represent code as plain text, it is difficult and sometimes impossible to embed interactive tools, annotations, and alternative views in the code itself. Barista is an implementation framework that enables the creation of such user interfaces by simplifying the implementation of editors that represent code internally as an abstract syntax tree and maintain a corresponding, fully structured visual representation on-screen. Barista also provides designers of editors with a standard text-editing interaction technique that closely mimics that of conventional text editors, overcoming a central usability issue of previous structured code editors.", "num_citations": "73\n", "authors": ["25"]}
{"title": "How to support designers in getting hold of the immaterial material of software\n", "abstract": " When designing novel GUI controls, interaction designers are challenged by the\" immaterial\" materiality of the digital domain; they lack tools that effectively support a reflecting conversation with the material of software as they attempt to conceive, refine, and communicate their ideas. To investigate this situation, we conducted two participatory design workshops. In the first workshop, focused on conceiving, we observed that designers want to invent controls by exploring gestures, context, and examples. In the second workshop, on refining and communicating, designers proposed tools that could refine movement, document context through usage scenarios, and support the use of examples. In this workshop they struggled to effectively communicate their ideas for developers because their ideas had not been fully explored. In reflecting on this struggle, we began to see an opportunity for the output of a design tool to\u252c\u00e1\u0393\u00c7\u00aa", "num_citations": "72\n", "authors": ["25"]}
{"title": "Creating interaction techniques by demonstration\n", "abstract": " When creating highly interactive, direct-manipulation interfaces, one of the most difficult design and implementation tasks is handling the mouse and other input devices. Peridot, a new user interface management system, addresses this problem by allowing the designer of the user interface to demonstrate how the input device should be handled by giving an example of the interface in action. The designer uses sample values for parameters, and the system automatically infers the general operation and creates the code. After an interaction is specified, it can be executed rapid prototyping, since it is very easy to design, implement, and modify mouse-based interfaces. Perudit also supports such additional input devices as touch tablets, as well as multiple input devices operating in parallel (for example, one in each hand) in a natural, easy-to-specify manner. All interaction techniques are implemented using active\u252c\u00e1\u0393\u00c7\u00aa", "num_citations": "72\n", "authors": ["25"]}
{"title": "An alternative to push, press, and tap-tap-tap: gesturing on an isometric joystick for mobile phone text entry\n", "abstract": " A gestural text entry method for mobile is presented. Unlike most mobile phone text entry methods, which rely on repeatedly pressing buttons, our gestural method uses an isometric joystick and the EdgeWrite alphabet to allow users to write by making letter-like\" pressure strokes.\" In a 15-session study comparing character-level EdgeWrite to Multitap, subjects' speeds were statistically indistinguishable, reaching about 10 WPM. In a second 15-session study comparing word-level EdgeWrite to T9, the same subjects were again statistically indistinguishable, reaching about 16 WPM. Uncorrected errors were low, around 1% or less for each method. In addition, subjective results favored EdgeWrite. Overall, results indicate that our isometric joystick-based method is highly competitive with two commercial keypad-based methods, opening the way for keypad-less designs and text entry on tiny devices. Additional results\u252c\u00e1\u0393\u00c7\u00aa", "num_citations": "71\n", "authors": ["25"]}
{"title": "Two-handed input using a PDA and a mouse\n", "abstract": " We performed several experiments using a Personal Digital Assistant (PDA) as an input device in the non-dominant hand along with a mouse in the dominant hand. A PDA is a small hand-held palm-size computer like a 3Com Palm Pilot or a Windows CE device. These are becoming widely available and are easily connected to a PC. Results of our experiments indicate that people can accurately and quickly select among a small numbers of buttons on the PDA using the left hand without looking, and that, as predicted, performance does decrease as the number of buttons increases. Homing times to move both hands between the keyboard and devices are only about 10% to 15% slower than times to move a single hand to the mouse, suggesting that acquiring two devices does not cause a large penalty. In an application task, we found that scrolling web pages using buttons or a scroller on the PDA matched the\u252c\u00e1\u0393\u00c7\u00aa", "num_citations": "71\n", "authors": ["25"]}
{"title": "Tabular and textual methods for selecting objects from a group\n", "abstract": " The accurate formulation of boolean expressions is a notorious problem in programming languages and database query tools. This paper studies the ways that untrained users naturally express and interpret queries, revealing some of the underlying reasons why this task is so difficult. Among the study's findings are: people interpret the word AND to mean either conjunction or disjunction depending on context, the scope to which they attribute the word NOT depends on whether the subsequent operator is AND or OR, and they often ignore parenthesis. Therefore, relying on these words and symbols for query formulation will result in poor usability. A tabular query form is proposed that avoids the need to name the operators, provides a clear distinction between conjunction and disjunction, and makes grouping more explicit. Comparing the tabular language with textual boolean expressions, the study finds that\u252c\u00e1\u0393\u00c7\u00aa", "num_citations": "70\n", "authors": ["25"]}
{"title": "Using handheld devices for tests in classes\n", "abstract": " An important method of evaluating students progress in courses is the administration of tests. The increasing availability of handheld computers, such as Palm and Windows CE devices, in conjunction with wireless networks, allows the automating of aspects of giving tests in the classroom. During the Spring 2000 academic semester, we experimented with using Windows CE devices in a chemistry course to allow the instructor to intersperse, with lecturing, the administration of a form of concept tests, in order to determine whether material just covered was understood, thereby enabling the instructor to modify the content or presentation of the rest of the lecture. We found that most students preferred the use of handhelds for this purpose to the use of a show of hands or holding up of flashcards.Descriptors:", "num_citations": "69\n", "authors": ["25"]}
{"title": "Creating charts by demonstration\n", "abstract": " ABSTRACT \u0393\u00c7\u00a3Gold\u0393\u00c7\u00a5 is a new interactive editor that allows a user to draw examples of the desired picture for business graphics and the system automatically produces a visualization. To specify a custom visualization in other systems, code must be written or a bewildering array of dialog boxes and commands must be used. In Gold, as the user is drawing an example of the desired visualization, knowledge of properties of the data and the typical graphics in business charts are used to generalize the example and create a picture for the actual data. The goal is to make designing a complex, composite chart almost as easy as sketching a picture on a napkin.", "num_citations": "69\n", "authors": ["25"]}
{"title": "Jadeite: improving API documentation using usage information\n", "abstract": " Jadeite is a new Javadoc-like API documentation system that takes advantage of multiple users' aggregate experience to reduce difficulties that programmers have learning new APIs. Previous studies have shown that programmers often guessed that certain classes or methods should exist, and looked for these in the API. Jadeite's\" placeholders\" let users add new\" pretend\" classes or methods that are displayed in the actual API documentation, and can be annotated with the appropriate APIs to use instead. Since studies showed that programmers had difficulty finding the right classes from long lists in documentation, Jadeite takes advantage of usage statistics to display commonly used classes more prominently. Programmers had difficulty finding the right helper objects and discovering how to instantiate objects, so Jadeite uses a large corpus of sample code to automatically identify the most common ways to\u252c\u00e1\u0393\u00c7\u00aa", "num_citations": "66\n", "authors": ["25"]}
{"title": "Mobile devices for control\n", "abstract": " With today\u0393\u00c7\u00d6s and tomorrow\u0393\u00c7\u00d6s wireless technologies, such as IEEE 802.11, BlueTooth, RF-Lite, and G3, mobile devices will frequently be in close, interactive communication. Many environments, including offices, meeting rooms, automobiles and classrooms, already contain many computers and computerized appliances, and the smart homes of the future will have ubiquitous embedded computation. When the user enters one of these environments carrying a mobile device, how will that device interact with the immediate environment? We are exploring, as part of the Pebbles research project, the many ways that mobile devices such as PalmOS Organizers or PocketPC / Windows CE devices, can serve as useful adjuncts to the \u0393\u00c7\u00a3fixed\u0393\u00c7\u00a5 computers in the user\u0393\u00c7\u00d6s vicinity. This brings up many interesting research questions, such as how to provide a user interface that spans multiple devices that are in use at the\u252c\u00e1\u0393\u00c7\u00aa", "num_citations": "64\n", "authors": ["25"]}
{"title": "Writing with a joystick: A comparison of date stamp, selection keyboard, and EdgeWrite\n", "abstract": " A joystick text entry method for game controllers and mobile phones would be valuable, since these devices often have joysticks but no conventional keyboards. But prevalent joystick text entry methods are slow because they are selection-based. EdgeWrite, a new joystick text entry method, is not based on selection but on gestures from a unistroke alphabet. Our experiment shows that this new method is faster, leaves fewer errors, and is more satisfying than date stamp and selection keyboard (two prevalent selection-based methods) for novices after minimal practice. For more practiced users, our results show that EdgeWrite is at least 1.5 times faster than selection keyboard, and 2.4 times faster than date stamp.", "num_citations": "63\n", "authors": ["25"]}
{"title": "Integrating pointer variables into one-way constraint models\n", "abstract": " Pointer variables have long been considered useful for constructing and manipulating data structures in traditional programming languages. This article discusses how pointer variables can be integrated into one-way constraint models and indicates how these constraints can be usefully employed in user interfaces. Pointer variables allow constraints to model a wide array of dynamic application behavior, simplify the implementation of structured objects and demonstrational systems, and improve the storage and efficiency of constraint-based applications. This article presents two incremental algorithms\u0393\u00c7\u00f6one lazy and one eager\u0393\u00c7\u00f6 for solving constraints with pointer variables. Both algorithms are capable of handling (1) arbitrary systems of one-way constraints, including  constraints that involve cycles, and (2) editing models that allow multiple changes between calls to the constraint solver. These algorithms are fault\u252c\u00e1\u0393\u00c7\u00aa", "num_citations": "63\n", "authors": ["25"]}
{"title": "Displaying data structures for interactive debugging\n", "abstract": " Many modern computer languages have a variety of basic data types and allow the programmer to define morc. The facilitics for debugging programs written in thesc languages, however, seldon provide any capabilities to capture thc abstraction represented in the programmer's mind by the data types. Incense, the system described hcre, is a working prototype systcm that allows the programmer to interactivcly investigatc data structures in programs. The desired displays can be specificd by the programmer or a dcfault can be used. Thc dcfaults include using the standard form for literals of the basic types, the actual namcs for cnumcrated typcs, stacked boxes for rccords, and curved lines with arrowhcads for pointers. The intention is that the display produccd should be similar to the picture thc programmer would have drawn to cxplain the data type. \u253c\u00e9ncense displays havc thc additional fcaturc that they can change\u252c\u00e1\u0393\u00c7\u00aa", "num_citations": "60\n", "authors": ["25"]}
{"title": "More natural programming languages and environments\n", "abstract": " Over the last six years, we have been working to create programming languages and environments that are more natural, by which we mean closer to the way people think about their tasks. The goal is to make it possible for people to express their ideas in the same way they think about them. To achieve this, we performed various studies about howpeople think about programming tasks, and then used this knowledge to develop a new programming language and environment called HANDS. This chapter provides an overviewof the goals and background for the Natural Programming research, the results of some of our user studies, and the highlights of the language design.", "num_citations": "59\n", "authors": ["25"]}
{"title": "The user interface for Sapphire.\n", "abstract": " BackgroundPersonal workstations. Interest in window management systems has expanded with the proliferation of personal computers. Personal workstations are personal computers that are used by only one person at a time but provide far more power than typical home computers. A personal workstation will usually have a processor that can execute over one million instructions per second, a hard disk that can hold over 20 million bytes of data, a memory of at least one million bytes, some number of input/output options, such as RS-232, Ethernet, IEEE 488, floppies, etc., and a high-performance screen that is capable of graphics. Most personal workstations currently use high-resolution bit-map screens (about 800 x 1000) where each point on the screen (called a pixel) is associated with one bit of memory. Each pixel can be either on or off (white or black). Many personal workstations have some sort of hardware that allows screen operations to run swiftly, and some offer color screens as an option. Most personal workstations run an operating system, such as Unix, 5 that allows the user to run a number of different jobs (sometimes called processes) at the same time. For example, the user might specify that a compilation should continue to run (in the background) while the user enters the editor to work on a different file. Even with the high performance of a personal workstation, there will unfortunately always be jobs that cannot be processed instantly (ie, fast enough so the user does not notice the delay). With multiprocessing the user does not have to wait idly for jobs to be finished, so time can be used more effectively.", "num_citations": "59\n", "authors": ["25"]}
{"title": "Topes\n", "abstract": " Programmers often omit input validation when inputs can appear in many different formats or when validation criteria cannot be precisely specified. To enable validation in these situations, we present a new technique that puts valid inputs into a consistent format and that identifies \"questionable\" inputs which might be valid or invalid, so that these values can be double-checked by a person or a program. Our technique relies on the concept of a \"tope\", which is an application-independent abstraction describing how to recognize and transform values in a category of data. We present our definition of topes and describe a development environment that supports the implementation and use of topes. Experiments with web application and spreadsheet data indicate that using our technique improves the accuracy and reusability of validation code and also improves the effectiveness of subsequent data cleaning such as\u252c\u00e1\u0393\u00c7\u00aa", "num_citations": "58\n", "authors": ["25"]}
{"title": "The importance of pointer variables in constraint models\n", "abstract": " Graphical tools are increasingly using constraints to specify the graphical layout and behavior of many parts of an application. However, conventional constraints directly encode the objects they reference, and thus cannot provide support for the dynamic rttntime creation and manipulation of application objects. This paper discusses an extension to current constraint models that allows constraints to indirectly reference objects through pointer variables. Pointer variables permit programmers to create the constraint equivalent of procedures in traditional programming languages. This procedural abstraction allows constraints to model a wide array of dynamic application behavior, simplifies the implementation of structured object and demonstrational systems, and improves the storage and efficiency of highly interactive, graphical applications. It also promotes a simpler, more effective style of programming than\u252c\u00e1\u0393\u00c7\u00aa", "num_citations": "57\n", "authors": ["25"]}
{"title": "Extracting and answering why and why not questions about Java program output\n", "abstract": " When software developers want to understand the reason for a program's behavior, they must translate their questions about the behavior into a series of questions about code, speculating about the causes in the process. The Whyline is a new kind of debugging tool that avoids such speculation by instead enabling developers to select a question about program output from a set of \u0393\u00c7\u00a3why did and why didn't\u0393\u00c7\u00a5 questions extracted from the program's code and execution. The tool then finds one or more possible explanations for the output in question. These explanations are derived using a static and dynamic slicing, precise call graphs, reachability analyses, and new algorithms for determining potential sources of values. Evaluations of the tool on two debugging tasks showed that developers with the Whyline were three times more successful and twice as fast at debugging, compared to developers with traditional\u252c\u00e1\u0393\u00c7\u00aa", "num_citations": "56\n", "authors": ["25"]}
{"title": "Agent-assisted task management that reduces email overload\n", "abstract": " RADAR is a multiagent system with a mixed-initiative user interface designed to help office workers cope with email overload. RADAR agents observe experts to learn models of their strategies and then use the models to assist other people who are working on similar tasks. The agents' assistance helps a person to transition from the normal email-centric workflow to a more efficient task-centric workflow. The Email Classifier learns to identify tasks contained within emails and then inspects new emails for similar tasks. A novel task-management user interface displays the found tasks in a to-do list, which has integrated support for performing the tasks. The Multitask Coordination Assistant learns a model of the order in which experts perform tasks and then suggests a schedule to other people who are working on similar tasks. A novel Progress Bar displays the suggested schedule of incomplete tasks as well as the\u252c\u00e1\u0393\u00c7\u00aa", "num_citations": "55\n", "authors": ["25"]}
{"title": "Design requirements for more flexible structured editors from a study of programmers' text editing\n", "abstract": " A detailed study of Java programmers' text editing found that the full flexibility of unstructured text was not utilized for the vast majority of programmers' character-level edits. Rather, programmers used a small set of editing patterns to achieve their modifications, which accounted for all of the edits observed in the study. About two-thirds of the edits were of name and list structures and most edits preserved structure except for temporary omissions of delimiters. These findings inform the design of a new class of more flexible structured program editors that may avoid well-known usability problems of traditional structured editors, while providing more sophisticated support such as more universal code completion and smarter copy and paste.", "num_citations": "55\n", "authors": ["25"]}
{"title": "Calcite: Completing code completion for constructors using crowds\n", "abstract": " Calcite is a new Eclipse plugin that helps address the difficulty of understanding and correctly using an API. Calcite finds the most popular ways to instantiate a given class or interface by using code examples. To allow the users to easily add these object instantiations to their code, Calcite adds items to the popup completion menu that will insert the appropriate code into the user's program. Calcite also uses crowd sourcing to add to the menu instructions in the form of comments that help the user perform functions that people have identified as missing from the API. In a user study, Calcite improved users' success rate by 40%.", "num_citations": "54\n", "authors": ["25"]}
{"title": "Using handhelds for wireless remote control of PCs and appliances\n", "abstract": " This article provides an overview of the capabilities that we are developing as part of the Pebbles research project for wireless handheld devices such as mobile phones and palm-size computers like Palm Organizers and PocketPCs. Instead of just being used as a phone or organizer, handheld devices can also be used as remote controls for computers and household and office appliances.", "num_citations": "54\n", "authors": ["25"]}
{"title": "Supporting selective undo in a code editor\n", "abstract": " Programmers often need to revert some code to an earlier state, or restore a block of code that was deleted a while ago. However, support for this backtracking in modern programming environments is limited. Many of the backtracking tasks can be accomplished by having a selective undo feature in code editors, but this has major challenges: there can be conflicts among edit operations, and it is difficult to provide usable interfaces for selective undo. In this paper, we present AZURITE, an Eclipse plug-in that allows programmers to selectively undo fine-grained code changes made in the code editor. With AZURITE, programmers can easily perform backtracking tasks, even when the desired code is not in the undo stack or a version control system. AZURITE also provides novel user interfaces specifically designed for selective undo, which were iteratively improved through user feedback gathered from actual users in\u252c\u00e1\u0393\u00c7\u00aa", "num_citations": "53\n", "authors": ["25"]}
{"title": "Requirements for automatically generating multi-modal interfaces for complex appliances\n", "abstract": " Several industrial and academic research groups are working to simplify the control of appliances and services by creating a truly universal remote control. Unlike the preprogrammed remote controls available today, these new controllers download a specification from the appliance or service and use it to automatically generate a remote control interface. This promises to be a useful approach because the specification can be made detailed enough to generate both speech and graphical interfaces. Unfortunately, generating good user interfaces can be difficult. Based on user studies and prototype implementations, this paper presents a set of requirements that we have found are needed for automatic interface generation systems to create high-quality user interfaces.", "num_citations": "53\n", "authors": ["25"]}
{"title": "Scripting graphical applications by demonstration\n", "abstract": " Writing scripts (often called \u0393\u00c7\u00a3macros\u0393\u00c7\u00a5) can be helpful for automating repetitive tasks. Scripting facilities for text editors like Emacs and Microsoft Word have been widely used and available. However, for graphical applications, scripting has been tried many times but has never been successful. This is mainly due to the data description problem of determining how to generalize the particular objects selected at demonstration time. Previous systems have mostly tried to solve this using inferencing, but this has a number of problems, including guessing wrong and providing appropriate feedback and control to users. Therefore, the Topaz framework does not use inferencing and instead allows the user to specify how the appropriate objects should be found, This is achieved by recording changes to which objects are selected and searches for objects, so that scripts can be written with respect to the selected object, in the\u252c\u00e1\u0393\u00c7\u00aa", "num_citations": "52\n", "authors": ["25"]}
{"title": "Report of the \u0393\u00c7\u00a3End-User Programming\u0393\u00c7\u00a5 working group\n", "abstract": " Report of the \u0393\u00c7\u00a3End-User Programming\u0393\u00c7\u00a5 working group | Languages for developing user interfaces ACM Digital Library home ACM home Google, Inc. (search) Advanced Search Browse About Sign in Register Advanced Search Journals Magazines Proceedings Books SIGs Conferences People More Search ACM Digital Library SearchSearch Advanced Search Browse Browse Digital Library Collections More HomeBrowse by TitleBooksLanguages for developing user interfacesReport of the \u0393\u00c7\u00a3End-User Programming\u0393\u00c7\u00a5 working group chapter Report of the \u0393\u00c7\u00a3End-User Programming\u0393\u00c7\u00a5 working group Share on Authors: Brad Allan Myers profile image Brad A. Myers View Profile , David Canfield Smith profile image David Canfield Smith View Profile , Bruce Lawrence Horn profile image Bruce Horn View Profile Authors Info & Affiliations Publication: Languages for developing user interfacesJune 1992 Pages 343\u0393\u00c7\u00f4366 6citation 0 \u0393\u00c7\u00aa", "num_citations": "52\n", "authors": ["25"]}
{"title": "Programming IoT devices by demonstration using mobile apps\n", "abstract": " The revolutionary advances of Internet of Things (IoT) devices and applications have helped IoT emerge as an increasingly important domain for end-user development (EUD). Past research has shown that end users desire to create various customized automations, which would often utilize multiple IoT devices. Many solutions exist to support EUD across multiple IoT devices, but they are limited to devices from the same manufacturer, within the same \u0393\u00c7\u00a3eco-system\u0393\u00c7\u00a5 or supporting a common API. We present Epidosite, a mobile programming-by-demonstration system that addresses this limitation by leveraging the smartphone as a hub for IoT automation. It enables the creation of automations for most consumer IoT devices on smartphones by demonstrating the desired behaviors through directly manipulating the corresponding smartphone app for each IoT device. Epidosite also supports using the\u252c\u00e1\u0393\u00c7\u00aa", "num_citations": "51\n", "authors": ["25"]}
{"title": "Demonstrating the viability of automatically generated user interfaces\n", "abstract": " We conducted a user study that demonstrates that automatically generated interfaces can support better usability through increased flexibility in two dimensions. First, we show that automatic generation can improve usability by moving interfaces that are constrained by cost and poor interaction primitives to another device with better interactive capabilities: subjects were twice as fast and four times as successful at completing tasks with automatically generated interfaces on a PocketPC device as with the actual appliance interfaces. Second, we show that an automatic generator can improve usability by automatically ensuring that new interfaces are generated to be consistent with users' previous experience: subjects were also twice as fast using interfaces consistent with their experiences as compared to normally generated interfaces. These two results demonstrate that automatic interface generation is now viable\u252c\u00e1\u0393\u00c7\u00aa", "num_citations": "51\n", "authors": ["25"]}
{"title": "In search of learning: facilitating data analysis in educational games\n", "abstract": " The field of Educational Games has seen many calls for added rigor. One avenue for improving the rigor of the field is developing more generalizable methods for measuring student learning within games. Throughout the process of development, what is relevant to measure and assess may change as a game evolves into a finished product. The field needs an approach for game developers and researchers to be able to prototype and experiment with different measures that can stand up to rigorous scrutiny, as well as provide insight into possible new directions for development. We demonstrate a toolkit and analysis tools that capture and analyze students' performance within open educational games. The system records relevant events during play, which can be used for analysis of player learning by designers. The tools support replaying student sessions within the original game's environment, which allows\u252c\u00e1\u0393\u00c7\u00aa", "num_citations": "50\n", "authors": ["25"]}
{"title": "ConstraintJS: programming interactive behaviors for the web by integrating constraints and states\n", "abstract": " Interactive behaviors in GUIs are often described in terms of states, transitions, and constraints, where the constraints only hold in certain states. These constraints maintain relationships among objects, control the graphical layout, and link the user interface to an underlying data model. However, no existing Web implementation technology provides direct support for all of these, so the code for maintaining constraints and tracking state may end up spread across multiple languages and libraries. In this paper we describe ConstraintJS, a system that integrates constraints and finite-state machines (FSMs) with Web languages. A key role for the FSMs is to enable and disable constraints based on the interface's current mode, making it possible to write constraints that sometimes hold. We illustrate that constraints combined with FSMs can be a clearer way of defining many interactive behaviors with a series of examples.", "num_citations": "50\n", "authors": ["25"]}
{"title": "The run-time structure of UIMS-supported applications\n", "abstract": " This group was concerned with the run-time support provided by a UIMS, as opposed to design, analysis, evaluation or other support. In particular, we wer e concerned with the demands placed on a dialogue manage r by user interfaces that require a high level of semantic feedback.Traditionally, dialogue managers have attempted a strong separation of the seman component and the use r interface component. The assumption was that these wer e relatively independent, and that separating them would lea d to the benefits of modular programming; each component could be developed and changed independently of the other, multiple interfaces could be provided to the sam e application, consistent interface styles could be developed, and so on.", "num_citations": "50\n", "authors": ["25"]}
{"title": "Usability evaluation for enterprise SOA APIs\n", "abstract": " SAP recently began offering access to web services through its Enterprise Service-Oriented Architecture (E-SOA) plat-form. It is in the best interest of SAP that its E-SOA service operations are easier for developers to use and understand, which will contribute to higher E-SOA adoption, and a more effective means of innovation on the part of business customers. To facilitate such a change, Carnegie Mellon University's Human-Computer Interaction Institute is working with SAP's E-SOA and Business Process Reno-vation Teams to analyze the E-SOA interfaces using HCI techniques and determine means by which developers assigned to create SOA APIs in general, and Enterprise SOA APIs in particular, can design superior interfaces. The identification of usable design patterns, and methodologies to determine these patterns, can streamline SOA projects for API developers and programmers who use SOA APIs.", "num_citations": "48\n", "authors": ["25"]}
{"title": "Peridot: creating user interfaces by demonstration\n", "abstract": " Peridot | Watch what I do ACM Digital Library home ACM home Google, Inc. (search) Advanced Search Browse About Sign in Register Advanced Search Journals Magazines Proceedings Books SIGs Conferences People More Search ACM Digital Library SearchSearch Advanced Search Browse Browse Digital Library Collections More HomeBrowse by TitleBooksWatch what I do: programming by demonstrationPeridot: creating user interfaces by demonstration chapter Peridot: creating user interfaces by demonstration Share on Author: Brad Allan Myers profile image Brad A. Myers View Profile Authors Info & Affiliations Publication: Watch what I do: programming by demonstrationAugust 1993 Pages 125\u0393\u00c7\u00f4153 9citation 0 Downloads Metrics Total Citations9 Total Downloads0 Last 12 Months0 Last 6 weeks0 Get Citation Alerts New Citation Alert added! This alert has been successfully added and will be sent to: You will \u0393\u00c7\u00aa", "num_citations": "47\n", "authors": ["25"]}
{"title": "Exploring exploratory programming\n", "abstract": " In open-ended tasks where a program's behavior cannot be specified in advance, exploratory programming is a key practice in which programmers actively experiment with different possibilities using code. Exploratory programming is highly relevant today to a variety of professional and end-user programmer domains, including prototyping, learning through play, digital art, and data science. However, prior research has largely lacked clarity on what exploratory programming is, and what behaviors are characteristic of this practice. Drawing on this data and prior literature, we provide an organized description of what exploratory programming has meant historically and a framework of four dimensions for studying exploratory programming tasks: (1) applications, (2) required code quality, (3) ease or difficulty of exploration, and (4) the exploratory process. This provides a basis for better analyzing tool support for\u252c\u00e1\u0393\u00c7\u00aa", "num_citations": "46\n", "authors": ["25"]}
{"title": "Studying the use of handhelds to control smart appliances\n", "abstract": " Today's complex appliances are plagued by difficult-to-use interfaces. In many cases, consumers use only a few of the many features on their appliances because the more complex features are hidden by confusing interfaces. This problem can only get worse as appliances get smarter, become more complex, and are subject to more demands by their users. This paper presents two studies that compare the accuracy and speed of real users controlling two common appliances, a stereo and a telephone/answering machine, using two different interaction techniques. Our studies found that people using an appliance interface presented on a handheld computer performed the same set of tasks in half the time while making half the errors as compared to using the appliance's built-in control panel. These studies are motivating us to build a generic remote appliance control system that we call the personal universal\u252c\u00e1\u0393\u00c7\u00aa", "num_citations": "46\n", "authors": ["25"]}
{"title": "Text formatting by demonstration\n", "abstract": " In text formatters such as troff, Scribe, and TEX, users write macro procedures to specify the desired visual appearance. In What-You-See-Is-What-You-Get text formatters, such as MacWrite and Microsoft Word, the formatting is specified by directly manipulating the text. However, some important functionality is lost in these systems since they are not programmable, For example, if the user wants to change the formatting and content of all the chapter headings or page headings, each one must be individually edited. If they had been generated by macros, then editing the macro definition would change them all at once. This paper describes the design for a demonstrational text formatter that allows the user to directly manipulate the formatting of one example, and then the system automatically creates the macro by generalizing the example. This technique makes the formatting for headers, itemized lists, tables\u252c\u00e1\u0393\u00c7\u00aa", "num_citations": "46\n", "authors": ["25"]}
{"title": "Creating a lightweight user interface description language: An overview and analysis of the personal universal controller project\n", "abstract": " Over six years, we iterated on the design of a language for describing the functionality of appliances, such as televisions, telephones, VCRs, and copiers. This language has been used to describe more than thirty diverse appliances, and these descriptions have been used to automatically generate both graphical and speech user interfaces on handheld computers, mobile phones, and desktop computers. In this article, we describe the final design of our language and analyze the key design choices that led to this design. Through this analysis, we hope to provide a useful guide for the designers of future user interface description languages.", "num_citations": "45\n", "authors": ["25"]}
{"title": "Few-key text entry revisited: mnemonic gestures on four keys\n", "abstract": " We present a new 4-key text entry method that, unlike most few-key methods, is gestural instead of selection-based. Importantly, its gestures mimic the writing of Roman letters for high learnability. We compare this new 4-key method to predominant 3-key and 5-key methods theoretically using KSPC and empirically using a longitudinal study of 5 subjects over 10 sessions. The study includes an evaluation of the 4-key method without any on-screen visualization-an impossible condition for the selection-based methods. Our results show that the new 4-key method is quickly learned, becoming faster than the 3-key and 5-key methods after just~ 10 minutes of writing, although it produces more errors. Interestingly, removing a visualization of the gestures being made causes no detriment to the 4-key method, which is an advantage for eyes-free text entry.", "num_citations": "45\n", "authors": ["25"]}
{"title": "Interactive recovery from speech recognition errors in speech user interfaces\n", "abstract": " The authors present a multimodal approach to interactive recovery from speech recognition errors for the design of speech user interfaces. They propose a framework to compare various error recovery methods, arguing that a rational user will prefer interaction methods which provide an optimal trade off between accuracy, speed and naturalness. They describe a prototypical implementation of multimodal interactive error recovery and present results from a preliminary evaluation in form filling and speech to speech translation tasks.", "num_citations": "45\n", "authors": ["25"]}
{"title": "An exploratory study of backtracking strategies used by developers\n", "abstract": " Developers frequently backtrack while coding. They go back to an earlier state by removing inserted code or by restoring removed code for various reasons. However, little is known about when and how the developers backtrack, and modern IDEs do not provide much assistance for backtracking. As a first step towards gathering baseline knowledge about backtracking and designing more robust backtracking assistance tools in modern IDEs, we conducted an exploratory study with 12 professional developers and a follow-up online survey. Our study revealed several barriers they faced while backtracking. Subjects often manually commented and uncommented code, and often had difficulty finding relevant parts to backtrack. Backtracking was reported to be needed by 3/4 of the developers at least \u0393\u00c7\u00a3sometimes\u0393\u00c7\u00a5.", "num_citations": "43\n", "authors": ["25"]}
{"title": "Extending an existing user interface toolkit to support gesture recognition\n", "abstract": " Gestures are a powerful way to specify both objects and operations with a single mark of a stylus or mouse. We have extended an existing user interface toolkit to support gestures asa standard type of interaction so that researchers can easily explore this technology..", "num_citations": "43\n", "authors": ["25"]}
{"title": "The role of conceptual knowledge in API usability\n", "abstract": " While many studies have investigated the challenges that developers face in finding and using API documentation, few have considered the role of developers' conceptual knowledge in these tasks. We designed a study in which developers were asked to explore the feasibility of two requirements concerning networking protocols and application platforms that most participants were unfamiliar with, observing the effect that a lack of conceptual knowledge had on their use of documentation. Our results show that without conceptual knowledge, developers struggled to formulate effective queries and to evaluate the relevance or meaning of content they found. Our results suggest that API documentation should not only include detailed examples of API use, but also thorough introductions to the concepts, standards, and ideas manifested in an API's data structures and functionality.", "num_citations": "42\n", "authors": ["25"]}
{"title": "Using objects of measurement to detect spreadsheet errors\n", "abstract": " There are many common spreadsheet errors that traditional spreadsheet systems do not help users find. This paper presents a statically-typed spreadsheet language that adds additional information about the objects that the spreadsheet values represent. By annotating values with both units and labels, users denote both the system of measurement in which the values are expressed as well as the properties of the objects to which the values refer. This information is used during computation to detect some invalid computations and allow users to identify properties of the resulting values.", "num_citations": "42\n", "authors": ["25"]}
{"title": "Exploring language support for immutability\n", "abstract": " Programming languages can restrict state change by preventing it entirely (immutability) or by restricting which clients may modify state (read-only restrictions). The benefits of immutability and read-only restrictions in software structures have been long-argued by practicing software engineers, researchers, and programming language designers. However, there are many proposals for language mechanisms for restricting state change, with a remarkable diversity of techniques and goals, and there is little empirical data regarding what practicing software engineers want in their tools and what would benefit them. We systematized the large collection of techniques used by programming languages to help programmers prevent undesired changes in state. We interviewed expert software engineers to discover their expectations and requirements, and found that important requirements, such as expressing immutability\u252c\u00e1\u0393\u00c7\u00aa", "num_citations": "41\n", "authors": ["25"]}
{"title": "Creating interactive web data applications with spreadsheets\n", "abstract": " While more and more data are available through web services, it remains difficult for end-users to create web applications that make use of these data without having to write complex code. We present Gneiss, a live programming environment that extends the spreadsheet metaphor to support creating interactive web applications that dynamically use local or web data from multiple sources. Gneiss closely integrates a spreadsheet editor with a web interface builder to let users demonstrate bindings between properties of web GUI elements and cells in the spreadsheet while working with real web service data. The spreadsheet editor provides two-way connections to web services, to both visualize and retrieve different data based on the user input in the web interface. Gneiss achieves rich interactivity without the need for event-based programming by extending the'pull model'of formulas that is familiar to the\u252c\u00e1\u0393\u00c7\u00aa", "num_citations": "41\n", "authors": ["25"]}
{"title": "Visual programming in a visual domain: a case study of cognitive dimension\n", "abstract": " We present a new visual programming language and environment that serves as a form of feedback and representation in a Programming by Demonstration system. The language di ers from existing visual languages because it explicitly represents data objects and implicitly represents operations by changes in data objects. The system was designed to provide non-programmers with programming support for common, repetitive tasks and incorporates some principles of cognition to assist these users in learning to use it. With this in mind, we analyzed the language and its editor along cognitive dimensions. The assessment provided insight into both strengths and weaknesses of the system, prompting a number of design changes. This demonstrates how useful such an analysis can be.", "num_citations": "41\n", "authors": ["25"]}
{"title": "Video Editing Using Lenses and Semantic Zooming\n", "abstract": " Digital video is becoming increasingly prevalent. Unfortunately, editing video remains difficult for several reasons: it is a time-based medium, it has dual tracks of audio and video, and current tools force users to work at the smallest level of detail. Based on interviews with professional video editors and observations of the use of our own editor, we have developed new interaction techniques for digital video based on semantic zooming and lenses. When copying or cutting a piece of video, it is desirable to select both ends precisely. However, although many video editing tools allow zooming into a fine level of detail, they do not allow zooming at more than one location simultaneously. Our system provides multiple lenses on the same timeline, so the user can see more than one location in detail.", "num_citations": "39\n", "authors": ["25"]}
{"title": "Demonstrational and constraint-based techniques for pictorially specifying application objects and behaviors\n", "abstract": " The Lapidary interface design tool is a demonstrational system that allows the graphics and run-time behaviors that go inside an application window to be specified pictorially. In particular, Lapidary allows the designer to draw example pictures of application-specific graphical objects that the end user will manipulate (such as boxes, arrows, or elements of a list), the feedback that shows which objects are selected (such as small boxes on the sides and corners of an object), and the dynamic feedback objects (such as hairline boxes to show where an object is being dragged). The run-time behavior of all these objects can be specified ina straightforward way using constraints, demonstration, and dialog boxes that allow the designer to provide abstract descriptions of the interactive response to the input devices. Lapidary generalizes from these specific example pictures and behaviors to create prototype objects and\u252c\u00e1\u0393\u00c7\u00aa", "num_citations": "39\n", "authors": ["25"]}
{"title": "Towards effective foraging by data scientists to find past analysis choices\n", "abstract": " Data scientists are responsible for the analysis decisions they make, but it is hard for them to track the process by which they achieved a result. Even when data scientists keep logs, it is onerous to make sense of the resulting large number of history records full of overlapping variants of code, output, plots, etc. We developed algorithmic and visualization techniques for notebook code environments to help data scientists forage for information in their history. To test these interventions, we conducted a think-aloud evaluation with 15 data scientists, where participants were asked to find specific information from the history of another person's data science project. The participants succeed on a median of 80% of the tasks they performed. The quantitative results suggest promising aspects of our design, while qualitative results motivated a number of design improvements. The resulting system, called Verdant, is released\u252c\u00e1\u0393\u00c7\u00aa", "num_citations": "38\n", "authors": ["25"]}
{"title": "WebCrystal: understanding and reusing examples in web authoring\n", "abstract": " Examples have been widely used in the area of web design to help web authors create web pages. However, without actually understanding how an example is constructed, people often have trouble extracting the elements they want and incorporating them into their own design. This paper introduces WebCrystal, a web development tool that helps users understand how a web page is built. WebCrystal contributes novel interaction techniques that let the user quickly access HTML and CSS information by selecting questions regarding how a selected element is designed. It provides answers using a textual description and a customized code snippet that can be copied-and-pasted to recreate the desired properties. WebCrystal also supports combining the styles and structures from multiple elements into the generated code snippet, and provides visualizations on the web page itself to explain layout relationships\u252c\u00e1\u0393\u00c7\u00aa", "num_citations": "38\n", "authors": ["25"]}
{"title": "The pebbles project: using PCs and hand-held computers together\n", "abstract": " Increasingly, people will be in situations where they have multiple communicating computing devices available at the same time. The Pebbles research project is investigating many ways that a hand-held computer such as a Personal Digital Assistant (PDA) can serve as a useful adjunct to the PC in those situations. We have created a large set of applications to support group work in meetings and individual work at the desktop. These run on both Palm Pilots and Windows CE devices, along with a PC. As an example, each hand-held computer can control the main PC's cursor and keyboard to support collaboration. For an individual giving a slide show, the notes and controls for the show can be on the hand-held, while the main computer is running the show. This demonstration will show the large variety of Pebbles applications.", "num_citations": "38\n", "authors": ["25"]}
{"title": "The Garnet toolkit reference manuals: Support for highly-interactive, graphical user interfaces in Lisp\n", "abstract": " The Garnet User Interface Development Environment contains a comprehensive set of tools that make it significantly easier to design and implement highly-interactive, graphical, direct manipulation user interfaces. Garnet provides a high level of support, while still being Look-and-Feel independent and providing the applications with tremendous flexibility. The Garnet tools are organized into two layers. The toolkit layer provides an object-oriented, constraint-based graphical system that allows properties of graphical objects to be specified in a simple, declarative manner, and then maintained automatically by the system. The dynamic, interactive behavior of the objects can be specified separately by attaching high-level\" interactor\" objects to the graphics. The higher layer of Garnet includes an interface builder tool, called Lapidary, that allows the user interface designer to draw pictures of all graphical aspects of the user interface.The Garnet toolkit layer software is now available for distribution. It uses Common Lisp and the X window manager, and is therefore portable across a wide variety of platforms. This document contains an overview, tutorial and a full set of reference manuals for the Garnet Toolkit.", "num_citations": "38\n", "authors": ["25"]}
{"title": "Software security in practice\n", "abstract": " This department is about building software with security in mind. Since it began in 2004, it has focused on the kinds of activities that constitute a secure development life cycle. As of to day, we're broadening that charter to include all the essential ingredients of a sustained soft ware security initiative. Instead of focusing on one turn of the crank that yields one new piece of software, we'll consider the ongoing organizational commitments necessary to facilitate se cure software development.", "num_citations": "37\n", "authors": ["25"]}
{"title": "Improving documentation for eSOA APIs through user studies\n", "abstract": " All software today is written using libraries, toolkits, frameworks and other application programming interfaces (APIs). We performed a user study of the online documentation a large and complex API for Enterprise Service-Oriented Architecture (eSOA), which identified many issues and recommendations for making API documentation easier to use. eSOA is an appropriate testbed because the target user groups range from high-level business experts who do not have significant programming expertise (and thus are end-participant developers), to professional programmers. Our study showed that the participants\u0393\u00c7\u00d6 background influenced how they navigated the documentation. Lack of familiarity with business terminology was a barrier we observed for developers without business application experience. Participants with business software experience had difficulty differentiating similarly named services. Both\u252c\u00e1\u0393\u00c7\u00aa", "num_citations": "37\n", "authors": ["25"]}
{"title": "Examining programmer practices for locally handling exceptions\n", "abstract": " Many have argued that the current try/catch mechanism for handling exceptions in Java is flawed. A major complaint is that programmers often write minimal and low quality handlers. We used the Boa tool to examine a large number of Java projects on GitHub to provide empirical evidence about how programmers currently deal with exceptions. We found that programmers handle exceptions locally in catch blocks much of the time, rather than propagating by throwing an Exception. Programmers make heavy use of actions like Log, Print, Return, or Throw in catch blocks, and also frequently copy code between handlers. We found bad practices like empty catch blocks or catching Exception are indeed widespread. We discuss evidence that programmers may misjudge risk when catching Exception, and face a tension between handlers that directly address local program statement failure and handlers that consider\u252c\u00e1\u0393\u00c7\u00aa", "num_citations": "36\n", "authors": ["25"]}
{"title": "JASPER: an Eclipse plug-in to facilitate software maintenance tasks\n", "abstract": " Recent research has shown that developers spend significant amounts of time navigating around code. Much of this time is spent on redundant navigations to code that the developer previously found. This is necessary today because existing development environments do not enable users to easily collect relevant information, such as web pages, textual notes, and code fragments. JASPER is a new system that allows users to collect relevant artifacts into a working set for easy reference. These artifacts are visible in a single view that represents the user's current task and allows users to easily make each artifact visible within its context. We predict that JASPER will significantly reduce time spent on redundant navigations. In addition, JASPER will facilitate multitasking, interruption management, and sharing task information with other developers.", "num_citations": "36\n", "authors": ["25"]}
{"title": "In-stroke word completion\n", "abstract": " We present the design and implementation of a word-level stroking system called Fisch, which is intended to improve the speed of character-level unistrokes. Importantly, Fisch does not alter the way in which character-level unistrokes are made, but allows users to gradually ramp up to word-level unistrokes by extending their letters in minimal ways. Fisch relies on in-stroke word completion, a flexible design for fluidly turning unistroke letters into whole words. Fisch can be memorized at the motor level since word completions always appear at the same positions relative to the strokes being made. Our design for Fisch is suitable for use with any unistroke alphabet. We have implemented Fisch for multiple versions of EdgeWrite, and results show that Fisch reduces the number of strokes during entry by 43.9% while increasing the rate of entry. An informal test of\" record speed\" with the stylus version resulted in 50-60\u252c\u00e1\u0393\u00c7\u00aa", "num_citations": "35\n", "authors": ["25"]}
{"title": "Programming by example: intelligence in demonstrational interfaces\n", "abstract": " In some of them, the system uses sophisticated AI algorithms, so complex behavior can be inferred from a few examples. In others, the user has to provide the full specification, and the examples are used primarily to help the user understand the programming situation. Here, we discuss what we\u0393\u00c7\u00d6ve learned about which situations require correct (assuming there are no bugs in the software), but the user has to make all the decisions. The use of inferencing falls into the general category of \u0393\u00c7\u00a3intelligent interfaces,\u0393\u00c7\u00a5 a term referring to any user interface with some intelligent or AI component, including demonstrational interfaces with inferencing, as well as other interfaces, including those using natural language. Systems with inferencing are often said to be guessing what the user wants. Many demonstrational systems use heuristics, or the rules they use to try to determine what the user actually means. The demonstrational\u252c\u00e1\u0393\u00c7\u00aa", "num_citations": "35\n", "authors": ["25"]}
{"title": "Building applications using only demonstration\n", "abstract": " By combining the strengths of multiple interaction techniques and inferencing algorithms, Gamut can infer behaviors from examples that previously required a developer to annotate or otherwise modify code by hand. Gamut is a programming-by-demonstration (PBD) tool for building whole applications. It revises code automatically when new examples are demonstrated using a recursive procedure that efficiently scans for the differences between a new example and the original behavior. Differences that cannot be resolved by generating a suitable description are handled by another AI algorithm, decision tree learning, providing a significantly greater ability to infer complex relationships. Gamut\u0393\u00c7\u00d6s interaction techniques facilitate demonstrating many examples quickly and allow the user to give the system hints that show relationships that would be too time consuming to discover by search alone. Altogether, the\u252c\u00e1\u0393\u00c7\u00aa", "num_citations": "35\n", "authors": ["25"]}
{"title": "Model-based user interfaces: What are they and why should we care?\n", "abstract": " Model-based user interfaces have been around for several years. Various research prototypes have been documented and a number of workshops have been organized around thisPermission to copy without fee all or part of this material is granted provided that the copies are not made or distributed for direct commercial advantage, the ACM copyright notice and the title of the publication and its date appear, and notice is given that copying is by permission of the Association for Computing Machinery. To copy otherwise, or to republish, requires a fee and/or specific permission.", "num_citations": "35\n", "authors": ["25"]}
{"title": "InterState: a language and environment for expressing interface behavior\n", "abstract": " InterState is a new programming language and environment that addresses the challenges of writing and reusing user interface code. InterState represents interactive behaviors clearly and concisely using a combination of novel forms of state machines and constraints. It also introduces new language features that allow programmers to easily modularize and reuse behaviors. InterState uses a new visual notation that allows programmers to better understand and navigate their code. InterState also includes a live editor that immediately updates the running application in response to changes in the editor and vice versa to help programmers understand the state of their program. Finally, InterState can interface with code and widgets written in other languages, for example to create a user interface in InterState that communicates with a database. We evaluated the understandability of InterState's programming\u252c\u00e1\u0393\u00c7\u00aa", "num_citations": "34\n", "authors": ["25"]}
{"title": "Apatite: A new interface for exploring APIs\n", "abstract": " We present Apatite, a new tool that aids users in learning and understanding a complex API by visualizing the common associations between its various components. Current object-oriented API documentation is usually navigated in a fixed tree structure, starting with a package and then filtering by a specific class. For large APIs, this scheme is overly restrictive, because it prevents users from locating a particular action without first knowing which class it belongs to. Apatite's design instead enables users to search across any level of an API's hierarchy. This is made possible by the introduction of a novel interaction technique that presents popular items from multiple categories simultaneously, determining their relevance by approximating the strength of their association using search engine data. The design of Apatite was refined through iterative usability testing, and it has been released publicly as a web application.", "num_citations": "34\n", "authors": ["25"]}
{"title": "A longitudinal study of programmers' backtracking\n", "abstract": " Programming often involves reverting source code to an earlier state, which we call backtracking. We performed a longitudinal study of programmers' backtracking, analyzing 1,460 hours of fine-grained code editing logs collected from 21 people. Our analysis method keeps track of the change history of each abstract syntax tree node and looks for backtracking instances within each node. Using this method, we detected a total of 15,095 backtracking instances, which gives an average backtracking rate of 10.3/hour. The size of backtracking varied con-siderably, ranging from a single character to thousands of char-acters. 34% of the backtracking was performed by manually deleting or typing the desired code, and 9.5% of all backtracking was selective, meaning that it could not have been performed using the conventional undo command present in the IDE. The study results show that programmers need better\u252c\u00e1\u0393\u00c7\u00aa", "num_citations": "33\n", "authors": ["25"]}
{"title": "User interface software technology\n", "abstract": " The user interface of an application is the part that the person using the software sees and interacts with. The part of the software that makes the user interface work is often large, complex, and difficult to implement, debug, and modify. Today direct manipulation interfaces (also called graphical user in-terface (GUI\u0393\u00c7\u00d6s)) are almost universal, and the part of the software that handles the user interface generally takes a significant percentage of the total system design and implementation time [Myers and Rosson 1992]. Therefore, specialized software tools have been created to ease the programmer\u0393\u00c7\u00d6s burden, and today virtually all new user interface software uses tools that make the implementation easier. Many of these tools have demonstrated significant productivity gains for programmers and have become important commercial products. Although most commercial tools concentrate on building the surface look of the\u252c\u00e1\u0393\u00c7\u00aa", "num_citations": "33\n", "authors": ["25"]}
{"title": "Interactions for untangling messy history in a computational notebook\n", "abstract": " Experimentation through code is central to data scientists' work. Prior work has identified the need for interaction techniques for quickly exploring multiple versions of the code and the associated outputs. Yet previous approaches that provide history information have been challenging to scale: real use produces a high number of versions of different code and non-code artifacts with dependency relationships and a convoluted mix of different analysis intents. Prior work has found that navigating these records to pick out the relevant information for a given task is difficult and time consuming. We introduce Verdant, a new system with a novel versioning model to support fast retrieval and sensemaking of messy version data. Verdant provides light-weight interactions for comparing, replaying, and tracing relationships among many versions of different code and non-code artifacts in the editor. We implemented Verdant into\u252c\u00e1\u0393\u00c7\u00aa", "num_citations": "32\n", "authors": ["25"]}
{"title": "Glacier: transitive class immutability for java\n", "abstract": " Though immutability has been long-proposed as a way to prevent bugs in software, little is known about how to make immutability support in programming languages effective for software engineers. We designed a new formalism that extends Java to support transitive class immutability, the form of immutability for which there is the strongest empirical support, and implemented that formalism in a tool called Glacier. We applied Glacier successfully to two real-world systems. We also compared Glacier to Java's final in a user study of twenty participants. We found that even after being given instructions on how to express immutability with final, participants who used final were unable to express immutability correctly, whereas almost all participants who used Glacier succeeded. We also asked participants to make specific changes to immutable classes and found that participants who used final all incorrectly mutated\u252c\u00e1\u0393\u00c7\u00aa", "num_citations": "32\n", "authors": ["25"]}
{"title": "User interface history\n", "abstract": " User Interfaces have been around as long as computers have existed, even well before the field of Human-Computer Interaction was established. Over the years, some papers on the history of Human-Computer Interaction and User Interfaces have appeared, primarily focusing on the graphical interface era and early visionaries such as Bush, Engelbart and Kay. With the User Interface being a decisive factor in the proliferation of computers in society and since it has become a cultural phenomenon, it is time to paint a more comprehensive picture of its history. This SIG will investigate the possibilities of launching a concerted effort towards creating a History of User Interfaces.", "num_citations": "32\n", "authors": ["25"]}
{"title": "From letters to words: Efficient stroke-based word completion for trackball text entry\n", "abstract": " We present a major extension to our previous work on Trackball EdgeWrite--a unistroke text entry method for trackballs--by taking it from a character-level technique to a word-level one. Our design is called stroke-based word completion, and it enables efficient word selection as part of the stroke-making process. Unlike most word completion designs, which require users to select words from a list, our technique allows users to select words by performing a fluid crossing gesture. Our theoretical model shows this word-level design to be 45.0% faster than our prior model for character-only strokes. A study with a subject with spinal cord injury comparing Trackball EdgeWrite to the onscreen keyboard WiViK, both using word prediction and completion, shows that Trackball EdgeWrite is competitive with WiViK in speed (12.09 vs. 11.82 WPM) and accuracy (3.95% vs. 2.21% total errors), but less visually tedious and\u252c\u00e1\u0393\u00c7\u00aa", "num_citations": "32\n", "authors": ["25"]}
{"title": "The influence of the psychology of programming on a language design: Project status report\n", "abstract": " Research in Psychology of Programming (PoP) and related fields over the past thirty years has identified many important usability issues for programming languages and tools. However, when new programming languages are designed these findings do not seem to have much impact, so popular modern languages continue to exhibit many of the same old problems. This paper reviews the progress of an ongoing project to elevate the influence of PoP on the design of a new programming language. In the context of designing a new programming language for children, we cataloged and interpreted the prior work, performed new studies where questions remained unanswered, and have focused on usability throughout the design. In addition to producing a system that is easier to learn and use than existing systems, we hope to exemplify a process that could be adopted by other language designers to improve the usability of their systems.", "num_citations": "32\n", "authors": ["25"]}
{"title": "API usability: CHI'2009 special interest group meeting\n", "abstract": " Programmers of all types from novice end-user developers to professional software engineers make use of application programming interfaces (API) within their various designs. And, while the use of these interfaces is ubiquitous, there is little research about their design. Recently, a number of researchers and practitioners have begun to treat API design as a first-order object of study and practice. The purpose of this special interest group meeting is to bring together the community of usability researchers and professionals interested in API usability. The time will be used to discuss attendees' ideas and opinions in order to stimulate this new and exciting emerging field that crosses the boundaries between human-computer interaction and software engineering.", "num_citations": "31\n", "authors": ["25"]}
{"title": "51. Graphical User Interface Programming\n", "abstract": " Almost as long as there have been user interfaces, there have been special software systems and tools to help design and implement the user interface software. Many of these tools have demonstrated significant productivity gains for programmers, and have become important commercial products. Others have proven less successful at supporting the kinds of user interfaces people want to build. Virtually all applications today are built using some form of user interface tool [Myers 2000].User interface (UI) software is often large, complex and difficult to implement, debug, and modify. As interfaces become easier to use, they become harder to create [Myers 1994]. Today, direct manipulation interfaces (also called \u0393\u00c7\u00a3GUIs\u0393\u00c7\u00a5 for Graphical User Interfaces) are almost universal. These interfaces require that the programmer deal with elaborate graphics, multiple ways for giving the same command, multiple asynchronous input devices (usually a keyboard and a pointing device such as a mouse), a \u0393\u00c7\u00a3mode free\u0393\u00c7\u00a5 interface where the user can give any command at virtually any time, and rapid \u0393\u00c7\u00a3semantic feedback\u0393\u00c7\u00a5 where determining the appropriate response to user actions requires specialized information about the objects in the program. Interfaces on handheld devices, such as a Palm organizer or a Microsoft PocketPC device, use similar metaphors and implementation strategies. Tomorrow\u0393\u00c7\u00d6s user interfaces will provide speech recognition, vision from cameras, 3-D, intelligent agents and integrated multi-media, and will probably be even more difficult to create. Furthermore, because user interface design is so difficult, the only reliable way to get good interfaces\u252c\u00e1\u0393\u00c7\u00aa", "num_citations": "31\n", "authors": ["25"]}
{"title": "A system-wide macro facility based on aggregate events: A proposal\n", "abstract": " A system-wide macro facility based on aggregate events | Watch what I do ACM Digital Library home ACM home Google, Inc. (search) Advanced Search Browse About Sign in Register Advanced Search Journals Magazines Proceedings Books SIGs Conferences People More Search ACM Digital Library SearchSearch Advanced Search Browse Browse Digital Library Collections More HomeBrowse by TitleBooksWatch what I do: programming by demonstrationA system-wide macro facility based on aggregate events: a proposal chapter A system-wide macro facility based on aggregate events: a proposal Share on Authors: David S. Kosbie View Profile , Brad A. Myers View Profile Authors Info & Affiliations Watch what I do: programming by demonstrationAugust 1993 Pages 433\u0393\u00c7\u00f4444 Published:30 August 1993 7citation 0 Downloads Metrics Total Citations7 Total Downloads0 Last 12 Months0 Last 6 weeks0 Get Alerts ! \u0393\u00c7\u00aa", "num_citations": "31\n", "authors": ["25"]}
{"title": "An approach for categorizing end user programmers to guide software engineering research\n", "abstract": " Over 64 million Americans used computers at work in 1997, and we estimate this number will grow to 90 million in 2012, including over 55 million spreadsheet and database users and 13 million self-reported programmers. Existing characterizations of this end user population based on software usage provide minimal guidance on how to help end user programmers practice better software engineering. We describe an enhanced method of characterizing the end user population, based on categorizing end users according to the ways they represent abstractions. Since the use of abstraction can facilitate or impede achieving key software engineering goals (such as improving reusability and maintainability), this categorization promises an improved ability to highlight niches of end users with special software engineering capabilities or struggles. We have incorporated this approach into an in-progress survey of end\u252c\u00e1\u0393\u00c7\u00aa", "num_citations": "30\n", "authors": ["25"]}
{"title": "Enabling rich human-agent interaction for a calendar scheduling agent\n", "abstract": " The RhaiCAL system provides novel visualizations and interaction techniques for interacting with an intelligent agent, with an emphasis on calendar scheduling. After an agent interprets natural language containing meeting information, a user can easily correct mistakes using RhaiCAL's clarification dialogs, which provide the agent with feedback to improve its performance. When an agent proposes actions to take on the user's behalf, it can ask the user to confirm them. RhaiCAL uses novel visualizations to present the proposal to the user and allow them to modify the proposal, and informs the agent of the user's actions in a manner that supports long-term learning of the user's preferences. We have designed a high-level XML-based language that allows an agent to express its questions and proposed actions without mentioning user interface details, and that enables RhaiCAL to generate high-quality user interfaces.", "num_citations": "30\n", "authors": ["25"]}
{"title": "Graphical representation of programs in a demonstrational visual shell\u0393\u00c7\u00f6an empirical evaluation\n", "abstract": " An open question in the area of Programming by Demonstration (PBD) is how to best represent the inferred program. Without a way to view, edit, and share programs, PBD systems will never reach their full potential. We designed and implemented two graphical representation languages for a PBD desktop similar to the Apple Macintosh Finder. Although a user study showed that both languages enabled nonprogrammers to generate and comprehend programs, the study also revealed that the language that more closely reflected the desktop domain doubled users' abilities to accurately generate programs. Trends suggest that the same language was easier for users to comprehend. These findings suggest that it is possible for a PBD system to enable nonprogrammers to construct programs and that the form of  the representation can impact the PBD system's effectiveness. A paper-and-pencil evaluation of the two\u252c\u00e1\u0393\u00c7\u00aa", "num_citations": "30\n", "authors": ["25"]}
{"title": "Pumice: A multi-modal agent that learns concepts and conditionals from natural language and demonstrations\n", "abstract": " Natural language programming is a promising approach to enable end users to instruct new tasks for intelligent agents. However, our formative study found that end users would often use unclear, ambiguous or vague concepts when naturally instructing tasks in natural language, especially when specifying conditionals. Existing systems have limited support for letting the user teach agents new concepts or explaining unclear concepts. In this paper, we describe a new multi-modal domain-independent approach that combines natural language programming and programming-by-demonstration to allow users to first naturally describe tasks and associated conditions at a high level, and then collaborate with the agent to recursively resolve any ambiguities or vagueness through conversations and demonstrations. Users can also define new procedures and concepts by demonstrating and referring to contents within\u252c\u00e1\u0393\u00c7\u00aa", "num_citations": "29\n", "authors": ["25"]}
{"title": "Intelligently creating and recommending reusable reformatting rules\n", "abstract": " When users combine data from multiple sources into a spreadsheet or dataset, the result is often a mishmash of different formats, since phone numbers, dates, course numbers and other string-like kinds of data can each be written in many different formats. Although spreadsheets provide features for reformatting numbers and a few specific kinds of string data, they do not provide any support for the wide range of other kinds of string data encountered by users. We describe a user interface where a user can describe the formats of each kind of data. We provide an algorithm that uses these formats to automatically generate reformatting rules that transform strings from one format to another. In effect, our system enables users to create a small expert system called a\" tope\" that can recognize and reformat instances of one kind of data. Later, as the user is working with a spreadsheet, our system recommends appropriate\u252c\u00e1\u0393\u00c7\u00aa", "num_citations": "29\n", "authors": ["25"]}
{"title": "Research directions for user interface software tools\n", "abstract": " Abstract", "num_citations": "29\n", "authors": ["25"]}
{"title": "Graphical styles for building interfaces by demonstration\n", "abstract": " Conventional interface builders allow the user interface designer to select widgets such as menus, buttons and scroll bars, and lay them out using a mouse. Although these are conceptually simple to use, in practice there are a number of problems. First, a typical widget will have dozens of properties which the designer might change. Insuring that these properties are consistent across multiple widgets in a dialog box and multiple dialog boxes in an application can be very difficult. Second, if the designer wants to change the properties, each widget must be edited individually. Third, getting the widgets laid out appropriately in a dialog box can be tedious. Grids and alignment commands are not sufficient. This paper describes Graphical Tabs and Graphical Styles in the Gild interface builder which solve all of these problems. A \u0393\u00c7\u00a3graphical tab\u0393\u00c7\u00a5 is an absolute position in a window. A \u0393\u00c7\u00a3graphical style\u0393\u00c7\u00a5 incorporates both\u252c\u00e1\u0393\u00c7\u00aa", "num_citations": "29\n", "authors": ["25"]}
{"title": "Tools for creating user interfaces: An introduction and survey\n", "abstract": " Creating good user interfaces for software programs is a very difficult task. There arc no guidelines or techniques that will guarantee that the software will be\" easy-to-use,'* and software implementors have generally proven poor at providing user interfaces that people like. Consequently, user interface software must often be prototyped and modified repeatedly. In addition, user interface software is inherently difficult to write, because it frequently requires that multiple devices be controlled (for example, a keyboard and a mouse) each of which may be sending streams of input events asynchronously. Also, user interfaces typically have stringent performance requirements to insure that there is no perceived lag between a user's actions and the system's response. The most popular style of user interfaces (called\" Direct Manipulation\" interfaces) is one of the most difficult kinds to implement Therefore, there is a great interest in software tools to aid in this process. This article discusses several different types of software tools and examples of their use.", "num_citations": "29\n", "authors": ["25"]}
{"title": "Extending programming by demonstration with hierarchical event histories\n", "abstract": " Programming by Demonstration, or PBD, is an exciting and developing branch of HCI research. With PBD techniques, end-users can add functionality to their environments without programming in the conventional sense. Virtually all research into PBD, however, presumes that the event history is a linear sequence of user actions. This paper challenges that notion by introducing Hierarchical Event Histories, a new approach which represents some of the end-user's task structure directly in the event history. PBD systems can then take advantage of this structure to operate more correctly and in more situations. To assist programmers in generating structured histories, we also present Hieractors, a new model that provides a simple and clear syntax for describing arbitrary, high-level application behaviors.", "num_citations": "28\n", "authors": ["25"]}
{"title": "Graphical representation and feedback in a PBD system\n", "abstract": " Graphical representation and feedback in a PBD system | Watch what I do ACM Digital Library home ACM home Google, Inc. (search) Advanced Search Browse About Sign in Register Advanced Search Journals Magazines Proceedings Books SIGs Conferences People More Search ACM Digital Library SearchSearch Advanced Search Browse Browse Digital Library Collections More HomeBrowse by TitleBooksWatch what I do: programming by demonstrationGraphical representation and feedback in a PBD system chapter Graphical representation and feedback in a PBD system Share on Authors: Francesmary Modugno profile image Francesmary Modugno View Profile , Brad Allan Myers profile image Brad A. Myers View Profile Authors Info & Affiliations Publication: Watch what I do: programming by demonstrationAugust 1993 Pages 415\u0393\u00c7\u00f4422 6citation 0 Downloads Metrics Total Citations6 Total Downloads0 Last ! .\u0393\u00c7\u00aa", "num_citations": "28\n", "authors": ["25"]}
{"title": "Comparing API Design Choices with Usability Studies: A Case Study and Future Directions.\n", "abstract": " There are more APIs than ever, and designing APIs that are usable by their target audience is difficult. Work at Microsoft has demonstrated that running controlled usability studies with participants from different personas and analyzing the results of these studies using the cognitive dimensions framework is effective at identifying and preventing usability problems in APIs. This paper presents a generalization of that technique in the form of usability studies of common API design choices. By studying a single design choice from multiple perspectives, we can generalize our results to any API that might be affected by the design choice. We show the feasibility of our approach with an initial study on whether or not to require constructor parameters, and present our current and planned work to study more API design choices.", "num_citations": "27\n", "authors": ["25"]}
{"title": "Environment for rapidly creating interactive design tools\n", "abstract": " The Garnet toolkit was specifically designed to make highly interactive graphical programs easier to design and implement. Visual, interactive, user-interface design tools clearly fall into this category. At this point, we have used the Garnet toolkit to create three different interactive design tools: Gilt, a simple interface builder for laying out widgets; Lapidary, a sophisticated design tool for constructing application-specific graphics and custom widgets; and C32, a spreadsheet interface to constraints. The features of the Garnet toolkit that made these easier to create include use of a prototype-instance object system instead of the usual class-instance model, integration of constraints with the object system, graphics model that supports automatic graphical update and saving to disk of on-screen objects, separation of specifying the graphics of objects from their behavior, automatic layout of graphical objects in a\u252c\u00e1\u0393\u00c7\u00aa", "num_citations": "27\n", "authors": ["25"]}
{"title": "Obsidian: Typestate and assets for safer blockchain programming\n", "abstract": " Blockchain platforms are coming into use for processing critical transactions among participants who have not established mutual trust. Many blockchains are programmable, supporting smart contracts, which maintain persistent state and support transactions that transform the state. Unfortunately, bugs in many smart contracts have been exploited by hackers. Obsidian is a novel programming language with a type system that enables static detection of bugs that are common in smart contracts today. Obsidian is based on a core calculus, Silica, for which we proved type soundness. Obsidian uses typestate to detect improper state manipulation and uses linear types to detect abuse of assets. We integrated a permissions system that encodes a notion of ownership to allow for safe, flexible aliasing. We describe two case studies that evaluate Obsidian\u0393\u00c7\u00d6s applicability to the domains of parametric insurance and supply\u252c\u00e1\u0393\u00c7\u00aa", "num_citations": "26\n", "authors": ["25"]}
{"title": "Investigating the solution space of an open-ended educational game using conceptual feature extraction\n", "abstract": " The rich interaction space of many educational games presents a challenge for designers and researchers who strive to help players achieve specific learning outcomes. Giving players a large amount of freedom over how they perform a complex game task makes it difficult to anticipate what they will do. In order to address this issue designers must ask: what are students doing in my game? And does it embody what I intended them to learn? To answer these questions, designers need methods to expose the details of student play. We describe our approach for automatic extraction of conceptual features from logs of student play sessions within an open educational game utilizing a two-dimensional context-free grammar. We demonstrate how these features can be used to cluster student solutions in the educational game RumbleBlocks. Using these clusters, we explore the range of solutions and measure how many students use the designers\u0393\u00c7\u00d6 envisioned solution. Equipped with this information, designers and researchers can focus redesign efforts to areas in the game where discrepancies exist between the designers\u0393\u00c7\u00d6 intentions and player experiences.", "num_citations": "26\n", "authors": ["25"]}
{"title": "The GARNET user interface development environment: A proposal\n", "abstract": " The Garnet project aims to create a set of tools that will help user interface designers create, modify and maintain highly-interactive, graphical, direct manipulation user interfaces. These tools will form a\" User Interface Development Environment\"(UBDE), which is sometimes called a4'User Interface Management System\"(UIMS). Garnet takes a new approach to UIDEs by concentrating on a particular class of programs: those whose primary focus is creating and editing graphical objects. Garnet is composed of six major parts: an object-oriented graphics package, a constraint system, encapsulated input device handlers called\" interactors,\" a user interface tool kit, user interface construction tools, and a\" graphical editor shell\" to help build editor-style programs. This document presents an overview of the approach that we propose to take for the Garnet project.", "num_citations": "26\n", "authors": ["25"]}
{"title": "Gaining general acceptance for UIMSs\n", "abstract": " User Interface Management Systems (UIMSs) have now gained acceptance in the research and business communities. Unfortunately, they are still not widely available or used. This paper proposes three reasons for this: that they are too hard to use, that they are still too limited in the types of interfaces that they can create, and that they are not portable with respect to different machines, operating systems and graphics systems. UIMSs can be made easier to use by avoiding programming-language-like techniques, and they can be made more functional by providing the ability to create Direct Manipulation interaction techniques and to integrate them into modern interfaces. UIMSs can be made more portable by inventing new input models and graphics packages that are appropriate for highly-interactive interfaces and that can work in various environments.", "num_citations": "26\n", "authors": ["25"]}
{"title": "An implementation architecture to support single-display groupware\n", "abstract": " Single Display Groupware SDG applications use a single display shared by multiple people. This kind of interaction has proven very useful for children, who often share a computer for games and educational software, and also for co-located meetings, where multiple people are in the same room discussing, annotating and editing a design or presentation which is shown on a computer screen. We have developed a number of SDG applications that use multiple 3Com PalmPilots and Windows CE devices to emulate a PCs mouse and keyboard. All users can take turns sharing a single cursor to use existing applications like PowerPoint. We have also created other new applications where all users have their own independent cursors. This paper describes the architectural additions to the Amulet toolkit that make it easy for programmers to develop applications with multiple input streams from multiple users. Amulet supports shared or independent editing, and shared or independent undo streams. The implementation differs from other Computer Supported Cooperative Work CSCW architectures in that others have one Model and multiple Views and Controllers one for each user, whereas we have one Model and one View, and multiple Controllers.Descriptors:", "num_citations": "25\n", "authors": ["25"]}
{"title": "API designers in the field: Design practices and challenges for creating usable APIs\n", "abstract": " Application Programming Interfaces (APIs) are a rapidly growing industry and the usability of the APIs is crucial to programmer productivity. Although prior research has shown that APIs commonly suffer from significant usability problems, little attention has been given to studying how APIs are designed and created in the first place. We interviewed 24 professionals involved with API design from 7 major companies to identify their training and design processes. Interviewees had insights into many different aspects of designing for API usability and areas of significant struggle. For example, they learned to do API design on the job, and had little training for it in school. During the design phase they found it challenging to discern which potential use cases of the API users will value most. After an API is released, designers lack tools to gather aggregate feedback from this data even as developers openly discuss the API\u252c\u00e1\u0393\u00c7\u00aa", "num_citations": "24\n", "authors": ["25"]}
{"title": "API usability: report on special interest group at CHI\n", "abstract": " The 27th annual International Conference on Human Factors in Computing (CHI) convened in Boston, MA (USA) from April 4-9, 2009. Included in this year's technical program was a special interest group (SIG) meeting on API usability. This report summarizes the SIG, emphasizing the primary takeaways, which include a greater understanding of the types of APIs, case studies, and a place to share our multi-disciplinary results.", "num_citations": "24\n", "authors": ["25"]}
{"title": "Designers\u0393\u00c7\u00d6 natural descriptions of interactive behaviors\n", "abstract": " While a designer's focus used to be the design of non-interactive elements such as graphics or animations, today's designers deal with various levels of interactivity such as mouse, keyboard and touch screen interaction. Unfortunately, it is challenging for designers to create these diverse interactions since most implementation tools such as Flash require the use of conventional programming languages and do not support the natural expressions used by designers. To better understand how designers think about interactive behaviors, we conducted a lab study where designers and programmers described various primitive and composite interactive behaviors using their own language. From this, we learned that there is significant commonality among designers in terms of the verbs, syntax, and structure when describing interactivity. These results can help guide the way to building more natural programming\u252c\u00e1\u0393\u00c7\u00aa", "num_citations": "24\n", "authors": ["25"]}
{"title": "Improving user performance on boolean queries\n", "abstract": " The accurate formulation of boolean expressions is a notorious problem in programming languages as well as database and web query tools. Users have demonstrated great difficulty with the common textual method for specifying these queries, which uses the boolean operators AND, OR, and NOT, partly because these words are used inconsistently in natural languages. This paper proposes a tabular boolean query language that avoids the need to use named operators, provides a concrete distinction between conjunction and disjunction, and makes grouping more explicit. A study comparing this tabular language with textual boolean expressions found that untrained users perform better when they express their queries in the tabular language, and about equally well when interpreting queries written in either language. We conclude that systems can benefit by adopting a tabular notation for query formulation.", "num_citations": "24\n", "authors": ["25"]}
{"title": "Gestural text entry on multiple devices\n", "abstract": " We present various adaptations of the EdgeWrite unistroke text entry method that work on multiple computer input devices: styluses, touchpads, displacement and isometric joysticks, four keys or buttons, and trackballs. We argue that consistent, flexible, multi-device input is important to both accessibility and to ubiquitous computing. For accessibility, multi-device input means users can switch among devices, distributing strain and fatigue among different muscle groups. For ubiquity, it means users can\" learn once, write anywhere,\" even as new devices emerge. By considering the accessibility and ubiquity of input techniques, we can design for both motor-impaired users and\" situationally impaired\" able-bodied users who are on-the-go. We discuss the requirements for such input and the challenges of multi-device text entry, such as solving the segmentation problem. This paper accompanies a demonstration of\u252c\u00e1\u0393\u00c7\u00aa", "num_citations": "23\n", "authors": ["25"]}
{"title": "Demonstrational interfaces: sometimes you need a little intelligence, sometimes you need a lot\n", "abstract": " Publisher SummaryDemonstrational interfaces allow the user to perform actions on concrete example objects (often by direct manipulation). This can allow the user to create parameterized procedures and objects without requiring the user to learn a programming language. The term demonstrational is used because the user is demonstrating the desired result using example values. Over the last fifteen years, many applications have been built in many domains where the user can define behaviors by demonstration. In some of these, the system uses sophisticated artificial intelligence (AI) algorithms so that complex behavior can be inferred from a few examples. In other systems, the user must provide the full specification, and the examples are primarily used to help the user understand the situation. This chapter discusses the findings about which situations require increased intelligence in the system, what AI\u252c\u00e1\u0393\u00c7\u00aa", "num_citations": "23\n", "authors": ["25"]}
{"title": "UIMSs, toolkits, interface builders\n", "abstract": " User interface software is often large, complex and difficult to implement, debug, and modify. A 1992 study found that an average of 48% of the code of applications is devoted to the user interface, and that about 50% of the implementation time is devoted to implementing the user interface portion [Myers 92a], and the numbers are probably much higher today. As interfaces become easier to use, they become harder to create [Myers 94]. Today, direct manipulation interfaces (also called \u0393\u00c7\u00ff\u0393\u00c7\u00ffGUIs\u0393\u00c7\u00d6\u0393\u00c7\u00d6for Graphical User Interfaces) are almost universal: one 1993 study found that 97% of all software development on Unix involved a GUI [XBusiness 94, p. 80]. These interfaces require that the programmer deal with elaborate graphics, multiple ways for giving the same command, multiple asynchronous input devices (usually a keyboard and a pointing device such as a mouse), a \u0393\u00c7\u00ff\u0393\u00c7\u00ffmode free\u0393\u00c7\u00d6\u0393\u00c7\u00d6interface where the user can give any command at virtually any time, and rapid \u0393\u00c7\u00ff\u0393\u00c7\u00ffsemantic feedback\u0393\u00c7\u00d6\u0393\u00c7\u00d6where determining the appropriate response to user actions requires specialized information about the objects in the program. Tomorrow\u0393\u00c7\u00d6s user interfaces will provide speech and gesture recognition, intelligent agents and integrated multi-media, and will probably be even more difficult to create. Furthermore, because user interface design is so difficult, the only reliable way to get good interfaces is to iteratively re-design (and therefore re-implement) the interfaces after user-testing, which makes the implementation task even harder.Fortunately, there has been significant progress in software tools to help with creating user interfaces, and today, virtually all user interface\u252c\u00e1\u0393\u00c7\u00aa", "num_citations": "23\n", "authors": ["25"]}
{"title": "Using and exploring hierarchical data in spreadsheets\n", "abstract": " More and more data nowadays exist in hierarchical formats such as JSON due to the increasing popularity of web applications and web services. While many end-user systems support getting hierarchical data from databases without programming, they provide very little support for using hierarchical data beyond turning the data into a flat string or table. In this paper, we present a spreadsheet tool for using and exploring hierarchical datasets. We introduce novel interaction techniques and algorithms to manipulate and visualize hierarchical data in a spreadsheet using the data's relative hierarchical relationships with the data in its adjacent columns. Our tool leverages the data's structural information to support selecting, grouping, joining, sorting and filtering hierarchical data in spreadsheets. Our lab study showed that our tool helped spreadsheet users complete data exploration tasks nearly two times faster than\u252c\u00e1\u0393\u00c7\u00aa", "num_citations": "22\n", "authors": ["25"]}
{"title": "Integrating isometric joysticks into mobile phones for text entry\n", "abstract": " We are investigating a new gestural text entry method for mobile phones that uses an isometric joystick and therefore consumes very little physical space. We have created a high-fidelity mobile phone prototype with two embedded isometric joysticks, one on the front for use with the thumb, and another on the back for use with the index finger. The joysticks can be used to enter text using a special version of the EdgeWrite text entry method. In our proposed studies, we would like to investigate the performance of using the joysticks as text input devices in stationary and mobile situations. With our prototype, the authors were able to write at~ 12 wpm with the front joystick, and~ 7 wpm with the back joystick. These numbers are sure to improve as further refinements are made.", "num_citations": "22\n", "authors": ["25"]}
{"title": "Availability bars for calendar scheduling\n", "abstract": " Calendar scheduling is a difficult task for people who have overbooked calendars with many constraints. Currently, calendar applications do not allow users to specify scheduling constraints such as how preferable a free time is for scheduling a new meeting or to what extent an existing meeting can be rescheduled. This paper introduces the\" availability bar,\" an interaction and visualization technique for complex calendar scheduling constraints. Availability bars, embedded in calendar applications, can help users who manually schedule meetings. Availability bars can also mediate communication with calendar scheduling agents that gather availability constraints, search for times that satisfy the constraints, and negotiate with invitees when no satisfactory time is found for the constraints.", "num_citations": "22\n", "authors": ["25"]}
{"title": "Citrus: a language and toolkit for simplifying the creation of structured editors for code and data\n", "abstract": " Direct-manipulation editors for structured data are increasingly common. While such editors can greatly simplify the creation of structured data, there are few tools to simplify the creation of the editors themselves. This paper presents Citrus, a new programming language and user interface toolkit designed for this purpose. Citrus offers language-level support for constraints, restrictions and change notifications on primitive and aggregate data, mechanisms for automatically creating, removing, and reusing views as data changes, a library of widgets, layouts and behaviors for defining interactive views, and two comprehensive interactive editors as an interface to the language and toolkit itself. Together, these features support the creation of editors for a large class of data and code.", "num_citations": "22\n", "authors": ["25"]}
{"title": "Human factors affecting dependability in end-user programming\n", "abstract": " Human factors affecting the dependability of end user's programs are discussed in the context of controlled and observational studies of both professional and end-user programmers. These factors include the influence of the types of behaviors that end users wish to implement, end user's fundamental cognitive biases, barriers in the languages, environments, libraries, and other tools used by end users, and end users' difficulties with understanding their code's meaning and execution.", "num_citations": "22\n", "authors": ["25"]}
{"title": "Amulet's dynamic and flexible prototype-instance object and constraint system in C++\n", "abstract": " In order to support rapid prototyping and efficient construction of user interface software, the Amulet user interface development environment uses a prototype-instance object model integrated with a constraint solver. The important innovations in the Amulet object and constraint systems are the automatic management of a part-owner hierarchy in addition to the prototype instance hierarchy, the support for multiple constraint solvers at the same time, control over slot inheritance, flexible demons, and a convenient integration of the models with C without requiring a pre-processor.Descriptors:", "num_citations": "22\n", "authors": ["25"]}
{"title": "Demonstrational interfaces: Coming soon?\n", "abstract": " This panel discusses what demonstrational interfaces are, how they can be used, and when and whether they will become more popular. For more information on demonstrational interfaces, you might refer to survey articles [4, 5], or the three papers in this conference on demonstrational interfaces (by Cypher, Stasko, and Myers). Some other references are listed below.", "num_citations": "22\n", "authors": ["25"]}
{"title": "Selective undo support for painting applications\n", "abstract": " Today's widely deployed painting applications use a linear undo model that allows users to backtrack previous operations in reverse chronological order. This undo model is not useful if the user has performed desired operations after undesired ones. Selective undo, in contrast, allows users to select specific operations in the past and only undo those, while keeping the remaining operations intact. Although selective undo has been widely explored in the context of text editing and object-oriented drawing, we explore selective undo for painting (bitmap) editing, which has received less attention and introduces many interesting user interface design challenges. Our system, called Aquamarine, explores the script model for selective undo, where selectively undone operations are skipped in the history, rather than the more explored inverse model, which puts an inverse of the selected operations at the end of the history\u252c\u00e1\u0393\u00c7\u00aa", "num_citations": "21\n", "authors": ["25"]}
{"title": "Using association metrics to help users navigate API documentation\n", "abstract": " In the past decade there has been spectacular growth in the number and size of third-party libraries, frameworks, toolkits and other Application Programming Interfaces (APIs) available to modern software developers. However, the time-saving advantages of code re-use are commonly hampered by the difficulty in finding the correct methods for a given task among the thousands of irrelevant ones. We have developed a tool called Apatite that helps address this issue by letting programmers browse APIs by viewing associations between their components. Apatite indicates which items of an API are popular in different contexts and allows browsing by initially selecting verbs (methods and actions) in addition to classes and packages. The associations are calculated by leveraging existing search engine data and source code, and verbs are identified by parsing the documentation descriptions. Apatite is available on the\u252c\u00e1\u0393\u00c7\u00aa", "num_citations": "21\n", "authors": ["25"]}
{"title": "Static Extraction and Conformance Analysis of Hierarchical Runtime Architectural Structure\n", "abstract": " A high-level architectural diagram of a system's organization can be useful during software evolution. Often, such a diagram is missing, hence the need to extract one from the code. Alternatively, a diagram may exist but may be inconsistent with the code, hence the need to analyze its conformance with the implementation. One important notion of conformance, the communication integrity principle, stipulates that each component in the implementation may only communicate directly with the components to which it is connected in the architecture.", "num_citations": "21\n", "authors": ["25"]}
{"title": "Feldspar: A system for finding information by association\n", "abstract": " We present Feldspar, the first system that allows people to find personal information on the computer by specifying chains of other information that it is associated with, emulating the information retrieval process of human associative memory. Feldspar\u0393\u00c7\u00d6s contributions include (1) a user interface for constructing retrieval queries that consist of multiple levels of associations, such as \u0393\u00c7\u00a3find the folder containing the email attachment from the person I met at an event\u0393\u00c7\u00a5; and (2) algorithms for collecting the association information and for providing answers to associative queries in real-time. A user study showed that Feldspar is easy to use, and is superior to conventional browsing and searching for these kinds of retrieval tasks. We have reported Feldspar\u0393\u00c7\u00d6s implementation and evaluation in our long paper at CHI 2008. Here, our discussion focuses on the design and implementation ideas that we have tried, or are currently investigating. We hope this will stimulate further discussions and help inspire more design ideas.", "num_citations": "21\n", "authors": ["25"]}
{"title": "Integrated text entry from power wheelchairs\n", "abstract": " Power wheelchair joysticks have be used to control a mouse cursor on desktop computers, but they offer no integrated text entry solution, confining users to point-and-click or point-and-dwell with on-screen keyboards. On-screen keyboards reduce useful screen real-estate, exacerbating the need for frequent window management, and impose a secondary focus of attention. By contrast, we present two integrated gestural text entry methods designed for use from power wheelchairs: one for use with joysticks and the other for use with touchpads. Both techniques are adaptations of EdgeWrite, originally a stylus-based unistroke method designed for people with tremor. In a preliminary text entry study of 7 power wheelchair users, we found that EdgeWrite with a touchpad was faster than the on-screen keyboard WiViK with a joystick, and EdgeWrite with a joystick was only slightly slower. These results warranted a multi\u252c\u00e1\u0393\u00c7\u00aa", "num_citations": "21\n", "authors": ["25"]}
{"title": "The impact of human-centered features on the usability of a programming system for children\n", "abstract": " HANDS is a new programming system for children that was designed for usability. This paper examines the effectiveness of three features of HANDS: queries, aggregate operations, and data visibility. The system is compared with a limited version that lacks these features. In the limited version, programmers can achieve the same results but must use more traditional programming techniques. Children using the full-featured HANDS system performed significantly better than their peers who used the limited version. This provides evidence that usability of programming systems can be improved by including these features.", "num_citations": "21\n", "authors": ["25"]}
{"title": "Natural programming: Project overview and proposal\n", "abstract": " End-users must write programs to control many different kinds of applications. Examples include multimedia authoring, controlling robots, defining manufacturing processes, setting up simulations, programming agents, scripting, etc. The languages used today for these tasks are usually difficult to learn and are based on professional programming languages. This is in spite of years of research highlighting the problems with these languages for novice programmers. The Natural Programming Project is developing general principles, methods, and programming language designs that will significantly reduce the amount of learning and effort needed to write programs for people who are not professional programmers. These principles are based on a thorough analysis of previous empirical studies of programmers, as well as new studies designed to discover the most natural programming paradigms. Our proposed research is to extend these results, and apply them to different domains. The result will be new programming languages and environments that are demonstrably superior for users.Descriptors:", "num_citations": "21\n", "authors": ["25"]}
{"title": "Evaluating program representation in a demonstrational visual shell\n", "abstract": " ABSTRACT For Programming by Demonstration(PBD) systems to reach their full potential, a program representation is needed so users can view, edit and share programs. We designed and implemented two equivalent representation languages for a PBD desktop similar to the Macintosh Finder. One language graphically depicts the program\u0393\u00c7\u00d6se~ ects. The other language describes the program\u0393\u00c7\u00d6s actions. A user study showed that both languages enabled users with no prior programming experience to generate and comprehend programs, and that the first language doubled users\u0393\u00c7\u00d6 abilities to generate programs.", "num_citations": "21\n", "authors": ["25"]}
{"title": "APPINITE: A Multi-Modal Interface for Specifying Data Descriptions in Programming by Demonstration Using Natural Language Instructions\n", "abstract": " A key challenge for generalizing programming-by-demonstration (PBD) scripts is the data description problem - when a user demonstrates performing an action, the system needs to determine features for describing this action and the target object in a way that can reflect the user's intention for the action. However, prior approaches for creating data descriptions in PBD systems have problems with usability, applicability, feasibility, transparency and/or user control. Our APPINITE system introduces a multimodal interface with which users can specify data descriptions verbally using natural language instructions. APPINITE guides users to describe their intentions for the demonstrated actions through mixed-initiative conversations. APPINITE constructs data descriptions for these actions from the natural language instructions. Our evaluation showed that APPINITE is easy-to-use and effective in creating scripts for tasks\u252c\u00e1\u0393\u00c7\u00aa", "num_citations": "20\n", "authors": ["25"]}
{"title": "Making end user development more natural\n", "abstract": " When end users approach a development task, they bring with them a set of techniques, expressions, and knowledge, which can be leveraged in order to make the process easier. The Natural Programming Project has been working for over twenty years to better understand how end users think about their tasks, and to develop new ways for users to express those tasks that will be more \u0393\u00c7\u00a3natural,\u0393\u00c7\u00a5 by which we mean closer to the way they think. Our chapter in the previous book covered the first 10 years of this research; and here we summarize the most recent 10 years. This includes studies on barriers that impede EUD, and a new tool that helps with the understanding and debugging barriers by showing developers why their program has its current behavior. We also describe a tool that we created to help EUDs input, process, and transform data in the context of spreadsheets and web pages. Interaction\u252c\u00e1\u0393\u00c7\u00aa", "num_citations": "20\n", "authors": ["25"]}
{"title": "The past, present and future of programming in HCI\n", "abstract": " The first computer users were all programmers, and the field of Human-Computer Interaction started, in part, with a focus on improving how programming was done. There was a significant amount of work in the 1980\u0393\u00c7\u00d6s on this topic, but it mostly died out in the 1990s. Now, there is a resurgence of work on what used to be called the Psychology of Programming, Software Psychology, and the Empirical Studies of Programming. Now, research that combines HCI and software engineering concerns regularly wins awards at both the software engineering and HCI conferences, and although there is no longer a conference devoted solely to this topic, it is a major focus of the popular VL/HCC conference series. In this paper, we argue that new HCI and software engineering methods and tools, along with a new acceptance of the programming community, makes it a propitious time for a renewed focus on this topic.", "num_citations": "20\n", "authors": ["25"]}
{"title": "Simplifying video editing with SILVER\n", "abstract": " Digital video is becoming more ubiquitous. Unfortunately, editing videos remains difficult for several reasons. It has dual tracks of audio and video and may require working at the smallest level of detail. Silver is an authoring tool that uses video metadata to overcome these problems. It provides mulitiple views with different content types and at different levels of abstraction. This paper focuses on Silver's smart selection and editing operations, which work at a high semantic level and handle different boundaries in audio and video. Our research suggests several ways in which video editing tools can assist users in the composition and reuse of video.", "num_citations": "20\n", "authors": ["25"]}
{"title": "User interface tools\n", "abstract": " ABSTRACT A user inte~ ace tool is any software that helps user interfaee designers or programmers design, implement and test user interfaces and user interfaee software. Whereas five years ago, user interface tools were primarily research projeets, today there are literally hundreds of successful commercial user interface tools. In addition, research into new techniques and tools is extremely active, with one or two sessions at each CHI conference, and an entire sepamte conference (UIST) devoted to this topic every year. This tutorial provides an overview of both the commercial and research segments of this area.", "num_citations": "20\n", "authors": ["25"]}
{"title": "Pursuit: Graphically representing programs in a demonstrational visual shell\n", "abstract": " Pursuit is a programmable direct manipulation interface to a file system that enables users to create programs by demonstration. To construct a program in Pursuit, users execute actions on real data and Pursuit creates a general procedure containing variables, loops and conditionals. During the demonstration, the evolving program is represented in an editable, visual programming language. Unlike other visual programming languages, which explicitly represent operations and leave users to imagine data in their heads, Pursuit\u0393\u00c7\u00d6s visual language explicitly represents data objects using icons and implicitly represents operations by the changes they cause to data icons. The language also serves as a novel form of feedback between Pursuit and the user.", "num_citations": "20\n", "authors": ["25"]}
{"title": "A nose gesture interface device: Extending virtual realities\n", "abstract": " This paper reportsl on the development of a nose-machine interface device that provides real-time gesture, position, smell and facial expression information. The DATA NOSETM2\u0393\u00c7\u00f6Data AtomaTa CORNUCOPIA pNeumatic Olfactory I/O-deviSE Tactile Manipulation [Olsen86, Myers91]\u0393\u00c7\u00f6allows novice users without any formal nose training to perform complex interactive tasks.", "num_citations": "20\n", "authors": ["25"]}
{"title": "A complete and efficient implementation of covered windows\n", "abstract": " BackgroundSapphire runs on a raster (also called bitmap) display, which means that an area of memory holds the picture shown on the screen. Each point on the screen (pixel) corresponds to one bit in memory (so each pixel can be either white or black). For example, to set a spot on the screen to black, the corresponding bit in memory is set to 1.The primary method for doing graphics on thePERQ's bitmap screen is the rasterop (sometimes called bitblt). 17 To avoid confusion this article uses\" hardware raster-op\" for the low-level function that actually moves bits, since it is implemented with special hardware on the PERQ.(The functionality of the hardware raster-op may actually be implemented by some combination of hardware, microcode, and software on other computers.)\" Window raster-op\" refers to the high-level function that works with covered windows.", "num_citations": "20\n", "authors": ["25"]}
{"title": "Replay analysis in open-ended educational games\n", "abstract": " Designers of serious games have an interest in understanding if their games are well-aligned, i.e., whether in-game rewards incentivize behaviors that will lead to learning. Few existing serious games analytics solutions exist to serve this need. Open-ended games in particular run into issues of alignment due to their affordances for wide player freedom. In this chapter, we first define open-ended games as games that have a complex functional solution spaces. Next, we describe our method for exploring alignment issues in an open-ended educational game using replay analysis. The method uses multiple data mining techniques to extract features from replays of player behavior. Focusing on replays rather than logging play-time metrics allows designers and researchers to run additional metric calculations and data transformations in a post hoc manner. We describe how we have applied this replay\u252c\u00e1\u0393\u00c7\u00aa", "num_citations": "19\n", "authors": ["25"]}
{"title": "Studying the documentation of an API for enterprise Service-Oriented Architecture\n", "abstract": " All software today is written using application programming interfaces (APIs). We performed a user study of the online documentation of a large and complex API for Enterprise Service-Oriented Architecture (eSOA), which identified many issues and recommendations for making API documentation easier to use. eSOA is an appropriate testbed because the target users include high-level business experts who do not have significant programming expertise and thus can be classified as \u0393\u00c7\u00a3end-user developers.\u0393\u00c7\u00a5 Our study showed that the participants\u0393\u00c7\u00d6 background influenced how they navigated the documentation. Lack of familiarity with business terminology was a barrier for developers without business application experience. Both groups avoided areas of the documentation that had an inconsistent visual design. A new design for the documentation that supports flexible navigation strategies seems to be required to\u252c\u00e1\u0393\u00c7\u00aa", "num_citations": "19\n", "authors": ["25"]}
{"title": "End user software engineering: CHI 2007 special interest group meeting\n", "abstract": " Recently, researchers have been working to bring the benefits of rigorous software engineering methodologies to end users who find themselves in programming situations, to try to make their software more reliable. End users create software whenever they write, for instance, educational simulations, spreadsheets, or dynamic e-business web applications. Unfortunately, errors are pervasive in end-user software, and the resulting impact is sometimes enormous. This special interest group meeting has three purposes: to bring the results of a recent (February 2007) week-long\" Dagstuhl\" meeting on end-user software engineering to interested researchers at CHI; to incorporate attendees' ideas and feedback into an emerging survey of the state of this interesting new subarea; and generally to bring together the community of researchers who are addressing this topic, with the companies that are creating end-user\u252c\u00e1\u0393\u00c7\u00aa", "num_citations": "19\n", "authors": ["25"]}
{"title": "Personal universal controllers: controlling complex appliances with GUIs and speech\n", "abstract": " We envision a future where each person will carry with them a personal universal controller (PUC), a portable computerized device that allows the user to control any ap-pliance within their environment. The PUC has a two-way communication channel with each appliance. It downloads a specification of the appliance's features and then automati-cally generates an interface for controlling that appliance (graphical, speech, or both). In this demonstration we pre-sent a working PUC system that automatically generates graphical and speech interfaces, and controls real appli-ances, including a shelf stereo and a Sony camcorder.", "num_citations": "19\n", "authors": ["25"]}
{"title": "Using multiple devices simultaneously for display and control\n", "abstract": " The Pebbles research project (http://www.cs.cmu.edu/spl sim/pebbles) has been studying the use of hand-held personal digital assistants (PDAs) along with other kinds of hand-held computers, at the same time as other computing devices. A key focus of our research is that the hand-held computers are used both as output devices and as input devices to control the activities on the other computers. Our previous articles have described parts of the project in detail. The article presents four scenarios that illustrate some of the capabilities we are already investigating.", "num_citations": "19\n", "authors": ["25"]}
{"title": "Clinical trials of health information technology interventions intended for patient use: unique issues and considerations\n", "abstract": " BackgroundDespite the proliferation of health information technology (IT) interventions, descriptions of the unique considerations for conducting randomized trials of health IT interventions intended for patient use are lacking.PurposeOur purpose is to describe the protocol to evaluate Pocket PATH\u252c\u00ab (Personal Assistant for Tracking Health), a novel health IT intervention, as an exemplar of how to address issues that may be unique to a randomized controlled trial (RCT) to evaluate health IT intended for patient use.MethodsAn overview of the study protocol is presented. Unique considerations for health IT intervention trials and strategies are described to maintain equipoise, to monitor data safety and intervention fidelity, and to keep pace with changing technology during such trials.Lessons LearnedThe sovereignty granted to technology, the rapid pace of changes in technology, ubiquitous use in health care, and\u252c\u00e1\u0393\u00c7\u00aa", "num_citations": "18\n", "authors": ["25"]}
{"title": "Predicting reuse of end-user web macro scripts\n", "abstract": " Repositories of code written by end-user programmers are beginning to emerge, but when a piece of code is new or nobody has yet reused it, then current repositories provide users with no information about whether that code might be appropriate for reuse. Addressing this problem requires predicting reusability based on information that exists when a script is created. To provide such a model for web macro scripts, we identified script traits that might plausibly predict reuse, then used IBM CoScripter repository logs to statistically test how well each corresponded to reuse. We then built a machine learning model that combines the useful traits and evaluated how well it can predict four different types of reuse that we saw in the repository logs. Our model was able to predict reuse from a surprisingly small set of traits. It is simple enough to be explained in only 6-11 rules, making it potentially viable for integration in\u252c\u00e1\u0393\u00c7\u00aa", "num_citations": "18\n", "authors": ["25"]}
{"title": "The garnet user interface development environment\n", "abstract": " ABSTRACT The Garnet User Interface Development Environment contains a comprehensive set of tools that make it significantly easier to design and implement highly-interactive, graphical, direct manipulation user interfaces. The toolkit layer of Garnet provides a prototype-instance object system, automatic constraint maintenance, an efficient retainedobject graphics output model, a novel input model, two complete widget sets, and complete debugging tools. Garnet also contains a set of interactive user interface editors that aim to make it possible to create the user interface without programming. Instead, the user draws examples of the desired graphics and demonstrates their behaviors. The associated video provides an overview of the entire Garnet system.", "num_citations": "18\n", "authors": ["25"]}
{"title": "Interdisciplinary programming language design\n", "abstract": " Approaches for programming language design used commonly in the research community today center around theoretical and performance-oriented evaluation. Recently, researchers have been considering more approaches to language design, including the use of quantitative and qualitative user studies that examine how different designs might affect programmers. In this paper, we argue for an interdisciplinary approach that incorporates many different methods in the creation and evaluation of programming languages. We argue that the addition of user-oriented design techniques can be helpful at many different stages in the programming language design process.", "num_citations": "17\n", "authors": ["25"]}
{"title": "Using extracted features to inform alignment-driven design ideas in an educational game\n", "abstract": " As educational games have become a larger field of study, there has been a growing need for analytic methods that can be used to assess game design and inform iteration. While much previous work has focused on the measurement of student engagement or learning at a gross level, we argue that new methods are necessary for measuring the alignment of a game to its target learning goals at an appropriate level of detail to inform design decisions. We present a novel technique that we have employed to examine alignment in an open-ended educational game. The approach is based on examining how the game reacts to representative student solutions that do and do not obey target principles. We demonstrate this method using real student data and discuss how redesign might be informed by these techniques.", "num_citations": "17\n", "authors": ["25"]}
{"title": "A case study of using HCI methods to improve tools for programmers\n", "abstract": " For more than five years, researchers at Carnegie Mellon University have been collaborating with several SAP teams to improve the usability of SAP's developer tools and programming APIs. Much research has shown that HCI techniques can improve the tools that developers use to write software. In a recent project, we applied HCI techniques to a SAP developer tool for the SAP NetWeaver Gateway product. The SAP team building this tool uses agile software development processes, which allowed them to quickly improve the tool's usability based upon the evaluations.", "num_citations": "17\n", "authors": ["25"]}
{"title": "More natural end-user software engineering\n", "abstract": " The\" Natural Programming\" project at Carnegie Mellon University has been working for more than 10 years to make programming more\" natural\", or closer to the way people think. We have addressed the needs of all kinds of programmers: novices, professionals and end-user programmers. Many studies were performed which provided new insights and led to new models of programmers. From these insights and models, we created new programming languages and environments. Evaluations of the resulting systems have shown that they are effective and successful. This paper provides an overview of the entire 10-year Natural Programming project, but focuses on our new results since WEUSE-III in Dagstuhl.", "num_citations": "17\n", "authors": ["25"]}
{"title": "Trial by water: creating Hurricane Katrina \u0393\u00c7\u00a3person locator\u0393\u00c7\u00a5 web sites\n", "abstract": " We interviewed six people who led teams that created web sites enabling Hurricane Katrina survivors to report their status. We learned that interviewees did not discover and communicate with other teams when they started their projects, which resulted in redundant sites. The absence of a shared task impeded trust between teams, ultimately inhibiting data collection and aggregation. Moreover, communication within teams was problematic; developers who had adequate technical skills to work alone were more positive about their sites\u0393\u00c7\u00d6 success compared to developers who had to shore up skill weaknesses through collaboration. These problems did not simply result from team leaders\u0393\u00c7\u00d6 oversized egos because site creators were generally motivated by concern for other people instead of self-interest. Rather, these problems highlight the need for improved development methods and systems to help developers\u252c\u00e1\u0393\u00c7\u00aa", "num_citations": "17\n", "authors": ["25"]}
{"title": "Describing appliance user interfaces abstractly with xml\n", "abstract": " This paper describes an XML-based language for describing the functions of appliances, such as televisions, VCRs, copiers, microwave ovens, and even manufacturing equipment. Our description language is designed to be concise, easy to use, and contain no presentation information. It has been used to describe more than twenty diverse appliances. The functional descriptions written in our language are used to automatically generate remote control interfaces for appliances. We have used these descriptions to generate both graphical and speech interfaces on handheld computers, mobile phones, and desktop computers.", "num_citations": "17\n", "authors": ["25"]}
{"title": "Tourmaline: Text formatting by demonstration\n", "abstract": " Tourmaline | Watch what I do ACM Digital Library home ACM home Google, Inc. (search) Advanced Search Browse About Sign in Register Advanced Search Journals Magazines Proceedings Books SIGs Conferences People More Search ACM Digital Library SearchSearch Advanced Search Browse Browse Digital Library Collections More HomeBrowse by TitleBooksWatch what I do: programming by demonstrationTourmaline: text formatting by demonstration chapter Tourmaline: text formatting by demonstration Share on Author: Brad A. Myers View Profile Authors Info & Affiliations Publication: Watch what I do: programming by demonstrationAugust 1993 Pages 309\u0393\u00c7\u00f4321 5citation 0 Downloads Metrics Total Citations5 Total Downloads0 Last 12 Months0 Last 6 weeks0 Get Citation Alerts New Citation Alert added! This alert has been successfully added and will be sent to: You will be notified whenever a record that . , .\u0393\u00c7\u00aa", "num_citations": "17\n", "authors": ["25"]}
{"title": "Invisible programming\n", "abstract": " A user interface in which the user gives an example of the desired operation and the system generalizes to construct a general-purpose procedure is discussed. The user sees the results of the program execution and the data the program is operating on, but the program itself is not shown. The program is specified by demonstrating the operations that should be performed using example data. These systems are called programming-by-example or demonstrational interfaces. An overview of this idea and a survey of such systems are presented.< >", "num_citations": "17\n", "authors": ["25"]}
{"title": "Unakite: Scaffolding Developers' Decision-Making Using the Web\n", "abstract": " Developers spend a significant portion of their time searching for solutions and methods online. While numerous tools have been developed to support this exploratory process, in many cases the answers to developers' questions involve trade-offs among multiple valid options and not just a single solution. Through interviews, we discovered that developers express a desire for help with decision-making and understanding trade-offs. Through an analysis of Stack Overflow posts, we observed that many answers describe such trade-offs. These findings suggest that tools designed to help a developer capture information and make decisions about trade-offs can provide crucial benefits for both the developers and others who want to understand their design rationale. In this work, we probe this hypothesis with a prototype system named Unakite that collects, organizes, and keeps track of information about trade-offs and\u252c\u00e1\u0393\u00c7\u00aa", "num_citations": "16\n", "authors": ["25"]}
{"title": "Using traits of web macro scripts to predict reuse\n", "abstract": " To help people find a code that they might want to reuse, repositories of end-user code typically sort scripts by number of downloads, ratings, or other information based on prior uses of the code. However, this information is unavailable when the code is new or when it has not yet been reused. Addressing this problem requires identifying reusable code based solely on information that exists when a script is created. To provide such a model for web macro scripts, we identified script traits that might plausibly predict reuse, then used IBM CoScripter repository logs to statistically test how well each corresponded to actual reuse. These tests confirmed that the traits generally did correspond to higher levels of reuse as anticipated. We then developed a machine learning model that uses these traits as features to predict reuse of macros. Evaluating this model on repository logs showed that its accuracy is comparable to\u252c\u00e1\u0393\u00c7\u00aa", "num_citations": "16\n", "authors": ["25"]}
{"title": "The \u0393\u00c7\u00ff55m end-user programmers\u0393\u00c7\u00d6 estimate revisited\n", "abstract": " In 1995, Boehm predicted that by 2005, there would be \u0393\u00c7\u00a355 million performers\u0393\u00c7\u00a5 of \u0393\u00c7\u00a3end-user programming\u0393\u00c7\u00a5 in the United States. Examining the original context and method which generated this number reveals that it actually estimates the number of computer users in businesses\u0393\u00c7\u00f6not programmers, per se\u0393\u00c7\u00f6and it assumes constant computer usage rates. This paper extends Boehm\u0393\u00c7\u00d6s estimate using fresh Bureau of Labor Statistics (BLS) data, including the latest BLS occupational projections (which are for 2012), and a richer estimation method.We estimate that in 2012, there will be 90 million end-users in American workplaces. Of these, we anticipate that over 55 million will use spreadsheets or databases (and therefore will be potential end-user programmers), while over 13 million will describe themselves as programmers. Thus, the potential pool of end-user programmers will probably substantially exceed the population who view themselves as programmers. Each of these estimates, in turn, substantially exceeds the latest BLS projections of fewer than 3 million professional programmers in 2012.", "num_citations": "16\n", "authors": ["25"]}
{"title": "A state-based visual language for a demonstrational visual shell\n", "abstract": " We present a new visual programming language and environment that serves as a form of feedback and representation in a Programming by Demonstration (PBD) system. The language differs from existing visual languages because it explicitly represents data objects and implicitly represents operations by changes in data objects. To improve feedback and provide a closer union between the PBD system and the program representation, the visual language is integrated into other parts of the system, such as the editor. Finally, in order to enable new operations to be added easily to the system, we introduce a declarative language for specifying how an operation's visual representation is generated.< >", "num_citations": "16\n", "authors": ["25"]}
{"title": "PBD invocation techniques: A review and proposal\n", "abstract": " PBD invocation techniques | Watch what I do ACM Digital Library home ACM home Google, Inc. (search) Advanced Search Browse About Sign in Register Advanced Search Journals Magazines Proceedings Books SIGs Conferences People More Search ACM Digital Library SearchSearch Advanced Search Browse Browse Digital Library Collections More HomeBrowse by TitleBooksWatch what I do: programming by demonstrationPBD invocation techniques: a review and proposal chapter PBD invocation techniques: a review and proposal Share on Authors: David S Kosbie profile image David S. Kosbie View Profile , Brad Allan Myers profile image Brad A. Myers View Profile Authors Info & Affiliations Publication: Watch what I do: programming by demonstrationAugust 1993 Pages 423\u0393\u00c7\u00f4431 2citation 0 Downloads Metrics Total Citations2 Total Downloads0 Last 12 Months0 Last 6 weeks0 Get Citation Alerts New Alert \u0393\u00c7\u00aa", "num_citations": "16\n", "authors": ["25"]}
{"title": "Key stakeholders' perceptions of the acceptability and usefulness of a tablet-based tool to improve communication and shared decision making in ICUs\n", "abstract": " PurposeAlthough barriers to shared decision making in intensive care units are well documented, there are currently no easily scaled interventions to overcome these problems. We sought to assess stakeholders' perceptions of the acceptability, usefulness, and design suggestions for a tablet-based tool to support communication and shared decision making in ICUs.MethodsWe conducted in-depth semi-structured interviews with 58 key stakeholders (30 surrogates and 28 ICU care providers). Interviews explored stakeholders' perceptions about the acceptability of a tablet-based tool to support communication and shared decision making, including the usefulness of modules focused on orienting families to the ICU, educating them about the surrogate's role, completing a question prompt list, eliciting patient values, educating about treatment options, eliciting perceptions about prognosis, and providing psychosocial\u252c\u00e1\u0393\u00c7\u00aa", "num_citations": "15\n", "authors": ["25"]}
{"title": "Data safety and monitoring for research involving remote health monitoring\n", "abstract": " Investigators conducting research involving human subjects are obligated to safeguard the wellbeing of the study participants. Other than requiring investigators to establish procedures for ongoing monitoring and reporting of adverse events, federal regulations do not dictate how human subject safety should be ensured. A variety of data safety monitoring (DSM) procedures may be acceptable depending on the nature, size, and complexity of the study. However, practical guidance for establishing and implementing appropriate DSM plans for such studies are lacking. In this article, we provide a review of the DSM considerations associated with monitoring health remotely and describe the Pocket Personal Assistant for Tracking Health project as an exemplar for how to develop effective DSM plans for research that captures clinical data using remote health-monitoring devices. Protecting the safety and welfare of\u252c\u00e1\u0393\u00c7\u00aa", "num_citations": "15\n", "authors": ["25"]}
{"title": "Using topes to validate and reformat data in end-user programming tools\n", "abstract": " End-user programming tools offer no data types except\" string\" for many categories of data, such as person names and street addresses. Consequently, these tools cannot automatically validate or reformat these data. To address this problem, we have developed a user-extensible model for string-like data. Each\" tope\" in this model is a user-defined abstraction that guides the interpretation of strings as a particular kind of data. Specifically, each tope implementation contains software functions for recognizing and reformatting instances of that tope's kind of data. This makes it possible at runtime to distinguish between invalid data, valid data, and questionable data that could be valid or invalid. Once identified, questionable and/or invalid data can be double-checked and possibly corrected, thereby increasing the overall reliability of the data. Valid data can be automatically reformatted to any of the formats appropriate\u252c\u00e1\u0393\u00c7\u00aa", "num_citations": "15\n", "authors": ["25"]}
{"title": "Exploring edge-based input techniques for handheld text entry\n", "abstract": " We are investigating how handheld devices like Palm PDAs and PocketPCs can be used as assistive technologies for computer access by people with motor impairments such as Muscular Dystrophy and Cerebral Palsy. As part of this research, we are developing new input techniques for handheld text entry. People with motor impairments suffer from symptoms that affect their ability to use conventional text entry methods. One symptom is a lack of stability in stylus movements caused by tremor or spasm. In an effort to create a more stable means of text entry, we are researching how to leverage elevated physical edges in our development of new text entry techniques. We present three edge-based techniques: Edge Keyboards, CornerSlide, and EdgeWrite.", "num_citations": "15\n", "authors": ["25"]}
{"title": "Heuristics in real user interfaces\n", "abstract": " It is the conventional wisdom in user interface design that direct manipulation is best and that interfaces should be predictable. This tends to argue against having a system \u0393\u00c7\u00a3guess\u0393\u00c7\u00a5 or use heuristics or other AI approaches. However, an increasing number of today's successful software products do use heuristics in their interfaces. The heuristics are used to help guide the user and to perform tasks that would be too difficult to specify by conventional direct manipulation approaches. We believe that user interface designers will increasingly need to consider using heuristic techniques in their interfaces. This panel discusses a number of today's successful products using heuristics and the important HCI design issues such as feedback.", "num_citations": "15\n", "authors": ["25"]}
{"title": "Smarter smart contract development tools\n", "abstract": " Much recent work focuses on finding bugs and security vulnerabilities in smart contracts written in existing languages. Although this approach may be helpful, it does not address flaws in the underlying programming language, which can facilitate writing buggy code in the first place. We advocate a re-thinking of the blockchain software engineering tool set, starting with the programming language in which smart contracts are written. In this paper, we propose and justify requirements for a new generation of blockchain software development tools. New tools should (1) consider users' needs as a primary concern; (2) seek to facilitate safe development by detecting relevant classes of serious bugs at compile time; (3) as much as possible, be blockchain-agnostic, given the wide variety of different blockchain platforms available, and leverage the properties that are common among blockchain environments to improve\u252c\u00e1\u0393\u00c7\u00aa", "num_citations": "14\n", "authors": ["25"]}
{"title": "Teaching agents when they fail: end user development in goal-oriented conversational agents\n", "abstract": " This chapter introduces an end user development (EUD) approach for handling common types of failures encountered by goal-oriented conversational agents. We start with identifying three common sources of failures in human-agent conversations: unknown concepts, out-of-domain tasks and wrong fulfillment means or level of generalization in task execution. To handle these failures, it is useful to enable the end user to program the agent and to \u0393\u00c7\u00a3teach\u0393\u00c7\u00a5 the agent what to do as a fallback strategy. Showing examples for this approach, we walk through our two integrated systems: Sugilite and Lia. Sugilite uses the programming by demonstration (PBD) technique, allowing the user to program the agent by demonstrating new tasks or new means for completing a task using the GUIs of third-party smartphone apps, while Lia learns new tasks from verbal instructions, enabling the user to teach the agent through\u252c\u00e1\u0393\u00c7\u00aa", "num_citations": "14\n", "authors": ["25"]}
{"title": "Preliminary Analysis of REST API Style Guidelines\n", "abstract": " We studied a collection of 32 publically published guideline sets for designing RESTful Application Programming Interfaces (APIs), each from a different company, to identify similarities and differences to see if there are overall best practices across ten different topics. Our contribution includes providing a list of topics that API authors can reference when creating or evaluating their own guideline sets. Additionally, we found that while some guideline sets attempt to enforce consistency, simplicity, and intuitiveness in the APIs that use these guidelines, cross-guideline set comparisons show a lack of consistency in some of the topics examined, and different interpretations of what is thought to be \u0393\u00c7\u00a3simple\u0393\u00c7\u00a5 and \u0393\u00c7\u00a3intuitive.\u0393\u00c7\u00a5", "num_citations": "14\n", "authors": ["25"]}
{"title": "Design annotations to improve API discoverability\n", "abstract": " User studies have revealed that programmers face several obstacles when learning application programming interfaces (APIs). A considerable part of such difficulties relate to discovery of API elements and the relationships among them. To address discoverability problems, we show how to complement APIs with design annotations, which document design decisions in a program-processable form for types, methods, and parameters. The information provided by the annotations is consumed by the integrated development environment (IDE) in order to assist API users with useful code completion proposals regarding object creation and manipulation, which facilitate API exploration and learning. As a proof of concept, we developed Dacite, a tool which comprises a set of Java annotations and an accompanying plugin for the Eclipse IDE. A user study revealed that Dacite is usable and effective, and Dacite\u0393\u00c7\u00d6s\u252c\u00e1\u0393\u00c7\u00aa", "num_citations": "14\n", "authors": ["25"]}
{"title": "Using scenario-based requirements to direct research on web macro tools\n", "abstract": " Web macros automate the interactions of end users with web sites and related information systems. Though web macro recorders and players have grown in sophistication over the past decade, these tools cannot yet meet many tasks that people perform in daily life. Based on observations of browser users, we have compiled ten scenarios describing tasks that users would benefit from automating. Our analysis of these scenarios yields specific requirements that web macro tools should support if those tools are to be applicable to these real-life tasks. Our set of requirements constitutes a benchmark for evaluating tools, which we demonstrate by evaluating the Robofox, CoScripter, and iMacros tools.", "num_citations": "14\n", "authors": ["25"]}
{"title": "Gamut: demonstrating whole applications\n", "abstract": " Gamut is a new tool for building interactive, graphical software like games, simulations, and educational software. A developer can build entire applications in Gamut\u0393\u00c7\u00d6s domain using only programming-by-demonstration (PBD) and never has to look at or modify code to build any behavior. To accomplish this, we have developed a simple, streamlined interaction for demonstrating so that developers can create new examples quickly and can specify negative examples without confusion. Also, Gamut allows the developer to give hints to point out objects in a relationship that would be too time consuming to find by searching. Gamut automatically revises generated code using an efficient algorithm that recursively scans for the differences between a new example and the previous behavior. To correct the discovered differences, Gamut couples heuristic search with a decision tree leamittg algorithm allowing it to build\u252c\u00e1\u0393\u00c7\u00aa", "num_citations": "14\n", "authors": ["25"]}
{"title": "Floor control in a highly collaborative co-located task\n", "abstract": " \u0393\u00c7\u00a3Floor control\u0393\u00c7\u00a5 is the protocol which determines which user has control and how to take turns when multiple people share a limited resource such as a single cursor in a synchronous task. First, we provide a new analysis and classification of floor control mechanisms. We then studied eight collaborative conditions in a highly-collaborative computer-based task, where all the subjects were colocated. We studied doing the task without a computer, compared to seven techniques where each user had an input device. This included two techniques where all users had their own cursor, and five floor control techniques for sharing one cursor. The floor control techniques included: having a moderator decide the turn, averaging all inputs together, blocking the other\u0393\u00c7\u00d6s input while the cursor was in use, explicit release, and explicit grab. We found no previous studies of all these mechanisms, although one prior paper predicted that the blocking mechanism should work best. Our primary result is that giving everyone a separate cursor works best, and we found no significant differences among the times using the floor-control mechanisms.", "num_citations": "14\n", "authors": ["25"]}
{"title": "The Lapidary graphical interface design tool\n", "abstract": " Lapidary is agraphical interface builder that allows designers to interactively speci~ all graphical aspects of an application, including both the widgets that go around the application windows, as well as the application-spccitlc graphics themselves [1]. The application-specific graphics may include static feedback such as selection handles, dynamic feedback such as hair-line boxes that indicate where an object is being dragged, and the components of the application itself such as boxes and arrows. The designer can also specify the behaviors that these graphics exhibit, either by demonstrating them directly, or entering parameters into behavior-defining dialog boxes. Lapidary is unique among graphical interface builders in that it allows the designer to specify the contents of the application window, not just the widgets that surround it.Lapidary is being developed as part of the Garnet project at Carnegie Mellon\u252c\u00e1\u0393\u00c7\u00aa", "num_citations": "14\n", "authors": ["25"]}
{"title": "A spreadsheet model for using web service data\n", "abstract": " Web services offer a more reliable and efficient way to access online data than scraping web pages. However, web service data are often in complex hierarchical structures that make it difficult for people to extract the desired parts or to perform any further data manipulation without writing a significant amount of surprisingly intricate code. In this paper, we present Gneiss, a tool that extends the familiar spreadsheet metaphor to support working with data returned from web services. Gneiss allows users to extract the desired fields in web service data using drag-and-drop, and refine the results through spreadsheet formulas, along with sorting and filtering the data. Hierarchical data are stored as nested tables in the spreadsheet and can be flattened for future operations. Data flow is two-way between the spreadsheet and the web services, enabling people to easily make a new request by modifying spreadsheet cells. In\u252c\u00e1\u0393\u00c7\u00aa", "num_citations": "13\n", "authors": ["25"]}
{"title": "A plug-in architecture for connecting to new data sources on mobile devices\n", "abstract": " A key use for mobile devices is to search and view online information while on the go. As a result, many mobile applications serve as front ends for online databases. While there are many thousands of data sources that provide web service APIs giving access to their databases, creating mobile applications to use those sources requires significant mobile programming knowledge and a significant amount of time. We introduce Spinel, a plug-in architecture for Android, and a set of web-based configuration tools that together enable users to connect mobile applications to new data sources without programming. Spinel also provides APIs that make it easy for developers to create new applications that use those data sources. We provide three demonstration Android applications that use such data: Listpad for entering personal lists, Listviewer for viewing results of data queries, and Mapviewer for displaying query\u252c\u00e1\u0393\u00c7\u00aa", "num_citations": "13\n", "authors": ["25"]}
{"title": "Designing useful tools for developers\n", "abstract": " Designing useful tools for developers requires identifying and understanding an important problem developers face and designing a solution that addresses this problem. This paper describes a design process that uses data to understand problems, design solutions, and evaluate solutions' usefulness.", "num_citations": "13\n", "authors": ["25"]}
{"title": "On the importance of understanding the strategies that developers use\n", "abstract": " Understanding the strategies that developers use during coding activities is an important way to identify challenges developers face and the corresponding opportunities for tools, languages, or processes to better address the challenges and more effectively support the strategies. After creating a design, evaluation studies often measure task success, time, and bugs to argue that the design improves programmer productivity. Considering the strategies that developers use while conducting these studies increases the likelihood of a successful test and makes the results easier to generalize. Therefore, we believe that identifying strategies developers use is an important goal. Beyond identifying strategies, there are also research opportunities in better understanding how developers choose strategies.", "num_citations": "13\n", "authors": ["25"]}
{"title": "Scenario-based requirements for web macro tools\n", "abstract": " Web macros automate interactions with Web sites and related information systems. Though Web macro recorders and players have grown in sophistication over the past decade, these tools cannot yet meet many needs of users in daily life. Based on observations of browser users, we have compiled ten scenarios describing tasks that users would benefit from automating. Our analysis of these scenarios yields specific requirements that Web macro tools should support if those tools are to be applicable to these real-life tasks. Our set of requirements constitutes a benchmark for evaluating tools.", "num_citations": "13\n", "authors": ["25"]}
{"title": "Visual programming in a visual shell\u0393\u00c7\u00f6A unified approach\n", "abstract": " Pursuit is a desktop interface designed to enable non-programmers to construct programs that automate routine repetitive tasks in a way that is consistent with the direct manipulation paradigm. Pursuit combines a Programming by Demonstration (PBD) interface with an editable, visual program representation language. The representation language differs from existing visual languages because it explicitly represents data objects and implicitly represents operations by changes to the data objects. In addition, the language provides concise ways to handle and represent error conditions and dialog boxes.", "num_citations": "13\n", "authors": ["25"]}
{"title": "Developing the family support tool: an interactive, web-based tool to help families navigate the complexities of surrogate decision making in ICUs\n", "abstract": " IntroductionAlthough family members of incapacitated, critically ill patients often struggle in the role of surrogate decision maker, there are no low-cost, easily-scaled interventions to address this problem.Aim of the studyTo develop and pilot-test the Family Support Tool, an interactive, web-based tool to help individuals navigate the complexities of surrogate decision making in ICUs.Material and methodsWe used a mixed methods, user-centered process to create the Family Support Tool, including: 1) creation of a preliminary design by an expert panel; 2) engagement of a key stakeholder panel to iteratively refine the preliminary design; 3) user testing of a low-fidelity prototype of the tool by 6 former ICU surrogates; 4) creation of a web-based prototype; and 5) user testing of the web-based prototype with 14 surrogates and ICU physicians, including semi-structured interviews and quantitative measurement of usability\u252c\u00e1\u0393\u00c7\u00aa", "num_citations": "12\n", "authors": ["25"]}
{"title": "Parsing graphic function sequences\n", "abstract": " With the rapid progress of desktop publishing, documents containing both texts and pictures can be easily composed on a computer display. In terms of the internal representation, pictures included in visual documents are usually represented as a sequence of graphic function calls. The paper describes an analysis technique for pictures which are expressed by means of graphic function sequences. This technique has a wide application area such as compilation of visual languages, information retrieval from visual documents, and so forth. The authors introduce graphic functional grammars in order to specify syntactic structures of pictures. Graphic functional grammars are based on definite clause grammar, which has been proposed for describing the syntax of natural languages. A vocabulary consists of not just symbols but graphic functions. A power of describing sentence structures are also enhanced by\u252c\u00e1\u0393\u00c7\u00aa", "num_citations": "12\n", "authors": ["25"]}
{"title": "Gneiss: spreadsheet programming using structured web service data\n", "abstract": " Web services offer a more reliable and efficient way to access online data than scraping web pages. However, interacting with web services to retrieve data often requires people to write a lot of code. Moreover, many web services return data in complex hierarchical structures that make it difficult for people to perform any further data manipulation. We developed Gneiss, a tool that extends the familiar spreadsheet metaphor to support using structured web service data. Gneiss lets users retrieve or stream arbitrary JSON data returned from web services to a spreadsheet using interaction techniques without writing any code. It introduces a novel visualization that represents hierarchies in data using nested spreadsheet cells and allows users to easily reshape and regroup the extracted structured data. Data flow is two-way between the spreadsheet and the web services, enabling people to easily make a new web\u252c\u00e1\u0393\u00c7\u00aa", "num_citations": "11\n", "authors": ["25"]}
{"title": "Debugging interface\n", "abstract": " A software tool and method is provided in which a user can ask questions about their computer programs. As the subject program is executed, information is collected about the units of code that are executed and the changes to data. The user can pause the program, for example by pressing a button labeled \u0393\u00c7\u00a3Why\u0393\u00c7\u00a5, which will prompt the user to select what they want to ask about. For example, the user can ask about why units of code did or did not get executed. The tool and method provide answers that can be in the form of prepared statements and interactive data and control flow visualizations that show the values of data and the particular units of code that caused the execution to occur or not occur. The user can ask further questions using the visualization.", "num_citations": "11\n", "authors": ["25"]}
{"title": "Enabling devices, empowering people: The design and evaluation of Trackball EdgeWrite\n", "abstract": " Purpose. To describe the research and development that led to Trackball EdgeWrite, a gestural text entry method that improves desktop input for some people with motor impairments. To compare the character-level version of this technique with a new word-level version. Further, to compare the technique with competitor techniques that use on-screen keyboards.Method. A rapid and iterative design-and-test approach was used to generate working prototypes and elicit quantitative and qualitative feedback from a veteran trackball user. In addition, theoretical modelling based on the Steering law was used to compare competing designs.Results. One result is a refined software artifact, Trackball EdgeWrite, which represents the outcome of this investigation. A theoretical result shows the speed benefit of word-level stroking compared to character-level stroking, which resulted in a 45.0% improvement. Empirical results\u252c\u00e1\u0393\u00c7\u00aa", "num_citations": "11\n", "authors": ["25"]}
{"title": "Text input to handheld devices for people with physical disabilities\n", "abstract": " There has been little study of how to adapt handheld devices for use by people with physical disabilities. We found that the tiny stylus keyboards on PalmOS devices work well for some people with Muscular Dystrophy, who tend to have good accuracy but little strength or range of motion. However, for people with other disabilities, such as Cerebral Palsy, Parkinson's Disease and other neuro-muscular disorders, accuracy is a problem. Text entry is also difficult on handhelds for able-bodied users some situations, such as when using small mobile devices while walking or riding. The EdgeWrite text entry technique is a new design which provides better stability of motion due to tracing along physical edges, ease of learning due to the similarity of its letters to Roman characters, and a simple implementation on a wide variety of input devices. Studies suggest that EdgeWrite works well when implemented for use with a stylus on a handheld device, a joystick on a power wheelchair or a videogame controller, and for a touchpad on a desktop computer. Future implementations will explore desktop text entry using a trackball and mobile phone text entry using tactile bumps.", "num_citations": "11\n", "authors": ["25"]}
{"title": "The case for an open data model\n", "abstract": " The trend in modern software systems such as Java is to support reflection, wherein independent software can query to find out the properties of objects. The authors have been investigating the implications of taking this property even further, so that all aspects of an application are open and available to inspection by external software. By giving the fundamental data structures of the application a standard format, external components can access the information they need without requiring a complex protocol. The authors have found that this gives the application developer and end users many important benefits, including support for increased automation, extensive end-user customization capabilities, external agents and tutors, sophisticated search and replace, scripting and macros, alternative interfaces without re-implementing the application, plug-ins that operate in the same space, and significantly higher re-use of common code. Many of these benefits are demonstrated in their Amulet user interface development environment, which uses the open data model.Descriptors:", "num_citations": "11\n", "authors": ["25"]}
{"title": "Authoring interactive behaviors for multimedia\n", "abstract": " The tools for authoring multimedia presentations start with sophisticated interactive tools like Director and ToolBook. However, to make the presentations truly interactive requires programming in \u0393\u00c7\u00a3scripting languages.\u0393\u00c7\u00a5 These languages have generally been difficult to learn for non-programmers.\u0393\u00c7\u00a3Interactive behaviors\u0393\u00c7\u00a5 allow users to click on, move, or otherwise interact with objects on the screen, as opposed to just watching the presentation like a TV show. Behaviors range from simply clicking on buttons or links, to sophisticated interactions with computerized characters. This paper presents a variety of ways we are studying to make authoring of these interactive behaviors more accessible to non-programmers. One approach is \u0393\u00c7\u00a3demonstrational\u0393\u00c7\u00a5 techniques, where the author gives examples of the desired actions and results, and the system generates the code to perform the same actions at run time. Using demonstrational techniques has proven successful for specifying simple behaviors. To represent the behaviors and allow the author to edit them, we are investigating new languages which are designed to be more \u0393\u00c7\u00a3natural\u0393\u00c7\u00a5 because they are based on how non-programmers actually think about these tasks. Human-factors studies have been performed to investigate how people naturally express algorithms. These studies have revealed some general principles which can be applied to the design of new languages, such as that a general case is often expressed first, with exceptions afterwards, and that loops are avoided by applying operations to sets of objects. Using these new results, along with results from the fields of Empirical Studies of\u252c\u00e1\u0393\u00c7\u00aa", "num_citations": "11\n", "authors": ["25"]}
{"title": "Designing interactive error recovery methods for speech interfaces\n", "abstract": " We present an approach to interactive recovery from speech recognition errors in the context of spoken language applications, which is motivated from research in the field of linguistics on repair dialogues in human to human conversations. We propose a framework to compare error recovery methods, arguing that a rational user will prefer error recovery methods which provide an optimal trade off between accuracy, speed and naturalness. We conjecture to beat skilled typing in speed, we need real-time speech recognition technology which performs on a 90% word accuracy level. Finally, we describe how we augmented our JANUS speech to speech translation system with prototypical error recovery methods, and presents results from a preliminary evaluation.", "num_citations": "11\n", "authors": ["25"]}
{"title": "Garnet: Uses of demonstrational techniques\n", "abstract": " Garnet | Watch what I do ACM Digital Library home ACM home Google, Inc. (search) Advanced Search Browse About Sign in Register Advanced Search Journals Magazines Proceedings Books SIGs Conferences People More Search ACM Digital Library SearchSearch Advanced Search Browse Browse Digital Library Collections More HomeBrowse by TitleBooksWatch what I do: programming by demonstrationGarnet: uses of demonstrational techniques chapter Garnet: uses of demonstrational techniques Share on Author: Brad Allan Myers profile image Brad A. Myers View Profile Authors Info & Affiliations Publication: Watch what I do: programming by demonstrationAugust 1993 Pages 219\u0393\u00c7\u00f4236 0citation 0 Downloads Metrics Total Citations0 Total Downloads0 Last 12 Months0 Last 6 weeks0 Get Citation Alerts New Citation Alert added! This alert has been successfully added and will be sent to: You will be notified . .\u0393\u00c7\u00aa", "num_citations": "11\n", "authors": ["25"]}
{"title": "Multi-Modal Repairs of Conversational Breakdowns in Task-Oriented Dialogs\n", "abstract": " A major problem in task-oriented conversational agents is the lack of support for the repair of conversational breakdowns. Prior studies have shown that current repair strategies for these kinds of errors are often ineffective due to:(1) the lack of transparency about the state of the system's understanding of the user's utterance; and (2) the system's limited capabilities to understand the user's verbal attempts to repair natural language understanding errors. This paper introduces SOVITE, a new multi-modal speech plus direct manipulation interface that helps users discover, identify the causes of, and recover from conversational breakdowns using the resources of existing mobile app GUIs for grounding. SOVITE displays the system's understanding of user intents using GUI screenshots, allows users to refer to third-party apps and their GUI screens in conversations as inputs for intent disambiguation, and enables users to\u252c\u00e1\u0393\u00c7\u00aa", "num_citations": "10\n", "authors": ["25"]}
{"title": "A user study to inform the design of the obsidian blockchain dsl\n", "abstract": " Blockchain platforms such as Ethereum and Hyperledger facilitate transactions between parties that have not established trust. Increased interest in these platforms has motivated the design of programming languages such as Solidity, which allow users to create blockchain programs. However, there have been several recent instances where Solidity programs have contained bugs that have been exploited. The security of blockchain programs is especially important given that they commonly involve the exchange of money or other objects with real-world value. We are currently developing a blockchain-based programming language called Obsidian with the goal of minimizing the risk of common security vulnerabilities. We are designing this language in a humancentered way, conducting exploratory user studies with a natural programming approach to inform our design choices. In this paper, we discuss our approach to the design of a user study, as well as our preliminary findings.", "num_citations": "10\n", "authors": ["25"]}
{"title": "Semantic zooming of code change history\n", "abstract": " Previously, we presented our technique for visualizing fine-grained code changes in a timeline view, designed to facilitate reviewing and interacting with the code change history. During user evaluations, it became evident that users often wanted to see the code changes at a higher level of abstraction. Therefore, we developed a novel approach to automatically summarize fine-grained code changes into more conceptual, higher-level changes in real time. Our system provides four collapse levels, which are integrated with the timeline via semantic zooming: raw level (no collapsing), statement level, method level, and type level. Compared to the raw level, the number of code changes shown in the timeline at each level is reduced by 55%, 77%, and 83%, respectively. This implies that the semantic zooming would help users better understand and interact with the history by minimizing the potential information overload.", "num_citations": "10\n", "authors": ["25"]}
{"title": "A spreadsheet model for handling streaming data\n", "abstract": " We present a spreadsheet model for working with streaming data. Our prototype tool presents techniques to let the user stream data from web services and web input elements to a spreadsheet without preprogramming those sources into the tool. Spreadsheet cells record metadata about where and when the data came from, allowing the user to view and manipulate streaming data using temporal information. Starting and pausing a data stream in the spreadsheet can be controlled programmatically using values computed by spreadsheet cells, making the spreadsheet program highly dynamic and interactive. We demonstrate the range of our design with a series of examples highlighting its ability to create different kinds of applications that process real-time data from the web using simple spreadsheet formulas.", "num_citations": "10\n", "authors": ["25"]}
{"title": "Fast, accurate creation of data validation formats by end-user developers\n", "abstract": " Inputs to web forms often contain typos or other errors. However, existing web form design tools require end-user developers to write regular expressions (\u0393\u00c7\u00a3regexps\u0393\u00c7\u00a5) or even scripts to validate inputs, which is slow and error-prone because of the poor match between common data types and the regexp notation. We present a new technique enabling end-user developers to describe data as a series of constrained parts, and we have incorporated our technique into a prototype tool. Using this tool, end-user developers can create validation code more quickly and accurately than with existing techniques, finding 90% of invalid inputs in a lab study. This study and our evaluation of the technique\u0393\u00c7\u00d6s generality have motivated several tool improvements, which we have implemented and now evaluate using the Cognitive Dimensions framework.", "num_citations": "10\n", "authors": ["25"]}
{"title": "End-user software engineering and professional end-user developers\n", "abstract": " There is a great variety of end user developers and a great variety of contexts within which they develop. End user developers may have little or no experience of using computers \u251c\u00e2\u252c\u00f3 \u251c\u00f3 \u0393\u00c7\u00dc\u252c\u00bc \u251c\u00f3\u0393\u00e9\u00bc \u253c\u00f4 or may be adept coders in general purpose programming languages. They may develop their software on their own over a few minutes \u251c\u00e2\u252c\u00f3 \u251c\u00f3 \u0393\u00c7\u00dc\u252c\u00bc \u251c\u00f3\u0393\u00e9\u00bc \u253c\u00f4 or in groups over years. The software produced may be for their own use only \u251c\u00e2\u252c\u00f3 \u251c\u00f3 \u0393\u00c7\u00dc\u252c\u00bc \u251c\u00f3\u0393\u00e9\u00bc \u253c\u00f4 or for a large community of users. It may be inconsequential \u251c\u00e2\u252c\u00f3 \u251c\u00f3 \u0393\u00c7\u00dc\u252c\u00bc \u251c\u00f3\u0393\u00e9\u00bc \u253c\u00f4 or the consequences of its failure may be great. In this paper, we identify and discuss the problems of one particular group of end user developers \u251c\u00e2\u252c\u00f3 \u251c\u00f3 \u0393\u00c7\u00dc\u252c\u00bc \u251c\u00f3\u0393\u00e9\u00bc \u253c\u00f4 professional end user developers \u251c\u00e2\u252c\u00f3 \u251c\u00f3 \u0393\u00c7\u00dc\u252c\u00bc \u251c\u00f3\u0393\u00e9\u00bc \u253c\u00f4 who have no fear of coding and who develop software which plays a vital part in furthering their professional goals.", "num_citations": "10\n", "authors": ["25"]}
{"title": "Joystick text entry with date stamp, selection keyboard, and EdgeWrite\n", "abstract": " ResultsData were analyzed using a mixed model ANOVA. Means are reported for tasks 2-10 due to learning in task 1. Results are reported below in this order: EdgeWrite, date stamp, selection keyboard. Standard deviations are in parentheses.", "num_citations": "10\n", "authors": ["25"]}
{"title": "Making structured graphics and constraints practical for large-scale applications\n", "abstract": " Providing a structured graphics model and a constraint system makes the programming of graphical applications significantly easier. In a structured graphics model, each graphic element on the screen is represented by a real object in the object system, while a constraint system automatically maintains relationships among the objects. Although many research systems and a few commercial environments provide structured graphics and constraints, none scale up to large interfaces with thousands of objects and thousands of constraints. This paper presents four techniques to overcome this problem automatic elimination of constraints that depend only on values that do not change, layout hints to help with refresh and hit detection, virtual aggregates that only pretend to allocate objects for their components, and compiling composite aggregates into a single object with a complex draw method. These have been implemented as part of the Garnet environment, and we have demonstrated that together they allow structured graphics and constraints to scale up to applications with tens of thousands of objects and constraints without compromising the ease-of-use.Descriptors:", "num_citations": "10\n", "authors": ["25"]}
{"title": "Interactive task learning from GUI-grounded natural language instructions and demonstrations\n", "abstract": " We show SUGILITE, an intelligent task automation agent that can learn new tasks and relevant associated concepts interactively from the user\u0393\u00c7\u00d6s natural language instructions and demonstrations, using the graphical user interfaces (GUIs) of third-party mobile apps. This system provides several interesting features:(1) it allows users to teach new task procedures and concepts through verbal instructions together with demonstration of the steps of a script using GUIs;(2) it supports users in clarifying their intents for demonstrated actions using GUI-grounded verbal instructions;(3) it infers parameters of tasks and their possible values in utterances using the hierarchical structures of the underlying app GUIs; and (4) it generalizes taught concepts to different contexts and task domains. We describe the architecture of the SUGILITE system, explain the design and implementation of its key features, and show a prototype in the form of a conversational assistant on Android.", "num_citations": "9\n", "authors": ["25"]}
{"title": "Citrus\n", "abstract": " Citrus is grown throughout the world in tropical and subtropical climates. The crops are grown primarily in a belt between 40 N and 40 S latitude, except at high elevations. Minimum temperature is the limiting factor, though the killing effect varies with variety, rootstock, absolute minimum and its duration, and dormancy of trees. Citrus appears to require the same complement of essential nutrient elements as other fruit trees. Perhaps the most distinctive thing about the nutrition of citrus is the large number of deficiencies of nutrient elements that have appeared under intensive cultivation. Foliage symptoms of deficiencies of N, P, K, Ca, Mg, Mn, Zn, Cu, Fe, B and Mo have been recognized in the field as well as in artificial cultures. Nitrogen is the key element in citrus fertilization and has pronounced effects on the growth and appearance of the tree, fruit production and fruit quality. It is used more extensively than any other\u252c\u00e1\u0393\u00c7\u00aa", "num_citations": "9\n", "authors": ["25"]}
{"title": "An end user development approach for failure handling in goal-oriented conversational agents\n", "abstract": " This chapter introduces an end user development (EUD) approach for handling common types of failures encountered by goal-oriented conversational agents. We start with identifying three common sources of failures in human-agent conversations: unknown concepts, out-of-domain tasks and wrong fulfillment means or level of generalization in task execution. To handle these failures, it is useful to enable the end user to program the agent and to \u0393\u00c7\u00a3teach\u0393\u00c7\u00a5 the agent what to do as a fallback strategy. Showing examples for this approach, we walk through our two integrated systems: SUGILITE and LIA. SUGILITE uses the programming by demonstration (PBD) technique, allowing the user to program the agent by demonstrating new tasks or new means for completing a task using the GUIs of third-party smartphone apps, while LIA learns new tasks from verbal instructions, enabling the user to teach the agent through breaking down the procedure verbally. LIA also supports the user to verbally define unknown concepts used in the commands and adds those concepts into the agent\u0393\u00c7\u00d6s ontology. Both SUGILITE and LIA can generalize what they have learned from the user across related entities and perform a task with new parameters in a different context.", "num_citations": "9\n", "authors": ["25"]}
{"title": "Empirical studies on the security and usability impact of immutability\n", "abstract": " Although it is well-known that API design has a large and long-term impact on security, the literature contains few substantial guidelines for practitioners on how to design APIs that improve security. Even fewer of those guidelines have been evaluated empirically. Security professionals have proposed that software engineers choose immutable APIs and architectures to enhance security. Unfortunately, prior empirical research argued that immutablity decreases API usability. This paper brings together the results from a number of previous papers that together aim to show that immutability, when carefully designed using usability as a first-class requirement, can have positive effects on both usability and security. We also make observations on study design in this field.", "num_citations": "9\n", "authors": ["25"]}
{"title": "How to Support Designers in...\n", "abstract": " When designing novel GUI controls, interaction designers are challenged by the \u0393\u00c7\u00a3immaterial\u0393\u00c7\u00a5 materiality of the digital domain; they lack tools that effectively support a reflecting conversation with the material of software as they attempt to conceive, refine, and communicate their ideas. To investigate this situation, we conducted two participatory design workshops. In the first workshop, focused on conceiving, we observed that designers want to invent controls by exploring gestures, context, and examples. In the second workshop, on refining and communicating, designers proposed tools that could refine movement, document context through usage scenarios, and support the use of examples. In this workshop they struggled to effectively communicate their ideas for developers because their ideas had not been fully explored. In reflecting on this struggle, we began to see an opportunity for the output of a design tool to be a boundary object that would allow for an ongoing conversation between the design and the material of software, in which the developer acts as a mediator for software.", "num_citations": "9\n", "authors": ["25"]}
{"title": "End-User Design\n", "abstract": " Are UML diagrams a good tool to teach middle school students how to make video games? Probably not, but what kinds end-user design aids such as mental models, scaffolding structures, examples or other kinds of objects to think we can we give to end-users in order to gradually introduce them to good programming practice?", "num_citations": "9\n", "authors": ["25"]}
{"title": "End user programming for scientists: Modeling complex systems\n", "abstract": " Towards the end of the 20th century, a paradigm shift took place in many scientific labs. Scientists embarked on a new form of scientific inquiry seeking to understand the behavior of complex adaptive systems that increasingly defied traditional reductive analysis. By combining experimental methodology with computer-based simulation tools, scientists gain greater understanding of the behavior of systems such as forest ecologies, global economies, climate modeling, and beach erosion. This improved understanding is already being used to influence policy in critical areas that will affect our nation\u251c\u00e2\u252c\u00f3 \u251c\u00f3 \u0393\u00c7\u00dc\u252c\u00bc \u251c\u00f3 \u0393\u00c7\u20a7\u252c\u00f3 s future, and the world\u251c\u00e2\u252c\u00f3 \u251c\u00f3 \u0393\u00c7\u00dc\u252c\u00bc \u251c\u00f3 \u0393\u00c7\u20a7\u252c\u00f3 s.", "num_citations": "9\n", "authors": ["25"]}
{"title": "Just draw it! Programming by sketching storyboards\n", "abstract": " Current interactive user interface construction tools make it hard for a user interface designer to illustrate the behavior of an interface. These tools focus on specifying widgets and making it easy to manipulate details such as colors, alignment, and fonts. They can show what the interface will look like, but make it hard to show what it will do, since they require programming or scripting in order to specify all but the most trivial interactions. For these reasons, most interface designers, especially those who have a background in graphic design, prefer to sketch early interface ideas on paper or on a whiteboard. We have developed an interactive tool called SILK that allows designers to quickly sketch an interface using an electronic pad and stylus. However, unlike a paper sketch, this electronic sketch is interactive. The designer can illustrate behaviors by sketching storyboards, which specify how the screen should change in response to end-user actions. This paper describes our storyboarding mechanism and provides design ideas for a production-level system.Descriptors:", "num_citations": "9\n", "authors": ["25"]}
{"title": "The design for the amulet user interface toolkit\n", "abstract": " Amulet is a new user interface software environment for C++ to support future user interface software research. This environment, which will be portable across X/11, Microsoft Windows, and the Macintosh, is designed to be very flexible: parts can be replaced and new technologies and widgets can be easily created and evaluated. Built-in support will be provided for direct manipulation, multi-font text editing, gesture recognition, speech recognition, 2-D and 3-D animations, visualizations including maps and large data sets, world-wide-web browsing and editing, and multiple people interacting with the system at the same time (CSCW). Another goal is to be useful for students, which means that Amulet must be easy to learn. Finally, the system will provide sufficient performance, robustness and documentation so it will be useful for general user interface developers.", "num_citations": "9\n", "authors": ["25"]}
{"title": "Tourmaline (abstract) macrostyles by example\n", "abstract": " Tourmaline is a system that simplifies the formatting of complicated headings and captions in a WYSIWYG word precessor. The style systems of typical commercial word processors, although very useful, are too limited when a user needs to format items such as paper headings, which may contain many different styles within a single heading. The style systems of some batch oriented systems give the user more power by providing macro facilities to automatically format text, but these systems are extremely difficult to learn and use. Tourma. line uses demonstrational techniques[2] to combine the ease-ofuse of WYSIWYG with the power of batch oriented text formatters. The system allows users to define macr-osfyles by example. A macrostyle is an abstract representation of a text object that allows different parts of the object to have completely different formatting attributes.In Tourmaline, the user provides an example\u252c\u00e1\u0393\u00c7\u00aa", "num_citations": "9\n", "authors": ["25"]}
{"title": "Can advanced type systems be usable? An empirical study of ownership, assets, and typestate in obsidian\n", "abstract": " Some blockchain programs (smart contracts) have included serious security vulnerabilities. Obsidian is a new typestate-oriented programming language that uses a strong type system to rule out some of these vulnerabilities. Although Obsidian was designed to promote usability to make it as easy as possible to write programs, strong type systems can cause a language to be difficult to use. In particular, ownership, typestate, and assets, which Obsidian uses to provide safety guarantees, have not seen broad adoption together in popular languages and result in significant usability challenges. We performed an empirical study with 20 participants comparing Obsidian to Solidity, which is the language most commonly used for writing smart contracts today. We observed that Obsidian participants were able to successfully complete more of the programming tasks than the Solidity participants. We also found that the\u252c\u00e1\u0393\u00c7\u00aa", "num_citations": "8\n", "authors": ["25"]}
{"title": "Evaluating the usability and acceptability of communication tools among older adults\n", "abstract": " Acutely ill patients may have trouble communicating their symptoms and needs verbally. The current study evaluated the usability and acceptability of six commercially available communication tools with older adults in a non-clinical, controlled setting. Participants evaluated various communication boards and communication applications (apps) by using the tools to communicate needs and symptoms in various scenarios. Participants completed a modified technology acceptance questionnaire and selected the tool they perceived as most useful and easy to use. Bivariate analysis was used to compare communication boards and apps. Performance on most tasks was significantly better using communication boards compared to communication apps. However, participants reported that given more time and training, the apps could be used effectively. A feasibility study is needed to determine whether acutely ill older\u252c\u00e1\u0393\u00c7\u00aa", "num_citations": "8\n", "authors": ["25"]}
{"title": "Barriers to successful end-user programming\n", "abstract": " In my research and my personal life, I have come to know numerous people that our research community might call end-user programmers. Some of them are scientists, some are artists, others are educators and other types of professionals. One thing that all of these people have in common is that their goals are entirely unrelated to producing code. In some cases, programming may be a necessary part of accomplishing their goals, such as a physicist writing a simulation in C or an interaction designer creating an interactive prototype. In other cases, programming may simply be the more efficient alternative to manually solving a problem: one might find duplicate entries in an address book by visual search or by writing a short Perl script.", "num_citations": "8\n", "authors": ["25"]}
{"title": "The Topes Format Editor and Parser\n", "abstract": " It is currently difficult and time-consuming to validate and manipulate data in web applications, so we have developed an editor and a parser to simplify these tasks. Our editor enables end-user programmers to create and debug reusable, flexible data formats without learning a complex new language. Our parser uses these formats to turn strings into structured objects and to report its level of confidence that each string is a valid instance of the format. End-user programmers can use our system to create validation code that takes a graduated response to slightly invalid data. We evaluate our system\u0393\u00c7\u00d6s expressiveness by defining formats for commonly-occurring web data.", "num_citations": "8\n", "authors": ["25"]}
{"title": "Automatically generating interfaces for multi-device environments\n", "abstract": " With the increasing pervasiveness of wireless technologies, users will increasingly want to interact with appliances in their environment from their mobile device. One of the challenges to supporting such ubiquitous control is the creation of user interfaces for the mobile device. Should the mobile device be pre-programmed with interfaces for each appliance that it can control, should it download pre-designed user interfaces from each appliance, or should it download an abstract description of the appliance and then automatically generate a user interface to enable control? In this position paper we describe the Personal Universal Controller project, which is studying the automatic generation solution to this problem, and show how our infrastructure supports multi-device environments, which could contain a peripheral awareness device.", "num_citations": "8\n", "authors": ["25"]}
{"title": "Studying development and debugging to help create a better programming environment\n", "abstract": " The event-based style is increasingly common in modern end-user programming languages. Visual Basic, Macromedia\u0393\u00c7\u00d6s Director, web scripting languages, as well as many recent novice-geared research prototypes such as Alice [9] and HANDS [8], provide event-based constructs and user interfaces, enabling programmers to create highly interactive environments. Yet very few of the user studies of programming environments and language usability investigate the event-based style. Since recent studies suggest that language paradigm is a predictor of program comprehension and programming strategies [2][6], eventbased programming environments and their user interfaces should be tailored to the event-based style.As part of the Natural Programming Project (http://www. cs. cmu. edu/~ NatProg/) we have begun to investigate how end users create, test, and debug eventbased programs in an effort to guide the design of novel programming environment tools for end-user event-based languages. While our research has thus-far focused on Alice (see Figure 1), a system for novice programmers, we believe that the techniques we are proposing will be useful to novice and expert programmers using more general languages with event support such as Visual Basic, Java and C#.", "num_citations": "8\n", "authors": ["25"]}
{"title": "Handheld devices for control\n", "abstract": " With  present  and  future wireless  technologies,  such  as  IEEE  802.11, BlueTooth, RF-Lite,  and G3,  handheld  devices will  frequently  be  in  close,  interactive  communication. Many  environments,  including  offices,  meeting  rooms,  automobiles  and  classrooms  already  contain many  computers  and  computerized  appliances,  and  the smart homes of the future will have ubiquitous embedded computation. When the user enters one of these environments  carrying a handheld device, how will that device interact with the environment? We are exploring, as  part of the Pebbles research project, the many ways that handheld devices such as PalmOS Organizers, PocketPC  and Windows CE devices, and smart cell phones can serve as useful adjuncts to the \u0393\u00c7\u00a3fixed\u0393\u00c7\u00a5 computers and computerized  appliances in the user\u0393\u00c7\u00d6s vicinity. This brings up many interesting research questions, such as: How can  the handheld device improve the user interfaces of everything else in the user\u0393\u00c7\u00d6s environment, rather than being just  be another complex gadget that must be learned? What is the best way to provide a user interface that spans multiple  devices that are in use at the same time? How will users and systems decide which functions should be presented  and in what manner on what device? How can the user\u0393\u00c7\u00d6s handheld device be effectively used as a \u0393\u00c7\u00a3Personal  Universal Controller\u0393\u00c7\u00a5 to provide an easy-to-use and familiar interface to all of the complex appliances available to  a user? How can communicating handheld devices enhance the effectiveness of meetings and classroom lectures?  We present some preliminary observations on these issues, and\u252c\u00e1\u0393\u00c7\u00aa", "num_citations": "8\n", "authors": ["25"]}
{"title": "Using AI techniques to create user interfaces by example\n", "abstract": " Using AI techniques to create user interfaces by example | Intelligent user interfaces ACM Digital Library Logo ACM Logo Google, Inc. (search) Advanced Search Browse About Sign in Register Advanced Search Journals Magazines Proceedings Books SIGs Conferences People More Search ACM Digital Library SearchSearch Advanced Search Browse Browse Digital Library Collections More HomeBrowse by TitleBooksIntelligent user interfacesUsing AI techniques to create user interfaces by example chapter Using AI techniques to create user interfaces by example Share on Author: Brad A. Myers profile image Brad A. Myers Univ. of Toronto, Toronto, Ont., Canada Univ. of Toronto, Toronto, Ont., Canada View Profile Authors Info & Affiliations Publication: Intelligent user interfacesMay 1991 Pages 385\u0393\u00c7\u00f4401https://doi.org/10.1145/107215.128719 1citation 0 Downloads Metrics Total Citations1 Total Downloads0 Last ! \u0393\u00c7\u00aa", "num_citations": "8\n", "authors": ["25"]}
{"title": "User interface programming survey\n", "abstract": " Are you tired of seeing papers start out with a line like \"user interfaces are hard to build and take 28% to 75% of the development time\" followed by a reference like (Sutton 78)? We are, and anecdotal evidence suggests that the percentage spent on the user interface is rising. Therefore, we are attempting to get more relevant and realistic data about the proportion of code and effort that is devoted to programming user interfaces in end-user applications. If you have experience with this aspect of application programming either in industry or research labs, we would very much appreciate your responses to the questions in this survey. If you have worked on an appropriate system but you do not feel qualified to answer this survey, please pass it along to someone who can answer the questions. Also, if you know someone who we might ask to participate, please send us his or her name and address. We will mail a copy\u252c\u00e1\u0393\u00c7\u00aa", "num_citations": "8\n", "authors": ["25"]}
{"title": "Marble: Mining for boilerplate code to identify API usability problems\n", "abstract": " Designing usable APIs is critical to developers' productivity and software quality, but is quite difficult. One of the challenges is that anticipating API usability barriers and real-world usage is difficult, due to a lack of automated approaches to mine usability data at scale. In this paper, we focus on one particular grievance that developers repeatedly express in online discussions about APIs: \"boilerplate code.\" We investigate what properties make code count as boilerplate, the reasons for boilerplate, and how programmers can reduce the need for it. We then present MARBLE, a novel approach to automatically mine boilerplate code candidates from API client code repositories. MARBLE adapts existing techniques, including an API usage mining algorithm, an AST comparison algorithm, and a graph partitioning algorithm. We evaluate MARBLE with 13 Java APIs, and show that our approach successfully identifies both\u252c\u00e1\u0393\u00c7\u00aa", "num_citations": "7\n", "authors": ["25"]}
{"title": "Interstate: Interaction-oriented language primitives for expressing gui behavior\n", "abstract": " The event-callback programming model used by most GUI development frameworks frequently leads to disorganized and hard-to-maintain code. We believe there is significant value in designing language primitives that expressly address the challenges of writing and re-using GUI code. To explore this, we created InterState, a language and programming environment for expressing interactive behaviors in graphical applications. With InterState, programmers express behaviors declaratively as combinations of states and constraints. InterState introduces new primitives for defining and re-using behaviors, a visual notation for these primitives, and a live editor. We conducted a laboratory study to evaluate InterState\u0393\u00c7\u00d6s usability and found that participants were faster at understanding and modifying GUI components written in InterState than in event-callback code. Additionally, to better understand InterState\u0393\u00c7\u00d6s scope and\u252c\u00e1\u0393\u00c7\u00aa", "num_citations": "7\n", "authors": ["25"]}
{"title": "Euclase: A live development environment with constraints and FSMs\n", "abstract": " Euclase is a live development environment focused on creating interactive web applications. It uses a programming model that combines constraints and finite state machines to specify interactive behaviors. Euclase is \u0393\u00c7\u00a3live\u0393\u00c7\u00a5 in the sense that while the user is developing code, their program is always executing. Changes made to the source of the program are reflected immediately in the running program. We identify some of the implementation and design challenges of making our development environment live, including performance issues, ensuring predictability, dealing with errors in the source, and handling edge cases such as the removal of code that is currently running. We also discuss how Euclase's use of finite state machines and constraints can help alleviate these difficulties.", "num_citations": "7\n", "authors": ["25"]}
{"title": "Creativity support in authoring and backtracking\n", "abstract": " The \u0393\u00c7\u00a3Natural Programming\u0393\u00c7\u00a5 group has been working for 15 years on making it easier for all kinds of programmers to be creative when writing software. Recently, one focus has been enabling \u0393\u00c7\u00a3end-user programmers\u0393\u00c7\u00a5(EUPs) such as interaction designers to more easily author interactive behaviors for the web. In a separate project, we are adding features to a code editor to support \u0393\u00c7\u00a3backtracking\u0393\u00c7\u00a5\u0393\u00c7\u00f6undoing operations to partially or fully restore the code to a previous state\u0393\u00c7\u00f6since creative exploration usually involves both moving forward to new designs and going backwards to retract some or all of the design that is not desired. In all of these projects, we seek to measure both the usability of our tools, and their effectiveness at fostering creativity.", "num_citations": "7\n", "authors": ["25"]}
{"title": "Engineering more natural interactive programming systems: keynote talk\n", "abstract": " We are all familiar with computing systems that are used by developers to create interactive computing systems for others. This includes the languages, libraries, and interactive development environments that we use every day. The Natural Programming Project has been working on tools, techniques and methods for designing and developing these systems, using methods from the HCI and Software Engineering fields. We have performed many studies about the barriers developers face performing their tasks, and people's natural expression of algorithms for new applications. We have created a wide variety of languages, tools and techniques that take advantage of this new knowledge. User studies of these techniques often show a dramatic impact in developer productivity. For example, we studied novice and expert programmers debugging their code, and found that they continuously are asking\" Why\" and\" Why\u252c\u00e1\u0393\u00c7\u00aa", "num_citations": "7\n", "authors": ["25"]}
{"title": "Successful user interfaces for radar\n", "abstract": " We are designing, implementing, and testing the user interface for RADAR (Reflective Agents with Distributed Adaptive Reasoning), which is a large multi-agent system that uses learning to help office workers cope with email overload and to complete routine tasks more efficiently. RADAR provides a mixed-initiative user interface in which artificial intelligence helps users perform the tasks that arrive in email messages. A large-scale user test of RADAR demonstrated the effectiveness of its user interface and AI.", "num_citations": "7\n", "authors": ["25"]}
{"title": "Visualizing and manipulating complex calendar scheduling information\n", "abstract": " Calendar scheduling is a difficult task for people who have overbooked calendars and many constraints. We are collaborating with artificial intelligence researchers, who are developing an intelligent calendar scheduling agent that gathers availability constraints, searches for times that satisfy the constraints, and negotiates with invitees when no satisfactory time is found for the constraints. The agent will never be able to act with complete autonomy because, just like a good human assistant, it will need to consult its supervisor when a task is under-specified, has ambiguous instructions, deviates from the normal, or when the task has changed. Furthermore, users need an interface to tell the agent all of their constraints, to see the agent\u0393\u00c7\u00d6s proposed solutions, and to respond to the agent\u0393\u00c7\u00d6s questions. Currently, calendar applications do not allow users to specify scheduling constraints such as how preferable a free time is for scheduling a new meeting or to what extent an existing meeting can be rescheduled. These requirements inspired the \u0393\u00c7\u00a3availability bar,\u0393\u00c7\u00a5 an interaction and visualization technique for complex, multi-dimensional calendar scheduling constraints. Availability bars were specifically designed to be embedded in calendar applications. Additionally, availability bars will help people who schedule their calendar by hand.", "num_citations": "7\n", "authors": ["25"]}
{"title": "Learning to detect partially labeled people\n", "abstract": " Deployed vision systems often encounter image variations poorly represented in their training data. While observing their environment, such vision systems obtain unlabeled data that could be used to compensate for incomplete training. In order to exploit these relatively cheap and abundant unlabeled data we present a family of algorithms called /spl lambda/MEEM. Using these algorithms, we train an appearance-based people detection model. In contrast to approaches that rely on a large number of manually labeled training points, we use a partially labeled data set to capture appearance variation. One can both avoid the tedium of additional manual labeling and obtain improved detection performance by augmenting a labeled training set with unlabeled data. Further, enlarging the original training set with new unlabeled points enables the update of detection models after deployment without human intervention\u252c\u00e1\u0393\u00c7\u00aa", "num_citations": "7\n", "authors": ["25"]}
{"title": "Towards more natural functional programming languages\n", "abstract": " Programming languages are the way for a person to express a mental plan in a way that the computer can understand. Therefore, it is appropriate to consider properties of people when designing new programming languages. In our research, we are investigating how people think about algorithms, and how programming languages can be made easier to learn and more effective for people to use. By taking human-productivity aspects of programming languages seriously, designers can more effectively match programming language features with human capabilities and problem solving methods. Human factors methods can be used to measure the effects, so unsubstantiated claims can be avoided.This talk will present a quick summary of new and old results in what is known about people and programming, from areas that are sometimes called \"empirical studies of programmers\" and \"psychology of programming\u252c\u00e1\u0393\u00c7\u00aa", "num_citations": "7\n", "authors": ["25"]}
{"title": "Single Display Groupware: Exploring Computer Support for Co-Located Collaboration\n", "abstract": " This panel will explore an interaction paradigm for colocated computer-based collaboration we term Single Display Groupware (SDG). SDG is a class of applications that support multiple simultaneous users interacting in a colocated environment on a single shared display with multiple input-devices. SDG are being used in various applications in the educational, entertainment and research communities, but many issues remain to be explored.", "num_citations": "7\n", "authors": ["25"]}
{"title": "Human-Computer Interaction in the School of Computer Science\n", "abstract": " The School of Computer Science SCS faculty who are interested in Human-Computer Interaction HCI present their position on what role HCI can play in Carnegie Mellons School of Computer Science. The authors present a short description of the need for HCI research and recommend a taskhumancomputer approach to satisfying that need. After presenting illustrative research scenarios, they draw implications of adopting this approach for their research and educational programs. SCS is well positioned to implement this approach, given the interests and skills of the faculty and faculty in other organizations at CMU. The authors recommend that the Computer Science Department form a new area in HCI. Research around the periphery of the taskhumancomputer triad can inform the design of computer systems. The knowledge and techniques resulting from HCI research can help meet the challenges that arise when designing systems of people and artifacts to accomplish complex tasks. Design, in turn, provides the arena within which research problems in HCI can be identified and investigated. To illustrate the potential contribution of HCI in concert with other areas of computer science, this report describes the challenges faced in three hypothetical research areas computer-aided laparoscopic surgery, crisis action planning, and software development.Descriptors:", "num_citations": "7\n", "authors": ["25"]}
{"title": "Screen2Vec: Semantic Embedding of GUI Screens and GUI Components\n", "abstract": " Representing the semantics of GUI screens and components is crucial to data-driven computational methods for modeling user-GUI interactions and mining GUI designs. Existing GUI semantic representations are limited to encoding either the textual content, the visual design and layout patterns, or the app contexts. Many representation techniques also require significant manual data annotation efforts. This paper presents Screen2Vec, a new self-supervised technique for generating representations in embedding vectors of GUI screens and components that encode all of the above GUI features without requiring manual annotation using the context of user interaction traces. Screen2Vec is inspired by the word embedding method Word2Vec, but uses a new two-layer pipeline informed by the structure of GUIs and interaction traces and incorporates screen-and app-specific metadata. Through several sample\u252c\u00e1\u0393\u00c7\u00aa", "num_citations": "6\n", "authors": ["25"]}
{"title": "Human-centered methods for improving API usability\n", "abstract": " Application programming interfaces (APIs) are the way that developers reuse functionality supplied in libraries, software development kits (SDKs), toolkits, frameworks, etc. By adapting a variety of user-centered methods from human-computer interaction (HCI), we have studied usability problems both for API users and for API designers. These studies revealed barriers both at a low level (such as using the factory pattern in an API) and at a high level (such as the lack of example code in the documentation). In lab studies, we have shown that some patterns can slow programmers down by a factor of 10, and in the field, we have seen problematic APIs block programmers for up to a week while they waited for an answer from the API designer. The implications of our results can guide the design of the API, and, when APIs cannot be changed, inspire novel documentation and tools to help use the APIs. Our collaboration\u252c\u00e1\u0393\u00c7\u00aa", "num_citations": "6\n", "authors": ["25"]}
{"title": "Supporting social-emotional development in collaborative inquiry games for K-3 science learning\n", "abstract": " While games for science learning show considerable promise, they tend not to focus on the youngest students. We are engaged in a project to create and evaluate a series of games for science learning for students in Kindergarten through grade 3. These games address a range of educational goals: to help students understand targeted science principles, develop scientific inquiry skill, and deal with situations that call for social-emotional skill. In two of our games, Beanstalk and Teeter Totter Go, players alternate between problem-solving activities and inquiry activities integrated in a single narrative context. The main contribution of the work is a design for science games for young children that synergistically addresses scientific inquiry, social-emotional development, and science content learning. The games serve as platforms for research into how best to support this synergy.", "num_citations": "6\n", "authors": ["25"]}
{"title": "The design and evaluation of user interfaces for the RADAR learning personal assistant\n", "abstract": " The RADAR project developed a large multi-agent system with a mixed-initiative user interface designed to help office workers cope with email overload. Most RADAR agents observe experts performing tasks and then assist other users who are performing similar tasks. The interaction design for RADAR focused on developing user interfaces that allowed the intelligent functionality to improve the user\u0393\u00c7\u00d6s workflow without frustrating the user when the system\u0393\u00c7\u00d6s suggestions were either unhelpful or simply incorrect. For example with regards to autonomy, the RADAR agents were allowed much flexibility in selecting ways to assist the user, but were restricted from taking actions that would be visible to other people. This policy ensured that the user remained in control and mitigated the negative effects of mistakes. A large evaluation of RADAR demonstrated that novice users confronted with an email overload test performed significantly better, achieving a 37% better overall score when assisted by RADAR. The evaluation showed that AI technologies can help users accomplish their goals.", "num_citations": "6\n", "authors": ["25"]}
{"title": "Model-driven development for end-users, too!?\n", "abstract": " Elicitating the requirements and creating a model of a software system are standard activities in the development process of professional software development. The talk discusses whether these two development phases are also present in end-user software development and how they could look like. It is argued that one has to distinguish between at least two types of end-user software developers. Those, who are not professional software developers, but work in an engineering domain and follow stepwise development processes. They are used to have requirements specifications as well as models, too. But, non-professional, non-engineering end-users, eg spreadsheet developers, don\u251c\u00e2\u252c\u00f3 \u251c\u00f3 \u0393\u00c7\u00dc\u252c\u00bc \u251c\u00f3 \u0393\u00c7\u20a7\u252c\u00f3 t and would not like to distinguish between different steps in the development process. Therefore, we propose to hide the distinction between these different steps by closely interconnecting requirements specification, models and code, and by putting them into one development box. By offering appropriate interface functions like create, adapt, refine, etc. to the box, the end-user is supported in developing software without being aware that he is undergoing a stepwise refinement process from requirements specifications towards concrete code.", "num_citations": "6\n", "authors": ["25"]}
{"title": "End-User Development Techniques for Enterprise Resource Planning Software Systems\n", "abstract": " The intent of this position paper is to present the focus of interest of our end-user development (EUD) related research at SAP Research CEC Darmstadt. As we are in an early phase of research, research topics will be presented rather than detailed results. We focus on investigating and applying EUD techniques suitable for enterprise resource planning (ERP) software systems, especially for small and medium-sized enterprises (SMEs). Our current research addresses the sub-domains of workflow management and business intelligence.", "num_citations": "6\n", "authors": ["25"]}
{"title": "Stimulus-response PBD: Demonstrating \u0393\u00c7\u00a3when\u0393\u00c7\u00a5 as well as \u0393\u00c7\u00a3what\u0393\u00c7\u00a5\n", "abstract": " Publisher SummaryA client hires a programmer to show how he wants the proposed application to behave. Using a graphics editor, scratch paper, or even a dinner napkin, the client sketches the proposed interface and then walks the programmer through its behaviors, first playing the role of the end user and showing what actions he can take, and then playing the role of the system and showing how it will respond to a particular stimulus. Many programming-by-demonstration (PBD) systems elaborate on the idea of macro recording, and they allow users to extend existing applications. Few, however, allow new interfaces to be created from scratch because they do not provide a means of demonstrating when a recorded macro should be invoked. This chapter discusses stimulus\u0393\u00c7\u00f4response systems that allow both the when (stimulus/event) and the what (response macro) to be demonstrated.", "num_citations": "6\n", "authors": ["25"]}
{"title": "Pursuit: Visual programming in a visual domain\n", "abstract": " We present a new visual programming language and environment that serves as a form of feedback and representation in a Programming by Demonstration system. The language differs from existing visual languages because it explicitly represents data objects and implicitly represents operations by changes in data objects. The system was designed to provide non-programmers with programming support for common, repetitive tasks and incorporates some principles of cognition to assist these users in learning to use it. With this in mind, we analyze the language and its editor along cognitive dimensions. The assessment provides insight into both strengths and weaknesses of the system, suggesting a number of design changes.Descriptors:", "num_citations": "6\n", "authors": ["25"]}
{"title": "User Interface Programming Languages\n", "abstract": " The Garnet user interface development environment [Myers 90e] contains a set of tools that make it easy to design and implement highly-interactive, graphical, direct manipulation user interfaces. Garnet has a number of important features that differentiate it from other user interface tools, including an emphasis on handling the run-time behavior of objects (how they change when the user operates on them), and on handling all aspects of the user interface for programs, including the graphics displayed by the program and the contents of all application-specific windows. Garnet is implemented in Common Lisp and interfaces to the X window manager.'It has been in use for over two years, with at least thirty active projects using Garnet, so the ideas discussed here have been proven to be workable.\u0393\u00c7\u00a5 Although we did not set out to create a new user interface language, we have extended Common Lisp with a special syntax for object-oriented", "num_citations": "6\n", "authors": ["25"]}
{"title": "Privacy-Preserving Script Sharing in GUI-based Programming-by-Demonstration Systems\n", "abstract": " An important concern in end user development (EUD) is accidentally embedding personal information in program artifacts when sharing them. This issue is particularly important in GUI-based programming-by-demonstration (PBD) systems due to the lack of direct developer control of script contents. Prior studies reported that these privacy concerns were the main barrier to script sharing in EUD. We present a new approach that can identify and obfuscate the potential personal information in GUI-based PBD scripts based on the uniqueness of information entries with respect to the corresponding app GUI context. Compared with the prior approaches, ours supports broader types of personal information beyond explicitly pre-specified ones, requires minimal user effort, addresses the threat of re-identification attacks, and can work with third-party apps from any task domain. Our approach also recovers obfuscated fields\u252c\u00e1\u0393\u00c7\u00aa", "num_citations": "5\n", "authors": ["25"]}
{"title": "Implementing multi-touch gestures with touch groups and cross events\n", "abstract": " Multi-touch gestures can be very difficult to program correctly because they require that developers build high-level abstractions from low-level touch events. In this paper, we introduce programming primitives that enable programmers to implement multi-touch gestures in a more understandable way by helping them build these abstractions. Our design of these primitives was guided by a formative study, in which we observed developers' natural implementations of custom gestures. Touch groups provide summaries of multiple fingers rather than requiring that programmers track them manually. Cross events allow programmers to summarize the movement of one or a group of fingers. We implemented these two primitives in two environments: a declarative programming system and in a standard imperative programming language. We found that these primitives are capable of defining nuanced multi-touch gestures\u252c\u00e1\u0393\u00c7\u00aa", "num_citations": "5\n", "authors": ["25"]}
{"title": "User-centered design of permissions, typestate, and ownership in the Obsidian blockchain language\n", "abstract": " Blockchains have been proposed to support transactions on distributed, shared state, but hackers have exploited security vulnerabilities in existing programs. In this paper, we describe how we are applying user-centered design in the creation of Obsidian, a new language that uses typestate and linearity to support stronger safety guarantees than current approaches for programming blockchain systems. We show how an iterative, user-centered design process can be used to elicit design feedback and show how we incorporated that feedback into the language. We found that formative user studies, even with a small number of participants, can lead to useful insights in language design. The study results motivated important language changes, such as adding explicit ownership transfer syntax and changing the structure of state initialization in state transitions.", "num_citations": "5\n", "authors": ["25"]}
{"title": "Moonstone: Support for understanding and writing exception handling code\n", "abstract": " Moonstone is a new plugin for Eclipse that supports developers in understanding exception flow and in writing exception handlers in Java. Understanding exception control flow is paramount for writing robust exception handlers, a task many developers struggle with. To help with this understanding, we present two new kinds of information: ghost comments, which are transient overlays that reveal potential sources of exceptions directly in code, and annotated highlights of skipped code and associated handlers. To help developers write better handlers, Moonstone additionally provides project-specific recommendations, detects common bad practices, such as empty or inadequate handlers, and provides automatic resolutions, introducing programmers to advanced Java exception handling features, such as try-with-resources. We present findings from two formative studies that informed the design of Moonstone. We\u252c\u00e1\u0393\u00c7\u00aa", "num_citations": "5\n", "authors": ["25"]}
{"title": "Software development practices, barriers in the field and the relationship to software quality\n", "abstract": " Context: Critical software systems developed for the government continue to be of lower quality than expected, despite extensive literature describing best practices in software engineering. Goal: We wanted to better understand the extent of certain issues in the field and the relationship to software quality. Method: We surveyed fifty software development professionals and asked about practices and barriers in the field and the resulting software quality. Results: There is evidence of certain problematic issues for developers and specific quality characteristics that seem to be affected. Conclusions: This motivates future work to address the most problematic barriers and issues impacting software quality.", "num_citations": "5\n", "authors": ["25"]}
{"title": "Visions for Euclase: Ideas for Supporting Creativity through Better Prototyping of Behaviors\n", "abstract": " Our research is investigating how to allow designers and other creative professionals to easily prototype and create interactive computer applications and web sites. In this paper, we discuss several studies we have conducted to better understand the requirements of an environment to support the authoring of interactive behaviors by creative professionals. Then we summarize our proposal for a new environment that tries to address those requirements. This environment would include the ability to explore multiple designs, support for collaboration, and the use of metaphors that better support the creative process. Finally, this paper poses questions related to computational support of creativity.", "num_citations": "5\n", "authors": ["25"]}
{"title": "The next challenge: from easy-to-use to easy-to-develop. are you ready?\n", "abstract": " The main challenge of next years is to allow users of software systems, who are non-professional software developers, to create, modify or extend software artefacts. In this panel we want to discuss with the CHI community the key aspects in the area of End User Development and an associated research agenda, which should be then proposed to the main research agencies, such as NSF and EU ICT.", "num_citations": "5\n", "authors": ["25"]}
{"title": "Unified associative information storage and retrieval\n", "abstract": " We present a novel system for performing information management in a unified manner. Users currently must manage large amounts of data which may be fragmented across file formats and applications. Our system, called Iolite, attempts to consolidate this information by automatically discovering associations within the data. Iolite uses these associations to provide a unified interface to navigate and operate on this information space.", "num_citations": "5\n", "authors": ["25"]}
{"title": "EdgeWrite: A new text entry technique designed for stability\n", "abstract": " EdgeWrite is a new design for text entry which yields methods that are accessible to some people with motor impairments or who are in physically destabilizing situations like walking or riding. Important properties of EdgeWrite include ease of learning due to the similarity of its letters to Roman characters, stability of motion due to tracing along physical edges, and simple implementation on a wide variety of input devices. Studies suggest that EdgeWrite works well when implemented for use with a stylus on a handheld device, a joystick on a power wheelchair, or for a touchpad on a desktop computer. A future implementation will explore desktop text entry using a trackball.", "num_citations": "5\n", "authors": ["25"]}
{"title": "Carnegie Mellon, M\n", "abstract": " The Gamet User Interface Development Environment contains a comprehensive set of tools that make it significantly easier to design and implement highly-interactive, graphical, direct manipulation user interfaces. Gamet provides a high level of support, while still being Look-and-Feel independent and providing the applications with tremendous flexibility. The Gamel tools are organized into two layers. The toolkit layer provides an object-oriented, constraint-based graphical system that allows properties of graphical objects to be sp_ecified in a simple, declarative manner, and then maintained automatically by the system. The dynamic, interactive behavior of the objects can be specified separately by attaching high-level\" interactor''objects to the graphics. The higher layer of Gamet includes an intetface builder too], called Lapidary, that allows the user interface designer to draw pictures of all graphical aspects of the user interface.The Gamet toolkit layer software is now available for distribution. It uses Common Lisp and the X window manager, and is therefore portable across a wide variety of platforms. This document contains an overview, tutorial and a full set of reference manuals for the Garnet Toolkit.", "num_citations": "5\n", "authors": ["25"]}
{"title": "The Amulet reference manuals\n", "abstract": " The Amulet User Interface Development Environment contains a comprehensive set of tools that make it significantly easier to design and implement highly interactive, graphical, direct manipulation user interfaces. Applications implemented in Amulet will run without modification on both Unix and PC platforms. Amulet provides a high level of support, while still being Look-and-Feel independent and providing applications with tremendous flexibility. Amulet currently provides a low-level toolkit layer, which is an object-oriented, constraint-based graphical system that allows properties of graphical objects to be specified in a simple, declarative manner, and then maintained automatically by the system. The dynamic, interactive behavior of the objects can be specified separately by attaching high-level \u0393\u00c7\u00a3interactor\u0393\u00c7\u00a5 objects to the graphics. Higher-level tools are currently in production, which will allow user interfaces to be layed out without programming.The Amulet toolkit is available for unlimited distribution by anonymous FTP. Amulet uses X/11 on Unix-based systems and the native Windows NT graphics on PC\u0393\u00c7\u00d6s. This document contains an overview with downloading and installation instructions, a tutorial, and a full set of reference manuals for the Amulet system.", "num_citations": "5\n", "authors": ["25"]}
{"title": "Interactive task and concept learning from natural language instructions and gui demonstrations\n", "abstract": " Natural language programming is a promising approach to enable end users to instruct new tasks for intelligent agents. However, our formative study found that end users would often use unclear, ambiguous or vague concepts when naturally instructing tasks in natural language, especially when specifying conditionals. Existing systems have limited support for letting the user teach agents new concepts or explaining unclear concepts. In this paper, we describe a new multi-modal domain-independent approach that combines natural language programming and programming-by-demonstration to allow users to first naturally describe tasks and associated conditions at a high level, and then collaborate with the agent to recursively resolve any ambiguities or vagueness through conversations and demonstrations. Users can also define new procedures and concepts by demonstrating and referring to contents within GUIs of existing mobile apps. We demonstrate this approach in PUMICE, an end-user programmable agent that implements this approach. A lab study with 10 users showed its usability.", "num_citations": "4\n", "authors": ["25"]}
{"title": "Methods for investigating mental models for learners of APIs\n", "abstract": " Despite almost all software development involving application programming interfaces (APIs), there is surprisingly little work on how people use APIs and how to evaluate and improve the usability of an API. One possible way of investigating the usability of APIs is through the user's mental model of the API. Through discussions with the developers and UX practitioners at Google along with our own evaluations, a distributed data processing API called Apache Beam has been identified as difficult to use and learn. In our on-going study, we investigate methods for understanding users' mental models of distributed data processing and how this understanding can lead to design insights for Beam and its documentation. We present our novel approach, which combines a background interview with two natural programming elicitation segments: the first designed for participants to express a high level mental model of a\u252c\u00e1\u0393\u00c7\u00aa", "num_citations": "4\n", "authors": ["25"]}
{"title": "How end users express conditionals in programming by demonstration for mobile apps\n", "abstract": " Though conditionals are an integral component of programming, providing an easy means of creating conditionals remains a challenge for programming-by-demonstration (PBD) systems for task automation. We hypothesize that a promising method for implementing conditionals in such systems is to incorporate the use of verbal instructions. Verbal instructions supplied concurrently with demonstrations have been shown to improve the generalizability of PBD. However, the challenge of supporting conditional creation using this multi-modal approach has not been addressed. In this extended abstract, we present our study on understanding how end users describe conditionals in natural language for mobile app tasks. We conducted a formative study of 56 participants asking them to verbally describe conditionals in different settings for 9 sample tasks and to invent conditional tasks. Participant responses were\u252c\u00e1\u0393\u00c7\u00aa", "num_citations": "4\n", "authors": ["25"]}
{"title": "Empirical evaluation of API usability and security\n", "abstract": " The aim of our project is to gather empirical evidence on the security impacts of language and Application Program Interface (API) design. Ultimately, the cause of cybersecurity failures is flawed code written by programmers. Our philosophy is that programmers are people, and we need to study how to design APIs which are usable by programmers\u0393\u00c7\u00f6APIs with which it is easy to develop secure code. It is well-known that API design can have a large impact on security, and this barrier is difficult, if not impossible, to overcome by training alone. For example, buffer overflows were understood and documented as early as 1972, but are still one of the most common vulnerabilities. Furthermore, APIs are typically designed by a small number of experienced developers but have an extremely long life-span, and therefore the impact of poor API design can have far reaching consequences.There has been some previous work on the usability of APIs, but so far this work has restricted itself to other software quality attributes, such as learnability. A relevant example of such work is Stylos et al [1], which studied the relative usability of different styles of constructing objects. The results were rather dismaying from a security point-ofview: programmers strongly preferred a style which would cause contructed objects to be mutable, whereas the security community generally considers mutability a source of security problems. One of our tasks will be to investigate and measure this apparent trade-off between traditional usability and security.", "num_citations": "4\n", "authors": ["25"]}
{"title": "Improving structured data entry on mobile devices\n", "abstract": " Structure makes data more useful, but also makes data entry more cumbersome. Studies have found that this is especially true on mobile devices, as mobile users often reject structured personal information management tools because the structure is too restrictive and makes entering data slower. To overcome these problems, we introduce a new data entry technique that lets users create customized structured data in an unstructured manner. We use a novel notepad-like editing interface with built-in data detectors that allow users to specify structured data implicitly and reuse the structures when desired. To minimize the amount of typing, it provides intelligent, context-sensitive autocomplete suggestions using personal and public databases that contain candidate information to be entered. We implemented these mechanisms in an example application called Listpad. Our evaluation shows that people using Listpad\u252c\u00e1\u0393\u00c7\u00aa", "num_citations": "4\n", "authors": ["25"]}
{"title": "Tool support for data validation by end-user programmers\n", "abstract": " End-user programming tools for creating spreadsheets and webforms offer no data types except \"string\" for storing many kinds of data, such as person names and street addresses. Consequently, these tools cannot automatically validate these data. To address this problem, we have developed a new userextensible model for string-like data. Each \"tope\" in this model is a user-defined abstraction that guides the interpretation of strings as a particular kind of data, such as a mailing address. Specifically, each tope implementation contains software functions for recognizing and reformatting that tope's kind of data. With our tools, end-user programmers define new topes and associate them with fields in spreadsheets, webforms, and other programs. This makes it possible at runtime to distinguish between invalid data, valid data, and questionable data that could be valid or invalid. Once identified, questionable and/or\u252c\u00e1\u0393\u00c7\u00aa", "num_citations": "4\n", "authors": ["25"]}
{"title": "Introduction to special issue on computers and accessibility\n", "abstract": " The Web has become pervasive in our society, with people using the Web for personal communication, research, company intranets, online purchasing, entertainment, and more. For many people, however, access to this information is not a given. Individuals with various disabilities including visual, physical, hearing, and cognitive impairments, often experience difficulties using the Web. While the W3C has created guidelines with the goal of making Web sites accessible, research has confirmed that adherence to these guidelines does not necessarily result in a site that is easily used by persons with disabilities. The goal of this special issue is to collect a set of articles which will help HCI professionals better understand how they can maximize the accessibility and usability of Web sites. More specifically, our goal was to collect articles that discuss either (1) empirical studies of issues related to the usability of Web\u252c\u00e1\u0393\u00c7\u00aa", "num_citations": "4\n", "authors": ["25"]}
{"title": "Challenges, Motivations, and Success Factors in the Creation of Hurricane Katrina\" Person Locator\" Web Sites.\n", "abstract": " We interviewed six people who led teams that created web sites enabling Hurricane Katrina survivors to report their status. We learned that interviewees did not discover and communicate with other teams when they started their projects, which resulted in redundant sites. The absence of a shared task impeded trust between teams, ultimately inhibiting data collection and aggregation. Moreover, communication within teams was problematic; developers who had adequate technical skills to work alone were more positive about their sites\u0393\u00c7\u00d6 success compared to developers who had to shore up skill weaknesses through collaboration. These problems did not simply result from team leaders\u0393\u00c7\u00d6 over-sized egos, since site creators were generally motivated by concern for other people instead of self-interested motivations. Rather, these problems highlight the need for improved development methods and systems to help developers discover and communicate with other teams\u0393\u00c7\u00d6 leaders in order to collaborate on widely distributed, time-critical projects.", "num_citations": "4\n", "authors": ["25"]}
{"title": "Identifying categories of end users based on the abstractions that they create\n", "abstract": " Software created by end users often lacks key quality attributes that professional programmers try to ensure through the use of abstraction. Yet to date, large-scale studies of end users have not examined end user software usage at a level which is sufficiently fine-grained to determine the extent to which they create abstractions.To address this, we deployed an online survey to Information Week subscribers to ask about not only software usage but also feature usage related to abstraction creation. Most respondents did create abstractions. Moreover, through factor analysis, we found that features fell into three clusters\u0393\u00c7\u00f4when users had a propensity to use one feature, then they also had a propensity to use other features in the same cluster. These clusters corresponded to macro features, linked data structure features, and imperative features.", "num_citations": "4\n", "authors": ["25"]}
{"title": "Introduction to workshop report\n", "abstract": " As Galileo struggled to view Jupiter through his newly built telescope, he adjusted the lenses and saw four twinkling points of light nearby. After recording their positions carefully, Galileo compared them to his drawings from previous nights. His conclusion that Jupiter had four moons circling it was a profound insight with far reaching implications.Paradigm shifting breakthroughs make for great stories, but normal science is equally important in the evolutionary development of science, engineering, and medicine. Large and small breakthroughs are often made by scientists, engineers, designers, and other professionals who have access to advanced tools. The telescopes and microscopes of previous generations are giving way to advanced user interfaces on computer tools that enable exploratory search, visualization, collaboration, and composition.", "num_citations": "4\n", "authors": ["25"]}
{"title": "Generating Consistent User Interfaces for Appliances\n", "abstract": " We are building a system called the personal universal controller (PUC) that automatically generates interfaces for handheld devices that allow users to remotely control all of the appliances in their surrounding environment. Within this system, we are interested in two forms of consistency: with other interfaces on the same handheld device and with previously generated interfaces for similar appliances. We have done some work on multi-device consistency, but it is not our focus. This paper presents three questions that we believe must be answered in order to achieve both multidevice and previous interface consistency. The importance of these questions is justified in the context of our PUC system.", "num_citations": "4\n", "authors": ["25"]}
{"title": "Report on the INCITS/V2 AIAP-URC standard\n", "abstract": " INCITS/V2, the Information Technology Access Interfaces Technical Committee of the InterNational Committee for Information Technology Standards (INCITS), is about to formally propose a standard for \u0393\u00c7\u00a3the discovery, selection, operation, and substitution of user interfaces and options\u0393\u00c7\u00a5[6] for everyday appliances. Their approach is similar to that of our personal universal controller (PUC) project [9]: each appliance has an abstract specification of its functions and user interfaces for the appliances are presented on a remote control device that users have with them. The remote control device could be a personal digital assistant,(PDAs), mobile phone, or any other computerized device with communication capabilities (eg Tablet PC, wristwatch of the future, etc.). The interfaces presented on the remote control device could also be in several modalities, such as graphical or speech.This report analyzes the V2 specification in detail, drawing on our experiences building the PUC system. We start by examining how the current version of the V2 specification addresses our comments on an earlier version, particularly by analyzing how the current standard meets our eight requirements for automatically generating user interfaces [10]. Then we contrast the current version of the V2 specification with our PUC system, and discuss the advantages and disadvantages of both approaches. The report concludes with an explanation for why we will not be using the V2 standard in our work, even though it provides most of the benefits of our PUC system.", "num_citations": "4\n", "authors": ["25"]}
{"title": "Lessons Learned: Using Contextual Inquiry Analysis to Improve PDA Control of Presentations\n", "abstract": " Contextual Inquiry is a method developed by Beyer and Holtzblatt for grounding design in the context of the work being performed. In this paper, we describe how we adapted the method successfully to perform analyses of pre-existing videotaped presentations.  Our goal was to find improvements for a slide presentation program currently in development, called \u0393\u00c7\u00ffSlideShow Commander,\u0393\u00c7\u00d6 which runs on hand-held \"Personal Digital Assistants\" (PDAs). Contextual Inquiry provided meaningful data on the structures and typical problems found in presentations, on which we based our design ideas. We then further analyzed the Contextual Inquiry data, beyond what Beyer and Holtzblatt suggest. This new step provided a means to prioritize the design suggestions, as well as a way to motivate the potential commercial usefulness of the software. Deciding upon the value and direction of further effort is essential for software development; by using our adapted form of Contextual Inquiry, we were able to make and defend these decisions.", "num_citations": "4\n", "authors": ["25"]}
{"title": "Gamut: Creating Complete Applications Using Only Programming by Demonstration\n", "abstract": " Programming-by-demonstration (PBD) can be used to create tools and methods that eliminate the need to learn difficult computer languages. Gamut is a PBD tool that nonprogrammers can use to create a broader range of interactive software, including games, simulations, and educational software, than other PBD tools. To do this, Gamut provides advanced interaction techniques that make it easier for a developer to express all aspects of an application along with improved inferencing that makes use of these techniques. The interaction techniques include a simplified way to demonstrate new examples, called nudges, and a way to give the system hints by highlighting objects to show they are important. Also, Gamut includes new objects and metaphors like the deck-of-cards metaphor for demonstrating collections of objects and randomness, guide objects for showing relationships that the system would find too difficult to guess, and temporal ghosts which simplify showing relationships with the recent past. Gamut can infer behaviors that other PBD systems would require a developer to code by hand. Gamut infers behaviors incrementally from multiple examples and never requires the developer to edit code. Gamut revises code automatically using a recursive procedure that efficiently scans for the differences between a new example and the original behavior. Differences that cannot be resolved by generating a suitable description are handled using decision tree learning providing a significantly greater ability to infer complex relationships. These techniques were tested in a formal setting with nonprogrammers to verify that they are effective.", "num_citations": "4\n", "authors": ["25"]}
{"title": "The garnet and amulet user interface development environments\n", "abstract": " Brad A. Myers Human Computer Interaction Institute School of Computer Science Carnegie Mellon University Pittsburgh, PA 15213 {garnet, amulet)@ cs. cmu. edu http://www. cs. cmu. edu: 8001/Web/Groups/garnet/gamet-home. html", "num_citations": "4\n", "authors": ["25"]}
{"title": "C3 nephritic factor in an individual with recurrent viral infection and lipodystrophy.\n", "abstract": " A patient with nephritic factor in the serum following an attack of disseminated herpes is described. In the majority of cases, the factor is associated with mesangio-capillary glomerulonephritis, with or without partial lipodystrophy. It has, however, been described in cases of partial lipodystrophy alone, in one patient with recurrent pyogenic infections, and in one healthy individual. It has not previously been described in an individual with disseminated viral infection.", "num_citations": "4\n", "authors": ["25"]}
{"title": "PLIERS: A Process that Integrates User-Centered Methods into Programming Language Design\n", "abstract": " Programming language design requires making many usability-related design decisions. However, existing HCI methods can be impractical to apply to programming languages: they have high iteration costs, programmers require significant learning time, and user performance has high variance. To address these problems, we adapted both formative and summative HCI methods to make them more suitable for programming language design. We integrated these methods into a new process, PLIERS, for designing programming languages in a user-centered way. We evaluated PLIERS by using it to design two new programming languages. Glacier extends Java to enable programmers to express immutability properties effectively and easily. Obsidian is a language for blockchains that includes verification of critical safety properties. Summative usability studies showed that programmers were able to program effectively in both languages after short training periods.", "num_citations": "3\n", "authors": ["25"]}
{"title": "The long tail: Understanding the discoverability of api functionality\n", "abstract": " Almost all software development revolves around the discovery and use of application programming interfaces (APIs). Once a suitable API is selected, programmers must begin the process of determining what functionality in the API is relevant to a programmer's task and how to use it. Our work aims to understand how API functionality is discovered by programmers and where tooling may be appropriate. We employed a mixed-methods approach to investigate Apache Beam, a distributed data processing API, by mining Beam client code and running a lab study to see how people discover Beam's available functionality. We found that programmers' prior experience with similar APIs significantly impacted their ability to find relevant features in an API and attempting to form a top-down mental model of an API resulted in less discovery of features.", "num_citations": "3\n", "authors": ["25"]}
{"title": "Considering productivity effects of explicit type declarations\n", "abstract": " Static types may be used both by the language implementation and directly by the user as documentation. Though much existing work focuses primarily on the implications of static types on the semantics of programs, relatively little work considers the impact on usability that static types provide. Though the omission of static type information may decrease program length and thereby improve readability, it may also decrease readability because users must then frequently derive type information manually while reading programs. As type inference becomes more popular in languages that are in widespread use, it is important to consider whether the adoption of type inference may impact productivity of developers.", "num_citations": "3\n", "authors": ["25"]}
{"title": "Searching across paths\n", "abstract": " Observations of developers indicate that developers try to answer a variety of questions by searching across control flow paths through a program for statements matching search criteria. We believe that tools that better support this activity can help developers answer these questions more easily, quickly, and accurately.", "num_citations": "3\n", "authors": ["25"]}
{"title": "A user acceptance equation for intelligent assistants\n", "abstract": " A User Acceptance Equation for Intelligent Assistants A User Acceptance Equation for Intelligent Assistants Page 1 Copyright \u252c\u2310 2007 \u0393\u00c7\u00f4 Brad A. Myers A User Acceptance Equation for Intelligent Assistants A User Acceptance Equation for Intelligent Assistants Brad A. Myers Human-Computer Interaction Institute School of Computer Science Carnegie Mellon University http://www.cs.cmu.edu/~bam bam@cs.cmu.edu Brad A. Myers Human-Computer Interaction Institute School of Computer Science Carnegie Mellon University http://www.cs.cmu.edu/~bam bam@cs.cmu.edu AAAI 2007 Spring Symposium on Interaction Challenges for Intelligent Assistants Page 2 Brad A. Myers, CMU 2 March 26, 2007 2 How To Make Users Happy \u0393\u00ea\u00c4 And avoid annoying users \u0393\u00ea\u00c4 And avoid annoying users Page 3 Brad A. Myers, CMU 3 March 26, 2007 3 User Happiness? H u = f (Performance) H u = f (Performance) Page 4 Brad A. Myers, 4 \u0393\u00c7\u00aa", "num_citations": "3\n", "authors": ["25"]}
{"title": "Lessons learned from programmers' experiences with one\u0393\u00c7\u00c9way constraints\n", "abstract": " One\u0393\u00c7\u00c9way constraints have been incorporated in many graphical user interface toolkits because they are simple to learn, easy to write, and can express many types of useful graphical relationships. This paper is an evaluative paper that examines users' experience with one\u0393\u00c7\u00c9way constraints in two user interface development toolkits, Garnet and Amulet, over a 15\u0393\u00c7\u00c9year time span. The lessons gained from this examination can help guide the design of future constraint systems. The most important lessons are that (1) constraints should be allowed to contain arbitrary code that is written in the underlying toolkit language and does not require any annotations, such as parameter declarations, (2) constraints are difficult to debug and better debugging tools are needed, and (3) programmers will readily use one\u0393\u00c7\u00c9way constraints to specify the graphical layout of an application, but must be carefully and time\u0393\u00c7\u00c9consumingly\u252c\u00e1\u0393\u00c7\u00aa", "num_citations": "3\n", "authors": ["25"]}
{"title": "How programmers use internet resources to aid programming\n", "abstract": " When programmers create new software or add functionality to existing software, a common and often difficult task is that of figuring out how to use libraries, toolkits and SDKs to achieve the desired functionality. Internet resources, in particular Google, have emerged as new and effective tools in this task, providing quick access to a large collection of tutorials and example code. However, there has been little study of how programmers use these Internet resources and how these resources could be designed to better aid programmers. In observations of programmers we find that their web queries can be classified into two categories: high level searches to find tutorials and available methods, and lower level searches to find code examples that use particular methods. In addition, we observe a tendency to iterate between these two types of searches as programmers refine their knowledge of the libraries and methods. We observe common difficulties in integrating example code and in using search engines to finding different ways to accomplish similar tasks. Given our observations, we suggest new types of programming support tools, such as IDE features to help programmers understand and run code snippets found online.", "num_citations": "3\n", "authors": ["25"]}
{"title": "SILVER: simplifying video editing with metadata\n", "abstract": " Digital video is becoming increasingly ubiquitous. However, editing video remains difficult for several reasons: it is a time-based medium, it has dual tracks of audio and video, and current tools force users to work at the smallest level of detail. Based on interviews with professional video editors, we developed a video editor, called Silver, that uses metadata to make digital video editing more accessible to novices. To help users visualize video, Silver provides multiple views with different semantic content and at different levels of abstraction, including storyboard, editable transcript, and timeline views. Silver offers smart editing operations that help users resolve the inconsistencies that arise because of the different boundaries in audio and video.", "num_citations": "3\n", "authors": ["25"]}
{"title": "Studying the use of handhelds to control everyday appliances\n", "abstract": " Everyday appliances, including telephones, ovens, and home stereos, increasingly contain embedded computers to provide greater functionality. Unfortunately, as these appliances become more complex, their interfaces are becoming harder to use. At the same time, more people than ever are carrying computerized devices that can communicate, such as cellular telephones, personal digital assistants, and even some watches. Our vision is that these devices will be able to communicate with our everyday appliances using a short-range wireless network, enabling people to control their appliances from a single handheld device. We present two studies that suggest that handheld devices could be used effectively as remote controls for everyday appliances.", "num_citations": "3\n", "authors": ["25"]}
{"title": "Using GOMS ofr User Interface Design and Evaluation: Which Technique?\n", "abstract": " CiNii \u03a6\u00bd\u00fb\u00b5\u00fb\u00e7 - Using GOMS ofr User Interface Design and Evaluation : Which Technique? CiNii \u03c3\u00a2\u255c\u03c4\u00bd\u00ef\u00b5\u00e2\u00e0\u03c3\u00e1\u2592\u03c3\u00a1\u00aa\u03c4\u00e1\u00f6\u03c4\u2310\u2562\u00b5\u00eb\u00c7 \u03c3\u00a1\u00aa\u03a6\u00ed\u00f4\u00b5\u00e2\u00e0\u03c3\u00e1\u2592\u03c0\u00e2\u00e8\u03c0\u00e2\u00f4\u03c0\u00e9\u2593\u03c0\u00e2\u255d\u03c0\u00e9\u2510[\u03c0\u00e9\u2561\u03c0\u00e9\u00f1\u03c0\u00e2\u00ef\u03c0\u00e9\u00fa] \u00b5\u00f9\u00d1\u00b5\u00a3\u00bc\u03c0\u00fc\u00ab\u03a6\u00bd\u00fb\u00b5\u00fb\u00e7\u03c0\u00e9\u00c6\u03c0\u00fc\u00f2\u03c0\u00fc\u00ee\u03c0\u00fc\u00d6 \u03c3\u00f1\u00ba\u03c3\u00a1\u00aa\u03c3\u00a2\u2502\u00b5\u00a2\u2555\u0398\u00f1\u00bf\u03c0\u00fc\u00ab\u00b5\u00a3\u00bc\u03c0\u00e9\u00c6\u03c0\u00fc\u00f2\u03c0\u00fc\u00ee\u03c0\u00fc\u00d6 \u00b5\u00f9\u00d1\u00b5\u00a3\u00bc\u03c0\u00fc\u00ab \u03c3\u00ec\u00dc\u03c3\u00fa\u00bd\u03a6\u00bd\u00fb\u00b5\u00fb\u00e7\u03c0\u00e9\u00c6\u03c0\u00fc\u00f2\u03c0\u00fc\u00ee\u03c0\u00fc\u00d6 \u00b5\u00fb\u2591\u03a6\u00aa\u00c5\u03c4\u00d6\u2557\u0398\u00ee\u2593 \u03c0\u00e2\u00a1\u03c0\u00e9\u2591\u03c0\u00e9\u00f1\u03c0\u00e2\u2502 English \u00b5\u00f1\u00a3\u03c4\u2524\u00f3 \u03c0\u00fc\u00d6\u03c0\u00fc\u2563\u03c0\u00fc\u00aa \u00b5\u00a3\u00bc\u00b5\u00fb\u00e7\u03c0\u00fc\u00e9\u03c0\u00e9\u00e8 \u03c0\u00fc\u00d6\u03c0\u00fc\u2563\u03c0\u00fc\u00aa \u00b5\u00a3\u00bc\u00b5\u00fb\u00e7\u03c0\u00fc\u00e9\u03c0\u00e9\u00e8 \u0398\u00fb\u00eb\u03c0\u00fc\u00ff\u03c0\u00e9\u00ef \u03c0\u00e9\u2510\u03c0\u00e9\u00f1\u03c0\u00e2\u00ea\u03c0\u00e2\u00bd \u03a6\u00e6\u00f9\u03a6\u00c7\u00e0\u03c3\u00c9\u00ec \u03a6\u00e6\u00f9\u03a6\u00c7\u00e0ID \u03a6\u00e6\u00f9\u03a6\u00c7\u00e0\u00b5\u00eb\u00c7\u03c3\u2592\u20a7 \u03c3\u00ea\u00e8\u03a6\u00ed\u00ee\u03c4\u00eb\u2310\u03c3\u00c9\u00ec ISSN \u03c3\u2556\u2557\u03c3\u00c5\u2556\u03c0\u00e2\u00dc\u03c0\u00e2\u255d\u03c0\u00e9\u2555 \u03c3\u00e7\u2551\u03c4\u00eb\u00ea\u03a6\u00c7\u00e0 \u03c3\u00c5\u00e9\u03a6\u00c7\u00e2\u00b5\u00fb\u00e7\u03c4\u00ee\u00ab \u03c3\u00e7\u2551\u03c4\u00eb\u00ea\u03c3\u2563\u2524 \u03c3\u2563\u2524\u03c0\u00fc\u00ef\u03c0\u00e9\u00eb \u03c3\u2563\u2524\u03c0\u00fc\u255b\u03c0\u00fc\u00ba \u00b5\u00f1\u00a3\u03c4\u2524\u00f3 \u00b5\u00f1\u00a3\u03c4\u2524\u00f3 \u00b5\u00f1\u00a3\u03c4\u2524\u00f3 CiNii\u03c0\u00fc\u00ab\u03c0\u00e9\u2561\u03c0\u00e2\u255d\u03c0\u00e2\u00f4\u03c0\u00e9\u2563\u03c0\u00fc\u00bd\u0398\u00fb\u00f3\u03c0\u00fc\u00d6\u03c0\u00e9\u00ef\u03c0\u00e9\u00f3\u03c0\u00e2\u2502\u03c0\u00e9\u2592\u03c0\u00e2\u255d\u03c0\u00e2\u00ea\u03c0\u00e9\u00c6\u03c3\u00ab\u0192\u00b5\u00fb\u255c\u03a3\u2555\u00a1\u03c0\u00fc\u00ba\u03c0\u00fc\u00d6\u2229\u255d\u00ea11/11(\u00b5\u2591\u2524)-12/23(\u00b5\u2591\u2524)\u2229\u255d\u00eb Using GOMS ofr User Interface Design and Evaluation : Which Technique? MYERS B. \u03a6\u00f3\u00bd\u03c3\u255d\u00f2\u03c4\u00f6\u00bf\u00b5\u00fb\u00e7\u03c4\u00ee\u00ab: 1\u03a3\u2557\u2562 \u03a6\u00e6\u00f9\u03a6\u00c7\u00e0 MYERS B. \u03c3\u00c5\u00c4\u0398\u00ee\u2593\u03c3\u00ea\u00e8\u03a6\u00ed\u00ee\u03c4\u00eb\u2310 ACM Trans. Computer Human Interaction ACM Trans. Computer Human Interaction 3(4), 387-319, 1996 \u03a6\u00f3\u00bd\u03c3\u255d\u00f2\u03c4\u00f6\u00bf\u00b5\u00fb\u00e7\u03c4\u00ee\u00ab: 1\u03a3\u2557\u2562\u03a3\u2555\u00a1 1-1\u03a3\u2557\u2562\u03c0\u00e9\u00c6 \u03a6\u00ed\u00bf\u03c4\u00f1\u2551 1 \u03a6\u00e4\u2502\u00b5\u2502\u00f3\u03a6\u00bf\u00ea\u00b5\u2555\u00bc\u03a6\u00fa\u00e0\u03c4\u255c\u00ab\u03c0\u00e9\u00c6\u03c4\u00f6\u00bf\u03c0\u00fc\u00e4\u03c0\u00fc\u0192 \u03c0\u00e2\u00aa\u03c0\u00e2\u255d\u03c0\u00e9\u2562\u03c0\u00e9\u00f1\u03c0\u00e2\u2502\u03c0\u00e9\u2510\u03c0\u00e2\u00f2\u03c0\u00e9\u00ba\u03c0\u00e2\u255d\u03c0\u00e9\u2563\u03c0\u00fc\u00ab\u03a6\u2310\u00f2\u03a3\u255b\u00ed \u03c4\u00f6\u2591\u03c3\u20a7\u00fa\u03c3\u00e5\u00e0 \u03c3\u00ec\u00dc\u03a3\u2555\u00c7 , \u03c3\u2502\u2562 \u03c3\u00c6\u00ee\u03a3\u2563\u00ef , \u00b5\u00a5\u255b\u00b5\u00a3\u00bc \u03c3\u00fc\u00d1\u03a3\u2555\u00c7 , \u0398\u2502\u00d1\u03c3\u2592\u00e0 \u03c3\u00ab\u00c5\u00b5\u00bc\u00ed \u0398\u00a2\u2557\u03c3\u00a1\u00c9\u00b5\u00e2\u00e0\u03c3\u00e1\u2592\u0398\u00c7\u00dc\u03a3\u2510\u00ed\u03c3\u00a1\u00aa\u03a3\u255d\u00dc\u00b5\u00e8\u00c7\u03a6\u00ed\u00f4 \u03c4\u00e1\u00f6\u03c4\u2310\u2562\u03c3\u00e1\u2592\u03c3\u00e6\u00e8. SS, \u03c0\u00e9\u255c\u03c0\u00e2\u00f2\u03c0\u00e2\u00ea\u03c0\u00e9\u00aa\u03c0\u00e9\u00ba\u03c0\u00e9\u00f3\u03c0\u00e9\u2561\u03c0\u00e9\u00f1\u03c0\u00e9\u00bf\u03c0\u00e2\u2502\u03c0\u00e9\u2563 98(675), 47-54, 1999-03-18 \u03c3\u00c5\u00e9\u03a6\u00c7\u00e2\u00b5\u00fb\u00e7\u03c4\u00ee\u00ab13\u03a3\u2557\u2562 \u03a6\u00f3\u00bd\u03c3\u255d\u00f2\u03c4\u00f6\u00bf\u00b5\u00fb\u00e7\u03c4\u00ee\u00ab(\u0393\u00c7\u00aa", "num_citations": "3\n", "authors": ["25"]}
{"title": "Debugging Interactive Applications\n", "abstract": " Although interactive, direct manipulation applications are known to be difficult to design and implement, the toolkits with which they are built generally do not contain any particular support for debugging.  The Amulet toolkit contains a comprehensive collection of monitoring and debugging tools, including an interactive \u0393\u00c7\u00ff\u0393\u00c7\u00ffInspector.\u0393\u00c7\u00d6\u0393\u00c7\u00d6 These tools are provided in a machine-independent way in C++ without using hooks into the compiler, symbol tables or the run-time stack.  Some of these capabilities are based on well-known techniques, but others are innovations that have never been provided before. Based on our experience with writing and debugging interactive applications, we have provided tools to address the most common and difficult programming bugs. The capabilities include: viewing values of objects as they change; breaking into the debugger when values change; viewing the inheritance and grouping hierarchies of objects; feedback for why objects are not visible or not interactive; tracing of constraint dependencies; and various techniques to search for objects. In addition, programmers can edit the values displayed in the Inspector, supporting rapid prototyping without requiring a C++ interpreter.  These features make debugging interactive applications written using Amulet is substantially easier than with other toolkits.", "num_citations": "3\n", "authors": ["25"]}
{"title": "The demonstrational interfaces project at cmu\n", "abstract": " The Demonstrational Interfaces Project at CMU has been investigating various aspects of demonstrational interfaces for the last eight years. During this time, we have created six interactive software building tools that use demonstrational techniques, as well as an architecture to support demonstrational programming in general. In addition, we have created a demonstrational Visual Shell (iconic interface to a file system, like the Macintosh Finder), a demonstrational text formatter, and a demonstrational charting tool. There are three fundamental research questions we explore through these tools: how to give the user appropriate feedback and control over inferencing, appropriate algorithms for inferencing, and which domains are appropriate for demonstrational techniques. This paper summarizes our activities, approach and lessons learned.", "num_citations": "3\n", "authors": ["25"]}
{"title": "Interactors Reference Manual: Encapsulating Mouse and Keyboard Behaviors\n", "abstract": " This document describes a set of objects which encapsulate mouse and keyboard behaviors. The motivation is to separate the complexities of input device handling from the other parts of the user interface. We have tried to identify some common mouse and keyboard behaviors and implement them in a separate place. There are only a small number of interactor types, but they are parameterized in a way that will support a wide range of different interaction techniques. These interactors form the basis for all interaction in the Garnet system.", "num_citations": "3\n", "authors": ["25"]}
{"title": "Using percent-done progress indicators to enhance user interfaces.\n", "abstract": " A \"percent-done progress indicator\" is a graphical technique which allows the user to monitor the progress through the processing of a task. Progress indicators can be displayed on almost all types of output devices, and can be used with many different kinds of programs. Practical experience and formal experiments show that progress indicators are an important and useful user-interface tool, and that they enhance the attractiveness and effectiveness of programs that incorporate them. This paper summarizes the results reported in another paper on progress indicators that includes the results of a formal experiment with progress indicators.", "num_citations": "3\n", "authors": ["25"]}
{"title": "Developing a Web-Based Tool to Enhance Communication and Shared Decision Making for Families of Critically Ill Patients Through User-Centered Methods\n", "abstract": " RATIONALE Although breakdowns in clinician-family communication in ICUs are well documented, there are currently no easily scaled interventions to overcome these problems. We sought to develop a web-based tool to support communication and shared decision making, then assess its usability, acceptability, and perceived usefulness among surrogate decision makers for critically ill patients. METHODS We employed a user-centered, iterative process of tool development. We assembled a panel of key stakeholders consisting of one intensivist, one palliative care physician, one nurse, one social worker, one pastor, and four surrogate decision makers, who participated in multiple meetings to develop the overall vision for the Family Support Tool (FST). Next, we developed a low-fidelity prototype of the FST, which was iteratively refined based on input from the key stakeholder panel and from the authors, who\u252c\u00e1\u0393\u00c7\u00aa", "num_citations": "2\n", "authors": ["25"]}
{"title": "Text entry using five to seven physical keys\n", "abstract": " We designed, implemented, and evaluated a small physical keyboard, composed of four to five keys with a variety of mappings for the letters, along with one or two navigational function keys operated by the thumb. The small size allows it to be used for smartwatch text entry, and can be mounted on various body parts as a wearable keyboard. It is primarily used as an ambiguous keyboard, akin to T9, although a multi-tap mode is also present. Our keyboard layouts include Alphabetic, Collapsed QWERTY, Mnemonic (where letters are grouped based on their shapes), and Optimized (which minimizes the number of conflicts). In a between-users study, participants achieved an average of 15.4 words per minute (WPM) across all layouts, with one user with the Collapsed QWERTY layout reaching a top speed of 30.6 WPM after 4 hours of practice. User feedback was generally favorable.", "num_citations": "2\n", "authors": ["25"]}
{"title": "EUKLAS: Supporting copy-and-paste strategies for integrating example code\n", "abstract": " Researchers have paid increasing attention in recent years to the fact that much development occurs though example modification. Helping programmers with some of the pit-falls and vagaries of working with example code is the goal of our tool, called Euklas. It helps developers to integrate JavaScript example code into their own projects by using familiar IDE interaction techniques of the Eclipse IDE. The Euklas plugin uses static, heuristic source code checks to highlight potential errors and to recommend potential fixes, when incomplete sections of code are copied from a work-ing JavaScript example and pasted into the program being edited. The most unique feature of the tool is the ability to automatically import missing variable and function defini-tions from an example file into a new project file. Our preliminary user study of Euklas suggests that it supports users in fixing errors more easily.", "num_citations": "2\n", "authors": ["25"]}
{"title": "Randomized controlled trial (RCT) of pocket PATH\u252c\u00ab, an mHealth intervention to promote self-management after lung transplantation\n", "abstract": " RATIONALE: transplant recipients. Self-management behaviors (adhering to regimen, self-monitoring and communicating condition changes to clinicians) are known to prevent and detect complications and promote better health outcomes. However, self-management is less than ideal which provided the impetus for the development of Pocket PATH (Personal Assistant for Tracking Health), an mHealth technology with customized data recording, graphing, and decision-support for LTRs to monitor their health indicators and receive automatic alert messages reporting condition changes. We conducted an RCT to evaluate the efficacy of Pocket PATH for promoting self-management behaviors and health outcomes relative to standard care among LTRs. 201 LTRs were randomized to receive Pocket PATH+ standard care (n= 99) or standard care only (n= 102) to supportMETHODS: self-management. Data were\u252c\u00e1\u0393\u00c7\u00aa", "num_citations": "2\n", "authors": ["25"]}
{"title": "Success of an Agent-Assisted System that Reduces Email Overload\n", "abstract": " RADAR is a large multi-agent system with a mixed-initiative user interface designed to help office workers cope with email overload. RADAR agents observe experts performing tasks and then assist other users who are performing similar tasks. The Email Classifier learns to identify tasks contained within emails and then inspects new emails for similar tasks, which are presented in a novel task-management user interface. The Multi-task Coordination Assistant learns a model of the order in which experts perform tasks and then presents subsequent users with a suggested schedule for performing their tasks. A large evaluation of RADAR demonstrated that novice users confronted with an email overload test performed significantly better (a 37% better overall score with a factor of four fewer errors) when assisted by both agents. Additionally, in a post-test survey users perceived the test to be significantly more difficult when they did not receive assistance from both agents, indicating a preference for the AI-based assistance. We also observed a wide variation among users in the amount of agent advice that they followed.", "num_citations": "2\n", "authors": ["25"]}
{"title": "Source-level debugging with the whyline\n", "abstract": " The visualizations of the Whyline are presented, which focus on supporting the exploration a source code and how it executes. The visualization is concise, simple to navigate, and mimics syntactic features of its target programming language for consistency. Two studies showed that users with the visualization completed a debugging task twice as fast as users without the visualization, partly due to features of the visualization. Applications of the visualizations to tasks other than debugging are discussed.", "num_citations": "2\n", "authors": ["25"]}
{"title": "End-user programming productivity tools\n", "abstract": " Our research focuses on developing interactive technologies for a broad range of end-user programming activities, including code construction, verification, debugging, and understanding. A common goal among all of these technologies is to identify core ideas that can be used across a variety of domains and programmer populations.", "num_citations": "2\n", "authors": ["25"]}
{"title": "More natural and open user interface tools\n", "abstract": " Our research is highlighting some potential directions for the future of user interface design tools. One approach is to make the tools and their SDKs more usable, effective and understandable by making them more natural. Another is to take advantage of an \u0393\u00c7\u00a3open data model\u0393\u00c7\u00a5 to more easily integrate new components. In addition, programming-bydemonstration techniques and model-based automatic generation still hold much promise.", "num_citations": "2\n", "authors": ["25"]}
{"title": "Communication Ubiquity Enables Ubiquitous Control\n", "abstract": " Handheld devices, such as cell-phones and PDAs, can be used for more than just communication. What happens when every person has a handheld that ubiquitously communicates with every appliance in the environment? As part of the Pebbles project, we are exploring technologies that allow handhelds to monitor and control appliances.", "num_citations": "2\n", "authors": ["25"]}
{"title": "User Interface Management Systems\n", "abstract": " The sections in this article are", "num_citations": "2\n", "authors": ["25"]}
{"title": "Sketching Interfaces: Toward More Human Interface Design\n", "abstract": " As computers grow more powerful, less ex-pensive, and more widely available, people are expecting them not only to perform obvious computational tasks, but also to assist in people-oriented tasks, such as writing, drawing, and designing. This shift is causing some user-interface (UI) researchers to rethink the traditional reliance on methods that are more machine-oriented and to look at ways to support properties like ambiguity, creativity, and informal communication. The idea is to bend computers to people\u0393\u00c7\u00d6s way of interacting, not the other way around. This flexibility is particularly important in the early stages of UI design itself, when designers need the freedom to sketch rough design ideas quickly, the ability to test designs by interacting with them, and the flexibility to fill in the design details as they make choices. 1 Tools at this stage must support conceptual design, which is characterized by ambiguity and the need to create several design variations quickly, as the \u0393\u00c7\u00a3Why Sketching Is Important\u0393\u00c7\u00a5 sidebar describes. Unfortunately, with current UI tools, designers tend to focus on issues such as colors, fonts, and alignment, which are more appropriate later in the design. Thus, most UI designers resort to sketching ideas on paper, but these are hard to edit and inconvenient for user evaluations. Researchers at University of California, Berkeley and Carnegie Mellon University (CMU) have designed, implemented, and evaluated SILK (Sketching Interfaces Like Krazy), an informal sketching tool that combines many of the benefits of paper-based sketching with the merits of current electronic tools.With SILK, designers can quickly sketch an interface using\u252c\u00e1\u0393\u00c7\u00aa", "num_citations": "2\n", "authors": ["25"]}
{"title": "Easily Adding Sound Output to Interfaces\n", "abstract": " Adding sound output to interfaces is a very difficult task with today\u0393\u00c7\u00d6s toolkits, even though there are many situations in which it would be useful and effective.  We have designed an architecture that makes it very easy to add sound output to an interface.  Any interaction behavior, animation, or command can be augmented with sounds to occur at the beginning or end, or for the duration. Parameters of the sound, such as the speed or volume can be easily tied to properties of the data using constraints. Two different sound objects are currently supplied: one for playing recorded sounds, and the other for text-to-speech. The text-to-speech sound object can be used to quickly build various kinds of screen readers.  Easy-to-use mechanisms give the programmer complete control over interrupting and pre-empting when multiple sounds are played at the same time.  Because sound output can be added to an existing application with as little as a single extra line of code, we expect that this new mechanism will make it easy for researchers and developers to investigate the use of sound in a wide variety of applications.", "num_citations": "2\n", "authors": ["25"]}
{"title": "Easily Programmable Shared Objects For Peer-To-Peer Distributed Applications\n", "abstract": " This paper presents our experiences in implementing PERSON, a toolkit for adapting single user applications into multi-machine multi-user applications.  This is achieved by providing a way to share objects in a peer-to-peer model using a programming model that emphasizes values rather than functions and ties the values together with constraints.  This encourages a modular and declarative style of program design.", "num_citations": "2\n", "authors": ["25"]}
{"title": "A Dynamic And Flexible Prototype-Instance Object And Constraint System In C++\n", "abstract": " The Amulet object system also supports a part-owner hierarchy, by which objects can be grouped together. AIn order to support rapid prototyping and efficient construccommon use for part-owner in Amulet is to group graphical tion of user interface software, the Amulet user interface objects into a collection or aggregate. For instance, the development environment uses a prototype-instance object graphics in a window are added as parts of the window. model integrated with a constraint solver. The important", "num_citations": "2\n", "authors": ["25"]}
{"title": "Exploring graphical feedback in a demonstrational visual shell\n", "abstract": " We present a visual language that serves as a novel form of feedback in a Programming by Demonstration (PBD) interface. The language explicitly represents data, such as files, with unique icons and implicitly represents operations by changes to data icons, so that operations reflect the changes seen in the interface when executed. In addition, the language is used to provide feedback to the user by indicating loops and inferred sets, specifying parameters, etc., and is integrated into other parts of the PBD system, such as the editor. This forms \u251c\u00f1 close union between the interface, the PBD system and the program representation and helps bridge the gap between the user's mental model of the programming process and the actual programming task.", "num_citations": "2\n", "authors": ["25"]}
{"title": "Program visualization\n", "abstract": " There has been a great interest recently in systems that use graphics to aid in the programming, debugging, and understanding of computer programs. The terms\" Visual Programming\" and \u0393\u00c7\u00a3Program Visualization\u0393\u00c7\u00a5 have been applied to these systems. Also, there has been a renewed interest in using examples to help alleviate the complexity of programming. This\u252c\u2557 technique is called \u0393\u00c7\u00a3Programming by Example.\u0393\u00c7\u00a5 This paper attempts to provide more meaning to these terms by giving precise de\u2229\u00bc\u00fcnitions, and then uses these de\u2229\u00bc\u00fcnitions to classify existing systems into a taxonomy.", "num_citations": "2\n", "authors": ["25"]}
{"title": "From research prototypes to usable, useful systems: lessons learned in the trenches\n", "abstract": " Permission to copy without fee all or part of this material is granted provided that the copies are not made or distributed for direct commercial advantage, the ACM copyright notice and the title of the publication and its date appear, and notice is given that copying is by permission of the Association for Computing Machinery. To copy otherwise, or to republish, requires a fee and/or specific permission.", "num_citations": "2\n", "authors": ["25"]}
{"title": "Garnet\n", "abstract": " The Garnet User Interface Development Environment contains a comprehensive set of tools that make it significantly easier to design and implement highly-interactive, graphical, direct manipulation user interfaces. Garnet provides a high level of support, while still being Look-and-Feel independent and providing the applications with tremendous flexibility. The Garnet tools are organized into two layers. The toolkit layer provides an object-oriented, constraint-based graphical system that allows properties of graphical objects to be specified in a simple, declarative manner, and then maintained automatically by the system. The dynamic, interactive behavior of the objects can be specified separately by attaching high-level \u0393\u00c7\u00ff\u0393\u00c7\u00ffinteractor\u0393\u00c7\u00d6\u0393\u00c7\u00d6objects to the graphics. This layer includes two complete widget sets, one with the Garnet look and feel, and the other with a Motif look and feel. The higher layer of Garnet includes three\u252c\u00e1\u0393\u00c7\u00aa", "num_citations": "2\n", "authors": ["25"]}
{"title": "The Second Garnet Compendium: Collected Papers 1990-1992.\n", "abstract": " KR is a portable object-oriented system with an integrated constraint maintenance mechanism. The object system implements the prototype-instance model and supports dynamic redefinition of prototypes. Constraints express relationships among values, and are specified using arbitrary Lisp expressions. The constraint system transparently keeps constraints up to date. For maximum performance, it is closely integrated with the object system. Several mechanisms, such as constraint value caching and copy-down inheritance, are used to improve performance. The close integration of object-oriented programming with flexible constraint maintenance makes the system well suited for a variety of application programs, including highly interactive graphical applications. KR is the basic building block of the Garnet user interface development toolkit.Descriptors:", "num_citations": "2\n", "authors": ["25"]}
{"title": "PLIERS: A Process that Integrates User-Centered Methods into Programming Language Design\n", "abstract": " Programming language design requires making many usability-related design decisions. However, existing HCI methods can be impractical to apply to programming languages: languages have high iteration costs, programmers require significant learning time, and user performance has high variance. To address these problems, we adapted both formative and summative HCI methods to make them more suitable for programming language design. We integrated these methods into a new process, PLIERS, for designing programming languages in a user-centered way. We assessed PLIERS by using it to design two new programming languages. Glacier extends Java to enable programmers to express immutability properties effectively and easily. Obsidian is a language for blockchains that includes verification of critical safety properties. Empirical studies showed that the PLIERS process resulted in languages\u252c\u00e1\u0393\u00c7\u00aa", "num_citations": "1\n", "authors": ["25"]}
{"title": "IUI4EUD: intelligent user interfaces for end-user development\n", "abstract": " End-User Developers program to meet some goal other than the code itself. This includes scientists, data analysts, and the general public when they write code. We have been working for many years on various ways to make end-user development more successful. In this talk, I will focus on two new projects where we are applying intelligent user interfaces to this long-standing challenge. In Sugilite, the user can teach an intelligent agent new skills interactively with the user interfaces of relevant smartphone apps through a combination of programming by example (PBE) and natural language instructions. For instance, a user can teach Sugilite how to order the cheaper car between Uber and Lyft, even though Sugilite has no access to their APIs, no knowledge about the task domain, and no understanding of the concept\" cheap\" in advance. Another project, called Verdant, is focusing on helping data scientists\u252c\u00e1\u0393\u00c7\u00aa", "num_citations": "1\n", "authors": ["25"]}
{"title": "Towards effective human-ai collaboration in gui-based interactive task learning agents\n", "abstract": " We argue that a key challenge in enabling usable and useful interactive task learning for intelligent agents is to facilitate effective Human-AI collaboration. We reflect on our past 5 years of efforts on designing, developing and studying the SUGILITE system, discuss the issues on incorporating recent advances in AI with HCI principles in mixed-initiative interactions and multi-modal interactions, and summarize the lessons we learned. Lastly, we identify several challenges and opportunities, and describe our ongoing work", "num_citations": "1\n", "authors": ["25"]}
{"title": "A Pilot Study of the Safety and Usability of the Obsidian Blockchain Programming Language\n", "abstract": " Although blockchains have been proposed for building systems that execute critical transactions, security vulnerabilities have plagued programs that are deployed on blockchain systems. The programming language Obsidian was developed with the purpose of statically preventing some of the more common of these security risks, specifically the loss of resources and improper manipulation of objects. The question then is whether Obsidian\u0393\u00c7\u00d6s novel features impact the usability of the language. In this paper, we begin to evaluate Obsidian with respect to usability, and develop materials for a quantitative user study through a sequence of pilot studies. Specifically, our goal was to assess a) potential usability problems of Obsidian, b) the effectiveness of a tutorial for participants to learn the language, and c) the design of programming tasks to evaluate performance using the language. Our preliminary results tentatively suggest that the complexity of Obsidian\u0393\u00c7\u00d6s features do not hinder usability, although these results will be validated in the quantitative study. We also observed the following factors as being important in a given programmer\u0393\u00c7\u00d6s ability to learn Obsidian: a) integrating very frequent opportunities for practice of the material-eg, after less than a page of material at a time, and b) previous programming experience and self-efficacy.", "num_citations": "1\n", "authors": ["25"]}
{"title": "Human-Centered Methods to Boost Productivity\n", "abstract": " Since programming is a human activity, we can look to fields which have already developed methods for better understanding the details of human interactions with technologies. In particular, the field of human-computer interaction (HCI) has dozens, if not hundreds, of methods that have been validated for answering a wide range of questions about human behaviors. (And many of these methods, in turn, have been adapted from methods used in psychology, ethnography, sociology, etc.) For example, in our research, we have documented the use of at least 10 different human-centered methods across all the phases of software development, almost all of which have impacts on programmer productivity.", "num_citations": "1\n", "authors": ["25"]}
{"title": "UNAKITE: Support Developers for Capturing and Persisting Design Rationales When Solving Problems Using Web Resources\n", "abstract": " UNAKITE is a new system that supports developers in collecting, organizing, consuming, and persisting design rationales while solving problems using web resources. Understanding design rationale has widely been recognized as significant for the success of a software engineering project. However, it is currently both time and labor intensive for little immediate payoff for a developer to generate and embed a useful design rationale in their code. Under this cost structure, there is very little effective tool support to help developers keep track of design rationales. UNAKITE addresses this challenge for some design decisions by changing the cost structure: developers are incentivized to make decisions using UNAKITE\u0393\u00c7\u00d6s collecting and organizing mechanisms as it makes tracking and deciding between alternatives easier than before; the structure thus generated is automatically embedded in the code as the design rationale when the developer copies sample code into their existing code. In a preliminary usability study, developers found UNAKITE to be usable for capturing design rationales and effective for interpreting the rationale of others.", "num_citations": "1\n", "authors": ["25"]}
{"title": "Smartphone text entry in cross-application tasks\n", "abstract": " In this position paper, we discuss our ongoing work on understanding the users\u0393\u00c7\u00d6 smartphone text entry behaviors and needs in cross-application tasks. We also propose a system that enables users to streamline context switch process in cross-application text entry tasks, and create automation for repetitive cross-application text entry tasks.", "num_citations": "1\n", "authors": ["25"]}
{"title": "A demonstration of AZURITE: Backtracking tool for programmers\n", "abstract": " Programmers often need to backtrack, but backtracking support in modern programming environments is limited. Previously, we have conducted a series of studies, which discovered that backtracking in programming is in fact prevalent and programmers need better backtracking tools. In this demonstration, we will present our backtracking tool called AZURITE, which provides selective undo and history search and visualization features in the Eclipse code editor. The demonstration will include the user interface presented in our previous work, as well as the new features added in response to user feedback.", "num_citations": "1\n", "authors": ["25"]}
{"title": "Successful visual and end-user programming systems from industry\n", "abstract": " Summary form only given. Above showsthat the next generation of mobile applications for MOPs need to be part of a much large mobile information system. Such system should be capable of receiving information from a large number of users, intelligently aggregating the information to useful, meaningful, real-time information and making them available to users. Users should be able to make queries and quickly find information that would enhance their day to day activities. It should also have the functionalities to detect different and unusual situations, provide alerts to users in unusual circumstances and emergencies so that users can respond accordingly. These next generation mobile applications for MOPs will open up a very large market currently estimated to be around 3 billion people [13]. These applications will empower them to be information users as well as information producers. Such applications would\u252c\u00e1\u0393\u00c7\u00aa", "num_citations": "1\n", "authors": ["25"]}
{"title": "Characterizing reusability of end-user web macro scripts.\n", "abstract": " Recommendations by software repositories depend on explicit or implicit models for evaluating the quality and relevance of components for programming tasks. As a step toward creating such a model for evaluating end-user web macro scripts, we have identified script characteristics that correspond to the likelihood of script reuse. For example, the likelihood of reuse increases with the number of variables and comments in the script, the number of online forum postings by the script\u0393\u00c7\u00d6s author, and the presence of popular keywords in the script\u0393\u00c7\u00d6s source code. We discuss possible applications of our results for new recommendation features.", "num_citations": "1\n", "authors": ["25"]}
{"title": "Special session in honor of Randy Pausch\n", "abstract": " Randy Pausch is an inspiration to all with his research, teaching, the way he has lived his life, and his courage while confronting pancreatic cancer. This session brings together people he has touched through various phases of his career to discuss his research and legacy.", "num_citations": "1\n", "authors": ["25"]}
{"title": "412: A Randomized Controlled Trial of Pocket PATH Versus Standard Care on Self-Care Behaviors after Lung Transplant\n", "abstract": " PurposeLung recipients are expected to perform self-monitoring, adhere to the medical regimen, and communicate changes to coordinators to improve transplant-related outcomes. Despite high nonadherence rates in performing these behaviors, interventions are lacking. We tested the impact of Pocket PATH, a handheld device with customized data recording, trending and decision-support programs, vs. standard care on the performance of self-care behaviors after lung transplant.", "num_citations": "1\n", "authors": ["25"]}
{"title": "A Demonstration of the RADAR Personal Assistant.\n", "abstract": " Email clients were not designed to serve as a task management tools, but a high volume of task-relevant information in email leads many people to use email clients for this purpose. Such usage aggravates a user\u0393\u00c7\u00d6s experience of email overload and reduces productivity. Prior research systems have sought to address this problem by experimentally adding task management capabilities to email client software. RADAR (Reflective Agents with Distributed Adaptive Reasoning) takes a different approach in which a software agent acts like a trusted human assistant. Many RADAR components employ machine learning to improve their performance. Human participant studies showed a clear impact of learning on user performance metrics.", "num_citations": "1\n", "authors": ["25"]}
{"title": "The EUSES Web Macro Scenario Corpus, Version 1.0\n", "abstract": " Web macros use the programming-by-example concept to automate user actions within a web browser. Although web macro recorders and players have grown in sophistication over the past decade, we believe that these tools cannot yet meet the needs of real users. Based on observations of browser users, we have compiled various scenarios describing tasks that end users would benefit from automating using web macros. Our analysis of these scenarios yields specific requirements that web macro tools must support if those tools are to be applicable to real-life situations. For example, these opportunities for improvement include better support for triggering macros on events, authenticating to sites, transporting data to/from spreadsheets, taking advantage of data\u0393\u00c7\u00d6s semantics, and recovering from errors. Our collection of requirements constitutes a benchmark for evaluating new and improved web macro tools. We developed this corpus as a collaboration within the EUSES Consortium, whose aim is to help End Users Shape Effective Software.", "num_citations": "1\n", "authors": ["25"]}
{"title": "Taking handheld devices to the next level\n", "abstract": " Thanks to increased processing power and wireless technologies such as Bluetooth and IEEE 802.11 (Wi-Fi), handheld devices are communicating more frequently with conventional computers in offices, meeting rooms, classrooms, and homes. The smart homes of the future will have ubiquitous embedded computation, and an increasing number of appliances can already communicate wirelessly. Many common home and office items contain computers\u0393\u00c7\u00f6televisions, VCRs, stereo equipment, ovens, thermostats, telephones, camcorders, factory equipment, automobiles, and even some light switches. Unfortunately, many computerized features are more of a hindrance than a convenience because their user interfaces are often too complex to intuitively understand. 1 In 1997, we and our colleagues in Carnegie Mellon University\u0393\u00c7\u00d6s Human-Computer Interaction Institute (HCII) launched the Pebbles project to determine whether a handheld device, such as a personal digital assistant (PDA) or cell phone, could serve as a simpler, more effective remote control. As part of the project, which is ongoing and will continue for the foreseeable future, we have been studying the simultaneous use of multiple devices, 2 and we have created more than 30 applications to explore novel ways users can apply handhelds as wireless remote controls in offices, meeting rooms, classrooms, homes, factories, and military command posts. Office-centered applications include using the PDA instead of a laser pointer, using a PDA to remotely control a PowerPoint presentation, and using a PDA with the nondominant hand to scroll windows on a PC.In the home, we are\u252c\u00e1\u0393\u00c7\u00aa", "num_citations": "1\n", "authors": ["25"]}
{"title": "Single Display Groupware: Exploring Computer Support for Co-Present Collaboration\n", "abstract": " This panel will explore an interaction paradigm for copresent computer-based collaboration we term Single Display Groupware (SDG). SDG is a class of applications that support multiple simultaneous users interacting in a co-present environment on a single shared display with multiple input-devices. SDG are being used in various applications in the educational, entertainment and research communities, but many issues remain to be explored.", "num_citations": "1\n", "authors": ["25"]}
{"title": "Overview of the Amulet User Interface Toolkit\n", "abstract": " Amulet is a new user interface software environment for C++ on X/11, Microsoft Windows NT or 95, and the Macintosh, which facilitates user interface research by being very open and flexible. In particular, new constraint and undo algorithms can be added, the widgets can modified and replaced, and support is provided for building high-level tools.", "num_citations": "1\n", "authors": ["25"]}
{"title": "Gilt Reference Manual: A Simple Interface Builder for Garnet\n", "abstract": " Gilt is a simple interface layout tool that helps the user design dialog boxes. It allows the user to place pre-defined Garnet gadgets in a window and then save them to a file. There are two versions: one for Garnet look-and-feel gadgets and one for Motif look-and-feel gadgets.", "num_citations": "1\n", "authors": ["25"]}
{"title": "Typed Output and Programming in the Interface\n", "abstract": " A visual shell,(eg, Apple Macintosh), is a direct manipulation interface to an operating system. Although such shells are easier to use than Unix, they have limitations: they are not programmable; the output of utilities can not be directly input to other utilities; and they lack the functionality of utilities such as awk.PURSUIT is a visual shell that introduces a novel interface model, typed utility output, to address some of these limitations. In PURSUIT, all objects are typed. A typed object is an iconic representation of an object in the system, such as a le, user id, network address, etc., that users can manipulate in the traditional direct manipulation way.", "num_citations": "1\n", "authors": ["25"]}
{"title": "Report on the CHI'91 Workshop on Languages for Developing User Interfaces\n", "abstract": " When computers first appeared, input/output commands were a minor afterthought to cohesive, often well crafted and occasionally pretentious programming languages. Today, these commands occupy over 70 percent of a programming system's instructions. Yet they, along with the user interface structures that they define, are far from cohesive, and, at least up until now, immune to standardization. We must therefore turn our thinking around and create a new breed of programming languages that are first and foremost input/output oriented and that integrate traditional processing commands into new user-oriented structures. And just as we know today that traditional commands fall into a handful of fixed categories---decision, repetition, naming, procedure definition and use--we need to search for and identify the corresponding natural classes of commands for user interfaces.[Dertouzos 90]Researchers in the areas\u252c\u00e1\u0393\u00c7\u00aa", "num_citations": "1\n", "authors": ["25"]}
{"title": "Status Report on the User Interface Magazine\n", "abstract": " In May 1989, the SIGCHI Executive Committee voted to form a Publications Committee to investigate CHI-related publications. The SIGCHI Publications Committee had a meeting on October 15, 1989 [1]. The committee recommended the founding of a new magazine on computer-human interaction to address the area of interface design and implementation.", "num_citations": "1\n", "authors": ["25"]}
{"title": "Strategies for Creating an Flasy to Use Window Manager with Icons\n", "abstract": " Sapphire is a powerful window manager for the PERQ personal work station. It was designed to facilitate the single. user\u0393\u00c7\u00ffs ability to monitor and control many different processes operating in parallel and running in different windows. Sapphire contains a full implementation of the covered window paradigm (where the rectangular windows can overlap like pieces of paper on a desk). In order Le make it easier to control processes Sapphire provides icons that display six pieces of dynamically changing state information about the process running in the associated window. In ordcr to make it casier tc control the windows, Sapphire provides a powerful set of operations including: top, bottom. move, grow. reshape. full-screen. baek-from-full-screen. off-screen. back-on-screen. and many others. These commands are presented in a way that is easy to use and selfexplanatory for novices. without penalizing the expert. Almost\u252c\u00e1\u0393\u00c7\u00aa", "num_citations": "1\n", "authors": ["25"]}
{"title": "More Natural Programming Languages\n", "abstract": " Over the last six years, we have been working to create programming languages and environments that are more natural, by which we mean closer to the way people think about their tasks. The goal is to make it possible for people to express their ideas in the same way they think about them. To achieve this, we performed various studies about how people think about programming tasks, and then used this knowledge to develop a new programming language and environment called HANDS. This chapter provides an overview of the goals and background for the Natural Programming research, the results of some of our user studies, and the highlights of the language design.", "num_citations": "1\n", "authors": ["25"]}