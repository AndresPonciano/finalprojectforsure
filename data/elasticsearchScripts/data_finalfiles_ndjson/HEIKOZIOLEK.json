{"title": "Performance evaluation of component-based software systems: A survey\n", "abstract": " Performance prediction and measurement approaches for component-based software systems help software architects to evaluate their systems based on component performance specifications created by component developers. Integrating classical performance models such as queueing networks, stochastic Petri nets, or stochastic process algebras, these approaches additionally exploit the benefits of component-based software engineering, such as reuse and division of work. Although researchers have proposed many approaches in this direction during the last decade, none of them has attained widespread industrial use. On this basis, we have conducted a comprehensive state-of-the-art survey of more than 20 of these approaches assessing their applicability. We classified the approaches according to the expressiveness of their component performance modelling languages. Our survey helps practitioners\u00a0\u2026", "num_citations": "456\n", "authors": ["178"]}
{"title": "Sustainability evaluation of software architectures: a systematic review\n", "abstract": " Long-living software systems are sustainable if they can be cost-efficiently maintained and evolved over their entire life-cycle. The quality of software architectures determines sustainability to a large extent. Scenario-based software architecture evaluation methods can support sustainability analysis, but they are still reluctantly used in practice. They are also not integrated with architecture-level metrics when evaluating implemented systems, which limits their capabilities. Existing literature reviews for architecture evaluation focus on scenario-based methods, but do not provide a critical reflection of the applicability of such methods for sustainability evaluation. Our goal is to measure the sustainability of a software architecture both during early design using scenarios and during evolution using scenarios and metrics, which is highly relevant in practice. We thus provide a systematic literature review assessing scenario\u00a0\u2026", "num_citations": "146\n", "authors": ["178"]}
{"title": "Metrics and benchmarks for self-aware computing systems\n", "abstract": " In this chapter, we propose a list of metrics grouped by the MAPE-K paradigm for quantifying properties of self-aware computing systems. This set of metrics can be seen as a starting point toward benchmarking and comparing self-aware computing systems on a level-playing field. We discuss state-of-the art approaches in the related fields of self-adaptation and self-protection to identify commonalities in metrics for self-aware computing. We illustrate the need for benchmarking self-aware computing systems with the help of an approach that uncovers real-time characteristics of operating systems. Gained insights of this approach can be seen as a way of enhancing self-awareness by a measurement methodology on an ongoing basis. At the end of this chapter, we address new challenges in reference workload definition for benchmarking self-aware computing systems, namely load intensity patterns and\u00a0\u2026", "num_citations": "83\n", "authors": ["178"]}
{"title": "Parameter dependencies for reusable performance specifications of software components\n", "abstract": " Despite the increasing computational power of modern computers, many large, distributed software systems still suffer from performance problems today. To avoid design-related performance problems, model-driven performance prediction methods analyse the response times, throughputs, and resource utilizations of systems under development based on design documents before and during implementation. For component-based software systems, existing prediction methods neglect the performance influence of different usage profiles (i.e., the number of requests and the included parameter values) in their specification languages. This thesis proposes new modelling languages and transformations, which allow a reusable description of usage profile dependencies in component-based software systems. The thesis includes an experimental evaluation, which shows that predictions based on the newly introduced models can support design decisions.", "num_citations": "78\n", "authors": ["178"]}
{"title": "Sustainability guidelines for long-living software systems\n", "abstract": " Economically sustainable software systems must be able to cost-effectively evolve in response to changes in their environment, their usage profile, and business demands. However, in many software development projects, sustainability is treated as an afterthought, as developers are driven by time-to-market pressure and are often not educated to apply sustainability-improving techniques. While software engineering research and practice has suggested a large amount of such techniques, a holistic overview is missing and the effectiveness of individual techniques is often not sufficiently validated. On this behalf we created a catalog of \u201csoftware sustainability guidelines\u201d to support project managers, software architects, and developers during system design, development, operation, and maintenance. This paper describes how we derived these guidelines and how we applied selected techniques from them in two\u00a0\u2026", "num_citations": "77\n", "authors": ["178"]}
{"title": "Automated transformation of component-based software architecture models to queueing petri nets\n", "abstract": " Performance predictions early in the software development process can help to detect problems before resources have been spent on implementation. The Palladio Component Model (PCM) is an example of a mature domain-specific modeling language for component-based systems enabling performance predictions at design time. PCM provides several alternative model solution methods based on analytical and simulation techniques. However, existing solution methods suffer from scalability issues and provide limited flexibility in trading-off between results accuracy and analysis overhead. Queueing Petri Nets (QPNs) are a general-purpose modeling formalism, at a lower level of abstraction, for which efficient and mature simulation-based solution techniques are available. This paper contributes a formal mapping from PCM to QPN models, implemented by means of an automated model-to-model\u00a0\u2026", "num_citations": "66\n", "authors": ["178"]}
{"title": "Goal, question, metric\n", "abstract": " This chapter gives an overview over the Goal-Question-Metric (GQM) approach, a way to derive and select metrics for a particular task in a top-down and goal-oriented fashion.", "num_citations": "59\n", "authors": ["178"]}
{"title": "Towards an Architectural Style for Multi-tenant Software Applications\n", "abstract": " Multi-tenant software applications serve different organizations from a single instance and help to save development, maintenance, and administration costs. The architectural concepts of these applications and their relation to emerging platform-as- a-service (PaaS) environments are still not well understood, so that it is hard for many developers to design and implement such an application. Existing attempts at a structured documentation of the underlying concepts are either technology-specific or restricted to certain details. We propose documenting the concepts as a new architectural style. This paper initially describes the architectural properties, elements, views, and constraints of this style. We illustrate how the architectural elements are implemented in current PaaS environments, such as Force.com, Windows Azure, and Google App Engine.", "num_citations": "56\n", "authors": ["178"]}
{"title": "A QoS driven development process model for component-based software systems\n", "abstract": " Non-functional specifications of software components are considered an important asset in constructing dependable systems, since they enable early Quality of Service (QoS) evaluations. Several approaches for the QoS analysis of component-based software architectures have been introduced. However, most of these approaches do not consider the integration into the development process sufficiently. For example, they envision a pure bottom-up development or neglect that system architects do not have complete information for QoS analyses at their disposal. We extent an existing component-based development process model by Cheesman and Daniels to explicitly include early, model-based QoS analyses. Besides the system architect, we describe further involved roles. Exemplary for the performance domain, we analyse what information these roles can provide to construct a performance model of a\u00a0\u2026", "num_citations": "56\n", "authors": ["178"]}
{"title": "The sposad architectural style for multi-tenant software applications\n", "abstract": " A multi-tenant software application is a special type of highly scalable, hosted software, in which the application and its infrastructure are shared among multiple tenants to save development and maintenance costs. The limited understanding of the underlying architectural concepts still prevents many software architects from designing such a system. Existing documentation on multi-tenant software architectures is either technology-specific or database-centric. A more technology-independent perspective is required to enable wide-spread adoption of multi-tenant architectures. We propose the SPOSAD architectural style, which describes the components, connectors, and data elements of a multi-tenant architecture as well as constraints imposed on these elements. This paper describes the benefits of a such an architecture and the trade-offs for the related design decisions. To evaluate our proposal, we illustrate\u00a0\u2026", "num_citations": "50\n", "authors": ["178"]}
{"title": "A large-scale industrial case study on architecture-based software reliability analysis\n", "abstract": " Architecture-based software reliability analysis methods shall help software architects to identify critical software components and to quantify their influence on the system reliability. Although researchers have proposed more than 20 methods in this area, empirical case studies applying these methods on large-scale industrial systems are rare. The costs and benefits of these methods remain unknown. On this behalf, we have applied the Cheung method on the software architecture of an industrial control system from ABB consisting of more than 100 components organized in nine subsystems with more than three million lines of code. We used the Littlewood/Verrall model to estimate subsystems failure rates and logging data to derive subsystem transition probabilities. We constructed a discrete time Markov chain as an architectural model and conducted a sensitivity analysis. This paper summarizes our experiences\u00a0\u2026", "num_citations": "45\n", "authors": ["178"]}
{"title": "Architectural decision guidance across projects-problem space modeling, decision backlog management and cloud computing knowledge\n", "abstract": " Architectural Knowledge Management (AKM) has been a major topic in software architecture research since 2004. Open AKM problems include an effective, seamless transition from reusable knowledge found in patterns books and technology blogs to project-specific decision guidance and an efficient, practical approach to knowledge application and maintenance. We extended our previous work with concepts for problem space modeling, focusing on reusable knowledge, as well as solution space management, focusing on project-level decisions. We implemented these concepts in ADMentor, an extension of Sparx Enterprise Architect. AD Mentor features rapid problem space modeling, UML model linkage, question-option-criteria diagram support, meta-information for model tailoring, as well as decision backlog management. We validated ADMentor by modeling and applying 85 cloud application design\u00a0\u2026", "num_citations": "43\n", "authors": ["178"]}
{"title": "Measuring architecture sustainability\n", "abstract": " It's difficult to express a software architecture's sustainability in a single metric: relevant information is spread across requirements, architecture design documents, technology choices, source code, system context, and software architects' implicit knowledge. Many aspects influence economic sustainability, including design decisions facilitating evolutionary changes, adherence to good modularization practices, and technology choices. An approach that focuses on a single artifact or perspective is likely to neglect important factors. ABB Corporate Research is tracking the architecture sustainability of a large-scale industrial control system currently under development. A former version of the system grew to several million LOC and suffered from architecture erosion and high maintenance costs. A multiperspective approach called Morphosis will help avoid such a situation in the future by focusing on requirements\u00a0\u2026", "num_citations": "39\n", "authors": ["178"]}
{"title": "Parameter dependent performance specifications of software components\n", "abstract": " Performance predictions based on design documents aim at improving the quality of software architectures. In component-based architectures, it is difficult to specify the performance of individual components, because it depends on the deployment context of a component, which may be unknown to its developers. The way components are used influences the perceived performance, but most performance prediction approaches neglect this influence. In this paper, we present a specification notation based on annotated UML diagrams to explicitly model the influence of parameters on the performance of a software component. The UML specifications are transformed into a stochastical model that allows the prediction of response times as distribution functions. Furthermore, we report on a case study performed on an online store. The results indicate that more accurate predictions could be obtained with the\u00a0\u2026", "num_citations": "34\n", "authors": ["178"]}
{"title": "Self-commissioning industrial IoT-systems in process automation: a reference architecture\n", "abstract": " Distributed control systems are currently evolving towards Industrial Internet-of-Things (IIoT) systems. However, they still suffer from complex commissioning processes that incur high costs. Researchers have proposed several so-called \"Plug and Produce\" (PnP) approaches, where commissioning shall be largely automated, but they have suffered from semantic ambiguities and usually rely on proprietary information models. We propose a novel reference architecture for PnP in IIoT systems, which is based on OPC UA and PLCopen standards and can reduce industrial device commissioning times across vendor products to a few seconds. Our proof-of-concept implementation can handle more than 500 signals per millisecond during runtime, sufficient for most application scenarios.", "num_citations": "28\n", "authors": ["178"]}
{"title": "Operational profiles for software reliability\n", "abstract": " Software needs to be tested extensively before it is considered dependable and trustworthy. To guide testing, software developers often use an operational profile, which is a quantitative representation of how a system will be used. By documenting user inputs and their occurrence probabilities in such a profile, it can be ensured that the most used functions of a system are tested the most. Test cases can be generated directly out of an operational profile. Operational profiles are also a necessary part of quality-of-service prediction methods for software architectures, because these models have to include user inputs into their calculations. This paper outlines how operational profiles can be modelled in principle. Different kinds of usage descriptions of software system have been developed and are summarized in this article.", "num_citations": "28\n", "authors": ["178"]}
{"title": "Parameter dependencies for component reliability specifications\n", "abstract": " Predicting the reliability of a software system at an architectural level during early design stages can help to make systems more dependable and avoid costs for fixing the implementation. Existing reliability prediction methods for component-based systems use Markov models and assume that the software architect can provide the transition probabilities between individual components. This is however not possible if the components are black boxes, only at the design stage, or not available for testing. We propose a new modelling formalism that includes parameter dependencies into software component reliability specifications. It allows the software architect to only model a system-level usage profile (i.e., parameter values and call frequencies), which a tool then propagates to individual components to determine the transition probabilities of the Markov model. We demonstrate the applicability of our approach by\u00a0\u2026", "num_citations": "26\n", "authors": ["178"]}
{"title": "Parametric performance contracts: Non-markovian loop modelling and an experimental evaluation\n", "abstract": " Even with todays hardware improvements, performance problems are still common in many software systems. An approach to tackle this problem for component-based software architectures is to predict the performance during early development stages by combining performance specifications of prefabricated components. Many existing methods in the area of component-based performance prediction neglect several influence factors on the performance of a component. In this paper, we present a method to calculate the performance of component services while including influences of external services and different usages. We use stochatic regular expressions with non-Markovian loop iterations to model the abstract control flow of a software component and probability mass functions to specify the time consumption of internal and external services in a fine grain way. An experimental evaluation is reported\u00a0\u2026", "num_citations": "24\n", "authors": ["178"]}
{"title": "Experiences from identifying software reuse opportunities by domain analysis\n", "abstract": " In a large corporate organization there are sometimes similar software products in certain subdomains with a perceived functional overlap. This promises to be an opportunity for systematic reuse to reduce software development and maintenance costs. In such situations companies have used different domain analysis approaches (eg, SEI Technical Probe) that helped to assess technical and organizational potential for a software product line approach. We applied existing domain analysis approaches for software product line engineering and tailored them to include a feature analysis as well as architecture evaluation. In this paper, we report our experiences from applying the approach in two subdomains of industrial automation.", "num_citations": "20\n", "authors": ["178"]}
{"title": "Empirical evaluation of model-based performance prediction methods in software development\n", "abstract": " Predicting the performance of software architectures during early design stages is an active field of research in software engineering. It is expected that accurate predictions minimize the risk of performance problems in software systems by a great extent. This would improve quality and save development time and costs of subsequent code fixings. Although a lot of different methods have been proposed, none of them have gained widespread application in practice. In this paper we describe the evaluation and comparison of three approaches for early performance predictions (Software Performance Engineering (SPE), Capacity Planning (CP) and umlPSI). We conducted an experiment with 31 computer science students. Our results show that SPE and CP are suited for supporting performance design decisions in our scenario. CP is also able to validate performance goals as stated in requirement\u00a0\u2026", "num_citations": "20\n", "authors": ["178"]}
{"title": "Transforming operational profiles of software components for quality of service predictions\n", "abstract": " Current Quality-of-Service (QoS) predictions methods for component-based software systems disregard the influence of the operational profile for anticipating an architecture\u2019s performance, reliability, security or safety. The operational profile captures the set of inputs and outputs to a software components. We argue, that a detailed operational profile especially for software components is necessary for accurate QoS-predictions and that a standardised form of it is needed. We demonstrate that components act as transformers to an operational profile and discuss that this transformation has to be described, so that QoS prediction methods are able to deliver appropriate results for component-based architectures.", "num_citations": "19\n", "authors": ["178"]}
{"title": "Identify impacts of evolving third party components on long-living software systems\n", "abstract": " Integrating 3rd party components in software systems provides promising advantages but also risks due to disconnected evolution cycles. Deciding whether to migrate to a newer version of a 3rd party component integrated into self-implemented code or to switch to a different one is challenging. Dedicated evolution support for 3rd party component scenarios is hence required. Existing approaches do not account for open source components which allow accessing and analyzing their source code and project information. The approach presented in this paper combines analyses for code dependency, code quality, and bug tracker information for a holistic view on the evolution with 3rd party components. We applied the approach in a case study on a communication middleware component for industrial devices used at ABB. We identified 7 methods potentially impacted by changes of 3rd party components despite the\u00a0\u2026", "num_citations": "17\n", "authors": ["178"]}
{"title": "Towards software sustainability guidelines for long-living industrial systems\n", "abstract": " Long-living software systems are sustainable if they can be cost-effectively maintained and evolved over their complete life-cycle. Software-intensive systems in the industrial automation domain are typically long-living and cause high evolution costs, because of new customer requirements, technology changes, and failure reports. Many methods for sustainable software development have been proposed in the scientific literature, but most of them are not applied in industrial practice. We identified typical evolution scenarios in the industrial automation domain and conducted an extensive literature search to extract a number of guidelines for sustainable software development based on the methods found in literature. For validation purposes, we map one evolution scenario to these guidelines in this paper.", "num_citations": "17\n", "authors": ["178"]}
{"title": "Software evolution for industrial automation systems: literature overview\n", "abstract": " 1.1 ObjectivesThis document contains a literature overview for the DARWIN research project. It is a living document and is regularly reviewed and extended. The ABB project manager, Roland Weiss, and FZI Project Manager, Klaus Krogmann, are responsible for upkeep of this document.The goal of this document is to provide an overview of various strategies concerning evolution of sustainable systems. The selection criteria for the survey include the applicability of the proposed approaches to real-world evolution scenarios and systems. The applicability is determined based on the availability of industrial experience reports and tooling.", "num_citations": "17\n", "authors": ["178"]}
{"title": "Assessing software product line potential: an exploratory industrial case study\n", "abstract": " Corporate organizations sometimes offer similar software products in certain domains due to former company mergers or due to the complexity of the organization. The functional overlap of such products is an opportunity for future systematic reuse to reduce software development and maintenance costs. Therefore, we have tailored existing domain analysis methods to our organization to identify commonalities and variabilities among such products and to assess the potential for software product line (SPL) approaches. As an exploratory case study, we report on our experiences and lessons learned from conducting the domain analysis in four application cases with large-scale software products. We learned that the outcome of a domain analysis was often a smaller integration scenario instead of an SPL and that business case calculations were less relevant for the stakeholders and managers from the\u00a0\u2026", "num_citations": "15\n", "authors": ["178"]}
{"title": "Evolving industrial software architectures into a software product line: A case study\n", "abstract": " Industrial software applications have high requirements on performance, availability, and maintainability. Additionally, diverse application landscapes of large corporate companies require systematic planning for reuse, which can be fostered by a software product-line approach. Analyses at the software architecture level can help improving the structure of the systems to account for extra-functional requirements and reuse. This paper reports a case study of product-line development for ABB\u2019s robotics PC software. We analysed the software architectures of three existing robotics applications and identified their core assets. As a result, we designed a new product-line architecture, which targets at fulfilling various extra-functional requirements. This paper describes experiences and lessons learned during the project.", "num_citations": "15\n", "authors": ["178"]}
{"title": "Bottleneck identification and performance modeling of OPC UA communication models\n", "abstract": " The OPC UA communication architecture is currently becoming an integral part of industrial automation systems, which control complex production processes, such as electric power generation or paper production. With a recently released extension for pub/sub communication, OPC UA can now also support fast cyclic control applications, but the bottlenecks of OPC UA implementations and their scalability on resource-constrained industrial devices are not yet well understood. Former OPC UA performance evaluations mainly concerned client/server round-trip times or focused on jitter, but did not explore resource bottlenecks or create predictive performance models. We have carried out extensive performance measurements with OPC UA client/server and pub/sub communication and created a CPU utilization prediction model based on linear regression that can be used to size hardware environments. We found\u00a0\u2026", "num_citations": "14\n", "authors": ["178"]}
{"title": "Semantic interoperability for asset communication within smart factories\n", "abstract": " Industrie 4.0 (I4.0) aims at a manufacturer-independent, vertical- and horizontal-oriented communication and cooperation within smart factories. This is only manageable using international standards. The so-called reference architecture model for Industrie 4.0 (RAMI4.0) and the requirement specification of an I4.0 component are already available. RAMI4.0 could be the basis for the interoperability of the interactions. The working group \u201cSemantic and interaction model for I4.0 components\u201d (GMA 7.20) made progress in this direction. The language used for the interaction of I4.0 components needs model definitions for the interaction consisting of the structure of the components, syntax for the description of the messages and the means to assign the meaning to the language elements. This paper discusses the results for a broader audience.", "num_citations": "14\n", "authors": ["178"]}
{"title": "Empirische bewertung von performance-analyseverfahren f\u00fcr software-architekturen\n", "abstract": " A goal of this work is evaluating the applicability of different performance prediction methods from the view of the developer by an empirical study. To attain this goal several research questions are posed:", "num_citations": "14\n", "authors": ["178"]}
{"title": "Robot system\n", "abstract": " A robot system is disclosed which includes at least two robots, each having a related processing unit. The processing units are connected to each other via a network bus for data transmission, and distributed sensors are provided for gathering first and/or second measurement data within a local extension of the robot system. First measurement data gathered by at least one first sensor are transmissible to at least one processing unit related thereto. Second measurement data gathered by at least one second sensor are feedable into the network bus and provided to the at least two processing units connected thereto. The processing units can analyze the second measurement data as a variable dynamic share of workload for feeding result-data of the analysis into the network bus.", "num_citations": "13\n", "authors": ["178"]}
{"title": "Measuring performance metrics: Techniques and tools\n", "abstract": " This chapter describes techniques for characterising workloads, which is a prerequisite for obtaining performance measurements in realistic settings, and presents an overview on performance measurement tools such as benchmarks, monitors, and load drivers.", "num_citations": "13\n", "authors": ["178"]}
{"title": "A comparison of MQTT brokers for distributed IoT edge computing\n", "abstract": " Many enterprise IoT application scenarios, such as connected cars, smart cities, and cloud-connected industrial plants require distributed MQTT brokers to achieve high scalability and availability. With a market of over 20 MQTT brokers, it is hard for software architects to make a good selection. Existing MQTT comparisons often include only non-distributed brokers, focus exclusively on performance, or are difficult to generalize. We compared three distributed MQTT brokers for performance, scalability, resilience, security, extensibility, and usability in an enterprise IoT scenario deployed to an edge gateway cluster. We found that EMQX provided the best performance (28K\u00a0msg/s), while only HiveMQ showed no message loss in our test scenario. VerneMQ offers similar features as the other brokers but is fully available as open source. The paper includes decision guidance for software architects, listing six\u00a0\u2026", "num_citations": "12\n", "authors": ["178"]}
{"title": "Combining architecture-based software reliability predictions with financial impact calculations\n", "abstract": " Software failures can lead to substantial costs for the user. Existing models for software reliability prediction do not provide much insight into this financial impact. Our approach presents a first step towards the integration of reliability prediction from the IT perspective and the business perspective. We show that failure impact should be taken into account not only at their date of occurrence but already in the design stage of the development. First we model cost relevant business processes as well as the associated IT layer and then connect them to failure probabilities. Based on this we conduct a reliability and cost estimation. The method is illustrated by a case study.", "num_citations": "12\n", "authors": ["178"]}
{"title": "Introduction to performance metrics\n", "abstract": " This chapter defines simple performance metrics and gives an outlook over the remaining chapters of Part IV.", "num_citations": "12\n", "authors": ["178"]}
{"title": "Industrie 4.0\n", "abstract": " This contribution provides an intuitive introduction into the topic of Industrie 4.0 and explains, why this topic is hard to grasp, and why it will come anyway. With the introduction of the internet into production systems Industrie 4.0 creates an area of tension: driven by the IT domain, whose innovation power is usually years ahead of the industry, and settled by the industry which existence depends on requirements with respect to investment protection, availability and data security.", "num_citations": "11\n", "authors": ["178"]}
{"title": "OpenPnP: a plug-and-produce architecture for the industrial internet of things\n", "abstract": " Industrial control systems are complex, software-intensive systems that manage mission-critical production processes. Commissioning such systems requires installing, configuring, and integrating thousands of sensors, actuators, and controllers and is still a largely manual and costly process. Therefore, practitioners and researchers have been working on \"plug and produce\" approaches that automate commissioning for more than 15 years, but have often focused on network discovery and proprietary technologies. We introduce the vendor-neutral OpenPnP reference architecture, which can largely automate the configuration and integration tasks for commissioning. Using an example implementation, we demonstrate that OpenPnP can reduce the configuration and integration effort up to 90 percent and scales up to tens of thousands of communicated signals per second for large Industrial Internet-of-Things (IIoT\u00a0\u2026", "num_citations": "10\n", "authors": ["178"]}
{"title": "MORPHOSIS: A lightweight method facilitating sustainable software architectures\n", "abstract": " Managing the cost-effective evolution of industrial software systems is a challenging task because of their complexity and long lifetimes. Limited pro-active evolution planning and software architecture erosion often lead to huge maintenance costs in such systems. However, formerly researched approaches for evolution scenario analysis and architecture enforcement are only reluctantly applied by practitioners due to their perceived overhead and high costs. We have applied several recent sustainability evaluation and improvement approaches in a case study to the software architecture of a large industrial software system currently under development at ABB. We combined our selection of approaches in a lightweight method called MORPHOSIS, for which this paper presents experiences and lessons learned. We found that reasonable sustainability evaluation and improvement is possible already with limited efforts.", "num_citations": "9\n", "authors": ["178"]}
{"title": "A classification framework for automated control code generation in industrial automation\n", "abstract": " Software development for the automation of industrial facilities (e.g., oil platforms, chemical plants, power plants, etc.) involves implementing control logic, often in IEC 61131-3 programming languages. Developing safe and efficient program code is expensive and today still requires substantial manual effort. Researchers have thus proposed numerous approaches for automatic control logic generation in the last two decades, but a systematic, in-depth analysis of their capabilities and assumptions is missing. This paper proposes a novel classification framework for control logic generation approaches defining criteria derived from industry best practices. The framework is applied to compare and analyze 13 different control logic generation approaches. Prominent findings include different categories of control logic generation approaches, the challenge of dealing with iterative engineering processes, and the need for\u00a0\u2026", "num_citations": "8\n", "authors": ["178"]}
{"title": "A catalogue of architectural decisions for designing IIoT systems\n", "abstract": " Designing Industrial IoT (IIoT) systems enforces new sets of architectural decisions on software/system architects. Although a rich set of materials for architecting enterprise software systems exist, there is a lack of reference documents on architectural decisions and alternatives that architects face to design IIoT systems. Based on our experience in designing IIoT systems in various domains such as process automation, discrete manufacturing and building automation, we provide a catalogue of architectural decisions, their impacts on the quality attributes of systems, and technology options to realize each design alternative.", "num_citations": "8\n", "authors": ["178"]}
{"title": "The role of experimentation in software engineering\n", "abstract": " Research proposals need to be validated either by formal proofs or by applying empirical methods (eg controlled experiments). Many authors have pointed out that the level of experimentation in software engineering is not satisfactory. The quantity of experimentation is too low as a lot of software engineering publication do not contain any empirical validation at all. But also the quality of software engineering experiments conducted so far is often weak, because no proper methodological approach is applied and statistical methods are misused. This paper provides an overview of the status of experimentation in software engineering. First, the role of experimentation among other types of research is clarified. Several research paradigms are introduced, a classification of different types of experiments in software engineering is provided, and a comparison with experimentation in other research disciplines is drawn. Afterwards the current state of experimentation in software engineering is analysed with more detail. Some discussion points from various researchers about the situation of experimentation are summed up. Their recommendations for improving the state of experimentation are provided as well as possible future directions of experimentation in software engineering.", "num_citations": "7\n", "authors": ["178"]}
{"title": "Automated industrial IoT\u2010device integration using the OpenPnP reference architecture\n", "abstract": " Distributed control systems are currently evolving towards industrial Internet of Things (IoT) systems communicating fully using Internet protocols. This creates opportunities for streamlining costly commissioning processes, which today require substantial manual work for installing, configuring, and integrating thousands of actuators and sensors. The vision of \u201cplug\u2010and\u2010produce\u201d control systems has been pursued for more than 15 years, but existing approaches fell short regarding configuration tasks and vendor neutrality. This paper introduces the standards\u2010based IoT reference architecture OpenPnP, which allows largely automating the configuration and integration tasks of industrial commissioning processes. The architecture includes a number of design and technology decisions and the required implementation can be scaled down to resource\u2010constrained industrial devices. This paper demonstrates how\u00a0\u2026", "num_citations": "6\n", "authors": ["178"]}
{"title": "Tool-driven technology transfer to support software architecture decisions\n", "abstract": " Software architecture design decisions are key drivers for the success of software systems. Despite awareness for their criticality, software architects often rationalize and document their decisions poorly. On this behalf, ABB Corporate Research initiated a technology transfer project to integrate an architecture decision framework from the University of Groningen into ABB software development processes. The project involved close communication between university researchers, industry researchers, and ABB software architects and resulted in the implementation of a plug-in for the UML tool Enterprise Architect. This paper summarizes success factors for the technology transfer, such as strong buy-in from the stakeholders, short feedback cycles, and seamless integration into existing tool-chains.", "num_citations": "6\n", "authors": ["178"]}
{"title": "Customizing domain analysis for assessing the reuse potential of industrial software systems: experience report\n", "abstract": " In companies with a large portfolio of software or software-intensive products, functional overlaps are often perceived between independent products. In such situations it is advisable to systematically analyze the potential of systematic reuse and Software Product Lines. To this end, several domain analysis approaches, eg, SEI Technical Probe, have been proposed to decide whether a set of products with a perceived functional overlap should be integrated into a single product line. Based on the principles of those approaches we devised our own approach. One important property is the inherent flexibility of the method to be able to apply it to four different application cases in industrial software products at ABB. In this paper we present our refined approach for domain analysis. The results and lessons learned are meant to support industrial researchers and practitioners alike. Moreover, the lessons learned highlight\u00a0\u2026", "num_citations": "4\n", "authors": ["178"]}
{"title": "Rapid performance modeling by transforming use case maps to palladio component models\n", "abstract": " Complex information flows in the domain of industrial software systems complicate the creation of performance models to validate the challenging performance requirements. Performance models using annotated UML diagrams or mathematical notations are difficult to discuss with stakeholders from the industrial automation domain, who often have a limited software engineering background. We introduce a novel model transformation from Use Case Maps (UCM) to the Palladio Component Model (PCM), which enables performance modeling based on an intuitive notation for complex information flows. The resulting models can be solved using existing simulators or analytical solvers. We validated the correctness of the transformation with three case study models, and performed a user study. The results showed a performance prediction deviation of less than 10 percent compared to a reference model in most cases.", "num_citations": "4\n", "authors": ["178"]}
{"title": "Service Architecture Meta Model\n", "abstract": " Service Architecture Meta Model | D3S D3S homepage For Students Research People Projects Software Publications Seminar Contact Service Architecture Meta Model Technical report Title: Service Architecture Meta Model Authors: S. Becker, L. Bulej, T. Bure\u0161, P. Hn\u011btynka, L. Kapova, J. Kofro\u0148, H. Koziolek, J. Kraft, R. Mirandola, J. Stammel, G. Tamburrelli, M. Trifu Publication: Technical report, Year: 2008 BibTeX: @techreport{becker_service_report_2008, title = {{Service Architecture Meta Model}}, author = {Becker, Steffen and Bulej, Lubom\u0131r and Bures, T. and Hnetynka, Petr and Kapova, Lucia and Kofron, Jan and Koziolek, Heiko and Kraft, Johan and Mirandola, Raffaella and Stammel, Johannes and Tamburrelli, Giordano and Trifu, Mircea}, year = {2008}, } \u00a9 D3S Edit this page Department of Distributed and Dependable Systems Faculty of Mathematics and Physics Charles University Malostransk\u00e9 n\u00e1m\u011bst\u00ed 25 1 \u2026", "num_citations": "4\n", "authors": ["178"]}
{"title": "Performance metrics for specific domains\n", "abstract": " Some performance metrics are specific for certain domains or are used differently under different circumstances. In the following, performance metrics for Internet-based systems and embedded systems will be described.", "num_citations": "4\n", "authors": ["178"]}
{"title": "Towards Resilient IoT Messaging: An Experience Report Analyzing MQTT Brokers\n", "abstract": " Many Internet-of-Things (IoT) applications for smart homes, connected factories, or car-to-car communication utilize broker-based publish/subscribe communication protocols, such as the MQTT protocol. Commercial IoT applications have high reliability requirements for messaging, as lost messages due to unstable Internet connections or node failures can harm devices or even human beings. MQTT brokers implement numerous architectural availability tactics, but former analyses of MQTT communication have mainly focused on performance measurements under stable conditions. We have created the MAYHEM resilience testing tool for MQTT brokers and applied it in various resilience experiments on different MQTT brokers (VerneMQ, Mosquitto, HiveMQ, EMQ X). We found that MQTT QoS level 0 is already robust against minor packet loss, that selected broker message persistency solutions can lead to lost\u00a0\u2026", "num_citations": "3\n", "authors": ["178"]}
{"title": "Grammatik f\u00fcr Industrie 4.0-Komponenten\n", "abstract": " Grammatik f\u00fcr Industrie 4.0-Komponenten - Tagungsbeitr\u00e4ge - VDE VERLAG Top Kontaktinformationen Newsletter Login / Registrieren Warenkorb (0) English Area VDE VERLAG Technik. Wissen. Weiterwissen. Suchen Alle Kategorien Alle Kategorien B\u00fccher VDE-Normen IEC-Normen Seminare VDE VERLAG Technik. Wissen. Weiterwissen. NORMEN VDE-Normen und Entw\u00fcrfe Produkt-\u00dcbersicht VDE-Vorschriftenwerk Auswahlen und Gruppen Entw\u00fcrfe Anwendungsregeln Englische \u00dcbersetzungen Apps zu Normen Informationen zum E-Handwerk Informationen zur Ausbildung Bezugsm\u00f6glichkeiten: Abonnement NormenBibliothek VDE-Normen: Suchen + Bestellen VDE-Neuerscheinungen Weitere Services: Preis-Infos FAQ IEC-Publikationen Produkt-\u00dcbersicht IEC-Normen: Suchen + Bestellen IEC-Datenbanken Erwerb von Mehrplatzlizenzen IEC-Neuerscheinungen B\u00dcCHER Buchprogramm-\u00dcbersicht Blitz- - \u2026", "num_citations": "3\n", "authors": ["178"]}
{"title": "The role of models in self-adaptive and self-healing systems\n", "abstract": " Self-healing and self-adaptive systems dynamically react on changes in the environment. They enable software systems to adjust to new conditions and work optimally even in unstable environments. However, such systems have to cope with an ever increasing complexity and size of software systems. In order to handle such systems, models are an efficient means for analysis, control, and documentation. Furthermore, hierarchically structured models can make self-healing and self-adaptation manageable. In this report, we discuss several questions that address the role of models in self-healing and self-adaptive systems. We outline today\u2019s challenges and present different viewpoints on the application and benefit of models.", "num_citations": "3\n", "authors": ["178"]}
{"title": "Life-Cycle-Herausforderungen f\u00fcr Prozessleitsysteme\n", "abstract": " Industrielle Prozessleitsysteme verursachen durch ihre lange Einsatzdauer dom\u00e4nenspezifische Herausforderungen f\u00fcr Betreiber und Lieferant, die sich mit etablierten Methoden aus dem IT-Bereich nur schwierig l\u00f6sen lassen. Obwohl nur noch gebrauchter Hardwareersatz f\u00fcr Komponenten \u00e4lterer Prozessleitsysteme verf\u00fcgbar sein mag, scheuen Betreiber in der Automatisierung\u2013anders als Endkunden im IT-Bereich\u2013aus Gr\u00fcnden des Investitionsschutzes die Migration auf neuere Hardware. Selbst bei Bereitschaft zur Migration erfordern existierende Migrationsl\u00f6sungen h\u00e4ufig kostspielige manuelle Nacharbeiten an den Steuerungsprogrammen. In diesem Beitrag werden anhand von f\u00fcnf industriellen Fallstudien die St\u00e4rken und Schw\u00e4chen verschiedener Strategien zum Life-Cycle-Management untersucht. Die Erkenntnisse liefern wertvolle Hinweise f\u00fcr die Entwicklung von neuen Methoden und Werkzeugen\u00a0\u2026", "num_citations": "2\n", "authors": ["178"]}
{"title": "Agreements for software reuse in corporations\n", "abstract": " Agreements for sharing of software between entities in a corporation have to be tailored to fit the situation. Such agreements are not legal documents and must address different issues than traditional software licenses. We found that these agreements should cover what is granted, payment, support, ownership and liability. In a case study we learned that an agreement should list its assumptions on the structure and processes of the software organization. The presented work enables others to create guidelines for software sharing agreements tailored to their organization and shares lessons about the differences between software product lines and corporate software sharing and reuse.", "num_citations": "2\n", "authors": ["178"]}
{"title": "Performance metrics in software design models\n", "abstract": " This chapter summarizes two extensions of the Unified Modeling Language (UML) that allow to express performance characteristics.", "num_citations": "2\n", "authors": ["178"]}
{"title": "Rule-based code generation in industrial automation: four large-scale case studies applying the CAYENNE method\n", "abstract": " Software development for industrial automation applications is a growing market with high economic impact. Control engineers design and implement software for such systems using standardized programming languages (IEC 61131-3) and still require substantial manual work causing high engineering costs and potential quality issues. Methods for automatically generating control logic using knowledge extraction from formal requirements documents have been developed, but so far only been demonstrated in simplified lab settings. We have executed four case studies on large industrial plants with thousands of sensors and actuators for a rule-based control logic generation approach called CAYENNE to determine its practicability. We found that we can generate more than 70 percent of the required interlocking control logic with code generation rules that are applicable across different plants. This can lead to\u00a0\u2026", "num_citations": "1\n", "authors": ["178"]}
{"title": "Industrie 4.0 and international perspective\n", "abstract": " This chapter discusses the German-driven initiative Industrie 4.0 and addresses some commonalities and differences. It suggests possible synergies and shows how Smart Manufacturing and Industrie 4.0 activities can support and complement each other. It also reviews some applications within Industrie 4.0 and summarizes the development roadmap.", "num_citations": "1\n", "authors": ["178"]}
{"title": "Architectural decision forces at work: experiences in an industrial consultancy setting\n", "abstract": " The concepts of decision forces and the decision forces viewpoint were proposed to help software architects to make architectural decisions more transparent and the documentation of their rationales more explicit. However, practical experience reports and guidelines on how to use the viewpoint in typical industrial project setups are not available. Existing works mainly focus on basic tool support for the documentation of the viewpoint or show how forces can be used as part of focused architecture review sessions. With this paper, we share experiences and lessons learned from applying the decision forces viewpoint in a distributed industrial project setup, which involves consultants supporting architects during the re-design process of an existing large software system. Alongside our findings, we describe new forces that can serve as template for similar projects, discuss challenges applying them in a distributed\u00a0\u2026", "num_citations": "1\n", "authors": ["178"]}
{"title": "Automatisierte Inbetriebnahme von Industriellen IoT-Systemen in der Prozessautomatisierung: Eine Referenzarchitektur\n", "abstract": " Die Inbetriebnahme von Prozessleitsystemen ist heutzutage teuer und umst\u00e4ndlich, da ein hoher manueller Aufwand n\u00f6tig ist. Durch den Trend zu Industrie 4.0 und IIoT sind bereits eine Vielzahl industrieller Standards verf\u00fcgbar, auf deren Basis herstellerunabh\u00e4ngige selbstkonfigurierende Ger\u00e4te (\u201ePlug-and-Produce\u201c (PnP)) realisiert werden k\u00f6nnen, die den Aufwand der Inbetriebnahme verringern. In diesem Papier stellen wir eine auf solchen Standards basierende Referenzarchitektur f\u00fcr IIoT-Prozessautomatisierungssysteme vor. Die Eckpfeiler der Architektur sind (i) die Verwendung modellbasierter Beschreibungen basierend auf PLCopen f\u00fcr gesteuerte Ger\u00e4te, (ii) die Spezifikation eines PnP-Dienstes, der das Abstimmen der Konfigurationen von Steuereinheit (engl. Controller) und Feldger\u00e4ten entkoppelt und hierzu auf OPC UA Pub/Sub zur\u00fcckgreift sowie (iii) die Verwendung von Technologien f\u00fcr\u00a0\u2026", "num_citations": "1\n", "authors": ["178"]}
{"title": "Customizing domain analysis for assessing the reuse potential of industrial software systems\n", "abstract": " In companies with a large portfolio of software or softwareintensive products, functional overlaps are often perceived between independent products. In such situations it is advisable to systematically analyze the potential of systematic reuse and Software Product Lines. To this end, several domain analysis approaches, eg, SEI Technical Probe, have been proposed to decide whether a set of products with a perceived functional overlap should be integrated into a single product line. Based on the principles of those approaches we devised our own approach. One important property is the inherent flexibility of the method to be able to apply it to four different application cases in industrial software products at ABB. In this paper we present our refined approach for domain analysis. The results and lessons learned are meant to support industrial researchers and practitioners alike. Moreover, the lessons learned highlight real-world findings concerning software reuse.", "num_citations": "1\n", "authors": ["178"]}