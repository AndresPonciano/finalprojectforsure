{"title": "Reliable communication in the presence of failures\n", "abstract": " The design and correctness of a communication facility for a distributed computer system are reported on. The facility provides support for fault-tolerant process groups in the form of a family of reliable multicast protocols that can be used in both local- and wide-area networks. These protocols attain high levels of concurrency, while respecting application-specific delivery ordering constraints, and have varying cost and performance that depend on the degree of ordering desired. In particular, a protocol that enforces causal delivery orderings is introduced and shown to be a valuable alternative to conventional asynchronous communication protocols. The facility also ensures that the processes belonging to a fault-tolerant process group will observe consistent orderings of events affecting the group as a whole, including process failures, recoveries, migration, and dynamic changes to group properties like member\u00a0\u2026", "num_citations": "1555\n", "authors": ["491"]}
{"title": "The process group approach to reliable distributed computing\n", "abstract": " One might expect the reliability of a distributed system to correspond directly to the reliability of its constituents, but this is not always the case. The mechanisms used to structure a distributed system and to implement cooperation between components play a vital role in determining the reliability of the system. Many contemporary distributed operating systems have placed emphasis on communication performance, overlooking the need for tools to integrate components into a reliable whole. The communication primitives supported give generally reliable behavior, but exhibit problematic semantics when transient failures or system configuration changes occur. The resulting building blocks are, therefore, unsuitable for facilitating the construction of systems where reliability is important. This article reviews 10 years of research on ISIS, a system that provides tools to support the construction of reliable distributed\u00a0\u2026", "num_citations": "1290\n", "authors": ["491"]}
{"title": "Exploiting virtual synchrony in distributed systems\n", "abstract": " We describe applications of a virtually synchronous environment for distributed programming, which underlies a collection of distributed programming tools in the ISIS 2 system. A virtually synchronous environment allows processes to be structured into process groups, and makes events like broadcasts to the group as an entity, group membership changes, and even migration of an activity from one place to another appear to occur instantaneously\u2014in other words, synchronously. A major advantage to this approach is that many aspects of a distributed application can be treated independently without compromising correctness. Moreover, user code that is designed as if the system were synchronous can often be executed concurrently. We argue that this approach to building distributed and fault-tolerant software is more straightforward, more flexible, and more likely to yield correct solutions than alternative\u00a0\u2026", "num_citations": "1056\n", "authors": ["491"]}
{"title": "Bimodal multicast\n", "abstract": " There are many methods for making a multicast protocol \u201creliable.\u201d At one end of the spectrum, a reliable multicast protocol might offer tomicity guarantees, such as all-or-nothing delivery, delivery ordering, and perhaps additional properties such as virtually synchronous addressing. At the other are protocols that use local repair to overcome transient packet loss in the network, offering \u201cbest effort\u201d reliability. Yet none of this prior work has treated stability of multicast delivery as a basic reliability property, such as might be needed in an internet radio, television, or conferencing application. This article looks at reliability with a new goal: development of a multicast protocol which is reliable in a sense that can be rigorously quantified and  includes throughput stability guarantees. We characterize this new protocol as a \u201cbimodal multicast\u201d in reference to its reliability model, which corresponds to a family of bimodal\u00a0\u2026", "num_citations": "978\n", "authors": ["491"]}
{"title": "Building secure and reliable network applications\n", "abstract": " Despite nearly 20 years of progress toward ubiquitous computer connectivity, distributed computing systems have only recently emerged to play a serious role in industry and society. Perhaps this explains why so few distributed systems are reliable in the sense of tolerating failures automatically, guaranteeing properties such as performance or response time, or offering security against intentional threats. In many ways the engineering discipline of reliable distributed computing is still in its infancy.", "num_citations": "642\n", "authors": ["491"]}
{"title": "EPOCHS: a platform for agent-based electric power and communication simulation built from commercial off-the-shelf components\n", "abstract": " This paper reports on the development and subsequent use of the electric power and communication synchronizing simulator (EPOCHS), a distributed simulation environment. Existing electric power simulation tools accurately model power systems of the past, which were controlled as large regional power pools without significant communication elements. However, as power systems increasingly turn to protection and control systems that make use of computer networks, these simulators are less and less capable of predicting the likely behavior of the resulting power grids. Similarly, the tools used to evaluate new communication protocols and systems have been developed without attention to the roles they might play in power scenarios. EPOCHS integrates multiple research and commercial off-the-shelf systems to bridge the gap.", "num_citations": "441\n", "authors": ["491"]}
{"title": "Replication and fault-tolerance in the ISIS system\n", "abstract": " The ISIS system transforms abstract type specifications into fault-tolerant distributed implementations while insulating users from the mechanisms used tO achieve fault-toleram: e. This paper discusses tedmiques for obtaining a fault-tolerant implementation from a now distributed specification and for achieving improved performanc~ by concurrently updating replicated data. The system itself is based on a small set of communication primitives, which are interesting because they achieve high levels of concurrency while respecting higher level ordering requirements. The performance of distributed fault-tolerant services runnin 8 on this initial version of ISIS is found to be nearly as good as that of non-distributed, fault-intolerant ones.", "num_citations": "406\n", "authors": ["491"]}
{"title": "Anonymous gossip: Improving multicast reliability in mobile ad-hoc networks\n", "abstract": " In recent years, a number of applications of ad-hoc networks have been proposed. Many of them are based on the availability of a robust and reliable multicast protocol. We address the issue of reliability and propose a scalable method to improve packet delivery of multicast routing protocols and decrease the variation in the number of packets received by different nodes. The proposed protocol works in two phases. In the first phase, any suitable protocol is used to multicast a message to the group, while in the second concurrent phase, the gossip protocol tries to recover lost messages. Our proposed gossip protocol is called Anonymous Gossip (AG) since nodes need not know the other group members for gossip to be successful. This is extremely desirable for mobile nodes, that have limited resources, and where the knowledge of group membership is difficult to obtain. As a first step, anonymous gossip is\u00a0\u2026", "num_citations": "346\n", "authors": ["491"]}
{"title": "Reliable distributed systems: technologies, web services, and applications\n", "abstract": " An understanding of the techniques used to make distributed computing systems and networks reliable, fault-tolerant and secure will be crucial to those who design and deploy the next generation of mission-critical applications and Web Services. Reliable Distributed Systems reviews and describes the key concepts, principles and applications of modern distributed computing systems and architectures. This self-contained book consists of five parts. The first covers introductory material, including the basic architecture of the Internet, simple protocols such as RPC and TCP, object oriented architectures, operating systems enhance-ments for high performance, and reliability issues. The second covers the Web, with a focus on Web Services technologies, Microsoft\u2019s. NET and the Java Enterprise Edition. The last three parts look at a number of reliability and fault-tolerance issues and techniques, with an emphasis on replication applied in Web Services settings. Topics and features:* Explains fault-tolerance in clear, readily understood terms with concrete examples drawn from real-world settings* A practical focus aimed at building\" mission-critical\" networked applications that keep working even when things go wrong* Includes modern topics, such as Corba, Web Services, XML,. NET, J2EE, group communication, transactions, peer-to-peer systems, time-critical protocols, scalability and security* Thorough coverage of fundamental mechanisms, with an emphasis on the idea of\" consistent behavior\" in systems that replicate critical components for availability* Reviews more than 25 major research efforts, placing them in context with pointers to sources\u00a0\u2026", "num_citations": "302\n", "authors": ["491"]}
{"title": "Using process groups to implement failure detection in asynchronous environments\n", "abstract": " Agreement on the membership of a group of processes in a distributed system is a basic problem that arises in a wide range of applications. Such groups occur when a set of processes co-operate to perform some task, share memory, monitor one another, subdivide a computation, and so forth. In this paper we discuss the Group Membership Problem as itrelates to failure detection in asynchronous, distributed systems. We present a rigorous, formal specification for group membership under this interpretation, then a solution for this problem that improves upon previous work.", "num_citations": "289\n", "authors": ["491"]}
{"title": "Implementing fault-tolerant distributed objects\n", "abstract": " This paper describes a technique for implementing k-resilient objects\u2013distributed objects that remain available, and whose operations are guaranteed to progress to completion, despite up to k site failures. The implementation is derived from the object specification automatically, and does not require any information beyond what would be required for a nonresilient nondistributed implementation. It is therefore unnecessary for an applications programmer to have knowledge of the complex protocols nonnally employed to implement fault-tolerant objects. Our technique is used in ISIS, a system being developed at Cornell to support resilient objects.", "num_citations": "212\n", "authors": ["491"]}
{"title": "Tools for distributed application management\n", "abstract": " The issues of managing distributed applications are discussed, and a set of tools, the meta system, that solves some longstanding problems is presented. The Meta model of a distributed application is described. To make the discussion concrete, it is shown how NuMon, a seismological analysis system for monitoring compliance with nuclear test-ban treaties is managed within the Meta framework. The three steps entailed in using Meta are described. First the programmer instruments the application and its environment with sensors and actuators. The programmer then describes the application structure using the object-oriented data modeling facilities of the authors' high-level control language, Lomita. Finally, the programmer writes a control program referencing the data model. Meta's performance and real-time behavior are examined.< >", "num_citations": "166\n", "authors": ["491"]}
{"title": "Deceit: A flexible distributed file system\n", "abstract": " Deceit, a distributed file system that provides flexibility in the fault-tolerance and availability of files, is described. Deceit provides many capabilities to the user: file replication with concurrent reads and writes, a range of update propagation strategies, automatic disk load balancing and the ability to have multiple versions of a file. Deceit provides Sun Network File Server (NFS) protocol compatibility; no change in NFS client software is necessary in order to use Deceit. The purpose of Deceit is to replace large collections of NFS servers. NFS suffers from several problems in an environment where most clients mount most servers. First, if any one server crashes, clients will block or fail when they try to access that server, and, as the number of servers increases, this problem becomes more likely. Second, servers have a (roughly) fixed capacity, yet it is difficult to move files from one NFS server to another without disrupting\u00a0\u2026", "num_citations": "161\n", "authors": ["491"]}
{"title": "The ISIS project: Real experience with a fault tolerant programming system\n", "abstract": " The ISIS project has developed a distributed programming toolkit [2, 3] and a collection of higher level applications based on these tools. ISIS is now in use at more than 300 locations world-wide. Here, we discuss the lessons (and surprises) gained from this experience with the real world.", "num_citations": "159\n", "authors": ["491"]}
{"title": "Low cost management of replicated data in fault-tolerant distributed systems\n", "abstract": " Many distributed systems replicate data for fault tolerance or availability. In such systems, a logical update on a data item results in a physical update on a number of copies. The synchronization and communication required to keep the copies of replicated data consistent introduce a delay when operations are performed. In this paper, we describe a technique that relaxes the usual degree of synchronization, permitting replicated data items to be updated concurrently with other operations, while at the same time ensuring that correctness is not violated. The additional concurrency thus obtained results in better response time when performing operations on replicated data. We also discuss how this technique performs in conjunction with a roll-back and a roll-forward failure recovery mechanism.", "num_citations": "159\n", "authors": ["491"]}
{"title": "The design and architecture of the Microsoft Cluster Service-a practical approach to high-availability and scalability\n", "abstract": " Microsoft Cluster Service (MSCS) extends the Windows NT operating system to support high-availability services. The goal is to offer an execution environment where off-the-shelf server applications can continue to operate, even in the presence of node failures. Later versions of MSCS will provide scalability via a node and application management system which allows applications to scale to hundreds of nodes. In this paper we provide a detailed description of the MSCS architecture and the design decisions that have driven the implementation of the service. The paper also describes how some major applications use the MSCS features, and describes features added to make it easier to implement and manage fault-tolerant applications on MSCS.", "num_citations": "157\n", "authors": ["491"]}
{"title": "The promise, and limitations, of gossip protocols\n", "abstract": " Recent years have seen a surge of interest in gossip protocols, with proposals to apply them for purposes ranging from autonomic self-management, repair of inconsistencies, reliable multicast and distributed search. Yet the field of distributed computing is littered with technologies that had initial promise, but were ultimately rejected by the industry. Researchers who measure their work through its impact need to ask some tough, basic questions. What are the uses to which gossip is particularly well-matched, and what are its limitations? What alternatives are there to gossip-based solutions, and when would we be better-off using a non-gossip protocol? When, in effect, is gossip the technology of choice?", "num_citations": "150\n", "authors": ["491"]}
{"title": "How to securely replicate services\n", "abstract": " We present a method for constructing replicated services that retain their availability and integrity despite several servers and clients being corrupted by an intruder, in addition to others failing benignly. We also address the issue of maintaining a causal order among client requests. We illustrate a security breach resulting from an intruder's ability to effect a violation of causality in the sequence of requests processed by the service and propose an approach to counter this attack. An important and novel feature of our techniques is that the client need not be able to identify or authenticate even a single server. Instead, the client is required to possess only a single public key for the service. We demonstrate the performance of our techniques with a service we have implemented using one of our protocols.", "num_citations": "144\n", "authors": ["491"]}
{"title": "Decentralized schemes for size estimation in large and dynamic groups\n", "abstract": " Large-scale and dynamically changing distributed systems such as the grid, peer-to-peer overlays, etc., need to collect several kinds of global statistics in a decentralized manner. In this paper, we tackle a specific statistic collection problem called group size estimation, for estimating the number of non-faulty processes present in the global group at any given point of time. We present two new decentralized algorithms for estimation in dynamic groups, analyze the algorithms, and experimentally evaluate them using real-life traces. One scheme is active: it spreads a gossip into the overlay first, and then samples the receipt times of this gossip at different processes. The second scheme is passive: it measures the density of processes when their identifiers are hashed into a real interval. Both schemes have low latency, scalable per-process overheads, and provide high levels of probabilistic accuracy for the estimate\u00a0\u2026", "num_citations": "134\n", "authors": ["491"]}
{"title": "Dr. multicast: Rx for data center communication scalability\n", "abstract": " IP Multicast (IPMC) in data centers becomes disruptive when the technology is used by a large number of groups, a capability desired by event notification systems. We trace the problem to root causes, and introduce Dr. Multicast (MCMD), a system that eliminates the issue by mapping IPMC operations to a combination of point-to-point unicast and traditional IPMC transmissions guaranteed to be safe. MCMD optimizes the use of IPMC addresses within a data center by merging similar multicast groups in a principled fashion, while simultaneously respecting hardware limits expressed through administrator-controlled policies. The system is fully transparent, making it backward-compatible with commodity hardware and software found in modern data centers. Experimental evaluation shows that MCMD allows a large number of IPMC groups to be used without disruption, restoring a powerful group communication\u00a0\u2026", "num_citations": "132\n", "authors": ["491"]}
{"title": "Preserving privacy in a network of mobile computers\n", "abstract": " Even as wireless networks create the potential for access to information from mobile platforms, they pose a problem for privacy. In order to retrieve messages, users must periodically poll the network. The information that the user must give to the network could potentially be used to track that user. However, the movements of the user can also be used to hide the user's location if the protocols for sending and retrieving messages are carefully designed. We have developed a replicated memory service which allows users to read from memory without revealing which memory locations they are reading. Unlike previous protocols, our protocol is efficient in its use of computation and bandwidth. We show how this protocol can be used in conjunction with existing privacy preserving protocols to allow a user of a mobile computer to maintain privacy despite active attacks.< >", "num_citations": "131\n", "authors": ["491"]}
{"title": "A response to Cheriton and Skeen's criticism of causal and totally ordered communication\n", "abstract": " In a paper to be presented at the 1993 ACM Symposium on Operating Systems Principles, Cheriton and Skeen offer their understanding of causal and total ordering as a communication property. In this brief rebuttal. I present some responses to their criticism, and also explain why I find their discussion of causal and total communication ordering to be narrow and incomplete.", "num_citations": "118\n", "authors": ["491"]}
{"title": "A review of experiences with reliable multicast\n", "abstract": " By understanding how real users have employed reliable multicast in real distributed systems, we can develop insight concerning the degree to which this technology has matched expectations. This paper reviews a number of applications with that goal in mind. Our findings point to trade\u2010offs between the form of reliability used by a system and its scalability and performance. We also find that to reach a broad user community (and a commercially interesting market) the technology must be better integrated with component and object\u2010oriented systems architectures. Looking closely at these architectures, however, we identify some assumptions about failure handling which make reliable multicast difficult to exploit. Indeed, the major failures of reliable multicast are associated with attempts to position it within object\u2010oriented systems in ways that focus on transparent recovery from server failures. The broader\u00a0\u2026", "num_citations": "110\n", "authors": ["491"]}
{"title": "Reliable time delay-constrained cluster computing\n", "abstract": " Apparatus and method of cluster computing are described. The present invention provides a useful compromise between the manageability, power, and ease of use of centralized systems and the reliability, fault-tolerance, upgradability, and scalability of distributed systems. Moreover, the present invention provides fault-tolerance and security while adhering to real-time to respond constraints or bounds. The invention is described in preferred embodiment examples in the context of two clustered applications: a telecommunication switch-controller and a Web servers, although many practical applications will benefit from the present invention.", "num_citations": "107\n", "authors": ["491"]}
{"title": "A local network based on the UNIX operating system\n", "abstract": " The design and implementation of a local network operating ystem based on the UNIX 1 operating system is described. UNIX has been extended to allow existing programs to access remote resources with no source program changes. Programs may access remote files, have a remote working directory, execute remote programs, and communicate with remote processes using the standard UNIX interprocess communication mechanism (pipe's). An efficient message-oriented interprocess communication mechanism and asynchronous I/O were added to the system to support the development of distributed applications and to make it easier to connect the local network to packet-switched networks.", "num_citations": "95\n", "authors": ["491"]}
{"title": "Transparent fault tolerant computer system\n", "abstract": " In a fault-tolerant computer system, a primary replica supervisor is interposed between an operating system and a primary replica of an application program being executed by a primary processor. An object-code editor locates calls to the operating system and loops in the application program and inserts instruction sequences that enable the replica supervisor to intercept the calls to the operating system, results returned by the operating system as a result of the calls and asynchronous events delivered by the operating system to the replica. A backup replica supervisor is similarly interposed between an operating system and a backup replica of the application program being executed by a backup processor. The primary replica interacts with an environment. The replica supervisors ensure that the backup replica undergoes state transformations, as a result of the calls to the operating system and asynchronous\u00a0\u2026", "num_citations": "93\n", "authors": ["491"]}
{"title": "Guide to Reliable Distributed Systems: Building High-Assurance Applications and Cloud-Hosted Services\n", "abstract": " As a growing range of applications shift to the cloud, developers face the task of creating reliable, fault-tolerant and secure distributed computing systems and networks. This Guide to Reliable Distributed Systems describes the key concepts, principles and implementation options for creating high-assurance cloud computing solutions. In combination with Birman\u2019s Isis2 software platform, an open-source library available for free download from Cornell, the text offers a practical path to success in this vital emerging area. The guide starts with a broad technical overview and basic introduction to cloud computing, looking at the overall architecture of the cloud, client systems, the modern Internet and cloud computing data centers. It then delves into the core challenges of showing how reliability and fault-tolerance can be abstracted, how the resulting questions can be solved, and how the solutions can be leveraged to create a wide range of practical cloud applications. The author\u2019s style is practical, and the guide should be readily understandable without any special background. Concrete examples are often drawn from real-world settings to illustrate key insights. Appendices show how the most important reliability models can be formalized, describe the API of the Isis2 platform, and offer more than 80 problems at varying levels of difficulty. Topics and features: examines cloud computing reliability from the perspectives of the client and of the network, and describes the significant components of cloud data centers; presents a practical focus aimed at building\" mission-critical\" networked applications that keep working even when things go wrong; covers\u00a0\u2026", "num_citations": "92\n", "authors": ["491"]}
{"title": "Exploiting replication in distributed systems\n", "abstract": " Techniques are examined for replicating data and execution in directly distributed systems: systems in which multiple processes interact directly with one another while continuously respecting constraints on their joint behavior. Directly distributed systems are often required to solve difficult problems, ranging from management of replicated data to dynamic reconfiguration in response to failures. It is shown that these problems reduce to more primitive, order-based consistency problems, which can be solved using primitives such as the reliable broadcast protocols. Moreover, given a system that implements reliable broadcast primitives, a flexible set of high-level tools can be provided for building a wide variety of directly distributed application programs.", "num_citations": "90\n", "authors": ["491"]}
{"title": "An agent-based current differential relay for use with a utility intranet\n", "abstract": " This paper proposes an agent-based current differential relay for use with a communication network. Agents are software processes capable of searching for information in networks, interacting with pieces of equipment and performing tasks on behalf of their owners (relays). Results illustrating the performance of the agent-based differential method proposed acting within a communication structure are presented for different traffic conditions. These results also show that a dedicated utility intranet is a viable and recommended option as a communication media for the proposed scheme.", "num_citations": "82\n", "authors": ["491"]}
{"title": "Epochs: Integrated cots software for agent-based electric power and communication simulation\n", "abstract": " Electric Power and Communication Synchronizing Simu-lator, a distributed simulation environment. Existing electric power simulation tools do a good job of modeling power systems of the past, which were controlled as large regional power pools without significant communication elements. As power systems increasingly turn to protection and control systems that make use of computer networks, existing power simulators are less and less capable of predicting the likely behavior of large power grids. Similarly, the tools used to evaluate new communication protocols and systems have been developed without any attention to the roles they might play in power scenarios. EPOCHS utilizes multiple research and commercial off-the-shelf (COTS) systems to bridge the gap. EPOCHS is also notable for allowing users to transparently encapsulate complex system behavior that bridges multiple domains through the use of a simple agent-based framework.", "num_citations": "80\n", "authors": ["491"]}
{"title": "Isis and the META project\n", "abstract": " From: reen@cs.cornell.edu (Maureen Robinson) Received(Date): Mon, 10 Feb 92 08:20:11 -0500 Subject: The ISIS pub list in bibtex format. Newsgroups: comp.os.research Approved: comp-os-research@ftp.cse.ucsc.edu % Also available via anonymous ftp from ftp.cse.ucsc.edu:/pub/bib/isis.bib @string{acm = \"Association for Computing Machinery\"} @string{acmhld=\"Proceedings of the ACM/SIGPLAN Software Engineering Symposium on High-Level Debugging\"} @string{cacm=\"Communications of the ACM\"} @string{cdcs = \"International Conference on Distributed Computing Systems\"} @string{compsurv = \"ACM Computing Surveys\"} @string{cornell = \"Cornell University\"} @string{cornellcs = \"Department of Computer Science, Cornell University\"} @string{cornellcs= \"Department of Computer Science, Cornell University\"} @string{dc = \"Distributed Computing\"} @string{dc=\"Distributed Computing\"} @string{dcs = \"of \"{\u2026", "num_citations": "80\n", "authors": ["491"]}
{"title": "Optimizing Power Consumption in Large Scale Storage Systems.\n", "abstract": " Data centers are the backend for a large number of services that we take for granted today. A significant fraction of the total cost of ownership of these large-scale storage systems is the cost of keeping hundreds of thousands of disks spinning. We present a simple idea that allows the storage system to turn off a large fraction of its disks, without incurring unacceptable performance penalties. Of particular appeal is the fact that our solution is not application-specific, and offers power-savings for a very generic data center model. In this paper, we describe our solution, identify the parameters that determine its cost-benefit tradeoffs, and present a simulator that allows us to explore this parameter space. We also present some initial simulation results that add weight to our claim that our solution represents a new power-saving opportunity for large-scale storage systems.", "num_citations": "73\n", "authors": ["491"]}
{"title": "Integrating security in a group oriented distributed system\n", "abstract": " A distributed security architecture is proposed for incorporation into group  oriented distributed systems, and in particular, into the Isis distributed  programming toolkit. The primary goal of the architecture is to make common  group oriented abstractions robust in hostile settings, in order to  facilitate the construction of high performance distributed applications that  can tolerate both component failures and malicious attacks. These  abstractions include process groups and causal group multicast. Moreover, a  delegation and access control scheme is proposed for use in group oriented  systems. The focus of the paper is the security architecture; particular  cryptosystems and key exchange protocols are not emphasized.", "num_citations": "73\n", "authors": ["491"]}
{"title": "Like it or not, web services are distributed objects\n", "abstract": " Despite the push to adopt Web services as the universal OO architecture, the Web services reliability model ignores many real-world issues routinely encountered by users.", "num_citations": "72\n", "authors": ["491"]}
{"title": "A churn-resistant peer-to-peer web caching system\n", "abstract": " Denial of service attacks on peer-to-peer (p2p) systems can arise from sources otherwise considered non-malicious. We focus on one such commonly prevalent source, called\" churn\". Churn arises from continued and rapid arrival and failure (or departure) of a large number of participants in the system, and traces from deployments have shown that it can lead to extremely stressful networking conditions. It has the potential to increase host loads and block a large fraction of normal insert and lookup operations in the peer-to-peer system. This paper studies a cooperative web caching system that is resistant to churn attacks. Based on the Kelips peer-to-peer routing substrate, it imposes a constant load on participants and is able to reorganize itself continuously under churn. Peer pointers are automatically established among more available participants, thus ensuring high cache hit rates even when the system is\u00a0\u2026", "num_citations": "72\n", "authors": ["491"]}
{"title": "Programming with process groups: Group and multicast semantics\n", "abstract": " Process groups are a natural tool for distributed programming, and are increasingly important in distributed computing environments. However, there is little agreement on the most appropriate semantics for process group membership and group communication. These issues are of special importance in the Isis system, a toolkit for distributed programming. Isis supports several styles of process group, and a collection of group communication protocols spanning a range of atomicity and ordering properties. This flexibility makes Isis adaptable to a variety of applications, but is also a source of complexity that limits performance. This paper reports on a new architecture that arose from an effort to simplify Isis process group semantics. Our findings include a refined notion of how the clients of a group should be treated, what the properties of a multicast primitive should be when systems contain large numbers of overlapping groups, and a new construct called the causality domain. A system based on this architecture is now being implemented in collaboration with the Chorus and Mach projects.", "num_citations": "70\n", "authors": ["491"]}
{"title": "Reliable broadcast protocols\n", "abstract": " * This work was supported by the Defense Advanced Research Projects Agency (DoD) under ARPA order 6037, Contract N00140-87-C-8904, and also by a grant from the Siemens Corporation. The views, opinions and findings contained in this report are those of the authors and should not be construed as an official Department of Defense position, policy, or decision.", "num_citations": "70\n", "authors": ["491"]}
{"title": "A gossip protocol for subgroup multicast\n", "abstract": " Gossip-based multicast can be an effective tool for providing highly reliable and scalable message dissemination. We consider the problem of gossiping within overlapping process groups. If each subgroup independently runs a uniform gossip protocol, then the total gossip overhead could be high for a process that is a member of many subgroups. We present a novel gossip protocol that allows individual subgroup members to trade-off update quality for gossip overhead, enabling processes to belong to several subgroups while maintaining a low total gossip overhead. Our results include a mathematical model for message dissemination under this modified gossip protocol, and an algorithm that computes gossip parameters such that all processes within a subgroup achieve their desired update quality.", "num_citations": "68\n", "authors": ["491"]}
{"title": "Rule-based learning for more accurate ECG analysis\n", "abstract": " Long-term electrocardiograms exhibit a small number of QRS morphologies (waveform shapes) whose analysis can reveal cardiac abnormalities. We considered the problem of accurately identifying instances of each in 24-h ECG recordings. A new learning algorithm was developed. Each QRS morphology is represented as a tree of rule activations, which associate attribute measurements with a rule. Each rule has a syntactic pattern together with a semantic procedure which manages and applies the knowledge stored in the activation. A single rule may be activated several times to learn different waveform segments. Delineation refinement improves each hypothesized signal interpretation. A simple conflict resolution mechanism resolves conflicting interpretations into a single unambiguous one. Comparison of the system with an existing program confirmed the promise of the new approach.", "num_citations": "67\n", "authors": ["491"]}
{"title": "The Maestro approach to building reliable interoperable distributed applications with multiple execution styles\n", "abstract": " This paper presents the Maestro tools for rapid development of reliable, interoperable, object\u2010oriented distributed applications. The tools include IIOP\u2010conformant Object Request Broker with an open architecture supporting multiple execution styles/request processing policies. The Replicated Updates execution style implemented in Maestro can be used to add reliability/high availability properties to client/server CORBA applications in settings where it is not feasible to make any modifications at the client side. Measurements over Horus group communication system have shown that Maestro offers good performance with little overhead for reliability. \u00a9 1998 John Wiley & Sons, Inc.", "num_citations": "66\n", "authors": ["491"]}
{"title": "The monoculture risk put into context\n", "abstract": " Conventional wisdom holds that software monocultures are exceptionally vulnerable to malware outbreaks. The authors argue that this oversimplifies and misleads. An analysis based on attacker reactions suggests that deploying a monoculture in conjunction with automated diversity is indeed a very sensible defense.", "num_citations": "65\n", "authors": ["491"]}
{"title": "Probabilistic broadcast\n", "abstract": " We present a class of scalable and probabilisticly reliable communication protocols.  The protocols are based on a probabilistic system model and thus their properties tend to be probabilistic in nature.  The protocols are scalable in two senses.  First, the message costs and latencies of the protocols grow slowly with the system size.  Second, the reliability of the protocols, expressed in terms of the probability of a failed run of a protocol, approaches 0 exponentially fast as the number of processes is increased.  This scalable reliability is achieved through a form of gossip protocol which is strongly self-stabilizing in a sense similar, although not identical to, the notion of self stabilizing systems proposed by Dijkstra.", "num_citations": "65\n", "authors": ["491"]}
{"title": "Developing an agent-based backup protection system for transmission networks\n", "abstract": " This paper proposes a system protection scheme to augment traditional backup relay methods in the transmission system. Agents are used to give each protection component its own thread of control as well as the ability to communicate with others. This leads to greater capabilities to self-check and self\u2013correct. We feel that this method naturally points towards a new philosophy for backup protection. Simulations are used to illustrate our concepts, using a simulation engine that combines the EMTDC/PSCAD power simulator with the NS2 network communications simulator. Results illustrate the improved performance of our backup protection scheme. Preliminary results give us hope that the proposed protection scheme may be able to contribute towards the mitigation of wide-area disturbances and the power blackouts that frequently follow.", "num_citations": "63\n", "authors": ["491"]}
{"title": "Active and passive techniques for group size estimation in large-scale and dynamic distributed systems\n", "abstract": " This paper presents two solutions to a distributed statistic collection problem, called Group Size Estimation. These algorithms are intended for large-scale and dynamic distributed systems such as Grids, peer-to-peer overlays, etc. Each algorithm estimates (both in a one-shot and continuous manner) the number of non-faulty processes present in the global group. The first active scheme samples receipt times of gossip messages, while the second passive scheme calculates the density of process identifiers when hashed to a real interval. Our analysis, trace-driven simulation and deployment on a 33-node Linux cluster study and compare the latencies, scalability, and accuracy of these schemes.", "num_citations": "60\n", "authors": ["491"]}
{"title": "Agent technology applied to adaptive relay setting for multi-terminal lines\n", "abstract": " This paper discusses the adaptation of the settings of distance relays for multi-terminal lines employing agents. Agents are software processes capable of searching for information in networks, interacting with pieces of equipment and performing tasks on behalf of their owners (relays). Results illustrating the performance of the adaptive method proposed compared to conventional fixed settings are presented. It is shown that the digital relays and agents acting within a communication structure (also called middleware) can alter adaptive settings to ensure correct performance over a wide variety of operation conditions, without the need of an additional communication link. The proposed relaying scheme can also be utilized for first zone clearing over the entire line.", "num_citations": "58\n", "authors": ["491"]}
{"title": "A randomized error recovery algorithm for reliable multicast\n", "abstract": " An efficient error recovery algorithm is essential for a liable multicast in large groups. Tree-based protocols (RMTP, TMTP, LBRRM) group receivers into local regions and select a repair server for performing error recovery in each region. Hence a single server bears the entire responsibility of error recovery for a region. In addition, the deployment of repair servers requires topological information of the underlying multicast tree, which is generally not available at the transport layer. This paper presents RRMP, a randomized reliable multicast protocol which improves the robustness of tree-based protocols by diffusing the responsibility of error recovery among all members in a group. The protocol works well within the existing IP multicast framework and does not require additional support from routers. Both analysis and simulation results show that the performance penalty due to randomization is low and can be tuned\u00a0\u2026", "num_citations": "54\n", "authors": ["491"]}
{"title": "Design alternatives for process group membership and multicast\n", "abstract": " Process groups are a natural tool for distributed programming, and are increasingly important in distributed computing environments. However, there is little agreement on the most appropriate semantics for process group membership and group communication. These issues are of special importance in the Isis system, a toolkit for distributed programming Bir91. Isis supports several styles of process group, and a collection of group communication protocols spanning a range of atomicity and ordering properties. This flexibility makes Isis adaptable to a variety of applications, but is also a source of complexity that limits performance. This paper reports on a new architecture that arose from an effort to simplify Isis process group semantics. Our findings include a refined notion of how the clients of a group should be treated, what the properties of a multicast primitive should be when systems contain large numbers of overlapping groups, and a new construct called the casualty domain. As an illustration, we apply the architecture to the problem of converting processes into fault-tolerant process groups in a manner that is transparent to other processes in the system. A system based on this architecture is now being implemented in collaboration with the Chorus and Mach projects.Descriptors:", "num_citations": "54\n", "authors": ["491"]}
{"title": "Integrated approach to data center power management\n", "abstract": " Energy accounts for a significant fraction of the operational costs of a data center, and data center operators are increasingly interested in moving toward low-power designs. Two distinct approaches have emerged toward achieving this end: the power-proportional approach focuses on reducing disk and server power consumption, while the green data center approach focuses on reducing power consumed by support-infrastructure like cooling equipment, power distribution units, and power backup equipment. We propose an integrated approach, which combines the benefits of both. Our solution enforces power-proportionality at the granularity of a rack or even an entire containerized data center; thus, we power down not only idle IT equipment, but also their associated support-infrastructure. We show that it is practical today to design data centers to power down idle racks or containers-and in fact, current online\u00a0\u2026", "num_citations": "53\n", "authors": ["491"]}
{"title": "Ricochet: Lateral Error Correction for Time-Critical Multicast.\n", "abstract": " Ricochet is a low-latency reliable multicast protocol designed for time-critical clustered applications. It uses IP Multicast to transmit data and recovers from packet loss in end-hosts using Lateral Error Correction (LEC), a novel repair mechanism in which XORs are exchanged between receivers and combined across overlapping groups. In datacenters and clusters, application needs frequently dictate large numbers of fine-grained overlapping multicast groups. Existing multicast reliability schemes scale poorly in such settings, providing latency of packet recovery that depends inversely on the data rate within a single group: the lower the data rate, the longer it takes to recover lost packets. LEC is insensitive to the rate of data in any one group and allows each node to split its bandwidth between hundreds to thousands of fine-grained multicast groups without sacrificing timely packet recovery. As a result, Ricochet provides developers with a scalable, reliable and fast multicast primitive to layer under high-level abstractions such as publish-subscribe, group communication and replicated service/object infrastructures. We evaluate Ricochet on a 64-node cluster with up to 1024 groups per node: under various loss rates, it recovers almost all packets using LEC in tens of milliseconds and the remainder with reactive traffic within 200 milliseconds.", "num_citations": "53\n", "authors": ["491"]}
{"title": "Isis: A system for fault-tolerant distributed computing\n", "abstract": " The ISIS system transforms abstract type specifications into fault-tolerant distributed implementations, while insulating users from the mechanisms whereby fault-tolerance is achieved. This paper discusses the transformations that are used within ISIS, methods for achieving improved performance by concurrently updating replicated data, and user-level issues that arise when ISIS is employed to solve a fault-tolerant distributed problem. We describe a small set of communication primitives upon which the system is based. These achieve high levels of concurrency while respecting ordering requirements imposed by the caller. Finally, the performance of a prototype is reported for a variety of system loads and configurations. In particular, we demonstrate that performance of a replicated object in ISIS can equal or exceed that of a nonreplicated object.Descriptors:", "num_citations": "53\n", "authors": ["491"]}
{"title": "A history of the virtual synchrony replication model\n", "abstract": " In this chapter, we discuss a widely used fault-tolerant data replication model called virtual synchrony. The model responds to two kinds of needs. First, there is the practical question of how best to embed replication into distributed systems. Virtual synchrony defines dynamic process groups that have self-managed membership. Applications can join or leave groups at will: a process group is almost like a replicated variable that lives in the network. The second need relates to performance. Although state machine replication is relatively easy to understand, protocols that implement state machine replication in the standard manner are too slow to be useful in demanding settings, and are hard to deploy in very large data centers of the sort seen in today\u2019s cloud-computing environments. Virtual synchrony implementations, in contrast, are able to deliver updates at the same data rates (and with the same low\u00a0\u2026", "num_citations": "49\n", "authors": ["491"]}
{"title": "Overcoming cap with consistent soft-state replication\n", "abstract": " CAP1 explores tradeoffs between {Consistency, Availability and Partition tolerance}, concluding that a replicated service can possess just two of the three. The theorem is proved by forcing a replicated service to respond to conflicting requests during a partitioning failure, triggering inconsistency. But there are replicated services for which the applicability of CAP is unclear. Here, we look at scalable \u201csoftstate\u201d services that run in the first-tier of a single cloud-computing data center. The puzzle is that such services live in a single data center and run on redundant networks. Partitioning events involve single machines or small groups and are treated as node failures; thus, the CAP proof doesn\u2019t apply. Nonetheless, developers believe in a generalized CAP \u201cfolk theorem,\u201d holding that scalability and elasticity are incompatible with strong forms of consistency. We present a first-tier consistency alternative that replicates data, combines agreement on update ordering with amnesia freedom, and supports both good scalability and fast response.", "num_citations": "47\n", "authors": ["491"]}
{"title": "Process membership in asynchronous environments\n", "abstract": " The development of reliable distributed software is simplified by the ability  to assume a fail-stop failure model. We discuss the emulation of such a  model in an asynchronous distributed environment. The solution we propose,  called Strong-GMP, can be supported through a highly efficient protocol, and  has been implemented as part of a distributed systems software project at  Cornell University. Here, we focus on the precise definition of the problem,  the protocol, correctness proofs and an analysis of costs. Keywords: Asynchronous computation; Fault detection; Process membership;  Fault tolerance; Process group.", "num_citations": "46\n", "authors": ["491"]}
{"title": "Performance of the Isis distributed computing toolkit\n", "abstract": " The ISIS Toolkit is a programming environment for building process-group  structured distributed software.  The system is widely used in settings  requiring high reliability, strong distributed consistency guarantees, and  highspeed communication.  In this paper, we describe experimental studies of  ISIS performance.  Our work explores the impact of hardware support for  multicast performance, with a focus on flow control mechanisms.  The use of  hardware multicast in ISIS has not been discussed elsewhere.  One conclusion  of the paper is that although ISIS performance is limited primarily by flow  control considerations, this type of hardware support can lead to significant  performance improvements for certain communication patterns.  A second  conclusion was that the ISIS flow-control problem is surprisingly difficult.   More work in this area, and on the underlying operating system communications  layer (UDP), could have significant impact on the system. Keywords and phrases:  Distributed computing, performance, process groups,  atomic broadcast, causal and total message ordering, cbcast, abcast, multiple  process groups, hardware multicast, IP multicast, virtual synchrony, fault- tolerance.", "num_citations": "45\n", "authors": ["491"]}
{"title": "The Maestro Group Manager: A Structuring Tool For Applications WithMultiple Quality of Service Requirements\n", "abstract": " {\\em Maestro} is a tool for managing sets of protocol stacks that satisfy varied quality of service or security requirements. Intended primarily for multimedia groupware settings, it permits a single application to efficiently operate over multiple side-by-side protocol stacks, each specialized to a different communication stream. Maestro can also be used to manage other sorts of external protocol stacks, for example to orchestrate connection setups that require coordinated actions at all endpoints in a multicast group. Our tools are fault-tolerant and secure; they can safely distribute session keys or handle delicate synchronization tasks that would otherwise complicate the managed stacks and potentially interfere with their quality-of-service objectives. Moreover, Maestro can automatically track subgroup membership on the basis of ``properties'', facilitating its use by developers who prefer not to work directly with multicast communication interfaces.", "num_citations": "44\n", "authors": ["491"]}
{"title": "Distributed architecture for an intelligent networking coprocessor\n", "abstract": " Group communication technology, such as the Horus process, is used to implement a fault-tolerant high performance, reactive, real-time distributed IN coprocessor. The architecture of the distributed IN coprocessor comprises workstation clusters, external adaptors and an update interface interconnected by high speed communication links. Each workstation of the IN architecture represents a query element, so all the databases used by the IN coprocessor in the course of servicing incoming requests are split between query elements, provided that each of the workstations has access to the information stored in a certain database or databases. Group communication systems provide necessary features for managing and obtaining high reliability and operability of the IN coprocessor including failure detection, notification of other members of the system about the failures, reconfiguration of the system to exclude failed\u00a0\u2026", "num_citations": "43\n", "authors": ["491"]}
{"title": "The untrustworthy web services revolution\n", "abstract": " The commoditization of the Web is bringing tremendous benefits, but also some serious risks. The benefits are obvious: Web-based technologies are becoming a universal standard. At the same time, however, the economics of the Web favor an untrustworthy technology base. The key driver for this concern is service-oriented architectures. Major database products, embedded systems platforms, and turnkey solutions in areas ranging from process planning to supply-chain and customer-relations management are adopting a service-oriented approach.", "num_citations": "41\n", "authors": ["491"]}
{"title": "Can web services scale up?\n", "abstract": " In the past, only major Internet players such as Amazon, eBay, and Google were interested in deploying large-scale Web services. However, this is changing rapidly as all sorts of companies and governmental organizations are suddenly looking toward Web services as a platform that might support a wide range of demanding applications. This emerging trend presents developers with a new challenge: building Web services solutions that scale. In a nutshell, a scalable system is one that can flexibly accommodate growth in its client base. Such systems typically run on a clustered computer or in a large data center and must be able to handle high loads or sudden demand bursts and a vast number of users. They must reliably respond even in the event of failures or reconfiguration. Ideally, they're self-managed and automate as many routine services such as backups and component upgrades as possible. Many\u00a0\u2026", "num_citations": "41\n", "authors": ["491"]}
{"title": "Novel backup protection system for the electric power grid using Agent [J]\n", "abstract": " This paper proposes a novel backup protection system for the electric power grid that makes use of Agents. Faster and allowing for more selective protection, the new relays are significantly better than their traditional counterparts. Maloperation is reduced by the Agent's self-checking and self-correcting ability. This paper presents the basic conception of Agents and analyzes the communication networks for relay Agents. The principle structure, protection strategies and IP-based communication methods of the Agent-based backup protection are proposed. Simulations run in a typical power system using the EPOCHS platform illustrate the effectiveness of the proposed method.[Fund]: \u4e2d\u56fd\u7559\u5b66\u57fa\u91d1\u59d4\u5458\u4f1a\u8d44\u52a9\u9879\u76ee \u7f8e\u56fd ARO/EPRI WO 8333-04 \u57fa\u91d1\u8d44\u52a9\u9879\u76ee \u5df4\u897f FAPESP \u57fa\u91d1\u8d44\u52a9\u9879\u76ee \u897f\u5357\u4ea4\u901a\u5927\u5b66\u79d1\u7814\u53d1\u5c55\u9879\u76ee\u8d44\u52a9.", "num_citations": "40\n", "authors": ["491"]}
{"title": "Reliability through consistency\n", "abstract": " In many distributed computing environments, failures are reported in a way that violates even the simplest notions of consistency. The authors argue that such practices are at the root of reliability problems, examine some distributed computing technologies in terms of consistency, and present strategies for implementing consistent failure reporting.< >", "num_citations": "39\n", "authors": ["491"]}
{"title": "A group communication approach for mobile computing\n", "abstract": " This paper describes the design and implementation of a set of tools, called MobileChannel, for use with the Isis system. A sirnple scheme to support user mobility-switching a control point between replicated seraers-proaides a uniforrn mechanism to handle both client migrations and serl)er failures. The handoff mechanism is simplified by integrating a FIFO channel implementation into the seraer replication mechanism. Our scherne provides a simple abstraction of migration, practically eliminates hand-off protocols, provides fault-tolerance and is implemented within the edsting group communication mechanisms of Isis.", "num_citations": "39\n", "authors": ["491"]}
{"title": "Maelstrom: Transparent Error Correction for Lambda Networks.\n", "abstract": " The global network of datacenters is emerging as an important distributed systems paradigm-commodity clusters running high-performance applications, connected by high-speedlambda'networks across hundreds of milliseconds of network latency. Packet loss on long-haul networks can cripple application performance-a loss rate of 0.1% is sufficient to reduce TCP/IP throughput by an order of magnitude on a 1 Gbps link with 50ms latency. Maelstrom is an edge appliance that masks packet loss transparently and quickly from inter-cluster protocols, aggregating traffic for high-speed encoding and using a new Forward Error Correction scheme to handle bursty loss.", "num_citations": "35\n", "authors": ["491"]}
{"title": "The next-generation internet: Unsafe at any speed?\n", "abstract": " Speed alone will not make future Internet applications secure. I propose a new networking isolation capability, termed a virtual overlay network (VON). Such software-based virtual networks, layered on top of physical networks, may provide the isolation that critical applications need. Although a VON offers a response to the reliability and security needs of critical applications, it would be prohibitively costly to implement using contemporary technologies. Extending an existing router feature and coupling it with well-understood group communication techniques, however, could support VONs at low cost, with good scalability.", "num_citations": "35\n", "authors": ["491"]}
{"title": "Using group communication technology to implement a reliable and scalable distributed in coprocessor\n", "abstract": " The SS7 switching network architecture speci es a hierarchical structure for telecommunication switching nodes 1]. According to this speci cation, each switching node is composed of a switch and an Intelligent Networking (IN) coprocessor. The switch must be able to handle a well known set of tasks on its own: call routing for regular calls, hang-up processing, and other simple functions. If the switch detects a more complex request, it hands it o to the IN coprocessor which can employ sophisticated software and database lookups to determine how the call should be handled.(See illustration in Figure 1.)An example of a call that requires the participation of the IN coprocessor is a 1-800 number. In this case, the IN coprocessor looks up the real number in a data-base, and instructs the switch to forward the call to the real number while reversing the charge. Other typical IN services include call ID, automatic transferring of a call according to the callers phone number, conference calling, and voice menus.", "num_citations": "35\n", "authors": ["491"]}
{"title": "Evaluating cloud computing techniques for smart power grid design using parallel scripting\n", "abstract": " Applications used to evaluate next-generation electrical power grids(``smart grids'') are anticipated to be compute and data-intensive. In this work, we parallelize and improve performance of one such application which was run sequentially prior to the use of our cloud-based configuration. We examine multiple cloud computing offerings, both commercial and academic, to evaluate their potential for improving the turnaround time for application results. Since the target application does not fit well into existing computational paradigms for the cloud, we employ parallel scripting tool, as a first step toward a broader program of adapting portable, scalable computational tools for use as enablers of the future smart grids. We use multiple clouds as a way to reassure potential users that the risk of cloud-vendor lock-in can be managed. This paper discusses our methods and results. Our experience sheds light on some of the\u00a0\u2026", "num_citations": "34\n", "authors": ["491"]}
{"title": "Middleware support for distributed multimedia and collaborative computing\n", "abstract": " Maestro is a middleware support tool for distributed multimedia and collaborative computing applications. These applications share a common need for managing multiple subgroups while providing a possibly different quality-of- service guarantees for each of these groups. Maestro's functionality maps well into these requirements, and can significantly shorten the development time of such applications. In this paper we report on Maestro, and demonstrate its utility in implementing IMUX, a pseudo X- server (proxy) for collaborative computing applications. Examples of other multimedia applications that benefit from Maestro appear in the full version of the paper.", "num_citations": "34\n", "authors": ["491"]}
{"title": "Consistent failure reporting in reliable communication systems\n", "abstract": " The difficulty of developing reliable distributed software is an impediment to applying distributed computing technology in many settings. This paper reviews some common platforms for distributed software development and argues that inconsistent failure reporting in communication mechanisms represents a significant obstacle to reliability.Descriptors:", "num_citations": "34\n", "authors": ["491"]}
{"title": "Exact temporal characterization of 10 Gbps optical wide-area network\n", "abstract": " We design and implement a novel class of highly precise network instrumentation and apply this tool to perform the first exact packet-timing measurements of a wide-area network ever undertaken, capturing 10 Gigabit Ethernet packets in flight on optical fiber. Through principled design, we improve timing precision by two to six orders of magnitude over existing techniques. Our observations contest several common assumptions about behavior of wide-area networks and the relationship between their input and output traffic flows. Further, we identify and characterize emergent packet chains as a mechanism to explain previously observed anomalous packet loss on receiver endpoints of such networks.", "num_citations": "33\n", "authors": ["491"]}
{"title": "Lateral error correction for time-critical multicast\n", "abstract": " A system and method for providing a low-latency reliable multicast protocol designed for time-critical clustered applications. Internet Protocol (IP) multicast is used to transmit data and recovers from packet loss in end-hosts using a repair mechanism involving the exchange of XOR repairs between receivers and across groups. The system and method of the present invention can be embodied in a scalable, reliable and fast multicast primitive that can be layered under high-level abstractions such as publish-subscribe, group communication and replicated service/object infrastructures.", "num_citations": "33\n", "authors": ["491"]}
{"title": "Viewpoint program committee overload in systems\n", "abstract": " Conference program committees must adapt their review and selection process dynamics in response to evolving research cultural changes and challenges.", "num_citations": "32\n", "authors": ["491"]}
{"title": "Practical algorithms for size estimation in large and dynamic groups\n", "abstract": " Large-scale distributed systems may be required to estimate the number of non-faulty processes present in the group at a given point of time. The problem is related to aggregation, and several solutions have been proposed. In this paper, we present two new sampling-based algorithms for estimation in dynamic groups (ie, where processes are constantly joining and crashing), and thoroughly evaluate them using real-life traces. One scheme spreads a gossip into the overlay first, and then samples the receipt times of this gossip at different processes. The second scheme measures the density of processes when their identifiers are hashed into a real interval. The schemes have low latency, per-process overheads, while providing high levels of probabilistic accuracy. We present simulation studies that measure and compare the performance of these approaches in static groups, and groups with significant turnaround (arrival and departure) of processes. The latter are done by using traces from deployed peer to peer overlays. The schemes are generic enough to be used by any distributed application.", "num_citations": "32\n", "authors": ["491"]}
{"title": "Building a secure and privacy-preserving smart grid\n", "abstract": " New technologies for computerized metering and data collection in the electrical power grid promise to create a more efficient, cost-effective, and adaptable smart grid. However, naive implementations of smart grid data collection could jeopardize the privacy of consumers, and concerns about privacy are a significant obstacle to the rollout of smart grid technology. Our work proposes a design for a smart metering system that will allow utilities to use the collected data effectively while preserving the privacy of individual consumers.", "num_citations": "31\n", "authors": ["491"]}
{"title": "The performance of Paxos in the cloud\n", "abstract": " This experience report presents the results of an extensive performance evaluation conducted using four open-source implementations of Paxos deployed in Amazon's EC2. Paxos is a fundamental algorithm for building fault-tolerant services, at the core of state-machine replication. Implementations of Paxos are currently used in many prototypes and production systems in both academia and industry. Although all protocols surveyed in the paper implement Paxos, they are optimized in a number of different ways, resulting in very different behavior, as we show in the paper. We have considered a variety of configurations and failure-free and faulty executions. In addition to reporting our findings, we propose and assess additional optimizations to existing implementations.", "num_citations": "31\n", "authors": ["491"]}
{"title": "GridCloud: infrastructure for cloud-based wide area monitoring of bulk electric power grids\n", "abstract": " The continuing rollout of phasor measurement units enables wide area monitoring and control (WAMS/WACS), but the difficulty of sharing data in a secure, scalable, cost-effective, low-latency manner limits exploitation of this new capability by bulk electric power grid operators. GridCloud is an open-source platform for real-time data acquisition and sharing across the jurisdictions that control a bulk interconnected grid. It leverages commercial cloud tools to reduce costs, employing cryptographic methods to protect sensitive data, and software-mediated redundancy to overcome failures. The system has been tested by ISO New England and the results reported here demonstrate a level of responsiveness, availability, and security easily adequate for regional WAMS/WACS, with the capacity for nation-wide scalability in the future.", "num_citations": "28\n", "authors": ["491"]}
{"title": "Routers for the cloud. Can the Internet Achieve 5-Nines Availability?\n", "abstract": " Accordingly, we adopt an approach first used in telephony, where availability measures the percentage of time when almost all calls go through (that is, only a small percentage are dropped, and in an uncorrelated way). The wired telephone infrastructure is engineered to guarantee 99.999 percent availability: the \u201c5-nines\u201d standard. In a one-year reliability study of IP core routers in a regional IP service provider network conducted by the University of Michigan, router interface downtime averaged roughly 955 minutes per year, which doesn\u2019t even reach the \u201c3-nines\u201d level. Figure 1 shows the breakdown of problems that this study identified. The results support the view that redundant hardware has great potential: back in 2004, when the university conducted the study, most deployed routers were monolithic (nonclustered), and many links played unique, critical roles.Hardware and link failures jointly accounted for almost a third of outages. With redundant hardware and links, both factors have since been sharply reduced\u2014putting ever greater emphasis on IP routing\u2019s reliability. This need for software that can survive hardware outages is vital because we must minimize the percentage of time that the routes the router is using are inconsistent with those its neighbors use\u2014for example, because the router has yet to apply routing updates that the neighbors are already employing. A more complete discussion of IP routing failures is available elsewhere. 1 BGP is designed for use in networks composed of interconnected autonomous systems (ASs). An AS could be a network operated by some ISP, or might be a campus or corporate network. BGP\u00a0\u2026", "num_citations": "28\n", "authors": ["491"]}
{"title": "Smoke and Mirrors: Reflecting Files at a Geographically Remote Location Without Loss of Performance.\n", "abstract": " The Smoke and Mirrors File System (SMFS) mirrors files at geographically remote datacenter locations with negligible impact on file system performance at the primary site, and minimal degradation as a function of link latency. It accomplishes this goal using wide-area links that run at extremely high speeds, but have long round-trip-time latencies\u2014a combination of properties that poses problems for traditional mirroring solutions. In addition to its raw speed, SMFS maintains good synchronization: should the primary site become completely unavailable, the system minimizes loss of work, even for applications that simultaneously update groups of files. We present the SMFS design, then evaluate the system on Emulab and the Cornell National Lambda Rail (NLR) Ring testbed. Intended applications include wide-area file sharing and remote backup for disaster recovery.", "num_citations": "28\n", "authors": ["491"]}
{"title": "Building net-centric military applications over service oriented architectures\n", "abstract": " We compare the overall structure of military GIG and NCES architectures with that of the object oriented architectures (CORBA, J2EE and .NET) and of the emerging Web Services architecture. While the match is good in many ways, particularly with respect to Web Services, we also identify a series of shortcomings that could stymie attempts to implement a GIG or NCES system directly on a commercial Web Services platform. Our comparison leads to suggestions for experimental investigations of some topics, but also for more fundamental inquiry in some areas where the scientific base is inadequate. Several issues of the latter sort arise when we consider the mixture of scalability, security, robustness, and time-criticality that must be simultaneously satisfied in demanding military applications.", "num_citations": "27\n", "authors": ["491"]}
{"title": "Technology challenges for virtual overlay networks\n", "abstract": " An emerging generation of mission-critical networked applications is placing demands on the Internet protocol suite that go well beyond the properties they were designed to guarantee. Although the \"next generation internet\" (NGI) is intended to respond to the need, when we review such applications in light of the expected functionality of the NGI, it becomes apparent that the NGI will be faster but not more robust. We propose a new kind of virtual overlay network (VON) that overcomes this deficiency and can be constructed using only simple extensions of existing network technology. In this paper, we use the restructured electric power grid to illustrate the issues, and elaborate on the technical implications of our proposal.", "num_citations": "27\n", "authors": ["491"]}
{"title": "Improving the protection of EHV teed feeders using local agents\n", "abstract": " This paper discusses the adaptation of the settings of distance relays for multi-terminal lines employing agents. Agents are software processes capable of searching for information in networks, interacting with pieces of equipment and performing tasks on behalf of their owners (relays). Moreover, they are autonomous and cooperative. Very few publications concerning the application of agents in the protection field have been reported in the literature. Y Tomita et al. (see IEEE Trans. on Power Delivery, vol.13, no.4, p.1060-6, 1998) proposed a cooperative protection system utilizing agents. Relay agents were constructed, and the cooperation of the main agents was simulated for primary, backup and adaptive protection. Results illustrating the improved performance of the adaptive method proposed compared to conventional fixed settings are presented in the paper.", "num_citations": "27\n", "authors": ["491"]}
{"title": "Consistency conditions for distributed shared memories\n", "abstract": " Highly parallel multiprocessors o er a potential for high-speed computing at a relatively low cost. This potential and the growing demand for computing power have increased the interest in multiprocessors. In order to fully utilize multiprocessors, simple and e cient paradigms for communication between processes must be developed. Shared memory is a convenient paradigm, since it is more high level than message passing and it is a natural extension of serial programming. This has led to a wide study of concurrent programming with shared memory, and many problems have already been solved using shared memory. Thus, supporting shared memory on distributed machines is a desired goal.Unfortunately, implementing shared memory on a multiprocessor is much more complicated than it is on a uniprocessor. This is due to the higher degree of parallelism and the lack of synchronization that is inherent in the distributed architecture. Thus, the exact semantics of the shared memory must be explicitly de ned. A consistency condition is the de nition of the memory's semantics. It describes the guarantees that hardware should present to software about the way memory operations may be seen at di erent processes.", "num_citations": "27\n", "authors": ["491"]}
{"title": "SENSTRAC: scalable querying of SENSor networks from mobile platforms using TRACking-style queries\n", "abstract": " Future applications running on mobile platforms will sometimes need to query sensors and track sensor data over time. This paper proposes a novel, but natural, solution to querying sensors from mobile platforms, based on the publish-subscribe paradigm. Various options are discussed and the most promising one is included into an implementation. Our evaluation focuses on scalability.", "num_citations": "26\n", "authors": ["491"]}
{"title": "Extensible web services architecture for notification in large-scale systems\n", "abstract": " Existing Web services notification and eventing standards are useful in many applications, but they have serious limitations precluding large-scale deployments: it is impossible to use IP multicast or for recipients to forward messages to others and scalable notification trees must be setup manually. We propose a design free of such limitations that could serve as a basis for extending or complementing these standards. The approach emerges from our prior work on QSM (Ostrowski et al., 2006), a new Web services eventing platform that can scale to extremely large environments", "num_citations": "26\n", "authors": ["491"]}
{"title": "The surprising power of epidemic communication\n", "abstract": " The focus of this position paper is on the most appropriate form of middleware to offer in support of distributed system management, control, information sharing and multicast communication. Our premise is that technology has been deficient in all of these areas. If recent advances can be transitioned into general practice, this could enable a new generation of better distributed systems, with value in settings ranging from such \u201ccritical infrastructure\u201d areas as air traffic control and control of the restructured electric power grid to emerging areas, such as large-scale sensor networks, data mining and data fusion. The middleware domain of interest to us has witnessed some three decades of debate between distributed computing systems with strong properties (such as virtual synchrony, fault-tolerance, security, or guaranteed consistency) and those with weak properties (typified by web browsers, but extending into\u00a0\u2026", "num_citations": "26\n", "authors": ["491"]}
{"title": "Object-oriented reliable distributed programming\n", "abstract": " The importance of reliability in large distributed systems can not be underestimated. Considerable effort has been directed towards the development of software reuse. However, the methods and models evolved are often complex, and the tools developed from these ideas reflect this complexity. Consequently, software structuring methods that can reduce or control complexity are important. The authors explore an object-oriented approach to address some programming methodology issues in reliable distributed computing. They begin by classifying group-related communication in an inheritance-based hierarchy. Next, they explore the use of object groups as a new programming paradigm, and present an implementation of an object-group programming toolkit based on these ideas.< >", "num_citations": "25\n", "authors": ["491"]}
{"title": "Empirical characterization of uncongested optical lambda networks and 10gbe commodity endpoints\n", "abstract": " High-bandwidth, semi-private optical lambda networks carry growing volumes of data on behalf of large data centers, both in cloud computing environments and for scientific, financial, defense, and other enterprises. This paper undertakes a careful examination of the end-to-end characteristics of an uncongested lambda network running at high speeds over long distances, identifying scenarios associated with loss, latency variations, and degraded throughput at attached end-hosts. We use identical fast commodity source and destination platforms, hence expect the destination to receive more or less what we send. We observe otherwise: degraded performance is common and easily provoked. In particular, the receiver loses packets even when the sender employs relatively low data rates. Data rates of future optical network components are projected to outpace clock speeds of commodity end-host processors\u00a0\u2026", "num_citations": "24\n", "authors": ["491"]}
{"title": "Fast causal multicast\n", "abstract": " We begin by outlining a new protocol that efficiently implements a reliable, causally ordered multicast primitive and is easily extended into a totally ordered one. Since measurements show that the dominant cost of this protocol is message transport, the design of a lower level multicast transport protocol is discussed. The overall scheme scales with bounded overhead. Our first conclusion is that systems such as Isis can achieve performance competitive with the best existing multicast facilities - a finding contradicting the widespread concern that fault-tolerance may be unacceptably costly. Our second conclusion is that the paradigm of multicast transport is extremely useful for constructing fault-tolerant applications. Our final conclusion is that the framework for fault-tolerant programming provided by Isis is very useful in the design and construction of these extensions to the basic system.", "num_citations": "23\n", "authors": ["491"]}
{"title": "An overview of the ISIS project\n", "abstract": " The goal of the ISIS projest is to provide a high-level support for  fault-tolerant distributed computing by automatically replicating data and  code. The extent to which information is replicated and the physical location  of information are not specified directly by the programmer, but are instead  inferred from a specification, which looks much like a conventional program in  an object-oriented language. This novel approach to fault-tolerant software  construction requires much less sophistication from programmers than current  alternatives. Moreover, optimization techniques that would be too complex for  implementation in general purpose applications can be supported by the ISIS  system. This overview discusses the goals of the project, its current status,  and some of the implications of our work.", "num_citations": "23\n", "authors": ["491"]}
{"title": "Distributional Differential Privacy for Large-Scale Smart Metering\n", "abstract": " In smart power grids it is possible to match supply and demand by applying control mechanisms that are based on fine-grained load prediction. A crucial component of every control mechanism is monitoring, that is, executing queries over the network of smart meters. However, smart meters can learn so much about our lives that if we are to use such methods, it becomes imperative to protect privacy. Recent proposals recommend restricting the provider to differentially private queries, however the practicality of such approaches has not been settled. Here, we tackle an important problem with such approaches: even if queries at different points in time over statistically independent data are implemented in a differentially private way, the parameters of the distribution of the query might still reveal sensitive personal information. Protecting these parameters is hard if we allow for continuous monitoring, a natural\u00a0\u2026", "num_citations": "22\n", "authors": ["491"]}
{"title": "Maelstrom: transparent error correction for communication between data centers\n", "abstract": " The global network of data centers is emerging as an important distributed systems paradigm-commodity clusters running high-performance applications, connected by high-speed \u201clambda\u201d networks across hundreds of milliseconds of network latency. Packet loss on long-haul networks can cripple applications and protocols: A loss rate as low as 0.1% is sufficient to reduce TCP/IP throughput by an order of magnitude on a 1-Gb/s link with 50-ms one-way latency. Maelstrom is an edge appliance that masks packet loss transparently and quickly from intercluster protocols, aggregating traffic for high-speed encoding and using a new forward error correction scheme to handle bursty loss.", "num_citations": "22\n", "authors": ["491"]}
{"title": "Slingshot: Time-CriticalMulticast for Clustered Applications\n", "abstract": " Datacenters are complex environments consisting of thousands of failure-prone commodity components connected by fast, high capacity interconnects. The software running on such datacenters typically uses multicast communication patterns involving multiple senders. We examine the problem of time-critical multicast in such settings, and propose Slingshot, a protocol that uses receiver-based FEC to recover lost packets quickly. Slingshot offers probabilistic guarantees on timeliness by having receivers exchange FEC packets in an initial phase, and optional complete reliability on packets not recovered in this first phase. We evaluate an implementation of Slingshot against SRM, a well-known multicast protocol, and show that it achieves two orders of magnitude faster recovery in datacenter settings", "num_citations": "22\n", "authors": ["491"]}
{"title": "The design and implementation of a private message service for mobile computers\n", "abstract": " Even as wireless networks create the potential for access to information from mobile platforms, they pose a problem for privacy. In order to retrieve messages, users must periodically poll the network. The information that the user must give to the network could potentially be used to track that user. However, the movements of the user can also be used to hide the user's location if the protocols for sending and retrieving messages are carefully designed. We have developed a replicated memory service which allows users to read from memory without revealing which memory locations they are reading. Unlike previous protocols, our protocol is efficient in its use of computation and bandwidth. In this paper, we will show how this protocol can be used in conjunction with existing privacy preserving protocols to allow a user of a mobile computer to maintain privacy despite active attacks.", "num_citations": "22\n", "authors": ["491"]}
{"title": "Integrating runtime consistency models for distributed computing\n", "abstract": " How should distributed systems preserve consistency in the presence of concurrency and failures? For systems designed as assemblies of independently developed components, concurrent access to data or data structures would normally arise within individual programs, and be controlled using mutual exclusion constructs, such as semaphores and monitors. Where data is persistent and/or sets of operations are related to one another, transactions or linearizability may be more appropriate. Systems that incorporate cooperative styles of distributed execution often replicate or distribute data within groups of components. In these cases, group-oriented consistency properties must be maintained, and tools based on the virtual synchrony execution model greatly simplify the task confronting an application developer. All three styles of distributed computing are likely to be seen in future systems-often, within the same\u00a0\u2026", "num_citations": "20\n", "authors": ["491"]}
{"title": "Maintaining consistency in distributed systems\n", "abstract": " The emerging generation of database systems and general purpose operating systems share many characteristics: object orientation, a stress on distribution, and the utilization of concurrency to increase performance. A consequence is that both types of systems are confronted with the problem of maintaining the consistency of multi-component distributed applications in the face of concurrency and failures. Moreover, large applications can be expected to combine database and general purpose components. This paper reviews four basic approaches to the distributed consistency problem as it arises in such hybrid applications:\u2022 Transactional serializability, a widely used database execution model, which has been adapted to distributed and object-oriented settings by several research efforts.\u2022 Traditional operating systems synchronization constructs, such as monitors, used within individual system components, and\u00a0\u2026", "num_citations": "20\n", "authors": ["491"]}
{"title": "The freeze-frame file system\n", "abstract": " Many applications perform real-time analysis on data streams. We argue that existing solutions are poorly matched to the need, and introduce our new Freeze-Frame File System. Freeze-Frame FS is able to accept streams of updates while satisfying\" temporal reads\" on demand. The system is fast and accurate: we keep all update history in a memory-mapped log, cache recently retrieved data for repeat reads, and use a hybrid of a real-time and a logical clock to respond to read requests in a manner that is both temporally precise and causally consistent. When RDMA hardware is available, the write and read throughput of a single client reaches 2.6 GB/s for writes and 5GB/s for reads, close to the limit (about 6GB/s) on the RDMA hardware used in our experiments. Even without RDMA, Freeze Frame FS substantially outperforms existing options for our target settings.", "num_citations": "18\n", "authors": ["491"]}
{"title": "Causally ordered multicast: the conservative approach\n", "abstract": " Process group toolkits provide methods to structure a system as a set of groups of cooperating processes, to detect process failures, and to order events (by ordering messages). Such tools have a performance cost for applications, particularly when a system is built using a large number of overlapping groups. We built an event-driven simulation to study performance of causally ordered message delivery in large systems composed of overlapping groups. Our studies, the first ever of multiple group systems, reveal some conditions under which the delays can be very large: two orders of magnitude greater than when delays are not required. Further, in a large system these delays can lead to increased system burstiness which limits system scalability. These results suggest that a system supporting multiple overlapping groups needs to be carefully designed and the system should often provide users with control over\u00a0\u2026", "num_citations": "18\n", "authors": ["491"]}
{"title": "GO: Platform support for gossip applications\n", "abstract": " Gossip-based protocols are increasingly popular in large-scale distributed applications that disseminate updates to replicated or cached content. GO (gossip objects) is a pernode gossip platform that we developed in support of this class of protocols. In addition to making it easy to develop new gossip protocols and applications, GO allows nodes to join multiple gossip groups without losing the appealing fixed bandwidth guarantee of gossip protocols, and the platform optimizes rumor delivery latency in a principled manner. Our heuristic is based on the observations that multiple rumors can often be squeezed into a single IP packet, and that indirect routing of rumors can speed up delivery. We formalize these observations and develop a theoretical analysis of this heuristic. We have also implemented GO, and study the effectiveness of the heuristic by comparing it to the more standard random dissemination gossip\u00a0\u2026", "num_citations": "17\n", "authors": ["491"]}
{"title": "Sharing private information across distributed databases\n", "abstract": " In industries such as healthcare, there is a need to electronically share privacy-sensitive data across distinct organizations. We show how this can be done while allowing organizations to keep their legacy databases and maintain ownership of the data that they currently store. Without sending or mirroring data to any trusted, centralized entity, we demonstrate how queries can be answered in a distributed manner that preserves the privacy of the original data. This paper explains our distributed query execution engine, outlines how to bootstrap the system when only real world identifiers such as a name and date-of-birth are initially known, and offers details on the tradeoff between privacy and performance. We evaluate the scalability of this approach through simulation.", "num_citations": "17\n", "authors": ["491"]}
{"title": "Scalability of two reliable multicast protocols\n", "abstract": " Growing demand for multicast commun-ication in large network settings has focused attention on the scalability of reliable multicast protocols.  Our paper uses both simulation tools and experiments to compare two scalable protocols, focusing on an aspect not often studied: we emphasize stability of latency distributions as these protocols scale, although also considering overhead and link utilization.   These properties are considered in a variety of network topologies and with several levels of packet loss.  Our findings confirm that SRM scales poorly under some conditions: to obtain reliability, the protocol incurs overhead linear in group size and throughput fluctuates erratically.  We also show that SRM latencies can be very large and that latency distributions are unstable as a function of group size and network topology.  Our own protocol, Bimodal Multicast, also exhibits overhead growth, but the rate of growth is slow, and latency distributions and delivery throughput rates are stable.", "num_citations": "17\n", "authors": ["491"]}
{"title": "Building reliable adaptive distributed objects with the maestro tools\n", "abstract": " This paper presents the Maestro Tools, a distributed object layer built on top of the Ensemble group communication system developed at Cornell. The Maestro tools include a visual application development environment an interface to and implementation of fundamental distributed object abstractions, such as CSCW (cooperative-work), client/server, and publish/subscribe objects and a set of adaptive control/policy modules which are used to adjust Ensemble failure detection and group multicast protocols in accordance with the application's quality of service requirements. The Maestro tools have been used in a reliable CORBA system and in a number of other projects. Results reported in this paper are work in progress: about 2/3 of our goals have been achieved, but there is still work to be done before the full-scale object layer is completed.", "num_citations": "17\n", "authors": ["491"]}
{"title": "Adaptive gravitational gossip: A gossip-based communication protocol with user-selectable rates\n", "abstract": " Gossip-based communication protocols are attractive in cases where absolute delivery guarantees are not required due to their scalability, low overhead, and probabilistically high reliability. In earlier work, a gossip-based protocol known as gravitational gossip was created that allows the selection of quality ratings within subgroups based on workload and information update frequency. This paper presents an improved protocol that adds an adaptive component that matches the actual subgroup communication rates with desired rates coping with network variations by modifying underlying gossip weights. The protocol is designed for use in environments where many information streams are being generated and interest levels vary between nodes in the system. The gossip-based protocol is able to allow subscribers to reduce their expected workload in return for a reduced information rate. The protocol is a good fit\u00a0\u2026", "num_citations": "16\n", "authors": ["491"]}
{"title": "Plato: Predictive latency-aware total ordering\n", "abstract": " PLATO is a predictive total ordering protocol designed for low-latency multicast in datacenters. It predicts out-of-order arrival of multicast packets by observing their inter-arrival times, and delays packets before passing them up to the application only if it believes the packets to have arrived in the wrong order. We show through experimentation on real datacenter-style networks that the inter-arrival time of consecutive packet pairs is an excellent predictor of out-of-order delivery. We evaluate an implementation of PLATO on the Emulab testbed, and show that it drives down delivery latencies by more than a factor of 2 compared to the fixed-sequencer protocol", "num_citations": "16\n", "authors": ["491"]}
{"title": "Using the ISIS resource manager for distributed, fault-tolerant computing\n", "abstract": " Under current versions of the UNIX operating system, it is difficult to take advantage of the massive computing power of idle or lightly loaded workstations on a network. The authors introduce the ISIS resource manager, a distributed fault-tolerant application capable of recapturing this processing power, as well as providing a transparent interface to network computing resources. They discuss the growing importance of high-speed workstation networks and the need for network management utilities and consider how advances in software technology have made it possible to easily construct a distributed fault-tolerant application to meet this need. The architecture of the resource manager is described as an example of this class of application.< >", "num_citations": "16\n", "authors": ["491"]}
{"title": "Kache: Peer-to-peer web caching using kelips\n", "abstract": " To achieve high performance, the emerging generation of Web-based database and Web Services systems will need to take full advantage of caching; latencies associated with their three or four-tier architectures would otherwise be prohibitive. Cooperative caching supported by peer-to-peer (p2p) indexing has been suggested as a scalable way to gain these benefits, but many performance concerns have not yet been addressed in this arena. Lookup latencies are required to be low, and the overhead and the potential for disruption as nodes join and leave the system need to be minimized. The second consideration is important because this kind of \u201cchurn\u201d is known to disrupt many p2p technologies. Our paper investigates the issue experimentally. We describe a cooperative caching system called Kache, which we implemented over a p2p index called Kelips, and evaluate it in a trace-driven experiment during which failures and other kinds of disruptions were injected. Under quiescent conditions, Kache can perform a lookup in one hop: a node seeking information can find it with high probability by querying just one other node that is topologically near-by, irrespective of system size. Even in settings subject to significant churn, Kache rapidly restabilizes after disruption, and the same cache hit rates seen in the quiescent case can be maintained at small additional cost. We conclude that Kache could be a good choice in settings where developers seek to reduce load on a shared server, or where a cluster of clients can communicate among themselves cheaply but incur long delays when communicating to a server.", "num_citations": "15\n", "authors": ["491"]}
{"title": "Middleware support for distributed multimedia and collaborative computing\n", "abstract": " Maestro is a middleware support tool for distributed multimedia and collaborative computing applications. These applications share a common need for managing multiple subgroups while providing possibly different quality\u2010of\u2010service guarantees for each of these groups. Maestro's functionality maps well into these requirements, and can significantly shorten the development time of such applications. In this paper, we report on Maestro, and demonstrate its utility in implementing several multimedia and collaborative computing applications. In particular, we provide a detailed description of the implementation of IMUX, a pseudo X\u2010server (proxy) for collaborative computing applications that is based on Maestro. Copyright \u00a9 1999 John Wiley & Sons, Ltd.", "num_citations": "15\n", "authors": ["491"]}
{"title": "Communication support for reliable distributed computing\n", "abstract": " We describe a collection of communication primitives integrated with a mechanism for handling process failure and recovery. These primitives facilitate the implementation of fault-tolerant process groups, which can be used to provide distributed services in an environment subject to non-malicious crash failures.", "num_citations": "15\n", "authors": ["491"]}
{"title": "The role of order in distributed programs\n", "abstract": " This document discusses the role of order in building distributed systems. It is our belief that a principle of event ordering underlies the wide range of operating systems mechanisms that have been put forward for building robust distributed software. Stated concisely, this principle is that one achieves correct distributed behavior by ordering classes of distributed events that conflict with one another. By focusing on order, one can obtain simplified descriptions and convincingly correct solutions to problems that might otherwise have looked extremely complex. Moreover, we observe that there are a limited number of ways to obtain order, and that the choice made impacts greatly on performance.Descriptors:", "num_citations": "15\n", "authors": ["491"]}
{"title": "ISIS documentation: release 1\n", "abstract": " Department of Computer Science Cornell University Ithaca, New York 14853-7501\" \u0442\u04bb\u0456\u0432 work was supported by the Defense Advanced Research Projects agency (DoD) under ARPA order 5378, Contract N00140-87-C-8904, and by the National Science Founda-tion under grant DCR-8412582. The views, opinions and findings contained in this report are those of the authors and should not be construed as an official Department of Defense position, policy, or decision.", "num_citations": "15\n", "authors": ["491"]}
{"title": "Using SEEK for multichannel pattern recognition\n", "abstract": " The author's work on computerized analysis of the 2-channel, 24-hr electrocardiogram has previously resulted in the development of multichannel signal processing systems that learn by observation. A new tool for implementing such algorithms is described: the pattern recognition language SEEK. Programs written in SEEK build a knowledge base containing treelike data structures, each of which stores acquired information about a particular multichannel waveform. Input data are interpreted by performing an efficient parallel evaluation of the structures in the knowledge base. The work is applicable to a wide variety of pattern recognition problems that arise in medical signal processing. The approach is illustrated with examples drawn from ECG analysis.", "num_citations": "15\n", "authors": ["491"]}
{"title": "A virtualization architecture for wireless network cards\n", "abstract": " There has been a recent interest in using multiple wireless cards in a device [9, 64, 87, 95, 115, 119]. This dissertation provides a cheaper and more energy-efficient scheme to get the functionality of multiple wireless cards while using only a single physical network interface. This approach is called MultiNet, which is a new architecture for virtualizing wireless cards. MultiNet is very useful in solving some of the key problems in wireless networks, and we explore it in greater detail in the rest of this chapter.", "num_citations": "14\n", "authors": ["491"]}
{"title": "MFS: an adaptive distributed file system for mobile hosts\n", "abstract": " Mobility is a critical feature of computer systems, and while wireless networks are common, most applications that run on mobile hosts lack flexible mechanisms for data access in an environment with large and frequent variations in network connectivity. Such conditions arise, for example, in collaborative work applications, particularly when wireless and wired users share files or databases. In this paper, we describe some techniques for adapting data access to network variability in the context of MFS, a client cache manager for a distributed file system. We show how MFS is able to adapt to widely varying bandwidth levels through the use of modeless adaptation, and evaluate the benefit of mechanisms for improving file system performance and cache consistency using microbenchmarks and file system traces.Descriptors:", "num_citations": "14\n", "authors": ["491"]}
{"title": "The Nile system architecture: Fault-tolerant, wide-area access to computing and data resources\n", "abstract": " NILE is a multi-disciplinary project building a distributed computing environment for HEP. It provides wide-area, fault-tolerant, integrated access to processing and data resources for collaborators of the CLEO experiment, though the goals and principles are applicable to many domains. NILE has three main objectives: a realistic distributed system architecture design, the design of a robust data model, and a Fast-Track implementation providing a prototype design environment which will also be used by CLEO physicists. This paper focuses on the software and wide-area system architecture design and the computing issues involved in making NILE services highly-available.", "num_citations": "14\n", "authors": ["491"]}
{"title": "Designing application software in wide area network settings\n", "abstract": " Recent progress in methodologies for developing robust local area network software has not been matched by similar results for wide-area settings. Our work considers the design of application software spanning multiple local area environments. For important classes of applications, simple design techniques are presented that yield fault-tolerant wide area programs. An implementation of these techniques as a set of tools for use within the ISIS system is described.", "num_citations": "14\n", "authors": ["491"]}
{"title": "RDMC: A reliable RDMA multicast for large objects\n", "abstract": " Multicast patterns are common in cloud computing and datacenter settings. Applications and infrastructure tools such as Spark frequently move large objects around, update files replicated to multiple nodes, or push new versions of programs to compute nodes. Some applications use replication directly, for example to increase fault-tolerance or achieve parallelism. Implementations of Paxos, block chains and other libraries often employ a hand-built reliable multicast as a primitive. Yet operating systems continue to be focused on point-to-point communication solutions such as TCP or RDMA, a hardware layer with TCP-like semantics that offers zero copy transfers, but lacks a reliable multi-destination transfer capability. Our system, RDMC (RDMA Multicast), offers reliable multicast functionality constructed from RDMA unicast. We discuss design choices, present a theoretical analysis of RDMC's robustness to delays\u00a0\u2026", "num_citations": "13\n", "authors": ["491"]}
{"title": "Privacy enforcement for distributed healthcare queries\n", "abstract": " In the healthcare industry and others, sensitive private information must be stored and shared between various organizations in the course of running their business. We have developed an architecture in which distributed data can be queried as if it resided in a single centralized database, while revealing minimal information beyond the answer to the query. In this paper we review the architecture and show how queries can be filtered to enforce user-specified privacy policies.We present a system for tracking information flow that is flexible enough to permit revealing sensitive data to those who have a need to know, while limiting the amount of useful information that can be obtained by a less-than-honest participant.", "num_citations": "13\n", "authors": ["491"]}
{"title": "Evaluation of an adaptive transport protocol\n", "abstract": " Applications on mobile computers must adapt to high variability in wireless network performance. Extending the semantics of transport protocols to offer more control over communication to the user allows applications to adapt their behavior to bandwidth variability. We examine adding bandwidth notifications, priorities and timeliness guarantees to a network API as a method for achieving greater application control over bursty traffic. Experiments demonstrate that the extended API allows applications to adjust to bandwidth variations effectively. We also compare three different implementations of the API: two which run on top of TCP, and one new protocol, ATP, which performs comparably to the TCP extensions, but has better performance for some workloads, including a workload simulating remote file system traffic.", "num_citations": "13\n", "authors": ["491"]}
{"title": "Network-aware adaptation techniques for mobile file systems\n", "abstract": " Wireless networks present unusual challenges for mobile file system clients, since they are characterised by unpredictable connectivity and widely-varying bandwidth. The traditional approach to adapting network communication to these conditions is to write back file updates asynchronously when bandwidth is low. Unfortunately, this can lead to underutilisation of bandwidth and inconsistencies between clients. We describe a new mobile file system, MAFS, that supports graceful degradation of file system performance as bandwidth is reduced, as well as rapid propagation of essential file updates. MAFS is able to achieve 10-20% improvements in execution time for real-life file system traces featuring read-write contention", "num_citations": "11\n", "authors": ["491"]}
{"title": "Building scalable solutions to distributed computing problems using probabilistic components\n", "abstract": " Distributed operations such as replica management, coordination, and gossip-based dissemination require each member of the group to maintain a local list of other members in the group. We call this a membership list. In a dynamic group with members constantly joining, leaving and failing silently (crash-stop) failures, the membership list is kept up to date by a group membership maintenance protocol. The challenge in designing a membership maintenance protocol for a large system is to ensure that (a) each member failure is detected quickly by at least one non-faulty member, and membership updates (including member joins and departures) are disseminated quickly to the group,(b) the per-member overhead required to do so is low, and (c) the rate of false positives wrt failure detection is low. Our probabilistic group membership maintenance protocol is called SWIM (for \u201cScalable Weakly Consistent Infection-style Membership protocol\u201d) and is composed from", "num_citations": "11\n", "authors": ["491"]}
{"title": "Overcoming the \u2018d\u2019in cap: Using isis2 to build locally responsive cloud services\n", "abstract": " The CAP theorem establishes that a cloud service can only guarantee two of {Consistency, Availability and Partition Tolerance}, motivating developers to reject transactional ACID properties. Instead, they use BASE: a methodology whereby one transforms an application into a faster and more scalable version by running it as a series of asynchronous steps that each use local data replicas (even if potentially stale), eschew locking, and are designed to tolerate unplanned failures and service launches. Along the way, consistency is substantially weakened.But CAP and BASE may not be the final word. The new Isis2 platform supports consistent, locally responsive cloud services. The system is scalable, highly available, and fast. Responses to client requests can be computed using purely local data, hence delays are limited only by local computational costs. Updates propagate asynchronously and map to a single IP multicast; locking is usually avoided by employing primary-copy replication, and otherwise is performed with an inexpensive token-passing scheme. The approach relaxes durability for softstate updates: this yields an \u201cACI and mostly D\u201d model. Durability violations are concealed using a form of firewall.", "num_citations": "10\n", "authors": ["491"]}
{"title": "Trading consistency for availability in distributed systems\n", "abstract": " This paper shows that two important classes of actions, {\\em non left commuting}\\/ and {\\em strongly non commuting}, cannot be executed by concurrent partitions in a system that provides serializable services. This result indicates that there is an inherent limitation to the ability of systems to provide services in a consistent manner during network partitions.", "num_citations": "10\n", "authors": ["491"]}
{"title": "The cost of order in asynchronous systems\n", "abstract": " We consider the Group Membership Problem (GMP) in asynchronous systems. This problem consists of maintaining a list of processes belonging to the system, and updating it as processes join (are started) and leave (terminate or fail). Our investigations led to four independent properties that characterize instances of this problem. We closely examine three membership services, comparing the message cost to implement them, as well as their fault-tolerance and ability to adapt to environmental changes. We also examine their relative merits by comparing the cost to a distributed application that employs each of the membership services. We show that in typical system executions Strong GMP is less expensive to implement, is always more responsive to dynamic aspects in the environment, and allows applications to accomplish more work with less effort. As Strong GMP is the sole instance providing a linear\u00a0\u2026", "num_citations": "10\n", "authors": ["491"]}
{"title": "Network support for a distributed data base system\n", "abstract": " COCANET is a local computer network being de: eloped, in part, to support distributed data base system research. A multidestination, or multicast, protocol is provided to satisfy the communication requirements of the INGRES distributed data base system. These requirements include sending messages to a dynamically varying subset of processes. Efficient implementation of the multicast protocol in a local broadcast network is described. In addition, internetwork support of the protocol is discussed. COCANET extends a conventional UNIX programming environment across multiple processors by supporting transparent resource sharing and messageoriented interprocess communication mechanisms.", "num_citations": "10\n", "authors": ["491"]}
{"title": "Storing and accessing live mashup content in the cloud\n", "abstract": " Today's Rich Internet Application (RIA) technologies such as Ajax, Flex, or Silverlight, are designed around the client-server paradigm and cannot easily take advantage of replication, publish-subscribe, or peer-to-peer mechanisms for better scalability or responsiveness. This is particularly true of storage: content is typically persisted in data centers and consumed via web services. We propose1 a checkpointed channel (CC) abstraction as an alternative model for storing and accessing content. CCs are architecture-agnostic: they could be implemented as web services, but also as replicated state machines running over peer-to-peer multicast protocols. They can seamlessly span across the data center boundaries, or live at the edge. They are a more natural way of consuming streaming content. CCs can store hierarchical documents with hyperlinks to other CCs, thus forming a web of interconnected CCs: a live\u00a0\u2026", "num_citations": "9\n", "authors": ["491"]}
{"title": "Edge mashups for service-oriented collaboration\n", "abstract": " The Live Distributed Objects platform makes it possible to combine hosted content with P2P protocols in a single object-oriented framework.", "num_citations": "9\n", "authors": ["491"]}
{"title": "A group communication approach for mobile computing mobile channel: An ISIS tool for mobile services\n", "abstract": " This paper examines group communication as an infrastructure to support mobility of users, and presents a simple scheme to support user mobility by means of switching a control point between replicated servers. We describe the design and implementation of a set of tools, called Mobile Channel, for use with the ISIS system. Mobile Channel is based on a combination of the two replication schemes the primary-backup approach and the state machine approach. Mobile Channel implements a reliable one-to-many FIFO channel, in which a mobile client sees a single reliable server servers, acting as a state machine, see multicast messages from clients. Migrations of mobile clients are handled as an intentional primary switch, and hand-offs or server failures are completely masked to mobile clients. To achieve high performance, servers are replicated at a sliding-window level. Our scheme provides a simple abstraction of migration, eliminates complicated hand-off protocols, provides fault-tolerance and is implemented within the existing group communication mechanism.Descriptors:", "num_citations": "9\n", "authors": ["491"]}
{"title": "On communication support for fault tolerant process groups\n", "abstract": " hjp: doc: RFC 0992: On communication support for fault tolerant process groups hjp doc RFCs RFC 0992 Rfc 0992 Title On communication support for fault tolerant process groups Author KP Birman, TA Joseph Date November 1986 Format: TXT, HTML Status: UNKNOWN KP Birman (Cornell) Network Working Group TA Joseph (Cornell) Request for Comments: 992 November 1986 On Communication Support for Fault Tolerant Process Groups KP Birman and TA Joseph Dept. of Computer Science, Cornell University Ithaca, NY 14853 607-255-9199 1. Status of this Memo. This memo describes a collection of multicast communication primi- tives integrated with a mechanism for handling process failure and recovery. These primitives facilitate the implementation of fault- tolerant process groups, which can be used to provide distributed services in an environment subject to non-malicious crash failures. Unlike other , as [\u2026", "num_citations": "9\n", "authors": ["491"]}
{"title": "Optimizing information flow in the gossip objects platform\n", "abstract": " Gossip-based protocols are commonly used for diffusing information in large-scale distributed applications. GO (Gossip Objects) is a per-node gossip platform that we developed in support of this class of protocols. GO allows nodes to join multiple gossip groups without losing the appealing fixed bandwidth guarantee of gossip protocols, and the platform also optimizes latency in a principled manner. Our algorithm is based on the observations that multiple rumors can often be squeezed into a single IP packet, and that indirect routing of rumors can speed up delivery. We formalize these observations and develop a theoretical analysis of this algorithm. We have also implemented GO, and studied the effectiveness of the algorithm by comparing it to the more standard random dissemination gossip strategy.", "num_citations": "8\n", "authors": ["491"]}
{"title": "Scalable, self-organizing technology for sensor networks\n", "abstract": " Sensor networks will often need to organize themselves automatically and adapt to changing environmental conditions, failures, intermittent connectivity, and in response to power considerations. We review a series of technologies that we find interesting both because they solve fundamental problems seen in these settings, and also because they appear to be instances of a broader class of solutions responsive to these objectives.", "num_citations": "8\n", "authors": ["491"]}
{"title": "Throughput stability of reliable multicast protocols\n", "abstract": " Traditional reliable multicast protocols depend on assumptions about flow control and reliability mechanisms, and they suffer from a kind of interference between these mechanisms. This in turn affects the overall performance, throughput and scalability of group applications utilizing these protocols. However, there exists a substantial class of distributed applications for which the throughput stability guarantee is indispensable. Pbcast protocol is a new option in scalable reliable multicast protocols that offers throughput stability, scalability and a bimodal delivery guarantee as the key features. In this paper, we focus on the throughput stability of reliable multicast protocols. We describe an experimental model developed for Pbcast and virtually synchronous protocols on a real system. We then give the analysis results of our study.", "num_citations": "8\n", "authors": ["491"]}
{"title": "Supporting large scale applications on networks of workstations\n", "abstract": " The extension of the ISIS distributed programming system to support large-scale distributed applications by providing hierarchical process groups is discussed. The present version of ISIS is limited to relatively small-scale applications, containing fewer than 50 workstations. The principal idea is to incorporate hierarchy in the program structure and exploit this to limit the communication and storage required in any one component of the distributed program. This approach seeks to maintain the advantages of virtual synchrony, while controlling those costs that grow as the size of a distributed application increases.< >", "num_citations": "8\n", "authors": ["491"]}
{"title": "Programming with Shared Bulletin Boards in Asynchronus Distributed Systems\n", "abstract": " We consider loosely coupled distributed computing systems in which processes  interact through shared resources, which are modeled as bulletin boards. The  first part of the paper formalizes the notion of consistent behavior when  unreliable processes concurrently access a bulletin board. This model is  interesting both as a tool for showing the correctness of a board  implementation and also because it provides a mechanism for reasoning about  consistency in distributed systems, which was previously lacking. The  remainder of the paper discusses software techniques for implementing  consistent bulletin boards in a network of processors lacking shared memory.  Applications for our approach range from asynchronous interprocess  communication to mechanisms for achieving mutual exclusion, deadlock  detection and for building distributed database systems.", "num_citations": "8\n", "authors": ["491"]}
{"title": "Quilt: a patchwork of multicast regions\n", "abstract": " Network bottlenecks, firewalls, restrictions on IP Multicast availability and administrative policies have long prevented the use of multicast even where the fit seems obvious. The confusion around multicast poses a problem for large-scale pub/sub-based applications that need blazing speed even across WAN networks. There are a number of multicast protocols, but none is universally available. Thus relatively few applications are able to exploit multicast technology. Here, we present Quilt, a system that automatically weaves a patchwork of multicast regions each running different protocols, creating an efficient and scalable wide-area overlay. By dynamically exploring the environment at and between end-hosts, Quilt clusters nodes into patches, selecting the best multicast protocol from a developer-provided set on a patch-by-patch basis and adapting as needed. Quilt orchestrates inter-patch forwarding to maximize\u00a0\u2026", "num_citations": "7\n", "authors": ["491"]}
{"title": "Self-replicating objects for multicore platforms\n", "abstract": " The paper introduces Self-Replicating Objects (SROs), a new concurrent programming abstraction. An SRO is implemented and used much like an ordinary .NET object and can expose arbitrary user-defined APIs, but it is aggressive about automatically exploiting multicore CPUs. It does so by spontaneously and transparently partitioning its state into a set of replicas that handle method calls in parallel and automatically merging replicas before processing calls that cannot execute in the replicated state. Developers need not be concerned about protecting access to shared data; each replica is a monitor and has its own state. The runtime ensures proper synchronization, scheduling, decides when to split/merge, and can transparently migrate replicas to other processes to decrease contention. Compared to threads/locks or toolkits such as .NET Parallel Extensions, SROs offer a simpler, more versatile\u00a0\u2026", "num_citations": "7\n", "authors": ["491"]}
{"title": "Code-partitioning gossip\n", "abstract": " Code-Partitioning Gossip (CPG) is a novel technique to facilitate implementation and analysis of gossip protocols. A gossip exchange is a pair-wise transaction between two nodes; a gossip system executes an endless sequence of exchanges between nodes chosen by a randomized procedure. Using CPG, the effects of a gossip exchange are succinctly defined by a single function that atomically updates a pair of node states based on their previous values. This function is automatically partitioned via program slicing into executable code for the roles of gossip-initiator and gossip-recipient, and networking code is added automatically. CPG may have concrete benefits for protocol analysis and authoring composite gossip protocols.", "num_citations": "7\n", "authors": ["491"]}
{"title": "Scalable group communication system for scalable trust\n", "abstract": " Programmers of large-scale trusted systems need tools to simplify tasks such as replicating services or data. Group communication systems achieve this via various flavors of reliable multicast, but the existing solutions do not scale in all major dimensions. Typically, they scale poorly in the number of groups; yet we believe that using groups casually could lead to new, easier ways of programming. We propose QSM [1], a new multicast substrate that scales in several dimensions at once. Our approach relies on a novel way of exploiting the overlap between groups.", "num_citations": "7\n", "authors": ["491"]}
{"title": "Reliable multicast for time-critical systems\n", "abstract": " We are interested in communication support for time-critical reliable computing. Over a two-decade period, the distributed computing community has explored a number of reliable communication models. Yet time-critical applications in which rapid response matters more than absolute reliability have received comparatively little attention. We believe that this category of application is becoming common, and propose a new probabilistic reliability model for time-critical communication.", "num_citations": "7\n", "authors": ["491"]}
{"title": "Holistic operations in large-scale sensor network systems: A probabilistic peer-to-peer approach\n", "abstract": " Smart sensor nodes integrate multiple sensors (e.g., temperature, humidity, accelerometers), processing capability (microprocessor connected to the sensors using I2C technology), wireless communications, and a battery power source. A sensor node could be as small as a few millimeters. See references [32.11], [32.12].", "num_citations": "7\n", "authors": ["491"]}
{"title": "How robust are distributed systems?\n", "abstract": " * This work was supported by the Defense Advanced Research Projects Agency (DoD) under ARPA order 6037, Contract N0014-87\u2014C-8904, and also by a grant from the Siemens Corporation. The views, opinions and findings contained in this report are those of the authors and should not be construed as an official Department of Defense Analysis position, policy, or decision.", "num_citations": "7\n", "authors": ["491"]}
{"title": "Hosting dynamic data in the cloud with Isis2 and the Ida DHT\n", "abstract": " The big-data community generally favors a two stage methodology whereby data is first collected, then uploaded for analysis using tools like MapReduce. During analysis the data won't change; this simplifies fault-tolerance and makes it worthwhile to cache intermediary results. In contrast, when it is necessary to capture data continuously and query it on the fly, cloud storage and access technologies must be reexamined. Isis2 aims at such scenarios, offering a base set of mechanisms that replicate data and perform computation with strong consistency and other assurance properties, then layering higher level abstractions over this core. Here we a focus on a subsystem called the Isis2 interactive data analysis infrastructure: Ida. Ida is a strongly-consistent distributed key-value store on which surprisingly complex computational tasks are feasible.", "num_citations": "6\n", "authors": ["491"]}
{"title": "Beyond power proportionality: Designing power-lean cloud storage\n", "abstract": " We present a power-lean storage system, where racks of servers, or even entire data center shipping containers, can be powered down to save energy. We show that racks and containers are more than the sum of their servers, and demonstrate the feasibility of designing a storage system that powers them up and down on demand further, we show that such a system would save an order of magnitude more energy than current disk-based power-proportional storage systems. Our simulation results using file system traces from the Internet Archive show over 44% energy savings, a 5x improvement over disk-based power management systems, without performance impact. We explore the tradeoffs in choosing the right unit to power off/on, and present an automated framework to compute the optimal power management unit for different scenarios.", "num_citations": "6\n", "authors": ["491"]}
{"title": "Building collaboration applications that mix web services hosted content with P2P protocols\n", "abstract": " The most commonly deployed web service applications employ client-server communication patterns, with clients running remotely and services hosted in data centers. In this paper, we make the case for Service-Oriented Collaboration applications that combine service-hosted data with collaboration features implemented using peer-to-peer protocols. Collaboration features are awkward to support solely based on the existing web services technologies. Indirection through the data center introduces high latencies and limits scalability, and precludes collaboration between clients connected to one-another but lacking connectivity to the data center. Cornellpsilas Live Distributed Objects platform combines web services with direct peer-to-peer communication to eliminate these issues.", "num_citations": "6\n", "authors": ["491"]}
{"title": "Consistency in distributed systems\n", "abstract": " We now tackle the last of the \u201cprocess group internals\u201d topics that will be covered in this textbook. As mentioned at the start of Chapters 14, a reader focused primarily on high assurance for Web Services doesn\u2019t really need to read the material that follows in any detail. The questions tackled here are a bit esoteric and while they do matter, platforms like Horus, Spread and Ensemble address these issues in a simple, standardized manner reflecting a sensible tradeoff between performance and guarantees. If your goal is to just use a group communication tool, it isn\u2019t necessarily important to understand precisely how that tool was implemented, just as one can use TCP without understanding the details of TCP \u201cslow start\u201d and the so called additive-increase multiplicative-backoff congestion control used in that protocol. On the other hand, we cite TCP as an example of why readers might want to be familiar with this\u00a0\u2026", "num_citations": "6\n", "authors": ["491"]}
{"title": "The league of SuperNets\n", "abstract": " The author proposes a major effort to transform the Internet into a league of SuperNets. Doing so offers the promise of revolutionary new business opportunities, and could save the emerging Web services technology area from a snarl of reliability and security problems. We can slash the costs of operating big networks, roll out new kinds of applications with real-time properties, and start to build other kinds of applications for purposes like controlling the restructured electrical power grid or managing military assets on a battlefield. Unfortunately, however, the proposal departs drastically from the way that the Internet is currently evolving. The technical side of the issue is likely to be the easy part; the problem centers on the politics of the Internet sector and the community that controls its future. Yet, the payoff could be so great that I want to argue for a community response. If we all get behind a common vision, we can\u00a0\u2026", "num_citations": "6\n", "authors": ["491"]}
{"title": "Lightweight causal and atomic group multicast\n", "abstract": " CiNii \u8ad6\u6587 - Lightweight Causal and Atomic Group Multicast CiNii \u56fd\u7acb\u60c5\u5831\u5b66\u7814\u7a76\u6240 \u5b66\u8853\u60c5\u5831 \u30ca\u30d3\u30b2\u30fc\u30bf[\u30b5\u30a4\u30cb\u30a3] \u65e5\u672c\u306e\u8ad6\u6587\u3092\u3055\u304c\u3059 \u5927\u5b66\u56f3\u66f8\u9928\u306e\u672c\u3092\u3055\u304c\u3059 \u65e5\u672c\u306e\u535a\u58eb\u8ad6\u6587\u3092\u3055\u304c\u3059 \u65b0\u898f\u767b\u9332 \u30ed\u30b0\u30a4\u30f3 English \u691c\u7d22 \u3059\u3079\u3066 \u672c\u6587\u3042\u308a \u3059\u3079\u3066 \u672c\u6587\u3042\u308a \u9589\u3058\u308b \u30bf\u30a4\u30c8\u30eb \u8457\u8005\u540d \u8457\u8005ID \u8457\u8005\u6240\u5c5e \u520a\u884c \u7269\u540d ISSN \u5dfb\u53f7\u30da\u30fc\u30b8 \u51fa\u7248\u8005 \u53c2\u8003\u6587\u732e \u51fa\u7248\u5e74 \u5e74\u304b\u3089 \u5e74\u307e\u3067 \u691c\u7d22 \u691c\u7d22 \u691c\u7d22 CiNii\u7a93\u53e3\u696d\u52d9\u306e\u518d\u958b \u306b\u3064\u3044\u3066 Lightweight Causal and Atomic Group Multicast BIRMAN Kenneth \u88ab\u5f15\u7528\u6587\u732e: 1\u4ef6 \u8457\u8005 BIRMAN Kenneth \u53ce\u9332\u520a\u884c\u7269 Distributed computing Distributed computing 7(3), 149-174, 1994 \u88ab\u5f15\u7528\u6587\u732e: 1\u4ef6\u4e2d 1-1\u4ef6\u3092 \u8868\u793a 1 \u5206\u6563\u30b7\u30b9\u30c6\u30e0\u306b\u304a\u3051\u308b\u56e0\u679c\u95a2\u4fc2\u3092\u4fdd\u5b58\u3059\u308b\u30e1\u30c3\u30bb\u30fc\u30b8 \u914d\u9001\u30d7\u30ed\u30c8\u30b3\u30eb \u771f\u934b \u5178\u884c , \u591a\u7530 \u77e5\u6b63 , \u6a0b\u53e3 \u660c\u5b8f , \u85e4\u4e95 \u8b77 \u60c5\u5831\u51e6\u7406\u5b66\u4f1a\u7814\u7a76\u5831\u544a. DPS,\u30de\u30eb\u30c1 \u30e1\u30c7\u30a3\u30a2\u901a\u4fe1\u3068\u5206\u6563\u51e6\u7406\u7814\u7a76\u4f1a\u5831\u544a 74, 221-226, 1996-01-25 \u53c2\u8003\u6587\u732e2\u4ef6 Tweet \u5404\u7a2e\u30b3\u30fc\u30c9 NII\u8ad6\u6587ID(NAID) 10020644520 \u8cc7\u6599\u7a2e\u5225 \u96d1\u8a8c\u8ad6\u6587 \u30c7\u30fc\u30bf\u63d0\u4f9b\u5143 CJP\u5f15\u7528 \u66f8\u304d\u51fa\u3057 RefWorks/(\u2026", "num_citations": "6\n", "authors": ["491"]}
{"title": "Cloud-hosted intelligence for real-time IoT applications\n", "abstract": " Deploying machine learning into IoT cloud settings will require an evolution of the cloud infrastructure. In this white paper, we justify this assertion and identify new capabilities needed for real-time intelligent systems. We also outline our initial efforts to create a new edge architecture more suitable for ML. Although the work is still underway, several components exist, and we review them. We then point to open technical problems that will need to be solved as we progress further in this direction.", "num_citations": "5\n", "authors": ["491"]}
{"title": "MiCA: A Compositional Architecture for Gossip Protocols\n", "abstract": " The developers of today\u2019s cloud computing systems are expected to not only create applications that will work well at scale, but also to create management services that will monitor run-time conditions and intervene to address problems as conditions evolve. Management tasks are generally not performance intensive, but robustness is critical: when a large system becomes unstable, the management infrastructure must remain reliable, predictable, and fault-tolerant.               A wide range of management tasks can be expressed as gossip protocols where nodes in the system periodically interact with random peers and exchange information about their respective states. Although individual gossip protocols are typically very simple, by composing multiple protocols one can create a wide variety of interesting, complex functionality with strong (albeit probabilistic) robustness and convergence guarantees. For\u00a0\u2026", "num_citations": "5\n", "authors": ["491"]}
{"title": "Rethinking multicast for massive-scale platforms\n", "abstract": " A dramatic scale-up of distributed computing platforms is underway. Internet routers can contain hundreds or thousands of line cards. Cloud computing platforms may contain tens or even hundreds of thousands of machines. What is gluing all of this together? Multicast to support data replication, event streams, and coordination. Yet yesterday\u2019s multicast protocols are poorly matched to this new generation of uses; so much so that many cloud platforms refuse to deploy multicast as such, and have instead resorted to clumsy alternatives, mapping multicast to TCP or even web services method invocations. This talk will explore inadequacies of existing protocols, early progress towards better ones, and the longer term research agenda.", "num_citations": "5\n", "authors": ["491"]}
{"title": "Ajil: Distributed rate-limiting for multicast networks\n", "abstract": " Multicast traffic patterns play a key role in dependable data centers, arising when data is replicated and distributed over multiple machines for fault-tolerance and availability. Such settings involve large numbers of multicast groups as well as multiple senders to each group\u2014a single system can have hundreds of such multicast channels. Without effective multi-channel rate control, multicast senders cannot determine the right rate to send data at and often transmit to groups as fast as possible. As a result, multicast channels are subject to traffic spikes that can overload individual end-hosts within the data center as well as its communication back-plane. This paper introduces and evaluates Ajil, a distributed rate-limiting protocol for data centers. Ajil enforces a system-wide quota on multicast traffic, and facilitates equitable distribution of this quota across all the multicast channels in the data center.", "num_citations": "5\n", "authors": ["491"]}
{"title": "Corba: The common object request broker architecture\n", "abstract": " With the emergence of object-oriented programming languages, such as Modula and C++, came a recognition that object-orientation could play a role similar to that of the OSI hierarchy for complex distributed systems. In this view, one would describe a computing system in terms of the set of objects from which it was assembled, together with the rules by which these objects interact with one another. Object-oriented system design became a major subject for research, with many of the key ideas pulled together for the first time by a British research effort, called the Advanced Network Systems Architecture group, or ANSA. In this chapter, we will briefly discuss ANSA, and then focus on a more recent standard, called CORBA, which draws on some of the ideas introduced by ANSA, and has emerged as a widely accepted standard for objected-oriented distributed computing. Finally, we touch briefly on J2EE and .NET\u00a0\u2026", "num_citations": "5\n", "authors": ["491"]}
{"title": "Providing efficient, robust error recovery through randomization\n", "abstract": " An efficient error recovery algorithm is essential for reliable multicast in large groups. This paper presents RRMP, a randomized reliable multicast protocol which improves the robustness of traditional tree-based protocols by diffusing the responsibility of error recovery among all members in a group. Both simulation and experimental results show that the protocol achieves good performance.", "num_citations": "5\n", "authors": ["491"]}
{"title": "Distributed Computing and Databases for High Energy Physics\n", "abstract": " We are proposing to develop a fault-tolerant distributed computing and database system for use in High Energy Physics, but applicable to other disciplines. This system will allow us to solve the challenging problem of data processing, analysis and simulation by exploiting developments in distributed systems, fault tolerance, high performance networks and database technology. We will extend the data storage paradigm so that data are directly accessible by eld as well as by event. The system will be scalable to at least hundreds of processors. We will incorporate Asynchronous Transfer Mode network technology and develop the system for wide-area use, particularly over the National Research and Education Network. i", "num_citations": "5\n", "authors": ["491"]}
{"title": "Concurrency control in resilient objects\n", "abstract": " Resilient objects are instances of distributed abstract data types that are  tolerant to failures. Due to the distributed nature of resilient objects and  the use of replicated data, the potential for a high degree of concurrency  exists within them. This paper introduces a new concurrency control algorithm  which achieves higher concurrency than conventional methods like two-phase  locking. Objects are specified in a high level language. The algorithm uses  the specification taking advantage of the structure of resilient objects and  exploiting semantic information about operations.", "num_citations": "5\n", "authors": ["491"]}
{"title": "A cloud-hosted synchrophasor data sharing platform\n", "abstract": " The deployment of Phasor Measurement Units (PMUs ) could support a new generation of wide area monitoring  and situational awareness  systems, but this has not yet occurred. Instead, PMU  data exchange occurs through bilateral agreements, each reflecting substantial human involvement. Our work proposes a new model for PMU  data sharing, based upon today\u2019s                  cloud computing                                 technology base. Cloud-based data capture, archiving, analysis and sharing represents a new paradigm, and provides access to flexible resources well-suited to intermittent bursts of heavy computational work. In addition, collaboration among entities could be greatly facilitated by hosting common applications  in the cloud, with the further assurance when different operators examine the same data, they will see consistent information. Accordingly, we created GridCloud, a new cloud-hosted\u00a0\u2026", "num_citations": "4\n", "authors": ["491"]}
{"title": "Network perspective\n", "abstract": " The previous chapter looked at cloud computing from a client\u2019s perspective. Late in the discussion we touched on one of the ways that cloud computing is forcing the Internet itself to evolve. In this chapter, we will say more about that topic. Dominant at the network level are issues stemming from the need of the cloud to control routing and maintain a seamlessly connected client experience even as a client system may be moving about, changing IP addresses and coping with potentially significant changes in connection quality, routing, DNS mapping and other properties.", "num_citations": "4\n", "authors": ["491"]}
{"title": "Group communication systems\n", "abstract": " Our goal in Chap.\u00a012 is to identify the best options for implementing high-speed data replication and other tools needed for fault-tolerant, highly assured Web Services and other forms of distributed computing. Given the GMS created in Chap.\u00a0                   11                                    , one option would be to plunge right in and build replicated applications using the protocol directly in the application. The approach builds on the GMS, but then uses it to create protocols that can only be operated under the assumption that if a failure occurs, the GMS will be notified and will reconfigure the system appropriately, notifying the new system configuration members of their new state, and taking steps to shut down any old members that are unreachable but later recover. We arrive at a rich collection of protocols and establish a subtle linkage to the Paxos framework.", "num_citations": "4\n", "authors": ["491"]}
{"title": "Overcoming failures in a distributed system\n", "abstract": " In this and the next two chapters, we will be focused on mechanisms for replicating data and computation while guaranteeing some form of consistent behavior to the end-user. For example, we might want to require that even though information has been replicated, the system behaves as if that information was not replicated and instead resides at a single place. This is an intuitively attractive model, because developers find it natural to think in terms of non-distributed systems, and it is reasonable to expect that a distributed system should be able to mimic the behavior of a non-distributed one. At the same time, though, it is not a minor undertaking to ensure that a distributed system will behave just like a non-distributed one. The technical content of the chapter centers on the components of Lamport\u2019s widely known Paxos protocol.", "num_citations": "4\n", "authors": ["491"]}
{"title": "Kevlar: A Flexible Infrastructure for Wide-Area Collaborative Applications\n", "abstract": " While Web Services ensure interoperability and extensibility for networked applications, they also complicate the deployment of highly collaborative systems, such as virtual reality environments and massively multiplayer online games. Quite simply, such systems often manifest a natural peer-to-peer structure. This conflicts with Web Services\u2019 imposition of a client-server communication model, vectoring all events through a data center and emerging as a performance bottleneck. We design and implement the Kevlar system to alleviate such choke points, using an overarching network-overlay structure to integrate central hosted content with peer-to-peer multicast. Kevlar leverages the given storage and communication models that best match the respective information: data most naturally retrieved from the cloud is managed using hosted objects, while edge updates are transmitted directly peer-to-peer using\u00a0\u2026", "num_citations": "4\n", "authors": ["491"]}
{"title": "Implementing High Performance Multicast in a Managed Environment\n", "abstract": " Component integration environments such as Microsoft .NET and J2EE have become widely popular with application developers, who benefit from standardized memory management, system-wide type checking, debugging, and performance analysis tools that operate across component boundaries. This paper describes QuickSilver Scalable Multicast QSM, a new multicast platform designed to achieve high performance in managed environments. Memory-related overheads and phenomena related to scheduling are shown to dominate the behavior of the system. We discuss techniques that helped us to alleviate these problems, and argue that they reveal general principles applicable to other kinds of high-data-rate protocols and applications in managed settings.Descriptors:", "num_citations": "4\n", "authors": ["491"]}
{"title": "Ricochet: Low-Latency Multicast for Scalable Time-Critical Services\n", "abstract": " Ricochet is a time-critical multicast protocol for use in clustered platforms and datacenters. Applications in such settings often are cloned for scalability and availability, hence updates involve multicast or publishsubscribe, with large numbers of heavily overlapping multicast groups. The applications that interest us are ones for which rapid response reflecting the most recent updates is important. Ricochet, a multicast protocol that combines native IP multicast with proactive forward error correction, achieves high levels of consistency with stable and tunable overhead. Evaluation on a 64-node rack-style cluster shows that existing technologies perform poorly relative to our goals, whereas Ricochet achieves extremely low and consistent delay, performs well with as many as 1024 multicast groups per node, and is not disrupted by packet loss. The price of this low latency is a modest loss in peak throughput.", "num_citations": "4\n", "authors": ["491"]}
{"title": "Scalable trust: engineering challenge or complexity barrier?\n", "abstract": " We consider the challenges of developing and deploying trusted computing platforms that can be operated on a large scale. The core question concerns scalability of trust properties: do these revolve around engineering challenges (which can potentially be overcome by clever design), complexity barriers (which might require completely new approaches), or other kinds of obstacles? Scalable trust means different things to different users; unless we limit the topic, we run the risk of scalability problems of our own. Accordingly, we'll narrow attention to the forms of trust needed in a hypothetical electronic medical records system that interconnects multiple institutions and includes telemetry or even active devices for monitoring patents. There are several efforts underway to develop prototype systems with this functionality. We begin by asking what trust means in the context of such a system. Then, we match technology\u00a0\u2026", "num_citations": "4\n", "authors": ["491"]}
{"title": "Scalable publish-subscribe in a managed framework\n", "abstract": " Reliable multicast, publish-subscribe and group communication are highly effective in support of replication and event notification, and could serve as the enabling technologies for new types of applications that are both interactive and decentralized. To fully realize this vision, we need a high-performance, scalable, and reliable multicast engine as an integral part of the runtime environment. Since the majority of development today is done in managed, strongly typed environments such as Java or .NET, integration with such environments is of particular importance. What factors limit performance and scalability of a reliable multicast engine in a managed environment What support from the runtime could improve performance, avoid instabilities, or make such systems easier to build This paper sheds light on these questions by analyzing the performance of QuickSilver Scalable Multicast QSM, a new multicast protocol and system built entirely in .NET. Memory-related overheads and scheduling-related phenomena are shown to dominate the behavior of our system. We discuss techniques that helped us alleviate some of these problems, and point to areas where better support from the runtime would be desirable.Descriptors:", "num_citations": "4\n", "authors": ["491"]}
{"title": "Achieving Critical Reliability With Unreliable Components andUnreliable Glue\n", "abstract": " Even the most aggressive quality assurance procedures yield at best probabilistic confidence in the reliability of complex systems.  Distributed systems, because of their large numbers of components, are enormously complex engineering artifacts, and hence may appear to be inherently unreliable -- despite the best efforts of researchers and developers.  A cellular distributed systems architecture offers the hope of drastically improving the reliability of current technologies in settings where reliability is critical. The approach combines a stateful style of distributed computing within cells with a loosely coupled probabilistic inter-cell computing model based on a probabilistic broadcast primitive.  We give an implementation of this primitive, called pbcast, and demonstrate how to use it to implement this methodology.  Our approach is compatible with the use of popular distributed computing and reliability technologies, while offering considerable isolation against the spread of failures among cells.", "num_citations": "4\n", "authors": ["491"]}
{"title": "Reliable enterprise computing systems\n", "abstract": " As organizations move to better exploit computing systems, a new class of largescale distributed applications is emerging. These enterprise computing systems offer highly integrated, highly reliable computing to users who may be physically separated by large distances and who interact using a multiplicity of computing devices. They combine large numbers of independently executing programs into an (apparently) seamless whole, and often provide services critical to the organization. The development of software for such systems is difficult, particularly because of the need to dynamically respond to failures and recoveries. This is further complicated by the constraint that such a system behave consistently regardless of where it is accessed. The basic premise of this paper is that enterprise computing will require advances in the way that we do distributed computing. Specifically, whereas modern distributed\u00a0\u2026", "num_citations": "4\n", "authors": ["491"]}
{"title": "Solo: Self organizing live objects\n", "abstract": " Data dissemination overlays are central in scalable multicast protocols and are used in many other kinds of distributed systems. Such overlays must self-assemble and in situations where there are multiple protocol options, a suitable choice of protocol may be key to achieving desired levels of performance, reliability or other QoS objectives. Here, we describe SOLO, a new platform were constructing as part of Cornells Live Objects project. SOLO automates the task of discovering the runtime environment by sensing such properties as NAT or firewall characteristics, bottlenecks and bandwidth fluctuations, etc. This paper presents the SOLO architecture and evaluates its effectiveness under a range of realistic scenarios that would be expected in wide-area environments.Descriptors:", "num_citations": "3\n", "authors": ["491"]}
{"title": "The Power of Indirection: Achieving Multicast Scalability by Mapping Groups to Regional Underlays\n", "abstract": " Reliable multicast is a powerful primitive, useful for data  replication, event notification (publish-subscribe), fault tolerance and other purposes. Yet many of the most interesting applications give rise to huge numbers of heavily overlapping groups, some of which may be large. Existing multicast systems scale scale poorly in one or both respects. We propose the QuickSilver Scalable Multicast protocol (QSM), a novel solution that delivers performance almost independent of the number of groups and introduces newmechanisms that scale well in the number of nodes with minimal performance and delay penalties when loss occurs. Key to the solution is a level of indirection: a mapping of groups to regions of group overlap in which communication associated with different protocols can be merged. The core of QSM is a new regional multicast protocol that offers scalability and performance benefits over a wide range of region sizes.", "num_citations": "3\n", "authors": ["491"]}
{"title": "Novel backup protection system for the electric power grid using agent.\n", "abstract": " This paper proposes a novel backup protection system for the electric power grid that makes use of Agents. Faster and allowing for more selective protection, the new relays are significantly better than their traditional counterparts. Maloperation is reduced by the Agent's self-checking and self-correcting ability. This paper presents the basic conception of Agents and analyzes the communication networks for relay Agents. The principle structure, protection strategies and IP-based communication methods of the Agent-based backup protection are proposed. Simulations run in a typical power system using the EPOCHS platform illustrate the effectiveness of the proposed method.", "num_citations": "3\n", "authors": ["491"]}
{"title": "Clock synchronization and synchronous systems\n", "abstract": " Previous chapters of this book have made a number of uses of clocks or time in distributed protocols. In this chapter, we look more closely at the underlying issues. Our focus is on aspects of real-time computing that are specific to distributed protocols and systems", "num_citations": "3\n", "authors": ["491"]}
{"title": "Distributed simulation in manufacturing: EPOCHS: integrated commercial off-the-shelf software for agent-based electric power and communication simulation\n", "abstract": " This paper reports on the development of the Electric Power and Communication Synchronizing Simulator (EPOCHS), a distributed simulation environment. Existing electric power simulation tools accurately model power systems of the past, which were controlled as large regional power pools without significant communication elements. However, as power systems increasingly turn to protection and control systems that make use of computer networks, these simulators are less and less capable of predicting the likely behavior of the resulting power grids. Similarly, the tools used to evaluate new communication protocols and systems have been developed without attention to the roles they might play in power scenarios. EPOCHS utilizes multiple research and commercial off-the-shelf (COTS) systems to bridge the gap. EPOCHS is also notable for allowing users to transparently encapsulate complex system\u00a0\u2026", "num_citations": "3\n", "authors": ["491"]}
{"title": "Anonymous gossip: Improving multicast reliability in ad-hoc mobile networks\n", "abstract": " In recent years, a number of applications of ad-hoc networks have been proposed. Many of them are based on the availability of a robust and reliable multicast protocol. In this paper, we address the issue of reliability and propose a scalable method to improve packet delivery of multicast routing protocols and decrease the variation in the number of packets received by different nodes. The proposed protocol works in two phases. In the first phase, any suitable protocol is used to multicast a message to the group, while in the second concurrent phase, the gossip protocol tries to recover lost messages. Our proposed gossip protocol is called Anonymous Gossip (AG) since nodes need not know the other group members for gossip to be successful. This is extremely desirable for mobile nodes, that have limited resources, and where the knowledge of group membership is difficult to obtain. As a first step, anonymous gossip is implemented over MAODV without much overhead and its performance is studied. Simulations show that the packet delivery of MAODV is significantly improved and the variation in number of packets delivered is decreased. 1.", "num_citations": "3\n", "authors": ["491"]}
{"title": "ISIS and META Projects: Progress Report\n", "abstract": " Isis and Meta are two distributed systems projects at Cornell University. The ISIS project, led by Ken Birman, has developed a new methodology, virtual synchony, for writing robust distributed software. This approach is directly support by Isis Toolkit, a programming system that is distributed to over 300 academic and industrial sites. As the basic Isis techniques have matured, we have focused increasingly on some of the remaining hard problems of reliable distributed programming. Principally these include high performance multicast, large scale applications, and wide area networks. We are also developing several interesting applications that exploit the strengths of Isis, including an NFS-compatible replicated system. The Meta project, led by Keith Marzullo, is about distributed control in a soft real-time environment incorporating feedback. This domain encompasses examples as diverse as monitoring inventory and consumption on a factory floor, and performing load-balancing on a distributed computing system. One of the first uses of Meta is for distributed application management the tasks of configuring a distributed program, dynamically adapting to failures, and monitoring its performance.Descriptors:", "num_citations": "3\n", "authors": ["491"]}
{"title": "A system for clinical data-base applications\n", "abstract": " Development of a new system for clinical data-base applications is reported. It was found that this class of applications gives rise to unique challenges, particularly with respect to the nature of the query language and the best strategies for solving queries. The system runs on inexpensive minicomputers under the UNIX operating system, and has been proven effective in an environment that is not dedicated to the database application. Utility is increased by interfaces to an interactive statistical package (ISP) and by facilities for data collection from monitoring equipment and other devices. Provisions were made for crash recovery, data protection, and simultneous database access by multiple users.", "num_citations": "3\n", "authors": ["491"]}
{"title": "Anonymous, fault-tolerant distributed queries for smart devices\n", "abstract": " Applications that aggregate and query data from distributed embedded devices are of interest in many settings, such as smart buildings and cities, the smart power grid, and mobile health applications. However, such devices also pose serious privacy concerns due to the personal nature of the data being collected. In this article, we present an algorithm for aggregating data in a distributed manner that keeps the data on the devices themselves, releasing only sums and other aggregates to centralized operators. We offer two privacy-preserving configurations of our solution, one limited to crash failures and supporting a basic kind of aggregation; the second supporting a wider range of queries and also tolerating Byzantine behavior by compromised nodes. The former is quite fast and scalable, the latter more robust against attack and capable of offering full differential privacy for an important class of queries, but it costs\u00a0\u2026", "num_citations": "2\n", "authors": ["491"]}
{"title": "Pushing Bytes: Cloud Scale Big-Data Replication with RDMC\n", "abstract": " Cloud computing frameworks replicate large objects for diverse reasons, often under time-pressure. RDMC (Reliable DMA Multicast) is a reliable data replication protocol that runs at exceptionally high speeds and low latencies, implementing multicast as a pattern of RDMA unicast operations using a novel approach that maximizes concurrency. Users with knowledge of datacenter topology can configure RDMC to use a pattern of data flow matched to the network. In networks with full bisection bandwidth our fastest protocol creates a collection of binomial trees and embeds them on a hypercube overlay, setting speed records while also achieving exceptionally low delivery-time skew.", "num_citations": "2\n", "authors": ["491"]}
{"title": "Brief announcement: Live streaming with utilities, quality and cost\n", "abstract": " The growth in Internet traffic associated with video streaming and sharing of live video content is so rapid that it may soon dwarf all other forms of Internet content. By late 2012, Internet video alone is projected to generate almost 10 exabytes of traffic per month, accounting for nearly 50 percent of all Internet traffic [3]. ISPs and content providers are faced with the challenge of devising and deploying technologies to accommodate the surging demand for bandwidth. Data generated in real-time such as by live video broadcasts (eg sports games or new episodes of popular TV shows), chat systems, immersive virtual reality applications and games typically can\u2019t be cached at all. In today\u2019s systems, each client may pull such information on its own point-to-point stream directly from the data center, even if large numbers of clients share interest in at least some aspects of the data.Here, we lay the groundwork for a new\u00a0\u2026", "num_citations": "2\n", "authors": ["491"]}
{"title": "Remote procedure calls and the client/server model\n", "abstract": " Up to now we have looked at cloud computing from a fairly high level, and used terms such as \u201cclient\u201d and \u201cserver\u201d in ways intended to evoke the reader\u2019s intuition into the way that modern computing systems work: our mobile devices, laptops and desktop systems operate fairly autonomously, requesting services from servers that might run in a machine up the hall, or might be situated in a massive cloud-computing data center across the country. Here we focus on client/server computing as a model and look at the issues that arise when a client platform cooperates with a server, potentially replicating state or holding locks.", "num_citations": "2\n", "authors": ["491"]}
{"title": "Instrumentation for exact packet timings in networks\n", "abstract": " We design and implement a novel class of highly precise network instrumentation, capable of the first-ever capture of exact packet timings of network traffic. Our instrumentation - combining real-time physics test equipment with off-line postprocessing software - prevents interference with the system under test, provides reproducible measurements by eliminating non-deterministic error, and uses transparent and ubiquitous lab equipment and open-source software for ease of replication. We use our technique to perform in-situ observations of 10 Gigabit Ethernet packets in flight on optical fiber, showing improvements in timing precision of two to six orders of magnitude over existing methods of measurement, which generally employ software on commodity computer endpoints of network paths.", "num_citations": "2\n", "authors": ["491"]}
{"title": "Enabling Tactical Edge Mashups with Live Objects\n", "abstract": " We introduce the Live Objects framework, which leverages our distributed object-oriented programming model and enables tactical edge mashups for battlefield command and control. Unlike most deployed web services, which are typically limited to client-server interactions, Live Objects can simultaneously support multiple patterns of communication, including direct client-to-client protocols. This means that when clients are forward deployed or accessible only through disadvantaged links, a Live Objects system can remain highly responsive, whereas more standard solutions might slow down precipitously, become unresponsive, or fail outright. Here, we summarize the approach and then suggest that, when using it, a new kind of Service-Oriented Collaboration SOC application can be created that will combine direct client-to-client sharing of imagery, videos, or other real-time data captured in the field, with service-hosted data, including geographic information systems, weather prediction systems, social networks, and other databases. The client-to-client solutions can include powerful new collaboration features implemented to help the user achieve tactical Command and Control C2 goals that require split-second coordination, for which reach-back to a server might be impossibly slow. We showcase key properties of our platform through a functional, proof-of-concept Combat Search and Rescue CSAR scenario.Descriptors:", "num_citations": "2\n", "authors": ["491"]}
{"title": "Empirical Characterization of Uncongested Lambda Networks and 10GbE Commodity Endpoints\n", "abstract": " High-bandwidth semi-private lambda networks, provisioned with dedicated wavelengths on fiber optic spans, serve as important transport mechanisms for critical data flows, including scientific, military, and financial users. This work provides a careful examination of the observed characteristics of such networks in an uncongested state, evaluating loss, latency, and throughput at the end-host. Through our measurements, we quantify both rates and locations of loss events, providing insight into the recognized degradation from promised network performance for the user community, and the loss of dependability of the network as a whole. Finally, we identify specific scenarios which engender greater loss rates and make suggestions for future directions that could alleviate these barriers to infrastructure performance and dependability.", "num_citations": "2\n", "authors": ["491"]}
{"title": "Peer-to-Peer Systems and Probabilistic Protocols\n", "abstract": " In this chapter, we consider a number of protocols representative of a new wave of research and commercial activity in distributed computing. The protocols in question share two characteristics. First, they exploit what are called peer-to-peer communication patterns. Peer-to-peer computing is in some ways a meaningless categorization, since all of the protocols we\u2019ve discussed in this book involve direct exchanges of messages between \u201cpeers.\u201d A better term might be \u201cclient to client\u201d protocols, because most peer-to-peer systems emerge from a world of client/server computing, but replace some or all functions of the servers by functionality hosted on the clients themselves. For example, in what has become the most standard example of peer-to-peer computing, individuals willing to share music might copy MP3 files onto their machines, then advertise their availability in some form of directory that others can query\u00a0\u2026", "num_citations": "2\n", "authors": ["491"]}
{"title": "Fault-tolerance in sixth generation operating systems\n", "abstract": " Sixth generation operating systems are likely to be structured as immense object-oriented systems, offering integrated access to tens of thousands of nodes. The need to support highly automated self-management and to provide a high degree of fault-tolerance argues that virtually synchronous object groups could play a key role in such systems.", "num_citations": "2\n", "authors": ["491"]}
{"title": "A formalism for fault-tolerant applications in asynchronous systems\n", "abstract": " Formal methods for specifying fault-tolerant requirements are extremely important for proving a given application correct and robust. Using a formal method provides a clear and specific description and can lead to a better uuderstanding of the problem. Distributed algorithms are difficult to write without considering fault-toleraace; adding failures to the equation makes it di~ cult to believe any'reasoning'about robustness or correctness without some sort of formalism. Moreover, formalism provides a means of quantifying problems and solutions and comparing their strengths. By quantifying both, minimal solutions can be fitted to problems.We believe that modal logics, derived from the model of computation, provide an accessible and useful means of specifying and reasoning about fault-tolerant requirements for asynchronous, distributed systems. Given that. the model is the semantic fouadation, its algebraic properties\u00a0\u2026", "num_citations": "2\n", "authors": ["491"]}
{"title": "Tools for distributed application management\n", "abstract": " Distributed application management consists of monitoring and controlling an application as it executes in a distributed  environment. It encompasses such activities as configuration,  initialization, performance monitoring, resource scheduling, and failure response. In this paper we describe the Meta system: a collection of tools for constructing distributed application management software. Meta provides the mechanism, while the programmer specifies the policy  for application management. The policy is manifested as a control program which is a soft real-time reactive program. The underlying  application is instrumented with a variety of built-in and user- defined sensors and actuators. These define the interface between the control program and the application. The control program also  has access to a database describing the structure of the application  and the characteristics of is environment. Some of the more difficult problems for application management occur when pre-existing, nondistributed programs are integrated into a  distributed application for which they may not have been intended.  Meta allows management functions to be retrofitted to such programs  with a minimum effort. Keywords: Distributed application management, configuration management, distributed operating systems, dynamic reconfiguration,  monitoring distributed systems, rule-based systems, Isis.", "num_citations": "2\n", "authors": ["491"]}
{"title": "The role of order in distributed programs\n", "abstract": " We discuss the role of order in building distributed systems. It is our  belief that a \"principle of event ordering\" underlies the wide range of  operating systems mechanisms that have been put forward for building robust  distributed software. Stated concisely, this principle is that one achieves  correct distributed behavior by ordering classes of distributed events that  conflict with one another. By focusing on order, one can obtain simplified  descriptions and convincingly correct solutions to problems that might  otherwise have looked extremely complex. Moreover, we observe that there are  a limited number of ways to obtain order, and that the choice made impacts  greatly on performance.", "num_citations": "2\n", "authors": ["491"]}
{"title": "MDB-1: A new database system for medical applications\n", "abstract": " This paper reports on the development of a new database system, MDB-1, at Columbia University. Most medical database systems are specialists, tailored to some aspect of medical information management at the expense of other aspects. Clearly, the more specialized a database system becomes, the harder it is to maintain and to integrate with other systems. We believe that the integration of medical information management services is a tremendously important goal; consequently, MDB-1 has been designed to be as general as possible. By coupling a layered system architecture to a hierarchical data structuring method, we have created a system that can support a variety of applications without compromising the potential for sharing data. The potential of the approach is illustrated by the range of problems to which it is already being applied. MDB-1 is being used for such traditional database services as reporting patient status, scheduling procedures, collecting and integrating data from multiple sources (including devices), record-keeping and billing. Mechanisms have been included for ensuring the privacy of data, integrating multiple databases into a single\" logical\" one, and transfering data to the major statistical packages and to other database systems. The system is also being applied to less traditional problems, for example the development of expert systems that are capable of reasoning about the contents of a database or watching for events of special interest.Viewed at a high level, the software that comprises MDB-1 decomposes into a collection of modular subsystems. In some cases these modules are interconnected by procedure\u00a0\u2026", "num_citations": "2\n", "authors": ["491"]}
{"title": "THE RELATIONSHIP BETWEEN SIGNAL REPRESENTATION AND LEARNING IN ECG ANALYSIS.\n", "abstract": " Degree: Ph. D.DegreeYear: 1981Institute: University of California, BerkeleyThis dissertation considers problems which arise during computerized analysis of 24-hour electrocardiogram records (ambulatory ECGs). ECG analysis systems learn to recognize a small number of fairly arbitrary QRS waveforms, and then identify instances of each type of waveform among a large num", "num_citations": "2\n", "authors": ["491"]}
{"title": "DerechoDDS: Efficiently leveraging RDMA for fast and consistent data distribution\n", "abstract": " Safety-critical applications have always struggled to balance strong consistency with high performance. Kernelbypassing technologies like RDMA (Remote Direct Memory Access) promise to ease this tension by offering fast communication options that can fully leverage modern hardware. We introduce DerechoDDS, an OMG-compliant data distribution service layered over Derecho, an open-source C++ library that combines the consistency guarantees of atomic multicast with the speed of RDMA networks. In adopting this layering, we encountered a significant challenge: DDS is dominated by small messages, whereas Derecho was optimized for large ones. Hence, we identified a set of optimization techniques for small-message atomic multicast over RDMA, obtaining significant performance improvements both for the Derecho library and for DerechoDDS.", "num_citations": "1\n", "authors": ["491"]}
{"title": "Reliable, Efficient Recovery for Complex Services with Replicated Subsystems\n", "abstract": " Applications with internal substructure are common in the cloud, where many systems are organized as independently logged and replicated subsystems that interact via flows of objects or some form of RPC. Restarting such an application is difficult: a restart algorithm needs to efficiently provision the subsystems by mapping them to nodes with needed data and compute resources, while simultaneously guaranteeing that replicas are in distinct failure domains. Additional failures can occur during recovery, hence the restart process must itself be a restartable procedure. In this paper we present an algorithm for efficiently restarting a service composed of sharded subsystems, each using a replicated state machine model, into a state that (1) has the same fault-tolerance guarantees as the running system, (2) satisfies resource constraints and has all needed data to restart into a consistent state, (3) makes safe decisions\u00a0\u2026", "num_citations": "1\n", "authors": ["491"]}
{"title": "Pushing Bytes: Cloud-Scale Data Replication with RDMC\n", "abstract": " Data center infrastructures frequently replicate objects to create backups or to copy executables and input files to compute nodes. This task occurs under time pressure: data is at risk of loss until replicated for fault-tolerance, and in the case of parallel processing systems like Spark, useful computation can't start until the nodes all have a copy of the executable images. Cloud elasticity creates a similar need to rapidly copy executables and their inputs. To address these needs, we introduce RDMC: a fast reliable data replication protocol that implements multicast as a pattern of RDMA unicast operations, which maximizes concurrency while minimizing unnecessary transfers. RDMC can be used in any setting that has RDMA or a software RDMA emulation. Our focus is on use of replication as an element of the data center infrastructure. We evaluate overheads for the hardware-supported case using microbenchmarks and heavy-load experiments, and also describe preliminary experiments using a technique that offloads the entire data transfer pattern into the NICs, further reducing latency while freeing server resources for other tasks.", "num_citations": "1\n", "authors": ["491"]}
{"title": "Evolution of fault tolerance\n", "abstract": " Ken Birman's talk focused on controversies surrounding fault-tolerance and consistency. Looking at the 1990's, he pointed to debate around the so-called CATOCS question (CATOCS refers to causally and totally ordered communication primitives) and drew a parallel to the more modern debate about consistency at cloud scale (often referred to as the CAP conjecture). Ken argued that the underlying tension is actually one that opposes basic principles of the field against the seemingly unavoidable complexity of mechanisms strong enough to solve consensus, particularly the family of protocols with Paxos-like structures. Over time, this was resolved: He concluded that today, we finally know how to build very fast and scalable solutions (those who attended SOSP 2015 itself saw ten or more of the paper on such topics). On the other hand, Ken sees a new generation of challenges on the horizon: cloud-scale\u00a0\u2026", "num_citations": "1\n", "authors": ["491"]}
{"title": "Dynamic Membership\n", "abstract": " The context established by Chap.\u00a0                   10                                     provides conceptual tools to develop an automated and highly dynamic membership tracking service, in which membership of a system varies as service instances are launched and join an active system, shut down and must leave it, or crash. We solve the problem in steps, first showing how a system can track its own membership, and then showing how the resulting group membership system (GMS) can be used to support the creation of protocols that, themselves, can largely ignore dynamic membership.", "num_citations": "1\n", "authors": ["491"]}
{"title": "How and Why Computer Systems Fail\n", "abstract": " Before jumping into the question of how to make systems reliable, it will be useful to briefly understand the reasons that distributed systems fail. In this chapter we discuss some of the thinking around failure: a surprisingly rich and varied technical topic.", "num_citations": "1\n", "authors": ["491"]}
{"title": "Dr. multicast\n", "abstract": " Dr. Multicast Presentation Page 1 Dr. Multicast for Data Center Communication Scalability Ymir Vigfusson Hussam Abu-Libdeh Mahesh Balakrishnan Ken Birman Cornell University Yoav Tock IBM Research Haifa LADIS, September 15, 2008 Page 2 IP Multicast in Data Centers IPMC is not used in data centers Page 3 IP Multicast in Data Centers Why is IP multicast rarely used? Page 4 IP Multicast in Data Centers Why is IP multicast rarely used? Limited IPMC scalability on switches/routers and NICs Page 5 IP Multicast in Data Centers Why is IP multicast rarely used? Limited IPMC scalability on switches/routers and NICs Broadcast storms: Loss triggers a horde of NACKs, which triggers more loss, etc. Disruptive even to non-IPMC applications. Page 6 IP Multicast in Data Centers IP multicast has a bad reputation Page 7 IP Multicast in Data Centers IP multicast has a bad reputation Works great up to a point, after which \u2026", "num_citations": "1\n", "authors": ["491"]}
{"title": "Rethinking reliable transport for the datacenter\n", "abstract": " Datacenter applications are inherently networked systems, distributed over multiple physical machines for scalability and availability. The predominant communication pattern within datacenters is multicast, where a packet is simultaneously sent to multiple nodes. However, the network communication options available today within datacenters are severely limited\u2014typically, application developers choose between using TCP sockets or building custom application-level protocols over UDP. Research into high-performance protocols for clustered environments has failed to produce implementations that are used in the real world. We believe that the deployment failure of new transport options stems from their intrinsic design characteristics:", "num_citations": "1\n", "authors": ["491"]}
{"title": "WS-OBJECTS: Extending Service-Oriented Architecture with Hierarchical Composition of Client-Side Asynchronous Event-Processing Logic\n", "abstract": " There is a growing need for a new type of WS-*/SOA standards that could facilitate hierarchical, object-oriented composition of client-side executable code. This is especially true for the sorts of client-side logic embedded in AJAX and rich Internet applications, virtual worlds and MMORPGs; code that deals with issuing requests to servers, processing their responses, rendering UI, interacting with users, and processing asynchronous events from other client nodes. The paper offers an analysis of client-side composition patterns, a brief explanation why they lack adequate support from the existing web technologies, and design guidelines for client-side component integration environments to follow. The proposed guidelines have been successfully implemented in a prototype system. Our analysis is thus strongly rooted in reality; it is based on real experiences with concrete application scenarios. The paper concludes\u00a0\u2026", "num_citations": "1\n", "authors": ["491"]}
{"title": "Live Distributed Objects for Service Oriented Collaboration\n", "abstract": " Advanced internet collaboration tools are often promoted as crucial to reducing healthcare costs, improving productivity, facilitating disaster response, enabling a more nimble informationaware military, and allowing more immersive professional remote collaboration. We term such tools service oriented collaboration (SOC) applications to reflect their ability to facilitate communication at the network edge. SOC systems have garnered increasing appeal to developers and users because of the growing body of rich servicehosted content, such as electronic medical health records, geographic information systems, image repositories, weather prediction systems, social networks, and a diversity of other databases. These systems may also interface with sensors, medical devices, video cameras, microphones, and other realworld data sources.The framework we demonstrate herein definitely addresses many of these applications; however, it also encourages many other uses, oriented more explicitly to entertainment and better aligned with the global theme of the Intetain 2009 Conference:\u201cPlayful interaction: with others and with the environment.\u201d Our work provides the basis for a modern incarnation of a Second Life environment, one that is constructed atop a more principled and more scalable foundation.", "num_citations": "1\n", "authors": ["491"]}
{"title": "Supporting large-scale continuous stream datacenters via pub/sub middleware and adaptive transport protocols\n", "abstract": " Large-scale datacenters that handle continuous data streams require scalable and flexible communication infrastructure. The scalability of publish/subscribe (pub/sub) middleware coupled with fine-grained quality-of-service (QoS) support and adaptive transport protocols constitutes a promising area of research to address the challenges of these types of large-scale datacenters. This paper describes how we are integrating pub/sub middleware with an adaptive transport protocol framework to support composable functionality for properties that\u2014coupled with the finegrained QoS middlware support\u2014can meet the required QoS of data conferencing applications that coordinate and manage multiple continuous data streams.", "num_citations": "1\n", "authors": ["491"]}
{"title": "In computers we trust\n", "abstract": " Computing systems are finding their way into increasingly sensitive roles and settings and for these and other uses, we need computers we can trust. The author states that unless we begin to teach our students how to build trustworthy computing systems, viewing trust in an enlarged way, and use that broad perspective to help frame the underlying technical issues, we can't expect those students to go forth and build those systems. Until we begin a broader dialog with those who are impacted by computing - indeed, immersed in computing - and yet aren't viewed as traditional stakeholders in the dialog, we'll continue to build systems that impact them negatively without appreciating our actions' consequences. It's about time for a new engagement on the trust issue. To develop computer systems we can trust, we'll need a broader social appreciation of the dimensions and limitations of trust in technology. And we need\u00a0\u2026", "num_citations": "1\n", "authors": ["491"]}
{"title": "The Virtual Synchrony Execution Model\n", "abstract": " We finally have the basics out of the way and can put things together into a comprehensive platform for group communication! The process group communication primitives introduced in the previous chapters create a powerful framework for algorithmic development. When the properties of the model are combined with these primitives, we will say that a virtually synchronous execution environment results (see Birman and Joseph [February 1987, November 1987], Birman and van Renesse [1994]). In chapters 14\u201316 of the book we built up our primitives from basic message passing, but for this chapter, it is probably easier to understand the idea behind virtual synchrony in a top-down treatment. We\u2019ll then use the approach to develop an extremely high performance replicated data algorithm, as well as several other tools for consistent distributed computing.", "num_citations": "1\n", "authors": ["491"]}
{"title": "Security options for distributed settings\n", "abstract": " The use of distributed computing systems for storage of sensitive data and in commercial applications has created significant pressure to improve the security options available to software developers. Yet distributed system security has many possible interpretations, corresponding to very different forms of guarantees, and even the contemporary distributed systems that claim to be secure often suffer from basic security weaknesses. In Chapter 9, we pointed to some of these limitations. The current chapter looks at the available security technologies, the nature of their guarantees and their limitations and discusses some of the issues raised when we require that a security system also guarantee high availability. The constraints of brevity make it difficult to do justice to security in a setting such as ours; the topic is deserving of entire textbooks in its own right. Yet it is also difficult to treat security as a problem orthogonal\u00a0\u2026", "num_citations": "1\n", "authors": ["491"]}
{"title": "Scalability challenges and solutions for emerging networks\n", "abstract": " Summary form only given. Computer networks are becoming increasingly common, and are used in sensitive applications in which serious damage could be done by a network failure. There is a need for design principles that would enable a new generation of solutions having the required properties. Needed are technologies that would be inherently robust, provably scalable, and sufficiently self-organizing to adapt as conditions change in the network. The Spinglass project has been successful in solving an important class of such problems. At the core of our work is a new style of gossip-based communication protocol. We are using this protocol in support of a variety of systems programming tools. The article discusses two of them: Bimodal Multicast, a scalable reliable multicast protocol having probabilistic reliability properties, and Astrolabe, a virtual distributed database constructed entirely through peer-to-peer\u00a0\u2026", "num_citations": "1\n", "authors": ["491"]}
{"title": "Anonymous Gossip: Improving Multicast Reliability in Mobile Ad-Hoc Networks\n", "abstract": " Abstract restrictions make the existing multicast routing protocols such as MAODV very unreliable even in moderately sized networks. This paper discusses our protocol, Anonymous", "num_citations": "1\n", "authors": ["491"]}
{"title": "Bimodal Multicast (revised)\n", "abstract": " There are many methods for making a multicast protocol \"reliable\".  At one end of the spectrum, a reliable multicast protocol might offer atomicity guarantees, such as all-or-nothing delivery, delivery ordering, and perhaps additional properties such as virtually synchronous addressing. At the other are protocols that use local repair to overcome transient packet loss in the network, offering 'best effort' reliability. Yet none of this prior work has treated stability of multicast delivery as a basic reliability property, such as might be needed in an internet radio, TV, or conferencing application. This paper looks at reliability with a new goal: development of a multicast protocol which is reliable in a sense that can be rigorously quantified and includes throughput stability guarantees.  We characterize this new protocol as a \"bimodal multicast\" in reference to its reliability model, which corresponds to a family of bimodal probability distributions.  Here, we introduce the protocol, provide a theoretical analysis of its behavior, review experimental results, and discuss some candidate applications.  These confirm that bimodal multicast is reliable, scalable, and that the protocol provides remarkably stable delivery throughput.", "num_citations": "1\n", "authors": ["491"]}
{"title": "Ensemble: A Tool for Building Highly Assured Networks\n", "abstract": " \u2022 Average message in Horus used to carry one hundred bytes or more of header data\u2022 Now see true size of header drop by 50% due to compaction opportunity\u2022 Highly dynamic header: just a few bytes\u2022 One bit to signal presence of \u201crarely changing\u201d header information", "num_citations": "1\n", "authors": ["491"]}
{"title": "Using group communication technology to implement a reliable andscalable distributed in coprocessor\n", "abstract": " In this paper we explore the use of group communication technology, developed in the Horus project to implement a reliable and scalable distributed IN coprocessor. The proposed implementation can handle up to 20,000 calls per second with 12 computing nodes, can tolerate a single node failure or recovery, and can recover from periods of overload.  Our work suggests that group communication technology can bring substantial benefits, including scalability, fault-tolerance, and real-time responsiveness to the most demanding telecommunications applications.", "num_citations": "1\n", "authors": ["491"]}
{"title": "The Nile system architecture: fault-tolerant, wide-area access to computing and data resources\n", "abstract": " NILE is a multi-disciplinary project building a distributed computing environment for HEP. Nile will provide fault-tolerant, integrated access to processing and data resources for collaborators of the CLEO experiment, though the goals and principles are applicable to many domains. Nile currently has three main objectives: a realistic distributed system architecture design, the design of a robust data model, and a Fast-Track implementation providing a prototype design environment which will also be used by CLEO physicists. This talk will focus on the software and system architecture plans and the computing issues involved in making Nile's services fault-tolerant. Various factors led us to structure Nile hierarchically: local autonomy (the ability to continue processing despite network failure), scalability, geographic distances (CLEO collaborators span North America), and flexibility. At the lowest level are providers, representatives of individual processors; next are fault-tolerant Local Resource Managers (LRM) which monitor, allocate, and coordinate resources at a geographic locality (typically a collaborating institution); highest is the Global Resource Manager (GRM) which monitors and coordinates all activity in the system. In large part, an LRM and the GRM perform the same functions, with the domain of the former restricted. o Local Resource Manager. An LRM is the entity reponsible for representing an institution within the Nile System; that is, it interacts with the GRM. An LRM maintains timely complete information regarding local processors and data use. A user at site S submits a job to S's LRM, which decides whether the job can be processed at S\u00a0\u2026", "num_citations": "1\n", "authors": ["491"]}
{"title": "Merits of a probabilistic approach to properties in process group systems\n", "abstract": " Distributed computing systems have traditionally been designed using either a purely asynchronous methodology, in which no use is made of time, or a purely synchronous one, in which all delays are bounded and clocks are assumed to be synchronized. We argue in favor of an intermediate approach, in which delay states would be systematically removed from an asynchronous system, resulting in a high probability of predictably good performance. Preliminary and very informal analysis suggests that this would yield systems with predictably high performance, and yet that are as likely to achieve this performance as would a real-time system based upon a traditional synchronous design. Such thinking leads to a paradox. On the one hand, we conclude that asynchronous systems may be able to offer real-time properties with high probability. On the other, it fosters concern that all properties of distributed\u00a0\u2026", "num_citations": "1\n", "authors": ["491"]}
{"title": "PROGRAMMING ENVIRONMENT FOR MULTI-CHANNEL SIGNAL PROCESSING.\n", "abstract": " The authors focus on the subset of multi-channel signal processing systems that detect and analyze events in long-term signals. Although ECG analysis programs are typical of this class of systems, signal processing programs from many other problem areas exhibit similar behavior. The authors' basic premise is that a considerable degree of uniformity can be identified in systems of this sort. The goal of the research is to construct a general-purpose framework that exploits this common structure--a programming environment within which the programmer need only address aspects of an analysis problem that are specific to the application. A description is given of the design and performance of SEEK/PE, a system which extends SEEK/MC by addressing apsects of multi-channel signal processing other than those related to learning and pattern recognition.", "num_citations": "1\n", "authors": ["491"]}
{"title": "Low Cost Management of Replicated Data in Fault-Tolerant Distributed Systems\n", "abstract": " Many distributed systems replicate data for fault tolerance or availability.  In such systems, a logical update on a data item results in a physical update  on a number of copies. The synchronization and communication required to  ensure that the copies of replicated data are kept consistent introduces a  delay when operations are performed. In this paper, we describe a technique  that relaxes the usual degree of synchronization, permitting copies of  replicated data to be updated concurrently with other operations, while at the  same time ensuring that correctness is not violated. The additional  concurrency thus obtained results in better response time when performing  operations on replicated data. We also discuss how this technique performs in  conjunction with roll-back and roll-forward failure recovery mechanisms.", "num_citations": "1\n", "authors": ["491"]}
{"title": "Extensible Web Services Architecture for Notification in Large-Scale Systems (Extended Version)\u201d. Cornell University Technical Report. Forthcoming\n", "abstract": " Existing web services notification and eventing standards are useful in many applications, but they have serious limitations precluding large-scale deployments: it is impossible to use IP multicast or for recipients to forward messages to others and scalable notification trees must be setup manually. We propose 1 a design free of such limitations that could serve as a basis for extending or complementing these standards. The approach emerges from our prior work on QSM [1], a new web services eventing platform that can scale to extremely large environments.", "num_citations": "1\n", "authors": ["491"]}