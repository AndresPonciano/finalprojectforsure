{"title": "Providing high availability using lazy replication\n", "abstract": " To provide high availability for services such as mail or bulletin boards, data must be replicated. One way to guarantee consistency of replicated data is to force service operations to occur in the same order at all sites, but this approach is expensive. For some applications a weaker causal operation order can preserve consistency while providing better performance. This paper describes a new way of implementing causal operations. Our technique also supports two other kinds of operations: operations that are totally ordered with respect to one another and operations that are totally ordered with respect to all other operations. The method performs well in terms of response time, operation-processing capacity, amount of stored state, and number and size of messages; it does better than replication methods based on reliable multicast techniques.", "num_citations": "588\n", "authors": ["531"]}
{"title": "Promises: Linguistic support for efficient asynchronous procedure calls in distributed systems\n", "abstract": " This paper deals with the integration of an efficient asynchronous remote procedure call mechanism into a programming language. It describes a new data type called a promise that was designed to support asynchronous calls. Promises allow a caller to run in parallel with a call and to pick up the results of the call, including any exceptions it raises, in a convenient and type-safe manner. The paper also discusses efficient composition of sequences of asynchronous calls to different locations in a network.", "num_citations": "505\n", "authors": ["531"]}
{"title": "Replication in the Harp file system\n", "abstract": " This paper describes the design and implementation of the Harp file system. Harp is a replicated Unix file system accessible via the VFS interface. It provides highly available and reliable storage for files and guarantees that file operations are executed atomically in spite of concurrency and failures. It uses a novel variation of the primary copy replication technique that provides good performance because it allows us to trade disk accesses for network communication. Harp is intended to be used within a file service in a distributed network; in our current implementation, it is accessed via NFS. Preliminary performance results indicate that Harp provides equal or better response time and system capacity than an unreplicated implementation of NFS that uses Unix files directly.", "num_citations": "462\n", "authors": ["531"]}
{"title": "HQ replication: A hybrid quorum protocol for Byzantine fault tolerance\n", "abstract": " There are currently two approaches to providing Byzantine-fault-tolerant state machine replication: a replica-based approach, eg, BFT, that uses communication between replicas to agree on a proposed ordering of requests, and a quorum-based approach, such as Q/U, in which clients contact replicas directly to optimistically execute operations. Both approaches have shortcomings: the quadratic cost of inter-replica communication is unnecessary when there is no contention, and Q/U requires a large number of replicas and performs poorly under contention.We present HQ, a hybrid Byzantine-fault-tolerant state machine replication protocol that overcomes these problems. HQ employs a lightweight quorum-based protocol when there is no contention, but uses BFT to resolve contention when it arises. Furthermore, HQ uses only 3f+ 1 replicas to tolerate f faults, providing optimal resilience to node failures.", "num_citations": "407\n", "authors": ["531"]}
{"title": "Ownership types for object encapsulation\n", "abstract": " Ownership types provide a statically enforceable way of specifying object encapsulation and enable local reasoning about program correctness in object-oriented languages. However, a type system that enforces strict object encapsulation is too constraining: it does not allow efficient implementation of important constructs like iterators. This paper argues that the right way to solve the problem is to allow objects of classes defined in the same module to have privileged access to each other's representations; we show how to do this for inner classes. This approach allows programmers to express constructs like iterators and yet supports local reasoning about the correctness of the classes, because a class and its inner classes together can be reasoned about as a module. The paper also sketches how we use our variant of ownership types to enable efficient software upgrades in persistent object stores.", "num_citations": "286\n", "authors": ["531"]}
{"title": "Lazy replication: Exploiting the semantics of distributed services\n", "abstract": " To provide high availability for services such as mail or bulletin boards, data must be replicated. One way to guarantee consistency of replicated data is to force service operations to occur in the same order at all sites, but this approach is expensive. In this paper, we propose lazy replication as a way to preserve consistency by exploiting the semantics of the service\u2019s operations to relax the constraints on ordering. Three kinds of operations are supported: operations for which the clients define the required order dynamically during the execution. operations for which the service defines the order, and operations that must be globally ordered with respect to both client ordered and service ordered operations. The method performs well in terms of response time, amount of stored state, number of messages, and availability. It is especially well suited to applications in which most operations require only the client-defined\u00a0\u2026", "num_citations": "252\n", "authors": ["531"]}
{"title": "Safe and efficient sharing of persistent objects in Thor\n", "abstract": " Thor is an object-oriented database system designed for use in a heterogeneous distributed environment. It provides highly-reliable and highly-available persistent storage for objects, and supports safe sharing of these objects by applications written in different programming languages.Safe heterogeneous sharing of long-lived objects requires encapsulation: the system must guarantee that applications interact with objects only by invoking methods. Although safety concerns are important, most object-oriented databases forgo safety to avoid paying the associated performance costs.This paper gives an overview of Thor's design and implementation. We focus on two areas that set Thor apart from other object-oriented databases. First, we discuss safe sharing and techniques for ensuring it; we also discuss ways of improving application performance without sacrificing safety. Second, we describe our approach to\u00a0\u2026", "num_citations": "200\n", "authors": ["531"]}
{"title": "Modular software upgrades for distributed systems\n", "abstract": " Upgrading the software of long-lived, highly-available distributed systems is difficult. It is not possible to upgrade all the nodes in a system at once, since some nodes may be unavailable and halting the system for an upgrade is unacceptable. Instead, upgrades must happen gradually, and there may be long periods of time when different nodes run different software versions and need to communicate using incompatible protocols. We present a methodology and infrastructure that make it possible to upgrade distributed systems automatically while limiting service disruption. We introduce new ways to reason about correctness in a multi-version system. We also describe a prototype implementation that supports automatic upgrades with modest overhead.", "num_citations": "155\n", "authors": ["531"]}
{"title": "Distributed Object Management in Thor.\n", "abstract": " Thor is a new object-oriented database management system (OODBMS), intended to be used in heterogeneous distributed systems to allow programs written in di erent programming languages to share objects in a convenient manner. Thor objects are persistent in spite of failures, are highly likely to be accessible whenever they are needed, and can be structured to re ect the kinds of information of interest to users. Thor combines the advantages of the object-oriented approach with those of database systems: users can store and manipulate objects that capture the semantics of their applications, and can also access objects via queries.", "num_citations": "151\n", "authors": ["531"]}
{"title": "Lazy modular upgrades in persistent object stores\n", "abstract": " Persistent object stores require a way to automatically upgrade persistent objects, to change their code and storage representation. Automatic upgrades are a challenge for such systems. Upgrades must be performed in a way that is efficient both in space and time, and that does not stop application access to the store. In addition, however, the approach must be modular: it must allow programmers to reason locally about the correctness of their upgrades similar to the way they would reason about regular code. This paper provides solutions to both problems.The paper first defines upgrade modularity conditions that any upgrade system must satisfy to support local reasoning about upgrades. The paper then describes a new approach for executing upgrades efficiently while satisfying the upgrade modularity conditions. The approach exploits object encapsulation properties in a novel way. The paper also describes a\u00a0\u2026", "num_citations": "124\n", "authors": ["531"]}
{"title": "Providing persistent objects in distributed systems\n", "abstract": " THOR is a persistent object store that provides a powerful programming model. THOR ensures that persistent objects are accessed only by calling their methods and it supports atomic transactions. The result is a system that allows applications to share objects safely across both space and time.               The paper describes how the THOR implementation is able to support this powerful model and yet achieve good performance, even in a wide-area, large-scale distributed environment. It describes the techniques used in THOR to meet the challenge of providing good performance in spite of the need to manage very large numbers of very small objects. In addition, the paper puts the performance of THOR in perspective by showing that it substantially outperforms a system based onmemorymapped files, even though that system provides much less functionality than THOR.", "num_citations": "114\n", "authors": ["531"]}
{"title": "Abstractions for usable information flow control in Aeolus\n", "abstract": " Despite the increasing importance of protecting confidential data, building secure software remains as challenging as ever. This paper describes Aeolus, a new platform for building secure distributed applications. Aeolus uses information flow control to provide confidentiality and data integrity. It differs from previous information flow control systems in a way that we believe makes it easier to understand and use. Aeolus uses a new, simpler security model, the first to combine a standard principal-based scheme for authority management with thread-granularity information flow tracking. The principal hierarchy matches the way developers already reason about authority and access control, and the coarse-grained information flow tracking eases the task of defining a program\u2019s security restrictions. In addition, Aeolus provides a number of new mechanisms (authority closures, compound tags, boxes, and shared volatile state) that support common design patterns in secure application design.", "num_citations": "106\n", "authors": ["531"]}
{"title": "Disconnected operation in the Thor object-oriented database system\n", "abstract": " This paper discusses issaes raised by providing disconnected operation in the Thor object-ortented database system. Disconnected operation in such a system poses new challenges because of the small size of obiects, the richness and complexity of their interconnections, the huge number of them, and the fact that they are accessed within atomic transactions. We propose three techniques to address these challenges: (l) using the database query language for hoarding; (2) using dependent commits to tentatively com' mit transactions at the disconnected client; (3) using the high-level semantic of objects to avoidtransaction aborts.", "num_citations": "96\n", "authors": ["531"]}
{"title": "The design of a robust peer-to-peer system\n", "abstract": " Peer-to-peer (P2P) overlay networks have recently become one of the hottest topics in OS research. These networks bring with them the promise of harnessing idle storage and network resources from client machines that voluntarily join the system; self-configuration and automatic load balancing; censorship resistance; and extremely good scalability due to the use of symmetric algorithms. However, the use of unreliable client machines leads to two defects of these systems that precludes their use in a number of applications: storage is inherently unreliable, and lookup algorithms have long latencies. In this paper we propose a design of a robust peer-to-peer storage service, composed not of client nodes, but server nodes that are dedicated to running the peer-to-peer application. We argue that our system overcomes the defects of peer-to-peer systems while retaining their nice properties with the exception of\u00a0\u2026", "num_citations": "89\n", "authors": ["531"]}
{"title": "Efficient at-most-once messages based on synchronized clocks\n", "abstract": " This paper describes a new at-most-once message passing protocol that provides guaranteed detection of duplicate messages even when the receiver has no state stored for the sender. It also discusses how to use  at-most-once messages to implement higher-level primitives such as at-once-remote procedure calls and sequenced bytestream protocols. Our performance measurements indicate that at-most-once RPCs can provide at the same cost as less desirable forms of RPCs that do not guarantee at-most-once execution. Our method is based on the assumption that clocks throughout the system are loosely synchronized. Modern clock synchronization protocols provide good bounds on clock skew with high probability; our method depends on the bound for performance but not for correctness.", "num_citations": "83\n", "authors": ["531"]}
{"title": "Scheduling and Simulation: How to Upgrade Distributed Systems.\n", "abstract": " Upgrading the software of long-lived distributed systems is difficult. It is not possible to upgrade all the nodes in a system at once, since some nodes may be down and halting the system for an upgrade is unacceptable. This means that different nodes may be running different software versions and yet need to communicate, even though those versions may not be fully compatible. We present a methodology and infrastructure that addresses these challenges and makes it possible to upgrade distributed systems automatically while limiting service disruption.", "num_citations": "64\n", "authors": ["531"]}
{"title": "Cross-chain deals and adversarial commerce\n", "abstract": " Modern distributed data management systems face a new challenge: how can autonomous, mutually distrusting parties cooperate safely and effectively? Addressing this challenge brings up familiar questions from classical distributed systems: how to combine multiple steps into a single atomic action, how to recover from failures, and how to synchronize concurrent access to data. Nevertheless, each of these issues requires rethinking when participants are autonomous and potentially adversarial. We propose the notion of a cross-chain deal, a new way to structure complex distributed computations that manage assets in an adversarial setting. Deals are inspired by classical atomic transactions, but are necessarily different, in important ways, to accommodate the decentralized and untrusting nature of the exchange. We describe novel safety and liveness properties, along with two alternative protocols for\u00a0\u2026", "num_citations": "52\n", "authors": ["531"]}
{"title": "Type-aware transactions for faster concurrent code\n", "abstract": " It is often possible to improve a concurrent system's performance by leveraging the semantics of its datatypes. We build a new software transactional memory (STM) around this observation. A conventional STM tracks read-and write-sets of memory words; even simple operations can generate large sets. Our STM, which we call STO, tracks abstract operations on transactional datatypes instead. Parts of the transactional commit protocol are delegated to these datatypes' implementations, which can use datatype semantics, and new commit protocol features, to reduce bookkeeping, limit false conflicts, and implement efficient concurrency control. We test these ideas on the STAMP benchmark suite for STM applications and on our own prior work, the Silo high-performance in-memory database, observing large performance improvements in both systems.", "num_citations": "51\n", "authors": ["531"]}
{"title": "From internet to activenet\n", "abstract": " The ActiveNet will address the mismatch between the rate at which user requirements can change, ie, overnight, and the pace at which physical assets can be deployed. As the Internet grows it is increasingly difficult to maintain, let alone accelerate, the pace of innovation. Today, after a concept is prototyped its large scale deployment takes about 8 years. The ActiveNet will accelerate the pace of innovation by decoupling network services from the underlying hardware and by allowing new services to be demand loaded into the infrastructure. In the same way that IP enabled a range of upper layer protocols and transmission substrates, the ActiveNet will facilitate the development of new network services and hardware platforms.", "num_citations": "50\n", "authors": ["531"]}
{"title": "Skippy: a new snapshot indexing method for time travel in the storage manager\n", "abstract": " The storage manager of a general-purpose database system can retain consistent disk page level snapshots and run application programs\" back-in-time\" against long-lived past states, virtualized to look like the current state. This opens the possibility that functions, such as on-line trend analysis and audit, formerly available in specialized temporal databases, can become available to general applications in general-purpose databases.", "num_citations": "47\n", "authors": ["531"]}
{"title": "Distributed k-selection: From a sequential to a distributed algorithm\n", "abstract": " A methodology for transforming sequential recursive algorithms to distributive ones is suggested. The assumption is that the program segments between recursive calls have a distributive implementation. The methodology is applied to two k-selection algorithms and yields new distributed k-selection algorithms. Some complexity issues of the resulting algorithms are discussed.", "num_citations": "46\n", "authors": ["531"]}
{"title": "Snap: Efficient snapshots for back-in-time execution\n", "abstract": " SNAP is a novel high-performance snapshot system for object storage systems. The goal is to provide a snapshot service that is efficient enough to permit \"back-in-time\" read-only activities to run against application-specified snapshots. Such activities are often impossible to run against rapidly evolving current state because of interference or because the required activity is determined in retrospect. A key innovation in SNAP is that it provides snapshots that are transactionally consistent, yet non-disruptive. Unlike earlier systems, we use novel in-memory data structures to ensure that frequent snapshots do not block applications from accessing the storage system, and do not cause unnecessary disk operations. SNAP takes a novel approach to dealing with snapshot meta-data using a new technique that supports both incremental meta-data creation and efficient meta-data reconstruction. We have implemented a\u00a0\u2026", "num_citations": "36\n", "authors": ["531"]}
{"title": "Opportunistic log: Efficient installation reads in a reliable object server\n", "abstract": " Opportunistic Log: Efficient Installation Reads in a Reliable Object Server | Guide books ACM Digital Library home ACM home Google, Inc. (search) Advanced Search Browse About Sign in Register Advanced Search Journals Magazines Proceedings Books SIGs Conferences People More Search ACM Digital Library SearchSearch Advanced Search Browse Browse Digital Library Collections More HomeBrowse by TitleReportsOpportunistic Log: Efficient Installation Reads in a Reliable Object Server ABSTRACT No abstract available. Comments Login options Check if you have access through your login credentials or your institution to get full access on this article. Sign in Full Access Get this Publication Information Contributors Published in Guide books cover image Opportunistic Log: Efficient Installation Reads in a Reliable Object Server April 1994 Authors: J O''Toole profile image J. O''Toole, Shrira, L profile image \u2026", "num_citations": "35\n", "authors": ["531"]}
{"title": "A modular proof of correctness for a network synchronizer\n", "abstract": " In this paper we offer a formal, rigorous proof of the correctness of Awerbuch's algorithm for network synchronization. We specify both the algorithm and the correctness condition using the I/O automaton model, which has previously been used to describe and verify algorithms for concurrency control and resource allocation. We show that the model is also a powerful tool for reasoning about distributed graph algorithms. Our proof of correctness follows closely the intuitive arguments made by the designer of the algorithm by exploiting the model's natural support for such important design techniques as stepwise refinement and modularity. In particular, since the algorithm uses simpler algorithms for synchronization within and between \u2018clusters\u2019 of nodes, our proof can import as lemmas the correctness of these simpler algorithms.", "num_citations": "31\n", "authors": ["531"]}
{"title": "A Highly Available Object Repository for Use in a Heterogeneous Distributed System.\n", "abstract": " This paper describes a new project to design and implement an object repository for use in a heterogeneous distributed system. The primary goal of this work is to provide a convenient medium for sharing of information among programs written in many different programming languages. In addition, the repository will provide highly reliable and highly available storage for objects entrusted to it. 1", "num_citations": "27\n", "authors": ["531"]}
{"title": "On proving communication closedness of distributed layers\n", "abstract": " The notion of communication closed layer has been introduced as a way to define structured composition of distributed systems. An interesting question is how to verify the closedness of a layer. We formulate a proof rule proving closedness of a distributed layer. The rule is developed as an extension of the Apt, Francez and de Roever proof system for CSP. The extension is proved to be sound and relatively complete.", "num_citations": "26\n", "authors": ["531"]}
{"title": "A technique for constructing highly available services\n", "abstract": " This paper describes a general method for constructing a highly available service for use in a distributed system. It gives a specific implementation of the method and proves the implementation correct. The service consists of replicas that reside at several different locations in a network. It presents its clients with a consistent view of its state, but the view may contain old information. Clients can indicate how recent the information must be. The method can be used in applications satisfying certain semantic constraints. For applications that can use it, the method performs better than other replication techniques.", "num_citations": "25\n", "authors": ["531"]}
{"title": "Device and method for enabling long-lived snapshots\n", "abstract": " Decreasing disk costs make it possible to take frequent snapshots of past storage system states and retain them for a long duration. Existing snapshot approaches offer no satisfactory solution to long-lived snapshots. Split snapshots are an approach that is promising because it does not disrupt the current state storage system in either the short or the long run. An unsolved problem has been how to maintain an efficient access method for long-lived split snapshots without imposing undesirable overhead on the storage system. Skippy is a new approach that inexpensively indexes long-lived snapshots in parallel with snapshot creation. An embodiment of Skippy uses append-only index data structures to optimize writes while simultaneously providing low-latency snapshot lookup. Performance evaluations of Skippy indicate that this new approach is effective and efficient. It provides close-to-optimal access to long-lived\u00a0\u2026", "num_citations": "23\n", "authors": ["531"]}
{"title": "Thresher: An Efficient Storage Manager for Copy-on-write Snapshots.\n", "abstract": " A new generation of storage systems exploit decreasing storage costs to allow applications to take snapshots of past states and retain them for long durations. Over time, current snapshot techniques can produce large volumes of snapshots. Indiscriminately keeping all snapshots accessible is impractical, even if raw disk storage is cheap, because administering such large-volume storage is expensive over a long duration. Moreover, not all snapshots are equally valuable. Thresher is a new snapshot storage management system, based on novel copyon-write snapshot techniques, that is the first to provide applications the ability to discriminate among snapshots efficiently. Valuable snapshots can remain accessible or stored with faster access while less valuable snapshots are discarded or moved off-line. Measurements of the Thresher prototype indicate that the new techniques are efficient and scalable, imposing minimal (4%) performance penalty on expected common workloads.", "num_citations": "23\n", "authors": ["531"]}
{"title": "Exo-leasing: Escrow synchronization for mobile clients of commodity storage servers\n", "abstract": " Escrow reservations is a well-known synchronization technique, useful for inventory control, that avoids conflicts by taking into account the semantics of fragmentable object types. Unfortunately, current escrow techniques cannot be used on generic \u201ccommodity\u201d servers because they require the servers to run the type-specific synchronization code. This is a severe limitation for systems that require application-specific synchronization but need to rely on generic components.               Our exo-leasing method provides a new way to implement escrow synchronization without running any type-specific code in the servers. Instead, escrow synchronization code runs in the client providing the ability to use commodity servers. Running synchronization code in the client provides an additional benefit. Unlike any other system, our system allows a disconnected client to obtain escrow reservation from another\u00a0\u2026", "num_citations": "22\n", "authors": ["531"]}
{"title": "A Modular and Efficient Past State System for Berkeley {DB}\n", "abstract": " Applications often need to analyze past states to predict trends and support audits. Adding efficient and nondisruptive support for consistent past-state analysis requires after-the-fact modification of the data store, a significant challenge for today\u2019s systems. This paper describes Retro, a new system for supporting consistent past state analysis in Berkeley DB. The key novelty of Retro is an efficient yet simple and robust implementation method, imposing 4% worst-case overhead. Unlike prior approaches, Retro protocols, backed by a formal specification, extend standard transaction protocols in a modular way, requiring minimal data store modification (about 250 lines of BDB code).", "num_citations": "21\n", "authors": ["531"]}
{"title": "Electing a leader in a ring with link failures\n", "abstract": " We investigate the message complexity of electing a leader in a ring of asynchronous processors. Our work deviates from the previous works on electing a leader in that we consider the effect of link failures. A link is said to fail if some message sent through it never reaches its destination. We distinguish the case where n is known from the case n unknown. Our main result is a O(n \u00b7 log n) algorithm for electing a leader on a n-processor ring (the case n is known).", "num_citations": "21\n", "authors": ["531"]}
{"title": "The effects of link failures on computations in asynchronous rings\n", "abstract": " We investigate the message complexity of distributed computations on rings of asynchronous processors. In such computations, each processor has an initial local value and the task is to compute some predetermined function of all local values. Our work deviates from the traditional approach to complexity of ring computations in that we consider the effect of link failures.We show that the complexity of any non-trivial function is O (n log n) messages when n, the number of processors, is a-priori known; and is O (n 2) when n is not known. Interestingly, these tight bounds do not depend on whether the identity of a leader is apriori known before the computation starts. These results stand in sharp contrast to the situation in an asynchronous ring with no link failures~", "num_citations": "20\n", "authors": ["531"]}
{"title": "Buddycache: high-performance object storage for collaborative strong-consistency applications in a wan\n", "abstract": " Collaborative applications provide a shared work environment for groups of networked clients collaborating on a common task. They require strong consistency for shared persistent data and efficient access to fine-grained objects. These properties are difficult to provide in wide area networks because of high network latency.BuddyCache is a new transactional caching approach that improves the latency of access to shared persistent objects for collaborative strong-consistency applications in high-latency network environments. The challenge is to improve performance while providing the correctness and availability properties of a transactional caching protocol in the presence of node failures and slow peers.We have implemented a BuddyCache prototype and evaluated its performance. Analytical results, confirmed by measurements of the BuddyCache prototype using the multi-user 007 benchmark indicate that\u00a0\u2026", "num_citations": "17\n", "authors": ["531"]}
{"title": "A replicated Unix file system\n", "abstract": " Our work is most similar in its goals to [6], but we use a general replication algorithm tailored to this application rather than building on top of an existing replication technique; we'expect to achieve better performance in this way. We differ from the work on Coda [11] because we take the NFS/Unix file system semantics as a given, and because we are not willing to implement front ends on client machines. We also differ from the work on Echo [5] for these reasons, although Echo will support Unix file system semantics as an option, and their replication technique is similar to ours.", "num_citations": "17\n", "authors": ["531"]}
{"title": "Fragment reconstruction: Providing global cache coherence in a transactional storage system\n", "abstract": " Cooperative caching is a promising technique to avoid the increasingly formidable disk bottleneck problem in distributed storage systems; it reduces the number of disk accesses by servicing client cache misses from the caches of other clients. However, existing cooperative caching techniques do not provide adequate support for fine grained sharing. We describe a new storage system architecture, split caching, and a new cache coherence protocol, fragment reconstruction, that combine cooperative caching with efficient support for fine grained sharing and transactions. We also present the results of performance studies that show that our scheme introduces little overhead over the basic cooperative caching mechanism and provides better performance when there is fine grained sharing.", "num_citations": "15\n", "authors": ["531"]}
{"title": "Hybrid Caching for Large-Scale Object Systems\n", "abstract": " Object-based client caching allows clients to keep more frequently accessed objects while discarding colder objects that reside on the same page. However, when these objects are modified and sent to the server, it may need to read the corresponding page from disk to install the update. These installation reads are not required with a page-based cache because whole pages are sent to the server.             We describe a hybrid system that permits clients to cache objects and pages. The system uses a simple cache design that combines the best of object caching and page caching. The client increases its cache hit ratio as in object-based caching. The client avoids some installation reads by sending pages to the server when possible. Using simulated workloads we explore the performance of our design and show that it can offer a significant performance improvement over both pure object caching and pure\u00a0\u2026", "num_citations": "14\n", "authors": ["531"]}
{"title": "Opportunities for optimism in contended main-memory multicore transactions\n", "abstract": " Optimistic concurrency control, or OCC, can achieve excellent performance on uncontended workloads for main-memory transactional databases. Contention causes OCC's performance to degrade, however, and recent concurrency control designs, such as hybrid OCC/locking systems and variations on multiversion concurrency control (MVCC), have claimed to outperform the best OCC systems. We evaluate several concurrency control designs under varying contention and varying workloads, including TPCC, and find that implementation choices unrelated to concurrency control may explain much of OCC's previously-reported degradation. When these implementation choices are made sensibly, OCC performance does not collapse on high-contention TPC-C. We also present two optimization techniques, commit-time updates and timestamp splitting, that can dramatically improve the high-contention performance\u00a0\u2026", "num_citations": "13\n", "authors": ["531"]}
{"title": "Ownership types and safe lazy upgrades in object-oriented databases\n", "abstract": " This paper describes a novel mechanism for upgrading objects in an object-oriented database. Unlike earlier systems, our mechanism is expressive, supporting a rich set of upgrades; it is efficient and does not stop application access to run an upgrade; it avoids making copies of the database; yet it provides good semantics. Expressive efficient upgrades can lead to problems for the code that upgrades objects. For example, the code might observe broken invariants or interfaces unknown at the time it was written. The paper shows how to use a variant of ownership types to avoid such problems and enable programmers to reason about the correctness of their upgrades. Our approach to correctness is novel, and is a significant contribution of this paper.This paper also presents a new ownership type system. Previous ownership type systems only supported a weak encapsulation property. Enforcing object encapsulation, while supporting subtyping and paradigms like iterators, has been an open problem. Our type system provides a satisfactory solution to this open problem. The novel idea is that we handle inner classes specially\u2014our type system allows objects of inner classes to have privileged access to the representations of the corresponding objects of the outer classes. This principled violation of encapsulation allows programmers to express paradigms like iterators, yet they can reason locally about program correctness.", "num_citations": "13\n", "authors": ["531"]}
{"title": "How to scale transactional storage systems\n", "abstract": " Applications of the future will need to support large numbers of clients and will require scalable storage systems that allow state to be shared reliably. Recent research in distributed file systems provides technology that increases the scalability of storage systems. But file systems only support sharing with weak consistency guarantees and can not support applications that require transactional consistency. The challenge is how to provide scalable storage systems that support transactional applications. We are developing technology for scalable transactional storage systems. Our approach combines scalable caching and coherence techniques developed in serverless file systems and DSM systems, with recovery techniques developed in traditional databases. This position paper describes the design rationale for split caching, a new scalable memory management technique for network-based transactional object\u00a0\u2026", "num_citations": "13\n", "authors": ["531"]}
{"title": "On the complexity of computation in the presence of link failures: the case of a ring\n", "abstract": " We investigate the message complexity of distributed computations on rings of asynchronous processors. In such computations, each processor has an initial local value and the task is to compute some predetermined function of all local values. Our work deviates from previous works concerning the complexity of ring computations in that we consider the effect oflink failures. A link is said to fail if some message sent through it never reaches its destination. We show that the message complexity of any function, which is \u201csensitive to all its inputs\u201d, is \u0398 (n logn) whenn, the number of processors, is a-priori known; and is \u0398(n                    2                 ) whenn is not known. Interestingly, these tight bounds do not depend on whether the identity of a leader is a-priori known before the computation starts. These results stand in sharp contrast to the situation in asynchronous rings with no link failures, where the message\u00a0\u2026", "num_citations": "13\n", "authors": ["531"]}
{"title": "A replicated Unix file system\n", "abstract": " Our work is most similar in its goals to [6], but we use a general replication algorithm tailored to this application rather than building on top of an existing replication technique; we expect to achieve better performance in this way. We differ from the work on Coda [11] because we take the NFS/Unix file system semantics as a given, and because we are not willing to implement front ends on client machines. We also differ from the work on Echo [5] for these reasons, although Echo will support Unix file system semantics as an option, and their replication technique is similar to ours.", "num_citations": "13\n", "authors": ["531"]}
{"title": "Trust but check: Mutable objects in untrusted cooperative caches\n", "abstract": " Cooperative caching is known to be an effective technique for improving the performance of large scale distributed storage systems (5, 6, 7, 11, 1]. Nevertheless, current cooperative caching techniques work only in environments when machines trust one other, a requirement that is likely to become more and more difficult to satisfy. We describe a novel technique for managing cooperative caches in an untrusted environment. Our principal innovation is a new way to update objects on pages in untrusted caches while guaranteeing page integrity.", "num_citations": "11\n", "authors": ["531"]}
{"title": "Opportunistic log: Efficient installation reads in a reliable storage server\n", "abstract": " In a distributed storage system, client caches managed on the basis of small granularity objects can provide better memory utilization then page-based caches. However, object servers, unlike page servers, must perform additional disk reads. These installation reads are required to install modified objects onto their corresponding disk pages. The opportunistic log is a new technique that significantly reduces the cost of installation reads. It defers the installation reads, removing them from the modification commit path, and manages a large pool of pending installation reads that can be scheduled efficiently.Using simulations, we show that the opportunistic log substantially enhances the I/O performance of reliable storage servers. An object server without the opportunistic log requires much better client caching to outperform a page server. With an opportunistic log, only a small client cache improvement suffices.", "num_citations": "11\n", "authors": ["531"]}
{"title": "The language-independent interface of the Thor persistent object system\n", "abstract": " Thor is a new object-oriented database system being developed at MIT. It allows applications written in di erent programming languages, and possibly running on heterogeneous machines and operating systems, to share objects conveniently. Our goal is to provide safe sharing of objects with higher-level semantics than is typical for today's le systems and databases, while still providing good performance. This paper describes the interface of Thor and also discusses some of the implementation techniques we are using to achieve our performance goal.", "num_citations": "10\n", "authors": ["531"]}
{"title": "Shared data management needs adaptive methods\n", "abstract": " Object-based client caching allows clients to keep more frequently accessed objects while discarding colder objects that reside on the same page. However, when these objects are modified and sent to the server, it may need to read the corresponding page from disk to install the update. These 'installation reads' are not required with a page-based cache because whole pages are sent to the server. The relative effectiveness of the two cache techniques depends crucially on the application workload and on the object layout on pages. In a large system, when many applications share data objects, customizing cache management to either an object-based or a page-based configuration may not be optimal to any of the applications. We describe a hybrid system that permits clients to cache objects and pages. The system uses a simple cache design that combines the best of object caching and page caching. The client\u00a0\u2026", "num_citations": "9\n", "authors": ["531"]}
{"title": "Opportunisic Log: Efficient Reads in a Reliable Object Server\n", "abstract": " Object servers offer the potential of improved client caching. However, in comparison to page servers, object servers must perform additional disk reads. These installation reads are required to install modified objects onto their corresponding disk pages. In this paper, we introduce the opportunistic log: a new technique that significantly reduces the cost of these installation reads in object servers. The opportunistic log provides a large pool of pending installation reads that can be scheduled efficiently. Using simulations, we show that the opportunistic log substantially enhances the performance of reliable object servers. An object server without the opportunistic log requires much better client caching to outperform a page server. With an opportunistic log, only a small client cache improvement suffices. Our results affect the fundamental design choice between page-based and object-based servers and imply that efficient scheduling of installation reads is important in future disk design.", "num_citations": "9\n", "authors": ["531"]}
{"title": "Time travel in the virtualized past: Cheap fares and first class seats\n", "abstract": " \u201cTime travel\u201d in the storage system is accessing past storage system states. Legacy application programs could run transparently over the past states if the past states were virtualized in a form that makes them look like the current state. There are many levels in the storage system at which past state virtualization could occur. How do we choose? We think that past state virtualization should occur at a high storage system buffer manager level, such as database buffer manager. Everything above this level can run legacy programs. The system below can manage the mechanisms needed to implement the virtualization. This approach can be applied to any kind of storage system, ranging from traditional databases and file systems to the new generation of specialized storage managers such as Bigtable. Granted that time travel is a desirable feature, this position paper considers the design axis for virtualizing past states for time travel, and asks what amounts to the question, can we sit in first class and still have cheap fares?", "num_citations": "8\n", "authors": ["531"]}
{"title": "Electing a leader in the presence of faults: A ring as a special case\n", "abstract": " We consider the problem of electing a leader in a network consisting of links which may fail. In particular, we study the special case in which the network is a ring of n-processors (and one of its links may fail). We present an O (n logn) algorithm for electing a leader in such a\" faulty\" ring.", "num_citations": "8\n", "authors": ["531"]}
{"title": "An Experimental Implementation of CSP.\n", "abstract": " The paper describes an experimental implement-ation of CSP-a high level language for distribut-ed programming. The implementation consists of a compiler translating into a specially designed intermediate laguage, whose execution is done in two levels: local code interpretation for sequence ing and local computation and an asymmetric dis-tributed handshaking protocol for handling inter-process communication. The paper stresses the handling of the novel features of CSP, especially the use of communication commands as guards in guarded commands. tions arised. Most of today's available languages lack this particular mechanism, or the available mechanism is unsatisfactory (PL/I), or the mechanism is strongly oriented towards a shared variable implementation (Concurrent PAS CAL (BH77], MODULA [W77]). A number of new proposals for suitable programming languages were recently made-ADA (DOD79],", "num_citations": "7\n", "authors": ["531"]}
{"title": "Safe lazy software upgrades in object-oriented databases\n", "abstract": " \u0427 \u0438\u0419\u0433\u0436 \u0432\u0438 \u0438 \u0437 \u0437 \u0430\u0430\u0433\u043b \u0433 \u0438\u0437 \u0438 \u0438 \u0436 \u0431 \u0419 \u0432 \u0434\u0439\u0430 \u0438 \u043d \u0434\u0436\u0433 \u0436 \u0431\u0437 \u0438\u0433 \u0437\u0438\u0433\u0436 \u0436 \u0430 \u0430\u043d \u0437\u0433 \u0438 \u0438 \u0438 \u043d \u0432 \u0439\u0437 \u0432 \u0430 \u0438 \u0436 \u0432 \u0437 \u0436 \u043b \u0438 \u0433\u0438 \u0436 \u0434\u0436\u0433 \u0436 \u0431\u0437\u041a \u042b \u0432 \u0433 \u0438\u0437 \u0432 \u0438 \u0427\u0427 \u0431 \u043d \u0430 \u043a \u0430\u0433\u0432 \u0438 \u0431 \u0418 \u0438 \u0436 \u0431 \u043d \u0432 \u0438\u0433 \u0439\u0434 \u0436 \u0438 \u0431 \u0438\u0433 \u0432 \u0438 \u0436 \u0433 \u0432 \u0437\u0438\u0433\u0436 \u0436 \u0434\u0436 \u0437 \u0432\u0438 \u0438 \u0433\u0432\u041a \u042c \u0437 \u0434 \u0434 \u0436 \u0437 \u0436 \u0437 \u0438 \u0419 \u0432 \u0435\u0439 \u0433\u0436 \u0439\u0434 \u0436 \u0432 \u0433 \u0438\u0437 \u0432 \u0432 \u0427\u0427 \u041a \u042c \u0434\u0434\u0436\u0433 \u0434\u0436 \u0437 \u0436\u043a \u0437 \u0438 \u0438 \u0437 \u0437\u0438 \u0438 \u043d \u0438\u0436 \u0432\u0437 \u0433\u0436\u0431 \u0432 \u0433 \u0438\u0437 \u0438\u0433 \u0438 \u0436 \u0432 \u043b \u0430 \u0437\u0437 \u0437 \u043b \u0430 \u0436 \u0438 \u0432 \u0432 \u0438 \u0436 \u0437\u0438 \u0438 \u0432 \u0438 \u0436 \u0432\u0438 \u0438\u043d\u041a \u042c \u0434\u0434\u0436\u0433 \u0437 \u0426 \u0432\u0438 \u043b \u0433 \u0432\u0433\u0438 \u0432\u0438 \u0436\u0436\u0439\u0434\u0438 \u0434\u0434\u0430 \u0438 \u0433\u0432 \u043c \u0439\u0438 \u0433\u0432 \u0438\u0433 \u0436\u0439\u0432 \u0432 \u0439\u0434 \u0436 \u0418 \u0439\u0438 \u0432\u0437\u0438 \u0436\u0439\u0432 \u0438 \u0439\u0434 \u0436 \u0432 \u0436 \u0431 \u0432\u0438 \u0430\u0430\u043d\u0418 \u0433\u0432 \u0438\u0436 \u0432\u0437 \u0433\u0436\u0431 \u0438 \u0438 \u0431 \u041a \u0427 \u0438\u0437 \u0436 \u0438\u0436 \u0432\u0437 \u0433\u0436\u0431 \u0430 \u043e \u0430\u043d\u0418 \u0439\u0438 \u0439\u0437\u0438 \u0432 \u0438 \u0431 \u0434\u0434\u0430 \u0419 \u0438 \u0433\u0432\u0437 \u0432 \u043a \u0436 \u0433 \u0437 \u0436\u043a \u0432\u0433\u0432\u0419\u0439\u0434 \u0436 \u0433 \u0438\u0437\u041a \u0424 \u043e \u0432 \u0437\u0437 \u0432 \u0437\u0433\u0431 \u0438 \u0431 \u0437 \u0430 \u0438\u0433 \u0434\u0436\u0433 \u0430 \u0431\u0437 \u0433\u0436 \u0438 \u0433 \u0438 \u0438 \u0438\u0436 \u0432\u0437 \u0433\u0436\u0431\u0437 \u0433 \u0438\u0437\u0418 \u0433\u043b \u043a \u0436 \u041a \u041a\u0418 \u0438\u0436 \u0432\u0437 \u0433\u0436\u0431 \u0431 \u0438 \u0433 \u0437 \u0436\u043a \u0436\u0433 \u0432 \u0432\u043a \u0436 \u0432\u0438\u0437 \u0433\u0436 \u0432\u0438 \u0436 \u0437 \u0439\u0432 \u0432\u0433\u043b\u0432 \u0438 \u0438 \u0438 \u0431 \u0438 \u043b \u0437 \u043b\u0436 \u0438\u0419 \u0438 \u0432\u041a \u042f \u040c\u0432 \u0434\u0436 \u0437 \u0430\u043d \u043b \u0432 \u0438 \u0437 \u0434\u0436\u0433 \u0430 \u0431\u0437 \u0436 \u0437 \u0418 \u0432 \u043b \u0430\u0437\u0433 \u0434\u0436\u0433\u043a \u0431 \u0432 \u0437\u0431\u0437 \u0433\u0436 \u043a\u0433 \u0432 \u0438 \u0431\u041a \u0427\u0439\u0436\u0437 \u0437 \u0438 \u040c\u0436\u0437\u0438 \u043b\u0433\u0436 \u0438\u0433 \u0434\u0436\u0433\u043a \u0439\u0430\u0430 \u0432 \u0430\u043d\u0437 \u0437 \u0433 \u0438 \u0437 \u0434\u0436\u0433 \u0419 \u0430 \u0431\u0437 \u0432 \u0438\u0433 \u0430\u0430\u0433\u043b \u0437 \u0430 \u043e\u043d \u0439\u0434 \u0436 \u0437 \u043a \u0432 \u043b \u0432 \u0434\u0436\u0433 \u0419 \u0430 \u0431\u0437 \u0436 \u0437 \u041a \u042f \u043a \u0431\u0434\u0430 \u0431 \u0432\u0438 \u0433\u0439\u0436 \u0434\u0434\u0436\u0433 \u0433\u0432 \u0438 \u042c \u0433\u0436 \u0427\u0427 \u0432 \u043b \u0434\u0436 \u0437 \u0432\u0438 \u0434 \u0436 \u0433\u0436\u0431 \u0432 \u0436 \u0437\u0439\u0430\u0438\u0437 \u0438 \u0438 \u0437 \u0433\u043b \u0438 \u0438 \u0438 \u0433\u043a \u0436 \u0433 \u0433\u0439\u0436 \u0432 \u0436 \u0437\u0438\u0436\u0439 \u0438\u0439\u0436 \u0437 \u0430\u0433\u043b\u041a", "num_citations": "6\n", "authors": ["531"]}
{"title": "Methodological construction of reliable distributed algorithms\n", "abstract": " The problem of designing distributed algorithms which operate in the presence of undetectable link failures is considered. A methodology is suggested for transforming distributed algorithms into reliable algorithms. The transformation is considered at two levels: reliable transmission through every single link, and as an alternative a reliable implementation of high level communication primitives. Application of the suggested methodology yields reliable implementation for distributed termination and k-selection.", "num_citations": "6\n", "authors": ["531"]}
{"title": "RQL: Retrospective Computations over Snapshot Sets.\n", "abstract": " Applications need to analyze the past state of their data to provide auditing and other forms of fact checking. Retrospective snapshot systems that support computations over data store snapshots, allow applications using simple data stores like Berkeley DB or SQLite, to provide past state analysis in a convenient way. Current snapshot systems however, offer no satisfactory support for computations that analyze multiple snapshots. We have developed a Retrospective Query Language (RQL), a simple declarative extension to SQL that allows to specify and run multi-snapshot computations conveniently in a snapshot system, using a small number of simple mechanisms defined in terms of relational constructs familiar to programmers. We describe RQL mechanisms, explain how they translate into SQL computations in a snapshot system, and show how to express a number of common analysis patterns with illustrative examples. We also describe how we implemented RQL in a simple way utilizing SQLite UDF framework in a Berkeley DB data store using Retro page-level incremental snapshot system. Multi-snapshot computations running over page-level incremental snapshots bring up interesting performance issues that have not been studied before. We present the first study defining a performance envelope for multi-snapshot computations over page-level incremental snapshots.", "num_citations": "3\n", "authors": ["531"]}
{"title": "Mx: Mobile object exchange for collaborative applications\n", "abstract": " MX is a new mobile caching system for collaborative applications accessing data residing in large storage repositories. MX supports mobile exchange \u2013 a direct user-to-user object transfer. Mobile exchange (MX) makes mobile computing more effective because it enables certain kinds of collaborative work that would be impossible otherwise. MX allows disconnected peers to learn of recent unknown updates, and to apply these updates to locally-cached data. MX validates the exchange, merging the more recent and modified data. MX combines efficient support for coarse-grained data transfer with efficient fine-grained validation, in a way that avoid the problem of false sharing. Performance evaluation of the MX prototype indicates that for transactional applications, the extra cost required to support mobile exchange is moderate. Moreover, the extra cost is offset by the cost of accessing remote repositories\u00a0\u2026", "num_citations": "3\n", "authors": ["531"]}
{"title": "Escaping the disk bottleneck in fast transaction processing\n", "abstract": " An approach to avoiding the disk access bottleneck for transaction processing applications is described. The approach is based on the use of primary copy replication, and takes advantage of recent hardware advances such as inexpensive high-speed CPUs and networks, and uninterruptable power supplies. In addition to improving response time, the architecture increases overall availability and reliability. The work described is in a preliminary stage. The overall architecture and its motivation are discussed. File system techniques in the context of transaction processing are reported.< >", "num_citations": "3\n", "authors": ["531"]}
{"title": "Fragment Reconstruction: A New Cache Coherence Scheme for Split Caching Storage Systems\n", "abstract": " Fragment reconstruction is a cache coherence protocol for transactional storage systems based on global caching in a network of workstations. It supports fine-grained sharing and works in the presence of object-based concurrency control algorithm. When transactions commit new versions of objects, stale cached copies of these objects get invalidated. Therefore, pages in a client's cache may become fragments, ie contain\" holes\u201d corresponding to invalid objects. When such a page is used in the global cache, the coherence protocol fills in the holes using modifications stored in a recoverable cache at the server.Fragment reconstruction is the first coherence protocol that supports fine-grained sharing and global caching in transactional storage systems. Because it is integrated with the recoverable modification cache, it works correctly even in the presence of client failures, and can take advantage of lazy update propagation and update absorption, which is beneficial when pages are updated repeatedly. This paper describes the fragment reconstruction protocol and presents its correctness invariant wich insures that only correctly reconstructed fragments are propagated to the database.", "num_citations": "2\n", "authors": ["531"]}
{"title": "Hybrid Caching for Scalable Object Systems (Think Globally, Act Locally)\n", "abstract": " Object-based client caching allows clients to keep more frequently accessed objects while discarding colder objects that reside on the same page. However, when these objects are modified and sent to the server, it may need to read the corresponding page from disk to install the update. These installation reads...", "num_citations": "2\n", "authors": ["531"]}
{"title": "Proving Noninteraction: An Optimized Approach\n", "abstract": " A recent work of Elrad and Francez introduces a novel methodology of analyzing distributed programs: decomposition into communication closed layers ie no interaction occurs between layers. This work proposes an optimization to the formal proof of layer non-interaction. The proof is localized to the bodies of component layers only. By this, the number of possible interaction cases to be considered in the proof is reduced substantially. Our main result contains a definition of new localized communication closeness and a suggestion of a sound and complete proof rule for proving layer non-interaction. The proof rule is maximaly efficient in the sense that it makes use only of the correctness proof of the layer itself. The obtained result, in addtion to program analysis, also sheds new light on the use of closed layer methodology in the construction of distributed programs.", "num_citations": "2\n", "authors": ["531"]}
{"title": "The Impact of Timestamp Granularity in Optimistic Concurrency Control\n", "abstract": " Optimistic concurrency control (OCC) can exploit the strengths of parallel hardware to provide excellent performance for uncontended transactions, and is popular in high-performance in-memory databases and transactional systems. But at high contention levels, OCC is susceptible to frequent aborts, leading to wasted work and degraded performance. Contention managers, mixed optimistic/pessimistic concurrency control algorithms, and novel optimistic-inspired concurrency control algorithms, such as TicToc, aim to address this problem, but these mechanisms introduce sometimes-high overheads of their own. We show that in real-world benchmarks, traditional OCC can outperform these alternative mechanisms by simply adding fine-grained version timestamps (using different timestamps for disjoint components of each record). With fine-grained timestamps, OCC gets 1.14x TicToc's throughput in TPC-C at 128 cores (previous work reported TicToc having 1.8x higher throughput than OCC at 80 hyperthreads). Our study shows that timestamp granularity has a greater impact than previously thought on the performance of transaction processing systems, and should not be overlooked in the push for faster concurrency control schemes.", "num_citations": "1\n", "authors": ["531"]}
{"title": "Skippy: Enabling long-lived snapshots of the long-lived past\n", "abstract": " Decreasing disk costs have made it practical to retain long- lived snapshots, enabling new applications that analyze past states and infer about future states. Current approaches offer no satisfactory way to organize long-lived snapshots because they disrupt the database in either short or long run. Split snapshots are a recent approach that overcomes some of the limitations. An unsolved problem has been how to support efficient application code access to arbitrarily long-lived snapshots. We describe Skippy, a new approach that solves this problem. Performance evaluation of Skippy, based on theoretical analysis and experimental measurements, indicates that the new approach is effective and efficient.", "num_citations": "1\n", "authors": ["531"]}
{"title": "Exosnap: a modular approach to semantic synchronization and snapshots\n", "abstract": " Current approaches to application-specific synchronization suffer from a limitation that precludes the use of generic\" commodity\" servers because they require to run the type-specific synchronization code at the servers. This is a problem for\" cloud computing\" systems that must rely on commodity components to exploit economies of scale yet need to adapt to application needs to provide good performance. We describe a new approach that overcomes the limitation. The new approach splits the synchronization code, so that the type-specific code runs outside the server, on the client side, and the generic performance-critical code runs in the server. New type-specific synchronization protocols can be developed without modifying the servers, providing the ability to use commodity servers.", "num_citations": "1\n", "authors": ["531"]}
{"title": "Hq replication: Properties and optimizations\n", "abstract": " There are currently two approaches to providing Byzantine-fault-tolerant state machine replication: a replica-based approach, e.g., BFT, that uses communication between replicas to agree on a proposed ordering of requests, and a quorum-based approach, such as Q/U, in which clients contact replicas directly to optimistically execute operations. Both approaches have shortcomings: the quadratic cost of inter-replica communication is unnecessary when there is no contention, and Q/U requires a large number of replicas and performs poorly under contention.We present HQ, a hybrid Byzantine-fault-tolerant state machine replication protocol that overcomes these problems. HQ employs a lightweight quorum-based protocol when there is no contention, but  uses BFT to resolve contention when it arises.  Furthermore, HQ uses only 3f+1 replicas to tolerate f faults, providing optimal resilience to node failures.We implemented a prototype of HQ, and we compare its performance to BFT and Q/U analytically and experimentally. Additionally, in this work we use a new implementation of BFT designed to scale as the number of faults increases.  Our results show that both HQ and our new implementation of BFT scale as f increases; additionally our hybrid approach of using BFT to handle contention works well.", "num_citations": "1\n", "authors": ["531"]}
{"title": "Buddycache: Cache coherence for transactional peer group applications\n", "abstract": " Universal network access has enabled a new class of distributed applications that allow collaborating peers to share cached data. Until now these applications had basic limitations: sharing was limited to read-only access, networks were limited to local area networks, and there was no support for fine-grained sharing or transactions. BuddyCache is a caching system for peer applications that provides updates to shared data from remote repositories. BuddyCache is the first system to provide transactional fine-grain coherence in high-latency networks. It provides consistent, low-latency access to shared objects cached by peers when consistency management requires coordination with remote repositories over high-latency wide-area networks.", "num_citations": "1\n", "authors": ["531"]}
{"title": "Efficient Recovery in Harp.\n", "abstract": " Harp is a replicated Unix file system accessible via the VFS interface. It provides highly available and reliable storage for files and guarantees that file operations are executed atomically in spite of concurrency and failures. Replication enables Harp to safely trade disk accesses for network communication and thus to provide good performance both during normal operation and during recovery. In this position statement, we focus on the techniques Harp uses to achieve efficient recovery.", "num_citations": "1\n", "authors": ["531"]}