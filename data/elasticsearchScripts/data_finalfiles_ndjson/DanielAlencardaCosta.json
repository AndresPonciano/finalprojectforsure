{"title": "The impact of refactoring changes on the szz algorithm: An empirical study\n", "abstract": " SZZ is a widely used algorithm in the software engineering community to identify changes that are likely to introduce bugs (i.e., bug-introducing changes). Despite its wide adoption, SZZ still has room for improvements. For example, current SZZ implementations may still flag refactoring changes as bug-introducing. Refactorings should be disregarded as bug-introducing because they do not change the system behaviour. In this paper, we empirically investigate how refactorings impact both the input (bug-fix changes) and the output (bug-introducing changes) of the SZZ algorithm. We analyse 31,518 issues of ten Apache projects with 20,298 bug-introducing changes. We use an existing tool that automatically detects refactorings in code changes. We observe that 6.5% of lines that are flagged as bug-introducing changes by SZZ are in fact refactoring changes. Regarding bug-fix changes, we observe that 19.9% of\u00a0\u2026", "num_citations": "37\n", "authors": ["1116"]}
{"title": "The impact of changes mislabeled by szz on just-in-time defect prediction\n", "abstract": " Just-in-Time (JIT) defect prediction\u2014a technique which aims to predict bugs at change level\u2014has been paid more attention. JIT defect prediction leverages the SZZ approach to identify bug-introducing changes. Recently, researchers found that the performance of SZZ (including its variants) is impacted by a large amount of noise. SZZ may considerably mislabel changes that are used to train a JIT defect prediction model, and thus impact the prediction accuracy. In this paper, we investigate the impact of the mislabeled changes by different SZZ variants on the performance and interpretation of JIT defect prediction models. We analyze four SZZ variants (ie, B-SZZ, AG-SZZ, MA-SZZ, and RA-SZZ) that are proposed by prior studies. We build the prediction models using the labeled data by these four SZZ variants. Among the four SZZ variants, RA-SZZ is least likely to generate mislabeled changes, and we construct the testing set by using RA-SZZ. All of the four prediction models are then evaluated on the same testing set. We choose the prediction model built on the labeled data by RA-SZZ as the baseline model, and we compare the performance and metric importance of the models trained using the labeled data by the other three SZZ variants with the baseline model. Through a large-scale empirical study on a total of 126,526 changes from ten Apache open source projects, we find that in terms of various performance measures (AUC, F1-score, G-mean and Recall@ 20%), the mislabeled changes by B-SZZ and MA-SZZ are not likely to cause a considerable performance reduction, while the mislabeled changes by AG-SZZ cause a statistically\u00a0\u2026", "num_citations": "27\n", "authors": ["1116"]}
{"title": "Studying the impact of adopting continuous integration on the delivery time of pull requests\n", "abstract": " Continuous Integration (CI) is a software development practice that leads developers to integrate their work more frequently. Software projects have broadly adopted CI to ship new releases more frequently and to improve code integration. The adoption of CI is motivated by the allure of delivering new functionalities more quickly. However, there is little empirical evidence to support such a claim. Through the analysis of 162,653 pull requests (PRs) of 87 GitHub projects that are implemented in 5 different programming languages, we empirically investigate the impact of adopting CI on the time to deliver merged PRs. Surprisingly, only 51.3% of the projects deliver merged PRs more quickly after adopting CI.We also observe that the large increase of PR submissions after CI is a key reason as to why projects deliver PRs more slowly after adopting CI. To investigate the factors that are related to the time-to-delivery of\u00a0\u2026", "num_citations": "17\n", "authors": ["1116"]}
{"title": "Revisiting and improving szz implementations\n", "abstract": " Background: The SZZ algorithm was proposed to identify bug-introducing changes, i.e., changes that are likely to induce bugs. Previous studies improved its implementation and evaluated its results.Aims: To address existing limitations of SZZ to improve the maturity of the algorithm. We also aim to verify if the improvements that have been proposed to the SZZ algorithm also hold in different datasets.Method: We re-evaluate two recent SZZ implementations using an adaptation of the Defects4J dataset, which works as a preprocessed dataset that can be used by SZZ. Furthermore, we revisit the limitations of RA-SZZ (refactoring aware SZZ) to improve the precision and recall of the algorithm.Results: We observe that a median of 44% of the lines that are flagged by the improved SZZ are very likely to introduce a bug. We manually analyze the SZZ-generated data and observe that there exist refactoring operations (31.17\u00a0\u2026", "num_citations": "11\n", "authors": ["1116"]}
{"title": "Unveiling developers contributions behind code commits: an exploratory study\n", "abstract": " The process and activities of software development are very dynamic and diverse. For instance, source code has to be written, tested and revised, e-mails have to be sent, bugs have to be communicated, managed and fixed. As a consequence, the contributions of the developers are very diversified. This paper describes an empirical study whose goal was to assess and compare the contributions of the developers through software repository mining. Two medium-sized projects--an open source and a commercial project--were analyzed. Overall, 17,490 commits and 10,308 bugs reports were analyzed. In the first part of our study, we have classified the developers based on their contribution to the software repository in three groups--core, active and peripheral developers. After that, we have collected a series of metrics--code contribution, buggy commits and resolution of priority bugs--for all the developers of the\u00a0\u2026", "num_citations": "11\n", "authors": ["1116"]}
{"title": "Assessing and evolving a domain specific language for formalizing software engineering experiments: An empirical study\n", "abstract": " The research about the formalization and conduction of controlled experiments in software engineering has reported important insights and guidelines for their organization. However, the computational support to formalize and execute controlled experiments still requires deeper investigation. In this context, this paper presents an empirical study that evaluates a domain-specific language (DSL) proposed to formalize controlled experiments in software engineering. The language is part of a model-driven approach that allows the generation of executable workflows for the experiment participants, according to the statistical design of the experiment. Our study involves the modeling of 16 software engineering experiments to analyze the completeness and expressiveness of the investigated DSL when specifying different controlled experiments. The results highlight several limitations of the DSL that affect the\u00a0\u2026", "num_citations": "7\n", "authors": ["1116"]}
{"title": "Modularizing Software Process Lines using Model-driven Approaches-A Comparative Study.\n", "abstract": " This work presents a comparative study of the usage of compositional and annotational approaches in the modularization of software process lines. In our comparative study, an Open-UP based software process line extracted from three existing projects are modelled and implemented using the compositional and annotative approaches with the main aim to address a systematic variability management and automatic process derivation. The results show that the GenArch-P\u2013annotative approach\u2013can bring many advantages to the modelling of software process lines considering our comparison criteria.", "num_citations": "6\n", "authors": ["1116"]}
{"title": "Software Process Monitoring Using Statistical Process Control Integrated in Workflow Systems.\n", "abstract": " This paper presents an approach that integrates statistical process control techniques with workflow systems in order to achieve software process monitoring. Our approach allows:(i) software process monitoring through the automated metrics collection; and (ii) the statistical process control of software process aided transparently by statistical tools. The use of workflow systems to this integration adds the benefits of statistical process control without the additional effort to integrate and use statistical tools. Our proposal allows project managers to identify problems early during the process execution, enabling quickly reactions (process improvements, training, etc.) to reduce costs and ensure software quality.", "num_citations": "3\n", "authors": ["1116"]}
{"title": "An Empirical Study of the Relationship between Continuous Integration and Test Code Evolution\n", "abstract": " Continuous Integration (CI) is the practice of automating and improving the frequency of code integration. CI has been widely adopted by software development teams and has brought the attention of researchers to study its benefits. Existing research shows that CI can improve software quality by identifying the errors earlier in the software development life-cycle. One question that remains open, however, is whether CI increases the adoption of testing practices in software projects. The goal of our work is to investigate the evolution of software tests and its relationship with the adoption of Continuous Integration. We set out to compare 82 projects that adopted CI (CI projects) and 82 projects that have never adopted CI (NOCI projects). In total, we studied 3,936 versions of our studied projects to investigate trends on the test code ratio and coverage. We observe that 40.2% of the CI projects have a rising test-code ratio\u00a0\u2026", "num_citations": "2\n", "authors": ["1116"]}
{"title": "Leveraging the Defects Life Cycle to Label Affected Versions and Defective Classes\n", "abstract": " Two recent studies explicitly recommend labeling defective classes in releases using the affected versions (AV) available in issue trackers (e.g., Jira). This practice is coined as the realistic approach. However, no study has investigated whether it is feasible to rely on AVs. For example, how available and consistent is the AV information on existing issue trackers? Additionally, no study has attempted to retrieve AVs when they are unavailable. The aim of our study is threefold: (1) to measure the proportion of defects for which the realistic method is usable, (2) to propose a method for retrieving the AVs of a defect, thus making the realistic approach usable when AVs are unavailable, (3) to compare the accuracy of the proposed method versus three SZZ implementations. The assumption of our proposed method is that defects have a stable life cycle in terms of the proportion of the number of versions affected by the\u00a0\u2026", "num_citations": "1\n", "authors": ["1116"]}
{"title": "Understanding the delivery delay of addressed issues in large software projects\n", "abstract": " The timely delivery of addressed software issues (ie, bug fixes, enhancements, and new features) is what drives software development. Previous research has investigated what impacts the time to triage and address (or fix) issues. Nevertheless, even though an issue is addressed, ie, a solution is coded and tested, such an issue may still suffer delay before being delivered to end users. Such delays are frustrating, since end users care most about when an addressed issue is available in the software system (ie, released). In this matter, there is a lack of empirical studies that investigate why addressed issues take longer to be delivered compared to other issues. In this thesis, we perform empirical studies to understand which factors are associated with the delayed delivery of addressed issues. In our studies, we find that 34% to 98% of the addressed issues of the ArgoUML, Eclipse and Firefox projects have their integration delayed by at least one release. Our explanatory models achieve ROC areas above 0.74 when explaining delivery delay. We also find that the workload of integrators and the moment at which an issue is addressed are the factors with the strongest association with delivery delay. We also investigate the impact of rapid release cycles on the delivery delay of addressed issues. Interestingly, we find that rapid release cycles of Firefox are not related to faster delivery of addressed issues. Indeed, although rapid release cycles address issues faster than traditional ones, such addressed issues take longer to be delivered. Moreover, we find that rapid releases deliver addressed issues more consistently than traditional ones. Finally, we\u00a0\u2026", "num_citations": "1\n", "authors": ["1116"]}