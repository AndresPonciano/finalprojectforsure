{"title": "A task oriented view of software visualization\n", "abstract": " A number of taxonomies to classify and categorize software visualization systems have been proposed in the past. Most notable are those presented by Price (1993) and Roman (1993). While these taxonomies are an accurate representation of software visualization issues, they are somewhat skewed with respect to current research areas on software visualization. We revisit this important work and propose a number of re-alignments with respect to addressing the software engineering tasks of large-scale development and maintenance. We propose a framework to emphasize the general tasks of understanding and analysis during development and maintenance of large-scale software systems. Five dimensions relating to the what, where, how, who, and why of software visualization make up this framework. The focus of this work is not so much as to classify software visualization system, but to point out the need for\u00a0\u2026", "num_citations": "240\n", "authors": ["78"]}
{"title": "Supporting source code difference analysis\n", "abstract": " The paper describes an approach to easily conduct analysis of source-code differences. The approach is termed meta-differencing to reflect the fact that additional knowledge of the differences can be automatically derived. Meta-differencing is supported by an underlying source-code representation developed by the authors. The representation, srcML, is an XML format that explicitly embeds abstract syntax within the source code while preserving the documentary structure as dictated by the developer. XML tools are leveraged together with standard differencing utilities (i.e., diff,) to generate a meta-difference. The meta-difference is also represented in an XML format called srcDiff. The meta-difference contains specific syntactic information regarding the source-code changes. In turn this can be queried and searched with XML tools for the purpose of extracting information about the specifics of the changes. A case\u00a0\u2026", "num_citations": "129\n", "authors": ["78"]}
{"title": "Supporting document and data views of source code\n", "abstract": " The paper describes the use of an XML format to store and represent program source code. A new XML application, srcML (SouRCe Markup Language), is presented. srcML presumes a document view of source code where information about the syntactic structure is layered over the original source code document. The resultant multi-layered document has a base layer of all the original text (and formatting). The second layer is the syntactic information, derived from the grammar of the programming language, and is encoded in XML. This multi-layered view supports both the creation and viewing of the source code in its original form and the use of XML technologies (for tasks such as analysis and transformation of the source). Although directed at source code documents,(particularly C++) srcML is also applicable to other programming languages and to languages with a strict syntax. srcML represents a departure\u00a0\u2026", "num_citations": "88\n", "authors": ["78"]}
{"title": "Improving feature location by enhancing source code with stereotypes\n", "abstract": " A novel approach to improve feature location by enhancing the corpus (i.e., source code) with static information is presented. An information retrieval method, namely Latent Semantic Indexing (LSI), is used for feature location. Adding stereotype information to each method/function enhances the corpus. Stereotypes are terms that describe the abstract role of a method, for example get, set, and predicate are well-known method stereotypes. Each method in the system is automatically stereotyped via a static-analysis approach. Experimental comparisons of using LSI for feature location with, and without, stereotype information are conducted on a set of open-source systems. The results show that the added information improves the recall and precision in the context of feature location. Moreover, the use of stereotype information decreases the total effort that a developer would need to expend to locate relevant methods\u00a0\u2026", "num_citations": "49\n", "authors": ["78"]}
{"title": "A lightweight transformational approach to support large scale adaptive changes\n", "abstract": " An approach to automate adaptive maintenance changes on large-scale software systems is presented. This approach uses lightweight parsing and lightweight on-the-fly static analysis to support transformations that make corrections to source code in response to adaptive maintenance changes, such as platform changes. SrcML, an XML source code representation, is used and transformations can be performed using either XSLT or LINQ. A number of specific adaptive changes are presented, based on recent adaptive maintenance needs from products at ABB Inc. The transformations are described in detail and then demonstrated on a number of examples from the production systems. The results are compared with manual adaptive changes that were done by professional developers. The approach performed better than the manual changes, as it successfully transformed instances missed by the developers\u00a0\u2026", "num_citations": "39\n", "authors": ["78"]}
{"title": "srcSlice: very efficient and scalable forward static slicing\n", "abstract": " A highly efficient lightweight forward static slicing approach is presented and evaluated. The approach does not compute the program/system dependence graph but instead dependence and control information is computed as needed while computing the slice on a variable. The result is a list of line numbers, dependent variables, aliases, and function calls that are part of the slice for all variables (both local and global) for the entire system. The method is implemented as a tool, called srcSlice, on top of srcML, an XML representation of source code. The approach is highly scalable and can generate the slices for all variables of the Linux kernel in approximately 20\u2009min on a typical desktop. Benchmark results are compared with the CodeSurfer slicing tool from GrammaTech Inc., and the approach compares well with regard to accuracy of slices. Copyright \u00a9 2014 John Wiley & Sons, Ltd.", "num_citations": "30\n", "authors": ["78"]}
{"title": "Addressing source code using srcml\n", "abstract": " The plain-text representation of source code is limited in addressing locations in the source code, providing context to locations, and integrating higher-level information such as from source models. The representation, srcML, attempts to solve these problems by providing an enhanced, XML view of the source code while at the same time preserving the current textual view. This paper discusses the problems that the plaintext representation has, and the philosophy behind srcML, which provides a rich addressing language to source code. The intent is to further the discussion of what is needed to enhance textual views of source code for comprehension.", "num_citations": "28\n", "authors": ["78"]}
{"title": "Meta-differencing: An infrastructure for source code difference analysis\n", "abstract": " The dissertation proposes, realizes, and validates a novel approach for the representation and analysis of differences between source-code documents. The approach is termed meta-differencing as it supports the derivation of high-level facts about differences from differences. By using meta-differencing questions such as \u201cWhat types of changes were made to a program?\u201d or \u201cWas a specific program entity changed?\u201d can be mechanically answered. Questions about the context of those changes can also be addressed. Importantly, it allows these types of questions to be answered from a syntactic, structural, or documentary perspective. This is almost impossible to do with current methods and is typically done by manual inspection. Additionally, the answers to these questions are in a form suitable for further processing of the source code and their differences. This research directly supports engineers in software\u00a0\u2026", "num_citations": "16\n", "authors": ["78"]}
{"title": "A slice-based estimation approach for maintenance effort\n", "abstract": " Program slicing is used as a basis for an approach to estimate maintenance effort. A case study of the GNU Linux kernel with over 900 versions spanning 17 years of history is presented. For each version a system dictionary is built using a lightweight slicing approach and encodes the forward decomposition static slice profiles for all variables in all the files in the system. Changes to the system are then modeled at the behavioral level using the difference between the system dictionaries of two versions. The three different granularities of slice (i.e., line, function, and file) are analyzed. We use a direct extension of srcML to represent computed change information. The retrieved information reflects the fact that additional knowledge of the differences can be automatically derived to help maintainers understand code changes. We consider the hypotheses: (1) The structured format helps create traceability links between\u00a0\u2026", "num_citations": "14\n", "authors": ["78"]}
{"title": "An empirical examination of the prevalence of inhibitors to the parallelizability of open source software systems\n", "abstract": " An empirical study is presented that examines the potential to parallelize general-purpose software systems. The study is conducted on 13 open source systems comprising over 14 MLOC. Each for-loop is statically analyzed to determine if it can be parallelized or not. A for-loop that can be parallelized is termed a free-loop. Free-loops can be easily parallelized using tools such as OpenMP. For the loops that cannot be parallelized, the various inhibitors to parallelization are determined and tabulated. The data shows that the most prevalent inhibitor by far, is functions called within for-loops that have side effects. This single inhibitor poses the greatest challenge in adapting and re-engineering systems to better utilize modern multi-core architectures. This fact is somewhat contradictory to the literature, which is primarily focused on the removal of data dependencies within loops. Results of this paper also show\u00a0\u2026", "num_citations": "12\n", "authors": ["78"]}
{"title": "A tool for efficiently reverse engineering accurate UML class diagrams\n", "abstract": " A tool that reverse engineers UML class diagrams from C++ source code is presented. The tool takes srcML as input and produces yUML as output. srcML is an XML representation of the abstract syntactic information of source code. The srcML parser (srcML.org) is highly scalable, efficient, and robust. yUML is a textual format for UML class diagrams that can be easily rendered into a graphical diagram via a web service (yUML.me) or a tool such as Graphvis. The approach utilizes efficient SAX (Simple API for XML) parsing to collect the information needed to construct the class diagram. Currently it supports the following UML features: differentiating between class, data type, or interface, identifying design level attributes, multiplicity and type, determining parameter direction, and identification of the relationships aggregation, composition, generalization, and realization. The tool produces yUML for all of Calligra (~1\u00a0\u2026", "num_citations": "9\n", "authors": ["78"]}
{"title": "An infrastructure to support meta-differencing and refactoring of source code\n", "abstract": " The proposed research aims to construct an underlying infrastructure to support (semi) automated construction of refactorings and system wide transformation via a fine grained syntax level differencing approach. We term this differencing approach meta-differencing as it has additional knowledge of the types of entities being differenced. The general approach is built on top of an XML representation of the source code, specifically srcXML by J. Maletic et al. (2002). This representation explicitly embeds high level syntactic information within the source code in such a way as to not interfere with program development and maintenance. Because both the source code and the difference are represented in XML, the transformational language, XSLT, can be used to model these changes. We propose to develop an environment (development/maintenance) that automatically generates XSLT programs based on changes to\u00a0\u2026", "num_citations": "9\n", "authors": ["78"]}
{"title": "srcDiff: A syntactic differencing approach to improve the understandability of deltas\n", "abstract": " An efficient and scalable rule\u2010based syntactic differencing approach is presented. The tool srcDiff is built upon the srcML infrastructure. srcML adds abstract syntactic information into the code via an XML format. A syntactic difference of srcML documents is then taken. During this process, the differences are further refined using a set of rules that model typical editing patterns of source code by developers. Thus, the resulting deltas model edits that are programmer centric versus a purely syntactic tree edit view. Other syntactic differencing approaches focus on obtaining an optimal tree edit distance with the assumption that this will produce an accurate difference. While this may work well for small or simple changes, the differences quickly become unreadable for more complex changes. By contrast, the approach presented here purposely deviates from an optimal tree edit difference in order to create a delta that is\u00a0\u2026", "num_citations": "7\n", "authors": ["78"]}
{"title": "The evaluation of an approach for automatic generated documentation\n", "abstract": " Two studies are conducted to evaluate an approach to automatically generate natural language documentation summaries for C++ methods. The documentation approach relies on a method's stereotype information. First, each method is automatically assigned a stereotype(s) based on static analysis and a set of heuristics. Then, the approach uses the stereotype information, static analysis, and predefined templates to generate a natural-language summary/documentation for each method. This documentation is automatically added to the code base as a comment for each method. The result of the first study reveals that the generated documentation is accurate, does not include unnecessary information, and does a reasonable job describing what the method does. Based on statistical analysis of the second study, the most important part of the documentation is the short description as it describes the intended\u00a0\u2026", "num_citations": "4\n", "authors": ["78"]}
{"title": "Textual views of source code to support comprehension\n", "abstract": " Source code can be viewed in many ways, with each view facilitating access to different information contained within the code. We explore the role that marked-up textual views can provide in support of software comprehension and maintenance. Text has the advantages of being easily communicated, effectively manipulated with existing tools, and highly scalable. Furthermore, marked-up text models may improve comprehension by expressing information directly within the context of maintainers' focus - the source code they are manipulating. The session intends to explore the expressibility of marked-up text and its applicability in support of program comprehension tasks. Topics will include: the roles these models fulfill, their limitations, their combination, and the exploration of future research directions.", "num_citations": "2\n", "authors": ["78"]}
{"title": "Working Session: Textual Views of Source Code to Support Comprehension.\n", "abstract": " Source code can be viewed in many ways, with each view facilitating access to different information contained within the code. In this working session, we will explore the role that marked-up textual views can provide in support of software comprehension and maintenance. Text has the advantages of being easily communicated, effectively manipulated with existing tools, and highly scalable. Furthermore, marked-up text models may improve comprehension by expressing information directly within the context of maintainers\u2019 focus\u2013the source code they are manipulating. This session intends to explore the expressibility of marked-up text and its applicability in support of program comprehension tasks. Topics will include: the roles these models fulfill, their limitations, their combination, and the exploration of future research directions.", "num_citations": "2\n", "authors": ["78"]}
{"title": "Adding Structure to Unstructured Text\n", "abstract": " An overview of the authors\u2019 research program in document engineering is presented. Underlying techniques are being developed for agile parsing of unstructured and semi-structured text to extract metadata. XML technologies are leveraged in novel ways to support complex querying, analysis, and transformation of large text bases. New methods for difference analysis are being developed to support document evolution and maintenance. Additionally, advanced information retrieval methods, namely latent semantic indexing, in conjunction with clustering techniques are used to extract high level features and concepts from large corpora.", "num_citations": "2\n", "authors": ["78"]}
{"title": "Enforcing Constraints Between Documentary Comments and Source Code\n", "abstract": " An approach for enforcing constraints between program entities and their documentary comments is presented. The approach uses srcML to represent Java source code and introduces an XML format, namely srcDoc, for marking up Javadoc-style comments. The enforced constraints are specified with a combination of XML and XQuery. An Eclipse plugin is described that demonstrates the use of XML and related technologies to express and enforce constraints on documentary comments. Examples of constraints enforcing design rationale for methods in an API are shown.", "num_citations": "1\n", "authors": ["78"]}