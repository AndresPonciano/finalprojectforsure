{"title": "Solving uncompromising problems with lexicase selection\n", "abstract": " We describe a broad class of problems, called \u201cuncompromising problems,\u201d which are characterized by the requirement that solutions must perform optimally on each of many test cases. Many of the problems that have long motivated genetic programming research, including the automation of many traditional programming tasks, are uncompromising. We describe and analyze the recently proposed \u201clexicase\u201d parent selection algorithm and show that it can facilitate the solution of uncompromising problems by genetic programming. Unlike most traditional parent selection techniques, lexicase selection does not base selection on a fitness value that is aggregated over all test cases; rather, it considers test cases one at a time in random order. We present results comparing lexicase selection to more traditional parent selection methods, including standard tournament selection and implicit fitness sharing, on four\u00a0\u2026", "num_citations": "119\n", "authors": ["1732"]}
{"title": "General program synthesis benchmark suite\n", "abstract": " Recent interest in the development and use of non-trivial benchmark problems for genetic programming research has highlighted the scarcity of general program synthesis (also called\" traditional programming\") benchmark problems. We present a suite of 29 general program synthesis benchmark problems systematically selected from sources of introductory computer science programming problems. This suite is suitable for experiments with any program synthesis system driven by input/output examples. We present results from illustrative experiments using our reference implementation of the problems in the PushGP genetic programming system. The results show that the problems in the suite vary in difficulty and can be useful for assessing the capabilities of a program synthesis system.", "num_citations": "103\n", "authors": ["1732"]}
{"title": "Tag-based modules in genetic programming\n", "abstract": " In this paper we present a new technique for evolving modular programs with genetic programming. The technique is based on the use of\" tags\" that evolving programs may use to label and later to refer to code fragments. Tags may refer inexactly, permitting the labeling and use of code fragments to co-evolve in an incremental way. The technique can be implemented as a minor modification to an existing, general purpose genetic programming system, and it does not require pre-specification of the module architecture of evolved programs. We demonstrate that tag-based modules readily evolve and that this allows problem solving effort to scale well with problem size. We also show that the tag-based module technique is effective even in complex, non-uniform problem environments for which previous techniques perform poorly. We demonstrate the technique in the context of the stack-based genetic programming\u00a0\u2026", "num_citations": "41\n", "authors": ["1732"]}
{"title": "A Probabilistic and Multi-Objective Analysis of Lexicase Selection and -Lexicase Selection\n", "abstract": " Lexicase selection is a parent selection method that considers training cases individually, rather than in aggregate, when performing parent selection. Whereas previous work has demonstrated the ability of lexicase selection to solve difficult problems in program synthesis and symbolic regression, the central goal of this article is to develop the theoretical underpinnings that explain its performance. To this end, we derive an analytical formula that gives the expected probabilities of selection under lexicase selection, given a population and its behavior. In addition, we expand upon the relation of lexicase selection to many-objective optimization methods to describe the behavior of lexicase selection, which is to select individuals on the boundaries of Pareto fronts in high-dimensional space. We show analytically why lexicase selection performs more poorly for certain sizes of population and training cases, and show why\u00a0\u2026", "num_citations": "34\n", "authors": ["1732"]}
{"title": "Improving generalization of evolved programs through automatic simplification\n", "abstract": " Programs evolved by genetic programming unfortunately often do not generalize to unseen data. Reliable synthesis of programs that generalize to unseen data is therefore an important open problem. We present evidence that smaller programs evolved using the PushGP system tend to generalize better over a range of program synthesis problems. Like in many genetic programming systems, programs evolved by PushGP usually have pieces that can be removed without changing the behavior of the program. We describe methods for automatically simplifying evolved programs to make them smaller and potentially improve their generalization. We present five simplification methods and analyze their strengths and weaknesses on a suite of general program synthesis benchmark problems. All of our methods use a straightforward hill-climbing procedure to remove pieces of a program while ensuring that the\u00a0\u2026", "num_citations": "34\n", "authors": ["1732"]}
{"title": "Lexicase selection for program synthesis: a diversity analysis\n", "abstract": " Lexicase selection is a selection method for evolutionary computation in which individuals are selected by filtering the population according to performance on test cases, considered in random order. When used as the parent selection method in genetic programming, lexicase selection has been shown to provide significant improvements in problem-solving power. In this chapter we investigate the reasons for the success of lexicase selection, focusing on measures of population diversity. We present data from eight program synthesis problems and compare lexicase selection to tournament selection and selection based on implicit fitness sharing. We conclude that lexicase selection does indeed produce more diverse populations, which helps to explain the utility of lexicase selection for program synthesis.", "num_citations": "33\n", "authors": ["1732"]}
{"title": "Genetic programming with epigenetic local search\n", "abstract": " We focus on improving genetic programming through local search of the space of program structures using an inheritable epigenetic layer that specifies active and inactive genes. We explore several genetic programming implementations that represent the different properties that epigenetics can provide, such as passive structure, phenotypic plasticity, and inheritable gene regulation. We apply these implementations to several symbolic regression and program synthesis problems. For the symbolic regression problems, the results indicate that epigenetic local search consistently improves genetic programming by producing smaller solution programs with better fitness. Furthermore, we find that incorporating epigenetic modification as a mutation step in program synthesis problems can improve the ability of genetic programming to find exact solutions. By analyzing population homology we show that the epigenetic\u00a0\u2026", "num_citations": "31\n", "authors": ["1732"]}
{"title": "Comparison of semantic-aware selection methods in genetic programming\n", "abstract": " This study investigates the performance of several semantic-aware selection methods for genetic programming (GP). In particular, we consider methods that do not rely on complete GP semantics (ie, a tuple of outputs produced by a program for fitness cases (tests)), but on binary outcome vectors that only state whether a given test has been passed by a program or not. This allows us to relate to test-based problems commonly considered in the domain of coevolutionary algorithms and, in prospect, to address a wider range of practical problems, in particular the problems where desired program output is unknown (eg, evolving GP controllers). The selection methods considered in the paper include implicit fitness sharing (ifs), discovery of derived objectives (doc), lexicase selection (lex), as well as a hybrid of the latter two. These techniques, together with a few variants, are experimentally compared to each other and\u00a0\u2026", "num_citations": "30\n", "authors": ["1732"]}
{"title": "Program synthesis using uniform mutation by addition and deletion\n", "abstract": " Most genetic programming systems use mutation and crossover operators to create child programs from selected parent programs. Typically the mutation operator will replace a randomly chosen subprogram in the parent with a new, randomly generated subprogram. In systems with linear genomes, a uniform mutation operator can be used that has some probability of replacing any particular gene with a new, randomly chosen gene. In this paper, we present a new uniform mutation operator called Uniform Mutation by Addition and Deletion (UMAD), which first adds genes with some probability before or after every existing gene, and then deletes random genes from the resulting genome. In UMAD it is not necessary that the new genes replace old genes, as the additions and deletions can occur in different locations. We find that UMAD, with relatively high rates of addition and deletion, results in significant increases\u00a0\u2026", "num_citations": "29\n", "authors": ["1732"]}
{"title": "Uniform linear transformation with repair and alternation in genetic programming\n", "abstract": " Several genetic programming researchers have argued for the utility of genetic operators that act uniformly. By \u201cact uniformly\u201d we mean two specific things: that the probability of an inherited program component being modified during inheritance is independent of the size and shape of the parent programs beyond the component in question; and that pairs of parents are combined in ways that allow arbitrary combinations of components from each parent to appear in the child. Uniform operators described in previous work have had limited utility, however, because of a mismatch between the relevant notions of uniformity and the hierarchical structure and variable sizes of many genetic programming representations. In this chapter we describe a new genetic operator, ULTRA, which incorporates aspects of both mutation and crossover and acts approximately uniformly across programs of variable sizes and\u00a0\u2026", "num_citations": "28\n", "authors": ["1732"]}
{"title": "Tag-based modularity in tree-based genetic programming\n", "abstract": " Several techniques have been developed for allowing genetic programming systems to produce programs that make use of subroutines, macros, and other modular program structures. A recently proposed technique, based on the\" tagging\" and tag-based retrieval of blocks of code, has been shown to have novel and desirable features, but this was demonstrated only within the context of the PushGP genetic programming system. Following a suggestion in the GECCO-2011 publication on this technique we show here how tag-based modules can be incorporated into a more standard tree-based genetic programming system. We describe the technique in detail along with some possible extensions, outline arguments for its simplicity and potential power, and present results obtained using the technique on problems for which other modularization techniques have been shown to be useful. The results are mixed\u00a0\u2026", "num_citations": "24\n", "authors": ["1732"]}
{"title": "The impact of hyperselection on lexicase selection\n", "abstract": " Lexicase selection is a parent selection method that has been shown to improve the problem solving power of genetic programming over a range of problems. Previous work has shown that it can also produce hyperselection events, in which a single individual is selected many more times than other individuals. Here we investigate the role that hyperselection plays in the problem-solving performance of lexicase selection. We run genetic programming on a set of program synthesis benchmark problems using lexicase and tournament selection, confirming that hyperselection occurs significantly more often and more drastically with lexicase selection, which also performs significantly better. We then show results from an experiment indicating that hyperselection is not integral to the problem-solving performance or diversity maintenance observed when using lexicase selection. We conclude that the power of lexicase\u00a0\u2026", "num_citations": "23\n", "authors": ["1732"]}
{"title": "What\u2019s in an evolved name? the evolution of modularity via tag-based reference\n", "abstract": " Programming languages provide a variety of mechanisms to associate names with values, and these mechanisms play a central role in programming practice. For example, they allow multiple references to the same storage location or function in different parts of a complex program. By contrast, the representations used in current genetic programming systems provide few if any naming mechanisms, and it is therefore generally not possible for evolved programs to use names in sophisticated ways. In this chapter we describe a new approach to names in genetic programming that is based on Holland\u2019s concept of tags. We demonstrate the use of tag-based names, we describe some of the ways in which they may help to extend the power and reach of genetic programming systems, and we look at the ways that tag-based names are actually used in an evolved program that solves a robot navigation problem.", "num_citations": "22\n", "authors": ["1732"]}
{"title": "Effects of lexicase and tournament selection on diversity recovery and maintenance\n", "abstract": " In genetic programming systems, parent selection algorithms select the programs from which offspring will be produced by random variation and recombination. While most parent selection algorithms select programs on the basis of aggregate performance on multiple test cases, the lexicase selection algorithm considers each test case individually, in random order, for each parent selection event. Prior work has shown that lexicase selection can produce both more diverse populations and more solutions when applied to several hard problems. Here we examine the effects of lexicase selection, compared to those of the more traditional tournament selection algorithm, on population error diversity using two program synthesis problems. We conduct experiments in which the same initial population is used to start multiple runs, each using a different random number seed. The initial populations are extracted from\u00a0\u2026", "num_citations": "21\n", "authors": ["1732"]}
{"title": "General program synthesis from examples using genetic programming with parent selection based on random lexicographic orderings of test cases\n", "abstract": " Software developers routinely create tests before writing code, to ensure that their programs fulfill their requirements. Instead of having human programmers write the code to meet these tests, automatic program synthesis systems can create programs to meet specifications without human intervention, only requiring examples of desired behavior. In the long-term, we envision using genetic programming to synthesize large pieces of software. This dissertation takes steps toward this goal by investigating the ability of genetic programming to solve introductory computer science programming problems.", "num_citations": "19\n", "authors": ["1732"]}
{"title": "On the difficulty of benchmarking inductive program synthesis methods\n", "abstract": " A variety of inductive program synthesis (IPS) techniques have recently been developed, emerging from different areas of computer science. However, these techniques have not been adequately compared on general program synthesis problems. In this paper we compare several methods on problems requiring solution programs to handle various data types, control structures, and numbers of outputs. The problem set also spans levels of abstraction; some would ordinarily be approached using machine code or assembly language, while others would ordinarily be approached using high-level languages. The presented comparisons are focused on the possibility of success; that is, on whether the system can produce a program that passes all tests, for all training and unseen testing inputs. The compared systems are Flash Fill, MagicHaskeller, TerpreT, and two forms of genetic programming. The two genetic\u00a0\u2026", "num_citations": "17\n", "authors": ["1732"]}
{"title": "Detailed problem descriptions for general program synthesis benchmark suite\n", "abstract": " Recent interest in the development and use of non-trivial benchmark problems for genetic programming research has highlighted the scarcity of general program synthesis (also called \u201ctraditional programming\u201d) benchmark problems. We present a suite of 29 general program synthesis benchmark problems systematically selected from sources of introductory computer science programming problems. This suite is suitable for experiments with any program synthesis system driven by input/output examples. We present results from illustrative experiments using our reference implementation of the problems in the PushGP genetic programming system. This technical report provides sufficient detail of the problems and our reference implementation for researchers to implement and attempt to solve these problems in other synthesis systems. The results show that the problems in the suite vary in difficulty and can be useful for assessing the capabilities of a program synthesis system.", "num_citations": "16\n", "authors": ["1732"]}
{"title": "Analyzing a decade of human-competitive (\u201chumie\u201d) winners: What can we learn?\n", "abstract": " Techniques                                                                                                                                                                                                                                                                                                                           in evolutionary computation (EC) have improved significantly over the years, leading to a substantial increase in the complexity of problems that can be solved by EC-based approaches. The HUMIES awards at the Genetic and Evolutionary Computation Conference are designed to recognize work that has not just solved some problem via techniques from evolutionary computation, but has produced a solution that is demonstrably human-competitive. In this chapter, we take a look across the winners of the past 10 years of the HUMIES awards, and analyze them to determine whether there are specific approaches that consistently show up in the HUMIE winners. We believe that this analysis may lead to interesting insights\u00a0\u2026", "num_citations": "16\n", "authors": ["1732"]}
{"title": "Linear genomes for structured programs\n", "abstract": " In most genetic programming systems, candidate solution programs themselves serve as genome upon which variation operators act. However, because of the hierarchical structure of computer programs and the syntactic constraints that they must obey, it is difficult to implement variation operators that affect different parts of programs with uniform probability. This lack of uniformity can have detrimental effects on evolutionary search, such as increases in code bloat. In prior work, structured programs were linearized prior to variation in order to facilitate uniform variation. However, this necessitated syntactic repair after variation, which reintroduced non-uniformities. In this chapter we describe a new approach that uses linear genomes that are translated into hierarchical programs for execution. We present the new approach in detail and show how it facilitates both uniform variation and the evolution of programs\u00a0\u2026", "num_citations": "14\n", "authors": ["1732"]}
{"title": "Visualizing genetic programming ancestries\n", "abstract": " Previous work has demonstrated the utility of graph databases as a tool for collecting, analyzing, and visualizing ancestry in evolutionary computation runs. That work focused on sections of individual runs, whereas this paper illustrates the application of these ideas on the entirety of large runs (up to three hundred thousand individuals) and combinations of multiple runs. Here we use these tools to generate graphs showing all the ancestors of successful individuals from a variety of stack-based genetic programming runs on software synthesis problems. These graphs highlight important moments in the evolutionary process. They also allow us to compare the dynamics for successful and unsuccessful runs. As well as displaying these full ancestry graphs, we use a variety of standard techniques such as size, color, pattern, labeling, and opacity to visualize other important information such as fitness, which genetic\u00a0\u2026", "num_citations": "14\n", "authors": ["1732"]}
{"title": "Using graph databases to explore the dynamics of genetic programming runs\n", "abstract": " For both practical reasons and those of habit, most evolutionary computation research is presented in highly summary form. These summaries, however, often obscure or completely mask the profusion of specific selections,\u00a0crossovers, and mutations that are ultimately responsible for the aggregate behaviors we\u2019re interested in. In this chapter we take a different approach and use the Neo4j graph database system to record and analyze the entire genealogical history of a set of genetic programming runs. We then explore a few of these runs in detail, discovering important properties of lexicase selection; these may in turn help us better understand the dynamics of lexicase selection, and the ways in which it differs from tournament selection. More broadly, we illustrate the value of recording and analyzing this level of detail, both as a means of understanding the dynamics of particular runs, and as a way of\u00a0\u2026", "num_citations": "14\n", "authors": ["1732"]}
{"title": "Relaxations of lexicase parent selection\n", "abstract": " In a genetic programming system, the parent selection algorithm determines which programs in the evolving population will be used as the material out of which new programs will be constructed. The lexicase parent selection algorithm chooses a parent by considering all test cases, individually, one at a time, in a random order, to reduce the pool of possible parent programs. Lexicase selection is ordinarily strict, in that a program can only be selected if it has the best error in the entire population on the first test case considered, and the best error relative to all other programs that remain in the pool each time it is reduced. This strictness may exclude high-quality candidates from consideration for parenthood, and hence from exploration by the evolutionary process. In this chapter we describe and present results of four variants of lexicase selection that relax these strict constraints: epsilon lexicase selection\u00a0\u2026", "num_citations": "12\n", "authors": ["1732"]}
{"title": "Effective simplification of evolved push programs using a simple, stochastic hill-climber\n", "abstract": " Genetic programming systems often produce programs that include unnecessary code. This is undesirable for several reasons, including the burdens that overly-large programs put on end-users for program interpretation and maintenance. The problem is exacerbated by recently developed techniques, such as genetic programming with geometric semantic crossover, that tend to produce enormous programs. Methods for automatically simplifying evolved programs are therefore of interest, but automatic simplification is non-trivial in the context of traditional program representations with unconstrained function sets. Here we show how evolved programs expressed in the stack-based Push programming language can be automatically and reliably simplified using a simple, stochastic hill-climber. We demonstrate and quantitatively characterize this simplification process on programs evolved to solve four non-trivial\u00a0\u2026", "num_citations": "12\n", "authors": ["1732"]}
{"title": "Word count as a traditional programming benchmark problem for genetic programming\n", "abstract": " The Unix utility program wc, which stands for\" word count,\" takes any number of files and prints the number of newlines, words, and characters in each of the files. We show that genetic programming can find programs that replicate the core functionality of the wc utility, and propose this problem as a\" traditional programming\" benchmark for genetic programming systems. This\" wc problem\" features key elements of programming tasks that often confront human programmers, including requirements for multiple data types, a large instruction set, control flow, and multiple outputs. Furthermore, it mimics the behavior of a real-world utility program, showing that genetic programming can automatically synthesize programs with general utility. We suggest statistical procedures that should be used to compare performances of different systems on traditional programming problems such as the wc problem, and present the\u00a0\u2026", "num_citations": "12\n", "authors": ["1732"]}
{"title": "Evolving a digital multiplier with the pushgp genetic programming system\n", "abstract": " A recent article on benchmark problems for genetic programming suggested that researchers focus attention on the digital multiplier problem, also known as the\" multiple output multiplier\" problem, in part because it is scalable and in part because the requirement of multiple outputs presents challenges for some forms of genetic programming [20]. Here we demonstrate the application of stack-based genetic programming to the digital multiplier problem using the PushGP genetic programming system, which evolves programs expressed in the stack-based Push programming language. We demonstrate the use of output instructions and argue that they provide a natural mechanism for producing multiple outputs in a stack-based genetic programming context. We also show how two recent developments in PushGP dramatically improve the performance of the system on the digital multiplier problem. These\u00a0\u2026", "num_citations": "12\n", "authors": ["1732"]}
{"title": "Evolution evolves with autoconstruction\n", "abstract": " In autoconstructive evolutionary algorithms, individuals implement not only candidate solutions to specified computational problems, but also their own methods for variation of offspring. This makes it possible for the variation methods to themselves evolve, which could, in principle, produce a system with an enhanced capacity for adaptation and superior problem solving power. Prior work on autoconsruction has explored a range of system designs and their evolutionary dynamics, but it has not solved hard problems. Here we describe a new approach that can indeed solve at least some hard problems. We present the key components of this approach, including the use of linear genomes for hierarchically structured programs, a diversity-maintaining parent selection algorithm, and the enforcement of diversification constraints on offspring. We describe a software synthesis benchmark problem that our new approach\u00a0\u2026", "num_citations": "10\n", "authors": ["1732"]}
{"title": "Benchmarking parent selection for program synthesis by genetic programming\n", "abstract": " In genetic programming, the parent selection method determines which individuals in the population are selected to be parents for the next generation, and how many children they create. This process directly impacts the search performance by determining on which areas of the search space genetic programming focuses its attention and how it balances exploration and exploitation. Many parent selection methods have been proposed in the literature, with aims of improving problem-solving performance or other characteristics of the GP system. This paper aims to benchmark many recent and common parent selection methods by comparing them within a single system and set of benchmark problems. We specifically focus on the domain of general program synthesis, where solution programs must make use of multiple data types and control flow structures, and use an existing benchmark suite within the domain\u00a0\u2026", "num_citations": "8\n", "authors": ["1732"]}
{"title": "Explaining and exploiting the advantages of down-sampled lexicase selection\n", "abstract": " In genetic programming, parent selection is ordinarily based on aggregate measures of performance across an entire training set. Lexicase selection, by contrast, selects on the basis of performance on random sequences of test cases; this has been shown to enhance problem-solving power in many circumstances. Lexicase selection can also be seen as better reflecting biological evolution, by modeling sequences of challenges that organisms face over their lifetimes. Recent work has demonstrated that the advantages of lexicase selection can be amplified by down-sampling, meaning that only a random subsample of the training cases is used each generation, which can also be seen as modeling environmental change over time. Here we provide the most extensive benchmarking of down-sampled lexicase selection to date, showing that its benefits hold up to increased scrutiny. The reasons that down-sampling\u00a0\u2026", "num_citations": "8\n", "authors": ["1732"]}
{"title": "Comparing and Combining Lexicase Selection and Novelty Search\n", "abstract": " Lexicase selection and novelty search, two parent selection methods used in evolutionary computation, emphasize exploring widely in the search space more than traditional methods such as tournament selection. However, lexicase selection is not explicitly driven to select for novelty in the population, and novelty search suffers from lack of direction toward a goal, especially in unconstrained, highly-dimensional spaces. We combine the strengths of lexicase selection and novelty search by creating a novelty score for each test case, and adding those novelty scores to the normal error values used in lexicase selection. We use this new novelty-lexicase selection to solve automatic program synthesis problems, and find it significantly outperforms both novelty search and lexicase selection. Additionally, we find that novelty search has very little success in the problem domain of program synthesis. We explore the effects\u00a0\u2026", "num_citations": "8\n", "authors": ["1732"]}
{"title": "Lexicase Selection of Specialists\n", "abstract": " Lexicase parent selection filters the population by considering one random training case at a time, eliminating any individuals with errors for the current case that are worse than the best error in the selection pool, until a single individual remains. This process often stops before considering all training cases, meaning that it will ignore the error values on any cases that were not yet considered. Lexicase selection can therefore select specialist individuals that have poor errors on some training cases, if they have great errors on others and those errors come near the start of the random list of cases used for the parent selection event in question. We hypothesize here that selecting these specialists, which may have poor total error, plays an important role in lexicase selection's observed performance advantages over error-aggregating parent selection methods such as tournament selection, which select specialists much\u00a0\u2026", "num_citations": "6\n", "authors": ["1732"]}
{"title": "On the importance of specialists for lexicase selection\n", "abstract": " Lexicase parent selection filters the population by considering one random training case at a time, eliminating any individual with an error for the current case that is worse than the best error of any individual in the selection pool, until a single individual remains. This process often stops before considering all training cases, meaning that it will ignore the error values on any cases that were not yet considered. Lexicase selection can therefore select specialist individuals that have high errors on some training cases, if they have low errors on others and those errors come near the start of the random list of cases used for the parent selection event in question. We hypothesize here that selecting such specialists, which may have high total error, plays an important role in lexicase selection\u2019s observed performance advantages over error-aggregating parent selection methods such as tournament selection, which select\u00a0\u2026", "num_citations": "5\n", "authors": ["1732"]}
{"title": "Size-based tournaments for node selection\n", "abstract": " In genetic programming, the reproductive operators of crossover and mutation both require the selection of nodes from the reproducing individuals. Both unbiased random selection and Koza 90/10 mechanisms remain popular, despite their arbitrary natures and a lack of evidence for their effectiveness. It is generally considered problematic to select from all nodes with a uniform distribution, since this causes terminal nodes to be selected most of the time. This can limit the complexity of program fragments that can be exchanged in crossover, and it may also lead to code bloat when leaf nodes are replaced with larger new subtrees during mutation. We present a new node selection method that selects nodes based on a tournament, from which the largest participating subtree is selected. We show this method of size-based tournaments improves performance on three standard test problems with no increases in code\u00a0\u2026", "num_citations": "5\n", "authors": ["1732"]}
{"title": "PSB2: the second program synthesis benchmark suite\n", "abstract": " For the past six years, researchers in genetic programming and other program synthesis disciplines have used the General Program Synthesis Benchmark Suite to benchmark many aspects of automatic program synthesis systems. These problems have been used to make notable progress toward the goal of general program synthesis: automatically creating the types of software that human programmers code. Many of the systems that have attempted the problems in the original benchmark suite have used it to demonstrate performance improvements granted through new techniques. Over time, the suite has gradually become outdated, hindering the accurate measurement of further improvements. The field needs a new set of more difficult benchmark problems to move beyond what was previously possible. In this paper, we describe the 25 new general program synthesis benchmark problems that make up PSB2, a new benchmark suite. These problems are curated from a variety of sources, including programming katas and college courses. We selected these problems to be more difficult than those in the original suite, and give results using PushGP showing this increase in difficulty. These new problems give plenty of room for improvement, pointing the way for the next six or more years of general program synthesis research.", "num_citations": "4\n", "authors": ["1732"]}
{"title": "Transfer learning of genetic programming instruction sets\n", "abstract": " The performance of a genetic programming system depends partially on the composition of the collection of elements out of which programs can be constructed, and by the relative probability of different instructions and constants being chosen for inclusion in randomly generated programs or for introduction by mutation. In this paper we develop a method for the transfer learning of instruction sets across different software synthesis problems. These instruction sets outperform unlearned instruction sets on a range of problems.", "num_citations": "4\n", "authors": ["1732"]}
{"title": "Specialization and elitism in lexicase and tournament selection\n", "abstract": " Prior work has demonstrated that genetic programming systems often maintain higher levels of population diversity when using lexicase selection than when using other parent selection methods, and that the use of lexicase selection improves problem-solving performance in many circumstances. It has been suggested that it is not only the maintenance of diversity that is responsible for the performance of lexicase selection, but more specifically the production and maintenance of\" specialists\" that matters, where specialists are defined to be individuals with the lowest error, relative to the rest of the population, on a small number of training cases regardless of total error. Here we provide results of experiments that uphold this suggestion by tracking the numbers of specialists selected by lexicase selection and by tournament selection in a genetic programming system solving software synthesis problems. Our results\u00a0\u2026", "num_citations": "4\n", "authors": ["1732"]}
{"title": "A detailed analysis of a PushGP run\n", "abstract": " In evolutionary computation we potentially have the ability to save and analyze every detail in an run. This data is often thrown away, however, in favor of focusing on the final outcomes, typically captured and presented in the form of summary statistics and performance plots. Here we use graph database tools to store every parent\u2013child relationship in a single genetic programming run, and examine the key ancestries in detail, tracing back from an solution to see how it was evolved over the course of 20 generations. To visualize this genetic programming run, the ancestry graph is extracted, running from the solution(s) in the final generation up to their ancestors in the initial random population. The key instructions in the solution are also identified, and a genetic ancestry graph is constructed, a subgraph of the ancestry graph containing only those individuals that contributed genetic information (or instructions\u00a0\u2026", "num_citations": "4\n", "authors": ["1732"]}
{"title": "Lexicase selection with weighted shuffle\n", "abstract": " Semantic-aware methods in genetic programming take into account information about programs\u2019 performances across a set of test cases. Lexicase parent selection, a semantic-aware selection, randomly shuffles the list of test cases and places more emphasis on those test cases that randomly appear earlier in the ordering than those that appear later in the ordering. In this work, we explore methods for weighting this shuffling of test cases to give some test cases more influence over selection than others. We design and test a variety of weighted shuffle algorithms and methods for weighting test cases. In experiments on two program synthesis benchmark problems, we find that none of these methods significantly outperform regular lexicase selection. We analyze these results by examining how each method affects population diversity, and find that those methods that perform much worse also have\u00a0\u2026", "num_citations": "4\n", "authors": ["1732"]}
{"title": "Using algorithm configuration tools to optimize genetic programming parameters: A case study\n", "abstract": " We use Sequential Model-based Algorithm Configuration (SMAC) to optimize a group of parameters for PushGP, a stack-based genetic programming system, for several software synthesis problems. Applying SMAC to one particular problem leads to marked improvements in the success rate and the speed with which a solution was found for that problem. Applying these\" tuned\" parameters to four additional problems, however, only improved performance on one, and substantially reduced performance on another. This suggests that SMAC is\" overfitting\", tuning the parameters in ways that are highly problem specific, and raises doubts about the value of using these\" tuned\" parameters on previously unsolved problems. Efforts to use SMAC to optimize PushGP parameters on other problems have been less successful due to a combination of long PushGP run times and low success rates, which make it hard for\u00a0\u2026", "num_citations": "4\n", "authors": ["1732"]}
{"title": "Evolving sql queries from examples with developmental genetic programming\n", "abstract": " Large databases are becoming ever more ubiquitous, as are the opportunities for discovering useful knowledge within them. Evolutionary computation methods such as genetic programming have previously been applied to several aspects of the problem of discovering knowledge in databases. The more specific task of producing human-comprehensible SQL queries has several potential applications but has thus far been explored only to a limited extent. In this chapter we show howdevelopmental genetic programming can automatically generate SQL queries from sets of positive and negative examples. We show that a developmental genetic programming system can produce queries that are reasonably accurate while excelling in human comprehensibility relative to the well-known C5.0 decision tree generation system.", "num_citations": "4\n", "authors": ["1732"]}
{"title": "Problem-solving benefits of down-sampled lexicase selection\n", "abstract": " In genetic programming, an evolutionary method for producing computer programs that solve specified computational problems, parent selection is ordinarily based on aggregate measures of performance across an entire training set. Lexicase selection, by contrast, selects on the basis of performance on random sequences of training cases; this has been shown to enhance problem-solving power in many circumstances. Lexicase selection can also be seen as better reflecting biological evolution, by modeling sequences of challenges that organisms face over their lifetimes. Recent work has demonstrated that the advantages of lexicase selection can be amplified by down-sampling, meaning that only a random subsample of the training cases is used each generation. This can be seen as modeling the fact that individual organisms encounter only subsets of the possible environments, and that environments change over time. Here we provide the most extensive benchmarking of down-sampled lexicase selection to date, showing that its benefits hold up to increased scrutiny. The reasons that down-sampling helps, however, are not yet fully understood. Hypotheses include that down-sampling allows for more generations to be processed with the same budget of program evaluations; that the variation of training data across generations acts as a changing environment, encouraging adaptation; or that it reduces overfitting, leading to more general solutions. We systematically evaluate these hypotheses, finding evidence against all three, and instead draw the conclusion that down-sampled lexicase selection's main benefit stems from the fact that it\u00a0\u2026", "num_citations": "3\n", "authors": ["1732"]}
{"title": "Genetic Source Sensitivity and Transfer Learning in Genetic Programming\n", "abstract": " Genetic programming uses biologically-inspired processes of variation and selection to synthesize computer programs that solve problems. Here we investigate the sensitivity of genetic programming to changes in the probability that particular instructions and constants will be chosen for inclusion in randomly generated programs or for introduction by mutation. We find, contrary to conventional wisdom within the field, that genetic programming can be highly sensitive to changes in this source of new genetic material. Additionally, we find that genetic sources can be tuned to significantly improve adaptation across sets of related problems. We study the evolution of solutions to software synthesis problems using untuned genetic sources and sources that have been tuned on the basis of problem statements, human intuition, or prevalence in prior solution programs. We find significant differences in performance across\u00a0\u2026", "num_citations": "3\n", "authors": ["1732"]}
{"title": "A comparison of semantic-based initialization methods for genetic programming\n", "abstract": " During the initialization step, a genetic programming (GP) system traditionally creates a population of completely random programs to populate the initial population. These programs almost always perform poorly in terms of their total error---some might not even output the correct data type. In this paper, we present new methods for initialization that attempt to generate programs that are somewhat relevant to the problem being solved and/or increase the initial diversity (both error and behavioral diversity) of the population prior to the GP run. By seeding the population---and thereby eliminating worthless programs and increasing the initial diversity of the population---we hope to improve the performance of the GP system. Here, we present two novel techniques for initialization (Lexicase Seeding and Pareto Seeding) and compare them to a previous method (Enforced Diverse Populations) and traditional, non-seeded\u00a0\u2026", "num_citations": "3\n", "authors": ["1732"]}
{"title": "Comparison of Linear Genome Representations for Software Synthesis\n", "abstract": " Inductive program synthesis is the field of producing executable programs from a set of input-output examples [7, 14, 16]. General software synthesis refers to the subfield of inductive program synthesis in which the programs produced are expected to be capable of manipulating a variety of data types, control structures, and data structures. The field of genetic programming has produced some the most capable general software synthesis methods, such as PushGP [5], Grammar Guided Genetic Programming [1], and SignalGP [10]. The experiments and discussion in this paper focuses on PushGP.PushGP synthesizes programs in the Push programming language. Push is a stack-based programming language designed for genetic programming, in which arguments for instructions are taken from typed stacks and return values are placed on the stacks [19]. A Push program is a sequence that may contain instructions, literals, and code blocks. A code block is also a sequence that may contain", "num_citations": "2\n", "authors": ["1732"]}
{"title": "Counterexample-driven genetic programming without formal specifications\n", "abstract": " Counterexample-driven genetic programming (CDGP) uses specifications provided as formal constraints in order to generate the training cases used to evaluate the evolving programs. It has also been extended to combine formal constraints and user-provided training data to solve symbolic regression problems. Here we show how the ideas underlying CDGP can also be applied using only user-provided training data, without formal specifications. We demonstrate the application of this method, called\" informal CDGP,\" to software synthesis problems.", "num_citations": "1\n", "authors": ["1732"]}
{"title": "Empirical investigation of size-based tournaments for node selection in genetic programming\n", "abstract": " In genetic programming systems, genetic operators must select nodes upon which to act; the method by which they select nodes influences problem solving performance and possibly also code growth. A recently proposed node selection method using\" size-based tournaments\" has been shown to have potential, but variations of the method have not been studied systematically. Here we extend the ideas of size-based tournaments and test how they can improve problem-solving performance. We consider allowing tournament size to depend on whether we are selecting nodes within\" donors\" for crossover,\" recipients\" for crossover, or targets of mutation. We also consider tournaments that bias selection toward smaller trees rather than larger trees. We find that differentiating between donors and recipients is probably not worthwhile and that size 2 tournaments perform near-optimally.", "num_citations": "1\n", "authors": ["1732"]}
{"title": "Fecundity and selectivity in evolutionary computation\n", "abstract": " The number of offspring produced by each parent---that is, the fecundity of reproducing individuals---varies among evolutionary computation methods and settings. In most prior work fecundity has been tied directly to selectivity, with higher selection pressure giving rise to higher fecundity among individuals selected to reproduce. In nature, however, there is a wider variety of strategies, with different organisms producing different numbers of offspring under the influence of a range of factors including not only selection pressure but also other factors such as environmental stability and competition within a niche. In this work we consider possible lessons that may be drawn from nature's approaches to these issues and applied to evolutionary computation systems. In particular, we consider ways in which fecundity can be dissociated from selectivity and situations in which it may be beneficial to do so. We present a\u00a0\u2026", "num_citations": "1\n", "authors": ["1732"]}