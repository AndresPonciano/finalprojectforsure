{"title": "Collaboration-Based Cloud Computing Security Management Framework\n", "abstract": " Although the cloud computing model is considered to be a very promising internet-based computing platform, it results in a loss of security control over the cloud-hosted assets. This is due to the outsourcing of enterprise IT assets hosted on third-party cloud computing platforms. Moreover, the lack of security constraints in the Service Level Agreements between the cloud providers and consumers results in a loss of trust as well. Obtaining a security certificate such as ISO 27000 or NIST-FISMA would help cloud providers improve consumers trust in their cloud platforms' security. However, such standards are still far from covering the full complexity of the cloud computing model. We introduce a new cloud security management framework based on aligning the FISMA standard to fit with the cloud computing model, enabling cloud providers and consumers to be security certified. Our framework is based on improving\u00a0\u2026", "num_citations": "257\n", "authors": ["573"]}
{"title": "Aspect-oriented requirements engineering for component-based software systems\n", "abstract": " Developing requirements for software components, and ensuring these requirements are met by component designs, is very challenging, as very often application domain and stakeholders are not fully known during component development. The author introduces a new methodology, aspect-oriented component engineering, that addresses some difficult issues of component requirements engineering by analysing and characterising components based on different aspects of the overall application a component addresses. He gives an overview of the aspect-oriented component requirements engineering process, focus on component requirements analysis specification and reasoning, and briefly discuss tool support.", "num_citations": "218\n", "authors": ["573"]}
{"title": "AUIT: Adaptable user interface technology with extended Java Server pages\n", "abstract": " Many web-based information systems require degrees of adaptation of the system\u2019s user interfaces to different client devices, users and user tasks [Vanderdonckt et al. 2001; Petrovski and Grundy 2001]. This includes providing interfaces that will run on conventional web browsers, using Hyper-Text Mark-up Language (HTML), as well as wireless PDAs, mobile phones and pagers using Wireless Mark-up Language (WML)[Marsic 2001a; Han et al. 2000; Zarikas et al. 2001]. In addition, adapting to different users and user tasks is required [Eisenstein and Puerta 2000; Grunst et al. 1996; Wing and Colomb 1996]. For example, hiding \u2018Update\u2019and \u2018Delete\u2019buttons if the user is a customer or if the user is", "num_citations": "163\n", "authors": ["573"]}
{"title": "A 3D metaphor for software production visualization\n", "abstract": " Software development is difficult because software is complex, the software production process is complex and understanding of software systems is a challenge. We propose a 3D visual approach to depict software production cost related program information to support software maintenance. The information helps us to reduce software maintenance costs, to plan the use of personnel wisely, to appoint experts efficiently and to detect system problems early.", "num_citations": "151\n", "authors": ["573"]}
{"title": "A Systematic Mapping Study of Mobile Application Testing Techniques\n", "abstract": " The importance of mobile application specific testing techniques and methods has been attracting much attention of software engineers over the past few years. This is due to the fact that mobile applications are different than traditional web and desktop applications, and more and more they are moving to being used in critical domains. Mobile applications require a different approach to application quality and dependability and require an effective testing approach to build high quality and more reliable software. We performed a systematic mapping study to categorize and to structure the research evidence that has been published in the area of mobile application testing techniques and challenges that they have reported. Seventy nine (79) empirical studies are mapped to a classification schema. Several research gaps are identified and specific key testing issues for practitioners are identified: there is a need for\u00a0\u2026", "num_citations": "135\n", "authors": ["573"]}
{"title": "Multi-perspective specification, design and implementation of software components using aspects\n", "abstract": " Current approaches to component-based systems engineering tend to focus on low-level software component interface design and implementation. This often leads to the development of components whose services are hard to understand and combine, make too many assumptions about other components they can be composed with and component documentation that is too low-level. Aspect-oriented component engineering is a new methodology that uses a concept of different system capabilities (\"aspects\") to categorise and reason about inter-component provided and required services. It supports the identification, description and reasoning about high-level component functional and non-functional requirements grouped by different systemic aspects, and the refinement of these requirements into design-level software component service implementation aspects. Aspect information is used to help implement\u00a0\u2026", "num_citations": "120\n", "authors": ["573"]}
{"title": "Automatic feature learning for predicting vulnerable software components\n", "abstract": " Code flaws or vulnerabilities are prevalent in software systems and can potentially cause a variety of problems including deadlock, hacking, information loss and system failure. A variety of approaches have been developed to try and detect the most likely locations of such code vulnerabilities in large code bases. Most of them rely on manually designing code features (e.g. complexity metrics or frequencies of code tokens) that represent the characteristics of the potentially problematic code to locate. However, all suffer from challenges in sufficiently capturing both semantic and syntactic representation of source code, an important capability for building accurate prediction models. In this paper, we describe a new approach, built upon the powerful deep learning Long Short Term Memory model, to automatically learn both semantic and syntactic features of code. Our evaluation on 18 Android applications and the\u00a0\u2026", "num_citations": "118\n", "authors": ["573"]}
{"title": "Lessons learned from using a deep tree-based model for software defect prediction in practice\n", "abstract": " Defects are common in software systems and cause many problems for software users. Different methods have been developed to make early prediction about the most likely defective modules in large codebases. Most focus on designing features (e.g. complexity metrics) that correlate with potentially defective code. Those approaches however do not sufficiently capture the syntax and multiple levels of semantics of source code, a potentially important capability for building accurate prediction models. In this paper, we report on our experience of deploying a new deep learning tree-based defect prediction model in practice. This model is built upon the tree-structured Long Short Term Memory network which directly matches with the Abstract Syntax Tree representation of source code. We discuss a number of lessons learned from developing the model and evaluating it on two datasets, one from open source\u00a0\u2026", "num_citations": "108\n", "authors": ["573"]}
{"title": "Collaborative software engineering: Challenges and prospects\n", "abstract": " Much work is presently ongoing in collaborative software engineering research. This work is beginning to make serious inroads into our ability to more effectively practice collaborative software engineering, with best practices, processes, tools, metrics, and other techniques becoming available for day-to-day use. However, we have not yet reached the point where the practice of collaborative software engineering is routine, without surprises, and generally as optimal as possible. This chapter summarizes the main findings of this book, draws some conclusions on these findings and looks at the prospects for software engineers in dealing with the challenges of collaborative software development. The chapter ends with prospects for collaborative software engineering.", "num_citations": "105\n", "authors": ["573"]}
{"title": "SoftArch/MTE: generating distributed system test-beds from high-level software architecture descriptions\n", "abstract": " Most distributed system specifications have performance benchmark requirements, for example the number of particular kinds of transactions per second required to be supported by the system. However, determining the likely eventual performance of complex distributed system architectures during their development is very challenging. We describe SoftArch/MTE, a software tool that allows software architects to sketch an outline of their proposed system architecture at a high level of abstraction. These descriptions include client requests, servers, server objects and object services, database servers and tables, and particular choices of middleware and database technologies. A fully-working implementation of this system is then automatically generated from this high-level architectural description. This implementation is deployed on multiple client and server machines and performance tests are then\u00a0\u2026", "num_citations": "90\n", "authors": ["573"]}
{"title": "NetPay: An off-line, decentralized micro-payment system for thin-client applications\n", "abstract": " Micro-payment systems have become popular in recent times as the desire to support low-value, high-volume transactions of text, music, clip-art, video and other media has increased. We describe NetPay, a micro-payment system characterized by de-centralized, off-line processing, customer anonymity and relatively high performance and security using one-way hashing functions for encryption. We describe the motivation for NetPay and its basic protocol, describe a software architecture and two NetPay prototypes we have developed, and report the results of several evaluations of these prototypes.", "num_citations": "89\n", "authors": ["573"]}
{"title": "Adaptable, Model-driven Security Engineering for SaaS Cloud-based Applications\n", "abstract": " Software-as-a-service (SaaS) multi-tenancy in cloud-based applications helps service providers to save cost, improve resource utilization, and reduce service customization and maintenance time. This is achieved by sharing of resources and service instances among multiple \u201ctenants\u201d of the cloud-hosted application. However, supporting multi-tenancy adds more complexity to SaaS applications required capabilities. Security is one of these key requirements that must be addressed when engineering multi-tenant SaaS applications. The sharing of resources among tenants\u2014i.e. multi-tenancy\u2014increases tenants\u2019 concerns about the security of their cloud-hosted assets. Compounding this, existing traditional security engineering approaches do not fit well with the multi-tenancy application model where tenants and their security requirements often emerge after the applications and services were first\u00a0\u2026", "num_citations": "71\n", "authors": ["573"]}
{"title": "Improving automated documentation to code traceability by combining retrieval techniques\n", "abstract": " Documentation written in natural language and source code are two of the major artifacts of a software system. Tracking a variety of traceability links between software documentation and source code assists software developers in comprehension, efficient development, and effective management of a system. Automated traceability systems to date have been faced with a major open research challenge: how to extract these links with both high precision and high recall. In this paper we introduce an approach that combines three supporting techniques, Regular Expression, Key Phrases, and Clustering, with a Vector Space Model (VSM) to improve the performance of automated traceability between documents and source code. This combination approach takes advantage of strengths of the three techniques to ameliorate limitations of VSM. Four case studies have been used to evaluate our combined technique\u00a0\u2026", "num_citations": "69\n", "authors": ["573"]}
{"title": "An Energy Consumption Model and Analysis Tool for Cloud Computing Environments\n", "abstract": " Cloud computing delivers computing as a utility to users worldwide. A consequence of this model is that cloud data centres have high deployment and operational costs, as well as significant carbon footprints for the environment. We need to develop Green Cloud Computing (GCC) solutions that reduce these deployment and operational costs and thus save energy and reduce adverse environmental impacts. In order to achieve this objective, a thorough understanding of the energy consumption patterns in complex Cloud environments is needed. We present a new energy consumption model and associated analysis tool for Cloud computing environments. We measure energy consumption in Cloud environments based on different runtime tasks. Empirical analysis of the correlation of energy consumption and Cloud data and computational tasks, as well as system performance, will be investigated based on our\u00a0\u2026", "num_citations": "65\n", "authors": ["573"]}
{"title": "Ink features for diagram recognition\n", "abstract": " The ability to automatically recognize a sketch accurately is important to computer-based diagramming. Many recognition techniques have been proposed but few researchers have reported the use of formal methods to select the most appropriate ink features for recognition algorithms. We have used a statistical approach to identify the most important distinguishing features of ink for dividing text and shapes. We implemented these into an existing recognition engine and conducted a comparative evaluation. Our feature set more successfully classified a range of common diagram elements than two existing dividers.", "num_citations": "61\n", "authors": ["573"]}
{"title": "Supporting traceability and inconsistency management between software artifacts\n", "abstract": " Software artifacts at different levels of abstraction are closely inter-related. Developers require support for managing these inter-relationships as artifacts evolve during development. We describe a conceptual architecture and prototype for supporting traceability and inconsistency management between software requirements descriptions, UML-style use case models and black-box test plans. Key information models are extracted from each of these different kinds of software artifacts and elements in different models are implicitly or explicitly linked. Changes to one software artifact are detected and propagated to related artifacts in different information models. Developers are informed of impacting changes and can view causal changes in related artifact views.", "num_citations": "61\n", "authors": ["573"]}
{"title": "Storage and retrieval of Software Components using Aspects\n", "abstract": " While component-based software engineering technologies have become popular, finding and reusing appropriate software components is often challenging. We describe a software component repository that uses a concept of component \"aspects\" to index and query components based on their high-level systemic characteristics, including their user interface, persistency, distribution, security and collaborative work support. Software components are queried for aspects of a system they provide or require and these are used to automatically generate a high-level indexing system. Developers and end users can formulate high-level, aspect-based queries to retrieve components providing or requiring services appropriate to their needs.", "num_citations": "59\n", "authors": ["573"]}
{"title": "Towards an integrated environment for method engineering\n", "abstract": " In order to facilitate better Information Systems Development (ISD), Method Engineering technqiues and tools are needed that support flexible creation, modification, and reuse of ISD methods and tools for use on specific problem domains. A metamodelling notation is needed for specifying and integrating different design notations. MetaCASE support is required for building, reusing and evolving tools for these design notations. Process modelling tools for both the coordination of these design notation tools and the evolution of software processes are also needed. We describe our work on developing an integrated environment which supports metamodelling, metaCASE and flexible software process modelling, and illustrate its use for supporting Method Engineering.", "num_citations": "59\n", "authors": ["573"]}
{"title": "Experimental Analysis of Task-based Energy Consumption in Cloud Computing Systems\n", "abstract": " Cloud computing delivers IT solutions as a utility to users. One consequence of this model is that large cloud data centres consume large amounts of energy and produce significant carbon footprints. A common objective of cloud providers is to develop resource provisioning and management solutions that minimise energy consumption while guaranteeing Service Level Agreements (SLAs). In order to achieve this objective, a thorough understanding of energy consumption patterns in complex cloud systems is imperative. We have developed an energy consumption model for cloud computing systems. To operationalise this model, we have conducted extensive experiments to profile the energy consumption in cloud computing systems based on three types of tasks: computation-intensive, data-intensive and communication-intensive tasks. We collected fine-grained energy consumption and performance data with\u00a0\u2026", "num_citations": "58\n", "authors": ["573"]}
{"title": "TOSSMA: A Tenant-Oriented SaaS Security Management Architecture\n", "abstract": " Multi-tenancy helps service providers to save costs, improve resource utilization, and reduce service customization and maintenance time by sharing of resources and services. On the other hand, supporting multi-tenancy adds more complexity to the shared application's required capabilities. Security is a key requirement that must be addressed when engineering new SaaS applications or when re-engineering existing applications to support multi-tenancy. Traditional security (re)engineering approaches do not fit with the multi-tenancy application model where tenants and their security requirements emerge after the system was first developed. Enabling, runtime, adaptable and tenant-oriented application security customization on single service instance is a key challenging security goal in multi-tenant application engineering. In this paper we introduce TOSSMA, a Tenant-Oriented SaaS Security Management\u00a0\u2026", "num_citations": "57\n", "authors": ["573"]}
{"title": "System having mobile terminals with wireless access to the internet and method for doing same\n", "abstract": " A system and method are provided for allowing a user to perform information management tasks and access the Internet (26). The system includes at least one terminal (20, 21) that is part of a group and capable of wireless communication, an Access Provider (AP) unit (22), an Internet Service Provider (ISP)(24), a server (28) for authenticating the terminal (20, 21), and a global unit (34) for providing the internet address of the server (28) to the terminal (20, 21). The method includes the steps of powering on the terminal (20, 21), establishing a communication link with a gateway to obtain an internet address for the terminal (20, 21) relative to an internet address of the gateway, obtaining an internet address for the server (28), and establishing a shared communication session between the terminal (20, 21) and the server (28) to allow access to information management services.", "num_citations": "55\n", "authors": ["573"]}
{"title": "KBRE: A Framework for knowledge-based Requirements Engineering\n", "abstract": " Detecting inconsistencies is a critical part of requirements engineering (RE) and has been a topic of interest for several decades. Domain knowledge and semantics of requirements not only play important roles in elaborating requirements but are also a crucial way to detect conflicts among them. In this paper, we present a novel knowledge-based RE framework (KBRE) in which domain knowledge and semantics of requirements are central to elaboration, structuring, and management of captured requirements. Moreover, we also show how they facilitate the identification of requirements inconsistencies and other-related problems. In our KBRE model, description logic (DL) is used as the fundamental logical system for requirements analysis and reasoning. In addition, the application of DL in the form of Manchester OWL Syntax brings simplicity to the formalization of requirements while preserving sufficient\u00a0\u2026", "num_citations": "44\n", "authors": ["573"]}
{"title": "Keyword Search for Building Service-Based Systems\n", "abstract": " With the fast growth of applications of service-oriented architecture (SOA) in software engineering, there has been a rapid increase in demand for building service-based systems (SBSs) by composing existing Web services. Finding appropriate component services to compose is a key step in the SBS engineering process. Existing approaches require that system engineers have detailed knowledge of SOA techniques which is often too demanding. To address this issue, we propose Keyword Search for Service-based Systems (KS3), a novel approach that integrates and automates the system planning, service discovery and service selection operations for building SBSs based on keyword search. KS3 assists system engineers without detailed knowledge of SOA techniques in searching for component services to build SBSs by typing a few keywords that represent the tasks of the SBSs with quality constraints and\u00a0\u2026", "num_citations": "43\n", "authors": ["573"]}
{"title": "Security, privacy and trust in cloud systems\n", "abstract": " Cloud computing has emerged as a new paradigm for on-demand delivery of computing resources to consumers as utilities. It offers unlimited computing resources to its users in a pay-as-you-go model with a higher level of quality of service such as availability and reliability in a substantially reduced infrastructure cost. With such an offering, it is not surprising that businesses are considering moving their IT infrastructure to cloud. However, it has been widely reported in the surveys of CTOs and CIOs that they have a number of reservations about adapting cloud computing for their businesses, and the security, privacy and trust of cloud systems is at the top of their list. The recent news reported in media about the leakage of customers\u2019 personal data have exacerbated their concerns even more. With the emergence of social media, such events are spreading faster than ever before and the impact of breach of privacy of\u00a0\u2026", "num_citations": "43\n", "authors": ["573"]}
{"title": "Software Engineering for the Cloud\n", "abstract": " Cloud computing is a new paradigm for software systems where applications are divided into sets of composite services hosted on leased, highly distributed platforms. There are many new software engineering challenges in building effective cloud-based software applications. This special issue provides a set of practical contributions to the engineering of cloud computing applications and includes software processes, architecture and design approaches, testing, scalability engineering, security engineering, and applications of highly parallel cloud-based systems.", "num_citations": "42\n", "authors": ["573"]}
{"title": "A visual language for design pattern modeling and instantiation\n", "abstract": " In this chapter we describe the Design pattern modeling language, a notation supporting the specification of Design pattern solutions and their instantiation into UML design models. DPML uses a simple set of visual abstractions and readily lends itself to tool support. DPML Design pattern solution specifications are used to construct visual, formal specifications of Design patterns. DPML instantiation diagrams are used to link a Design pattern solution specification to instances of a UML model, indicating the roles played by different UML elements in the generic Design pattern solution. A prototype tool is described, together with an evaluation of the language and tool.", "num_citations": "42\n", "authors": ["573"]}
{"title": "Neural Network Based Detection of Self-admitted Technical Debt: From Performance to Explainability\n", "abstract": " Technical debt is a metaphor to reflect the tradeoff software engineers make between short-term benefits and long-term stability. Self-admitted technical debt (SATD), a variant of technical debt, has been proposed to identify debt that is intentionally introduced during software development, e.g., temporary fixes and workarounds. Previous studies have leveraged human-summarized patterns (which represent n-gram phrases that can be used to identify SATD) or text-mining techniques to detect SATD in source code comments. However, several characteristics of SATD features in code comments, such as vocabulary diversity, project uniqueness, length, and semantic variations, pose a big challenge to the accuracy of pattern or traditional text-mining-based SATD detection, especially for cross-project deployment. Furthermore, although traditional text-mining-based method outperforms pattern-based method in\u00a0\u2026", "num_citations": "40\n", "authors": ["573"]}
{"title": "Automated Analysis of Performance and Energy  Consumption for Cloud Applications\n", "abstract": " In cloud environments, IT solutions are delivered to users via shared infrastructure. One consequence of this model is that large cloud data centres consume large amounts of energy and produce significant carbon footprints. A key objective of cloud providers is thus to develop resource provisioning and management solutions at minimum energy consumption while still guaranteeing Service Level Agreements (SLAs). However, a thorough understanding of both system performance and energy consumption patterns in complex cloud systems is imperative to achieve a balance of energy efficiency and acceptable performance. In this paper, we present StressCloud, a performance and energy consumption analysis tool for cloud systems. StressCloud can automatically generate load tests and profile system performance and energy consumption data. Using StressCloud, we have conducted extensive experiments to\u00a0\u2026", "num_citations": "38\n", "authors": ["573"]}
{"title": "Beautifying sketching-based design tool content: issues and experiences\n", "abstract": " With the advent of the Tablet PC and stylus-based PDAs, sketching-based user interfaces for design tools have become popular. However, a major challenge with such interfaces is the need for appropriate \u201cbeautification\u201d of the sketches. This includes both interactive beautification as content is sketched and post-design conversion of sketches to formalised, computer-drawn diagrams. We discuss a number of beautification issues and requirements for sketching-based design tools, illustrating these with examples from two quite different sketchingbased applications. We illustrate ways of supporting beautification, user interface design and implementation challenges, and results from preliminary evaluations of such interfaces.", "num_citations": "36\n", "authors": ["573"]}
{"title": "Predicting Delivery Capability in Iterative Software Development\n", "abstract": " Iterative software development has become widely practiced in industry. Since modern software projects require fast, incremental delivery for every iteration of software development, it is essential to monitor the execution of an iteration, and foresee a capability to deliver quality products as the iteration progresses. This paper presents a novel, data-driven approach to providing automated support for project managers and other decision makers in predicting delivery capability for an ongoing iteration. Our approach leverages a history of project iterations and associated issues, and in particular, we extract characteristics of previous iterations and their issues in the form of features. In addition, our approach characterizes an iteration using a novel combination of techniques including feature aggregation statistics, automatic feature learning using the Bag-of-Words approach, and graph-based complexity measures. An\u00a0\u2026", "num_citations": "35\n", "authors": ["573"]}
{"title": "Using data mining for digital ink recognition: Dividing text and shapes in sketched diagrams\n", "abstract": " The low accuracy rates of text\u2013shape dividers for digital ink diagrams are hindering their use in real world applications. While recognition of handwriting is well advanced and there have been many recognition approaches proposed for hand drawn sketches, there has been less attention on the division of text and drawing ink. Feature based recognition is a common approach for text\u2013shape division. However, the choice of features and algorithms are critical to the success of the recognition. We propose the use of data mining techniques to build more accurate text\u2013shape dividers. A comparative study is used to systematically identify the algorithms best suited for the specific problem. We have generated dividers using data mining with diagrams from three domains and a comprehensive ink feature library. The extensive evaluation on diagrams from six different domains has shown that our resulting dividers, using\u00a0\u2026", "num_citations": "35\n", "authors": ["573"]}
{"title": "Architecture of a micro-payment system for thin-client web applications\n", "abstract": " Some web-based services need to be charged for on a per-use basis, where each usage may be many thousands or even millions per day. Micro-payment is an approach to charging for web content (typically) for situations with a small cost-peruse/high use-frequency. We describe a prototype architecture for a new micro-payment model, called NetPay. We present an object-oriented design and describe a prototype implementation of NetPay for an on-line newspaper. We report on initial evaluation results deploying our NetPay prototype and outline directions for future research in micro-payment implementations.", "num_citations": "35\n", "authors": ["573"]}
{"title": "An environment for developing adaptive, multi-device user interfaces\n", "abstract": " There is a growing demand for the development of multi-device, adaptive user interfaces\u2013interfaces that will run on and adapt to the characteristics of multiple display devices and networks as well as multiple users and user tasks. We describe a design and implementation environment for the development of such interfaces. This tool allows developers to specify their desired interfaces using an abstract set of screen element and layout constructs. It then generates a Java Server Page implementation using a custom tag library that realises a multi-device, adaptive interface. We compare and contrast our approach to other techniques and describe our experiences using it..", "num_citations": "34\n", "authors": ["573"]}
{"title": "Comparing and contrasting micro-payment models for E-commerce systems\n", "abstract": " The current macro-payment systems used by most e-commerce sites are not suitable for high-volume, low-cost produce or service purposes, such as charging per page for Web site browsing. These payment technologies suffer from the use of heavyweight encryption technologies and reliance on always-online authorisation servers. Micro-payment systems offer an alternative strategy of pay-as-you-go charging, even for very low-cost, very high-volume charging. However, several different micro-payment schemes exist, not all of which are suitable for all e-commerce uses. We compare and contrast several micro-payment models and outline a new micro-payment technology which we have been developing.", "num_citations": "34\n", "authors": ["573"]}
{"title": "Off-line micro-payment protocol for multiple vendors in mobile commerce\n", "abstract": " Micro-payment systems have the potential to provide non-intrusive, high-volume and low-cost pay as-you-use services for a wide variety of Web-based applications. Previously we have developed NetPay, at off-line micro-payment protocol for e-commerce. In this paper, we describe a set of extensions, mobile NetPay, optimised for mobile e-commerce. Mobile NetPay provides high performance and security using one-way hashing functions for e-coin encryption. Each mobile user's transaction does not involve any broke, and double spending is detected during the redeeming transaction. We describe the motivation for mobile NetPay and describe three transactions of the mobile NetPay protocol in detail to illustrate the approach. We then discuss future research on this protocol", "num_citations": "31\n", "authors": ["573"]}
{"title": "Developing software components with the UML, Enterprise Java Beans and aspects\n", "abstract": " Component-based systems have become increasingly popular approaches to developing complex systems, offering well formed abstractions, strong potential for reuse, dynamic plug-and-play and sometimes end-user application enhancement. Unfortunately the design, implementation and deployment of components is very challenging, particularly achieving appropriate division of responsibility among components, designing components and implementing components. We have developed the aspect-oriented component engineering method to help improve component development by the use of aspects during component specification, design, implementation and deployment. We describe our work extending the UML to facilitate aspect-oriented component design and the use of Enterprise Java Beans to implement these designs.", "num_citations": "30\n", "authors": ["573"]}
{"title": "Providing integrated support for multiple development notations\n", "abstract": " A new method for providing integrated support for multiple development notations (including analysis, design, and implementation) within Information Systems Engineering Environments (ISEEs) is described. Our method supports both static integration of multiple notations and the implementation of dynamic support for them within an integrated ISEE. First, conceptual data models of different analysis and design notations are identified and modelled, and then merged into an integrated conceptual data model. Second, mappings are derived from the integrated conceptual data model, which translates data changes in one notation to appropriate data changes in the other notations. Third, individual ISEEs for each notation are developed. Finally, the individual ISEEs are integrated via an integrated repository based on the integrated conceptual data model and mappings. An environment supporting integrated\u00a0\u2026", "num_citations": "30\n", "authors": ["573"]}
{"title": "Reporting Usability Defects - Do reporters Report What Software Developers Need?\n", "abstract": " Reporting usability defects can be a challenging task, especially in convincing the software developers that the reported defect actually requires attention. Stronger evidence in the form of specific details is often needed. However, research to date in software defect reporting has not investigated the value of capturing different information based on defect type. We surveyed practitioners in both open source communities and industrial software organizations about their usability defect reporting practices to better understand information needs to address usability defect reporting issues. Our analysis of 147 responses show that reporters often provide observed result, expected result and steps to reproduce when describing usability defects, similar to the way other types of defects are reported. However, reporters rarely provide usability-related information. In fact, reporters ranked cause of the problem is the most difficult\u00a0\u2026", "num_citations": "28\n", "authors": ["573"]}
{"title": "The future of software engineering\n", "abstract": " In just a few decades, the development of quality software has evolved into one of the critical needs of our society. Meeting these needs would not be possible without the principles, best practices, and theoretical and technological foundations developed within the field of software engineering. Despite many major achievements over the years, an even larger number of challenges have emerged, making it easy to predict a long and exciting future for this discipline. The contributions in this book provide an insight into the nature of these challenges, and how they are rooted in past achievements. Written by some of the field\u2019s most prominent researchers and technologists, the articles reflect the views of the individual authors on whatever they feel is important for the future of software engineering. Hence a broad range of topics is treated, both from academic and industrial perspectives.The origin of this book was the\u00a0\u2026", "num_citations": "28\n", "authors": ["573"]}
{"title": "Software Quality Assurance\n", "abstract": " Software Quality Assurance in Large Scale and Complex Software-intensive Systems presents novel and high-quality research related approaches that relate the quality of software architecture to system requirements, system architecture and enterprise-architecture, or software testing. Modern software has become complex and adaptable due to the emergence of globalization and new software technologies, devices and networks. These changes challenge both traditional software quality assurance techniques and software engineers to ensure software quality when building today (and tomorrow\u2019s) adaptive, context-sensitive, and highly diverse applications. This edited volume presents state of the art techniques, methodologies, tools, best practices and guidelines for software quality assurance and offers guidance for future software engineering research and practice. Each contributed chapter considers the practical application of the topic through case studies, experiments, empirical validation, or systematic comparisons with other approaches already in practice. Topics of interest include, but are not limited, to: quality attributes of system/software architectures; aligning enterprise, system, and software architecture from the point of view of total quality; design decisions and their influence on the quality of system/software architecture; methods and processes for evaluating architecture quality; quality assessment of legacy systems and third party applications; lessons learned and empirical validation of theories and frameworks on architectural quality; empirical validation and testing for assessing architecture quality. Focused on quality assurance\u00a0\u2026", "num_citations": "26\n", "authors": ["573"]}
{"title": "Generating service models by trace subsequence substitution\n", "abstract": " Software service emulation is an emerging technique for creating realistic executable models of server-side behaviour and is particularly useful in quality assurance: replicating production-like conditions for large-scale enterprise software systems. This allows performance engineers to mimic very large numbers of servers and/or provide a means of controlling dependencies on diverse third-party systems. Previous approaches to service emulation rely on manual definition of interaction behaviour requiring significant human effort. They also rely on either a system expert or documentation of system protocol and behaviour, neither of which are necessarily available. We present a novel method of automatically building client-server and server-server interaction models of complex software systems directly from interaction trace data, utilising longest common subsequence matching and field substitution algorithms. We\u00a0\u2026", "num_citations": "26\n", "authors": ["573"]}
{"title": "Three Kinds of E-wallets for a NetPay Micro-payment System\n", "abstract": " We have developed NetPay, a micro-payment protocol characterized by off-line processing, customer anonymity and relatively high performance and security using one-way hashing functions for encryption. In our NetPay prototypes we have identified three kinds of electronic wallets to store e-coins \u2013 a server-side wallet, client-side wallet application, and cookie-based wallet cache. We describe the motivation for NetPay and describe the three kinds of e-wallets and their design. We report on prototype implementations of these wallets and end-user perceptions of their use.", "num_citations": "25\n", "authors": ["573"]}
{"title": "FogWorkflowSim: An Automated Simulation Toolkit for Workflow Performance Evaluation in Fog Computing\n", "abstract": " Workflow underlies most process automation software, such as those for product lines, business processes, and scientific computing. However, current Cloud Computing based workflow systems cannot support real-time applications due to network latency, which limits their application in many IoT systems such as smart healthcare and smart traffic. Fog Computing extends the Cloud by providing virtualized computing resources close to the End Devices so that the response time of accessing computing resources can be reduced significantly. However, how to most effectively manage heterogeneous resources and different computing tasks in the Fog is a big challenge. In this paper, we introduce \"FogWorkflowSim\" an efficient and extensible toolkit for automatically evaluating resource and task management strategies in Fog Computing with simulated user-defined workflow applications. Specifically, FogWorkflowSim\u00a0\u2026", "num_citations": "24\n", "authors": ["573"]}
{"title": "Focusing on learning through constructive alignment with task-oriented portfolio assessment\n", "abstract": " Approaches to learning have been shown to have a significant impact on student success in technical units. This paper reports on an action research study that applied the principles of constructive alignment to improve student learning outcomes in programming units. The proposed model uses frequent formative feedback to engage students with unit material, and encourage them to adopt deep approaches to learning. Our results provide a set of guiding principles and a structured teaching approach that focuses students on meeting unit learning objectives, the goal of constructive alignment. The results are demonstrated via descriptions of the resulting teaching and learning environment, student results, and staff and student reflections.", "num_citations": "24\n", "authors": ["573"]}
{"title": "Integrating and supporting entity relationship and object role models\n", "abstract": " This paper describes the conceptual integration and computer-based support of two important groups of conceptual data models, Entity Relationship Models and Object Role Models (e.g. NIAM). We perform conceptual integration using the conceptual data modelling language CoCoA to specify separate data models of individual notations. We then merge these into an integrated conceptual data model for both notations. These data models form the basis of the repository for an I-CASE tool supporting modelling with both notations, with full consistency management between the two notation data models.", "num_citations": "24\n", "authors": ["573"]}
{"title": "FastTagRec: fast tag recommendation for software information sites\n", "abstract": " Software information sites such as StackOverflow and Freeecode enable information sharing and communication for developers around the world. To facilitate correct classification and efficient search, developers need to provide tags for their postings. However, tagging is inherently an uncoordinated process that depends not only on developers\u2019 understanding of their own postings but also on other factors, including developers\u2019 English skills and knowledge about existing postings. As a result, developers keep creating new tags even though existing tags are sufficient. The net effect is an ever increasing number of tags with severe redundancy along with more postings over time. Any algorithms based on tags become less efficient and accurate. In this paper we propose FastTagRec, an automated scalable tag recommendation method using neural network-based classification. By learning existing postings\u00a0\u2026", "num_citations": "23\n", "authors": ["573"]}
{"title": "Collaborative work with the World Wide Web: adding CSCW support to a Web browser\n", "abstract": " There has been much recent interest in using the World Wide Web to facilitate distributed, cooperative work. Unfortunately, most existing Internet tools do not provide adequate cooperative work support to make this possible. We describe our efforts in extending a simple Web browser to support a range of CSCW facilities, including telepointers, group awareness widgets, text chats, shared whiteboards, collaborative note, message and URL annotations, and collaborative text editors. We also discuss the preliminary results of usability tests of this browser which show how effectively these different CSCW extensions support cooperative work with the World Wide Web.", "num_citations": "23\n", "authors": ["573"]}
{"title": "Improving Cloud-based Online Social Network Data Placement and Replication\n", "abstract": " Online social networks make it more convenient for people to find and communicate with other people based on shared interests, ideas, association with different groups, etc. Common social networks such as Facebook and Twitter have hundreds of millions or even billions of users scattered all around the world sharing interconnected data. Users demand low latency access to not only their own data but also their friends' data, often very large, e.g. videos, pictures etc. However, social network service providers have a limited monetary capital to store every piece of data everywhere to minimise users' data access latency. Geo-distributed cloud services with virtually unlimited capabilities are suitable for large scale social networks data storage in different geographical locations. Key problems including how to optimally store and replicate these huge datasets and how to distribute the requests to different datacenters\u00a0\u2026", "num_citations": "22\n", "authors": ["573"]}
{"title": "DeepSoft: A vision for a deep model of software\n", "abstract": " Although software analytics has experienced rapid growth as a research area, it has not yet reached its full potential for wide industrial adoption. Most of the existing work in software analytics still relies heavily on costly manual feature engineering processes, and they mainly address the traditional classification problems, as opposed to predicting future events. We present a vision for DeepSoft, an end-to-end generic framework for modeling software and its development process to predict future risks and recommend interventions. DeepSoft, partly inspired by human memory, is built upon the powerful deep learning-based Long Short Term Memory architecture that is capable of learning long-term temporal dependencies that occur in software evolution. Such deep learned patterns of software can be used to address a range of challenging problems such as code and task recommendation and prediction. DeepSoft\u00a0\u2026", "num_citations": "21\n", "authors": ["573"]}
{"title": "Architecture for a Component-based, Plug-in Micro-payment System\n", "abstract": " Micro-payment systems have the potential to provide non-intrusive, high-volume and low-cost pay-as-you-use services for a wide variety of web-based applications. However, adding micro-payment support to web-sites is usually time-consuming and intrusive, both to the web site\u2019s software architecture and its user interface implementation. We describe a plug-in, component model for adding micro-payment support to web applications. We use J2EE software components to encapsulate micro-payment E-coin debiting and redemption and discrete user interface enhancement. A CORBA infrastructure is used to inter-connect J2EE and non-J2EE vendors and micro-payment brokers. We demonstrate the feasibility of our approach with an on-line, pay-as-you-use journal portal example and outline an approach to using web services to further generalize our architecture.", "num_citations": "21\n", "authors": ["573"]}
{"title": "StressCloud: A Tool for Analysing Performance and Energy Consumption of Cloud Applications\n", "abstract": " Finding the best deployment configuration that maximises energy efficiency while guaranteeing system performance of cloud applications is an extremely challenging task. It requires the evaluation of system performance and energy consumption under a wide variety of realistic workloads and deployment configurations. This paper demonstrates StressCloud, an automatic performance and energy consumption analysis tool for cloud applications in real-world cloud environments. StressCloud supports 1) the modelling of realistic cloud application workloads, 2) the automatic generation and running of load tests, and 3) the profiling of system performance and energy consumption.", "num_citations": "20\n", "authors": ["573"]}
{"title": "Experiences in developing a micro-payment system for peer-to-peer networks\n", "abstract": " Micro-payment systems are an important part of peer-to-peer (P2P) networks and address the \u201cfree-rider\u201d problem in most existing content sharing systems. To address this issue, the authors have developed a new micro-payment system for content sharing in P2P networks called P2P-Netpay. This is an offline, debit based protocol that provides a secure, flexible, usable and reliable credit service. This article compares micro-payment with non-micro-payment credit systems for file sharing applications and finds that this approach liberates the \u201cfree-rider\u201d problem. The authors analyse the heuristic evaluation performed by a set of evaluators and present directions for research aiming to improve the overall satisfaction and efficiency of the proposed model.", "num_citations": "20\n", "authors": ["573"]}
{"title": "A data collection tool for sketched diagrams\n", "abstract": " Repositories of digital ink sketches would be invaluable for testing and evaluation of sketch recognition software. However, there is no existing tool for flexible data collection and management of digital ink data for building repositories of hand drawn diagrams. We present a tool for the efficient collection, management and analysis of ink data. A resultant dataset records each ink stroke accompanied by participant and diagram information, stroke labels and measurements of various stroke features. This tool enables the effective construction of a large database of sketches to aid the development of recognition techniques.", "num_citations": "20\n", "authors": ["573"]}
{"title": "Multiple textual and graphical views for Interactive Software Development Environments\n", "abstract": " Diagram construction can be used to visually analyse and design a complex software system using natural, graphical representations describing high-level structure and semantics. Textual programming can specify detailed documentation and functionality not well expressed at a visual level. Integrating multiple textual and graphical views of software development allows programmers to utilise both representations as appropriate. Consistency management between these views must be automatically maintained by the development environment.MViews, a model for such software development environments, has been developed. MViews supports integrated textual and graphical views of software development with consistency management. MViews provides flexible program and view representation using a novel object dependency graph approach. Multiple views of a program may contain common information and are stored as graphs with textual or graphical renderings and editing. Change propagation between program components and views is supported using a novel update record mechanism. Different editing tools are integrated as views of a common program repository and new program representations and editors can be integrated without affecting existing views.", "num_citations": "20\n", "authors": ["573"]}
{"title": "An approach to developing web services with aspect-oriented component engineering\n", "abstract": " Web services have become a popular new technology for describing, locating and using distributed system functionality. However, existing web service development approaches lack aspect-based development support for distributed components. We describe the application of Aspect-Oriented Component Engineering to web service development. This includes grouping web service operations into components and characterising the cross-cutting functional and non-functional aspects of these components such as transaction support, distribution technology, persistency, performance and reliability, security, resource utilisation, collaboration support and so on. Web services are described with an extended, aspect-oriented description language and are indexed and located using these aspect extensions. Aspect descriptions are used to statically and dynamically validate located services and to integrate them with client components. We describe an example of applying this approach to a highly distributed sample application.", "num_citations": "19\n", "authors": ["573"]}
{"title": "External requirements of groupware development tools\n", "abstract": " The EHCI\u201998 Workshop on Requirements of Groupware Development Tools examined six groupware applications in order to derive requirements for tools for developing groupware. We hope that these requirements will be useful to designers of new tools in motivating what features their tools should have.", "num_citations": "19\n", "authors": ["573"]}
{"title": "Off-line micro-payment system for content sharing in P2P networks\n", "abstract": " Micro-payment systems have the potential to provide non-intrusive, high-volume and low-cost pay-as-you-use services for a wide variety of web-based applications. We propose an extension, P2P-NetPay, a micro-payment protocol characterized by off-line processing, suitable for peer-to-peer network services sharing. Our approach provides high performance and security using one-way hashing functions for e-coin encryption. In our P2P-NetPay protocol, each peer\u2019s transaction does not involve any broker and double spending is detected during the redeeming transaction. We describe the motivation for P2P-NetPay and describe three transactions of the P2P-NetPay protocol in detail to illustrate the approach. We then discuss future research on this protocol.", "num_citations": "18\n", "authors": ["573"]}
{"title": "A Taxonomy of Supervised Learning for IDSs in SCADA Environments\n", "abstract": " Supervisory Control and Data Acquisition (SCADA) systems play an important role in monitoring industrial processes such as electric power distribution, transport systems, water distribution, and wastewater collection systems. Such systems require a particular attention with regards to security aspects, as they deal with critical infrastructures that are crucial to organizations and countries. Protecting SCADA systems from intrusion is a very challenging task because they do not only inherit traditional IT security threats but they also include additional vulnerabilities related to field components (e.g., cyber-physical attacks). Many of the existing intrusion detection techniques rely on supervised learning that consists of algorithms that are first trained with reference inputs to learn specific information, and then tested on unseen inputs for classification purposes. This article surveys supervised learning from a specific security\u00a0\u2026", "num_citations": "17\n", "authors": ["573"]}
{"title": "Is Deep Learning Better than Traditional Approaches in Tag Recommendation for Software Information Sites?\n", "abstract": " ContextInspired by the success of deep learning in other domains, this new technique been gaining widespread recent interest in being applied to diverse data analysis problems in software engineering. Many deep learning models, such as CNN, DBN, RNN, LSTM and GAN, have been proposed and recently applied to software engineering tasks including effort estimation, vulnerability analysis, code clone detection, test case selection, requirements analysis and many others. However, there is a perception that applying deep learning is a \u201dsilver bullet\u201d if it can be applied to a software engineering data analysis problem.ObjectThis motivated us to ask the question as to whether deep learning is better than traditional approaches in tag recommendation task for software information sites.MethodIn this paper we test this question by applying both the latest deep learning approaches and some traditional approaches\u00a0\u2026", "num_citations": "17\n", "authors": ["573"]}
{"title": "A comparative analysis of design principles for project-based IT courses\n", "abstract": " Project-based courses have become increasingly popular in Information Technology (IT) curricula. We have found the design of such courses needs to take into account a variety of desired learning outcomes in order to maximise the efectiveness of such courses. This paper describes four quite different project-based courses we have developed and run over several years, and are continuing to develop. We compare and contrast the different course objectives, group management, project characteristics, course content and student assessment used in these courses. We also reflect on the evolution of these courses and how feedback from diflerent kinds of course evaluation is used to continue their refinement. We have our experiences will be useful for others designing or refining their own projectbased courses.", "num_citations": "16\n", "authors": ["573"]}
{"title": "Maintenance-Related Concerns for Post-deployed Ethereum Smart Contract Development: Issues, Techniques, and Future Challenges\n", "abstract": " Software development is a very broad activity that captures the entire life cycle of a software, which includes designing, programming, maintenance and so on. In this study, we focus on the maintenance-related concerns of the post-deployment of smart contracts. Smart contracts are self-executed programs that run on a blockchain. They cannot be modified once deployed and hence they bring unique maintenance challenges compared to conventional software. According to the definition of ISO/IEC 14764, there are four kinds of software maintenance, ie, corrective, adaptive, perfective, and preventive maintenance. This study aims to answer (i) What kinds of issues will smart contract developers encounter for corrective, adaptive, perfective, and preventive maintenance after they are deployed to the Ethereum?(ii) What are the current maintenance-related methods used for smart contracts? To obtain the answers to\u00a0\u2026", "num_citations": "15\n", "authors": ["573"]}
{"title": "PathRec: Visual Analysis of Travel Route Recommendations\n", "abstract": " We present an interactive visualisation tool for recommending travel trajectories. This system is based on new machine learning formulations and algorithms for the sequence recommendation problem. The system starts from a map-based overview, taking an interactive query as starting point. It then breaks down contributions from different geographical and user behavior features, and those from individual points-of-interest versus pairs of consecutive points on a route. The system also supports detailed quantitative interrogation by comparing a large number of features for multiple points. Effective trajectory visualisations can potentially benefit a large cohort of online map users and assist their decision-making. More broadly, the design of this system can inform visualisations of other structured prediction tasks, such as for sequences or trees.", "num_citations": "15\n", "authors": ["573"]}
{"title": "A Framework for Convergence of Cloud Services and Internet of Things\n", "abstract": " Today, Cloud Computing and the Internet of things are two \u201cmajor forces\u201d that drive the development of new Information Technology (IT) solutions. Many Internet of things (IoT) based large-scale applications rely on a cloud platform for data processing and storage. However, big data generated or collected by large-scale geo-distributed devices needs to be transferred to the cloud, often becoming a bottleneck for the system. In this paper, we propose a framework that integrates popular cloud services with a network of IoT devices. In the framework, novel methods have been designed for reliable and efficient data transportation. This framework provides a convergence of cloud services and devices that will ease the development of IoT based, cloud-enabled applications. We have implemented a prototype of the framework to demonstrate the convergence of popular cloud services and IoT technologies.", "num_citations": "15\n", "authors": ["573"]}
{"title": "REInDetector: A Framework for Knowledge-based Requirements Engineering\n", "abstract": " Requirements engineering (RE) is a coordinated effort to allow clients, users, and software engineers to jointly formulate assumptions, constraints, and goals about a software solution. However, one of the most challenging aspects of RE is the detection of inconsistencies between requirements. To address this issue, we have developed REInDetector, a knowledge-based requirements engineering tool, supporting automatic detection of a range of inconsistencies. It provides facilities to elicit, structure, and manage requirements with distinguished capabilities for capturing the domain knowledge and the semantics of requirements. This permits an automatic analysis of both consistency and realizability of requirements. REInDetector finds implicit consequences of explicit requirements and offers all stakeholders an additional means to identify problems in a more timely fashion than existing RE tools. In this paper, we\u00a0\u2026", "num_citations": "15\n", "authors": ["573"]}
{"title": "The influence of textual and verbal word-of-mouth on website usability and visual appeal\n", "abstract": " Word-of-Mouth (WOM) may impact the perception and experience of website usability and visual appeal. This study aimed to highlight the effects of WOM, implemented textually and verbally, on subjective and objective usability and visual appeal in a web environment. This research was spread over three studies and was undertaken using an unfamiliar city council website to exclude the influence of past experiences and to allow for greater control of WOM implementation. The statistical results showed that both visual appeal and objective and subjective usability were influenced via text that established expectations around these and that the results were only more compelling when verbal WOM was added. The result implications show that when the message is simple, such as it usually is in communication on social media and advertising, then it does impact people\u2019s perceptions of website visual appeal\u00a0\u2026", "num_citations": "14\n", "authors": ["573"]}
{"title": "Ontology-based Automated Support for Goal-Use case Model Analysis\n", "abstract": " Combining goal-oriented and use case modeling has been proven to be an effective method in requirements elicitation and elaboration. To ensure the quality of such modeled artifacts, a detailed model analysis needs to be performed. However, current requirements engineering approaches generally lack reliable support for automated analysis of consistency, correctness and completeness (3Cs problems) between and within goal models and use case models. In this paper, we present a goal\u2013use case integration framework with tool support to automatically identify such 3Cs problems. Our new framework relies on the use of ontologies of domain knowledge and semantics and our goal\u2013use case integration meta-model. Moreover, functional grammar is employed to enable the semiautomated transformation of natural language specifications into Manchester OWL Syntax for automated reasoning. The\u00a0\u2026", "num_citations": "14\n", "authors": ["573"]}
{"title": "Flexible modeling tools (flexitools2010)\n", "abstract": " Modeling tools are often not used for tasks during the software lifecycle for which they should be helpful; more free-from approaches, such as office tools and white boards, are frequently used instead. Why is this? What might be done to make modeling tools more suitable? What key research challenges must be overcome to achieve this? The goal of this workshop is to bring together people who understand the activities and needs of developers and other stakeholders throughout the software lifecycle, user interface design and tool infrastructure to explore these questions.", "num_citations": "14\n", "authors": ["573"]}
{"title": "Cost-Effective Social Network Data Placement and Replication using Graph-Partitioning\n", "abstract": " Social network users are connected based on shared interests, ideas, association with different groups, etc. Common social networks such as Facebook and Twitter have hundreds of millions or even billions of users scattered all around the world sharing interconnected data. Users demand low latency access to not only their own data but also their friends' data. However, social network service providers wish to pay as less as possible to store all data items to meet users' data access latency requirement. Geo-distributed cloud services with virtually unlimited capabilities are suitable for large scale social networks data storage in different geographical locations. Key problems including how to optimally store and replicate these huge data items and how to distribute the requests to different datacentres are addressed in this paper. A novel graph-partitioning based approach is proposed to find a near-optimal data\u00a0\u2026", "num_citations": "13\n", "authors": ["573"]}
{"title": "Mobile Application Testing in Industrial Contexts: An Exploratory Multiple Case Study\n", "abstract": " Recent empirical studies in the area of mobile application testing indicate the need for specific testing techniques and methods for mobile applications. This is due to mobile applications being significantly different than traditional web and desktop applications, particularly in terms of the physical constraints of mobile devices and the very different features of their operating systems. In this paper, we presented a multiple case-study involving four software development companies in the area of mobile and smartphones application. We aimed to identify testing techniques currently being applied by developers and challenges that they are facing. Our principle results are that many industrial teams seem to lack sufficient knowledge on how to test mobile applications, particularly in the areas of mobile application life-cycle conformance, context-awareness, and integration testing. We also found that there is no\u00a0\u2026", "num_citations": "13\n", "authors": ["573"]}
{"title": "CONVErT: A Framework for Complex Model Visualisation and Transformation\n", "abstract": " Model Driven Engineering (MDE) has become a commonly used approach in software engineering. It promotes using models as primary artefacts and proposes methods for transforming them to desired software products. However, the specification of models and their transformations in MDE with current techniques is not user-friendly, due to excessive use of high level abstract models and textual representation of transformation languages. This paper briefly describes CONVErT, an approach and tool developed for user-centric transformation generation using concrete model visualisations.", "num_citations": "13\n", "authors": ["573"]}
{"title": "EML: A tree overlaybased visual language for business process modelling\n", "abstract": " \u2022 However, a common source of difficulty in all of these approaches is an appropriate visual method to reduce the complexity of large business modelling diagrams\u2022 Most existing modelling technologies are effective in only limited problem domains or have major weaknesses when attempting to scale to large systems modelling eg \u201ccobweb\u201d and \u201clabyrinth\u201d problems", "num_citations": "13\n", "authors": ["573"]}
{"title": "Supporting dynamic software tool integration via web service-based components\n", "abstract": " Most software engineering tools come with fixed functionality or limited plug-in extension capabilities. Building software development environments that support truly dynamic extension capabilities to incorporate a wide range of additional facilities at run-time has proved to be a very challenging task. We describe a new approach using Web service components to support the dynamic discovery, integration and invocation of remote software tool facilities for JEdit, an open source integrated development environment. In this approach discrete software tool functionality is encapsulated in software \"toolets\", accessed as remote Web service-based components. These toolet services are registered and discovered, and then dynamically integrated and invoked from within the JEdit IDE as required. We describe the architecture of our approach, key design and implementation issues, and illustrate the feasibility of the\u00a0\u2026", "num_citations": "13\n", "authors": ["573"]}
{"title": "An architecture for efficient, flexible enterprise system integration\n", "abstract": " Integrating complex enterprise systems is challenging and reliability and performance of the integrated systems can be problematic when using typical solutions of distributed transactions or on-demand message-based querying. We describe a data-oriented approach for enterprise system integration that uses information brokering. A broker application isolates the interactions between a local enterprise application server and a wide variety of remote systems, performing data acquisition, storage, transformation, update and status management. We describe a prototype book brokering system developed using Java 2 Enterprise Edition, CORBA, Java Messaging Service and Web Services and using our integration strategy. We outline the architecture, design and implementation of this prototype and summarise our experiences with this information integration technique.", "num_citations": "13\n", "authors": ["573"]}
{"title": "Supporting aspect-oriented component-based systems engineering\n", "abstract": " Current approaches to component-based systems development do not adequately capture high-level knowledge about component provided and required services for use during design, implementation and runtime deployment. We describe a new approach to engineering such systems that characterises components by the various\" aspects\" of the overall system each component provides to or requires from end users or other components. These aspects include user interface, persistency, distribution, collaboration, inter-component relationships. Appropriate software architecture and CASE tool support is needed in order to effectively describe, reason about and implement this encoding of high level knowledge about components. We motivate the need for aspect-oriented component engineering, describe and illustrate our approach and its current software architecture and development tool support, and report on our component-based system development experiences.", "num_citations": "13\n", "authors": ["573"]}
{"title": "Interpreting Cloud Computer Vision Pain-Points: A Mining Study of Stack Overflow,\n", "abstract": " Intelligent services are becoming increasingly more pervasive; application developers want to leverage the latest advances in areas such as computer vision to provide new services and products to users, and large technology firms enable this via RESTful APIs. While such APIs promise an easy-to-integrate on-demand machine intelligence, their current design, documentation and developer interface hides much of the underlying machine learning techniques that power them. Such APIs look and feel like conventional APIs but abstract away data-driven probabilistic behaviour\u2014the implications of a developer treating these APIs in the same way as other, traditional cloud services, such as cloud storage, is of concern. The objective of this study is to determine the various pain-points developers face when implementing systems that rely on the most mature of these intelligent services, specifically those that provide\u00a0\u2026", "num_citations": "12\n", "authors": ["573"]}
{"title": "Towards Human-Centric Model-Driven Software Engineering\n", "abstract": " Many current software systems suffer from a lack of consideration of the human differences between end users. This includes age, gender, language, culture, emotions, personality, education, physical and mental challenges, and so on. We describe our work looking to consider these characteristics by incorporation of human centric-issues throughout the model-driven engineering process lifecycle. We propose the use of the co-creational\u201d living lab\u201d model to better collect human-centric issues in the software requirements. We focus on modelling these human-centric factors using domain-specific visual languages, themselves humancentric modelling artefacts. We describe work to incorporate these human-centric issues into model-driven engineering design models, and to support both code generation and run-time adaptation to different user human factors. We discuss continuous evaluation of such human-centric issues in the produced software and feedback of user reported defects to requirements and model refinement.", "num_citations": "11\n", "authors": ["573"]}
{"title": "Capturing Security Requirements Using Essential Use Cases (EUCs)\n", "abstract": " Capturing security requirements is a complex process, but it is crucial to the success of a secure software product. Hence, requirements engineers need to have security knowledge when eliciting and analyzing the security requirements from business requirements. However, the majority of requirements engineers lack such knowledge and skills, and they face difficulties to capture and understand many security terms and issues. This results in capturing inaccurate, inconsistent and incomplete security requirements that in turn may lead to insecure software systems. In this paper, we describe a new approach of capturing security requirements using an extended Essential Use Cases (EUCs) model. This approach enhances the process of capturing and analyzing security requirements to produce accurate and complete requirements. We have evaluated our prototype tool using usability testing and assessment of the quality of our generated EUC security patterns.", "num_citations": "11\n", "authors": ["573"]}
{"title": "Comparing and Contrasting Micro-payment Models for Content Sharing in P2P Networks\n", "abstract": " Micro-payment systems have the potential to provide non-intrusive, high-volume and low-cost pay-as-you-use services for a wide variety of web-based applications. We proposed a new model, P2P-NetPay, a micro-payment protocol characterized by off-line processing, suitable for peer-to-peer network service charging. P2P micro-payment systems must provide a secure, highly efficient, flexible, usable and reliable environment, the key issues in P2P micro-payment systems development. Therefore, in order to assist in the design of an efficient micro-payment model suitable for P2P networks, we compare and contrast several existing P2P micro-payment models in this paper and outline a new P2P micro-payment scheme we have been developing that addresses the disadvantages in current schemes.", "num_citations": "11\n", "authors": ["573"]}
{"title": "An environment for automated performance evaluation of J2EE and ASP. NET thin-client architectures\n", "abstract": " Assessing the likely run-time performance of applications using thin-client architectures during their design is very difficult. We describe SoftArch/Thin, a thin-client test-bed generator that synthesises performance test-bed thin-client and server code from high-level software architecture models. This generated code is performance tested using a third-party tool and the results summarised. Architecture models can be evolved and tests repeated during application development to inform software engineers of realistic performance characteristics of their designs. Our environment currently supports J2EE and ASP.NET-based thin-client code generation and performance testing.", "num_citations": "11\n", "authors": ["573"]}
{"title": "Customer perceptions of a thin-client micro-payment system: issues and experiences\n", "abstract": " Two fundamental payment methods exist for on-line information purchase: macro-payment and micro-payment. Traditional macro-payment methods, like credit and charge cards and digital currency, are suitable for large-value, low-volume transactions. However, large-volume, low-value commodities, such as discrete units of information from a Web site, better suit a micro-payment model. In micro-payment, customers pay for large numbers of small value goods (eg per-Web page view) with \u201ce-coins\u201d, typically of very small value each. We have carried out an empirical assessment of micro-payment and macro-payment purchasing models for an on-line newspaper application. We report on the design of our experiment, the two kinds of micro-payment (client and server-side e-wallets) used, and customer feedback. We also carried out an assessment of customer effort and economic trade-off when using these services\u00a0\u2026", "num_citations": "11\n", "authors": ["573"]}
{"title": "Web-enabling an integrated health informatics system\n", "abstract": " Potential users of Health Information Systems include General Practioners, Pharmacists, Hospital Staff, Community Nurses and patients. Ideally an infrastructure for such a system will support the integration of data and processing as well as a diverse range of user interface technologies and devices. We describe a prototype system that uses a range of current Java-based object-oriented technologies to achieve this, including CORBA, XML, Jini, Enterprise Java Beans, and Java Server Pages (for both HTML and WML). We present an architecture for this system, key parts of its object-oriented design, examples of some of its user interfaces, report on our experiences building and evaluating this system. We identify strengths and weaknesses with these technologies we hope will be useful for others considering adding a range of web-and mobile-interfaces to enterprise systems.", "num_citations": "11\n", "authors": ["573"]}
{"title": "A method and support environment for distributed software component engineering\n", "abstract": " Engineering component based software systems is challenging, and made even more difficult when multiple developers are involved. A suitable software process for distributed component engineering is required, along with appropriate development notations and collaborative work supporting tools. The paper describes a component engineering methodology we have been developing, along with examples of its notations, development tools and tool collaborative work facilities. Key characteristics of the process and notations include their use of multiple perspectives on component capabilities and the extension of the Unified Modelling Language to capture these. We have integrated and extended several software tools to support the use of this new component engineering method. We have also provided a range of collaborative work facilities in these tools to facilitate collaborative component engineering. We\u00a0\u2026", "num_citations": "11\n", "authors": ["573"]}
{"title": "Human Interaction Issues for User-configurable Collaborative Editing Systems\n", "abstract": " \u00a9 1998 IEEE. Personal use of this material is permitted. However, permission to reprint/republish this material for advertising or promotional purposes or for creating new collective works for resale or redistribution to servers or lists, or to reuse any copyrighted component of this work in other works must be obtained from the IEEE.", "num_citations": "11\n", "authors": ["573"]}
{"title": "Experiences with facilitating student learning in a group information systems project course\n", "abstract": " One of the main aims of university education is to help students become intellectually independent. As the Software Engineering and Information Systems fields are changing so rapidly, such independent thinkers are essential. This paper describes a third-year Information Systems Project course we have designed to facilitate the process of university students becoming real-world software practitioners. The course covers a diverse range of Information Systems Development topics. Students work together in groups throughout the course on a single project chosen from a real-world business client. The organisation and rationale for the course structure are described together with our experiences with the course evolution, its successful and unsuccessful aspects, and student and industry feedback.", "num_citations": "11\n", "authors": ["573"]}
{"title": "On the Reproducibility and Replicability of Deep Learning in Software Engineering\n", "abstract": " Context: Deep learning (DL) techniques have gained significant popularity among software engineering (SE) researchers in recent years. This is because they can often solve many SE challenges without enormous manual feature engineering effort and complex domain knowledge. Objective: Although many DL studies have reported substantial advantages over other state-of-the-art models on effectiveness, they often ignore two factors: (1) reproducibility\u2014whether the reported experimental results can be obtained by other researchers using authors\u2019 artifacts (i.e., source code and datasets) with the same experimental setup; and (2) replicability\u2014whether the reported experimental result can be obtained by other researchers using their re-implemented artifacts with a different experimental setup. We observed that DL studies commonly overlook these two factors and declare them as minor threats or leave them for\u00a0\u2026", "num_citations": "10\n", "authors": ["573"]}
{"title": "Adapting Teaching of a Software Engineering Service Course due to COVID-19\n", "abstract": " The COVID-19 pandemic has impacted almost every sphere of life. Higher education in Australia was similarly majorly impacted, and due to the sudden necessity of ensuring physical distancing, on campus teaching became impossible. Most of the higher educational institutes in Australia moved to using a distance education mode to continue delivery of teaching with barely a few weeks warning. This article presents experiences moving a data structures and networking course taught to Software Engineering students at an Australian university during COVID-19 pandemic to online delivery. Due to the nature of the course and student cohort, a number of challenges were faced teaching the course in online mode compared to that for which it was designed. We summarize key lessons learned and propose some guidelines for future course design to take advantage of online learning while maintaining learning\u00a0\u2026", "num_citations": "9\n", "authors": ["573"]}
{"title": "Exploring agile mobile app development in industrial contexts: A qualitative study\n", "abstract": " Agile development methods have been proposed as a natural fit for mobile app development contexts. Despite many studies addressing the adoption of agile methods for traditional web and desktop applications, there is a lack of studies of how mobile app development teams can adopt agile methods and the challenges they are facing. Our study explores this area to better understand how some representative industrial teams approach agile mobile app development, and the challenges they are facing. We conducted a qualitative study involving four different mobile app development companies. Our research method is based on multiple-case study design. From our findings, we argue that not all agile development principals are necessarily applicable within the mobile app development context. Furthermore, mobile app development teams face additional challenges when adopting agile methods such as\u00a0\u2026", "num_citations": "9\n", "authors": ["573"]}
{"title": "Efficient Keyword Search for Building Service-based Systems based on Dynamic Programming\n", "abstract": " The advances in service-oriented architecture (SOA) have fueled the demand for building service-based systems (SBSs) by composing existing services. Finding appropriate component services is a key step during the process for building SBSs. However, existing approaches require that system engineers have detailed knowledge of SOA techniques, which is often too demanding. A recent approach has been proposed to address this issue. However, it suffers from poor efficiency, which is increasingly critical as the service repository continues to grow. To address this issue, this paper proposes KS3+, a new, highly efficient approach that allows a system engineer to query for a system solution with a few keywords that represent the required system tasks. Modeling the problem of answering such a keyword query as a dynamic programming problem, KS3+ can quickly find a system solution composed of\u00a0\u2026", "num_citations": "9\n", "authors": ["573"]}
{"title": "Parametric statecharts: designing flexible IoT apps: deploying android m-health apps in dynamic smart-homes\n", "abstract": " Mobile apps can integrate sensors and actuators in Internet-of-Things systems to achieve novel and diverse functionalities. For instance, apps can implement self-management and monitoring functions to help patients manage a large number of health conditions within their (smart-) homes. However, each smart-home may contain a different and often dynamic sensor-actuator configuration and it is undesirable to write new code for every new installation or change. Statecharts present an appropriate formal and visual design model to design apps and support automatic code generation. However, these designs assume a specific and static sensor-actuator configuration. We propose parametric statecharts, an extension to statecharts that can be automatically customised to a dynamic smart-home's configuration. We develop a translator to convert parametric statecharts into standard statecharts customised to a given\u00a0\u2026", "num_citations": "9\n", "authors": ["573"]}
{"title": "Heuristics-based Indoor Positioning Systems: A Systematic Literature Review\n", "abstract": " Context: Many heuristics-based indoor positioning approaches have been developed to enhance positioning estimation. However, there is no comprehensive survey of these heuristics information and methods. Objective: The main objective of this study is to provide a holistic view and an in-depth analysis of what heuristics information and methods have been used, their general achievements and limitations. This study aims to provide a comprehensive summary to facilitate further research on indoor positioning heuristics. Method: We conducted a systematic literature review (SLR) on indoor positioning heuristics. Results: Ninety-three (93) primary studies were selected. We found two general types of heuristics information and four primary heuristics methods, which we summarised in this paper. We also found that many of these positioning heuristics are tested in experimental settings only. Some heuristics claim\u00a0\u2026", "num_citations": "9\n", "authors": ["573"]}
{"title": "A Study of Architectural Information Foraging in Software Architecture Documents\n", "abstract": " When using Software Architecture documents (ADs), users typically \u201cforage\u201d for information. However, it is little understood how they do this foraging or how to structure architecture documentation to assist them. We conducted a survey of two different groups of foragers, industry practitioner and academic AD users, to investigate issues - types of forages, foraging sequences and styles - related to task-based architectural information foraging in software architecture documents. Our results show that there were different pre-conceived ideas of what to forage for prior to the search, but during foraging there was commonly foraged information. The different groups of foragers place different emphasis on information related to quality requirements, purpose of the system, use cases, physical view and process view. Foraging sequences starting with certain information were suggested to better support understanding of the\u00a0\u2026", "num_citations": "9\n", "authors": ["573"]}
{"title": "Extending a persistent object framework to enhance enterprise application server performance\n", "abstract": " High-volume transaction processing speed is critical for adequate performance in many enterprise application servers. We describe our experiences using an object-oriented persistency framework to achieve greatly enhanced server response by the transparent use of main-memory database technology. We took an application server whose data persistency is abstracted via a persistent object framework and replaced a version of the framework using a relational database for persistency with one that uses a memory database. No changes to any of the application server components were necessary to achieve this and we achieved between 10-20 times transaction processing performance improvement. We briefly discuss some extensions to our memory database and mapping framework necessary for large-scale enterprise systems support and for data-oriented systems integration. We hope our experiences will be useful for others, both in terms of techniques for abstracting object persistency mechanisms and in approaches to application server performance enhancement.", "num_citations": "9\n", "authors": ["573"]}
{"title": "An implementation architecture for aspect-oriented component engineering\n", "abstract": " Aspect-oriented component engineering (AOCE) is a new technique for engineering software components, using a concept of provided and required systemic aspects of a component\u2019s nonfunctional and functional characteristics to support component composition and interaction. These aspects include component user interfaces, collaborative work support, distribution and persistency, security, data management, processing, component inter-relationship and configuration characteristics. We describe support for AOCE in the JViews software architecture via the use of aspects, aspect details and detail properties. We describe implementation of this aspect information using the Java language, including the use of AspectDetail classes to augment JavaBeans, with different specialisations supporting decoupled component aspect querying and access to component services in a very de-coupled manner.", "num_citations": "9\n", "authors": ["573"]}
{"title": "Visual specification and monitoring of software agents in decentralized process-centred environments\n", "abstract": " Distributed, cooperating software agents are useful in many problem domains, such as task automation and work coordination in process-centered environments. We describe a visual language for specifying such software agents, which uses the composition of event-based software components. These specifications may contain interfaces to remotely executing agents, and agents may be run locally or on distributed machines using a decentralized software architecture. As facilities to configure and monitor the state and activities of such distributed, cooperating software agents is essential, we provide primarily visual capabilities to achieve this. Our static and dynamic software agent visualization techniques have been used on several projects where distributed information processing, system interfacing, work coordination and task automation are required. We illustrate our visualization techniques with examples\u00a0\u2026", "num_citations": "9\n", "authors": ["573"]}
{"title": "Global teams for the millennium\n", "abstract": " Offers a glimpse of leading edge work in the management of geographically dispersed teams, looking at the practical aspects of using communication and information technology in business applications.", "num_citations": "9\n", "authors": ["573"]}
{"title": "Coordinating Collaborative Work in an Integrated Information Systems Engineering Enviornment\n", "abstract": " The development of complex Information Systems requires the use of many Information Systems engineering tools. These diverse tools need to be integrated in order to be effectively used by multiple cooperating developers. In addition, the users of these environments require features that facilitate effective cooperation, such as support for collaboratively planning cooperative work, notification of changes to parts of a system under development (but only when necessary or desired), support for keeping aware of other developers' work contexts, and the ability to flexibly engineer or adapt development processes and methods. We describe an integrated Information Systems engineering environment which includes a work coordination tool supporting these requirements.", "num_citations": "9\n", "authors": ["573"]}
{"title": "Human-centric Software Engineering for Next Generation Cloud- and Edge-based Smart Living Applications\n", "abstract": " Humans are a key part of software development, including customers, designers, coders, testers and end users. In this keynote talk I explain why incorporating human-centric issues into software engineering for next-generation applications is critical. I use several examples from our recent and current work on handling human-centric issues when engineering various \u2018smart living\u2019 cloud- and edge-based software systems. This includes using human-centric, domain-specific visual models for non-technical experts to specify and generate data analysis applications; personality impact on aspects of software activites; incorporating end user emotions into software requirements engineering for smart homes; incorporating human usage patterns into emerging edge computing applications; visualising smart city-related data; reporting diverse software usability defects; and human-centric security and privacy requirements\u00a0\u2026", "num_citations": "8\n", "authors": ["573"]}
{"title": "Providing Fairer Resource Allocation for Multi-tenant Cloud-based Systems\n", "abstract": " A fundamental premise in cloud computing is trying to provide a more sophisticated computing resource sharing capability. In order to provide better allocation, the Dominant Resource Fairness (DRF) approach has been developed to address the \"fair resource allocation problem\" at the application layer for multi-tenant cloud applications. Nevertheless conventional DRF only considers the interplay of CPU and memory, which may result in over allocation of resources to one tenant's application to the detriment of others. In this paper, we propose an improved DRF algorithm with 3-dimensional demand vector to support disk resources as the third dominant shared resource, enhancing fairer resource sharing. Our technique is integrated with LINUX 'group' controls resource utilisation and realises data isolation to avoid undesirable interactions between co-located tasks. Our method ensures all tenants receive system\u00a0\u2026", "num_citations": "8\n", "authors": ["573"]}
{"title": "A Survey of Australian Human Services Agency Software Usage\n", "abstract": " Human Services agencies use a wide range of software systems to manage caseloads, maintain records, deliver services to clients, and for interagency communication. Some systems are generic, such as Word or Excel, while some are specialized to the organization, such as specialized databases for tracking case notes. Some software systems are shared across organizations. We surveyed nearly 40 Australian Human Services agencies to ascertain the range of software currently in use by agencies and their opinions on it, with a view to identifying promising new Human Services applications. We interviewed representatives from a selection of smaller agencies. This resulted in detailed feedback on key issues to consider when developing and deploying new Human Services software.", "num_citations": "8\n", "authors": ["573"]}
{"title": "Cost Effective Dynamic Data Placement for Efficient Access of Social Networks\n", "abstract": " Social networks boast a huge number of worldwide users who join, connect, and publish various content, often very large, e.g. videos, images etc. For such very large-scale data storage, data replication using geo-distributed cloud services with virtually unlimited capabilities are suitable to fulfill the users\u2019 expectations, such as low latency when accessing their and their friends\u2019 data. However, service providers ideally want to spend as little as possible on replicating users\u2019 data. Moreover, social networks have a dynamic nature and thus replicas need to be adaptable according to the environment, users\u2019 behaviors, social network topology, and workload at runtime. Hence, it is not only crucial to have an optimized data placement and request distribution \u2013 meeting individual users\u2019 acceptable latency requirements while incurring minimum cost for service providers \u2013 but the data placement must be adapted based on\u00a0\u2026", "num_citations": "7\n", "authors": ["573"]}
{"title": "Performance Analysis using Subsuming Methods: An Industrial Case Study\n", "abstract": " Large-scale object-oriented applications consist of tens of thousands of methods and exhibit highly complex runtime behaviour that is difficult to analyse for performance. Typical performance analysis approaches that aggregate performance measures in a method-centric manner result in thinly distributed costs and few easily identifiable optimisation opportunities. Subsuming methods analysis is a new approach that aggregates performance costs across repeated patterns of method calls that occur in the application's runtime behaviour. This allows automatic identification of patterns that are expensive and represent practical optimisation opportunities. To evaluate the practicality of this analysis with a real world large-scale object-oriented application we completed a case study with the developers of letterboxd.com - a social network website for movie goers. Using the results of the analysis we were able to rapidly\u00a0\u2026", "num_citations": "7\n", "authors": ["573"]}
{"title": "Software Engineering for Multi-tenancy Computing - Challenges and Implications\n", "abstract": " Multi-tenancy is a cloud computing phenomenon. Multiple instances of an application occupy and share resources from a large pool, allowing different users to have their own version of the same application running and coexisting on the same hardware but in isolated virtual spaces. In this position paper we survey the current landscape of multi-tenancy, laying out the challenges and complexity of software engineering where multi-tenancy issues are involved. Multi-tenancy allows cloud service providers to better utilise computing resources, supporting the development of more flexible services to customers based on economy of scale, reducing overheads and infrastructural costs. Nevertheless, there are major challenges in migration from single tenant applications to multi-tenancy. These have not been fully explored in research or practice to date. In particular, the reengineering effort of multi-tenancy in Software-as\u00a0\u2026", "num_citations": "7\n", "authors": ["573"]}
{"title": "Developing CASE tools which support integrated development notations\n", "abstract": " This paper discusses the recent work of the authors in developing Integrated CASE (ICASE) tools which support multiple development notations. We use a four-step methodology to develop these integrated tools. The conceptual data models of different notations are first developed, and then merged into an integrated conceptual data model. Dynamic mappings between different notations components are used to describe how related notation components are kept consistent under change. The conceptual data models and mappings are used to implement individual CASE tools for each notation. Separate tools are then integrated by linking their repositories via a shared repository based on the integrated conceptual data model. We discuss extensions to this work which will provide MetaCASE facilities for environment generation and evolution.", "num_citations": "7\n", "authors": ["573"]}
{"title": "Integrated object-oriented software development in SPE\n", "abstract": " ABSTRACT SPE is a software development environment which supports multiple textual and graphical views of a program. Views are kept consistent with one another using a mechanism of update records. SPE is useful throughout all phases of the software development life-cycle. It provides support for conceptual level object-oriented analysis and design using diagrams, visual and textual programming, hypertext-based browsing, and visual debugging, together with a modification history. SPE is implemented as a specialisation of an object-oriented framework and provides an environment for Snart, an object-oriented programming language.", "num_citations": "7\n", "authors": ["573"]}
{"title": "A systematic review of scheduling approaches on multi-tenancy cloud platforms\n", "abstract": " Context:Scheduling in cloud is complicated as a result of multi-tenancy. Diverse tenants have different requirements, including service functions, response time, QoS and throughput. Diverse tenants require different scheduling capabilities, resource consumption and competition. Multi-tenancy scheduling approaches have been developed for different service models, such as Software as a Service (SaaS), Platform as a service (PaaS), Infrastructure as a Service (IaaS), and Database as a Service (DBaaS).Objective:In this paper, we survey the current landscape of multi-tenancy scheduling, laying out the challenges and complexity of software engineering where multi-tenancy issues are involved. This study emphasises scheduling policies, cloud provisioning and deployment with regards to multi-tenancy issues. We conduct a systematic literature review of research studies related to multi-tenancy scheduling\u00a0\u2026", "num_citations": "6\n", "authors": ["573"]}
{"title": "AndroZooOpen: Collecting Large-scale Open Source Android Apps for the Research Community\n", "abstract": " It is critical for research to have an open, well-curated, representative set of apps for analysis. We present a collection of open-source Android apps collected from several sources, including Github. Our dataset, AndroZooOpen, currently contains over 45,000 app artefacts, a representative picture of Github-hosted Android apps. For apps released on Google Play, metadata including categories, ratings and user reviews, are also stored. We share this new dataset as part of our ongoing research to better support and enable new research topics involving Android app artefact analysis, and as a supplement dataset for AndroZoo, a well-known app collection of close-sourced Android apps.", "num_citations": "6\n", "authors": ["573"]}
{"title": "Dual-Component Deep Domain Adaptation: A New Approach for Cross Project Software Vulnerability Detection\n", "abstract": " Owing to the ubiquity of computer software, software vulnerability detection (SVD) has become an important problem in the software industry and computer security. One of the most crucial issues in SVD is coping with the scarcity of labeled vulnerabilities in projects that require the laborious manual labeling of code by software security experts. One possible solution is to employ deep domain adaptation (DA) which has recently witnessed enormous success in transferring learning from structural labeled to unlabeled data sources. Generative adversarial network (GAN) is a technique that attempts to bridge the gap between source and target data in the joint space and emerges as a building block to develop deep DA approaches with state-of-the-art performance. However, deep DA approaches using the GAN principle to close the gap are subject to the mode collapsing problem that negatively impacts the predictive\u00a0\u2026", "num_citations": "6\n", "authors": ["573"]}
{"title": "A highly efficient data locality aware task scheduler for cloud-based systems\n", "abstract": " Scheduling tasks in the vicinity of stored data can significantly diminish network traffic. Scheduling optimisation can improve data locality by attempting to locate a task and its related data on the same node. Existing schedulers tend to ignore overhead and tradeoff between data transfer and task placement, and bandwidth consumption, by only emphasising data locality without considering other factors. We present a novel data locality aware scheduler for balancing time consumption and network bandwidth traffic - DLAforBT - to improve data locality for tasks and throughput, with the optimal placement policy exhibiting a threshold-based structure. DLAforBT uses bipartite graph modelling to represent data placement, adopts a judgment mechanism and a precise prediction model to determine moving data or moving computation. It integrates an improved Dominant Resource Fairness (DRF) resource allocation to\u00a0\u2026", "num_citations": "6\n", "authors": ["573"]}
{"title": "A Deadline-Constrained Preemptive Scheduler Using Queuing Systems for Multi-tenancy Clouds\n", "abstract": " Scheduling on clouds is required so that service providers can meet Quality of Service (QoS) requirements of tenants. Deadline is a major criterion in judging QoS. This work presents a real-time, preemptive, constrained scheduler using queuing theory - PDSonQueue - which enables better meetinhg of QoS requirements. PDSonQueue also shortens a job's completion time and improves system's throughput. PDSon-Queue, as a dynamic priority real-time greedy scheduler, builds a queuing-based mathematical model to accurately predict a job's execution and waiting time, where jobs arrive by following a stochastic process and request resources. Our scheduler introduces a novel \"Earliest Maximal Waiting Time First (EMWTF)\" concept to fine tune job scheduling to guarantee the job being accomplished within the deadline. Deadline constrained jobs are scheduled preemptively from low priority jobs with the intent of\u00a0\u2026", "num_citations": "6\n", "authors": ["573"]}
{"title": "A static analysis of android source code for lifecycle development usage patterns\n", "abstract": " Building robust Android apps is a non-trivial task that requires skilled developers to understand various Android platform peculiarities. However, among the Android developers community, a large fractions are considered to be novice and inexperienced developers. One of the main peculiarities in the Android app development is the activity lifecycle model. A developer needs to have deep understanding of the different lifecycle states and callback methods that an Android activity can go through during its runtime. These callback methods are called by the system whenever an app activity changes its state. The developer needs to override appropriate callback methods correctly to avoid app memory leaks and data loss or other phone resource compromise. Detailed static analysis of software applications provides actionable insights and helps us to understand how applications are actually built. Although there have been many studies focusing on static analysis of Android apps in the areas of testing, quality, design, privacy and security; no studies to date focus on lifecycle development practices and usage patterns thus far. In this paper, we analyzed 842 open-source Android apps containing 5577 activities to explore and understand how Android developers actually comply with best practices regarding the Android activity lifecycle model. We developed a tool named SAALC that is capable of analyzing Android activities and extracting valuable information about lifecycle callback methods usage. Our results show, which callback methods are implemented and the nature of the code they contain. The results also show incorrect implementation of the\u00a0\u2026", "num_citations": "6\n", "authors": ["573"]}
{"title": "Static Analysis of Android Apps for Lifecycle Conformance\n", "abstract": " Building robust and reliable mobile applications requires the developer to be fully aware of the lifecycle models for mobile applications. During different states of the mobile application lifecycle, such as start-up, running, background etc., various system resources need to be acquired for use and released so that other applications can use them. However, novice and amateur developers, who are a growing fraction in the mobile development community, often find such a task to be non-trivial and complex and limited in support for by existing tools. This paper presents an automated approach based on static code analysis to aid novice developers in managing system resources during different stages of a mobile application's lifecycle. In order to achieve this, we present a software model to encapsulate lifecycle rules for system resources and then create a repository for these resources. In addition, a novel code\u00a0\u2026", "num_citations": "6\n", "authors": ["573"]}
{"title": "What Influences Usability Defect Reporting? \u2013 A Survey of Software Development Practitioners\n", "abstract": " Software development organizations invest in test automation tools and methods to optimize defect discovery rates. The true value of these tools is realized when the defects are addressed before release, and hence good quality defect reports are critical. We describe a survey we conducted to better understand usability defect reporting, in particular, influences on the quality of usability defect reports. We analyze feedback from nearly 150 software developers and usability defect reporters and identify key determinants of quality defect reports, aspects of usability defects that are challenging to report and directions for future research into usability defect reporting tools to improve usability defect reports quality.", "num_citations": "6\n", "authors": ["573"]}
{"title": "Software Architecture Modelling and Performance Analysis with Argo/MTE.\n", "abstract": " We describe Argo/MTE, an extension of the open-source Argo/UML CASE tool that incorporates software architecture modelling facilities and performance test-bed code generation. We illustrate its application by example and explain the tool architecture and our experience using and evaluating it to date.", "num_citations": "6\n", "authors": ["573"]}
{"title": "Experiences Developing a Collaborative Travel Planning Application with .NET Web Services\n", "abstract": " Web services have the potential to provide much more seamless, dynamic and open distributed applications than earlier technologies. We describe our experiences developing an integrated, collaborative travel planning application using .NET, C# and web services. This application provides a unified portal for customers and travel agents to plan, revise and book travel itineraries, with interaction with a wide range of travel provider systems (airlines, hotels, rental cars, trains etc). We describe the web services-based architecture of our prototype solution and discuss some of the key issues of using a web service-based approach for this application domain, outlining key areas for future research and development.", "num_citations": "6\n", "authors": ["573"]}
{"title": "Experiences developing a thin-client, multi-device travel planning application\n", "abstract": " Many applications now require access from diverse human-computer interaction devices, such as desktop computers, web browsers, PDAs, mobile phones, pagers and so on. We describe our experiences developing a multi-device travel planning application built from reusable components, many of these developed from several different previous projects. We focus on key user interface design and component adaptation and integration issues as encountered in this problem domain. We report on the results of a useability evaluation of our prototype and our current research directions addressing HCI and interface development problems we encountered.", "num_citations": "6\n", "authors": ["573"]}
{"title": "Graph-based Data Caching Optimization in Edge Computing\n", "abstract": " Edge computing has emerged as a new computing paradigm that allows computation and storage resources in the cloud to be distributed to edge servers. Those edge servers are deployed at base stations to provide nearby users with high-quality services. Thus, data caching is extremely important in ensuring low latency for service delivery in the edge computing environment. To minimize the data caching cost and maximize the reduction in service latency, we formulate this Edge Data Caching (EDC) problem as a constrained optimization problem in this paper. We prove the NP-completeness of this EDC problem and provide an optimal solution named IPEDC to solve this problem based on Integer Programming. Then, we propose an approximation algorithm named AEDC to find approximate solutions with a limited bound. We conduct intensive experiments on a real-world data set and a synthesized data set to\u00a0\u2026", "num_citations": "5\n", "authors": ["573"]}
{"title": "Knowledge Graphing Git Repositories: A Preliminary Study\n", "abstract": " Knowledge Graph, being able to connect information from a variety of sources, has become very famous in recent years since its creation in 2012 by Google. Researchers in our community have leveraged Knowledge Graph to achieve various purposes such as improving API caveats accessibilities, generating answers to developer questions, and reasoning common software weaknesses, etc. In this work, we would like to leverage the knowledge graph concept for helping developers and project managers to comprehend software repositories. To this end, we design and implement a prototype tool called GitGraph, which takes as input a Git repository and constructs automatically a knowledge graph associated with the repository. Our preliminary experimental results show that GitGraph can correctly generate knowledge graphs for Git projects and the generated graphs are also useful for users to comprehend the\u00a0\u2026", "num_citations": "5\n", "authors": ["573"]}
{"title": "Vision: a New Mobile eHealth Learning and Intervention Platform\n", "abstract": " Face-to-face health educational and intervention programs are helpful in addressing mental and physical illness challenges in focused groups. However, these programs are expensive, resource-intensive and struggle with scalability and reachability, leading to limited take-up and short-term impact. Digital Health Intervention (DHI) programs incorporate the use of technology-mobile, web, wearables, virtual and augmented reality-to address these limitations while being more cost-effective. DHIs have shown major success in improving physical and mental health outcomes for the general public as well as reducing adverse outcomes or high-risk groups. However, it is still very challenging and expensive to design and run high quality mobile-based DHI programs, in part due to the lack of technical skills of researchers in this field. Our proposed mobile eHealth Learning and Intervention Platform (eHeLP) aims to\u00a0\u2026", "num_citations": "5\n", "authors": ["573"]}
{"title": "Building digital ink recognizers using data mining: distinguishing between text and shapes in hand drawn diagrams\n", "abstract": " The low accuracy rates of text-shape dividers for digital ink diagrams are hindering their use in real world applications. While recognition of handwriting is well advanced and there have been many recognition approaches proposed for hand drawn sketches, there has been less attention on the division of text and drawing. The choice of features and algorithms is critical to the success of the recognition, yet heuristics currently form the basis of selection. We propose the use of data mining techniques to automate the process of building text-shape recognizers. This systematic approach identifies the algorithms best suited to the specific problem and generates the trained recognizer. We have generated dividers using data mining and training with diagrams from three domains. The evaluation of our new recognizer on realistic diagrams from two different domains, against two other recognizers shows it to be\u00a0\u2026", "num_citations": "5\n", "authors": ["573"]}
{"title": "Directions in engineering non-functional requirement compliant middleware applications\n", "abstract": " Large Enterprise Distributed Systems (EDSs) are proliferating with many organisations undertaking major software developments in order to meet increased Information Technology usage demands. Many of these stem from the move to providing E-commerce and E-business solutions, the need to integrate information systems from many sources, and the needs of virtual organisations. Key challenges in engineering such systems include the large range non-functional constraints the systems impose. These range from scalability, performance, fault-tolerence and security constraints, to management issues such as the need for developers to organise very complex systems development artefacts. This position paper proposes an approach for better-factoring non-functional requirements into middleware development, and proposals for extending an architecture modelling and analysis tool to support this technique.", "num_citations": "5\n", "authors": ["573"]}
{"title": "Predictive Models in Software Engineering: Challenges and Opportunities,\n", "abstract": " Predictive models are one of the most important techniques that are widely applied in many areas of software engineering. There have been a large number of primary studies that apply predictive models and that present well-preformed studies and well-desigeworks in various research domains, including software requirements, software design and development, testing and debugging and software maintenance. This paper is a first attempt to systematically organize knowledge in this area by surveying a body of 139 papers on predictive models. We describe the key models and approaches used, classify the different models, summarize the range of key application areas, and analyze research results. Based on our findings, we also propose a set of current challenges that still need to be addressed in future work and provide a proposed research road map for these opportunities.", "num_citations": "4\n", "authors": ["573"]}
{"title": "Unveiling the Mystery of API Evolution in Deep Learning Frameworks -- A Case Study of Tensorflow 2\n", "abstract": " API developers have been working hard to evolve APIs to provide more simple, powerful, and robust API libraries. Although API evolution has been studied for multiple domains, such as Web and Android development, API evolution for deep learning frameworks has not yet been studied. It is not very clear how and why APIs evolve in deep learning frameworks, and yet these are being more and more heavily used in industry. To fill this gap, we conduct a large-scale and in-depth study on the API evolution of Tensorflow 2, which is currently the most popular deep learning framework. We first extract 6,329 API changes by mining API documentation of Tensorflow 2 across multiple versions and mapping API changes into functional categories on the Tensorflow 2 framework to analyze their API evolution trends. We then investigate the key reasons for API changes by referring to multiple information sources, e.g., API\u00a0\u2026", "num_citations": "4\n", "authors": ["573"]}
{"title": "Human-Centric Issues in eHealth App Development and Usage: A Preliminary Assessment\n", "abstract": " Health-related mobile applications are known as eHealth apps. These apps make people more aware of their health, help during critical situations, provide home-based disease management, and monitor/support personalized care through sensing/interaction. eHealth app usage is rapidly increasing with a large number of new apps being developed. Unfortunately, many eHealth apps do not successfully adopt Human-Centric Issues (HCI) in the app development process and its deployment stages, leading them to become ineffective and not inclusive of diverse end-users. This paper provides an initial assessment of key human factors related to eHealth apps by literature review, existing guidelines analysis, and user studies. Preliminary results suggest that Usability, Accessibility, Reliability, Versatility, and User Experience are essential HCIs for eHealth apps, and need further attention from researchers and\u00a0\u2026", "num_citations": "4\n", "authors": ["573"]}
{"title": "Technical Q&A Site Answer Recommendation via Question Boosting\n", "abstract": " Software developers have heavily used online question-and-answer platforms to seek help to solve their technical problems. However, a major problem with these technical Q8A sites is \u201canswer hungriness,\u201d i.e., a large number of questions remain unanswered or unresolved, and users have to wait for a long time or painstakingly go through the provided answers with various levels of quality. To alleviate this time-consuming problem, we propose a novel DEEPANS neural network\u2013based approach to identify the most relevant answer among a set of answer candidates. Our approach follows a three-stage process: question boosting, label establishment, and answer recommendation. Given a post, we first generate a clarifying question as a way of question boosting. We automatically establish the positive, neutral+, neutral-, and negative training samples via label establishment. When it comes to answer\u00a0\u2026", "num_citations": "4\n", "authors": ["573"]}
{"title": "Using Work System Design, User Stories and Emotional Goal Modeling for an mHealth System\n", "abstract": " In Malaysia, Heart Failure (HF) is one of the commonest reasons for hospitalization, with a quarter of HF patients readmitted within 30 days from the onset of acute HF. Reducing frequent hospitalization from HF would significantly reduce the burden on the health care system and resources. The opportunity exists to create digital health system to provide continuous patient care after the diagnosis of HF and subsequent discharge from inpatient care to reduce hospital readmission. This paper reports our ongoing project in Malaysia with the Ministry of Health Malaysia cardiac centers to address some of the barriers to continuous care for patients with chronic HF using digital health systems\u2019 interventions. We have applied a combination of existing requirements approaches \u2013 work system design, User Stories, personas, and emotional goal modeling \u2013 for the elicitation, modeling, and analysis of requirements. In this\u00a0\u2026", "num_citations": "4\n", "authors": ["573"]}
{"title": "Deep Cost-sensitive Kernel Machine for Binary Software Vulnerability Detection\n", "abstract": " Owing to the sharp rise in the severity of the threats imposed by software vulnerabilities, software vulnerability detection has become an important concern in the software industry, such as the embedded systems industry, and in the field of computer security. Software vulnerability detection can be carried out at the source code or binary level. However, the latter is more impactful and practical since when using commercial software, we usually only possess binary software. In this paper, we leverage deep learning and kernel methods to propose the Deep Cost-sensitive Kernel Machine, a method that inherits the advantages of deep learning methods in efficiently tackling structural data and kernel methods in learning the characteristic of vulnerable binary examples with high generalization capacity. We conduct experiments on two real-world binary datasets. The experimental results have shown a convincing\u00a0\u2026", "num_citations": "4\n", "authors": ["573"]}
{"title": "Predicting Indoor Spatial Movement Using Data Mining and Movement Patterns\n", "abstract": " The ability to accurately predict the movement trajectory of people holds potential benefits for many applications, such as aged care and retail. Such movement predictions rely on collecting and analyzing large amounts of positioning data from sensors. In this work, we describe new algorithms to mine and predict people's movement in an indoor environment. Movement patterns are mined from historical positioning data, and the patterns are used to construct a probability tree which is a visual representation of frequent movements. We have conducted an empirical study in a staff tearoom to capture positioning data, mine movement patterns and construct a probability tree. We show the predictive power of the algorithms using different trajectory estimation strategies.", "num_citations": "4\n", "authors": ["573"]}
{"title": "Using Concrete Visual Notations as First Class Citizens for Model Transformation Specification\n", "abstract": " Model transformations are an important part of Model Driven Engineering (MDE). To generate a transformation with current MDE approaches, users are required to specify (or provide) complex meta-models and then engage in quite low-level coding in textual transformation scripting languages. This paper introduces a new approach to visualising source and target models that allows specifiers of complex data transformations to use the resultant visual notations for specifying transformations by example using drag and drop. We demonstrate the applicability of our new approach by an example case study.", "num_citations": "4\n", "authors": ["573"]}
{"title": "Development of Robust Traceability Benchmarks\n", "abstract": " Traceability benchmarks are essential for the evaluation of traceability recovery techniques. This includes the validation of an individual trace ability technique itself and the objective comparison of the technique with other traceability techniques. However, it is generally acknowledged that it is a real challenge for researchers to obtain or build meaningful and robust benchmarks. This is because of the difficulty of obtaining or creating suitable benchmarks. In this paper, we describe an approach to enable researchers to establish affordable and robust benchmarks. We have designed rigorous manual identification and verification strategies to determine whether or not a link is correct. We have developed a formula to calculate the probability of errors in benchmarks. Analysis of error probability results shows that our approach can produce high quality benchmarks, and our strategies significantly reduce error probability\u00a0\u2026", "num_citations": "4\n", "authors": ["573"]}
{"title": "DIGGER: Identifying Operating System Dynamic Kernel Objects for Run-time Security Analysis\n", "abstract": " In operating systems, we usually refer to a running instance of a data structure (data type) as an object. Locating runtime dynamic kernel objects in physical memory is the most difficult step towards enabling implementation of robust operating system security solutions. In this paper, we address the problem of systemically uncovering all operating system runtime dynamic kernel objects, without any prior knowledge of the operating system kernel data layout in memory. We present a new hybrid approach\u2013called DIGGER\u2013that enables uncovering kernel runtime objects with nearly complete coverage, high accuracy and robust results. Unlike previous approaches, DIGGER is designed to address the challenges of indirect points-to relations between kernel data structures. DIGGER employs a hybrid approach that combines a new value-invariant approach and a systematic memory mapping technique in order to get accurate results. We have implemented a prototype of DIGGER and conducted an evaluation of its efficiency and effectiveness. To demonstrate our approach\u2019s potential, we have also developed three different proof-of-concept operating system security tools based on DIGGER approach.", "num_citations": "4\n", "authors": ["573"]}
{"title": "Distributed component engineering using a decentralised, internet-based environment\n", "abstract": " Engineering component-based software systems in a distributed fashion is challenging. Particular issues to address include software process and work co-ordination, sharing and collaborative editing of component specifications, designs and implementations, and appropriate sharing of reusable components. This paper describes our approach to tool support for distributed component engineering. Several tools are integrated for each developer, and a decentralised, multi-user work environment established. Key characteristics of this environment include flexible process management and process-based tool co-ordination, collaborative editing support, distributed work co-ordination and 3rd party tool integration agents, and distributed component storage and retrieval support. We illustrate some of these tools in use during multi-user development, and discuss the architectural realisation of these tools and their integration.", "num_citations": "4\n", "authors": ["573"]}
{"title": "Checking App Behavior Against App Descriptions: What If There are No App Descriptions?\n", "abstract": " Classifying mobile apps based on their description is beneficial for several purposes. However, many app descriptions do not reflect app functionalities, whether accidentally or on purpose. Most importantly, these app classification methods do not work if the app description is unavailable. This paper investigates a Reverse Engineering-based Approach to Classify mobile apps using The data that exists in the app, called REACT. To validate the proposed REACT method, we use a large set of Android apps (24,652 apps in total). We also show REACTs' extendibility for malware/anomaly detection and prove its reliability and scalability. However, our analysis shows some limitations in REACT procedure and implementation, especially for similar feature based app grouping. We discuss the root cause of these failures, our key lessons learned, and some future enhancement ideas. We also share our REACT tools and reproduced datasets for the app market analyst, mobile app developers and software engineering research communities for further research purposes.", "num_citations": "3\n", "authors": ["573"]}
{"title": "SRCM: A Semi Formal Requirements Representation Model Enabling System Visualisation and Quality Checking\n", "abstract": " Requirements engineering is pivotal to the successful development of any given system. The core artifact for such phase is the requirements specification document. Requirements can be specified in informal, semiformal, and formal notations. The majority of the requirements across many fields and domains are written natural language. However, natural language is inherently ambiguous and imprecise and the requirements cannot be automatically validated. Formal notations on the other hand enable automated testing and validation but is only comprehensible by experts and requires rewriting the requirements. Semi-formal notations strikes a good balance between comprehension and checking for several systems. However, the majority of the existing representation models mandates the requirements to be (re) written to adhere to certain templates. They also do not support automated checking. In this paper, we present SRCM\u2013a semi-formal requirements representation model based on a comprehensive requirements capturing model (RCM) that does not enforce much limitations on how the requirements can be written. We also provide an automated approach to construct SRCM from RCM. In addition to providing a unified visualisation of the system entities and relations between the requirements key components, SRCM also enables automated quality checking on the requirements.", "num_citations": "3\n", "authors": ["573"]}
{"title": "Does Textual Word-of-Mouth Affect Look and Feel?\n", "abstract": " In the field of HCI, website usability and visual appeal have been studied extensively. Participant experience with a website genre influences the use and perception of the website. Word-of-Mouth (WOM), such as user reviews, influences users in hotel, restaurant, movie, and many other e-commerce domains. Thus, a company's or product's reputation can alter a consumer's behaviour towards that product. Our work aimed to acquire an understanding of the effect of textual WOM on usability and visual appeal. This is a novel approach to the topic. This research was undertaken using an unfamiliar city council website to exclude the influence of one's own past experiences and to allow for greater control of the textual WOM. We found that visual appeal, objective and subjective usability were all influenced by text that established reputations.", "num_citations": "3\n", "authors": ["573"]}
{"title": "Workshop on directions in software engineering environments (WoDiSEE)\n", "abstract": " This report gives an overview of the Workshop on Directions in Software Engineering Environments WoDiSEE 2004) held at the 26th International Conference on Software Engineering (ICSE 2004). The goal of this workshop was to bring together researchers and practitioners with an interest in developing, extending, deploying and using software engineering tools. The workshop provided an interactive forum for the exchange of ideas and discussion about current research and future trends in software engineering environment research and development. The workshop proceedings contain fourteen short papers, giving a snapshot of current research in this area, which provided the framework for presentations at the workshop. This report summarises the presentations given at the workshop and the discussions that took place.", "num_citations": "3\n", "authors": ["573"]}
{"title": "Construction of an Integrated and Extensible Software Architecture Modelling Environment\n", "abstract": " Constructing complex software engineering tools and integrating them with other tools to form an effective development environment is a very challenging task. Difficulties are exacerbated when the tool under construction needs to be extensible, flexible and enhanceable by end users. We describe the construction of SoftArch, a novel software architecture modelling and analysis tool, which needs to support an extensible set of architecture abstractions and processes, a flexible modelling notation and editing tools, a user-controllable and extensible set of analysis agents and integration with OOA/D CASE tools and programming environments. We developed solutions to these problems using an extensible meta-model, user-tailorable notation editors, event-driven analysis agents, and component-based integration with process support, OOA/D, code generation and reverse engineering tools.", "num_citations": "3\n", "authors": ["573"]}
{"title": "Accessibility in Software Practice: A Practitioner\u2019s Perspective\n", "abstract": " Being able to access software in daily life is vital for everyone, and thus accessibility is a fundamental challenge for software development. However, given the number of accessibility issues reported by many users, e.g., in app reviews, it is not clear if accessibility is widely integrated into current software projects and how software projects address accessibility issues. In this paper, we report a study of the critical challenges and benefits of incorporating accessibility into software development and design. We applied a mixed qualitative and quantitative approach for gathering data from 15 interviews and 365 survey respondents from 26 countries across five continents to understand how practitioners perceive accessibility development and design in practice. We got 44 statements grouped into eight topics on accessibility from practitioners' viewpoints and different software development stages. Our statistical analysis reveals substantial gaps between groups, e.g., practitioners have Direct v.s. Indirect accessibility relevant work experience when they reviewed the summarized statements. These gaps might hinder the quality of accessibility development and design, and we use our findings to establish a set of guidelines to help practitioners be aware of accessibility challenges and benefit factors. We also propose some remedies to resolve the gaps and to highlight key future research directions.", "num_citations": "2\n", "authors": ["573"]}
{"title": "Software Engineering for Internet of Things: The Practitioners\u2019 Perspective\n", "abstract": " Internet of Things based systems (IoT systems for short) are becoming increasingly popular across different industrial domains and their development is rapidly increasing to provide value-added services to end-users and citizens. Little research to date uncovers the core development process lifecycle needed for IoT systems, and thus software engineers find themselves unprepared and unfamiliar with this new genre of system development. To ameliorate this gap, we conducted a mixed quantitative and qualitative research study where we derived a conceptual process framework from the extant literature on IoT, that identifies 27 key tasks for incorporating into development processes for IoT systems. The framework was then validated by means of a survey of 127 IoT systems practitioners developers from 35 countries across 6 continents with 15 different industry backgrounds. Our research provides an understanding of the most important development process tasks and informs both software engineering practitioners and researchers of the challenges and recommendations related to the development of next generation of IoT systems.", "num_citations": "2\n", "authors": ["573"]}
{"title": "On the Impact of Sample Duplication in Machine Learning based Android Malware Detection\n", "abstract": " Malware detection at scale in the Android realm is often carried out using machine learning techniques. State-of-the-art approaches such as DREBIN and MaMaDroid are reported to yield high detection rates when assessed against well-known datasets. Unfortunately, such datasets may include a large portion of duplicated samples, which may bias recorded experimental results and insights. In this article, we perform extensive experiments to measure the performance gap that occurs when datasets are de-duplicated. Our experimental results reveal that duplication in published datasets has a limited impact on supervised malware classification models. This observation contrasts with the finding of Allamanis on the general case of machine learning bias for big code. Our experiments, however, show that sample duplication more substantially affects unsupervised learning models (e.g., malware family clustering\u00a0\u2026", "num_citations": "2\n", "authors": ["573"]}
{"title": "Taming Reflection: An Essential Step Towards Whole-Program Analysis of Android Apps\n", "abstract": " Android developers heavily use reflection in their apps for legitimate reasons. However, reflection is also significantly used for hiding malicious actions. Unfortunately, current state-of-the-art static analysis tools for Android are challenged by the presence of reflective calls, which they usually ignore. Thus, the results of their security analysis, e.g., for private data leaks, are incomplete, given the measures taken by malware writers to elude static detection. We propose a new instrumentation-based approach to address this issue in a non-invasive way. Specifically, we introduce to the community a prototype tool called DroidRA, which reduces the resolution of reflective calls to a composite constant propagation problem and then leverages the COAL solver to infer the values of reflection targets. After that, it automatically instruments the app to replace reflective calls with their corresponding Java calls in a traditional\u00a0\u2026", "num_citations": "2\n", "authors": ["573"]}
{"title": "An Efficient Deadline Constrained and Data Locality Aware Dynamic Scheduling Framework for Multi-Tenancy Clouds\n", "abstract": " Scheduling and resource allocation in clouds is used to harness the power of the underlying resource pool. Service providers can meet quality of service (QoS) requirements of tenants specified in Service Level Agreements. Improving resource allocation ensures that all tenants will receive fairer access to system resources, which improves overall utilization and throughput. Real\u2010time applications and services require critical deadlines in order to guarantee QoS. A growing number of data\u2010intensive applications drive the optimization of scheduling through utilizing data locality in which the scheduler locates a task and ensures the task's relevant data to be on the same server. Choosing suitable scheduling mechanisms for running applications that support multitenancy has consistently been a major challenge. This work proposes a new adaptive Deadline constrained and Data locality aware Dynamic Scheduling\u00a0\u2026", "num_citations": "2\n", "authors": ["573"]}
{"title": "HumaniSE: Approaches to Achieve More Human-Centric Software Engineering\n", "abstract": " A common problem with many existing software systems and the approaches to engineering them is their lack of the human aspects of their target end users. People are different - with diverse characteristics including age, gender, ethnicity, physical and mental challenges, personality, technical proficiency, emotional reactions to software systems, socio-economic status, educational attainment, language, and so on. In this paper we describe our work at looking to better consider these characteristics by incorporation of human aspects throughout the software engineering lifecycle. We are developing a co-creational living lab approach to better collect human aspects in the software requirements. We are using domain-specific visual languages, themselves a more human-centric modelling approach, to capture these diverse human aspects of target software systems. We are working on incorporating these\u00a0\u2026", "num_citations": "2\n", "authors": ["573"]}
{"title": "International Capstone Exchange \u2013 the SUT and NDSU Experience\n", "abstract": " We describe out experiences in running an \u201cInternational Capstone Exchange\u201d project between North Dakota State University (NDSU) in Fargo, ND in the USA and Swinburne University of Technology (SUT) in Melbourne, Australia. An NDSU-based student team worked on an industry capstone project with a Melbourne-based organization (National ICT Australia) and a Melbourne-based student team worked on an industry capstone project with a Fargo-based organization (Upper Great Plains Transportation Institute). We describe the rationale behind the international capstone exchange, how we organized the projects and teams, how the projects and teams fared, lessons learned, and plans for expanding in the future.", "num_citations": "2\n", "authors": ["573"]}
{"title": "Generating Reusable Visual Notations using Model Transformation\n", "abstract": " Visual notations are a key aspect of visual languages. They provide a direct mapping between the intended information and set of graphical symbols. Visual notations are most often implemented using the low level syntax of programming languages which is time consuming, error prone, difficult to maintain and hardly human-centric. In this paper we describe an alternative approach to generating visual notations using by-example model transformations. In our new approach, a semantic mapping between model and view is implemented using model transformations. The notations resulting from this approach can be reused by mapping varieties of input data to their model and can be composed into different visualizations. Our approach is implemented in the CONVErT framework and has been applied to many visualization examples. Three case studies for visualizing statistical charts, visualization of traffic data, and\u00a0\u2026", "num_citations": "2\n", "authors": ["573"]}
{"title": "Guest editors introduction: special issue on innovative automated software engineering tools\n", "abstract": " BackgroundTraditionally Automated Software Engineering (ASE) has been supported by a variety of tools. These particularly include tools for theorem proving, model checking and other complex model analysis all being techniques which are extremely difficult if not impossible to do without tool support (Holzmann 1997). Other early ASE tools developed included tools to assist in requirements capture and analysis, particularly for very formal requirements modeling; tools to support software testing, particularly test case generation and test result analysis; and tools to support complex software development processes. These included CASE (Computer Aided Software Engineering) tools with model analysis features, process-centered environments with enactable software processes, project management tools, and version control and configuration management tools.", "num_citations": "2\n", "authors": ["573"]}
{"title": "Visualising Event-based Information Models: Issues and Experiences\n", "abstract": " We describe challenges in visualising event-based system specification and execution and illustrate how we address these from our experience developing a set of notations and tools, the Marama meta-tool platform.", "num_citations": "2\n", "authors": ["573"]}
{"title": "Development of techniques for sketched diagram recognition\n", "abstract": " The focus of this research is to develop general diagram recognition techniques based on quantitative experiments using machine learning to determine the most significant ink features and effective algorithms for use throughout the recognition process. This should improve on existing recognition success rates.", "num_citations": "2\n", "authors": ["573"]}
{"title": "Supporting information mapping in Health Informatics via integrated message transformation\n", "abstract": " In order to provide an effective overall health information system, a number of separate systems used by different providers must typically be integrated. However supporting the exchange of data between these disparate health information systems often requires complex data transformation from one system\u2019s data formats to another\u2019s. We describe a novel data mapping specification tool, domain-specific language and mapping engine that greatly simplifies building such integration infrastructure. Our system allows health systems integrators to specify correspondences between information messages generated by one system to messages that another system consumes. A special mapping language is used to express these correspondences and is run by a mapping engine to effect data transformation. Input and output messages can be expressed in XML or EDI formats and a separate message exchange system is used to communicate between the data source and data target health information systems. We describe our mapping system approach, key elements of its architecture and experiences in commercializing our basic research to produce a successful new product.", "num_citations": "2\n", "authors": ["573"]}
{"title": "Summary of the INTERACT97 Workshop on the Next Generation of CSCW Systems\n", "abstract": " The INTERACT\u201997 Workshop on the Next Generation of CSCW Systems focuses on new directions for CSCW. Participants are selected on the basis of short position papers which provide forward-looking insights into CSCW. Position papers cover diverse, yet related, topics ranging from new theoretical foundations for CSCW, design methodologies and HCI issues in groupware, architectures and infrastructure for groupware, evaluation of CSCW systems, and new applications for CSCW. All accepted position papers appear in the workshop proceedings, and it is intended to make this available electronically via the World Wide Web.", "num_citations": "2\n", "authors": ["573"]}
{"title": "Supporting flexible collaborative software development with SPE\u2013Serendipity\n", "abstract": " Collaborative software development environments are large cooperative work systems. To effectively support collaborative development, such environments should support software process modelling and enactment, work coordination, and fully integrated software development tools. We describe the facilitation of collaborative software development using the Serendipity process modelling environment and SPE integrated software development environment. Serendipity provides flexible, graphical process modelling tools which are used to describe, enact and improve work processes. A graphical event processing language is used to specify event handling and rules for process models. SPE provides integrated tools for objectoriented software development. Enacted Serendipity process stages define a work context for SPE, and process model views are animated to keep multiple developers aware of others\u2019 work. Enacted process stages record each software artefact modification in SPE, forming a history of work. Shared notes added to process stages and software artefacts facilitate asynchronous communication, and messages and talk-style dialogues facilitate synchronous communication. Process models can be modified and improved during or after use, and be abstracted to form reusable templates. We describe how our approach to integrating Serendipity and SPE addresses many of the foundational issues of process-centred software engineering environments.", "num_citations": "2\n", "authors": ["573"]}
{"title": "Code2Que: A Tool for Improving Question Titles from Mined Code Snippets in Stack Overflow,\n", "abstract": " Stack Overflow is one of the most popular technical Q&A sites used by software developers. Seeking help from Stack Overflow has become an essential part of software developers\u2019 daily work for solving programming-related questions. Although the Stack Overflow community has provided quality assurance guidelines to help users write better questions, we observed that a significant number of questions submitted to Stack Overflow are of low quality. In this paper, we introduce a new web-based tool, Code2Que, which can help developers in writing higher quality questions for a given code snippet. Code2Que consists of two main stages: offline learning and online recommendation. In the offline learning phase, we first collect a set of good quality\u27e8 code snippet, question\u27e9 pairs as training samples. We then train our model on these training samples via a deep sequence-to-sequence approach, enhanced with an\u00a0\u2026", "num_citations": "1\n", "authors": ["573"]}
{"title": "Operationalizing Human Values in Software Engineering: A Survey\n", "abstract": " Human values, such as inclusion and diversity, are defined as what an individual or a society deems important. Failing to address them in software may lead to several undesired effects and issues (e.g., loss of life) for individuals and societies. Different types of solutions (e.g., frameworks) have been proposed to support \"operationalizing values in software\", that is, ensuring creating software (better) reflects and respects human values. In this paper, \"operationalizing values\" is referred to as the process of identifying human values and translating them to accessible and concrete concepts so that they can be implemented, validated, verified, and measured in software. This paper provides a deep understanding of the research landscape on operationalizing values in software engineering, covering 51 primary studies. It also presents an analysis and taxonomy of 51 solutions for operationalizing values in software engineering. Our survey reveals that most solutions attempt to help operationalize values in the early phases (requirements and design) of the software development life cycle. However, the later phases (implementation and testing) and other aspects of software development (e.g., \"team organization\") still need adequate consideration. We outline implications for research and practice and identify open issues and future research directions to advance this area.", "num_citations": "1\n", "authors": ["573"]}
{"title": "Information-theoretic Source Code Vulnerability Highlighting\n", "abstract": " Software vulnerabilities are a crucial and serious concern in the software industry and computer security. A variety of methods have been proposed to detect vulnerabilities in real-world software. Recent methods based on deep learning approaches for automatic feature extraction have improved software vulnerability identification compared with machine learning approaches based on hand-crafted feature extraction. However, these methods can usually only detect software vulnerabilities at a function or program level, which is much less informative because, out of hundreds (thousands) of code statements in a program or function, only a few core statements contribute to a software vulnerability. This requires us to find a way to detect software vulnerabilities at a fine-grained level. In this paper, we propose a novel method based on the concept of mutual information that can help us to detect and isolate software\u00a0\u2026", "num_citations": "1\n", "authors": ["573"]}
{"title": "Identifying and Characterizing Silently-Evolved Methods in the Android API\n", "abstract": " With over 500,000 commits and more than 700 contributors, the Android platform is undoubtedly one of the largest industrial-scale software projects. This project provides the Android API, and developers heavily rely on this API to develop their Android apps. Unfortunately, because the Android platform and its API evolve at an extremely rapid pace, app developers need to continually monitor API changes to avoid compatibility issues in their apps (i.e., issues that prevent apps from working as expected when running on newer versions of the API). Despite a large number of studies on compatibility issues in the Android API, the research community has not yet investigated issues related to silently-evolved methods (SEMs). These methods are functions whose behavior might have changed but the corresponding documentation did not change accordingly. Because app developers rely on the provided documentation\u00a0\u2026", "num_citations": "1\n", "authors": ["573"]}
{"title": "Context-Aware Retrieval-based Deep Commit Message Generation\n", "abstract": " Commit messages recorded in version control systems contain valuable information for software development, maintenance, and comprehension. Unfortunately, developers often commit code with empty or poor quality commit messages. To address this issue, several studies have proposed approaches to generate commit messages from commit diffs. Recent studies make use of neural machine translation algorithms to try and translate git diffs into commit messages and have achieved some promising results. However, these learning-based methods tend to generate high-frequency words but ignore low-frequency ones. In addition, they suffer from exposure bias issues, which leads to a gap between training phase and testing phase. In this article, we propose CoRec to address the above two limitations. Specifically, we first train a context-aware encoder-decoder model that randomly selects the previous output of\u00a0\u2026", "num_citations": "1\n", "authors": ["573"]}
{"title": "A Multi-dimensional Study of Requirements Changes in Agile Software Development Projects\n", "abstract": " Agile processes are now widely practiced by software engineering (SE) teams, and the agile manifesto claims that agile methods support responding to changes well. However, no study appears to have researched whether this is accurate in reality. Requirements changes (RCs) are inevitable in any software development environment, and we wanted to acquire a holistic picture of how RCs occur and are handled in agile SE teams in practice. We also wanted to know whether responding to changes is the only or a main reason for software teams to use agile in their projects. To do this we conducted a mixed-methods research study which comprised of interviews of 10 agile practitioners from New Zealand and Australia, a literature review, and an in-depth survey with the participation of 40 agile practitioners world-wide. Through this study we identified different types of RCs, their origination including reasons for origination, forms, sources, carriers, and events at which they originate, challenging nature, and finally whether agile helps to respond to changes or not. We also found that agile teams seem to be reluctant to accept RCs, and therefore, they use several mitigation strategies. Additionally, as they accept the RCs, they use a variety of techniques to handle them. Furthermore, we found that agile allowing better response to RCs is only a minor reason for practicing agile. Several more important reasons included being able to deliver the product in a shorter period and increasing team productivity. Practitioners stated this improves the agile team environment and thus are the real motivators for teams to practice agile. Finally, we provide a set of\u00a0\u2026", "num_citations": "1\n", "authors": ["573"]}
{"title": "DiffTech: A tool for differencing similar technologies from question-and-answer discussions\n", "abstract": " Developers can use different technologies for different software development tasks in their work. However, when faced with several technologies with comparable functionalities, it can be challenging for developers to select the most appropriate one, as trial and error comparisons among such technologies are time-consuming. Instead, developers resort to expert articles, read official documents or ask questions in Q&A sites for technology comparison. However, it is still very opportunistic whether they will get a comprehensive comparison, as online information is often fragmented, contradictory and biased. To overcome these limitations, we propose the DiffTech system that exploits the crowd sourced discussions from Stack Overflow, and assists technology comparison with an informative summary of different comparison aspects. We found 19,118 comparative sentences from 2,410 pairs of comparable technologies\u00a0\u2026", "num_citations": "1\n", "authors": ["573"]}
{"title": "An Informed Consent Model for Handling the Privacy Paradox in Smart Buildings\n", "abstract": " Smart Buildings are defined as the\" buildings of the future\" and use the latest Internet of Things (IoT) technologies to automate building operations and services. This is to both increase operational efficiency as well as maximize occupant comfort and environmental impact. However, these\" smart devices\"-typically used with default settings-also enable the capture and sharing of a variety of sensitive and personal data about the occupants. Given the non-intrusive nature of most IoT devices, individuals have little awareness of what data is being collected about them and what happens to it downstream. Even if they are aware, convenience overrides any privacy concerns, and they do not take sufficient steps to control the data collection, thereby exacerbating the privacy paradox. At the same time, IoT-based building automation systems are revealing highly sensitive insights about the building occupants by synthesizing\u00a0\u2026", "num_citations": "1\n", "authors": ["573"]}
{"title": "SplashKit: A Development Framework for Motivating and Engaging Students in Introductory Programming\n", "abstract": " Learning to program is known to be challenging for many students. Upon entry, students often have poor perceptions of their capabilities with some anxiety around the challenges they expect to face in learning to code. Lowering the barriers to entry will help ease students into programming and enable a broader range of student to continue programming. SplashKit is an educationally focused development framework designed to aid the teaching of programming by empowering students to create interesting and dynamic programs from their first programming tasks. This paper explores how SplashKit can be used in tertiary education to underpin a range of introductory programming approaches.", "num_citations": "1\n", "authors": ["573"]}
{"title": "Technical Report: Anomaly Detection for a Critical Industrial System using Context, Logs and Metrics\n", "abstract": " Recent advances in contextual anomaly detection attempt to combine resource metrics and event logs to uncover unexpected system behaviors and malfunctions at runtime. These techniques are highly relevant for critical software systems, where monitoring is often mandated by international standards and guidelines. In this technical report, we analyze the effectiveness of a metrics-logs contextual anomaly detection technique in a middleware for Air Traffic Control systems. Our study addresses the challenges of applying such techniques to a new case study with a dense volume of logs, and finer monitoring sampling rate. We propose an automated abstraction approach to infer system activities from dense logs and use regression analysis to infer the anomaly detector. We observed that the detection accuracy is impacted by abrupt changes in resource metrics or when anomalies are asymptomatic in both resource metrics and event logs. Guided by our experimental results, we propose and evaluate several actionable improvements, which include a change detection algorithm and the use of time windows on contextual anomaly detection.This technical report accompanies the paper \u201cContextual Anomaly Detection for a Critical Industrial System based on Logs and Metrics\u201d[1] and provides further details on the analysis method, case study and experimental results.", "num_citations": "1\n", "authors": ["573"]}
{"title": "Insights into Visualizing Trajectory Recommendation Rankings\n", "abstract": " Maps are the center point of many ancient and current visualizations. Recently, increased usage of mobile devices has promoted application of map-based visualizations, specially for navigation and point of interest representation. The types of representations on these maps however have not changed significantly. In this paper we discuss our studies on map visualizations in the context of visualizing trajectories and their ranking order for a trip recommender system. We have asked set of participants to demonstrate how they perceive trajectory recommendations and how they represent their rankings. We hope our findings help trip recommender tool designers to choose more human centered visual representations.", "num_citations": "1\n", "authors": ["573"]}
{"title": "Automating Performance and Energy Consumption Analysis for Cloud Applications\n", "abstract": " In cloud environments, IT solutions are delivered to users via shared infrastructure, enabling cloud service providers to deploy applications as services according to user QoS (Quality of Service) requirements. One consequence of this cloud model is the huge amount of energy consumption and significant carbon footprints caused by large cloud infrastructures. A key and common objective of cloud service providers is thus to develop cloud application deployment and management solutions with minimum energy consumption while guaranteeing performance and other QoS specified in Service Level Agreements (SLAs). However, finding the best deployment configuration that maximises energy efficiency while guaranteeing system performance is an extremely challenging task, which requires the evaluation of system performance and energy consumption under various workloads and deployment configurations. In\u00a0\u2026", "num_citations": "1\n", "authors": ["573"]}
{"title": "Determining the cause of design model inconsistencies\n", "abstract": " This installment of Computer's series highlighting the work published in IEEE Computer Society journals comes from IEEE Transactions on Software Engineering.", "num_citations": "1\n", "authors": ["573"]}
{"title": "CONVErT Meets KIELER: Integrating Advanced Layout Algorithms into By-Example Visualisations\n", "abstract": " The CONcrete Visual assistEd Transformation (CONVErT) framework provides facilities to generate reusable notations and compose them to form a wide variety of visualisations. With an increased number of notations in large scale visualisations, it is crucial to use advanced layout algorithms to improve understandability of such complex visualisations. This showpiece paper demonstrates how advanced layout algorithms can be integrated into the notation specifications of CONVErT to generate layouts of complex visualisations.", "num_citations": "1\n", "authors": ["573"]}
{"title": "Australian Social Services Agency Software: Requirements, Current Usage and Opportunities\n", "abstract": " Social Service agencies use a wide range of software systems to manage caseloads, maintain records, deliver services to clients and for inter-agency communication. Some systems are generic, such as Word or Excel, while some are specialised to the organisation, such as specialised databases for tracking case notes. Some software systems are shared across organisations such as web-based government agency provider sites. We surveyed forty Australian social services agencies to ascertain the range of software currently in use by agencies and their opinions on it, with a view to identifying promising new social services applications. We identified some candidate future systems and interviewed representatives from a selection smaller social services agencies. This resulted in detailed feedback on key issues that must be considered when developing social services agency software and some possible directions for research and development in this area.", "num_citations": "1\n", "authors": ["573"]}
{"title": "Workshop on flexible modeling tools:(FlexiTools 2011)\n", "abstract": " Modeling tools are often not used for tasks during the software lifecycle for which they should be more helpful; instead free-from approaches, such as office tools and white boards, are frequently used. Prior workshops explored why this is the case and what might be done about it. The goal of this workshop is to continue those discussions and also to form an initial set of challenge problems and research challenges that researchers and developers of flexible modeling tools should address.", "num_citations": "1\n", "authors": ["573"]}
{"title": "VikiBuilder: Let\u2019s build a Visual Wiki\n", "abstract": " Following our previous work with building\" Visual Wiki\" applications, we introduce\" VikiBuilder\", a Visual Wiki meta-tool, which provides end-user supported modeling and generation of Visual Wiki instances.", "num_citations": "1\n", "authors": ["573"]}
{"title": "What we know (and do not know) about collaborative software engineering\n", "abstract": " Software engineering must be practiced by people within organizations. Recent trends in software engineering practice have resulted in much more complicated issues around collaboration than in its historical context. Traditionally software engineering was practiced by small teams\u2013with a large problem decomposed via divide-and-conquer methods into smaller teams\u2013that were co-located, shared a common methodology, used common techniques and tools, and could communicate if not directly face-to-face then via leaders and managers face-to-face. While collaborative software engineering in such a context is still very challenging, the homogeneous team, process, method, tool and management structures greatly help. New models of software engineering have made collaboration issues much less straightforward. Multi-site software teams are very common to large organizations [8]. Even smaller organizations\u00a0\u2026", "num_citations": "1\n", "authors": ["573"]}
{"title": "The Software Engineering Academic\u2019s Role in Industrial Innovation\n", "abstract": " Summary form only given. Universities are under increasing pressure globally to both diversify revenue streams, and develop a role beyond simply teaching and research and, particularly in the technological disciplines such as our own, to act as agents for economic development and change. This diversification of roles naturally creates tensions between investigator led curiosity driven research and applied research that has the potential for more immediate economic impact. The introduction of research quality measurement frameworks such as those in New Zealand and Australia exacerbate this tension. In this article, the author gives a personal perspective on how these tensions can be mitigated, in the process generating a win-win partnership with industry. This requires compromises on both sides of the industry academic divide but can be immensely rewarding in both an academic and a financial sense. The\u00a0\u2026", "num_citations": "1\n", "authors": ["573"]}
{"title": "Software engineering tools\n", "abstract": " Software tools are a crucial part of successful software development. Good tool support allows developers to more effectively plan and co-ordinate their work, appropriately specify and design large software systems while maintaining control of their complexity, implement and test software with a range of technologies, and effectively and efficiently maintain software over time. The construction of software tools themselves is a challenge, a significant software engineering task in its own right. This mini-track's papers address many uses of software tools and techniques for tool development.", "num_citations": "1\n", "authors": ["573"]}
{"title": "Approaches for utilising \u2018Work Contexts\u2019 in CSCW systems\n", "abstract": " When working together using CSCW tools, people have a \u201cwork context\u201d within which they perform their work. A work context includes the tools they are using to perform the work, the work artefacts being modified, the tools used to communicate with collaborators, and the other people they are collaborating with. We describe our recent work with trying to represent work context information in a workflow system. We then describe our current work which tries to determine work context information, rather than requiring it to be explicitly specified, by monitoring user activities. We describe how both approaches allow work context information to be communicated between collaborating users, allowing users to better coordinate their work and understand why others have done certain things or are doing certain things. We claim such facilities are necessary in order to enable the next generation of workflow-based CSCW systems to better support work coordination amoung multiple users.", "num_citations": "1\n", "authors": ["573"]}
{"title": "Qualitative Evaluation of a Collaborative Web Browser\n", "abstract": " Many tools have been developed to support cooperative work, but many of these have not been evaluated. This paper describes various experiments conducted to derive a qualitative evaluation of a WWW browser with CSCW support. These experiments are not restricted to this particular domain but can also be applied to other types of CSCW systems.", "num_citations": "1\n", "authors": ["573"]}