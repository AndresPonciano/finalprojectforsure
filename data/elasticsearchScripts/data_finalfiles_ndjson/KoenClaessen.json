{"title": "Lava: hardware design in Haskell\n", "abstract": " Lava is a tool to assist circuit designers in specifying, designing, verifying and implementing hardware. It is a collection of Haskell modules. The system design exploits functional programming language features, such as monads and type classes, to provide multiple interpretations of circuit descriptions. These interpretations implement standard circuit analyses such as simulation, formal verification and the generation of code for the production of real circuits.Lava also uses polymorphism and higher order functions to provide more abstract and general descriptions than are possible in traditional hardware description languages. Two Fast Fourier Transform circuit examples illustrate this.", "num_citations": "535\n", "authors": ["1042"]}
{"title": "New techniques that improve MACE-style finite model finding\n", "abstract": " We describe a new method for finding finite models of unsorted first-order logic clause sets. The method is a MACE-style method, ie it\u201d flattens\u201d the first-order clauses, and for increasing model sizes, instantiates the resulting clauses into propositional clauses which are consecutively solved by a SAT-solver. We enhance the standard method by using 4 novel techniques: term definitions, which reduce the number of variables in flattened clauses, incremental SAT, which enables reuse of search information between consecutive model sizes, static symmetry reduction, which reduces the number of isomorphic models by adding extra constraints to the SAT problem, and sort inference, which allows the symmetry reduction to be applied at a finer grain. All techniques have been implemented in a new model finder, called Paradox, with very promising results.", "num_citations": "315\n", "authors": ["1042"]}
{"title": "SAT-based verification without state space traversal\n", "abstract": " Binary Decision Diagrams (BDDs) have dominated the area of symbolic model checking for the past decade. Recently, the use of satisfiability (SAT) solvers has emerged as an interesting complement to BDDs. SAT-based methods are capable of coping with some of the systems that BDDs are unable to handle. The most challenging problem that has to be solved in order to adapt standard symbolic model checking to SAT-solvers is the boolean quanti fication necessary for traversing the state space. A possible approach to extending the applicability of SAT-based model checkers is therefore to reduce the amount of traversal. In this paper, we investigate a BDD-based verification algorithm due to van Eijk. Van Eijk\u2019s algorithm tries to compute information that is sufficient to prove a given safety property directly. When this is not possible, the computed information can be used to reduce the amount of traversal\u00a0\u2026", "num_citations": "226\n", "authors": ["1042"]}
{"title": "Feldspar: A domain specific language for digital signal processing algorithms\n", "abstract": " A new language, Feldspar, is presented, enabling high-level and platform-independent description of digital signal processing (DSP) algorithms. Feldspar is a pure functional language embedded in Haskell. It offers a high-level dataflow style of programming, as well as a more mathematical style based on vector indices. The key to generating efficient code from such descriptions is a high-level optimization technique called vector fusion. Feldspar is based on a low-level, functional core language which has a relatively small semantic gap to machine-oriented languages like C. The core language serves as the interface to the back-end code generator, which produces C. For very small examples, the generated code performs comparably to hand-written C code when run on a DSP target. While initial results are promising, to achieve good performance on larger examples, issues related to memory access patterns and\u00a0\u2026", "num_citations": "122\n", "authors": ["1042"]}
{"title": "Static contract checking for Haskell\n", "abstract": " Program errors are hard to detect and are costly both to programmers who spend significant efforts in debugging, and for systems that are guarded by runtime checks. Static verification techniques have been applied to imperative and object-oriented languages, like Java and C#, but few have been applied to a higher-order lazy functional language, like Haskell. In this paper, we describe a sound and automatic static verification framework for Haskell, that is based on contracts and symbolic execution. Our approach is modular and gives precise blame assignments at compile-time in the presence of higher-order functions and laziness.", "num_citations": "120\n", "authors": ["1042"]}
{"title": "Observable sharing for functional circuit description\n", "abstract": " Pure functional programming languages have been proposed as a vehicle to describe, simulate and manipulate circuit specifications. We propose an extension to Haskell to solve a standard problem when manipulating data types representing circuits in a lazy functional language. The problem is that circuits are finite graphs but viewing them as an algebraic (lazy) datatype makes them indistinguishable from potentially infinite regular trees. However, implementations of Haskell do indeed represent cyclic structures by graphs. The problem is that the sharing of nodes that creates such cycles is not observable by any function which traverses such a structure. In this paper we propose an extension to call-by-need languages which makes graph sharing observable. The extension is based on non updatable reference cells and an equality test (sharing detection) on this type. We show that this simple and\u00a0\u2026", "num_citations": "112\n", "authors": ["1042"]}
{"title": "A poor man's concurrency monad\n", "abstract": " Without adding any primitives to the language, we define a concurrency monad transformer in Haskell. This allows us to add a limited form of concurrency to any existing monad. The atomic actions of the new monad are lifted actions of the underlying monad. Some extra operations, such as fork, to initiate new processes, are provided. We discuss the implementation, and use some examples to illustrate the usefulness of this construction.", "num_citations": "100\n", "authors": ["1042"]}
{"title": "Automating inductive proofs using theory exploration\n", "abstract": " HipSpec is a system for automatically deriving and proving properties about functional programs. It uses a novel approach, combining theory exploration, counterexample testing and inductive theorem proving. HipSpec automatically generates a set of equational theorems about the available recursive functions of a program. These equational properties make up an algebraic specification for the program and can in addition be used as a background theory for proving additional user-stated properties. Experimental results are encouraging: HipSpec compares favourably to other inductive theorem provers and theory exploration systems.", "num_citations": "96\n", "authors": ["1042"]}
{"title": "Expressive array constructs in an embedded GPU kernel programming language\n", "abstract": " Graphics Processing Units (GPUs) are powerful computing devices that with the advent of CUDA/OpenCL are becomming useful for general purpose computations. Obsidian is an embedded domain specific language that generates CUDA kernels from functional descriptions. A symbolic array construction allows us to guarantee that intermediate arrays are fused away. However, the current array construction has some drawbacks; in particular, arrays cannot be combined efficiently. We add a new type of push arrays to the existing Obsidian system in order to solve this problem. The two array types complement each other, and enable the definition of combinators that both take apart and combine arrays, and that result in efficient generated code. This extension to Obsidian is demonstrated on a sequence of sorting kernels, with good results. The case study also illustrates the use of combinators for expressing the\u00a0\u2026", "num_citations": "80\n", "authors": ["1042"]}
{"title": "A coverage analysis for safety property lists\n", "abstract": " We present a coverage analysis that can be used in property-based verification. The analysis helps identifying \"forgotten cases\"; scenarios where the property list under analysis does not constrain a certain output at a certain point in time. These scenarios can then be manually investigated, possibly leading to new, previously forgotten properties being added. As there often exist cases in which outputs are not supposed to be specified, we also provide means for the specificier to annotate properties in order to control what cases are supposed to be underconstrained. Two main differences with earlier proposed similar analyses exist: The presented analysis is design-independent, and it makes an explicit distinction between intentionally and unintentionally underspecified behavior.", "num_citations": "80\n", "authors": ["1042"]}
{"title": "Using the TPTP language for writing derivations and finite interpretations\n", "abstract": " One of the keys to the success of the TPTP and related projects is their consistent use of the TPTP language. The ability of the TPTP language to express solutions as well as problems, in conjunction with the simplicity of the syntax, sets it apart from other languages used in ATP. This paper provides a complete definition of the TPTP language, and describes how the language should be used to write derivations and finite interpretations.", "num_citations": "78\n", "authors": ["1042"]}
{"title": "The TPTP typed first-order form with arithmetic\n", "abstract": " The TPTP World is a well established infrastructure supporting research, development, and deployment of Automated Theorem Proving systems. Recently, the TPTP World has been extended to include a typed first-order logic, which in turn has enabled the integration of arithmetic. This paper describes these developments.", "num_citations": "74\n", "authors": ["1042"]}
{"title": "The design and implementation of Feldspar\n", "abstract": " Feldspar is a domain specific language, embedded in Haskell, for programming digital signal processing algorithms. The final aim of a Feldspar program is to generate low level code with good performance. Still, we chose to provide the user with a purely functional DSL. The language is implemented as a minimal, deeply embedded core language, with shallow extensions built upon it. This paper presents full details of the essential parts of the implementation. Our initial conclusion is that this approach works well in our domain, although much work remains.", "num_citations": "72\n", "authors": ["1042"]}
{"title": "HALO: Haskell to logic through denotational semantics\n", "abstract": " Even well-typed programs can go wrong in modern functional languages, by encountering a pattern-match failure, or simply returning the wrong answer. An increasingly-popular response is to allow programmers to write contracts that express semantic properties, such as crash-freedom or some useful post-condition. We study the static verification of such contracts. Our main contribution is a novel translation to first-order logic of both Haskell programs, and contracts written in Haskell, all justified by denotational semantics. This translation enables us to prove that functions satisfy their contracts using an off-the-shelf first-order logic theorem prover.", "num_citations": "69\n", "authors": ["1042"]}
{"title": "Embedded languages for describing and verifying hardware.\n", "abstract": " Degree: Ph. D.DegreeYear: 2001Institute: Chalmers Tekniska Hogskola (Sweden)Publisher: Department of Computing Science, Chalmers University of Technology, SE-412 96 Goteborg, Sweden.Lava is a system for designing, specifying, verifying and implementing hardware. It is embedded in the functional programming language Haskell, which means that hardware descriptions are first-class objects in Haskell. We are thus able to use modern programming language features, such as higher-order functions, polymorphism, type classes and laziness, in hardware descriptions.", "num_citations": "65\n", "authors": ["1042"]}
{"title": "A liveness checking algorithm that counts\n", "abstract": " We present a simple but novel algorithm for checking liveness properties of finite-state systems, called k-Liveness, which is based on counting and bounding the number of times a fairness constraint can become true. Our implementation of the algorithm is completely SAT-based, works fairly well in practice, and is competitive in performance with alternative methods. In addition, we present a pre-processing technique which can automatically derive extra fairness constraints for any given liveness problem. These constraints can be used to potentially boost the performance of any liveness algorithm. The experimental results show that the extra constraints are particularly beneficial in combination with our k-Liveness algorithm.", "num_citations": "64\n", "authors": ["1042"]}
{"title": "Wired: Wire-aware circuit design\n", "abstract": " Routing wires are dominant performance stoppers in deep sub-micron technologies, and there is an urgent need to take them into account already at higher levels of abstraction. However, the normal design flow gives the designer only limited control over the details of the lower levels, risking the quality of the final result. We propose a language, called Wired, which lets the designer express circuit function together with layout, in order to get more precise control over the result. The complexity of larger designs is managed by using parameterised connection patterns. The resulting circuit descriptions are compact, and yet capture detailed layout, including the size and positions of wires. We are able to analyse non-functional properties of these descriptions, by \u201crunning\u201d them using non-standard versions of the wire and gate primitives. The language is relational, which means that we can build forwards\u00a0\u2026", "num_citations": "59\n", "authors": ["1042"]}
{"title": "Generating constrained random data with uniform distribution\n", "abstract": " We present a technique for automatically deriving test data generators from a given executable predicate representing the set of values we are interested in generating. The distribution of these generators is uniform over values of a given size. To make the generation efficient, we rely on laziness of the predicate, allowing us to prune the space of values quickly. In contrast, implementing test data generators by hand is labour intensive and error prone. Moreover, handwritten generators often have an unpredictable distribution of values, risking that some values are arbitrarily underrepresented. We also present a variation of the technique that has better performance, but where the distribution is skewed in a limited, albeit predictable way. Experimental evaluation of the techniques shows that the automatically derived generators are much easier to define than handwritten ones, and their performance, while lower, is\u00a0\u2026", "num_citations": "57\n", "authors": ["1042"]}
{"title": "Sort it out with monotonicity\n", "abstract": " We present a novel analysis for sorted logic, which determines if a given sort is monotone. The domain of a monotone sort can always be extended with an extra element. We use this analysis to significantly improve well-known translations between unsorted and many-sorted logic, making use of the fact that it is cheaper to translate monotone sorts than non-monotone sorts. Many interesting problems are more naturally expressed in many-sorted first-order logic than in unsorted logic, but most existing highly-efficient automated theorem provers solve problems only in unsorted logic. Conversely, some reasoning tools, for example model finders, can make good use of sort-information in a problem, but most problems today are formulated in unsorted logic. This situation motivates translations in both ways between many-sorted and unsorted problems. We present the monotonicity analysis and its implementation\u00a0\u2026", "num_citations": "53\n", "authors": ["1042"]}
{"title": "The design and verification of a sorter core\n", "abstract": " We show how the Lava system is used to design and analyse fast sorting circuits for implementation on Field Programmable Gate Arrays (FPGAs). We present both recursive and periodic sorting networks, based on recursive merging networks such as Batcher\u2019s bitonic and odd-even mergers. We show how a design style that concentrates on capturing connection patterns gives elegant generic circuit descriptions. This style aids circuit analysis and also gives the user fine control of the final layout on the FPGA. We demonstrate this by analysing andd implementing four sorters on a Xilinx Virtex-II\u2122 FPGA. Performance figures are presented.", "num_citations": "51\n", "authors": ["1042"]}
{"title": "Obsidian: A domain specific embedded language for parallel programming of graphics processors\n", "abstract": " We present a domain specific language, embedded in Haskell, for general purpose parallel programming on GPUs. Our intention is to explore the use of connection patterns in parallel programming. We briefly present our earlier work on hardware generation, and outline the current state of GPU architectures and programming models. Finally, we present the current status of the Obsidian project, which aims to make GPU programming easier, without relinquishing detailed control of GPU resources. Both a programming example and some details of the implementation are presented. This is a report on work in progress.", "num_citations": "50\n", "authors": ["1042"]}
{"title": "Hipster: Integrating theory exploration in a proof assistant\n", "abstract": " This paper describes Hipster, a system integrating theory exploration with the proof assistant Isabelle/HOL. Theory exploration is a technique for automatically discovering new interesting lemmas in a given theory development. Hipster can be used in two main modes. The first is exploratory mode, used for automatically generating basic lemmas about a given set of datatypes and functions in a new theory development. The second is proof mode, used in a particular proof attempt, trying to discover the missing lemmas which would allow the current goal to be proved. Hipster\u2019s proof mode complements and boosts existing proof automation techniques that rely on automatically selecting existing lemmas, by inventing new lemmas that need induction to be proved. We show example uses of both modes.", "num_citations": "45\n", "authors": ["1042"]}
{"title": "TIP: tons of inductive problems\n", "abstract": " This paper describes our collection of benchmarks for inductive theorem provers. The recent spur of interest in automated inductive theorem proving has increased the demands for evaluation and comparison between systems. We expect the benchmark suite to continually grow as more problems are submitted by the community. New challenge problems will promote further development of provers which will greatly benefit both developers and users of inductive theorem provers.", "num_citations": "41\n", "authors": ["1042"]}
{"title": "Testing polymorphic properties\n", "abstract": " This paper is concerned with testing properties of polymorphic functions. The problem is that testing can only be performed on specific monomorphic instances, whereas parametrically polymorphic functions are expected to work for any type. We present a schema for constructing a monomorphic instance for a polymorphic property, such that correctness of that single instance implies correctness for all other instances. We also give a formal definition of the class of polymorphic properties the schema can be used for. Compared to the standard method of testing such properties, our schema leads to a significant reduction of necessary test cases.", "num_citations": "41\n", "authors": ["1042"]}
{"title": "Structuring graphical paradigms in TkGofer\n", "abstract": " In this paper we describe the implementation of several graphical programming paradigms (Model View Controller, Fudgets, and Functional Animations) using the GUI library TkGofer. This library relies on a combination of monads and multiple-parameter type classes to provide an abstract, type safe interface to Tcl/Tk. We show how choosing the right abstractions makes the given implementations surprisingly concise and easy to understand.", "num_citations": "40\n", "authors": ["1042"]}
{"title": "Typed Logical Variables in Haskell.\n", "abstract": " We describe how to embed a simple typed functional logic programming language in Haskell. The embedding is a natural extension of the Prolog embedding by Seres and Spivey [16]. To get full static typing we need to use the Haskell extensions of quantified types and the ST-monad.", "num_citations": "38\n", "authors": ["1042"]}
{"title": "GPGPU kernel implementation and refinement using Obsidian\n", "abstract": " Obsidian is a domain specific language for data-parallel programming on graphics processors (GPUs). It is embedded in the functional programming language Haskell. The user writes code using constructs familiar from Haskell (like map and reduce), recursion and some specially designed combinators for combining GPU programs. NVIDIA CUDA code is generated from these high level descriptions, and passed to the nvcc compiler\u00a0[1]. Currently, we consider only the generation of single kernels, and not their coordination.This paper is focussed on how the user should work with Obsidian, starting with an obviously correct (or welltested) description of the required function, and refining it by the introduction of constructs to give finer control of the computation on the GPU. For some combinators, this approach results in CUDA code with satisfactory performance, promising increased productivity, as the high level\u00a0\u2026", "num_citations": "36\n", "authors": ["1042"]}
{"title": "Splittable pseudorandom number generators using cryptographic hashing\n", "abstract": " We propose a new splittable pseudorandom number generator (PRNG) based on a cryptographic hash function. Splittable PRNGs, in contrast to linear PRNGs, allow the creation of two (seemingly) independent generators from a given random number generator. Splittable PRNGs are very useful for structuring purely functional programs, as they avoid the need for threading around state. We show that the currently known and used splittable PRNGs are either not efficient enough, have inherent flaws, or lack formal arguments about their randomness. In contrast, our proposed generator can be implemented efficiently, and comes with a formal statements and proofs that quantify how 'random' the results are that are generated. The provided proofs give strong randomness guarantees under assumptions commonly made in cryptography.", "num_citations": "34\n", "authors": ["1042"]}
{"title": "An operational semantics for weak PSL\n", "abstract": " Extending linear temporal logic by adding regular expressions increases its expressiveness. However, as for example, problems in recent versions of Accellera\u2019s Property Specification Language (PSL) as well as in OpenVera\u2019s ForSpec and other property languages show, it is a non-trivial task to give a formal denotational semantics with desirable properties to the resulting logic. In this paper, we argue that specifying an operational semantics may be helpful in guiding this work, and as a bonus leads to an implementation of the logic for free. We give a concrete operational semantics for Weak PSL, which is the safety property subset of PSL. We also propose a denotational semantics which we show to be equivalent to the operational one. This semantics is inspired by a new denotational semantics proposed in recent related work.", "num_citations": "34\n", "authors": ["1042"]}
{"title": "The design and implementation of Mondrian\n", "abstract": " The Haskell dialect Mondrian is designed using the explicit philosophy of keeping things simple and consistent. Mondrian generalizes some of Haskell's (too) complex constructs, and adds a few simple new ones. This results in a small, intuitively comprehensible language with an object oriented avor.", "num_citations": "31\n", "authors": ["1042"]}
{"title": "A tutorial on Lava: A hardware description and verification system\n", "abstract": " Lava is an experimental tool for hardware design and veri cation. Using Lava, one can describe circuits using a simple functional hardware description language. The descriptions are short and sweet, and do not su er from the verbosity of more standard hardware description languages (HDLs) like VHDL and Verilog. On the other hand, we cannot express the same things as in these large, expressive (and complicated) languages. For example, we cannot express low level details about timing. What we can express very nicely, though, is the ways in which circuits are built from sub-circuits. Lava facilitates the description of connection patterns so that they are easily reusable. For some kinds of circuits, for example in signal processing, this is exactly what we want to do. Lava also provides many di erent ways of analysing our circuit descriptions. We can simulate circuits, just as with more standard HDLs, but we can also use symbolic methods to generate input to analysis tools such as automatic theorem provers and model checkers. Indeed, the same methods are used to generate structural VHDL from Lava circuit descriptions. Our aim in this tutorial is to gently introduce this new style of circuit design and analysis, by means of examples.Lava is used at Chalmers as a platform for experiments in the formal veri cation of hardware 3, 2].(Note, however, that both of these references are about an older version of Lava, in which circuit descriptions are a bit more complicated.) Satnam Singh, on the other hand, uses Lava in real industrial design projects at Xilinx Inc., one of the main suppliers of Field Programmable Gate Arrays (FPGAs). In particular, Lava\u00a0\u2026", "num_citations": "30\n", "authors": ["1042"]}
{"title": "A semantics for distributed Erlang\n", "abstract": " We propose an extension to Fredlund's formal semantics for Erlang that models the concept of nodes. The motivation is that there exist sequences of events that can occur in practice, but are impossible to describe using a single-node semantics, such as Fredlund's. The consequence is that some errors in distributed systems might not be detected by model checkers based on Fredlund's original semantics, or by other single-node verification techniques such as testing. Our extension is modest; it re-uses most of Fredlund's work but adds an extra layer at the top-level.", "num_citations": "28\n", "authors": ["1042"]}
{"title": "Practical principled FRP: forget the past, change the future, FRPNow!\n", "abstract": " We present a new interface for practical Functional Reactive Programming (FRP) that (1) is close in spirit to the original FRP ideas,(2) does not have the original space-leak problems, without using arrows or advanced types, and (3) provides a simple and expressive way for performing IO actions from FRP code. We also provide a denotational semantics for this new interface, and a technique (using Kripke logical relations) for reasoning about which FRP functions may\" forget their past\", ie which functions do not have an inherent space-leak. Finally, we show how we have implemented this interface as a Haskell library called FRPNow.", "num_citations": "27\n", "authors": ["1042"]}
{"title": "A seamless, client-centric programming model for type safe web applications\n", "abstract": " We propose a new programming model for web applications which is (1) seamless; one program and one language is used to produce code for both client and server, (2) client-centric; the programmer takes the viewpoint of the client that runs code on the server rather than the other way around, (3) functional and type-safe, and (4) portable; everything is implemented as a Haskell library that implicitly takes care of all networking code. Our aim is to improve the painful and error-prone experience of today's standard development methods, in which clients and servers are coded in different languages and communicate with each other using ad-hoc protocols. We present the design of our library called Haste.App, an example web application that uses it, and discuss the implementation and the compiler technology on which it depends.", "num_citations": "26\n", "authors": ["1042"]}
{"title": "HipSpec: Automating Inductive Proofs of Program Properties.\n", "abstract": " We present ongoing work on HipSpec, a system for automatically deriving and proving properties about functional programs. HipSpec uses a combination of theory exploration, counter-example testing and inductive theorem proving to automatically generate a set of equational theorems about recursive functions in a program, which are later used as a background theory for proving stated properties about a program. Initial experiments are encouraging; our initial HipSpec prototype already compares favourably to other, similar systems.", "num_citations": "26\n", "authors": ["1042"]}
{"title": "SAT-based assistance in abstraction refinement for symbolic trajectory evaluation\n", "abstract": " We present a SAT-based algorithm for assisting users of Symbolic Trajectory Evaluation (STE) in manual abstraction refinement. As a case study, we demonstrate the usefulness of the algorithm by showing how to refine and verify an STE specification of a CAM.", "num_citations": "24\n", "authors": ["1042"]}
{"title": "A new SAT-based algorithm for symbolic trajectory evaluation\n", "abstract": " We present a new SAT-based algorithm for Symbolic Trajectory Evaluation (STE), and compare it to more established SAT-based techniques for STE.", "num_citations": "24\n", "authors": ["1042"]}
{"title": "Quick specifications for the busy programmer\n", "abstract": " QuickSpec is a theory exploration system which tests a Haskell program to find equational properties of it, automatically. The equations can be used to help understand the program, or as lemmas to help prove the program correct. QuickSpec is largely automatic: the user just supplies the functions to be tested and QuickCheck data generators. Previous theory exploration systems, including earlier versions of QuickSpec itself, scaled poorly. This paper describes a new architecture for theory exploration with which we can find vastly more complex laws than before, and much faster. We demonstrate theory exploration in QuickSpec on problems both from functional programming and mathematics.", "num_citations": "22\n", "authors": ["1042"]}
{"title": "Semi-formal development of a fault-tolerant leader election protocol in Erlang\n", "abstract": " We present a semi-formal analysis method for fault-tolerant distributed algorithms written in the distributed functional programming language Erlang. In this setting, standard model checking techniques are often too expensive or too limiting, whereas testing techniques often do not cover enough of the state space.               Our idea is to first run instances of the algorithm on generated stimuli, thereby creating traces of events and states. Then, using an abstraction function specified by the user, our tool generates from these traces an abstract state transition diagram of the system, which can be nicely visualized and thus greatly helps in debugging the system. Lastly, formal requirements of the system specified in temporal logic can be checked automatically to hold for the generated abstract state transition diagram. Because the state transition diagram is abstract, we know that the checked requirements hold for a\u00a0\u2026", "num_citations": "22\n", "authors": ["1042"]}
{"title": "An embedded language approach to hardware description and verification\n", "abstract": " Lava is a system for designing, specifying, verifying and implementing hardware. It is embedded in the functional programming language Haskell, which means that hardware descriptions are rst-class objects in Haskell. We are thus able to use modern programming language features, such as higher-order functions, polymorphism, type classes and laziness, in hardware descriptions. We present two rather di erent versions of Lava. One version realises the embedding by using monads to keep track of the information speci ed in a hardware description. The other version uses a new language construct, called observable sharing, which eliminates the need for monads so that descriptions are much cleaner. Adding observable sharing to Haskell is a non-conservative extension, meaning that some properties of Haskell are lost. We thus investigate to what extent we are still allowed to use a normal Haskell compiler or\u00a0\u2026", "num_citations": "18\n", "authors": ["1042"]}
{"title": "Model-checking signal transduction networks through decreasing reachability sets\n", "abstract": " We consider model checking of Qualitative Networks, a popular formalism for modeling signal transduction networks in biology. One of the unique features of qualitative networks, due to them lacking initial states, is that of \u201creducing reachability sets\u201d. Simply put, a state that is not visited after i steps will not be visited after i\u2032 steps for every i\u2032\u2009>\u2009i. We use this feature to create a compact representation of all the paths of a qualitative network of a certain structure. Combining this compact path representation with LTL model checking leads to significant acceleration in performance. In particular, for a recent model of Leukemia, our approach works at least 5 times faster than the standard approach and up to 100 times faster in some cases. Our approach enhances the iterative hypothesis-driven experimentation process used by biologists, enabling fast turn-around of executable biological models.", "num_citations": "17\n", "authors": ["1042"]}
{"title": "Design-time railway capacity verification using SAT modulo discrete event simulation\n", "abstract": " Railway capacity is complex to define and analyze, and existing tools and methods used in practice require comprehensive models of the railway network and its timetables. Design engineers working within the limited scope of construction projects report that only ad-hoc, experience-based methods of capacity analysis are available to them. Designs have subtle capacity pitfalls which are discovered too late, only when network-wide timetables are made - there is a mismatch between the scope of construction projects and the scope of capacity analysis, as currently practiced.We suggest a language for capacity specifications suited for construction projects, expressing properties such as running time, train frequency, overtaking and crossing. Verifying these properties amounts to solving a planning problem constrained by discrete control system logic, network topology, laws of motion, and sparse communication. To\u00a0\u2026", "num_citations": "16\n", "authors": ["1042"]}
{"title": "Using Lava to design and verify recursive and periodic sorters\n", "abstract": " The Lava system is an experimental framework for designing, verifying, and implementing circuits using powerful concepts borrowed from the world of lazy functional programming. We show how the Lava system is used to design and analyse fast sorting circuits for implementation on Field Programmable Gate Arrays (FPGAs). Two types of sorting networks are described, analyzed, and implemented. We present recursive sorting networks and periodic sorting networks based on Batcher\u2019s bitonic merger and on Batcher\u2019s odd even merger. We show how a design style that concentrates on capturing connection patterns gives elegant generic circuit descriptions. This style aids circuit analysis and also gives the user fine control of the final layout on the FPGA. We demonstrate this by analysing and implementing four sorters on a XilinxVirtexTM-IIFPGA.Performance figures are presented.", "num_citations": "16\n", "authors": ["1042"]}
{"title": "Shrinking and showing functions: (functional pearl)\n", "abstract": " Although quantification over functions in QuickCheck properties has been supported from the beginning, displaying and shrinking them as counter examples has not. The reason is that in general, functions are infinite objects, which means that there is no sensible show function for them, and shrinking an infinite object within a finite number of steps seems impossible. This paper presents a general technique with which functions as counter examples can be shrunk to finite objects, which can then be displayed to the user. The approach turns out to be practically usable, which is shown by a number of examples. The two main limitations are that higher-order functions cannot be dealt with, and it is hard to deal with terms that contain functions as subterms.", "num_citations": "14\n", "authors": ["1042"]}
{"title": "Automated inference of finite unsatisfiability\n", "abstract": " We present Infinox, an automated tool for analyzing first-order logic problems, aimed at showing finite unsatisfiability, i.e., the absence of models with finite domains. Finite satisfiability is not a decidable problem (only semi-decidable), which means that such a tool can never be complete. Nonetheless, our hope is that Infinox be a useful complement to finite model finders in practice. Infinox uses several different proof techniques for showing infinity of a set, each of which requires the identification of a function or a relation with particular properties. Infinox enumerates candidates to such functions and relations, and subsequently uses an automated theorem prover as a sub-procedure to try to prove the resulting proof obligations. We have evaluated Infinox on the relevant problems from the TPTP benchmark suite, and we are able to automatically show finite unsatisfiability for over 25% of these problems.", "num_citations": "14\n", "authors": ["1042"]}
{"title": "Explaining symbolic trajectory evaluation by giving it a faithful semantics\n", "abstract": " Symbolic Trajectory Evaluation (STE) is a formal verification technique for hardware. The current STE semantics is not faithful to the proving power of existing STE tools, which obscures the STE theory unnecessarily. In this paper, we present a new closure semantics for STE which does match the proving power of STE model-checkers, and makes STE easier to understand.", "num_citations": "14\n", "authors": ["1042"]}
{"title": "Safety property verification of cyclic synchronous circuits\n", "abstract": " Today\u2019s most common formal verification tools for hardware are unable to deal with circuits containing combinational loops. However, in the areas of hardware compilation, circuit synthesis and circuit optimization, it is quite natural for a subclass of these loops, the so-called constructive loops, to arise. These are loops that physically exist in a circuit, but are never logically taken. In this paper, we present a method for safety property verification of circuits containing constructive combinational loops, based on propositional theorem proving and temporal induction. It can be used to just prove constructivess of circuits, but also to directly prove safety properties of the circuits. Unlike previously proposed methods, no fixed point iteration is needed, we do not have to compute reachable states, and no cycle-free representation of the circuit has to be computed.", "num_citations": "14\n", "authors": ["1042"]}
{"title": "SAT modulo intuitionistic implications\n", "abstract": " We present a new method for solving problems in intuitionistic propositional logic, which involves the use of an incremental SAT-solver. The method scales to very large problems, and fits well into an SMT-based framework for interaction with other theories.", "num_citations": "13\n", "authors": ["1042"]}
{"title": "Efficient divide-and-conquer parsing of practical context-free languages\n", "abstract": " We present a divide-and-conquer algorithm for parsing context-free languages efficiently. Our algorithm is an instance of Valiant's (1975), who reduced the problem of parsing to matrix multiplications. We show that, while the conquer step of Valiant's is O (n 3) in the worst case, it improves to O (logn 3), under certain conditions satisfied by many useful inputs. These conditions occur for example in program texts written by humans. The improvement happens because the multiplications involve an overwhelming majority of empty matrices. This result is relevant to modern computing: divide-and-conquer algorithms can be parallelized relatively easily.", "num_citations": "12\n", "authors": ["1042"]}
{"title": "Proving equational Haskell properties using automated theorem provers\n", "abstract": " This Master thesis gives a new tool to automatically verify equational properties written in the functional programming language Haskell. The aim is to be able to reason about infinite and partial values available in Haskell from general recursion and lazy data structures. The novelty of this approach is to use automated theorem provers for first order logic by means of a translation from Haskell to first order theories. The properties are instantiated with different induction techniques applicable to non strict functional languages: structural induction, fixed point induction and the approximation lemma. As the target logic is untyped, Haskell features such as pattern matching and higher order functions needs to be dealt with special care. The results from using the tool on a test suite are convincing as the automated provers quickly deduce theorems for a variety of properties. To be able to compete on fair grounds with\u00a0\u2026", "num_citations": "12\n", "authors": ["1042"]}
{"title": "Using valued booleans to find simpler counterexamples in random testing of cyber-physical systems\n", "abstract": " We propose a new logic of valued Booleans for writing properties which are not just true or false but compute how severely they are falsified. The logic is reminiscent of STL or MTL but gives the tester control over what severity means in the particular problem domain. We use this logic to simplify failing test inputs in the context of random testing of cyber-physical systems and show that it improves the quality of counterexamples found. The logic of valued Booleans might also be used as an alternative to the standard robust semantics of STL formulas in optimization-based approaches to falsification.", "num_citations": "11\n", "authors": ["1042"]}
{"title": "Obsidian: GPU programming in Haskell\n", "abstract": " Obsidian is a language for data-parallel programming embedded in Haskell. As the Obsidian programs are run, C code is generated. This C code can be compiled for an NVIDIA 8800 series GPU (Graphics Processing Unit), or for other high-end NVIDIA GPUs. The idea is that the style of programming used in Lava for structural hardware design [2] can be applied to data-parallel programming as well. Therefore Obsidian programmers use combinators that have much in common with those used in Lava. However, where Lava generates the netlist for a fixed-size circuit, Obsidian can generate GPU programs that are parametric in input size.", "num_citations": "11\n", "authors": ["1042"]}
{"title": "Finding counter examples in induction proofs\n", "abstract": " This paper addresses a problem arising in automated proof of invariants of transition systems, for example transition systems modelling distributed programs. Most of the time, the actual properties we want to prove are too weak to hold inductively, and auxiliary invariants need to be introduced. The problem is how to find these extra invariants. We propose a method where we find minimal counter examples to candidate invariants by means of automated random testing techniques. These counter examples can be inspected by a human user, and used to adapt the set of invariants at hand. We are able to find two different kinds of counter examples, either indicating (1) that the used invariants are too strong (a concrete trace of the system violates at least one of the invariants), or (2) that the used invariants are too weak (a concrete transition of the system does not maintain all invariants). We have developed and\u00a0\u2026", "num_citations": "11\n", "authors": ["1042"]}
{"title": "Automated inference of finite unsatisfiability\n", "abstract": " We present Infinox, an automated tool for analyzing first-order logic problems, aimed at showing finite unsatisfiability, i.e. the absence of models with finite domains. Finite satisfiability is a semi-decidable problem, which means that such a tool can never be complete. Nevertheless, our hope is that Infinox be a complement to finite model finders in practice. The implementation consists of several different proof techniques for showing infinity of a set, each of which requires the identification of a function or a relation with particular properties. Infinox enumerates candidates to such functions and relations, and subsequently uses an automated theorem prover as a sub-procedure to try to prove the resulting proof obligations. We have evaluated Infinox on the relevant problems from the TPTP benchmark suite, with very promising results.", "num_citations": "10\n", "authors": ["1042"]}
{"title": "Embedded hardware description languages: Exploring the design space\n", "abstract": " The embedding of hardware description languages in functional programming languages has been actively explored for a number of decades, and a surprising number of such embedded languages have been developed and used. The first thing a developer of such a language realises, is the rich set of options and possible approaches. In this presentation, we discuss these issues, and examine their advantages and disadvantages in different settings, for languages developed with different objectives in mind.", "num_citations": "7\n", "authors": ["1042"]}
{"title": "Enhancing temporal logic falsification with specification transformation and valued booleans\n", "abstract": " Cyber-physical systems (CPSs) are systems with both physical and software components, for example, cars and industrial robots. Since these systems exhibit both discrete and continuous dynamics, they are complex and it is thus difficult to verify that they behave as expected. Falsification of temporal logic properties is an approach to find counterexamples to CPSs by means of simulation. In this article, we propose two additions to enhance the capability of falsification and make it more viable in a large-scale industrial setting. The first addition is a framework for transforming specifications from a signal-based model into signal temporal logic. The second addition is the use of valued Booleans and an additive robust semantics in the falsification process. We evaluate the performance of the additive robust semantics on a set of benchmark models, and we can see that which semantics are preferable depend both on the\u00a0\u2026", "num_citations": "6\n", "authors": ["1042"]}
{"title": "Multiple objective functions for falsification of cyber-physical systems\n", "abstract": " Cyber-physical systems are typically safety-critical, thus it is crucial to guarantee that they conform to given specifications, that are the properties that the system must fulfill. Optimization-based falsification is a model-based testing method to find counterexamples of the specifications. The main idea is to measure how far away a specification is from being broken, and to use an optimization procedure to guide the testing towards falsification. The efficiency of the falsification is affected by the objective function used to evaluate the test results; different objective functions are differently efficient for different types of problems. However, the efficiency of various objective functions is not easily determined beforehand. This paper evaluates the efficiency of using multiple objective functions in the falsification process. The hypothesis is that this will, in general, be more efficient, meaning that it falsifies a system in fewer iterations\u00a0\u2026", "num_citations": "6\n", "authors": ["1042"]}
{"title": "Efficient encodings of first-order Horn formulas in equational logic\n", "abstract": " We present several translations from first-order Horn formulas to equational logic. The goal of these translations is to allow equational theorem provers to efficiently reason about non-equational problems. Using these translations we were able to solve 37 problems of rating 1.0 (i.e. which had not previously been automatically solved) from the TPTP.", "num_citations": "6\n", "authors": ["1042"]}
{"title": "An embedded language approach to teaching hardware compilation\n", "abstract": " This paper describes a course in hardware description and synthesis (hardware compilation), taught as an introductory graduate course at Chalmers University of Technology, and as an advanced undergraduate course at the University of Malta. The functional programming language Haskell was used both to describe circuits and circuit synthesis schemes.", "num_citations": "6\n", "authors": ["1042"]}
{"title": "A Tutorial on Lava\n", "abstract": " Lava is an experimental toolfor hardware design and verification. Using Lava, one can descri be circuits using a simple functional hard w are description language. The descriptions are short and sweet, and do not suffer from the verbosity ofmore standard hardware description languages (HDLs) like VHDL and Verilog. On the other hand, we cannot express the same things as in these large, expressive (and complicated) languages. For example, we cannot express low level details about timing. W hat we can express very nicely, though, is the ways in which circuits are built from su b-circuits. Lava facilitates the description of connection patterns so that they are easily reusable. For somekinds ofcircuits, for example in signal processing, this is exactly what we want to do. Lava also provides many different w ays of analysing our circuit descriptions. W e can simulate circuits, just as with more standard HDLs, but we can\u00a0\u2026", "num_citations": "5\n", "authors": ["1042"]}
{"title": "Using circular programs for higher-order syntax: functional pearl\n", "abstract": " This pearl presents a novel technique for constructing a first-order syntax tree directly from a higher-order interface. We exploit circular programming to generate names for new variables, resulting in a simple yet efficient method. Our motivating application is the design of embedded languages supporting variable binding, where it is convenient to use higher-order syntax when constructing programs, but first-order syntax when processing or transforming programs.", "num_citations": "4\n", "authors": ["1042"]}
{"title": "High level architectural modelling for early estimation of power and performance\n", "abstract": " We present a work in progress report on yet another project that aims to use programming language technology to help raise the level of abstraction at which microprocessor and system-on-chip design is done. We are fully aware that inside Intel alone there have been many such projects, none of which has succeeded. In this talk, we explain why we are trying again, and clarify the differences between our approach and the previous ones.", "num_citations": "4\n", "authors": ["1042"]}
{"title": "Verifying hardware compilers\n", "abstract": " The use of hardware compilers to generate complex circuits from a high-level description is becoming more and more prevalent in a variety of application areas. However, this introduces further risks as the compilation process may introduce errors in otherwise correct high-level descriptions of circuits. In this paper, we present techniques to enable the automatic verification of hardware compilers through the use of finite-state model checkers. We illustrate the use of these techniques on a simple regular expression hardware compiler and discuss how these techniques can be further developed and used on more complex hardware- description languages.", "num_citations": "4\n", "authors": ["1042"]}
{"title": "Testing Safety PLCs Using QuickCheck\n", "abstract": " The testing of safety-related industrial systems is usually carried out by means of checklists. A tester has a list of scenarios that he or she manually applies to the system to check whether the system behaves according to its specification. However, operators behave unpredictably. Their behavior may not be covered by the set of scenarios tested and may lead to dangerous situations. To avoid this, randomized test case generation can be useful as it allows for unanticipated scenarios. The presented framework uses a tool for randomized test case generation, QuickCheck, to trigger event sequences that are then applied to a Safety Programmable Logic Controller (Safety PLC). Experiments show that this concept is capable of finding errors in safety code or increasing the tester's confidence in the correctness of the code by exhibiting a large number of passing test cases. While this concept proves to be powerful, it does\u00a0\u2026", "num_citations": "3\n", "authors": ["1042"]}
{"title": "The Anatomy of Equinox\u2013An Extensible Automated Reasoning Tool for First-Order Logic and Beyond\n", "abstract": " Equinox is an automated reasoning tool for first-order logic. It is also a framework for building highly targeted automated reasoning tools for specific domains.             The aim behind Equinox is to obtain an automated reasoning tool with a modular and extensible architecture. SAT modulo theory (SMT) solvers have the same aim. However, the way in which this aim is realized in Equinox is quite different from the way this is done traditional SMT solvers.", "num_citations": "3\n", "authors": ["1042"]}
{"title": "GPGPU kernel implementation using an embedded language: a status report\n", "abstract": " Obsidian is a domain specific language for general purpose computations on graphics processing units (GPUs) embedded Haskell. This report present examples of GPU kernels written in Obsidian as well as parts of the current implementation of Obsidian. The goal with Obsidian is to raise the level of abstraction for the programmer while not scarifying performance. The kind of decisions and tradeoffs considered by a GPU kernel implementer should be easy to make and change in Obsidian.", "num_citations": "3\n", "authors": ["1042"]}
{"title": "A faithful semantics for generalised symbolic trajectory evaluation\n", "abstract": " Generalised Symbolic Trajectory Evaluation (GSTE) is a high-capacity formal verification technique for hardware. GSTE uses abstraction, meaning that details of the circuit behaviour are removed from the circuit model. A semantics for GSTE can be used to predict and understand why certain circuit properties can or cannot be proven by GSTE. Several semantics have been described for GSTE. These semantics, however, are not faithful to the proving power of GSTE-algorithms, that is, the GSTE-algorithms are incomplete with respect to the semantics. The abstraction used in GSTE makes it hard to understand why a specific property can, or cannot, be proven by GSTE. The semantics mentioned above cannot help the user in doing so. The contribution of this paper is a faithful semantics for GSTE. That is, we give a simple formal theory that deems a property to be true if-and-only-if the property can be proven by a GSTE-model checker. We prove that the GSTE algorithm is sound and complete with respect to this semantics.", "num_citations": "3\n", "authors": ["1042"]}
{"title": "An introduction to symbolic trajectory evaluation\n", "abstract": " The rapid growth in hardware complexity has lead to a need for formal verification of hardware designs to prevent bugs from entering the final silicon. Model-checking [3] is by far the most popular technique for automatically verifying properties of designs. In model-checking, a model of a design is exhaustively checked against a property, often specified in some temporal logic. Today, all major hardware companies use model-checkers in order to reduce the number of bugs in their designs.             Most model-checking techniques are state-based. This means that some kind of representation of all reachable states of the design is used when checking that the temporal properties are fulfilled. One popular way of representing the set of reachable states of a design is by using Binary Decision Diagrams (BDDs) [2]. A BDD is a canonical way of representing a boolean formula over a fixed set of variables. When the\u00a0\u2026", "num_citations": "3\n", "authors": ["1042"]}
{"title": "Automated Drawing of Railway Schematics Using Numerical Optimization in SAT\n", "abstract": " Schematic drawings showing railway tracks and equipment are commonly used to visualize railway operations and to communicate system specifications and construction blueprints. Recent advances in on-line collaboration and modeling tools have raised the expectations for quickly making changes to models, resulting in frequent changes to layouts, text, and/or symbols in schematic drawings. Automating the creation of high-quality schematic views from geographical and topological models can help engineers produce and update drawings efficiently. This paper describes three methods for automatically producing schematic railway drawings with increasing level of quality and control over the result. The final method, implemented in the tool that we present, can use any combination of the following optimization criteria, which have different priorities in different use cases: width and height of the drawing, the\u00a0\u2026", "num_citations": "2\n", "authors": ["1042"]}
{"title": "A supervisory control algorithm based on property-directed reachability\n", "abstract": " We present an algorithm for synthesising a controller (supervisor) for a discrete event system (DES) based on the property-directed reachability (PDR) model checking algorithm. The discrete event systems framework is useful in both software, automation and manufacturing, as problems from those domains can be modelled as discrete supervisory control problems. As a formal framework, DES is also similar to domains for which the field of formal methods for computer science has developed techniques and tools. In this paper, we attempt to marry the two by adapting PDR to the problem of controller synthesis. The resulting algorithm takes as input a transition system with forbidden states and uncontrollable transitions, and synthesises a safe and minimally-restrictive controller, correct-by-design. We also present an implementation along with experimental results, showing that the algorithm has potential as\u00a0\u2026", "num_citations": "2\n", "authors": ["1042"]}
{"title": "Analysing Constraint Grammars with a SAT-solver\n", "abstract": " We describe a method for analysing Constraint Grammars (CG) that can detect internal conflicts and redundancies in a given grammar, without the need for a corpus. The aim is for grammar writers to be able to automatically diagnose, and then manually improve their grammars. Our method works by translating the given grammar into logical constraints that are analysed by a SAT-solver. We have evaluated our analysis on a number of non-trivial grammars and found inconsistencies.", "num_citations": "2\n", "authors": ["1042"]}
{"title": "Constraint Grammar as a SAT problem\n", "abstract": " We represent Constraint Grammar (CG) as a Boolean satisfiability (SAT) problem. Encoding CG in logic brings some new features to the grammars. The rules are interpreted in a more declarative way, which makes it possible to abstract away from details such as cautious context and ordering. A rule is allowed to affect its context words, which makes the number of the rules in a grammar potentially smaller. Ordering can be preserved or discarded; in the latter case, we solve eventual rule conflicts by finding a solution that discards the least number of rule applications. We test our implementation by parsing texts in the order of 10,000 s\u2013100,000 s words, using grammars with hundreds of rules.", "num_citations": "2\n", "authors": ["1042"]}
{"title": "Linearly ordered attribute grammar scheduling using SAT-solving\n", "abstract": " Many computations over trees can be specified using attribute grammars. Compilers for attribute grammars need to find an evaluation order (or schedule) in order to generate efficient code. For the class of linearly ordered attribute grammars such a schedule can be found statically, but this problem is known to be NP-hard.                 In this paper, we show how to encode linearly ordered attribute grammar scheduling as a SAT-problem. For such grammars it is necessary to ensure that the dependency graph is cycle free, which we approach in a novel way by transforming the dependency graph to a chordal graph allowing the cycle freeness to be efficiently expressed and computed using SAT solvers.                 There are two main advantages to using a SAT-solver for scheduling: (1) the scheduling algorithm runs faster than existing scheduling algorithms on real-world examples, and (2) by adding extra\u00a0\u2026", "num_citations": "2\n", "authors": ["1042"]}
{"title": "Efficient parallel and incremental parsing of practical context-free languages\n", "abstract": " We present a divide-and-conquer algorithm for parsing context-free languages efficiently. Our algorithm is an instance of Valiant's (1975; General context-free recognition in less than cubic time. J. Comput. Syst. Sci.10(2), 308\u2013314), who reduced the problem of parsing to matrix multiplications. We show that, while the conquer step of Valiant's is O(n3), it improves to O(log2n) under certain conditions satisfied by many useful inputs that occur in practice, and if one uses a sparse representation of matrices. The improvement happens because the multiplications involve an overwhelming majority of empty matrices. This result is relevant to modern computing: divide-and-conquer algorithms with a polylogarithmic conquer step can be parallelized relatively easily.", "num_citations": "2\n", "authors": ["1042"]}
{"title": "Generating counterexamples for structural inductions by exploiting nonstandard models\n", "abstract": " Induction proofs often fail because the stated theorem is noninductive, in which case the user must strengthen the theorem or prove auxiliary properties before performing the induction step. (Counter)model finders are useful for detecting non-theorems, but they will not find any counterexamples for noninductive theorems. We explain how to apply a well-known concept from first-order logic, nonstandard models, to the detection of noninductive invariants. Our work was done in the context of the proof assistant Isabelle/HOL and the counterexample generator Nitpick.", "num_citations": "2\n", "authors": ["1042"]}
{"title": "Using lava and wired for design exploration\n", "abstract": " Lava has been used successfully in structural circuit description and layout generation for FPGAs. It has been demonstrated that Lava is suitable for describing so-called \"clever\" or adaptive circuits -- circuits whose structure adapts to various properties of their contexts. This can be incorporated quite naturally into the descriptions due to the fact that Lava is embedded in the powerful functional programming language Haskell.  The rising problems associated with chip design in the deep sub-micron (DSM) era calls for new methods that are able to account for low-level effects already in higher-level descriptions. In particular, interconnect wires need to be modeled in order to get reliable estimates of non-functional properties, such as delay and power consumption. We are working on a system -- Wired -- which aims to bring the ideas from Lava down to lower levels. What distinguishes Wired from other layout-aware\u00a0\u2026", "num_citations": "2\n", "authors": ["1042"]}
{"title": "Induction and state machines\n", "abstract": " This short paper describes a well-known and a non-standard technique for proving properties about sequential circuits. The techniques are based on transforming the circuit to an abstract state machine, and performing several ways of induction on these state machines.", "num_citations": "2\n", "authors": ["1042"]}
{"title": "Testing cyber-physical systems using a line-search falsification method\n", "abstract": " Cyber-physical systems (CPSs) are complex and exhibit both continuous and discrete dynamics, hence it is difficult to guarantee that they satisfy given specifications, i.e., the properties that must be fulfilled by the system. Falsification of temporal logic properties is a testing approach that searches for counterexamples of a given specification that can be used to increase the confidence that a CPS does fulfill its specifications. Falsification can be done using random search methods or optimization methods, both of which have their own benefits and drawbacks. This paper introduces two methods that exploit randomness to different degrees: the optimization-free Hybrid-Corner-Random (), and the direct-search method Line-search Falsification (). combines randomly chosen parameter values with extreme parameter values, which performs surprisingly well on benchmark evaluations. The gradient-free optimization\u00a0\u2026", "num_citations": "1\n", "authors": ["1042"]}
{"title": "SAT modulo discrete event simulation applied to railway design capacity analysis\n", "abstract": " This paper proposes a new method of combining SAT with discrete event simulation. This new integration proved useful for designing a solver for capacity analysis in early phase railway construction design. Railway capacity is complex to define and analyze, and existing tools and methods used in practice require comprehensive models of the railway network and its timetables. Design engineers working within the limited scope of construction projects report that only ad-hoc, experience-based methods of capacity analysis are available to them. Designs often have subtle capacity pitfalls which are discovered too late, only when network-wide timetables are made\u2014there is a mismatch between the scope of construction projects and the scope of capacity analysis, as currently practiced. We suggest a language for capacity specifications suited for construction projects, expressing properties such as running time, train\u00a0\u2026", "num_citations": "1\n", "authors": ["1042"]}
{"title": "Towards secure IoT programming in Haskell\n", "abstract": " IoT applications are often developed in programming languages with low-level abstractions, where a seemingly innocent mistake might lead to severe security vulnerabilities. Current IoT development tools make it hard to identify these vulnerabilities as they do not provide end-to-end guarantees about how data flows within and between appliances. In this work we present Haski, an embedded domain specific language in Haskell (eDSL) for secure programming of IoT devices. Haski enables developers to write Haskell programs that generate C code without falling into many of C\u2019s pitfalls. Haski is designed after the synchronous programming language Lustre, and sports a backwards compatible information-flow control extension to restrict how sensitive data is propagated and modified within the application. We present a novel eDSL design which uses recursive monadic bindings and allows a natural use of\u00a0\u2026", "num_citations": "1\n", "authors": ["1042"]}
{"title": "Inferring morphological rules from small examples using 0/1 linear programming\n", "abstract": " We show how to express the problem of finding an optimal morpheme segmentation from a set of labelled words as a 0/1 linear programming problem, and how to build on this to analyse a language\u2019s morphology. The approach works even when there is very little training data available.", "num_citations": "1\n", "authors": ["1042"]}
{"title": "Applying valued booleans in testing of cyber-physical systems\n", "abstract": " In software testing, as in cyber-physical systems testing, test suites are traditionally developed by hand. In this work we consider one framework for putting the computer in charge of the testing instead: constrained random test case generation as supported by the tool QuickCheck. This is implemented by the use of Valued Booleans (VBools). VBools naturally allow for an extension of QuickCheck into cyber-physical systems, which is useful particularly since QuickCheck can perform shrinking of test cases. Shrinking is a technique to make test cases simpler while preserving failure.", "num_citations": "1\n", "authors": ["1042"]}
{"title": "The Key monad: type-safe unconstrained dynamic typing\n", "abstract": " We present a small extension to Haskell called the Key monad. With the Key monad, unique keys of different types can be created and can be tested for equality. When two keys are equal, we also obtain a concrete proof that their types are equal. This gives us a form of dynamic typing, without the need for Typeable constraints. We show that our extension allows us to safely do things we could not otherwise do: it allows us to implement the ST monad (inefficiently), to implement an embedded form of arrow notation, and to translate parametric HOAS to typed de Bruijn indices, among others. Although strongly related to the ST monad, the Key monad is simpler and might be easier to prove safe. We do not provide such a proof of the safety of the Key monad, but we note that, surprisingly, a full proof of the safety of the ST monad also remains elusive to this day. Hence, another reason for studying the Key monad is that a\u00a0\u2026", "num_citations": "1\n", "authors": ["1042"]}
{"title": "Using fusion to enable late design decisions for pipelined computations\n", "abstract": " We present an embedded language in Haskell for programming pipelined computations. The language is a combination of Feldspar (a functional language for array computations) and a new implementation of Ziria (a language for describing streaming computations originally designed for programming software defined radio). The resulting language makes heavy use of fusion: as in Feldspar, computations over arrays are fused to eliminate intermediate arrays, but Ziria processes can also be fused, eliminating the message passing between them, which in turn can give rise to more fusion at the Feldspar level. The result is a language in which we can first describe pipelined computations at a very fine-grained level, and only afterwards map computations onto the details of a specific parallel architecture, where the fusion helps us to generate efficient code. This flexible design method enables late design decisions\u00a0\u2026", "num_citations": "1\n", "authors": ["1042"]}
{"title": "Using Wired for Design Exploration\n", "abstract": " The rising problems associated with chip design in the deep sub-micron era call for new methods that are able to account for low-level effects already in higher-level descriptions. In particular, interconnect wires need to be modeled in order to get reliable estimates of non-functional properties, such as delay and power consumption. We are working on a system\u2013Wired [1]\u2013which aims to bring the ideas from Lava down to lower levels. What distinguishes Wired from other layout-aware languages is that wires are modelled explicitly. Also, we have settled on a relational model of information flow, giving some decoupling of information flow from the structural combinators, in the style of Ruby [3]. Wired supports a number of different circuit analyses. We can, for example, analyse for signal flow direction and delay. Our most advanced delay model uses Elmore approximation to appropriately take account of fanout and load capacitance. This analysis is, we feel, an important advance on the version of Wired presented at DCC 2004. It makes essential use of the relational aspect of Wired, with resistances flowing in one direction and capacitances in the other. We have, in Wired, described some tiny circuits that adapt to the delays in their inputs using the idea of clever circuits from Lava [4]. But scaling this up has not been as straight-forward as we had hoped. While adapting to forwards properties (like Lava-style unit delay) can usually be done greedily, adapting to bi-directional properties (like Elmore delay) seems to require some back-tracking, which does not come very naturally in Wired. Still, we hope to tackle more complicated delay-adaptive circuits in\u00a0\u2026", "num_citations": "1\n", "authors": ["1042"]}
{"title": "Wired-a Language for Describing Non-Functional Properties of Digital Circuits\n", "abstract": " Increasingly, designers need to estimate non-functional properties such as area, power consumption and timing, even when working at a high level of abstraction, early in the design. In deep sub-micron processes, it is the routing wires that account for most of the power consumption and signal delays. So, information about the wires is vital for controlling non-functional properties. To deal with more and more complex constructions, current design methods and languages strive towards higher and higher levels of abstraction, and provide only very limited possibilities for low-level control. Often, detailed information about wire properties is only available in the very last design stages-after placement and routing.We propose a language, Wired, that aims to bridge this gap in abstraction levels. The main idea is construction with combinators, an approach previously used in Ruby and Lava [3, 1]. Regular circuits, such as arrays and trees, are described with generic higher-order connection patterns [1]. The key to the usefulness of this style is that the connection patterns have both functional and geometric interpretations. This allows us to construct circuits at high-level, without loosing control over lower levels. The descriptions have a recursive structure, with the leaves being primitive building blocks.", "num_citations": "1\n", "authors": ["1042"]}
{"title": "Safety property verification of cyclic circuits\n", "abstract": " Today's most common formal verification tools are unable to deal with circuits containing combinational loops. However, in the areas of hardware compilation, circuit synthesis and circuit optimization, it is quite natural for a subclass of these loops, the so-called constructive loops, to arise. These are loops that physically exist in a circuit, but are never logically taken. In this paper, we present a method for safety property verification of circuits containing constructive combinational loops, based on propositional theorem proving and temporal induction. It can be used to just prove constructivess of circuits, but also to directly prove safety properties of the circuits. Unlike previously proposed methods, no fixed point iteration is needed, we do not have to compute reachable states, and no cycle-free representation of the circuit has to be computed.", "num_citations": "1\n", "authors": ["1042"]}
{"title": "Graphs in compilation (poster)\n", "abstract": " Traditionally, inside compilers, expression trees are used as an internal representation of functional programs. A big disadvantage of trees is the w of explicit variable names in expressions. When expression trees are transformed to optimize a program [5], we end up doing a lot of administration on the variables. Aleo, substitution of variables is a costly and awkward operation. Variable names create an extra indirection we do not want, but still have to deal with.Alternatively, programs can be represented by expression graphs. This is the approach we took in the compiler of Mondrian[3], a new lazy functional language that we are currently designing and implementing. Expression constructors (such as application and lambda abstraction) are represented aa nodes in the graphs, whereas their arguments (other expressions or variables) are pointers to other pieces of the graph.", "num_citations": "1\n", "authors": ["1042"]}
{"title": "Program Transformations in and on a Lazy Functional Language\n", "abstract": " Mondrian'Meij96] is a lazy functional language currently being developed by Erik Meijer et al. The compiler process consists mainly of source-to-source transformations. This article describes a way to implement these transformations concisely, and shows examples using this implementation.", "num_citations": "1\n", "authors": ["1042"]}