{"title": "Yale: Rapid prototyping for complex data mining tasks\n", "abstract": " KDD is a complex and demanding task. While a large number of methods has been established for numerous problems, many challenges remain to be solved. New tasks emerge requiring the development of new methods or processing schemes. Like in software development, the development of such solutions demands for careful analysis, specification, implementation, and testing. Rapid prototyping is an approach which allows crucial design decisions as early as possible. A rapid prototyping system should support maximal re-use and innovative combinations of existing methods, as well as simple and quick integration of new ones. This paper describes Yale, a free open-source environment forKDD and machine learning. Yale provides a rich variety of methods whichallows rapid prototyping for new applications and makes costlyre-implementations unnecessary. Additionally, Yale offers extensive functionality for\u00a0\u2026", "num_citations": "1497\n", "authors": ["1072"]}
{"title": "Detecting Concept Drift with Support Vector Machines.\n", "abstract": " For many learning tasks where data is collected over an extended period of time, its underlying distribution is likely to change. A typical example is information ltering, ie the adaptive classi cation of documents with respect to a particular user interest. Both the interest of the user and the document content change over time. A ltering system should be able to adapt to such concept changes. This paper proposes a new method to recognize and handle concept changes with support vector machines. The method maintains a window on the training data. The key idea is to automatically adjust the window size so that the estimated generalization error is minimized. The new approach is both theoretically well-founded as well as e ective and e cient in practice. Since it does not require complicated parameterization, it is simpler to use and more robust than comparable heuristics. Experiments with simulated concept drift scenarios based on real-world text data compare the new method with other window management approaches. We show that it can e ectively select an appropriate window size in a robust way.", "num_citations": "623\n", "authors": ["1072"]}
{"title": "Learning drifting concepts: Example selection vs. example weighting\n", "abstract": " For many learning tasks where data is collected over an extended period of time, its underlying distribution is likely to change. A typical example is information filtering, ie the adaptive classification of documents with respect to a particular user interest. Both the interest of the user and the document content change over time. A filtering system should be able to adapt to such concept changes. This paper proposes several methods to handle such concept drifts with support vector machines. The methods either maintain an adaptive time window on the training data [13], select representative training examples, or weight the training examples [15]. The key idea is to automatically adjust the window size, the example selection, and the example weighting, respectively, so that the estimated generalization error is minimized. The approaches are both theoretically well-founded as well as effective and efficient in practice\u00a0\u2026", "num_citations": "591\n", "authors": ["1072"]}
{"title": "Boosting classifiers for drifting concepts\n", "abstract": " In many real-world classification tasks, data arrives over time and the target concept to be learned from the data stream may change over time. Boosting methods are well-suited for learning from data streams, but do not address this concept drift problem. This paper proposes a boosting-like method to train a classifier ensemble from data streams that naturally adapts to concept drift. Moreover, it allows to quantify the drift in terms of its base learners. Similar as in regular boosting, examples are re-weighted to induce a diverse ensemble of base models. In order to handle drift, the proposed method continuously re-weights the ensemble members based on their performance on the most recent examples only. The proposed strategy adapts quickly to different kinds of concept drift. The algorithm is empirically shown to outperform learning algorithms that ignore concept drift. It performs no worse than advanced adaptive\u00a0\u2026", "num_citations": "183\n", "authors": ["1072"]}
{"title": "An ensemble classifier for drifting concepts\n", "abstract": " This paper proposes a boosting-like method to train a classifier ensemble from data streams. It naturally adapts to concept drift and allows to quantify the drift in terms of its base learners. The algorithm is empirically shown to outperform learning algorithms that ignore concept drift. It performs no worse than advanced adaptive time window and example selection strategies that store all the data and are thus not suited for mining massive streams.", "num_citations": "120\n", "authors": ["1072"]}
{"title": "Yale: Yet another learning environment\n", "abstract": " In many data mining and knowledge discovery applications, the problem at hand cannot be solved satisfactorily by just taking the raw data as it is and simply applying a single one-step machine learning method. Instead, some data pre-processing and maybe representation changes are necessary to provide the data in a form suitable for the learning task and the chosen learning method and to improve the performance of the learned model. One example is the task of predicting certain properties of a chemical given its chromatogram curve, ie a time series with concentrations of the chemical measured at di erent points of time at the end of a column the chemical is sent through. The sensor readings may be noisy and perhaps slightly shifted along the time axis between di erent measurements, so that chromatograms looking very similar to a human expert, may seem very di erent for a learning method depending on the chosen representation. The extraction or construction of characteristic, robust features may signi cantly improve the result obtained by a learning method. Hence in many data mining applications, like the one just mentioned, one rather considers chains of pre-processing and learning steps rather than just a single one-step method. This paper proposes Yale, yet another learning environment, which allows to easily specify and execute such data mining operator chains for pre-processing, especially feature generation and selection, and multistrategy learning. This modular, non-commercial environment supports nested operator chains and the exchange of individual operators and thereby the systematic evaluation and comparison of\u00a0\u2026", "num_citations": "76\n", "authors": ["1072"]}
{"title": "Using labeled and unlabeled data to learn drifting concepts\n", "abstract": " For many learning tasks, where data is collected over an extended period of time, one has to cope two problems. The distribution underlying the data is likely to change and only little labeled training data is available at each point in time. A typical example is information filtering, ie the adaptive classification of documents with respect to a particular user interest. Both the interest of the user and the document content change over time. A filtering system should be able to adapt to such concept changes. Since users often give little feedback, a filtering system should also be able to achieve a good performance, even if only few labeled training examples are provided. This paper proposes a method to recognize and handle concept changes with support vector machines and to use unlabeled data to reduce the need for labeled data. The method maintains windows on the training data, whose size is automatically adjusted so that the estimated generalization error is minimized. The approach is both theoretically well-founded as well as effective and efficient in practice. Since it does not require complicated parameterization, it is simpler to use and more robust than comparable heuristics. Experiments with simulated concept drift scenarios based on real-world text data compare the new method with other window management approaches and show that it can effectively select an appropriate window size in a robust way. In order to achieve an acceptable performance with fewer labeled training examples, the proposed method exploits unlabeled examples in a transductive way.", "num_citations": "76\n", "authors": ["1072"]}
{"title": "Concept drift and the importance of examples\n", "abstract": " For many learning tasks where data is collected over an extended period of time, its underlying distribution is likely to change. A typical example is information ltering, ie the adaptive classi cation of documents with respect to a particular user interest. Both the interest of the user and the document content change over time. A ltering system should be able to adapt to such concept changes.", "num_citations": "63\n", "authors": ["1072"]}
{"title": "Yale: Yet Another Learning Environment\u2013Tutorial\n", "abstract": " In practical data mining applications data often has to be pre-processed to be usable bya chosen machine learning method and to achieve an acceptable level ofperformance in prediction. One central problem in this context is the representation ofthe examples by a good set of features, ie a set of features that allows the learning method to find a candidate hypothesis solving the learning task at hand within its hypothesis search space. Hence, finding a suitable set of features maybefar more importantfor the overall learning success than the choice ofa particular learning method. Therefore it is often necessaryto use complex operator chains, combining different preprocessing and learning steps, rather than using a particular single learning scheme. While such methods can be combined manually and by writing special scripts whenever a new data mining task arises, much less effort is required, ifaflexible machine\u00a0\u2026", "num_citations": "56\n", "authors": ["1072"]}
{"title": "Meta-Learning, Model Selection, and Example Selection in Machine Learning Domains with Concept Drift.\n", "abstract": " For many tasks where data is collected over an extended period of time, its underlying distribution is likely to change. A typical example is information filtering, ie the adaptive classification of documents with respect to a particular user interest. The interest of the user may change over time. Machine learning approaches handling concept drift have been shown to outperform more static approaches ignoring it in experiments with different types of simulated concept drifts on real-word text data and in experiments on real-world data for the task of classifying phases in business cycles exhibiting real concept drift. While previous concept drift handling approaches only use a single base learning algorithm and employ this same base learner at each step in time, this paper proposes a metalearning approach allowing the use of alternative learners and automatically selecting the most promising base learner at each step in time. This work in progress investigates, if such a contextdependent selection of the base learner leads to a better adaptation to the drifting concept, ie to lower classification error rates, than approaches based on single base learner only. Furthermore it investigates, how much the proposed metalearning approach allows to speed up the selection process and how much of the gained reduction in the error rate may be lost by that speed-up. The approaches with and without base learner selection and meta-learning are to be compared in experiments using real-world data from the above mentioned domains with simulated and real-world concept drifts, respectively. 1", "num_citations": "42\n", "authors": ["1072"]}
{"title": "A flexible platform for knowledge discovery experiments: Yale\u2013yet another learning environment\n", "abstract": " Real-world knowledge discovery processes typically consist of complex data pre-processing, machine learning, evaluation, and visualization steps. Hence a data mining platform should allow complex nested operator chains or trees, provide transparent data handling, comfortable parameter handling and optimization, be flexible, extendible and easy-to-use. Depending on the task at hand, a user may want to interactively explore different knowledge discovery chains and continuously inspect intermediate results, or he may want to perform highly automated experiments off-line in batch mode. Therefore an ideal data mining platform should offer both, interactive and batch interfaces. In this paper, we propose YALE, Yet Another Learning Environment, which meets these requirements.", "num_citations": "41\n", "authors": ["1072"]}
{"title": "Data mining-supported generation of assembly process plans\n", "abstract": " The application and functional scope of digital assembly planning tools have been permanently increasing in order to deal with product and process complexity. Consequently a large amount of assembly-related data is stored in different systems alongside the product emergence process. By means of data mining techniques an intelligent utilization of this data can be accomplished for future assembly planning. This paper presents an approach for data mining-supported generation of assembly process plans to enhance planning efficiency. The approach is based on the classification and clustering of both product and process data as well as on the identification of their correlations.", "num_citations": "16\n", "authors": ["1072"]}
{"title": "Defining Software Architectures for Big Data Enabled Operator Support Systems\n", "abstract": " Big Data technologies enable new possibilities to analyze historical data generated by process plants. One possible application is the development of new types of operator support systems (OSS), which could help plant operators during operations in identifying and dealing with critical situations. The project FEE has the objective to develop such support functions based on Big Data analytics of historical plant data. In this contribution we describe our approach to define software architectures for Big Data enabled OSS in industrial plants.", "num_citations": "13\n", "authors": ["1072"]}
{"title": "Learning drifting concepts with partial user feedback\n", "abstract": " The task of information filtering is to classify texts from a stream of documents into relevant and irrelevant, respectively, with respect to a particular category or user interest, which may change over time. A filtering system should be able to adapt to such concept changes and to cope the problem of users giving only partial feedback. This paper explores methods to recognize concept changes and to maintain windows on the training data, whose size is either fixed or automatically adapted to the current extent of concept change. Experiments with two simulated concept drift scenarios based on real-world text data and four learning methods are performed to evaluate three indicators for concept changes and to compare approaches with fixed and adjustable window sizes, respectively, to each other and to learning on all previously seen examples. Additional experiments test the adaptive window size approach with four simulated user behaviours with partial feedback in the two aforementioned scenarios. Even using only a simple window on the data already improves the performance of the classifiers significantly as compared to learning on all examples. For most of the classifiers, the window adjustments lead to a further increase in performance compared to windows of fixed size. The chosen indicators allow to reliably recognize concept changes, even if only partial user feedback is available.", "num_citations": "13\n", "authors": ["1072"]}
{"title": "Yale: Yet another learning environment\n", "abstract": " \u041d \u0421\u0432\u0438\u0436\u0433 \u0439 \u0438 \u0433\u0432 \u041d\u041d \u041d\u041a\u041d \u0425\u0433\u0438 \u043a \u0438 \u0433\u0432 \u041a \u041a \u041a \u041a \u041a \u041a \u041a \u041a \u041a \u041a \u041a \u041a \u041a \u041a \u041a \u041a \u041a \u041a \u041a \u041a \u041a \u041a \u041a \u041a \u041a \u041a \u041a \u041a \u041d\u041d \u041d\u041a\u041e \u043c \u0437\u0438 \u0432 \u0432\u043a \u0436\u0433\u0432\u0431 \u0432\u0438\u0437 \u041a \u041a \u041a \u041a \u041a \u041a \u041a \u041a \u041a \u041a \u041a \u041a \u041a \u041a \u041a \u041a \u041a \u041a \u041a \u041a \u041a \u041a \u041d\u041e \u041d\u041a\u041f \u0427\u0434 \u0436 \u0438\u0433\u0436\u0437 \u0432 \u0433\u0434 \u0436 \u0438\u0433\u0436 \u0432\u0437 \u041a \u041a \u041a \u041a \u041a \u041a \u041a \u041a \u041a \u041a \u041a \u041a \u041a \u041a \u041a \u041a \u041a \u041d\u041f \u041d\u041a \u0438 \u0432 \u0430 \u0432 \u041a \u041a \u041a \u041a \u041a \u041a \u041a \u041a \u041a \u041a \u041a \u041a \u041a \u041a \u041a \u041a \u041a \u041a \u041a \u041a \u041a \u041a \u041a \u041a \u041a \u041a \u041a \u041d \u041d\u041a \u0425 \u0438 \u0432\u0433\u043b\u0430 \u041a \u041a \u041a \u041a \u041a \u041a \u041a \u041a \u041a \u041a \u041a \u041a \u041a \u041a \u041a \u041a \u041a \u041a \u041a \u041a \u041a \u041a \u041a \u041a \u041a \u041a \u041d\u041e \u0421\u0432\u0437\u0438 \u0430\u0430 \u0438 \u0433\u0432 \u0432\u0433\u0438 \u0437 \u041d \u041e\u041a\u041d \u0433\u043b\u0432\u0430\u0433 \u041a \u041a \u041a \u041a \u041a \u041a \u041a \u041a \u041a \u041a \u041a \u041a \u041a \u041a \u041a \u041a \u041a \u041a \u041a \u041a \u041a \u041a \u041a \u041a \u041a \u041a \u041a \u041a \u041a \u041d \u041e\u041a\u041e \u0421\u0432\u0437\u0438 \u0430\u0430 \u0438 \u0433\u0432 \u041a \u041a \u041a \u041a \u041a \u041a \u041a \u041a \u041a \u041a \u041a \u041a \u041a \u041a \u041a \u041a \u041a \u041a \u041a \u041a \u041a \u041a \u041a \u041a \u041a \u041a \u041a \u041a \u041d \u041e\u041a\u041f \u0432 \u0436 \u0430 \u0437 \u0438\u0438 \u0432 \u0437 \u041a \u041a \u041a \u041a \u041a \u041a \u041a \u041a \u041a \u041a \u041a \u041a \u041a \u041a \u041a \u041a \u041a \u041a \u041a \u041a \u041a \u041a \u041a \u041a \u041a \u041a \u041d", "num_citations": "12\n", "authors": ["1072"]}
{"title": "Predicting phases in business cycles under concept drift\n", "abstract": " For many tasks where data is collected over an extended period of time, its underlying distribution is likely to change. A typical example is information filtering, ie the adaptive classification of documents with respect to a particular user interest. Both the interest of the user and the document content change over time. Machine learning approaches handling this type of concept drift have been shown to outperform more static approaches ignoring it in experiments with different types of simulated concept drifts on real-word text data. In this paper, these approaches to learning drifting concepts are applied to the problem of classifying phases in business cycles. Their performance is compared to the more static approaches on real-world data for this classification task, in order to evaluate whether this domain also exhibits concept drifts and whether the concept drift approaches also allow performance gains in this domain. While previous studies were based on simulated concept drift scenarios, the experiments in this domain are not based on any simulated drift, but on the real concept drift inherent to this real-world data. Hence this paper provides significant support for the applicability of the proposed machine learning approaches to handling concept drift in realworld problems.", "num_citations": "11\n", "authors": ["1072"]}
{"title": "Knowledge discovery from data streams\n", "abstract": " Joao Gama a, Jesus Aguilar-Ruiz b and Ralf Klinkenberg c a LIAAD-University of Porto, Porto, Portugal b Polytechnic Pablo de Olavide University, Seville, Spain c University of Dortmund, Dortmund, GermanyTraditional pratice in machine learning algorithms involve fixed data sets and static models. Most of the times, all the data is loaded into memory and the learning task is solved by performing multiple scans over the training data. These assumptions fail with the advent of new application areas, like ubiquitous computing, sensor networks, e-commerce, etc., where data flows continuously, eventually at high speed rate. Other examples include scientific data, customer click streams, telephone records, large sets of web pages, multimedia data, sets of retail chain transactions, etc. These sources of continuous data are called data streams.", "num_citations": "9\n", "authors": ["1072"]}
{"title": "Evolutionary feature space transformation using type-restricted generators\n", "abstract": " Data preprocessing, especially in terms of feature selection and generation, is an important issue in data mining and knowledge discovery tasks. Genetic algorithms proved to work well on feature selection problems where the search space produced by the initial feature set already contains the target hypothesis. In cases where this precondition is not fulfilled, one needs to construct new features to adequately extend the search space. As a solution to this representation problem, we introduce a framework combining feature selection and type-restricted feature generation in a wrapper-based approach using a modified canonical genetic algorithm for the feature space transformation and an inductive learner for the evaluation of the constructed feature set.", "num_citations": "7\n", "authors": ["1072"]}
{"title": "Zukunftsweisende Informations-und Kommunikations-Technologien\n", "abstract": " Wie k\u00f6nnen bekannte Unternehmensprozesse von neuen Technologien profitieren und neue Perspektiven geschaffen werden? Welche Vorteile ergeben sich aus der Digitalisierung von Prozessen? Diesen und anderen Fragen werden wir in diesem Kapitel nachgehen. Zun\u00e4chst einmal soll ein potenzieller Informationsfluss betrachtet werden, um Einblicke in m\u00f6gliche Szenarien zu erhalten, die durch neue Technologien er\u00f6ffnet werden. Ziele k\u00f6nnen beispielsweise eine h\u00f6here Transparenz und Prozesszuverl\u00e4ssigkeit, ein besseres Verst\u00e4ndnis von Problemursachen, Prozess(teil)automatisierungen, Prozessbeschleunigungen, h\u00f6here Agilit\u00e4t und Flexibilit\u00e4t, Kostenreduktionen, h\u00f6here Prozessrobustheit, vorhersagbarere Produktqualit\u00e4t, Prognose und Vermeidung von Maschinen- und Produktionsausf\u00e4llen oder eine Bedarfs-, Bestellmengen und Preisprognose sein.", "num_citations": "6\n", "authors": ["1072"]}
{"title": "Interactive extreme: Scale analytics towards battling cancer\n", "abstract": " A synergetic understanding of cancer evolution and the effect of combination drug therapies on the disease is the cornerstone for developing effective personalized treatments, which can radically improve patients' well-being and their quality of (work and social) life. By extension, improving the treatment of patients indirectly enhances the quality of life for families, friends, and careers. Moreover, personalizing effective therapeutic approaches reduces treatment duration, cutting down healthcare monetary costs, which can be redirected to other health and social services. Given that three out of four U.S. families will at some point experience a family member suffering from cancer (http://natamcancer.org/NAP_Native_American_Priorities.pdf), the potential impact of improved cancer treatment is of considerable socio-economic and organizational significance.", "num_citations": "5\n", "authors": ["1072"]}
{"title": "Novel learning tasks from practical applications\n", "abstract": " Some classes of learning problems have been well-posed and investigated, especially the ones of classi cation and regression. However, in practice we are often confronted with modi ed learning tasks that deviate from these standard scenarios. In other words, given an application problem, the assumptions made when treating it as a standard learning task are often not appropriate.", "num_citations": "5\n", "authors": ["1072"]}
{"title": "INforE: Interactive Cross-platform Analytics for Everyone\n", "abstract": " We present INforE, a prototype supporting non-expert programmers in performing optimized, cross-platform, streaming analytics at scale. INforE offers: a) a new extension to the RapidMiner Studio for graphical design of Big streaming Data workflows,(b) a novel optimizer to instruct the execution of workflows across Big Data platforms and clusters,(c) a synopses data engine for interactivity at scale via the use of data summaries,(d) a distributed, online data mining and machine learning module. To our knowledge INforE is the first holistic approach in streaming settings. We demonstrate INforE in the fields of life science and financial data analysis.", "num_citations": "4\n", "authors": ["1072"]}
{"title": "Novel learning tasks, optimization, and their application\n", "abstract": " This chapter describes methods for learning and optimizing solutions to engineering problems. Where standard learning tasks do not fit the requirements of the applications, they are varied. In particular, the use of prior knowledge and unlabeled examples may ease a learning task. In contrast, learning target concepts that change over time and constructing new features are challenging learning tasks. The changes of the learning tasks that ease as well as those that challenge learning cover a broad range of application problems. Solutions to the new, nonstandard learning tasks are developed, integrating numerical optimization strategies, evolutionary algorithms, support vector machines, neural networks, and fuzzy controllers. A workbench for learning methods allows their systematic evaluation with respect to the engineering problems.               The chapter is structured as follows: First, extensions of\u00a0\u2026", "num_citations": "4\n", "authors": ["1072"]}
{"title": "Conception of a Reference Architecture for Machine Learning in the Process Industry\n", "abstract": " The increasing global competition demands continuous optimization of products and processes from companies in the process industry. Where conventional methods of Lean Management and Six Sigma reach their limits, new opportunities and challenges arise through increasing connectivity in the Industrial Internet of Things and machine learning. The majority of industrial projects do not reach the deployment or are isolated solutions, as the structures for data integration, training, deployment and maintenance of models are not established. This paper presents the conception of a reference architecture for machine learning in the process industry to support companies in implementing their own specific structures. The focus is on the development process and an exemplary implementation in the brewing industry.", "num_citations": "3\n", "authors": ["1072"]}
{"title": "Density-and Correlation-based Table Extension.\n", "abstract": " With thousands of data sources available on the Web as well as within organizations, data scientists increasingly spend more time searching for data than analyzing it. In order to ease the task of finding relevant data for data mining projects, this paper presents two data discovery and data integration methods that have been developed in a joint research project by RapidMiner Research and the University of Mannheim. Given a corpus of relational tables, the methods extend a query table with additional attributes and automatically fill these new attributes with data values from the corpus. The first method, densitybased table extension, extends the query table with all attributes that can be filled with data values so that a user-specified density threshold is reached. The second method, correlation-based table extension, extends the query table with all attributes that correlate with a specific attribute of the query table. Both methods are integrated as operators into RapidMiner Studio, a popular data mining environment. This enables data scientists to search for data and apply a wide range of different mining methods to the discovered data within the same environment.", "num_citations": "2\n", "authors": ["1072"]}
{"title": "Bestimmung von isothermenparametern mit hilfe des maschinellen lernens\n", "abstract": " Zusammenfassung Die Modellierung eines chromatographischen Prozesses erm\u00f6glicht die Bestimmung der optimalen Betriebsparameter f\u00fcr die Trennung der Komponenten eines Stoffgemisches mittels modellbasierter Optimierung. Voraussetzung f\u00fcr eine genaue Modellierung ist dabei die Kenntnis der stoffabh\u00e4ngigen Parameter des zugrunde liegenden physikalischen Modells, insbesondere der Adsorptionsisotherme. Die messtechnische Bestimmung der Isotherme ist zeit-und materialaufw\u00e4ndig und deshalb nicht generell durchf\u00fchrbar. Eine Bestimmung der Isothermenparameter aus Chromatogrammen mittels mathematischer Parametersch\u00e4tzung hingegen senkt diesen Aufwand, hat jedoch den Nachteil der Abh\u00e4ngigkeit von guten Startwerten. Die hier vorgestellte Methode nutzt die Approximationsf\u00e4higkeiten von Support Vector Machines zur Bestimmung von Isothermenparametern aus wenigen Merkmalen von Chromatogrammen und erfordert derartige Startwerte nicht.", "num_citations": "2\n", "authors": ["1072"]}
{"title": "Wissensmanagement in der Computational Intelligence: Systematisierung der Beschreibung von Problemen, Methoden und Methodeneins\u00e4tzen\n", "abstract": " In der Computational Intelligence (CI) wurden und werden zahlreiche Methoden aus den Bereichen der evolution\u00e4ren Algorithmen, der neuronalen Netze und der Fuzzy Logik entwickelt. Eine wesentliche Schwierigkeit aus Anwendersicht besteht in der Auswahl von Methoden und deren Anpassung an die konkrete Problemstellung. W\u00fcnschenswert w\u00e4re also eine Taxonomie, wann und warum welche CI-Methode einzusetzen ist. Hierbei ist auch eine Abgrenzung zu anderen, insbesondere klassischen Verfahren vorzunehmen. Wichtige Voraussetzung daf\u00fcr sind klare begriffliche Definitionen und ein systematischer Methodenvergleich auf breiter Basis. Mit dem langfristigen Ziel ein Wissensmanagement\u2013System aufzubauen ist im Sonderforschungsbereich 531 (CI) ein Ansatz f\u00fcr die formalisierte Beschreibung von Problemen, Methoden, Analysemethoden, Methodeneins\u00e4tzen und Prozessketten entwickelt und umgesetzt worden. In diesem Beitrag wird zun\u00e4chst das diesem Ansatz zugrunde liegende Konzept vorgestellt. Zur Demonstration der Tragf\u00e4higkeit des Konzepts wird dann exemplarisch f\u00fcr zwei CI\u2013Methoden beschrieben, wie bei ihrer Parametrierung systematisch vorgegangen werden kann. Anhand von sechs Benchmarkproblemen wird f\u00fcr eine der beiden CI-Methoden das Ergebnis dieses systematischen Vorgehens mit dem bisher besten Ergebnis mit dieser Methode verglichen, um die Qualit\u00e4t der Resultate abzusch\u00e4tzen, die ein nicht so versierter Benutzer mit der systematischen Vorgehensweise erzielen k\u00f6nnte.", "num_citations": "2\n", "authors": ["1072"]}
{"title": "Systematisierung der Beschreibung von Problemen, Methoden und Methodeneins atzen\n", "abstract": " In der Computational Intelligence (CI) wurden und werden zahlreiche Methoden aus den Bereichen der evolution aren Algorithmen, der neuronalen Netze und der Fuzzy Logik entwickelt. Eine wesentliche Schwierigkeit aus Anwendersicht besteht in der Auswahl von Methoden und deren Anpassung an die konkrete Problemstellung. W unschenswert w are also eine Taxonomie, wann und warum welche CI-Methode einzusetzen ist. Hierbei ist auch eine Abgrenzung zu anderen, insbesondere klassischen Verfahren vorzunehmen. Wichtige Voraussetzung daf ur sind klare begri iche De nitionen und ein systematischer Methodenvergleich auf breiter Basis. Mit dem langfristigen Ziel ein Wissensmanagement {System aufzubauen ist im Sonderforschungsbereich 531 (CI) ein Ansatz f ur die formalisierte Beschreibung von Problemen, Methoden, Analysemethoden, Methodeneins atzen und Prozessketten entwickelt und umgesetzt worden. In diesem Beitrag wird zun achst das diesem Ansatz zugrunde liegende Konzept vorgestellt. Zur Demonstration der Tragf ahigkeit des Konzepts wird dann exemplarisch f ur zwei CI {Methoden beschrieben, wie bei ihrer Parametrierung systematisch vorgegangen werden kann. Anhand von sechs Benchmarkproblemen wird f ur eine der beiden CI-Methoden das Ergebnis dieses systematischen Vorgehens mit dem bisher besten Ergebnis mit dieser Methode verglichen, um die Qualit at der Resultate abzusch atzen, die ein nicht so versierter Benutzer mit der systematischen Vorgehensweise erzielen k onnte.", "num_citations": "2\n", "authors": ["1072"]}
{"title": "Big Data in der Prozessindustrie: Fr\u00fchzeitige Erkennung und Entscheidungsunterst\u00fctzung\n", "abstract": " Big Data in Process Industries: Early Detection and Decision Support \u2014 Tilburg University Research Portal Skip to main navigation Skip to search Skip to main content Tilburg University Research Portal Logo Contact, Help & FAQ Home Profiles Research output Research Units Activities Projects Press / Media Prizes / Recognition Search by expertise, name or affiliation Big Data in der Prozessindustrie: Fr\u00fchzeitige Erkennung und Entscheidungsunterst\u00fctzung Translated title of the contribution : Big Data in Process Industries: Early Detection and Decision Support Sebastian Heinze, Markus Graube, Luise Schegner, David Arnu, Ralf Klinkenberg, Andreas Schmidt, Martin Atzmueller, Benjamin Kloepper, Marcel Dix, Martin Hollender, M. Chioua, Hassan Al Mawla, Alexander Rehmer, Andreas Kroll, G. Stumme, Leon Urbas Research output: Chapter in Book/Report/Conference proceeding \u203a Conference contribution \u203a \u2026", "num_citations": "1\n", "authors": ["1072"]}