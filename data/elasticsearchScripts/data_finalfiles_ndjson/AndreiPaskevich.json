{"title": "Why3\u2014where programs meet provers\n", "abstract": " We present Why3, a tool for deductive program verification, and WhyML, its programming and specification language. WhyML is a first-order language with polymorphic types, pattern matching, and inductive predicates. Programs can make use of record types with mutable fields, type invariants, and ghost code. Verification conditions are discharged by Why3 with the help of various existing automated and interactive theorem provers. To keep verification conditions tractable and comprehensible, WhyML imposes a static control of aliases that obviates the use of a memory model. A user can write WhyML programs directly and get correct-by-construction OCaml programs via an automated extraction mechanism. WhyML is also used as an intermediate language for the verification of C, Java, or Ada programs. We demonstrate the benefits of Why3 and WhyML on non-trivial examples of program verification.", "num_citations": "537\n", "authors": ["695"]}
{"title": "Why3: Shepherd your herd of provers\n", "abstract": " Why3 is the next generation of the Why software verification platform. Why3 clearly separates the purely logical specification part from generation of verification conditions for programs. This article focuses on the former part. Why3 comes with a new enhanced language of logical specification. It features a rich library of proof task transformations that can be chained to produce a suitable input for a large set of theorem provers, including SMT solvers, TPTP provers, as well as interactive proof assistants.", "num_citations": "333\n", "authors": ["695"]}
{"title": "The spirit of ghost code\n", "abstract": " In the context of deductive program verification, ghost code is a part of the program that is added for the purpose of specification. Ghost code must not interfere with regular code, in the sense that it can be erased without observable difference in the program outcome. In particular, ghost data cannot participate in regular computations and ghost code cannot mutate regular data or diverge. The idea exists in the folklore since the early notion of auxiliary variables and is implemented in many state-of-the-art program verification tools. However, ghost code deserves rigorous definition and treatment, and few formalizations exist. In this article, we describe a simple ML-style programming language with mutable state and ghost code. Non-interference is ensured by a type system with effects, which allows, notably, the same data types and functions to be used in both regular and ghost code. We define the procedure\u00a0\u2026", "num_citations": "70\n", "authors": ["695"]}
{"title": "TFF1: The TPTP typed first-order form with rank-1 polymorphism\n", "abstract": " The TPTP World is a well-established infrastructure for automatic theorem provers. It defines several concrete syntaxes, notably an untyped first-order form (FOF) and a typed first-order form (TFF0), that have become de facto standards. This paper introduces the TFF1 format, an extension of TFF0 with rank-1 polymorphism. The format is designed to be easy to process by existing reasoning tools that support ML-style polymorphism. It opens the door to useful middleware, such as monomorphizers and other translation tools that encode polymorphism in FOF or TFF0. Ultimately, the hope is that TFF1 will be implemented in popular automatic theorem provers.", "num_citations": "69\n", "authors": ["695"]}
{"title": "Let\u2019s verify this with Why3\n", "abstract": " We present solutions to the three challenges of the VerifyThis competition held at the 18th FM symposium in August 2012. These solutions use the Why3 environment for deductive program verification.", "num_citations": "57\n", "authors": ["695"]}
{"title": "Expressing polymorphic types in a many-sorted language\n", "abstract": " In this paper, we study translation from a first-order logic with polymorphic types la ML (of which we give a formal description) to a many-sorted or one-sorted logic as accepted by mainstream automated theorem provers. We consider a three-stage scheme where the last stage eliminates polymorphic types while adding the necessary \u201cannotations\u201d to preserve soundness, and the first two stages serve to protect certain terms so that they can keep their original unannotated form. This protection allows us to make use of provers\u2019 built-in theories and operations. We present two existing translation procedures as sound and complete instances of this generic scheme. Our formulation generalizes over the previous ones by allowing us to protect terms of arbitrary monomorphic types. In particular, we can benefit from the built-in theory of arrays in SMT solvers such as Z3, CVC3, and Yices. The proposed methods are\u00a0\u2026", "num_citations": "56\n", "authors": ["695"]}
{"title": "ForTheL \u2014 the language of formal theories\n", "abstract": " The paper describes the language ForTheL (FORmal THEory Language) aimed at representation of formal theories\u2014in strict mathematical sense of the term. Its syntax is strictly formalised in the terms of BNF and its semantics can be precisely defined with the help of syntactical transformation that maps ForTheL-phrases to the formulae of first-order logic with equality. At the same time ForTheL is intended to be close to the natural language of mathematical texts, it formalises and uses expressive means of the human language. The short history of the language is as follows. In 1960s academician V. Glushkov initiated a project\u2014called \u201cAlgoritm Ochevidnosti\u201d\u2014that was aimed at mathematical text processing \u201cin large\u201d on the base of evolving an automated theorem proving system [1]. One of the goals was to help to working mathematicians in constructing and verifying automatically long but in some sense \u201cevident\u201d proofs. The \u201cAlgoritm Ochevidnosti\u201d project included three main components: the deductive part, mathematical knowledge base and finally the language for knowledge representation\u2014the component uniting other two. The core of the deductive part was so-called \u201cevidence routine\u201d that established the evidence in the terms of some deduction technique (cf. Lyaletski-Degtyarev calculus [2]). Besides, there were presupposed various means enforcing the evidence routine\u2014the search for the auxiliary lemmata or for some other relevant information, involving the user in the proof search and so on. The first sketch of the language in question was given in [3]. Then the work was continued by V. Bodnarchuk and finally it was resulted in TL\u00a0\u2026", "num_citations": "53\n", "authors": ["695"]}
{"title": "A3PAT, an approach for certified automated termination proofs\n", "abstract": " Software engineering, automated reasoning, rule-based programming or specifications often use rewriting systems for which termination, among other properties, may have to be ensured. This paper presents the approach developed in Project A3PAT to discover and moreover certify, with full automation, termination proofs for term rewriting systems.", "num_citations": "44\n", "authors": ["695"]}
{"title": "System for Automated Deduction (SAD): a tool for proof verification\n", "abstract": " In this paper a proof assistant called SAD is presented. SAD deals with mathematical texts that are formalized in the ForTheL language (a brief description of which is also given) and checks their correctness. We give a short description of SAD and a series of examples that show what can be done with it. Note that abstract notion of correctness on which the implementation is based, can be formalized with the help of a calculus (not presented here).", "num_citations": "39\n", "authors": ["695"]}
{"title": "System for automated deduction (SAD): Linguistic and deductive peculiarities\n", "abstract": " In this paper a state-of-the-art of a system for automated deduction called SAD is described *. An architecture of SAD corresponds well to a modern vision of the Evidence Algorithm programme advanced by Academician V.Glushkov. The system is intended for accumulating mathematical knowledge and using it in a regular and efficient manner for processing a self-contained mathematical text in order to prove a given statement that always is considered as a part of the text. Two peculiarities are inherent in SAD: (a) mathematical texts under consideration are formalized using a specific formal language, which is close to natural languages from usual mathematical publications; (b) proof search is based on a specific sequenttype calculus, which gives a possibility to formalize \u201cnatural reasoning style\u201d. The language may be used as a tool to write and to verify mathematical papers, theorems, and formal\u00a0\u2026", "num_citations": "31\n", "authors": ["695"]}
{"title": "The 2nd verified software competition: Experience report\n", "abstract": " We report on the second verified software competition. It was organized by the three authors on a 48 hours period on November 8-10, 2011. This paper describes the competition, presents the five problems that were proposed to the participants, and gives an overview of the solutions sent by the 29 teams that entered the competition.", "num_citations": "29\n", "authors": ["695"]}
{"title": "On correctness of mathematical texts from a logical and practical point of view\n", "abstract": " Formalizing mathematical argument is a fascinating activity in itself and (we hope!) also bears important practical applications. While traditional proof theory investigates deducibility of an individual statement from a collection of premises, a mathematical proof, with its structure and continuity, can hardly be presented as a single sequent or a set of logical formulas. What is called \u201cmathematical text\u201d, as used in mathematical practice through the ages, seems to be more appropriate. However, no commonly adopted formal notion of mathematical text has emerged so far.                 In this paper, we propose a formalism which aims to reflect natural (human) style and structure of mathematical argument, yet to be appropriate for automated processing: principally, verification of its correctness (we consciously use the word rather than \u201csoundness\u201d or \u201cvalidity\u201d).                 We consider mathematical texts that are\u00a0\u2026", "num_citations": "28\n", "authors": ["695"]}
{"title": "Reasoning with triggers\n", "abstract": " SMT solvers can decide the satisfiability of ground formulas modulo a combination of built-in theories. Adding a built-in theory to a given SMT solver is a complex and time consuming task that requires internal knowledge of the solver. However, many theories can be easily expressed using first-order formulas. Unfortunately, since universal quantifiers are not handled in a complete way by SMT solvers, these axiomatics cannot be used as decision procedures. In this paper, we show how to extend a generic SMT solver to accept a custom theory description and behave as a decision procedure for that theory, provided that the described theory is complete and terminating in a precise sense. The description language consists of first-order axioms with triggers, an instantiation mechanism that is found in many SMT solvers. This mechanism, which usually lacks a clear semantics in existing languages and tools, is rigorously defined here; this definition can be used to prove completeness and termination of the theory. We demonstrate on two examples, how such proofs can be achieved in our formalism.", "num_citations": "26\n", "authors": ["695"]}
{"title": "Theorem proving and proof verification in the system SAD\n", "abstract": " In this paper, the current state of the System for Automated Deduction, SAD, is described briefly. The system may be considered as the modern vision of the Evidence Algorithm programme advanced by Academician V.\u00a0Glushkov in early 1970s. V.\u00a0Glushkov proposed to make investigation simultaneously into formalized languages for presenting mathematical texts in the form most appropriate for a user, formalization and evolutionary development of computer-made proof step, information environment having an influence on the evidence of a proof step, and man-assisted search for a proof. In this connection, SAD supports a number of formal languages for representing and processing mathematical knowledge along with the formal language ForTheL as their top representative, uses a sequent formalism developed for constructing an efficient technique of proof search within the signature of an initial theory\u00a0\u2026", "num_citations": "25\n", "authors": ["695"]}
{"title": "Adding Decision Procedures to SMT Solvers using Axioms with Triggers\n", "abstract": " Satisfiability modulo theories (SMT) solvers are efficient tools to decide the satisfiability of ground formulas, including a number of built-in theories such as congruence, linear arithmetic, arrays, and bit-vectors. Adding a theory to that list requires delving into the implementation details of a given SMT solver, and is done mainly by the developers of the solver itself. For many useful theories, one can alternatively provide a first-order axiomatization. However, in the presence of quantifiers, SMT solvers are incomplete and exhibit unpredictable behavior. Consequently, this approach can not provide us with a complete and terminating treatment of the theory of interest. In this paper, we propose a framework to solve this problem, based on the notion of instantiation patterns, also known as triggers. Triggers are annotations that suggest instances which are more likely to be useful in proof search. They are\u00a0\u2026", "num_citations": "21\n", "authors": ["695"]}
{"title": "A Pragmatic Type System for Deductive Verification\n", "abstract": " In the context of deductive verication, it is customary today to handle programs with pointers using either separation logic, dynamic frames, or explicit memory models. Yet we can observe that in numerous programs, a large amount of code ts within the scope of Hoare logic, provided we can statically control aliasing. When this is the case, the code correctness can be reduced to simpler verication conditions which do not require any explicit memory model. This makes verication conditions more amenable both to automated theorem proving and to manual inspection and debugging. In this paper, we devise a method of such static aliasing control for a programming language featuring nested data structures with mutable components. Our solution is based on a type system with singleton regions and eects, which we prove to be sound.", "num_citations": "20\n", "authors": ["695"]}
{"title": "Formalizing semantics with an automatic program verifier\n", "abstract": " A common belief is that formalizing semantics of programming languages requires the use of a proof assistant providing (1) a specification language with advanced features such as higher-order logic, inductive definitions, type polymorphism, and (2) a corresponding proof environment where higher-order and inductive reasoning can be performed, typically with user interaction.                 In this paper we show that such a formalization is nowadays possible inside a mostly-automatic program verification environment. We substantiate this claim by formalizing several semantics for a simple language, and proving their equivalence, inside the Why3 environment.", "num_citations": "20\n", "authors": ["695"]}
{"title": "VerifyThis 2018: A Program Verification Competition\n", "abstract": " VerifyThis 2018 was a two-day program verification competition which took place on April 14 and 15, 2018 in Thessaloniki, Greece as part of the European Joint Conferences on Theory and Practice of Software (ETAPS 2018). It was the sixth instalment in the VerifyThis competition series. This article provides an overview of the VerifyThis 2018 event, the challenges that were posed during the competition, and a high-level overview of the solutions to these challenges. It concludes with the results of the competition.", "num_citations": "19\n", "authors": ["695"]}
{"title": "M\u00e9thodes de formalisation des connaissances et des raisonnements math\u00e9matiques: aspects appliqu\u00e9s et th\u00e9oriques\n", "abstract": " Introduction h ns l th\u00e8seD nous \u00e9tudions les moyens de pr\u00e9sent tion des onn iss n es m th\u00e9m tiques insi que les s h\u00e9m s du r isonnement m th\u00e9m tiqueF xotre re her he est destin\u00e9e \u00e0 l onstru E tion d9un syst\u00e8me de v\u00e9rifi tion utom tique de textes m th\u00e9m tiques form lis\u00e9sF xotre ppro he est s\u00e9e sur les prin ipes suiv nts X! ve texte \u00e0 v\u00e9rifier est \u00e9 rit d ns un l ng ge formel qui imite ll ngue et le style n tuE rels des pu li tions m th\u00e9m tiquesF v v\u00e9rifi tion onsiste en l d\u00e9monstr tion que le texte estD premi\u00e8rementD sens\u00e9 D 9estE\u00e0Edire que toutes les fon tions et rel tions sont employ\u00e9es d ns leurs dom inesD onform\u00e9ment ux d\u00e9finitions@ on dit d9un tel texte qu9il est ontologiquement orre t AY etD deuxi\u00e8mementD fond\u00e9 D 9estE\u00e0Edire que toutes les ffirm tions sont d\u00e9du ti les de leurs pr\u00e9misses d ns le texte@ on dit d9un tel texte qu9il est logiquement orre t AF! v re her he de preuveD n\u00e9 ess ire pour l v\u00e9rifi tionD est effe tu\u00e9e \u00e0 deux nive uxF ve nive us est un d\u00e9monstr teur utom tique puiss ntD s\u00e9 sur une pro \u00e9dure omE in toire oh\u00e9rente et ompl\u00e8te en logique l ssique du premier ordreF@ v9existen e de d\u00e9monstr teurs puiss nts pour ette logique est une r ison pour l quelle elle est hoisie omme notre logique de seAF ve nive uh ut est un r isonneur D le dirige nt d9un sE sortiment des m\u00e9thodes heuristiquesD dont le devoir est de tr nsformer X filtrerD simplifierD d\u00e9 omposer une t\u00e2 he de preuve v nt de lp sser u d\u00e9monstr teurF ge r isonneur est le\u00f7 ur du syst\u00e8meF v9id\u00e9e est d9exploiter les indi es qui nous sont donn\u00e9s prl forme hum ine du pro l\u00e8me \u00e0 tr v iller@ e qu9une pro \u00e9dure om in toire ne f it jm isA X tr iter les d\u00e9finitions utrement que les xiomesD les\u00a0\u2026", "num_citations": "17\n", "authors": ["695"]}
{"title": "Connection tableaux with lazy paramodulation\n", "abstract": " It is well known that the connection refinement of clause tableaux with paramodulation is incomplete (even with weak connections). In this paper, we present a new connection tableau calculus for logic with equality. This calculus is based on a lazy form of paramodulation where parts of the unification step become auxiliary subgoals in a tableau and may be subjected to subsequent paramodulations. Our calculus uses ordering constraints and a certain form of the basicness restriction.", "num_citations": "16\n", "authors": ["695"]}
{"title": "SAD as a mathematical assistant\u2014how should we go from here to there?\n", "abstract": " Abstract The System for Automated Deduction (SAD) is developed in the framework of the Evidence Algorithm research project and is intended for automated processing of mathematical texts. The SAD system works on three levels of reasoning:(a) the level of text presentation where proofs are written in a formal natural-like language for subsequent verification;(b) the level of foreground reasoning where a particular theorem proving problem is simplified and decomposed;(c) the level of background deduction where exhaustive combinatorial inference search in classical first-order logic is applied to prove end subgoals. We present an overview of SAD describing the ideas behind the project, the system's design, and the process of problem formalization in the fashion of SAD. We show that the choice of classical first-order logic as the background logic of SAD is not too restrictive. For example, we can handle binders\u00a0\u2026", "num_citations": "16\n", "authors": ["695"]}
{"title": "How to avoid proving the absence of integer overflows\n", "abstract": " When proving safety of programs, we must show, in particular, the absence of integer overflows. Unfortunately, there are lots of situations where performing such a proof is extremely difficult, because the appropriate restrictions on function arguments are invasive and may be hard to infer. Yet, in certain cases, we can relax the desired property and only require the absence of overflow during the first n steps of execution, n being large enough for all practical purposes. It turns out that this relaxed property can be easily ensured for large classes of algorithms, so that only a minimal amount of proof is needed, if at all. The idea is to restrict the set of allowed arithmetic operations on the integer values in question, imposing a \u201cspeed limit\u201d on their growth. For example, if we repeatedly increment a 64-bit integer, starting from zero, then we will need at least  steps to reach an overflow; on current hardware, this takes\u00a0\u2026", "num_citations": "15\n", "authors": ["695"]}
{"title": "Linguistic tools and deductive technique of the System for Automated Deduction\n", "abstract": " This paper is devoted to a brief description of some peculiarities and of the rst software implementation of the System for Automated Deduction, SAD. Architecture of SAD corresponds well to a modern vision of the Evidence Algorithm that was conceived by V. Glushkov as a programme for constructing open systems for automated theorem-proving that are intended for computer-aided\\doing\" mathematics: ie for extracting and accumulating mathematical computer knowledge and for using it in a regular and e cient manner to prove a given statement that is always considered as a part of a self-contained mathematical text. In addition, the main principles of SAD re ect the current understanding of the problem of man-assisted processing of mathematical computer knowledge.", "num_citations": "13\n", "authors": ["695"]}
{"title": "Goal-driven inference search in classical propositional logic\n", "abstract": " Two goal-driven strategies for inference search in propositional logic are presented in the form of special sequent calculi. Some results on their soundness and completeness are given, and comparison of these calculi is made. It is shown that no one of them is preferable to another in the sense of constructing minimal inferences.", "num_citations": "13\n", "authors": ["695"]}
{"title": "On verification tools implemented in the System for Automated Deduction\n", "abstract": " Among the tasks of the Evidence Algorithm programme, the verification of formalized mathematical texts is of great significance. Our investigations in this domain were brought to practice in the last version of the System for Automated Deduction (SAD). The system exploits a formal language to represent mathematical knowledge in a \u201cnatural\u201d form and a sequential first-order formalism to prove statements in the frame of a self-contained mathematical text. In the paper, we give an overview of the architecture of SAD and its verification tools. In order to demonstrate the work of SAD, a sample verification session is examined3.", "num_citations": "11\n", "authors": ["695"]}
{"title": "Connection tableaux with lazy paramodulation\n", "abstract": " It is well-known that the connection refinement of clause tableaux with paramodulation is incomplete (even with weak connections). In this paper, we present a new connection tableau calculus for logic with equality. This calculus is based on a lazy form of paramodulation where parts of the unification step become auxiliary subgoals in a tableau and may be subjected to subsequent paramodulations. Our calculus uses ordering constraints and a certain form of the basicness restriction.", "num_citations": "9\n", "authors": ["695"]}
{"title": "Reasoning inside a formula and ontological correctness of a formal mathematical text\n", "abstract": " Dealing with a formal mathematical text (which we regard as a structured collection of hypotheses and conclusions), we often want to perform various analysis and transformation tasks on the initial formulas, without preliminary normalization. One particular example is checking for \u201contological correctness\u201d, namely, that every occurrence of a nonlogical symbol stems from some definition of that symbol in the foregoing text. Generally, we wish to test whether some known fact (axiom, definition, lemma) is \u201capplicable\u201d at a given position inside a statement, and to actually apply it (when needed) in a logically sound way. In this paper, we introduce the notion of a locally valid statement, a statement that can be considered true at a given position inside a firstorder formula. We justify the reasoning about \u201cinnards\u201d of a formula; in particular, we show that a locally valid equivalence is a sufficient condition for an equivalent transformation of a subformula. Using the notion of local validity, we give a formal definition of ontological correctness for a text written in a special formal language called ForTheL.", "num_citations": "8\n", "authors": ["695"]}
{"title": "Abstraction and genericity in Why3\n", "abstract": " The benefits of modularity in programming\u2014abstraction barriers, which allow hiding implementation details behind an opaque interface, and genericity, which allows specializing a single implementation to a variety of underlying data types\u2014apply just as well to deductive program verification, with the additional advantage of helping the automated proof search procedures by reducing the size and complexity of the premises and by instantiating and reusing once-proved properties in a variety of contexts  In this paper, we demonstrate the modularity features of WhyML, the language of the program verification tool Why3. Instead of separating abstract interfaces and fully elaborated implementations, WhyML uses a single concept of module, a collection of abstract and concrete declarations, and a basic operation of cloning which instantiates a module with respect to a given partial substitution, while verifying its\u00a0\u2026", "num_citations": "7\n", "authors": ["695"]}
{"title": "Deductive verification with ghost monitors\n", "abstract": " We present a new approach to deductive program verification based on auxiliary programs called ghost monitors. This technique is useful when the syntactic structure of the target program is not well suited for verification, for example, when an essentially recursive algorithm is implemented in an iterative fashion. Our approach consists in implementing, specifying, and verifying an auxiliary program that monitors the execution of the target program, in such a way that the correctness of the monitor entails the correctness of the target. The ghost monitor maintains the necessary data and invariants to facilitate the proof. It can be implemented and verified in any suitable framework, which does not have to be related to the language of the target programs. This technique is also applicable when we want to establish relational properties between two target programs written in different languages and having different\u00a0\u2026", "num_citations": "7\n", "authors": ["695"]}
{"title": "Verified programs with binders\n", "abstract": " Programs that treat datatypes with binders, such as theorem provers or higher-order compilers, are regularly used for mission-critical purposes, and must be both reliable and performant. Formally proving such programs using as much automation as possible is highly desirable. In this paper, we propose a generic approach to handle datatypes with binders both in the program and its specification in a way that facilitates automated reasoning about such datatypes and also leads to a reasonably efficient code. Our method is implemented in the Why3 environment for program verification. We validate it on the examples of a lambda-interpreter with several reduction strategies and a simple tableaux-based theorem prover.", "num_citations": "7\n", "authors": ["695"]}
{"title": "The syntax and semantics of the ForTheL language\n", "abstract": " ForTheL, an acronym for \u201cFormal Theory Language\u201d, is a formal language of mathematical texts, which imitates the natural (English) language of mathematical publications issued by human beings. There are two reasons to pursue a verbose \u201cnatural\u201d style instead of basing on a terse unifying notation of some traditional language of logic. First, a text composed with correct English sentences will hopefully be more readable than a collection of formulas built with quantifiers, parentheses, lambdas, junctors and so on. As for our own experience, it is also more pleasant to write. So, the first reason is to provide our framework with a user-friendly interface.Second, we observe in a natural human text a lot of information that lies beyond logic as such and that usually vanishes in translation. In a natural speech, we meet nouns, which denote classes of entities; adjectives and verbs, which act as attributes and restrict classes; adjectives and verbs, which act as predicates and may relate different entities. In a traditional mathematical text, we meet definitions and axioms, important theorems and auxiliary lemmas, we meet various reasoning schemes. Where human language makes distinctions, the language of mathematical logic unifies: subjects, objects, attributes, predicates all become predicate symbols; axioms, definitions, theorems all become formulas-premises; case analysis, reductio ad absurdum, definition expansion all become applications of modus ponens, or resolution, or tableau rules.", "num_citations": "7\n", "authors": ["695"]}
{"title": "Des transformations logiques passent leur certicat\n", "abstract": " Dans un contexte de v\u00e9rification formelle de programmes, utilisant des d\u00e9monstrateurs automatiques, la base de confiance des environnements de v\u00e9rification est typiquement tr\u00e8s large. Ainsi, un outil de v\u00e9rification de programmes tel que Why3 comporte de nombreuses proc\u00e9dures complexes : g\u00e9n\u00e9ration de conditions de v\u00e9rification, transformations logiques de t\u00e2ches de preuve et interactions avec des d\u00e9monstrateurs externes. En ne consid\u00e9rant que les transformations logiques dans Why3, leur implantation comporte d\u00e9j\u00e0 plus de 17000 lignes de code OCaml. Afin d'augmenter notre confiance dans la correction d'un tel outil de v\u00e9rification, nous proposons un m\u00e9canisme de transformations certifiantes, produisant des certificats pouvant \u00eatre valid\u00e9s par un outil externe, selon l'approche sceptique. Nous pr\u00e9sentons ce m\u00e9canisme de g\u00e9n\u00e9ration de certificats et explorons deux m\u00e9thodes pour les valider : une fond\u00e9e sur un v\u00e9rificateur d\u00e9di\u00e9 d\u00e9velopp\u00e9 en OCaml, l'autre reposant sur le v\u00e9rificateur de preuves universel Dedukti. Une sp\u00e9cificit\u00e9 de nos certificats est d'\u00eatre \u00ab \u00e0 petits grains \u00bb et composables, ce qui rend notre approche incr\u00e9mentale, permettant d'ajouter graduellement de nouvelles transformations certifiantes.", "num_citations": "5\n", "authors": ["695"]}
{"title": "Verified Software\n", "abstract": " This volume contains the proceedings of the 9th International Working Conference on Verified Software: Theories, Tools, and Experiments (VSTTE 2017), held during July 22\u201323, 2017 in Heidelberg, Germany, and co-located with the 29th International Conference on Computer-Aided Verification. The goal of the VSTTE conference series is to advance the state of the art in the science and technology of software verification, through the interaction of theory development, tool evolution, and experimental validation. We solicited contributions describing significant advances in the production of verified software, ie, software that has been proven to meet its functional specifications. Submissions of theoretical, practical, and experimental contributions were equally encouraged, including those that focus on specific problems or problem domains. We were especially interested in submissions describing large-scale\u00a0\u2026", "num_citations": "5\n", "authors": ["695"]}
{"title": "The Why3 platform 0.81\n", "abstract": " Why3 is a platform for deductive program verification. It provides a rich language for specification and programming, called WhyML, and relies on external theorem provers, both automated and interactive, to discharge verification conditions. Why3 comes with a standard library of logical theories (integer and real arithmetic, Boolean operations, sets and maps, etc.) and basic programming data structures (arrays, queues, hash tables, etc.). A user can write WhyML programs directly and get correct-by-construction OCaml programs through an automated extraction mechanism. WhyML is also used as an intermediate language for the verification of C, Java, or Ada programs.", "num_citations": "4\n", "authors": ["695"]}
{"title": "Verification of Programs with Pointers in SPARK\n", "abstract": " In the field of deductive software verification, programs with pointers present a major challenge due to pointer aliasing. In this paper, we introduce pointers to SPARK, a well-defined subset of the Ada language, intended for formal verification of mission-critical software. Our solution uses a permission-based static alias analysis method inspired by Rust\u2019s borrow-checker and affine types. To validate our approach, we have implemented it in the SPARK GNATprove formal verification toolset for Ada. In the paper, we give a formal presentation of the analysis rules for a core version of SPARK and discuss their implementation and scope.", "num_citations": "3\n", "authors": ["695"]}
{"title": "Algebraic types and pattern matching in the logical language of the Why verification platform\n", "abstract": " We introduce an extension of the logical language of a software verification tool Why with algebraic types and pattern matching expressions. We describe the corresponding additions to the syntax of Why and give the semantics of the new constructions in terms of first-order logic with polymorphic types as it is adopted in Why and the Alt-Ergo prover.", "num_citations": "3\n", "authors": ["695"]}
{"title": "Evidential Paradigm and SAD Systems: Features and Peculiarities\n", "abstract": " Research on automated reasoning systems based on a number of paradigms that support human activity in formalized text processing began in the late 1950s\u2013early 1960s, when computer performance and memory space became sufficient for programming of complex intelligent processes. The so-called evidential paradigm was among them and it can be viewed as a way for integrating all reasonable paradigms oriented to the development of computer languages for representing formalized texts in the form most suitable for a user, formalization and development of the evidence of a computer-made proof step, creation of the information environment having influence on a current evidence of a machine proof step, and an active human-machine interaction. This work contains a brief description of the evidential paradigm and its implementation in the form of intelligent systems intended for the symbolic and deductive processing of mathematical texts focusing main attention on their features and peculiarities.", "num_citations": "2\n", "authors": ["695"]}
{"title": "The SAD system: Deductive assistance in an intelligent linguistic environment\n", "abstract": " Formal methods are widely used in the computer science community. Formal verification and certification is an important component of any formal approach. Such a work can not be done by hand, hence the software that can do a part of it is rather required. The verification methods are often based on a deductive system and \"verify\" means \"prove\". Corresponding software is called proof assistant. We describe in this paper the System for Automated Deduction (SAD): its architecture, input language, and reasoning facilities. We show how to use SAD as a proof assistant. We outline specific features of SAD - a handy input language, powerful reasoning strategy, opportunity to use various low level inference engines. Examples and results of some experiments are also given", "num_citations": "2\n", "authors": ["695"]}
{"title": "A Toolchain to Produce Verified OCaml Libraries\n", "abstract": " This paper presents a methodology to get correct-by-construction OCaml programs using the Why3 tool. First, a formal behavioral specification is given in the form of an OCaml module signature extended with type invariants and function contracts, in the spirit of JML. Second, an implementation is written in the programming language of Why3 and then verified with respect to the specification. Finally, an OCaml program is obtained by an automated translation. Our methodology is illustrated with the proof of a union-find library. Several other proofs of data structures and algorithms are included in the companion artifact to this paper.", "num_citations": "1\n", "authors": ["695"]}
{"title": "Deductive Verification via Ghost Debugging\n", "abstract": " We present a verification approach based on auxiliary programs, which we call ghost debuggers. This approach leads to notable verification gains when the structure of the program does not match the execution structure, notably when that latter structure is recursive. We present a theoretical foundation of our approach over a flavor of transfinite games, which let us specify and prove fine-grained properties about infinite behaviors of programs. By making use of the game structure, we also show that our approach can be applied to relational properties like simulation between programs. Our approach is backed by a mechanized development in the Why3 tool, which formally proves sound the Hoare-style logic backbone of our approach.", "num_citations": "1\n", "authors": ["695"]}
{"title": "Evidential paradigm and intelligent mathematical text processing\n", "abstract": " This paper presents the evidential paradigm of computer-supported mathematical assistance in \"doing\" mathematics and in reasoning activity. At present, the evidential paradigm is implemented in the form of System for Automated Deduction (SAD). The system is based on the methods of automated theorem proving and is intended for intelligent mathematical text processing. It proves mathematical theorems, verifies validity of self-contained mathematical texts and can be used for inference search in first-order sequent-based logic as well. For human-like representation of mathematical knowledge, SAD exploits an original formal language close to natural languages of scientific publications. Since the problem of automated text verification is of great importance for industrial applications (checking specifications, proving safety properties of network protocols, etc), the paper illustrates some principles and peculiarities of the evidential paradigm by means of exemplifying the verification of a part of a non-trivial mathematical text.", "num_citations": "1\n", "authors": ["695"]}