{"title": "A framework for ocean satellite image classification based on ontologies\n", "abstract": " In this paper we present a framework for ocean image classification based on ontologies. With this aim, we will describe how low and high level content of ocean satellite images can be modeled with an ontology. In addition, we will show how the image classification can be modeled with the ontology in which decision tree based classifiers and rule-based expert systems are represented. Particularly, the rule based expert systems include rules about low-level features (called training and labeling rules), and rules defined from the labeling (called human expert rules). The modeling with the ontology provides an extensible framework in which accommodate several methods of image classification. One of the main aims of our proposal is to provide a mechanism to share data about image classification between applications. We have developed an extensible Prot\u00e9g\u00e9 plugin to classify images.", "num_citations": "47\n", "authors": ["1840"]}
{"title": "Describing use cases with activity charts\n", "abstract": " The Model-Driven Development (MDD) describes and maintains models of the system under development. The Unified Modeling Language (UML) supports a set of semantics and notation that addresses all scales of architectural complexity by using a MDD perspective. Use Cases and Activity Charts are two modeling techniques of the UML. The first one helps the designers to identify the requirements of the system discovering its high level functionality. The second one helps them to specify the internal behaviour of a certain entity or subsystem of the software developed, such as a database, a graphical interface, a software component, or any specific software. However, there is not a direct way to relate/model the requirements (use cases) with their internal behavior (activity charts). In this paper we present a method for describing use cases with activity charts. Our technique also allow us to identify the two\u00a0\u2026", "num_citations": "43\n", "authors": ["1840"]}
{"title": "Describing use-case relationships with sequence diagrams\n", "abstract": " One of the key tools of the unified modelling language for behaviour modelling is the use-case model. The behaviour of a use case can be described by means of interaction diagrams (sequence and collaboration diagrams), activity charts and state diagrams or by pre-conditions and post-conditions, as well as natural language text, where appropriate. This article explains a technique to describe use cases by means of sequence diagrams. It compares sequence diagrams in order to define sequence-diagram relationships for identifying and defining use-case relationships. This article uses an automatic teller machine system case study to illustrate our proposal.", "num_citations": "41\n", "authors": ["1840"]}
{"title": "Designing GUI components from UML use cases\n", "abstract": " In this paper we present how to develop graphical user interfaces from two UML models: use case and activity diagrams. Our method obtains from them a UML class diagram for representing GUI components, and it is suitable for generating code fragments, which can be considered as GUI prototypes.", "num_citations": "38\n", "authors": ["1840"]}
{"title": "Querying XML documents in logic programming\n", "abstract": " Extensible Markup Language (XML) is a simple, very flexible text format derived from SGML. Originally designed to meet the challenges of large-scale electronic publishing, XML is also playing an increasingly important role in the exchange of a wide variety of data on the Web and elsewhere. XPath language is the result of an effort to provide address parts of an XML document. In support of this primary purpose, it becomes in a query language against an XML document. In this paper we present a proposal for the implementation of the XPath language in logic programming. With this aim we will describe the representation of XML documents by means of a logic program. Rules and facts can be used for representing the document schema and the XML document itself. In particular, we will present how to index XML documents in logic programs: rules are supposed to be stored in main memory, however facts are\u00a0\u2026", "num_citations": "36\n", "authors": ["1840"]}
{"title": "A flexible XPath-based query language implemented with fuzzy logic programming\n", "abstract": " In this paper we present an extension of the XPath query language for the handling of flexible queries. In order to provide ranked answers, our approach proposes fuzzy variants of and, or and avg operators for XPath conditions, as well as two structural constraints, called down and deep, for which a certain degree of relevance is associated. Our proposal has been implemented with a fuzzy logic language to take profit of the clear sinergies between both target and source fuzzy languages.", "num_citations": "32\n", "authors": ["1840"]}
{"title": "A performance comparison of distance-based query algorithms using R-trees in spatial databases\n", "abstract": " Efficient processing of distance-based queries (DBQs) is of great importance in spatial databases due to the wide area of applications that may address such queries. The most representative and known DBQs are the K Nearest Neighbors Query (KNNQ), \u03c1 Distance Range Query (\u03c1DRQ), K Closest Pairs Query (KCPQ) and \u03c1 Distance Join Query (\u03c1DJQ). In this paper, we propose new pruning mechanism to apply them in the design of new Recursive Best-First Search (RBFS) algorithms for DBQs between spatial objects indexed in R-trees. RBFS is a general search algorithm that runs in linear space and expands nodes in best-first order, but it can suffer from node re-expansion overhead (i.e. to expand nodes in best-first order, some nodes can be considered more than once). The R-tree and its variations are commonly cited spatial access methods that can be used for answering such spatial queries. Moreover, an\u00a0\u2026", "num_citations": "31\n", "authors": ["1840"]}
{"title": "An RDF query language based on logic programming\n", "abstract": " In this paper we investigate an extension of XQuery for querying (and inferring) from RDF documents. Following a graph based approach for specifying queries against RDF, XQuery is extended with construction of answers and boolean predicates for RDF entailment relationship inference. We will also study how to implement it in logic programming by using logic rules for executing RDF/XQuery queries.", "num_citations": "29\n", "authors": ["1840"]}
{"title": "An extension of UML for the modeling of WIMP user interfaces\n", "abstract": " Abstract The Unified Modeling Language (UML)[OMG, Unified Modeling Language Specification, Version 2.0, Technical Report, Object Management Group< http://www. omg. org/technology/documents/formal/uml. htm>, 2005] provides system architects working on analysis and design (A&D) with one consistent language for specifying, visualizing, constructing, and documenting the artifacts of software systems, as well as for the business modeling. The user interface (UI), as a significant part of most applications, should be modeled using UML, and automatic CASE tools may help to generate UIs from UML designs. In this paper, we describe how to use and specialize UML diagrams in order to describe the UIs of a software system based on WIMP (Windows, Icons, Menus and Pointers). Use case diagrams are used for extracting the main UIs. Use cases are described by means of user-interaction diagrams, a special\u00a0\u2026", "num_citations": "28\n", "authors": ["1840"]}
{"title": "Fuzzy logic programming for implementing a flexible xpath-based query language\n", "abstract": " FLOPER is the \u201cFuzzy LOgic Programming Environment for Research\u201d designed in our research group for assisting the development of real-world applications where fuzzy logic might play an important role. This is the case of our recently proposed extension for the popular XPath query language in order to handle flexible queries which provide ranked answers, fuzzy variants of operators and, or and avg for XPath conditions, as well as two structural constraints, called down and deep, for which a certain degree of relevance can be associated.", "num_citations": "24\n", "authors": ["1840"]}
{"title": "Annotating \u201cfuzzy chance degrees\u201d when debugging XPath queries\n", "abstract": " In this paper we present a method for debugging XPath queries which has been implemented with the fuzzy logic language MALP by using the FLOPER\u00a0tool developed in our group. We describe how XPath expressions can be manipulated for obtaining a set of alternative queries matching a given XML document. For each new proposed query, we give a \u201cchance degree\u201d that represents an estimation on its deviation w.r.t. the initial expression. Our work is focused on providing to the programmers a repertoire of paths which can be used to retrieve answers.", "num_citations": "22\n", "authors": ["1840"]}
{"title": "An encoding of xQuery in prolog\n", "abstract": " In this paper we describe the implementation of (a subset of) the XQuery language using logic programming (in particular, by means of Prolog). Such implementation has been developed using the Prolog interpreter SWI-Prolog. XML files are handled by means of the XML Library of SWI-Prolog. XPath/XQuery are encoded by means of Prolog rules. Such Prolog rules are executed in order to obtain the answer of the query.", "num_citations": "22\n", "authors": ["1840"]}
{"title": "UML modeling of user and database interaction\n", "abstract": " In this paper, we will present a design technique for user and database interaction based on UML. User interaction will be modeled by means of UML state diagrams, and database interaction by means of UML sequence diagrams. The proposed design technique establishes how to integrate both diagrams in order to describe the user interface and database interaction of a business software system. A case study of an Internet Book Shopping system will be shown to illustrate the proposal.", "num_citations": "21\n", "authors": ["1840"]}
{"title": "Fuzzy xpath through fuzzy logic programming\n", "abstract": " In this paper we present a fuzzy variant of the XPath query language for the flexible information retrieval on XML documents. Our main purpose is to provide a repertoire of operators that offer the possibility of managing satisfaction degrees by adding structural constraints and fuzzy operators inside conditions, in order to produce a ranked sorted list of answers according to user\u2019s preferences when composing queries. By using the FLOPER system designed in our research group, our proposal has been implemented with a fuzzy logic language to take profit of the clear synergies between both target and source fuzzy languages.", "num_citations": "20\n", "authors": ["1840"]}
{"title": "Magic Sets for the XPath Language.\n", "abstract": " The eXtensible Markup Language (XML) is considered as the format of choice for the exchange of information among various applications on the Internet. Since XML is emerging as a standard for data exchange, it is natural that queries among applications should be expressed as queries against data in XML format. This use gives rise to a requirement for a query language expressly designed for XML resources. World Wide Web Consortium (W3C) convened to create the XQuery language, concretely, a typed functional language for querying XML documents. One key aspect of the XQuery language is the use of the XPath language as basis for handling the structure of an XML document. In this paper, we present a proposal for the representation of XML documents by means of a logic program. Rules and facts can be used for representing the document schema and the XML document itself. In addition, we study\u00a0\u2026", "num_citations": "20\n", "authors": ["1840"]}
{"title": "Analyzing the Tagging Quality of the Spanish OpenStreetMap\n", "abstract": " In this paper, a framework for the assessment of the quality of OpenStreetMap is presented, comprising a batch of methods to analyze the quality of entity tagging. The approach uses Taginfo as a reference base and analyses quality measures such as completeness, compliance, consistence, granularity, richness and trust. The framework has been used to analyze the quality of OpenStreetMap in Spain, comparing the main cities of Spain. Also a comparison between Spain and some major European cities has been carried out. Additionally, a Web tool has been also developed in order to facilitate the same kind of analysis in any area of the world. View Full-Text", "num_citations": "16\n", "authors": ["1840"]}
{"title": "Integrating XQuery and Logic Programming\n", "abstract": " In this paper we investigate how to integrate the XQuery language and logic programming. With this aim, we represent XML documents by means of a logic program. This logic program represents the document schema by means of rules and the document itself by means of facts. Now, XQuery expressions can be integrated into logic programming by considering a translation (i.e. encoding) of for-let-where-return expressions by means of logic rules and a goal.", "num_citations": "16\n", "authors": ["1840"]}
{"title": "Fuzzy queries of social networks with FSA-SPARQL\n", "abstract": " Social networks have become a source of data which are of interest in all areas, and their querying and analysis is a hot topic in computer science. Our research group has developed a fuzzy extension of the Semantic Web query language SPARQL, called FSA-SPARQL (Fuzzy Sets and Aggregators based SPARQL). This extension provides mechanisms to express fuzzy queries against RDF data. FSA-SPARQL works with social networks. With this aim, FSA-SPARQL enables the transformation and fuzzification of social network API data. Fuzzification of social networks data is automatic and user-defined enabling a wide range of mechanisms for ranking and categorization, including sentiment analysis and topic detection. As a case study, FSA-SPARQL has been used to query three well-known social networks: Twitter, Foursquare and TMDb.", "num_citations": "14\n", "authors": ["1840"]}
{"title": "A xpath debugger based on fuzzy chance degrees\n", "abstract": " We describe how we can manipulate an XPath expression in order to obtain a set of alternative XPath expressions that match to a given XML document. For each alternative XPath expression we will give a chance degree that represents the degree in which the expression deviates from the initial expression. Thus, our work is focused on providing the programmer a repertoire of paths that (s)he can use to retrieve answers. The approach has been implemented and tested.", "num_citations": "12\n", "authors": ["1840"]}
{"title": "Integrating and querying OpenStreetMap and linked geo open data\n", "abstract": " In recent years, Open Street Map (OSM) has evolved into a highly popular geospatial system. The key of success of OSM is that OSM is open to absolutely everyone. OSM is not dependent on any one government, company, university or international organization. OSM is based on crowdsourcing, in which users collaborate to collect spatial data of urban and rural areas on the earth. With the arising of Linked Open Data (LOD) initiative, and more concretely with Linked Geo Open Data (LGOD), many Web resources have been made available to everyone, providing geo-located datasets. In this paper, a framework, called XOSM (XQuery for OpenStreetMap), for integrating and querying OSM and LGOD resources, is presented. The framework is equipped with a Web tool and a rich XQuery-based library, enabling the definition of queries combining OSM layers and layers created from LGOD resources (KML\u00a0\u2026", "num_citations": "11\n", "authors": ["1840"]}
{"title": "Fuzzy xpath for the automatic search of fuzzy formulae models\n", "abstract": " In this paper we deal with propositional fuzzy formulae containing several propositional symbols linked with connectives defined in a lattice of truth degrees more complex than Bool. Instead of focusing on satisfiability (i.e., proving the existence of at least one model) as usually done in a SAT/SMT setting, our interest moves to the problem of finding the whole set of models (with a finite domain) for a given fuzzy formula. We reuse a previous method based on fuzzy logic programming where the formula is conceived as a goal whose derivation tree, provided by our FLOPER tool, contains on its leaves all the models of the original formula, together with other interpretations. Next, we use the ability of the FuzzyXPath tool (developed in our research group with FLOPER) for exploring these derivation trees once exported in XML format, in order to discover whether the formula is a tautology, satisfiable, or a\u00a0\u2026", "num_citations": "11\n", "authors": ["1840"]}
{"title": "An ontology-based modeling of an ocean satellite image retrieval system\n", "abstract": " The need to access information in large volumes of image data, e.g. big images, large images archives, distributed image repositories, etc, has stimulated the research in the field of Content-based Image Retrieval during last decade [DJLW08, LZLM07, Han08]. Many new concepts have been developed and prototyped. However, the dramatic increase in volume, details, diversity and complexity and the user demand for simultaneous access to multi-domain data urgently requires new approaches for image information mining, multi-domain information management, knowledge management and sharing. In this work we will present the elements of the architecture of a satellite image retrieval system. In order to have a flexible and dynamic image retrieval system, we have designed an architecture which integrates Web technologies with modern pattern recognition systems applied to satellite images [PGC05]. Our\u00a0\u2026", "num_citations": "11\n", "authors": ["1840"]}
{"title": "Automatic generation of ecore models for testing ATL transformations\n", "abstract": " Model transformation testing is crucial to detect incorrect transformations. Buggy transformations can lead to incorrect target models, either violating target meta-model requirements or more complex target model properties. In this paper we present a tool for testing ATL transformations. This tool is an extension of a previously developed tool for testing XML-based languages. With this aim an Ecore to XML Schema transformation is defined which makes to automatically generate random Ecore models possible. These randomly generated Ecore models are used to test ATL transformations. Properties to be tested are specified by OCL constraints, describing input and output conditions on source and target models, respectively.", "num_citations": "10\n", "authors": ["1840"]}
{"title": "OBIA system for identifying mesoscale oceanic structures in SeaWiFS and MODIS-Aqua images\n", "abstract": " The ocean covers over 70% of the surface of our planet and plays a key role in the global climate. Most ocean circulation is mesoscale (scales of 50-500 km and 10-100 days), and the energy in mesoscale circulation is at least one order of magnitude greater than general circulation; therefore, the study of mesoscale oceanic structures (MOS) is crucial to ocean dynamics, making it especially useful for analyzing global changes. The detection of MOS, such as upwellings or eddies, from satellites images is significant for marine environmental studies and coastal resource management. In this paper, we present an object-based image analysis (OBIA) system which segments and classifies regions contained in sea-viewing field-of-view sensor (SeaWiFS) and Moderate Resolution Imaging Spectro-radiometer (MODIS)-Aqua sensor satellite images into MOS. After color clustering and hierarchical data format (HDF) file\u00a0\u2026", "num_citations": "10\n", "authors": ["1840"]}
{"title": "Fuzzy xpath queries in xquery\n", "abstract": " We have recently designed a fuzzy extension of the XPath language which provides ranked answers to flexible queries taking profit of fuzzy variants of and, or and avg operators for XPath conditions, as well as two structural constraints, called down and deep, for which a certain degree of relevance is associated. In this work, we describe how to implement the proposed fuzzy XPath with the XQuery language. Basically, we have defined an XQuery library able to fuzzily handle XPath expressions in such a way that our proposed fuzzy XPath can be encoded as XQuery expressions. The advantages of our approach is that any XQuery processor can handle a fuzzy version of XPath by using the library we have implemented.", "num_citations": "10\n", "authors": ["1840"]}
{"title": "A safe relational calculus for functional logic deductive databases\n", "abstract": " In this paper, we present an extended relational calculus for expressing queries in functional-logic deductive databases. This calculus is based on first-order logic and handles relation predicates, equalities and inequalities over partially defined terms, and approximation equations. For the calculus formulas, we have studied syntactic conditions in order to ensure the domain independence property. Finally, we have studied its equivalence w.r.t. the original query language, which is based on equality and inequality constraints.", "num_citations": "10\n", "authors": ["1840"]}
{"title": "A fuzzy extension of SPARQL based on fuzzy sets and aggregators\n", "abstract": " SPARQL has been adopted as query language for the Semantic Web. RDF and OWL have also been established as vocabularies to describe ontologies in this setting. While RDF/OWL/SPARQL have been designed for querying crisp information, some contexts require to manage uncertainty, vagueness and imprecise knowledge. In this paper a SPARQL extension, called FSA-SPARQL (Fuzzzy Sets and Aggregators based SPARQL) is proposed, in which queries can involve different fuzzy connectives and (aggregation) operators. The language has been implemented as an extension of the ARQ Jena SPARQL engine and it is equipped with a Web tool from which queries can be executed on-line.", "num_citations": "9\n", "authors": ["1840"]}
{"title": "Analyzing fuzzy logic computations with fuzzy xpath\n", "abstract": " Implemented with a fuzzy logic language by using the FLOPER tool developed in our research group, we have recently designed a fuzzy dialect of the popular XPath language for the flexible manipulation of XML documents. In this paper we focus on the ability of Fuzzy XPath for exploring derivation trees generated by FLOPER once they are exported in XML format, which somehow serves as a debugging/analizing tool for discovering the set of fuzzy computed answers for a given goal, performing depth/breadth-first traversals of its associated derivation tree, finding non fully evaluated branches, etc., thus reinforcing the bi-lateral synergies between Fuzzy XPath and FLOPER.", "num_citations": "9\n", "authors": ["1840"]}
{"title": "A prolog-based query language for OWL\n", "abstract": " In this paper we investigate how to use logic programming (in particular, Prolog) as query language against OWL resources. Our query language will be able to retrieve data and meta-data about a given OWL based ontology. With this aim, firstly, we study how to define a query language based on a fragment of Description Logic, then we show how to encode the defined query language into Prolog by means of logic rules and finally, we identify Prolog goals which correspond to queries.", "num_citations": "9\n", "authors": ["1840"]}
{"title": "Algebraic semantics for functional logic programming with polymorphic order-sorted types\n", "abstract": " In this paper we present the semantics of a functional logic language with parametric and order-sorted polymorphism. Typed programs consist of a polymorphic signature and a set of constructor-based conditional rewriting rules for which we define a semantic calculus. The denotational semantics of the language is based on Scott domains interpreting constructors and functions by monotonic and continuous mappings, respectively, in every instance of the declared type. We prove initiality results for the free ground term algebra. We also prove that the free term algebra with variables is freely generated in the category of models. The semantic calculus is proved to be sound and complete w.r.t. the denotational semantics. As in logic programming, we define the immediate consequence operator, proving that the Hebrand model is the least model of a program.", "num_citations": "9\n", "authors": ["1840"]}
{"title": "XQuery testing from XML schema based random test cases\n", "abstract": " In this paper we present the elements of an XQuery testing tool which makes possible to automatically test XQuery programs. The tool is able to systematically generate XML instances (i.e., test cases) from a given XML schema. The number and type of instances is defined by the human tester. These instances are used to execute the given XQuery program. In addition, the tool makes possible to provide an user defined property to be tested against the output of the XQuery program. The property can be specified with a Boolean XQuery function. The tool is implemented as an oracle able to report whether the XQuery program passes the test, that is, all the test cases satisfy the property, as well as the number of test cases used for testing. In the case of the XQuery program fails the testing, the tool shows counterexamples found in the test cases. The tool has been implemented as an XQuery library which\u00a0\u2026", "num_citations": "8\n", "authors": ["1840"]}
{"title": "Dynamic filtering of ranked answers when evaluating fuzzy xpath queries\n", "abstract": " We have recently designed an extension of the XPath language which provides ranked answers to flexible queries taking profit of fuzzy variants of and, or and avg operators for XPath conditions, as well as two structural constraints, called down and deep, for which a certain degree of relevance is associated. In practice, this degree is very low for some answers weakly accomplishing with the original query, and hence, they should not be computed in order to alleviate the computational complexity of the information retrieval process. In this work we focus on the scalability of our interpreter for dealing with massive XML files by making use of its ability for prematurely disregarding those computations leading to non significant solutions (i.e., with a poor degree of relevance according the preferences expressed by users when using the new command FILTER). Since our proposal has been implemented with a\u00a0\u2026", "num_citations": "8\n", "authors": ["1840"]}
{"title": "A framework for goal-directed bottom-up evaluation of functional logic programs\n", "abstract": " In this paper we start the design of a functional-logic deductive database language. Given that most logic deductive languages consider bottom-up evaluation as operational mechanism, here we will focus on the development of an operational semantics based on bottomup evaluation for functional logic languages. As in the logic paradigm, the bottom-up evaluation will consist in a magic transformation for a given program-query into a magic program-query for which the bottomup evaluation will simulate the top-down one of the original program.", "num_citations": "8\n", "authors": ["1840"]}
{"title": "Automatic property\u2010based testing and path validation of XQuery programs\n", "abstract": " Property\u2010based testing has gained popularity in recent years in many areas of software development. The specification of assertions/properties helps to understand the semantics of pieces of code, and in modern programming environments, it can serve to test the program behavior. In this paper an XQuery property\u2010based testing tool is presented, which enables to automatically test XQuery programs. The tool is able to systematically generate XML instances (i.e., test cases) from a given XML schema, and to filter XML instances with input properties specified by the programmer. Additionally, the tool automatically checks output (respectively, input\u2010output) properties in each output instance (respectively, each pair of input\u2010output instances). The tool is able to report whether the XQuery program passes the test, that is, if all the test cases satisfy the (input\u2010)output property, as well as the number of test cases used for\u00a0\u2026", "num_citations": "7\n", "authors": ["1840"]}
{"title": "A prolog library for OWL RL\n", "abstract": " In this paper we describe the development of a Prolog library for OWL RL. OWL RL has been recently proposed by the W3C consortium as a fragment of OWL 2 for which reasoning can be done efficiently. In this context, we have studied how to implement a Prolog library based on OWL RL. By means of Prolog rules we are able to infer new knowledge from a given ontology. The OWL RL library has been implemented under the SWI-Prolog interpreter and is based on the RDF library provided by the SWI-Prolog environment, in such a way that OWL triples are computed and stored in secondary memory.", "num_citations": "7\n", "authors": ["1840"]}
{"title": "Constraint logic programming over sets of spatial objects\n", "abstract": " Constraint Logic Programming (CLP) is a framework integrating Constraint Programming (CP) and Logic Programming (LP). CLP is described as a general schema of combination of logic-based languages and constraint solvers. Recently, a constraint system for the handling of constraints over sets of spatial objects has been presented. In this paper we study how to consider a CLP instance for this kind of constraints. In particular, we study the fixed-point and operational semantics of such instance. With respect to the operational semantics it is described how the constraint solver interacts with the mechanism of resolution, in particular how to detect failure branches by means of a consistence constraint checker and how to achieve constraint propagation and compute solved forms.", "num_citations": "7\n", "authors": ["1840"]}
{"title": "A model transformation language based on logic programming\n", "abstract": " In this paper we present a model transformation language based on logic programming. The language, called PTL (Prolog based Transformation Language), can be considered as a hybrid language in which ATL-style rules are combined with logic rules for defining transformations. The proposal has been implemented so that a Prolog program is automatically obtained from a PTL program. We have equipped our language with debugging and tracing capabilities which help developers to detect programming errors in PTL rules.", "num_citations": "6\n", "authors": ["1840"]}
{"title": "Querying and Reasoning with RDF (S)/OWL in XQuery\n", "abstract": " In this paper we investigate how to use the XQuery language for querying and reasoning with RDF(S)/OWL-style ontologies. Our proposal allows the handling of RDF(S)/OWL triples by means of a XQuery library for the Semantic Web, and it encodes RDF(S)/OWL reasoning by means of XQuery functions. We have tested and implemented the approach.", "num_citations": "6\n", "authors": ["1840"]}
{"title": "ODM-based UML model transformations using Prolog\n", "abstract": " In this paper we present a framework for the specification of model transformations by means of Prolog rules, using the ODM representation of UML models. In addition, Prolog rules are also used for the validation of source and target models wrt their ODM based metamodels. We have validated our proposal by means of a prototype developed under SWI-Prolog.", "num_citations": "6\n", "authors": ["1840"]}
{"title": "Extending XQuery for Semantic Web Reasoning\n", "abstract": " In this paper we investigate an extension of the XQuery language for querying and reasoning with OWL-style ontologies. The proposed extension incorporates new primitives (i.e. boolean operators) in XQuery for the querying and reasoning with OWL-style triples in such a way that XQuery can be used as query language for the Semantic Web. In addition, we propose a Prolog-based implementation of the extension.", "num_citations": "6\n", "authors": ["1840"]}
{"title": "Ontology Querying and Reasoning with XQuery\n", "abstract": " In this paper we investigate an extension of XQuery for querying and reasoning with OWL-style ontologies. The proposed extension adds new primitives (ie boolean operators) in XQuery for querying OWL-style triples in such a way that XQuery can be used as query language for OWL. We also study how to implement the cited extension of XQuery into logic programming.", "num_citations": "6\n", "authors": ["1840"]}
{"title": "A computational model for functional logic deductive databases\n", "abstract": " This paper adds the handling of negative information to a functional-logic deductive database language. By adopting as semantics for negation the so-called CRWLF, wherein the negation is intended as \u2018finite failure\u2019 of reduction, we will define Herbrand algebras and models for this semantics and a fix point operator to be used in a new goaldirected bottom-up evaluation mechanism based on magic transformations. This bottom-up evaluation will simulate the top-down one of the original program; in fact, it will carry out a goal-directed lazy evaluation.", "num_citations": "6\n", "authors": ["1840"]}
{"title": "Discovery and diagnosis of wrong SPARQL queries with ontology and constraint reasoning\n", "abstract": " The discovery and diagnosis of wrong queries in database query languages have gained more attention in recent years. While for imperative languages well-known and mature debugging tools exist, the case of database query languages has traditionally attracted less attention. SPARQL is a database query language proposed for the retrieval of information in Semantic Web resources. RDF and OWL are standardized formats for representing Semantic Web information, and SPARQL acts on RDF/OWL resources allowing to retrieve answers of user\u2019s queries. In spite of the SPARQL apparent simplicity, the number of mistakes a user can make in queries can be high and their detection, localization, and correction can be difficult to carry out. Wrong queries have as consequence most of the times empty answers, but also wrong and missing (expected but not found) answers. In this paper we present two ontology and\u00a0\u2026", "num_citations": "5\n", "authors": ["1840"]}
{"title": "Debugging while interpreting fuzzy xpath queries\n", "abstract": " We have recently introduced \u201cdynamic thresholding\u201d techniques into our debugger of XPath queries which produces a set of correct XPath expressions with better chance degrees for retrieving answers from large XML files in a very efficient way. In this paper we focus on a new command called DEBIN intended to automatically interpret all these correct queries for the retrieval of their answers. The interest of the new command resides in the fact that users can retrieve now new information not necessarily reported by the execution of their initial queries, thus collecting useful novel answers (very often accompanied with a greater \u201cretrieval status value\u201d or satisfaction degree) associated to correct queries which slightly deviate from the original ones. In this paper we justify why, apart for automatically removing redundant solutions and sorting them, the use of appropriate filters seems to be mandatory when managing\u00a0\u2026", "num_citations": "5\n", "authors": ["1840"]}
{"title": "PTL: A model transformation language based on logic programming\n", "abstract": " In this paper we present a model transformation language based on logic programming. The language, called PTL (Prolog based Transformation Language), can be considered as a hybrid language in which ATL (Atlas Transformation Language)-style rules are combined with logic rules for defining transformations. ATL-style rules are used to define mappings from source models to target models while logic rules are used as helpers. The implementation of PTL is based on the encoding of the ATL-style rules by Prolog rules. Thus, PTL makes use of Prolog as a transformation engine. We have provided a declarative semantics to PTL and proved the semantics equivalent to the encoded program. We have studied an encoding of OCL (Object Constraint Language) with Prolog goals in order to map ATL to PTL. Thus a subset of PTL can be considered equivalent to a subset of ATL. The proposed language can be also\u00a0\u2026", "num_citations": "5\n", "authors": ["1840"]}
{"title": "Thresholded debugging of XPath queries\n", "abstract": " We have recently designed/implemented a method for debugging XPath queries which produces a set of alternative XPath expressions with higher chances for retrieving answers from XML files. In this paper we focus on the scalability of our debugger for dealing with massive XML documents by making use of the new command FILTER which is intended to prematurely disregard those computations leading to non significant solutions (i.e., with a poor \u201cchance degree\u201d according to the user's preferences). The key point is the natural capability for performing \u201cdynamic thresholding\u201d enjoyed by the fuzzy logic language used for implementing the tool, which somehow connects with the so-called \u226atop-k answering problem\u226b very well-known in the fuzzy logic and soft computing arenas.", "num_citations": "5\n", "authors": ["1840"]}
{"title": "Querying open street map with xquery\n", "abstract": " In this paper we present a library for querying Open Street Map (OSM) with XQuery. This library is based on the well-known spatial operators defined by Clementini and Egenhofer, providing a repertoire of XQuery functions which encapsulate the search on the XML document representing a layer of OSM, and make the definition of queries on top of OSM layers easy. In essence, the library provides a repertoire of OSM Operators for points and lines which, in combination with Higher Order facilities of XQuery, facilitates the composition of queries and the definition of keyword based search geo-localized queries. OSM data are indexed by an R-tree structure, in which points and lines are enclosed by Minimum Bounding Rectangles (MBRs), in order to get shorter answer time.", "num_citations": "5\n", "authors": ["1840"]}
{"title": "Tuning fuzzy SPARQL queries in a fuzzy logic programming environment\n", "abstract": " We have recently designed FSA-SPARQL, an extension of the SPARQL query language for querying fuzzy RDF datasets. Answers of FSA-SPARQL queries are usually annotated with truth degrees which are computed from fuzzy connectives and operators that act on truth degrees associated to RDF triples. While FSA-SPARQL offers a rich repertoire of fuzzy connectives and operators, it is not always easy to retrieve the user's expected answers. This is very often due to wrong formulation of queries, caused by inadequate use/combination of fuzzy connectives, operators and thresholds. For instance, a high threshold for truth degrees in some RDF datasets can lead to an empty set of answers, some strong or weak restrictive combination of fuzzy conditions might produce few or too many answers, etc. On the other hand, our research group has also developed the fuzzy logic programming language , which has\u00a0\u2026", "num_citations": "4\n", "authors": ["1840"]}
{"title": "Syntactic and semantic validation of sparql queries\n", "abstract": " In this paper we present a tool to syntactically and semantically validate SPARQL queries. With this aim, we extract triple patterns and filter conditions from SPARQL queries and we use the OWL API and an OWL ontology reasoner in order to detect wrong expressions. Given an ontology and a query, the tool reports different kinds of programming errors: wrong use of vocabulary, wrong use of resources and literals, wrong filter conditions and wrong use of variables in triple patterns and filter conditions. When the OWL ontology reasoner is used the tool reports a diagnosis.", "num_citations": "4\n", "authors": ["1840"]}
{"title": "Model validation in ontology based transformations\n", "abstract": " Model Driven Engineering (MDE) is an emerging approach of software engineering. MDE emphasizes the construction of models from which the implementation should be derived by applying model transformations. The Ontology Definition Meta-model (ODM) has been proposed as a profile for UML models of the Web Ontology Language (OWL). In this context, transformations of UML models can be mapped into ODM/OWL transformations. On the other hand, model validation is a crucial task in model transformation. Meta-modeling permits to give a syntactic structure to source and target models. However, semantic requirements have to be imposed on source and target models. A given transformation will be sound when source and target models fulfill the syntactic and semantic requirements. In this paper, we present an approach for model validation in ODM based transformations. Adopting a logic programming based transformational approach we will show how it is possible to transform and validate models. Properties to be validated range from structural and semantic requirements of models (pre and post conditions) to properties of the transformation (invariants). The approach has been applied to a well-known example of model transformation: the Entity-Relationship (ER) to Relational Model (RM) transformation.", "num_citations": "4\n", "authors": ["1840"]}
{"title": "Development of a Query Language for GML based on XPath.\n", "abstract": " Geography Markup Language (GML) has been established as the standard language for the transport, storage and modelling of geographic information. In this paper we study how to adapt the XPath query language to GML documents. With this aim, we have defined a semantic based XPath language which is not based on the (tree-based) syntactic structure of GML documents, instead it is based on the \u201csemantic structure\u201d of GML documents. In other words, the proposed XPath language is based on the GML schema. We have developed a system called UALGIS, in order to implement the approach. Such system stores GML documents by means of the PostGIS RDBMS. In order to execute semantic-based XPath queries we have defined a translation of the queries into SQL. Such translation takes into account the GML schema. Finally, the system allows to visualize the result. With this aim, the result of a query is exported to the Keyhole Markup Language (KML) format.", "num_citations": "4\n", "authors": ["1840"]}
{"title": "User interaction and interface design with UML\n", "abstract": " This chapter will show you how to use and specialise UML diagrams for describing the user interfaces of a software system. In order to accomplish the description of user interfaces, the proposed technique considers three specialised UML diagrams called user-interaction, user-interface, and GUI-class diagrams, which will be built following a model-driven development (MDD) perspective. These diagrams can be seen as the UML-based UI models of the system. In addition, this chapter is concerned with code-generation to implement the user interfaces of the system by using GUI-class diagrams and user-interaction diagrams. A case study of an Internet book shopping system is introduced in this chapter to proof and illustrate the proposed user interaction and interface design technique.", "num_citations": "4\n", "authors": ["1840"]}
{"title": "Solving constraints on sets of spatial objects\n", "abstract": " In this paper, we present a constraint solver for constraints on sets of spatial objects. With this aim, we define a constraint system for handling spatial data types (points, lines, polygons and regions) and constraints on them (equalities and inequalities, memberships, metric, topological and structural constraints), and provide a suitable theory for this constraint system. The constraint solver is presented in the form of transformation rules. These transformation rules handle a special kind of constraints used for consistency checking, enabling an optimized and efficient solving of spatial constraints.", "num_citations": "4\n", "authors": ["1840"]}
{"title": "A relational algebra for functional logic deductive databases\n", "abstract": " In this paper, we study the integration of functional logic programming and databases by presenting a data model, and a query and data definition language. The data model is adopted from functional logic programming by allowing complex values. The query and data definition language is based on the use of algebra expressions built from a set of algebra operators over an extended relational algebra. In addition, algebra expressions can be used for defining functions, typical in a functional logic program.", "num_citations": "4\n", "authors": ["1840"]}
{"title": "Bases for the development of LAST: a formal method for business software requirements specification\n", "abstract": " This paper proposes a possible approach to IS requirements specification. It relies on the application of standard (i.e. conventional) discrete mathematics, more precisely, it uses a fairly limited number of concepts from the fields of linear algebra and set theory (hence its name, LAST). The use of LAST for data definition and query\u2013answer are discussed in some detail, given the data-rich quality of Business IS and the fact that a solid data-model is therefore essential to their specification. The proposed approach implies integration with other semiformal specification methods, two of the possibilities being integration with UML\u2013OCL and with the Entity Relationship Model, which are discussed in this paper. Finally, mapping of LAST specifications to the Relational Model is also addressed; this possibility having an interest both, for (partial) implementation and for model simulation.", "num_citations": "4\n", "authors": ["1840"]}
{"title": "Property-based testing of SPARQL queries\n", "abstract": " In this paper we describe a property-based testing tool for SPARQL. Given a SPARQL query, the tool randomly generates test cases which consist on instances of an ontology. The tool checks the well typed-ness of the SPARQL query as well as the consistency of the test cases with the ontology axioms. With this aim, a type system has been defined for SPARQL. Test cases are later used to execute the SPARQL query. The output of the SPARQL query is tested with a Boolean property which is defined in terms of membership of ontology individuals to ontology classes. The testing tool reports counterexamples when the Boolean property is not satisfied.", "num_citations": "3\n", "authors": ["1840"]}
{"title": "A web tool for type checking and testing of sparql queries\n", "abstract": " In this paper a property-based testing tool for SPARQL is described. The tool randomly generates test cases in the form of instances of an ontology. The tool checks the well typed-ness of the SPARQL query as well as the consistency of the test cases with the ontology axioms. Test cases are after used to execute queries. The output of the queries is tested with a Boolean property which is defined in terms of membership of ontology individuals to classes. The testing tool reports counterexamples when the Boolean property is not satisfied.", "num_citations": "3\n", "authors": ["1840"]}
{"title": "Distance based queries in open street map\n", "abstract": " Volunteered geographic information (VGI) makes available a very large resource of geographic data. The exploitation of data coming from such resources requires an additional effort in the form of tools and effective processing techniques. One of the most stablished VGI is Open Street Map (OSM) offering data of urban and rural maps from the earth. Recently, we have presented a library for querying OSM data with the XML query language XQuery. This library is based on the well-known spatial operators defined by Clementini and Egenhofer, providing a repertoire of XQuery functions which encapsulate the search on the XML document representing a layer of OSM, and make the definition and composition of queries on top of OSM layers easier. In this paper, we will show how to extend the library in order to express distance based queries. Distances will be used either to get layers of objects in a certain distance\u00a0\u2026", "num_citations": "3\n", "authors": ["1840"]}
{"title": "Transformation and Validation with SWRL and OWL of ODM-Based Models\n", "abstract": " In this paper we present an approach for the specification of transformations and validations of ODM models. Adopting a SWRL/OWL based approach we will show how transform and validate models. Model-to-model transformations are described with SWRL rules, and validation of source and target models is achieved by SWRL.", "num_citations": "3\n", "authors": ["1840"]}
{"title": "Validation of XML Documents with SWRL\n", "abstract": " In this paper we describe how XML documents are mapped into an OWL ontology and how SWRL rules are used to validate the semantic content of XML documents. XML completion and data constraints are specified with SWRL. The semantic completion of the XML document can be mapped into a semantic completion of the corresponding ontology. Besides, SWRL serves for specifying and reasoning with data constraints. We will illustrate our approach with an example that shows that user intervention is vital to XML mapping and completion and SWRL helps to detect relevant data constraints. The approach has been tested with the well-known Prot\u00e9g\u00e9 tool.", "num_citations": "3\n", "authors": ["1840"]}
{"title": "Xpath for querying GML-based representation of urban maps\n", "abstract": " Geography Markup Language (GML) has been established as the standard language for the transport, storage and modelling of geographic information. In this paper we study how to adapt the XPath query language to GML documents. With this aim, we have defined a XPath based query language which handles the \u201csemantic structure\u201d of GML. Our approach focuses on querying urban maps whose representation is based on GML. We have developed a system called UALGIS, in order to implement the approach. Such system stores GML documents by means of the PostGIS RDBMS. In order to execute semantic-based XPath queries we have defined a translation of the queries into SQL. Such translation takes into account the GML schema. Finally, the system allows to visualize the result. With this aim, the result of a query is exported to the Keyhole Markup Language (KML) format.", "num_citations": "3\n", "authors": ["1840"]}
{"title": "Database query languages and functional logic programming\n", "abstract": " Functional logic programming is a paradigm which integrates functional and logic programming. It is based on the use of rewriting rules for defining programs, and rewriting for goal solving. In this context, goals, usually, consist of equality (and, sometimes, inequality) constraints, which are solved in order to obtain answers, represented by means of substitutions. On the other hand, database programming languages involve a data model, a data definition language and, finally, a query language against the data defined according to the data model. To use functional logic programming as a database programming language, (1) we will propose a data model involving the main features adopted from functional logic programming (for instance, handling of partial and infinite data), (2) we will use conditional rewriting rules as data definition language, and finally, (3) we will deal with equality and inequality\u00a0\u2026", "num_citations": "3\n", "authors": ["1840"]}
{"title": "Lazy narrowing with parametric order sorted types\n", "abstract": " Recently, a model theoretic semantics for lazy functional programming combining parametric and inclusion polymorphism has been proposed in [2]. The aim of the present work is to provide the previous one with the incorporation of a typed lazy narrowing calculus for goal solving which combines lazy unification, sharing and type checking at run-time. Furthermore, we state soundness and completeness results of the goal solving procedure w.r.t. the typed rewriting calculi presented in [2] which were proved to be also sound and complete w.r.t. the notion of model in [2]. Thus, all theoretical results described there are also preserved in this framework.", "num_citations": "3\n", "authors": ["1840"]}
{"title": "Declarative Debugging of XML Queries\n", "abstract": " In this paper we present the elements of an algorithmic debugger for XQuery. Given a XQuery program/query, a debugging tree is built in which the root is the query and the answer, and non-root nodes contain the results of function calls and XPath expressions computed from the query. Using the higher-order capabilities of XQuery several navigation strategies can be defined, enabling the adaptation of the debugging to the program/query and the user needs. Debugging trees and concepts as (partially) incomplete and incorrect answers are formally defined for queries in terms of XQuery semantics. A Web tool has been developed allowing the visualization of the debugging tree and the debugging of a XQuery program/query with the selected navigation strategy.", "num_citations": "2\n", "authors": ["1840"]}
{"title": "Detecting and diagnosing syntactic and semantic errors in SPARQL queries\n", "abstract": " In this paper we present a tool to syntactically and semantically validate SPARQL queries. With this aim, we extract triple patterns and filter conditions from SPARQL queries and we use the OWL API and an OWL ontology reasoner in order to detect wrong expressions. Given an ontology and a query, the tool reports different kinds of programming errors: wrong use of vocabulary, wrong use of resources and literals, wrong filter conditions and wrong use of variables in triple patterns and filter conditions. When the OWL ontology reasoner is used the tool reports a diagnosis.", "num_citations": "2\n", "authors": ["1840"]}
{"title": "A location-based approach to the classification of mesoscale oceanic structures in SeaWiFS and Aqua-MODIS images of Northwest Africa\n", "abstract": " This study presents a different approach to the classification of Mesoscale Oceanic Structures (MOS) present in the Northwest African area, based on their location. The main improvement stems from the partition of this area in four large zones perfectly differentiated by their morphological characteristics, with attention to seafloor topography and coastal relief. This decomposition makes it easier to recognize structures under adverse conditions, basically the presence of clouds partly hiding them. This is observed particularly well in upwellings, which are usually very large structures with a different morphology and genesis in each zone. This approach not only improves the classification of the upwellings, but also makes it possible to analyse changes in the MOS over time, thereby improving the prediction of its morphological evolution. To identify and label the MOS classified in the Sea-viewing Wide Field-of-view\u00a0\u2026", "num_citations": "2\n", "authors": ["1840"]}
{"title": "Automatic validation of XQuery programs\n", "abstract": " In this paper we present a tool for the automatic validation of XQuery programs. Firstly, the tool is able to detect wrong paths in XQuery expressions with respect to an XML Schema. Secondly, it makes possible the specification of input and output properties, as well as input-output properties (ie, properties relating input and output data) of programs. Thirdly, the tool is able to filter randomly generated test cases with input properties, as well as to test output and input-output properties on randomly generated test cases and the corresponding output. It reports counterexamples when output or input-output properties are not satisfied. The tool has been implemented as an XQuery library which can be used from any XQuery interpreter.", "num_citations": "2\n", "authors": ["1840"]}
{"title": "Aggregation operators in geospatial queries for open street map\n", "abstract": " One of the most stablished Volunteered Geographic Information (VGI) systems is Open Street Map (OSM) offering data from the earth of urban and rural maps. Recently [1], we have presented a library for querying OSM data with the XML query language XQuery. This library is based on the well-known spatial operators defined by Clementini and Egenhofer, providing a repertoire of XQuery functions which encapsulates the search on the XML document representing a layer of OSM, and makes the definition and composition of queries on top of OSM layers easier. This paper goes towards the incorporation in the library of aggregation operators in order to be able to express queries involving data summarization and ranking. A rich repertoire of aggregation operators has been defined which, in combination with the previously proposed library, makes possible to easily formulate aggregation-based queries\u00a0\u2026", "num_citations": "2\n", "authors": ["1840"]}
{"title": "OWL RL in logic programming: querying, reasoning and inconsistency explanations\n", "abstract": " In this paper we describe a logic programming based implementation of the OWL 2 RL fragment. We show how goals are used for querying, forward reasoning permits to infer new knowledge, and ontology inconsistency is handled by backward reasoning, where explanations and (minimal) justifications are given to inconsistent ontologies.", "num_citations": "2\n", "authors": ["1840"]}
{"title": "Ontology-based modelling of ocean satellite images\n", "abstract": " In this paper we will define an ontology about the semantic content of ocean satellite images in which we are able to represent types of ocean structures, spatial and morphological concepts, and knowledge about measures of temperature, chrolophyll concentration, among others. Such ontology will provide the basis of a classification system based on the low-level features of images. We have tested our approach using the Proteg\u00e9 semantic web tool.", "num_citations": "2\n", "authors": ["1840"]}
{"title": "INDALOG: A Declarative Deductive Database Language\n", "abstract": " In this paper we present the main features of a deductive database language named IN DALOG based on the integration of functional and logic paradigms. As most deductive database systems, INDALOG allows the handling of negation, higher-order functions, grouping operators, support for aggregation, handling of non-ground facts, and support for indexing structures on both extensional and intensional relations of a database. Moreover, we present the semantic foundations of this language.", "num_citations": "2\n", "authors": ["1840"]}
{"title": "Metamorphic testing of OpenStreetMap\n", "abstract": " Context:OpenStreetMap represents a collaborative effort of many different and unrelated users to create a free map of the world. Although contributors follow some general guidelines, unsupervised additions are prone to include erroneous information. Unfortunately, it is impossible to automatically detect most of these issues because there does not exist an oracle to evaluate whether the information is correct or not. Metamorphic testing has shown to be very useful in assessing the correctness of very heterogeneous artifacts when oracles are not available.Objective:The main goal of our work is to provide a (fully implemented) framework, based on metamorphic testing, that will support the analysis of the information provided in OpenStreetMap with the goal of detecting faulty information.Method:We defined a general metamorphic testing framework to deal with OpenStreetMap. We identified a set of good metamorphic\u00a0\u2026", "num_citations": "1\n", "authors": ["1840"]}
{"title": "A Web Tool for XQuery Debugging\n", "abstract": " This system demo shows how to debug XQuery programs using an algorithmic debugger developed for XQuery. The debugging process consists in the building of a debugging tree and the answering of questions Yes/No by the user about the results of Function calls and XPath expressions until a bug is found (or no more questions remain). Using the higher-order capabilities of XQuery several debugging strategies\u2013children selection strategies\u2013can be used, enabling the adaptation of the debugging to the program/query.", "num_citations": "1\n", "authors": ["1840"]}
{"title": "The Retrieval of Social Network Data for Points-of-Interest in OpenStreetMap\n", "abstract": " OpenStreetMap is a volunteered geographic information system aimed at creating a free editable map of the world. One of the central elements of OpenStreetMap is the point-of-interest (POI). OpenStreetMap\u2019s contributors label POIs with information about them, including their name, type, address, etc. However, to use OpenStreetMap for touristic purposes, POIs should be annotated with useful information for visitors. Recently, our group developed XOSM, a query language and visualization tool for OpenStreetMap. This paper describes how to integrate social network queries into the XOSM query language. As a consequence of such integration, XOSM enables the definition and visualization of queries in which social network data are retrieved for POIs. XOSM social network queries serve to analyze the characteristics and relevance of POIs by visualizing Twitter and YouTube data. XOSM APIs have been built on top of the social network APIs to map XOSM POIs to social network data. To obtain better accuracy and reduce noise in the matching of OpenStreetMap POIs and social network data, some improvements are proposed. In particular, this paper suggests restricting the search space of the APIs by using the city name and the type of POI and then filtering the results of the APIs using the Levenshtein distance, examines the advantages of such improvements, and provides benchmarks that validate the proposal.", "num_citations": "1\n", "authors": ["1840"]}
{"title": "SemSynX: Flexible Similarity Analysis of XML Data via Semantic and Syntactic Heterogeneity/Homogeneity Detection\n", "abstract": " In this paper we introduce and experimentally assess SemSynX, a novel technique for supporting similarity analysis of XML data via semantic and syntactic heterogeneity/homogeneity detection. Given two XML trees, SemSynX retrieves a list of semantic and syntactic heterogeneity/homogeneity matches of objects (i.e., elements, values, tags, attributes) occurring in certain paths of the trees. A local score that takes into account the path and value similarity is given for each heterogeneity/homogeneity found. A global score that summarizes the number of equal matches as well as the local scores globally is also provided. The proposed technique is highly customizable, and it permits the specification of thresholds for the requested degree of similarity for paths and values as well as for the degree of relevance for path and value matching. It thus makes possible to \u201cadjust\u201d the similarity analysis depending on\u00a0\u2026", "num_citations": "1\n", "authors": ["1840"]}
{"title": "Towards flexible similarity analysis of XML data\n", "abstract": " The problem of supporting similarity analysis of XML data is a major problem in the data fusion research area. Several approaches have been proposed in literature, but lack of flexibility represents a hard challenge to be faced-off, especially in modern Cloud Computing environments. Inspired by this motivation, we propose SemSynX, a novel technique for supporting similarity analysis of XML data via semantic and syntactic heterogeneity/homogeneity detection. SemSynX retrieves several similarity scores over input XML documents, thus enabling flexible management and \u201ccustomization\u201d of similarity tools over XML data. In particular, the proposed technique is highly customizable, and it permits the specification of thresholds for the requested degree of similarity for paths and values as well as for the degree of relevance for path and value matching. Also, selection of paths and semantics-based\u00a0\u2026", "num_citations": "1\n", "authors": ["1840"]}
{"title": "Using OWL and SWRL for the Semantic Analysis of XML Resources\n", "abstract": " In this paper we describe how to analyze the semantic content of XML documents. With this aim, XML resources are mapped into an OWL ontology and SWRL rules are used for specifying XML semantic content. We have implemented and tested the approach. The implementation is based on a semantic web library for XQuery which includes primitives for mapping XML into OWL, and for specifying and executing SWRL.", "num_citations": "1\n", "authors": ["1840"]}
{"title": "A Query Language for OWL based on Logic Programming\n", "abstract": " In this paper we investigate how to use logic programming (in particular, Prolog) as query language against OWL resources. Our query language will be able to retrieve data and meta-data about a given OWL based ontology. With this aim, firstly, we study how to define a query language based on a fragment of Description Logic, then we show how to encode the defined query language into Prolog by means of logic rules and finally, we identify Prolog goals which correspond to queries.", "num_citations": "1\n", "authors": ["1840"]}
{"title": "A Prolog-based approach for model transformation\n", "abstract": " In this paper we present a framework for using logic programming (in particular, Prolog) for specifying model transformations in the context of UML. Our approach describes how the UML metamodel can be represented in Prolog, and how model transformations can be expressed by means of Prolog rules. It uses rules for specifying queries in source models and rules for expressing how to build the target model. Therefore we can distinguish between a model query language and a model creation/update language. In addition, our approach shows how Prolog can be used for checking constraints on source and target models by means of a model verification language. Our approach will be applied to a well-known example of model transformation in which an UML class diagram representing a database (as an entity-relationship diagram) is transformed into an UML diagram representing a relational database. We\u00a0\u2026", "num_citations": "1\n", "authors": ["1840"]}