{"title": "Calculating \u03c4-Confluence Compositionally\n", "abstract": " \u03c4-confluence is a reduction technique used in enumerative model-checking of labeled transition systems to avoid the state explosion problem. In this paper, we propose a new on-the-fly algorithm to calculate partial \u03c4-confluence, and propose new techniques to do so on large systems in a compositional manner. Using information inherent in the way a large system is composed of smaller systems, we show how we can deduce partial \u03c4-confluence in a computationally cheap manner. Finally, these techniques are applied to a number of case studies, including the rel/REL atomic multicast protocol.", "num_citations": "50\n", "authors": ["1654"]}
{"title": "Evolutionary algorithms for definition extraction\n", "abstract": " Books and other text-based learning material contain implicit information which can aid the learner but which usually can only be accessed through a semantic analysis of the text. Definitions of new concepts appearing in the text are one such instance. If extracted and presented to the learner in form of a glossary, they can provide an excellent reference for the study of the main text. One way of extracting definitions is by reading through the text and annotating definitions manually\u2014a tedious and boring job. In this paper, we explore the use of machine learning to extract definitions from nontechnical texts, reducing human expert input to a minimum. We report on experiments we have conducted on the use of genetic programming to learn the typical linguistic forms of definitions and a genetic algorithm to learn the relative importance of these forms. Results are very positive, showing the feasibility of exploring further the use of these techniques in definition extraction. The genetic program is able to learn similar rules derived by a human linguistic expert, and the genetic algorithm is able to rank candidate definitions in an order of confidence.", "num_citations": "44\n", "authors": ["1654"]}
{"title": "Recovery within long-running transactions\n", "abstract": " As computer systems continue to grow in complexity, the possibility of failure increases. At the same time, the increase in computer system pervasiveness in day-to-day activities bring along increased expectations on their reliability. This has led to the need for effective and automatic error-recovery techniques to resolve failures. Transactions enable the handling of failure propagation over concurrent systems due to dependencies, restoring the system to the point before the failure occurred. However, in various settings, especially when interacting with the real world, reversal is not possible. The notion of compensations has been long advocated as a way of addressing this issue, through the specification of activities which can be executed to undo partial transactions. Still, there is no accepted standard theory; the literature offers a plethora of distinct formalisms and approaches. In this survey, we review the\u00a0\u2026", "num_citations": "42\n", "authors": ["1654"]}
{"title": "Runtime verification of ethereum smart contracts\n", "abstract": " The notion of smart contracts in distributed ledger systems have been hailed as a safe way of enforcing contracts between participating parties. However, unlike legal contracts, which talk about ideal behaviour and consequences of not adhering to such behaviour, smart contracts are by their very nature executable code, giving explicit instructions on how to achieve compliance. Executable specification languages, particularly Turing complete ones, are notoriously known for the difficulty of ensuring correctness, and recent incidents which led to huge financial losses due to bugs in smart contracts, have highlighted this issue. In this paper we show how standard techniques from runtime verification can be used in the domain of smart contracts, including a novel stake-based instrumentation technique which ensures that the violating party provides insurance for correct behaviour. The techniques we describe have been\u00a0\u2026", "num_citations": "41\n", "authors": ["1654"]}
{"title": "Alkylvm: A virtual machine for smart contract blockchain connected internet of things\n", "abstract": " Blockchain technology and the application of smart contracts allow for automation of verifiable digital processes between any number of parties. The Internet of Things (IoT) has seen great potential in the past decade to revolutionise our day-to-day lives with the aim of automating physical processes by incorporating Internet-connected devices into commodities. By integrating the IoT with blockchain systems and smart contracts it is possible to provide verifiable automation of physical processes involving different parties. The challenge lies in that due to resource constraints, many of the computational devices used within the IoT are not capable of directly interacting with blockchain implementations. In this paper, we describe and give a reference design and implementation of a split-virtual machine, AlkylVM, which allows for resource constrained IoT devices to interact with blockchain systems.", "num_citations": "36\n", "authors": ["1654"]}
{"title": "Distributed system contract monitoring\n", "abstract": " Runtime verification of distributed systems poses various challenges. A pivotal challenge is the choice of howto distribute the monitors themselves across the system.On one hand, centralised monitoringmay result in increased communication overhead and information exposure across locations, while, on the other hand, systems with dynamic topologies and properties are difficult to address using static monitor choreographies. In this paper we present mDPi, a location-aware \u03c0-calculus extension for reasoning about the distributed monitoring scenario.We also define numerousmonitoring strategies for a regular expression-based logic, including a novel approach in which monitors migrate to ensure local monitoring. Finally, we present a number of results which emerge from this formalism, justifying our approach.", "num_citations": "35\n", "authors": ["1654"]}
{"title": "polyLarva: Runtime Verification with Configurable Resource-Aware Monitoring Boundaries\n", "abstract": " Runtime verification techniques are increasingly being applied in industry as a lightweight formal approach to achieve added assurance of correctness at runtime. A key issue determining the adoption of these techniques is the overheads introduced by the runtime checks, affecting the performances of the monitored systems. Despite advancements in the development of optimisation techniques lowering these overheads, industrial settings such as online portals present new challenges, since they frequently involve the handling of high volume transaction throughputs and cannot afford substantial deterioration in the service they provide.               One approach to reduce overheads is the deployment of the verification computation on auxiliary computing resources, creating a boundary between the system and the verification code. This limits the use of system resources with resource intensive verification\u00a0\u2026", "num_citations": "32\n", "authors": ["1654"]}
{"title": "Support vector machines with profile-based kernels for remote protein homology detection\n", "abstract": " Two new techniques for remote protein homology detection particulary suited for sparse data are introduced. These methods are based on position specific scoring matrices or profiles and use a support vector machine (SVM) for discrimination. The performance on standard benchmarks outperforms previous non-discriminative techniques and is comparable to that of other SVM-based methods while giving distinct advantages.", "num_citations": "32\n", "authors": ["1654"]}
{"title": "Distributing fibre boards: a practical application of the heterogeneous fleet vehicle routing problem with time windows and three-dimensional loading constraints\n", "abstract": " The Heterogeneous Fleet Capacitated Vehicle Routing Problem with Time Windows and Three- Dimensional Loading Constraints (3L-HFCVRPTW) combines the aspects of 3D loading, heterogeneous transport with capacity constraints and time windows for deliveries. It is the first formulation that comprises all these aspects and takes its inspiration from a practical problem of distributing daily fibre board deliveries faced by our industry partner. Given the shape of the goods to transport, the delivery vehicles are customised and their loading constraints take a specialised form. This study introduces the problem and its constraints as well as a specialised procedure for loading the boards. The loading module can be called during or after the route optimisation. In this initial work, we apply simple local search procedures to the routing problem to two data sets obtained from our industry partner and subsequently employ\u00a0\u2026", "num_citations": "30\n", "authors": ["1654"]}