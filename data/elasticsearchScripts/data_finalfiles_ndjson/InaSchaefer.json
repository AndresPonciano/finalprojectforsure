{"title": "Evolution of software in automated production systems: Challenges and research directions\n", "abstract": " Coping with evolution in automated production systems implies a cross-disciplinary challenge along the system's life-cycle for variant-rich systems of high complexity. The authors from computer science and automation provide an interdisciplinary survey on challenges and state of the art in evolution of automated production systems. Selected challenges are illustrated on the case of a simple pick and place unit. In the first part of the paper, we discuss the development process of automated production systems as well as the different type of evolutions during the system's life-cycle on the case of a pick and place unit. In the second part, we survey the challenges associated with evolution in the different development phases and a couple of cross-cutting areas and review existing approaches addressing the challenges. We close with summarizing future research directions to address the challenges of evolution in\u00a0\u2026", "num_citations": "245\n", "authors": ["1506"]}
{"title": "Abstract delta modelling\n", "abstract": " Delta modelling is an approach to facilitate the automated product derivation for software product lines. It is based on a set of deltas specifying modifications that are incrementally applied to a core product. The applicability of deltas depends on application conditions over features. This paper presents abstract delta modelling, which explores delta modelling from an abstract, algebraic perspective. Compared to the previous work, we take a more flexible approach to conflicts between modifications by introducing the notion of conflict-resolving deltas. Furthermore, we extend our approach to allow the nesting of delta models for increased modularity. We also present conditions on the structure of deltas to ensure unambiguous product generation.", "num_citations": "139\n", "authors": ["1506"]}
{"title": "Incremental model-based testing of delta-oriented software product lines\n", "abstract": " Software product line (SPL) engineering provides a promising approach for developing variant-rich software systems. But, testing of every product variant in isolation to ensure its correctness is in general not feasible due to the large number of product variants. Hence, a systematic approach that applies SPL reuse principles also to testing of SPLs in a safe and efficient way is essential. To address this issue, we propose a novel, model-based SPL testing framework that is based on a delta-oriented SPL test model and regression-based test artifact derivations. Test artifacts are incrementally constructed for every product variant by explicitly considering commonality and variability between two consecutive products under test. The resulting SPL testing process is proven to guarantee stable test coverage for every product variant and allows the derivation of redundancy-reduced, yet reliable retesting obligations\u00a0\u2026", "num_citations": "107\n", "authors": ["1506"]}
{"title": "Variability Modelling for Model-Driven Development of Software Product Lines.\n", "abstract": " Model-driven development of software-intensive systems aims at designing systems by stepwise model refinement. In order to create software product lines by model-driven development, product variability has to be represented on every modelling level and preserved under model refinement. In this paper, we propose\u2206-modelling as an generally applicable variability modelling concept that is orthogonal to model refinement. Products on each modelling level are represented by a core model and a set of\u2206-models specifying changes to the core to incorporate product features. Core and\u2206-models can be refined independently to obtain a more detailed model of the product line. Based on a formalization of\u2206-modelling, we establish conditions that model refinement and model configuration commute resulting in an incremental model-driven development process.", "num_citations": "104\n", "authors": ["1506"]}
{"title": "First-class variability modeling in matlab/simulink\n", "abstract": " Modern cars exist in an vast number of variants. Thus, variability has to be dealt with in all phases of the development process, in particular during model-based development of software-intensive functionality using Matlab/Simulink. Currently, variability is often encoded within a functional model leading to so called 150%-models which easily become very complex and do not scale for larger product lines. To counter these problems, we propose a modular variability modeling approach for Matlab/Simulink based on the concept of delta modeling [8, 9, 24]. A functional variant is described by a delta encapsulating a set of modifications. A sequence of deltas can be applied to a core product to derive the desired variant. We present a prototypical implementation, which is integrated into Matlab/Simulink and offers graphical editing of delta models.", "num_citations": "88\n", "authors": ["1506"]}
{"title": "Hierarchical variability modeling for software architectures\n", "abstract": " Hierarchically decomposed component-based system development reduces design complexity by supporting distribution of work and component reuse. For product line development, the variability of the components to be deployed in different products has to be represented by appropriate means. In this paper, we propose hierarchical variability modeling which allows specifying component variability integrated with the component hierarchy and locally to the components. Components can contain variation points determining where components may vary. Associated variants define how this variability can be realized in different component configurations. We present a meta model for hierarchical variability modeling to formalize the conceptual ideas. In order to obtain an implementation of the proposed approach together with tool support, we extend the existing architectural description language MontiArc with\u00a0\u2026", "num_citations": "82\n", "authors": ["1506"]}
{"title": "From model-based design to formal verification of adaptive embedded systems\n", "abstract": " Adaptation is important in dependable embedded systems to cope with changing environmental conditions. However, adaptation significantly complicates system design and poses new challenges to system correctness. We propose an integrated model-based development approach facilitating intuitive modelling as well as formal verification of dynamic adaptation behaviour. Our modelling concepts ease the specification of adaptation behaviour and improve the design of adaptive embedded systems by hiding the increased complexity from the developer. Based on a formal framework for representing adaptation behaviour, our approach allows to employ theorem proving, model checking as well as specialised verification techniques to prove properties characteristic for adaptive systems such as stability.", "num_citations": "71\n", "authors": ["1506"]}
{"title": "Engineering delta modeling languages\n", "abstract": " Delta modeling is a modular, yet flexible approach to capture spatial and temporal variability by explicitly representing the differences between system variants or versions. The conceptual idea of delta modeling is language-independent. But, in order to apply delta modeling for a concrete language, so far, a delta language had to be manually developed on top of the base language leading to a large variety of heterogeneous language concepts. In this paper, we present a process that allows deriving a delta language from the grammar of a given base language. Our approach relies on an automatically generated language extension that can be manually adapted to meet domain-specific needs. We illustrate our approach using delta modeling on a textual variant of statecharts.", "num_citations": "64\n", "authors": ["1506"]}
{"title": "Delta modeling for software architectures\n", "abstract": " Architectural modeling is an integral part of modern software development. In particular, diverse systems benefit from precise architectural models since similar components can often be reused between different system variants. However, during all phases of diverse system development, system variability has to be considered and modeled by appropriate means. Delta modeling is a language-independent approach for modeling system variability. A set of diverse systems is represented by a core system and a set of deltas specifying modifications to the core system. In this paper, we give a first sketch of how to apply delta modeling in MontiArc, an existing architecture description language, in order to obtain an integrated modeling language for architectural variability. The developed language, MontiArc, allows the modular modeling of variable software architectures and supports proactive as well as extractive product line development.", "num_citations": "63\n", "authors": ["1506"]}
{"title": "Delta-oriented architectural variability using monticore\n", "abstract": " Modeling of software architectures is a fundamental part of software development processes. Reuse of software components and early analysis of software topologies allow the reduction of development costs and increases software quality. Integrating variability modeling concepts into architecture description languages (ADLs) is essential for the development of diverse software systems with high demands on software quality. In this paper, we present the integration of delta modeling into the existing ADL MontiArc. Delta modeling is a language-independent variability modeling approach supporting proactive, reactive and extractive product line development. We show how \u0394-MontiArc, a language for explicit modeling of architectural variability based on delta modeling, is implemented as domain-specific language (DSL) using the DSL development framework MontiCore. We also demonstrate how MontiCore's\u00a0\u2026", "num_citations": "53\n", "authors": ["1506"]}
{"title": "Verification of software product lines with delta-oriented slicing\n", "abstract": " Software product line (SPL) engineering is a well-known approach to develop industry-size adaptable software systems. SPL are often used in domains where high-quality software is desirable; the overwhelming product diversity, however, remains a challenge for assuring correctness. In this paper, we present delta-oriented slicing, an approach to reduce the deductive verification effort across an SPL where individual products are Java programs and their relations are described by deltas. On the specification side, we extend the delta language to deal with formal specifications. On the verification side, we combine proof slicing and similarity-guided proof reuse to ease the verification process.", "num_citations": "49\n", "authors": ["1506"]}
{"title": "Delta-oriented model-based integration testing of large-scale systems\n", "abstract": " Software architecture specifications are of growing importance for coping with the complexity of large-scale systems. They provide an abstract view on the high-level structural system entities together with their explicit dependencies and build the basis for ensuring behavioral conformance of component implementations and interactions, e.g., using model-based integration testing. The increasing inherent diversity of such large-scale variant-rich systems further complicates quality assurance. In this article, we present a combination of architecture-driven model-based testing principles and regression-inspired testing strategies for efficient, yet comprehensive variability-aware conformance testing of variant-rich systems. We propose an integrated delta-oriented architectural test modeling and testing approach for component as well as integration testing that allows the generation and reuse of test artifacts among\u00a0\u2026", "num_citations": "48\n", "authors": ["1506"]}
{"title": "Multi-objective test suite optimization for incremental product family testing\n", "abstract": " The design of an adequate test suite is usually guided by identifying test requirements which should be satisfied by the selected set of test cases. To reduce testing costs, test suite minimization heuristics aim at eliminating redundancy from existing test suites. However, recent test suite minimization approaches lack (1) to handle test suites commonly derived for families of similar software variants under test, and (2) to incorporate fine-grained information concerning cost/profit goals for test case selection. In this paper, we propose a formal framework to optimize test suites designed for sets of software variants under test w.r.t. multiple conflicting cost/profit objectives. The problem representation is independent of the concrete testing methodology. We apply integer linear programming (ILP) to approximate optimal solutions. We further develop an efficient incremental heuristic for deriving a sequence of representative\u00a0\u2026", "num_citations": "48\n", "authors": ["1506"]}
{"title": "Evolving delta-oriented software product line architectures\n", "abstract": " Diversity is prevalent in modern software systems. Several system variants exist at the same time in order to adapt to changing user requirements. Additionally, software systems evolve over time in order to adjust to unanticipated changes in their application environment. In modern software development, software architecture modeling is an important means to deal with system complexity by architectural decomposition. This leads to the need of architectural description languages that can represent spatial and temporal variability. In this paper, we present delta modeling of software architectures as a uniform modeling formalism for architectural variability in space and in time. In order to avoid degeneration of the product line model under system evolution, we present refactoring techniques to maintain and improve the quality of the variability model. Using a running example from the automotive domain, we\u00a0\u2026", "num_citations": "48\n", "authors": ["1506"]}
{"title": "Family model mining for function block diagrams in automation software\n", "abstract": " Automation systems are mostly individual highly customized system variants, consisting both of hardware and software. In order to reduce development effort, it is a common practice to use a clone-and-own approach by modifying an existing variant to fit the changed requirements of a new variant. The information about the commonalities and differences between those variants is usually not well documented and leads to problems in maintenance, testing and evolution. To alleviate these problems, in this paper, we present an improved version of a family mining approach for automatically discovering commonality and variability between related system variants. We apply this approach to function block diagrams used to develop automation software and show its feasibility by a manufacturing case study.", "num_citations": "46\n", "authors": ["1506"]}
{"title": "Variability modelling in the ABS language\n", "abstract": " The HATS project aims at developing a model-centric methodology for the design, implementation and verification of highly configurable systems, such as software product lines, centred around the Abstract Behavioural Specification (ABS) modelling Language. This article describes the variability modelling features of the ABS Modelling framework. It consists of four languages, namely, \u03bcTVL for describing feature models at a high level of abstraction, the Delta Modelling Language DML for describing variability of the \u2018code\u2019 base in terms of delta modules, the Product Line Configuration Language CL for linking feature models and delta modules together and the Product Selection Language PSL for describing a specific product to extract from a product line. Both formal semantics and examples of each language are presented.", "num_citations": "46\n", "authors": ["1506"]}
{"title": "Delta-oriented software product line test models-the body comfort system case study\n", "abstract": " Delta-oriented Software Product Line Test Models - The Body Comfort System Case Study - TUbiblio TUbiblio TU Darmstadt / ULB / TUbiblio Delta-oriented Software Product Line Test Models - The Body Comfort System Case Study Lity, Sascha ; Lachmann, Remo ; Lochau, Malte ; Schaefer, Ina (2013): Delta-oriented Software Product Line Test Models - The Body Comfort System Case Study. [Report] Typ des Eintrags: Report Erschienen: 2013 Autor(en): Lity, Sascha ; Lachmann, Remo ; Lochau, Malte ; Schaefer, Ina Titel: Delta-oriented Software Product Line Test Models - The Body Comfort System Case Study Sprache: Englisch Fachbereich(e)/-gebiet(e): 18 Fachbereich Elektrotechnik und Informationstechnik > Institut f\u00fcr Datentechnik > Echtzeitsysteme 18 Fachbereich Elektrotechnik und Informationstechnik 18 Fachbereich Elektrotechnik und Informationstechnik > Institut f\u00fcr Datentechnik Hinterlegungsdatum: 05 \u2026", "num_citations": "43\n", "authors": ["1506"]}
{"title": "Family-based performance analysis of variant-rich software systems\n", "abstract": " We study models of software systems with variants that stem from a specific choice of configuration parameters with a direct impact on performance properties. Using UML activity diagrams with quantitative annotations, we model such systems as a product line. The efficiency of a product-based evaluation is typically low because each product must be analyzed in isolation, making difficult the re-use of computations across variants. Here, we propose a family-based approach based on symbolic computation. A numerical assessment on large activity diagrams shows that this approach can be up to three orders of magnitude faster than product-based analysis in large models, thus enabling computationally efficient explorations of large parameter spaces.", "num_citations": "36\n", "authors": ["1506"]}
{"title": "Scaling size and parameter spaces in variability-aware software performance models (t)\n", "abstract": " In software performance engineering, what-if scenarios, architecture optimization, capacity planning, run-time adaptation, and uncertainty management of realistic models typically require the evaluation of many instances. Effective analysis is however hindered by two orthogonal sources of complexity. The first is the infamous problem of state space explosion -- the analysis of a single model becomes intractable with its size. The second is due to massive parameter spaces to be explored, but such that computations cannot be reused across model instances. In this paper, we efficiently analyze many queuing models with the distinctive feature of more accurately capturing variability and uncertainty of execution rates by incorporating general (i.e., non-exponential) distributions. Applying product-line engineering methods, we consider a family of models generated by a core that evolves into concrete instances by\u00a0\u2026", "num_citations": "33\n", "authors": ["1506"]}
{"title": "Selected challenges of software evolution for automated production systems\n", "abstract": " Automated machines and plants are operated for some decades and undergo an everlasting evolution during this time. In this paper, we present three related open evolution challenges focusing on software evolution in the domain of automated production systems, i.e. evolution and co-evolution of (interdisciplinary) engineering models and code, quality assurance as well as variant and version management during evolution.", "num_citations": "30\n", "authors": ["1506"]}
{"title": "Compositional algorithmic verification of software product lines\n", "abstract": " Software product line engineering allows large software systems to be developed and adapted for varying customer needs. The products of a software product line can be described by means of a hierarchical variability model specifying the commonalities and variabilities between the artifacts of the individual products. The number of products generated by a hierarchical model is exponential in its size, which poses a serious challenge to software product line analysis and verification. For an analysis technique to scale, the effort has to be linear in the size of the model rather than linear in the number of products it generates. Hence, efficient product line verification is only possible if compositional verification techniques are applied that allow the analysis of products to be relativized on the properties of their variation points. In this paper, we propose simple hierarchical variability models (SHVM) with explicit\u00a0\u2026", "num_citations": "30\n", "authors": ["1506"]}
{"title": "Specification and verification of dynamic communication systems\n", "abstract": " Dynamic communication systems (DCS) are complex because of their unboundedness in several dimensions. They have an unbounded and changing number of objects, a dynamically changing communication topology and unbounded message queues for asynchronous communication. We present a specification language for DCS that captures these features but is still amenable for formal verification. The verification of relevant properties of DCS is demonstrated using a combination of model-checking and abstract interpretation. Our approach is illustrated using the application domain of car platoons", "num_citations": "28\n", "authors": ["1506"]}
{"title": "Delta modeling for variant-rich and evolving manufacturing systems\n", "abstract": " Manufacturing systems exist in many different variants and evolve over time in order to meet changing requirements or environment contexts. This leads to an increased design complexity as well as to increased maintenance effort. In order to appropriately handle this inherent complexity, we propose a multi-perspective modeling approach combining UML activity, component-based and state chart diagrams to separately represent different system aspects. We combine the multi-perspective modeling approach with delta modeling to capture the variability and evolution of these manufacturing systems. Delta modeling allows a flexible, yet concise and understandable representation of variability in a modular manner. We examine our approach by applying it to a manufacturing lab demonstrator system with automated code generation from models obtained by delta application.", "num_citations": "27\n", "authors": ["1506"]}
{"title": "Delta-oriented model-based SPL regression testing\n", "abstract": " Testing software product lines by considering each product variant in isolation is impracticable due to the high number of potential product configurations. Therefore, applying SPL reuse principles also to test artifacts in a concise way is essential. We address this open issue by a novel, model-based SPL testing framework based on reusable delta-oriented state machine test models and regression-based test suite evolution. Therein, SPL test artifacts are incrementally evolved for every product variant by explicitly considering commonality and variability between two subsequent products under test. Our approach guarantees for every product configuration stable test coverage and allows the derivation of redundancy-reduced, yet reliable retesting obligations. We illustrate our framework by means of an automotive case study and compare our experimental results with alternative SPL testing strategies w.r.t. efficiency\u00a0\u2026", "num_citations": "23\n", "authors": ["1506"]}
{"title": "Security of multi-agent systems: A case study on comparison shopping\n", "abstract": " The multi-agent-systems paradigm is becoming more and more popular as a basis for realizing net-based solutions. This development is accompanied by an increasing relevance of security issues. For instance, the potential loss of privacy and other assets is a major concern for, both merchants and customers, in Internet-based commerce and, without being properly addressed, such very legitimate concerns hamper the growth of e-commerce.This article uses a comparison-shopping scenario to introduce a general methodology for formally verifying the security of multi-agent systems. Following the approach of possibilistic information flow security, the flow of information between and within agents is restricted in order to ensure that secrets will not be disclosed to unauthorized meddlers. The security requirements for the overall system are then decomposed into requirements for the individual agents that can be\u00a0\u2026", "num_citations": "22\n", "authors": ["1506"]}
{"title": "A qualitative study of variability management of control software for industrial automation systems\n", "abstract": " Software product line engineering (SPLE) provides a systematic approach to manage variants and versions arising throughout the development of software systems. While SPLE is successfully applied for variant management in the domain of software engineering, the approach is still not widely spread in industrial automated production systems (aPS). Previous studies highlight the interdisciplinary nature of aPS as a reason for not applying SPLE, since control software variants and versions also result from changes in other disciplines such as the mechanical engineering department (i.e. exchange of a sensor). Additionally, the software may evolve over decades at the customer site. In order to gain a better understanding of the challenges in the development of aPS and the constraints hindering the use of SPLE, we conducted several interviews with software development engineers from the domain of aPS. The\u00a0\u2026", "num_citations": "21\n", "authors": ["1506"]}
{"title": "Detecting and explaining conflicts in attributed feature models\n", "abstract": " Product configuration systems are often based on a variability model. The development of a variability model is a time consuming and error-prone process. Considering the ongoing development of products, the variability model has to be adapted frequently. These changes often lead to mistakes, such that some products cannot be derived from the model anymore, that undesired products are derivable or that there are contradictions in the variability model. In this paper, we propose an approach to discover and to explain contradictions in attributed feature models efficiently in order to assist the developer with the correction of mistakes. We use extended feature models with attributes and arithmetic constraints, translate them into a constraint satisfaction problem and explore those for contradictions. When a contradiction is found, the constraints are searched for a set of contradicting relations by the QuickXplain algorithm.", "num_citations": "20\n", "authors": ["1506"]}
{"title": "Fine-grained test case prioritization for integration testing of delta-oriented software product lines\n", "abstract": " Software product line (SPL) testing is a challenging task, due to the huge number of variants sharing common functionalities to be taken into account for efficient testing. By adopting the concept of regression testing, incremental SPL testing strategies cope with this challenge by exploiting the reuse potential of test artifacts between subsequent variants under test. In previous work, we proposed delta-oriented test case prioritization for incremental SPL integration testing, where differences between architecture test model variants allow for reasoning about the order of reusable test cases to be executed. However, the prioritization left two issues open, namely (1) changes to component behavior are ignored, which may also influence component interactions and,(2) the weighting and ordering of similar test cases result in an unintended clustering of test cases. In this paper, we extend the test case prioritization technique\u00a0\u2026", "num_citations": "19\n", "authors": ["1506"]}
{"title": "Higher-order delta modeling for software product line evolution\n", "abstract": " In software product lines (SPL), ie, a family of similar software systems sharing common and variable artifacts, modeling evolution and reasoning about it is challenging, as not only a single system, but rather a set of system variants as well as their interdependencies change. An integrated modeling formalism for variability and evolution is required to allow the capturing of evolution operations that are applied to SPL artifacts, and to facilitate the impact analysis of evolution on the artifact level. Delta modeling is a flexible transformational variability modeling approach, where the variability and commonality between variants are explicitly documented and analyzable by means of transformations modeled as deltas. In this paper, we lift the notion of delta modeling to capture both, variability and evolution, by deltas. We evolve a delta model specifying a set of variants by applying higher-order deltas. A higher-order delta\u00a0\u2026", "num_citations": "16\n", "authors": ["1506"]}
{"title": "Towards efficient and effective testing in automotive software development\n", "abstract": " Software systems become more and more complex and control safetycritical applications. Hence, efficient and effective testing procedures are required in order to ensure software and system quality. Automotive software engineering has particular challenges with respect to efficient and effective testing, such as black-box test scenarios, natural language specifications and highly manual testing activities. In this paper, we present six automotive testing challenges and suitable approaches to solve them. We cover uniform test case specification to remove redundancies in test cases, automatic test case selection and prioritization, test case combination, and machine learning techniques for regression test selection. The presented approaches are illustrated by a case study from the automotive domain.", "num_citations": "15\n", "authors": ["1506"]}
{"title": "Herausforderungen beim Testen von Fahrerassistenzsystemen\n", "abstract": " Moderne Fahrerassistenzsysteme (FAS) werden immer komplexer. Wegen ihres sicherheitskritischen Charakters m\u00fcssen sie ausgiebig getestet werden, um Serienreife zu erreichen. Das Testen von FAS bringt verschiedene Herausforderungen mit sich, die \u00fcberwunden werden m\u00fcssen. Wir stellen in diesem Artikel Herausforderungen aus verschiedenen Dom\u00e4nen vor und pr\u00e4sentieren L\u00f6sungsans\u00e4tze, wie diese \u00fcberwunden werden k\u00f6nnen. Die untersuchten Herausforderungen bestehen im Softwareentwicklungsprozess, der Testphase selbst sowie in der Organisation eines FAS- Entwicklungsprojekts.", "num_citations": "15\n", "authors": ["1506"]}
{"title": "Requirements-Based Delta-Oriented SPL Testing\n", "abstract": " Variability of modern software systems increases potential sources of errors and demands appropriate quality assurance strategies. In order to reduce the test effort when testing software product lines, incremental model-based testing strategies have been proposed, based on the conceptual ideas of delta modeling. It requires executable system specifications to derive and classify test cases. However, in industrial practice such system models rarely exist, but requirements and test cases are captured in natural language. In order to make delta-oriented testing strategies applicable in this context, we transfer them to the requirements level and show how a delta-oriented classification of requirements and associated test cases reduce test effort in these less formal domains.", "num_citations": "15\n", "authors": ["1506"]}
{"title": "Translation validation of system abstractions\n", "abstract": " Abstraction is intensively used in the verification of large, complex or infinite-state systems. With abstractions getting more complex it is often difficult to see whether they are valid. However, for using abstraction in model checking it has to be ensured that properties are preserved. In this paper, we use a translation validation approach to verify property preservation of system abstractions. We formulate a correctness criterion based on simulation between concrete and abstract system for a property to be verified. For each distinct run of the abstraction procedure the correctness is verified in the theorem prover Isabelle/HOL. This technique is applied in the verification of adaptive embedded systems.", "num_citations": "15\n", "authors": ["1506"]}
{"title": "Using abstraction in modular verification of synchronous adaptive systems\n", "abstract": " Self-adaptive embedded systems autonomously adapt to changing environment conditions to improve their functionality and to increase their dependability by downgrading functionality in case of fail-ures. However, adaptation behaviour of embedded systems significantly complicates system design and poses new challenges for guaranteeing system correctness, in particular vital in the automotive domain. Formal verification as applied in safety-critical applications must therefore be able to address not only temporal and functional properties, but also dynamic adaptation according to external and internal stimuli. In this paper, we introduce a formal semantic-based framework to model, specify and verify the functional and the adaptation behaviour of syn-chronous adaptive systems. The modelling separates functional and adap-tive behaviour to reduce the design complexity and to enable modular reasoning about both aspects independently as well as in combination. By an example, we show how to use this framework in order to verify properties of synchronous adaptive systems. Modular reasoning in com-bination with abstraction mechanisms makes automatic model checking efficiently applicable.", "num_citations": "15\n", "authors": ["1506"]}
{"title": "Using multi-viewpoint contracts for negotiation of embedded software updates\n", "abstract": " In this paper we address the issue of change after deployment in safety-critical embedded system applications. Our goal is to substitute lab-based verification with in-field formal analysis to determine whether an update may be safely applied. This is challenging because it requires an automated process able to handle multiple viewpoints such as functional correctness, timing, etc. For this purpose, we propose an original methodology for contract-based negotiation of software updates. The use of contracts allows us to cleanly split the verification effort between the lab and the field. In addition, we show how to rely on existing viewpoint-specific methods for update negotiation. We illustrate our approach on a concrete example inspired by the automotive domain.", "num_citations": "12\n", "authors": ["1506"]}
{"title": "Systematic synthesis of delta modeling languages\n", "abstract": " Delta modeling is a modular, yet flexible approach to capture variability by explicitly representing differences between system variants or versions. The conceptual idea of delta modeling is language-independent. But, to apply delta modeling to a concrete language, either a generic transformation language has to be used or the corresponding delta language has to be manually developed for each considered base language. Generic languages and their tool support often lack readability and specific context condition checking, since they are unrelated to the base language. In this paper, we present a process that allows synthesizing a delta language from the grammar of a given base language. Our method relies on an automatically generated language extension that can be manually adapted to meet domain-specific needs. We illustrate our method using delta modeling on a textual variant of architecture\u00a0\u2026", "num_citations": "12\n", "authors": ["1506"]}
{"title": "Integrating formal verification into the model-based development of adaptive embedded systems.\n", "abstract": " Embedded systems increasingly control safety-critical functionality in many domains. In this context, adaptation has become state-of-the art to meet the high demands on availability without additional hardware costs. However, adaptation significantly complicates system design. Model-based development is one approach to deal with the increased complexity by providing means to focus on adaptation and functionality of a system in isolation. Furthermore, formal verification of models and their properties increases reliability of adaptive systems. However, modelling concepts use a highlevel of abstraction for specifying relevant system aspects, while input for verification tools is based on low-level mathematical concepts. To alleviate this problem, this thesis presents a semantics-based integration of model-based development of adaptive embedded system with existing verification techniques. The integration uses synchronous adaptive systems as formal semantics-based intermediate representation of adaptive systems. Static analysis can be applied to check models for structural consistency. Translating formal intermediate models to input of a theorem prover facilitates verifying properties directly. In order to make models amenable to automatic verification by model checking, verification complexity is reduced by model transformations using slicing techniques in different granularities and data domain abstraction. The model transformations are formally verified to be property-preserving using translation validation. Furthermore, compositional reasoning strategies reduce the verification effort significantly by splitting the global verification task into less\u00a0\u2026", "num_citations": "12\n", "authors": ["1506"]}
{"title": "Model-based testing\n", "abstract": " Software more and more pervades our everyday lives. Hence, we have high requirements towards the trustworthiness of the software. Software testing greatly contributes to the quality assurance of modern software systems. However, as today\u2019s software system get more and more complex and exist in many different variants, we need rigorous and systematic approaches towards software testing. In this tutorial, we, first, present model-based testing as an approach for systematic test case generation, test execution and test result evaluation for single system testing. The central idea of model-based testing is to base all testing activities on an executable model-based test specification. Second, we consider model-based testing for variant-rich software systems and review two model-based software product line testing techniques. Sample-based testing generates a set of representative variants for testing, and\u00a0\u2026", "num_citations": "11\n", "authors": ["1506"]}
{"title": "Correctness-by-construction and post-hoc verification: a marriage of convenience?\n", "abstract": " Correctness-by-construction (CbC), traditionally based on weakest precondition semantics, and post-hoc verification (PhV) aspire to ensure functional correctness. We argue for a lightweight approach to CbC where lack of formal rigour increases productivity. In order to mitigate the risk of accidentally introducing errors during program construction, we propose to complement lightweight CbC with PhV. We introduce lightweight CbC by example and discuss strength and weaknesses of CbC and PhV and their combination, both conceptually and using a case study.", "num_citations": "10\n", "authors": ["1506"]}
{"title": "Towards incremental model slicing for delta-oriented software product lines\n", "abstract": " The analysis of nowadays software systems for supporting, e.g., testing, verification or debugging is becoming more challenging due to their increasing complexity. Model slicing is a promising analysis technique to tackle this issue by abstracting from those parts not influencing the current point of interest. In the context of software product lines, applying model slicing separately for each variant is in general infeasible. Delta modeling allows exploiting the explicit specification of commonality and variability within deltas and enables the reuse of artifacts and already obtained results to reduce the modeling and analysis efforts. In this paper, we propose a novel approach for incremental model slicing for delta-oriented software product lines. Based on the specification of model changes between variants by means of model regression deltas, an incremental adaptation of variant-specific dependency graphs as well as an\u00a0\u2026", "num_citations": "10\n", "authors": ["1506"]}
{"title": "Model-based verification of adaptive embedded systems under environment constraints\n", "abstract": " Model-based verification of adaptive embedded systems is a promising approach to deal with the increased complexity that adaptation imposes on system design. Properties of embedded systems typically depend on the environment in which they are deployed. Thus, the environment has to be considered for verification. In this paper, we propose a technique to verify properties of design-level models of adaptive embedded systems under environment constraints. We transfer ideas originating from assume-guarantee reasoning for Kripke structures to design-level models of adaptive embedded systems in order to reduce conditional validity checking to standard model checking.", "num_citations": "10\n", "authors": ["1506"]}
{"title": "Compositional reasoning in model-based verification of adaptive embedded systems\n", "abstract": " Formal verification of adaptive systems allows rigorously proving critical requirements. However, design-level models are in general too complex to be handled by verification tools directly. To counter this problem, we propose to reduce model complexity on design-model level in order to facilitate model-based verification. First, we transfer existing compositional reasoning techniques for foundational models used in verification tools to design-level models. Second, we develop new compositional strategies exploiting the special features of adaptive models. Based on these results, we establish a framework for modular model-based verification of adaptive systems by model checking.", "num_citations": "10\n", "authors": ["1506"]}
{"title": "Towards interdisciplinary variability modeling for automated production systems: Opportunities and challenges when applying delta modeling: A case study\n", "abstract": " Automated production systems involve multiple engineering disciplines and often operate for several decades. Therefore, in order to leverage benefits of model-based system engineering, modeling approaches must handle both multiple disciplines and variability. As a first step towards variability modeling and management, a small case study is carried out to investigate the opportunities and challenges when enhancing an interdisciplinary modeling approach with delta modeling - a technique for specifying variants and versions. The paper reflects critically its applicability, implications as well as potential beneficial impacts and discusses encouraging challenges and next steps towards an interdisciplinary approach for variability modeling and management.", "num_citations": "9\n", "authors": ["1506"]}
{"title": "Ontology-based modeling of context-aware systems\n", "abstract": " Context-aware systems aim to improve the interaction between a computer and a human being by using contextual information about the system itself, the user, and their environment. The number of relevant contextual information is expected to grow rapidly within the next years which tends to result in a complex, error-prone and hence, expensive task of programming context-aware systems. Model-based development can overcome these issues. Current approaches do not allow to model calculation of reliabilities and do not offer options to handle multiple sources of contextual information.               In this paper, we present an approach of modeling contextual information of a context-aware system using the example of a context-aware in-car infotainment system. In particular, we show how developers of context-aware in-car infotainment systems can model reliability calculations of contextual information\u00a0\u2026", "num_citations": "9\n", "authors": ["1506"]}
{"title": "Towards confidentiality-by-construction\n", "abstract": " Guaranteeing that information processed in computing systems remains confidential is vital for many software applications. To this end, language-based security mechanisms enforce fine-grained access control policies for program variables to prevent secret information from leaking through unauthorized access. However, approaches for language-based security by information flow control mostly work post-hoc, classifying programs into whether they comply with information flow policies or not after the program has been constructed. Means for constructing programs that satisfy given information flow control policies are still missing. Following the correctness-by-construction approach, we propose a development method for specifying information flow policies first and constructing programs satisfying these policies subsequently. We replace functional pre- and postcondition specifications with confidentiality\u00a0\u2026", "num_citations": "8\n", "authors": ["1506"]}
{"title": "Clustering variation points in matlab/simulink models using reverse signal propagation analysis\n", "abstract": " Model-based languages such as MATLAB/Simulink play an essential role in the model-driven development of software systems. During their development, these systems can be subject to modification numerous times. For large-scale systems, to manually identify performed modifications is infeasible. However, their precise identification and subsequent validation is essential for the evolution of model-based systems. If not fully identified, modifications may cause unaccountable behavior as the system evolves and their redress can significantly delay the entire development process. In this paper, we propose a fully automated technique called Reverse Signal Propagation Analysis, which identifies and clusters variations within evolving MATLAB/Simulink models. With each cluster representing a clearly delimitable variation point between models, we allow model engineers not only to specifically focus on\u00a0\u2026", "num_citations": "8\n", "authors": ["1506"]}
{"title": "Constraint-oriented variability modeling\n", "abstract": " Traditional syntax-oriented variability modeling specifies the set of possible system variants by explicitly describing how variability is expressed by linguistic means and it concentrates on the set of features that may or may not be present in a product. In contrast, constraint-based variability modeling defines variability in a top-down way by restricting the set of possible compositions of reusable artifacts in terms of properties and by including in this declarative description also some behavioral knowledge the experts may have about the product. Concretely, we propose here to integrate constraint-based solution space variability modeling with feature-oriented problem space variability modeling. This new approach paves the way to significantly simplify feature-oriented software development of product lines: Each feature is described by a set of constraints capturing what the feature contributes to a product variant and\u00a0\u2026", "num_citations": "8\n", "authors": ["1506"]}
{"title": "Towards verification as a service\n", "abstract": " Modern software systems are highly configurable and evolve over time. Simultaneously, they have high demands on their correctness and trustworthiness. Formal verification technique are a means to ensure critical system requirements, but still require a lot of computation power and manual intervention. In this paper, we argue that formal verification processes can be cast as workflows known from business process modeling. Single steps in the verification process constitute verification tasks which can be flexibly combined to verification workflows. The verification tasks can be carried out using designated services which are provided by highly scalable computing platforms, such as cloud computing environments. Verification workflows share the characteristics of business processes such that well-established results and tool support from workflow modeling, management and analysis are directly\u00a0\u2026", "num_citations": "8\n", "authors": ["1506"]}
{"title": "Analyzing variability in automation software with the variability analysis toolkit\n", "abstract": " Control software for automated production systems (aPs) becomes increasingly complex as it evolves due to changing requirements. To address varying customer demands or altered regulatory guidelines, it is common practice to create a new system variant by copying and subsequently modifying existing control software. Referred to as clone-and-own, proper documentation is typically not cherished, thereby entailing severe maintenance issues in the long-run. To mitigate such problems and to reinstate sustainable development, respective software systems need to be compared and their variability information needs to be reverse-engineered. However, recent work identified variability management in the domain of aPs to remain a challenging endevour and appropriate tool support to be missing.", "num_citations": "7\n", "authors": ["1506"]}
{"title": "Dependable ADAS by combining design time testing and runtime monitoring\n", "abstract": " The increasing degree of the complexity of advanced driver assistance systems (ADAS) requires sound, but efficient methods to ensure the ADAS\u2019dependability. Common vehicle field tests cannot fully guarantee the system\u2019s dependability, since they need too many miles to be driven in order to prove that the system is safe. Modern test and simulation environments only verify a part of the real situations the system encounters. In order to ensure the dependability of ADAS, we propose the combination of design time testing and runtime monitoring. The test cases, which are successfully executed at design-time, are transferred to runtime monitoring in order to verify if the system remains within its tested and safe behaviour. Otherwise, no guarantees about the dependability of the vehicle can be given. We will evaluate our approach with an advanced lane changing assistance system.", "num_citations": "7\n", "authors": ["1506"]}
{"title": "A hierarchical variability model for software product lines\n", "abstract": " A key challenge in software product line engineering is to represent solution space variability in an economic, yet easily understandable fashion. We introduce the notion of hierarchical variability models to describe families of products in a manner that facilitates their modular design and analysis. In this model, a family is represented by a common set of artifacts and a set of variation points with associated variants. A variant is again a hierarchical variability model, leading to a hierarchical structure. These models, however, are not unique with respect to the families they define. We therefore propose a quantitative measure on hierarchical variability models that expresses the degree to which a variability model captures commonality and variability in a family. Further, by imposing well-formedness constraints, we identify a class of variability models that, by construction, have maximal measure and are unique\u00a0\u2026", "num_citations": "7\n", "authors": ["1506"]}
{"title": "Model-based development of an adaptive vehicle stability control system\n", "abstract": " Safety and availability are major requirements for embedded systems in modern vehicles. However, in the automotive domain, neither conventional shutdown mechanisms nor full-fledged redundancy are appropriate means for handling faults such as failures of sensors and actuators. A suitable means for achieving the high requirements on safety and availability at low costs is graceful degradation by adapting the functionality of a system to the current driving situation and the available resources. However, adaptation significantly complicates the development of embedded systems. In this paper, we present an approach to the model-based design of adaptive embedded systems that allows coping with the increased complexity posed by adaptation. Furthermore, we show how the obtained models can be formally verified and demonstrate the feasibility of our approach by applying it to a vehicle stability control system.", "num_citations": "7\n", "authors": ["1506"]}
{"title": "Experience Report on Formally Verifying Parts of OpenJDK's API with KeY\n", "abstract": " Deductive verification of software has not yet found its way into industry, as complexity and scalability issues require highly specialized experts. The long-term perspective is, however, to develop verification tools aiding industrial software developers to find bugs or bottlenecks in software systems faster and more easily. The KeY project constitutes a framework for specifying and verifying software systems, aiming at making formal verification tools applicable for mainstream software development. To help the developers of KeY, its users, and the deductive verification community, we summarize our experiences with KeY 2.6.1 in specifying and verifying real-world Java code from a users perspective. To this end, we concentrate on parts of the Collections-API of OpenJDK 6, where an informal specification exists. While we describe how we bridged informal and formal specification, we also exhibit accompanied challenges that we encountered. Our experiences are that (a) in principle, deductive verification for API-like code bases is feasible, but requires high expertise, (b) developing formal specifications for existing code bases is still notoriously hard, and (c) the under-specification of certain language constructs in Java is challenging for tool builders. Our initial effort in specifying parts of OpenJDK 6 constitutes a stepping stone towards a case study for future research.", "num_citations": "6\n", "authors": ["1506"]}
{"title": "Supporting commissioning of production plants by model-based testing and model learning\n", "abstract": " During the commissioning phase of production systems the identification and correction of malfunctions is a tedious task mainly done manually by commissioning engineers. This task is of high importance because missed malfunctions may result in hazardous behavior during operation phase. At this point, regardless of the engineers expertise a systematic support can drastically decrease the risk of missed malfunctions. A promising systematic approach is to use engineering artifacts of the system design phase as an information source to identify unexpected behavior regarding the specification. This paper proposes such a systematic approach based on model-based testing resulting in automatic test case generation and execution which allows to support engineers with learned models representing the expected transient system behavior. Subsequently, the obtained models are used for detection of unexpected\u00a0\u2026", "num_citations": "6\n", "authors": ["1506"]}
{"title": "Towards a family-based analysis of applicability conditions in architectural delta models\n", "abstract": " Modeling variability in software architectures is a fundamental part of software product line development. ?-MontiArc allows describing architectural variability in a modular way by a designated core architecture and a set of architectural delta models modifying the core architecture to realize other architecture variants. Delta models have to satisfy a set of applicability conditions for the definedness of the architectural variants. The applicability conditions can in principle be checked by generating all possible architecture variants, which requires considering the same intermediate architectures repeatedly. In order to reuse previously computed architecture variants, we propose a family-based analysis of the applicability conditions using the concept of inverse deltas.", "num_citations": "6\n", "authors": ["1506"]}
{"title": "Product Configuration in the Wild: Strategies for Conflicting Decisions in Web Configurators.\n", "abstract": " Customization is omnipresent in our everyday live. There are web configurators to customize cars, trucks, bikes, computers, clothes, furniture, and food. At first glance, customization using configurators appears trivial; we simply select the configuration options that we want. However, in practice, options are usually dependent on each other. Reasons for dependencies are manifold and are typically specific for the particular domain. Dependencies can be simple, such as one option requiring or excluding another option, but also arbitrarily complex, involving numerous options. In this study, we aim to understand how today\u2019s web configurators support users in their decision making process. In particular, we are interested in understanding how configurators handle decisions that are in conflict with dependencies. To abstract from different visualizations, we classify the existing strategies of web configurators and discuss advantages and disadvantages of them. While we identified eight strategies, a single configurator typically uses several of those strategies.", "num_citations": "5\n", "authors": ["1506"]}
{"title": "Correctness-by-Construction  Taxonomies  Deep Comprehension of Algorithm Families\n", "abstract": " Correctness-by-construction (CbC) is an approach for developing algorithms inline with rigorous correctness arguments. A high-level specification is evolved into an implementation in a sequence of small, tractable refinement steps guaranteeing the resulting implementation to be correct. CbC facilitates the design of algorithms that are more efficient and more elegant than code that is hacked into correctness. In this paper, we discuss another benefit of CbC, i.e., that it supports the deep comprehension of algorithm families. We organise the different refinements of the algorithms carried out during CbC-based design in a taxonomy. The constructed taxonomy provides a classification of the commonality and variability of the algorithm family and, hence, provides deep insights into their structural relationships. Such taxonomies together with the implementation of the algorithms as toolkits provide an excellent\u00a0\u2026", "num_citations": "5\n", "authors": ["1506"]}
{"title": "Towards Reducing the Complexity of Enterprise Architectures by Identifying Standard Variants Using Variability Mining\n", "abstract": " For decades, Enterprise Architectures (EAs) of car manufacturers have been constantly evolved to respond to growing requirements. As a consequence, EAs have often reached a very high level of complexity, which leads to problems in adapting EAs to new environmental conditions. Such a new condition is, for instance, digitalization of society (e.g., social media, Internet of Things) which has a huge effect on the automotive industry and the grown EA. Resulting changes in complex EAs have long implementation cycles, require enormous communication efforts, and lead to high development costs. To alleviate these problems, in this paper, we present a concept to reduce the complexity of grown EAs by adapting the Family Mining approach. This approach is originally used to compare block-oriented models, such as MATLAB/Simulink models, and to identify commonalities and differences between these models. In our concept, we utilize the Family Mining approach to analyze the variability of a particular EA and to identify the contained variants. All information about the variability and the variants will be used to derive standard variants representing default solutions for different issues. Using these standard variants, the existing EA will be restructured involving economic considerations (e.g., which standard variant yields best benefits under certain circumstances). Hence, applying this concept to a complex EA should allow reducing the complexity of the EA, alleviating related problems and making suitable design decisions for future extensions.", "num_citations": "5\n", "authors": ["1506"]}
{"title": "Model-based development and performance analysis for evolving manufacturing systems\n", "abstract": " Manufacturing systems and their control software exhibit a large number of variants, which evolve over time in order to meet changing functional and non-functional requirements. To handle the resulting complexity, we propose a multi-perspective modeling approach with different viewpoints regarding workflow, architecture and component behavior. We combine it with delta modeling to seamlessly capture variability and evolution by the same means on each of the viewpoints. We show how the separation in different viewpoints enables early performance analysis as well as code generation. The approach is illustrated using a case study.", "num_citations": "5\n", "authors": ["1506"]}
{"title": "Secure mobile multiagent systems in virtual marketplaces: a case study on comparison shopping\n", "abstract": " The growth of the Internet has deeply influenced our daily lives as well as our commercial structures. Agents and multiagent systems will play a major role in the further development of Internet-based applications like virtual marketplaces. However, there is an increasing awareness of the security problems involved. These systems will not be successful until their problems are solved. This report examines comparison shopping, a virtual marketplace scenario and an application domain for a mobile multiagent system, with respect to its security issues. The interests of the participants in the scenario, merchants and clients, are investigated. Potential security threats are identified and security objectives counteracting those threats are established. These objectives are refined into building blocks a secure multiagent system should provide. The building blocks are transformed into features of agents and executing platforms. Originating from this analysis, solutions for the actual implementation of these building blocks are suggested. It is pointed out under which assumptions it is possible to achieve the security goals, if at all.", "num_citations": "5\n", "authors": ["1506"]}
{"title": "Visualization of variability analysis of control software from industrial automation systems\n", "abstract": " Industrial automated production systems are mechatronic and long living systems that undergo changing requirements throughout their life cycle. While the proportion of functionality implemented by software is growing, adjustments are usually implemented using a clone-and-own principle, which results in unmanaged software variants and versions. Furthermore, the need for adapting the control software also results from changes in other disciplines such as mechanical or electrical/electronics. The various drawbacks on software maintainability, that are provoked through clone-andown, call for a shift to modular development. As a first step to realize this migration, software projects need to be analyzed in terms of variability. Secondly, visualization patterns reflecting variability are needed to present the analysis results to domain experts. However, choosing an appropriate visualization is challenging as different\u00a0\u2026", "num_citations": "4\n", "authors": ["1506"]}
{"title": "Applying Higher-Order Delta Modeling for the Evolution of Delta-Oriented Software Product Lines\n", "abstract": " In this technical report, we define and document the evolution of four delta-oriented software product lines based on the application of higher-order delta modeling. Higher-order delta modeling is a variability modeling technique for capturing the variability and evolution of a variant-rich system by the same means, where di erences between variants and versions of variants are specified in terms of (higher-order) deltas. For every product line, we describe the complete evolution history including the original version and the higher-order deltas specifying the respective evolution steps. As underlying modeling formalism, we use finite state machines.", "num_citations": "4\n", "authors": ["1506"]}
{"title": "Incremental consistency checking in delta-oriented uml-models for automation systems\n", "abstract": " Automation systems exist in many variants and may evolve over time in order to deal with different environment contexts or to fulfill changing customer requirements. This induces an increased complexity during design-time as well as tedious maintenance efforts. We already proposed a multi-perspective modeling approach to improve the development of such systems. It operates on different levels of abstraction by using well-known UML-models with activity, composite structure and state chart models. Each perspective was enriched with delta modeling to manage variability and evolution. As an extension, we now focus on the development of an efficient consistency checking method at several levels to ensure valid variants of the automation system. Consistency checking must be provided for each perspective in isolation, in-between the perspectives as well as after the application of a delta.", "num_citations": "4\n", "authors": ["1506"]}
{"title": "Modelling Adaptable Distributed Object Oriented Systems Using the HATS Approach: A Fredhopper Case Study\n", "abstract": " The HATS project aims at developing a model-centric engineering methodology for the design, implementation and verification of distributed, concurrent and highly configurable systems. Such systems also have high demands on their dependability and trustworthiness. The HATS approach is centered around the Abstract Behavioural Specification modelling language (ABS) and its accompanying tools suite. The HATS approach allows the precise specification and analysis of the abstract behaviour of distributed software systems and their variability. The HATS project measures its success by applying its framework not only to toy examples, but to real industrial scenarios. In this paper, we evaluate the HATS approach for modelling an industrial scale case study provided by the eCommerce company Fredhopper. In this case study we consider Fredhopper Access Server (FAS). We model the commonality and\u00a0\u2026", "num_citations": "4\n", "authors": ["1506"]}
{"title": "Special issue on engineering collaborative embedded systems\n", "abstract": " Welcome to the special issue on \u201cCollaborative Embedded Systems\u201d(CrESt). While in the old days software in embedded systems was isolated and mainly concentrating on predefined functionalities within the overall system context, software has now become the connecting factor between cooperating systems of systems and, because of its increasing functionality, also the driving complexity factor. Cyber-physical systems are composed of several autonomous individual systems, which have to collaborate in order to achieve common objectives. Collaboration of systems is necessarily based on collaboration of connected software components that control and govern the overall cyber-physical system behaviour. In this context, the German ministry of research and education (BMBF) launched a large research initiative on development methods for collaborative embedded systems. The CrESt project (2017\u20132020\u00a0\u2026", "num_citations": "3\n", "authors": ["1506"]}
{"title": "Re-engineering automation systems as dynamic software product lines\n", "abstract": " Software engineering is an important development task in the automation domain due to the increasing number of embedded systems applied for controlling various system functions. In general, those automation systems are highly configurable, but share common functionality and engineering artifacts. If the knowledge about commonality and variability is not taken into account, this would result in a separate development process for each new system without reusing engineering artifacts. Software product line engineering is a promising approach for the development of highly configurable automation systems explicitly exploiting the knowledge about commonality and variability. In addition to the specification of the problem space, ie, all possible system configurations derivable from a feature model, reusable engineering artifacts are defined in the solution space by incorporating variability mechanisms. In this paper, we describe the re-engineering of an existing family of automation systems, a medical device for a novel radiotherapy, ie, as a software product line. According to the concepts of software product line engineering, we describe (1) how we created a corresponding feature model for the problem space specification, and (2) how we integrated variability modeling into existing engineering artifacts. We provide details about our real-world case study and further explain the adaptation of its re-engineered version as dynamic software product line allowing for re-configuration at runtime.", "num_citations": "3\n", "authors": ["1506"]}
{"title": "Brief announcement: towards modular verification of stabilisation in self-adaptive embedded systems\n", "abstract": " We introduce a formal semantic-based modelling framework to model, specify and verify the functional and adaptive behaviour of synchronous adaptive systems.", "num_citations": "3\n", "authors": ["1506"]}
{"title": "Variant and Product Line Co-Evolution\n", "abstract": " Individual collaborative embedded systems (CESs) in a collaborative system group (CSG) are typically provided by different manufacturers. Variability in such systems is pivotal for deploying a CES in different CSGs and environments. Changing requirements may entail the evolution of a CES. Such changed requirements can be manifold: individual variants of a CES are updated to fix bugs, or the manufacturer changes the entire CES product line to provide new capabilities. Both types of evolution, the variant evolution and the product line evolution, may be performed in parallel. However, neither type of evolution should lead to diverging states of CES variants and the CES product line, otherwise both would be incompatible, it would not be possible to update the CES variants, and it would not be possible to reuse bug fixes of an individual variant for the entire product line. To avoid this divergence, we present\u00a0\u2026", "num_citations": "2\n", "authors": ["1506"]}
{"title": "Reengineering Workflow for Planned Reuse of IEC 61131-3 Legacy Software\n", "abstract": " In automated production systems, an increasing proportion of functionality is implemented by control software. However, currently most companies do not implement variant and version management for their control software and, thus, lack a global knowledge base on existing software variants and versions. Further, despite its known drawbacks, i.e., low maintainability, the reuse strategy copy, paste & modify is commonly applied, leading to an even higher amount of unmanaged, historically grown software variants and versions. Since the resulting control software contains a vast amount of essential domain knowledge, strategies for its planned reuse are required. Therefore, this paper presents a workflow to enable the transfer from copy, paste & modify to planned reuse by analyzing the historically grown control software variants and deriving reusable library modules from them. For the library module development\u00a0\u2026", "num_citations": "2\n", "authors": ["1506"]}
{"title": "Change analysis on evolving PLC software in automated production systems\n", "abstract": " Control software for automated Production Systems (aPSs) becomes increasingly complex. Respective systems undergo constant evolution. Yet, proper documentation may not always be present, entailing maintenance issues in the long run. While manual examination of software for aPSs is an error-prone task, static analysis can improve system quality. However, it has not been applied to describe software evolution by means of changed systems artifacts. The authors address this issue and perform change analyses on IEC61131-3 projects, identifying introduced and removed systems artifacts as well as existing ones affected. By that, the authors aim to support sustainable evolution. Two feasibility studies, implemented independently, but for the same evolution scenarios for an automation plant, are used for evaluation. The technique is shown to be efficient and highly precise.", "num_citations": "2\n", "authors": ["1506"]}
{"title": "Variant Management and Reuse\n", "abstract": " Variability management and reuse are important concerns in the development of variant-rich software-intensive systems. In this chapter, we present the SPES XT modeling framework's mechanism to capture the orthogonal concern of variability.", "num_citations": "2\n", "authors": ["1506"]}
{"title": "Towards interdisciplinary variability modeling for automated production systems\n", "abstract": " Automated Production Systems involve multiple engineering disciplines and often operate for several decades. Therefore, in order to leverage benefits of model-based system engineering, modeling approaches must handle both multiple disciplines and variability. As a first step towards variability modeling and management, a small case study is carried out to investigate the opportunities and challenges when enhancing an interdisciplinary modeling approach with delta modeling--a technique for spec...\u00bb", "num_citations": "2\n", "authors": ["1506"]}
{"title": "Fomal methods and analyses in software product line engineering\n", "abstract": " Software product line engineering (SPLE) [5,11] aims to develop a family of software-intensive systems via systematic, large-scale reuse in order to reduce time-to-market and costs and to increase the quality of individual products. In order to achieve these goals, formal methods offer promising analysis techniques, which are best applied throughout the product-line lifecycle so as to maximize their overall efficiency and effectiveness.", "num_citations": "2\n", "authors": ["1506"]}
{"title": "Konzepte zur Erweiterung des SPES Meta-Modells um Aspekte der Variabilit\u00e4ts-und Deltamodellierung\n", "abstract": " In diesem Beitrag werden Konzepte zur Erweiterung eines mehrperspektivischen Meta-Modells (am Beispiel des SPES Meta-Modells) um Aspekte der Variabilit\u00e4tsmodellierung durch das Konzept der Delta-Modellierung vorgestellt. Die Konzepte werden exemplarisch anhand der logischen und der funktionalen Perspektive des SPES Meta-Modells illustriert. Die vorgestellten Konzepte k\u00f6nnen ohne Weiteres auch auf die Anforderungsund die technische Perspektive angewendet werden. Eine Besonderheit dabei sind die Cross-Cutting-Deltas. Diese gruppieren Deltas der einzelnen Perspektiven und erm\u00f6glichen somit Deltas \u00fcber mehrere Perspektiven hinweg.", "num_citations": "2\n", "authors": ["1506"]}
{"title": "Supporting agile software development by natural language processing\n", "abstract": " Agile software development puts more emphasis on working programs than on documentation. However, this may cause complications from the management perspective when an overview of the progress achieved within a project needs to be provided. In this paper, we outline the potential for applying natural language processing (NLP) in order to support agile development. We point out that using NLP, the artifacts created during agile software development activities can be traced back to the requirements expressed in user stories. This allows determining how far the project has progressed in terms of realized requirements.", "num_citations": "2\n", "authors": ["1506"]}
{"title": "Integration of UVL in FeatureIDE\n", "abstract": " Variability models are prevalent for specifying the commonalities and variabilities of configurable systems. A large variety of tools support using, editing, and analyzing variability models. However, the different tools often depend on distinct textual notations to store and read variability models which induces a large effort for researchers and practitioners. This additional effort could be reduced if the community adopted a single format. Following the goal of the MODEVAR initiative to develop a widely adopted variability language, we provided a first proposal with the Universal Variability language (UVL) in previous work. For a textual format to be adopted, an important aspect is an as small as possible effort when integrating the format in other tools. In this work, we discuss the integration of UVL in FeatureIDE. We use the integration to examine the applicability of UVL and our parser library to existing tools and gather\u00a0\u2026", "num_citations": "1\n", "authors": ["1506"]}
{"title": "Correctness-by-construction for feature-oriented software product lines\n", "abstract": " Software product lines are increasingly used to handle the growing demand of custom-tailored software variants. They provide systematic reuse of software paired with variability mechanisms in the code to implement whole product families rather than single software products. A common domain of application for product lines are safety-critical systems, which require behavioral correctness to avoid dangerous situations in-field. While most approaches concentrate on post-hoc verification for product lines, we argue that a stepwise approach to create correct programs may be beneficial for developers to manage the growing variability. Correctness-by-construction is such a stepwise approach to create programs using a set of small, tractable refinement rules that guarantee the correctness of the program with regard to its specification. In this paper, we propose the first approach to develop correct-by-construction\u00a0\u2026", "num_citations": "1\n", "authors": ["1506"]}
{"title": "Scaling correctness-by-construction\n", "abstract": " The correctness-by-construction paradigm allows developers to derive formally correct programs from a pair of first-order precondition and postcondition. Although tool support has been proposed recently, and thus correctness-by-construction has left the period of pen-and-paper proofs, it is still applied in an unstructured manner to independent algorithmic problems only. To scale correctness-by-construction to more complex programs and to establish a repository of reusable off-the-shelf components, we present a formal framework and open-source tool support called ArchiCorC. In ArchiCorC, a developer models UML-style software components comprising required and provided interfaces, where methods contained in interfaces are associated to specification contracts and mapped to correct-by-construction implementations. We describe our proposed mathematical model for the horizontal and vertical\u00a0\u2026", "num_citations": "1\n", "authors": ["1506"]}
{"title": "Automated Verification of Embedded Control Software\n", "abstract": " Embedded control software is used in a variety of industries, such as in the automotive and railway domains, or in industrial automation and robotization. The development of such software is subject to tight time-to-market requirements, but at the same time also to very high safety requirements posed by various safety standards. To assure the latter, formal methods such as model-based testing and formal verification are increasingly used. However, the main obstacle to a more wide-scale adoption of these methods, and especially of formal verification, is the currently relative low level of automation of the verification process and integration in the general software development cycle. At present, writing formal specifications and annotating the embedded code is still a highly labour intensive activity requiring special competence and skills. In this track we address this challenge from various angles. We start by\u00a0\u2026", "num_citations": "1\n", "authors": ["1506"]}
{"title": "Risk-based compatibility analysis in automotive systems engineering\n", "abstract": " Software is the new leading factor for innovation in the automotive industry. With the increase of software in road vehicles new business models, such as after-sale updates (ie, Function-on-Demand) and Over-the-Air-Updates come into focus of manufacturers. When updating a road vehicle in the field, it is required to ensure functional safety. An update shall not influence existing functionality and break its safety. Hence, it must be compatible with the existing software. The compatibility of an update is ensured by testing. However, testing all variants of a highly configurable system, such as a modern car's software, is infeasible, due to the combinatorial explosion. To address this problem, in this paper, we propose a risk-based change-impact analysis to identify system variants relevant for retesting after an update. We combine existing concepts from product sampling, risk-based testing, and configuration prioritization\u00a0\u2026", "num_citations": "1\n", "authors": ["1506"]}
{"title": "Variability Visualization of IEC 61131-3 Legacy Software for Planned Reuse\n", "abstract": " Automated production systems (aPS) are variant-rich, design-to-order systems and an increasing proportion of their functionality is implemented by control software. In control software development, software reuse is still commonly performed via clone-and-own despite many drawbacks, e.g., copying errors. This unplanned reuse leads to a high amount of historically grown software variants, which contain valuable domain expertise. Therefore, to enable planned reuse of existing control software solutions, an analysis of legacy software, inducing documentation of identified variability, is required. While so-called Software Product Lines enable the documentation of variability, they lack suitable variability visualization tailored to the needs of aPS stakeholders such as application or module developers. To address this gap, this paper introduces a variability visualization concept tailored to the needs of aPS stakeholders\u00a0\u2026", "num_citations": "1\n", "authors": ["1506"]}
{"title": "A Personal History of Delta Modelling\n", "abstract": " Delta modelling is a transformational approach to represent variability of software systems through change operations to transform one software variant to another variant realizing different functionality. The term delta for a container of those change operations was coined by Arnd Poetzsch-Heffter in early 2009. This article gives a personal account of the achievements in delta modelling since then by a collection of quotes from collaborators, students and friends.", "num_citations": "1\n", "authors": ["1506"]}
{"title": "Many-MADFAct: Concurrently Constructing MADFAs.\n", "abstract": " Minimal acyclic deterministic finite automata (MADFAs) are used to represent dictionaries, ie, finite sets of finite words, in, eg, spell checkers and network security applications. Given the size of such dictionaries, which may contain millions of words, their efficient construction is a critical issue. Watson [31] published a classification of such algorithms in an algorithm taxonomy with correctness arguments. We report on a new algorithm which constructs MADFAs in parallel\u2014each for a keyword set from a partition of the original keyword set\u2014and afterwards merges and minimizes the resulting automata into a single MADFA; on our experience implementing the algorithms in a Java-based toolkit; and on empirical performance results obtained.", "num_citations": "1\n", "authors": ["1506"]}
{"title": "Towards an Expert System for Identifying and Reducing Unnecessary Complexity of IT Architectures\n", "abstract": " Over the course of time, IT architectures in business environments grow and often include a range of different architectural variants. This causes various redundancies and a high level of IT complexity leading to higher costs and increased effort for evolving and maintaining the entire IT landscape. In this paper, we propose a concept for a rule based system that analyzes the variability within IT architectures automatically and supports experts in identifying and reducing the architecture\u2019s complexity by eliminating unnecessary architectural variants.", "num_citations": "1\n", "authors": ["1506"]}
{"title": "A methodology for hierarchical multidisciplinary modeling and analysis of mechatronic systems\n", "abstract": " Mechatronic systems as a combination of the disciplines mechanical engineering, electrical engineering, and software engineering offer extensive new capabilities for systems design. However, this class of systems also introduces massive complexity due to size and heterogeneity. Existing development approaches either only handle this complexity for single disciplines such that they lack support for crossdiscipline properties, or require the involved disciplines to utilize completely new modeling formalisms ignoring widely accepted formalisms and tools within this discipline. In this work, we propose a methodology to enable analyses of non-functional cross-discipline properties. Therefore, existing discipline-specific models and methods are reused by interfacing them to different abstract models of the system, depending on the type of property to be examined. These abstractions of domain-specific models are integrated into a holistic development process, both reducing complexity and enabling overall analyses of cross-discipline properties.", "num_citations": "1\n", "authors": ["1506"]}