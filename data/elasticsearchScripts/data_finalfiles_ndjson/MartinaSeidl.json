{"title": "UML@ classroom: An introduction to object-oriented modeling\n", "abstract": " The challenges in today\u2019s software development are diverse and go far beyond implementation tasks. They range from requirement specification over system design and implementation to maintenance and further adaptation of the software\u2014to name just a few phases in the software life cycle. In all of these phases of the software development process, many people with different backgrounds and experiences are usually involved. These people need a common language for efficient communication. Obviously, such a language should be as precise as possible without the ambiguities of a natural language. For this purpose, modeling languages have emerged. They are used to create sketches and blueprints for software systems, which in turn serve as a basis for the implementation or even automatic generation of executable code. In the area of object-oriented software development, the Unified Modeling Language\u00a0\u2026", "num_citations": "100\n", "authors": ["682"]}
{"title": "A posteriori operation detection in evolving software models\n", "abstract": " As every software artifact, also software models are subject to continuous evolution. The operations applied between two successive versions of a model are crucial for understanding its evolution. Generic approaches for detecting operations a posteriori identify atomic operations, but neglect composite operations, such as refactorings, which leads to cluttered difference reports.To tackle this limitation, we present an orthogonal extension of existing atomic operation detection approaches for detecting also composite operations. Our approach searches for occurrences of composite operations within a set of detected atomic operations in a post-processing manner. One major benefit is the reuse of specifications available for executing composite operations also for detecting applications of them. We evaluate the accuracy of the approach in a real-world case study and investigate the scalability of our implementation in\u00a0\u2026", "num_citations": "60\n", "authors": ["682"]}
{"title": "Matching Metamodels with Semantic Systems-An Experience Report.\n", "abstract": " Ontology and schema matching are well established techniques, which have been applied in various integration scenarios, eg, web service composition and database integration. Consequently, matching tools enabling automatic matching of various kinds of schemas with various matching techniques are available. In the field of model-driven engineering, in contrast to schema and ontology integration, the integration of modeling languages relies on manual tasks such as writing model transformation code, which is tedious and error-prone. Therefore, we propose the application of ontology and schema matching techniques for automatically exploring semantic correspondences between metamodels, which are currently the modeling language definitions of choice. The main focus of this paper is on reporting preliminary results and lessons learned by evaluating currently available ontology matching tools for their metamodel matching potential.", "num_citations": "57\n", "authors": ["682"]}
{"title": "Comparing different prenexing strategies for quantified boolean formulas\n", "abstract": " The majority of the currently available solvers for quantified Boolean formulas (QBFs) process input formulas only in prenex conjunctive normal form. However, the natural representation of practicably relevant problems in terms of QBFs usually results in formulas which are not in a specific normal form. Hence, in order to evaluate such QBFs with available solvers, suitable normal-form translations are required. In this paper, we report experimental results comparing different prenexing strategies on a class of structured benchmark problems. The problems under consideration encode the evaluation of nested counterfactuals over a propositional knowledge base, and span the entire polynomial hierarchy. The results show that different prenexing strategies influence the evaluation time in different ways across different solvers. In particular, some solvers are robust to the chosen strategies while others are not.", "num_citations": "55\n", "authors": ["682"]}
{"title": "Why model versioning research is needed!? an experience report\n", "abstract": " The status of current model-driven engineering technologies has matured over the last years whereas the infrastructure supporting model management is still in its infancy. Infrastructural means include version control systems, which are successfully used for the management of textual artifacts like source code. Unfortunately, they are only limited suitable for models. Consequently, dedicated solutions emerge. These approaches are currently hard to compare, because no common quality measure has been established yet and no structured test cases are available. In this paper, we analyze the challenges coming along with merging different versions of one model and derive a first categorization of typical changes and the therefrom resulting conflicts. On this basis we create a set of test cases on which we apply state-of-the-art versioning systems and report our experiences.", "num_citations": "52\n", "authors": ["682"]}
{"title": "We can work it out: Collaborative conflict resolution in model versioning\n", "abstract": " For the versioning of code a pantheon of version control system (VCS) solutions has been realized and is successfully applied in practice. Nevertheless, when it comes to merging two different versions of one artifact, the resolution of conflicts poses a major challenge. In standard systems, the developer who performs the later commit is sole in charge of this often time-consuming, error-prone task. This commit carries the inherent danger of losing the modifications of the other developer. Recently, collaborative merge approaches for code versioning systems have been proposed to minimize this risk. In this paper we propose to apply similar techniques in the context of model versioning where the challenge of merging two versions is even more formidable due to their graph-structure and their rich semantics. In particular, modeling is used in the early phases of the software development, where a collaborative\u00a0\u2026", "num_citations": "48\n", "authors": ["682"]}
{"title": "Adaptable model versioning in action\n", "abstract": " In optimistic versioning, multiple developers are allowed to modify an artifact at the same time. On the one hand this approach increases productivity as the development process is never stalled due to locks on an artifact. On the other hand conflicts may arise when it comes to merging the different modifications into one consolidated version. In general, the resolution of such conflicts is not only cumbersome, but also error-prone. Especially if the artifacts under version control are models, little support is provided by standard versioning systems. In this paper we present the enhanced versioning process of the model versioning system AMOR. We show how AMOR is configured in order to obtain a precise conflict report which allows the recommendation of automatically executable resolution patterns. The user of AMOR chooses either one of the recommendations or performs manual resolution. The manual resolution may be in collaboration with other developers and allows to infer new resolution patterns which may be applied in similar situations.", "num_citations": "40\n", "authors": ["682"]}
{"title": "Towards end-user adaptable model versioning: The by-example operation recorder\n", "abstract": " For the realization of language-independent, effective, and user-friendly model versioning systems, generic and efficient conflict detection is essential for correct and complete identification of conflicts caused by parallel modifications on one artifact. Usually, the genericity of the conflict detection costs a high price: language-specific operations and refactorings often remain undetected. Consequently, conflicts are not found or conflicts are wrongly indicated. To improve the quality of conflict detection, language-specific features have to be added. This involves usually much programming effort. We present a descriptive approach to define language-specific operations and refactorings by macro recording which allows an easy integration in generic conflict detection components.", "num_citations": "40\n", "authors": ["682"]}
{"title": "A solver for QBFs in negation normal form\n", "abstract": " Various problems in artificial intelligence can be solved by translating them into a quantified boolean formula (QBF) and evaluating the resulting encoding. In this approach, a QBF solver is used as a black box in a rapid implementation of a more general reasoning system. Most of the current solvers for QBFs require formulas in prenex conjunctive normal form as input, which makes a further translation necessary, since the encodings are usually not in a specific normal form. This additional step increases the number of variables in the formula or disrupts the formula\u2019s structure. Moreover, the most important part of this transformation, prenexing, is not deterministic. In this paper, we focus on an alternative way to process QBFs without these drawbacks and describe a solver, , which is able to handle arbitrary formulas. To this end, we extend algorithms for QBFs to the non-normal form case and compare \u00a0\u2026", "num_citations": "32\n", "authors": ["682"]}
{"title": "A solver for QBFs in nonprenex form\n", "abstract": " Various problems in AI can be solved by translating them into a quantified boolean formula (QBF) and evaluating the resulting encoding. In this approach, a QBF solver is used as a black box in a rapid implementation of a more general reasoning system. Most of the current solvers for QBFs require formulas in prenex conjunctive normal form as input, which makes a further translation necessary, since the encodings are usually not in a specific normal form. This additional step increases the number of variables in the formula or disrupts the formula\u2019s structure. Moreover, the most important part of this transformation, prenexing, is not deterministic. In this paper, we focus on an alternative way to process QBFs without these drawbacks and implement a solver, qpro, which is able to handle arbitrary formulas. To this end, we extend algorithms for QBFs to the nonnormal form case and compare qpro with the leading normal-form provers on problems from the area of AI.", "num_citations": "32\n", "authors": ["682"]}
{"title": "Q-resolution with generalized axioms\n", "abstract": " Q-resolution is a proof system for quantified Boolean formulas (QBFs) in prenex conjunctive normal form (PCNF) which underlies search-based QBF solvers with clause and cube learning (QCDCL). With the aim to derive and learn stronger clauses and cubes earlier in the search, we generalize the axioms of the Q-resolution calculus resulting in an exponentially more powerful proof system. The generalized axioms introduce an interface of Q-resolution to any other QBF proof system allowing for the direct combination of orthogonal solving techniques. We implemented a variant of the Q-resolution calculus with generalized axioms in the QBF solver DepQBF. As two case studies, we apply integrated SAT solving and resource-bounded QBF preprocessing during the search to heuristically detect potential axiom applications. Experiments with application benchmarks indicate a substantial performance\u00a0\u2026", "num_citations": "30\n", "authors": ["682"]}
{"title": "Turning conflicts into collaboration\n", "abstract": " In model-driven software development, software models are the main artifacts used not only for supporting brainstorming, analysis, and design purposes, but also for generating executable code. Such software models are usually not created by one single developer, but within a team. To coordinate team work, versioning systems have proven to be indispensable for managing modifications performed by different modelers at the same time. When concurrently performed modifications are contradicting each other, the standard versioning paradigm requires the person who detected the conflict to resolve it immediately in order to keep the evolved artifacts in a consistent state. Whereas this approach works well in later phases of the software development process, in early phases, when the development team had not established a consolidated view on the system under development yet, the conflicts might\u00a0\u2026", "num_citations": "30\n", "authors": ["682"]}
{"title": "A classification of model checking-based verification approaches for software models\n", "abstract": " We present a feature-based classification of software model verification approaches. We classify a verification approach in a system-centric view according to the pursued verification goal, the representation of the input and the verification domain, the specification language of the properties, and the employed verification technique, which is one of either model checking, theorem proving, or static analysis. Our proposed feature model reflects this classification. Due to space limitations we focus on model checking-based verification techniques in this paper.", "num_citations": "29\n", "authors": ["682"]}
{"title": "The QBF gallery: Behind the scenes\n", "abstract": " Over the last few years, much progress has been made in the theory and practice of solving quantified Boolean formulas (QBF). Novel solvers have been presented that either successfully enhance established techniques or implement novel solving paradigms. Powerful preprocessors have been realized that tune the encoding of a formula to make it easier to solve. Frameworks for certification and solution extraction emerged that allow for a detailed interpretation of a QBF solver's results, and new types of QBF encodings were presented for various application problems.To capture these developments the QBF Gallery was established in 2013. The QBF Gallery aims at providing a forum to assess QBF tools and to collect new, expressive benchmarks that allow for documenting the status quo and that indicate promising research directions. These benchmarks became the basis for the experiments conducted in the\u00a0\u2026", "num_citations": "28\n", "authors": ["682"]}
{"title": "Non-cnf QBF solving with QCIR\n", "abstract": " While it is empirically confirmed folklore that conjunctive normal form (CNF) is not the ideal input format for QBF solvers, most tool developers and therefore also the users focus on formulas in this restricted structure. One important factor for establishing non-CNF solving is the input format. To overcome drawbacks of available formats, the QCIR format has recently been presented. The QCIR format is a circuit-based input format for quantified Boolean formulas which supports structure sharing. In contrast to previous formats, the representation is very compact, yet still easy to parse and to read for the human user. In this paper, we analyze the QCIR format in detail and provide tools and benchmarks which, we hope, will make its usage attractive and motivate tool developers to support this format as well as users to formulate their encodings in this format.", "num_citations": "23\n", "authors": ["682"]}
{"title": "The operation recorder: specifying model refactorings by-example\n", "abstract": " Predefined composite operations are handy for efficient software modeling, eg, for the automatic execution of refactorings, and for the introduction of patterns in existing models. Some modeling environments provide an initial set of basic refactoring operations, but hardly offer any extension points for the user. Even if extension points exist, the introduction of new composite operations requires programming skills and deep knowledge of the respective metamodel.", "num_citations": "23\n", "authors": ["682"]}
{"title": "A feature-based classification of formal verification techniques for software models\n", "abstract": " Software models are the core development artifact in model-based engineering (MBE). The MBE paradigm promotes the use of software models to describe structure and behavior of the system under development and proposes the automatic generation of executable code from the models. Thus, defects in the models most likely propagate to executable code. To detect defects already at the modeling level, many approaches propose to use formal verification techniques to ensure the correctness of these models. These approaches are the subject of this survey. We review the state of the art of formal verification techniques for software models and provide a feature-based classification that allows us to categorize and compare the different approaches.", "num_citations": "22\n", "authors": ["682"]}
{"title": "Towards scenario-based testing of UML diagrams\n", "abstract": " In model-driven engineering, models are not primarily developed for documentation and requirement specification purposes, but promoted to first-class artifacts, from which executable code is generated. As a consequence, typical development activities like testing must be performed on the model level. In this paper, we propose to use overlapping information inherent in multiple views of models for automatic testing. Using a prototype based on the model checker Spin we show the feasibility of this approach and identify future challenges.", "num_citations": "18\n", "authors": ["682"]}
{"title": "Colex: a web-based collaborative conflict lexicon\n", "abstract": " While graphical modeling languages gained recognition as being a promising successor of third-generation programming languages, their widespread employment is still decelerated by the absence of adequate version control management for modeling artifacts. Even worse, the expected behavior and quality requirements for upcoming model versioning systems are only vaguely stated and understood. When it comes to defining, detecting, and resolving conflicts, no consolidated categorization and no common benchmark exist which impedes a uniform comparison of current approaches. With this paper, we invite the model versioning community to conjointly accomplish a consolidated body of knowledge which documents various types of conflicts, their detectability, as well as applicable resolution strategies. Therefore, we present Colex, an open, web-based, collaborative conflict lexicon. As a starting point, we\u00a0\u2026", "num_citations": "18\n", "authors": ["682"]}
{"title": "The 2016 and 2017 QBF solvers evaluations (QBFEVAL'16 and QBFEVAL'17)\n", "abstract": " After a break of about five years, in 2016 the classical QBFEVAL has been revived. QBFEVAL is a competitive evaluation of solvers for quantified Boolean formulas (QBF), the extension of propositional formulas with existential and universal quantifiers over the propositional variables.Due to the enormous interest in QBFEVAL'16, more recently, QBFEVAL'17 was organized. Both competitions were affiliated to the respective editions of the International Conference on Theory and Applications of Satisfiability Testing (SAT'16 and SAT'17), the major conference in research on SAT and related areas.In this paper we report about the 2016 and 2017 competitive evaluations of QBF solvers (QBFEVAL'16 and QBFEVAL'17), the two most recent events in a series of competitions established with the aim of assessing the advancements in reasoning about QBFs. This report gives an overview of the setup of these two events, on\u00a0\u2026", "num_citations": "17\n", "authors": ["682"]}
{"title": "QBF Gallery 2014: The QBF Competition at the FLoC 2014 Olympic Games\n", "abstract": " The QBF Gallery 2014 was a competitive evaluation for QBF solvers organized as part of the FLoC 2014 Olympic Games during the Vienna Summer of Logic. The QBF Gallery 2014 featured three different tracks on formulas in prenex conjunctive normal form (PCNF) including more than 1200 formulas to be solved. Gold, silver, and bronze track medals were awarded to the solvers that solved the most formulas in each of the three tracks. Additionally, the three participants that were most successful over the complete benchmark set were awarded with Kurt G\u00f6del medals, the official prizes of the FLoC 2014 Olympic Games.", "num_citations": "17\n", "authors": ["682"]}
{"title": "VIDEAS: A development tool for answer-set programs based on model-driven engineering technology\n", "abstract": " In the object-oriented world, much effort is spent into the development of dedicated tools to ease programming and to prevent programming errors. Recently, the techniques of model-driven engineering (MDE) have been proven especially valuable to manage the complexity of modern software systems during the software development process. In the world of answer-set programming (ASP), the situation is different. Much effort is invested into the development of efficient solvers, but the pragmatics of programming itself has not received much attention and more tool support to ease the actual programming phase would be desirable. To address this issue, we introduce the tool VIDEAS which graphically supports the partial specification of answer-set programs, applying technologies provided by MDE.", "num_citations": "17\n", "authors": ["682"]}
{"title": "Model checking of CTL-extended OCL specifications\n", "abstract": " In software modeling, the Object Constraint Language (OCL) is an important language to specify properties that a model has to satisfy. The design of OCL reflects the structure of MOF-based modeling languages like UML and its tight integration results in an intuitive usability. But OCL allows to express properties only in the context of a single instance model and not with respect to a sequence of instance models that capture the execution of the system.             In this paper, we show how OCL can be extended with CTL-based temporal operators to express properties over the lifetime of an instance model. We formally introduce syntax and semantics of our OCL extension cOCL. The properties specified with our OCL extension can be verified with our explicit state space model checking framework, called MocOCL. In a case study, we illustrate the expressiveness and usability of our approach and evaluate the\u00a0\u2026", "num_citations": "16\n", "authors": ["682"]}
{"title": "OCL meets CTL: Towards CTL-Extended OCL Model Checking.\n", "abstract": " In software modeling, the Object Constraint Language (OCL) is an important tool to specify properties that a model has to satisfy. The design of OCL reflects the structure of MOF-based modeling languages like UML and the tight integration results in an intuitive usability. However, OCL allows to express properties in the context of the current state of an instance model only but not with respect to its evolution. In this paper, we show how OCL can be extended with CTL-based temporal operators to express properties over the lifetime of an instance model. We explain syntax and semantics of our OCL extension and provide a prototypical implementation of our MocOCL model checker.", "num_citations": "16\n", "authors": ["682"]}
{"title": "Towards semantics-aware merge support in optimistic model versioning\n", "abstract": " Current optimistic model versioning systems, which are indispensable to coordinate the collaboration within teams, are able to detect several kinds of conflicts between two concurrently modified versions of one model. These systems support the detection of syntactical problems such as contradicting changes, violations of the underlying metamodel, and violations of OCL constraints. However, violations of the models\u2019 semantics remain unreported. In this paper, we suggest to use redundant information inherent in multi-view models to check if the semantics is violated during the merge process. In particular, we exploit the information encoded in state machine diagrams to validate evolving sequence diagrams by means of the model checker Spin.", "num_citations": "16\n", "authors": ["682"]}
{"title": "Replacing traditional classroom lectures with lecture videos: an experience report\n", "abstract": " Lecture videos are slides enhanced with the audio recording of the lecturer's talk. Such lecture videos offer numerous advantages to the students as well as to the lecturers themselves. The former may organize their studies in a more flexible way by consuming the content of a lecture anytime and at any place as often as they want. The latter do not have to give the same lecture over and over again and may use the saved time for personal contact to the students. In this paper, we report on our experiences with using lecture videos in the course Introduction to Object-Oriented Modeling offered by the Business Informatics Group (BIG) at the Vienna University of Technology. We shortly review the structure of the course and discuss the creation and integration of the lecture videos. For the evaluation of this approach, we performed an online survey where the students could provide feedback. Parts of the results of this\u00a0\u2026", "num_citations": "15\n", "authors": ["682"]}
{"title": "Conflict Visualization for Evolving UML Models.\n", "abstract": " The urgent demand for supporting teamwork and continuous evolution of software models triggered intensive research on optimistic version control systems for models. State-of-the-art model versioning approaches primarily focus on detecting changes and conflicts between concurrently evolved versions of a model. However, techniques for conflict visualization have been hardly investigated yet. In this paper, we propose to support the visualization of conflicts in the concrete syntax of UML models. For this purpose, we present an approach to tentatively merge concurrently evolved versions of one model featuring all performed changes, yet keeping conformance to the UML metamodel. Changes and conflicts are visualized in this tentatively merged model without requiring any editor extensions. Instead, we employ the powerful profile mechanism of UML to enable modelers to resolve conflicts within their favorite UML editor.", "num_citations": "15\n", "authors": ["682"]}
{"title": "The past, present, and future of model versioning\n", "abstract": " The evolution of software models induces a plethora of challenging research issues. Only when these problems are solved, the techniques of model-driven engineering (MDE) are able to fully exploit their potential in practice. Otherwise the advantages of MDE are relativized by time-consuming and cumbersome management tasks which are already well supported for traditional development based on textual code. One of these challenges is model versioning.Version Control Systems (VCS) are an essential part of the software development infrastructure which (i) store the history of evolution of software artifacts,(ii) support multiple developers working in parallel, and (iii) manage different development branches. For all of these tasks, changes performed on the artifacts under version control have to be tracked. For the second and third task it is additionally necessary to detect conflicts between concurrently evolved\u00a0\u2026", "num_citations": "14\n", "authors": ["682"]}
{"title": "Conflicts as first-class entities: a UML profile for model versioning\n", "abstract": " The urgent demand for optimistic version control support for software models induced active research within the modeling community. Recently, several approaches have been proposed addressing the task of detecting conflicts when merging two concurrently changed versions of a model. In this context, the holistic representation and supportive visualization of detected merge conflicts pose a challenge.               In this paper, we present a modeling language independent conflict model comprising all necessary information to profoundly represent merge conflicts. From this conflict model, we leverage the dynamic extension power of UML profiles by introducing a dedicated conflict profile to visually assist modelers in resolving merge conflicts of UML models. As a result, modelers may resolve conflicts in the concrete graphical syntax conducting their familiar UML editors without tool extensions.", "num_citations": "14\n", "authors": ["682"]}
{"title": "Teaching model engineering in the large\n", "abstract": " Traditionally, models are considered as pretty pictures supporting merely the documentation of a software development project. With the rise of model-driven engineering (MDE) this viewpoint has to be reconsidered. Models become firstclass artifacts which yield the basis for the generation of executable program code. In modern university curricula of computer science and related fields this paradigm shift must not be ignored. At the Business Informatics Group (BIG) of the Vienna University of Technology we offer an advanced modeling course called Model Engineering where we elaborate current trends, development, and state-of-the-art techniques necessary to realize the visions of MDE. In this paper we report which concrete concepts and approaches we teach and how we structure and organize a practical hands-on lab where the students have to build their own model-driven development environment consisting of their own modeling languages, certain types of model transformations, and code generation facilities.", "num_citations": "14\n", "authors": ["682"]}
{"title": "Teaching Models@ BIG: How to Give 1000 Students an Understanding of the UML\n", "abstract": " In this paper, we report our experiences on teaching the Unified Modeling Language in the large. More precisely, about 1000 computer science and business informatics students attend our course Object-Oriented Modeling each year. Requiring a profound understanding of the UML, many advanced courses like Software Engineering or Model Engineering build on the knowledge imparted by our course. In order to achieve our ambitious teaching targets, we establish personal mentoring despite the mass enhanced with e-learning facilities.", "num_citations": "13\n", "authors": ["682"]}
{"title": "cc {\\rm T}: A Tool for Checking Advanced Correspondence Problems in Answer-Set Programming\n", "abstract": " In recent work, a general framework for specifying correspondences between logic programs under the answer-set semantics has been defined. The framework allows to define different notions of equivalence, including well-known notions like strong equivalence as well as refined ones based on the projection of answer sets, where not all parts of an answer set are of relevance. In this paper, we describe a system, called ccT, to verify program correspondences in this general framework, relying on linear-time constructive reductions to quantified propositional logic using extant solvers for the latter language as back-end inference engines. We provide a preliminary performance evaluation which sheds light on some crucial design issues", "num_citations": "13\n", "authors": ["682"]}
{"title": "A study on topological descriptors for the analysis of 3d surface texture\n", "abstract": " Methods from computational topology are becoming more and more popular in computer vision and have shown to improve the state-of-the-art in several tasks. In this paper, we investigate the applicability of topological descriptors in the context of 3D surface analysis for the classification of different surface textures. We present a comprehensive study on topological descriptors, investigate their robustness and expressiveness and compare them with state-of-the-art methods including Convolutional Neural Networks (CNNs). Results show that class-specific information is reflected well in topological descriptors. The investigated descriptors can directly compete with non-topological descriptors and capture complementary information. As a consequence they improve the state-of-the-art when combined with non-topological descriptors.", "num_citations": "10\n", "authors": ["682"]}
{"title": "A SAT-based debugging tool for state machines and sequence diagrams\n", "abstract": " An effective way to model message exchange in complex settings is to use UML sequence diagrams in combination with state machine diagrams. A natural question that arises in this context is whether these two views are consistent, i.e., whether a desired or forbidden scenario modeled in the sequence diagram can be or cannot be executed by the state machines.In case of an inconsistency, a concrete communication trace of the state machines can give valuable information for debugging purposes on the model level.This trace either hints to a message in the sequence diagram where the communication between the state machines fails, or describes a concrete forbidden communication trace between the state machines.To detect and explain such inconsistencies, we propose a novel SAT-based formalization which can be solved automatically by an off-the-shelf SAT solver. To this end, we present the\u00a0\u2026", "num_citations": "9\n", "authors": ["682"]}
{"title": "A Framework for the Specification of Random SAT and QSAT Formulas\n", "abstract": " We present the framework [q]bfGen which allows the declarative specification of random models for generating SAT and QSAT formulas not necessarily in (prenex) conjunctive normal form. To this end, [q]bfGen realizes a generic formula generator which creates formula instances by interpreting the random model specification expressed in XML. Consequently, the implementation of specific random formula generators becomes obsolete, because our framework subsumes their functionality.", "num_citations": "9\n", "authors": ["682"]}
{"title": "Concurrent modeling in early phases of the software development life cycle\n", "abstract": " Software engineering deals with the development of complex software systems which is an inherently team-based task. Therefore, version control support is needed to coordinate the teamwork and to manage parallel modifications. If conflicting modifications occur, in standard approaches the developer who detected the conflict is responsible for the conflict resolution alone and has to resolve the conflict immediately.               Especially in early project phases, when software models are typically employed for brainstorming, analysis, and design purposes, such an approach bears the danger of losing important viewpoints of different stakeholders and domain engineers, resulting in a lower quality of the overall system specification. In this paper, we propose conflict-tolerant model versioning to overcome this problem. Conflicts are marked during the merge phase and are tolerated temporarily in order to resolve\u00a0\u2026", "num_citations": "9\n", "authors": ["682"]}
{"title": "Integrating ontologies with car-mappings\n", "abstract": " CAR is a declarative language which can be used to map between different schemas in general and which allows the integration of ontologies in special. CAR provides mapping operators whose expressivity exceeds the possibilities of simple equivalence mappings by far. Due to the declarative nature of this approach, CAR which we implemented in a graphical mapping framework, offers a very user-friendly way to overcome schematic heterogenities. Furthermore, the mappings can be executed on Colored Petri Nets, and therefore they can be easily simulated and debugged in a framework for representing schemas and mapping models as Transformation Nets which can be applied to transform concrete instances of schemas expressed as tokens.", "num_citations": "9\n", "authors": ["682"]}
{"title": "cc\u22a4: a correspondence-checking tool for logic programs under the answer-set semantics\n", "abstract": " In recent work, a general framework for specifying correspondences between logic programs under the answer-set semantics has been defined. The framework captures different notions of equivalence, including well-known ones like ordinary, strong, and uniform equivalence, as well as refined ones based on the projection of answer sets where not all parts of an answer set are of relevance. In this paper, we describe an implementation to verify program correspondences in this general framework. The system, called cc\u22a4, relies on linear-time constructible reductions to quantified propositional logic and uses extant solvers for the latter language as back-end inference engines.", "num_citations": "9\n", "authors": ["682"]}
{"title": "MPIDepQBF: Towards Parallel QBF Solving without Knowledge Sharing\n", "abstract": " Inspired by recent work on parallel SAT solving, we present a lightweight approach for solving quantified Boolean formulas (QBFs) in parallel. In particular, our approach uses a sequential state-of-the-art QBF solver to evaluate subformulas in working processes. It abstains from globally exchanging information between the workers, but keeps learnt information only locally. To this end, we equipped the state-of-the-art QBF solver DepQBF with assumption-based reasoning and integrated it in our novel solver MPIDepQBF as backend solver. Extensive experiments on standard computers as well as on the supercomputer Tsubame show the impact of our approach.", "num_citations": "8\n", "authors": ["682"]}
{"title": "Managing variability and evolution of business document models\n", "abstract": " The United Nations Centre for Trade Facilitation and eBusiness (UN/CEFACT) standardizes business documents for electronic data interchange. Their approaches towards UN/EDIFACT and XML have later been followed by a conceptual modeling approach called Core Components (CC). Having used this approach for four years in practice, it became evident that the support for managing business document models is a prerequisite for successfully utilizing CC. This includes handling variants of business document models on the one hand, and managing the evolution of business document models on the other hand. In this paper we propose an approach to face these challenges by the means of Software Product Line Engineering (SPLE) in combination with dedicated model management operators. The contribution of the approach is twofold. First, SPLE is successfully applied in a new field enabling us to manage variants of business document models. Second, the model management operators support the evolution of business document model variants, whereas the operators defined, contribute to the evolution of product lines as well.", "num_citations": "8\n", "authors": ["682"]}
{"title": "Teaching Models@ BIG: On Efficiently Assessing Modeling Concepts\n", "abstract": " Approximately 1000 students of computer science and business informatics attend the course Introduction to Object-Oriented Modeling (OOM) offered by the Business Informatics Group (BIG) of the Vienna University of Technology each year in order to learn the basic concepts of the Unified Modeling Language (UML) and to obtain a certificate. For finishing the course successfully, the students must pass three small tests where they have to prove their theoretical knowledge about UML concepts as well as their ability to apply this knowledge in practical exercises. In this paper we report our experiences in assessing the modeling knowledge of our students and we reveal how we design the tests.", "num_citations": "8\n", "authors": ["682"]}
{"title": "Short proofs for some symmetric quantified Boolean formulas\n", "abstract": " We exploit symmetries to give short proofs for two prominent formula families of QBF proof complexity theory. On the one hand, we employ symmetry breakers. On the other hand, we enrich the (relatively weak) QBF resolution calculus Q-Res with the symmetry rule and obtain separations to powerful QBF calculi.", "num_citations": "7\n", "authors": ["682"]}
{"title": "Symmetries of quantified boolean formulas\n", "abstract": " While symmetries are well understood for Boolean formulas and successfully exploited in practical SAT solving, less is known about symmetries in quantified Boolean formulas (QBF). There are some works introducing adaptions of propositional symmetry breaking techniques, with a theory covering only very specific parts of QBF symmetries. We present a general framework that gives a concise characterization of symmetries of QBF. Our framework naturally incorporates the duality of universal and existential symmetries resulting in a general basis for QBF symmetry breaking.", "num_citations": "7\n", "authors": ["682"]}
{"title": "A recommender for conflict resolution support in optimistic model versioning\n", "abstract": " The usage of optimistic version control systems comes along with cumbersome and time-consuming conflict resolution in the case that the modifications of two developers are contradicting. For code as well as for any other artifact the resolution support moves hardly beyond the choices\" keep mine\",\" keep theirs\",\" take all changes\", or\" abandon all changes\".", "num_citations": "7\n", "authors": ["682"]}
{"title": "On using UML profiles in ATL transformations\n", "abstract": " For defining modeling languages, metamodels and UML profiles are the proposed options. While metamodels are supported by several dedicated model transformation approaches, currently no transformation language exists which support UML profiles as first class language definitions. Instead, the usage of UML profiles in transformations is implicit by using calls to external UML APIs. In this paper, we first discuss the state-of-the-art of using UML profiles in ATL. Subsequently, three approaches for supporting profiles as first class language definitions within ATL transformations are introduced and discussed. In particular, these approaches aim at using stereotypes and tagged values within declarative rules without using external API calls. The benefits are: first, the enhanced static checking of ATL transformations, second, the more explicit representation of transformations logic enhances the application of higher-order transformations, and third, enhanced tool support such as code completion may be provided.", "num_citations": "7\n", "authors": ["682"]}
{"title": "A tool for advanced correspondence checking in answer-set programming\n", "abstract": " In previous work, a general framework for specifying correspondences between logic programs under the answer-set semantics has been defined. The framework allows to define different notions of equivalence, including well-known notions like strong equivalence as well as refined ones based on the projection of answer sets, where not all parts of an answer set are of relevance (like, eg, removal of auxiliary letters). In the general case, deciding the correspondence of two programs lies on the fourth level of the polynomial hierarchy and therefore this task can (presumably) not be efficiently reduced to answer-set programming. In this paper, we describe an implementation to verify program correspondences in this general framework. The system, called cc\u22a4, relies on linear-time constructible reductions to quantified propositional logic using extant solvers for the latter language as back-end inference engines. We provide some preliminary performance evaluation which shed light on some crucial design issues.", "num_citations": "7\n", "authors": ["682"]}
{"title": "Detection of Road Passability from Social Media and Satellite Images.\n", "abstract": " This paper presents the contribution of Team MC-FHSTP to the multimedia satellite task at the MediaEval 2018 benchmark. We present two methods, one for the estimation of the passability of roads from social media images due to flooding and one method that estimates passability from satellite images. We present the results obtained in the benchmark for both methods.", "num_citations": "6\n", "authors": ["682"]}
{"title": "Bringing your own device into multi-device ecologies: a technical concept\n", "abstract": " Almost every visitor brings their own mobile device (eg, smartphone or tablet) to the museum. Although, many museums include interactive exhibits (eg, multi-touch tables), the visitors' own devices are rarely used as part of a device ecology. Currently, there is no suitable infrastructure to seamlessly link different devices in museums. Our approach is to integrate the visitor's own device in a multi-device ecology (MDE) in the museum to enhance the visitor's exhibition experience. Thus, we present a technical concept to set up such MDEs integrating the well-established TUIO framework for multi-touch interaction on and between devices.", "num_citations": "6\n", "authors": ["682"]}
{"title": "cc\u22a4 on stage: Generalised uniform equivalence testing for verifying student assignment solutions\n", "abstract": " The tool cc\u22a4 is an implementation for testing various parameterised notions of program correspondence between logic programs under the answer-set semantics, based on reductions to quantified propositional logic. One such notion is relativised uniform equivalence with projection, which extends standard uniform equivalence via two additional parameters: one for specifying the input alphabet and one for specifying the output alphabet. In particular, the latter parameter is used for projecting answer sets to the set of designated output atoms, i.e. ignoring auxiliary atoms during answer-set comparison. In this paper, we discuss an application of cc\u22a4 for verifying the correctness of students\u2019 solutions drawn from a laboratory course on logic programming, employing relativised uniform equivalence with projection as the underlying program correspondence notion. We complement our investigation by discussing\u00a0\u2026", "num_citations": "6\n", "authors": ["682"]}
{"title": "QRAT Polynomially Simulates \n", "abstract": " The proof system  formally captures expansion-based solving of quantified Boolean formulas (QBFs) whereas the  proof system captures QBF preprocessing. From previous work it is known that certain families of formulas have short proofs in  but not in . However, it was not known if the two proof systems were incomparable (i.e., if there also existed QBFs with short  proofs but without short  proofs), or if  polynomially simulates . We close this gap of the QBF-proof-complexity landscape by presenting a polynomial simulation of  in . Our simulation shows how definition introduction combined with extended-universal reduction can mimic the concept of universal expansion.", "num_citations": "5\n", "authors": ["682"]}
{"title": "Global State Checker: Towards SAT-Based Reachability Analysis of Communicating State Machines.\n", "abstract": " We present a novel propositional encoding for the reachability problem of communicating state machines. The problem deals with the question whether there is a path to some combination of states in a state machine view starting from a given configuration. Reachability analysis finds its application in many verification scenarios. By using an encoding inspired by approaches to encode planning problems in artificial intelligence, we obtain a compact representation of the reachability problem in propositional logic. We present the formal framework for our encoding and a prototype implementation. A first case study underpins its effectiveness.", "num_citations": "5\n", "authors": ["682"]}
{"title": "On realizing a framework for self-tuning mappings\n", "abstract": " Realizing information exchange is a frequently recurring challenge in nearly every domain of computer science. Although languages, formalisms, and storage formats may differ in various engineering areas, the common task is bridging schema heterogeneities in order to transform their instances. Hence, a generic solution for realizing information exchange is needed. Conventional techniques often fail, because alignments found by matching tools cannot be executed automatically by transformation tools. In this paper we present the Smart Matching approach, a successful combination of matching techniques and transformation techniques, extended with self-tuning capabilities. With the Smart Matching approach, complete and correct executable mappings are found in a test-driven manner.", "num_citations": "5\n", "authors": ["682"]}
{"title": "Intra-and interdiagram consistency checking of behavioral multiview models\n", "abstract": " Multiview modeling languages like UML are a very powerful tool to deal with the ever increasing complexity of modern software systems. By splitting the description of a system into different views\u2014the diagrams in the case of UML\u2014system properties relevant for a certain development activity are highlighted while other properties are hidden. This multiview approach has many advantages for the human modeler, but at the same time it is very susceptible to various kinds of defects that may be introduced during the development process. Besides defects which relate only to one view, it can also happen that two different views, which are correct if considered independently, contain inconsistent information when combined. Such inconsistencies between different views usually indicate a defect in the model and can be critical if they propagate up to the executable system.In this paper, we present an approach to formally\u00a0\u2026", "num_citations": "4\n", "authors": ["682"]}
{"title": "The Use Case Diagram\n", "abstract": " The use case diagram allows us to describe the possible usage scenarios (use cases) that a system is developed for. It expresses what a system should do but does not address any realization details such as data structures, algorithms, etc. These details are covered by other diagrams such as the class diagram (see Chapter                  4                                ) or the interaction diagrams (see Chapter                  6                                ). The use case diagram also models which user of the system uses which functionality, i.e., it expresses who will actually work with the system to be built.", "num_citations": "4\n", "authors": ["682"]}
{"title": "Making UML\" hip\": A First Experience Report on Using Modern Teaching Tools for Object-Oriented Modelling.\n", "abstract": " We steadily aim at improving our first year\u2019s university course Introduction to Object-Oriented Modelling. To that end we explore how technological teaching support may be used to extend the classical classroom experience for the students. For several years, we used Web-based out-of-the-box e-learning tools for providing additional teaching support. This solution works well, but has some severe restrictions. In this paper, we show how to overcome these restrictions with a custom implementation. Further, we are now starting to explore mobile facilities as offered by smartphone Apps as well as social media facilities in order to enhance the learning experience in our modelling course. We report on our first experiences with these kinds of technologies.", "num_citations": "4\n", "authors": ["682"]}
{"title": "Mining of model repositories for decision support in model versioning\n", "abstract": " State-of-the-art software repositories support optimistic versioning and hence the concurrent editing of one artifact by multiple developers is possible. The drawback of this method is the time-consuming, manual merge process when conflicting changes occur. This is even a bigger problem when the artifacts are models. Although similar kinds of conflicts frequently reoccur, current systems hardly provide any resolution support. To tackle this problem, this paper introduces enhanced resolution support based on past resolution decisions. In order to keep the necessary information to learn recommendations for improved conflict resolution, a generic extension to current repository technology is proposed.", "num_citations": "4\n", "authors": ["682"]}
{"title": "Testing Relativised Uniform Equivalence under Answer-Set Projection in the System cc\u2009\u22a4\u2009\n", "abstract": " The system cc\u22a4 is a tool for testing correspondence between propositional logic programs under the answer-set semantics with respect to different refined notions of program correspondence. The underlying methodology of cc\u22a4 is to reduce a given correspondence problem to the satisfiability problem of quantified propositional logic and to employ extant solvers for the latter language as back-end inference engines. In a previous version of cc\u22a4, the system was designed to test correspondence between programs based on relativised strong equivalence under answer-set projection. Such a setting generalises the standard notion of strong equivalence by taking the alphabet of the context programs as well as the projection of the compared answer sets to a set of designated output atoms into account. This paper outlines a newly added component of cc\u22a4 for testing similarly parameterised correspondence\u00a0\u2026", "num_citations": "4\n", "authors": ["682"]}
{"title": "An extension of the system cc\u22a4 for testing relativised uniform equivalence under answer-set projection\n", "abstract": " The system cc\u22a4 is a tool for testing correspondence between nonmonotonic logic programs under the answer-set semantics with respect to different refined notions of program correspondence. The basic architecture of cc\u22a4 is to reduce a given correspondence problem into the satisfiability problem for quantified propositional logic and to employ off-the-shelf solvers for the latter language as backend inference engines. In a previous incarnation of cc\u22a4, the system was designed to test correspondence between logic programs based on relativised strong equivalence under answer-set projection. Such a setting generalises the usual notion of strong equivalence by taking the alphabet of the context programs as well as the projection of the compared answer sets to a set of designated output atoms into account. In this paper, we describe an extension of cc\u22a4 for testing similarly parameterised correspondence problems but generalising uniform equivalence, which have recently been introduced in previous work. Besides reviewing the formal underpinnings of the new component of cc\u22a4, we discuss an alternative encoding as well as optimisations for special problem classes. Furthermore, we give a prelimi-* The authors of this work were partially supported by the Austrian Science Fund (FWF) under grant P18019; the second author was also supported by the Austrian Federal Ministry of Transport, Innovation, and Technology (BMVIT) and the Austrian Research Promotion Agency (FFG) under grant FIT-IT-810806.", "num_citations": "4\n", "authors": ["682"]}
{"title": "A Tool for Advanced Correspondence Checking in Answer-Set Programming: Preliminary Experimental Results.\n", "abstract": " In recent work, a general framework for specifying program correspondences under the answer-set semantics has been defined. The framework allows to define different notions of equivalence, including the well-known notions of strong and uniform equivalence, as well as refined equivalence notions based on the projection of answer sets, where not all parts of an answer set are of relevance (like, eg, removal of auxiliary letters). In the general case, deciding the correspondence of two programs lies on the fourth level of the polynomial hierarchy and therefore this task can (presumably) not be efficiently reduced to answer-set programming. In this paper, we give an overview about an implementation to compute program correspondences in this general framework. The system, called eqcheck, relies on linear-time constructible reductions to quantified propositional logic using extant solvers for the latter language as back-end inference engines. We provide some preliminary performance evaluation, which shed light on some crucial design issues.", "num_citations": "4\n", "authors": ["682"]}
{"title": "Semantics-Aware Versioning Challenge: Merging Sequence Diagrams along with State Machine Diagrams\n", "abstract": " In multi-view modeling languages like UML, models contain several diagrams, each of which focusing on a specific aspect of the system. However, when the diagrams are combined, they give a coherent description of all static and dynamic aspects of the system. Diagrams may then extend each other or add constraints to other diagrams. Considering this additional information improves model versioning, as conflicts are revealed also in case their changes are not overlapping, and merge algorithms may provide solutions which are correct by construction. This paper describes a challenge benchmark for semantics-aware merging of sequence diagrams with respect to their corresponding state machine diagrams.", "num_citations": "3\n", "authors": ["682"]}
{"title": "An introduction to model versioning\n", "abstract": " Publikationseintrag [Zur\u00fcck] @inproceedings{TUW-208475, author = {Kaufmann, Petra and Kappel, Gerti and Langer, Philip and Seidl, Martina and Wieland, Konrad and Wimmer, Manuel}, title = {An Introduction to Model Versioning}, booktitle = {Formal Methods for Model-Driven Engineering}, year = {2012}, editor = {Bernardo, Marco and Cortellessa, Vittorio and Pierantonio, Alfonso}, pages = {336--398}, publisher = {Springer}, address = {LNCS 7320}, url = {http://publik.tuwien.ac.at/files/PubDat_208475.pdf}, issn = {0302-9743}, doi = {10.1007/978-3-642-30982-3{\\_}10}, keywords = {model-driven engineering, model versioning, model evolution}, note = {eingeladen; Vortrag: International School on Formal Methods for the Design of Computer, Communcation, and Software Systems, Bertinoro, Italy; 2012-06-18 -- 2012-06-23} } Erstellt aus der Publikationsdatenbank der Technischen Universit\u00e4t Wien. \u2026", "num_citations": "3\n", "authors": ["682"]}
{"title": "Software modeling in education\n", "abstract": " 314 Editorial consists of three components, which include a core component consisting of three modules, an application component consisting of two modules and a managing MDE projects component consisting of one module. The supporting team of personnel to implement the MDE diploma consists of a coordinator, two full time faculty lecturers, a research engineer, an industrial relations person, a scientific advisor and a pedagogic assistant. In addition to the personnel mentioned, there were more than 20 guest lecturers from both academia and industry. One of the main contributions of the paper was the lessons learned section that describes (1) the application of the concepts learned in class,(2) difficulty in finding lecturers for the Managing MDE Projects module,(3) student selection and (4) economic and social toll on the administrative staff. We thank the reviewers for their insightful reviews and the feedback\u00a0\u2026", "num_citations": "3\n", "authors": ["682"]}
{"title": "Towards an Understanding of Requirements for Model Versioning Support\n", "abstract": " When software is developed in teams\u2013the standard way software is developed today\u2013versioning systems are the first choice for the management of collaboration. From a technical point of view, versioning systems have to face several challenges. Depending on the applied versioning paradigm, functionalities such as synchronous editing, branching, storing different versions, merging, etc. are required. Since much effort has been spent into realizing these tasks, measurable progress has been achieved over the last decades. Unfortunately, there is a lack of empirical studies to find out the actual requirements arising from practice. Therefore, the authors conducted an online survey and interviewed representative users of versioning systems from academia and industry. Special emphasis is placed on the versioning of software models, which are nowadays becoming more and more important as there is a trend to\u00a0\u2026", "num_citations": "3\n", "authors": ["682"]}
{"title": "VIDEAS: Supporting Answer-Set Program Development using Model-Driven Engineering Techniques\n", "abstract": " Recently, the techniques of model-driven engineering (MDE) have been proven valuable to manage the complexity of modern software systems during the software development process. In the area of answer-set programming (ASP), the focus is set so far on theoretical aspects, applications, and the development of efficient solvers, reducing the attention that is paid to the pragmatics of programming and assisting tools. To address this issue, we propose the MDE-based program development method VIDEAS by introducing explicit model-tocode mappings and code generation strategies ensuring compliant specification of facts and essential constraints. Its practical applicability is realised on the basis of a prototypical implementation.", "num_citations": "3\n", "authors": ["682"]}
{"title": "Viennar: User-centered-design of a bring your own device mobile application with augmented reality\n", "abstract": " In many museums it is still common that visitors have to read static texts from boards to gain information about the exhibits. In times where almost every visitor carries a smartphone in their pocket, these devices could be utilized for a more personalized and interactive visitor experience. In this paper we present a design study for a \u201cBring your own device\u201d setting that combines augmented reality (AR) and navigation in museums. We applied an iterative user centered design approach that included conceptual design, prototyping, user tests, as well as a field test in a large museum in Vienna. One of the main results is that a new and digital form of navigation isn\u2019t as essential as the museum thought it would be. Apart from that the application was well received during the field test.", "num_citations": "2\n", "authors": ["682"]}
{"title": "QBF Gallery 2014\n", "abstract": " SOLVER SAT UNSAT TOTAL cghostq 80 63 143 bcghostq 80 63 143 xbdepqbf 70 68 138 brareqs 66 68 134 hiqqer3 71 62 133 hiqqer1 66 64 130 cbdepqbf 63 62 125 ghostq 68 56 124 pre_dual_ooq13 64 53 117 dual_ooq13 60 45 105 sqube 50 44 94 depqbf 41 50 91 rareqs 32 47 79 ooq13 30 35 65", "num_citations": "2\n", "authors": ["682"]}
{"title": "Position Paper: Software Modeling Education\n", "abstract": " Model-driven engineering (MDE) is a promising paradigm to deal with the ever increasing complexity of modern software systems. Its powerful abstraction mechanisms allow practitioners to focus on the essential development challenges, thereby hiding the irrelevant aspects of the system under development. Within the last few years, noticeable progress has been made in putting MDE into practice, particularly in those areas where the activity of programming is substituted by modeling. The recent availability of matured concepts and stable tools has resulted in MDE becoming more applicable in software engineering projects. Nevertheless, the availability of the best technology is worthless, if it is not accepted and used by practitioners in the field. To alleviate this problem there is a need for extensive training both in academia and industry to fully exploit the power of MDE.", "num_citations": "2\n", "authors": ["682"]}
{"title": "On formalizing emf modeling operations with graph transformations\n", "abstract": " The development of software in accordance with the model-driven engineering paradigm places model transformations at a central position. Desirable yet contradicting properties of model transformations are user-friendliness as offered by-demonstration approaches and formal conciseness as provided by algebraic graph transformations which is indispensable for verification tasks. In this paper, we show how to unite the properties of the two different approaches. We employ the state-of-the-art by-demonstration environment Emo to prototype graph transformations by embedding the operations obtained from Emo in the formal framework of graph transformation theory.", "num_citations": "2\n", "authors": ["682"]}
{"title": "Gradual transition detection in historic film material\u2014a systematic study\n", "abstract": " The segmentation of films and videos into shots requires the detection of gradual transitions such as dissolves and fades. There are two types of approaches: unified approaches, that is, one detector for all gradual transition types, and approaches that use specialized detectors for each gradual transition type. We present an overview on existing methods and extend an existing unified approach for the detection of gradual transitions in historic material. In an experimental study, we evaluate the proposed approach on complex and low-quality historic material as well as on contemporary material from the TRECVid evaluation. Additionally, we investigate different features, feature combinations, and fusion strategies. We observe that the historic material requires the use of texture features, in contrast to the contemporary material that, in most of the cases, requires the use of color and luminance features.", "num_citations": "2\n", "authors": ["682"]}
{"title": "By-example adaptation of the generic model versioning system AMOR: how to include language-specific features for improving the check-in process\n", "abstract": " We present configuration mechanisms based on by-example approaches for the adaptable model versioning system AMOR improving the complete versioning workflow. The Operation Recorder allows the specification of composite operations. Those operation definitions are used by the Conflict Manager supporting the specification of potential merge conflicts and suitable resolution strategies.", "num_citations": "2\n", "authors": ["682"]}
{"title": "QBFFam: A Tool for Generating QBF Families from Proof Complexity\n", "abstract": " We present QBFFam, a tool for the generation of formula families originating from the field of proof complexity. Such formula families are used to investigate the strength of proof systems and to show how they relate to each other in terms of simulations and separations. Furthermore, these proof systems underlie the reasoning power of QBF solvers. With our tool, it is possible to generate informative and scalable benchmarks that help to analyse the behavior of solvers. As we will see in this paper, runtime behavior predicted by proof complexity is indeed reflected by recent solver implementations.", "num_citations": "1\n", "authors": ["682"]}
{"title": "Towards Distinction of Rock Art Pecking Styles with a Hybrid 2D/3D Approach\n", "abstract": " We present a qualitative study on the distinction of pecking styles in prehistoric rock art captured by high-resolution 3D scans. Different pecking styles result from different shapes, sizes, depths and spatial distributions of individual peck marks. Pecking style distinction enables inter alia automated detection of superimpositions. To our knowledge, this is the first attempt towards an automatic analysis and characterization of pecking styles in rock art. We model pecking style similarity by local descriptions of the surface joining full 3D and 2D (image-space) representations. Our results show that different pecking styles can be efficiently retrieved and distinguished by combined 3D/2D surface analysis.", "num_citations": "1\n", "authors": ["682"]}
{"title": "Software Technologies: Applications and Foundations: STAF 2017 Collocated Workshops, Marburg, Germany, July 17-21, 2017, Revised Selected Papers\n", "abstract": " This book contains the thoroughly refereed technical papers presented in six workshops collocated with the International Conference on Software Technologies: Applications and Foundations, STAF 2017, held in Marburg, Germany, in July 2017. The 15 full and 22 short papers presented were carefully reviewed and selected from 37 submissions. The events whose papers are included in this volume are: BigMDE 2017: 5th International Workshop on Scalable Model Driven Engineering GCM 2017: 8th International Workshop on Graph Computation Models GRAND 2017: 1st International Workshop on Grand Challenges in Modeling MORSE 2017: 4th International Workshop on Model-driven Robot Software Engineering OCL 2017: 17th International Workshop in OCL and Textual Modeling STAF Projects Showcase 2017: 3rd event dedicated to international and national project dissemination and cooperation", "num_citations": "1\n", "authors": ["682"]}
{"title": "Parallel Solving of Quantified Boolean Formulas\n", "abstract": " Quantified Boolean formulas (QBFs) extend propositional logic by universal and existential quantifiers over the propositional variables. In the same way as the satisfiability problem of propositional logic is the archetypical problem for NP, the satisfiability problem of QBFs is the archetypical problem for PSPACE. Hence, QBFs provide an attractive framework for encoding many applications from verification, artificial intelligence, and synthesis, thus motivating the quest for efficient solving technology. Already in the very early stages of QBF solving history, attempts have been made to parallelize the solving process, either by splitting the search space or by portfolio-based approaches. In this chapter, we review and compare approaches for solving QBFs in parallel.", "num_citations": "1\n", "authors": ["682"]}
{"title": "Lightweight Symbolic Verification of Graph Transformation Systems with Off-the-Shelf Hardware Model Checkers\n", "abstract": " We present a novel symbolic bounded model checking approach to test reachability properties of model-driven software implementations. Given a concrete initial state of a software system, a type graph, and a set of graph transformations, which describe the system\u2019s structure and its behavior, the system is tested against a reachability property that is expressed in terms of a graph constraint. Without any user intervention, our approach exploits state-of-the-art model checking technologies successfully used in hardware industry. The efficiency of our approach is demonstrated in two case studies.", "num_citations": "1\n", "authors": ["682"]}
{"title": "Computational analysis of petroglyphs\n", "abstract": " Numerous petroglyphs have been pecked, scratched and carved into rock surfaces in the northern Italian valley Valcamonica. The classic documentation work carried out by archaeologists is a massively time-consuming process. The rising availability of digital images and 3D scans of petroglyphs facilitates digital workflows which can improve the documentation process. In this thesis, we aim at supporting the classic documentation pipeline for petroglyphs. The first step of the pipeline is the determination of the boundaries and spatial locations of petroglyphs on a rock surface. This is usually done by time-consuming manual contact tracing. Then, the found figures are classified according to their shapes and pecking styles. The large number of petroglyphs (Valcamonica contains up to 300.000 figures) demands large efforts for manual classification. The investigation of pecking styles is often impossible based on the contact tracings and thus requires researchers to return to the rocks frequently. Following the classic documentation pipeline for petroglyphs, we propose and evaluate novel methods. To determine the positions and shapes of petroglyphs on a rock panel we approach segmentation of 2D and 3D petroglyph images in pecked regions and natural rock surface. Furthermore, we use 3D scans to investigate the similarity of pecking styles, i.e. the shape, size, depth and spatial distribution of the peck marks a figure consists of. Finally, we develop a petroglyph shape descriptor which allows the classification of petroglyphs. Our tasks are challenging. The figures have been pecked over thousands of years. The rocks are subject to weathering\u00a0\u2026", "num_citations": "1\n", "authors": ["682"]}
{"title": "MocOCL: A Model Checker for CTL-Extended OCL Specifications\u22c6\n", "abstract": " We present the model checker MocOCL, a tool for model checking software models. The design rationale behind MocOCL is to close the gap between formal verification based on model checking and model-based engineering. Our approach avoids conversions that translate the software models into a format that a model checker can process. To this end, we implemented an explicit state model checker that directly processes the software model and verifies them against a specification formulated in a temporal extension of the constraint language OCL. MocOCL offers a web interface that interacts with the Eclipse Modeling Framework.", "num_citations": "1\n", "authors": ["682"]}
{"title": "Multitouch Rocks: User Experience Metrics for a Multi-user Game on a Multi-touch Table\n", "abstract": " More than 50.000 petroglyphs are engraved in rock panels on the flanks of the UNESCO world heritage site Valcamonica (Northern Italy). The engravings are not always visible and are often on steep slopes on which it is forbidden to walk for conservation reasons. To overcome these problems, and to be able to transfer the rock art experience to other places, we designed a collaborative computer game for a multi-touch tabletop display. The game contains the image of a full rock panel and several mini-games to be played on the panel. This paper describes the game design as well as the interface and interaction design and a large-scale user experience test. We propose novel user experience metrics for multi-user multi-touch tables. We used a public event for a user experience test to validate these metrics. The test achieved largely good results.", "num_citations": "1\n", "authors": ["682"]}
{"title": "Generic vs. Language-Specific Model Versioning\n", "abstract": " In this paper, we discuss how to make a generic model versioning system language-specific by using various adaptation techniques. In particular, we recap some lessons learned during the AMOR project and outline some open challenges for adaptable model versioning systems.", "num_citations": "1\n", "authors": ["682"]}
{"title": "Guiding modelers through conflict resolution: A recommender for model versioning\n", "abstract": " Like traditional code, softwaremodels are usually developed in teams requiring collaboration support in terms of version control systems (VCS). One use case of such a system is integrating concurrently evolved versions of one model into one consistent version. When the modifications are contradicting, then the VCS reports the conflict, but the cumbersome resolution process is left to the user. We present a recommender system which suggests automatically executable conflict resolution patterns.", "num_citations": "1\n", "authors": ["682"]}
{"title": "Software Modeling in Education: The 6th Educators\u2019 Symposium at MODELS 2010\n", "abstract": " The Educators\u2019 Symposium (EduSymp) yields a major forum for software modeling education. Traditionally collocated with the ACM/IEEE International Conference on Model-Driven Engineering Languages and Systems (MODELS), EduSymp offers a unique opportunity for educators to present and discuss innovative pedagogical software modeling approaches. In this paper, a short retrospective on the 6th edition of EduSymp hosted in Oslo is presented. The program was a manifold of activities including interesting and thought-provoking oral presentations, an interactive breakout-session, and a panel discussion.", "num_citations": "1\n", "authors": ["682"]}