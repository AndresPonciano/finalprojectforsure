{"title": "A systematic literature review to identify and classify software requirement errors\n", "abstract": " Most software quality research has focused on identifying faults (i.e., information is incorrectly recorded in an artifact). Because software still exhibits incorrect behavior, a different approach is needed. This paper presents a systematic literature review to develop taxonomy of errors (i.e., the sources of faults) that may occur during the requirements phase of software lifecycle. This taxonomy is designed to aid developers during the requirement inspection process and to improve overall software quality. The review identified 149 papers from the software engineering, psychology and human cognition literature that provide information about the sources of requirements faults. A major result of this paper is a categorization of the sources of faults into a formal taxonomy that provides a starting point for future research into error-based approaches to improving software quality.", "num_citations": "239\n", "authors": ["172"]}
{"title": "Software development environments for scientific and engineering software: A series of case studies\n", "abstract": " The need for high performance computing applications for computational science and engineering projects is growing rapidly, yet there have been few detailed studies of the software engineering process used for these applications. The DARPA High Productivity Computing Systems Program has sponsored a series of case studies of representative computational science and engineering projects to identify the steps involved in developing such applications (i.e. the life cycle, the workflows, technical challenges, and organizational challenges). Secondary goals were to characterize tool usage and identify enhancements that would increase the programmers' productivity. Finally, these studies were designed to develop a set of lessons learned that can be transferred to the general computational science and engineering community to improve the software engineering process used for their applications. Nine lessons\u00a0\u2026", "num_citations": "197\n", "authors": ["172"]}
{"title": "Characterizing software architecture changes: A systematic review\n", "abstract": " With today\u2019s ever increasing demands on software, software developers must produce software that can be changed without the risk of degrading the software architecture. One way to address software changes is to characterize their causes and effects. A software change characterization mechanism allows developers to characterize the effects of a change using different criteria, e.g. the cause of the change, the type of change that needs to be made, and the part of the system where the change must take place. This information then can be used to illustrate the potential impact of the change. This paper presents a systematic literature review of software architecture change characteristics. The results of this systematic review were used to create the Software Architecture Change Characterization Scheme (SACCS). This report addresses key areas involved in making changes to software architecture. SACCS\u2019s\u00a0\u2026", "num_citations": "188\n", "authors": ["172"]}
{"title": "Towards reporting guidelines for experimental replications: A proposal\n", "abstract": " The value of experimental replications has been well established. In order for the replicating researcher and the community to receive the greatest benefit from a replication, the right information about it must be published. This paper proposes publishing guidelines to increase the value of experimental replications. First, a review of some published replications highlights the variation in current publishing practice. Then, a set of guidelines are proposed. The goal of this paper is to provide a starting point for a discussion that will formalize and publish a set of guidelines.", "num_citations": "147\n", "authors": ["172"]}
{"title": "Evaluating source code summarization techniques: Replication and expansion\n", "abstract": " During software evolution a developer must investigate source code to locate then understand the entities that must be modified to complete a change task. To help developers in this task, Haiduc et al. proposed text summarization based approaches to the automatic generation of class and method summaries, and via a study of four developers, they evaluated source code summaries generated using their techniques. In this paper we propose a new topic modeling based approach to source code summarization, and via a study of 14 developers, we evaluate source code summaries generated using the proposed technique. Our study partially replicates the original study by Haiduc et al. in that it uses the objects, the instruments, and a subset of the summaries from the original study, but it also expands the original study in that it includes more subjects and new summaries. The results of our study both support the\u00a0\u2026", "num_citations": "99\n", "authors": ["172"]}
{"title": "Claims about the use of software engineering practices in science: A systematic literature review\n", "abstract": " Context: Scientists have become increasingly reliant on software in order to perform research that is too time-intensive, expensive, or dangerous to perform physically. Because the results produced by the software drive important decisions, the software must be correct and developed efficiently. Various software engineering practices have been shown to increase correctness and efficiency in the development of traditional software. It is unclear whether these observations will hold in a scientific context.Objective: This paper evaluates claims from software engineers and scientific software developers about 12 different software engineering practices and their use in developing scientific software.Method: We performed a systematic literature review examining claims about how scientists develop software. Of the 189 papers originally identified, 43 are included in the literature review. These 43 papers contain 33\u00a0\u2026", "num_citations": "82\n", "authors": ["172"]}
{"title": "Increased retention of early computer science and software engineering students using pair programming\n", "abstract": " An important problem faced by many Computer Science and Software Engineering programs is declining enrollment. In an effort to reverse that trend at Mississippi State University, we have instituted pair programming for the laboratory exercises in the introductory programming course. This paper describes a study performed to analyze whether using pair programming would increase retention. An important goal of this study was not only to measure increased retention, but to provide insight into why retention increased or decreased. The results of the study showed that retention significantly increased for those students already majoring in Computer Science, Software Engineering, or Computer Engineering. In addition, survey results indicated that the students viewed many aspects of pair programming to be very beneficial to their learning experience.", "num_citations": "81\n", "authors": ["172"]}
{"title": "The impact of background and experience on software inspections\n", "abstract": " This dissertation is an initial study into the relationship between an inspector's characteristics and his or her effectiveness in an inspection. Research has shown that improving the individual effectiveness of the inspectors improves the overall effectiveness of an inspection team. But, the performance of inspectors varies widely, even when using the same inspection technique. This variation is often due to the inherent differences among the inspectors who used the technique. In order to better understand this variation and provide guidance to inspection planners, this dissertation has focused on the background and experience of the inspector as the source of variation.", "num_citations": "73\n", "authors": ["172"]}
{"title": "Identifying barriers to the systematic literature review process\n", "abstract": " Conducting a systematic literature review (SLR) is difficult and time-consuming for an experienced researcher, and even more so for a novice graduate student. With a better understanding of the most common difficulties in the SLR process, mentors will be better prepared to guide novices through the process. This understanding will help researchers have more realistic expectations of the SLR process and will help mentors guide novices through its planning, execution, and documentation phases. Consequently, the objectives of this work are to identify the most difficult and time-consuming phases of the SLR process. Using data from two sources - 52 responses to an online survey sent to all authors of SLRs published in software engineering venues and qualitative experience reports from 8 PhD students who conducted SLRs as part of a course - we identified specific difficulties related to each phase of the SLR\u00a0\u2026", "num_citations": "72\n", "authors": ["172"]}
{"title": "Measuring the efficacy of code clone information in a bug localization task: An empirical study\n", "abstract": " Much recent research effort has been devoted to designing efficient code clone detection techniques and tools. However, there has been little human-based empirical study of developers as they use the outputs of those tools while performing maintenance tasks. This paper describes a study that investigates the usefulness of code clone information for performing a bug localization task. In this study 43 graduate students were observed while identifying defects in both cloned and non-cloned portions of code. The goal of the study was to understand how those developers used clone information to perform this task. The results of this study showed that participants who first identified a defect then used it to look for clones of the defect were more effective than participants who used the clone information before finding any defects. The results also show a relationship between the perceived efficacy of the clone\u00a0\u2026", "num_citations": "52\n", "authors": ["172"]}
{"title": "Identification of SLR tool needs\u2013results of a community workshop\n", "abstract": " Context: With the increasing popularity of the Systematic Literature Review (SLR) process, there is also an increasing need for tool support. Objective:The goal of this work was to consult the software engineering researchers who conduct SLRs to identify and prioritize the necessary SLR tool features. Method: To gather information required to address this goal, we invited SLR authors to participate in an interactive 2\u00a0h workshop structured around the Nominal Group Technique. Results: The workshop outcomes indicated that Search & Selection and Collaboration are the two highest priority tool features. The results also showed that most of the high-priority features are not well-supported in current tools. Conclusion: These results support and extend the results of prior work. SLR tool authors can use these findings to guide future development efforts.", "num_citations": "45\n", "authors": ["172"]}
{"title": "Outcomes of a community workshop to identify and rank barriers to the systematic literature review process\n", "abstract": " Systematic Literature Reviews (SLRs) are an important tool used by software engineering researchers to summarize the state of knowledge about a particular topic. Currently, SLR authors must perform the difficult, time-consuming task in largely manual fashion. To identify barriers faced by SLR authors, we conducted an interactive community workshop prior to ESEM'13. Workshop participants generated a total of 100 ideas that, through group discussions, formed 37 composite barriers to the SLR process. Further analysis reveals the barriers relate to latent themes regarding the SLR process, primary studies, the practitioner community, and tooling. This paper describes the barriers identified during the workshop along with a ranking of those barriers that is based on votes by workshop attendees. The paper concludes by describing the impact of these barriers on three important constituencies: SLR Methodology\u00a0\u2026", "num_citations": "43\n", "authors": ["172"]}
{"title": "Effects of cloned code on software maintainability: A replicated developer study\n", "abstract": " Code clones are a common occurrence in most software systems. Their presence is believed to have an effect on the maintenance process. Although these effects have been previously studied, there is not yet a conclusive result. This paper describes an extended replication of a controlled experiment (i.e. a strict replication with an additional task) that analyzes the effects of cloned bugs (i.e. bugs in cloned code) on the program comprehension of programmers. In the strict replication portion, the study participants attempted to isolate and fix two types of bugs, cloned and non-cloned, in one of two small systems. In the extension of the original study, we provided the participants with a clone report describing the location of all cloned code in the other system and asked them to again isolate and fix cloned and non-cloned bugs. The results of the original study showed that cloned bugs were not significantly more difficult\u00a0\u2026", "num_citations": "41\n", "authors": ["172"]}
{"title": "Development of a human error taxonomy for software requirements: a systematic literature review\n", "abstract": " BackgroundHuman-centric software engineering activities, such as requirements engineering, are prone to error. These human errors manifest as faults. To improve software quality, developers need methods to prevent and detect faults and their sources.AimsHuman error research from the field of cognitive psychology focuses on understanding and categorizing the fallibilities of human cognition. In this paper, we applied concepts from human error research to the problem of software quality.MethodWe performed a systematic literature review of the software engineering and psychology literature to identify and classify human errors that occur during requirements engineering.ResultsWe developed the Human Error Taxonomy (HET) by adding detailed error classes to Reason's well-known human error taxonomy of Slips, Lapses, and Mistakes.ConclusionThe process of identifying and classifying human error\u00a0\u2026", "num_citations": "40\n", "authors": ["172"]}
{"title": "Using error abstraction and classification to improve requirement quality: conclusions from a family of four empirical studies\n", "abstract": " Achieving high software quality is a primary concern for software development organizations. Researchers have developed many quality improvement methods that help developers detect faults early in the lifecycle. To address some of the limitations of fault-based quality improvement approaches, this paper describes an approach based on errors (i.e. the sources of the faults). This research extends Lanubile et al.\u2019s, error abstraction process by providing a formal requirement error taxonomy to help developers identify both faults and errors. The taxonomy was derived from the software engineering and psychology literature. The error abstraction and classification process and the requirement error taxonomy are validated using a family of four empirical studies. The main conclusions derived from the four studies are: (1) the error abstraction and classification process is an effective approach for identifying\u00a0\u2026", "num_citations": "40\n", "authors": ["172"]}
{"title": "The use of grounded theory in empirical software engineering\n", "abstract": " Empirical software engineering research has much in common with social science research (e.g. Cognitive Science, Psychology). Both types of research focus on understanding how people behave and react in different situations. An important research method for developing hypotheses and insight that is commonly used in these other fields is grounded theory. The basic principle behind grounded theory is that the hypotheses and theories emerge bottom-up from the data rather than top-down from existing theory. Using this approach, a researcher begins with an existing data set and abstracts a hypothesis or a theory that accurately describes that data. Then, as more data sets become available, the hypotheses and theories are refined so that they continue to accurately describe all of the extant data.", "num_citations": "39\n", "authors": ["172"]}
{"title": "Self-perceptions about software engineering: A survey of scientists and engineers\n", "abstract": " Scientists and engineers devote considerable effort to developing large, complex codes to solve important problems. However, while they often develop useful code, many scientists and engineers are frequently unaware of how various software engineering practices can help them write better code. This article presents the results of a survey on this topic.", "num_citations": "37\n", "authors": ["172"]}
{"title": "Development of a weather forecasting code: A case study\n", "abstract": " Computational science is increasingly supporting advances in scientific and engineering knowledge. The unique constraints of these types of projects result in a development process that differs from the process more traditional information technology projects use. This article reports the results of the sixth case study conducted under the support of the Darpa High Productivity Computing Systems Program. The case study aimed to investigate the technical challenges of code development in this environment, understand the use of development tools, and document the findings as concrete lessons learned for other developers' benefit. The project studied here is a major component of a weather forecasting system of systems. It includes complex behavior and interaction of several individual physical systems (such as the atmosphere and the ocean). This article describes the development of the code and presents\u00a0\u2026", "num_citations": "37\n", "authors": ["172"]}
{"title": "Requirement error abstraction and classification: an empirical study\n", "abstract": " Software quality and reliability is a primary concern for successful development organizations. Monitoring and controlling quality by helping developers detect as many faults as possible is a subjective and intricate approach. Due to the inherent difficulties and limitations, additional methods are required to obtain a more complete solution to the software quality problem. This paper analyzes the software quality problem from a different perspective involving a step back from faults to focus on the fundamental causes of faults. The first step in this direction is the application of the Error Abstraction Process (EAP) to the requirements phase of the software lifecycle to develop a Requirement Error Taxonomy (RET). This paper presents an empirical study on the application of the EAP and RET to requirement documents in a controlled classroom setting. The results show that the EAP significantly improves the productivity of\u00a0\u2026", "num_citations": "37\n", "authors": ["172"]}
{"title": "Change Risk Assessment: Understanding Risks Involved in Changing Software Requirements.\n", "abstract": " One certainty in software development is that all projects will have to deal with change. Being able to effectively handle proposed changes is crucial for allowing continued development of a software project to occur. In order to effectively manage the changes and their effects, developers must first assess the risks involved in making the change. To understand the risks, the project manager must determine how the change will affect not only the source code, but also the entire project. These risks may affect a project\u2019s schedule, budget, and quality factors. Risk assessment will help to determine if the desired change can be implemented into the system. This paper identifies risks associated with late changes to the software requirements. Late changes are those changes that occur after one cycle of the development process has been completed and a working version of the system exists. It is important to understand late changes, because late changes to requirements often result in the most cost to an ongoing development project both in time and money. In this paper we identify several key risks that must be addressed when dealing with late changes to requirements. Then we provide a discussion of techniques for handling those risks.", "num_citations": "36\n", "authors": ["172"]}
{"title": "A proposed taxonomy for software development risks for high-performance computing (HPC) scientific/engineering applications\n", "abstract": " Because the development of large-scale scientificengineering application codes is an often difficult, complicated, and sometimes uncertain process, success depends on identifying and managing risk. One of the drivers of the evolution of software engineering, as a discipline, has been the desire to identify reliable, quantifiable ways to manage software development risks. The taxonomy that follows represents an attempt to organize the sources of software development risk for scientificengineering applications around three principal aspects of the software development activity the software development cycle, the development environment, and the programmatic environment. These taxonomic classes are divided into elements and each element is further characterized by its attributes.Descriptors:", "num_citations": "33\n", "authors": ["172"]}
{"title": "Report: the second international workshop on software engineering for CSE\n", "abstract": " Held during the 2009 International Conference on Software Engineering, this workshop provided a venue for software engineering researchers to interact with CSE researchers and practitioners and further strengthen the evolving dialogue between them. This report offers a brief overview of the workshop's position papers and summarizes the breakout group discussions.", "num_citations": "29\n", "authors": ["172"]}
{"title": "An empirical study of the effects of gestalt principles on diagram understandability\n", "abstract": " Comprehension errors in software design must be detected at their origin to avoid propagation into later portions of the software lifecycle and also the final system. This research synthesizes software engineering and Gestalt principles of similarity, proximity, continuity for the purpose of discovering whether certain visual attributes of diagrams can affect the accuracy and efficiency of understanding the diagram. The experiment tested whether two dependent variables, accuracy and response time, were significantly affected by independent variables, diagram type (simple 1, simple2, complex), Gestalt principles (good vs. bad), and question order (forward/backward). The results of this study indicated that the Gestalt principles did affect the comprehension in the complex diagrams. Post-hoc analysis results indicated that number of bends per line, length of line in inches, number of lines crossing, boxes per diagram, and\u00a0\u2026", "num_citations": "29\n", "authors": ["172"]}
{"title": "PBR vs. checklist: a replication in the n-fold inspection context\n", "abstract": " Inspection is considered a powerful method to check software documents for defects. Many published work shows that inspections in requirements specification phase are particularly effective and efficient. Perspective-Based Reading (PBR) is one of the systematic techniques to support defect detection in requirements documents. In this paper we describe an experiment to validate the effectiveness of PBR in a meeting-based N-fold inspection. Our goals were:(1) re-test the hypothesis of the original experiment that PBR helps to increase individual and team defect detection effectiveness compared to an checklist approach;(2) investigate the different impact of PBR and checklist on the effectiveness of N-fold team meeting; and (3) investigate some interesting characteristics of PBR (eg the relationship between background experiences and performance of the subjects). The results of the study showed that PBR was\u00a0\u2026", "num_citations": "29\n", "authors": ["172"]}
{"title": "Are one-time contributors different? a comparison to core and periphery developers in floss repositories\n", "abstract": " Context: Free/Libre Open Source Software (FLOSS) communities consist of different types of contributors. Core contributors and peripheral contributors work together to create a successful project, each playing a different role. One-Time Contributors (OTCs), who are on the very fringe of the peripheral developers, are largely unstudied despite offering unique insights into the development process. In a prior survey, we identified OTCs and discovered their motivations and barriers. Aims: The objective of this study is to corroborate the survey results and provide a better understand of OTCs. We compare OTCs to other peripheral and core contributors to determine whether they are distinct. Method: We mined data from the same code-review repository used to identify survey respondents in our previous study. After identifying each contributor as core, periphery, or OTC, we compared them in terms of patch size, time\u00a0\u2026", "num_citations": "27\n", "authors": ["172"]}
{"title": "Evaluating the testing ability of senior-level computer science students\n", "abstract": " Testing is a key skill for computer science students to acquire during their studies. To determine how well students are learning this skill, we conducted an empirical study in two offerings of a senior-level computer science course. The goal of the study was to determine whether students would be able to create a small, complete test suite for a simple program. The students created a test suite first without the aid of a coverage tool and then with the aid of a coverage tool. The results indicate that without a coverage tool, students achieved significantly less than 100% statement, branch or condition coverage. When provided with a code coverage tool, students increased coverage levels. Still, examination of the test suites indicated that they were significantly larger than the minimum required. These results indicate that students cannot conduct adequate testing of even a small program. To provide context for our results\u00a0\u2026", "num_citations": "27\n", "authors": ["172"]}
{"title": "Test-Driven Development in scientific software: a survey\n", "abstract": " Scientific software developers are increasingly employing various software engineering practices. Specifically, scientists are beginning to use Test-Driven Development (TDD). Even with this increasing use of TDD, the effect of TDD on scientific software development is not fully understood. To help scientific developers determine whether TDD is appropriate for their scientific projects, we surveyed scientific developers who use TDD to understand: (1) TDDs effectiveness, (2) the benefits and challenges of using TDD, and (3) the use of refactoring practices (an important part of the TDD process). Some key positive results include: (1) TDD helps scientific developers increase software quality, in particular functionality and reliability; and (2) TDD helps scientific developers reduce the number of problems in the early phase of projects. Conversely, some key challenges include: (1) TDD may not be effective for all\u00a0\u2026", "num_citations": "26\n", "authors": ["172"]}
{"title": "Software engineering for computational science and engineering\n", "abstract": " The guest editor describes the key issues and ongoing concerns in the field of software engineering for computational science and engineering, and discusses how the articles in this special issue explore necessary solutions.", "num_citations": "26\n", "authors": ["172"]}
{"title": "FLOSS participants' perceptions about gender and inclusiveness: a survey\n", "abstract": " Background: While FLOSS projects espouse openness and acceptance for all, in practice, female contributors often face discriminatory barriers to contribution. Aims: In this paper, we examine the extent to which these problems still exist. We also study male and female contributors' perceptions of other contributors. Method: We surveyed participants from 15 FLOSS projects, asking a series of open-ended, closed-ended, and behavioral scale questions to gather information about the issue of gender in FLOSS projects. Results: Though many of those we surveyed expressed a positive sentiment towards females who participate in FLOSS projects, some were still strongly against their inclusion. Often, the respondents who were against inclusiveness also believed their own sentiments were the prevailing belief in the community, contrary to our findings. Others did not see the purpose of attempting to be inclusive\u00a0\u2026", "num_citations": "24\n", "authors": ["172"]}
{"title": "Software engineering for science\n", "abstract": " Software Engineering for Science provides an in-depth collection of peer-reviewed chapters that describe experiences with applying software engineering practices to the development of scientific software. It provides a better understanding of how software engineering is and should be practiced, and which software engineering practices are effective for scientific software. The book starts with a detailed overview of the Scientific Software Lifecycle, and a general overview of the scientific software development process. It highlights key issues commonly arising during scientific software development, as well as solutions to these problems. The second part of the book provides examples of the use of testing in scientific software development, including key issues and challenges. The chapters then describe solutions and case studies aimed at applying testing to scientific software development efforts. The final part of the book provides examples of applying software engineering techniques to scientific software, including not only computational modeling, but also software for data management and analysis. The authors describe their experiences and lessons learned from developing complex scientific software in different domains. About the Editors Jeffrey Carver is an Associate Professor in the Department of Computer Science at the University of Alabama. He is one of the primary organizers of the workshop series on Software Engineering for Science (http://www. SE4Science. org/workshops). Neil P. Chue Hong is Director of the Software Sustainability Institute at the University of Edinburgh. His research interests include barriers and incentives in\u00a0\u2026", "num_citations": "23\n", "authors": ["172"]}
{"title": "Using a cognitive psychology perspective on errors to improve requirements quality: An empirical investigation\n", "abstract": " Software inspections are an effective method for early detection of faults present in software development artifacts (e.g., requirements and design documents). However, many faults are left undetected due to the lack of focus on the underlying sources of faults (i.e., what caused the injection of the fault?). To address this problem, research work done by Psychologists on analyzing the failures of human cognition (i.e., human errors) is being used in this research to help inspectors detect errors and corresponding faults (manifestations of errors) in requirements documents. We hypothesize that the fault detection performance will demonstrate significant gains when using a formal taxonomy of human errors (the underlying source of faults). This paper describes a newly developed Human Error Taxonomy (HET) and a formal Error-Abstraction and Inspection (EAI) process to improve fault detection performance of\u00a0\u2026", "num_citations": "23\n", "authors": ["172"]}
{"title": "Design patterns in software maintenance: An experiment replication at University of Alabama\n", "abstract": " Design patterns are widely used within the software engineer community. Researchers claim that design patterns improve software quality. In this paper, we describe two experiments, using graduate student participants, to study whether design patterns improve the software quality, specifically maintainability and understandability. We replicated a controlled experiment to compare the maintainability of two implementations of an application, one using a design pattern and the other using a simpler alternative. The maintenance tasks in this replication experiment required the participants to answer questions about a Java program and then modify that program. Prior to the replication, we performed a preliminary exercise to investigate whether design patterns improve the understandability of software designs. We gave the participants the graphical design of the systems that would be used in the replication study. The\u00a0\u2026", "num_citations": "23\n", "authors": ["172"]}
{"title": "Effectiveness of Human Error Taxonomy during Requirements Inspection: An Empirical Investigation.\n", "abstract": " Software inspections are an effective method for achieving high quality software. We hypothesize that inspections focused on identifying errors (ie, root cause of faults) are better at finding requirements faults when compared to inspection methods that rely on checklists created using lessons-learned from historical fault-data. Our previous work verified that, error based inspections guided by an initial requirements errors taxonomy (RET) performed significantly better than standard fault-based inspections. However, RET lacked an underlying human information processing model grounded in Cognitive Psychology research. The current research reports results from a systematic literature review (SLR) of Software Engineering and Cognitive Science literature-Human Error Taxonomy (HET) that contains requirements phase human errors. The major contribution of this paper is a report of control group study that compared the fault detection effectiveness and usefulness of HET with the previously validated RET. Results of this study show that subjects using HET were not only more effective at detecting faults, but they found faults faster. Post-hoc analysis of HET also revealed meaningful insights into the most commonly occurring human errors at different points during requirements development. The results provide motivation and feedback for further refining HET and creating formal inspection tools based on HET.", "num_citations": "22\n", "authors": ["172"]}
{"title": "First international workshop on software engineering for computational science & engineering\n", "abstract": " In recognition of the general lack of exposure scientists have to software engineering and vice versa, a workshop was held during the 2008 International Conference on Software Engineering in Leipzig, Germany. The workshop's goal was to bring together researchers and practitioners from the software engineering and computational science and engineering (CS&E) communities to build a common understanding of the issues involved in the complex process of CS&E software development and identify common themes to pursue in future research.", "num_citations": "22\n", "authors": ["172"]}
{"title": "Requirement error abstraction and classification: a control group replicated study\n", "abstract": " This paper is the second in a series of empirical studies about requirement error abstraction and classification as a quality improvement approach. The Requirement error abstraction and classification method supports the developers' effort in efficiently identifying the root cause of requirements faults. By uncovering the source of faults, the developers can locate and remove additional related faults that may have been overlooked, thereby improving the quality and reliability of the resulting system. This study is a replication of an earlier study that adds a control group to address a major validity threat. The approach studied includes a process for abstracting errors from faults and provides a requirement error taxonomy for organizing those errors. A unique aspect of this work is the use of research from human cognition to improve the process. The results of the replication are presented and compared with the results from\u00a0\u2026", "num_citations": "22\n", "authors": ["172"]}
{"title": "Vision for SLR tooling infrastructure: Prioritizing value-added requirements\n", "abstract": " ContextEven with the increasing use of Systematic Literature Reviews (SLR) in software engineering (SE), there are still a number of barriers faced by SLR authors. These barriers increase the cost of conducting SLRs.ObjectiveFor many of these barriers, appropriate tool support could reduce their impact. In this paper, we use interactions with the SLR community in SE to identify and prioritize a set of requirements for SLR tooling infrastructure.MethodThis paper analyzes and combines the results from three studies on SLR process barriers and SLR tool requirements to produce a prioritized list of functional requirements for SLR tool support. Using this list of requirements, we perform a feature analysis of the current SLR support tools to identify requirements that are supported as well as identify the need for additional tooling infrastructure.ResultsThe analysis resulted in a list 112 detailed requirements (consolidated\u00a0\u2026", "num_citations": "21\n", "authors": ["172"]}
{"title": "Specification and reasoning in SE projects using a Web IDE\n", "abstract": " A key goal of our research is to introduce an approach that involves at the outset using analytical reasoning as a method for developing high quality software. This paper summarizes our experiences in introducing mathematical reasoning and formal specification-based development using a web-integrated environment in an undergraduate software engineering course at two institutions at different levels, with the goal that they will serve as models for other educators. At Alabama, the reasoning topics are introduced over a two-week period and are followed by a project. At Clemson, the topics are covered in more depth over a five-week period and are followed by specification-based software development and reasoning assignments. The courses and project assignments have been offered for multiple semesters. Evaluation of student performance indicates that the learning goals were met.", "num_citations": "21\n", "authors": ["172"]}
{"title": "Position paper: The importance of experience with industry in software engineering education\n", "abstract": " This paper describes experiences and lessons learned at an ABET accredited software engineering program with respect to students at the undergraduate and graduate levels studying and/or researching the application of software engineering techniques. Examples of successful interactions are provided as well as the rationale for including industry experience. Disadvantages of such interactions are also included when appropriate.", "num_citations": "21\n", "authors": ["172"]}
{"title": "Extracting uml class diagrams from object-oriented fortran: Foruml\n", "abstract": " Many scientists and engineers who implement high performance computing (HPC) software have adopted the object-oriented (OO) Fortran paradigm. One of the challenges faced by OO Fortran developers is the inability to obtain high level software design descriptions of existing applications. Knowledge of the overall software design is not only valuable in the absence of documentation, it can also serve to assist developers with accomplishing different tasks during the software development process, especially maintenance and refactoring. The software engineering community commonly uses reverse engineering techniques to deal with this challenge. A number of reverse engineering-based tools have been proposed, but few of them can be applied to object-oriented Fortran applications.", "num_citations": "19\n", "authors": ["172"]}
{"title": "Evaluation of capture-recapture models for estimating the abundance of naturally-occurring defects\n", "abstract": " Project managers can use capture-recapture models to manage the inspection process by estimating the number of defects present in an artifact and determining whether a reinspection is necessary. Researchers have previously evaluated capture-recapture models on artifacts with a known number of defects. Before applying capture-recapture models in real development, an evaluation of those models on naturally-occurring defects is imperative. The data in this study is drawn from two inspections of real requirements documents (that later guided implementation) created as part of a capstone course (ie with naturally occurring defects). The major results show that: a) estimators improve from being negatively biased after one inspection to being positively biased after two inspections, b) the results contradict the earlier result that a model that includes two sources of variation is a significant improvement over models\u00a0\u2026", "num_citations": "19\n", "authors": ["172"]}
{"title": "Detection of requirement errors and faults via a human error taxonomy: a feasibility study\n", "abstract": " Background: Developing correct software requirements is important for overall software quality. Most existing quality improvement approaches focus on detection and removal of faults (ie problems recorded in a document) as opposed identifying the underlying errors that produced those faults. Accordingly, developers are likely to make the same errors in the future and fail to recognize other existing faults with the same origins. Therefore, we have created a Human Error Taxonomy (HET) to help software engineers improve their software requirement specification (SRS) documents. Aims: The goal of this paper is to analyze whether the HET is useful for classifying errors and for guiding developers to find additional faults. Methods: We conducted a empirical study in a classroom setting to evaluate the usefulness and feasibility of the HET. Results: First, software developers were able to employ error categories in the\u00a0\u2026", "num_citations": "18\n", "authors": ["172"]}
{"title": "A (updated) review of empiricism at the sigcse technical symposium\n", "abstract": " The computer science education (CSEd) research community consists of a large group of passionate CS educators who often contribute to other disciplines of CS research. There has been a trend in other disciplines toward more rigorous and empirical evaluation of various hypotheses. Prior investigations of the then-current state of CSEd research showed a distinct lack of rigor in the top research publication venues, with most papers falling in the general category of experience reports. In this paper, we present our examination of the two most recent proceedings of the SIGCSE Technical Symposium, providing a snapshot of the current state of empiricism at the largest CSEd venue. Our goal to categorize the current state of empiricism in the SIGCSE Technical Symposium and identify where the community might benefit from increased empiricism when conducting CSEd research. We found an increase in empirical\u00a0\u2026", "num_citations": "18\n", "authors": ["172"]}
{"title": "A visual analytic framework for exploring relationships in textual contents of digital forensics evidence\n", "abstract": " We describe the development of a set of tools for analyzing the textual contents of digital forensic evidence for the purpose of enhancing an investigator's ability to discover information quickly and efficiently. By examining the textual contents of files and unallocated space, relationships between sets of files and clusters can be formed based on the information that they contain. Using the information gathered from the evidence through the analysis tool, the visualization tool can be used to search through the evidence in an organized and efficient manner. The visualization depicts both the frequency of relevant terms and their location on disk. We also discuss a task analysis with forensics officers to motivate the design.", "num_citations": "17\n", "authors": ["172"]}
{"title": "Code clones and developer behavior: results of two surveys of the clone research community\n", "abstract": " The literature presents conflicting claims regarding the effects of clones on software maintainability. For a community to progress, it is important to identify and address those areas of disagreement. Many claims, such as those related to developer behavior, either lack human-based empirical validation or are contradicted by other studies. This paper describes the results of two surveys to evaluate the level of agreement among clone researchers regarding claims that have not yet been validated through human-based empirical study. The surveys covered three key clone-related research topics: general information, developer behavior, and evolution. Survey 1 focused on high-level information about all three topics, whereas Survey 2 focused specifically on developer behavior. Approximately 20 clone researchers responded to each survey. The survey responses showed a lack of agreement on some major\u00a0\u2026", "num_citations": "16\n", "authors": ["172"]}
{"title": "Best Practices for managing the fuzzy front-end of software development (SD): Insights from a systematic review of new product development (NPD) literature\n", "abstract": " Although they have followed independent paths of development, the two fields of software development (SD) and new product development (NPD) face common problems (Buyukozkan and Feyzioglu, 2004; Shane and Ulrich, 2004) and share many similarities (Nambisan and Wilemon, 2000). The research findings in the NPD domain are therefore relevant to SD (Nambisan and Wilemon, 2000). In this article we conduct a systematic literature review to identify the empirically validated best practices in the fuzzy front end (FFE) phase of NPD. The findings presented in this article will be useful as any improvement in the upstream front end phase of SD can result in the most positive impact on downstream SD activities (Hannola, Oinonen and Nikula, 2011).", "num_citations": "16\n", "authors": ["172"]}
{"title": "An empirical evaluation of a testing and debugging methodology for Excel\n", "abstract": " Spreadsheets are one of the most commonly used types of programs in the world, and it is important that they be sufficiently dependable. To help end users who create spreadsheets do so more reliably, we have created a testing and debugging methodology and environment for use in spreadsheets, known as the WYSIWYT methodology. Our prior experiments with WYSIWYT show that users can utilize it to ensure that their spreadsheets are more dependable, but these experiments to date have considered only an unfamiliar prototype spreadsheet environment, and have not involved spreadsheet creation tasks. In this work we conducted a controlled experiment that addresses these limitations. The results of this study indicate that the use of WYSIWYT did not affect the correctness of spreadsheets created by users, but it did significantly reduce the amount of effort required to create them. Further, the subjects'\u00a0\u2026", "num_citations": "16\n", "authors": ["172"]}
{"title": "Identification and prioritization of SLR search tool requirements: an SLR and a survey\n", "abstract": " Context                 The number of published systematic literature reviews (SLRs) in software engineering venues is increasing. However, even with their high adaptation rate, the task of performing an SLR requires a large amount of effort and presents a number of barriers. Specifically, during the SLR search phase authors must expend a lot of time and overcome a large number of barriers.                                               Objective                  To help alleviate some of the barriers in the search phase, we identify and prioritize SLR search tool requirements based on input from the SLR community. These requirements will help tool builders ensure they focus their efforts appropriately.                                               Method                 We conducted an SLR and a survey of SLR authors in software engineering. In the SLR we extracted problems and solutions SLR authors reported during their search processes. In the\u00a0\u2026", "num_citations": "15\n", "authors": ["172"]}
{"title": "Assessing the Frequency of Empirical Evaluation in Software Modeling Research.\n", "abstract": " Researchers in software modeling often publish new tools or methodologies that claim to offer some advantage to the modeling community. There are different methods by which those claims can be evaluated. In this paper, we examine the degree to which such claims are supported by various types of empirical evaluation. We surveyed five editions of the MoDELS conference from 2006-2010, as well as the primary conference that focuses on empirical software engineering (the International Symposium on EmpiricalSoftware Engineering and Metrics), to understand the frequency with which empirical evaluation has been reported in the software modeling community. Our summary of 266 MoDELS papers found that 195 (73%) of the publications performed no empirical evaluation. This paper summarizes our findings from that survey and offers recommendations for improving the awareness and need for empirical evaluation in software modeling research.", "num_citations": "15\n", "authors": ["172"]}
{"title": "An empirical study of power aware load balancing in local cloud architectures\n", "abstract": " In this paper, resource load balancing is empirically investigated from the perspective of power consumption and resource availability. An experiment was conducted to investigate the impact of introducing a power aware load balancing algorithm on availability and operational cost of a local cloud as it scales to size. The experiment involved a comparison of a conventional round robin approach to load balancing with a proposed new power aware load balancing algorithm. The results have shown that there is significant cost savings while implementing the power aware algorithms. There also may be a trade-off in cost savings versus availability. In our experiment, a user may incur a waiting period as a compute node powers on. Our algorithm uses a best effort approach to reduce the latency on availability of resources.", "num_citations": "14\n", "authors": ["172"]}
{"title": "Cloning: The need to understand developer intent\n", "abstract": " Many researchers have studied the positive and negative effects of code clones on software quality. However, little is known about the intent and rationale of the developers who clone code. Studies have shown that reusing code is a common practice for developers while programming, but there are many possible motivations for and approaches to code reuse. Although we have some ideas about the intentions of developers when cloning code, comprehensive research is needed to gather conclusive evidence about these intentions and categorize clones based on them. In this paper we argue that to provide developers with better clone management tools, we need to interview developers to better understand their intentions when managing cloned code.", "num_citations": "13\n", "authors": ["172"]}
{"title": "Joint UIUC/UMD parallel algorithms/programming course\n", "abstract": " This extended abstract reviews an education experiment conducted through shared teleconferencing sessions between a University of Illinois course on Parallel Programming for Science and Engineering Majors and a University of Maryland on Parallel Algorithms in fall 2010, as well as shared programming assignments. The students were given the opportunity to compare OpenMP programming on an 8-processor SMP machine with PRAM-like programming using a 64-processor XMT machine.", "num_citations": "13\n", "authors": ["172"]}
{"title": "Characterizing software architecture changes: An initial study\n", "abstract": " With today's ever increasing demands on software, developers must produce software that can be changed without the risk of degrading the software architecture. Degraded software architecture is problematic because it makes the system more prone to defects and increases the cost of making future changes. The effects of making changes to software can be difficult to measure. One way to address software changes is to characterize their causes and effects. This paper introduces an initial architecture change characterization scheme created to assist developers in measuring the impact of a change on the architecture of the system. It also presents an initial study conducted to gain insight into the validity of the scheme. The results of this study indicated a favorable view of the viability of the scheme by the subjects, and the scheme increased the ability of novice developers to assess and adequately estimate\u00a0\u2026", "num_citations": "13\n", "authors": ["172"]}
{"title": "Using human error information for error prevention\n", "abstract": " Developing error-free software requirements is of critical importance to the success of a software project. Problems that occur during requirements collection and specification, if not fixed early, are costly to fix later. Therefore, it is important to develop techniques that help requirements engineers detect and prevent requirements problems. As a human-centric activity, requirements engineering can be influenced by psychological research about human errors, which are the failings of human cognition during the process of planning and executinge a task. We have employed human error research to describe the types of problems that occur during requirements engineering. The goals of this research are: (1) to evaluate whether understanding human errors contributes to the prevention of errors and concomitant faults during requirements engineering and (2) to identify error prevention techniques used in\u00a0\u2026", "num_citations": "12\n", "authors": ["172"]}
{"title": "Examination of the software architecture change characterization scheme using three empirical studies\n", "abstract": " Software maintenance is one of the most crucial aspects of software development. Software engineering researchers must develop practical solutions to handle the challenges presented in maintaining mature software systems. Research that addresses practical means of mitigating the risks involved when changing software, reducing the complexity of mature software systems, and eliminating the introduction of preventable bugs is paramount to today\u2019s software engineering discipline. The Software Architecture Change Characterization Scheme (SACCS) provides software maintainers with a systematic approach to analyzing and characterizing the impact of a change prior to its implementation. SACCS was designed to help novice developers understand change requests, facilitate discussion among developers, and provide a higher-quality change compared with an ad hoc approach. In addition, this paper\u00a0\u2026", "num_citations": "12\n", "authors": ["172"]}
{"title": "Software engineering for computational science and engineering [guest editors' introduction]\n", "abstract": " This special issue contains extensions of the best papers from the 2013 International Workshop on Software Engineering for Computational Science and Engineering. In addition to summaries of the included articles, this introduction also contains a summary of the workshop discussion.", "num_citations": "12\n", "authors": ["172"]}
{"title": "Claims and beliefs about code clones: Do we agree as a community? a survey\n", "abstract": " Research on code clones and their impact on software development has been increasing in recent years. There are a number of potentially competing claims among members of the community. There is currently not enough empirical evidence to provide concrete information about these claims. This paper presents the results of a survey of members of the code clone community. The goal of the survey was to determine the level of agreement of community members regarding some key topics. While the results showed a good bit of agreement, there was no universal consensus on all topics. Survey respondents were not in complete agreement about the definitions of Type III and Type IV clones. The survey respondents were more uncertain about how developers behave when working with clones. From the survey it is clear that there are areas where more empirical research is needed to better understand how to\u00a0\u2026", "num_citations": "12\n", "authors": ["172"]}
{"title": "Development of Requirement Error Taxonomy as a Quality Improvement Approach: A Systematic Literature Review\n", "abstract": " CONTEXT: Software quality and reliability is a major concern for successful software organizations. Over the years, researchers have developed fault detection techniques to help developers detect as many faults as possible. Due to some inherent limitations with using only fault information and the fact that faults are still present in software, this review analyzes the software quality problem from a different perspective. This study examines the sources of the faults (ie the errors). Using this error information should help fill in the gaps and provide a better solution to quality problem.OBJECTIVES: The objective is to perform a systematic review to develop a method that utilizes error information to help developers improve software quality at requirements stage. METHOD: A systematic review of literature across different research domains was conducted to address a set of research questions. The data sources, search\u00a0\u2026", "num_citations": "12\n", "authors": ["172"]}
{"title": "Usefulness of a human error identification tool for requirements inspection: an experience report\n", "abstract": " Context and Motivation: Our recent work leverages Cognitive Psychology research on human errors to improve the standard fault-based requirements inspections. Question: The empirical study presented in this paper investigates the effectiveness of a newly developed Human Error Abstraction Assist (HEAA) tool in helping inspectors identify human errors to guide the fault detection during the requirements inspection. Results: The results showed that the HEAA tool, though effective, presented challenges during the error abstraction process. Contribution: In this experience report, we present major challenges during the study execution and lessons learned for future replications.", "num_citations": "11\n", "authors": ["172"]}
{"title": "Modeling as a Service: A Survey of Existing Tools.\n", "abstract": " Modeling tools are needed to deliver the promises of Model-Driven Engineering, which include reduced development time and enhanced software quality. However, users must typically install these tools locally. The tools often have complex configurations and inter-dependency requirements that discourage non-technical users or novices from adopting such tools. The local installation also hampers collaborative modeling and reuse of modeling artifacts. A solution to these challenges is to deliver modeling functionality as a service. In this paper, we present a survey of current tools that deliver modeling functionality as service. We analyzed various approaches used to develop existing tools and the functionalities exhibited by them. The results of our review show that support for collaboration and domain-specific modeling are the dominant features exhibited by the tools, but collaboration is the major feature that drives tool adoption. The paper concludes by proposing future research directions that can facilitate the wider adoption of modeling as a service.", "num_citations": "11\n", "authors": ["172"]}
{"title": "Review of systematic literature review tools\n", "abstract": " Ahmed Al-Zubidy, Jeffrey C. Carver Department of Computer Science The University of Alabama Tuscaloosa, AL 35487-0290 aalzubidy@ crimson. ua. edu, carver@ cs. ua. edu", "num_citations": "11\n", "authors": ["172"]}
{"title": "Show me how you see: Lessons from studying computer forensics experts for visualization\n", "abstract": " As the first part of a Analyze-Visualize-Validate cycle, we have initiated a domain analysis of email computer forensics to determine where visualization may be beneficial. To this end, we worked with police detectives and other forensics professionals. However, the process of designing and executing such a study with real-world experts has been a non-trivial task. This paper presents our efforts in this area and the lessons learned as guidance for other practitioners.", "num_citations": "11\n", "authors": ["172"]}
{"title": "Viope as a tool for teaching introductory programming: an empirical investigation\n", "abstract": " In this paper we describe the use of a tool from Viope for teaching introductory programming. We have noticed in our previous courses that the students often have trouble connecting the small classroom exercises with the larger laboratory projects. This tool allows the students to get extra practice with those concepts to help ensure they are understood. In this study data was collected using a survey. We surveyed students at the end of a semester in which the tool was not used to gather information about where the tool might be useful. Then we had students in a second semester use the tool and complete a similar survey. The results of our study showed that while there were some consistent complaints about the tool, overall the students found it useful enough to indicate they would like to use something similar in later semesters", "num_citations": "11\n", "authors": ["172"]}
{"title": "Evaluating the use of requirement error abstraction and classification method for preventing errors during artifact creation: A feasibility study\n", "abstract": " Defect prevention techniques can be used during the creation of software artifacts to help developers create high-quality artifacts. These artifacts should have fewer faults that must be removed during inspection and testing. The Requirement Error Taxonomy that we have developed helps focus developers' attention on common errors that can occur during requirements engineering. Our claim is that, by focusing on those errors, the developers will be less likely to commit them. This paper investigates the usefulness of the Requirement Error Taxonomy as a defect prevention technique. The goal was to determine if making requirements engineers' familiar with the Requirement Error Taxonomy would reduce the likelihood that they commit errors while developing a requirements document. We conducted an empirical study in which the participants were given the opportunity to learn how to use the Requirement Error\u00a0\u2026", "num_citations": "10\n", "authors": ["172"]}
{"title": "Evaluating the effect of the number of naturally occurring faults on the estimates produced by capture-recapture models\n", "abstract": " Project managers can use the capture-recapture models to estimate the number of faults in a software artifact. The capture-recapture estimates are calculated using the number of unique faults and the number of times each fault is found. The accuracy of the estimates is affected by the number of inspectors and the number of faults. Our earlier research investigated the effect that the number of inspectors had on the accuracy of the estimates. In this paper, we investigate the effect of the number of faults on the performance of the estimates using real requirement artifacts. These artifacts have an unknown amount of naturally occurring faults. The results show that while the estimators generally underestimate, they improve as the number of faults increases. The results also show that the capture-recapture estimators can be used to make correct re-inspection decisions.", "num_citations": "10\n", "authors": ["172"]}
{"title": "Use of software process in research software development: a survey\n", "abstract": " Background: Developers face challenges in building high-quality research software due to its inherent complexity. These challenges can reduce the confidence users have in the quality of the result produced by the software. Use of a defined software development process, which divides the development into distinct phases, results in improved design, more trustworthy results, and better project management. Aims: This paper focuses on gaining a better understanding of the use of software development process for research software. Method: We surveyed research software developers to collect information about their use of software development processes. We analyze whether and demographic factors influence the respondents' use of and perceived value in defined process. Results: Based on 98 responses, research software developers appear to follow a defined software development process at least some of\u00a0\u2026", "num_citations": "9\n", "authors": ["172"]}
{"title": "Defect prevention in requirements using human error information: An empirical study\n", "abstract": " Context and Motivation: The correctness of software requirements is of critical importance to the success of a software project. Problems that occur during requirements collection and specification, if not fixed early, are costly to fix later. Therefore, it is important to develop approaches that help requirement engineers not only detect, but also prevent requirements problems. Because requirements engineering is a human-centric activity, we can build upon developments from the field of human cognition. Question/Problem: Human Errors are the failings of human cognition during the process of solving, planning, or executing a task. We have employed research about Human Errors to describe the types of problems that occur during requirements engineering. The goal of this paper is to determine whether knowledge of Human Errors can serve as a fault prevention mechanism during requirements\u00a0\u2026", "num_citations": "9\n", "authors": ["172"]}
{"title": "Building cliime via Test-Driven Development: A case study\n", "abstract": " The multidisciplinary nature of contemporary computational modeling impacts the development of computational science and engineering (CSE) software. Multidisciplinary efforts often require large-scale software development to serve a broad audience of developers and users. This article describes software engineering practices adopted in the Community Laser-Induced Incandescence Modeling Environment (CLiiME). The authors explain how CLiiME's design enables extension of the model. The project uses the agile methodology of test-driven development (TDD) to implement the infrastructure for a collaborative model that different researchers will use, modify, and extend. They discuss some of the software engineering practices that developers can integrate throughout the life of a project, beginning with its inception when only a few developers are contributing to the project. They also describe the\u00a0\u2026", "num_citations": "9\n", "authors": ["172"]}
{"title": "Using error information to improve software quality\n", "abstract": " Problem Definition: To help ensure high-quality software artifacts, researchers and practitioners have developed various techniques for identifying and repairing problems early in the software lifecycle (e.g., requirements and design documents). Most of these techniques are fault-based, and have been empirically validated. However, results show that even when developers faithfully apply these techniques, they are not able to identify all types of problems and that 40-50% of effort is spent on fixing these early problems later in the development process. The studies have revealed the inadequacy of fault-based approaches, which treats the symptoms of software defects, not their underlying causes. Prior research that only analyzed a sample of faults to determine their causes and suggest process improvements (e.g., RCA, ODC) overlooked many errors due to a lack of underlying cognitive theory. Proposed Solution\u00a0\u2026", "num_citations": "9\n", "authors": ["172"]}
{"title": "On the need for human-based empirical validation of techniques and tools for code clone analysis\n", "abstract": " Code clone analysis techniques and tools are popular topics among the software engineering research community. Many studies draw conclusions solely based on an analytical analysis. These claims focus primarily on tool performance in terms of portability, scalability, robustness, precision, and recall. However, these types of analytical studies cannot adequately evaluate the behavior of the developers while using the tools. Human-based empirical studies are complementary to studies based on analytical data because they provide direct insight into developer behavior. In this paper we argue for the need for more humanbased empirical studies in the area of code clone analysis techniques and tools.", "num_citations": "9\n", "authors": ["172"]}
{"title": "Third international workshop on software engineering for high performance computing (hpc) applications\n", "abstract": " High performance computing systems are used to develop software in a wide variety of domains including nuclear physics, crash simulation, satellite data processing, fluid dynamics, climate modeling, bioinformatics, and financial modeling. The TOP500 website (http://www.top500.org) lists the top 500 high performance computing systems. The diversity of government, scientific, and commercial organizations present on this list illustrates the growing prevalence and impact of HPC applications on modern society.", "num_citations": "9\n", "authors": ["172"]}
{"title": "Support for computer forensics examination planning with domain modeling: a report of one experiment trial\n", "abstract": " In any forensic investigation, planning and analysis activities are required in order to determine what digital media will be seized, what types of information will be sought in the examination, and how the examination will be conducted. Existing literature and suggested practices indicate that such planning should occur, but few tools provide support for such activities. Planning an examination may be an essential activity when investigators and technicians are faced with unfamiliar case types or unusually complex, large-scale cases. This paper presents the results of an empirical study that evaluates two planning methods for computer forensics examination: a methodology that includes domain modeling and a more typical, ad hoc planning approach. This paper briefly describes the case domain modeling and planning methodology, describes the empirical study, and presents preliminary results of and conclusions\u00a0\u2026", "num_citations": "9\n", "authors": ["172"]}
{"title": "Issues and opportunities for human error-based requirements inspections: an exploratory study\n", "abstract": " [Background] Software inspections are extensively used for requirements verification. Our research uses the perspective of human cognitive failures (i.e., human errors) to improve the fault detection effectiveness of traditional fault-checklist based inspections. Our previous evaluations of a formal human error based inspection technique called Error Abstraction and Inspection (EAI) have shown encouraging results, but have also highlighted a real need for improvement. [Aims and Method] The goal of conducting the controlled study presented in this paper was to identify the specific tasks of EAI that inspectors find most difficult to perform and the strategies that successful inspectors use when performing the tasks. [Results] The results highlighted specific pain points of EAI that can be addressed by improving the training and instrumentation.", "num_citations": "8\n", "authors": ["172"]}
{"title": "Idea Paper: Development of a Software Framework for Formalizing Force1eld Atom-Typing for Molecular Simulation\n", "abstract": " Forcefields are a crucial ingredient of Molecular Dynamics (MD) simulations, describing the types and parameters of interactions between the simulated particles. These parameter sets, however, are typically specific to the molecule in which the atoms appears, where within the molecule the atom is positioned, the phase or state point of the system, as well as the simulator tool in use. This makes choosing the correct parameter values a tedious and error prone task. Forcefield parameters, furthermore, are often hard to locate: some are published in scientific papers, others come with MD tools, often with no or ambiguous documentation on their applicability. In this paper, we present a framework that aims to solve this data management issue, proposing a common format for forcefields that is self-documenting with machine readable, declarative usage rules. We believe that processes and tools that are commonly used today in software development (eg, unit testing, verification and validation, continuous integration, and version control) are, with proper infrastructure support, applicable to forcefield development, as well. The paper describes how such an infrastructure can tackle managing and evolving forcefields by the MD community, and proposes a way to encourage and incentivize involvement by the stakeholders.", "num_citations": "8\n", "authors": ["172"]}
{"title": "SE-CSE 2008: The first international workshop on software engineering for computational science and engineering\n", "abstract": " Computational Science and Engineering (CS&E) software supports a wide variety of domains including nuclear physics, crash simulation, satellite data processing, fluid dynamics, climate modeling, bioinformatics, and financial modeling. The recent increase in the importance of this type of software motivates the need to better understand how it is developed. This movement creates an opportunity for the software engineering community to apply our techniques and knowledge to a new and important application domain. Furthermore, the design, implementation, and maintenance used in CS&E software systems can be significantly different from that used in systems more typically studied by the software engineering community. This workshop brings together researchers from the software engineering community with researchers and practitioners from the CS&E community. The workshop allows participants to share\u00a0\u2026", "num_citations": "8\n", "authors": ["172"]}
{"title": "Post-workshop report for the third international workshop on software engineering for high performance computing applications (se-hpc 07)\n", "abstract": " This is the report from a one-day workshop that took place on Saturday, May 26, 2007 as part of the International Conference on Software Engineering in Minneapolis, MN, USA.", "num_citations": "8\n", "authors": ["172"]}
{"title": "Automating Systematic Literature Review\n", "abstract": " Systematic literature reviews (SLRs) have become the foundation of evidence-based software engineering (EBSE). Conducting an SLR is largely a manual process. In the past decade, researchers have made major advances in automating the SLR process, aiming to reduce the workload and effort for conducting high-quality SLRs in software engineering (SE). The goal of this chapter is to provide an overview of strategies researchers have developed to automate the SLR process. We used a systematic search methodology to survey the literature about the strategies used to automate the SLR process in SE. Study selection is the most supported activity, while protocol definition, data extraction, and synthesis have only partial support. SE researchers have most frequently explored the visual text mining strategy. Visual text mining is useful from the beginning of the process (formulation of research questions) to\u00a0\u2026", "num_citations": "7\n", "authors": ["172"]}
{"title": "Empirical research on concurrent software testing: A systematic mapping study\n", "abstract": " Background: Concurrent software testing is a costly and difficult task, especially due to the exponential increase in the test sequences caused by non-determinism. Such an issue has motivated researchers to develop testing techniques that select a subset of the input domain that has a high probability of revealing faults. Academics and industrial practitioners rarely use most concurrent software testing techniques because of the lack of data about their applicability. Empirical evidence can provide an important scientific basis for the strengths and weaknesses of each technique to help researchers and practitioners choose concurrent testing techniques appropriate for their environments.Aim: This paper gathers and synthesizes empirical research on concurrent software testing to characterize the field and the types of empirical studies performed.Method: We performed a systematic mapping study to identify and\u00a0\u2026", "num_citations": "7\n", "authors": ["172"]}
{"title": "A survey of software metric use in research software development\n", "abstract": " Background: Breakthroughs in research increasingly depend on complex software libraries, tools, and applications aimed at supporting specific science, engineering, business, or humanities disciplines. The complexity and criticality of this software motivate the need for ensuring quality and reliability. Software metrics are a key tool for assessing, measuring, and understanding software quality and reliability. Aims: The goal of this work is to better understand how research software developers use traditional software engineering concepts, like metrics, to support and evaluate both the software and the software development process. One key aspect of this goal is to identify how the set of metrics relevant to research software corresponds to the metrics commonly used in traditional software engineering. Method: We surveyed research software developers to gather information about their knowledge and use of code\u00a0\u2026", "num_citations": "7\n", "authors": ["172"]}
{"title": "The Effect of the Number of Defects on Estimates Produced by Capture-Recapture Models\n", "abstract": " Project managers use inspection data as input to capture-recapture (CR) models to estimate the total number of faults present in a software artifact. The CR models use the number of faults found during an inspection and the overlap of faults among inspectors to calculate the estimate. A common belief is that CR models underestimate the number of faults but their performance can be improved with more input data. This paper investigates the minimum number of faults that has to be present in an artifact before the CR method can be used. The result shows that the minimum number of faults varies from ten faults to twenty-three faults for different CR estimators.", "num_citations": "7\n", "authors": ["172"]}
{"title": "Test-driven development in HPC science: A case study\n", "abstract": " Many scientific software developers have applied software engineering practices in their work in recent years. Agile methods are gaining increased interest from both industry and academia, including scientific application domains. Test-driven development (TDD) and refactoring practices are critical to the success of agile methods. Although many scientific projects employ agile practices, the effect of TDD on scientific software development remains unknown and should thus be investigated. The authors investigated the effects of using TDD to develop scientific software in a high-performance computing environment, finding both advantages and disadvantages. In particular, they observed that developers face problems with writing unit tests and with a lack of experience with software engineering practices.", "num_citations": "6\n", "authors": ["172"]}
{"title": "An overview of emerging privacy issues in the Internet of Things\n", "abstract": " This paper presents an overview of the privacy issues that are expected to emerge as a result of the Internet of Things (IoT). IoT expands digital world to include different things in our physical world. This ambitious aspiration is becoming true with the utilization of already existing technologies that enable things to be identified and to communicate with each other. Unfortunately, the ubiquitous collection and dissemination of data that characterize IoT come at the expense of data privacy. We have witnessed many privacy breaches during the last decade, more vicious breaches will find its way to the huge amounts of qualitative data that are collected in IoT with more expected catastrophic consequences to individuals and organizations. Evaluating some papers, the lessons to be learnt and some possible directions for future research were highlighted.", "num_citations": "6\n", "authors": ["172"]}
{"title": "Error Abstraction Accuracy and Fixation during Error-Based Requirements Inspections\n", "abstract": " Software inspections are widely used as a requirements verification technique. Our research uses the tried-and-tested perspective of cognitive failures (i.e., human errors) to improve the effectiveness of fault detection during requirements inspections. We have previously shown that inspection effectiveness can be significantly improved by augmenting the current fault-based inspection technique with the proposed Error Abstraction and Inspection (supported by a Human Error Taxonomy). This paper investigates the impact of an inspector's ability to accurately abstract human errors on their fault-detection effectiveness.", "num_citations": "6\n", "authors": ["172"]}
{"title": "Using TAU for performance evaluation of scientific software\n", "abstract": " The ability of performance technology to keep pace with the growing complexity of parallel and distributed systems depends on robust performance framew1orks that can at once provide system-specific performance capabilities and support high-level performance problem solving. Flexibility and portability in empirical methods and processes are influenced primarily by the strategies available for instrumentation and measurement, and how effectively they are integrated and composed. This demo will present the TAU (Tuning and Analysis Utilities) parallel performance system [1] and describes how it addresses diverse requirements for performance engineering of scientific software.", "num_citations": "6\n", "authors": ["172"]}
{"title": "Software engineering need not be difficult\n", "abstract": " \u201cProgress in scientific research is dependent on the quality and accessibility of software at all levels\u201d(the overall premise of the workshop). We argue that true progress depends on embracing the best traditional\u2013and emergent\u2013practices in software engineering, especially agile practices that intersect with the tradition of software engineering. Software engineering as practiced today is more than the stereotypical monolithic lifecycle processes (eg waterfall, spiral, etc.) that historically have impeded progress for small/medium sized development efforts. In addition, the discipline and practice of software engineering includes software quality (with an established tradition of software metrics). Software processes can be pragmatic and use best features/practices of various models without impeding developer productivity. The embracement of these practices may also be important to prevent a brain drain of sorts, as students are increasingly eschewing traditional scientific/computation science research in favor of industry opportunities, where they can literally apply what they have learned in software development courses where pragmatic software engineering practices (eg test-driven design, RESTful architecture, etc.) are already prevalent.", "num_citations": "6\n", "authors": ["172"]}
{"title": "Development of a mesh generation code with a graphical front-end: A case study\n", "abstract": " Scientists and engineers are increasingly developing software to enable them to do their work. A number of characteristics differentiate the software development environment in which a scientist or engineer works from the development environment in which a more traditional business/IT software developer works. This paper describes a case study, specifically about the development of a mesh-generation code. The goal of this case study was to understand the process for developing the code and identify some lessons learned that can be of use to other similar teams. Specifically, the paper reports on lessons learned concerning: requirements evolution, programming language choice, methods of communication among teammates, and code structure.", "num_citations": "6\n", "authors": ["172"]}
{"title": "Visual analysis for textual relationships in digital forensic evidence\n", "abstract": " We present a visual analytics framework for exploring the textual relationships in computer forensics. Based on a task analysis study performed with practitioners, our tool addresses the inefficiency of searching for related text documents on a hard drive. Our framework searches both allocated and unallocated sectors for text and performs some pre-analysis processing; this information is then presented via a visualization that displays both the frequency of relevant terms and their location on the disk. We also present a case study that demonstrates our framework's operation, and we report on an informal evaluation conducted with forensics analysts from the Mississippi State Attorney General's Office and National Forensics Training Center.", "num_citations": "6\n", "authors": ["172"]}
{"title": "How to test your concurrent software: an approach for the selection of testing techniques\n", "abstract": " High-Performance Computing (HPC) applications consist of concurrent programs with multi-process and/or multithreaded models with varying degrees of parallelism. Although their design patterns, models, and principles are similar to those of sequential ones, their non-deterministic behavior makes the testing activity more complex. In an attempt to solve such complexity, several techniques for concurrent software testing have been developed over the past years. However, the transference of knowledge between academy and industry remains a challenge, mainly due to the lack of a solid base of evidence with information that assists the decision-making process. This paper proposes the construction of a body of evidence for the concurrent programming field that supports the selection of an adequate testing technique for a software project. We propose a characterization schema which assists the decision-making\u00a0\u2026", "num_citations": "5\n", "authors": ["172"]}
{"title": "Using Human Error Abstraction Method for Detecting and Classifying Requirements Errors: A Live Study.\n", "abstract": " Inspections, a proven quality improvement approach [3, 7], are a process where a team of skilled individuals review a software artifact (eg, requirements specification document) to identify faults. Traditional fault-based software inspections (like Fault Checklist inspection) focus inspectors\u2019 attention on different type of faults (eg, incorrect or incomplete or ambiguous requirements)[7]. Even a faithful application of validated fault-based techniques does not help inspectors in finding all faults. As a result, a larger part of (40%-50%) the development effort is spent fixing issues that should have been fixed in an earlier phase [3]. Hence, there is a real need to improve early fault detection and to help developers avoid the unnecessary rework. We hypothesize that inspections focused on identifying human errors (ie, the underlying cause of faults) are better at identifying requirements problems when compared to inspections focused on faults (ie, manifestation of human error). On those lines, our recent work [1, 5] uses a Cognitive Psychology perspective on human errors to improve the practice of requirements inspections. Human errors are understood as purely mental events, failings of human cognition in the process of problem solving, planning, and acting. Errors, in turn, will produce faults, a physical manifestation of the error. It is important that a clear distinction is made between human errors (mental events) vs program errors (related to coding or programmatic failures). To help inspectors in identifying human errors, the authors over the past two years, have worked on developing a Human Error Taxonomy (HET) that classifies human errors that commonly\u00a0\u2026", "num_citations": "5\n", "authors": ["172"]}
{"title": "Teaching mathematical reasoning across the curriculum\n", "abstract": " It is all too often the case that CS students learn concepts of mathematical reasoning in a required discrete math course, but fail to apply what they have learned to their CS courses. This may occur because the courses are taught in different departments with little communication between faculty members, so that different terminology may be used in the math course from what is used in the CS curriculum, making it seem as though these two areas are not connected. Even when discrete math faculty collaborate with CS course instructors, students may not carry over what they learned into their CS curriculum.", "num_citations": "5\n", "authors": ["172"]}
{"title": "Software engineering for CSE\n", "abstract": " This special issue contains extensions of the best papers from the First International Workshops on Software Engineering for High Performance Computing in Computational Science & Engineering (SE-HPCCSE 2013), which was held during the SC\u201913 conference. For full details about the workshop (and others in this series), please visit the workshop website http://SE4Science. org/workshops, where the interested reader can find an overview of the workshop, the schedule, and links to the published proceedings. The goal of the workshop was to bring together researchers from different domains (ie, computational science, software engineering, and high-performance computing) to present their work and discuss important issues related to the intersection of these fields. Because the format of the workshop allows for short paper presentations along with ample time for small group discussion, this workshop provides a unique venue where researchers from different backgrounds can meet and interact in a more informal setting. This editorial first briefly describes the interesting results of the group discussions. Then, it provides a brief overview of the three papers included in the special issue.", "num_citations": "4\n", "authors": ["172"]}
{"title": "Brain-Computer Interface virtual keyboard for accessiblity\n", "abstract": " This paper describes our experiences in building a virtual keyboard implemented using a Brain-Computer Interface (BCI) that interacts with the eMotiv EPOC Neural Headset. The contribution of the work is an alternative input device for those who have a motor disability and are challenged by traditional input devices. The advantages of a virtual keyboard based on BCI are summarized and we describe its design and implementation. We also present the results of a preliminary study that has suggested several improvements for enhancing the effectiveness of the virtual keyboard.", "num_citations": "4\n", "authors": ["172"]}
{"title": "What scientists and engineers think they know about software engineering: a survey\n", "abstract": " Scientists and engineers devote considerable effort to developing large, complex codes to solve important problems. Our personal experience with such teams suggested that, while they often develop good code, many of these developers are frequently unaware of how various software engineering practices can help them write better code. Our hypothesis is that many of these developers \u201cdon\u2019t know what they don\u2019t know,\u201d as was the case for one of the authors of this article. To test this hypothesis, we conducted a survey of computational scientists and engineers. We received 141 responses to the survey. The first main finding of the survey was that most developers were largely self-taught. The second main finding was that while most respondents thought they knew enough software engineering to be effective, many were not familiar with standard software engineering practices used in commercial industry.", "num_citations": "4\n", "authors": ["172"]}
{"title": "Gestalt principles applied to software engineering diagrams: An initial study\n", "abstract": " Discovering root-causes of comprehension errors in software design is important to prevent their presence in software systems. This research synthesizes software engineering and Gestalt principles of similarity, proximity, and continuity for the purpose of discovering whether certain visual attributes of diagrams (dashed arrows, severe complexity, etc.) can affect the accuracy and efficiency of understanding correct relationships amongst the entities in the diagram. Twenty-seven subjects viewed diagrams of different types and answered questions about them. The experiment tested whether two dependent variables, accuracy and response time, were significantly affected by independent variables, diagram type (simple 1, simple2, complex), Gestalt principles (good vs. bad), and forward/backward (question order). The results of this study indicated that the Gestalt principles did affect the comprehension in the complex diagrams.", "num_citations": "4\n", "authors": ["172"]}
{"title": "Architecture reading techniques: A feasibility study\n", "abstract": " In order to correctly determine if the software architecture for a system complies with the user requirements, it is necessary to review the software architecture description. There are different means available to perform these reviews ranging from checklists to detailed step-by-step protocols. In this paper we propose the ARTs, a new set of reading techniques focused on software architecture. We provide an overview of these new techniques and report on an initial feasibility study. The results of the feasibility study showed that the techniques were useful and seen by the subjects to provide benefit over a checklist-based approach. Another interesting result requiring additional research is that the checklist seemed to focus reviewers on defects of commission while the reading techniques seemed to focus reviewers on defects of type omission.", "num_citations": "4\n", "authors": ["172"]}
{"title": "The 4th International Workshop on Software Engineering for HPC in Computational Science and Engineering\n", "abstract": " Despite the increasing demand for utilizing high-performance computing (HPC) for CSE applications, software development for HPC historically attracted little attention from the software engineering (SE) community. Paradoxically, the HPC CSE community has increasingly been adopting SE techniques and tools. Indeed, the development of CSE software for HPC differs significantly from the development of more traditional business information systems, from which many SE best practices and tools have been drawn. The workshop summarized in this column, the fourth in the series to be collocated with the Supercomputing conference series, examined two main topics: testing and tradeoffs. Through presentations of work in this area and structured group discussions, the participants highlighted some of the key issues, as well as indicated the direction the community needs to go. In particular, there is a need for more\u00a0\u2026", "num_citations": "3\n", "authors": ["172"]}
{"title": "Understanding Human Errors In Software Requirements: An Online Survey.\n", "abstract": " The elicitation and documentation of software requirements is a human-based activity. Therefore, it is not surprising that most failures can be traced back to defects related to human factors [3]. Cognitive Psychologists have long studied the topic of Human Error which focuses on how human mental processes fail when carrying out various tasks. In software engineering, the term error is overloaded. It can mean either a human error or a program error (ie an incorrect program state). In our work, we focus on those issues that are human errors. In our research, we are applying the findings from human error research to improve the process of requirements engineering. To clarify the terms, we introduce some definitions:\u2013Human error\u2013A mental error, ie failings of the thought process during problem solving, while formulating the plan, or while executing the plan.\u2013Example\u2013The requirements author lacks domain knowledge. As a result she incorrectly believes that the stakeholders have told her all information relevant to that functionality.", "num_citations": "3\n", "authors": ["172"]}
{"title": "Why do we need to compare research software, and how should we do it\n", "abstract": " Why do we need to compare research software, and how should we do it? \u2013 Projects \u2014 University of Edinburgh Research Explorer Skip to main navigation Skip to search Skip to main content University of Edinburgh Research Explorer Logo Help & FAQ Home Research output Profiles Research Units Projects Datasets Prizes Activities Press / Media Equipment Search by expertise, name or affiliation Why do we need to compare research software, and how should we do it? Neil Chue Hong College of Science and Engineering Edinburgh Parallel Computing Centre Computer Systems Research output: Chapter in Book/Report/Conference proceeding \u203a Conference contribution Overview Fingerprint Projects (1) Activities (3) Projects Projects per year 2015 2019 1 Finished 1 results Status, start date (descending) Title Start date End date Type Status, start date(ascending) Filter Finished Search results Finished The : 2 , N. \u2026", "num_citations": "3\n", "authors": ["172"]}
{"title": "The relationship between development problems and use of software engineering practices in computational science & engineering: A survey\n", "abstract": " The development of software has become critical to progress in many important scientific and engineering fields. In general, the use of business/IT software engineering practices in these fields is relatively low. This paper describes the results of a survey of Computational Science & Engineering (CSE) developers that analyzed the current state of software engineering in the CSE community. Specifically, we examined four important CSE software development problems and the use of software engineering practices that should help address those problems. The results showed that in general, CSE developers are not using the software engineering practices that would most help those development problems as frequently as they could be.", "num_citations": "3\n", "authors": ["172"]}
{"title": "Third international workshop on software engineering for computational science and engineering\n", "abstract": " This workshop focuses on bringing together members of the software engineering community with members of the computational science and engineering community to discuss approaches for developing computational science & engineering software. The workshop provides a venue for members of these communities, who do not normally interact, to meet and discuss important issues.", "num_citations": "3\n", "authors": ["172"]}
{"title": "Structured Forensics Examination Planning with Domain Modeling: A Report of Three Experiment Trials\n", "abstract": " In any forensic investigation, planning and analysis activities are required in order to determine what digital media will be seized, what types of information will be sought in the examination, and how the examination will be conducted. Existing literature and suggested practices indicate that such planning should occur, but few tools provide support for such activities. Planning an examination may be an essential activity when investigators and technicians are faced with unfamiliar case types or unusually complex, large-scale cases.             This article reports the results of empirical studies that evaluate two planning methods for planning computer forensics examinations: an experimental methodology that includes domain modeling and a typical planning method that does not include domain modeling. These studies were conducted to evaluate two research questions:                                                Will the domain\u00a0\u2026", "num_citations": "3\n", "authors": ["172"]}
{"title": "Modifiability measurement from a task complexity perspective: A feasibility study\n", "abstract": " Despite the critical role of software modifiability, it has no universally accepted measurement model. Measuring modifiability in terms of maintenance effort is problematic because it confounds modifiability with the ability of individual maintainers. In this paper, we apply Wood's task complexity model to propose a general analytical model that describes the characteristics of maintenance tasks and the analytical dimensions of modifiability independent of the individual maintainers. The results of a case study demonstrate the construct validity of the model.", "num_citations": "3\n", "authors": ["172"]}
{"title": "SE-CSE 2009: The second international workshop on software engineering for computational science and engineering\n", "abstract": " This workshop is concerned with the development of Computational Science & Engineering (CS&E) software. This software includes: 1) Scientific software applications, where the focus is on directly solving scientific problems, including, but not limited to, large parallel models/simulations of the physical world (high performance computing systems); and 2) Applications that support scientific endeavors, including, but not limited to, systems for managing and/or manipulating large amounts of data. Despite its importance in our everyday lives, the development of CS&E software has historically attracted little attention from the software engineering community. Due to significant differences in the development context, CS&E software development needs to be studied in its own right. This workshop will devote approximately equal time to presentation of position papers and to discussing topics that arise out of those\u00a0\u2026", "num_citations": "3\n", "authors": ["172"]}
{"title": "Special issue on scientific end user computing\n", "abstract": " We are all of us in our daily lives heavily dependent on scientific software. For example, as we take our medicine, listen to the weather forecast, anticipate flying to warmer climes, turn up the thermostat on our central heating, we should stop to acknowledge the underlying software:", "num_citations": "3\n", "authors": ["172"]}
{"title": "Characterizing changes to assess architectural impact\n", "abstract": " With today\u2019s ever increasing demands on software, software developers must produce software that can be changed without the risk of degrading the software architecture. Degraded software architecture is problematic because it makes the system more prone to defects and increases the cost of making future changes. The effects of making changes to software can be difficult to measure. One way to address software changes is to characterize their causes and effects. A software change characterization mechanism allows characterize the effects of a change using different criteria, eg the cause of the change, the type of change that needs to be made, and the part of the system where the change must take place. This information then can be used to illustrate the potential impact of the change. Another benefit of characterizing the changes is that it allows engineers to develop a common approach to deal with changes that have similar characteristics, rather than addressing each change individually. This paper introduces an architecture change characterization scheme created to assist developers in measuring the impact of a software change on the architecture of the system.", "num_citations": "3\n", "authors": ["172"]}
{"title": "Insights for Serverless Application Engineering\n", "abstract": "", "num_citations": "2\n", "authors": ["172"]}
{"title": "Blockchain and Smart Contract Engineering\n", "abstract": " FOLLOWING ALONG WITH the theme of this special issue, the \u201cPractitioners\u2019 Digest\u201d department reports on papers about blockchain and smart contract engineering from the 42nd International Conference on Software Engineering and the 2020 IEEE International Conference on Blockchain and Cryptocurrency. Feedback or suggestions are welcome. In addition, if you try or adopt any of the practices included in this article, please send me and the authors of the paper (s) a note about your experiences.", "num_citations": "2\n", "authors": ["172"]}
{"title": "Software engineering and community codes track in ATPESC\n", "abstract": " SOFTWARE ENGINEERING AND COMMUNITY CODES TRACK IN ATPESC Page 1 WSSSPE 2016 13 September 2016 ANSHU DUBEY KATHERINE RILEY SOFTWARE ENGINEERING AND COMMUNITY CODES TRACK IN ATPESC Page 2 MOTIVATION \u25aa To bring knowledge of useful software engineering practices to HPC scientific code developers \u25aa Not to prescribe any set of practices as must use \u25aa Be informative about practices that have worked for some projects \u25aa Emphasis on adoption of practices that help productivity rather than put unsustainable burden \u25aa Customization as needed \u2013 based on information made available \u25aa We do it through examples and case studies \u25aa References for available resources \u25aa Suggestions for further reading 9/12/16 2 Page 3 INTEREST FROM STAKEHOLDERS \u25aa Facilities \u25aa Well prepared users better use machines \u25aa Funding agencies \u25aa No reinventing the wheel over and over \u25aa \u25aa \u2026", "num_citations": "2\n", "authors": ["172"]}
{"title": "Making it easier to understand research software impact\n", "abstract": " Making it easier to understand research software impact \u2013 Projects \u2014 University of Edinburgh Research Explorer Skip to main navigation Skip to search Skip to main content University of Edinburgh Research Explorer Logo Help & FAQ Home Research output Profiles Research Units Projects Datasets Prizes Activities Press / Media Equipment Search by expertise, name or affiliation Making it easier to understand research software impact Neil P. Chue Hong College of Science and Engineering Computer Systems Research output: Chapter in Book/Report/Conference proceeding \u203a Conference contribution Overview Fingerprint Projects (1) Research output (1) Activities (1) Projects Projects per year 2015 2019 1 Finished 1 results Status, start date (descending) Title Start date End date Type Status, start date(ascending) Search results Finished The Software Sustainability Institute: Phase 2 Chue Hong, N. EPSRC 1/06/15 \u2026", "num_citations": "2\n", "authors": ["172"]}
{"title": "Establishing a professional society for research software\n", "abstract": " ESTABLISHING A PROFESSIONAL SOCIETY FOR RESEARCH SOFTWARE Page 1 ESTABLISHING A PROFESSIONAL SOCIETY FOR RESEARCH SOFTWARE Gabrielle Allen University of Illinois, Urbana-Champaign Page 2 RESEARCH SOFTWARE \u2022 The custom software essential to support research across physical & social sciences, engineering, arts, humanities and education \u2022 Simulation and modeling codes \u2022 Workflow scripts \u2022 Visualization tools \u2022 Supercomputer custom I/O drivers \u2022 Etc, etc. Page 3 RESEARCH SOFTWARE \u2022 Primarily developed, used, supported and sustained at universities, institutes & national laboratories by \u2022 Students, postdocs, early faculty, research and technical staff who are \u2022 Distributed \u2022 Unconnected \u2022 Under-represented (institution/nationally) \u2022 Not well credited / rewarded Page 4 PROFESSIONAL SOCIETIES \u2022 Researchers in traditional domains traditionally join existing, well , . \u2022 a \u2026", "num_citations": "2\n", "authors": ["172"]}
{"title": "Composing, reproducing, and sharing simulations\n", "abstract": " Every year, research groups around the world contribute papers and artifacts to the computer science literature. In many areas, simulation and modeling play key roles in bringing about these new contributions. Simulation is used to test and validate new ideas prior to their implementation, and thus, the artifacts (software, data sets, benchmarks, etc.) used in simulation are fundamental to the empirical valuation of a research hypothesis.Often, the primary focus of a paper is on the validation of a central hypothesis, and the details surrounding the artifacts used during this process are sometimes scarce. Many researchers do not intend to build a foolproof software component to share with the community. Artifacts may end up limited in scope or usability, and hidden assumptions may make the artifact difficult (if not impossible) to reuse, extend, or compose. Many artifacts take a tremendous amount of effort to build and\u00a0\u2026", "num_citations": "2\n", "authors": ["172"]}
{"title": "Toward a Framework for Evaluating Software Success: A Proposed First Step\n", "abstract": " Software is a particularly critical technology in many computational science and engineering (CSE) sectors. Consequently, software is increasingly becoming an important component in the evaluation of competitive grants and the execution of research projects. As a result, software can be viewed as a scholarly contribution and has been proposed as a new factor to consider in tenure and promotion processes. However, existing metrics for evaluating the capability, use, reusability, or success of software are sorely lacking. This lack of software metrics permits the development of software based on poor development practices, which in turn allows poorly written software to \u201cfly under the radar\u201d in the scientific community and persist undetected. The absence of evaluation by knowledgeable peers often leads to the establishment and adoption of tools based on aggressive promotion by developers, ease-of-use, and\u00a0\u2026", "num_citations": "2\n", "authors": ["172"]}
{"title": "Identifying Programmer Ability Using Peer Evaluation: An Exploratory Study\n", "abstract": " Programmer ability is important to assess in both research and professional settings, but it is very difficult to measure directly. The objective of this study was to measure the ability of programmers to accurately rate the programming ability of their peers. The participants were computer science students in a senior-level undergraduate programming languages course. The peer rating of ability on a 5-point scale was compared with the average programming assignment grade. The Spearman correlation rho value was between. 432 and. 684 depending on which measure of central tendency was used (mode, median, mean, weighted mean), compared with. 48 when using individual assignment data as a predictor. Initial results indicate that peerratings are a promising mechanism for identifying the programming ability of a set of developers. This study leaves many open questions that will be the subject of future studies.", "num_citations": "2\n", "authors": ["172"]}
{"title": "Empirical Studies in End-User Software Engineering and Viewing Scientific Programmers as End-Users--POSITION STATEMENT--\n", "abstract": " My work has two relationships with End User Software Engineering. First, as an Empirical Software Engineer, I am interested in meeting with people who do research into techniques for improving end-user software engineering. All of these techniques need to have some type of empirical validation. In many cases this validation is performed by the researcher, but in other cases it is not. Regardless, an independent validation of a new approach is vital. Second, an area where I have done a fair amount of work is in software engineering for scientific software (typically written for a parallel supercomputer). These programmers are typically scientists who have little or no training in formal software engineering. Yet, to accomplish their work, they often write very complex simulation and computation software. I believe these programmers are a unique class of End-Users that must be addressed", "num_citations": "2\n", "authors": ["172"]}
{"title": "A Systematic Literature Review of Empiricism and Norms of Reporting in Computing Education Research Literature\n", "abstract": " Context. Computing Education Research (CER) is critical to help the computing education community and policy makers support the increasing population of students who need to learn computing skills for future careers. For a community to systematically advance knowledge about a topic, the members must be able to understand published work thoroughly enough to perform replications, conduct meta-analyses, and build theories. There is a need to understand whether published research allows the CER community to systematically advance knowledge and build theories. Objectives. The goal of this study is to characterize the reporting of empiricism in Computing Education Research literature by identifying whether publications include content necessary for researchers to perform replications, meta-analyses, and theory building. We answer three research questions related to this goal: (RQ1) What percentage of\u00a0\u2026", "num_citations": "1\n", "authors": ["172"]}
{"title": "Understanding peer review of software engineering papers\n", "abstract": " Context                 Peer review is a key activity intended to preserve the quality and integrity of scientific publications. However, in practice it is far from perfect.                                               Objective                 We aim at understanding how reviewers, including those who have won awards for reviewing, perform their reviews of software engineering papers to identify both what makes a good reviewing approach and what makes a good paper.                                               Method                 We first conducted a series of interviews with recognised reviewers in the software engineering field. Then, we used the results of those interviews to develop a questionnaire used in an online survey and sent out to reviewers from well-respected venues covering a number of software engineering disciplines, some of whom had won awards for their reviewing efforts.                                               Results                 We analyzed\u00a0\u2026", "num_citations": "1\n", "authors": ["172"]}
{"title": "Requirements Engineering Research: News From the Trenches\n", "abstract": " \u201cDesign Thinking in a Nutshell for Eliciting Requirements of a Business Process: A Case Study of a Design-Thinking Workshop\u201d by Levy and Huli 1 describes a design-thinking workshop for facilitating requirements elicitation for business processes. The paper describes simple guidelines to facilitate such workshops:", "num_citations": "1\n", "authors": ["172"]}
{"title": "Development of A Taxonomy of Requirements Phase Human Errors Using a Systematic Literature Review: A Technical Report\n", "abstract": " Software engineers construct artifacts of extraordinary complexity. For example, modern cars have about 30,000 different mechanical components, including pistons, gears, and screws, but require approximately 100 million lines of code to run [13]. The Boeing 787 Dreamliner uses a far more efficient 6.5 million lines of code to keep its 2.3 million parts in the air. Yet, as in all other known human activities, software engineers fall short of divine perfection: They make errors.In the current context, errors are understood as purely mental events, failings of human cognition in the process of problem solving, planning, and acting. Errors, in turn, will produce faults, a physical manifestation of the error. If faults are not detected and corrected, the error may result in a system failure [2]. The chain from mental error to fault to failure is not unbroken and inevitable. Indeed, people detect and correct their own errors, faults may be\u00a0\u2026", "num_citations": "1\n", "authors": ["172"]}
{"title": "SE4HPCS'15: the 2015 international workshop on software engineering for high performance computing in science\n", "abstract": " HPC software is developed and used in a wide variety of scientific domains including nuclear physics, computational chemistry, crash simulation, satellite data processing, fluid dynamics, climate modeling, bioinformatics, and vehicle development. The increase in the importance of this software motivates the need to identify and understand appropriate software engineering (SE) practices for HPC architectures. Because of the variety of the scientific domains addressed using HPC, existing SE tools and techniques developed for the business/IT community are often not efficient or effective. Appropriate SE solutions must account for the salient characteristics of the HPC, research oriented development environment. This situation creates a need for members of the SE community to interact with members of the scientific and HPC communities to address this need. This workshop facilitates that collaboration by bringing\u00a0\u2026", "num_citations": "1\n", "authors": ["172"]}
{"title": "Report from the second international workshop on software engineering for computational science and engineering (SE-CSE 09)\n", "abstract": " This is the report from a one-day workshop that took place on May 23, 2009 in as part of the International Conference on Software Engineering in Vancouver, Canada. The main focus of this workshop was to provide a venue for discussion of problems related to the application of software engineering principles to the development of Computational Science and Engineering software.", "num_citations": "1\n", "authors": ["172"]}
{"title": "Using Error Abstraction and Classification to Improve Quality of Requirements: Conclusions after Three Controlled Experiments\n", "abstract": " Achieving software quality is a primary concern for software development organizations. Researchers have developed many quality improvement methods that help developers detect faults early in the lifecycle. To address some of the limitations of fault-based quality improvement approaches, this paper describes an approach based on errors (ie the sources of the faults). This research extends Lanubile, et al.\u2019s, error abstraction process by providing a formal requirement error taxonomy to help developers identify both faults and errors. The taxonomy was derived from the requirement errors found in the software engineering and psychology literature to help developers identify both errors and faults. This error abstraction and classification process is then validated with a series of three controlled experiments. The main conclusions derived from the three experiments are:(1) the error abstraction and classification\u00a0\u2026", "num_citations": "1\n", "authors": ["172"]}
{"title": "A Lightweight UML-based Reverse Engineering for Object-Oriented Fortran: ForUML\n", "abstract": " Many scientists who implement computational science and engineering software have adopted the object-oriented (OO) Fortran paradigm. One of the challenges faced by OO Fortran developers is the inability to obtain high level software design descriptions of existing applications. Knowledge of the overall software design is not only valuable in the absence of documentation, it can also serve to assist developers with accomplishing different tasks during the software development process, especially maintenance and refactoring. The software engineering community commonly uses reverse engineering techniques to deal with this challenge. A number of reverse engineering-based tools have been proposed, but few of them can be applied to objectoriented Fortran applications.In this paper, we propose a software tool to extract unified modeling language (UML) class diagram from Fortran code. The UML class\u00a0\u2026", "num_citations": "1\n", "authors": ["172"]}
{"title": "Programming Ability: Do we know it when we see it\n", "abstract": " On a software development project, the inherent ability of the team members plays a much larger role than the particular technologies or processes used. Despite its importance, the community does not really know how good we are recognizing programming ability. This paper describes a study to measure the ability of programmers to accurately rate the programming ability of their peers. The study was conducted in sophomore-level and junior-level computer science courses at the University of Alabama, comparing peer evaluations of ability to grades on programming assignments. The results showed large discrepancies across the two classes, with students in the sophomore-level class showing much greater ability to assess peer ability.", "num_citations": "1\n", "authors": ["172"]}