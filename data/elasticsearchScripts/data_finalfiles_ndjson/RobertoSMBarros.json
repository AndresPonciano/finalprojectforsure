{"title": "RCD: A recurring concept drift framework\n", "abstract": " This paper presents recurring concept drifts (RCD), a framework that offers an alternative approach to handle data streams that suffer from recurring concept drifts (on-line learning). It creates a new classifier to each context found and stores a sample of data used to build it. When a new concept drift occurs, the algorithm compares the new context to previous ones using a non-parametric multivariate statistical test to verify if both contexts come from the same distribution. If so, the corresponding classifier is reused. The RCD framework is compared with several algorithms (among single and ensemble approaches), in both artificial and real data sets, chosen from frequently used algorithms and data sets in the concept drift research area. We claim the proposed framework had better average ranks in data sets with abrupt and gradual concept drifts compared to both the single classifiers and the ensemble approaches\u00a0\u2026", "num_citations": "97\n", "authors": ["1081"]}
{"title": "Concept drift detection based on Fisher\u2019s Exact test\n", "abstract": " Concept drift detectors are software that usually attempt to estimate the positions of concept drifts in large data streams in order to replace the base learner after changes in the data distribution and thus improve accuracy. Statistical Test of Equal Proportions (STEPD) is a simple, efficient, and well-known method which detects concept drifts based on a hypothesis test between two proportions. However, statistically, this test is not recommended when sample sizes are small or data are sparse and/or imbalanced. This article proposes an ingeniously efficient implementation of the statistically preferred but computationally expensive Fisher\u2019s Exact test and examines three slightly different applications of this test for concept drift detection, proposing FPDD, FSDD, and FTDD. Experiments run using four artificial dataset generators, with both abrupt and gradual drift versions, as well as three real-world datasets, suggest that\u00a0\u2026", "num_citations": "54\n", "authors": ["1081"]}
{"title": "Wilcoxon rank sum test drift detector\n", "abstract": " Online learning regards extracting information from large quantities of data (streams) usually affected by changes in the distribution (concept drift). Drift detectors are software that estimate the positions of these changes to substitute the base learner and ultimately improve accuracy. Statistical Test of Equal Proportions (STEPD) is a simple, well-known, efficient detector which uses a hypothesis test between two proportions to signal the concept drifts. However, despite identifying the existing drifts close to their correct positions, STEPD tends to identify many false positives. This article examines the application of the Wilcoxon rank sum statistical test for concept drift detection, proposing WSTD. Experiments run in the MOA framework using four artificial dataset generators, with abrupt and gradual drift versions of three sizes, as well as seven real-world datasets, suggest WSTD improves the detections of STEPD and\u00a0\u2026", "num_citations": "52\n", "authors": ["1081"]}
{"title": "On the formal specification and derivation of relational database applications\n", "abstract": " The development of database applications is usually carried out informally. The derivation of database programs directly from formal specifications is a well known and unsolved problem. Most of the previous work on the area either tried to solve the problem too generally or was restricted to some trivial aspects, for example deriving the database structure and/or simple operations. However difficult in general, deriving relational database applications directly from Z specifications satisfying a certain set of rules (the method) is not arduous. With appropriate tool support, writing formal specifications according to the method and deriving the corresponding relational database programs can be straightforward. Moreover, it should produce code which is standardized and thus easier to understand and maintain.This paper summarizes material from my Ph.D. thesis [4]. Therefore, it is a pleasure to thank again my supervisors\u00a0\u2026", "num_citations": "34\n", "authors": ["1081"]}
{"title": "Providing geographic-multidimensional decision support over the Web\n", "abstract": " For the last years, many researchers have been addressing their efforts to try to solve the problem regarding the integration between analytic and geographic processing systems. The main goal is to provide users with a system capable of processing both geographic and multidimensional data by abstracting the complexity of separately querying and analyzing these data in a decision making process. However, this integration may not be fully achieved yet or may be built by using proprietary technologies. This paper presents a service integration model for supporting analytic and/or geographic requests over the Web. This model has been implemented by a Web Service, named GMLA WS, which is strongly based on standardized technologies such as Web Services, Java and XML. The GMLA WS query results are displayed using a Web browser as maps and/or tables for helping users in their decision making.", "num_citations": "22\n", "authors": ["1081"]}
{"title": "Towards a Web Service for Geographic and Multidimensional Processing.\n", "abstract": " A lot of research has been developed for integrating the analysis functionality that is available in both analytic and geographic processing systems. The main goal is to provide users with a system capable of processing both geographic and multidimensional data by abstracting the complexity of separately querying and analyzing these data in a decision making process. However, this integration may not be fully achieved yet or may be built by using proprietary technologies. This paper presents a service integration model for supporting analytic and/or geographic requests over the Web. This model has been implemented by a Web Service, named GMLA WS, which is strongly based on standardized technologies such as Web Services, Java and XML. The GMLA WS query results are displayed in a Web browser as maps and/or tables for helping users in their decision making.", "num_citations": "21\n", "authors": ["1081"]}
{"title": "Deriving relational database programs from formal specifications\n", "abstract": " The derivation of database programs directly from formal specifications is a well known and unsolved problem. Most of the previous work on the area either tried to solve the problem too generally or was restricted to some trivial aspects, for example deriving the database structure and/or simple operations. However difficult in general, deriving relational database applications directly from Z specifications satisfying a certain set of rules (the method) is not arduous. This paper describes a set of rules on how to map such specifications to database programs. If appropriate tool support is provided, writing formal specifications according to the method and deriving the corresponding relational database programs should be straightforward. Moreover it should produce code which is standardized and thus easier to understand and maintain.", "num_citations": "21\n", "authors": ["1081"]}
{"title": "A method for the specification of relational database applications\n", "abstract": " The development of database applications is usually carried out informally. In this paper, we propose an extension to the traditional database design process aimed at formalizing the development of (relational) database applications. Specifically, we present a general method which prescribes how to specify the important aspects of relational database applications using Z. It includes the definition of relations, the specification of candidate and foreign keys, and querying and updating of relations, including error handling. Some features of the relational model itself are specified as pre-defined operators which simplify the use of the method. We illustrate the method using a simple example application.", "num_citations": "16\n", "authors": ["1081"]}
{"title": "The real numbers in Z\n", "abstract": " Exact real number computation is a fast growing field with applications varying from debugging to specification of numerical to program. We present a specification of the real numbers represented as infinite lists of signed digits in Z. The expressive power and closeness to usual set theoretical mathematical notation gives us a clean and readable specification which is further directly implementable. A comparison with other formal methods is given together with a partial proof that the object being specified is actually the real numbers.", "num_citations": "13\n", "authors": ["1081"]}
{"title": "Formal development of relational database applications\n", "abstract": " As a first step in the formal development of relational database applications, we present a method for the specification of such applications. The method prescribes how to capture the important aspects of a relational application, including the definition of relations, the specification of candidate and foreign keys, and querying and updating of relations, including error handling. Some features of the relational model itself are specified as pre-defined operators, which simplify the use of the method. We illustrate the method using a simple example application. The specification language used in this paper is Zc, a Z-like formalism.", "num_citations": "11\n", "authors": ["1081"]}
{"title": "Advances in data stream mining with concept drift\n", "abstract": " Online learning regards extracting information from large quantities of data flowing rapidly and continuously (data streams), which are usually affected by changes in the data distribution (concept drift). Drift detection methods are software that mostly attempt to estimate the concept drift positions in data streams in order to substitute the base learner after these changes and ultimately improve accuracy. Ensembles of classifiers have also been proposed to address the problem of mining data streams, with or without explicit concept drift detection, and those ensembles which explicitly detect the drifts, sometimes, use concept drift detectors as auxiliary methods.This thesis proposes two new concept drift detection methods (RDDM and WSTD) and a new ensemble algorithm (BOLE), which is configurable with an auxiliary concept drift detector, aimed at improving the detections of the drifts and the accuracy of current methods in data streams containing concept drift.", "num_citations": "9\n", "authors": ["1081"]}
{"title": "Designing user interface for web interactive systems\n", "abstract": " The user interface design aims at enabling work and other activities to be performed more effectively, efficiently and with more enjoyment and satisfaction. User interface of multiuser Web applications is a medium where all objects being shared on it can be viewed indifferently from the geographical location and its users can interact with each other in real-time. Designing such an interface for users working collaboratively requires dealing with a number of issues. Herein, our concern lies on the control component of Human-Computer Interaction design and corresponding User Interface (UI) software that implements it. Our interactive systems development process based on the MPX-Mapping from PAN (Protagonist Action Notation) into Xchart (extended Statechart) is used to improve the product quality. Then, we illustrate this methodological approach through a case study of a Web interactive system.", "num_citations": "9\n", "authors": ["1081"]}
{"title": "Desenvolvimento de solu\u00e7\u00e3o \u00fanica de software para o Sistema Cart\u00e3o Nacional de Sa\u00fade\n", "abstract": " Este artigo apresenta o projeto de desenvolvimento da segunda gera\u00e7\u00e3o do software do Sistema Cart\u00e3o Nacional de Sa\u00fade, o que inclui a unifica\u00e7\u00e3o das duas vers\u00f5es atualmente existentes, aproveitando o que h\u00e1 de melhor em cada uma delas; a incorpora\u00e7\u00e3o de novas funcionalidades, tanto no atendimento quanto na gest\u00e3o da sa\u00fade; e a ado\u00e7\u00e3o de novas op\u00e7\u00f5es do ponto de vista tecnol\u00f3gico, inclusive com a op\u00e7\u00e3o de outros tipos de equipamentos. Esta vers\u00e3o unificada e melhorada do software dever\u00e1 ser a base da futura expans\u00e3o do projeto piloto, atualmente sendo implantado em 44 munic\u00edpios, para o resto do pa\u00eds.", "num_citations": "8\n", "authors": ["1081"]}
{"title": "Arquitetura do sistema cart\u00e3o nacional de sa\u00fade\n", "abstract": " O Sistema do Cartao Nacional de Sa\u00fade, os componentes dos cinco n\u0131veis e suas fun\u00e7oes sao apresentados e descritos. Aspectos de seguran\u00e7a e privacidade dos dados coletados e armazenados no sistema, bem como os desafios associadosa capacita\u00e7ao de pessoal ea expansao do sistema sao discutidos.", "num_citations": "7\n", "authors": ["1081"]}
{"title": "On the use of data mining tools for data preparation in classification problems\n", "abstract": " The data preparation phase is a critical step in the KDD (Knowledge Discovery in Databases) process. This phase is crucial for a good data mining result because if data is not correctly prepared, all the next phases of the process are compromised. DMPML is a framework that stores preprocessed data for different data mining algorithms in an XML document and retrieves the correct codification by the use of an XSLT document according to the needs of the data mining algorithm. This paper presents a comparison between DMPML and three data mining applications (Weka, Rapid Miner, and KNIME) that implement the directed graph approach, concerning the time spent to create and execute the data preparation tasks for two data mining algorithms. The tests were executed using different types of data sets: numerical, categorical, and mixed. We observed that the scheme used by DMPML can simplify the usage of\u00a0\u2026", "num_citations": "6\n", "authors": ["1081"]}
{"title": "An\u00e1lise de produ\u00e7\u00f5es textuais sobre metazo\u00e1rios negligenciados: import\u00e2ncia das estrat\u00e9gias did\u00e1ticas ilustrando os caracteres e o ambiente\n", "abstract": " Os conte\u00fados de Zoologia muitas vezes provocam dificuldades de aprendizagem, principalmente quando se trata do estudo dos organismos com ancestrais pr\u00f3ximos da origem dos Metazoa. O objetivo deste trabalho foi, ent\u00e3o, analisar as informa\u00e7\u00f5es registradas nos trabalhos divulgados em um Evento Cient\u00edfico abordando estrat\u00e9gias did\u00e1ticas no estudo dos aspectos morfol\u00f3gicos, filogen\u00e9ticos e ambientais de t\u00e1xons. Dos 30 trabalhos analisados, houve refer\u00eancia ao jogo como atividade l\u00fadica facilitadora do aprendizado sobre os caracteres morfol\u00f3gicos em metade deles. O tema filogenia esteve abordado no momento de fundamentar a Introdu\u00e7\u00e3o do artigo constru\u00eddo. Apesar dos animais estudados serem, em sua maioria, representantes de ambiente marinho, tal informa\u00e7\u00e3o encontra-se pouco evidenciada.", "num_citations": "5\n", "authors": ["1081"]}
{"title": "A model-driven method for the development of web applications user interaction layer\n", "abstract": " In the context of Web applications, the interaction between the user and the system is critical. However, the emphasis of software process is usually on the functionality, whereas the user interaction layer is often considered of minor relevance. This paper presents an approach aimed at the specification of the layer that captures the interaction of the user with the system, through the derivation of analysis abstract models into design models. These models shall then be used as input to source code generation, in the implementation discipline, using a tool integrated to an IDE.", "num_citations": "5\n", "authors": ["1081"]}
{"title": "Uma Proposta para Gerenciamento de Metadados nos Padr\u00f5es XML e DTD em Reposit\u00f3rios MOF.\n", "abstract": " Este artigo prop\u00f5e dois metamodelos MOF que d\u00e3o suporte \u00e0 representa\u00e7\u00e3o e gerenciamento de metadados nos padr\u00f5es XML e DTD. Um metamodelo define um modelo para construir modelos. Ele \u00e9 um conjunto de metadados inter-relacionados utilizados para definir modelos. O padr\u00e3o MOF define uma linguagem abstrata e um framework para especifica\u00e7\u00e3o, constru\u00e7\u00e3o e gerenciamento de metamodelos independentes de tecnologia de implementa\u00e7\u00e3o.", "num_citations": "5\n", "authors": ["1081"]}
{"title": "A comparison on how statistical tests deal with concept drifts\n", "abstract": " RCD is a framework proposed to deal with recurring concept drifts. It stores classifiers together with a sample of data used to train them. If a concept drift occurs, RCD tests all the stored samples with a sample of actual data, trying to verify if this is a new context or an old one that is recurring. This is performed by a non-parametric multivariate statistical test to make the verification. This paper describes how two statistical tests (KNN and Cramer) can distinguish between new and old contexts. RCD is tested with several base classifiers, in environments with different rates-of-change values, with gradual and abrupt concept drifts. Results show that RCD improves single classifiers accuracy independently of the statistical test used.", "num_citations": "4\n", "authors": ["1081"]}
{"title": "Automating data preprocessing with dmpml and kddml\n", "abstract": " This paper presents a graphical application for the Data Mining Preparation Markup Language (DMPML), which is an XML application designed to represent the data preparation phase of the KDD process. DMPML supports the reuse of data preprocessing directives using XSLT to map raw data into data ready to be used by many data mining algorithms. The application presented here, DMPML-TS, automates the data preparation phase, speeding up the codification and transformation of data, and providing support to facilitate the use of different data mining algorithms in the same and/or similar data, based on their codification stored in separate XML documents. This paper also presents improvements made to DMPML like the adoption of XRFF for input and output data and the use of only one XSLT file for data transformation. We also present the integration of DMPML-TS and KDDML, an XML language used to\u00a0\u2026", "num_citations": "4\n", "authors": ["1081"]}
{"title": "Amadeus recommends: um sistema de recomenda\u00e7\u00e3o para objetos de aprendizagem\n", "abstract": " Cada vez mais os recursos digitais v\u00eam sendo utilizados na educa\u00e7\u00e3o. Os Objetos de Aprendizagem s\u00e3o bons exemplos dessa populariza\u00e7\u00e3o: j\u00e1 \u00e9 poss\u00edvel encontrar na Internet reposit\u00f3rios de Objetos de Aprendizagem, onde um grande n\u00famero de recursos digitais est\u00e3o dispon\u00edveis para alunos e professores. Este trabalho traz o conceito de Sistema de Recomenda\u00e7\u00e3o para um reposit\u00f3rio de Objetos de Aprendizagem, de modo que o usu\u00e1rio possa ser beneficiado com recomenda\u00e7\u00f5es de outros objetos de aprendizagem que estejam relacionados com o assunto desejado. O trabalho apresenta tanto as funcionalidades, como uma descri\u00e7\u00e3o do algoritmo utilizado para recomenda\u00e7\u00e3o.Abstract: Nowadays, Learning Objects are becoming more popular. We can find several Learning Objects Repositories on the Internet, where teachers and students can download digital resources. In this paper, we present a Learning Object Recommendation System. In this tool, the user can receive recommendations about other learning objects which are related to the searched subject. In addition, we describe the features of the system and the algorithm used to give the recommendation.", "num_citations": "4\n", "authors": ["1081"]}
{"title": "Cosine similarity drift detector\n", "abstract": " Concept drift detection algorithms have several applications. For example, nowadays many systems are interconnected by computer networks and generate a lot of data constantly over time (data stream). Thus, it is essential to detect when this data flow presents an abnormal behavior as this might be an attack on the security of the network. This paper proposes CSDD, a new method that uses the Cosine similarity and windowing techniques to compare recent and older data and detect concept drifts. To validate it, experiments were run with both synthetic and real-world datasets and using Naive Bayes and Hoeffding Tree as base learners. The accuracy results were evaluated using a variation of the Friedman test and the Bonferroni-Dunn post-hoc test, whereas the detections were evaluated using several metrics including the mean distance (D), False Positives (FP), false Negatives (FN), precision, recall\u00a0\u2026", "num_citations": "3\n", "authors": ["1081"]}
{"title": "Dmpml data mining preparation markup language\n", "abstract": " In this paper we propose the language DMPML as an alternative to the standardization of the data preparation phase in a KDD process. DMPML is based on XML and uses XSL transformations to map raw data into processed data. DMPML features, such as extensibility, robustness and platform independence, support exchanging of data preparation projects among DMPML producers in an efficient way. This promotes work reusability and experience interchange among similar projects.", "num_citations": "2\n", "authors": ["1081"]}
{"title": "Interaction pattern gathering in service-oriented applications\n", "abstract": " Application integration is a challenge and continues to be for the next few years. The industry is still figuring out how to best address the challenges of application heterogeneity through modern integration tools and service-oriented and event driven architectures. We are experiencing a new paradigm shift. However, the impact of service-oriented technology is evolutionary rather than revolutionary. Companies need to support enterprise service buses and selectively apply business component design practices and Web services. This paper addresses how interaction patterns in service-oriented applications can be gathered and discusses related collaboration patterns.", "num_citations": "2\n", "authors": ["1081"]}
{"title": "Projetando um Servi\u00e7o de Descoberta de Canais para TV Digital\n", "abstract": " Diversas propostas referentes a TV Digital est\u00e3o sendo desenvolvidas no \u00e2mbito mundial. Entretanto muitos paises como o Brasil, por exemplo, ainda n\u00e3o sabem que sistema ser\u00e1 adotado, muito embora, as pesquisas e interesses pelas operadoras de TV e desenvolvedores j\u00e1 sejam bem significativas. Aplica\u00e7\u00f5es para serem utilizadas dentro do cen\u00e1rio da TV digital v\u00eam sendo projetadas, e possivelmente um n\u00famero muito extenso de canais ser\u00e1 disponibilizado aos seus usu\u00e1rios. Dessa forma, \u00e9 muito importante a cria\u00e7\u00e3o de um servi\u00e7o de localiza\u00e7\u00e3o de canais, pois ficar\u00e1 invi\u00e1vel para os usu\u00e1rios memorizarem um n\u00famero muito grande de canais, principalmente quando se considera que este usu\u00e1rio se desloca com a sua TV em um ve\u00edculo e pretende continuar assistindo a sua programa\u00e7\u00e3o durante o seu deslocamento. Sendo assim, a proposta deste artigo \u00e9 desenvolver um servi\u00e7o de registro e sele\u00e7\u00e3o de canais para a TV Digital, usando para isso a linguagem XML.", "num_citations": "2\n", "authors": ["1081"]}
{"title": "A proposal for management of rdf and rdf schema metadata in mof\n", "abstract": " This paper proposes two MOF metamodels to support the representation and management of RDF and RDF Schema metadata. A metamodel is a set of related metadata used to build models. The MOF defines an abstract language and a framework to support the specification, implementation and ma-nagement of platform independent metamodels. RDF and RDF Schema are standards for the web, and are used for describing, reusing and interchanging metadata. This approach takes advantage of the flexibility of the W3C standards and of the interoperability of the OMG ones to support metadata management. The proposed metamodels may be used by any application that needs to re-resent RDF and RDF Schema metadata.", "num_citations": "2\n", "authors": ["1081"]}
{"title": "Designing user interface for Web interactive systems\n", "abstract": " The user interface design aims at enabling work and other activities to be performed more effectively, efficiently and with more enjoyment and satisfaction. The user interface of multiuser Web applications is a medium where all objects being shared on it can be viewed independently from the geographical location and its users can interact with each other in real time. Designing such an interface for users working collaboratively requires dealing with a number of issues. Herein, our concerns lies on the control component of human-computer interaction design and corresponding user interface (UI) software that implements it. Our interactive systems development process based on the MPX Mapping from PAN (Protagonist Action Notation) into Xchart (eXtended Statechart) is used to improve the product quality. Then, we illustrate this methodological approach through a case study of a Web interactive system.", "num_citations": "2\n", "authors": ["1081"]}
{"title": "Deriving Relational Database Programs\n", "abstract": " The derivation of database programs directly from formal specifications is a well known and unsolved problem. Most of the previous work on the area either tried to solve the problem too generally or was restricted to some trivial aspects, for example deriving the database structure and/or simple operations.", "num_citations": "2\n", "authors": ["1081"]}
{"title": "Statistical Tests Ensemble Drift Detector\n", "abstract": " Several classifiers use supervised inductive learning and, to improve accuracy, they are often combined with concept drift detectors. The ideal learning algorithm associates robustness to noise with sensitivity to concept drifts. Motivated by these statements, this paper proposes a concept drift detector aiming to validate empirically the idea of implementing a drift detection method based on the combination of statistical tests as a viable option to improve the classification. The Statistical Tests Ensemble Detector (STED) uses the results of Brown-Forsythe, O\u2019Brien, and ANOVA statistical tests combined by two voting strategies. To signal warnings, the majority vote is used with the results of the three tests, and, to detect concept drifts, the \u201cEarlyfind-early-report\u201d rule is adopted with the results of the Brown-Forsythe and O\u2019Brien tests only. The experiments\u2019 results using Hoeffding Tree (HT) as base learner in 24 artificial and\u00a0\u2026", "num_citations": "1\n", "authors": ["1081"]}
{"title": "A Change Detector for Prior Probabilities of Classes\n", "abstract": " The majority of current concept drift detectors focus on the results of a base classifier. But if there is a change in the data distribution or in the prior probability of the classes, these methods are unable to identify these types of change. This paper proposes Prior Probability Change Detection Method (PCDM), a method suited to identify changes in the prior probabilities of the classes. It works by associating traditional drift detection methods to analyze how the instances belonging to each class changes in time. Experiments in 24 artificial datasets of six generators indicate that PCDM presented the best results considering the sensitivity metric, the Matthews Correlation Coefficient, and the F1 score without losing any performance in the specificity metric.", "num_citations": "1\n", "authors": ["1081"]}
{"title": "Improving fast adaptive stacking of ensembles\n", "abstract": " The treatment of large data streams in the presence of concept drifts is one of the main challenges in the fields of machine learning and data mining. This article presents two ensemble algorithms designed to quickly adapt to concept drifts, both abrupt and gradual. Fast Stacking of Ensembles boosting the Best (FASEB) and Fast Ensemble boosting the Best with Combined Weighting Voting (FASEB wv ) are adaptations of Fast Adaptive Stacking of Ensembles (FASE), designed to improve their execution time without causing considerable losses in the algorithm's accuracy. In order to achieve a more efficient model, adjustments were made in the update strategy and voting procedure of the ensemble. To evaluate the proposals against the state of the art, we used Naive Bayes (NB) and Hoeffding Tree (HT) as learners to compare the performance of the algorithms on artificial and real-world data sets. The experiments\u00a0\u2026", "num_citations": "1\n", "authors": ["1081"]}
{"title": "Comparing segmentation methods with different base classifiers\n", "abstract": " Large Companies often use statistical models and artificial intelligence to predict several kinds of risks. In general, only one statistical model or a neural network technique is used to predict these risks. It is not so uncommon for some companies to use segmentation to define subpopulation splits for the development of specific predictors to improve decision accuracy. However, the use of segmentation usually depends on the experience of the specialist. The basic premise of this paper is to compare three kinds of segmentation methods, crossed with three different base classifiers, and using five datasets from the UCI Repository. The segmentation methods are: NNTree-a Neural Network Tree based method, the traditional segmentation using Information Gain to split, and an experimental method called FBTSeg. Results show that blending classifiers using segmentation is a viable option to improve results of known and traditional techniques such as statistic regressions and neural networks.", "num_citations": "1\n", "authors": ["1081"]}
{"title": "Comparing approaches to prepare data in classification problems\n", "abstract": " This paper presents a comparison between DMPML and three data mining applications (Weka, RapidMiner, and KN-IME) that implement the directed graph approach, concerning the time spent to create and execute the data preparation tasks for two data mining algorithms. The tests were executed using different types of data sets: numerical, categorical, and mixed. We observed that the scheme used by the DMPML framework can simplify the usage of different data mining algorithms and reduce the time spent creating the data preparation tasks.", "num_citations": "1\n", "authors": ["1081"]}
{"title": "A XML-based quality model for web services certification.\n", "abstract": " Internet has made possible the development of software as services, consumed on demand and developed by third parties. In this sense, a quality model is necessary to enable evaluation and, consequently, reuse of the services by consumers. In this way, this paper proposes a quality model based on the ISO 9126 standard, defining a set of attributes and metrics for an effective evaluation of Web services. A XML-based representation model was created to support this quality model, and a security schema was proposed to guarantee integrity and authenticity of the model.", "num_citations": "1\n", "authors": ["1081"]}
{"title": "Managing Petri nets in MOF repositories\n", "abstract": " The necessity of interoperability among Petri net tools has led to the development of the PNML (Petri Net Markup Language) standard. By adopting PNML, tools mainly concentrated on modeling activities should generate PNML files to be analyzed by analysis-specific Petri net tools. In this context, we propose an extension to the PNML based on MOF (Meta Object Facility). The implementation of the MOF metamodel enables us to manager Petri net specifications within MOF repositories. In order to illustrate our approach, we present a case study.", "num_citations": "1\n", "authors": ["1081"]}
{"title": "ProcML: Padroniza\u00e7\u00e3o de processos administrativos p\u00fablicos utilizando XML\n", "abstract": " Atualmente, um dos grandes desafios para o setor p\u00fablico \u00e9 tornar mais \u00e1gil a presta\u00e7\u00e3o dos seus servi\u00e7os. Racionalizar os custos e melhorar a qualidade dos servi\u00e7os oferecidos consiste em desenvolver solu\u00e7\u00f5es onde a utiliza\u00e7\u00e3o da Tecnologia da Informa\u00e7\u00e3o torna-se um dos fatores primordiais. O objetivo principal deste projeto \u00e9 estabelecer um padr\u00e3o, ProcML\u2013Processos Markup Language, para a representa\u00e7\u00e3o de processos administrativos que tramitam em \u00f3rg\u00e3os p\u00fablicos baseado em XML. XML \u00e9 uma linguagem de marca\u00e7\u00e3o que prov\u00ea conceitos para descrever, armazenar, intercambiar e manipular dados estruturados e semiestruturados. Tomando como refer\u00eancia o banco de dados existente na UFPE\u2013Universidade Federal de Pernambuco, propomos a cria\u00e7\u00e3o de processos administrativos digitais. Tais processos s\u00e3o controlados eletronicamente e podem ser acessados pelos interessados atrav\u00e9s\u00a0\u2026", "num_citations": "1\n", "authors": ["1081"]}
{"title": "Um Framework para Extra\u00e7\u00e3o de Dados em Documentos Cient\u00edficos: Uma Abordagem baseada em XML\n", "abstract": " Hoje em dia, documentos s\u00e3o facilmente publicados atrav\u00e9s da Internet. Assim. um grande n\u00famero de documentos torna-se avaliados diariamente, fazendo o gerenciamento e a manipula\u00e7\u00e3o desses progressivamente mais dif\u00edcil. Al\u00e9m disso, a exist\u00eancia de formatos incompat\u00edveis faz o desenvolvimento de ferramentas eficientes para o tratamento com documentos uma tarefa altamente complexa. Este artigo prop\u00f5e um framework de reestrutura\u00e7\u00e3o sem\u00e2ntica para a convers\u00e3o de documentos para XML, fazendo poss\u00edvel o uso consistente de linguagens de consulta e transforma\u00e7\u00e3o.", "num_citations": "1\n", "authors": ["1081"]}
{"title": "A protagonist-oriented approach for multiple user interface design\n", "abstract": " Multiple user interface is a medium where all objects being shared on it can be viewed indifferently from the geographical location and its users can interact with each other in real-time. Designing such an interface for users working collaboratively requires to deal with a number of issues. Herein, our concerns lies on the control component of human-computer interaction design and corresponding user interface software that implements it. We propose a protagonist-based approach approach for multiple user interface design which considers the mapping from a protagonist-oriented notation into extended statecharts.", "num_citations": "1\n", "authors": ["1081"]}
{"title": "Sistematizando o Ciclo de Vida da Integra\u00e7\u00e3o de Servi\u00e7os na Web\n", "abstract": " Service integration over the Web is not an easy task, as these services are supposed to work in a synchronized manner to gain satisfactory results. This process implies in the development of a software module that takes into account the users needs, some integration requirements and many other aspects related to the traditional software development process. Considering the importance of the service integration process systematization, we propose in this paper a means of systematizing the cycle life of service integration over the Web. Finally, a case study, regarding to the XMLA and WFS services integration on the Web, is presented to validate the proposed ideas.", "num_citations": "1\n", "authors": ["1081"]}
{"title": "XML para Audiometria\n", "abstract": " The audiometry is formed by the set of different tests that compose the auditive function evaluation; in other words, it is formed by the set of necessary exams for prevention and identification, as well as the treatment, of people with auditive deficiencies. The evaluation of the auditive function includes different exams that inform us about origin, location, quality, evolution, prediction, etc. of the deficiencies. The results of these exams produce a lot of information, which represents a problem for the audiologist, both in storage and data manipulation. Another problem is the presentation template of the results, which must use the specification of an international pattern (ASHA, ISO, ANSI, etc.). Given these, this work proposes the development of a XML (eXtensible Markup Language) capable of representing the results of the basic exams that compose contemporary audiometry, using the specification of the DTD (Document Type Definition) structure, the XML data and the XSL (eXtensible Stylesheet Language) template. The result is a language proposal, in XML, for representation of audiologic data, capable of being the communication pattern between audiologists, allowing storage and transmission of general audiometric exams, and producing benefits like remote patient monitoring, on-line transference of exams results, etc.", "num_citations": "1\n", "authors": ["1081"]}
{"title": "Designing Multiple User Interface for Internet-based Interactive Systems\n", "abstract": " Multiple user interface is a medium where all objects being shared on it can be viewed indifferently from the geographical location and its users can interact with each other in real-time. Designing such an interface for users working collaboratively requires to deal with a number of issues. Herein, our concerns lies on the control component of human-computer interaction design and corresponding user interface software that implements it. We make use of our approach to interactive systems development based on the mapping from a protagonist-oriented notation into extended statecharts.", "num_citations": "1\n", "authors": ["1081"]}