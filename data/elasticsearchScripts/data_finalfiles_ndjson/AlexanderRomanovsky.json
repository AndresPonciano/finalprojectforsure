{"title": "Coordinated forward error recovery for composite web services\n", "abstract": " This paper proposes a solution based on forward error recovery, oriented towards providing dependability of composite Web services. While exploiting their possible support for fault tolerance (e.g., transactional support at the level of each service), the proposed solution has no impact on the autonomy of the individual Web services, our solution lies in system structuring in terms of co-operative atomic actions that have a well-defined behavior, both in the absence and in the presence of service failures. More specifically, we define the notion of Web Service Composition Action (WSCA), based on the Coordinated Atomic Action concept, which allows structuring composite Web services in terms of dependable actions. Fault tolerance can then be obtained as an emergent property of the aggregation of several potentially non-dependable services. We further introduce a framework enabling the development of composite\u00a0\u2026", "num_citations": "141\n", "authors": ["523"]}
{"title": "Dependability in the Web services architecture\n", "abstract": " The Web services architecture is expected to play a prominent role in developing next generation distributed systems. This chapter discusses how to build dependable systems based on the Web services architecture. More specifically, it surveys base fault tolerance mechanisms, considering both backward and forward error recovery mechanisms, and shows how they are adapted to deal with the specifics of the Web in the light of ongoing work in the area. Existing solutions, targeting the development of dependable composite Web services, may be subdivided into two categories that are respectively related to the specification of Web services composition and to the design of dedicated distributed protocols.", "num_citations": "120\n", "authors": ["523"]}
{"title": "Supporting reuse in Event B development: modularisation approach\n", "abstract": " Recently, Space Systems Finland has undertaken formal Event B development of a part of the on-board software for the BepiColombo space mission. As a result, lack of modularisation mechanisms in Event B has been identified as a serious obstacle to scalability. One of the main benefits of modularisation is that it allows us to decompose system models into components that can be independently developed. It also helps to manage complexity of models that in the industrial setting are usually very large and difficult to comprehend. On the other hand, modularisation enables reuse of formally developed components in the formal product line development. In this paper we propose a conservative extension of Event B formalism to support modularisation. We demonstrate how our approach can support reuse in the formal development in the space domain.", "num_citations": "85\n", "authors": ["523"]}
{"title": "Industrial deployment of system engineering methods\n", "abstract": " This book is about experience gained and lessons learnt in the course of a major European project on industrial deployment of formal methods. The DEPLOY Integrated Project ran for 4 years and involved 15 partners from academia and industry. The editors came to the project from different backgrounds and with different motivations. Sascha (Alexander) Romanovsky has been working on system dependability and fault tolerance for many years and has always stressed the importance of reasoning about faults and fault tolerance at the earlier phases of system development. He coordinated the RODIN project, preceding DEPLOY, and became involved in writing the DEPLOY proposal and coordination of DEPLOY to see the tools and methods originated in RODIN further advanced and applied in wide industrial settings. Martyn Thomas is an industrialist who has been concerned with safety-critical and other high\u00a0\u2026", "num_citations": "84\n", "authors": ["523"]}
{"title": "Cost effective, reliable and secure workflow deployment over federated clouds\n", "abstract": " The significant growth in cloud computing has led to increasing number of cloud providers, each offering their service under different conditions - one might be more secure whilst another might be less expensive or more reliable. At the same time user applications have become more and more complex. Often, they consist of a diverse collection of software components, and need to handle variable workloads, which poses different requirements on the infrastructure. Therefore, many organisations are considering using a combination of different clouds to satisfy these needs. It raises, however, a non-trivial issue of how to select the best combination of clouds to meet the application requirements. This paper presents a novel algorithm to deploy workflow applications on federated clouds. First, we introduce an entropy-based method to quantify the most reliable workflow deployments. Second, we apply an extension of\u00a0\u2026", "num_citations": "69\n", "authors": ["523"]}
{"title": "Co-ordinated atomic actions: from concept to implementation\n", "abstract": " The Co-ordinated Atomic Action (or CA action) concept is a unified scheme for co-ordinating complex concurrent activities and supporting error recovery between multiple interacting objects in a distributed object-oriented system. It provides a conceptual framework for dealing with different kinds of concurrency and achieving fault tolerance by extending and integrating two complementary concepts-conversations and transactions. Conversations (enhanced with concurrent exception handling) are used to control co-operative concurrency and to implement co-ordinated error recovery whilst transactions are used to maintain the consistency of shared resources in the presence of failures and competitive concurrency. This paper explains the CA action concept in detail and then addresses related design issues such as multi-thread co-ordination, exception handling and resolution, co-ordinated access to shared objects and provision of software fault tolerance. Finally, brief details are given of a number of experimental prototype implementations and case studies.", "num_citations": "67\n", "authors": ["523"]}
{"title": "Advances in exception handling techniques\n", "abstract": " Modern software systems are becoming more complex in many ways and have to cope with a growing number of abnormal situations which, in turn, are increasingly complex to handle. The most general way of dealing with these problems is by incorporating exception handling techniques in software design. In the past, various exception handling models and techniques have been proposed and many of them are part of practical languages and software composition technologies. This book is composed of five parts, which deal with topics related to exception handling in the context of programming language models, design methodologies, concurrent and distributed systems, applications and experiences, and large-scale systems such as database and workflow process mangagement systems. The 17 coherently written chapters by leading researchers competently address a wide range of issues in exception handling.", "num_citations": "53\n", "authors": ["523"]}
{"title": "A metadata-based architectural model for dynamically resilient systems\n", "abstract": " Designing open and distributed systems that can dynamically adapt in a predictable way to unexpected events is a challenging issue still not solved. Achieving this objective is a very complex task since it implies reasoning at run-time, explicitly and in a combined way, on a system's functional and non-functional characteristics. This paper proposes a service-oriented architectural model allowing the dynamic enforcement of formally expressed metadata-based resilience policies. It also describes preliminary dynamic resilience experiments acting as proof of concept.", "num_citations": "51\n", "authors": ["523"]}
{"title": "MetaSelf: an architecture and a development method for dependable self-* systems\n", "abstract": " This paper proposes a software architecture and a development process for engineering dependable and controllable self-organising (SO) systems. Our approach addresses dependability by exploiting metadata to support decision making and adaptation based on the dynamic enforcement of explicitly defined policies. Control is obtained by actively modifying metadata, policies or components. We show how this applies to two different systems:(1) a dynamically resilient Web service system; and (2) an industrial assembly system with self-adaptive and SO capabilities.", "num_citations": "48\n", "authors": ["523"]}
{"title": "Developing mode-rich satellite software by refinement in Event B\n", "abstract": " To ensure dependability of on-board satellite systems, the designers should, in particular, guarantee correct implementation of the mode transition scheme, i.e., ensure that the states of the system components are consistent with the global system mode. However, there is still a lack of scalable approaches to formal verification of correctness of complex mode transitions. In this paper we present a formal development of an Attitude and Orbit Control System (AOCS) undertaken within the ICT DEPLOY project. AOCS is a complex mode-rich system, which has an intricate mode-transition scheme. We show that refinement in Event B provides the engineers with a scalable formal technique that enables both development of mode-rich systems and proof-based verification of their mode consistency.", "num_citations": "46\n", "authors": ["523"]}
{"title": "Using inherent service redundancy and diversity to ensure web services dependability\n", "abstract": " Achieving high dependability of Service-Oriented Architecture (SOA) is crucial for a number of emerging and existing critical domains, such as telecommunication, Grid, e-science, e-business, etc. One of the possible ways to improve this dependability is by employing service redundancy and diversity represented by a number of component web services with the identical or similar functionality at each level of the composite system hierarchy during service composition. Such redundancy can clearly improve web service reliability (trustworthiness) and availability. However to apply this approach we need to solve a number of problems. The paper proposes several solutions for ensuring dependable services composition when using the inherent service redundancy and diversity. We discuss several composition models reflecting different dependability objectives (enhancement of service availability\u00a0\u2026", "num_citations": "42\n", "authors": ["523"]}
{"title": "Exception handling in component-based system development\n", "abstract": " Designers of component-based software face two problems related to dealing with abnormal events: developing exception handling at the level of the integrated system and accommodating (and adjusting, if necessary) exceptions and exception handling provided by individual components. Our intention is to develop an exception handling framework suitable for component-based system development by applying general exception handling mechanisms which have been proposed and successfully used in concurrent/distributed systems and in programming languages. The framework is applied in three steps. Firstly, individual components are wrapped in such a way that the wrappers perform activity related to local error detection and exception handling, and signal, if necessary, external exceptions outside the component. At the second step the execution of the overall system is structured as a set of dynamic\u00a0\u2026", "num_citations": "42\n", "authors": ["523"]}
{"title": "Current trends in exception handling\n", "abstract": " THE importance of exception handling is well-recognized by system designers and software engineers. Exception handing is very often the most important part of the system because it deals with abnormal situations. The goal of exception handling mechanisms is to make programs robust and reliable. However, for a variety of reasons, not the least among which is the fact that more than half of the code is often devoted to exception detection and handling, many failures are caused by incomplete or incorrect handling of these abnormal situations. Analysis of accidents in computer controlled systems has shown that very often their causes tend to be in improper dealing with exceptional situations (see, for example,[1],[2]). The requirements for correct system behavior during exception handling are in some sense even higher than for the system operating in a normal mode. Even the programs that are generally\u00a0\u2026", "num_citations": "41\n", "authors": ["523"]}
{"title": "Improving the dependability of web services integration\n", "abstract": " The WS-Mediator framework employs an off-the-shelf mediator architecture and resilience-explicit computing in pursuit of dependable, dynamic Web services integration. Web services and service-oriented architectures (SOAs) represent a new paradigm for building distributed computing applications. Web services offer advantages over conventional distributed computing middleware platforms. Web services' loosely coupled architecture, combined with their standardized interoperability, lead to a new computing paradigm that supports the construction of more flexible and dynamic distributed applications", "num_citations": "40\n", "authors": ["523"]}
{"title": "Augmenting Event-B modelling with real-time verification\n", "abstract": " A large number of dependable embedded systems have stringent real-time requirements imposed on them. Analysis of their real-time behaviour is usually conducted at the implementation level. However, it is desirable to obtain an evaluation of real-time properties early at the development cycle, i.e., at the modelling stage. In this paper we present an approach to augmenting Event-B modelling with verification of real-time properties in Uppaal. We show how to extract a process-based view from an Event-B model that together with introducing time constraints allows us to obtain a timed automata model - an input model of Uppaal. We illustrate the approach by development and verification of the data processing software of the BepiColombo Mission.", "num_citations": "38\n", "authors": ["523"]}
{"title": "Protective wrapper development: A case study\n", "abstract": " We have recently proposed a general approach to engineering protective wrappers as a means of detecting errors or unwanted behaviour in systems employing an OTS (Off-The-Shelf) item, and launching appropriate recovery actions. This paper presents results of a case study in protective wrapper development, using a Simulink model of a steam boiler system together with an OTS PID (Proportional, Integral and Derivative) controller. The protective wrappers are developed for the model of the system in such a way that they allow detection and tolerance of typical errors caused by unavailability of signals, violations of constraints, and oscillations.", "num_citations": "37\n", "authors": ["523"]}
{"title": "Action-oriented exception handling in cooperative and competitive concurrent object-oriented systems\n", "abstract": " The chief aim of this survey is to discuss exception handling models which have been developed for concurrent object systems. In conducting this discussion we rely on the following fundamental principles: exception handling should be associated with structuring techniques; concurrent systems require exception handling which is different from that used in sequential systems; concurrent systems are best structured out of (nested) actions; atomicity of actions is crucial for developing complex systems. In this survey we adhere to the well-known classification of concurrent systems, developed in the 70s by C.A.R. Hoare, J.J. Horning and B. Randell, into cooperative, competitive and disjoint ones. Competitive systems are structured using atomic transactions. Atomic actions are used for structuring cooperative systems. Complex systems in which components can compete and cooperate are structured using\u00a0\u2026", "num_citations": "37\n", "authors": ["523"]}
{"title": "On systematic design of protectors for employing OTS items\n", "abstract": " Off-the-shelf (OTS) components are increasingly used in application areas with stringent dependability requirements. Component wrapping is a well known structuring technique used in many areas. We propose a general approach to developing protective wrappers that assist in integrating OTS items with a focus on the overall system dependability. The wrappers are viewed as redundant software used to detect errors or suspicious activity and to execute appropriate recovery when possible; wrapper development is considered as a part of system integration activities. Wrappers are to be rigorously specified and executed at run time as a means of protecting OTS items against faults in the rest of the system, and the system against the OTS item's faults. Possible symptoms of erroneous behaviour to be detected by a protective wrapper and possible actions to be undertaken in response are listed and discussed. The\u00a0\u2026", "num_citations": "36\n", "authors": ["523"]}
{"title": "Patterns for representing FMEA in formal specification of control systems\n", "abstract": " Failure Modes and Effects analysis (FMEA) is a widely used technique for inductive safety analysis. FMEA provides engineers with valuable information about failure modes of system components as well as procedures for error detection and recovery. In this paper we propose an approach that facilitates representation of FMEA results in formal Event-B specifications of control systems. We define a umber of patterns for representing requirements derived from FMEA in formal system model specified in Event-B. The patterns help the developers to trace the requirements from safety analysis to formal specification. Moreover, they allow them to increase automation of formal system development by refinement. Our approach is illustrated by an example - a sluice control system.", "num_citations": "35\n", "authors": ["523"]}
{"title": "Context-aware exception handling in mobile agent systems: the MoCA case\n", "abstract": " Handling erroneous conditions in context-aware mobile agent systems is challenging due to their intrinsic characteristics: openness, lack of structuring, mobility, asynchrony, and increased unpredictability. Even though several context-aware middleware systems support now the development of mobile agent-based applications, they rarely provide explicit and adequate features for context-aware exception handling. This paper reports our experience in implementing error handling strategies in some prototype context-aware collaborative applications built with the MoCA (Mobile Collaboration Architecture) system. MoCA is a publish-subscribe middleware supporting the development of collaborative mobile applications by incorporating explicit services to empower software agents with context-awareness. We propose a novel context-aware exception handling mechanism and discuss some lessons learned during its\u00a0\u2026", "num_citations": "34\n", "authors": ["523"]}
{"title": "Structuring integrated web applications for fault tolerance\n", "abstract": " This paper shows how modern structuring techniques can be employed in integrating complex web applications such as travel agency systems. The main challenges the developers of such systems face are dealing with legacy web services and incorporating means for tolerating errors. Because of the very nature of such systems, exception handling is the main recovery technique to be applied in their development. We employ coordinated atomic actions to allow disciplined handling of such abnormal situations by recursively structuring the integrated system and by associating handlers with such actions. We use protective wrappers in such a way that each operation on legacy components is transformed into an atomic action with a well-defined interface. To accommodate a combined use of several ready-made environments (such as communication packages, services and run-time supports), we employ a\u00a0\u2026", "num_citations": "34\n", "authors": ["523"]}
{"title": "Experimenting with exception propagation mechanisms in service-oriented architecture\n", "abstract": " Exception handling is one of the popular means used for improving dependability and supporting recovery in the Service-Oriented Architecture (SOA). This practical experience paper presents the results of error and fault injection into Web Services. We summarize our experiments with the SOA-specific exception handling features provided by the two development kits: the Sun Microsystems JAX-RPC and the IBM WebSphere Software Developer Kit for Web Services. The main focus of the paper is on analyzing exception propagation and performance as the major factors affecting fault tolerance (in, particular, error handling, and fault diagnosis) in Web Services.", "num_citations": "33\n", "authors": ["523"]}
{"title": "Software engineering for multi-agent systems II: research issues and practical applications\n", "abstract": " Advances in networking technology have revitalized the investigation of agent technologyasapromisingparadigmforengineeringcomplexdistributedsoftware systems. Agent technology has been applied to a wide range of application-mains, including e-commerce, human-computer interfaces, telecommunications, and software assistants. Multi-agent systems (MASs) and their underlying t-ories provide a more natural support for ensuring important properties such as autonomy, mobility, environment heterogeneity, organization, openness, and intelligence. As a consequence, agent-based systems are likely to provide new-proaches to dealing with the complexity of developing and maintaining modern software. However, developing robust large-scale agent-based systems will-quire new software engineering approaches. There are currently many methods and techniques for working with individual agents or with systems built using only a few agents. Unfortunately, agent-based software engineering is still in its infancy and existing software engineering approaches are unable to cope with large MASs. The complexity associated with a large MAS is considerable. When a huge number of agents interact over heterogeneous environments, various phenomena occur which are not as easy to capture as when only a few agents are working together. As the multiple software agents are highly collaborative and operate in networked environments, they have to be context-aware and deal with-vironment uncertainty. This makes their coordination and management more di? cult and increases the likelihood of exceptional situations, such as security holes\u00a0\u2026", "num_citations": "33\n", "authors": ["523"]}
{"title": "An application of fault tolerance patterns and coordinated atomic actions to a problem in railway scheduling\n", "abstract": " Developing and applying advanced approaches for system structuring is vital for fighting ever-increasing complexity of modern and future software systems. The concept of Coordinated Atomic (CA) actions has been developed at Newcastle University for designing and structuring complex concurrent and distributed applications. Certain successful experience has been gained in applying them in several application areas. The purpose of the research, some initial results of which we report here, is twofold: to show how CA actions can be used in a new application area (a railway control system) and to analyse how the design patterns which have been developed using our previous experience can help in designing such system using CA actions.", "num_citations": "32\n", "authors": ["523"]}
{"title": "Tracking dengue epidemics using twitter content classification and topic modelling\n", "abstract": " Detecting and preventing outbreaks of mosquito-borne diseases such as Dengue and Zika in Brasil and other tropical regions has long been a priority for governments in affected areas. Streaming social media content, such as Twitter, is increasingly being used for health vigilance applications such as flu detection. However, previous work has not addressed the complexity of drastic seasonal changes on Twitter content across multiple epidemic outbreaks. In order to address this gap, this paper contrasts two complementary approaches to detecting Twitter content that is relevant for Dengue outbreak detection, namely supervised classification and unsupervised clustering using topic modelling. Each approach has benefits and shortcomings. Our classifier achieves a prediction accuracy of about 80\u00a0% based on a small training set of about 1,000 instances, but the need for manual annotation makes it hard to\u00a0\u2026", "num_citations": "31\n", "authors": ["523"]}
{"title": "Method for deadlock recovery using consistent global checkpoints\n", "abstract": " A method for deadlock recovery in a shared resource multiprocess message passing computer system. The processes executing in the computer system perform periodic local checkpoints and communicate via inter-process messages. Upon detection of a deadlock in the computer system, inter-process rollback dependency is analyzed in order to choose a resource to reclaim. The choice of a resource to reclaim is made such that a resource manager which manages the resource can be rolled back so as to reclaim the resource, and such that an application process which is waiting for the resource is not rolled back past the point at which deadlock was detected. Thus, upon system restart, the reclaimed resource can be provided to the waiting process, and the waiting process can execute past the deadlock point. In one embodiment, the recovery line is determined by selecting appropriate checkpoints from a\u00a0\u2026", "num_citations": "31\n", "authors": ["523"]}
{"title": "Exception handling in coordination-based mobile environments\n", "abstract": " Mobile agent systems have many attractive features including asynchrony, openness, dynamicity and anonymity, which makes them indispensable in designing complex modern applications that involve moving devices, human participants and software. To be comprehensive this list should include fault tolerance, yet as our analysis shows, this property is, unfortunately, often overlooked by middleware designers. A few existing solutions for fault tolerant mobile agents are developed mainly for tolerating hardware faults without providing any general support for application-specific recovery. In this paper we describe a novel exception handling model that allows application-specific recovery in coordination-based systems consisting of mobile agents. The proposed mechanism is general enough to be used in both loosely-and tightly-coupled communication models. The general ideas behind the mechanism are\u00a0\u2026", "num_citations": "30\n", "authors": ["523"]}
{"title": "Dependable composite web services with components upgraded online\n", "abstract": " Achieving high dependability of Web Services (WSs) dynamically composed from component WSs is an open problem. One of the main difficulties here is due to the fact that the component WSs can and will be upgraded online, which will affect the dependability of the composite WS. The paper introduces the problem of component WS upgrade and proposes solutions for dependable upgrading in which natural redundancy, formed by the latest and the previous releases of a WS being kept operational, is used. The paper describes how \u2018confidence in correctness\u2019 can be systematically used as a measure of dependability of both the component and the composite WSs. We discuss architectures for a composite WS in which the upgrade of the component WS is managed by switching the composite WS from using the old release of the component WS to using its newer release only when the confidence is high\u00a0\u2026", "num_citations": "30\n", "authors": ["523"]}
{"title": "Framework based on design patterns for providing persistence in object-oriented programming languages\n", "abstract": " An approach is described providing object persistence in object-oriented programming languages without modifying the run-time system or the language itself By successively applying design patterns such as the 'serialiser', 'factory method', and 'strategy' patterns we develop an object-oriented framework for providing object persistence. The advantages of object-orientation are highlighted: structured classification through class-hierarchies, extensibility and promotion of reuse. The framework clearly separates persistence control from storage control. A hierarchy of different storage types, useful in different application domains, is introduced. The framework does not rely on any kind of special programming language features. It only uses basic object-oriented programming techniques, and is therefore implementable in any object-oriented programming language. An experimental implementation in Ada 95 is presented.", "num_citations": "30\n", "authors": ["523"]}
{"title": "A looming fault tolerance software crisis?\n", "abstract": " Experience suggests that it is edifying to talk about software crises at NATO workshops. It is argued in this position paper that proper engineering of fault tolerance software has not been getting the attention it deserves. The paper outlines the difficulties in building fault tolerant systems and describes the challenges software fault tolerance is facing. The solution being advocated is to place a special emphasis on fault tolerance software engineering which would provide a set of methods, techniques, models and tools that would exactly fit application domains, fault assumptions and system requirements and support disciplined and rigorous fault tolerance throughout all phases of the life cycle. The paper finishes with an outline of some directions of work requiring special focused efforts from the R&D community.", "num_citations": "29\n", "authors": ["523"]}
{"title": "Drip catalyst: An MDE/MDA method for fault-tolerant distributed software families development\n", "abstract": " Coordinated Atomic Actions (CAAs) offer a structuring technique for cooperative exception handling in open distributed systems. The DRIP framework embodies in terms of a set of Java classes the CAAs. It has been proven to be successful in IST DeVa and DSoS Projects. This paper communicates DRIP Catalyst, a method for stepwise and rigorous development of complex, fault-tolerant distributed software families. This method is designed to facilitate reuse and instantiation of DRIP. It comprises an MDE process, a UML-based notation and an M DA development support tool. This tool is implemented as an extension of IBM/Rational XDE. DRIP Catalyst has been experimentally validated by developing two service-oriented, fault-tolerant, software family prototypes. It is also designed to allow formal verification of fault-tolerance applications properties.", "num_citations": "29\n", "authors": ["523"]}
{"title": "Verifying mode consistency for on-board satellite software\n", "abstract": " Space satellites are examples of complex embedded systems. Dynamic behaviour of such systems is typically described in terms of operational modes that correspond to the different stages of a mission and states of the components. Components are susceptible to various faults that complicate the mode transition scheme. Yet the success of a mission depends on the correct implementation of mode changes. In this paper we propose a formal approach that ensures consistency of mode changes while developing a system architecture by refinement. The approach relies on recursive application of modelling and refinement patterns that enforce correctness while implementing the mode transition scheme. The proposed approach is exemplified by the development of an Attitude and Orbit Control System undertaken within the ICT DEPLOY project.", "num_citations": "28\n", "authors": ["523"]}
{"title": "Modal systems: Specification, refinement and realisation\n", "abstract": " Operation modes are useful structuring units that facilitate design of several safety-critical systems such as such as avionic, transportation and space systems. Although some support to the construction of modal systems can be found in the literature, modelling abstractions for the formal specification, analysis and correct construction of modal systems are still lacking.               This paper discusses existing support for the construction of modal systems and proposes both a formalisation and a refinement notion for modal systems. A modal system, specified using the proposed abstractions, can be realised using different specification languages. Complementing the contribution, we define the requirements for an Event-B model to realise a modal system specification. A case study illustrates the proposed approach.", "num_citations": "28\n", "authors": ["523"]}
{"title": "The threat of uncertainty in service-oriented architecture\n", "abstract": " In this paper we present our practical experience in benchmarking a number of existing Web Services, and investigating the instability of their performance and the delays induced by the communication medium. We provide the results of statistical data analysis and discuss a technique of Web Services performance assessment taking out of the network delays. We have found that the uncertainty discovered in Web Services operations affects dependability of Service-Oriented Architecture and will require additional specific resilience techniques.", "num_citations": "28\n", "authors": ["523"]}
{"title": "Open multithreaded transactions: Keeping threads and exceptions under control\n", "abstract": " Although transactional models have proved to be very useful for numerous applications, the development of new models to reflect the ever-increasing complexity and diversity of modern applications is a very active area of research. Analysis of the existing models of multithreaded transactions shows that they either give too much freedom to threads and do not control their participation in transactions, or unnecessarily restrict the computational model by assuming that only one thread can enter a transaction. Another important issue, which many models do not address properly, is providing adequate exception handling features. A new model of multithreaded transactions is proposed. Its detailed description is given, including rules of thread behaviour when transactions start, commit and abort, and rules of exception raising, propagation and handling. This model is supported by enhanced error detection techniques to\u00a0\u2026", "num_citations": "28\n", "authors": ["523"]}
{"title": "CAA-DRIP: a framework for implementing Coordinated Atomic Actions\n", "abstract": " This paper presents an implementation framework, called CAA-DRIP, that has been defined to allow a straightforward implementation of dependable distributed applications designed using the coordinated atomic action (CAA) paradigm. CAAs provide a coherent set of concepts adapted to the design of fault tolerant distributed systems that includes: structured transactions, distribution, cooperation, competition, and forward and backward error recovery mechanisms triggered by exceptions. DRIP (dependable remote interacting processes) is an efficient Java implementation framework, which provides support for implementing \"dependable multiparty interactions (DMI)\" which includes a general exception handling mechanism. As DMI has a softer exception handling semantics with respect to CAA semantics, a CAA design can be implemented by DRIP. The aim of the CAA-DRIP framework is to provide a set of Java\u00a0\u2026", "num_citations": "27\n", "authors": ["523"]}
{"title": "Cama: Structured coordination space and exception propagation mechanism for mobile agents\n", "abstract": " Exception handling has been proven to be the most general fault tolerance technique as it allows effective application-specific recovery. If exception handling is to make programmer\u00d5s work more productive and less error-prone, however, it requires adequate support from the programming and execution environments. Scoping is a dynamic structuring technique which makes it easier for the developers to deal with the complexity of system execution by narrowing down the context visible for the individual system components. In this work we are specifically interested in scoping that supports error confinement and allows system error recovery to be limited to the area surrounding the error. The approach we propose aims at assisting in rigorous development of structured multilevel fault tolerant agent systems.", "num_citations": "27\n", "authors": ["523"]}
{"title": "A generic framework for the engineering of self-adaptive and self-organising systems.\n", "abstract": " This paper provides a unifying view for the engineering of self-adaptive (SA) and self-organising (SO) systems. We first identify requirements for designing and building trustworthy self-adaptive and self-organising systems. Second, we propose a generic framework combining design-time and run-time features, which permit the definition and analysis at design-time of mechanisms that both ensure and constrain the run-time behaviour of an SA or SO system, thereby providing some assurance of its self-* capabilities. We show how this framework applies to both an SA and an SO system, and discuss several current proof-of-concept studies on the enabling technologies.", "num_citations": "26\n", "authors": ["523"]}
{"title": "Choosing Effective Methods for Diversity\u2014How to Progress from Intuition to Science\n", "abstract": " Design diversity is a popular defence against design faults in safety critical systems. Design diversity is at times pursued by simply isolating the development teams of the different versions, but it is presumably better to \u201cforce\u201d diversity, by appropriate prescriptions to the teams. There are many ways of forcing diversity. Yet, managers who have to choose a cost-effective combination of these have little guidance except their own intuition. We argue the need for more scientifically based recommendations, and outline the problems with producing them. We focus on what we think is the standard basis for most recommendations: the belief that, in order to produce failure diversity among versions, project decisions should aim at causing \u201cdiversity\u201d among the faults in the versions. We attempt to clarify what these beliefs mean, in which cases they may be justified and how they can be checked or disproved\u00a0\u2026", "num_citations": "25\n", "authors": ["523"]}
{"title": "Trustworthy cyber-physical systems engineering\n", "abstract": " From the Foreword\" Getting CPS dependability right is essential to forming a solid foundation for a world that increasingly depends on such systems. This book represents the cutting edge of what we know about rigorous ways to ensure that our CPS designs are trustworthy. I recommend it to anyone who wants to get a deep look at these concepts that will form a cornerstone for future CPS designs.\"--Phil Koopman, Carnegie Mellon University, Pittsburgh, Pennsylvania, USA Trustworthy Cyber-Physical Systems Engineering provides practitioners and researchers with a comprehensive introduction to the area of trustworthy Cyber Physical Systems (CPS) engineering. Topics in this book cover questions such as What does having a trustworthy CPS actually mean for something as pervasive as a global-scale CPS? How does CPS trustworthiness map onto existing knowledge, and where do we need to know more? How can we mathematically prove timeliness, correctness, and other essential properties for systems that may be adaptive and even self-healing? How can we better represent the physical reality underlying real-world numeric quantities in the computing system? How can we establish, reason about, and ensure trust between CPS components that are designed, installed, maintained, and operated by different organizations, and which may never have really been intended to work together? Featuring contributions from leading international experts, the book contains sixteen self-contained chapters that analyze the challenges in developing trustworthy CPS, and identify important issues in developing engineering methods for CPS. The book\u00a0\u2026", "num_citations": "24\n", "authors": ["523"]}
{"title": "Synthesis of processor instruction sets from high-level ISA specifications\n", "abstract": " As processors continue to get exponentially cheaper for end users following Moore's law, the costs involved in their design keep growing, also at an exponential rate. The reason is ever increasing complexity of processors, which modern EDA tools struggle to keep up with. This paper focuses on the design of Instruction Set Architecture (ISA), a significant part of the whole processor design flow. Optimal design of an instruction set for a particular combination of available hardware resources and software requirements is crucial for building processors with high performance and energy efficiency, and is a challenging task involving a lot of heuristics and high-level design decisions. This paper presents a new compositional approach to formal specification and synthesis of ISAs. The approach is based on a new formalism, called Conditional Partial Order Graphs, capable of capturing common behavioural patterns\u00a0\u2026", "num_citations": "24\n", "authors": ["523"]}
{"title": "SafeCap domain language for reasoning about safety and capacity\n", "abstract": " The on-going UK SAFECAP project develops modeling techniques and tools for improving railway capacity while ensuring that safety standards are maintained. This paper reports recent SAFECAP results on designing a Domain Specific Language (DSL) that will allow engineers to improve the node and junction capacity while guaranteeing operational safety. The SAFECAP DSL is introduced to define railway topology, its logical structure and signalling rules. The formal semantics of this graphical DSL, defined as part of our work, allows us to reason about system safety. The tooling environment, the SAFECAP Platform, offers graphical editing of railway schemas and an interface to a range of verification for ensuring railway operational safety. The work on extending the environment and its deployment in the railway sector continues with our SAFECAP partners: Invensys Rail and Swansea University.", "num_citations": "24\n", "authors": ["523"]}
{"title": "Using diversity in cloud-based deployment environment to avoid intrusions\n", "abstract": " This paper puts forward a generic intrusion-avoidance architecture to be used for deploying web services on the cloud. The architecture, targeting the IaaS cloud providers, avoids intrusions by employing software diversity at various system levels and dynamically reconfiguring the cloud deployment environment. The paper studies intrusions caused by vulnerabilities of system software and discusses an approach allowing the system architects to decrease the risk of intrusions. This solution will also reduce the so-called system\u2019s days-of-risk which is calculated as a time period of an increased security risk between the time when a vulnerability is publicly disclosed to the time when a patch is available to fix it.", "num_citations": "24\n", "authors": ["523"]}
{"title": "Advanced topics in exception handling techniques\n", "abstract": " Exception handling is an essential part of software and system architectures and a crucial element in the tool-set that enables the building of resilient, robust and safe software systems. The term \u201cexception\u201d has been variously defined but most commonly is used to refer to, as explained in the foreword to this book,\u201cpredictable but uncommon situations\u201d encountered during the execution of a program. Since the mid-1970s, when John Goodenough, David Parnas and Brian Randell published the first papers to define the research areas of fault-tolerant computing and programmed exception handling, a range of design principles and programming techniques have been developed to cope with such uncommon situations. A \u2018when others\u2019 clause has also been introduced, as it is sometimes clearly impossible to predict all of them. Having held a fruitful ECOOP workshop in 2000, in 2001 we published the first collection of\u00a0\u2026", "num_citations": "24\n", "authors": ["523"]}
{"title": "Looking ahead in open multithreaded transactions\n", "abstract": " Open multithreaded transactions constitute building blocks that allow a developer to design and structure the execution of complex distributed systems featuring cooperative and competitive concurrency in a reliable way. In this paper we describe an optimization to the standard open multithreaded transaction model that does not impose any participant synchronization when committing a transaction, but still provides the same execution semantics. This optimization - letting participants \"look ahead\" and continue their execution on the outside of the transaction - makes it possible to speed up the execution of in individual transaction with multiple participants tremendously. The paper describes all technical issues that had to be solved, e.g. adapting concurrency control of transactional objects to be look-ahead aware, adapting joining rules for look-ahead participants, and re-defining exception handling in the presence\u00a0\u2026", "num_citations": "24\n", "authors": ["523"]}
{"title": "On dependability of composite Web services with components upgraded online\n", "abstract": " Ensuring dependability of composite Web services, dynamically composed of component Web services, is an open issue. One of the main difficulties here is due to the fact that component Web services can and will be upgraded online. The challenge is then to ensure that the overall dependability of the composite service is not undermined. The solutions we propose in this position paper make use of natural redundancy present in systems containing a new and an old release of the component.", "num_citations": "24\n", "authors": ["523"]}
{"title": "On applying coordinated atomic actions and dependable software architectures for developing complex systems\n", "abstract": " Modern concurrent and distributed applications are becoming increasingly complex; so, in order to provide fault tolerance, special structuring mechanisms are required to help reduce this complexity. Unfortunately, such structuring techniques are mostly introduced as design and implementation features, which complicates their employment. The approach we propose relies on introducing the appropriate software structuring together with associated fault tolerance measures at the earlier phases of software development and on supporting it with special software architectures and design patterns.", "num_citations": "24\n", "authors": ["523"]}
{"title": "Diversity for off-the-Shelf Components\n", "abstract": " \" Commercial-off-the-shelf\"(COTS) or, generally,\" offthe-shelf\"(OTS) software items are increasingly used in building systems, instead of only relying on bespoke software items1. This trend is driven by a wish to reduce costs, and by some hope that greater re-use of software may lead to higher quality (via more feedback from use). Thus, for instance, the US Dept of Defence policy is now to encourage the use of COTS items. This trend extends to critical systems with high dependability requirements, like a computer-based railway signalling systems by Alcatel (Austria)[1].A serious problem with OTS items (software, but also complex digital hardware) is that they often lack the guarantee of good development practice, and the extensive documentation of it, which are traditionally the basis for accepting/certifying software for critical applications. Even for commercial applications with modest dependability requirements, using OTS items requires some trust that they will not become a\" weak link\", making the final product intolerably unreliable. If the OTS items have already seen much operational use, this experience could be used to forecast their dependability in a new context; but this experience is seldom documented with sufficient accuracy and detail to allow confident predictions. Much of the on-going discussion about OTS items addresses this issue. A notorious case of a US warship being disabled by a crash of Windows NT in 1997 [2] is often quoted to illustrate the problems with dependence on COTS items. The debate is open about how COTS items could be certified to have sufficient reliability but what is clear is that a solution will not be widely\u00a0\u2026", "num_citations": "24\n", "authors": ["523"]}
{"title": "The SafeCap platform for modelling railway safety and capacity\n", "abstract": " This paper describes a tooling platform that supports reasoning about railway capacity while ensuring system safety. It uses a Domain Specific Language (DSL) that allows signalling engineers to design stations and junctions, to check their safety and to evaluate the potential improvements of capacity while applying various alteration patterns that change the railway schemas. The platform uses a combination of model checking and SMT solving to verify system safety in the most efficient and user-friendly way. It includes several plug-ins that evaluate various capacity parameters. The tool uses the Eclipse technology, including its EMF and GMF frameworks. It has been developed in close cooperation with the Invensys Rail engineers and applied in a variety of mediumscale projects, which has demonstrated its ability to help understand the effects that changes in the plans and schemas can potentially have on\u00a0\u2026", "num_citations": "23\n", "authors": ["523"]}
{"title": "Measuring the dependability of web services for use in e-science experiments\n", "abstract": " This paper introduces a dependability assessment tool (WSsDAT) for Web Services monitoring and testing. It allows users to evaluate dependability of Web Services from the point of view of their clients by collecting metadata representing a number of dependability metrics. This Java-based tool can be deployed in diverse geographical locations to monitor and test the behavior of a selected set of Web Services within preset time intervals. The graphical user interface of the tool provides real-time statistical data describing dependability of the Web Services under monitoring. The tool makes it possible for the users to identify typical patterns of dependability-specific behavior depending on the time of the day, days of the week or the client locations. In addition, WSsDAT can collect and analyze service dependability measurements during long periods of time, as well as obtaining dependability-related\u00a0\u2026", "num_citations": "23\n", "authors": ["523"]}
{"title": "Development of dependable web services out of undependable web components\n", "abstract": " The aim of this work is to develop novel approaches to constructing and modelling dependable Web Services (WSs) built out of Web Components that can be undependable. To achieve this aim we have been working on the following tasks:-Analysing the WS failures modes and introducing a failure taxonomy;-Analysing Web security as an attribute of WS dependability;-Investigating a structured approach to the Web Service development that is based the Web Service Composition Actions (WSCA) scheme;-Proposing an event-driven simulation model of the Composite WSs;-Analysing the WS upgrading problem and developing schemes for WSs online upgrade;-Outlining future directions of WSCA-based systems development focusing specifically on the means for dependability achievement and assessment.", "num_citations": "23\n", "authors": ["523"]}
{"title": "Transaction support for ada\n", "abstract": " This paper describes the transaction support framework OPTIMA and its implementation for Ada 95. First, a transaction model that fits concurrent programming languages is presented. Then the design of the framework is given. Applications from many different domains can benefit from using transactions; it is therefore important to provide means to customize the framework depending on the application requirements. This flexibility is achieved by using design patterns. Class hierarchies with classes implementing standard transactional behavior are provided, but a programmer is free to extend the hierarchies by implementing application-specific functionalities. An interface for Ada programmers is presented and its use demonstrated via a simple example.", "num_citations": "23\n", "authors": ["523"]}
{"title": "Practical exception handling and resolution in concurrent programs\n", "abstract": " The paper discusses how atomic actions based on forward error recovery in the form of concurrent exception handling and resolution can be programmed within standard conventional languages (Ada and Ada 95). We express the main characteristics of the general atomic action scheme in terms of these languages and discuss a set of templates and programmers' conventions which would allow the programming of atomic actions within Ada and Ada 95. We offer an approach to implementing a resolution procedure (function) and outline other approaches. The scheme is very flexible in that it gives an opportunity for programmers to use any sort of the resolution procedure. We introduce a general concept of self-checking programming, which allows the kind of failure assumption necessary for simplifying the atomic action support, and discuss how it can be applied (to Ada, in particular). It is shown how this approach\u00a0\u2026", "num_citations": "23\n", "authors": ["523"]}
{"title": "Fault-tolerant communication for distributed embedded systems\n", "abstract": " Fault-tolerant communication is a crucial point in building distributed safety-critical real-time systems, as they are used today e.g. in the automotive and avionics domain. To argue about the timing properties of a distributed system and to show the fault-tolerance of its communication, a predictable timing of the system is needed. This can be solved using the time-triggered paradigm. In accordance with this paradigm, a time-triggered communication protocol, FlexRay, and an operating system OSEKtime with corresponding communication layer FTCom for the fault-tolerant communication were introduced by the FlexRay Consortium and OSEK/VDX respectively. In this chapter we present the formal specifications of FlexRay and FTCom that allow us not only to argue about their properties in a precise, formal manner and to infer the dependences between their properties, but also to prove the correctness of the\u00a0\u2026", "num_citations": "22\n", "authors": ["523"]}
{"title": "Rigorous development of fault-tolerant agent systems\n", "abstract": " Agent systems are examples of complex distributed systems. Though agents operate in unreliable communication environment, often such systems have high reliability requirements imposed on them. Therefore, we need methods which allow us not only to ensure system correctness but also to integrate design of fault tolerance mechanisms in the development process. In this paper we present a formal approach for the development of fault tolerant location-based mobile agent systems. Our approach is based on stepwise refinement in the Event B framework. We start from an abstract system specification modelling agents together with their communication environment and gradually introduce implementation details in a number of correctness-preserving transformations. Such stepwise development allows us to specify complex system properties, such as fault tolerance, in a structured and rigorous way\u00a0\u2026", "num_citations": "22\n", "authors": ["523"]}
{"title": "Model-based development of fault tolerant systems of systems\n", "abstract": " This paper puts forward a new method for model-based development of fault tolerant systems of systems. The method covers early architectural design, formal modelling and verification. The focus is on supporting modelling techniques that ensure systematic and structured reasoning about faults, error detection and fault and error recovery. The method combines semi-formal modelling in SysML with formal modelling and verification conducted in CSP. The work is part of the EC COMPASS Integrated Project on Comprehensive Modelling for Advanced Systems of Systems 1 .", "num_citations": "21\n", "authors": ["523"]}
{"title": "Fault modelling for systems of systems\n", "abstract": " This paper proposes a systematic model-based approach to the architectural description of faults and fault tolerance mechanisms in systems of systems (SoSs). The challenges of engineering dependable SoSs motivate a proposal for the view elements that would be needed to support a fault tolerance profile for SoSs using the Systems Modelling Language (SysML). The effectiveness of the approach is evaluated on a case study based on a real emergency response SoS. Results suggest that this is a promising approach, and that a comprehensive solution to the engineering of dependable SoSs requires that such a profile is linked to methods and tools for requirements elicitation, safety analysis, architectural design and formal verification.", "num_citations": "21\n", "authors": ["523"]}
{"title": "Patterns for modelling time and consistency in business information systems\n", "abstract": " Maintaining semantic consistency of data is a significant problem in distributed information systems, particularly those on which a business may depend. Our current work aims to use Event-B and the Rodin tools to support the specification and design of such systems in a way that integrates well into existing development processes. This paper presents Event-B patterns that may be used to represent recovery from time-bounded inconsistency and illustrates their use in a model derived from industrial applications.", "num_citations": "21\n", "authors": ["523"]}
{"title": "Osmotic monitoring of microservices between the edge and cloud\n", "abstract": " Osmotic computing is a new IoT application programming paradigm that's driven by the significant increase in resource capacity/capability at the network edge, along with support for data transfer protocols that enable such resources to interact more seamlessly with Cloud-based services. Much of the difficulty in QoS and performance monitoring of IoT applications in an Osmotic computing environment is due to the massive scale and heterogeneity (IoT + Edge + Cloud) of computing environments. To, this end, this work presents an integrated monitoring system for monitoring IoT applications decomposed as microservices and executed in an Osmotic computing environment. A real-world smart parking IoT application is used for an experimental evaluation and for demonstrating the effectiveness of the proposed approach. Through rigorous experimental evaluation, we validate the Osmotic monitoring system ability to\u00a0\u2026", "num_citations": "20\n", "authors": ["523"]}
{"title": "Metaself-a framework for designing and controlling self-adaptive and self-organising systems\n", "abstract": " This paper proposes a unifying framework for the engineering of dependable self-adaptive (SA) and self-organising (SO) systems. We first identify requirements for designing and building such SA and SO systems. Second, we propose a generic framework combining design-time and run-time features which permit the definition and analysis at design-time of mechanisms that both ensure and constrain the run-time behaviour of an SA or SO system, thereby providing some assurance of its self-* capabilities. We show how this framework applies to two different systems: (1) a dynamically resilient Web service system (2) design of an industrial assembly system with both SA and SO capabilities.", "num_citations": "20\n", "authors": ["523"]}
{"title": "Using the b method for the formalization of coordinated atomic actions\n", "abstract": " Coordinated Atomic Actions have been proven successful for building dependable distributed systems due to their support for error recovery for both competitive and cooperative concurrent activities. This chapter introduces the formal specification of Coordinated Atomic Actions emphasizing the formalization of proposed dependability mechanisms using the B formal method. The specification then allows developing dependable systems, where the B formal specification can be refined to obtain a correct implementation of the associated runtime support.", "num_citations": "20\n", "authors": ["523"]}
{"title": "Protective Wrapping of OTS components\n", "abstract": " Off-the-shelf (OTS) components are increasingly used in application areas with high dependability requirements. We propose a general approach to developing protective wrappers, in order to integrate OTS items with the rest of the system without reducing the system dependability.", "num_citations": "20\n", "authors": ["523"]}
{"title": "On composing dependable web services using undependable web components\n", "abstract": " This paper proposes a novel approach to constructing and modelling Dependable Web Services (DeW) that are built by composing web components that can be undependable. This is achieved by applying a structured approach to the Web Services (WSs) development, based on the Web Service Composition Actions (WSCAs) scheme and a corresponding event-driven simulation model of composite WS. The dependability and fault-tolerance of composite WS is achieved by employing forward error recovery based on multilevel system structuring enabling application-specific exception handling.", "num_citations": "19\n", "authors": ["523"]}
{"title": "Except for exception handling\u2026\n", "abstract": " Exception handling in Ada has a number of well-known problems. It allows for the propagation of unhandled and anonymous exceptions, it is error-prone and it is inappropriate for some language features such as tasking and tagged types. Ada programs with exceptions can be difficult to understand, develop, modify and analyse, and the exception handling features can be misused in a number of ways.In this paper we introduce the requirements for good exception handling features. We classify the problems with Ada exception handling into two subsets: serious conceptual problems that require an improvement of the language features, and problems attributable to the misuse of the existing features. Problems in the second category can be solved by improving programmers' understanding of the features and ways of using them.", "num_citations": "19\n", "authors": ["523"]}
{"title": "An exception handling framework for n-version programming in object-oriented systems\n", "abstract": " An approach to introducing exception handling into object oriented N-version programming (NVP) is proposed. General principles of structuring systems with diversity are outlined. The importance of using exceptions while applying diversely developed software is shown. Internal and external exceptions are clearly separated in our framework: each version has its own internal exceptions but the external exceptions of all versions have to be the same and identical to the interface exceptions of the diversely designed class. This scheme requires an adjudicator of a special kind to allow signalling interface exceptions when a majority of versions have signalled the same exception. These ideas are demonstrated using a general class diversity framework developed recently. An Ada implementation is outlined.", "num_citations": "19\n", "authors": ["523"]}
{"title": "Real distribution of response time instability in service-oriented architecture\n", "abstract": " This paper reports our practical experience of benchmarking a complex System Biology Web Service, and investigates the instability of its behaviour and the delays induced by the communication medium. We present the results of our statistical data analysis and distributions which fit and predict the response time instability typical of Service-Oriented Architectures (SOAs) built over the Internet. Our experiment has shown that the request processing time of the target e-science Web Service (WS) has a higher instability than the network round trip time. It has been found that by using a particular theoretical distribution, within short time intervals the request processing time can be represented better than the network round trip time. Moreover, certain characteristics of the probability distribution series of the round trip time make it particularly difficult to fit them theoretically. The experimental work reported in the paper\u00a0\u2026", "num_citations": "18\n", "authors": ["523"]}
{"title": "Designing fault-tolerant mobile systems\n", "abstract": " The purpose of this paper is to investigate how several innovative techniques, not all initially intended for fault-tolerance, can be applied in providing fault tolerance of complex mobile agent systems. Due to their roaming nature, mobile agents usually run on Java-based platforms, which ensures full portability of mobile code. The first part of the paper discusses specific characteristics of mobile systems, outlines the application areas benefiting from code mobility, and shows why the existing error recovery techniques are not suitable for mobile systems. In the next part of the paper we present evaluation criteria for fault tolerance techniques, and propose several possible solutions for error recovery at the application level: meta-agent, Coordinated Atomic actions, asynchronous resolution, self-repair, and proof carrying code. The intention is to allow system developers to choose the approach which is suited best\u00a0\u2026", "num_citations": "18\n", "authors": ["523"]}
{"title": "Extending conventional languages by distributed/concurrent exception resolution\n", "abstract": " The state of art in handling and resolving concurrent exceptions is discussed and a brief outline of all research in this area is given. Our intention is to demonstrate that exception resolution is a very useful concept which facilitates joint forward error recovery in concurrent and distributed systems. To do this, several new arguments are considered. We understand resolution as reaching an agreement among cooperating participants of an atomic action. It is provided by the underlying system to make it unified and less error prone, which is important for forward error recovery, complex by nature. We classify atomic action schemes into asynchronous and synchronous ones and discuss exception handling for schemes of both kinds. The paper also deals with introducing atomic action schemes based on exception resolution into existing concurrent and distributed languages, which usually have only local exceptions. We\u00a0\u2026", "num_citations": "18\n", "authors": ["523"]}
{"title": "Exploring uncertainty of delays as a factor in end-to-end cloud response time\n", "abstract": " This paper reports our experience in benchmarking a cloud-based web-service and investigates instability of its performance and the delays induced by the communication medium when measured from multiple client locations. We compare the performance of MS Azure, Go Grid and an in-house server running the same benchmark web service and analyze how the client and service implementation technologies affect its performance. The uncertainty discovered in the network delay affects the overall performance and dependability of cloud computing provisioning and requires specific resilience techniques.", "num_citations": "17\n", "authors": ["523"]}
{"title": "On fault tolerance reuse during refinement\n", "abstract": " Complex modern applications have to be developed to be dependable to meet their requirements and expectations of their users. An important part of this is their ability to deal with various threats (such as faults in the system environment, operator's mistakes, underlying hardware and software support problems). Development of modern applications is complicated by the need for systematic and rigorous integration of fault tolerance measures. The paper focuses on reuse of fault tolerance modelling. First, it introduces the idea of general modelling templates reflecting abstract views on system behaviour with respect to faults. These templates are used during system detalisation (refinement) to capture the user's view on system external behaviour. Secondly, it proposes to use a library of concrete modelling patterns allowing developers to systematically integrate specific fault tolerance mechanisms (eg recovery blocks\u00a0\u2026", "num_citations": "17\n", "authors": ["523"]}
{"title": "Coordinated atomic actions as a technique for implementing distributed gamma computation\n", "abstract": " The intentions of this paper are to discuss Coordinated Atomic (CA) actions and to demonstrate how they can be used in a very new application area. We apply this concept to designing a particular case of the Gamma computational paradigm, i.e. distributed Gamma computation. Within our approach, each Gamma reaction is an action. We demonstrate how Gamma computation can be effectively implemented in conventional distributed message passing systems using CA actions. The paper discusses our design and the benefits we gain by applying CA actions: allowing as much concurrency as possible, together with guaranteeing data consistency, a better system structuring, clear separation of different system levels, and additional flexibility. This experimental design and the Java implementation allow us to conclude that CA actions are a very powerful paradigm which can be used for implementing many\u00a0\u2026", "num_citations": "17\n", "authors": ["523"]}
{"title": "Patterns for refinement automation\n", "abstract": " Formal modelling is indispensable for engineering highly dependable systems. However, a wider acceptance of formal methods is hindered by their insufficient usability and scalability. In this paper, we aim at assisting developers in rigorous modelling and design by increasing automation of development steps. We introduce a notion of refinement patterns \u2013 generic representations of typical correctness-preserving model transformations. Our definition of a refinement pattern contains a description of syntactic model transformations, as well as the pattern applicability conditions and proof obligations for verifying correctness preservation. This work establishes a basis for building a tool that would support formal system development via pattern reuse and instantiation. We present a prototype of such a tool and some examples of refinement patterns for automated development in the Event B formalism.", "num_citations": "16\n", "authors": ["523"]}
{"title": "Structuring specifications with modes\n", "abstract": " The two dependability means considered in this paper are rigorous design and fault tolerance. It can be complex to rigorously design some classes of systems, including fault tolerant ones, therefore appropriate abstractions are needed to better support system modelling and analysis. The abstraction proposed in this paper for this purpose is the notion of operation mode. Modes are formalised and their relation to a state-based formalism in a refinement approach is established. The use of modes for fault tolerant systems is then discussed and a case study presented. Using modes in state-based modelling allows us to improve system structuring, the elicitation of system assumptions and expected functionality, as well as requirement traceability.", "num_citations": "16\n", "authors": ["523"]}
{"title": "Formal modelling and analysis of business information applications with fault tolerant middleware\n", "abstract": " Distributed information systems are critical to the functioning of many businesses; designing them to be dependable is a challenging but important task. We report our experience in using formal methods to enhance processes and tools for development of business information software based on service-oriented architectures. In our work, which takes place in an industrial setting, we focus on the configuration of middleware, verifying application-level requirements in the presence of faults. In pilot studies provided by SAP, we used the Event-B formalism and the open Rodin tools platform to prove properties of models of business protocols and expose weaknesses of certain middleware configurations with respect to particular protocols. We then extended the approach to use models automatically generated from diagrammatic design tools, opening the possibility of seamless integration with current development\u00a0\u2026", "num_citations": "16\n", "authors": ["523"]}
{"title": "Structured coordination spaces for fault tolerant mobile agents\n", "abstract": " Exception handling has proved to be the most general fault tolerance technique as it allows effective application-specific recovery. If exception handling is to make the programmer\u2019s work more productive and less error-prone, however, it requires adequate support from programming and execution environments. Scoping is a dynamic structuring technique which makes it easier for developers to deal with the complexity of system execution by narrowing down the context visible to individual system components.This study is specifically concerned with scoping that supports error confinement and allows system error recovery to be limited to the area confining the error. The approach we propose is designed to assist in rigorous development of structured multi-level fault tolerant agent systems.", "num_citations": "16\n", "authors": ["523"]}
{"title": "Open Multithreaded Transactions: A Transaction Model for Concurrent Object-Oriented Programming\n", "abstract": " Modern programming languages provide features that allow a programmer to express concurrency in an application by using active objects, ie objects with their own thread of control, and distribution. Concurrent systems can be classified into cooperative systems, where individual components collaborate, share results and work for a common goal, and competitive systems, where the individual components are not aware of each other and compete for shared resources. Programming languages address collaboration and competition by providing means for communication and synchronization among active objects. The realization of complex object-oriented systems often needs sophisticated and elaborate concurrency features which may go beyond the traditional concurrency control associated with separate method calls. A transaction groups together a sequence of actions, and can therefore encapsulate complex behavior and embrace groups of objects and method calls. Transactions structure the dynamic system execution as opposed to the static structuring based on objects. Because of the ACID properties, transactions are able to hide the effects of concurrency and at the same time act as firewalls for errors, making them appropriate building blocks for structuring reliable distributed systems. This thesis investigates how transactions can be integrated with concurrent object-oriented programming, and in particular, how transactions can be made available to an application programmer at the programming language level.In the first part of the thesis, existing transaction models are reviewed and their suitability for concurrent programming\u00a0\u2026", "num_citations": "16\n", "authors": ["523"]}
{"title": "Formal development and validation of Java dependable distributed systems\n", "abstract": " The rapid expansion of Java programs into the software market is often not supported by a proper development methodology. We present a formal development methodology, well suited for Java dependable distributed applications. It is based on the stepwise refinement of model oriented formal specifications, and enables validation of the obtained system wrt the client's requirements. Three refinement steps have been identified in the case of fault tolerant distributed applications: first, starting from informal requirements, an initial formal specification is derived. It does not depend on implementation constraints and provides a centralized solution; second, dependability and distribution constraints are integrated; third, the Java implementation is realised. The CO-OPN/2 language is used to express specifications formally; and the dependability and distribution design as based on the Coordinated Atomic action concept\u00a0\u2026", "num_citations": "16\n", "authors": ["523"]}
{"title": "A generic framework for the engineering of self-adaptive and self-organising systems\n", "abstract": " This paper provides a unifying view for the engineering of self-adaptive (SA) and self-organising (SO) systems. We first identify requirements for designing and building trustworthy self-adaptive and self-organising systems. Second, we propose a generic framework combining design-time and run-time features, which permit the definition and analysis at design-time of mechanisms that both ensure and constrain the run-time behaviour of an SA or SO system, thereby providing some assurance of its self-* capabilities. We show how this framework applies to both an SA and an SO system, and discuss several current proof-of-concept studies on the enabling technologies.", "num_citations": "15\n", "authors": ["523"]}
{"title": "Recruiting from the network: discovering Twitter users who can help combat Zika epidemics\n", "abstract": " Tropical diseases like Chikungunya and Zika have come to prominence in recent years as the cause of serious health problems. We explore the hypothesis that monitoring and analysis of social media content streams may effectively complement institutional disease prevention efforts. Specifically, we aim to identify selected members of the public who are likely to be sensitive to virus combat initiatives. Focusing on Twitter and on the topic of Zika, our approach involves (i) training a classifier to select topic-relevant tweets from the Twitter feed, and (ii) discovering the top users who are actively posting relevant content about the topic. In this short paper we describe our analytical approach and prototype architecture, discuss the challenges of dealing with noisy and sparse signal, and present encouraging preliminary results.", "num_citations": "14\n", "authors": ["523"]}
{"title": "Dynamically partitioning workflow over federated clouds for optimising the monetary cost and handling run-time failures\n", "abstract": " Several real-world problems in domain of healthcare, large scale scientific simulations, and manufacturing are organised as workflow applications. Efficiently managing workflow applications on the Cloud computing data-centres is challenging due to the following problems: (i) they need to perform computation over sensitive data (e.g., Healthcare workflows) hence leading to additional security and legal risks especially considering public cloud environments and (ii) the dynamism of the cloud environment can lead to several run-time problems such as data loss and abnormal termination of workflow task due to failures of computing, storage, and network services. To tackle above challenges, this paper proposes a novel workflow management framework call Deploy on Federated Cloud Framework (DoFCF) that can dynamically partition scientific workflows across federated cloud (public/private) data-centres for\u00a0\u2026", "num_citations": "14\n", "authors": ["523"]}
{"title": "Experiments with odroid-xu3 board\n", "abstract": " Power and energy consumption is a crucial factor for modern computer systems. The optimal operation of the system could be attained only if the interplay between performance and energy consumption was considered during the design. We performed several experiments with the Ordoid-XU3 board. The results of these experiments will help to model runtime for high performance and energy efficient system operations.", "num_citations": "14\n", "authors": ["523"]}
{"title": "3.2. 2 Traceable Engineering of Fault\u2010Tolerant SoSs\n", "abstract": " Systems of systems (SoSs) are characterised by a challenging combination of continuous evolution, emergent behaviour and distributed, autonomous and independent constituents. The development of SoSs that can tolerate faults and harmful events is hampered by these and other complexities. Currently there is little in the way of methods or tools to help SoS developers to design fault\u2010tolerant SoSs. In this paper we present a structured approach for capturing requirements for a fault\u2010tolerant SoS and a fault modelling architectural framework (FMAF) that supports disciplined and reusable development of fault\u2010tolerant architectures. We also provide a traceable mapping of the fault\u2010tolerant requirements into SoS architectural designs. Finally we apply our techniques to a real\u2010world SoS case study.", "num_citations": "14\n", "authors": ["523"]}
{"title": "Dependability of service-oriented computing: time-probabilistic failure modelling\n", "abstract": " In the paper we discuss a failure and servicing model of software applications that employ the service-oriented paradigm for defining cooperation with clients. The model takes into account a time-probabilistic relationship between different servicing outcomes and failures modes. We put forward a set of measures for estimating dependability of service provisioning from the client\u2019s viewpoint and present analytical models to be used for the assessment of the mean servicing and waiting times depending on client\u2019s timeout settings.", "num_citations": "14\n", "authors": ["523"]}
{"title": "Studying the interplay of concurrency, performance, energy and reliability with archon--an architecture-open resource-driven cross-layer modelling framework\n", "abstract": " The interplay between pairs of critical factors such as performance, energy and reliability within modern computing systems has always been an interesting topic of study. However, studying the interplay of all three factors together in a many-core, multi-layer design setting has been a relatively recent undertaking. This work explores the practical problems encountered in such studies and introduces the modelling framework ArchOn, which is based on a novel resource-driven graph representation. ArchOn facilitates the analysis and potentially design and synthesis of systems whose design domains are more conveniently organized into multiple layers or levels (e.g. application, OS, hardware, etc.) and potentially large scale and diverse types of concurrency. The layer-agnostic formalism helps designers reason about cross-layer issues and the resource-driven approach is advantageous for reasoning about such\u00a0\u2026", "num_citations": "13\n", "authors": ["523"]}
{"title": "Frameworks for designing and implementing dependable systems using coordinated atomic actions: a comparative study\n", "abstract": " This paper1 presents ways of implementing dependable distributed applications designed using the Coordinated Atomic Action (CAA) paradigm. CAAs provide a coherent set of concepts adapted to fault tolerant distributed system design that includes structured transactions, distribution, cooperation, competition, and forward and backward error recovery mechanisms triggered by exceptions. DRIP (Dependable Remote Interacting Processes) is an efficient Java implementation framework which provides support for implementing Dependable Multiparty Interactions (DMI). As DMIs have a softer exception handling semantics compared with the CAA semantics, a CAA design can be implemented using the DRIP framework. A new framework called CAA-DRIP allows programmers to exclusively implement the semantics of CAAs using the same terminology and concepts at the design and implementation levels. The new\u00a0\u2026", "num_citations": "13\n", "authors": ["523"]}
{"title": "Refinement patterns for fault tolerant systems\n", "abstract": " The paper puts forward the idea of using fault tolerance refinement patterns to assist system developers in disciplined application of software fault tolerance mechanisms in rigorous system design. Two patterns are proposed to support a correct introduction of recovery blocks and N- version programming into a system model; these are formally defined and their correctness proven. We also discuss several important issues involved in the use of these patterns in engineering systems, including tool support and pattern composition.", "num_citations": "13\n", "authors": ["523"]}
{"title": "Experimenting with exception handling mechanisms of web services implemented using different development kits\n", "abstract": " Achieving high dependability and fault-tolerance in service-oriented architecture (SOA) is an open problem. Exception handling is one of the powerful means for improving the quality of SOA. The paper discusses the results of experimental analysis of the SOA-specific exceptions and factors affecting availability and fault-tolerance of Web Services, implemented using two development kits: JAX-RPC implementation at Sun Microsystems and IBM WebSphere Software Developer Kit for Web Services. We specifically focus on the results of exception propagation and performance analysis. Finally, applications of different error recovery strategies including backward, forward and enhanced forward error recovery, in the context of SOA are briefly discussed.", "num_citations": "13\n", "authors": ["523"]}
{"title": "Dependable self-organising software architectures-An approach for self-managing systems\n", "abstract": " We argue that principles from the design of dependable software, especially separation of concerns and the use of formality, can be applied beneficially in the construction of self-managing systems. We illustrate this approach by presenting an experimental architecture for dynamic and resilient computer-based systems which utilises component metadata to govern reconfigurations in accordance with formally stated policies. Initial experiments with the architecture are described. We argue that the architecture describes a self-organising system and, further, provides a basis for self-managing systems.", "num_citations": "13\n", "authors": ["523"]}
{"title": "Coordinated atomic actions: how to remain ACID in the modern world\n", "abstract": " In the last 10-15 years many models have been proposed to extend conventional ACID (atomicity, consistency, isolation and durability) transactions [1, 2]. Some of the main reasons for this are as follows:\u2022 in some applications data have to be locked for a very long period of time until a long-lived transaction releases them after commit or abort (many extensions allow violations of atomicity and leave the responsibility of tracking the smuggled non~ ommitted information with programmers; some go further and provide support for tracking all dependent transactions which have to be aborted should the transaction from which the non-committed data have been prematurely released be aborted)\u2022 ACID transactions often do not provide suitable recovery techniques (apart~ om the transaction abort) as they are intended only for tolerating hardware faults (node crashes mainly). This is, for example, one of the reasons for\u00a0\u2026", "num_citations": "13\n", "authors": ["523"]}
{"title": "On programming atomic actions in Ada 95\n", "abstract": " This paper describes the development of two kinds of atomic action schemes for Ada 95. We start by discussing the basic features required of an atomic action scheme and what choices, e.g. between synchronous and asynchronous actions, are appropriate for Ada 95. We then present two implementations of actions; first using Ada 95 packages to create asynchronous actions and secondly, as sets of tasks for synchronous actions. For each action type, we present code fragments illustrating their development and use. Finally, we discuss some related issues (exception resolution, action nesting, state restoration, software re-use and extension, preventing information smuggling, distributed execution) which have been addressed in our work and show some of the problems encountered (the deserter problem, using different sorts of interparticipant communications and resources).", "num_citations": "13\n", "authors": ["523"]}
{"title": "Formal derivation of a distributed program in Event B\n", "abstract": " Achieving high dependability of distributed systems remains a major challenge due to complexity arising from concurrency and communication. There are a number of formal approaches to verification of properties of distributed algorithms. However, there is still a lack of methods that enable a transition from a verified formal model of communication to a program that faithfully implements it. In this paper we aim at bridging this gap by proposing a state-based formal approach to correct-by-construction development of distributed programs. In our approach we take a systems view, i.e., formally model not only application but also its environment \u2013 the middleware that supports it. We decompose such an integrated specification to obtain the distributed program that should be deployed on the targeted network infrastructure. To illustrate our approach, we present a development of a distributed leader election protocol.", "num_citations": "12\n", "authors": ["523"]}
{"title": "Improving reliability of cooperative concurrent systems with exception flow analysis\n", "abstract": " Developers of fault-tolerant distributed systems need to guarantee that fault tolerance mechanisms they build are in themselves reliable. Otherwise, these mechanisms might in the end negatively affect overall system dependability, thus defeating the purpose of introducing fault tolerance into the system. To achieve the desired levels of reliability, mechanisms for detecting and handling errors should be developed rigorously or formally. We present an approach to modeling and verifying fault-tolerant distributed systems that use exception handling as the main fault tolerance mechanism. In the proposed approach, a formal model is employed to specify the structure of a system in terms of cooperating participants that handle exceptions in a coordinated manner, and coordinated atomic actions serve as representatives of mechanisms for exception handling in concurrent systems. We validate the approach through two\u00a0\u2026", "num_citations": "12\n", "authors": ["523"]}
{"title": "Exception handling in context-aware agent systems: A case study\n", "abstract": " Handling erroneous conditions in context-aware mobile agent systems is challenging due to their intrinsic characteristics: openness, lack of structuring, mobility, asynchrony and increased unpredictability. Even though several context-aware middleware systems now support the development of mobile agent-based applications, they rarely provide explicit and adequate features for context-aware exception handling. This paper reports our experience in implementing error handling strategies in some prototype context-aware collaborative applications built with the MoCA (Mobile Collaboration Architecture) system. MoCA is a publish-subscribe middleware supporting the development of collaborative mobile applications by providing explicit services that empower software agents with context-awareness. We propose a novel context-aware exception handling mechanism and discuss some lessons learned\u00a0\u2026", "num_citations": "12\n", "authors": ["523"]}
{"title": "Mobility as an aspect: The AspectM framework\n", "abstract": " Software engineers of multi-agent systems (MASs) are faced with the design and implementation of the mobility concern in addition to the agents\u2019 basic functionalities and other agent-related concerns. As the agents\u2019 complexity increases, the mobility concern cannot be modularized based only on object-oriented abstractions. The mobility concern tends to spread across several system classes and methods, which in turn leads to the production of MASs that are difficult to maintain and reuse. MAS developers, however, have mostly relied on object-oriented frameworks and on object-oriented programming languages, such as Java. This paper presents an aspect-oriented framework, called the AspectM framework, that supports improved modularization of the mobility concern and a flexible integration with multiple mobility platforms. The use of our framework minimizes code replication, and increases the reusability and maintainability of the mobility concern and other agent concerns.", "num_citations": "12\n", "authors": ["523"]}
{"title": "Dependability-explicit computing in service-oriented architectures\n", "abstract": " We explore a notion of dependability-explicit computing in which dependability-related metadata is published and exploited at run-time. In serviceoriented architectures, on-line reasoning about dependability characteristics can aid service lookup, and achieve dynamic reconfiguration for fault tolerance and entails the development of on-line reasoning services to permit the matching of dependability requirements. We identify challenging areas of future work to realize these potential benefits.", "num_citations": "12\n", "authors": ["523"]}
{"title": "Auction system design using open multithreaded transactions\n", "abstract": " Open Multithreaded Transactions form an advanced transaction model that provides features for controlling and structuring not only accesses to objects, as usual in transaction systems, but also threads taking part in transactions. The model allows several threads to enter the same transaction in order to perform a joint activity. It provides a flexible way of manipulating threads executing inside a transaction by allowing them to be forked and terminated, but it restricts their behavior in order to guarantee correctness of transaction nesting and isolation among transactions. In addition, transactions are exception handling contexts, and the model therefore provides forward and backward error recovery. In this paper we show that the model is indeed powerful, and that a complex application, i.e. an online auction system, can be designed and implemented in a very elegant way.", "num_citations": "12\n", "authors": ["523"]}
{"title": "Supporting evolution of interface exceptions\n", "abstract": " Interface exceptions (explicitly declared exceptions that a method can propagate outside) are an inherent part of the interface describing the behaviour of a particular class of objects. Evolution of system behaviour is thus necessarily accompanied by and reflected in the evolution of interface exceptions. While the evolution of normal system behaviour is adequately supported by various language mechanisms, such as subtyping and inheritance, few contemporary object-oriented program- ming languages offer support for the evolution of interface exceptions. Some languages allow interface exceptions to be specialised and deleted while subtyping, but none of them provides adequate support for adding exceptions. In this paper we propose two complementary solutions to dealing with additional exceptions introduced during system evolution. To solve the problem of non-conforming interfaces resulting from\u00a0\u2026", "num_citations": "12\n", "authors": ["523"]}
{"title": "Faulty version recovery in object-oriented N-version programming\n", "abstract": " Many long-running applications would greatly benefit from being able to recover faulty versions in N-version programs since their exclusion from further use undermines the availability of the system. Developing a recovery feature, however, is a very complex and error-prone task, which the author believes has not received adequate attention. Although many researchers are aware of the importance of version recovery, there are very few schemes which include these features. Even when they do, they rely on ad hoc programming and are not suitable for object-oriented systems. The author believes that developing systematic approaches here is crucial, and formulates a general approach to version recovery in class diversity schemes, which is based on the concept of the abstract version state. The approach extends the recently-developed class diversity scheme and relies on important ideas motivated by community\u00a0\u2026", "num_citations": "12\n", "authors": ["523"]}
{"title": "Guaranteed deadlock recovery: Deadlock resolution with rollback propagation\n", "abstract": " Traditionally, deadlock resolution is performed by simply aborting any process or the lowest-priority process (called the victim) involved in a deadlock cycle. In message-passing applications where rollback propagation due to message dependencies is possible, the rollback of the victim may require other processes to roll back as well, and the restarted processes may get into the same deadlock again. We introduce the concept of guaranteed deadlock recovery which guarantees that a broken deadlock cycle will not be re-formed after the rollback, and show how to achieve this by carefully selecting the victim based on run-time dependency information. We also demonstrate a technique to incorporate a dynamic priority scheme into a distributed deadlock detection algorithm to perform guaranteed deadlock recovery.", "num_citations": "12\n", "authors": ["523"]}
{"title": "On distribution of coordinated atomic actions\n", "abstract": " The concept of coordinated atomic (CA) actions was introduced about two years ago. Since then this research has addressed many new problems and, in particular, problems of CA action distribution and implementation. Recently we have gained some experience in implementing different schemes in Ada 95 and Java. Our intention within this paper is to discuss how distributed CA action schemes can be realised. In particular, we outline different ways of action component distribution, trade-offs, applications for which these schemes are applicable. We discuss a wide range of schemes (some of them have not yet been implemented) based on a classification of various approaches to CA action distribution; to do this we analyse all possible ways of different action component distribution. We believe that this general discussion should help to better understand the current state of CA action implementation and is\u00a0\u2026", "num_citations": "12\n", "authors": ["523"]}
{"title": "Backward error recovery via conversations in Ada\n", "abstract": " An approach is proposed for using backward error recovery in Ada. The advantages and disadvantages of Ada are not discussed, nor are new run-time algorithms for Ada proposed, but a practical method is offered for using backward recovery and software diversity within this language. The authors believe that Ada has sufficient facilities to allow the use of software diversity to develop fault-tolerant systems. However, previous researchers have noticed problems in attempting to use this possibility, and restrictive rules are necessary to avoid these problems. 'Conversations' for co-ordinated backward recovery of concurrent processes are considered and the following proposals are made: a restricted scheme similar to Kim's (1982) 'concurrent recovery block', but providing for deadlines on the execution of the diverse modules; programming rules for applying this scheme to Ada procedures; and a way for automatically\u00a0\u2026", "num_citations": "12\n", "authors": ["523"]}
{"title": "Experience report: Study of vulnerabilities of enterprise operating systems\n", "abstract": " This experience report analyses security problems of modern computer systems caused by vulnerabilities in their operating systems. An aggregated vulnerability database has been developed by joining vulnerability records from two publicly available vulnerability databases: the Common Vulnerabilities and Exposures system (CVE) and the National Vulnerabilities database (NVD). The aggregated data allow us to investigate the stages of the vulnerability life cycle, vulnerability disclosure and the elimination statistics for different operating systems. The specific technical areas the paper covers are the quantitative assessment of vulnerabilities discovered and fixed in operating systems, the estimation of time that vendors spend on patch issuing, and the analysis of the vulnerability criticality and identification of vulnerabilities common for different operating systems.", "num_citations": "11\n", "authors": ["523"]}
{"title": "Towards cloud-based enactment of safety-related processes\n", "abstract": " Engineering safety-critical systems is a complex task which involves multiple stakeholders. It requires shared and scalable computation to systematically involve geographically distributed teams. The paper proposes a model-driven cloud-based enactment architecture automating safety-critical processes. This work adapts our previous work on cloud-based software engineering by enriching the architecture with an automatic support for generation of both, product-based safety arguments from failure logic analysis results and process-based arguments from the process model and the enactment data. The approach is demonstrated using a fragment of a process adapted from the aerospace domain.", "num_citations": "11\n", "authors": ["523"]}
{"title": "Time-outing internet services\n", "abstract": " Uncertainty and response time instability can affect invoked Web services' usability, performance, trustworthiness, and dependability. To resolve uncertainty, researchers have applied a three-pronged approach. First, they remove uncertainty through advances in data collection, response time measurement, and benchmarking. Second, they employ a mathematical foundation for modeling uncertainty. Finally, they improve fault-tolerance techniques by making well-considered choices of time-outs and trade-offs between cost, availability, trustworthiness, and performance.", "num_citations": "11\n", "authors": ["523"]}
{"title": "How to enhance UDDI with dependability capabilities\n", "abstract": " How dependability is to be assessed and ensured during Web service operation and how unbiased and trusted mechanisms supporting this are to be developed are still open issues. This paper addresses the following questions: who should publish dependability parameters, in which way they should be distributed, and who (and how) should monitor these parameters in the global service-oriented architecture. We discuss several techniques of on-line dependability monitoring and measurement, which extend the UDDI (Universal Description, Discovery and Integration) business registry with dependability metadata publishing and monitoring capabilities. The paper also proposes UDDI add-ons and light-weight user-side mechanisms for public operational and exceptional reporting.", "num_citations": "11\n", "authors": ["523"]}
{"title": "Error Recovery for a Boiler System with OTS PID Controller\n", "abstract": " We have previously presented initial results of a case study which illustrated an approach to engineering protective wrappers as a means of detecting errors or unwanted behaviour in systems employing an OTS (off-the-shelf) item. The case study used a Simulink model of a steam boiler system together with an OTS PID (proportional, integral and derivative) controller. The protective wrappers are developed for the model of the system in such a way that they allow detection and tolerance of typical errors caused by unavailability of signals, violations of range limitations, and oscillations. In this paper, we extend the case study to demonstrate how forward error recovery based on exception handling can be systematically incorporated at the level of the protective wrappers.", "num_citations": "11\n", "authors": ["523"]}
{"title": "Looking ahead in atomic actions with exception handling\n", "abstract": " An approach to introducing exception handling into object-oriented N is presented. A novel atomic action scheme is developed that does not impose any participant synchronisation on action exit. In order to use cooperative exception handling at the action level as the main fault tolerance mechanism, we develop a distributed protocol that finds, for any exception raised, an action containing all potentially erroneous information, aborts all of its nested actions, resolves multiple concurrent exceptions and involves all the action participants into cooperative handling of the resolved exception. In the scheme, no service messages are sent and no service synchronisation is introduced if there are no exceptions raised. This flexible scheme can be applied in a number of emerging areas in which entities of a different nature (including software tasks, people, plants, documents, organisations, etc.) participate in cooperative\u00a0\u2026", "num_citations": "11\n", "authors": ["523"]}
{"title": "Aspects of Exceptions at the Meta-level\n", "abstract": " In this paper we describe our motivation for explicitly considering exceptions at the meta-level and outline an extension of the Kava [4] metaobject protocol that brings exception raising under the control of the meta-level.", "num_citations": "11\n", "authors": ["523"]}
{"title": "Class diversity support in object-oriented languages\n", "abstract": " We start with a general approach to introducing software fault tolerance (SFT) into object-oriented (OO) systems [Xu, J., Randell, B., Rubira, C.M.F., Stroud, R.J., 1995. Toward an object-oriented approach to software fault-tolerance. In: Avreski, D. (Ed.) Fault-Tolerant Parallel and Distributed Systems. DEEE CS Press, Silver Spring, MD.] and proceed in two directions. The first one is the use of SFT schemes within standard OO languages. New questions which arise when we are dealing with these languages are addressed. Our intention is to thoroughly analyse all engineering steps which allow diversity to be introduced in systems programmed in these languages. Some new general problems are spotted and discussed as well. The second direction is dealing with version concurrency and distributedness in a general way. We investigate providing SFT by class diversity, which is the most general way of designing\u00a0\u2026", "num_citations": "11\n", "authors": ["523"]}
{"title": "On structuring cooperative and competitive concurrent systems\n", "abstract": " Developing advanced structuring techniques has always been of great importance for computer science and practice. Many structuring approaches are used to help capture certain characteristics of applications: group communications, replication features, file services, etc. Associating fault tolerance measures with structuring units allows us to benefit from state and behaviour encapsulation while designing dependable systems. Procedures were among the first general techniques intended for structuring application software. They reflect both the static and dynamic structures of sequential systems (a stack of procedure contexts of nested calls represents the state of program execution). The situation is much more complex in concurrent systems, in which the states of several concurrent components should be taken into consideration while describing system behaviour in general, and its fault tolerance in particular\u00a0\u2026", "num_citations": "11\n", "authors": ["523"]}
{"title": "Fault tolerant internet computing: Benchmarking and modelling trade-offs between availability, latency and consistency\n", "abstract": " The paper discusses our practical experience and theoretical results of investigating the impact of consistency on latency in distributed fault tolerant systems built over the Internet and clouds. We introduce a time-probabilistic failure model of distributed systems that employ the service-oriented paradigm for defining cooperation with clients over the Internet and clouds. The trade-offs between consistency, availability and latency are examined, as well as the role of the application timeout as the main determinant in the interplay between system availability and responsiveness. The model introduced heavily relies on collecting and analysing a large amount of data representing the probabilistic behaviour of such systems. The paper presents experimental results of measuring the response time in a distributed service-oriented system whose replicas are deployed at different Amazon EC2 location domains. These results\u00a0\u2026", "num_citations": "10\n", "authors": ["523"]}
{"title": "Speedup and power scaling models for heterogeneous many-core systems\n", "abstract": " Traditional speedup models, such as Amdahl's law, Gustafson's, and Sun and Ni's, have helped the research community and industry better understand system performance capabilities and application parallelizability. As they mostly target homogeneous hardware platforms or limited forms of processor heterogeneity, these models do not cover newly emerging multi-core heterogeneous architectures. This paper reports on novel speedup and energy consumption models based on a more general representation of heterogeneity, referred to as the normal form heterogeneity, that supports a wide range of heterogeneous many-core architectures. The modelling method aims to predict system power efficiency and performance ranges, and facilitates research and development at the hardware and system software levels. The models were validated through extensive experimentation on the off-the-shelf big. LITTLE\u00a0\u2026", "num_citations": "10\n", "authors": ["523"]}
{"title": "Exe-spem: Towards cloud-based executable software process models\n", "abstract": " Executing software processes in the cloud can bring several benefits to software development. In this paper, we discuss the benefits and considerations of cloud-based software processes. EXE-SPEM is our extension of the Software and Systems Process Engineering (SPEM2.0) Meta-model to support creating cloud-based executable software process models. Since SPEM2.0 is a visual modelling language, we introduce an XML notation meta-model and mapping rules from EXE-SPEM to this notation which can be executed in a workflow engine. We demonstrate our approach by modelling an example software process using EXE-SPEM and mapping it to the XML notation.", "num_citations": "10\n", "authors": ["523"]}
{"title": "Cost effective, reliable, and secure workflow deployment over federated clouds\n", "abstract": " The federation of clouds can provide benefits for cloud-based applications. Different clouds have different advantages - one might be more reliable whilst another might be more secure or less expensive. However, being able to select the best combination of clouds to meet the application requirements is not trivial. This paper presents a novel algorithm to deploy workflow applications on federated clouds. Firstly, we introduce an entropy-based method to quantify the most reliable workflow deployments. Secondly, we apply an extension of the Bell-LaPadula Multi-Level security model to meet application security requirements. Finally, we optimise deployment in terms of its entropy and also its monetary cost, taking into account the price of computing power, data storage and inter-cloud communication. To evaluate the new algorithm we compared it against two existing scheduling algorithms: Dynamic Constraint\u00a0\u2026", "num_citations": "10\n", "authors": ["523"]}
{"title": "Coordinated Atomic Actions for dependable distributed systems: the current state in concepts, semantics and verification means\n", "abstract": " Coordinated Atomic Actions (CAAs) have been introduced about ten years ago as a conceptual framework for developing fault-tolerant concurrent systems. All the work done since then extended the CAA framework with the capabilities to model, verify, and implement concurrent distributed systems following pre-defined development methodologies. As a result, CAAs, compared to other approaches available, offer a rich set of means for engineering dependable systems. Nevertheless, it is sometimes difficult to have a global and analytical view of all the features available as this concept provides a number of features which need to be applied in combination. The main contribution of this paper is in presenting a complete state-of-the-art overview of the work done around CAAs from the three perspectives: the definitions of the fundamental concepts, their various semantics and the means supporting formal verification\u00a0\u2026", "num_citations": "10\n", "authors": ["523"]}
{"title": "Verification of coordinated exception handling\n", "abstract": " An important challenge faced by the developers of fault-tolerant distributed systems is to build fault tolerance mechanisms that are reliable. To achieve the desired levels of reliability, the development of mechanisms for detecting and handling errors should be rigorous or formal. In this paper, we present an approach to modeling and verifying fault-tolerant distributed systems that use exception handling as the main fault tolerance mechanism. The proposed approach is based on a formal model for specifying the structure of a system in terms of cooperating participants that handle exceptions in a coordinated manner. We use a medical control system as a case study to validate the proposed approach.", "num_citations": "10\n", "authors": ["523"]}
{"title": "Towards formal development of mobile location-based systems\n", "abstract": " Mobile agents have many attractive features to offer and they are often mentioned as a future mainstream industry-level software technology. The agent technology naturally solves the problem of decoupling complex software into smaller parts that are easier to design, code and maintain. It helps to use distributed computing power effectively while hiding many of the details and complexities of a hosting environment. Recent advances in mobile computing and wireless networks lead to introduction of host (physical) mobility that offers totally new opportunities and as well raises new problems. Though substantial research has been conducted on developing middleware solutions supporting mobile agents, the mobile agent technology is still not mature enough to become a practice in industrial software development. There are several areas in which no general solutions have been found yet. One of them is ensuring interoperability of independently designed agents and correctness of the overall mobile system. In this work we will present a background for building a formal development methodology that addresses this problem.Agent software is designed to interact with other agents during its lifetime. Most research in the area discusses only centralized development process, when all the participating pieces of software (code of the agents) are created at the same site to solve common problems. In this case agents are mostly useful as a replacement of conventional client-server scheme with migrating clients or/and servers. However the application area of the mobile agents is much broader and, to make full use of their communication and migration\u00a0\u2026", "num_citations": "10\n", "authors": ["523"]}
{"title": "On persistent and reliable streaming in ada\n", "abstract": " Saving internal program data for further use is one of the most useful ideas in programming. Developing general features to provide such data saving/restoring is a very active research area. There are two application areas for such features we believe to be crucial: system fault tolerance and data persistence. Our analysis shows that the features used in these areas have a lot in common: they are to flatten data of different types and save them in a store which can be used later on. The recent revision of the Ada language standard, Ada 95, introduces a new mechanism called streams that allows structured data to be flattened. Streams are sequences of elements comprising values from possibly different types. Ada 95 allows programmers to develop their streams following the standard abstract class interface. In this paper we show how to use the stream concept for developing new features to provide internal\u00a0\u2026", "num_citations": "10\n", "authors": ["523"]}
{"title": "Towards modelling and verification of concurrent ada programs using petri nets\n", "abstract": " Ada 95 is an expressive concurrent programming language with which it is possible to build complex multi-tasking applications. Much of the complexity of these applications stems from the interactions between the tasks. This paper argues that Petri nets offer a promising, tool-supported, technique for checking the logical correctness of the tasking algorithms. The paper illustrates the effectiveness of this approach by showing the correctness of an Ada implementation of the atomic action protocol using a variety of Petri net tools, including PED, PEP and INA for P/T nets and Design/CPN for Coloured Petri nets.", "num_citations": "10\n", "authors": ["523"]}
{"title": "Formal verification of signalling programs with SafeCap\n", "abstract": " SafeCap is a modern toolkit for modelling, simulation and formal verification of railway networks. This paper discusses the use of SafeCap for formal analysis and fully-automated scalable safety verification of solid state interlocking (SSI) programs \u2013 a technology at the heart of many railway signalling solutions. The focus of the work is on making it easy for signalling engineers to use the developed technology and thus to help with its smooth industrial deployment. In this paper we explain the formal foundations of the proposed method, its tool support, and their application to real life railway verification problems.", "num_citations": "9\n", "authors": ["523"]}
{"title": "Rodin platform why3 plug-in\n", "abstract": " We briefly present the motivation, architecture and usage experience as well as proof statistics for a new Rodin Platform proof back-end based on the Why3 umbrella prover. Why3 offers a simple and versatile notation as a common interface to a large number of automated provers including all the leading SMT-LIB and TPTP compliant tools. The plug-in can function either in a local mode when all the provers are installed locally, or remotely as a cloud service. We discuss the experience of building the tool, the current status and the potential advantages of a cloud-hosted proof infrastructure.", "num_citations": "9\n", "authors": ["523"]}
{"title": "Order graphs and cross-layer parametric significance-driven modelling\n", "abstract": " Traditional hierarchical modelling methods tend to have layers of abstraction corresponding to naturally existing layers of concern in multi-level systems. Although logically and functionally intuitive, this is not always optimal for analysis and design. For instance, parts of a system in the same logical layer may not contribute to the same degree on some metric, e.g. system power consumption. When focusing on a specific parameter or set of parameters, to moderate the analysis, design and runtime effort, less significant parts of the system should be modelled at higher levels of abstraction and more significant ones with more detail. This parametric significance-driven modelling approach focuses more on optimal parametric fidelity than on logical intuition. Using system power consumption as an example parameter, this paper presents Order Graphs (OGs), which have a clear hierarchical structure, and provide\u00a0\u2026", "num_citations": "9\n", "authors": ["523"]}
{"title": "Rigorous development of dependable systems using fault tolerance views\n", "abstract": " This paper introduces the Mode and Fault Tolerance Views approach to stepwise rigorous development of critical systems. It supports systematic, structured and recursive modelling of system fault tolerance, including error detection, error recovery and degraded modes. Built on our previous work extending the Event-B method with reasoning about fault tolerance, the paper focuses on a practical application and evaluation of the approach. The proposed modelling approach is backed by an integrated toolset. The paper is illustrated with a case study from the aerospace domain.", "num_citations": "9\n", "authors": ["523"]}
{"title": "Combining tasking and transactions, part II: open multithreaded transactions\n", "abstract": " This position paper is a follow-up paper of [1], presented at the last IRTAW workshop. The paper describes a model for providing transaction support for concurrent programming languages such as Ada 95. In order to achieve smooth integration, the use of the concurrency features provided by the Ada language should not be restricted inside a transaction. A transaction model that meets this requirement is presented. Tasks inside such a transaction may spawn new tasks, but also external tasks are allowed to join an ongoing transaction. A blocking commit protocol ensures that no task leaves the transaction before its outcome has been determined. Exceptions are used to inform all participants in case a transaction aborts. Possible interfaces for the Ada programmer are discussed.", "num_citations": "9\n", "authors": ["523"]}
{"title": "Abstract object state and version recovery in N-version programming\n", "abstract": " The paper deals with the use of software diversity, specifically, N-version programming (NVP) in object oriented (OO) systems. We formulate the problem of faulty version recovery and show how our NVP scheme, developed recently, can be extended to solve it. Our approach relies on using the abstract version state, which represents a common general description of the states of all correct version objects. The recovery consists in mapping the state of a correct version onto the state of the faulty version via the abstract state. We introduce a formal description of our model and show that many ideas related to object state abstraction can be found in the existing research on OO programming. We discuss extensions of LAYOM and PSL as promising practical approaches for developing recovery features in OO programming. As an alternative solution, we propose a meta-object architecture and a related protocol which\u00a0\u2026", "num_citations": "9\n", "authors": ["523"]}
{"title": "Voltage, throughput, power, reliability, and multicore scaling\n", "abstract": " This article studies the interplay between the performance, energy, and reliability (PER) of parallel-computing systems. It describes methods supporting the meaningful cross-platform analysis of this interplay. These methods lead to the PER software tool, which helps designers analyze, compare, and explore these properties. The web extra at https://youtu.be/aijVMM3Klfc illustrates the PER (performance, energy, and reliability) tool, expanding on the main engineering principles described in the article.", "num_citations": "8\n", "authors": ["523"]}
{"title": "Rigorous development of fault-tolerant systems through co-refinement\n", "abstract": " With our increasing dependency on computer-based systems, ensuring their dependability becomes one the most important concerns during system development. This is especially true for safety-critical systems. Critical systems typically use fault tolerance mechanisms to mitigate runtime errors. However, fault tolerance modelling and, in particular, rigorous definitions of fault tolerance requirements, fault assumptions and system recovery have not been given enough attention during formal system development. This paper proposes a development method for stepwise modelling of high-level system fault tolerant behaviour. The method provides an environment for explicit modelling of fault tolerance and modal aspects of system behaviour and is supported by tools that are smoothly integrated into an industry-strength development environment. A case study is used to demonstrate the proposed method.", "num_citations": "8\n", "authors": ["523"]}
{"title": "Benchmarking dependability of a system biology application\n", "abstract": " In this paper we report our practical experience in benchmarking a System Biology Web Service, and investigate instability of its performance and the delays induced by the communication medium. We discuss the results of a statistical data analysis and discuss the causes affecting the Web Service performance. The uncertainty discovered in Web Services operations reduces the overall dependability of Service-Oriented Architecture and require specific resilience techniques.", "num_citations": "8\n", "authors": ["523"]}
{"title": "On specification and verification of location-based fault tolerant mobile systems\n", "abstract": " In this paper, we investigate context aware location-based mobile systems. In particular, we are interested how their behaviour, including fault tolerant aspects, could be captured using a formal semantics, which would then be suitable for analysis and verification. We propose a new formalism and middleware, called Cama, which provides a rich environment to test our approach. The approach itself aims at giving Cama a formal concurrency semantics in terms of a suitable process algebra, and then applying efficient model checking techniques to the resulting process expressions in a way which alleviates the state space explosion. The model checking technique adopted in our work is partial order model checking based on Petri net unfoldings, and we use a semantics preserving translation from the process terms used in the modelling of Cama to a suitable class of high-level Petri nets.", "num_citations": "8\n", "authors": ["523"]}
{"title": "Using co-ordinated atomic actions for building complex web applications: A learning experience\n", "abstract": " This paper discusses some of the typical characteristics of modern Web applications and analyses some of the problems the developers of such systems have to face. One of such types of applications is integrated Web application, i.e. application that integrates several independent Web services. The paper focuses on providing software fault tolerance for such systems. The solution we put forward employs the concept of co-ordinated atomic (CA) actions for structuring such applications and for providing fault tolerance using exception handling. The paper discusses important design and implementation decisions we have made while developing a travel agency (TA) case study and attempts to generalize them to allow CA actions to be easily applied for building dependable Web applications.", "num_citations": "8\n", "authors": ["523"]}
{"title": "A study of atomic action schemes intended for standard Ada\n", "abstract": " Although the number of proposals discussing various atomic action schemes is increasing, these schemes are very rarely used in designing practical applications. To a large extent, this is accounted for by the gap existing between the languages used in research and the standard or widely spread languages (e.g. C, C++, Ada 83, Ada 95, Java) employed by practitioners. Moreover, very often researchers extend languages with new features or invent new languages to express their ideas better. Even though these approaches seem to be quite natural, they widen the gap between practice and research. To bridge this gap, we should consider fault tolerance schemes in terms of a standard language, taking the language itself for granted. The question which we believe should be addressed is how to use/implement a particular scheme in these languages rather than how to modify the language. Only in this way the\u00a0\u2026", "num_citations": "8\n", "authors": ["523"]}
{"title": "Conversations of objects\n", "abstract": " An increasing range of application systems implemented in concurrent object oriented languages (COOLs) creates a pressing demand for developing approaches which provide a systematic way of tolerating software and hardware faults by using software diversity. This paper deals with the problem of tolerating faults in concurrent systems of this type. The purposes of this paper are as follows: to discuss the most appropriate ways of implementing conversations in COOLs; to map all attributes of conversations onto these languages; to discuss the most relevant peculiarities of COOLs in these terms; to suggest approaches to using the conversation scheme; to find the ways in which characteristics of COOLs can facilitate the use of conversation schemes. Thus we try to show how conversations can be used in existing COOLs in a more practical and realistic manner.", "num_citations": "8\n", "authors": ["523"]}
{"title": "Using osmotic services composition for dynamic load balancing of smart city applications\n", "abstract": " Edge computing takes computation away from the Cloud closer to the physical world. Therefore, it reduces the cost of communication bandwidth between IoT devices and the Cloud. However, Edge computing imposes certain limitations in computation power because due to poor hardware capacity of the devices. This restriction may significantly affect the performance of the deployed applications, especially Smart City applications. This limitations also could be aggravated by unpredictable human behaviors wich will easily make the Edge computation node overloaded. Osmotic computing is a new IoT application programming paradigm that provides an opportunity to balance the workload between Edge and Cloud therefore to overcome the load imbalance problem of Smart City applications. To this end, we propose an Osmotic Execution Framework that leverages state-of-the-art microservices techniques to deploy\u00a0\u2026", "num_citations": "7\n", "authors": ["523"]}
{"title": "Practical formal methods in railways-the safecap approach\n", "abstract": " This paper presents the SafeCap Platform approach to the verification of railway safety properties. We discuss how the hierarchy of formal theories is used to capture the railway domain and interface with verification tools; we explain the contribution of each individual theory to the overall task of safety verification and capacity assessment. Finally, we briefly relate our experience of using two independent verification chains to validate concrete track layouts and control tables against the SafeCap safety theories.", "num_citations": "7\n", "authors": ["523"]}
{"title": "Towards cloud-based software process modelling and enactment\n", "abstract": " Model Driven Engineering (MDE) considers models as a key artifact in software processes, and focus on the creation of models and transformations between them in order to (semi) automatically generate code. In this paper, we step back and consider the software process model itself as a key artifact that can be enacted and semi automated. We support our vision by proposing an architecture for a cloud-based software processes modelling and enactment environment which integrates software development tools and maintains repositories of modelling artifacts and the history of development.", "num_citations": "7\n", "authors": ["523"]}
{"title": "Measuring and Dealing with the Uncertainty of SOA Solutions\n", "abstract": " The chapter investigates the uncertainty of Web Services performance and the instability of their communication medium (the Internet), and shows the influence of these two factors on the overall dependability of SOA. We present our practical experience in benchmarking and measuring the behaviour of a number of existing Web Services used in e-science and bio-informatics, provide the results of statistical data analysis and discuss the probability distribution of delays contributing to the Web Services response time. The ratio between delay standard deviation and its average value is introduced to measure the performance uncertainty of a Web Service. Finally, we present the results of error and fault injection into Web Services. We summarise our experiments with SOA-specific exception handling features provided by two web service development kits and analyse exception propagation and performance as the\u00a0\u2026", "num_citations": "7\n", "authors": ["523"]}
{"title": "Fault tolerant middleware for agent systems: a refinement approach\n", "abstract": " Agent technology offers a number of advantages over traditional distributed systems, such as asynchronous communication, anonymity of individual agents and ability to change operational context. However, it is notoriously difficult to ensure dependability of agent systems. In this paper we present a formal approach for the top-down development of fault tolerant middleware for agent systems. We demonstrate how to develop the middleware that besides providing agent coordination is also able to cope with their failures. We focus on handling agent crushes and transient faults caused by volatile communication environment. We argue that formal development of middleware with integrated fault tolerance mechanisms has potential to enhance dependability of an agent system.", "num_citations": "7\n", "authors": ["523"]}
{"title": "SAL, Kodkod, and BDDs for Validation of B Models. Lessons and Outlook.\n", "abstract": " PROB is a model checker for high-level B and Event-B models based on constraint-solving. In this paper we investigate alternate approaches for validating high-level B models using alternative techniques and tools based on using BDDs, SAT-solving and SMT-solving. In particular, we examine whether PROB can be complemented or even supplanted by using one of the tools BDDBDDB, Kodkod or SAL.", "num_citations": "7\n", "authors": ["523"]}
{"title": "Formal approach to ensuring interoperability of mobile agents\n", "abstract": " Mobile agent systems are complex distributed systems that are dynamically composed from autonomous agents. It is difficult to guarantee agent interoperability since they are often developed independently. We propose a formal approach to ensuring agent interoperabiilty which relies on decomposition of a specification of the multiagent application into a set of specifications of the agent roles. We use refinement in the Event-B framework to formally define the process of decomposition.", "num_citations": "7\n", "authors": ["523"]}
{"title": "Rigorous open development environment for complex systems-RODIN\n", "abstract": " RODIN is a strategic targeted research project which falls squarely within the remit of the strategic objective \u2018Open Development Platforms for Software and Services\u2019 of the IST FP6 second call. RODIN focuses on tackling complexity caused by the environment in which the software is to operate and which comes from poorly conceived architectural structure.Mastering complexity requires design techniques that support clear thinking and rigorous validation and verification. Formal design methods do so. Coping with complexity also requires architectures that are tolerant of faults and unpredictable changes in environment. This is addressed by fault tolerance design techniques.", "num_citations": "7\n", "authors": ["523"]}
{"title": "CORRECT Developing Fault-Tolerant Distributed Systems\n", "abstract": " CORRECT Developing Fault-Tolerant Distributed Systems - Capozucca Alfredo Open Repository and Bibliography Login Home Help? EN FR University of Luxembourg Library You are here: ORBi lu Detailled reference Reference : CORRECT Developing Fault-Tolerant Distributed Systems Document type : Scientific journals : Article Discipline(s) : Engineering, computing & technology : Computer science To cite this reference: http://hdl.handle.net/10993/9883 Title : CORRECT Developing Fault-Tolerant Distributed Systems Language : English Author, co-author : Capozucca, Alfredo mailto [University of Luxembourg > Faculty of Science, Technology and Communication (FSTC) > Computer Science and Communications Research Unit (CSC) >] Gallina, Barbara [University of Luxembourg > Faculty of Science, Technology and Communication (FSTC) > Computer Science and Communications Research Unit (CSC) >] \u2026", "num_citations": "7\n", "authors": ["523"]}
{"title": "Wrapping the future\n", "abstract": " Enclosing a component within a software \u201cwrapper\u201d is a well-established way of adapting components for use in new environments. This paper presents an overview of an experimental evaluation of the use of a wrapper to protect against faults arising during the (simulated) operation of a practical and critical system; the specific context is a protective wrapper for an off-the-shelf software component at the heart of the control system of a steam raising boiler. Encouraged by the positive outcomes of this experimentation we seek to position protective wrappers as a basis for structuring the provision of fault tolerance in component-based open systems and networks. The paper addresses some key issues and developments relating wrappers to the provision of dependability in future computing systems.", "num_citations": "7\n", "authors": ["523"]}
{"title": "Asynchronous object calculus: confluence and determinacy\n", "abstract": " L'objectif de cette th\u00e8se est de concevoir un calcul d'objets permettant d'\u00e9crire des applications parall\u00e8les et distribu\u00e9es, en particulier dans un cadre \u00e0 grande \u00e9chelle, tout en assurant de bonnes propri\u00e9t\u00e9s. Le calcul propos\u00e9 s' intitule ASP: Asynchronous Sequential Processes. Les principales caract\u00e9ristiques de ce calcul sont: des communications asynchrones, la pr\u00e9sence de futurs et une ex\u00e9cution s\u00e9quentielle dans chacun des processus. Ce calcul exhibe de fortes propri\u00e9t\u00e9s de confluence et de d\u00e9terminisme. Cette th\u00e8se a donc aussi pour objectif de prouver de telles propri\u00e9t\u00e9s dans un cadre aussi g\u00e9n\u00e9ral que possible. ASP est bas\u00e9 sur une r\u00e9partition des objets en diff\u00e9rentes activit\u00e9s disjointes. Une activit\u00e9 est un ensemble d'objets g\u00e9r\u00e9s par un unique processus. Les objets actifs sont des objets accessibles par des r\u00e9f\u00e9rences globales/distantes. Ils communiquent \u00e0 travers des appels de m\u00e9thodes asynchrones avec un m\u00e9canisme de futurs. Un futur est une r\u00e9f\u00e9rence globale d\u00e9signant un r\u00e9sultat qui n'est pas encore calcul\u00e9. Cette th\u00e8se mod\u00e9lise ces diff\u00e9rents aspects, leurs principales propri\u00e9t\u00e9s et les cons\u00e9quences de ces m\u00e9canismes sur la notion de comportement d\u00e9terministe des programmes. Le r\u00e9sultat principal consiste en une propri\u00e9t\u00e9 de confluence et son application \u00e0 l'identification d'un ensemble de programmes se comportant de fa\u00e7on d\u00e9terministe. Du point de vue pratique, ASP peut aussi \u00eatre consid\u00e9r\u00e9 comme une mod\u00e9lisation de la librairie ProActive. Cette librairie fournit des outils pour d\u00e9velopper des applications parall\u00e8les et distribu\u00e9es en Java.R\u00e9sum\u00e9The objective of this thesis is to design an object calculus that\u00a0\u2026", "num_citations": "7\n", "authors": ["523"]}
{"title": "On version state recovery and adjudication in class diversity\n", "abstract": " The paper proposes a general approach to recovering faulty versions and adjudicating complete states of versions in object-oriented N-version programming which is based on the concepts of the abstract version state and mapping functions. Our recent progress in developing recovery features is reported (the previous results are presented in [1, 2]). We propose employing adjudication of version states as a means for advanced error detection. The properties which the abstract version state and mapping functions should have, in order to be used in both version recovery and state adjudication, are formulated. We introduce state and result adjudication which are useful for object-oriented programming, demonstrate how they can serve the purpose of error detection and discuss situations when the former can be effective (assuming that the latter is always used to guarantee the correctness of results). The paper describes the engineering of abstract version states: we consider three types of programmers involved in N-version programming and show how they share responsibilities and cooperate while applying the approach proposed. The paper discusses important practical issues related to implementation and application of the concepts proposed and demonstrates, with numerous examples, the usability of the approach. A thorough comparison of the existing schemes with our proposal concludes the paper.", "num_citations": "7\n", "authors": ["523"]}
{"title": "An evolutionary and adaptive approach for n-version programming\n", "abstract": " In this paper a concept is described to further improve the dependability characteristics of n-version systems. As one part of this strategy, we introduce an adaptive version management scheme. It is based on the use of dynamically changeable weight factors associated to the different versions of the system. Additionally, we propose to use a specific evolutionary scheme of design diversity combining n-version programming with genetic algorithms. Moreover, an additionally introduced segmentation scheme allows the combination of this strategy with recovery approaches.", "num_citations": "7\n", "authors": ["523"]}
{"title": "Diversely designed classes for use by multiple tasks\n", "abstract": " This paper proposes a new N-version programming (NVP) scheme which allows several caller tasks to jointly use components which are designed diversely. Diversity is applied here at the level of classes in such a way that several version classes (objects) are developed separately and independently, and are encapsulated into a diversely designed object. Such objects are to be implemented in a special stylised way to incorporate a controlling mechanism which would deal with task and version synchronisation, adjudication of version output parameters and states, faulty version recovery, etc. The general approach is demonstrated using Ada. We outline the characteristics of applications which benefit from using such NVP scheme, discuss the engineering of diversely designed objects and of the software which uses them and describe several possible extensions of the scheme.", "num_citations": "7\n", "authors": ["523"]}
{"title": "On N-Version Programming and Exception Handling\n", "abstract": " On N-Version Programming and Exception Handling - ePrints - Newcastle University Newcastle University Toggle Main Menu Toggle Search Home Browse Latest Stats Policies About Home Browse Latest Policies About Open Access padlock ePrints Browse by author On N-Version Programming and Exception Handling Lookup NU author(s): Professor Alexander Romanovsky Downloads Full text for this publication is not currently held within this repository. Alternative links are provided below where available. Publication metadata Author(s): Romanovsky A Editor(s): Puschner, P. Publication type: Conference Proceedings (inc. Abstract) Publication status: Published Conference Name: 10th European Workshop on Dependable Computing (EWDC-10): Design Methods and Tools for Dependable Systems and Quality of Service, Year of Conference: 1999 Pages: 126-130 Publisher: OCG Library holdings: Search \u2026", "num_citations": "7\n", "authors": ["523"]}
{"title": "Formal development and validation of the DSGamma system based on CO-OPN/2 and Coordinated Atomic Actions\n", "abstract": " The objectives of this research are twofold. On the rst hand, it aims to show the interest of Coordinated Atomic actions (CA actions) as a design concept and, on the other hand it explains how the formal language CO-OPN/2 can be used to express a CA action design. A real distributed application is developed according to a simple development life cycle: informal requirements, speci cation, design, implementation. The design phase is built according to the CA action concept. The CO-OPN/2 language is used to express the speci cation, and design phase. The implementation is made in Java based on a library of generic classes adapted to CA action concepts. The validation phase is brie y addressed, in order to demonstrate the extent to which the development methodology followed in this paper can be useful for proving properties.", "num_citations": "7\n", "authors": ["523"]}
{"title": "Unplanned recovery for non-program objects\n", "abstract": " Unplanned Recovery for Non-program Objects - ePrints - Newcastle University Newcastle University Toggle Main Menu Toggle Search Home Browse Latest Stats Policies About Home Browse Latest Policies About Open Access padlock ePrints Browse by author Unplanned Recovery for Non-program Objects Lookup NU author(s): Professor Alexander Romanovsky Downloads Full text for this publication is not currently held within this repository. Alternative links are provided below where available. Publication metadata Author(s): Romanovsky A, Shturtz IV Publication type: Article Publication status: Published Journal: International Journal of Computer Systems Science and Engineering Year: 1993 Volume: 8 Issue: 2 Pages: 72-79 ISSN (print): 0267-6192 Publisher: CRL Publishing Ltd. Actions Find at Newcastle University icon Link to this publication Share Newcastle University Library, NE2 4HQ, United Kingdom. Tel\u2026", "num_citations": "7\n", "authors": ["523"]}
{"title": "From analyzing operating system vulnerabilities to designing multiversion intrusion-tolerant architectures\n", "abstract": " This paper analyzes security problems of modern computer systems caused by vulnerabilities in their operating systems (OSs). Our scrutiny of widely used enterprise OSs focuses on their vulnerabilities by examining the statistical data available on how vulnerabilities in these systems are disclosed and eliminated, and by assessing their criticality. This is done by using statistics from both the National Vulnerabilities Database and the Common Vulnerabilities and Exposures System. The specific technical areas the paper covers are the quantitative assessment of forever-day vulnerabilities, estimation of days-of-grey-risk, the analysis of the vulnerabilities severity and their distributions by attack vector and impact on security properties. In addition, the study aims to explore those vulnerabilities that have been found across a diverse range of OSs. This leads us to analyzing how different intrusion-tolerant architectures\u00a0\u2026", "num_citations": "6\n", "authors": ["523"]}
{"title": "A refinement based method for developing distributed protocols\n", "abstract": " This paper presents a methodology for modelling and verification of high-assurance distributed protocols. In the paper we describe two main technical contributions needed for the development method: communication modelling patterns and a refinement strategy. The applicability of the proposed method is demonstrated by developing a new distributed resource allocation protocol. We also discuss the necessity of integrating other tools such as stochastic model checkers for enabling verification of wider range of protocol properties.", "num_citations": "6\n", "authors": ["523"]}
{"title": "Concepts of dependable cyber-physical systems engineering: model-based approaches\n", "abstract": " CONTENTS 1.1 Introduction 2 1.2 Denitions and Concept Bases of CPS 2 1.3 Types of System 3", "num_citations": "6\n", "authors": ["523"]}
{"title": "A generic model for system substitution\n", "abstract": " A Generic Model for System Substitution\u25a0 77 substitution. The properties of the substitution operator we have defined are discussed in Section 4.6. A case study illustrating the approach is presented in Section 4.7. The possible applications of the defined substitution operator are discussed in Section 4.8. Finally, a conclusion summarizes our contribution in the last section.4.2 STATE OF THE ART CPSs are strongly linked to their environment, which can change significantly. Thus, there is a strong requirement for these systems to adapt to these changes to ensure their correctness. System substitution is a key element to implement adaptation. There are various techniques and tools that are proposed by several authors. First, various formal tools are used to ensure the correctness of dynamic reconfiguration. In Reference 3, \u03c0-calculus and process algebra are used to model the system and exploit behavioral matching based on bisimulation to reconfigure the system appropriately. An extended transaction model is presented to ensure consistency during reconfiguration of distributed systems in Reference 4. The B method is applied for validating dynamic reconfiguration of the component-based distributed systems using proofs techniques for consistency checking and model-checking for timing requirements [5]. A high-level language is used to model architectures (with categorical diagrams) and for operating changes over a configuration (with algebraic graph rewriting)[6]. Second, dynamic reconfiguration can be used as part of a fault-tolerance mechanism that is a major concern for designing the dependable systems [7, 8]. Rodrigues et al.[9\u00a0\u2026", "num_citations": "6\n", "authors": ["523"]}
{"title": "Formal analysis of railway signalling data\n", "abstract": " This paper presents an approach to a tool-assisted analysis and verification of safety-critical interlocking and signalling data. We show how to combine multiple, non-homogeneous sources of data and render such data as a collection of mathematical entities, namely sets, relations and functions. We then demonstrate how top-level railway safety concerns can be broken down, via a combination of informal structured argumentation and formal inference, into formal verification goals suitable for automatic verification tools.", "num_citations": "6\n", "authors": ["523"]}
{"title": "A reactive architecture for cloud-based system engineering\n", "abstract": " The paper introduces an architecture to support system engineering on the cloud. It employs the main benefits of the cloud: scalability, parallelism, cost-effectiveness, multi-user access and flexibility. The architecture includes an open toolbox which provides tools as a service to support various phases of system engineering. The architecture uses the Open Services for Life-cycle Collaboration (OSLC) technology to create a reactive middleware that informs all stakeholders about any changes in the development artefacts. It facilitates the interoperability of tools and enables the workflow of tools to support complex engineering steps. Another component of the architecture is a shared repository of artefacts. All the artefacts generated during a system engineering process are stored in the repository, and can be accessed by relevant stakeholders. The shared repository also serves as a platform to support a protocol for\u00a0\u2026", "num_citations": "6\n", "authors": ["523"]}
{"title": "Power-proportional modelling fidelity\n", "abstract": " Traditional hierarchical modelling methods tend to have layers of abstraction corresponding to naturally existing layers of concern in multilevel systems. Although convenient, this is not always optimal for analysis and design. For instance, parts of a system which are in the same layer may not contribute to the same degree on some metric, eg system power consumption. To moderate the modelling, analysis and design effort, and potentially runtime control overhead for models used at runtime, less significant parts of the system should be studied at higher levels of abstraction and more significant ones with more detail. Concentrating on system power consumption, this paper presents Order Graphs (OGs), which have a clear hierarchical structure, but provide straightforward vertical zooming across multiple layers (orders) of model fidelity, resulting in the discovery of power-proportional cuts that run through different orders to be analysed together in a flat manner. Stochastic Activity Networks (SANs), a good flat modelling method, is suggested as an example of studying technique for cuts discovered with OGs. A series of experiments on an Odroid development system consisting of an ARM big. LITTLE multi-core structure provides initial validation for the approach.", "num_citations": "6\n", "authors": ["523"]}
{"title": "The SafeCap project on railway safety verification and capacity simulation\n", "abstract": " This paper introduces the UK SafeCap project on Overcoming the railway capacity challenges without undermining rail network safety. The focus of the project has been on developing methods and tools that will allow signalling engineers to model railway nodes (junctions and stations), to verify their safety and to analyse the node capacity provided the safety is ensured. The paper outlines the project approach, its objectives and the outcomes. The main result of the project is the development of a method for analysing railway safety and capacity in a unified way and the Eclipse-based SafeCap platform supporting this method. The platform is extendable with the new modelling plugins and is openly available at SourceForge. It has been developed in a close cooperation with industry and thoroughly evaluated using the layouts of several UK railway stations.", "num_citations": "6\n", "authors": ["523"]}
{"title": "Vertical and Horizontal Composition in Service-Oriented Architecture\n", "abstract": " Achieving high dependability in the Service-Oriented Architecture (SOA) is an open problem. One of the possible solutions for this problem is employing service diversity represented by a number of component web services with the identical or similar functionality at the each level of the composite system hierarchy during service composition. It is clear that such redundancy can improve web service reliability (trustworthiness) and availability. However to apply this approach we need to solve a number of problems. The paper proposes several solutions for ensuring dependable services composition when natural service redundancy and diversity are used.", "num_citations": "6\n", "authors": ["523"]}
{"title": "A modular implementation framework for code mobility\n", "abstract": " With the growing popularity of open distributed applications, mobile agents have naturally emerged as the fundamental technique for tackling the complexity of the emerging applications. However, the pervasive nature of code mobility issues implies that their implementation cannot be modularized based only on object-oriented (OO) abstractions and mechanisms. In fact, programmers of complex mobile agent systems frequently evidence the presence of mobility tangling and scattering in the modules of their systems. Despite these modularity breakdowns caused by code mobility, the developers have mostly relied on OO application programming interfaces (APIs) from mobility platforms and on the Java programming language. As a consequence, there is a pressing need for empowering developers with a modular implementation framework that supports a transparent, flexible incorporation of code mobility-specific\u00a0\u2026", "num_citations": "6\n", "authors": ["523"]}
{"title": "Web services dependability and performance monitoring\n", "abstract": " The dependability of Web Services is becoming increasingly important for many application domains, such as e-Science, virtual organizations and service-oriented computing. The understanding of how a Web Service behaves in practice will help the developers to improve their service and provide clients with the information to determine the best ways of employing the Web Service. To fulfill such needs, we have developed a tool that monitors the dependability and performance of Web Services. The paper reports some initial results of the experiments in which the tool has been used.", "num_citations": "6\n", "authors": ["523"]}
{"title": "Architecting Dependable Systems II\n", "abstract": " Architecting Dependable Systems II | Guide books ACM Digital Library home ACM home Google, Inc. (search) Advanced Search Browse About Sign in Register Advanced Search Journals Magazines Proceedings Books SIGs Conferences People More Search ACM Digital Library SearchSearch Advanced Search Browse Browse Digital Library Collections More HomeBrowse by TitleBooksArchitecting Dependable Systems II ABSTRACT No abstract available. Index Terms (auto-classified) 1.Architecting Dependable Systems II 1.Applied computing 1.Enterprise computing Comments Login options Check if you have access through your login credentials or your institution to get full access on this article. Sign in Full Access Get this Publication Information Contributors Published in Guide books cover image Architecting Dependable Systems II November 2004 ISBN:3540231684 Authors: Rog\u00e9rio de Lemos profile image \u2026", "num_citations": "6\n", "authors": ["523"]}
{"title": "Designing Fault-Tolerant Mobile Systems\n", "abstract": " The purpose of this paper is to investigate how several innovative techniques, not all initially intended for fault-tolerance, can be applied in providing fault tolerance of complex mobile agent systems. Due to their roaming nature, mobile agents usually run on Java-based platforms, which ensures full portability of mobile code. The first part of the paper discusses specific characteristics of mobile systems, outlines the application areas benefiting from code mobility, and shows why the existing error recovery techniques are not suitable for mobile systems. In the next part of the paper we present evaluation criteria for fault tolerance techniques, and propose several possible solutions for error recovery at the application level: meta-agent, Coordinated Atomic actions, asynchronous resolution, self-repair, and proof carrying code. The intention is to allow system developers to choose the approach which is suited best to the\u00a0\u2026", "num_citations": "6\n", "authors": ["523"]}
{"title": "Interplaying Cassandra NoSQL consistency and performance: A benchmarking approach\n", "abstract": " This experience report analyses performance of the Cassandra NoSQL database and studies the fundamental trade-off between data consistency and delays in distributed data storages. The primary focus is on investigating the interplay between the Cassandra performance (response time) and its consistency settings. The paper reports the results of the read and write performance benchmarking for a replicated Cassandra cluster, deployed in the Amazon EC2 Cloud. We present quantitative results showing how different consistency settings affect the Cassandra performance under different workloads. One of our main findings is that it is possible to minimize Cassandra delays and still guarantee the strong data consistency by optimal coordination of consistency settings for both read and write requests. Our experiments show that (i) strong consistency costs up to 25% of performance and (ii) the best setting for\u00a0\u2026", "num_citations": "5\n", "authors": ["523"]}
{"title": "Modelling hybrid train speed controller using proof and refinement\n", "abstract": " The modern radio-based railway signalling systems aim to increase network's capacity by enabling trains to run closer to each other. At the core of such systems is train's on-board computer (discrete) responsible for computing and controlling the speed (continuous) of the train. Such systems are best captured by hybrid models, which capture discrete and continuous system's aspects. Hybrid models are notoriously difficult to model and verify, in our research we address this problem by applying hybrid systems' modelling patterns and stepwise refinement for developing hybrid train speed controller model.", "num_citations": "5\n", "authors": ["523"]}
{"title": "Architecting holistic fault tolerance\n", "abstract": " The efficiency and maintainability of fault tolerance mechanisms in a computer system has typically not been a major topic of concern, mostly because fault tolerance is a non-functional system requirement. This paper proposes a Holistic Fault Tolerance architecture, based on a centralised fault tolerance management, with related functionality distributed across the entire system. The most suitable error detection and error recovery strategies for a given application are chosen by a special crosscutting controller depending on error rates, system performance and resource utilisation requirements. We discuss the motivation for introducing this holistic fault tolerance architecture and reason about its benefits from the point of view of optimal system operation and improved maintainability. The advantages and possible implementation challenges of the proposed approach are demonstrated by a real-world application.", "num_citations": "5\n", "authors": ["523"]}
{"title": "Selective abstraction and stochastic methods for scalable power modelling of heterogeneous systems\n", "abstract": " With the increase of system complexity in both platforms and applications, power modelling of heterogeneous systems is facing grand challenges from the model scalability issue. To address these challenges, this paper studies two systematic methods: selective abstraction and stochastic techniques. The concept of selective abstraction via black-boxing is realised using hierarchical modelling and cross-layer cuts, respecting the concepts of boxability and error contamination. The stochastic aspect is formally underpinned by Stochastic Activity Networks (SANs). The proposed method is validated with experimental results from Odroid XU3 heterogeneous 8-core platform and is demonstrated to maintain high accuracy while improving scalability.", "num_citations": "5\n", "authors": ["523"]}
{"title": "On structuring holistic fault tolerance\n", "abstract": " Computer systems are developed taking into account that they should be easily maintained in the future. It is one of the main requirements for the sound architectural design. The existing approaches to introducing fault tolerance rely on recursive system structuring out of functional components\u2013this typically results in non-optimal fault tolerance. The paper proposes a vision of structuring complex many-core systems by introducing a special component supporting system-wide fault tolerance coordination. The component acts as a central module making decisions about fault tolerance strategies to be implemented by individual system components depending on the performance and energy requirements specified as system operating modes.", "num_citations": "5\n", "authors": ["523"]}
{"title": "Enabling global software development via cloud-based software process enactment\n", "abstract": " Global software development (GSD) is a software development model where the development effort spans across distributed locations. Although GSD has gained vast popularity due to its economical benefits, it faces various challenges as a result of cultural, temporal and spatial distances. Cloud computing is becoming the norm for consuming computing resources due to its economies of scale. While the potential for using the cloud for GSD has been investigated in the literature, in this paper, we go one step forward and propose a cloud-based software process enactment architecture. This architecture facilitates bridging the spatial and temporal distances and aims at addressing communication, managerial and technical GSD challenges. We use EXE-SPEM-an extension of SPEM2. 0 which supports cloud-based executability of software process models-to model software processes. These models are then enacted in the cloud where the type and amount of resources to be used can be configured. We demonstrate our approach using a simple verification process example that we enact in a proof-of-concept implementation of the architecture.", "num_citations": "5\n", "authors": ["523"]}
{"title": "From requirements engineering to safety assurance: refinement approach\n", "abstract": " Formal modelling and verification are widely used in the development of safety-critical systems. They aim at providing a mathematically-grounded argument about system safety. In particular, this argument can facilitate construction of a safety case \u2013 a structured safety assurance document required for certification of safety-critical systems. However, currently there is no adequate support for using the artefacts created during formal modelling in safety case development. In this paper, we present an approach and the corresponding tool support that tackles this problem in the Event-B modelling framework. Our approach establishes a link between safety requirements, Event-B models and corresponding fragments of a safety case. The supporting automated tool ensures traceability between requirements, models and safety cases.", "num_citations": "5\n", "authors": ["523"]}
{"title": "ArchOn: Architecture-open resource-driven cross-layer modelling framework\n", "abstract": " This paper describes the first steps towards the development of a modelling method for large complex computing systems focusing on many-core types and concentrating on the cross-layer aspects. The models resulting from this method will help system designers reason about, analyse, and ultimately design such systems across all conventional computing and communication layers, from application, operating system, down to the finest hardware details. The main points of concern are energy and power and the physical parameters related to them, such as supply voltages and temperature, among other things, and how these impact on and relate to system\" performance\" metrics, including speed, throughput, and crucially, reliability.", "num_citations": "5\n", "authors": ["523"]}
{"title": "DEPLOY: Industrial deployment of advanced system engineering methods for high productivity and dependability\n", "abstract": " The work of the new FP7 ICT DEPLOY Integrated Project (February 2008--January 2012)[1] is driven by the tasks of achieving and evaluating industrial take-up, initially by DEPLOY industrial partners, of DEPLOY methods and tools, together with the necessary further research on methods and tools.", "num_citations": "5\n", "authors": ["523"]}
{"title": "An aspect\u2010oriented software architecture for code mobility\n", "abstract": " Mobile agents have come forward as a technique for tackling the complexity of open distributed applications. However, the pervasive nature of code mobility implies that it cannot be modularized using only object\u2010oriented (OO) concepts. In fact, developers frequently evidence the presence of mobility scattering in their system's modules. Despite these problems, they usually rely on OO application programming interfaces (APIs) offered by the mobility platforms. Such classical API\u2010oriented designs suffer a number of architectural restrictions, and there is a pressing need for empowering developers with an architectural framework supporting a flexible incorporation of code mobility in the agent applications. This work presents an aspect\u2010oriented software architecture, called ArchM, ensuring that code mobility has an enhanced modularization and variability in agent systems, and is straightforwardly introduced in\u00a0\u2026", "num_citations": "5\n", "authors": ["523"]}
{"title": "On exceptions, exception handling, requirements and software lifecycle\n", "abstract": " It is often the case that faults and fault tolerance are not dealt with left until late implementation phases [1]. In a similar way, exceptions and exception handling are typically viewed as language features. Fortunately, it is becoming clear now that exception handling should be an immanent part of all development phases [2]. It is difficult to underestimate the importance of identifying the correct and complete set of requirements for exceptions and exception handling. Thus, at a meeting in Imperial College, London in 2005 D. Parnas claimed that up to 80% of requirements may have to deal with exceptions and emphasized that there is no practical upper bound on the number of things that can go wrong [3].There is no widely accepted methodology for eliciting these requirements but this is now clearly becoming an area of very active research with several groups already contributing: paper [4] extends use cases to include a description of exceptional behaviour which uses sequences of actions performed by the system; paper [5] does the same to express the situations that can prevent the system from achieving its goals; an approach in [6] is based on usage models to allow specification and modeling of exception handling using a requirement state machine language; and paper [7] discusses a semi-formal specification of fault-tolerance requirements using the concept of deviation from requirements.", "num_citations": "5\n", "authors": ["523"]}
{"title": "Scientific Engineering of Distributed Java Applications.: Third International Workshop, FIDJI 2003, Luxembourg-Kirchberg, Luxembourg, November 27-28, 2003, Revised Papers\n", "abstract": " FIDJI 2003 was an international forum for researchers and practitioners in-rested in the advances in, and applications of, software engineering for distri-ted applicationdevelopment. Concerningthe technologies, the workshopfocused on \u201cJava-related\u201d technologies. It was an opportunity to present and observe the latest research, results, and ideas in these areas. Allpaperssubmittedtothisworkshopwerereviewedbyatleasttwomembers of the International Program Committee. Acceptance was based primarily on originality and contribution. We selected, for these post-workshop proceedings, 14 papers, amongst 29 submitted, two tutorials, and one keynote talk. FIDJI2003aimedatpromotingascienti? capproachtosoftwareengineering. The scope of the workshop included the following topics:\u2013design of distributed Java applications\u2013Java-related technologies\u2013software and system architecture engineering and development methodo-gies\u2013development methodologies for UML\u2013development methodologies for reliable distributed systems\u2013component-based development methodologies\u2013managementofevolutions/iterationsintheanalysis, design, implementation, and test phases\u2013dependability support during system life-cycles\u2013managing inconsistencies during application development\u2013atomicity and exception handling in system development\u2013software architectures, frameworks, and design patterns for developing d-tributed systems\u2013integration of formal techniques in the development process\u2013formal analysis and grounding of modeling notation and techniques (eg, UML, metamodeling)\u2013supporting the security requirements of distributed applications in the\u00a0\u2026", "num_citations": "5\n", "authors": ["523"]}
{"title": "Formalizing dependability mechanisms in B: From specification to development support\n", "abstract": " The CA action concept has been proven successful for building dependable distributed systems due to its support for error recovery for both competitive and cooperative concurrent actions. This paper introduces the formal specification of dependability mechanisms offered by CA actions using the B formal method, from which an XML-based language is derived. The resulting language then allows developing dependable systems, where the B formal specification is refined to obtain an implementation of the associated runtime support.", "num_citations": "5\n", "authors": ["523"]}
{"title": "Dependable on-line upgrading of distributed systems\n", "abstract": " The main theme of the workshop is to develop approaches to dependable systematic on-line system upgrading. The workshop aims at: bringing together practitioners, researchers and system developers working on the issues related to online upgrading of distributed systems; developing a better understanding of the problems that developers face while dealing with on-line system upgrading; defining a research agenda for developing distributed upgradable systems. We sought submissions from both industry and academia on all topics related to on-line upgrading of distributed systems. This \"Dependable On-line Upgrading of Distributed Systems\" workshop broadens the discussion from the 'simple' upgrading of objects in a closed environment to the asynchronous integration of upgraded components (objects, tasks, interfaces, etc.) in a distributed, independently managed, heterogeneous environment in which\u00a0\u2026", "num_citations": "5\n", "authors": ["523"]}
{"title": "Distributed atomic actions in Ada 95\n", "abstract": " This paper discusses the development of a distributed asynchronous atomic action scheme for Ada 95. The scheme makes use of many unique Ada 95 features including protected objects, asynchronous transfer of control and the distributed systems annex. We present the packages which implement the local and global action support and illustrate their use in a (partial) implementation of the FZI production cell problem. We also discuss a number of variations of the model and how these might be included. Finally, we discuss how the distribution model used in Ada 95 has influenced our design.", "num_citations": "5\n", "authors": ["523"]}
{"title": "Coordinated backward recovery between client processes and data servers\n", "abstract": " The authors discuss backward error recovery for complex software systems, where different subsystems may belong to essentially different application areas. Such heterogeneous subsystems are naturally built according to different design 'models', namely the 'object-action' model (where the long-term state of the computation is encapsulated in data objects, and active processes invoke operations on these objects), and the 'process-conversation' model (where the state is contained in the processes, communicating via messages). To allow backward error recovery in these two 'models' of computation, two different schemes are most appropriate: atomic transactions for the object-action model, and conversations for the process-conversation model. Assuming that each of these two kinds of subsystem already has functioning mechanisms for backward error recovery, the authors describe the additional provisions\u00a0\u2026", "num_citations": "5\n", "authors": ["523"]}
{"title": "Designing fault-tolerant objects in object-oriented programming\n", "abstract": " Designing fault-tolerant objects in object-oriented programming | Proceedings of the seventh international conference on Technology of object-oriented languages and systems ACM Digital Library home ACM home Google, Inc. (search) Advanced Search Browse About Sign in Register Advanced Search Journals Magazines Proceedings Books SIGs Conferences People More Search ACM Digital Library SearchSearch Advanced Search Browse Browse Digital Library Collections More HomeBrowse by TitleProceedingsTOOLS 7Designing fault-tolerant objects in object-oriented programming ARTICLE Designing fault-tolerant objects in object-oriented programming Share on Authors: Alexander Romanovsky profile image AB Romanovsky View Profile , IV Shturtz profile image IV Shturtz View Profile , VR Vassilyev profile image VR Vassilyev View Profile Authors Info & Affiliations Publication: TOOLS 7: Proceedings of \u2026", "num_citations": "5\n", "authors": ["523"]}
{"title": "A railway simulation suite for modelling advanced railway control systems\n", "abstract": " All large railway networks use a mixture of outdated, modern and emerging signalling and train operation principles. There is a need to develop novel modelling and verification mechanisms to support mixed traffic scenarios, including, for example, mixing different types of signalling and driving. In our previous work we introduced the unified Train Driving Policy (uTDP) formal modelling language for uniformly capturing diverse signalling principles and mixing, in a demonstratively safe manner, at the node and/or network-level novel and legacy signalling principles. This paper describes our work on making uTDP practical and useful for the engineers.", "num_citations": "4\n", "authors": ["523"]}
{"title": "Formalizing goal-oriented development of resilient cyber-physical systems\n", "abstract": " -(CPS), that is, the systems that can deliver trustworthy services despite changes, is a complex engineering task. Resilience can be considered as either a system\u2019s ability to achieve its goals despite negative changes, such as failures of components, or as a system\u2019s capability to achieve its desired goals more efficiently, for instance by increasing component utilization. In this work, we present a formal goal-oriented approach to developing resilient CPS in Event-B. We define the main abstractions required for reasoning about system goals and introduce the specification patterns explicitly defining architectural reconfiguration mechanisms allowing the system to achieve resilience. We demonstrate how formal goal-oriented development in Event-B facilitates the structuring of component interdependencies and derivation of the overall distributed architecture of CPS.", "num_citations": "4\n", "authors": ["523"]}
{"title": "The impact of consistency on system latency in fault tolerant internet computing\n", "abstract": " The paper discusses our practical experience and theoretical results in investigating the impact of consistency on latency in distributed fault tolerant systems built over the Internet. Trade-offs between consistency, availability and latency are examined, as well as the role of the application timeout as the main determinant of the interplay between system availability and performance. The paper presents experimental results of measuring response time for replicated service-oriented systems that provide different consistency levels: ONE, ALL and QUORUM. These results clearly show that improvements in system consistency increase system latency. A set of novel analytical models is proposed that would enable quantified response time prediction depending on the level of consistency provided by a replicated system.", "num_citations": "4\n", "authors": ["523"]}
{"title": "Adaptive resource control in multi-core systems\n", "abstract": " Multi-core systems present a set of unique challenges and opportunities. In this paper we discuss the issues of power-proportional computing in a multi-core environment and argue that a cross-layer approach spanning from hardware to user-facing software is necessary to successfully address this problem.\u2282", "num_citations": "4\n", "authors": ["523"]}
{"title": "Concurrency in Dependable Computing\n", "abstract": " Concurrency in Dependable Computing focuses on concurrency related issues in the area of dependable computing. Failures of system components, be hardware units or software modules, can be viewed as undesirable events occurring concurrently with a set of normal system events. Achieving dependability therefore is closely related to, and also benefits from, concurrency theory and formalisms. This beneficial relationship appears to manifest into three strands of work. Application level structuring of concurrent activities. Concepts such as atomic actions, conversations, exception handling, view synchrony, etc., are useful in structuring concurrent activities so as to facilitate attempts at coping with the effects of component failures. Replication induced concurrency management. Replication is a widely used technique for achieving reliability. Replica management essentially involves ensuring that replicas perceive concurrent events identically. Application of concurrency formalisms for dependability assurance. Fault-tolerant algorithms are harder to verify than their fault-free counterparts due to the fact that the impact of component faults at each state need to be considered in addition to valid state transitions. CSP, Petri nets, CCS are useful tools to specify and verify fault-tolerant designs and protocols. Concurrency in Dependable Computing explores many significant issues in all three strands. To this end, it is composed as a collection of papers written by authors well-known in their respective areas of research. To ensure quality, the papers are reviewed by a panel of at least three experts in the relevant area.", "num_citations": "4\n", "authors": ["523"]}
{"title": "The SafeCap toolset for improving railway capacity while ensuring its safety\n", "abstract": " The on-going RSSB/EPSRC UK SafeCap project develops modelling techniques and tools for improving railway capacity while ensuring that safety standards are maintained. This paper reports recent SafeCap results on designing a Domain Specific Language (DSL), a verification infrastructure and the approaches to estimating and improving capacity.", "num_citations": "4\n", "authors": ["523"]}
{"title": "MASTAC: new curriculum for master and doctoral studies in critical software and computing\n", "abstract": " The paper presents the on-going EC-funded Tempus project\" MSc and PhD studies in Aerospace Critical Computing\" executed by the National Aerospace University, Kharkiv, Ukraine with the support of Newcastle University and City University of London, UK and \u00c5bo Akademi University, Turku, Finland. The state-of-the-art, completed work as well as the next steps of the development of master and doctoral courses for the specialty in critical software engineering, computer systems and networks are described. The inputs from each of the European consortium members are presented.", "num_citations": "4\n", "authors": ["523"]}
{"title": "A mediator system for improving dependability of web services\n", "abstract": " This paper presents a novel architectural solution for improving dependability of Web Services (WSs). This solution is based on a concept of WSs Mediator, which acts as a WSs intermediary implementing fault tolerance mechanisms, multi-routing strategy and making use of existing service redundancy. The distributed architecture of this system makes it possible to collect, publish and make decisions using runtime dependability metadata specifically representing the end-user\u2019s perspective of the network and component WSs behaviour, therefore paving the way to achieve dependability-explicit operation of WSs [1].", "num_citations": "4\n", "authors": ["523"]}
{"title": "Tla specification of a mechanism for concurrent exception handling\n", "abstract": " Recently the concept of dependable multiparty interaction (DMI) has been introduced. In a multiparty interaction, several parties (objects or processes) somehow \u201ccome together\u201d to produce an intermediate and temporary combined state, use this state to execute some activity, and then leave this interaction and continue their normal execution. The concept of multiparty interactions has been investigated by several researchers, but to the best of our knowledge none have considered how failures in one or more participants of the multiparty interaction could be dealt with. In this paper, we show how this mechanism deals with concurrent exceptions raised during an interaction. This is shown through a formal description of the DMI concept. We use Temporal Logic of Actions (TLA) in order to formally describe the DMI features.", "num_citations": "4\n", "authors": ["523"]}
{"title": "Aspects of Exceptions at the Meta-Level (Position Paper)\n", "abstract": " This paper describes the design and usage of a metaobject protocol that explicitly includes support for handling exceptions. We are not proposing implementing exception mechanisms anew [2, 4] or proposing a unified meta-level software architecture for exception handling [3]. To make our discussion concrete we describe an extension of the Kava [9] metaobject protocol that includes exceptions as first class values in its metaobject protocol, and provide examples of Kava\u2019s use. It is our opinion that insufficient attention has been paid to exceptions by designers of metaobject protocols for object-oriented languages. In our view, exceptions should be explicitly considered when designing a metaobject protocol. Our rationale is that exceptions should be treated in the same way that the parameters of a method or its return value are treated. Therefore, if the behaviour of method execution is reflected upon, then not only should the return value be reified and available to the meta-level, so should an exception that is signalled from within a method. However, the implementation of a metaobject protocol that deals with exceptions should not lead to base-level programmer\u2019s expectations being confounded, as doing so would make both programming and verification very difficult. For example, the exception model should not be able to be changed dynamically, say from a termination model to a resumption model (as opposed to [1]).Handling exceptions at the meta-level must be considered when using reflection to satisfy non-functional requirements. For example, consider distributing an object through the use of reflection. In order to preserve the full\u00a0\u2026", "num_citations": "4\n", "authors": ["523"]}
{"title": "Using coala to develop a distributed object-based application\n", "abstract": " COALA is a new language for high level design of distributed object applications. The design concepts used in COALA are those of Coordinated Atomic Actions (J. Xu et al., 1995), which propose a unified transactional approach to structuring complex concurrent activities and supporting error recovery. COALA integrates several formal techniques (D. Buchs and N. Guelfi, 2000) in order to address verification and validation issues. The paper presents a case study of a distributed object application designed in COALA. The main contribution of this case study consists of validating the research value of the COALA language. This case study is concerned with the design of an Auction Service system. Our experiment shows that COALA is indeed helpful in designing the static and dynamic structure of complex concurrent systems. It offers a flexible way of dealing with the cooperation and competition of systems as well as\u00a0\u2026", "num_citations": "4\n", "authors": ["523"]}
{"title": "Recovery in heterogeneous systems\n", "abstract": " We discuss backward error recovery for large software systems, where different subsystems may belong to essentially different application areas, like databases and process control. Examples of such systems are found in modern telecommunication, transportation, manufacturing and military applications. Such heterogeneous subsystems are naturally built according to different design\" models\", viz. the\" object-action\" model (where the long-term state of the computation is encapsulated in data objects, and active processes invoke operations on these objects), and the\" process-conversation\" model (where the state is contained in the processes, communicating via messages), which also imply different ways of organising backward error recovery. In the objectaction model, backward recovery is naturally organised via atomic transactions; in the process-conversation model, via conversations. We show how checkpointing and roll-back can be co-ordinated between two sets of such heterogeneous subsystems, namely sets of message passing processes organised in conversations and data servers offering atomic transactions. Our solution involves altering the virtual machine on which the programs run, and programming conventions which seem rather natural and can be automatically enforced. We demonstrate the feasibility of the approach by showing how it would work with the Ada language, and show a toy example.", "num_citations": "4\n", "authors": ["523"]}
{"title": "PARMA: parallelization-aware run-time management for energy-efficient many-core systems\n", "abstract": " Performance and energy efficiency considerations have shifted computing paradigms from single-core to many-core architectures. At the same time, traditional speedup models such as Amdahl's Law face challenges in the run-time reasoning for system performance and energy efficiency, because these models typically assume limited variations of the parallel fraction. Moreover, the parallel fraction, which varies dynamically in workloads, is generally unknown at run-time without application-level instrumentation. This article describes novel performance/energy trade-off models based on realistic architectural considerations, which describe the parallel fraction and speedup as functions of performance counter values available in modern processors, removing the need for application-level instrumentation. These are then used to develop a Parallelization-Aware Run-time Management (PARMA) approach. PARMA\u00a0\u2026", "num_citations": "3\n", "authors": ["523"]}
{"title": "A formal approach to designing reliable advisory systems\n", "abstract": " This paper proposes a method in which to formally specify the design and reliability criteria of an advisory system for use within mission-critical contexts. This is motivated by increasing demands from industry to employ automated decision-support tools capable of operating as highly reliable applications under strict conditions. The proposed method applies the user requirements and design concept of the advisory system to define an abstract architecture. A Markov reliability model and real-time scheduling model are used to effectively capture the operational constraints of the system and are incorporated to the abstract architectural design to define an architectural model. These constraints describe component relationships, data flow and dependencies and execution deadlines of each component. This model is then expressed and proven using SPARK. It was found that the approach useful in simplifying\u00a0\u2026", "num_citations": "3\n", "authors": ["523"]}
{"title": "Formalisation-driven development of safety-critical systems\n", "abstract": " The use of formal modelling and verification is recommended by several standards in the development of highly critical systems. However, the standards do not prescribe a process that enables a seamless integration of formalisation activities into the development process. In this paper, we propose a model and an automated tool support for an iterative formalisation-driven development of safety-critical systems in Event-B framework. Event-B supports correct-by-construction development and provides the designers with a continuous feedback on the correctness of models and corresponding system requirements, including safety. To automate the proposed formalisation-driven development, we present a prototype of an automated tool support relying on the novel OSLC technology. It allows us to seamlessly integrate derivation of system requirements with formal modelling and proof-based verification.", "num_citations": "3\n", "authors": ["523"]}
{"title": "Engineering cross-layer fault tolerance in many-core systems\n", "abstract": " Engineering modern many-core systems is a challenging task because of their scale and complexity. We cannot focus on ensuring their dependability without understanding its interplay with performance and energy consumption. This calls for developing new structuring mechanisms that step away from the traditional ways systems are developed (such as strict layering, strong encapsulation, abstractions, hiding). The paper reports on the initial steps of a PhD work focusing on development methods and tools for architecting cross-layer fault tolerance in many-core systems in which error detection and error recovery are applied at several system layers in a concerted coordinated fashion to ensure the overall system efficiency.", "num_citations": "3\n", "authors": ["523"]}
{"title": "Advanced modelling, simulation and verification for future traffic regulation optimisation\n", "abstract": " This paper introduces a new project supported by the UK Technical Strategy Leadership Group (TSLG) to contribute to its vision of Future Traffic Regulation Optimisation (FuTRO). In this project Newcastle University will closely cooperate with Siemens Rail Automation on developing novel modelling, verification and simulation techniques and tools that support and explore in an integrated approach to efficient dynamic improvement of capacity and energy consumption of railway networks and nodes while ensuring whole systems safety. The SafeCap+ (or SafeCap for FuTRO) project builds on the two previous projects (SafeCap and SafeCap Impact) which have developed a novel modelling environment that helps signalling engineers to design nodes (stations or junctions) in a way that guarantees their safety and allows engineers to explore different design options to select the ones that ensure the\u00a0\u2026", "num_citations": "3\n", "authors": ["523"]}
{"title": "Unified train driving policy\n", "abstract": " This chapter presents a domain\u2010specific formal modeling language uniformly addressing fixed and moving block principles in both discrete and continuous contexts. An objective of this work is to help signaling engineers to reason about safety and performance within the scope of a single railway model and thus help them to design safe railway networks that achieve higher capacity. The chapter proposes a modeling notation called Unified Train Driving Policy (UTDP). It introduces the UTDP modeling notation based on the constraint concept and shows how to use it to indirectly define horizon, evolution and mutation of actors, in particular actors modeling train progress through a railway network. The chapter demonstrates invariants and hazards, we must also prove that a given UTDP specification satisfies the well\u2010formedness condition and behavioral constraints are satisfiable.", "num_citations": "3\n", "authors": ["523"]}
{"title": "Software Engineering for Resilient Systems: Third International Workshop, SERENE 2011, Geneva, Switzerland, September 29-30, 2011, Proceedings\n", "abstract": " This book constitutes the refereed proceedings of the Third International Workshop on Software Engineering for Resilient Systems, SERENE 2011, held in Geneva, Switzerland, in September 2011. The 13 revised full papers presented together with 2 invited talks were carefully reviewed and selected from numerous submissions. The papers address all aspects of formal modeling and verification, architecting resilient systems, fault tolerance, requirements engineering and product lines, monitoring and self-adaption, and security and intrusion avoidance.", "num_citations": "3\n", "authors": ["523"]}
{"title": "DT4BP: A Business Process Modelling Language for Dependable Time-Constrained Business Processes\n", "abstract": " [en] Today, numerous organisations rely on information software systems to run their businesses. The effectiveness of the information software system then, depends largely on the degree to which the organisation's business is accurately captured in the business model. The business model is an abstract description of the way an organisation's functions. Thus, the more precise the business model, the more accurate the requirement definition of the information software system to be engineered. There are an abundance of tools and notations available today to support the development of many types of business process. Many of these artifacts rely on the concept of a business process to describe a business model. A business process is commonly known as a set of one or more linked procedures or activities which collectively realise a business objective or policy goal, normally within the context of an organisational structure defining functional roles and relationships\". This thesis is concerned with modelling business processes as a means to accurately capture an organisation's activities and thus, the requirements of the software system that supports these activities. Among the infinite set of possible business processes, this thesis targets only those characterized by the qualities of dependability, collaboration and time. Business processes having these specific dimensions are referred to as Dependable, Collaborative and Time-Constrained (DCTC) business processes. A dependable business process is one whose failures or the number of occurrences in which business process misses its goal are not unacceptably frequent or severe (from\u00a0\u2026", "num_citations": "3\n", "authors": ["523"]}
{"title": "Architecting Dependable Systems IV\n", "abstract": " Architecting Dependable Systems IV - ePrints - Newcastle University Newcastle University Toggle Main Menu Toggle Search Home Browse Latest Stats Policies About Home Browse Latest Policies About Open Access padlock ePrints Architecting Dependable Systems IV Lookup NU author(s): Dr Rogerio De Lemos, Dr Cristina Gacek, Professor Alexander Romanovsky Downloads Full text for this publication is not currently held within this repository. Alternative links are provided below where available. Publication metadata Editor(s): de Lemos R, Gacek C, Romanovsky A Publication type: Edited Book Publication status: Published Series Title: Lecture Notes in Computer Science Year: 2007 Volume: 4615 Number of Pages: 435 Publisher: Springer-Verlag Place Published: Berlin Notes: State-of-the-Art Survey. Selected papers from WADS 2006, plus invited papers. Library holdings: Search Newcastle University Library \u2026", "num_citations": "3\n", "authors": ["523"]}
{"title": "Architecting dependable systems\n", "abstract": " (2006) Architecting Dependable Systems. Journal of Systems and Software, 79 (10). pp. 1359-1360. ISSN 0164-1212.(doi: 10.1016/j. jss. 2006.04. 008)(The full text of this publication is not currently available from this repository. You may be able to access a copy if URLs are provided)(KAR id: 13850)", "num_citations": "3\n", "authors": ["523"]}
{"title": "Coordinated Forward Error Recovery for Web Services\n", "abstract": " This paper puts forward a solution based on forward error recovery, oriented towards providing dependability of composed Web services. The proposed solution has no impact on the autonomy of the individual Web services, while exploiting their possible support for dependability (eg, transactional support at the level of each service). Our solution lies in system structuring in terms of co-operative atomic actions that have a well-defined behaviour, both in the absence and in the presence of service failures. More specifically, we define the notion ofWeb Service Composition Action (WSCA) based on the Coordinated Atomic Action concept, which allows structuring composite Web services in terms of dependable actions. We then introduce a framework enabling the development of compositeWeb services based onWSCAs, consisting of an XML-based language for the specification of WSCAs and a platform supporting the execution of WSCAs.", "num_citations": "3\n", "authors": ["523"]}
{"title": "Component Based Dependable System Modelling for Easier Verification\n", "abstract": " The aim of this Chapter is to present an example of incremental modelling in CO-OPN that allows easier verification. We show how to build the crossroads specification by \u201ccleanly\u201d integrating physical and logical modelling of the system by means of the CO-OPN component and context notions. We take the example of the crossroads controller, and proceed to \u201cobserve\u201d it, i.e., to check some basic properties we might expect from such a system. We also incrementally include failure behaviours, and show how we then barely need to modify the observing apparatus.", "num_citations": "3\n", "authors": ["523"]}
{"title": "On developing and verifying design abstractions for reliable concurrent programming in Ada\n", "abstract": " Ada 95 is an expressive concurrent programming language, which allows building large multi-tasking applications. Much of the complexity of these applications stems from the interactions between the tasks. Design abstractions (such as atomic actions, conversations etc.) have been proposed to deal with such complexity. This paper argues that Petri nets offer a promising, tool-supported, technique for checking the logical correctness of abstractions. The paper illustrates the effectiveness of this approach by showing the correctness of an Ada implementation of the atomic action protocol using a variety of Petri net tools.", "num_citations": "3\n", "authors": ["523"]}
{"title": "Formal Development and Validation of the DSGamma System Based on CO-OPN/2 and Coordinated Atomic Actions\n", "abstract": " The rapid expansion of Java programs into software market is often not supported by a proper development methodology. Here, we present a formal development methodology well-suited for Java dependable distributed applications. It is based on the stepwise refinement of model-oriented formal specifications, and enables validation of the obtained system wrt the client's requirements. Three refinement steps have been identified in the case of fault-tolerant distributed applications: first, starting from informal requirements, an initial formal specification is derived. It does not depend on implementation constraints and provides a centralized solution, second, dependability and distribution constraints are integrated; third, the Java implementation is realised. The CO-OPN/2 language is used to express specifications formally; and the dependability and distribution design is based on the Coordinated Atomic action concept. The methodology and the three refinement steps are presented through a very simple fault-tolerant distributed Java application.", "num_citations": "3\n", "authors": ["523"]}
{"title": "Application specific conversation schemes for ADA programs\n", "abstract": " The paper considers a development of the conversation scheme version proposed by A. Clematis and V. Gianuzzi in Microprocessing and Microprogramming (Vol. 32, No. 1\u20135, 1991) [5] and Computer Languages (Vol. 18, No. 3, 1993) [6]. The authors discussed the methodology of using conversations within a conventional concurrent language (Ada), which makes the conversation scheme practical. In our paper we concentrate on the improvements for their scheme. We believe that it is important for the programmer to have more choice, and propose what could be called a library of schemes from which the appropriate scheme could be chosen depending on the application. We discuss ways of setting dynamically the number of processes participating in a conversation; of having different sets of servers involved in different alternates of the same conversation; of introducing a global acceptance test which would be\u00a0\u2026", "num_citations": "3\n", "authors": ["523"]}
{"title": "Bringing the computer revolution down to a personal level\n", "abstract": " A survey of software that may be especially useful to scientists in a variety of fields is presented. Products range in areas of specialization from solving equations to scientific word processing.", "num_citations": "3\n", "authors": ["523"]}
{"title": "Modelling for systems with holistic fault tolerance\n", "abstract": " Trade-offs between extra-functional properties, such as performance, reliability and resource utilisation, have been recognised as crucial in system design. The concept of Holistic Fault Tolerance (HFT) is aimed at targeting these trade-offs in run-time system control. Previous work has shown that HFT systems can have significant complexity, which may require sophisticated modelling at the design stage. This paper presents a novel HFT design methodology based on hierarchical modelling and stochastic simulations. The former caters to system complexity and the latter estimates extra-functional properties in the trade-offs. The method is demonstrated with an application example of number plate recognition software.", "num_citations": "2\n", "authors": ["523"]}
{"title": "Selective abstraction for estimating extra-functional properties in Networks-on-Chips using archon framework\n", "abstract": " The analysis for extra-functional properties like power and performance takes a critical role in the system design workflow. Hardware-software co-simulation is one of the commonly used ways to perform this type of analysis. However, with the modern development of many-core systems the problem of scalability is becoming a bottleneck for all analysis techniques including simulation, especially when a simple extrapolation from the single core results is unacceptable. This paper presents a framework aimed at the extra-functional analysis during the rapid prototyping stages of system design. The tool is based on stochastic modelling and simulation of cross-layer system representations. The concept of selective abstraction is applied to ensure a sufficient level of accuracy where it is needed, while reducing the complexity of the parts that are of less importance. A set of Networks-on-Chip topologies has been analysed\u00a0\u2026", "num_citations": "2\n", "authors": ["523"]}
{"title": "Enabling GSD task allocation via cloud-based software processes\n", "abstract": " Allocating tasks to distributed sites in Global Software Development (GSD) projects is often done unsystematically and based on the personal experience of project managers. Wrong allocation decisions increase the project\u2019s risks as tasks have dependencies that are inherited by the distributed sites. Decision support can help make the task allocation a more informed and systematic process. The challenges in allocating tasks to distributed sites exist because of three distance dimensions between sites (geographical, temporal and cultural). An informed task allocation decision needs to consider these distances. Therefore, in this paper, we propose to integrate and semi-automate the calculation of an existing Global Distance Metric (GDM) into an architecture that supports executing cloud-based software processes. We analyze the potential of integrating the GDM into this architecture and identify the needed\u00a0\u2026", "num_citations": "2\n", "authors": ["523"]}
{"title": "Software Engineering for Resilient Systems\n", "abstract": " This volume contains the proceedings of the 9th International Workshop on Software Engineering for Resilient Systems (SERENE 2017). SERENE 2017 took place in Geneva, Switzerland on September 4\u20135, 2017. The SERENE workshop is an annual event that brings together researchers and practitioners working on the various aspects of design, verification, and assessment of resilient systems. In particular it covers such areas as:\u2022 Development of resilient systems;\u2022 Engineering processes for resilient systems;\u2022 Requirements engineering and re-engineering for resilience;\u2022 Frameworks, patterns, and software architectures for resilience;\u2022 Engineering of self-healing autonomic systems;\u2022 Design of trustworthy and intrusion-safe systems;\u2022 Resilience at run-time (mechanisms, reasoning, and adaptation);\u2022 Resilience and dependability (resilience vs. robustness, dependable vs. adaptive systems);", "num_citations": "2\n", "authors": ["523"]}
{"title": "Software development in the post-PC era: towards software development as a service\n", "abstract": " Over the years, software development has evolved to meet the needs of new types of applications and to embrace new technological disruptions. Today, we witness the rise of mobility where the role of the conventional high-end PC is declining. Some refer to this era as the Post-PC era. This technological shift, powered by a key enabling technology, cloud computing, has opened new opportunities for human advancement. Consequently, the evolving landscape of software systems drives the need for new methods for conceiving them. Such methods need to: (a) address the challenges and requirements of this era and (b) embrace the benefits of new technological breakthroughs. In this paper, we list the characteristics of the Post-PC era from the software development perspective and describe two motivating trends of software development processes. Then, we derive a list of requirements for the future\u00a0\u2026", "num_citations": "2\n", "authors": ["523"]}
{"title": "OSLC-based Support for Integrated Development of Dependable Systems\n", "abstract": " Engineering of dependable systems is an inherently heterogenous field and involves the use of a wide range of techniques to analyse different aspects of the system behaviour and properties. Various standards typically prescribe a set of techniques to be used and a development process that should be followed to achieve a high degree of dependability and demonstrate it during certification. In this paper, we address the problem of building integrated environments that implement the processes required for engineering dependable systems. We discuss the use of OSLC (Open Services for Lifecycle Collaborations) \u2013 a rapidly developing industry-driven standard as a technological platform for such integration and present our ongoing work on building an integrated environment for formal development of dependable systems. Our prototype environment spans over requirements engineering, formal modelling and verification in Event-B as well as safety case construction. I. COMPLEMENTARITY AND DIVERSITY IN DEVELOPMENT PROCESS Development of dependable systems is an engineering field that is heavily regulated by standards [1]. Though standards are often criticised for their rigidness, they nevertheless capture the best practices and define recommendations based on decades of experience in engineering and operation of dependable systems. The majority of modern standards adopt process-oriented approaches to dependability assurance, i.e., they prescribe a set of methods and tools to be used to achieve dependability and demonstrate it during certification. Let us note that, despite differences in details, the majority of\u00a0\u2026", "num_citations": "2\n", "authors": ["523"]}
{"title": "Real-time ATO reconfiguration for operational stability\n", "abstract": " This paper briefly describes a technique for improving capacity and operational stability of busy mainline junctions and stations. The technique, called the SafeCap advisory system, employs a mixture of existing train monitoring and control technologies to introduce an advisory control layer on top of fixed-block signalling. We present the main design principles and illustrate the advantages of the proposed solution with some experiments conducted in a train simulation toolkit.", "num_citations": "2\n", "authors": ["523"]}
{"title": "Deployment of formal methods in industry: the legacy of the FP7 ICT DEPLOY integrated project\n", "abstract": " The work of the major EU-funded ICT DEPLOY Integrated Project (February 2008 -- April 2012) on Industrial Deployment of Advanced\\ System Engineering Methods for High Productivity and Dependability [1] was driven by the tasks of achieving and evaluating industrial takeup, initially by DEPLOY industrial partners, of DEPLOY methods and tools, together with the necessary further research on methods and tools. Our previous SEN paper [2] introduced the project. The project has been one of the most significant efforts ever focusing on understanding the issues researchers and engineers face during the deployment of formal methods. This paper briefly reports on the project legacy and provides pointers to the various sources of information produced by the project.", "num_citations": "2\n", "authors": ["523"]}
{"title": "Reminiscences of Whetstone ALGOL\n", "abstract": " These reminiscences centre on the implementation, by Lawford Russell and myself, of an ALGOL 60 compiler for the English Electric KDF9 Computer in the early 1960s. However details are also given of preceding work on so-called\" automatic programming\", and of other contemporary ALGOL compiler projects.", "num_citations": "2\n", "authors": ["523"]}
{"title": "Formal development of cooperative exception handling for mobile agent systems\n", "abstract": " Mobile agent systems often require sophisticated cooperation and coordination during error detection and recovery. In this paper we propose novel fault tolerance mechanisms that support co-operative exception handling in such systems. The paper demonstrates how mechanisms like these can be formally developed and analysed. We start with identifying the typical modes of failures in agents and analysing possible failure and recovery scenarios in mobile systems. Stepwise refinement is used as our formal framework for top-down development and verification. Using the framework we formally verify the essential model properties, such as interoperability, local and global state consistency and termination of error recovery. Our approach provides developers with formal generic patterns for incorporating fault-tolerance mechanisms into mobile agent systems. We also demonstrate how the results of our formal\u00a0\u2026", "num_citations": "2\n", "authors": ["523"]}
{"title": "Towards rigorous engineering of resilient pervasive systems\n", "abstract": " While pervasive systems offer versatile computing environment, their complexity poses a significant challenge to their developers. Hence ensuring resilience of pervasive systems is an important issue, which should be tackled by adopting rigorous design methods and systems approach. In this short paper we identify the key research directions in engineering pervasive resilient systems and our experience in rigorous development of a multi-agent application called Ambient Campus.", "num_citations": "2\n", "authors": ["523"]}
{"title": "Software Engineering for Multi-Agent Systems V: Research Issues and Practical Applications\n", "abstract": " Software is present in every aspect of our lives, pushing us inevitably towards a world of distributed computing systems. Agent concepts hold great promise for responding to the new realities of large-scale distributed systems. Multi-agent systems (MASs) and their underlying theories provide a more natural support for ensuring important agent properties, such as autonomy, environment heterogeneity, organization and openness. Nevertheless, a software agent is an inherently more complex abstraction, posing new challenges to software engineering. Without adequate development te-niques and methods, MASs will not be sufficiently dependable, thus making their wide adoption by the industry more difficult. The dependability of a computing system is its ability to deliver a service that can be justifiably trusted. It is a singular time for dependable distributed systems, since the traditional models we use to express the relationships between a computational process and its environment are changing from the standard deterministic types into ones that are more distributed and dynamic. This served as a guiding principle for planning the Software Engineering for Large-Scale Multi-Agent Systems (SELMAS 2006) workshop, starting with selecting the theme,\u201cbuilding dependable multi-agent systems.\u201d It acknowledges our belief in the increasingly vital role dependability plays as an essential element of MAS development.", "num_citations": "2\n", "authors": ["523"]}
{"title": "RODIN-Rigorous Open Development Environment for Complex Systems\n", "abstract": " RODIN - Rigorous Open Development Environment for Complex Systems - ePrints - Newcastle University Newcastle University Toggle Main Menu Toggle Search Home Browse Latest Stats Policies About Home Browse Latest Policies About Open Access padlock ePrints Browse by author RODIN - Rigorous Open Development Environment for Complex Systems Lookup NU author(s): Professor Alexander Romanovsky Downloads Full text for this publication is not currently held within this repository. Alternative links are provided below where available. Publication metadata Author(s): Romanovsky A Publication type: Article Publication status: Published Journal: Software Engineering Notes Year: 2005 Volume: 30 Issue: 1 Pages: 2 Print publication date: 01/01/2005 ISSN (print): Link to this publication Share Newcastle University \u2026", "num_citations": "2\n", "authors": ["523"]}
{"title": "Developing Systems that Handle Exceptions\n", "abstract": " Modern systems are becoming more complex, and the number of exceptional situations they have to cope with is increasing. The most general way of dealing with these problems is employing exception handling techniques. While a number of object-oriented mechanisms for handling exceptions have been proposed, there are still serious problems with applying them in practice due to complexity of exception code design and analysis, to their improper use, to failure to employ exception handling at the appropriate development phases, to shortage of methodologies supporting correct use of exception handling as well as lack of mechanisms specific to various application domains and design paradigms.", "num_citations": "2\n", "authors": ["523"]}
{"title": "Fault Tolerance through Exception Handling in Ambient and Pervasive Systems\n", "abstract": " 19 October, 2005 SBES 2005\u2022 defines nested fault-tolerant units\u2022 encapsulates internal recovery inside units\u2022 separates normal behaviour from the abnormal one\u2022 introduces and separates normal and abnormal flows of control\u2022 separates normal and abnormal outcomes of the unit\u2022 defines the rules of how normal and exceptional activities are related\u2022 allows recovery to be systematically developed and associated with the units to be executed in the same context", "num_citations": "2\n", "authors": ["523"]}
{"title": "CaberNet Vision of Research and Technology Development in Distributed and Dependable Systems\n", "abstract": " CiteSeerX \u2014 CaberNet Vision of Research and Technology Development in Distributed and Dependable Systems Documents Authors Tables Log in Sign up MetaCart DMCA Donate CiteSeerX logo Documents: Advanced Search Include Citations Authors: Advanced Search Include Citations Tables: DMCA CaberNet Vision of Research and Technology Development in Distributed and Dependable Systems (2004) Cached Download as a PDF Download Links [ddg.jaist.ac.jp] [homepages.cs.ncl.ac.uk] Save to List Add to Collection Correct Errors Monitor Changes by Edited Alexander Romanovsky , Richard Snow Summary Citations Active Bibliography Co-citation Clustered Documents Version History Share Facebook Twitter Reddit Bibsonomy OpenURL Abstract Mueller (Kaiserslautern University), Bernd Reuther (Kaiserslautern University), Keyphrases cabernet vision dependable system technology development \u2026", "num_citations": "2\n", "authors": ["523"]}
{"title": "Exception handling in object oriented systems: Towards emerging application areas and new programming paradigms\n", "abstract": " Exception handling continues to be a challenging problem in object oriented system development. One reason for this is that today\u2019s software systems are getting increasingly more complex. Moreover, exception handling is needed in a wide range of emerging application areas, sometimes requiring domain-specific models for handling exceptions. Moreover, new programming paradigms such as pervasive computing, service oriented computing, grid, ambient and mobile computing, web add new dimensions to the existing challenges in this area. The integration of exception handling mechanisms in a design needs to be based on well-founded principles and formal models to deal with the complexities of such systems and to ensure robust and reliable operation. It needs to be pursued at the very start of a design with a clear understanding of the ensuing implications at all stages, ranging from design\u00a0\u2026", "num_citations": "2\n", "authors": ["523"]}
{"title": "Using exception handling for fault-tolerance in mobile coordination-based environments\n", "abstract": " Mobility of users and code, coupled with todays powerful handheld devices, allows us to anticipate that a class of applications, which will take more and more importance in the next years, is that of mobile agent-based applications. Indeed, handheld devices need light code that can be freely moved from one device to another, according to the user's mobility or needs. Mobile agent-based applications typically run on a mobile coordination-based environment, where programs communicate asynchronously through a shared memory space. There is a number of outstanding issues in providing fault tolerance of such applications. The aim of this paper is to propose an exception handling model suitable for mobile coordination-based environments.", "num_citations": "2\n", "authors": ["523"]}
{"title": "Implementing exceptions in open multithreaded transactions based on Ada 95 exceptions\n", "abstract": " This position paper shows how Ada 95 exceptions have been used in a prototype implementation of a transaction support in order to provide more elaborate exception handling. The paper summarizes the open multithreaded transaction model, which is a transaction model suitable for concurrent programming languages, reviews in detail its elaborate exception handling features, and analyzes the exception mechanism provided by the Ada 95 programming language. Different interfaces to the transaction support for the application programmer are presented, and the problems encountered during implementation of the prototype with respect to exception handling are discussed", "num_citations": "2\n", "authors": ["523"]}
{"title": "Modelling and verification of an atomic action protocol implemented in Ada\n", "abstract": " Ada 95 is an expressive concurrent programming language with which it is possible to build complex multi-tasking applications. Much of the complexity of these applications stems from the interactions between the tasks. This paper argues that Petri nets offer a promising, tool-supported, technique for checking the logical correctness of the tasking algorithms. The paper illustrates the effectiveness of this approach by showing the correctness of an Ada implementation of the atomic action protocol using a variety of Petri net tools, including PED, PEP and INA for P/T nets and Design/CPN for coloured Petri nets.(37 References).", "num_citations": "2\n", "authors": ["523"]}
{"title": "Conversations with fixed and potential participants\n", "abstract": " Sauf mention contraire ci-dessus, le contenu de cette notice bibliographique peut \u00eatre utilis\u00e9 dans le cadre d\u2019une licence CC BY 4.0 Inist-CNRS/Unless otherwise stated above, the content of this bibliographic record may be used under a CC BY 4.0 licence by Inist-CNRS/A menos que se haya se\u00f1alado antes, el contenido de este registro bibliogr\u00e1fico puede ser utilizado al amparo de una licencia CC BY 4.0 Inist-CNRS", "num_citations": "2\n", "authors": ["523"]}
{"title": "Co-opn/2 specifications of the DSGamma system designed using coordinated atomic actions\n", "abstract": " The objectives of this paper are twofold. On the one hand, it aims to show the advantages of Coordinated Atomic actions (CA actions) as a design concept for dependable distributed system development, and on the other hand, it explains how the formal language CO-OPN/2 can be used to express the semantics of CA action design. A fault-tolerant distributed application is developed according to a simple development life cycle: informal requirements, speci cation, design, implementation. The design phase is built according to the CA action concept. The CO-OPN/2 language is used to formally express the design phase. The implementation is made in Java based on a library of generic classes implementing the CA action concept. The paper is to serve as a basis for a more general approach aimed at de ning CA action semantics.", "num_citations": "2\n", "authors": ["523"]}
{"title": "Mutation Testing for Rule-Based Verification of Railway Signaling Data\n", "abstract": " Industry applications of formal verification to signaling control tables require formulation of a large number of mathematical conjectures expressing verification rules. It is paramount to establish the validity and completeness of these conjectures. This article discusses a mutation-based validation technique that guides domain experts in the construction of such verification rules. Furthermore, we use genetic programming to quickly generate millions of well-formed data mutations of control tables and to synthesize mutation programs. The technique is illustrated by a synthetic running example and a discussion of our experience in using it in the industrial setting.", "num_citations": "1\n", "authors": ["523"]}
{"title": "Low-Complexity Run-time Management of Concurrent Workloads for Energy-Efficient Multi-Core Systems\n", "abstract": " Contemporary embedded systems may execute multiple applications, potentially concurrently on heterogeneous platforms, with different system workloads (CPU-or memory-intensive or both) leading to different power signatures. This makes finding the most energy-efficient system configuration for each type of workload scenario extremely challenging. This paper proposes a novel run-time optimization approach aiming for maximum power normalized performance under such circumstances. Based on experimenting with PARSEC applications on an Odroid XU-3 and Intel Core i7 platforms, we model power normalized performance (in terms of instruction per second (IPS)/Watt) through multivariate linear regression (MLR). We derive run-time control methods to exploit the models in different ways, trading off optimization results with control overheads. We demonstrate low-cost and low-complexity run-time algorithms that continuously adapt system configuration to improve the IPS/Watt by up to 139% compared to existing approaches. View Full-Text", "num_citations": "1\n", "authors": ["523"]}
{"title": "Amdahl's law in the context of heterogeneous many\u2010core systems\u2013a survey\n", "abstract": " For over 50 years, Amdahl's Law has been the hallmark model for reasoning about performance bounds for homogeneous parallel computing resources. As heterogeneous, many\u2010core parallel resources continue to permeate into the modern server and embedded domains, there has been growing interest in promulgating realistic extensions and assumptions in keeping with newer use cases. This study aims to provide a comprehensive review of the purviews and insights provided by the extensive body of work related to Amdahl's law to date, focusing on computation speedup. The authors show that a significant portion of these studies has looked into analysing the scalability of the model considering both workload and system heterogeneity in real\u2010world applications. The focus has been to improve the definition and semantic power of the two key parameters in the original model: the parallel fraction (f) and the\u00a0\u2026", "num_citations": "1\n", "authors": ["523"]}
{"title": "Formal distributed protocol development for reservation of railway sections\n", "abstract": " The decentralisation of railway signalling systems has the potential to increase railway network capacity, availability and reduce maintenance costs. Given the safety-critical nature of railway signalling and the complexity of novel distributed signalling solutions, their safety should be guaranteed by using thorough system validation methods. In this paper, we present a rigorous formal development and verification of a distributed protocol for reservation of railway sections, which we believe could deliver benefits of a decentralised signalling while ensuring safety and liveness properties. For the formal distributed protocol development and verification, we devised a multifaceted framework, which aims to reduce modelling and verification effort, while still providing complementary techniques to study protocol from all relevant perspectives.", "num_citations": "1\n", "authors": ["523"]}
{"title": "A customisable pipeline for continuously harvesting socially-minded Twitter users\n", "abstract": " On social media platforms and Twitter in particular, specific classes of users such as influencers have been given satisfactory operational definitions in terms of network and content metrics. Others, for instance online activists, are not less important but their characterisation still requires experimenting. We make the hypothesis that such interesting users can be found within temporally and spatially localised contexts, i.e., small but topical fragments of the network containing interactions about social events or campaigns with a significant footprint on Twitter. To explore this hypothesis, we have designed a continuous user profile discovery pipeline that produces an ever-growing dataset of user profiles by harvesting and analysing contexts from the Twitter stream. The profiles dataset includes key network and content-based users metrics, enabling experimentation with user-defined score functions that\u00a0\u2026", "num_citations": "1\n", "authors": ["523"]}
{"title": "Quantitative validation of formal domain models\n", "abstract": " Application of formal methods to verification of well-formedness and semantic correctness of data sets from a particular domain becomes increasingly practical with the advances in automated verification tools. However, it is difficult for domain experts to understand and formulate formal verification constraints (VCs), yet much trust is invested in their validity and completeness. The paper discusses a novel validation approach based on statistical testing of VCs against pre-validated data sets. We illustrate the proposed technique using a synthetic railway example and also relate our experience of integrating the approach within a large-scale industry-based project.", "num_citations": "1\n", "authors": ["523"]}
{"title": "Droideh: An exception handling mechanism for android applications\n", "abstract": " App crashing is the most common cause of complaints about Android mobile phone apps according to recent studies. Since most Android applications are written in Java, exception handling is the primary mechanism they employ to report and handle errors, similar to standard Java applications. Unfortunately, the exception handling mechanism for the Android platform has two liabilities: (1) the \"Terminate ALL\" approach and (2) a lack of a holistic view on exceptional behavior. As a consequence, exceptions easily get \"out of control\" and, as system development progresses, exceptional control flows become less well-understood, with potentially negative effects on program reliability. This paper presents an innovative exception handling mechanism for the Android platform, named DroidEH, that provides abstractions to support systematic engineering of holistic fault tolerance by applying cross-cutting reasoning\u00a0\u2026", "num_citations": "1\n", "authors": ["523"]}
{"title": "Extending multi-fraction speedup models to normal form heterogeneity\n", "abstract": " Amdahl\u2019s Law is the classical model of parallelization speedup. Its simplistic assumptions have caused it to be extended on multiple occasions to cover wider workload and system realities. This report describes the newest step in the continued extension and generalization of Amdahl\u2019s Law to better cover modern multi-and many-core architectures executing realistic workloads. The key contribution is the vectorization of both parameters of Amdahl\u2019s Law, which allows the representation of wide system architecture heterogeneity and the effects of the parallelism of workloads.", "num_citations": "1\n", "authors": ["523"]}
{"title": "Error-based metric for cross-layer cut determination\n", "abstract": " With the increase of system complexity in both platforms and applications, power modelling of heterogeneous systems is facing grand challenges from the model scalability issue. To address these challenges, this chapter studies two systematic methods: selective abstraction and stochastic techniques. The concept of selective abstraction via black-boxing is realised using hierarchical modelling and cross-layer cuts, respecting the concepts of boxability and error contamination. The stochastic aspect is formally underpinned by Stochastic Activity Networks (SANs). The proposed method is validated with experimental results from Odroid XU3 heterogeneous 8-core platform and is demonstrated to maintain high accuracy while improving scalability.", "num_citations": "1\n", "authors": ["523"]}
{"title": "An Approach for Designing Knowledge-Based Systems for High-Integrity Applications\n", "abstract": " The development of knowledge-based systems (KBSs) has been an area subject to much criticism due to the general lack of structured engineering methods. Although many design and development methods have been proposed and successfully realised, such as CommonKADS, there is still a continuing concern that the reliability of KBSs is difficult to evaluate. This is partly due to the limited incorporation of reliability modelling and validation and verification techniques at various stages of the development life cycle that provide such assurances. Given that current development trends of KBSs indicate a continuing integration with complex, high-integrity systems, it is important to develop KBSs with an engineering process that consolidates rigorous specification and evaluation techniques and methods that ensures the developed software meets the necessary certification standards. This paper presents a proposal\u00a0\u2026", "num_citations": "1\n", "authors": ["523"]}
{"title": "Experience Report: Evaluation of Holistic Fault Tolerance\n", "abstract": " Software maintenance is a crucial phase of the software development life cycle. It is important to facilitate this stage, complying with both functional and non-functional requirements. However, very often the main focus is made on the functional features of the application, whereas fault tolerance mechanisms are neglected and as a result do not provide sufficient maintainability and reusability. In our previous work we introduced the concept of Holistic Fault Tolerance as a novel crosscutting approach to the design and implementation of fault tolerance mechanisms for developing reliable software applications that meet non-functional requirements, such as performance and resource utilisation. This paper evaluates the maintainability of the Holistic Fault Tolerance architecture using experimental analysis of the developer's effort required to implement various modifications of the fault tolerance functionality. The paper starts by justifying the choice of modifications and evaluation techniques. Then the aspect-oriented implementation we proposed for Holistic Fault Tolerance is evaluated by conducting its experimental comparison with a standard objectoriented fault tolerance implementation. The evaluation shows that the implementation with Holistic Fault Tolerance makes fault tolerance mechanisms easier to maintain and ensures higher modularity of the source code.", "num_citations": "1\n", "authors": ["523"]}
{"title": "Resource-driven modelling for managing model fidelity\n", "abstract": " Model complexity is a major concern affecting the design, analysis and runtime management of computing systems. One way of dealing with model complexity is to compromise on the fidelity of a model\u2019s representation of entities and issues that the model is supposed to represent. This chapter describes a resource-driven modelling approach whereby the fidelity of a model can be managed rationally in order to control model complexity. This approach includes two concrete and related methods targeting two aspects of the problem. Dynamic resource graphs highlight the dependencies between system resources and describe a system\u2019s progression as resource and dependency evolution steps. This forms a theoretical foundation for the tracking of parameters that can be regarded as resources, e.g. power consumption, time, computation units, etc. With this resource-oriented view of a system, a hierarchical\u00a0\u2026", "num_citations": "1\n", "authors": ["523"]}
{"title": "Reliability, Safety, and Security of Railway Systems. Modelling, Analysis, Verification, and Certification: First International Conference, RSSRail 2016, Paris, France, June 28\u00a0\u2026\n", "abstract": " This book constitutes the refereed proceedings of the FirstInternational Conference on Reliability, Safety, and Security of RailwaySystems, RSSRail 2016, held in Paris, France, in June 2016. The 15 revised full papers presented were carefully reviewed andselected from 36 initial submissions. The papers cover a wide range oftopics including failure analysis, interlocking verification, formalsystem specification and refinement, security analysis of ERTMS, safetyverification, formalisation of requirements, proof automation, operational security, railway system reliability, risk assessment forERTMS, and verification of EN-50128 safety requirements.", "num_citations": "1\n", "authors": ["523"]}
{"title": "Reliability, safety, and security of railway systems. modelling, analysis, verification, and certification\n", "abstract": " Reliability, Safety, and Security of Railway Systems. Modelling, Analysis, Verification, and Certification - ePrints - Newcastle University Newcastle University Toggle Main Menu Toggle Search Home Browse Latest Stats Policies About Home Browse Latest Policies About Open Access padlock ePrints Browse by author Reliability, Safety, and Security of Railway Systems. Modelling, Analysis, Verification, and Certification Lookup NU author(s): Professor Alexander Romanovsky Downloads Full text is not currently available for this publication. Publication metadata Author(s): Lecomte T, Pinger R, Romanovsky A Series Editor(s): Thierry Lecomte Ralf Pinger Alexander Romanovsky Publication type: Authored Book Publication status: Published Series Title: Programming and Software Engineering Year: 2016 Number of Pages: 261 Print publication date: 01/01/2016 Acceptance date: 01/01/2016 Publisher: Springer \u2026", "num_citations": "1\n", "authors": ["523"]}
{"title": "A formal specification and prototyping language for multi-core system management\n", "abstract": " We relate the experience of a defining a formal domain specific language (DSL) for the construction and reasoning about OS-level management logic of multi-core systems. The approach is based on a novel, iterative development principle where results of prototyping studies feed back into the next language revision. We illustrate the DSL with several examples of executable scripts.", "num_citations": "1\n", "authors": ["523"]}
{"title": "Design and development of the train advisory systems for the future\n", "abstract": " William Blewitt School of Computer Science Newcastle University Newcastle upon Tyne NE1 7RU, UK william. blewitt@ newcastle. ac. uk", "num_citations": "1\n", "authors": ["523"]}
{"title": "Refinement-based Approach to Co-engineering Requirements and Formal Models\n", "abstract": " Formal modelling is widely recognised to contribute to the rigour and comprehensiveness of requirements. At the same time, a formal specification does not offer the flexibility and legibility of informal requirements, expected by system designers and software engineers. In this paper we propose a method and a supporting platform for tightly integrated co-engineering of a requirements document and the corresponding formal specification. We show that bi-directional transformation between requirements and models affects the practice of requirements construction by, arguably, bringing additional rigour and discipline while retaining the flexibility of informal requirements. We report on the experience of applying the OSLC framework to integrate a requirements engineering tool with the Rodin modelling and verification environment. A prototype implementation illustrates the main steps of the proposed approach.", "num_citations": "1\n", "authors": ["523"]}
{"title": "Tooling in DEPLOY\n", "abstract": " Tooling in DEPLOY - ePrints Soton The University of Southampton Courses University life Research Business Global About Visit Alumni Departments News Events Contact \u00d7 Search the Site Search Filter your search: All Courses Projects Staff University of Southampton Institutional Repository Search Advanced Search Policies & Help Latest Download Statistics Browse by Year Browse by Divisions LeftRight Tooling in DEPLOY Butler, Michael, Voisin, Laurent and Muller, Thomas (2013) Tooling in DEPLOY. In, Romanovsky, Alexander and Thomas, Martin (eds.) Industrial Deployment of System Engineering Methods. Springer. Record type: Book Section Full text not available from this repository. More information Published date: 2013 Related URLs: http://www.springer.com/comput...MCS20693_1 Organisations: Electronic & Software Systems Learn more about Cyber Physical Systems research Identifiers Local EPrints \u2026", "num_citations": "1\n", "authors": ["523"]}
{"title": "After and Outside DEPLOY: The DEPLOY Ecosystem\n", "abstract": " This chapter introduces the DEPLOY ecosystem that has been created over the project lifetime and will live on after its end to ensure that its results, including the methods and tools built for it, are widely used, extended and explored, and that the community of its industrial and academic users continues to grow. This ecosystem will help reassure newcomers that the community is active, welcoming and prepared to share the knowledge and experience accumulated. The primary aim of this work was to develop support for the growing community of companies using Event-B and Rodin.", "num_citations": "1\n", "authors": ["523"]}
{"title": "Engineering Resilient Systems: Models, Methods and Tools (Dagstuhl Seminar 13022)\n", "abstract": " Software-intensive systems are becoming widely used in such critical infrastructures as railway, air-and road traffic, power management, health care and banking. In spite of drastically increased complexity and need to operate in unpredictable volatile environment, high dependability remains a must for such systems. Resilience--the ability to deliver services that can be justifiably trusted despite changes-is an evolution of the dependability concept. It adds several new dimensions to dependability concepts including adaptability to evolving requirements and proactive error prevention. To address these challenges we need novel models, methods and tools that enable explicit modeling of resilience aspects and reasoning about them. The Dagstuhl Seminar 13022\" Engineering Resilient Systems: Models, Methods and Tools\" discussed the most promising techniques for achieving resilience both at the system design stage and at runtime. It brought together researchers from dependability, formal methods, fault tolerance and software engineering communities that promoted vivid cross-disciplinary discussions.", "num_citations": "1\n", "authors": ["523"]}
{"title": "A method for rigorous development of fault-tolerant systems\n", "abstract": " With the rapid development of information systems and our increasing dependency on computer-based systems, ensuring their dependability becomes one the most important concerns during system development. This is especially true for the mission and safety critical systems on which we rely not to put signi cant resources and lives at risk. Development of critical systems traditionally involves formal modelling as a fault prevention mechanism. At the same time, systems typically support fault tolerance mechanisms to mitigate runtime errors. However, fault tolerance modelling and, in particular, rigorous de nitions of fault tolerance requirements, fault assumptions and system recovery have not been given enough attention during formal system development. The main contribution of this research is in developing a method for top-down formal design of fault tolerant systems. The re nement-based method provides modelling guidelines presented in the following form:   a set of modelling principles for systematic modelling of fault tolerance,   a fault tolerance re nement strategy, and   a library of generic modelling patterns assisting in disciplined integration of error detection and error recovery steps into models. The method supports separation of normal and fault tolerant system behaviour during modelling. It provides an environment for explicit modelling of fault tolerance and modal aspects of system behaviour which ensure rigour of the proposed development process. The method is supported by tools that are smoothly integrated into an industry-strength development environment. The proposed method is demonstrated on two case studies. In\u00a0\u2026", "num_citations": "1\n", "authors": ["523"]}
{"title": "Intrusion-avoidance via system diversity\n", "abstract": " The paper discusses a generic intrusion-avoidance architecture allowing the system architects to decrease the risk of intrusions. The architecture employs software diversity at various system levels and dynamically reconfigures the deployment environment to avoid intrusions. This solution reduces the so-called system\u2019s days-of-risk which is a period of an increased security risk between the time when a vulnerability is publicly disclosed to the time when a patch is available to fix it. To select the less vulnerable system configuration we propose metrics estimating security risks by accounting a number of not-fixed vulnerabilities and their severity.", "num_citations": "1\n", "authors": ["523"]}
{"title": "On Fault Tolerance Reuse during Re\ufb01nement\n", "abstract": " Complex modern applications have to be developed to be dependable to meet their requirements and expectations of their users. An important part of this is their ability to deal with various threats (such as faults in the system environment, operator's mistakes, underlying hardware and software support problems). Development of modern applications is complicated by the need for systematic and rigorous integration of fault tolerance measures. The paper focuses on reuse of fault tolerance modelling. First, it introduces the idea of general modelling templates reflecting abstract views on system behaviour with respect to faults. These templates are used during system detalisation (re finement) to capture the user's view on system external behaviour. Secondly, it proposes to use a library of concrete modelling patterns allowing developers to systematically integrate speci c fault tolerance mechanisms (e.g. recovery blocks, checkpoints, exception handling) into the models. The proposed solutions are linked to the Event-B method and demonstrated using a case study.", "num_citations": "1\n", "authors": ["523"]}
{"title": "System Architecture, Dependability and Modes\n", "abstract": " The mode, defining the specific type of functional behaviour that a system exhibits during its operation, is an important architectural level concept, which has a significant impact on system design, verification and dependability. The notions of modes and mode changes are widely used by the industrial engineers to structure reasoning about different conditions of system functioning. Even though there has been some work on developing modal systems, we still lack a general understanding of how to architect, verify and ensure dependability of such systems. In our work we rely on formal modelling and verification to study intricate relationships between fault tolerance, operation modes and architectural design.", "num_citations": "1\n", "authors": ["523"]}
{"title": "Guest Editors' Introduction to the Special Section on Exception Handling: From Requirements to Software Maintenance\n", "abstract": " SINCE their first appearance in the 1970s, exception handling models in mainstream programming languages, frameworks, and platforms have not changed much. Modern exception handling mechanisms obviously differ in how to specify exceptions and their handlers, how to declare exceptions in module interfaces, how to specify protected regions, and how to continue the control flow after exceptions have been handled. However, these differences are insignificant, and exception handling models still rely on the same well-known traditional principles for structuring error recovery in software systems, such as supporting explicit separation between normal and exceptional behaviors.Moreover, exception handling is still an afterthought issue and not much support for it has been provided throughout the software process, from requirement elicitation to software maintenance and evolution. With the heterogeneity and complexity of contemporary software applications growing, there is a pressing need for an indepth reflection about the most appropriate mechanisms and methods for exception handling across the software lifecycle. Sometimes, given the increasing uncertainty in open software systems, it is even necessary to identify and apply more dynamic mechanisms for exception handling. In fact, modern software applications, such as contextaware mobile systems and service-based processes, pose new error handling challenges, partly because they cannot be designed as a coherent whole. Their decentralized character means that collaborative exception handling is potentially more difficult to develop correctly and consistently. Separate\u00a0\u2026", "num_citations": "1\n", "authors": ["523"]}
{"title": "Towards Automated Refinement: Patterns in Event B\n", "abstract": " Formal modelling is indispensable for engineering highly dependable systems. However, a wider acceptance of formal methods is hindered by their insufficient usability and scalability. In this paper, we aim at assisting developers in rigorous modelling and design by increasing automation of development steps. We introduce a notion of refinement patterns\u2013generic representations of typical correctness-preserving model transformations. Our definition of a refinement pattern contains a description of syntactic model transformations, as well as the pattern applicability conditions and proof obligations for verification of correctness preservation. This establishes a basis for building a tool supporting formal system development via pattern reuse and instantiation. We present a prototype of such a tool and some examples of refinement patterns for automated development in the Event B formalism.", "num_citations": "1\n", "authors": ["523"]}
{"title": "Formal Development of the BepiColombo Pilot\n", "abstract": " Formal development of the Bepi Colombo pilot Page 1 Formal development of the Bepi Colombo pilot Linas Laibinis, Elena Troubitsyna (\u00c5AU) together with Alexei Iliasov, Alexander Romanovsky (NU) Page 2 \uf097 Summer 2008 \u2013 a large collection of requirements documents \uf097 August 2008 \u2013 \u201cwhite paper\u201d describing modelling approach for Bepi Colombo \uf097 October 2008 \u2013 formal models for Bepi Colombo produced by SSF \uf097 November 2008 \u2013 analysis of SSF development and a proposal for alternative development Page 3 \uf097 Formal modelling of service-oriented development \u25e6 Different types of incoming service requests (tele-commands) and outcoming responses (tele-messages) \u25e6 Different tasks: producing scientific data or housekeeping/diagnostic reports, changing execution modes and control flags Page 4 \uf097 Separate layers for core software and application software \u25e6 The core software (CSW) serves as general \u2026", "num_citations": "1\n", "authors": ["523"]}
{"title": "FSE16 Foundation of Software Engineering\n", "abstract": " FSE16 Foundation of Software Engineering - LIRMM - Laboratoire d\u2019Informatique, de Robotique et de Micro\u00e9lectronique de Montpellier Acc\u00e9der directement au contenu Acc\u00e9der directement \u00e0 la navigation Toggle navigation CCSD HAL HAL HALSHS TEL M\u00e9diHAL Liste des portails AUR\u00e9HAL API Data Documentation Episciences.org Episciences.org Revues Documentation Sciencesconf.org Support Portail Hal-Lirmm Hal-Lirmm - Archives Ouvertes HAL Accueil Consulter Consultation par p\u00e9riode Consultation par auteur Consultation par type de publication Consultation par revue Consultation par conf\u00e9rence Consultation par ANR Consultation par discipline Consultation par collections Consultation des derniers d\u00e9p\u00f4ts Rechercher D\u00e9poser Outils Id\u00e9es re\u00e7ues... Rapport HC\u00c9RES lirmm-00377319, version 1 Ouvrage (y compris \u00e9dition critique et traduction) FSE16 Foundation of Software Engineering: 4th \u2026", "num_citations": "1\n", "authors": ["523"]}
{"title": "Formal Refinement Automation\n", "abstract": " Formal methods focus on a posteriori analysis and a modeller gets little assistance in constructing a model which makes formal modelling more expensive and laborious than it could be. In this paper we discuss a mechanism for automation of formal refinement based on reusable refinement steps, called refinement patterns. Refinement patterns offer a constructive top-down approach to formal modelling; for many patterns, correctness can be proved once-for-all. The approach is illustrated with the discussion of Event-B refinement patterns and a tool supporting pattern-based Event-B developments.", "num_citations": "1\n", "authors": ["523"]}
{"title": "Mobile B Systems\n", "abstract": " Mobile agent systems (MAS) are complex distributed systems that are dynamically composed from communicating autonomous components. In this paper we introduce high level programming notation for the specification of MAS. This notation can faithfully capture both the behavioral and the functional model of a mobile agent. Furthermore, we provide its structured operational semantics through a set of rewriting rules together with a brief presentation of the supporting tool.", "num_citations": "1\n", "authors": ["523"]}
{"title": "Generic Framework for the Engineering of Self-Adaptive and Self-Organising Systems\n", "abstract": " This paper provides a unifying view for the engineering of self-adaptive (SA) and self-organising (SO) systems. We first identify requirements for designing and building trustworthy self-adaptive and self-organising systems. Second, we propose a generic framework combining design-time and run-time features, which permit the definition and analysis at design-time of mechanisms that both ensure and constrain the run-time behaviour of an SA or SO system, thereby providing some assurance of its self-* capabilities. We show how this framework applies to both an SA and an SO system, and discuss several current proof-of-concept studies on the enabling technologies.", "num_citations": "1\n", "authors": ["523"]}
{"title": "Improving Service Availability without Improving Availability of Individual Services\n", "abstract": " This paper presents a novel architectural solution for improving dependability of Web Services. This approach is based on the concepts from the emerging resilience-explicit computing combined with the traditional fault-tolerance techniques such as recovery blocks and N-version programming applied in the context of the service-oriented architecture. We propose a distributed solution called WS-Mediator, which is implemented as an overlay network of specialized services. The globally distributed architecture of the WS-Mediator system collects dependability metadata from the end-user\u2019s perspective, analyses them and acts upon them to tolerate faults using dynamic reconfiguration. Therefore to improve dependability of Web Services by introducing service redundancy. We have implemented a Java WS-Mediator framework based upon WS-Mediator concept, which can be easily integrated into implementation of Java Web Services applications. We report the results of the extensive experiments conducted in the context of the bioinformatics domain, in which we demonstrate the applicability of our approach.", "num_citations": "1\n", "authors": ["523"]}
{"title": "Investigative Case Study: Protective Wrapping of OTS items in Simulated Environments\n", "abstract": " This practical experience report summarises the lessons learned during investigation of a case study which focused on engineering protective wrappers as a means of detecting and tolerating errors or undesirable behaviour in systems employing OTS components. We developed a protective wrapper capable of dealing with typical errors caused by unavailability of signals, violations of range limitations, and oscillations. The work was carried out in a simulation environment using a Simulink model of an industrial steam boiler system together with an OTS PID (Proportional, Integral and Derivative) controller. The lessons learned from the development of, and experimentation with, our case study are categorised as: those relating specifically to the use of Simulink for system modelling; those that concern the use of simulation more generally, as a means of analysing design options; and those that inform the development of protective wrappers.", "num_citations": "1\n", "authors": ["523"]}
{"title": "Exception handling in object oriented systems\n", "abstract": " Exception handling continues to be a challenging problem in object oriented system design. One reason for this is that today\u2019s software systems are getting increasingly more complex. Moreover, exception handling is needed in a wide range of application systems, sometimes requiring domain-specific models for handling exceptions. Also, concurrency, distribution, and code mobility add new dimensions to the existing challenges in this area. The integration of exception handling mechanisms in a design needs to be based on well- founded principles and formal models to deal with the complexities of such systems and to ensure robust and reliable operation. It needs to be pursued at the very start of a design with a clear understanding of the ensuing implications at all stages, ranging from design specification, implementation, operation, maintenance, and evolution. This workshop was structured around the\u00a0\u2026", "num_citations": "1\n", "authors": ["523"]}
{"title": "Object Persistence: A Framework Based On Design Patterns\n", "abstract": " This poster presents a framework providing persistence support for object-oriented programming languages without modifying the run-time system or the language itself. It does only rely on basic object-oriented programming techniques, and can therefore be implemented in any object-oriented programming language. It is based on design patterns. Its strengths are:", "num_citations": "1\n", "authors": ["523"]}
{"title": "The domino effect as a deadlock\n", "abstract": " The possibility of effects like an unpredictable growth of resource and computation time losses and of expenditures on recovery (eg the domino effect) makes backward recovery schemes unpracticable for systems with high fault-tolerance requirements, although they have a number of advantages. The main purpose of this paper is to propose a formal model of the execution of concurrent programs, in which the domino effect can happen, and of the way this effect can be detected statically by analysing the programs. In particular, this can be done by reducing the domino effect problem to that of detecting a deadlock condition. This would allow the existing techniques for analysing the correctness of concurrent systems and detecting deadlocks statically to be used to analyse the properties of recovering systems and statically obtain additional information on the behaviour of concurrent systems in the event of a fault and rollback. By performing a static analysis of all system paths (which relies on looking through the entire reachability tree of process joint behaviours), several behavioural system properties concerning recovery can be checked prior to system use. Detecting bottle-necks at the system design stage will help to avoid unpredictable resource expenditures, and their elimination will help to ensure certain properties of system behaviour when recovering from faults.", "num_citations": "1\n", "authors": ["523"]}
{"title": "Predictable toleration of design faults: Recovery blocks in real time systems\n", "abstract": " The purpose of the paper is to present a recovery block (RB) scheme that is suitable for a real time application. For this purpose, it has to have a predictable fault tolerant behaviour. We analyze the basic problems to be tackled for introducing the RB scheme into real time systems and propose some approaches and solutions allowing to handle them. Steps of calculating the RB worst case execution time are discussed; in particular, several approaches to reducing this time and making it easier to estimate more precisely are considered. We address the problems of the RB implementation and the original language construct extensions which allow to guarantee the predictability of the RB behaviour in the run time. In particular, features which guarantee the fault tolerance of the RB scheme and, as a result, allow to predict its behaviour in cases of software and hardware faults are discussed. The differences between\u00a0\u2026", "num_citations": "1\n", "authors": ["523"]}
{"title": "CO-OPN/2 Specification of the DSGamma System Designed Using Co-ordinated Atomic Actions\n", "abstract": " The objective of this paper are twofold. On the one hand, it sims to show the advantages of Co-ordinated Atomic actions (CA actions) as a design concept for dependable distributed system development, and on the other hand, it explains how the formal language CO-OPN/2 can be used to express the semantics of CA action design. A fault-tolerant distributed application is developed according to a simple development life cycle: informal requirements, specification, design, implementation. The design phase is built according to the CA action concept. The CO-OPN/2 language is used to formally express the design phase. The implementation is made in Java based on a library of generic classes implementing the CA action concept. The paper is to seve as a basis for a more general approach aimed at defining CA action semantics.", "num_citations": "1\n", "authors": ["523"]}
{"title": "Object-oriented approach to state restoration by reversion in fault tolerant systems\n", "abstract": " This paper describes an approach to providing object state restoration in fault tolerant (FT) objectoriented (OO) computing systems by means of a reversion strategy. The unit of reversion is an object method. Two primitives are introduced that are used for creating a reverse-recoverable (RR) object: state saving primitive save and state restoring primitive restore. Reverse operations are processed in the order specified by a third primitive, undo. It is demonstrated how the approach suggested can be generalised to build a hierarchy of RR objects in the case of inheritance. The implementation of the approach is described for both the entire system and a separate object. The requirements for reverse operations are analysed. Finally, preferable areas of reversion applicability are discussed.", "num_citations": "1\n", "authors": ["523"]}
{"title": "A distributed coordinated atomic action scheme\n", "abstract": " Coordinated Atomic actions have proved to be a very general concept which can be successfully applied for structuring complex concurrent systems consisting of elements which both cooperate and compete. The canonical Coordinated Atomic action is built of several cooperating participants (roles) and a set of local objects which represent the action state and provide the feature for cooperation. In addition, Coordinated Atomic actions can compete for external objects which have conventional transactional properties. The intention of this paper is to offer a general approach to designing distributed Coordinated Atomic action schemes. Problems of action components partitioning and distribution are discussed. We consider ways of dealing with external and local objects within distributed Coordinated Atomic action schemes; several proposals are discussed in detail. The approach proposed relies on using forward error recovery in the form of distributed and concurrent exception handling and resolution. After discussing the general approach, we demonstrate how it can be applied when the standard distributed model of Ada 95 is used. The presentation of the scheme is sufficiently detailed for it to be used in practice. In particular, a thorough description of the action support and all patterns (skeletons) required for designing application software are given.", "num_citations": "1\n", "authors": ["523"]}
{"title": "On a scheme for backward recovery in complex systems including both client processes and data servers\n", "abstract": " We discuss a design scheme for co-ordinated backward recovery in complex systems. This report concludes a series of papers on this topic. We give the rationale of our proposed approach, a complete, reasoned specification of the mechanisms, a comparison with other related research, and pointers to other papers describing proof-of-concept examples of use and implementation of this scheme..We consider backward error recovery for complex software systems, where different subsystems may belong to essentially different application areas, like databases and process control. Examples of such systems are found in modern telecommunication, transportation, manufacturing and military applications. Such heterogeneous subsystems are naturally built according to different design\" models\", viz. the\" object-action\" model (where the long-term state of the computation is encapsulated in data objects, and active processes invoke operations on these objects), and the\" process-conversation\" model (where the state is contained in the processes, communicating via messages). To allow backward error recovery in these two\" models\" of computation, two different schemes are most appropriate. For the object-action model of computation, atomic transactions are now the accepted model of backward recovery. For the process-conversation model, a recovery scheme based on planned conversations has been widely studied. We have shown how checkpointing and roll-back can be co-ordinated between two sets of such heterogeneous subsystems, namely sets of message passing processes organised in conversations and data servers offering atomic\u00a0\u2026", "num_citations": "1\n", "authors": ["523"]}
{"title": "Dynamic conversions\n", "abstract": " Dynamic conversions \u041f\u041e\u0418\u0421\u041a \u041d\u0410\u0412\u0418\u0413\u0410\u0422\u041e\u0420 \u041d\u0430\u0447\u0430\u043b\u044c\u043d\u0430\u044f \u0441\u0442\u0440\u0430\u043d\u0438\u0446\u0430 \u041a\u0430\u0442\u0430\u043b\u043e\u0433 \u0436\u0443\u0440\u043d\u0430\u043b\u043e\u0432 \u0410\u0432\u0442\u043e\u0440\u0441\u043a\u0438\u0439 \u0443\u043a\u0430\u0437\u0430\u0442\u0435\u043b\u044c \u0421\u043f\u0438\u0441\u043e\u043a \u043e\u0440\u0433\u0430\u043d\u0438\u0437\u0430\u0446\u0438\u0439 \u0422\u0435\u043c\u0430\u0442\u0438\u0447\u0435\u0441\u043a\u0438\u0439 \u0440\u0443\u0431\u0440\u0438\u043a\u0430\u0442\u043e\u0440 \u041f\u043e\u0438\u0441\u043a\u043e\u0432\u044b\u0435 \u0437\u0430\u043f\u0440\u043e\u0441\u044b \u041d\u043e\u0432\u044b\u0435 \u043f\u043e\u0441\u0442\u0443\u043f\u043b\u0435\u043d\u0438\u044f \u041d\u0430\u0441\u0442\u0440\u043e\u0439\u043a\u0430 \u0421\u0415\u0421\u0421\u0418\u042f \u041a\u041e\u041d\u0422\u0410\u041a\u0422\u042b \u0418\u041d\u0424\u041e\u0420\u041c\u0410\u0426\u0418\u042f \u041e \u041f\u0423\u0411\u041b\u0418\u041a\u0410\u0426\u0418\u0418 DYNAMIC CONVERSIONS ROMANOVSKY AB* 1 , SHTURTZ IV 1 1 Applied Mathematics Department, St. Petersburg State Tech. Univ., St Petersburg 195251 \u0422\u0438\u043f: \u0441\u0442\u0430\u0442\u044c\u044f \u0432 \u0436\u0443\u0440\u043d\u0430\u043b\u0435 - \u043d\u0430\u0443\u0447\u043d\u0430\u044f \u0441\u0442\u0430\u0442\u044c\u044f \u042f\u0437\u044b\u043a: \u0430\u043d\u0433\u043b\u0438\u0439\u0441\u043a\u0438\u0439 \u0422\u043e\u043c: 11 \u041d\u043e\u043c\u0435\u0440: 2 \u0413\u043e\u0434: 1996 \u0421\u0442\u0440\u0430\u043d\u0438\u0446\u044b: 109-116 \u0416\u0423\u0420\u041d\u0410\u041b: COMPUTER SYSTEMS SCIENCE AND ENGINEERING \u0418\u0437\u0434\u0430\u0442\u0435\u043b\u044c\u0441\u0442\u0432\u043e: CRL Publishing Ltd. ISSN: 0267-6192 \u0411\u0418\u0411\u041b\u0418\u041e\u041c\u0415\u0422\u0420\u0418\u0427\u0415\u0421\u041a\u0418\u0415 \u041f\u041e\u041a\u0410\u0417\u0410\u0422\u0415\u041b\u0418: \u0412\u0445\u043e\u0434\u0438\u0442 \u0432 \u0420\u0418\u041d\u0426 \u00ae : \u0434\u0430 \u0426\u0438\u0442\u0438\u0440\u043e\u0432\u0430\u043d\u0438\u0439 \u0432 \u0420\u0418\u041d\u0426 \u00ae : 0 \u0412\u0445\u043e\u0434\u0438\u0442 \u0432 \u044f\u0434\u0440\u043e \u0420\u0418\u041d\u0426 \u00ae : \u0434\u0430 \u0426\u0438\u0442\u0438\u0440\u043e\u0432\u0430\u043d\u0438\u0439 \u0438\u0437 \u044f\u0434\u0440\u0430 \u0420\u0418\u041d\u0426 \u00ae : 0 \u0412\u0445\u043e\u0434\u0438\u0442 \u0432 Scopus \u00ae : \u0426\u0438\u0442\u0438\u0440\u043e\u0432\u0430\u043d\u0438\u0439 \u0432 Scopus \u00ae : \u0412\u0445\u043e\u0434\u0438\u0442 \u0432 Web of Science \u00ae : <t\u2026", "num_citations": "1\n", "authors": ["523"]}
{"title": "Software diversity as a way to well-structured concurrent software\n", "abstract": " We assume that a system consists of components (programs, processes, tasks, threads, objects, etc.) which can be executed concurrently and which can communicate during this execution. There are a lot of sophisticated facilities to support interaction. It can exist in the forms of message passing, signals, rendezvous, variable sharing; it can occur together with the control flow movement when information is transferred between components as a set of parameters (remote procedure calls); it can be synchronous or asynchronous, etc. We will follow the generalized classification of concurrent systems that is arrived at in [1]. Three categories of these are outlined here; they are independent, competing and cooperating systems.Generally speaking, competitive concurrency exists when two or more components are designed separately and use the same system resources (which are components as well). So, the former\u00a0\u2026", "num_citations": "1\n", "authors": ["523"]}
{"title": "The problems of designing a conversation scheme for concurrent object oriented languages\n", "abstract": " The paper discusses the problems to be tackled while designing conversation schemes for concurrent object oriented languages (COOLs). Some approaches to solving these problems and to using conversations in COOLs in the most appropriate ways are proposed. The most relevant characteristics of these languages with respect to conversation scheme design are outlined. The paper attempts to define all accessories of the conversation concept within the concurrent object oriented paradigm. It is considered how the peculiarities of COOLs (such as inheritance, concurrency control, reuse of the concurrency control code) can facilitate the use of conversation schemes. Worthwhile directions of future research are pointed out.", "num_citations": "1\n", "authors": ["523"]}