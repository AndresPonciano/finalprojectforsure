{"title": "ScanDal: Static analyzer for detecting privacy leaks in android applications\n", "abstract": " Smartphone applications can steal users\u2019 private data and send it out behind their back. The worldwide Android smartphone market is growing, which raises security and privacy concerns. However, current Android\u2019s permissionbased approach is not enough to ensure the security of private information.In this paper, we present SCANDAL, a sound and automatic static analyzer for detecting privacy leaks in Android applications. We analyzed 90 popular applications using SCANDAL from Android Market and detected privacy leaks in 11 applications. We also analyzed 8 known malicious applications from third-party markets and detected privacy leaks in all 8 applications.", "num_citations": "257\n", "authors": ["683"]}
{"title": "Proofs about a folklore let-polymorphic type inference algorithm\n", "abstract": " The Hindley/Milner let-polymorphic type inference system has two different algorithms: one is the de factostandard Algorithm \ud835\udcb2 that is bottom-up (or context-insensitive), and the other is a \u201cfolklore\u201d algorithm that is top-down (or context-sensitive). Because the latter algorithm has not been formally presented with its soundness and completeness proofs, and its relation with the \ud835\udcb2 algorithm has not been rigorously investigated, its use in place of (or in combination with) \ud835\udcb2 is not well founded. In this article, we formally define the context-sensitive, top-down type inference algorithm (named \u201cM\u201d), prove its soundness and completeness, and show a distinguishing property that M always stops earlier than \ud835\udcb2 if the input program is ill typed. Our proofs can be seen as theoretical justifications for various type-checking strategies being used in practice.", "num_citations": "142\n", "authors": ["683"]}
{"title": "Taming false alarms from a domain-unaware C analyzer by a bayesian statistical post analysis\n", "abstract": " We present our experience of combining, in a realistic setting, a static analyzer with a statistical analysis. This combination is in order to reduce the inevitable false alarms from a domain-unaware static analyzer. Our analyzer named Airac(Array Index Range Analyzer for C) collects all the true buffer-overrun points in ANSI C programs. The soundness is maintained, and the analysis\u2019 cost-accuracy improvement is achieved by techniques that static analysis community has long accumulated. For still inevitable false alarms (e.g. Airac raised 970 buffer-overrun alarms in commercial C programs of 5.3 million lines and 737 among the 970 alarms were false), which are always apt for particular C programs, we use a statistical post analysis. The statistical analysis, given the analysis results (alarms), sifts out probable false alarms and prioritizes true alarms. It estimates the probability of each alarm being true. The\u00a0\u2026", "num_citations": "124\n", "authors": ["683"]}
{"title": "Design and implementation of sparse global analyses for C-like languages\n", "abstract": " In this article we present a general method for achieving global static analyzers that are precise, sound, yet also scalable. Our method generalizes the sparse analysis techniques on top of the abstract interpretation framework to support relational as well as non-relational semantics properties for C-like languages. We first use the abstract interpretation framework to have a global static analyzer whose scalability is unattended. Upon this underlying sound static analyzer, we add our generalized sparse analysis techniques to improve its scalability while preserving the precision of the underlying analysis. Our framework determines what to prove to guarantee that the resulting sparse version should preserve the precision of the underlying analyzer.", "num_citations": "110\n", "authors": ["683"]}
{"title": "Automatic generation and management of interprocedural program analyses\n", "abstract": " We have designed and implemented an interprocedural program analyzer generator, called system Z. Our goal is to automate the generation and management of semantics-based interprocedural program analysis for a wide range of target languages.", "num_citations": "94\n", "authors": ["683"]}
{"title": "Selective context-sensitivity guided by impact pre-analysis\n", "abstract": " We present a method for selectively applying context-sensitivity during interprocedural program analysis. Our method applies context-sensitivity only when and where doing so is likely to improve the precision that matters for resolving given queries. The idea is to use a pre-analysis to estimate the impact of context-sensitivity on the main analysis's precision, and to use this information to find out when and where the main analysis should turn on or off its context-sensitivity. We formalize this approach and prove that the analysis always benefits from the pre-analysis-guided context-sensitivity. We implemented this selective method for an existing industrial-strength interval analyzer for full C. The method reduced the number of (false) alarms by 24.4%, while increasing the analysis cost by 27.8% on average.", "num_citations": "90\n", "authors": ["683"]}
{"title": "A polymorphic modal type system for lisp-like multi-staged languages\n", "abstract": " This article presents a polymorphic modal type system and its principal type inference algorithm that conservatively extend ML by all of Lisp's staging constructs (the quasi-quotation system). The combination is meaningful because ML is a practical higher-order, impure, and typed language, while Lisp's quasi-quotation system has long evolved complying with the demands from multi-staged programming practices. Our type system supports open code, unrestricted operations on references, intentional variable-capturing substitution as well as capture-avoiding substitution, and lifting values into code, whose combination escaped all the previous systems.", "num_citations": "80\n", "authors": ["683"]}
{"title": "Interprocedural exception analysis for Java\n", "abstract": " ABSTRACT\u00a9 A\u00aaH\u00aaH p \u00abU\u00ac &\u00ae UU S\u00a3 P\u00b1\u00a2 p\u00a6 \u00aai \u00aaH\u00a6 \u00b2 H\u00a3 p\u00a3\u00a4 A\u00a3 P 1\u00a2 A\u00aaH\u00a3 P U\u00aa e\u00a5 \u00aa \u00b3 4 H\u00a2 r\u00a6 rww R\u00a3 P \u00b5}\u00a3 P\u00aa4 A\u00b6 P t\u00b7 ept H ot A we AP po\u00a1 p\u00a2 AR\u00a3 PA\u00a3 w\u00b5\u00b1HA \u00abA\u00a2 t A i\u00a2 A\u00aaH\u00a3 P P\u00aa w\u00a3 \u00b9R\u00a3 A\u00a3 P iw \u00a7 r\u00a3 P\u00aa w H \u00ba S t\u00a3 U t U@ H\u00a3\u00aaH\u00a5\u00a3 e U\u00a3\u00a2 A\u00aaH\u00a3 P U\u00aa e\u00b1\u00b1S\u00aa \u00b3\u00b1AA t SH e\u00aaH\u00a4 \u00a7 e A\u00e4 \u00aaH q\u00bb} \u00bc\" t\u00a4\u00a2 A\u00aaH\u00a3 P U\u00aa e\u00a5 \u00aa \u00b3\" H\u00a2 r S\u00a6 re R\u00a3 P \u00a7 \u00b1w\u00aaH H\u00a3 p\u00a3 wp A\u00bdC A\u00a3 P\u00aa\u00be HAPUH \u00be H\u00a3\u00a2 A\u00aaH\u00a3 P U\u00aa e\u00a5 \u00aaH\u00b1\u00b5}\u00a3 P\u00aa\u00b1H\u00a2 \u00a7 \u00a6\u00bf S \u00a7 e A\u00e4\u00a6 AP\u00bb} \u00bc\" A \u00c0\u00a2 A\u00aaH\u00a3 P U\u00aa e\u00b1\u00b1S\u00aa \u00b3 H\u00a2 r\u00a6\u00a5 \u00a7 ww R\u00a3 PA\u00a3 w\u00aaH H\u00a3 p\u00a3\u00a3 PS t \u00aa \u00bd q \u00c1 \u00ab\u00a2 A\u00aaH\u00a3 P\u00a2 r\u00a3 UH i\u00a3 H e R \u00b2 wrp R \u00c2\u00a3 w\u00b5 UU \u00be\u00a2 A\u00aaH\u00a3 P P\u00aa w\u00b1H \u00a7 e 4 HR w HHA \u00aa S\u00a1 p\u00a2 AR\u00a3 P\u00b1\u00c3r\u00a3 w\u00bc\"\u00a5 t\u00c4\u00a2 rp\u00a5 \u00c4 p R\u00a3 w\u00b5 HA\u00a2 t\u00aaH\u00a3 U P\u00aa w\u00b1\u00b1\u00aa \u00b3 TH\u00a2 r\u00a6 \u00a7 ww R\u00a3 PA e\u00b2 \u00c4\" ae \u00a7 p R\u00b1\u00c4 RU t \u00c5 e A\u00c0\u00b1\u00a2 p\u00b1p HS@ \u00a7\u00a7 e H 1\u00a3 U \u00c0 HR\u00a5 \u00c6\u00a3 U t H H\u00aa p\u00a3 \u00b5} \u00aa e\u00a5 \u00bco\u00a3 P\u00aaH\u00b6 r \u00b9\u00c6 H\"\u00a3 PHR\u00a5 \u00c6 \u00c7# SRPAH \u00be & H t UPHH \u00ef \u00a7 p \u00b2 H\u00a2 r w\u00aaH H qe \u00a7 p\u00bf\u00a5 A\u00a3 HA\u00a2 t\u00aaH\u00a3 U P\u00aa e\u00c8 e \u00be H t\u00a3 pp\u00a5} P \u00be\u00bb} AA\u00b1\u00aaH \u00c4 tti HA p A\u00a5 \u00a7\u00a7 \u00aa\u00a3 e\u00b5 A t\u00b6 p A\u00a3 w\u00bcC A\u00a3 \u00c0 HA\u00a0\u2026", "num_citations": "80\n", "authors": ["683"]}
{"title": "Practical memory leak detector based on parameterized procedural summaries\n", "abstract": " We present a static analyzer that detects memory leaks in C programs. It achieves relatively high accuracy at a relatively low cost on SPEC2000 benchmarks and several open-source software packages, demonstrating its practicality and competitive edge against other reported analyzers: for a set of benchmarks totaling 1,777 KLOCs, it found 332 bugs with 47 additional false positives (a 12.4% false-positive ratio), and the average analysis speed was 720 LOC/sec.", "num_citations": "70\n", "authors": ["683"]}
{"title": "An uncaught exception analysis for Java\n", "abstract": " Current JDK Java compiler relies on programmer's declarations (by throws clauses) for checking against uncaught exceptions of the input program. It is not elaborate enough to remove programmer's unnecessary handlers nor suggest to programmers for specialized handlings (when programmer's declarations are too broad). We propose a static analysis of Java programs that estimates their uncaught exceptions independently of the programmer's declarations. This analysis is designed and implemented based on set-based framework. Its cost-effectiveness is suggested by sparsely analyzing the program at method level (hence reducing the number of unknowns in the flow equations). We have shown that our interprocedural exception analysis is more precise than JDK-style intraprocedural analysis, and also that our analysis can effectively detect uncaught exceptions for realistic Java programs.", "num_citations": "62\n", "authors": ["683"]}
{"title": "Towards a cost-effective estimation of uncaught exceptions in SML programs\n", "abstract": " We present a static analysis that detects potential runtime exceptions that are raised and never handled inside Standard ML (SML) programs. This analysis will predict abrupt termination of SML programs, which is SML's only one \u201csafety hole\u201d.             Even though SML program's control flow and exception flow are in general mutually dependent, analyzing the two flows are safely decoupled. Program's control-flow is firstly estimated from a set of equations defined by simple case analysis of call expressions. Using this call-graph information, program's exception flow is derived as set-constraints, whose least model is our analysis result. Both of these two analyses are proven safe and the reasons behind each design decision are discussed.             A preliminary implementation of this analysis has been applied to realistic SML programs and shows a promising cost-accuracy performance. For the ML-Lex program\u00a0\u2026", "num_citations": "57\n", "authors": ["683"]}
{"title": "Sound non-statistical clustering of static analysis alarms\n", "abstract": " We present a sound method for clustering alarms from static analyzers. Our method clusters alarms by discovering sound dependencies between them such that if the dominant alarm of a cluster turns out to be false (respectively true) then it is assured that all others in the same cluster are also false (respectively true). We have implemented our clustering algorithm on top of a realistic buffer-overflow analyzer and proved that our method has the effect of reducing 54% of alarm reports. Our framework is applicable to any abstract interpretation-based static analysis and orthogonal to abstraction refinements and statistical ranking schemes.", "num_citations": "52\n", "authors": ["683"]}
{"title": "A cost-effective estimation of uncaught exceptions in Standard ML programs\n", "abstract": " We present a static analysis that detects potential runtime exceptions that are raised and never handled inside Standard ML (SML) programs. This analysis will predict abrupt termination of SML programs, which is SMLs only one \u201csafety hole\u201d. Even though SML program's control flow and exception flow are in general mutually dependent, analyzing the two flows are safely decoupled. Program's control flow is firstly estimated by simple case analysis of call expressions. Using this call-graph information, program's exception flow is derived as set constraints, whose least model is our analysis result. Both of these two analyses are proven safe and the reasons behind each design decision are discussed.Our implementation of this analysis has been applied to realistic SML programs and shows a promising cost-accuracy performance. For the ML-Lex program, for example, the analysis takes 1.36 s and it reports 3 may\u00a0\u2026", "num_citations": "45\n", "authors": ["683"]}
{"title": "Engaging students with theory through acm collegiate programming contest\n", "abstract": " How formal methods can be presented in a popular---but mathematically sound---manner to undergraduate students of various disciplines.", "num_citations": "42\n", "authors": ["683"]}
{"title": "Machine-learning-guided selectively unsound static analysis\n", "abstract": " We present a machine-learning-based technique for selectively applying unsoundness in static analysis. Existing bug-finding static analyzers are unsound in order to be precise and scalable in practice. However, they are uniformly unsound and hence at the risk of missing a large amount of real bugs. By being sound, we can improve the detectability of the analyzer but it often suffers from a large number of false alarms. Our approach aims to strike a balance between these two approaches by selectively allowing unsoundness only when it is likely to reduce false alarms, while retaining true alarms. We use an anomaly-detection technique to learn such harmless unsoundness. We implemented our technique in two static analyzers for full C. One is for a taint analysis for detecting format-string vulnerabilities, and the other is for an interval analysis for buffer-overflow detection. The experimental results show that our\u00a0\u2026", "num_citations": "41\n", "authors": ["683"]}
{"title": "Static analysis of multi-staged programs via unstaging translation\n", "abstract": " Static analysis of multi-staged programs is challenging because the basic assumption of conventional static analysis no longer holds: the program text itself is no longer a fixed static entity, but rather a dynamically constructed value. This article presents a semantic-preserving translation of multi-staged call-by-value programs into unstaged programs and a static analysis framework based on this translation. The translation is semantic-preserving in that every small-step reduction of a multi-staged program is simulated by the evaluation of its unstaged version. Thanks to this translation we can analyze multi-staged programs with existing static analysis techniques that have been developed for conventional unstaged programs: we first apply the unstaging translation, then we apply conventional static analysis to the unstaged version, and finally we cast the analysis results back in terms of the original staged program\u00a0\u2026", "num_citations": "38\n", "authors": ["683"]}
{"title": "An empirical study on classification methods for alarms from a bug-finding static C analyzer\n", "abstract": " A key application for static analysis is automatic bug-finding. Given the program source, a static analyzer computes an approximation of dynamic program states occurring at each program point, and reports possible bugs by examining the approximate states. From such static bug-finding analysis, false alarms are inevitable. Because static analysis is done at compile-time, exact computation of the program\u2019s run-time states is impossible. Hence some approximation must be involved, so that the detected bugs can contain some false positives. Methodologies such as the abstract interpretation framework [6\u20138] counsel us to design a correct (conservative) static analyzer. The correctness criterion exacerbates the false alarm problem, because whenever in doubt the analysis must err on the pessimistic side.", "num_citations": "37\n", "authors": ["683"]}
{"title": "Termination analysis with algorithmic learning\n", "abstract": " An algorithmic-learning-based termination analysis technique is presented. The new technique combines transition predicate abstraction, algorithmic learning, and decision procedures to compute transition invariants as proofs of program termination. Compared to the previous approaches that mostly aim to find a particular form of transition invariants, our technique does not commit to any particular one. For the examples that the previous approaches simply give up and report failure our technique can still prove the termination. We compare our technique with others on several benchmarks from literature including PolyRank examples, SNU realtime benchmark, and Windows device driver examples. The result shows that our technique outperforms others both in efficiency and effectiveness.", "num_citations": "35\n", "authors": ["683"]}
{"title": "Access analysis-based tight localization of abstract memories\n", "abstract": " On-the-fly localization of abstract memory states is vital for economical abstract interpretation of imperative programs. Such localization is sometimes called \u201cabstract garbage collection\u201d or \u201cframing\u201d. In this article we present a new memory localization technique that is more effective than the conventional reachability-based approach. Our technique is based on a key observation that collecting the reachable memory parts is too conservative and the accessed parts are usually tiny subsets of the reachable. Our technique first estimates, by an efficient pre-analysis, the set of locations that will be accessed during the analysis of each code block. Then the main analysis uses the access-set results to trim the memory entries before analyzing code blocks. In experiments with an industrial-strength global C static analyzer, the technique is applied right before analyzing each procedure\u2019s body and reduces the average\u00a0\u2026", "num_citations": "31\n", "authors": ["683"]}
{"title": "The implicit calculus: a new foundation for generic programming\n", "abstract": " Generic programming (GP) is an increasingly important trend in programming languages. Well-known GP mechanisms, such as type classes and the C++0x concepts proposal, usually combine two features: 1) a special type of interfaces; and 2) implicit instantiation of implementations of those interfaces. Scala implicits are a GP language mechanism, inspired by type classes, that break with the tradition of coupling implicit instantiation with a special type of interface. Instead, implicits provide only implicit instantiation, which is generalized to work for any types. This turns out to be quite powerful and useful to address many limitations that show up in other GP mechanisms. This paper synthesizes the key ideas of implicits formally in a minimal and general core calculus called the implicit calculus (\u03bb\u21d2), and it shows how to build source languages supporting implicit instantiation on top of it. A novelty of the calculus is its\u00a0\u2026", "num_citations": "30\n", "authors": ["683"]}
{"title": "Exception analysis for Java\n", "abstract": " Current JDK Java compiler relies too much on programmer's specification for checking against uncaught exceptions of the input program. lt is not elaborate enough to remove programmer's unnecessary handlers (when programmer's specifications are too many) nor suggest to programmers for specialized handlings (when programmer's specifications are too general).We propose a static analysis of Java programs that estimates their exception flows independently of the programmer's specifications. This analysis is an extension of a dass analysis to Java's exception mechanism. Its cost-effectiveness balance is suggested by sparsely analyzing the program at method-level (hence reducing the number of unknowns in the flow equations).", "num_citations": "28\n", "authors": ["683"]}
{"title": "How to find a coin: propositional program logics made easy\n", "abstract": " The following sections are included:  Introduction   How the Story Began  A Hard Puzzle Put It for Programming     Games with Dynamic Logic  Game Interpretation Elementary Propositional Dynamic Logic Finite Games in EPDL Model Checking and Abstraction     Propositional \u00b5-Calculus  Toward Stronger Logic \u00b5-Calculus Syntax \u00b5-Calculus Semantics Properties of \u00b5C Semantics     Algorithmic Problems for the \u00b5-Calculus  Model Checking Decidability and Axiomatizations     Program Logics in General  What Are \u201cProgram Logics\u201d? Why Should We Know Program Logics? People and Ideas in Program Logics     Back to the Metaprogram Problem  Concrete Model Abstract Model     Acknowledgments   References", "num_citations": "27\n", "authors": ["683"]}
{"title": "Global sparse analysis framework\n", "abstract": " In this article, we present a general method for achieving global static analyzers that are precise and sound, yet also scalable. Our method, on top of the abstract interpretation framework, is a general sparse analysis technique that supports relational as well as nonrelational semantics properties for various programming languages. Analysis designers first use the abstract interpretation framework to have a global and correct static analyzer whose scalability is unattended. Upon this underlying sound static analyzer, analysis designers add our generalized sparse analysis techniques to improve its scalability while preserving the precision of the underlying analysis. Our method prescribes what to prove to guarantee that the resulting sparse version should preserve the precision of the underlying analyzer. We formally present our framework and show that existing sparse analyses are all restricted instances of our\u00a0\u2026", "num_citations": "24\n", "authors": ["683"]}
{"title": "GMeta: A Generic Formal Metatheory Framework for First-Order Representations\n", "abstract": " This paper presents GMeta: a generic framework for first-order representations of variable binding that provides once and for all many of the so-called infrastructure lemmas and definitions required in mechanizations of formal metatheory. The key idea is to employ datatype-generic programming (DGP) and modular programming techniques to deal with the infrastructure overhead. Using a generic universe for representing a large family of object languages we define datatype-generic libraries of infrastructure for first-order representations such as locally nameless or de Bruijn indices. Modules are used to provide templates: a convenient interface between the datatype-generic libraries and the end-users of GMeta. We conducted case studies based on the POPLmark challenge, and showed that dealing with challenging binding constructs, like the ones found in System F               <\u2009:, is possible with GMeta. All\u00a0\u2026", "num_citations": "24\n", "authors": ["683"]}
{"title": "Deriving invariants by algorithmic learning, decision procedures, and predicate abstraction\n", "abstract": " By combining algorithmic learning, decision procedures, and predicate abstraction, we present an automated technique for finding loop invariants in propositional formulae. Given invariant approximations derived from pre- and post-conditions, our new technique exploits the flexibility in invariants by a simple randomized mechanism. The proposed technique is able to generate invariants for some Linux device drivers and SPEC2000 benchmarks in our experiments.", "num_citations": "21\n", "authors": ["683"]}
{"title": "Assessing the overhead of ML exceptions by selective CPS transformation\n", "abstract": " \u042c\u0433 \u0438 \u0437 \u0432 \u0418 \u043b \u0438\u0436 \u0432\u0437 \u0433\u0436\u0431 \u0437\u0433\u0439\u0436 \u0434\u0436\u0433 \u0436 \u0431\u0437 \u0432\u0438\u0433 \u0433\u0432\u0438 \u0432\u0439 \u0438 \u0433\u0432\u0419\u0434 \u0437\u0437\u0419 \u0432 \u0437\u0438\u043d\u0430 \u0414 \u0428\u042b\u0415\u0418 \u0436 \u0434\u0430 \u0432 \u0432 \u0430 \u0432 \u0436 \u0437 \u043c\u0434\u0436 \u0437\u0437 \u0433\u0432\u0437 \u043d \u0433\u0432\u0438 \u0432\u0439 \u0438 \u0433\u0432\u0419 \u0438 \u0432 \u0432 \u0438 \u0436\u0433\u043b \u0432 \u043c\u0434\u0436 \u0437\u0437 \u0433\u0432\u0437\u0418 \u0436 \u0437\u0434 \u0438 \u043a \u0430\u043d\u041a \u0428\u042b\u0419\u0438\u0436 \u0432\u0437 \u0433\u0436\u0431 \u0432 \u043a\u0419 \u0436\u043d \u043c\u0434\u0436 \u0437\u0437 \u0433\u0432\u0418 \u0433\u043b \u043a \u0436\u0418 \u0432\u0438\u0436\u0433 \u0439 \u0437 \u0432 \u043b \u0433\u0437\u0438\u041a \u042f \u0438 \u0436 \u0433\u0436 \u0439\u0437 \u0432 \u043c\u0419 \u0434\u0438 \u0433\u0432 \u0432 \u0430\u043d\u0437 \u0437 \u0438\u0433 \u0438\u0436 \u0432\u0437 \u0433\u0436\u0431 \u043c\u0434\u0436 \u0437\u0437 \u0433\u0432\u0437 \u0437 \u0430 \u0438 \u043a \u0430\u043d \u0432 \u043c\u0434\u0436 \u0437\u0437 \u0433\u0432 \u0437 \u0437\u0438 \u0438 \u0430\u0430\u043d \u0438 \u0436\u0431 \u0432 \u0438\u0433 \u0432\u043a\u0433\u0430\u043a \u043c \u0434\u0438 \u0433\u0432\u0437 \u0438 \u0432 \u0438 \u0437 \u0428\u042b\u0419\u0438\u0436 \u0432\u0437 \u0433\u0436\u0431 \u0433\u0438 \u0436\u043b \u0437 \u0418 \u0438 \u0437 \u0430 \u0438 \u0432 \u0436 \u0438 \u0437\u0438\u043d\u0430 \u041a \u0421\u0432 \u0438 \u0437 \u0436\u0438 \u0430 \u0418 \u043b \u0433\u0436\u0431 \u0430 \u043e \u0438 \u0437 \u0437 \u0430 \u0438 \u043a \u0428\u042b \u0438\u0436 \u0432\u0437 \u0433\u0436\u0431 \u0438 \u0433\u0432\u0418 \u0434\u0436\u0433\u043a \u0438\u0437 \u0433\u0436\u0436 \u0438\u0432 \u0437\u0437\u0418 \u0432 \u0434\u0436 \u0437 \u0432\u0438 \u0436\u0430\u043d \u043c\u0434 \u0436 \u0431 \u0432\u0438 \u0430 \u0438 \u0432 \u0438 \u0432 \u0438\u0437 \u040b \u0438 \u0433\u0432 \u0425\u0424 \u0434\u0436\u0433 \u0436 \u0431\u0437\u041a", "num_citations": "19\n", "authors": ["683"]}
{"title": "An abstract interpretation for estimating uncaught exceptions in Standard ML programs\n", "abstract": " We present a static analysis that detects potential runtime exceptions that are raised and never handled inside Standard ML(SML) programs. This analysis enhances the software safety by predicting, prior to the program execution, the abnormal termination caused by unhandled exceptions.The analysis is specified as a finite, abstract semantics of an intermediate language. The intermediate language, into which SML programs are translated before the analysis begins, is defined such that the mechanism of SML's exception propagation becomes explicit in its text. This syntactic manipulation makes our analysis easy.Our analysis prototype has been implemented by using an analyzer generator called Z1 and has been used to analyze SML programs consisting of thousand lines. Our analysis is limited to SML programs that are type-correct and are operationally invariant even if the generative nature of SML's data-type\u00a0\u2026", "num_citations": "18\n", "authors": ["683"]}
{"title": "Access-based localization with bypassing\n", "abstract": " We present an extension of access-based localization technique to mitigate a substantial inefficiency in handling procedure calls. Recently, access-based localization was proposed as an effective way of tightly localizing abstract memories. However, it has a limitation in handling procedure calls: the localized input memory for a procedure contains not only memory locations accessed by the procedure but also those accessed by transitively called procedures. The weakness is especially exacerbated in the presence of recursive call cycles, which is common in analysis of realistic programs. In this paper, we present a technique, called bypassing, that mitigates the problem. Our technique localizes input memory states only with memory locations that the procedure directly accesses. Those parts not involved in analysis of the procedure are bypassed to transitively called procedures. In experiments with an\u00a0\u2026", "num_citations": "17\n", "authors": ["683"]}
{"title": "Unified interprocedural parallelism detection\n", "abstract": " In this paper, we outline a new way of detecting parallelism interprocedurally within a program. Our method goes beyond mere dependence testing, to embrace methods of removing dependences as well, namely privatization, induction recognition and reduction recognition. This method is based on a combination of techniques: a \u201cuniversal\u201d form for representing memory accesses within a section of code (the Linear Memory Access Descriptor), a technique for classifying memory locations based on the accesses made to them by the code (Memory Classification Analysis), and a dependence test (the Access Region Test). The analysis done with Linear Memory Access Descriptors is based on an intersection operation, for which we present an algorithm. Linear Memory Access Descriptors are independent of any declarations that may exist in a program, so they are subroutine- and language-independent\u00a0\u2026", "num_citations": "17\n", "authors": ["683"]}
{"title": "An algorithmic mitigation of large spurious interprocedural cycles in static analysis\n", "abstract": " We present a simple algorithmic extension of the approximate call\u2010strings approach to mitigate substantial performance degradation caused by spurious interprocedural cycles. Spurious interprocedural cycles are, in a realistic setting, the key reasons for why approximate call\u2010return semantics in both context\u2010sensitive and \u2010insensitive static analysis can make the analysis much slower than expected. In the approximate call\u2010strings\u2010based context\u2010sensitive static analysis, because the number of distinguished contexts is finite, multiple call\u2010contexts are inevitably joined at the entry of a procedure and the output at the exit is propagated to multiple return\u2010sites. We found that these multiple returns frequently create a single large cycle (we call it \u2018butterfly cycle\u2019) covering almost all parts of the program and such a spurious cycle makes analyses very slow and inaccurate. Our simple algorithmic technique (within the\u00a0\u2026", "num_citations": "16\n", "authors": ["683"]}
{"title": "Puzzles for learning model checking, model checking for programming puzzles, puzzles for testing model checkers\n", "abstract": " Paper discusses some issues related to the utility of finite games for early formal methods teaching and for validation of automatic tools which implement formal methods. In particular, some experience with (1) undergraduate teaching model checking via finite games, (2) solving game-based constraints via model checking, (3) testing model checkers against game test suits is presented. Basic ideas are illustrated by a model checking based solution for a complicated puzzle how to identify a unique false coin among given ones balancing them limited times.", "num_citations": "15\n", "authors": ["683"]}
{"title": "Proving syntactic properties of exceptions in an ordered logical framework\n", "abstract": " We formally prove the stackability and linearity of exception handlers with ML-style semantics using a novel proof technique via an ordered logical framework (OLF). We first transform exceptions into continuation-passing-style (CPS) terms and formalize the exception properties as a judgement on the CPS terms. Then, rather than directly proving that the properties hold for terms, we prove our theorem for the representations of the CPS terms and transform in OLF. We rely upon the correctness of our representations to transfer the results back to the actual CPS terms and transform.               Our work can be seen as two-fold: we present a theoretical justification of using the stack mechanism to implement exceptions of ML-like semantics; and we demonstrate the value of an ordered logical framework as a conceptual tool in the theoretical study of programming languages.", "num_citations": "15\n", "authors": ["683"]}
{"title": "Compile-time detection of uncaught exceptions in standard ML programs\n", "abstract": " We present a static analysis that detects potential runtime exceptions that are raised and never handled inside Standard ML programs. This analysis enhances the software safety by predicting, prior to the program execution, the abnormal termination caused by unhandled exceptions.             Our analysis prototype has been implemented by using a semantics-based analyzer generator and has been successfully tested with real Standard ML programs consisting of thousand lines.             We introduce semantic sparse analysis to reduce the analysis cost without compromising the analysis accuracy. In this method, expressions will only be analyzed when their evaluations are relevant to our analysis.", "num_citations": "15\n", "authors": ["683"]}
{"title": "A generalized let-polymorphic type inference algorithm\n", "abstract": " We present a generalized let-polymorphic type inference algorithm, prove that any of its instances is sound and complete with respect to the Hindley/Milner let-polymorphic type system, and nd a condition on two instance algorithms so that one algorithm should nd type errors earlier than the other.By instantiating the generalized algorithm with di erent parameters, we can achieve not only the two opposite algorithms (the bottom-up standard Algorithm W and the top-down folklore algorithm M) but also other various hybrid algorithms that avoid their extremities in type-checking (W fails too late, while M fails too early). Such hybrid algorithms' soundness, completeness, and their relative earliness in detecting type-errors follow automatically. The set of hybrid algorithms that come from the generalized algorithm is a superset of those used in the two most popular ML compilers, SML/NJ and OCaml.", "num_citations": "12\n", "authors": ["683"]}
{"title": "Proofs of a set of hybrid let-polymorphic type inference algorithms\n", "abstract": " We present a generalized let-polymorphic type inference algorithm, prove that any of its instances is sound and complete with respect to the Hindley/Milner let-polymorphic type system, and find a condition on two instance algorithms so that one algorithm should find type errors earlier than the other.               By instantiating the generalized algorithm with different parameters, we can obtain not only the two opposite algorithms (the bottom-up standard algorithmW and the top-down algorithmM) but also other hybrid algorithms which are used in real compilers. Such instances\u2019 soudness and completeness follow automatically, and their relative earliness in detecting type-errors is determined by checking a simple condition. The set of instances of the generalized algorithm is a superset of those used in the two most popular ML compilers: SML/NJ and OCaml.", "num_citations": "10\n", "authors": ["683"]}
{"title": "Static monotonicity analysis for \u03bb-definable functions over lattices\n", "abstract": " We employ static analysis to examine monotonicity of functions defined over lattices in a \u03bb-calculus augmented with constants, branching, meets, joins and recursive definitions. The need for such a verification procedure has recently arisen in our work on a static analyzer generator called Zoo, in which the specification of static analysis (input to Zoo) consists of finite-height lattice definitions and function definitions over the lattices. Once monotonicity of the functions is ascertained, the generated analyzer is guaranteed to terminate.", "num_citations": "10\n", "authors": ["683"]}
{"title": "Automatic Generation and Management of Program Analyses\n", "abstract": " Designing a program analysis (for use in optimizing compilers) is a time-consuming, complicated process because it involves many parameters. In particular, one must carefully measure the accuracy of the analysis against its cost. To reach an acceptable cost-accuracy balance the designer must repeatedly implement the analysis, measure its behavior, and alter its design.In this thesis we present a software system called system Z1, by which one can quickly specify a program analysis, obtain automatically from this speci cation an executable version, measure its performance, and alter the design (adjust the cost-accuracy balance), and repeat the cycle until the desired behavior is seen. Speci cation language Z1 is designed in which the user can conveniently express various program analyses for a wide range of target languages. System Z1 is based on the abstract interpretation framework. The input to system Z1 is a high-level speci cation of an abstract interpreter. The output is a C code for the speci ed interprocedural program analyzer.", "num_citations": "10\n", "authors": ["683"]}
{"title": "A progress bar for static analyzers\n", "abstract": " We present a technique for devising a progress indicator of static analyzers. Progress indicator is a useful user interface that shows how close a static analysis has progressed so far to its completion. Because static analysis\u2019 progress depends on the semantic complexity, not on the code size, of the target software, devising an accurate progress-indicator is not obvious. Our technique first combines a semantic-based pre-analysis and a statistical method to approximate how a main analysis progresses in terms of lattice height of the abstract domain. Then, we use this information during the main analysis and estimate the analysis\u2019 current progress. We apply the technique to three existing analyses (interval, octagon, and pointer analyses) for C and show the technique estimates the actual analysis progress for various benchmarks.", "num_citations": "9\n", "authors": ["683"]}
{"title": "Access-based abstract memory localization in static analysis\n", "abstract": " On-the-fly localization of abstract memory states is vital for economical abstract interpretation of imperative programs. Such localization is sometimes called \u201cabstract garbage collection\u201d or \u201cframing\u201d. In this article we present a new memory localization technique that is more effective than the conventional reachability-based approach. Our technique is based on a key observation that collecting the reachable memory parts is too conservative and the accessed parts are usually tiny subsets of the reachable part. Our technique first estimates, by an efficient pre-analysis, which parts of input states will be accessed during the analysis of each code block. Then the main analysis uses the access-set results to trim the memory entries before analyzing code blocks. In experiments with an industrial-strength global C static analyzer, the technique is applied right before analyzing each procedure\u2019s body and reduces the average\u00a0\u2026", "num_citations": "9\n", "authors": ["683"]}
{"title": "Identifying static analysis techniques for finding non-fix hunks in fix revisions\n", "abstract": " Mining software repositories for bug detection requires accurate techniques of identifying bug-fix revisions. There have been many researches to find exact bug-fix revisions. However there are still noises, we call these noises non-fix hunks, even in exactly identified bug-fix revisions. Our goal is to remove these non-fix hunks automatically. First we inspected every 50 bug-fix revisions of three open source projects (Eclipse, Lucene, and Columba). Among total 2146 hunks we found 179 non-fix hunks. We classified these non-fix hunks into 11 patterns. For all patterns we enumerate enabling static analysis techniques.", "num_citations": "9\n", "authors": ["683"]}
{"title": "A static reference flow analysis to understand design pattern behavior\n", "abstract": " Design patterns are actively used by developers expecting that they provide the design with good quality such as flexibility and reusability. However, according to industrial reports on the use of design patterns, the expectation is not always realized . Especially, points out two causes of inappropriately applied patterns from a case study on a large commercial project: developers inexperienced in design patterns and no connection with project requirement. Wrong decisions on the use of design patterns make the program difficult to understand, and refactoring the program to improve the underlying structure, especially without documentation, can be very tricky. To eliminate wrongly applied patterns or document important decisions automatically, design pattern recovery is important for not only the development phase but also the maintenance phase. Many design pattern recovery approaches focus on structural\u00a0\u2026", "num_citations": "9\n", "authors": ["683"]}
{"title": "A proof method for the correctness of modularized 0CFA\n", "abstract": " This article is about our findings when we tried to derive a modular version from a whole-program control-flow analysis (CFA). Deriving a modular version from a whole-program kCFA makes the resulting analysis polyvariant at modulelevel. Hence the correctness of its modularized version cannot be proven in general with respect to the original kCFA. A convenient stepping-stone to prove the correctness of a modularized version is a whole-program kCFA that is polyvariant at module-level.Because CFA is a basis of almost all analyses for higher-order programs, our result can be seen as a general hint of using the module-variant whole-program analysis in order to ease the correctness proof for a modularized version. Our work can also be seen as a formal investigation, for CFA, of the folklore that modularization improves the analysis accuracy.", "num_citations": "9\n", "authors": ["683"]}
{"title": "Exception analysis for multithreaded Java programs\n", "abstract": " This paper presents a static analysis that estimates uncaught exceptions in multithreaded Java programs. In Java, throwing exceptions across threads is deprecated because of the safely problem. Instead of restricting programmers' freedom, we extend the Java language to support multithreaded exception handling and propose a tool to detect uncaught exceptions in the input programs. Our analysis consists of two steps. The analysis firstly, estimates concurrently evaluated expressions of the multithreads in Java programs by the synchronization relation among the threads. Using this concurrency information, the program's exception flow is derived as set-constraints, whose least model is our analysis result. Both of these two steps are proved safe.", "num_citations": "9\n", "authors": ["683"]}
{"title": "On expressive and model checking power of propositional program logics\n", "abstract": " We examine when a model checker for a propositional program logic can be used for checking another propositional program logic in spite of lack of expressive power of the first logic. We prove that (1) a branching time Computation Tree Logic CTL, (2) the propositional \u03bc-Calculus of D. Kozen \u03bcC, and (3) the second-order propositional program logic 2M of C. Stirling enjoy the equal model checking power in spite of difference in their expressive powers CTL < \u03bcC < 2M: every listed logic has a formula such that every model checker for this particular formula for models in a class closed w.r.t. finite models, Cartesian products and power-sets can be reused for checking all formulae of these logics in all models in this class. We also suggest a new second-order propositional program logic SOEPDL and demonstrate that this logic is more expressive than 2M, is as expressive as the Second order Logic of monadic\u00a0\u2026", "num_citations": "9\n", "authors": ["683"]}
{"title": "Interconnecting between CPS terms and non-CPS terms\n", "abstract": " We present a type-based partial CPS transformation (CPS-transforming only a sub-part of a program) and its correctness proof. A program's sub-parts which need to be CPS-transformed are initially annotated as such. Partial CPS-transformation scans the expressions and selectively apply the transformation depending on the annotation. Wherever an interface between CPS-transformed and direct-style expressions is needed, proper conversion code is padded based on expression types. The correctness of the partial CPS transformation is proven similarly to that of Plotkin's simulation theorem Plo75].", "num_citations": "9\n", "authors": ["683"]}
{"title": "Abstract interpretation+ impure catalysts: Our Sparrow experience\n", "abstract": " Programs Size Time True False KLOC(sec) Alarms Alarms art 1.2 0.68 1 0 equake 1.5 1.03 0 0 mcf 1.9 2.77 0 0 bzip2 4.6 1.52 1 0 gzip 7.7 1.56 1 4 parser 10.9 15.93 0 0 ammp 13.2 9.68 20 0 vpr 16.9 7.85 0 9 crafty 19.4 84.32 0 0 twolf 19.7 68.80 5 0 mesa 50.2 43.15 9 0 vortex 52.6 34.79 0 1 gap 59.4 31.03 0 0 gcc 205.8 1330.33 44 1 gnuchess-5.07 17.8 9.44 4 0 tcl8. 4.14 17.9 266.09 4 4 hanterm-3.1. 6 25.6 13.66 0 0 sed-4.0. 8 26.8 13.68 29 31 tar-1.13 28.3 13.88 5 3 grep-2.5. 1a 31.5 22.19 2 3 openssh-3.5 p1 36.7 10.75 18 4 bison-2.3 48.4 48.60 4 1 openssh-4.3 p2 77.3 177.31 1 7 fftw-3.1. 2 184.0 15.20 0 0 httpd-2.2. 2 316.4 102.72 6 1 net-snmp-5.4 358.0 201.49 40 20 binutils-2.13. 1 909.4 712.09 228 25", "num_citations": "8\n", "authors": ["683"]}
{"title": "Experiments on the Effectiveness of an Automatic Insertion of Memory Reuses into ML-like Programs\n", "abstract": " We present extensive experimental results on our static analysis and source-level transformation [12, 11] that adds explicit memory-reuse commands into ML program text.", "num_citations": "8\n", "authors": ["683"]}
{"title": "An Improved Differential Fixpoint Iteration Method for Program Analysis.\n", "abstract": " We present a differential fixpoint iteration method to be used in static program analyses. The differential method consists of two phases: first we transform the program analysis equations into differential ones, and then we apply a differential fixpoint iteration to the equations computing with the differences from the previous iterations. We implemented the method for the exception analysis of ML programs and also for the constant propagation and alias analysis of C and Fortran programs. For the exception analysis, our differential method saves about 20-50% computations. For the constant propagation and alias analysis, our method has a linear asymptotic performance: its cost remains linear to the height of the lattice structures. Our algorithm is not yet formally proven correct, but for the experiments the analysis results are confirmed identical to those from a non-differential fixpoint algorithm. Both analyses are for realistic ML/C/Fortran programs.", "num_citations": "8\n", "authors": ["683"]}
{"title": "Programming Languages and Systems\n", "abstract": " This volume contains the papers presented at the 17th Asian Symposium on Programming Languages and Systems (APLAS 2019), held in Bali, Indonesia, between December 1\u20134, 2019. APLAS aims to stimulate programming language research by providing a forum for the presentation of the latest results and the exchange of ideas in programming languages and systems. APLAS is based in Asia but is an international forum that serves the worldwide programming languages community. This year we solicited contributions in the forms of regular research papers and tool papers. The conference solicts contributions in, but is not limited to, the following topics: semantics, logics, and foundational theory; design of languages, type systems, and foundational calculi; domain-specific languages compilers, interpreters, and abstract machines; program derivation, synthesis, and transformation; program analysis, verification\u00a0\u2026", "num_citations": "7\n", "authors": ["683"]}
{"title": "Optimizing homomorphic evaluation circuits by program synthesis and term rewriting\n", "abstract": " We present a new and general method for optimizing homomorphic evaluation circuits. Although fully homomorphic encryption (FHE) holds the promise of enabling safe and secure third party computation, building FHE applications has been challenging due to their high computational costs. Domain-specific optimizations require a great deal of expertise on the underlying FHE schemes, and FHE compilers that aims to lower the hurdle, generate outcomes that are typically sub-optimal as they rely on manually-developed optimization rules. In this paper, based on the prior work of FHE compilers, we propose a method for automatically learning and using optimization rules for FHE circuits. Our method focuses on reducing the maximum multiplicative depth, the decisive performance bottleneck, of FHE circuits by combining program synthesis and term rewriting. It first uses program synthesis to learn equivalences of\u00a0\u2026", "num_citations": "6\n", "authors": ["683"]}
{"title": "Sound non-statistical clustering of static analysis alarms\n", "abstract": " We present a sound method for clustering alarms from static analyzers. Our method clusters alarms by discovering sound dependencies between them such that if the dominant alarms of a cluster turns out to be false, all the other alarms in the same cluster are guaranteed to be false. We have implemented our clustering algorithm on top of a realistic buffer-overflow analyzer and proved that our method reduces 45% of alarm reports. Our framework is applicable to any abstract interpretation-based static analysis and orthogonal to abstraction refinements and statistical ranking schemes.", "num_citations": "6\n", "authors": ["683"]}
{"title": "Program Logics Made Easy\n", "abstract": " In spite of the importance of Formal Methods for development of a reliable hard-and software this domain is not well acquainted to non-professionals. In particular, many students consider Formal Methods either too poor for their pure mathematics, either too pure for their poor mathematics. We suppose that a deficit of a popular papers on Formal Methods is the main reason for this ignorance. In the paper we would like to present in a popular (but mathematically sound) form a Program Logics tributary creek of a powerful stream called Formal Methods. From the application viewpoint, the paper is oriented on model checking of program logics in finite models. The basic ideas, definitions and theorems are illustrated by game examples usually presented as puzzles. Only some knowledge of propositional calculus, elementary set theory and theory of binary relations is prerequested.", "num_citations": "6\n", "authors": ["683"]}
{"title": "Constraint-based analysis for Java\n", "abstract": " This paper presents constraint-based analysis for Java, and presents a systematic way to design a less costly analysis from an existing analysis. The basic idea is to approximate original set constraints by partitioning their set variables and replacing each set variable in them by the block, to which it belongs. We design a more e cient analysis by transforming the original constraint derivation rules using partition function. As an instance of the transformation, we provide a sparse uncaught exception analysis for Java, which approximates all the uncaught exceptions at method-level.", "num_citations": "6\n", "authors": ["683"]}
{"title": "Interprocedural data flow analysis for compile-time memory management\n", "abstract": " We have designed and implemented in C an interprocedural data ow analysis that will estimate the memory object lifetime and its temporal locality. The analysis is an abstract interpretation. The target language is a multilingual intermediate language called MIL. Since we have ANSI C, Fortran, and Scheme front-ends for the target language, the analysis works for programs written in these high-level languages.", "num_citations": "6\n", "authors": ["683"]}
{"title": "EDUCATIONAL PEARL:\u2018Proof-directed debugging\u2019revisited for a first-order version\n", "abstract": " Some 10 years ago, Harper illustrated the powerful method of proof-directed debugging for developing programs with an article in this journal. Unfortunately, his example uses both higher-order functions and continuation-passing style, which is too difficult for students in an introductory programming course. In this pearl, we present a first-order version of Harper's example and demonstrate that it is easy to transform the final version into an efficient state machine. Our new version convinces students that the approach is useful, even essential, in developing both correct and efficient programs.", "num_citations": "5\n", "authors": ["683"]}
{"title": "Yet another ensemble of abstract interpreter, higher-order dataflow equations, and model checking\n", "abstract": " This work is a rst step to our goal: building a\\realistic\" program analysis generator, like lex and yacc in syntax analysis. Toward this goal one question is which program analysis technique (s) should be supported by such a tool? We agree that with a right cooperation of di erent techniques might we be able to build a realistic tool. We are currently building a program-analysis generator (named\\Zoo\") that is an ensemble of three frameworks: abstract interpretation CC77, CC92], conventional data-ow analysis RP86, KU76, KU77], and model checking CGP99]. The Zoo system applies each of the three frameworks to a di erent phase in analysis' speci cation and generation.A similar combinational methodology has been presented by Schmidt and Ste en SS98]. The main di erence of Zoo is in how to build nite models of the input programs. Given an input program, Zoo compiles it into a set of data-ow equations by referencing the abstract interpreter speci cation. On the way to reach the solutions of the equations, a nite data-ow graph is constructed, which is later queried by model checking for program properties of interest. Moreover, the abstract interpreter is in the style of the de nitional interpreter Rey98a, Rey98b, Rey72], not in the style of a small-step operational semantics. This stylistic di erence is meaningful in an analysis generation tool, because small-step operational semantics can be too ne-grained (hence, low-level) semantic speci cations for higher-order languages. In Zoo, each of the three frameworks plays the following role:", "num_citations": "5\n", "authors": ["683"]}
{"title": "Static analysis with set-closure in secrecy\n", "abstract": " We report that the homomorphic encryption scheme can unleash the possibility of static analysis of encrypted programs. Static analysis in cipher-world is desirable in the static-analysis-as-a-service setting, because it allows the program owners to encrypt and upload their programs to the static analysis service while the service provider can still analyze the encrypted programs without decrypting them. Only the owner of the decryption key (the program owner) is able to decrypt the analysis result. As a concrete example, we describe how to perform a pointer analysis in secrecy. In our method, a somewhat homomorphic encryption scheme of depth  is able to evaluate a simple pointer analysis with  homomorphic matrix multiplications, for the number m of pointer variables when the maximal pointer level is bounded. We also demonstrate the viability of our method by implementing the pointer\u00a0\u2026", "num_citations": "4\n", "authors": ["683"]}
{"title": "Automatically inferring loop invariants via algorithmic learning\n", "abstract": " By combining algorithmic learning, decision procedures, predicate abstraction and simple templates for quantified formulae, we present an automated technique for finding loop invariants. Theoretically, this technique can find arbitrary first-order invariants (modulo a fixed set of atomic propositions and an underlying satisfiability modulo theories solver) in the form of the given template and exploit the flexibility in invariants by a simple randomized mechanism. In our study, the proposed technique was able to find quantified invariants for loops from the Linux source and other realistic programs. Our contribution is a simpler technique than the previous works yet with a reasonable derivation power.", "num_citations": "4\n", "authors": ["683"]}
{"title": "LR error repair using the A* algorithm\n", "abstract": " This article presents a local LR error repair method that repairs syntax errors quickly by adoption of the A* algorithm that helps remove unproductive configurations. The new method also enhances the repair quality by adoption of a flexible edit strategy to support shifting symbols unrestrictedly, as well as inserting and deleting symbols, in order to repair invalid input strings. Experimental results show that the new method excels existing works in repair quality and efficiency.", "num_citations": "4\n", "authors": ["683"]}
{"title": "A control flow analysis for 2-staged programming languages\n", "abstract": " As a program written in multi-staged language can generate and execute code fragments in excution time, it is hard to predict what code fragments will be generated and run in execution time. Therefore we need a new method to predict what code fragments would be generated in execution time to analyze a control flow of software. In this article, we present static analysis which detects code fragments generated in execution time using abstract interpretation. Moreover we prove the correctness of analyzer.", "num_citations": "4\n", "authors": ["683"]}
{"title": "Program Analysis System Zoo\n", "abstract": " Free identifiers must not be bound in the de-sugar\u2019ed definitions. set setdesc1,\u00b7\u00b7\u00b7, setdescn\u2261 set setdesc1\u00b7\u00b7\u00b7 set setdescn lattice latdesc1,\u00b7\u00b7\u00b7, latdescn\u2261 lattice latdesc1\u00b7\u00b7\u00b7 lattice latdescn pat po1 pat1\u00b7\u00b7\u00b7 pon pon\u2261 po1 (pat, pat1)|\u00b7\u00b7\u00b7| pon (patn\u2212 1, patn)(e1, e2, e3)\u2261(e1,(e2, e3)) e. domid\u2261 e. k e: D= A1\u00d7\u00b7\u00b7\u00b7\u00d7 An and domid= Ak e [pat=> e]\u2261{pat=> e, x=> e x} new x mp mrule1|\u00b7\u00b7\u00b7| mrulen\u2261{mrule1,\u00b7\u00b7\u00b7, mrulen} case e of match\u2261(fn match) e if e1 then e2 else e3\u2261 case e1 of true=> e2| false=> e3 guard1, guard2\u2261 guard1 and guard2 (pat1, pat2, pat3)\u2261(pat1,(pat2, pat3)) const\u2261 x with x= const new x pat rop e\u2261 x as pat with x rop e new x pat in e\u2261 x as pat with x in e new x fun varid pat1= e1| varid pat2= e2\u2261 val rec varid= fn pat1=> e1| pat2=> e2 map varid pat1= e1| varid pat2= e2\u2261 val varid={pat1=> e1, pat2=> e2} eqn varid pat1= e1| varid pat2= e2\u2261 eqn rec varid= fn pat1=> e1| pat2=> e2 form1<-> form2\u2261 form1-> form2 and form2-> form1", "num_citations": "4\n", "authors": ["683"]}
{"title": "On-the-fly circuit to measure the average working set size\n", "abstract": " Two economic methods (Markov chain method and filtering method) which estimate the average working set size of a program on the fly are presented. Both methods are simple enough to be implemented inside a VLSI processor chip with small space requirements, or outside the chip to probe the memory reference traffic. The on-the-fly circuit tools that can estimate the average working set size of a program without much loss of accuracy make unnecessary the problematic and expensive procedures (hardware monitoring or simulation) of collecting the reference traces. Such tools can be used in all studies that require program locality measurements, including the study of a program locality, the effectiveness study of locality improvement techniques, and the study of optimizing compiler's effect on program locality. Since both methods require only one comparison and an increment of one or two counters per memory\u00a0\u2026", "num_citations": "4\n", "authors": ["683"]}
{"title": "Widening with thresholds via binary search\n", "abstract": " In this paper, we present a useful technique for implementing practical static program analyzers that use widening. Our technique aims to improve the efficiency of the conventional widening\u2010with\u2010thresholds technique at a small precision compromise. In static analysis, widening is used to accelerate (or converge) fixed point iterations. Unfortunately, this acceleration often comes with a significant loss in analysis precision. A standard method to improve the precision is to apply the widening with a set of thresholds. However, this technique may significantly slow down the analysis, because in practice it is commonplace to use a large set of thresholds. In worst case, the technique increases the analysis cost by the size N of the threshold set. In this paper, we propose a technique to reduce the worst case by  , by employing a binary search in the process of applying threshold values. We formalize the technique in the\u00a0\u2026", "num_citations": "3\n", "authors": ["683"]}
{"title": "Method and apparatus for detecting leak of information resource of device\n", "abstract": " A method and apparatus for detecting a leak of an information resource of a device. Source code is obtained from an application and is analyzed to determine whether at least one information resource from among information resources of a device is transmittable to outside the device by tracking a task performed on the at least one information resource, thereby detecting whether the application is externally leaking an information resource from the device.", "num_citations": "3\n", "authors": ["683"]}
{"title": "Unstaging translation from metaml-like multi-staged calculus to context calculus\n", "abstract": " Multi-staged calculus has many syntactic categories for values and expressions including n-staged values, Valuen S, and n-staged expressions, Exprn S. The operational semantics depends on the diversified syntactic categories to rule out ill-formed programs. The substitution in MetaML-like multi-staged calculus works across staging constructs. To clarify n-staged values and expressions, we define the depth of expressions. For e\u2208 ExprS, depth of e, depth (e), is the number of nested unboxes that are not enclosed with boxes, defined as Definition 1.", "num_citations": "3\n", "authors": ["683"]}
{"title": "Abstract parsing for two-staged languages with concatenation\n", "abstract": " This article, based on Doh, Kim, and Schmidt's \"abstract parsing\" technique, presents an abstract interpretation for statically checking the syntax of generated code in two-staged programs. Abstract parsing is a static analysis technique for checking the syntax of generated strings. We adopt this technique for two-staged programming languages and formulate it in the abstract interpretation framework. We parameterize our analysis with the abstract domain so that one can choose the abstract domain as long as it satisfies the condition we provide. We also present an instance of the abstract domain, namely an abstract parse stack and its widening with k-cutting.", "num_citations": "3\n", "authors": ["683"]}
{"title": "Type and effect system for multi-staged exceptions\n", "abstract": " We present a type and effect system for a multi-staged language with exceptions. The proposed type and effect system checks if we safely synthesize complex controls with exceptions in multi-staged programming. The proposed exception constructs in multi-staged programming has no artificial restriction. Exception-raise and -handle expressions can appear in expressions of any stage, though they are executed only at stage 0. Exceptions can be raised during code composition and may escape before they are handled. Our effect type system support such features. We prove our type and effect system sound: empty effect means the input program has no uncaught exceptions during its execution.", "num_citations": "3\n", "authors": ["683"]}
{"title": "Model Checking Puzzles in-Calculus\n", "abstract": " Tne paper discusses some issues related to model checking utility and reliability:(1) utility of model checking and games for solving puzzles, and (2) importance of games and puzzles for validation of model checkers.", "num_citations": "3\n", "authors": ["683"]}
{"title": "A Generalization of Hybrid Let-Polymorphic Type Inference Algorithms.\n", "abstract": " \u2022 Objective Caml 2.04 employs a variant of M.# fun fac n= if n= 0 then 1 else n* fac (n= 1);; its type is bool, but its type is expected as int.", "num_citations": "3\n", "authors": ["683"]}
{"title": "Assessing the Overhead of ML Exceptions by Selective CPS...\n", "abstract": " ML's exception handling makes it possible to describe exceptional execution ows conveniently, but it also forms a performance bottleneck.", "num_citations": "3\n", "authors": ["683"]}
{"title": "System Z1 programming manual\n", "abstract": " This report presents how to use system Z1 which is a prototyping tool for interprocedural program analyses. The input to system Z1 is a high-level speci cation of a program analysis. The output is a C code for the speci ed interprocedural program analyzer. The system provides a high-level command set (called projection expressions) in which the user can tune the analysis in accuracy and cost.", "num_citations": "3\n", "authors": ["683"]}
{"title": "Z1: A data flow analyzer generator\n", "abstract": " We have developed a software tool called Z1 by which one can quickly achieve an accurate yet a ordable program analysis. The user writes an analysis speci cation and sets a parameter for a desired cost-accuracy tradeo. The tool then creates an executable analyzer that has the speci ed performance balance.Z1 has been used for developing both conventional and non-conventional ow analyses. These analyses were for programs written in C, FORTRAN, and Standard ML, without restriction upon the programs treated. We present experimental data showing the performances of Z1 for analyzing C, FORTRAN, and Standard ML programs.", "num_citations": "3\n", "authors": ["683"]}
{"title": "Selective conjunction of context\u2010sensitivity and octagon domain toward scalable and precise global static analysis\n", "abstract": " We present a practical technique for achieving a scalable and precise global static analysis by selectively applying context\u2010sensitivity and the octagon relational domain. For precise analysis, context\u2010sensitivity and relational analysis are key properties, but it has been hard to practically combine both of them. Our approach turns on those precision improvement features only when the analysis is likely to improve the precision to resolve given queries. The guidance comes from an impact pre\u2010analysis that estimates the impact of a fully context\u2010sensitive and relational octagon analysis. We designed a cost\u2010effective pre\u2010analysis and implemented this method in a realistic octagon analysis for full C. The experimental results show that our approach proves eight times more queries, while saving the time cost by 73.1% compared with a partially relational octagon analysis enabled by a syntactic heuristic. Copyright \u00a9 2017\u00a0\u2026", "num_citations": "2\n", "authors": ["683"]}
{"title": "Method for analysing program code of electronic device and electronic device\n", "abstract": " A method of analyzing a program code of an electronic device includes configuring a tree by using a key string included in the program code and; in response to a command to find a specific key being received, performing a predetermined order traversal of the tree by using a string included in the specific key; in response to a node which matches a last string included in the specific key having a leaf node as a result of the predetermined order traversal, returning a value of the leaf node; and analyzing the program code by using the return value.", "num_citations": "2\n", "authors": ["683"]}
{"title": "Encrypted Execution\n", "abstract": " We present secret execution in which an encrypted program is evaluated without decryption, to give an encrypted result whose decryption yields the original result.", "num_citations": "2\n", "authors": ["683"]}
{"title": "Goal-directed weakening of abstract interpretation results\n", "abstract": " One problem of this approach is that abstract interpreters often compute invariants that are not needed for the proof goal. The reason is that the abstract interpreter does not know what the proof goal is, so it simply tries to find as strong invariants as possible. These unnecessary invariants increase the size of the constructed proofs. Unless the proof-construction phase is notified which invariants are not needed, it blindly proves all the computed invariants. In this paper, we present a framework for designing algorithms, called abstract-value slicers, that slice out unnecessary invariants from the abstract interpretation results. The framework provides a generic abstract-value slicer that can be instantiated into a slicer for a particular abstract interpretation. Such an instantiated abstract-value slicer works as a post-processor to an abstract interpretation in the whole proof-construction process, and notifies to the next proof-construction phase which invariants it does not have to prove. Using the framework, we designed an abstractvalue slicer for an existing relational analysis and applied it on programs. In this experiment, the slicer identified 62%\u2212 81% of the computed invariants as unnecessary, and resulted in 52%\u2212 84% reduction in the size of constructed proofs.", "num_citations": "2\n", "authors": ["683"]}
{"title": "Static Analysis\n", "abstract": " Static Analysis is increasingly recognized as a fundamental tool for program verification, bug detection, compiler optimization, program understanding, and software maintenance. The series of Static Analysis Symposia has served as the primary venue for presentation of theoretical, practical, and applicational advances in the area.This volume contains the proceedings of the 13th International Static Analysis Symposium (SAS 2006), which was held 29-31 August 2006 at Seoul National University, Seoul, Korea. A total of 80 papers were submitted; the Program Committee held a 6-day long online discussion, during which they selected 23 papers. The selection was based on scientific quality, originality and relevance to the scope of SAS. Almost all submissions were reviewed by three (or more) PC members with the help of external reviewers. In addition to the 23 accepted papers, this volume also contains abstracts\u00a0\u2026", "num_citations": "2\n", "authors": ["683"]}
{"title": "Soundness by static analysis and false-alarm removal by statistical analysis: Our airac experience\n", "abstract": " We present our experience of combining, in a realistic setting, a static analysis for soundness and a statistical analysis for false-alarm removal. The static analyzer is Airac that we have developed in the abstract interpretation framework for detecting buffer overruns in ANSI+ GNU C programs. Airac is sound (finding all bugs) but with false alarms. Airac raised, for example, 970 buffer-overrun alarms in commercial C programs of 5.3 million lines and 233 among the 970 alarms were true. We addressed the false alarm problem by computing a probability of each alarm being true. We used Bayesian analysis and Monte Carlo method to estimate the probabilities and their credible sets. Depending on the user-provided ratio of the risk of silencing true alarms to that of false alarming, the system selectively present the analysis results (alarms) to the user. Though preliminary, the performance of the combination let us not hastefully trade the analysis soundness for a reduced number of false alarms.", "num_citations": "2\n", "authors": ["683"]}
{"title": "Static Extensionality Analysis for \u03bb-Definable Functions Over Lattices\n", "abstract": " We employ static analysis to examine extensionality (\u2200 x: x\u2264 f (x)) of functions defined over lattices in a \u03bb-calculus augmented with constants, branching, meets, joins and recursive definitions. The need for such a verification procedure has arisen in our work with a static analyzer generator called Zoo, in which the specification of static analysis (input to Zoo) consists of finite-height lattice definitions and function definitions over the lattices. Once extensionality of the functions is ascertained, the generated analyzer is guaranteed to terminate. In a disjunctive combination with the previous work [MY02] on the static monotonicity analysis (checking\u2200 x\u2264 y: f (x)\u2264 f (y)), the extensionality analysis will enlarge the set of input programs accepted by Zoo.", "num_citations": "2\n", "authors": ["683"]}
{"title": "A New Proof of Exponential Decidability for the Propositional-Calculus with Program Converse\n", "abstract": " The propositional-Calculus (C) is a powerful propositional program logic with xpoints. C decidability with exponential upper bound was sketched for the rst time in 1988 by EA Emerson and Ch. S. Jutla on base of automata-theoretic technique, while a complete proof was published in 1999 only. Meanwhile M. Vardi sketched in 1998 an automata-theoretic proof of exponential decidability for the propositional-Calculus with program converse (C?). We believe that alternative, independent and automata-free proofs of exponential decidabilities for C and for C? are important for validation of these upper bounds and due to a complexity of automata-theoretic proofs. Previously the author published in 1997 a proof of exponential upper bound for C which exploited a so-called Program Schemata Technique (PST) for decidability of propositional program logics. This time an extended PST is applied to C? and yields exponential upper bound too. Subject classi cation: 03B25 {Decidability of theories and sets of sentences, 03B70 {Logic in Computer Science, 68Q60 {Speci cation and veri cation.", "num_citations": "2\n", "authors": ["683"]}
{"title": "Escape Analysis for Stack Allocation in Java\n", "abstract": " We suggest an escaping analysis for Java programs, to identify stack-allocatable objects. This analysis considers an object escaping if it is used after the deactivation of the method that created it. For each object, this analysis records the interprocedural movement of the method of its creation. An object is considered escaping the method that created it, if the method of its creation has been already deactivated. Our approach is different from prior works, in that special cares of non-local variables need not be taken. This enables us to handle some cases that are missed in the previous approach. The whole analysis is done in a single phase.", "num_citations": "2\n", "authors": ["683"]}
{"title": "Method and device for analyzing application\n", "abstract": " A method and device for analyzing an application are provided. The method includes obtaining the application, obtaining at least one of environment information, which is information about an environment where the application is executed, and execution information, which is information about operations of components of the application, obtaining code data to analyze from the application, based on at least one of the environment information and the execution information, obtaining function information, and analyzing the code data, based on the obtained function information.", "num_citations": "1\n", "authors": ["683"]}
{"title": "Static Useless-Code-Detection for Two-Stage Language\n", "abstract": " \uc774 \ub17c\ubb38\uc5d0\uc11c\ub294 \uc815\uc801\uc73c\ub85c 2 \ub2e8\uacc4 \uc5b8\uc5b4\uc758 \ubd88\ud544\uc694\ud55c \uc2dd\uc744 \ucc3e\ub294 \ubd84\uc11d \ubc29\ubc95\uc744 \uc81c\uc548\ud55c\ub2e4. \ubd88\ud544\uc694\ud55c \uc2dd\uc774\ub780 \uc2dd\uc758 \uc2e4\ud589\uc758\ubbf8\uac00 \ud504\ub85c\uadf8\ub7a8\uc758 \uacb0\uacfc\uc5d0 \uc601\ud5a5\uc744 \ubbf8\uce58\uc9c0 \uc54a\ub294 \uc2dd\uc744 \ub9d0\ud55c\ub2e4. \ub2e4\ub2e8\uacc4 \ud504\ub85c\uadf8\ub7a8\uc774 \ubd88\ud544\uc694\ud55c \uc2dd\uc744 \ub9cc\ub4e4\uc5b4\ub0b4\ub294 \uc9c0 \ud504\ub85c\uadf8\ub7a8 \uc2e4\ud589\uc804\uc5d0 \uc54c \uc218 \uc788\ub2e4\uba74 \ud504\ub85c\uadf8\ub7a8 \uc2e4\ud589\uc5d0 \ub4dc\ub294 \ube44\uc6a9\uc744 \uc904\uc77c \uc218 \uc788\ub2e4. \uc774 \ubd84\uc11d\uc740 \ub2e4\ud615\ud0c0\uc785\uc744 \uac00\uc9c0\ub294 \ub2e4\ub2e8\uacc4 \uc5b8\uc5b4\uc758 \ud0c0\uc785\uc2dc\uc2a4\ud15c\uacfc \ud0c0\uc785\uc2dc\uc2a4\ud15c\uc5d0 \uc62c\ub77c\ud0c4 \ubd84\uc11d\uc5d0 \uae30\ubc18\ud558\uace0 \uc788\ub2e4. \uc774 \ubd84\uc11d\uc73c\ub85c \ud504\ub85c\uadf8\ub7a8 \uc2e4\ud589 \uc2dc \ubd88\ud544\uc694\ud55c \uc2dd\uc774 \ud504\ub85c\uadf8\ub7a8 \ucf54\ub4dc \ud615\ud0dc\ub85c \uc804\ud30c\ub418\ub294 \uac83\uc744 \uc54c \uc218 \uc788\uc73c\uba70 \ub2e4\ud615\ud0c0\uc785\uc744 \uc774\uc6a9\ud55c \uc815\uad50\ud55c \ubd84\uc11d\uc774 \uac00\ub2a5\ud558\ub2e4.", "num_citations": "1\n", "authors": ["683"]}
{"title": "Inferring quantified invariants via algorithmic learning, decision procedure, and predicate abstraction\n", "abstract": " By combining algorithmic learning, decision procedures, predicate abstraction, and templates, we present an automated technique for finding quantified loop invariants. Our technique can find arbitrary first-order invariants in the form of the given template and exploits the flexibility in invariants by a simple randomized mechanism. The proposed technique is able to find quantified invariants for sample loops in Linux source code and benchmarks in previous work.", "num_citations": "1\n", "authors": ["683"]}
{"title": "Clone Detection by Comparing Abstract Memory States, ROSAEC Research On Software Analysis For Error Free Computing, ROSAEC MEMO 2010-008 March 5, 2010 [2\n", "abstract": " In this paper, we propose a new semantic clone detection technique by comparing programs\u2019 abstract memory states, which are computed by a semantic-based static an-alyzer. Our experimental study using three large-scale open source projects shows that our technique can detect semantic clones that existing syntactic-or semantic-based clone detectors miss. Our technique can help developers identify inconsistent clone changes, find refactoring candidates, and understand software evolution related to semantic clones. 1", "num_citations": "1\n", "authors": ["683"]}
{"title": "Static Analysis: 13th International Symposium, SAS 2006, Seoul, Korea, August 29-31, 2006, Proceedings\n", "abstract": " This book constitutes the refereed proceedings of the 13th International Symposium on Static Analysis, SAS 2006. The book presents 23 revised full papers together with the abstracts of 3 invited talks. The papers address all aspects of static analysis including program and systems verification, shape analysis and logic, termination analysis, bug detection, compiler optimization, software maintenance, security and safety, abstract interpretation and algorithms, abstract domain and data structures and more.", "num_citations": "1\n", "authors": ["683"]}
{"title": "Programming Languages and Systems: Third Asian Symposium, APLAS 2005, Tsukuba, Japan, November 2-5, 2005, Proceedings\n", "abstract": " APLAS 2005 was the Asian Symposium on Programming Languages and S-tems, held in Tsukuba, Japan in November 2-5, 2005. It was the latest event in the series of annual meetings started in 2000 by Asian researchers in the? eld of programming languages and systems. The? rst three were organized as wo-shops, and were held in Singapore (2000), Daejeon (2001), and Shanghai (2002). Theenthusiasmthere, encouragedbytherichproductionoforiginalresearch-pers, and the support of the internationalresearchcommunities in programming languagesandsystems, ledtothe? rstAPLASasasymposiuminBeijing (2003), followed by the one in Taipei (2004). APLAS 2005 was the third symposium in the series. In the past? ve yearswe havewitnessed the growing role of APLAS as one of thekeyresearchcommunitiesoftheworld. ThisisnotonlybecauseAsia andthe Paci? c Rim is a fast-growing region of IT industries, but because it is a region of highly cultivated human resources. We are con? dent that forums like APLAS will further engender interaction among Asian researchers and with the rest of the world. As for the scope of APLAS, from the very beginning we have been striving to achieve the cross-fertilization of theories and system developments of p-gramming and programming languages. The papers selected for the publication of this volume of the proceedings are the evidence of our e? orts. We are very grateful to the contributors of the submitted papers; they came not only from Asia and Australia but from Europe and North America.", "num_citations": "1\n", "authors": ["683"]}
{"title": "Airac: Static Analyzer for Automatic Verification of Array Index Ranges in C Programs\n", "abstract": " \uc544\uc774\ub77d (Airac) \uc740 C \ud504\ub85c\uadf8\ub7a8\uc758 \ubc84\ud37c\uc624\ubc84\ub7f0 (buffer overrun) \uc624\ub958\ub97c \ucc3e\uc544\uc8fc\ub294 \uc815\uc801 \ud504\ub85c\uadf8\ub7a8 \ubd84\uc11d\uae30 (static program analyzer) \uc774\ub2e4. \uc544\uc774\ub77d\uc740 \uc694\uc57d\ud574\uc11d (abstract interpretation) \uc758 \ud2c0 \uc18d\uc5d0\uc11c \ub514\uc790\uc778\ub418\uc5c8\ub2e4. \uc124\uacc4 \ubc0f \uad6c\ud604 \uacfc\uc815\uc5d0\uc11c \ud504\ub85c\uadf8\ub7a8 \ubd84\uc11d \ubd84\uc57c\uc5d0\uc11c \ucd95\uc801\ub418\uc5b4\uc628 \ub2e4\uc591\ud55c \uae30\uc220\ub4e4\uc744 \uc801\uc6a9\ud558\uc5ec \ubd84\uc11d\uc758 \uc131\ub2a5 \ubc0f \uc815\ud655\ub3c4 \ud5a5\uc0c1\uc744 \uc774\ub8e9\ud558\uc600\ub2e4. \uc544\uc774\ub77d\uc740 \ub9ac\ub205\uc2a4 \ucee4\ub110 (linux kernel), GNU \uc18c\ud504\ud2b8\uc6e8\uc5b4, \uc0c1\uc6a9 \uc18c\ud504\ud2b8\uc6e8\uc5b4\ub4f1\uc5d0 \uc801\uc6a9\ub418\uc5b4 \uc624\ub958\ub97c \ucc3e\uc544\ub0c8\ub2e4.", "num_citations": "1\n", "authors": ["683"]}
{"title": "Correctness proof on an algorithm to insert memory reuse commands into ML-like programs\n", "abstract": " We present a static analysis that estimates reusable memory cells and a sourcelevel transformation that adds explicit memory-reuse commands into the program text. For benchmark ML programs, our analysis and transformation achieves the memory reuse ratio from 5.2% to 91.3% and reduces the memory peak from 0.0% to 71.9%. The small-ratio cases are for programs that have too prevalent sharings among memory cells. For other cases, our experimental results are encouraging in terms of accuracy and cost. Major features of our analysis are:(1) poly-variant analysis of functions by parameterization for the argument heap cells;(2) use of multiset formulas in expressing the sharings and partitionings of heap cells;(3) deallocations conditioned by dynamic flags that are passed as extra arguments to functions;(4) individual heap cell as the granularity of explicit memory-free. Our analysis and transformation is fully automatic.", "num_citations": "1\n", "authors": ["683"]}
{"title": "Automatic test data generation for exceptions in first-order ML programs\n", "abstract": " We present a static analysis to automatically generate test data that raise exceptions in the input programs. Using the test data from our analysis, the programmer can check whether the raised exceptions are correctly handled with respect to the program's specication.For a given program, starting from the initial constraint that a particular raise expression should be executed, our analysis derives necessary constraints for its input variable. The correctness of our analysis assures that any value that satis es the derived constraints for the input variable will activate the designated raise expression. In this paper, we formally present such an analysis for a rst-order language with the ML-style exception handling constructs and algebraic data values, prove its correctness, and show a set of examples.", "num_citations": "1\n", "authors": ["683"]}
{"title": "SparrowBerry: A verified validator for an industrial-strength static analyzer\n", "abstract": " In this article we present SparrowBerry: a verified validator for Sparse Sparrow, an industrial-strength static analyzer for the C language. Sparse Sparrow is a sound, global, yet scalable static analyzer whose design is proven correct by the abstract interpretation and our general sparse analysis frameworks. However, it does not necessarily mean that the implementation, which has lots of engineering, is also correct conforming to the design. To solve this problem, we attach a verified validator to the analyzer: the validator checks if the analysis result from Sparse Sparrow is indeed a sound abstract semantics of the input C program. The validator is extracted from our 20 K-line Coq proof for the correctness of the underlying \u201cvanilla\u201d abstract interpreter of Sparse Sparrow. We have demonstrated the feasibility of this verified validator by experiments with realistic benchmarks.", "num_citations": "1\n", "authors": ["683"]}