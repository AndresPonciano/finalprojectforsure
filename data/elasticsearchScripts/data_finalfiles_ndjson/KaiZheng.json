{"title": "Adapting to user interest drift for poi recommendation\n", "abstract": " Point-of-Interest recommendation is an essential means to help people discover attractive locations, especially when people travel out of town or to unfamiliar regions. While a growing line of research has focused on modeling user geographical preferences for POI recommendation, they ignore the phenomenon of user interest drift across geographical regions, i.e., users tend to have different interests when they travel in different regions, which discounts the recommendation quality of existing methods, especially for out-of-town users. In this paper, we propose a latent class probabilistic generative model Spatial-Temporal LDA (ST-LDA) to learn region-dependent personal interests according to the contents of their checked-in POIs at each region. As the users' check-in records left in the out-of-town regions are extremely sparse, ST-LDA incorporates the crowd's preferences by considering the public's visiting\u00a0\u2026", "num_citations": "225\n", "authors": ["2104"]}
{"title": "Online discovery of gathering patterns over trajectories\n", "abstract": " The increasing pervasiveness of location-acquisition technologies has enabled collection of huge amount of trajectories for almost any kind of moving objects. Discovering useful patterns from their movement behaviors can convey valuable knowledge to a variety of critical applications. In this light, we propose a novel concept, called gathering, which is a trajectory pattern modeling various group incidents such as celebrations, parades, protests, traffic jams and so on. A key observation is that these incidents typically involve large congregations of individuals, which form durable and stable areas with high density. In this work, we first develop a set of novel techniques to tackle the challenge of efficient discovery of gathering patterns on archived trajectory dataset. Afterwards, since trajectory databases are inherently dynamic in many real-world scenarios such as traffic monitoring, fleet management and battlefield\u00a0\u2026", "num_citations": "191\n", "authors": ["2104"]}
{"title": "Towards efficient search for activity trajectories\n", "abstract": " The advances in location positioning and wireless communication technologies have led to a myriad of spatial trajectories representing the mobility of a variety of moving objects. While processing trajectory data with the focus of spatio-temporal features has been widely studied in the last decade, recent proliferation in location-based web applications (e.g., Foursquare, Facebook) has given rise to large amounts of trajectories associated with activity information, called activity trajectory. In this paper, we study the problem of efficient similarity search on activity trajectory database. Given a sequence of query locations, each associated with a set of desired activities, an activity trajectory similarity query (ATSQ) returns k trajectories that cover the query activities and yield the shortest minimum match distance. An order-sensitive activity trajectory similarity query (OATSQ) is also proposed to take into account the order of\u00a0\u2026", "num_citations": "172\n", "authors": ["2104"]}
{"title": "User Oriented Trajectory Search for Trip Recommendation\n", "abstract": " Trajectory sharing and searching have received significant attentions in recent years. In this paper, we propose and investigate a novel problem called User Oriented Trajectory Search (UOTS) for trip recommendation. In contrast to conventional trajectory search by locations (spatial domain only), we consider both spatial and textual domains in the new UOTS query. Given a trajectory data set, the query input contains a set of intended places given by the traveler and a set of textual attributes describing the traveler's preference. If a trajectory is connecting/close to the specified query locations, and the textual attributes of the trajectory are similar to the traveler'e preference, it will be recommended to the traveler for reference. This type of queries can bring significant benefits to travelers in many popular applications such as trip planning and recommendation.", "num_citations": "165\n", "authors": ["2104"]}
{"title": "Short text understanding through lexical-semantic analysis\n", "abstract": " Understanding short texts is crucial to many applications, but challenges abound. First, short texts do not always observe the syntax of a written language. As a result, traditional natural language processing methods cannot be easily applied. Second, short texts usually do not contain sufficient statistical signals to support many state-of-the-art approaches for text processing such as topic modeling. Third, short texts are usually more ambiguous. We argue that knowledge is needed in order to better understand short texts. In this work, we use lexical-semantic knowledge provided by a well-known semantic network for short text understanding. Our knowledge-intensive approach disrupts traditional methods for tasks such as text segmentation, part-of-speech tagging, and concept labeling, in the sense that we focus on semantics in all these tasks. We conduct a comprehensive performance evaluation on real-life data\u00a0\u2026", "num_citations": "156\n", "authors": ["2104"]}
{"title": "An effectiveness study on trajectory similarity measures\n", "abstract": " The last decade has witnessed the prevalence of sensor and GPS technologies that produce a sheer volume of trajectory data representing the motion history of moving objects. Measuring similarity between trajectories is undoubtedly one of the most important tasks in trajectory data management since it serves as the foundation of many advanced analyses such as similarity search, clustering, and classification. In this light, tremendous efforts have been spent on this topic, which results in a large number of trajectory similarity measures. Generally, each individual work introducing a new distance measure has made specific claims on the superiority of their proposal. However, for most works, the experimental study was focused on demonstrating the efficiency of the search algorithms, leaving the effectiveness aspect unverified empirically. In this paper, we conduct a comparative experimental study on the effectiveness of six widely used trajectory similarity measures based on a real taxi trajectory dataset. By applying a variety of transformations we designed for each original trajectory, our experimental observations demonstrate the advantages and drawbacks of these similarity measures in different circumstances.", "num_citations": "155\n", "authors": ["2104"]}
{"title": "Discovering interpretable geo-social communities for user behavior prediction\n", "abstract": " Social community detection is a growing field of interest in the area of social network applications, and many approaches have been developed, including graph partitioning, latent space model, block model and spectral clustering. Most existing work purely focuses on network structure information which is, however, often sparse, noisy and lack of interpretability. To improve the accuracy and interpretability of community discovery, we propose to infer users' social communities by incorporating their spatiotemporal data and semantic information. Technically, we propose a unified probabilistic generative model, User-Community-Geo-Topic (UCGT), to simulate the generative process of communities as a result of network proximities, spatiotemporal co-occurrences and semantic similarity. With a well-designed multi-component model structure and a parallel inference implementation to leverage the power of multicores\u00a0\u2026", "num_citations": "142\n", "authors": ["2104"]}
{"title": "Personalized trajectory matching in spatial networks\n", "abstract": " With the increasing availability of moving-object tracking data, trajectory search and matching is increasingly important. We propose and investigate a novel problem called personalized trajectory matching (PTM). In contrast to conventional trajectory similarity search by spatial distance only, PTM takes into account the significance of each sample point in a query trajectory. A PTM query takes a trajectory with user-specified weights for each sample point in the trajectory as its argument. It returns the trajectory in an argument data set with the highest similarity to the query trajectory. We believe that this type of query may bring significant benefits to users in many popular applications such as route planning, carpooling, friend recommendation, traffic analysis, urban computing, and location-based services in general. PTM query processing faces two challenges: how to prune the search space during the query\u00a0\u2026", "num_citations": "138\n", "authors": ["2104"]}
{"title": "Lc-rnn: A deep learning model for traffic speed prediction.\n", "abstract": " Traffic speed prediction is known as an important but challenging problem. In this paper, we propose a novel model, called LC-RNN, to achieve more accurate traffic speed prediction than existing solutions. It takes advantage of both RNN and CNN models by a rational integration of them, so as to learn more meaningful time-series patterns that can adapt to the traffic dynamics of surrounding areas. Furthermore, since traffic evolution is restricted by the underlying road network, a network embedded convolution structure is proposed to capture topology aware features. The fusion with other information, including periodicity and context factors, is also considered to further improve accuracy. Extensive experiments on two real datasets demonstrate that our proposed LC-RNN outperforms seven well-known existing methods.", "num_citations": "117\n", "authors": ["2104"]}
{"title": "Trajectory similarity join in spatial networks\n", "abstract": " The matching of similar pairs of objects, called similarity join, is fundamental functionality in data management. We consider the case of trajectory similarity join (TS-Join), where the objects are trajectories of vehicles moving in road networks. Thus, given two sets of trajectories and a threshold \u03b8, the TS-Join returns all pairs of trajectories from the two sets with similarity above \u03b8. This join targets applications such as trajectory near-duplicate detection, data cleaning, ridesharing recommendation, and traffic congestion prediction.With these applications in mind, we provide a purposeful definition of similarity. To enable efficient TS-Join processing on large sets of trajectories, we develop search space pruning techniques and take into account the parallel processing capabilities of modern processors. Specifically, we present a two-phase divideand-conquer algorithm. For each trajectory, the algorithm first finds similar trajectories. Then it merges the results to achieve a final result. The algorithm exploits an upper bound on the spatiotemporal similarity and a heuristic scheduling strategy for search space pruning. The algorithm\u2019s per-trajectory searches are independent of each other and can be performed in parallel, and the merging has constant cost. An empirical study with real data offers insight in the performance of the algorithm and demonstrates that is capable of outperforming a well-designed baseline algorithm by an order of magnitude.", "num_citations": "109\n", "authors": ["2104"]}
{"title": "Probabilistic range queries for uncertain trajectories on road networks\n", "abstract": " Trajectories representing the motion of moving objects are typically obtained via location sampling, eg using GPS or road-side sensors, at discrete time-instants. In-between consecutive samples, nothing is known about the whereabouts of a given moving object. Various models have been proposed (eg, sheared cylinders; spacetime prisms) to represent the uncertainty of the moving objects both in unconstrained Euclidian space, as well as road networks. In this paper, we focus on representing the uncertainty of the objects moving along road networks as time-dependent probability distribution functions, assuming availability of a maximal speed on each road segment. For these settings, we introduce a novel indexing mechanism--UTH (Uncertain Trajectories Hierarchy), based upon which efficient algorithms for processing spatio-temporal range queries are proposed. We also present experimental results that\u00a0\u2026", "num_citations": "106\n", "authors": ["2104"]}
{"title": "Calibrating trajectory data for similarity-based analysis\n", "abstract": " Due to the prevalence of GPS-enabled devices and wireless communications technologies, spatial trajectories that describe the movement history of moving objects are being generated and accumulated at an unprecedented pace. Trajectory data in a database are intrinsically heterogeneous, as they represent discrete approximations of original continuous paths derived using different sampling strategies and different sampling rates. Such heterogeneity can have a negative impact on the effectiveness of trajectory similarity measures, which are the basis of many crucial trajectory processing tasks. In this paper, we pioneer a systematic approach to trajectory calibration that is a process to transform a heterogeneous trajectory dataset to one with (almost) unified sampling strategies. Specifically, we propose an anchor-based calibration system that aligns trajectories to a set of anchor points, which are fixed locations\u00a0\u2026", "num_citations": "99\n", "authors": ["2104"]}
{"title": "Interactive top-k spatial keyword queries\n", "abstract": " Conventional top-k spatial keyword queries require users to explicitly specify their preferences between spatial proximity and keyword relevance. In this work we investigate how to eliminate this requirement by enhancing the conventional queries with interaction, resulting in Interactive Top-k Spatial Keyword (ITkSK) query. Having confirmed the feasibility by theoretical analysis, we propose a three-phase solution focusing on both effectiveness and efficiency. The first phase substantially narrows down the search space for subsequent phases by efficiently retrieving a set of geo-textual k-skyband objects as the initial candidates. In the second phase three practical strategies for selecting a subset of candidates are developed with the aim of maximizing the expected benefit for learning user preferences at each round of interaction. Finally we discuss how to determine the termination condition automatically and estimate\u00a0\u2026", "num_citations": "96\n", "authors": ["2104"]}
{"title": "Modeling user mobility for location promotion in location-based social networks\n", "abstract": " With the explosion of smartphones and social network services, location-based social networks (LBSNs) are increasingly seen as tools for businesses (eg, restaurants, hotels) to promote their products and services. In this paper, we investigate the key techniques that can help businesses promote their locations by advertising wisely through the underlying LBSNs. In order to maximize the benefit of location promotion, we formalize it as an influence maximization problem in an LBSN, ie, given a target location and an LBSN, which a set of k users (called seeds) should be advertised initially such that they can successfully propagate and attract most other users to visit the target location. Existing studies have proposed different ways to calculate the information propagation probability, that is how likely a user may influence another, in the settings of static social network. However, it is more challenging to derive the\u00a0\u2026", "num_citations": "89\n", "authors": ["2104"]}
{"title": "Crowdplanner: A crowd-based route recommendation system\n", "abstract": " As travel is taking more significant part in our life, route recommendation service becomes a big business and attracts many major players in IT industry. Given a pair of user-specified origin and destination, a route recommendation service aims to provide users with the routes of best travelling experience according to criteria, such as travelling distance, travelling time, traffic condition, etc. However, previous research shows that even the routes recommended by the big-thumb service providers can deviate significantly from the routes travelled by experienced drivers. It means travellers' preferences on route selection are influenced by many latent and dynamic factors that are hard to model exactly with pre-defined formulas. In this work we approach this challenging problem with a very different perspective- leveraging crowds' knowledge to improve the recommendation quality. In this light, CrowdPlanner - a novel\u00a0\u2026", "num_citations": "86\n", "authors": ["2104"]}
{"title": "Social influence-based group representation learning for group recommendation\n", "abstract": " As social animals, attending group activities is an indispensable part in people's daily social life, and it is an important task for recommender systems to suggest satisfying activities to a group of users. The major challenge in this task is how to aggregate personal preferences of group members to infer the decision of a group. Conventional group recommendation methods applied a predefined strategy for preference aggregation. However, these static strategies are too simple to model the real and complex process of group decision-making, especially for occasional groups which are formed ad-hoc. Moreover, group members should have non-uniform influences or weights in a group, and the weight of a user can be varied in different groups. Therefore, an ideal group recommender system should be able to accurately learn not only users' personal preferences but also the preference aggregation strategy from data\u00a0\u2026", "num_citations": "85\n", "authors": ["2104"]}
{"title": "Efficient secure similarity computation on encrypted trajectory data\n", "abstract": " Outsourcing database to clouds is a scalable and cost-effective way for large scale data storage, management, and query processing. Trajectory data contain rich spatio-temporal relationships and reveal many forms of individual sensitive information (e.g., home address, health condition), which necessitate them to be encrypted before being outsourced for privacy concerns. However, efficient query processing over encrypted trajectory data is a very challenging task. Though some achievements have been reported very recently for simple queries (e.g., SQL queries, kNN queries) on encrypted data, there is rather limited progress on secure evaluation of trajectory queries because they are more complex and need special treatment. In this paper, we focus on secure trajectory similarity computation that is the cornerstone of secure trajectory query processing. More specifically, we propose an efficient solution to\u00a0\u2026", "num_citations": "82\n", "authors": ["2104"]}
{"title": "Parallel trajectory similarity joins in spatial networks\n", "abstract": " The matching of similar pairs of objects, called similarity join, is fundamental functionality in data management. We consider two cases of trajectory similarity joins (TS-Joins), including a threshold-based join (Tb-TS-Join) and a top-k TS-Join (k-TS-Join), where the objects are trajectories of vehicles moving in road networks. Given two sets of trajectories and a threshold , the Tb-TS-Join returns all pairs of trajectories from the two sets with similarity above . In contrast, the k-TS-Join does not take a threshold as a parameter, and it returns the top-k most similar trajectory pairs from the two sets. The TS-Joins target diverse applications such as trajectory near-duplicate detection, data cleaning, ridesharing recommendation, and traffic congestion prediction. With these applications in mind, we provide purposeful definitions of similarity. To enable efficient processing of the TS-Joins on large sets of trajectories, we\u00a0\u2026", "num_citations": "77\n", "authors": ["2104"]}
{"title": "GeoMF++ scalable location recommendation via joint geographical modeling and matrix factorization\n", "abstract": " Location recommendation is an important means to help people discover attractive locations. However, extreme sparsity of user-location matrices leads to a severe challenge, so it is necessary to take implicit feedback characteristics of user mobility data into account and leverage the location\u2019s spatial information. To this end, based on previously developed GeoMF, we propose a scalable and flexible framework, dubbed GeoMF++, for joint geographical modeling and implicit feedback-based matrix factorization. We then develop an efficient optimization algorithm for parameter learning, which scales linearly with data size and the total number of neighbor grids of all locations. GeoMF++ can be well explained from two perspectives. First, it subsumes two-dimensional kernel density estimation so that it captures spatial clustering phenomenon in user mobility data; Second, it is strongly connected with widely used\u00a0\u2026", "num_citations": "74\n", "authors": ["2104"]}
{"title": "Multimedia event detection using a classifier-specific intermediate representation\n", "abstract": " Multimedia event detection (MED) plays an important role in many applications such as video indexing and retrieval. Current event detection works mainly focus on sports and news event detection or abnormality detection in surveillance videos. Differently, our research aims to detect more complicated and generic events within a longer video sequence. In the past, researchers have proposed using intermediate concept classifiers with concept lexica to help understand the videos. Yet it is difficult to judge how many and what concepts would be sufficient for the particular video analysis task. Additionally, obtaining robust semantic concept classifiers requires a large number of positive training examples, which in turn has high human annotation cost. In this paper, we propose an approach that exploits the external concepts-based videos and event-based videos simultaneously to learn an intermediate representation\u00a0\u2026", "num_citations": "71\n", "authors": ["2104"]}
{"title": "Sharkdb: An in-memory column-oriented trajectory storage\n", "abstract": " The last decade has witnessed the prevalence of sensor and GPS technologies that produce a high volume of trajectory data representing the motion history of moving objects. However some characteristics of trajectories such as variable lengths and asynchronous sampling rates make it difficult to fit into traditional database systems that are disk-based and tuple-oriented. Motivated by the success of column store and recent development of in-memory databases, we try to explore the potential opportunities of boosting the performance of trajectory data processing by designing a novel trajectory storage within main memory. In contrast to most existing trajectory indexing methods that keep consecutive samples of the same trajectory in the same disk page, we partition the database into frames in which the positions of all moving objects at the same time instant are stored together and aligned in main memory. We\u00a0\u2026", "num_citations": "66\n", "authors": ["2104"]}
{"title": "Understand short texts by harvesting and analyzing semantic knowledge\n", "abstract": " Understanding short texts is crucial to many applications, but challenges abound. First, short texts do not always observe the syntax of a written language. As a result, traditional natural language processing tools, ranging from part-of-speech tagging to dependency parsing, cannot be easily applied. Second, short texts usually do not contain sufficient statistical signals to support many state-of-the-art approaches for text mining such as topic modeling. Third, short texts are more ambiguous and noisy, and are generated in an enormous volume, which further increases the difficulty to handle them. We argue that semantic knowledge is required in order to better understand short texts. In this work, we build a prototype system for short text understanding which exploits semantic knowledge provided by a well-known knowledgebase and automatically harvested from a web corpus. Our knowledge-intensive approaches\u00a0\u2026", "num_citations": "62\n", "authors": ["2104"]}
{"title": "An improved early detection method of type-2 diabetes mellitus using multiple classifier system\n", "abstract": " The specific causes of complex diseases such as Type-2 Diabetes Mellitus (T2DM) have not yet been identified. Nevertheless, many medical science researchers believe that complex diseases are caused by a combination of genetic, environmental, and lifestyle factors. Detection of such diseases becomes an issue because it is not free from false presumptions and is accompanied by unpredictable effects. Given the greatly increased amount of data gathered in medical databases, data mining has been used widely in recent years to detect and improve the diagnosis of complex diseases. However, past research showed that no single classifier can be considered optimal for all problems. Therefore, in this paper, we focus on employing multiple classifier systems to improve the accuracy of detection for complex diseases, such as T2DM. We proposed a dynamic weighted voting scheme called multiple factors\u00a0\u2026", "num_citations": "62\n", "authors": ["2104"]}
{"title": "EtherQL: a query layer for blockchain system\n", "abstract": " Blockchain - the innovation behind Bitcoin - enables people to exchange digital money with complete trust, and seems to be completely transforming the way we think about trust. While blockchain is designed for secured, immutable funds transfer in trustless and decentralized environment, the underlying storage of blockchain is very simple with only limited supports for data access. Moreover, blockchain data are highly compressed before flushing to hard disk, making it harder to have an insight of these valuable data set. In this work, we develop EtherQL, an efficient query layer for Ethereum \u2013 the most representative open-source blockchain system. EtherQL provides highly efficient query primitives for analyzing blockchain data, including range queries and top-k queries, which can be integrated with other applications with much flexibility. Moreover, EtherQL is designed to provide different levels of\u00a0\u2026", "num_citations": "61\n", "authors": ["2104"]}
{"title": "Calibrating trajectory data for spatio-temporal similarity analysis\n", "abstract": " Due to the prevalence of GPS-enabled devices and wireless communications technologies, spatial trajectories that describe the movement history of moving objects are being generated and accumulated at an unprecedented pace. Trajectory data in a database are intrinsically heterogeneous, as they represent discrete approximations of original continuous paths derived using different sampling strategies and different sampling rates. Such heterogeneity can have a negative impact on the effectiveness of trajectory similarity measures, which are the basis of many crucial trajectory processing tasks. In this paper, we pioneer a systematic approach to trajectory calibration that is a process to transform a heterogeneous trajectory dataset to one with (almost) unified sampling strategies. Specifically, we propose an anchor-based calibration system that aligns trajectories to a set of anchor points, which are fixed\u00a0\u2026", "num_citations": "58\n", "authors": ["2104"]}
{"title": "Discovery of path nearby clusters in spatial networks\n", "abstract": " The discovery of regions of interest in large cities is an important challenge. We propose and investigate a novel query called the path nearby cluster (PNC) query that finds regions of potential interest (e.g., sightseeing places and commercial districts) with respect to a user-specified travel route. Given a set of spatial objects O (e.g., POIs, geo-tagged photos, or geo-tagged tweets) and a query route q, if a cluster c has high spatial-object density and is spatially close to q, it is returned by the query (a cluster is a circular region defined by a center and a radius). This query aims to bring important benefits to users in popular applications such as trip planning and location recommendation. Efficient computation of the PNC query faces two challenges: how to prune the search space during query processing, and how to identify clusters with high density effectively. To address these challenges, a novel collective search\u00a0\u2026", "num_citations": "56\n", "authors": ["2104"]}
{"title": "Learning transferable self-attentive representations for action recognition in untrimmed videos with weak supervision\n", "abstract": " Action recognition in videos has attracted a lot of attention in the past decade. In order to learn robust models, previous methods usually assume videos are trimmed as short sequences and require ground-truth annotations of each video frame/sequence, which is quite costly and time-consuming. In this paper, given only video-level annotations, we propose a novel weakly supervised framework to simultaneously locate action frames as well as recognize actions in untrimmed videos. Our proposed framework consists of two major components. First, for action frame localization, we take advantage of the self-attention mechanism to weight each frame, such that the influence of background frames can be effectively eliminated. Second, considering that there are trimmed videos publicly available and also they contain useful information to leverage, we present an additional module to transfer the knowledge from trimmed videos for improving the classification performance in untrimmed ones. Extensive experiments are conducted on two benchmark datasets (ie, THUMOS14 and ActivityNet1. 3), and experimental results clearly corroborate the efficacy of our method.", "num_citations": "53\n", "authors": ["2104"]}
{"title": "Keyword-aware continuous knn query on road networks\n", "abstract": " It is nowadays quite common for road networks to have textual contents on the vertices, which describe auxiliary information (e.g., business, traffic, etc.) associated with the vertex. In such road networks, which are modelled as weighted undirected graphs, each vertex is associated with one or more keywords, and each edge is assigned with a weight, which can be its physical length or travelling time. In this paper, we study the problem of keyword-aware continuous k nearest neighbour (KCkNN) search on road networks, which computes the k nearest vertices that contain the query keywords issued by a moving object and maintains the results continuously as the object is moving on the road network. Reducing the query processing costs in terms of computation and communication has attracted considerable attention in the database community with interesting techniques proposed. This paper proposes a framework\u00a0\u2026", "num_citations": "53\n", "authors": ["2104"]}
{"title": "Multi-constrained graph pattern matching in large-scale contextual social graphs\n", "abstract": " Graph Pattern Matching (GPM) plays a significant role in social network analysis, which has been widely used in, for example, experts finding, social community mining and social position detection. Given a pattern graph G Q  and a data graph G D , a GPM algorithm finds those subgraphs, G M , that match G Q  in G D . However, the existing GPM methods do not consider the multiple constraints on edges in G Q , which are commonly exist in various applications such as, crowdsourcing travel, social network based e-commerce and study group selection, etc. In this paper, we first conceptually extend Bounded Simulation to Multi-Constrained Simulation (MCS), and propose a novel NP-Complete Multi-Constrained Graph Pattern Matching (MC-GPM) problem. Then, to address the efficiency issue in large-scale MC-GPM, we propose a new concept called Strong Social Component (SSC), consisting of participants with\u00a0\u2026", "num_citations": "53\n", "authors": ["2104"]}
{"title": "Parallel trajectory-to-location join\n", "abstract": " The matching between trajectories and locations, called Trajectory-to-Location join (TL-Join), is fundamental functionality in spatiotemporal data management. Given a set of trajectories, a set of locations, and a threshold 8, the TL-Join finds all (trajectory, location) pairs from the two sets with spatiotemporal correlation above 8. This join targets diverse applications, including location recommendation, event tracking, and trajectory activity analyses. We address three challenges in relation to the TL-Join: how to define the spatiotemporal correlation between trajectories and locations, how to prune the search space effectively when computing the join, and how to perform the computation in parallel. Specifically, we define new metrics to measure the spatiotemporal correlation between trajectories and locations. We develop a novel parallel collaborative (PCol) search method based on a divide-and-conquer strategy. For\u00a0\u2026", "num_citations": "52\n", "authors": ["2104"]}
{"title": "Making sense of trajectory data: A partition-and-summarization approach\n", "abstract": " Due to the prevalence of GPS-enabled devices and wireless communication technology, spatial trajectories that describe the movement history of moving objects are being generated and accumulated at an unprecedented pace. However, a raw trajectory in the form of sequence of timestamped locations does not make much sense for humans without semantic representation. In this work we aim to facilitate human's understanding of a raw trajectory by automatically generating a short text to describe it. By formulating this task as the problem of adaptive trajectory segmentation and feature selection, we propose a partition-and-summarization framework. In the partition phase, we first define a set of features for each trajectory segment and then derive an optimal partition with the aim to make the segments within each partition as homogeneous as possible in terms of their features. In the summarization phase, for each\u00a0\u2026", "num_citations": "51\n", "authors": ["2104"]}
{"title": "Efficient clue-based route search on road networks\n", "abstract": " With the advances in geo-positioning technologies and location-based services, it is nowadays quite common for road networks to have textual contents on the vertices. Previous work on identifying an optimal route that covers a sequence of query keywords has been studied in recent years. However, in many practical scenarios, an optimal route might not always be desirable. For example, a personalized route query is issued by providing some clues that describe the spatial context between PoIs along the route, where the result can be far from the optimal one. Therefore, in this paper, we investigate the problem of clue-based route search (CRS), which allows a user to provide clues on keywords and spatial relationships. First, we propose a greedy algorithm and a dynamic programming algorithm as baselines. To improve efficiency, we develop a branch-and-bound algorithm that prunes unnecessary vertices in\u00a0\u2026", "num_citations": "48\n", "authors": ["2104"]}
{"title": "Planning unobstructed paths in traffic-aware spatial networks\n", "abstract": " Route planning and recommendation have received significant attention in recent years. In this light, we study a novel problem of planning unobstructed paths in traffic-aware spatial networks (TAUP queries) to avoid potential traffic congestions. We propose two probabilistic TAUP queries: (1) a time-threshold query like \u201cwhat is the path from the check-in desk to the flight SK 1217 with the minimum congestion probability to take at most 45 minutes?\u201d, and (2) a probability-threshold query like \u201cwhat is the fastest path from the check-in desk to the flight SK 1217 whose congestion probability is less than 20 %?\u201d. These queries are mainly motivated by indoor space applications, but are also applicable in outdoor spaces. We believe that these queries are useful in some popular applications, such as planning unobstructed paths for VIP bags in airports and planning convenient routes for travelers. The TAUP\u00a0\u2026", "num_citations": "46\n", "authors": ["2104"]}
{"title": "K-nearest neighbor search for fuzzy objects\n", "abstract": " The K-Nearest Neighbor search (kNN) problem has been investigated extensively in the past due to its broad range of applications. In this paper we study this problem in the context of fuzzy objects that have indeterministic boundaries. Fuzzy objects play an important role in many areas, such as biomedical image databases and GIS. Existing research on fuzzy objects mainly focuses on modelling basic fuzzy object types and operations, leaving the processing of more advanced queries such as kNN query untouched. In this paper, we propose two new kinds of kNN queries for fuzzy objects, Ad-hoc kNN query (AKNN) and Range kNN query (RKNN), to find the k nearest objects qualifying at a probability threshold or within a probability range. For efficient AKNN query processing, we optimize the basic best-first search algorithm by deriving more accurate approximations for the distance function between fuzzy objects\u00a0\u2026", "num_citations": "44\n", "authors": ["2104"]}
{"title": "Microblog entity linking with social temporal context\n", "abstract": " Nowadays microblogging sites, such as Twitter and Chinese Sina Weibo, have established themselves as an invaluable information source, which provides a huge collection of manually-generated tweets with broad range of topics from daily life to breaking news. Entity linking is indispensable for understanding and maintaining such information, which in turn facilitates many real-world applications such as tweet clustering and classification, personalized microblog search, and so forth. However, tweets are short, informal and error-prone, rendering traditional approaches for entity linking in documents largely inapplicable. Recent work addresses this problem by utilising information from other tweets and linking entities in a batch manner. Nevertheless, the high computational complexity makes this approach infeasible for real-time applications given the high arrival rate of tweets. In this paper, we propose an efficient\u00a0\u2026", "num_citations": "43\n", "authors": ["2104"]}
{"title": "Destination-aware task assignment in spatial crowdsourcing\n", "abstract": " With the proliferation of GPS-enabled smart devices and increased availability of wireless network, spatial crowdsourcing (SC) has been recently proposed as a framework to automatically request workers (ie, smart device carriers) to perform location-sensitive tasks (eg, taking scenic photos, reporting events). In this paper we study a destination-aware task assignment problem that concerns the optimal strategy of assigning each task to proper worker such that the total number of completed tasks can be maximized whilst all workers can reach their destinations before deadlines after performing assigned tasks. Finding the global optimal assignment turns out to be an intractable problem since it does not imply optimal assignment for individual worker. Observing that the task assignment dependency only exists amongst subsets of workers, we utilize tree-decomposition technique to separate workers into independent\u00a0\u2026", "num_citations": "39\n", "authors": ["2104"]}
{"title": "STMaker: a system to make sense of trajectory data\n", "abstract": " Widely adoption of GPS-enabled devices generates large amounts of trajectories every day. The raw trajectory data describes the movement history of moving objects by a sequence of < longitude, latitude, time-stamp > triples, which are nonintuitive for human to perceive the prominent features of the trajectory, such as where and how the moving object travels. In this demo, we present the STMaker system to help users make sense of individual trajectories. Given a trajectory, STMaker can automatically extract the significant semantic behavior of the trajectory, and summarize the behavior by a short human-readable text. In this paper, we first introduce the phrases of generating trajectory summarizations, and then show several real trajectory summarization cases.", "num_citations": "39\n", "authors": ["2104"]}
{"title": "PNN query processing on compressed trajectories\n", "abstract": " Trajectory compression is widely used in spatial-temporal databases as it can notably reduce (i) the computation/communication load of clients (GPS-enabled mobile devices) and (ii) the storage cost of servers. Compared with original trajectories, compressed trajectories have clear advantages in data processing, transmitting, storing, etc. In this paper, we investigate a novel problem of searching the Path Nearest Neighbor based on Compressed Trajectories (PNN-CT query). This type of query is conducted on compressed trajectories and the target is to retrieve the PNN with the highest probability (lossy compression leads to the uncertainty), which can bring significant benefits to users in many popular applications such as trip planning. To answer the PNN-CT query effectively and efficiently, a two-phase solution is proposed. First, we use the meta-data and sample points to specify a tight search range. The\u00a0\u2026", "num_citations": "37\n", "authors": ["2104"]}
{"title": "SRA: Secure reverse auction for task assignment in spatial crowdsourcing\n", "abstract": " In this paper, we study a new type of spatial crowdsourcing, namely competitive detour tasking, where workers can make detours from their original travel paths to perform multiple tasks, and each worker is allowed to compete for preferred tasks by strategically claiming his/her detour costs. The objective is to make suitable task assignment by maximizing the social welfare of crowdsourcing systems and protecting workers' private sensitive information. We first model the task assignment problem as a reverse auction process. We formalize the winning bid selection of reverse auction as an n-to-one weighted bipartite graph matching problem with multiple 0-1 knapsack constraints. Since this problem is NP-hard, we design an approximation algorithm to select winning bids and determine corresponding payments. Based on this, a Secure Reverse Auction (SRA) protocol is proposed for this novel spatial crowdsourcing\u00a0\u2026", "num_citations": "36\n", "authors": ["2104"]}
{"title": "Rest: A reference-based framework for spatio-temporal trajectory compression\n", "abstract": " The pervasiveness of GPS-enabled devices and wireless communication technologies results in massive trajectory data, incurring expensive cost for storage, transmission, and query processing. To relieve this problem, in this paper we propose a novel framework for compressing trajectory data, REST (Reference-based Spatio-temporal trajectory compression), by which a raw trajectory is represented by concatenation of a series of historical (sub-) trajectories (called reference trajectories) that form the compressed trajectory within a given spatio-temporal deviation threshold. In order to construct a reference trajectory set that can most benefit the subsequent compression, we propose three kinds of techniques to select reference trajectories wisely from a large dataset such that the resulting reference set is more compact yet covering most footprints of trajectories in the area of interest. To address the computational\u00a0\u2026", "num_citations": "36\n", "authors": ["2104"]}
{"title": "A survey of trajectory distance measures and performance evaluation\n", "abstract": " The proliferation of trajectory data in various application domains has inspired tremendous research efforts to analyze large-scale trajectory data from a variety of aspects. A fundamental ingredient of these trajectory analysis tasks and applications is distance measures for effectively determining how similar two trajectories are. We conduct a comprehensive survey of the trajectory distance measures. The trajectory distance measures are classified into four categories according to the trajectory data type and whether the temporal information is measured. In addition, the effectiveness and complexity of each distance measure are studied. The experimental study is also conducted on their effectiveness in the six different trajectory transformations.", "num_citations": "35\n", "authors": ["2104"]}
{"title": "Graph-based clustering and ranking for diversified image search\n", "abstract": " In this paper, we consider the problem of clustering and re-ranking web image search results so as to improve diversity at high ranks. We propose a novel ranking framework, namely cluster-constrained conditional Markov random walk (CCCMRW), which has two key steps: first, cluster images into topics, and then perform Markov random walk in an image graph conditioned on constraints of image cluster information. In order to cluster the retrieval results of web images, a novel graph clustering model is proposed in this paper. We explore the surrounding text to mine the correlations between words and images and therefore the correlations are used to improve clustering results. Two kinds of correlations, namely word to image and word to word correlations, are mainly considered. As a standard text process technique, tf-idf method cannot measure the correlation of word to image directly. Therefore, we\u00a0\u2026", "num_citations": "35\n", "authors": ["2104"]}
{"title": "Finding alternative shortest paths in spatial networks\n", "abstract": " Shortest path query is one of the most fundamental queries in spatial network databases. There exist algorithms that can process shortest path queries in real time. However, many complex applications require more than just the calculation of a single shortest path. For example, one of the common ways to determine the importance (or price) of a vertex or an edge in spatial network is to use Vickrey pricing, which intuitively values the vertex v (or edge e) based on how much harder for travelling from the sources to the destinations without using v (or e). In such cases, the alternative shortest paths without using v (or e) are required. In this article, we propose using a precomputation based approach for both single pair alternative shortest path and all pairs shortest paths processing. To compute the alternative shortest path between a source and a destination efficiently, a na\u00efive way is to precompute and store all\u00a0\u2026", "num_citations": "35\n", "authors": ["2104"]}
{"title": "Go slow to go fast: minimal on-road time route scheduling with parking facilities using historical trajectory\n", "abstract": " For thousands of years, people have been innovating new technologies to make their travel faster, the latest of which is GPS technology that is used by millions of drivers every day. The routes recommended by a GPS device are computed by path planning algorithms (e.g., fastest path algorithm), which aim to minimize a certain objective function (e.g., travel time) under the current traffic condition. When the objective is to arrive the destination as early as possible, waiting during travel is not an option as it will only increase the total travel time due to the First-In-First-Out property of most road networks. However, some businesses such as logistics companies are more interested in optimizing the actual on-road time of their vehicles (i.e., while the engine is running) since it is directly related to the operational cost. At the same time, the drivers\u2019 trajectories, which can reveal the traffic conditions on the roads, are\u00a0\u2026", "num_citations": "34\n", "authors": ["2104"]}
{"title": "TOSI: A trust-oriented social influence evaluation method in contextual social networks\n", "abstract": " Online Social Networks (OSNs) have been used as the means for a variety of applications. For example, social networking platform has been used in employment system, e-Commerce and CRM system to improve the quality of recommendations with the assistance of social networks. In these applications, social influence acts as a significant role, affecting people's decision-making. However, the existing social influence evaluation methods do not fully consider the social contexts, i.e., the social relationships and the social trust between participants, and the preferences of participants, which have significant impact on social influence evaluation in OSNs. Thus, these existing methods cannot deliver accurate social influence evaluation results. In our paper, we propose a Trust-Oriented Social Influence evaluation method, called TOSI, with taking the social contexts into account. We conduct experiments onto two real\u00a0\u2026", "num_citations": "34\n", "authors": ["2104"]}
{"title": "MCS-GPM: Multi-constrained simulation based graph pattern matching in contextual social graphs\n", "abstract": " Graph Pattern Matching (GPM) has been used in lots of areas, like biology, medical science, and physics. With the advent of Online Social Networks (OSNs), recently, GPM has been playing a significant role in social network analysis, which has been widely used in, for example, finding experts, social community mining, and social position detection. Given a query which contains a pattern graph G Q  and a data graph G D , a GPM algorithm finds those subgraphs, G M , that match G Q  in G D . However, the existing GPM methods do not consider the multiple end-to-end constraints of the social contexts, like social relationships, social trust, and social positions on edges in G Q , which are commonly found in various applications, such as crowdsourcing travel, social network based ecommerce, and study group selection, etc. In this paper, we first conceptually extend Bounded Simulation to Multi-Constrained Simulation\u00a0\u2026", "num_citations": "33\n", "authors": ["2104"]}
{"title": "Popularity-aware spatial keyword search on activity trajectories\n", "abstract": " The proliferation of GPS-enabled smart mobile devices enables us to collect a large-scale trajectories of moving objects with GPS tags. While the raw trajectories that only consists of positional information have been studied extensively, many recent works have been focusing on enriching the raw trajectories with semantic knowledge. The resulting data, called activity trajectories, embed the information about behaviors of the moving objects and support a variety of applications for better quality of services. In this paper, we propose a Top-k Spatial Keyword (TkSK) query for activity trajectories, with the objective to find a set of trajectories that are not only close geographically but also meet the requirements of the query semantically. Such kind of query can deliver more informative results than existing spatial keyword queries for static objects, since activity trajectories are able to reflect the popularity of user\u00a0\u2026", "num_citations": "33\n", "authors": ["2104"]}
{"title": "Probesim: scalable single-source and top-k simrank computations on dynamic graphs\n", "abstract": " Single-source and top- SimRank queries are two important types of similarity search in graphs with numerous applications in web mining, social network analysis, spam detection, etc. A plethora of techniques have been proposed for these two types of queries, but very few can efficiently support similarity search over large dynamic graphs, due to either significant preprocessing time or large space overheads. This paper presents ProbeSim, an index-free algorithm for single-source and top- SimRank queries that provides a non-trivial theoretical guarantee in the absolute error of query results. ProbeSim estimates SimRank similarities without precomputing any indexing structures, and thus can naturally support real-time SimRank queries on dynamic graphs. Besides the theoretical guarantee, ProbeSim also offers satisfying practical efficiency and effectiveness due to several non-trivial optimizations. We conduct extensive experiments on a number of benchmark datasets, which demonstrate that our solutions significantly outperform the existing methods in terms of efficiency and effectiveness. Notably, our experiments include the first empirical study that evaluates the effectiveness of SimRank algorithms on graphs with billion edges, using the idea of pooling.", "num_citations": "32\n", "authors": ["2104"]}
{"title": "Multi-view ensemble learning for dementia diagnosis from neuroimaging: An artificial neural network approach\n", "abstract": " Identifying abnormalities from neuroimaging of brain matters has been a crucial way of diagnosis of two closely associated diseases, namely Alzheimer\u05f3s Disease (AD) and Mild Cognitive Impairment (MCI). Different types of neuroimaging have been developed to help such diagnosis, and significant research efforts are put into the automation and quantification of such diagnosis by computer algorithms over the past decades. In this paper we propose an ensemble learning framework to create effective models for AD/MCI related classification tasks from multiple modalities of neuroimaging and multiple baseline estimators. The framework is based on artificial neural networks and it resembles a composite model that solves the feature fusion learning problem as well as the prediction problem simultaneously, which targets at exploiting the prediction power of both fusing multiple data modalities and leveraging multiple\u00a0\u2026", "num_citations": "31\n", "authors": ["2104"]}
{"title": "Semantic-aware top-k spatial keyword queries\n", "abstract": " The fast development of GPS equipped devices has aroused widespread use of spatial keyword querying in location based services nowadays. Existing spatial keyword query methodologies mainly focus on the spatial and textual similarities, while leaving the semantic understanding of keywords in spatial Web objects and queries to be ignored. To address this issue, this paper studies the problem of semantic based spatial keyword querying. It seeks to return the k objects most similar to the query, subject to not only their spatial and textual properties, but also the coherence of their semantic meanings. To achieve that, we propose novel indexing structures, which integrate spatial, textual and semantic information in a hierarchical manner, so as to prune the search space effectively in query processing. Extensive experiments are carried out to evaluate and compare them with other baseline algorithms.", "num_citations": "30\n", "authors": ["2104"]}
{"title": "PM-LSH: A fast and accurate LSH framework for high-dimensional approximate NN search\n", "abstract": " Nearest neighbor (NN) search in high-dimensional spaces is inherently computationally expensive due to the curse of dimensionality. As a well-known solution to approximate NN search, locality-sensitive hashing (LSH) is able to answer c-approximate NN (c-ANN) queries in sublinear time with constant probability. Existing LSH methods focus mainly on building hash bucket based indexing such that the candidate points can be retrieved quickly. However, existing coarse-grained structures fail to offer accurate distance estimation for candidate points, which translates into additional computational overhead when having to examine unnecessary points. This in turn reduces the performance of query processing. In contrast, we propose a fast and accurate LSH framework, called PM-LSH, that aims to compute the c-ANN query on large-scale, high-dimensional datasets. First, we adopt a simple yet effective PM-tree to index the data points. Second, we develop a tunable confidence interval to achieve accurate distance estimation and guarantee high result quality. Third, we propose an efficient algorithm on top of the PM-tree to improve the performance of computing c-ANN queries. Extensive experiments with real-world data offer evidence that PM-LSH is capable of outperforming existing proposals with respect to both efficiency and accuracy.", "num_citations": "29\n", "authors": ["2104"]}
{"title": "Reference-based framework for spatio-temporal trajectory compression and query processing\n", "abstract": " The pervasiveness of GPS-enabled devices and wireless communication technologies results in massive trajectory data, incurring expensive cost for storage, transmission, and query processing. To relieve this problem, in this paper we propose a novel framework for compressing trajectory data, REST ( Re ference-based  S patio- t emporal trajectory compression), by which a raw trajectory is represented by concatenation of a series of historical (sub-)trajectories (called reference trajectories) that form the compressed trajectory within a given spatio-temporal deviation threshold. In order to construct a reference trajectory set that can most benefit the subsequent compression, we propose three kinds of techniques to select reference trajectories wisely from a large dataset such that the resulting reference set is more compact yet covering most footprints of trajectories in the area of interest. To address the computational\u00a0\u2026", "num_citations": "29\n", "authors": ["2104"]}
{"title": "Exploiting spatio-temporal user behaviors for user linkage\n", "abstract": " Cross-device and cross-domain user linkage have been attracting a lot of attention recently. An important branch of the study is to achieve user linkage with spatio-temporal data generated by the ubiquitous GPS-enabled devices. The main task in this problem is twofold, ie, how to extract the representative features of a user; how to measure the similarities between users with the extracted features. To tackle the problem, we propose a novel model STUL (Spatio-Temporal User Linkage) that consists of the following two components. 1) Extract users-spatial features with a density based clustering method, and extract the users-temporal features with the Gaussian Mixture Model. To link user pairs more precisely, we assign different weights to the extracted features, by lightening the common features and highlighting the discriminative features. 2) Propose novel approaches to measure the similarities between users\u00a0\u2026", "num_citations": "28\n", "authors": ["2104"]}
{"title": "Bilinear graph neural network with neighbor interactions\n", "abstract": " Graph Neural Network (GNN) is a powerful model to learn representations and make predictions on graph data. Existing efforts on GNN have largely defined the graph convolution as a weighted sum of the features of the connected nodes to form the representation of the target node. Nevertheless, the operation of weighted sum assumes the neighbor nodes are independent of each other, and ignores the possible interactions between them. When such interactions exist, such as the co-occurrence of two neighbor nodes is a strong signal of the target node's characteristics, existing GNN models may fail to capture the signal. In this work, we argue the importance of modeling the interactions between neighbor nodes in GNN. We propose a new graph convolution operator, which augments the weighted sum with pairwise interactions of the representations of neighbor nodes. We term this framework as Bilinear Graph Neural Network (BGNN), which improves GNN representation ability with bilinear interactions between neighbor nodes. In particular, we specify two BGNN models named BGCN and BGAT, based on the well-known GCN and GAT, respectively. Empirical results on three public benchmarks of semi-supervised node classification verify the effectiveness of BGNN -- BGCN (BGAT) outperforms GCN (GAT) by 1.6% (1.5%) in classification accuracy.Codes are available at: https://github.com/zhuhm1996/bgnn.", "num_citations": "27\n", "authors": ["2104"]}
{"title": "From anomaly detection to rumour detection using data streams of social platforms\n", "abstract": " Social platforms became a major source of rumours. While rumours can have severe real-world implications, their detection is notoriously hard: Content on social platforms is short and lacks semantics; it spreads quickly through a dynamically evolving network; and without considering the context of content, it may be impossible to arrive at a truthful interpretation. Traditional approaches to rumour detection, however, exploit solely a single content modality, e.g., social media posts, which limits their detection accuracy. In this paper, we cope with the aforementioned challenges by means of a multi-modal approach to rumour detection that identifies anomalies in both, the entities (e.g., users, posts, and hashtags) of a social platform and their relations. Based on local anomalies, we show how to detect rumours at the network level, following a graph-based scan approach. In addition, we propose incremental methods\u00a0\u2026", "num_citations": "27\n", "authors": ["2104"]}
{"title": "Discovering neighborhood pattern queries by sample answers in knowledge base\n", "abstract": " Knowledge bases have shown their effectiveness in facilitating services like Web search and question-answering. Nevertheless, it remains challenging for ordinary users to fully understand the structure of a knowledge base and to issue structural queries. In many cases, users may have a natural language question and also know some popular (but not all) entities as sample answers. In this paper, we study the Reverse top-k Neighborhood Pattern Query problem, with the aim of discovering structural queries of the question based on: (i) the structure of the knowledge base, and (ii) the sample answers of the question. The proposed solution contains two phases: filter and refine. In the filter phase, a search space of candidate queries is systematically explored. The invalid queries whose result sets do not fully cover the sample answers are filtered out. In the refine phase, all surviving queries are verified to ensure that\u00a0\u2026", "num_citations": "27\n", "authors": ["2104"]}
{"title": "Finding regions of interest using location based social media\n", "abstract": " The discovery of regions of interest in city groups is increasingly important in recent years. In this light, we propose and investigate a novel problem called Region Discovery query (RD query) that finds regions of interest with respect to a user\u05f3s current geographic location. Given a set of spatial objects O and a query location q, if a circular region \u03c9 is with high spatial-object density and is spatially close to q, it is returned by the query and is recommended to users. This type of query can bring significant benefit to users in many useful applications such as trip planning and region recommendation. The RD query faces a big challenge: how to prune the search space in the spatial and density domains. To overcome the challenge and process the RD query efficiently, we propose a novel collaboration search method and we define a pair of bounds to prune the search space effectively. The performance of the RD query is\u00a0\u2026", "num_citations": "27\n", "authors": ["2104"]}
{"title": "Privacy-preserving task assignment in spatial crowdsourcing\n", "abstract": " With the progress of mobile devices and wireless networks, spatial crowdsourcing (SC) is emerging as a promising approach for problem solving. In SC, spatial tasks are assigned to and performed by a set of human workers. To enable effective task assignment, however, both workers and task requesters are required to disclose their locations to untrusted SC systems. In this paper, we study the problem of assigning workers to tasks in a way that location privacy for both workers and task requesters is preserved. We first combine the Paillier cryptosystem with Yao\u2019s garbled circuits to construct a secure protocol that assigns the nearest worker to a task. Considering that this protocol cannot scale to a large number of workers, we then make use of Geohash, a hierarchical spatial index to design a more efficient protocol that can securely find approximate nearest workers. We theoretically show that these two protocols are secure against semi-honest adversaries. Through extensive experiments on two real-world datasets, we demonstrate the efficiency and effectiveness of our protocols.", "num_citations": "26\n", "authors": ["2104"]}
{"title": "Compressing large scale urban trajectory data\n", "abstract": " With the increasing size of trajectory data generated by location-based services and applications which are built from inexpensive GPS-enabled devices in urban environments, the need for compressing large scale trajectories becomes obvious. This paper proposes a scalable urban trajectory compression scheme (SUTC) that can compress a set of trajectories collectively by exploiting common movement behaviors among the urban moving objects such as vehicles and smartphone users. SUTC exploits that urban objects moving in similar behaviors naturally, especially large-scale of human and vehicle which are moving constrained by some geographic context (eg, road networks or routes). To exploit redundancy across a large set of trajectories, SUTC first transforms trajectory sequences from Euclidean space to network-constrained space and represents each trajectory with a sequence of symbolic positions in\u00a0\u2026", "num_citations": "25\n", "authors": ["2104"]}
{"title": "Spatial query processing for fuzzy objects\n", "abstract": " Range and nearest neighbor queries are the most common types of spatial queries, which have been investigated extensively in the last decades due to its broad range of applications. In this paper, we study this problem in the context of fuzzy objects that have indeterministic boundaries. Fuzzy objects play an important role in many areas, such as biomedical image databases and GIS communities. Existing research on fuzzy objects mainly focuses on modeling basic fuzzy object types and operations, leaving the processing of more advanced queries largely untouched. In this paper, we propose two new kinds of spatial queries for fuzzy objects, namely single threshold query and continuous threshold query, to determine the query results which qualify at a certain probability threshold and within a probability interval, respectively. For efficient single threshold query processing, we optimize the classical R\u00a0\u2026", "num_citations": "25\n", "authors": ["2104"]}
{"title": "Discovering Subsequence Patterns for Next POI Recommendation.\n", "abstract": " Next Point-of-Interest (POI) recommendation plays an important role in location-based services. State-of-the-art methods learn the POI-level sequential patterns in the user\u2019s check-in sequence but ignore the subsequence patterns that often represent the socio-economic activities or coherence of preference of the users. However, it is challenging to integrate the semantic subsequences due to the difficulty to predefine the granularity of the complex but meaningful subsequences. In this paper, we propose Adaptive Sequence Partitioner with Power-law Attention (ASPPA) to automatically identify each semantic subsequence of POIs and discover their sequential patterns. Our model adopts a state-based stacked recurrent neural network to hierarchically learn the latent structures of the user\u2019s check-in sequence. We also design a power-law attention mechanism to integrate the domain knowledge in spatial and temporal contexts. Extensive experiments on two real-world datasets demonstrate the effectiveness of our model.", "num_citations": "24\n", "authors": ["2104"]}
{"title": "Destination-aware task assignment in spatial crowdsourcing: A worker decomposition approach\n", "abstract": " With the proliferation of GPS-enabled smart devices and increased availability of wireless network, spatial crowdsourcing (SC) has been recently proposed as a framework to automatically request workers (i.e., smart device carriers) to perform location-sensitive tasks (e.g., taking scenic photos, reporting events). In this paper, we study a destination-aware task assignment problem that concerns the optimal strategy of assigning each task to proper worker such that the total number of completed tasks can be maximized whilst all workers can reach their destinations before deadlines after performing assigned tasks. Finding the global optimal assignment turns out to be an intractable problem since it does not imply optimal assignment for individual worker. Observing that the task assignment dependency only exists amongst subsets of workers, we utilize tree-decomposition technique to separate workers into\u00a0\u2026", "num_citations": "24\n", "authors": ["2104"]}
{"title": "Answering why-not group spatial keyword queries\n", "abstract": " With the proliferation of geo-textual objects on the web, extensive efforts have been devoted to improving the efficiency of top-k spatial keyword queries in different settings. However, comparatively much less work has been reported on enhancing the quality and usability of such queries. In this context, we propose means of enhancing the usability of a top-k group spatial keyword query, where a group of users aim to find k objects that contain given query keywords and are nearest to the users. Specifically, when users receive the result of such a query, they may find that one or more objects that they expect to be in the result are in fact missing, and they may wonder why. To address this situation, we develop a so-called why-notquery that is able to minimally modifythe original query into a query that returns the expected, but missing, objects, in addition to other objects. Specifically, we formalize the why-not query in\u00a0\u2026", "num_citations": "24\n", "authors": ["2104"]}
{"title": "Semantic-aware query processing for activity trajectories\n", "abstract": " Nowadays, users of social networks like tweets and weibo have generated massive geo-tagged records, and these records reveal their activities in the physical world together with spatio-temporal dynamics. Existing trajectory data management studies mainly focus on analyzing the spatio-temporal properties of trajectories, while leaving the understanding of their activities largely untouched. In this paper, we incorporate the semantic analysis of the activity information embedded in trajectories into query modelling and processing, with the aim of providing end users more accurate and meaningful trip recommendations. To this end, we propose a novel trajectory query that not only considers the spatio-temporal closeness but also, more importantly, leverages probabilistic topic modelling to capture the semantic relevance of the activities between data and query. To support efficient query processing, we design a novel\u00a0\u2026", "num_citations": "24\n", "authors": ["2104"]}
{"title": "What-if analysis with conflicting goals: Recommending data ranges for exploration\n", "abstract": " What-if analysis is a data-intensive exploration to inspect how changes in a set of input parameters of a model influence some outcomes. It is motivated by a user trying to understand the sensitivity of a model to a certain parameter in order to reach a set of goals that are defined over the outcomes. To avoid an exploration of all possible combinations of parameter values, efficient what-if analysis calls for a partitioning of parameter values into data ranges and a unified representation of the obtained outcomes per range. Traditional techniques to capture data ranges, such as histograms, are limited to one outcome dimension. Yet, in practice, what-if analysis often involves conflicting goals that are defined over different dimensions of the outcome. Working on each of those goals independently cannot capture the inherent trade-off between them. In this paper, we propose techniques to recommend data ranges for what-if\u00a0\u2026", "num_citations": "23\n", "authors": ["2104"]}
{"title": "Spatial and temporal scoring for egocentric video summarization\n", "abstract": " We present a summarization approach for egocentric video. Given hours of video, the proposed method produces a compact storyboard summary of the camera wearer's day. In contrast to traditional keyframe selection techniques, the resulting summary focuses on the most important video shots which reflect high stable salience, discrimination and representativeness. To accomplish this, we utilize egocentric salience cues, motion cues and a selection model to capture stable salience weight, discriminative weight and representative weight of a video shot respectively. We further combine these weights in a unified framework to predict the importance score of a shot, based on which, important shots are selected for the storyboard. Critically, the approach is neither camera-wearer-specific nor object-specific; that means the learned importance metric need not be trained for a given user or context, and it can predict the\u00a0\u2026", "num_citations": "23\n", "authors": ["2104"]}
{"title": "Sharkdb: An in-memory storage system for massive trajectory data\n", "abstract": " An increasing amount of motion history data, which is called trajectory, is being collected from different sources such as GPS-enabled mobile devices, surveillance cameras and social networks. However it is hard to store and manage trajectory data in traditional database systems, since its variable lengths and asynchronous sampling rates do not fit disk-based and tuple-oriented structures, which are the fundamental structures of traditional database systems. We implement a novel trajectory storage system that is motivated by the success of column store and recent development of in-memory based databases. In this storage design, we try to explore the potential opportunities, which can boost the performance of query processing for trajectory data. To achieve this, we partition the trajectories into frames as column-oriented storage in order to store the sample points of a moving object, which are aligned by the time\u00a0\u2026", "num_citations": "23\n", "authors": ["2104"]}
{"title": "Discovering the Most Influential Sites over Uncertain Data: A Rank Based Approach\n", "abstract": " With the rapidly increasing availability of uncertain data in many important applications such as location-based services, sensor monitoring, and biological information management systems, uncertainty-aware query processing has received a significant amount of research effort from the database community in recent years. In this paper, we investigate a new type of query in the context of uncertain databases, namely uncertain top-k influential sites query (UTkIS query for short), which can be applied in a wide range of application areas such as marketing analysis and mobile services. Since it is not so straightforward to precisely define the semantics of top-k query with uncertain data, in this paper we introduce a novel and more intuitive formulation of the query on the basis of expected rank semantics. To address the efficiency issue caused by possible worlds exploration, we propose effective pruning rules and a\u00a0\u2026", "num_citations": "23\n", "authors": ["2104"]}
{"title": "Towards secure and truthful task assignment in spatial crowdsourcing\n", "abstract": " The ubiquity of mobile device and wireless networks flourishes the market of spatial crowdsourcing, in which location constrained tasks are sent to workers and expected to be performed in some designated locations. To obtain a global optimal task assignment scheme, the platform usually needs to collect location information of all workers. During this process, there is a significant security concern, that is, the platform may not be trustworthy, so it brings about a threat to workers location privacy. In this paper, to tackle the privacy-preserving task assignment problem, we propose a privacy-preserving reverse auction based assignment model which consists of two key parts. In the first part, we generalize private location to travel cost and protect it by an anonymity based data aggregation protocol. In the second part, we propose a reverse auction task assignment algorithm, which is a truthful incentive mechanism\u00a0\u2026", "num_citations": "22\n", "authors": ["2104"]}
{"title": "Location-Based Top-k Term Querying over Sliding Window\n", "abstract": " In part due to the proliferation of GPS-equipped mobile devices, massive svolumes of geo-tagged streaming text messages are becoming available on social media. It is of great interest to discover most frequent nearby terms from such tremendous stream data. In this paper, we present novel indexing, updating, and query processing techniques that are capable of discovering top-k locally popular nearby terms over a sliding window. Specifically, given a query location and a set of geo-tagged messages within a sliding window, we study the problem of searching for the top-k terms by considering both the term frequency and the proximities between the messages containing the term and the query location. We develop a novel and efficient mechanism to solve the problem, including a quad-tree based indexing structure, indexing update technique, and a best-first based searching algorithm. An empirical study is\u00a0\u2026", "num_citations": "22\n", "authors": ["2104"]}
{"title": "Differential private collaborative Web services QoS prediction\n", "abstract": " Collaborative Web services QoS prediction has proved to be an important tool to estimate accurately personalized QoS experienced by individual users, which is beneficial for a variety of operations in the service ecosystem, such as service selection, composition and recommendation. While a number of achievements have been attained on the study of improving the accuracy of collaborative QoS prediction, little work has been done for protecting user privacy in this process. In this paper, we propose a privacy-preserving collaborative QoS prediction framework which can protect the private data of users while retaining the ability of generating accurate QoS prediction. We introduce differential privacy, a rigorous and provable privacy model, into the process of collaborative QoS prediction. We first present DPS, a method that disguises a user\u2019s observed QoS values by applying differential privacy to the user\u2019s QoS\u00a0\u2026", "num_citations": "21\n", "authors": ["2104"]}
{"title": "The interaction between schema matching and record matching in data integration\n", "abstract": " Schema Matching (SM) and Record Matching (RM) are two necessary steps in integrating multiple relational tables of different schemas, where SM unifies the schemas and RM detects records referring to the same real-world entity. The two processes have been thoroughly studied separately, but few attention has been paid to the interaction of SM and RM. In this work, we find that, even alternating them in a simple manner, SM and RM can benefit from each other to reach a better integration performance (i.e., in terms of precision and recall). Therefore, combining SM and RM is a promising solution for improving data integration. To this end, we define novel matching rules for SM and RM, respectively, that is, every SM decision is made based on intermediate RM results, and vice versa, such that SM and RM can be performed alternately. The quality of integration is guaranteed by a Matching Likelihood Estimation\u00a0\u2026", "num_citations": "21\n", "authors": ["2104"]}
{"title": "Sharkdb: an in-memory column-oriented storage for trajectory analysis\n", "abstract": " The last decade has witnessed the prevalence of sensor and GPS technologies that produce a high volume of trajectory data representing the motion history of moving objects. However some characteristics of trajectories such as variable lengths and asynchronous sampling rates make it difficult to fit into traditional database systems that are disk-based and tuple-oriented. Motivated by the success of column store and recent development of in-memory databases, we try to explore the potential opportunities of boosting the performance of trajectory data processing by designing a novel trajectory storage within main memory. In contrast to most existing trajectory indexing methods that keep consecutive samples of the same trajectory in the same disk page, we partition the database into frames in which the positions of all moving objects at the same time instant are stored together and aligned in main memory\u00a0\u2026", "num_citations": "20\n", "authors": ["2104"]}
{"title": "Exploiting viral marketing for location promotion in location-based social networks\n", "abstract": " With the explosion of smartphones and social network services, location-based social networks (LBSNs) are increasingly seen as tools for businesses (e.g., restaurants and hotels) to promote their products and services. In this article, we investigate the key techniques that can help businesses promote their locations by advertising wisely through the underlying LBSNs. In order to maximize the benefit of location promotion, we formalize it as an influence maximization problem in an LBSN, i.e., given a target location and an LBSN, a set of k users (called seeds) should be advertised initially such that they can successfully propagate and attract many other users to visit the target location. Existing studies have proposed different ways to calculate the information propagation probability, that is, how likely it is that a user may influence another, in the setting of a static social network. However, it is more challenging to derive\u00a0\u2026", "num_citations": "19\n", "authors": ["2104"]}
{"title": "Spatio-temporal top-k term search over sliding window\n", "abstract": " In part due to the proliferation of GPS-equipped mobile devices, massive volumes of geo-tagged streaming text messages are becoming available on social media. It is of great interest to discover most frequent nearby terms from such tremendous stream data. In this paper, we present novel indexing, updating, and query processing techniques that are capable of discovering top-k most frequent nearby terms over a sliding window. Specifically, given a query location and a set of geo-tagged messages within a sliding window, we study the problem of searching for the top-k terms by considering term frequency, spatial proximity, and term freshness. We develop a novel and efficient mechanism to solve the problem, including a quad-tree based indexing structure, indexing update technique, and a best-first based searching algorithm. An empirical study is conducted to show that our proposed techniques are\u00a0\u2026", "num_citations": "18\n", "authors": ["2104"]}
{"title": "Profit-driven Task Assignment in Spatial Crowdsourcing.\n", "abstract": " In Spatial Crowdsourcing (SC) systems, mobile users are enabled to perform spatio-temporal tasks by physically traveling to specified locations with the SC platforms. SC platforms manage the systems and recruit mobile users to contribute to the SC systems, whose commercial success depends on the profit attained from the task requesters. In order to maximize its profit, an SC platform needs an online management mechanism to assign the tasks to suitable workers. How to assign the tasks to workers more cost-effectively with the spatio-temporal constraints is one of the most difficult problems in SC. To deal with this challenge, we propose a novel Profit-driven Task Assignment (PTA) problem, which aims to maximize the profit of the platform. Specifically, we first establish a task reward pricing model with tasks\u2019 temporal constraints (ie, expected completion time and deadline). Then we adopt an optimal algorithm based on tree decomposition to achieve the optimal task assignment and propose greedy algorithms to improve the computational efficiency. Finally, we conduct extensive experiments using real and synthetic datasets, verifying the practicability of our proposed methods.", "num_citations": "18\n", "authors": ["2104"]}
{"title": "Preference-aware task assignment in spatial crowdsourcing\n", "abstract": " With the ubiquity of smart devices, Spatial Crowdsourcing (SC) has emerged as a new transformative platform that engages mobile users to perform spatio-temporal tasks by physically traveling to specified locations. Thus, various SC techniques have been studied for performance optimization, among which one of the major challenges is how to assign workers the tasks that they are really interested in and willing to perform. In this paper, we propose a novel preference-aware spatial task assignment system based on workers\u2019 temporal preferences, which consists of two components: History-based Context-aware Tensor Decomposition (HCTD) for workers\u2019 temporal preferences modeling and preference-aware task assignment. We model worker preferences with a three-dimension tensor (worker-task-time). Supplementing the missing entries of the tensor through HCTD with the assistant of historical data and other two context matrices, we recover worker preferences for different categories of tasks in different time slots. Several preference-aware task assignment algorithms are then devised, aiming to maximize the total number of task assignments at every time instance, in which we give higher priorities to the workers who are more interested in the tasks. We conduct extensive experiments using a real dataset, verifying the practicability of our proposed methods.", "num_citations": "18\n", "authors": ["2104"]}
{"title": "Cluster-based subscription matching for geo-textual data streams\n", "abstract": " Geo-textual data that contain spatial, textual, and temporal information are being generated at a very high rate. These geo-textual data cover a wide range of topics. Users may be interested in receiving local popular topics from geo-textual messages. We study the cluster-based subscription matching (CSM) problem. Given a stream of geo-textual messages, we maintain up-to-date clustering results based on a threshold-based online clustering algorithm. Based on the clustering result, we feed subscribers with their preferred geo-textual message clusters according to their specified keywords and location. Moreover, we summarize each cluster by selecting a set of representative messages. The CSM problem considers spatial proximity, textual relevance, and message freshness during the clustering, cluster feeding, and summarization processes. To solve the CSM problem, we propose a novel solution to cluster\u00a0\u2026", "num_citations": "18\n", "authors": ["2104"]}
{"title": "Context-aware trust network extraction in large-scale trust-oriented social networks\n", "abstract": " In recent years, social networking sites have been used as a means for a rich variety of activities, such as movie recommendations and product recommendations. In order to evaluate the trust between a truster (i.e., the source) and a trustee (i.e., the target) who have no direct interaction in Online Social Networks (OSNs), the trust network between them that contains important intermediate participants, the trust relations between the participants, and the social context, has an important influence on trust evaluation. Thus, to deliver a reasonable trust evaluation result, before performing any trust evaluation (i.e., trust transitivity), the contextual trust network from a given source to a given target needs to be first extracted from the social network, where constraints on social context should also be considered to guarantee the quality of the extracted networks. However, this problem has been proved to be NP\u00a0\u2026", "num_citations": "18\n", "authors": ["2104"]}
{"title": "User guidance for efficient fact checking\n", "abstract": " The Web constitutes a valuable source of information. In recent years, it fostered the construction of large-scale knowledge bases, such as Freebase, YAGO, and DBpedia. The open nature of the Web, with content potentially being generated by everyone, however, leads to inaccuracies and misinformation. Construction and maintenance of a knowledge base thus has to rely on fact checking, an assessment of the credibility of facts. Due to an inherent lack of ground truth information, such fact checking cannot be done in a purely automated manner, but requires human involvement. In this paper, we propose a comprehensive framework to guide users in the validation of facts, striving for a minimisation of the invested effort. Our framework is grounded in a novel probabilistic model that combines user input with automated credibility inference. Based thereon, we show how to guide users in fact checking by identifying the facts for which validation is most beneficial. Moreover, our framework includes techniques to reduce the manual effort invested in fact checking by determining when to stop the validation and by supporting efficient batching strategies. We further show how to handle fact checking in a streaming setting. Our experiments with three real-world datasets demonstrate the efficiency and effectiveness of our framework: A knowledge base of high quality, with a precision of above 90%, is constructed with only a half of the validation effort required by baseline techniques.", "num_citations": "17\n", "authors": ["2104"]}
{"title": "Modeling the dynamic trust of online service providers using HMM\n", "abstract": " Online trading takes place in a very complex environment full of uncertainty in which deceitful service providers or sellers may strategically change their behaviors to maximize their profits. The proliferation of deception cases makes it essential and challenging to model the dynamics of a service provider and predict the trustworthiness of the service provider in transactions. Recently, probabilistic trust models have been used to assist decision making in computing environments. Although the typical Hidden Markov Model (HMM) has been used to model a provider's behavior dynamics, existing approaches focus only on the outcomes or ignore the hidden characteristics of the HMM model. In this paper, we model the dynamic trust of service providers concerning a forthcoming transaction in light of as much information as we can consider, including the static features, such as the provider's reputation and item price, and\u00a0\u2026", "num_citations": "16\n", "authors": ["2104"]}
{"title": "Predictive task assignment in spatial crowdsourcing: a data-driven approach\n", "abstract": " With the rapid development of mobile networks and the widespread usage of mobile devices, spatial crowdsourcing, which refers to assigning location-based tasks to moving workers, has drawn increasing attention. One of the major issues in spatial crowdsourcing is task assignment, which allocates tasks to appropriate workers. However, existing works generally assume the static offline scenarios, where the spatio-temporal information of all the workers and tasks is determined and known a priori. Ignorance of the dynamic spatio-temporal distributions of workers and tasks can often lead to poor assignment results. In this work we study a novel spatial crowdsourcing problem, namely Predictive Task Assignment (PTA), which aims to maximize the number of assigned tasks by taking into account both current and future workers/tasks that enter the system dynamically with location unknown in advance. We propose a\u00a0\u2026", "num_citations": "15\n", "authors": ["2104"]}
{"title": "Multi-modal knowledge graphs for recommender systems\n", "abstract": " Recommender systems have shown great potential to solve the information explosion problem and enhance user experience in various online applications. To tackle data sparsity and cold start problems in recommender systems, researchers propose knowledge graphs (KGs) based recommendations by leveraging valuable external knowledge as auxiliary information. However, most of these works ignore the variety of data types (eg, texts and images) in multi-modal knowledge graphs (MMKGs). In this paper, we propose Multi-modal Knowledge Graph Attention Network (MKGAT) to better enhance recommender systems by leveraging multi-modal knowledge. Specifically, we propose a multi-modal graph attention technique to conduct information propagation over MMKGs, and then use the resulting aggregated embedding representation for recommendation. To the best of our knowledge, this is the first work that\u00a0\u2026", "num_citations": "14\n", "authors": ["2104"]}
{"title": "AUC-MF: point of interest recommendation with AUC maximization\n", "abstract": " The task of point of interest (POI) recommendation aims to recommend unvisited places to users based on their check-in history. A major challenge in POI recommendation is data sparsity, because a user typically visits only a very small number of POIs among all available POIs. In this paper, we propose AUC-MF to address the POI recommendation problem by maximizing Area Under the ROC curve (AUC). AUC has been widely used for measuring classification performance with imbalanced data distributions. To optimize AUC, we transform the recommendation task to a classification problem, where the visited locations are positive examples and the unvisited are negative ones. We define a new lambda for AUC to utilize the LambdaMF model, which combines the lambda-based method and matrix factorization model in collaborative filtering. Experiments on two datasets show that the proposed AUC-MF\u00a0\u2026", "num_citations": "14\n", "authors": ["2104"]}
{"title": "Category co-occurrence modeling for large scale scene recognition\n", "abstract": " Scene recognition involves complex reasoning from low-level local features to high-level scene categories. The large semantic gap motivates that most methods model scenes resorting to mid-level representations (e.g. objects, topics). However, this implies an additional mid-level vocabulary and has implications in training and inference. In contrast, the semantic multinomial (SMN) represents patches directly in the scene-level semantic space, which leads to ambiguity when aggregated to a global image representation. Fortunately, this ambiguity appears in the form of scene category co-occurrences which can be modeled a posteriori with a classifier. In this paper we observe that these patterns are essentially local rather than global, sparse, and consistent across SMNs obtained from multiple visual features. We propose a co-occurrence modeling framework where we exploit all these patterns jointly in a common\u00a0\u2026", "num_citations": "14\n", "authors": ["2104"]}
{"title": "Social context-aware trust prediction in social networks\n", "abstract": " Online social networks have been widely used for a large number of activities in recent years. Utilizing social network information to infer or predict trust among people to recommend services from trustworthy providers have drawn growing attention, especially in online environments. Conventional trust inference approaches predict trust between people along paths connecting them in social networks. However, most of the state-of-the-art trust prediction approaches do not consider the contextual information that influences trust and trust evaluation. In this paper, we first analyze the personal properties and interpersonal properties which impact trust transference between contexts. Then, a new trust transference method is proposed to predict the trust in a target context from that in different but relevant contexts. Next, a social context-aware trust prediction model based on matrix factorization is proposed to\u00a0\u2026", "num_citations": "14\n", "authors": ["2104"]}
{"title": "Consensus-based group task assignment with social impact in spatial crowdsourcing\n", "abstract": " With the pervasiveness of GPS-enabled smart devices and increased wireless communication technologies, spatial crowdsourcing (SC) has drawn increasing attention in assigning location-sensitive tasks to moving workers. In real-world scenarios, for the complex tasks, SC is more likely to assign each task to more than one worker, called group task assignment (GTA), for the reason that an individual worker cannot complete the task well by herself. It is a challenging issue to assign worker groups the tasks that they are interested in and willing to perform. In this paper, we propose a novel framework for group task assignment based on worker groups\u2019 preferences, which includes two components: social impact-based preference modeling (SIPM) and preference-aware group task assignment (PGTA). SIPM employs a bipartite graph embedding model and the attention mechanism to learn the social impact-based\u00a0\u2026", "num_citations": "13\n", "authors": ["2104"]}
{"title": "Hidden poi ranking with spatial crowdsourcing\n", "abstract": " Exploring Hidden Points of Interest (H-POIs), which are rarely referred in online search and recommendation systems due to insufficient check-in records, benefits business and individuals. In this work, we investigate how to eliminate the hidden feature of H-POIs by enhancing conventional crowdsourced ranking aggregation framework with heterogeneous (ie, H-POI and Popular Point of Interest (P-POI)) pairwise tasks. We propose a two-phase solution focusing on both effectiveness and efficiency. In offline phase, we substantially narrow down the search space by retrieving a set of geo-textual valid heterogeneous pairs as the initial candidates and develop two practical data-driven strategies to compute worker qualities. In the online phase, we minimize the cost of assessment by introducing an active learning algorithm to jointly select pairs and workers with worker quality, uncertainty of P-POI rankings and\u00a0\u2026", "num_citations": "13\n", "authors": ["2104"]}
{"title": "Reconstruction regularized deep metric learning for multi-label image classification\n", "abstract": " In this paper, we present a novel deep metric learning method to tackle the multi-label image classification problem. In order to better learn the correlations among images features, as well as labels, we attempt to explore a latent space, where images and labels are embedded via two unique deep neural networks, respectively. To capture the relationships between image features and labels, we aim to learn a two-way deep distance metric over the embedding space from two different views, i.e., the distance between one image and its labels is not only smaller than those distances between the image and its labels\u2019 nearest neighbors but also smaller than the distances between the labels and other images corresponding to the labels\u2019 nearest neighbors. Moreover, a reconstruction module for recovering correct labels is incorporated into the whole framework as a regularization term, such that the label embedding\u00a0\u2026", "num_citations": "13\n", "authors": ["2104"]}
{"title": "Trip oriented search on activity trajectory\n", "abstract": " Driven by the flourish of location-based services, trajectory search has received significant attentions in recent years. Different from existing studies that focus on searching trajectories with spatio-temporal information and text de-scriptions, we study a novel problem of searching trajectories with spatial distance, activities, and rating scores. Given a query q with a threshold of distance, a set of activities, a start point S and a destination E, trip oriented search on activity trajectory (TOSAT) returns k trajectories that can cover the activities with the highest rating scores within the threshold of distance. In addition, we extend the query with an order, i.e., order-sensitive trip oriented search on activity trajectory (OTOSAT), which takes both the order of activities in a query q and the order of trajectories into consideration. It is very challenging to answer TOSAT and OTOSAT efficiently due to the structural complexity of\u00a0\u2026", "num_citations": "13\n", "authors": ["2104"]}
{"title": "VID join: Mapping trajectories to points of interest to support location-based services\n", "abstract": " Variable influence duration (VID) join is a novel spatio-temporal join operation between a set T of trajectories and a set P of spatial points. Here, trajectories are traveling histories of moving objects (e.g., travelers), and spatial points are points of interest (POIs, e.g., restaurants). VID join returns all pairs of (\u03c4                                                    s                 , p) if \u03c4                                                    s                  is spatially close to p for a long period of time, where \u03c4                                                    s                  is a segment of trajectory \u03c4 \u2208 T and p \u2208 P. Each returned (\u03c4                                                    s                 , p) implies that the moving object associated with \u03c4                                                    s                  stayed at p (e.g., having dinner at a restaurant). Such information is useful in many aspects, such as targeted advertising, social security, and social activity analysis. The concepts of influence and influence duration are introduced to\u00a0\u2026", "num_citations": "13\n", "authors": ["2104"]}
{"title": "Collective spatial keyword search on activity trajectories\n", "abstract": " Collective spatial keyword query (CSKQ) is one of the most useful spatial queries in location-based service systems. Although the availability of large-scale activity trajectories has given us useful knowledge of users\u2019 behavior, existing activity trajectory search methods are unable to support CSKQ queries reasonably. This paper studies effective and efficient CSKQ processing on activity trajectories to cover the gap. Specifically, we first formalize the problem by a trajectory based model that considers the spatial, activity and popularity issues, enabling more rational CSKQ results to be returned. To avoid high I/O cost, a novel hybrid index structure is further proposed to seamlessly integrate multi-domain information, so that inferior trajectories can be pruned during query processing. A novel candidate sub-trajectory search algorithm is also presented to reduce computation overhead by a linear scan on the trajectory\u00a0\u2026", "num_citations": "12\n", "authors": ["2104"]}
{"title": "Graph-based analysis of city-wide traffic dynamics using time-evolving graphs of trajectory data\n", "abstract": " This paper proposes a graph-based approach to representing spatio-temporal trajectory data that allows an effective visualization and characterization of city-wide traffic dynamics. With the advance of sensor, mobile, and Internet of Things (IoT) technologies, vehicle and passenger trajectories are increasingly being collected in massive scale and are becoming a critical source of insight into traffic pattern and traveller behaviour. To leverage such trajectory data to better understand traffic dynamics in a large-scale urban network, this study develops a trajectory-based network traffic analysis method that converts individual trajectory data into a sequence of graphs that evolve over time (known as dynamic graphs or time-evolving graphs) and analyses network-wide traffic patterns in terms of a compact and informative graph-representation of aggregated traffic flows. First, we partition the entire network into a set of cells based on the spatial distribution of data points in individual trajectories, where the cells represent spatial regions between which aggregated traffic flows can be measured. Next, dynamic flows of moving objects are represented as a time-evolving graph, where regions are graph vertices and flows between them are treated as weighted directed edges. Given a fixed set of vertices, edges can be inserted or removed at every time step depending on the presence of traffic flows between two regions at a given time window. Once a dynamic graph is built, we apply graph mining algorithms to detect changepoints in time, which represent time points where the graph exhibits significant changes in its overall structure and, thus, correspond to\u00a0\u2026", "num_citations": "12\n", "authors": ["2104"]}
{"title": "Landmark-based route recommendation with crowd intelligence\n", "abstract": " Route recommendation is one of the most widely used location-based services nowadays, as it is vital for nice-driving experience and smooth public traffic. Given a pair of user-specified origin and destination, a route recommendation service aims to provide users with the routes of the best travelling experience according to given criteria. However, even the routes recommended by the big-thumb service providers can deviate significantly from the ones travelled by experienced drivers, which motivates the previous research that leverages crowds\u2019 knowledge to improve the recommendation quality. Since route recommendation is normally an online task, low-latency response to drivers\u2019 queries is required in this kind of systems. Unfortunately, latency of crowdsourced systems is usually high, because they need to generate tasks and wait for workers\u2019 feedbacks before answering queries. To address this issue\u00a0\u2026", "num_citations": "12\n", "authors": ["2104"]}
{"title": "Overcoming data sparsity in group recommendation\n", "abstract": " It has been an important task for recommender systems to suggest satisfying activities to a group of users in peoples daily social life. The major challenge in this task is how to aggregate personal preferences of group members to infer the decision of a group. In this paper, we propose a novel end-to-end group recommender system named CAGR (short for Centrality-Aware Group Recommender), which takes the Bipartite Graph Embedding Model (BGEM), the self-attention mechanism and Graph Convolutional Networks (GCNs) as basic building blocks to learn group and user representations in a unified way. Specifically, we first extend BGEM to model group-item interactions, and then in order to overcome the sparsity of the interaction data generated by occasional groups, we propose a self-attentive mechanism to represent groups based on the group members. To further alleviate the group data sparsity problem\u00a0\u2026", "num_citations": "11\n", "authors": ["2104"]}
{"title": "Improving one-class collaborative filtering via ranking-based implicit regularizer\n", "abstract": " One-class collaborative filtering (OCCF) problems are vital in many applications of recommender systems, such as news and music recommendation, but suffers from sparsity issues and lacks negative examples. To address this problem, the state-of-the-arts assigned smaller weights to unobserved samples and performed low-rank approximation. However, the ground-truth ratings of unobserved samples are usually set to zero but ill-defined. In this paper, we propose a ranking-based implicit regularizer and provide a new general framework for OCCF, to avert the ground-truth ratings of unobserved samples. We then exploit it to regularize a ranking-based loss function and design efficient optimization algorithms to learn model parameters. Finally, we evaluate them on three realworld datasets. The results show that the proposed regularizer significantly improves ranking-based algorithms and that the proposed framework outperforms the state-of-the-art OCCF algorithms.", "num_citations": "11\n", "authors": ["2104"]}
{"title": "Interactive spatial keyword querying with semantics\n", "abstract": " Conventional spatial keyword queries confront the difficulty of returning desired objects that are synonyms but morphologically different to query keywords. To overcome this flaw, this paper investigates the interactive spatial keyword querying with semantics. It aims to enhance the conventional queries by not only making sense of the query keywords, but also refining the understanding of query semantics through interactions. On top of the probabilistic topic model, a novel interactive strategy is proposed to precisely infer the latent query semantics by learning from user feedbacks. In each interaction, the returned objects are carefully selected to ensure effective inference of user intended query semantics. Query processing is carried out on a small candidate object set at each round of interaction, and the whole querying process terminates when the latent query semantics learned from user feedback becomes explicit\u00a0\u2026", "num_citations": "11\n", "authors": ["2104"]}
{"title": "Efficient retrieval of top-k most similar users from travel smart card data\n", "abstract": " Understanding the dynamics of human daily mobility patterns is essential for the management and planning of urban facilities and services. Travel smart cards, which record users' public transporting histories, capture rich information of users' mobility pattern. This provides the opportunity to discover valuable knowledge from these transaction records. In recent years, research on measuring user similarity for behavior analysis has attracted a lot of attention in applications such as recommendation systems, crowd behavior analysis applications, and numerous data mining tasks. In this paper, our goal is to estimate the similarity between users' travel patterns according to their travel smart card data. The core of our proposal is a novel user similarity measurement, namely, Travel Spatial-Temporal Similarity (TST), which measures the spatial range and temporal similarity between users. Moreover, we also propose a\u00a0\u2026", "num_citations": "11\n", "authors": ["2104"]}
{"title": "DMRAN: A Hierarchical Fine-Grained Attention-Based Network for Recommendation.\n", "abstract": " The conventional methods for the next-item recommendation are generally based on RNN or onedimensional attention with time encoding. They are either hard to preserve the long-term dependencies between different interactions, or hard to capture fine-grained user preferences. In this paper, we propose a Double Most Relevant Attention Network (DMRAN) that contains two layers, ie, Item level Attention and Feature Level Selfattention, which are to pick out the most relevant items from the sequence of user\u2019s historical behaviors, and extract the most relevant aspects of relevant items, respectively. Then, we can capture the fine-grained user preferences to better support the next-item recommendation. Extensive experiments on two real-world datasets illustrate that DMRAN can improve the efficiency and effectiveness of the recommendation compared with the state-of-the-art methods.", "num_citations": "10\n", "authors": ["2104"]}
{"title": "Privacy-preserving collaborative web services QoS prediction via differential privacy\n", "abstract": " Collaborative Web services QoS prediction has become an important tool for the generation of accurate personalized QoS. While a number of achievements have been attained on the study of improving the accuracy of collaborative QoS prediction, little work has been done for protecting user privacy in this process. In this paper, we propose a privacy-preserving collaborative QoS prediction framework which can protect the private data of users while retaining the ability of generating accurate QoS prediction. We introduce differential privacy, a rigorous and provable privacy preserving technique, into the preprocess of QoS data prediction. We implement the proposed approach based on a general approach named Laplace mechanism and conduct extensive experiments to study its performance on a real world dataset. The experiments evaluate the privacy-accuracy trade-off on different settings and show\u00a0\u2026", "num_citations": "10\n", "authors": ["2104"]}
{"title": "Efficient query processing with mutual privacy protection for location-based services\n", "abstract": " Data privacy in location-based services involves two aspects. The location of a user is a kind of private data as many sensitive information can be inferred from it given some background knowledge. On the other hand, the POI database is a great asset to the LBS provider as its construction requires many resources and efforts. In this paper, we propose a method of protecting mutual privacy (i.e., the location of the user issuing a query and the POI database of the LBS provider) for location-based query processing. Our approach consists of two steps: data preparation and query processing. Data preparation is conducted by LBS itself and is totally an offline computation, while query processing involves some online computation and multiple rounds of communication between LBS and the user. We implement the query processing by two rounds of oblivious transfer extension (OT-Extension) on two small key\u00a0\u2026", "num_citations": "10\n", "authors": ["2104"]}
{"title": "Ranking based activity trajectory search\n", "abstract": " With the proliferation of the GPS-enabled devices and mobile techniques, there has been a lot of work on trajectory search in the last decade. Previous trajectory search has focused on spatio-temporal features and text descriptions. Different from them, we study a novel problem of searching trajectories with activities and corresponding ranking information. Given a query q, which is attached with a set of activities and a threshold of distance, the results of ranking based activity trajectory search (RTS) are k trajectories such that the given activities are performed with the highest ranking within the threshold of distance. In addition, we also extend the query with an order, i.e., order-sensitive ranking based activity trajectory search (ORTS), which takes both the order of activities in a query q and the order of trajectories into account. It is challenging to answer RTS and ORTS efficiently due to the structural complexity\u00a0\u2026", "num_citations": "10\n", "authors": ["2104"]}
{"title": "GFilter: A general gram filter for string similarity search\n", "abstract": " Numerous applications such as data integration, protein detection, and article copy detection share a similar core problem: given a string as the query, how to efficiently find all the similar answers from a large scale string collection. Many existing methods adopt a prefix-filter-based framework to solve this problem, and a number of recent works aim to use advanced filters to improve the overall search performance. In this paper, we propose a gram-based framework to achieve near maximum filter performance. The main idea is to judiciously choose the high-quality grams as the prefix of query according to their estimated ability to filter candidates. As this selection process is proved to be NP-hard problem, we give a cost model to measure the filter ability of grams and develop efficient heuristic algorithms to find high-quality grams. Extensive experiments on real datasets demonstrate the superiority of the proposed\u00a0\u2026", "num_citations": "10\n", "authors": ["2104"]}
{"title": "Preference-aware task assignment in spatial crowdsourcing: from individuals to groups\n", "abstract": " With the ubiquity of smart devices, Spatial Crowdsourcing (SC) has emerged as a new transformative platform engaging mobile users to perform tasks by physically traveling to specified locations. In this paper, we propose a novel preference-aware task assignment system based on workers' temporal preferences, which includes two components: History-based Context-aware Tensor Decomposition (HCTD) for workers' temporal preferences modeling and preference-aware task assignment. We model workers' preferences with a three-dimension tensor. Supplementing missing entries of the tensor through HCTD with the assistant of historical data and other two context matrices, we recover workers' preferences for different categories of tasks in different time slots. Several preference-aware individual task assignment algorithms are then devised, aiming to maximize the total number of task assignments at every time\u00a0\u2026", "num_citations": "9\n", "authors": ["2104"]}
{"title": "Misinformation-oriented expert finding in social networks\n", "abstract": " Due to the distributed and decentralized nature of social media, respective content that contains misinformation is usually propagated without any type of moderation, which may mislead the public and have a profound real-world impact. In addition, it is quite challenging to distinguish misinformation with high precision, since the content is often short and lacks of semantics. A promising solution is to utilize the crowdsourcing wisdom that pushes the suspected misinformation to relevant users based on the expertise and collects the assessments to judge the credibility. Even though a lot of expert finding models have been employed, however, these methods cannot effectively deal with the misinformation-oriented expert matching tasks since the data collected from social network is different form traditional text collection. To this end, we focus on how to obtain an appropriate matching between the suspect\u00a0\u2026", "num_citations": "9\n", "authors": ["2104"]}
{"title": "A framework for parallel map-matching at scale using Spark\n", "abstract": " Map-matching is a problem of matching recorded GPS trajectories to a digital representation of the road network. GPS data may be inaccurate and heterogeneous, due to limitations or error on electronic sensors, as well as law restrictions. How to accurately match trajectories to the road map is an important preprocessing step for many real-world applications, such as trajectory data mining, traffic analysis, and routes prediction. However, the high availability of GPS trajectories and map data challenges the scalability of current map-matching algorithms, which are limited for small datasets since they focus only on the accuracy of the matching rather than scalability. Therefore, we propose a distributed parallel framework for efficient and scalable offline map-matching on top of the Spark framework. Spark uses distributed in-memory data storage and the MapReduce paradigm to achieve horizontal scaling and\u00a0\u2026", "num_citations": "9\n", "authors": ["2104"]}
{"title": "Searching activity trajectory with keywords\n", "abstract": " Driven by the advances in location positioning techniques and the popularity of location sharing services, semantic enriched trajectory data has become unprecedentedly available. While finding relevant Point-of-Interests (PoIs) based on users\u2019 locations and query keywords has been extensively studied in the past years, it is, however, largely untouched to explore the keyword queries in the context of activity trajectory database. In this paper, we study the problem of searching activity trajectories by keywords. Given a set of query keywords, a keyword-oriented query for activity trajectory (KOAT) returns k trajectories that contain the most relevant keywords to the query and yield the least travel effort in the meantime. The main difference between KOAT and conventional spatial keyword queries is that there is no query location in KOAT, which means the search area cannot be localized. To capture the travel\u00a0\u2026", "num_citations": "9\n", "authors": ["2104"]}
{"title": "Trajectory Flow Map: Graph-Based Approach to Analysing Temporal Evolution of Aggregated Traffic Flows in Large-Scale Urban Networks\n", "abstract": " This paper proposes a graph-based approach to representing spatio-temporal trajectory data that allows an effective visualization and characterization of city-wide traffic dynamics. With the advance of sensor, mobile, and Internet of Things (IoT) technologies, vehicle and passenger trajectories are being increasingly collected on a massive scale and are becoming a critical source of insight into traffic pattern and traveller behaviour. To leverage such trajectory data to better understand traffic dynamics in a large-scale urban network, this study develops a trajectory-based network traffic analysis method that converts individual trajectory data into a sequence of graphs that evolve over time (known as dynamic graphs or time-evolving graphs) and analyses network-wide traffic patterns in terms of a compact and informative graph-representation of aggregated traffic flows. First, the authors partition the entire network into a set of cells based on the spatial distribution of data points in individual trajectories, where the cells represent spatial regions between which aggregated traffic flows can be measured. Next, dynamic flows of moving objects are represented as a time-evolving graph, where regions are graph vertices and flows between them are treated as weighted directed edges. Given a fixed set of vertices, edges can be inserted or removed at every time step depending on the presence of traffic flows between two regions at a given time window. Once a dynamic graph is built, the authors apply graph mining algorithms to detect change-points in time, which represent time points where the graph exhibits significant changes in its overall structure and\u00a0\u2026", "num_citations": "9\n", "authors": ["2104"]}
{"title": "A crowd-based route recommendation system-crowdplanner\n", "abstract": " Route recommendation service has become a big business in industry since traveling is now an important part of our daily life. We can travel to unknown places by simply typing in our destination and then following recommendation service's guidance, that a pleasant trip desires them to provide a good route. However, previous research shows that even the routes recommended by the big-thumb service providers can deviate significantly from the routes travelled by experienced drivers since the many latent factors affect drivers' preferences and it is hard for a single route recommendation algorithm to model all of them. In this demo we will present the CrowPlanner system to leverage crowds' knowledge to improve the recommendation quality. It requests human workers to evaluate candidates routes recommended by different sources and methods, and determines the best route based on the feedbacks of these\u00a0\u2026", "num_citations": "9\n", "authors": ["2104"]}
{"title": "Modeling spatial trajectories with attribute representation learning\n", "abstract": " The widespread use of positioning devices has given rise to many trajectories, with each having three explicit attributes: user ID, location ID, and time-stamp and an implicit attribute: activity type (akin to \u201ctopic\u201d in text mining). To model these trajectories, existing works learn different attribute representations by either introducing latent activity types based on topic models or transforming the location and time context into a low-dimensional space via embedding techniques. In this paper, we propose a holistic approach named Human Mobility Representation Model (HMRM) to simultaneously produce the vector representations of all four (explicit and implicit) attributes. The merits of HMRM lie in that: (1) it models the latent activity types and learns trajectory attribute embeddings in an integrated manner, and (2) it connects the activity-related distributions and these attributes embeddings by adding a newly designed\u00a0\u2026", "num_citations": "8\n", "authors": ["2104"]}
{"title": "CEM: A convolutional embedding model for predicting next locations\n", "abstract": " The widespread use of positioning devices and cameras has given rise to a deluge of trajectory data (e.g., vehicle passage records and check-in data), offering great opportunities for location prediction. One problem that has received much attention recently is predicting next locations for an object given previous locations. Several location prediction methods based on embedding learning have been proposed to tackle this issue. They usually focus on check-in trajectories and model sequential locations using an average of the embedding vectors. In this paper, we have proposed a Convolutional Embedding Model (CEM) to predict next locations using traffic trajectory data, via modeling the relative ordering of locations with a one-dimensional convolution. CEM is further augmented by considering constraints posed by road networks in the traffic trajectory data, learning a double-prototype representation for each\u00a0\u2026", "num_citations": "8\n", "authors": ["2104"]}
{"title": "On efficient spatial keyword querying with semantics\n", "abstract": " The fast development of GPS equipped devices has aroused widespread use of spatial keyword querying in location based services nowadays. Existing spatial keyword indexing and querying methodologies mainly focus on the spatial and textual similarities, while leaving the semantic understanding of keywords in spatial web objects and queries to be ignored. To address this issue, this paper studies the problem of semantic based spatial keyword querying. It seeks to return the k objects most similar to the query, subject to not only their spatial and textual properties, but also the coherence of their semantic meanings. To achieve that, we propose a novel indexing structure called NIQ-tree, which integrates spatial, textual and semantic information in a hierarchical manner, so as to prune the search space effectively in query processing. Extensive experiments are carried out to evaluate and compare it with\u00a0\u2026", "num_citations": "8\n", "authors": ["2104"]}
{"title": "Efficient aggregate farthest neighbour query processing on road networks\n", "abstract": " This paper addresses the problem of searching the k aggregate farthest neighbours (AkFN query in short) on road networks. Given a query point set, AkFN is aimed at finding the top-k points from a dataset with the largest aggregate network distance. The challenge of the AkFN query on the road network is how to reduce the number of network distance evaluation which is an expensive operation. In our work, we propose a three-phase solution, including clustering points in dataset, network distance bound pre-computing and searching. By organizing the objects into compact clusters and pre-calculating the network distance bound from clusters to a set of reference points, we can effectively prune a large fraction of clusters without probing each individual point inside. Finally, we demonstrate the efficiency of our proposed approaches by extensive experiments on a real Point- of-Interest (POI) dataset.", "num_citations": "8\n", "authors": ["2104"]}
{"title": "Cost-efficient spatial network partitioning for distance-based query processing\n", "abstract": " The efficiency of spatial query processing is crucial for many applications such as location-based services. In spatial networks, queries like k-NN queries are all based on network distance evaluation. Classic solutions for these queries rely on network expansion and are not efficient enough for large networks. Some approaches have improved the query efficiency but brought considerable space cost for index. To address these problems, we propose a hierarchical graph partitioning based index named Partition Tree. It organizes the vertices of a spatial network into a hierarchy through a series of graph partitioning processes. Meanwhile precomputed distances are associated with this hierarchy to facilitate efficient query processing. Inspired by the observation that queries are usually invoked around objects of interest, we propose a query-oriented optimization on top of the Partition Tree. It uses a cost model to\u00a0\u2026", "num_citations": "8\n", "authors": ["2104"]}
{"title": "Group task assignment with social impact-based preference in spatial crowdsourcing\n", "abstract": " With the pervasiveness of GPS-enabled smart devices and increased wireless communication technologies, Spatial Crowdsourcing (SC) has drawn increasing attention in assigning location-sensitive tasks to moving workers. In real-world scenarios, for the complex tasks, SC is more likely to assign each task to more than one worker, called Group Task Assignment (GTA), for the reason that an individual worker cannot complete the task well by herself. It is a challenging issue to assign worker groups the tasks that they are interested in and willing to perform. In this paper, we propose a novel framework for group task assignment based on worker groups\u2019 preferences, which includes two components: Social Impact-based Preference Modeling (SIPM) and Preference-aware Group Task Assignment (PGTA). SIPM employs a Bipartite Graph Embedding Model (BGEM) and the attention mechanism to learn the social\u00a0\u2026", "num_citations": "7\n", "authors": ["2104"]}
{"title": "Multi-constrained top-K graph pattern matching in contextual social graphs\n", "abstract": " Graph Pattern Matching (GPM) plays a significant role in many real applications, where given a graph pattern Q and a data graph G, computing the set M(Q, G) of matching subgraphs of Q in G. However, many applications like the experts recommendation in social networks, often need to find Top-K matches of a designated node v 0 , rather than the entire set M(Q, G). Moreover, the existing GPM method for matching the designated node v 0  does not consider the multiple constraints of the attributes associated with each vertex and each edge which commonly exist in real applications, like the constraints of social contexts for the experts recommendation in contextual social. In this paper, we first propose the Multi-Constrained Top-K Graph Pattern Matching problem (MC-Top-K-GPM), which involves the NP-Complete Multiple Constrained GPM problem. To address the efficiency and effectiveness issues of MC-Top-K\u00a0\u2026", "num_citations": "7\n", "authors": ["2104"]}
{"title": "Binet: Trust sub-network extraction using binary ant colony algorithm in contextual social networks\n", "abstract": " Online Social Networks (OSNs) have become an integral part of daily life in recent years. OSNs contain important participants, the trust relations between participants, and the contexts in which participants interact with each other. All of these have a great influence on the prediction of the trust between a source participant and a target participant, which is important for a participant's decision-making process in many applications, such as seeking service providers. However, predicting the trust from a source participant to a target one based on the whole social network is not really feasible. Thus, prior to trust prediction, the extraction of a small-scale sub-network containing most of the important nodes and contextual information with a high density rate could make trust prediction more efficient and effective. However, extracting such a sub-network has been proved to be an NP-Complete problem. To address this\u00a0\u2026", "num_citations": "7\n", "authors": ["2104"]}
{"title": "Hierarchical Hyperedge Embedding-based Representation Learning for Group Recommendation\n", "abstract": " In this work, we study group recommendation in a particular scenario, namely Occasional Group Recommendation (OGR). Most existing works have addressed OGR by aggregating group members' personal preferences to learn the group representation. However, the representation learning for a group is most complex beyond the fusion of group member representation, as the personal preferences and group preferences may be in different spaces. In addition, the learned user representation is not accurate due to the sparsity of users' interaction data. Moreover, the group similarity in terms of common group members has been overlooked, which however has the great potential to improve the group representation learning. In this work, we focus on addressing the above challenges in group representation learning task, and devise a hierarchical hyperedge embedding-based group recommender, namely HyperGroup. Specifically, we propose to leverage the user-user interactions to alleviate the sparsity issue of user-item interactions, and design a GNN-based representation learning network to enhance the learning of individuals' preferences from their friends' preferences, which provides a solid foundation for learning groups' preferences. To exploit the group similarity to learn a more accurate group representation from highly limited group-item interactions, we connect all groups as a network of overlapping sets, and treat the task of group preference learning as embedding hyperedges in a hypergraph, where an inductive hyperedge embedding method is proposed. To further enhance the group-level preference modeling, we develop a joint\u00a0\u2026", "num_citations": "6\n", "authors": ["2104"]}
{"title": "Online trichromatic pickup and delivery scheduling in spatial crowdsourcing\n", "abstract": " In Pickup-and-Delivery problems (PDP), mobile workers are employed to pick up and deliver items with the goal of reducing travel and fuel consumption. Unlike most existing efforts that focus on finding a schedule that enables the delivery of as many items as possible at the lowest cost, we consider trichromatic (worker-item-task) utility that encompasses worker reliability, item quality, and task profitability. Moreover, we allow customers to specify keywords for desired items when they submit tasks, which may result in multiple pickup options, thus further increasing the difficulty of the problem. Specifically, we formulate the problem of Online Trichromatic Pickup and Delivery Scheduling (OTPD) that aims to find optimal delivery schedules with highest overall utility. In order to quickly respond to submitted tasks, we propose a greedy solution that finds the schedule with the highest utility-cost ratio. Next, we introduce a\u00a0\u2026", "num_citations": "6\n", "authors": ["2104"]}
{"title": "Temporal paths discovery with multiple constraints in attributed dynamic graphs\n", "abstract": " Temporal path discovery in dynamic graphs is significant in many applications, such as the trip planning in transportation networks, and the disease progression tracking in gene networks. Attributed Dynamic Graph (ADG) contains multiple value-changed attributes on edges, such as the speed of a bus between two stations, and the price of the bus ticket in different time periods. The traditional methods for temporal path discovery in ADGs assume users only consider a single constraint on the attributes in their models, such as finding the fast route to reach the destination under the constraint of a given budget, which makes the path discovery problem simple though it still suffers expensive time cost. However, such an assumption is too strict in real applications, where users can specify multiple constraints, such as finding the fast route under the constraints of a given budget and the total number of stopovers. In such a\u00a0\u2026", "num_citations": "6\n", "authors": ["2104"]}
{"title": "Concept for evaluation of techniques for trajectory distance measures\n", "abstract": " Measuring the similarity (or distance) between trajectories of moving objects is a common procedure taken by most trajectory data-driven applications. One of the biggest challenges of trajectory distances measurement is that the distance needs to be carefully defined in order to reflect the true underlying similarity. This is due to the fact that trajectories are essentially non-uniform sequential data with variable length, attached with both spatial and temporal attributes, which may or may not be considered for similarity measures. Therefore, tens of similarity measures for trajectory data have been proposed; every technique claim an advantage over the others in a different aspect. Hence, it's difficult for users to choose the best-suited technique, as well as the appropriate parameter values, since each technique has distinct performance and characteristics depending on various factors. In this paper, we develop an\u00a0\u2026", "num_citations": "6\n", "authors": ["2104"]}
{"title": "Discovering expert drivers from trajectories\n", "abstract": " Discovering expert drivers is highly important for a broad range of location based services, but this issue is largely untouched in previous trajectory mining and search studies. In this paper, we study the problem of trajectory data driven expert driver discovery. It aims to find out top-k expert drivers about a region of interest, based on the understanding of their historical trajectories. To this end, we first investigate the construction of reference system, which collectively describes exemplar routes among important junctions, so that the driving behaviors embedded in each trajectory can be evaluated. To discover expert drivers accurately, a novel tf-idf concept based measure is proposed afterwards, such that the rationality of their trajectories are not only precisely evaluated by the match to reference system, but also properly aggregated for modelling expert drivers. Extensive experimental evaluation using real trajectory\u00a0\u2026", "num_citations": "6\n", "authors": ["2104"]}
{"title": "PerNav: A route summarization framework for personalized navigation\n", "abstract": " In this paper, we study a route summarization framework for Personalized Navigation dubbed PerNav-with which the goal is to generate more intuitive and customized turn-by-turn directions based on user generated content. The turn-by-turn directions provided in the existing navigation applications are exclusively derived from underlying road network topology information ie, the connectivity of nodes to each other. Therefore, the turn-by-turn directions are simplified as metric translation of physical world (eg distance/time to turn) to spoken language. Such translation-that ignores human cognition about the geographic space-is often verbose and redundant for the drivers who have knowledge about the geographical areas. PerNav utilizes wealth of user generated historical trajectory data to extract namely\" landmarks\"(eg, point of interests or intersections) and frequently visited routes between them from the road\u00a0\u2026", "num_citations": "6\n", "authors": ["2104"]}
{"title": "Dimension reduction with meta object-groups for efficient image retrieval\n", "abstract": " Bag-of-Word (BoW) has been a prominent form for representing visual content such as image and video in recent years, as a result of its unique capability of characterizing visual content in a picture-level while still preserving part of the object-level information. However, it is also noticed that the dimensionality of BoW is usually as high as a few hundreds or even thousands, posing a serious challenge for any application that requires efficient processing. In this paper we propose a dimension reduction method called Meta object-Group Component (MGC) to tackle this problem. MGC aims at discovering the hidden relations of objects by examining the correlations between dimensions in the BoW features and maximizing the relations of the members in a meta object-group. By exchanging message passing between object-groups, meta object-groups are identified for a dataset. A meta object-group does not only\u00a0\u2026", "num_citations": "6\n", "authors": ["2104"]}
{"title": "Contextual sub-network extraction in contextual social networks\n", "abstract": " Predicting the trust between a source participant and a target participant in a social network is important in many applications, e.g., assessing the recommendation from a target participant from the perspective of a source participant. In general, social networks contain participants, the links and trust relations between them and the contextual information for their interactions. All such information has important influence on trust prediction. However, predicting the trust between two participants based on the whole network is ineffective and inefficient. Thus, prior to trust prediction, it is necessary to extract a small-scale contextual network that contains most of the important participants as well as trust and contextual information. However, extracting such a sub-network has been proved to be an NP-Complete problem. To solve this challenging problem, we propose a social context-aware trust sub-network extraction model\u00a0\u2026", "num_citations": "6\n", "authors": ["2104"]}
{"title": "Go Beyond Raw Trajectory Data: Quality and Semantics.\n", "abstract": " Past decades have witnessed extensive studies from both academia and industries over trajectory data, which are generated from a diverse range of applications. Existing literature mainly focuses on raw trajectories with spatio-temporal features such as location, time, speed, direction and so on. Recently, the pervasive use of smart mobile devices like smart phones, watches and bands have brought about more generation of trajectory by personal users (instead of companies or organizations) and from online space (instead of physical space), where individuals can decide when and where to log on and share their locations with others. The more discentralized and contextualized trajectory sources have brought some unique challenges for database management with respect to the quality and semantics of trajectories data. With more applications and services relying on trajectory data analysis, it is necessary for us to think about how these new issues will affect the traditional way that trajectories are digested and processed. In this paper we will elaborate on these challenges and introduce our recent progress in the respective directions. The message we try to deliver is that raw trajectories themselves no longer satisfy the requirement of today\u2019s mainstream applications. To really release the power of trajectory-based applications, we should go beyond the raw trajectory data by enhancing their quality and semantics, which calls for novel computing architectures, paradigms and algorithms with sufficient capabilities to manage and analyse the enhanced trajectory data.", "num_citations": "6\n", "authors": ["2104"]}
{"title": "Coalition-based task assignment in spatial crowdsourcing\n", "abstract": " With the fast-paced development of mobile networks and the widespread usage of mobile devices, Spatial Crowdsourcing (SC), which refers to assigning location-based tasks to moving workers, has drawn increasing attention in recent years. One of the critical issues in SC is task assignment that allocates tasks to appropriate workers. In this paper, we propose a novel SC problem, namely Coalition-based Task Assignment (CTA), where the spatial tasks (e.g., house removals, furniture installation) may require more than one workers (forming a coalition) to cooperate in order to maximize the overall rewards of workers. To tackle the CTA problem, we design both greedy method and equilibrium-based method. In particular, the greedy method aims to form a set of worker coalitions greedily to perform the tasks, in which we introduce an acceptance possibility to find the high-value task assignments. In the equilibrium\u00a0\u2026", "num_citations": "5\n", "authors": ["2104"]}
{"title": "Efficient user guidance for validating participatory sensing data\n", "abstract": " Participatory sensing has become a new data collection paradigm that leverages the wisdom of the crowd for big data applications without spending cost to buy dedicated sensors. It collects data from human sensors by using their own devices such as cell phone accelerometers, cameras, and GPS devices. This benefit comes with a drawback: human sensors are arbitrary and inherently uncertain due to the lack of quality guarantee. Moreover, participatory sensing data are time series that exhibit not only highly irregular dependencies on time but also high variance between sensors. To overcome these limitations, we formulate the problem of validating uncertain time series collected by participatory sensors. In this article, we approach the problem by an iterative validation process on top of a probabilistic time series model. First, we generate a series of probability distributions from raw data by tailoring a state-of-the\u00a0\u2026", "num_citations": "5\n", "authors": ["2104"]}
{"title": "Origin-destination trajectory diversity analysis: Efficient top-k diversified search\n", "abstract": " Given a pair of Origin-Destination (OD) locations, the set of trajectories passing from the original to destination, usually possesses the nature to reflect different traveling patterns between OD. In general, the higher diversity these trajectories have, the more various traveling behaviors and greater robustness of the connectivity can be revealed, which highly raises the value of transportation analysis towards the corresponding OD pair. Therefore, in this paper, we introduce a comprehensive and rational measure for trajectory diversity, on top of which we propose a novel query, Top-k Diversified Search (TkDS), that aims to find a set of k OD pairs among all the given OD pairs such that the trajectories traversing in-between have the highest diversity. Owing to the intrinsic characteristics of trajectory data, the computational cost for diversity is considerably high. Thus we present an efficient bounding algorithm with early\u00a0\u2026", "num_citations": "5\n", "authors": ["2104"]}
{"title": "Distributed in-memory analytics for big temporal data\n", "abstract": " The temporal data is ubiquitous, and massive amount of temporal data is generated nowadays. Management of big temporal data is important yet challenging. Processing big temporal data using a distributed system is a desired choice. However, existing distributed systems/methods either cannot support native queries, or are disk-based solutions, which could not well satisfy the requirements of high throughput and low latency. To alleviate this issue, this paper proposes an In-memory based Two-level Index Solution in Spark (ITISS) for processing big temporal data. The framework of our system is easy to understand and implement, but without loss of efficiency. We conduct extensive experiments to verify the performance of our solution. Experimental results based on both real and synthetic datasets consistently demonstrate that our solution is efficient and competitive.", "num_citations": "5\n", "authors": ["2104"]}
{"title": "Cnn-iets: A cnn-based probabilistic approach for information extraction by text segmentation\n", "abstract": " Information Extraction by Text Segmentation (IETS) aims at segmenting text inputs to extract implicit data values contained in them. The state-of-art IETS approaches mainly rely on machine learning techniques, either supervised or unsupervised. However, while the supervised approaches require a large labelled training data, the performance of the unsupervised ones could be unstable on different data sets. To overcome their weaknesses, this paper introduces CNN-IETS, a novel unsupervised probabilistic approach that takes the advantages of pre-existing data and a Convolution Neural Network (CNN)-based probabilistic classification model. While using the CNN model can ease the burden of selecting high-quality features in associating text segments with attributes of a given domain, the pre-existing data as a domain knowledge base can provide training data with a comprehensive list of features for building\u00a0\u2026", "num_citations": "5\n", "authors": ["2104"]}
{"title": "A context-aware approach for trustworthy worker selection in social crowd\n", "abstract": " Crowdsourcing applications like Amazon Mechanical Turk (AMT) make it possible to address many difficult tasks (e.g., image tagging and sentiment analysis) on the internet and make full use of the wisdom of crowd, where worker quality is one of the most crucial issues for the task owners. Thus, a challenging problem is how to effectively and efficiently select the high quality workers, so that the tasks online can be accomplished successfully under a certain budget. The existing methods on the crowd worker selection problem mainly based on the quality measurement of the crowd workers, those who have to register on the crowdsourcing platforms. With the connect of the OSNs and the crowdsourcing applications, the social contexts like social relationships and social trust between participants and social positions of participants can assist requestors to select one or a group of trustworthy crowdsourcing\u00a0\u2026", "num_citations": "5\n", "authors": ["2104"]}
{"title": "Anonymity-based privacy-preserving task assignment in spatial crowdsourcing\n", "abstract": " The ubiquity of mobile device and wireless networks flourishes the market of Spatial Crowdsourcing (SC), in which location constrained tasks are sent to workers and expected to be performed in some designated locations. To obtain a global optimal task assignment scheme, the SC-server usually needs to collect location information of all workers. During this process, there is a significant security concern, that is, SC-server may not be trustworthy, so it brings about a threat to workers location privacy. In this paper, we focus on the privacy-preserving task assignment in SC. By introducing a semi-honest third party, we present an approach for task assignment in which location privacy of workers can be protected in a k-anonymity manner. We theoretically show that the proposed model is secure against semi-honest adversaries. Experimental results show that our approach is efficient and can scale to real SC applications.", "num_citations": "5\n", "authors": ["2104"]}
{"title": "A performance study on large-scale data analytics using disk-based and in-memory database systems\n", "abstract": " With the significant increase in memory size, in-memory database systems are becoming the dominant way of dealing with large scale data analytics as compared to the traditional disk-based systems such as data warehouses. Due to the significant differences in both physical and logical designs, these two systems show totally different characteristics on massive data analytic workload. In order to address the difference and technical reasons behind, we contrast the performance between disk-based data warehousing and in-memory database systems by comparing two state-of-the-art commercial systems using a large-scale real transportation dataset. This independent performance study reveals several interesting insights. Experimental evaluation shows that the in-memory system can achieve competitive performance on most data analytics queries with less model maintenance cost and more flexibility, but it is\u00a0\u2026", "num_citations": "5\n", "authors": ["2104"]}
{"title": "An efficient method to find the optimal social trust path in contextual social graphs\n", "abstract": " Online Social Networks (OSN) have been used as platforms for many emerging applications, where trust is a critical factor for participants\u2019 decision making. In order to evaluate the trustworthiness between two unknown participants, we need to perform trust inference along the social trust paths formed by the interactions among the intermediate participants. However, there are usually a large number of social trust paths between two participants. Thus, a challenging problem is how to effectively and efficiently find the optimal social trust path that can yield the most trustworthy evaluation result based on the requirements of participants. In this paper, the core problem of finding the optimal social trust path with multiple constraints of social contexts is modelled as the classical NP-Complete Multi-Constrained Optimal Path (MCOP) selection problem. To make this problem practically solvable, we propose an\u00a0\u2026", "num_citations": "5\n", "authors": ["2104"]}
{"title": "Trust prediction in online social networks\n", "abstract": " Online Social Networks (OSNs) have become an integral part of daily life in recent years. They have been used as a means for a rich variety of activities, such as seeking service providers or recommendations. In these activities, trust is one of the most important factors for participants\u2019 decision-making process. Therefore, it is necessary and significant to predict the trust between two participants who have no direct interactions. My thesis aims to provide effective and efficient trust prediction approaches to evaluate trust values, which are introduced from the following four aspects. The first aspect of the work is to study the factors that affect trust in OSNs and solve the trust network extraction problem. OSNs contain important participants, the trust relations between participants, and the contexts in which participants interact with each other. All of such information has a significant influence on the prediction of the trust from a source participant to a target participant without direct interactions. In addition, the trust network, containing a truster and a trustee without direct interactions, is the foundation to perform trust prediction. The extraction of a small-scale trust subnetwork can deliver efficient and effective trust prediction results. We propose two heuristic algorithms called NBACA and NACA for the extraction of such subnetworks.The second aspect of the work is to address the trust prediction problem in the trust network without any contextual information. We first analyze and extract the features which affect the trust prediction from trust rating values in a trust network. Then, a new trust prediction model based on trust decomposition and matrix factorization is\u00a0\u2026", "num_citations": "5\n", "authors": ["2104"]}
{"title": "Rights protection for trajectory streams\n", "abstract": " More and more trajectory data are available as streams due to the unprecedented prevalence of mobile positioning devices. Meanwhile, an increasing number of applications are designed to be dependent on real-time trajectory streams. Therefore, the protection of ownership rights over such data becomes a necessity. In this paper, we propose an online watermarking scheme that can be used for the rights protection of trajectory streams. The scheme works in a finite window, single-pass streaming model. It embeds watermark by modifying feature distances extracted from the streams. The fact that these feature distances can be recovered ensures a consistent overlap between the recovered watermark and the embedded one. Experimental results verify the robustness of the scheme against domain-specific attacks, including geometric transformations, noise addition, trajectory segmentation and compression.", "num_citations": "5\n", "authors": ["2104"]}
{"title": "Point-of-interest recommendation with global and local context\n", "abstract": " The task of point of interest (POI) recommendation aims to recommend unvisited places to users based on their check-in history. A major challenge in POI recommendation is data sparsity, because a user typically visits only a very small number of POIs among all available POIs. In this paper, we propose AUC-MF to address the POI recommendation problem by maximizing Area Under the ROC curve (AUC). AUC has been widely used for measuring classification performance with imbalanced data distributions. To optimize AUC, we transform the recommendation task to a classification problem, where the visited locations are positive examples and the unvisited are negative ones. We define a new lambda for AUC to utilize the LambdaMF model, which combines the lambda-based method and matrix factorization model in collaborative filtering. Many studies have shown that geographic information plays an\u00a0\u2026", "num_citations": "4\n", "authors": ["2104"]}
{"title": "Spatial-temporal demand forecasting and competitive supply via graph convolutional networks\n", "abstract": " We consider a setting with an evolving set of requests for transportation from an origin to a destination before a deadline and a set of agents capable of servicing the requests. In this setting, an assignment authority is to assign agents to requests such that the average idle time of the agents is minimized. An example is the scheduling of taxis (agents) to meet incoming requests for trips while ensuring that the taxis are empty as little as possible. In this paper, we study the problem of spatial-temporal demand forecasting and competitive supply (SOUP). We address the problem in two steps. First, we build a granular model that provides spatial-temporal predictions of requests. Specifically, we propose a Spatial-Temporal Graph Convolutional Sequential Learning (ST-GCSL) algorithm that predicts the service requests across locations and time slots. Second, we provide means of routing agents to request origins while\u00a0\u2026", "num_citations": "4\n", "authors": ["2104"]}
{"title": "Efficient and robust data augmentation for trajectory analytics: a similarity-based approach\n", "abstract": " Trajectories between the same origin and destination (OD) offer valuable information for us to better understand the diversity of moving behaviours and the intrinsic relationships between the moving objects and specific locations. However, due to the data sparsity issue, there are always insufficient trajectories to carry out mining algorithms, e.g., classification and clustering, to discover the intrinsic properties of OD mobility. In this work, we propose an efficient and robust trajectory augmentation approach to construct sizeable qualified trajectories with existing data to address the sparsity issue. The high-level idea is to concatenate existing trajectories to reconstruct a sufficient number of trajectories to represent the ones going across the OD pair directly. To achieve this goal, we first propose a transition graph to support efficient sub-trajectories concatenation to tackle the sparsity issue. In addition, we develop a novel\u00a0\u2026", "num_citations": "4\n", "authors": ["2104"]}
{"title": "An efficient method for top-k graph based node matching\n", "abstract": " Graph Pattern Matching (GPM) is to find those subgraphs that match a given pattern graph. In many applications, users are interested in the top-k nodes that matches the label of a specific node, (named as the designated node vd) included in a given pattern graph, rather than the entire set of matching. This is called Graph Pattern based Node Matching (GPNM) problem. However, the existing GPM methods for matching the designated node vd in social graphs do not consider the social contexts like the social relationships, the social trust and the social positions which commonly exist in real applications, like the experts recommendation in social graphs, leading to deliver low quality designated nodes. In this paper, we first propose the conText-Aware Graph pattern based Top-K designed nodes finding problem (TAG-K), which involves the NP-Complete Multiple Constrained GPM problem, and thus it is NP\u00a0\u2026", "num_citations": "4\n", "authors": ["2104"]}
{"title": "Context-aware graph pattern based top-k designated nodes finding in social graphs\n", "abstract": " Graph Pattern Matching (GPM) plays a significant role in many real applications, where many applications often need to find Top-K matches of a specific node, (named as the designated node vd) based on a pattern graph, rather than the entire set of matching. However, the existing GPM methods for matching the designated node vd in social graphs do not consider the social contexts like the social relationships, the social trust and the social positions which commonly exist in real applications, like the experts recommendation in social graphs, leading to deliver low quality designated nodes. In this paper, we first propose the conText-Aware Graph pattern based Top-K designed nodes finding problem (TAG-K), which involves the NP-Complete Multiple Constrained GPM problem, and thus it is NP-Complete. To address the efficiency and effectiveness issues of TAG-K in large-scale social graphs, we propose\u00a0\u2026", "num_citations": "4\n", "authors": ["2104"]}
{"title": "Ranking weighted clustering coefficient in large dynamic graphs\n", "abstract": " Efficiently searching top-k representative vertices is crucial for understanding the structure of large dynamic graphs. Recent studies show that communities formed by a vertex with high local clustering coefficient and its neighbours can achieve enhanced information propagation speed as well as disease transmission speed. However, local clustering coefficient, which measures the cliquishness of a vertex in its local neighbourhood, prefers vertices with small degrees. To remedy this issue, in this paper we propose a new ranking measure, weighted clustering coefficient (WCC) of vertices, by integrating both local clustering coefficient and degree. WCC not only inherits the properties of local clustering coefficient but also approximately measures the density (i.e., average degree) of its neighbourhood subgraph. Thus, vertices with higher WCC are more likely to be representative. We study efficiently computing\u00a0\u2026", "num_citations": "4\n", "authors": ["2104"]}
{"title": "A novel hybrid friends recommendation framework for twitter\n", "abstract": " As one of the key features of social networks, friends recommendation is a kind of link prediction task with ranking that was extensively investigated recently in the area of social networks analysis as users would like to follow people who have similar interests to them. We use Twitter as a case study and propose a novel hybrid friends recommendation framework that is not only based on friends relationship but also users\u2019 location information, which are recorded by Twitter when they posted their tweets. Our framework can recommend friends to users who have similar interests based on location features by using collaborative filtering to effectively filter out those common places which are meaningless, e.g., bus station; and focuses on those places that have high probability that people are there more likely to become friends, e.g., dance studio. In addition, we propose a multiple classifiers combination method\u00a0\u2026", "num_citations": "4\n", "authors": ["2104"]}
{"title": "Web Technologies and Applications: 18th Asia-Pacific Web Conference, APWeb 2016, Suzhou, China, September 23-25, 2016. Proceedings, Part I\n", "abstract": " This LNCS double volume LNCS 9931-9932 constitutes the refereed proceedings of the 18th Asia-Pacific Conference APWeb 2016 held in Suzhou, China, in September 2016. The 79 full papers and presented together with 24 short papers and 17 demo papers were carefully reviewed and selected from 215 submissions. the focus of the conference was on following subjects: Spatio-temporal, Textual and Multimedia Data Management Social Media Data Analysis Modelling and Learning with Big Data Streaming and Real-time Data Analysis Recommendation System Data Quality and Privacy Query Optimization and Scalable Data Processing", "num_citations": "4\n", "authors": ["2104"]}
{"title": "Strong social component-aware trust sub-network extraction in contextual social networks\n", "abstract": " In Online Social Networks (OSNs), the important participants, the trust relations between participants, and the interaction contexts between participants greatly impact a participant's decision-making in many applications, such as service provider selection and crowdsourcing service invocation. However, predicting the trust between two unknown participants based on the whole large-scale social network can lead to very high computation costs. Thus, prior to trust prediction, extracting a small-scale sub-network containing the important participants and the corresponding contextual information with a high density could make the trust prediction more efficient and effective. However, extracting such a sub-network has been proved to be an NP-Complete problem. To address this challenging problem, we propose a strong social component-aware trust sub-network extraction model, So-BiNet, to search for near-optimal\u00a0\u2026", "num_citations": "4\n", "authors": ["2104"]}
{"title": "Storing and processing massive trajectory data on SAP HANA\n", "abstract": " Owing to the development of cheap RAM-based storage technology, modern computing hardware can afford much larger main memory. Consequently, traditional database systems can be re-designed to store and manage all the data in main memory permanently. Such kind of in-memory database systems (IMDB) have attracted increasing attention from both academia and industry due to its outstanding performance in processing large amount of data. In this work, we will exploit the computational power of SAP HANA, the in-memory column-oriented data analytics platform designed by SAP, to support efficient query processing for moving object trajectories. We have tailored the frame-based data structure designed by our previous SharkDB project and made the trajectory data with variable lengths and sampling rates suitable for relational database model in SAP HANA. Extensive experiments based on\u00a0\u2026", "num_citations": "4\n", "authors": ["2104"]}
{"title": "Benchmarking big data for trip recommendation\n", "abstract": " The availability of massive trajectory data collected from GPS devices has received significant attentions in recent years. A hot topic is trip recommendation, which focuses on searching trajectories that connect (or are close to) a set of query locations, e.g., several sightseeing places specified by a traveller, from a collection of historic trajectories made by other travellers. However, if we know little about the sample coverage of trajectory data when developing an application of trip recommendation, it is difficult for us to answer many practical questions, such as 1) how many (future) queries can be supported with a given set of raw trajectories? 2) how many trajectories are required to achieve a good-enough result? 3) how frequent the update operations need to be performed on trajectory data to keep it long-term effective? In this paper, we focus on studying the overall quality of trajectory data from both spatial and\u00a0\u2026", "num_citations": "4\n", "authors": ["2104"]}
{"title": "Fairness-aware Task Assignment in Spatial Crowdsourcing: Game-Theoretic Approaches\n", "abstract": " The widespread diffusion of smartphones offers a capable foundation for the deployment of Spatial Crowdsourcing (SC), where mobile users, called workers, perform location- dependent tasks assigned to them. A key issue in SC is how best to assign tasks, e.g., the delivery of food and packages, to appropriate workers. Specifically, we study the problem of Fairness-aware Task Assignment (FTA) in SC, where tasks are to be assigned in a manner that achieves some notion of fairness across workers. In particular, we aim to minimize the payoff difference among workers while maximizing the average worker payoff. To solve the problem, we first generate so-called Valid Delivery Point Sets (VDPSs) for each worker according to an approach that exploits dynamic programming and distance- constrained pruning. Next, we show that FTA is NP-hard and proceed to propose two heuristic algorithms, a Fairness-aware\u00a0\u2026", "num_citations": "3\n", "authors": ["2104"]}
{"title": "Efficient Similarity-aware Influence Maximization in Geo-social Network\n", "abstract": " With the explosion of GPS-enabled smartphones and social media platforms, geo-social networks are increasing as tools for businesses to promote their products or services. Influence maximization, which aims to maximize the expected spread of influence in the networks, has drawn increasing attention. However, most recent work tries to study influence maximization by only considering geographic distance, while ignoring the influence of users' spatio-temporal behavior on information propagation or location promotion, which can often lead to poor results. To relieve this problem, we propose a Similarity-aware Influence Maximization (SIM) model to efficiently maximize the influence spread by taking the effect of users' spatio-temporal behavior into account, which is more reasonable to describe the real information propagation. We first calculate the similarity between users according to their historical check-ins\u00a0\u2026", "num_citations": "3\n", "authors": ["2104"]}
{"title": "Strong social graph based trust-oriented graph pattern matching with multiple constraints\n", "abstract": " Online social network is popular and graph pattern matching (GPM) has been significant in many social network based applications, such as experts finding and social position detection. However, the existing GPM methods do not consider the multiple constraints of the social contexts in GPM, which are commonly found in various applications, or they do not consider the changes of graph structure in the index maintenance of GPM, leading to low efficiency. In this paper, we first propose a  multi-constrained simulation  based on the bounded graph simulation, and propose a multi-constrained graph pattern matching (MC-GPM) problem. To improve the efficiency of MC-GPM in large social graphs, we propose a new concept, strong social graph (SSG), that contains the users who have strong social connections. Then, we propose an SSG-index method to index the reachability, the graph patterns, and the social\u00a0\u2026", "num_citations": "3\n", "authors": ["2104"]}
{"title": "BPF++: a unified factorization model for predicting retweet behaviors\n", "abstract": " Recently, the prediction of retweet behaviors has attracted significant attention, as it can facilitate with a number of tasks, such as popular tweet prediction, personalized recommendation and business intelligence. However, in existing studies, two main problems exists in the prediction of retweet behaviors. (1) The relationship between users is extremely simple when social influences are used for prediction. (2) An effective framework that unifies the effects of both heterogeneous social relations of users and multidimensional similarities of tweets does not exist. Therefore, we propose a unified factorization model that incorporates social influence and tweet similarity into a traditional Bayesian Poisson factorization (BPF) model, named BPF++. Specifically, we utilize a variety of social influence and tweet similarity jointly to improve performance. Furthermore, we integrate trust strengths between users and degrees of\u00a0\u2026", "num_citations": "3\n", "authors": ["2104"]}
{"title": "Location prediction in social networks\n", "abstract": " User locations in social networks are needed in many applications which utilize location information to recommend local news and places of interest to users, as well as detect and alert emergencies around users. However, considering individual privacy, only a small portion users share their location on social networks. Thus, to predict the fine-grained locations of user tweets, we present a joint model containing three sub models: content-based model, social relationship based model and behavior habit based model. In the content-based model, we filter out those location-independent tweets and use deep learning algorithm to mine the relationship between semantics and locations. User trajectory similarity measure is used to build a social graph for users, and historical check-ins is used to provide users\u2019 daily activity habits. We conduct experiments using tweets collected from Shanghai during one year\u00a0\u2026", "num_citations": "3\n", "authors": ["2104"]}
{"title": "Quality-Aware Entity-Level Semantic Representations for Short Texts.\n", "abstract": " Recent prevalence of Web search engines, microblogging services as well as instant messaging tools give rise to a large amount of short texts including queries, tweets and instant messages. A better understanding of the semantics embedded in short texts is indispensable for various Web applications. We adopt the entity-level semantic representation which interpretes a short text as a sequence of mentionenity pairs. A typical strategy consists of two steps: entity extraction to locate entity mentions, and entity linking to identify their corresponding entities. However, it is never a trivial task to achieve high quality (ie, complete and accurate) interpretations for short texts. First, short texts are noisy, containing massive abbreviations, nicknames and misspellings. As a result, traditional entity extraction methods cannot detect every potential entity mentions. Second, entities are ambiguous, calling for entity linking methods to\u00a0\u2026", "num_citations": "3\n", "authors": ["2104"]}
{"title": "Making sense of spatial trajectories\n", "abstract": " Spatial trajectory data is widely available today. Over a sustained period of time, trajectory data has been collected from numerous GPS devices, smartphones, sensors and social media applications. Daily increases of real-time trajectory data have also been phenomenal in recent years. More and more new applications have emerged to derive business values from both trajectory data warehouses and real-time trajectory data. Due to their very large volumes, their nature of streaming, their highly variable levels of data quality, as well as many possible links with other types of data, making sense of spatial trajectory data becomes one of the crucial areas for big data analytics. In this paper we will present a review of the extensive work in spatiotemporal data management and trajectory mining, and discuss new challenges and new opportunities in the context of new applications, focusing on recent advances in\u00a0\u2026", "num_citations": "3\n", "authors": ["2104"]}
{"title": "CSky: An Online Efficient Algorithm for Subspace Skyline Computation in High Dimensional Space\n", "abstract": " BackgroundAbstract Skyline computation aims to find the points that are not dominated by any other point in the dataset. It has been becoming a hot topic due to its potential applications in real-time online services. Usually, such applications expect to return the first Skyline point quickly, without ransacking all the points. This paper focuses on the problem of progressive subspace Skyline queries in high dimensional space. To the best of our knowledge, the existing algorithms and their variations cannot be easily extended to support arbitrary subspace Skyline query efficiently. The BNL (Blocked Nested Loop) method can be used for subspace Skyline queries, but it is very inefficiently, and not progressive. A novel algorithm, called CSky (stands for Count the Skyline), is proposed in this paper to solve this problem. With CSky, the Skyline points can be rapidly obtained in any query subspace of a high dimensional\u00a0\u2026", "num_citations": "3\n", "authors": ["2104"]}
{"title": "Open-world knowledge graph completion with multiple interaction attention\n", "abstract": " Knowledge Graph Completion (KGC) aims at complementing missing relationships between entities in a Knowledge Graph (KG). While closed-world KGC approaches utilizing the knowledge within KG could only complement very limited number of missing relations, more and more approaches tend to get knowledge from open-world resources such as online encyclopedias and newswire corpus. For instance, a recent proposed open-world KGC model called ConMask learns embeddings of the entity\u2019s name and parts of its text-description to connect unseen entities to the KGs. However, this model does not make full use of the rich feature information in the text descriptions, besides, the proposed relationship-dependent content masking method may easily miss to find the target-words. In this paper, we propose to use a Multiple Interaction Attention (MIA) mechanism to model the interactions between the\u00a0\u2026", "num_citations": "2\n", "authors": ["2104"]}
{"title": "Benchmarking on intensive transaction processing\n", "abstract": " Benchmarks play a crucial role in database performance evaluation, and have been effectively promoting the development of database management systems. With critical transaction processing requirements of new applications, we see an explosion of innovative database technologies for dealing with highly intensive transaction workloads (OLTP) with the obvious characteristics of sharp dynamics, terrificskewness, high contention, or high concurrency (abbr. DSC2), which can not be well described or evaluated by current standard benchmarks. In this paper, based on the representative SecKill applications, we define a pacakge of workloads simulating intensive transactional processing requirements. And we create a general and flexible benchmark framework PeakBench for evaluating intensive OLTP workloads on databases. We are the first work to have full control on simulating DSC2, especially for the fine\u00a0\u2026", "num_citations": "2\n", "authors": ["2104"]}
{"title": "Modeling Product's Visual and Functional Characteristics for Recommender Systems\n", "abstract": " An effective recommender system can significantly help customers to find desired products and assist business owners to earn more income. Nevertheless, the decision-making process of users is highly complex, not only dependent on the personality and preference of a user, but also complicated by the characteristics of a specific product. For example, for products of different domains (e.g., clothing vs. office products), the product aspects that affect a user's decision are very different. As such, traditional collaborative filtering methods that model only user-item interactions would deliver unsatisfactory recommendation results. In this work, we first divide a product's characteristics into visual and functional aspects. We then contribute a novel probabilistic model, named Visual and Functional Probabilistic Matrix Factorization (VFPMF), to unify the two factors to estimate user preferences on products. Nevertheless, such\u00a0\u2026", "num_citations": "2\n", "authors": ["2104"]}
{"title": "ITISS: an efficient framework for querying big temporal data\n", "abstract": " In the real word, temporal data can be found in many applications, and it is rapidly increasing nowadays. It is urgently important and challenging to manage and operate big temporal data efficiently and effectively, due to the large volume of big temporal data and the real-time response requirement. Processing big temporal data using a distributed system is a desired choice, since a single-machine based system usually has the limited computing ability. Nevertheless, existing distributed systems or methods either are disk-based solutions, or cannot support native queries, which may not well meet the demands of low latency and high throughput. To attack these issues, this article suggests a new approach to handle big temporal data. Our approach is an In-memory based Two-level Index Solution in Spark, dubbed as ITISS. The proposed framework of our solution is easily understood and implemented, but without\u00a0\u2026", "num_citations": "2\n", "authors": ["2104"]}
{"title": "DMFP: A Dynamic Multi-faceted Fine-Grained Preference Model for Recommendation\n", "abstract": " The time signals behind a user's historical behaviors are important for better inferring what she prefers to interact with at the next time. For the attention-based recommendation methods, relative position encoding and time intervals division are two common ways to model the time signal behind each behavior. They either only consider the relative position of each behavior in the behavior sequence, or process the continuous temporal features into discrete category features for subsequent tasks, which can hardly capture the dynamic preferences of a user. In addition, although the existing recommendation methods have considered both long-term preference and short-term preference, they ignore the fact that the long-term preference of a user may be multi-faceted, and it is difficult to learn a user's fine-grained short-term preference. In this paper, we propose a Dynamic Multi-faceted Fine-grained Preference model\u00a0\u2026", "num_citations": "2\n", "authors": ["2104"]}
{"title": "Personalized Route Description Based On Historical Trajectories\n", "abstract": " The turn-by-turn route descriptions provided in the existing navigation applications are exclusively derived from underlying road network topology information, ie, the connectivity of edges to each other. Therefore, the turn-by-turn route descriptions are simplified as metric translation of physical world (eg distance/time to turn) to spoken language. Such translation that ignores human cognition of the geographic space, is frequently verbose and redundant for the drivers who have knowledge of the geographical areas. In this paper, we study a Personalized Route Description system dubbed PerRD-with which the goal is to generate more customized and intuitive route descriptions based on user generated content. PerRD utilizes a wealth of user generated historical trajectory data to extract frequently visited routes in the road network. The extracted information is used to make cognitive customized route description for\u00a0\u2026", "num_citations": "2\n", "authors": ["2104"]}
{"title": "Social context-aware trust paths finding for trustworthy service provider selection in social media\n", "abstract": " Online Social Network (OSN) has been used to enhance service provision and service selection, where trust is one of the most important factors for the decision making of service consumers. Thus, a significant and challenging problem is how to effectively and efficiently find those social trust paths that can yield trustworthy trust evaluation results based on the requirements of a service consumer particularly in contextual OSNs which contains social contexts, like social relationships and social trust between participants, and social positions of participants. In this paper, we propose a new concept called Strong Social Graph (SSG), consisting of participants with strong social connections. We also propose an approach to identify SSGs, and propose a novel index method and a graph compression method for SSG. Then based on the compressed SSG and indices, we propose a new efficient and effective\u00a0\u2026", "num_citations": "2\n", "authors": ["2104"]}
{"title": "Music playlist recommendation with long short-term memory\n", "abstract": " Music playlist recommendation is an important component in modern music streaming services, which is used for improving user experience by regularly pushing personalized music playlists based on users\u2019 preferences. In this paper, we propose a novel music playlist recommendation problem, namely Personalized Music Playlist Recommendation (PMPR), which aims to provide a suitable playlist for a user by taking into account her long/short-term preferences and music contextual data. We propose a data-driven framework, which is comprised of two phases: user/music feature extraction and music playlist recommendation. In the first phase, we adopt a matrix factorization technique to obtain long-term features of users and songs, and utilize the Paragraph Vector (PV) approach, an advanced natural language processing technique, to capture music context features, which are the basis of the subsequent music\u00a0\u2026", "num_citations": "2\n", "authors": ["2104"]}
{"title": "Towards privacy-preserving travel-time-first task assignment in spatial crowdsourcing\n", "abstract": " With the ubiquity of mobile devices and wireless networks, spatial crowdsourcing (SC) has gained considerable popularity and importance as a new tool of problem-solving. It enables complex tasks at specific locations to be performed by a crowd of nearby workers. In this paper, we study the privacy-preserving travel-time-first task assignment problem where tasks are assigned to workers who can arrive at the required locations first and no private information are revealed to unauthorized parties. Compared with existing work on privacy-preserving task assignment, this problem is novel as tasks are allocated according to travel time rather than travel distance. Moreover, it is challenging as secure computation of travel time requires secure division which is still an open problem nowadays. Observing that current solutions for secure division do not scale well, we propose an efficient algorithm to securely\u00a0\u2026", "num_citations": "2\n", "authors": ["2104"]}
{"title": "Trajectory set similarity measure: an emd-based approach\n", "abstract": " To address the trajectory sparsity issue concerning Origin-Destination (OD) pairs, in general, most existing studies strive to reconstruct trajectories by concatenating the sub-trajectories along the specific paths and filling up the sparsity with conceptual trajectories. However, none of them gives the robustness validation for their reconstructed trajectories. By intuition, the reconstructed trajectories are more qualified if they are more similar to the exact ones traversing directly from the origin\u00a0to the destination, which indicates the effectiveness of the corresponding trajectory augmentation algorithms. Nevertheless, to our knowledge, no existing work has studied the similarity of trajectory sets. Motivated by this, we propose a novel similarity measure to evaluate the similarity between two set of trajectories, borrowing the idea of the Earth Mover\u2019s Distance. Empirical studies on a large real trajectory dataset show that\u00a0\u2026", "num_citations": "2\n", "authors": ["2104"]}
{"title": "Exploring data partitions for what-if analysis\n", "abstract": " What-if analysis is a data-intensive exploration to inspect how changes in a set of input parameters of a model influence some outcomes. It is motivated by a user trying to understand the sensitivity of a model to a certain parameter in order to reach a set of goals that are defined over the outcomes. To avoid an exploration of all possible combinations of parameter values, efficient what-if analysis calls for a partitioning of parameter values into data ranges and a unified representation of the obtained outcomes per range. Traditional techniques to capture data ranges, such as histograms, are limited to one outcome dimension. Yet, in practice, what-if analysis often involves conflicting goals that are defined over different dimensions of the outcome. Working on each of those goals independently cannot capture the inherent trade-off between them. In this paper, we propose techniques to recommend data ranges for what-if analysis, which capture not only data regularities, but also the trade-off between conflicting goals. Specifically, we formulate a parametric data partitioning problem and propose a method to find an optimal solution for it. Targeting scalability to large datasets, we further provide a heuristic solution to this problem. By theoretical and empirical analyses, we establish performance guarantees in terms of runtime and result quality.", "num_citations": "2\n", "authors": ["2104"]}
{"title": "Crowd-guided entity matching with consolidated textual data\n", "abstract": " Entity matching (EM) identifies records referring to the same entity within or across databases. Existing methods using structured attribute values (such as digital, date or short string values) may fail when the structured information is not enough to reflect the matching relationships between records. Nowadays more and more databases may have some unstructured textual attribute containing extra consolidated textual information (CText) of the record, but seldom work has been done on using the CText for EM. Conventional string similarity metrics such as edit distance or bag-of-words are unsuitable for measuring the similarities between CText since there are hundreds or thousands of words with each piece of CText, while existing topic models either cannot work well since there are no obvious gaps between topics in CText. In this paper, we propose a novel cooccurrence-based topic model to identify\u00a0\u2026", "num_citations": "2\n", "authors": ["2104"]}
{"title": "Web-ADARE: A web-aided data repairing system\n", "abstract": " Data repairing aims at discovering and correcting erroneous data in databases. In this paper, we develop Web-ADARE, an end-to-end web-aided data repairing system, to provide a feasible way to involve the vast data sources on the Web in data repairing. Our main attention in developing Web-ADARE is paid on the interaction problem between web-aided repairing and rule-based repairing, in order to minimize the Web consultation cost while reaching predefined quality requirements. The same interaction problem also exists in crowd-based methods but this is not yet formally defined and addressed. We first prove in theory that the optimal interaction scheme is not feasible to be achieved, and then propose an algorithm to identify a scheme for efficient interaction by investigating the inconsistencies and the dependencies between values in the repairing process. Extensive experiments on three data collections\u00a0\u2026", "num_citations": "2\n", "authors": ["2104"]}
{"title": "KPMCF: A learning model for measuring social relationship strength\n", "abstract": " We present the demonstration of the KPMCF model for measuring relationship strength, highlighting the concepts of the model, two experimental applications, and a comparison with other methods.", "num_citations": "2\n", "authors": ["2104"]}
{"title": "SOUP: Spatial-Temporal Demand Forecasting and Competitive Supply\n", "abstract": " We consider a setting with an evolving set of requests for transportation from an origin to a destination before a deadline and a set of agents capable of servicing the requests. In this setting, an assignment authority is to assign agents to requests such that the average idle time of the agents is minimized. An example is the scheduling of taxis (agents) to meet incoming passenger requests for trips while ensuring that the taxis are empty as little as possible. In this paper, we study the problem of spatial-temporal demand forecasting and competitive supply (SOUP). We address the problem in two steps. First, we build a granular model that provides spatial-temporal predictions of requests. Specifically, we propose a Spatial-Temporal Graph Convolutional Sequential Learning (ST-GCSL) model that predicts the requests across locations and time slots. Second, we provide means of routing agents to request origins while\u00a0\u2026", "num_citations": "1\n", "authors": ["2104"]}
{"title": "Automated Creative Optimization for E-Commerce Advertising\n", "abstract": " Advertising creatives are ubiquitous in E-commerce advertisements and aesthetic creatives may improve the click-through rate (CTR) of the products. Nowadays smart advertisement platforms provide the function of compositing creatives based on source materials provided by advertisers. Since a great number of creatives can be generated, it is difficult to accurately predict their CTR given a limited amount of feedback. Factorization machine (FM), which models inner product interaction between features, can be applied for the CTR prediction of creatives. However, interactions between creative elements may be more complex than the inner product, and the FM-estimated CTR may be of high variance due to limited feedback. To address these two issues, we propose an Automated Creative Optimization (AutoCO) framework to model complex interaction between creative elements and to balance between\u00a0\u2026", "num_citations": "1\n", "authors": ["2104"]}
{"title": "Intention-based destination recommendation in navigation systems\n", "abstract": " Taking natural languages as inputs has been widely used in applications. Since the navigation application, which one of the fundamental and most used applications, is usually used during driving, thus the navigation application to take natural language as inputs can reduce the risk of driving. In reality, people use different ways to express their moving intentions. For example, \u2018I want to go to the bank\u2019 and \u2018I want to cash check\u2019 both reveal that the user wants to go to the bank. So we propose a new navigation system to take natural languages as inputs and recommend destinations to users by detecting users\u2019 moving intentions. The navigation system firstly utilizes a wealth of check-in data to extract corresponding words, including stuff and actions, for different types of locations. Then the extracted information is used to detect users\u2019 moving intentions and recommend suitable destinations. We formalize this task as a\u00a0\u2026", "num_citations": "1\n", "authors": ["2104"]}
{"title": "Searching Activity Trajectories by Exemplar\n", "abstract": " The rapid explosion of urban cities has modernized the residents\u2019 lives and generated a large amount of data (e.g., human mobility data, traffic data, and geographical data), especially the activity trajectory data that contains spatial and temporal as well as activity information. With these data, urban computing enables to provide better services such as location-based applications for smart cities. Recently, a novel exemplar query paradigm becomes popular that considers a user query as an example of the data of interest, which plays an important role in dealing with the information deluge. In this article, we propose a novel query, called searching activity trajectory by exemplar, where, given an exemplar trajectory \u03c4q, the goal is to find the top-k trajectories with the smallest distances to \u03c4q. We first introduce an inverted-index-based algorithm (ILA) using threshold ranking strategy. To further improve the efficiency, we\u00a0\u2026", "num_citations": "1\n", "authors": ["2104"]}
{"title": "Introduction to spatio-temporal data driven urban computing\n", "abstract": " This special issue of Distributed and Parallel Databases journal covers recent advances in spatio-temporal data analytics in the context of urban computing. It contains 9 articles that present solid research studies and innovative ideas in the area of spatio-temporal data analytics for urban computing applications. All of the 9 papers went through at least two rounds of rigorous reviews by the guest editors and invited reviewers.Location-based recommender systems are becoming increasingly important in the community of urban computing. The paper, by Hao Zhou et al.,\u201cHybrid route recommendation with taxi and shared bicycles,\u201d develops a two-phase data-driven recommendation framework that integrates prediction and recommendation phases for providing reliable route recommendation results. Another paper, by Hao Zhang et al.,\u201cOn accurate POI recommendation via transfer learning,\u201d proposes a transfer\u00a0\u2026", "num_citations": "1\n", "authors": ["2104"]}
{"title": "Collaborative filtering with ranking-based priors on unknown ratings\n", "abstract": " Advanced collaborative filtering methods based on explicit feedback assume that unknown ratings are missing not at random. The state-of-the-art algorithm hypothesizes that unknown items are weakly rated and sets an explicit prior to unknown ratings. However, the prior assuming unknown ratings be close to zero may be questionable and it is challenging to set appropriate prior ratings for unknown items. In this article, to avert the use of prior ratings, we propose a ranking-based prior by hypothesizing that each user's unknown ratings are close to each other. This prior essentially acts as a regularizer to penalize the discrepancy of predicted ratings between any two unknown items. With the ranking-based prior, we design a generic collaborative filtering framework for explicit feedback and develop an efficient optimization algorithm for parameter learning. We finally evaluate the proposed algorithms on four real\u00a0\u2026", "num_citations": "1\n", "authors": ["2104"]}
{"title": "Personalized recommendation algorithm considering time sensitivity\n", "abstract": " Aiming to solve the problem of goods popularity bias, this paper introduces the prevalence of items into user interest modeling, and proposes an item popularity model based on user interest feature. Usually, traditional model that does not take into account the stability of user\u2019s interests, which leads to the difficulty in capturing their interest. To cope with this limitation, we propose a time-sensitive and stabilized interest similarity model that involves a process of calculating the similarity of user interest. Moreover, by combining those two kinds of similarity model based on weight factors, we develop a novel algorithm for calculation, which is named as IPSTS (IPSTS). To evaluate the proposed approach, experiments are performed and results indicate that Mean Absolute Difference (MAE) and root mean square error (RMSE) could be significantly reduced, when compared with those of traditional collaborative filtering\u00a0\u2026", "num_citations": "1\n", "authors": ["2104"]}
{"title": "Reinforcement Learning Based Monte Carlo Tree Search for Temporal Path Discovery\n", "abstract": " An Attributed Dynamic Graph (ADG) contains multiple dynamic attributes associated with each edge. In ADG based applications, people usually can specify multiple constrains in the attributes to illustrate their requirements, such as the total cost, the total travel time and the stopover interval of a flight between two cities. This inspires a type of Multi-Constrained Temporal Path (MCTP) discovery in ADGs, which is a challenging NP-Complete problem. In order to deliver an efficient and effective temporal path discovery method to be used in real-time environment, we propose a Reinforcement Learning (RL) based, Monte Carlo Tree Search algorithm (RLMCTS). RL-MCTS uses a newly designed memory structure to address the challenges of Monte Carlo Tree Search (MCTS) in MCTP discovery. To the best of our knowledge, RL-MCTS is the first RL algorithm that supports path discovery in ADGs. The experimental\u00a0\u2026", "num_citations": "1\n", "authors": ["2104"]}
{"title": "PerRD: A System for Personalized Route Description\n", "abstract": " Nowadays, mobile devices are already seen everywhere in life, which makes the application of vehicle navigation more and more widely. The traditional turn-by-turn navigation does the path planning just based on the characteristics of the roads themselves, and then gives mechanized steering instructions at each corner. For those roads people are familiar with in this route, path descriptions which provide detailed route description information, will become redundant and verbose. In this paper, we study a Personalized Route Description system dubbed PerRD - with which the goal is to generate more customized and intuitive route descriptions based on user generated content. The goal is to optimize a given route description with paths which users know well, which makes the route more consistent with users' driving habits, and to create a concise and meaningful route descriptions with POIs and street names.", "num_citations": "1\n", "authors": ["2104"]}
{"title": "Mining High-Quality Fine-Grained Type Information from Chinese Online Encyclopedias\n", "abstract": " Entity typing is a necessary step in building knowledge graphs. So far, plenty of efforts have been made in mining type information for entities from online encyclopedias, but usually only coarse-grained type information could be obtained for entities, which are not fine enough for the purpose of knowledge graphs construction or query answering. The situation becomes even worse for mining type information for entities in Chinese. In this paper, we work on mining high-quality fine-grained type information for entities from not only the title-labels and info-boxes in the entity\u2019s encyclopedias page, but also the abstracts and crowd-labels in the page, which could provide a lot more candidate fine-grained type information (with noises). To maintain the high quality of the mined type information, initially we only get reliable type information from the title-labels and info-boxes. Then by putting entities, attributes, values\u00a0\u2026", "num_citations": "1\n", "authors": ["2104"]}
{"title": "Reverse Top-k Query on Uncertain Preference\n", "abstract": " As a reverse rank-aware query, reverse top-k query returns the user preferences which make the given object belong to the top-k result set. This paper studies the reverse top-k query on uncertain preferences for the first time. A user\u2019s uncertain preference consists of several probable preference instances, which reflects the user\u2019s potential consumption tendency. In this paper, we design an optimization algorithm BBUPR based on the proposed RUI-tree index. Our experiment results show that BBUPR outperforms the other algorithms.", "num_citations": "1\n", "authors": ["2104"]}
{"title": "A Time-Aware Path-Based Publish/Subscribe Framework\n", "abstract": " Nowadays, massive geo-tagged records are generated on the social media. These records are useful when the users intend to plan a trip and are interested in some specific topics along the trip. With such redundant records, a publish/subscribe system has been designed to allow the users who are interested in certain information (i.e., the subscribers) to receive messages from some message generators (i.e., the publishers). Existing efforts on publish/subscribe mainly focus on the textual content or the spatial location of the subscribers, while leaving the consideration of incorporating the subscribers\u2019 moving behaviors and temporal information. Therefore, in this paper, we propose a Time-aware Path-based Publish/Subscribe (TPPS) model, where we propose a filtering-verification framework that contains two kinds of filters, i.e., time-aware location-based filter and time-aware region-based filter, with considering\u00a0\u2026", "num_citations": "1\n", "authors": ["2104"]}
{"title": "Modeling Travel Behavior Similarity with Trajectory Embedding\n", "abstract": " The prevalence of GPS-enabled devices and wireless communication technologies has led to myriads of spatial trajectories describing the movement history of moving objects. While a substantial research effort has been undertaken on the spatio-temporal features of trajectory data, recent years have witnessed the flourish of location-based web applications (i.e., Foursquare, Facebook), enriching the traditional trajectory data by associating locations with activity information, called activity trajectory. These trajectory data contain a wealth of activity information and offer unprecedented opportunities for heightening our understanding about human behaviors. In this paper, we propose a novel framework, called TEH (Trajectory Embedding and Hashing), to mine the similarity among users based on their activity trajectories. Such user similarity is of great importance for individuals to effectively retrieve the information\u00a0\u2026", "num_citations": "1\n", "authors": ["2104"]}
{"title": "Electrolytic Production of Ti 5 Si 3/TiC Composites by Solid Oxide Membrane Technology\n", "abstract": " This paper investigated the electrolytic production of Ti5Si3/TiC composites from TiO2/SiO2/C in molten CaCl2. The solid-oxide oxygen-ion-conducting membrane tube filled with carbon-saturated liquid tin was served as the anode, and the pressed spherical TiO2/SiO2/C pellet was used as the cathode. The electrochemical reduction process was carried out at 1273\u00a0K and 3.8\u00a0V. The characteristics of the obtained cathode products and the reaction mechanism of the electroreduction process were studied by a series of time-dependent electroreduction experiments. It was found that the electroreduction process generally proceeds through the following steps: TiO2/SiO2/C\u00a0\u2192\u00a0Ti2O3, CaTiO3, Ca2SiO4, SiC\u00a0\u2192\u00a0Ti5Si3, TiC. The morphology observation and the elemental distribution analysis indicate that the reaction routes for Ti5Si3 and TiC products are independent during the electroreduction process.", "num_citations": "1\n", "authors": ["2104"]}
{"title": "RUM: network Representation learning throUgh Multi-level structural information preservation\n", "abstract": " We have witnessed the discovery of many techniques for network representation learning in recent years, ranging from encoding the context in random walks to embedding the lower order connections, to finding latent space representations with auto-encoders. However, existing techniques are looking mostly into the local structures in a network, while higher-level properties such as global community structures are often neglected. We propose a novel network representations learning model framework called RUM (network Representation learning throUgh Multi-level structural information preservation). In RUM, we incorporate three essential aspects of a node that capture a network's characteristics in multiple levels: a node's affiliated local triads, its neighborhood relationships, and its global community affiliations. Therefore the framework explicitly and comprehensively preserves the structural information of a network, extending the encoding process both to the local end of the structural information spectrum and to the global end. The framework is also flexible enough to take various community discovery algorithms as its preprocessor. Empirical results show that the representations learned by RUM have demonstrated substantial performance advantages in real-life tasks.", "num_citations": "1\n", "authors": ["2104"]}
{"title": "Gps-simulated trajectory detection\n", "abstract": " Due to the prevalence of GPS-enabled devices and wireless communication technology, spatial trajectories have become the basis of many location based applications, e.g., Didi. However, trajectory data suffers low quality problems causing by sensor errors and artificial forgeries. Sensor errors are inevitable while forgeries are always constructed on bad purpose. For example, some Didi drivers use GPS simulators to generate forgery trajectories and make fake transactions. In this work we aim to distinguish whether a given trajectory is a GPS simulated trajectory. By formulating this task as the problem of traffic speed extracting and irregular measuring, we propose a simulated trajectory detection framework. In traffic speed extracting phase, we first divide time into time slots and then extract the regular speed of each road during each time slot. In irregular measuring phase, we propose three methods to\u00a0\u2026", "num_citations": "1\n", "authors": ["2104"]}
{"title": "A Robust Approach to Finding Trustworthy Influencer in Trust-Oriented E-Commerce Environments\n", "abstract": " With the recognition of the significance of OSNs (Online Social Networks) in the recommendation of services in e-commerce, there are more and more e-commerce platform being combined with OSNs, forming social e-commerce, where a participant could recommend a product to his/her friends based on the participant\u2019s corresponding purchasing experience. For example, at Epinions, a buyer could share product reviews with his/her friends. In such platforms, a buyer providing lots of high quality reviews is very likely to influence many potential buyers\u2019 purchase behaviours. Such a buyer is believed to have strong social influence. However, dishonest participants in OSNs can deceive the existing social influence evaluation models, by mounting attacks, such as Constant (Dishonest advisors constantly provide unfairly positive/negative ratings to sellers.) and Camouflage (Dishonest advisors camouflage\u00a0\u2026", "num_citations": "1\n", "authors": ["2104"]}