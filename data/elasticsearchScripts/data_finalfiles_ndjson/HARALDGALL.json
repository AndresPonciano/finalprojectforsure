{"title": "Detection of logical coupling based on product release history\n", "abstract": " Code-based metrics such as coupling and cohesion are used to measure a system's structural complexity. But dealing with large systems-those consisting of several millions of lines-at the code level faces many problems. An alternative approach is to concentrate on the system's building blocks such as programs or modules as the unit of examination. We present an approach that uses information in a release history of a system to uncover logical dependencies and change patterns among modules. We have developed the approach by working with 20 releases of a large Telecommunications Switching System. We use release information such as version numbers of programs, modules, and subsystems together with change reports to discover common change behavior (i.e. change patterns) of modules. Our approach identifies logical coupling among modules in such a way that potential structural shortcomings\u00a0\u2026", "num_citations": "620\n", "authors": ["105"]}
{"title": "CVS release history data for detecting logical couplings\n", "abstract": " The dependencies and interrelations between classes and modules affect the maintainability of object-oriented systems. It is therefore important to capture weaknesses of the software architecture to make necessary corrections. We describe a method for software evolution analysis. It consists of three complementary steps, which form an integrated approach for the reasoning about software structures based on historical data: 1) the quantitative analysis uses version information for the assessment of growth and change behavior; 2) the change sequence analysis identifies common change patterns across all system parts; and 3) the relation analysis compares classes based on CVS release history data and reveals the dependencies within the evolution of particular entities. We focus on the relation analysis and discuss its results; it has been validated based on empirical data collected from a concurrent versions\u00a0\u2026", "num_citations": "417\n", "authors": ["105"]}
{"title": "Classifying change types for qualifying change couplings\n", "abstract": " Current change history analysis approaches rely on information provided by versioning systems such as CVS. Therefore, changes are not related to particular source code entities such as classes or methods but rather to text lines added and/or removed. For analyzing whether some change coupling between source code entities is significant or only minor textual adjustments have been checked in, it is essential to reflect the changes to the source code entities. We have developed an approach for analyzing and classifying change types based on code revisions. We can differentiate between several types of changes on the method or class level and assess their significance in terms of the impact of the change types on other source code entities and whether a change may be functionality-modifying or functionality-preserving. We applied our change taxonomy to a case study and found out that in many cases large\u00a0\u2026", "num_citations": "235\n", "authors": ["105"]}
{"title": "Do code and comments co-evolve? on the relation between source code and comment changes\n", "abstract": " Comments are valuable especially for program understanding and maintenance, but do developers comment their code? To which extent do they add comments or adapt them when they evolve the code? We examine the question whether source code and associated comments are really changed together along the evolutionary history of a software system. In this paper, we describe an approach to map code and comments to observe their co-evolution over multiple versions. We investigated three open source systems (i.e., ArgoUML, Azureus, and JDT core) and describe how comments and code co-evolved over time. Some of our findings show that: 1) newly added code - despite its growth rate - barely gets commented; 2) class and method declarations are commented most frequently but far less, for example, method calls; and 3) that 97% of comment changes are done in the same revision as the associated\u00a0\u2026", "num_citations": "231\n", "authors": ["105"]}
{"title": "Generation of business process models for object life cycle compliance\n", "abstract": " Business process models usually capture data exchanged between tasks in terms of objects. These objects are commonly standardized using reference data models that prescribe, among other things, allowed object states. Allowed state transitions can be modeled as object life cycles that require compliance of business processes. In this paper, we first establish a notion of compliance of a business process model with an object life cycle. We then propose a technique for generating a compliant business process model from a set of given reference object life cycles.", "num_citations": "219\n", "authors": ["105"]}
{"title": "Software evolution observations based on product release history\n", "abstract": " Large software systems evolve slowly but constantly. In this paper, we examine the structure of several releases of a telecommunication switching system (TSS) based on information stored in a database of product releases. We tracked the historical evolution of the TSS structure and related the adaptations made (e.g. addition of new features, etc.) to the structure of the system. Such a systematic examination can uncover potential shortcomings in the structure of the system and identify modules or subsystems that should be subject to restructuring or reengineering. Further, we have identified additional information that would be useful for such investigations but is currently lacking in the database", "num_citations": "218\n", "authors": ["105"]}
{"title": "Visualizing software release histories: The use of color and third dimension\n", "abstract": " The data regarding the components of a software system consists of a large amount of information such as version history, number of lines, defect density, and complexity measures. The ability to quickly grasp a comprehensive view of the evolution and dependencies of such information is the key to making informed decisions about future developments of the system. Managers usually make such decision based only on expert judgement. For help in making such decisions, we can turn to the evolution history of large software systems, which contain a wealth of hidden information. Traditionally, this information is passed on through anecdotes without any supporting analytical data. This paper reports on our attempts to make such information more concrete through information visualization techniques. We present a three-dimensional visual representation for examining a system's software release history. The\u00a0\u2026", "num_citations": "197\n", "authors": ["105"]}
{"title": "Combining text mining and data mining for bug report classification\n", "abstract": " Bug reports represent an important information source for software construction. Misclassification of these reports inevitably introduces bias. Manual examinations can help reduce the noise, but bring a heavy burden for developers instead. In this paper, we propose a multi\u2010stage approach by combining both text mining and data mining techniques to automate the prediction process. The first stage leverages text mining techniques to analyze the summary parts of bug reports and classifies them into three levels of probability. The extracted features and some other structured features of bug reports are then fed into the machine learner in the second stage. Data grafting techniques are employed to bridge the two stages. Comparative experiments with previous studies on the same data\u2014three large\u2010scale open\u2010source projects\u2014consistently achieve a reasonable enhancement (from 77.4% to 81.7%, 76.1% to 81.6\u00a0\u2026", "num_citations": "165\n", "authors": ["105"]}
{"title": "On the relation of refactorings and software defect prediction\n", "abstract": " This paper analyzes the influence of evolution activities such as refactoring on software defects. In a case study of five open source projects we used attributes of software evolution to predict defects in time periods of six months. We use versioning and issue tracking systems to extract 110 data mining features, which are separated into refactoring and non-refactoring related features. These features are used as input into classification algorithms that create prediction models for software defects. We found out that refactoring related features as well as non-refactoring related features lead to high quality prediction models. Additionally, we discovered that refactorings and defects have an inverse correlation: The number of software defects decreases, if the number of refactorings increased in the preceding time period. As a result, refactoring should be a significant part of both bug fixes and other evolutionary changes to\u00a0\u2026", "num_citations": "148\n", "authors": ["105"]}
{"title": "A comparison of RDB-to-RDF mapping languages\n", "abstract": " Mapping Relational Databases (RDB) to RDF is an active field of research. The majority of data on the current Web is stored in RDBs. Therefore, bridging the conceptual gap between the relational model and RDF is needed to make the data available on the Semantic Web. In addition, recent research has shown that Semantic Web technologies are useful beyond the Web, especially if data from different sources has to be exchanged or integrated. Many mapping languages and approaches were explored leading to the ongoing standardization effort of the World Wide Web Consortium (W3C) carried out in the RDB2RDF Working Group (WG). The goal and contribution of this paper is to provide a feature-based comparison of the state-of-the-art RDB-to-RDF mapping languages. It should act as a guide in selecting a RDB-to-RDF mapping language for a given application scenario and its requirements wrt mapping\u00a0\u2026", "num_citations": "142\n", "authors": ["105"]}
{"title": "A comparison of four reverse engineering tools\n", "abstract": " Reverse engineering tools support software engineers in the process of analyzing and understanding complex software systems during maintenance activities. The functionality of such tools varies from editing and browsing capabilities to the generation of textual and graphical reports. There are several commercial reverse engineering tools on the market providing different capabilities and supporting specific source code languages. We evaluated four reverse engineering tools that analyze C source code: Refine/C, Imagix4D, Sniff+, and Rigi. We investigated the capabilities of these tools by applying them to a commercial embedded software system as a case study. We identified benefits and shortcomings of these four tools and assessed their applicability for embedded software systems, their usability, and their extensibility.", "num_citations": "132\n", "authors": ["105"]}
{"title": "Improving evolvability through refactoring\n", "abstract": " Refactoring is one means of improving the structure of existing software. Locations for the application of refactoring are often based on subjective perceptions such as\" bad smells\", which are vague suspicions of design shortcomings. We exploit historical data extracted from repositories such as CVS and focus on change couplings: if some software parts change at the same time very often over several releases, this data can be used to point to candidates for refactoring. We adopt the concept of bad smells and provide additional change smells. Such a smell is hardly visible in the code, but easy to spot when viewing the change history. Our approach enables the detection of such smells allowing an engineer to apply refactoring on these parts of the source code to improve the evolvability of the software. For that, we analyzed the history of a large industrial system for a period of 15 months, proposed spots for\u00a0\u2026", "num_citations": "124\n", "authors": ["105"]}
{"title": "Software-architekturen f\u00fcr verteilte Systeme: Prinzipien, Bausteine und Standardarchitekturen f\u00fcr moderne Software\n", "abstract": " Software-Architektur ist ein aktuelles und wichtiges Gebiet sowohl in der Industrie als auch in der Forschung. Neue Technologien, Software-Plattformen oder Open-Source-Software bewirken zunehmende Komplexit\u00e4t der zu entwickelnden Software-Systeme, sodass eine wohl durchdachte Architektur immer bedeutender wird. Es gibt wenige\u2013haupts\u00e4chlich englischsprachige\u2013B\u00fccher zum Thema Software-Architektur, die diese Fragen in klarer und komprimierter Weise behandeln, aber unseres Wissens nach kein einziges, das sich auf Software-Architekturen f\u00fcr verteilte Systeme spezialisiert hat. Diese L\u00fccke zu f\u00fcllen, und Wissen aus der Forschung zum Anwender zu transportieren, stellt die Motivation dieses Buch dar.", "num_citations": "122\n", "authors": ["105"]}
{"title": "Consistency of business process models and object life cycles\n", "abstract": " Business process models and object life cycles can provide two different views on behavior of the same system, requiring that these models are consistent with each other. However, it is difficult to reason about consistency of these two types of models since their relation is not well-understood. We clarify this relation and propose an approach to establishing the required consistency. Object state changes are first made explicit in a business process model and then the process model is used to generate life cycles for each object type used in the process. We define two consistency notions for a process model and an object life cycle and express these in terms of conditions that must hold between a given life cycle and a\u00a0life cycle generated from the process model.", "num_citations": "104\n", "authors": ["105"]}
{"title": "Finding objects in procedural programs: an alternative approach\n", "abstract": " Effective software maintenance requires a detailed knowledge of the system's artifacts, the way these artifacts are used or modified and their interrelationships. Based on some useful characteristics of the object-oriented paradigm the identification of objects within procedural programs has become a promising approach to reduce the effort in program understanding and, hence, the maintenance cost. In this paper we present a new approach to object identification in procedural programs that not only relies on information exclusively extractable from source code but integrates human expertise and external domain- and application-specific knowledge.", "num_citations": "101\n", "authors": ["105"]}
{"title": "Architectural concerns in distributed and mobile collaborative systems\n", "abstract": " Organizations increasingly coordinate their product and service development processes to deliver their products and services as fast as possible, and to involve employees, customers, suppliers, and business partners seamlessly in different stages of the processes. These processes have to consider that their participants are increasingly on the move or distributed while they are working. Expertise needs to be shared across locations and different mobile devices. This paper describes a framework for distributed and mobile collaboration, defines a set of requirements for virtual communities, and discusses a mobile teamwork support software architecture that has been developed in the EU-project MOTION. The framework together with the architecture enables to enhance current collaboration approaches to include the dimension of mobile participants and virtual communities for distributed product development. This\u00a0\u2026", "num_citations": "99\n", "authors": ["105"]}
{"title": "Analyzing reviews and code of mobile apps for better release planning\n", "abstract": " The mobile applications industry experiences an unprecedented high growth, developers working in this context face a fierce competition in acquiring and retaining users. They have to quickly implement new features and fix bugs, or risks losing their users to the competition. To achieve this goal they must closely monitor and analyze the user feedback they receive in form of reviews. However, successful apps can receive up to several thousands of reviews per day, manually analysing each of them is a time consuming task. To help developers deal with the large amount of available data, we manually analyzed the text of 1566 user reviews and defined a high and low level taxonomy containing mobile specific categories (e.g. performance, resources, battery, memory, etc.) highly relevant for developers during the planning of maintenance and evolution activities. Then we built the User Request Referencer (URR\u00a0\u2026", "num_citations": "98\n", "authors": ["105"]}
{"title": "Mining software evolution to predict refactoring\n", "abstract": " Can we predict locations of future refactoring based on the development history? In an empirical study of open source projects we found that attributes of software evolution data can be used to predict the need for refactoring in the following two months of development. Information systems utilized in software projects provide a broad range of data for decision support. Versioning systems log each activity during the development, which we use to extract data mining features such as growth measures, relationships between classes, the number of authors working on a particular piece of code, etc. We use this information as input into classification algorithms to create prediction models for future refactoring activities. Different state-of-the-art classifiers are investigated such as decision trees, logistic model trees, prepositional rule learners, and nearest neighbor algorithms. With both high precision and high recall we can\u00a0\u2026", "num_citations": "96\n", "authors": ["105"]}
{"title": "A web-based peer-to-peer architecture for collaborative nomadic working\n", "abstract": " With the recent advances in mobile computing, distributed organizations are facing a growing need for advanced information and communication technologies (ICT) that support mobile working. The ability to use information effectively anywhere and anytime has become a key business success factor. Although many computer supported collaborative work (CSCW) systems have been introduced to date, technologies and architectures that support the collaboration of nomadic workers on a wide range of mobile devices, notebooks and personal computers is still a challenge. The MObile Teamwork Infrastructure for Organizations Networking (MOTION) project is aiming to design a highly flexible, open and scalable ICT architecture for mobile collaboration. We present the mobile collaboration requirements of two MOTION industry case studies, and highlight the advantages of a Web-based peer-to-peer architecture for\u00a0\u2026", "num_citations": "92\n", "authors": ["105"]}
{"title": "Analyzing APIs documentation and code to detect directive defects\n", "abstract": " Application Programming Interface (API) documents represent one of the most important references for API users. However, it is frequently reported that the documentation is inconsistent with the source code and deviates from the API itself. Such inconsistencies in the documents inevitably confuse the API users hampering considerably their API comprehension and the quality of software built from such APIs. In this paper, we propose an automated approach to detect defects of API documents by leveraging techniques from program comprehension and natural language processing. Particularly, we focus on the directives of the API documents which are related to parameter constraints and exception throwing declarations. A first-order logic based constraint solver is employed to detect such defects based on the obtained analysis results. We evaluate our approach on parts of well documented JDK 1.8 APIs\u00a0\u2026", "num_citations": "77\n", "authors": ["105"]}
{"title": "Analyzing the co-evolution of comments and source code\n", "abstract": " Source code comments are a valuable instrument to preserve design decisions and to communicate the intent of the code to programmers and maintainers. Nevertheless, commenting source code and keeping comments up-to-date is often neglected for reasons of time or programmers obliviousness. In this paper, we investigate the question whether developers comment their code and to what extent they add comments or adapt them when they evolve the code. We present an approach to associate comments with source code entities to track their co-evolution over multiple versions. A set of heuristics are used to decide whether a comment is associated with its preceding or its succeeding source code entity. We analyzed the co-evolution of code and comments in eight different open source and closed source software systems. We found with statistical significance that (1) the relative amount of comments\u00a0\u2026", "num_citations": "75\n", "authors": ["105"]}
{"title": "Visualizing feature evolution of large\u2010scale software based on problem and modification report data\n", "abstract": " Gaining higher\u2010level evolutionary information about large software systems is a key challenge in dealing with increasing complexity and architectural deterioration. Modification reports and problem reports (PRs) taken from systems such as the concurrent versions system (CVS) and Bugzilla contain an overwhelming amount of information about the reasons and effects of particular changes. Such reports can be analyzed to provide a clearer picture about the problems concerning a particular feature or a set of features. Hidden dependencies of structurally unrelated but over time logically coupled files exhibit a good potential to illustrate feature evolution and possible architectural deterioration. In this paper, we describe the visualization of feature evolution by taking advantage of this logical coupling introduced by changes required to fix a reported problem. We compute the proximity of PRs by applying a standard\u00a0\u2026", "num_citations": "74\n", "authors": ["105"]}
{"title": "Tracking concept drift of software projects using defect prediction quality\n", "abstract": " Defect prediction is an important task in the mining of software repositories, but the quality of predictions varies strongly within and across software projects. In this paper we investigate the reasons why the prediction quality is so fluctuating due to the altering nature of the bug (or defect) fixing process. Therefore, we adopt the notion of a concept drift, which denotes that the defect prediction model has become unsuitable as set of influencing features has changed - usually due to a change in the underlying bug generation process (i.e., the concept). We explore four open source projects (Eclipse, OpenOffice, Netbeans and Mozilla) and construct file-level and project-level features for each of them from their respective CVS and Bugzilla repositories. We then use this data to build defect prediction models and visualize the prediction quality along the time axis. These visualizations allow us to identify concept drifts and\u00a0\u2026", "num_citations": "72\n", "authors": ["105"]}
{"title": "An evaluation of reverse engineering tool capabilities\n", "abstract": " Reverse engineering tools support software engineers in the process of analysing and understanding complex software systems during maintenance, re\u2010engineering or re\u2010architecturing. The functionality of such tools varies from editing and browsing capabilities to the generation of textual and graphical reports. There are several commercial reverse engineering tools on the market providing different capabilities and supporting specific source code languages. We evaluated four reverse engineering tools that analyse C source code: Refine/C, Imagix 4D, SNiFF+ and Rigi. We investigated the capabilities of these tools by applying them to a real\u2010world embedded software system as a case study. We identified benefits and shortcomings of these tools and assessed their applicability for embedded software systems, their usability and their extensibility. \u00a9 1998 John Wiley & Sons, Ltd.", "num_citations": "72\n", "authors": ["105"]}
{"title": "Supporting developers with natural language queries\n", "abstract": " The feature list of modern IDEs is steadily growing and mastering these tools becomes more and more demanding, especially for novice programmers. Despite their remarkable capabilities, IDEs often still cannot directly answer the questions that arise during program comprehension tasks. Instead developers have to map their questions to multiple concrete queries that can be answered only by combining several tools and examining the output of each of them manually to distill an appropriate answer. Existing approaches have in common that they are either limited to a set of predefined, hardcoded questions, or that they require to learn a specific query language only suitable for that limited purpose. We present a framework to query for information about a software system using guided-input natural language resembling plain English. For that, we model data extracted by classical software analysis tools with an\u00a0\u2026", "num_citations": "70\n", "authors": ["105"]}
{"title": "A bayesian network based approach for change coupling prediction\n", "abstract": " Source code coupling and change history are two important data sources for change coupling analysis. The popularity of public open source projects in recent years makes both sources available. Based on our previous research, in this paper, we inspect different dimensions of software changes including change significance or source code dependency levels, extract a set of features from the two sources and propose a Bayesian network-based approach for change coupling prediction. By combining the features from the co-changed entities and their dependency relation, the approach can model the underlying uncertainty. The empirical case study on two medium-sized open source projects demonstrates the feasibility and effectiveness of our approach compared to previous work.", "num_citations": "70\n", "authors": ["105"]}
{"title": "WEESA: Web engineering for semantic Web applications\n", "abstract": " The success of the Semantic Web crucially depends on the existence of Web pages that provide machine-understandable meta-data. This meta-data is typically added in the semantic annotation process which is currently not part of the Web engineering process. Web engineering, however, proposes methodologies to design, implement and maintain Web applications but lack the generation of meta-data. In this paper we introduce a technique to extend existing Web engineering methodologies to develop semantically annotated Web pages. The novelty of this approach is the definition of a mapping from XML Schema to ontologies, called WEESA, that can be used to automatically generate RDF meta-data from XML content documents. We further show how we integrated the WEESA mapping into an Apache Cocoon transformer to easily extend XML based Web applications to semantically annotated Web application.", "num_citations": "69\n", "authors": ["105"]}
{"title": "A study of language usage evolution in open source software\n", "abstract": " The use of programming languages such as Java and C in Open Source Software (OSS) has been well studied. However, many other popular languages such as XSL or XML have received minor attention. In this paper, we discuss some trends in OSS development that we observed when considering multiple programming language evolution of OSS. Based on the revision data of 22 OSS projects, we tracked the evolution of language usage and other artefacts such as documentation files, binaries and graphics files. In these systems several different languages and artefact types including C/C++, Java, XML, XSL, Makefile, Groovy, HTML, Shell scripts, CSS, Graphics files, JavaScript, JSP, Ruby, Phyton, XQuery, OpenDocument files, PHP, etc. have been used. We found that the amount of code written in different languages differs substantially. Some of our findings can be summarized as follows:(1) JavaScript and\u00a0\u2026", "num_citations": "66\n", "authors": ["105"]}
{"title": "Evolens: Lens-view visualizations of evolution data\n", "abstract": " Visualizing software evolution is essential for identifying design erosion that has occurred over the past releases. Making evolutionary aspects explicit via visual representations can help the engineer to focus on particular software parts to identify such hot-spots. Although many tools exist that provide zooming-in and -out within the hierarchical decomposition of a software system, only very few allow an engineer to view a system through a kind of lens view. Our approach called EvoLens is a visualization approach for explorations of evolution data across multiple dimensions. EvoLens is based on temporal lens views. But the graphical representation of this visualization integrates enhanced zooming by navigating through software hierarchies with arbitrary selectable groups of software parts across module or package boundaries. EvoLens allows an engineer to define a focal point for the lens view and navigate along\u00a0\u2026", "num_citations": "65\n", "authors": ["105"]}
{"title": "Discovering patterns of change types\n", "abstract": " The reasons why software is changed are manyfold; new features are added, bugs have to be fixed, or the consistency of coding rules has to be re-established. Since there are many types of of source code changes we want to explore whether they appear frequently together in time and whether they describe specific development activities. We describe a semi-automated approach to discover patterns of such change types using agglomerative hierarchical clustering. We extracted source code changes of one commercial and two open-source software systems and applied the clustering. We found that change type patterns do describe development activities and affect the control flow, the exception flow, or change the API.", "num_citations": "62\n", "authors": ["105"]}
{"title": "A service architecture for mobile teamwork\n", "abstract": " Mobile teamwork has become an emerging requirement in the daily  business of large enterprises. Employees collaborate across locations  and need team support while they are on the move. Business documents  and expertise need to be shared independent of the actual location or  connectivity (e.g., access through a mobile phone, laptop, Personal  Digital Assistant, etc.) of employees. Although many collaboration  tools and systems exist, most do not deal with new demanding  requirements such as locating artifacts and experts through distributed  searches, advanced information subscription and notification, and  mobile information sharing and access. The MOTION service architecture  that we have developed supports mobile teamwork by taking into account  the different connectivity modes of users, provides access support for  various devices such as laptop computers and mobile phones, and uses  XML\u00a0\u2026", "num_citations": "60\n", "authors": ["105"]}
{"title": "Software architecture recovery of a program family\n", "abstract": " The concept of software architecture has gained a lot of attention and has found its way into the software development process in industry. Software architecture recovery focuses on the recovery of architectural information from existing systems. This paper presents a framework for recovering the software architecture of a program family. Based on the available system information architectural properties such as safety or system control are recovered using different reverse engineering methods and tools in combination with architectural descriptions. We describe our architecture recovery process and discuss the recovery of system structure as one example of the case study. The framework was developed while working on the recovery of the family architecture of a train control system.", "num_citations": "59\n", "authors": ["105"]}
{"title": "Towards an access control system for mobile peer-to-peer collaborative environments\n", "abstract": " Access control is one of the key requirements in enterprise security. A number of approaches in distributed systems have been designed that support various (new) paradigms such as peer-to-peer, nomadic working, and team working. Few of them, however, explicitly take into account the possible superposition of these concepts. Such a superposition often results in conflicting and additional requirements. We present ongoing work in developing an access control system for peer-to-peer mobile teamwork environments. This system is developed as part of the MOTION project. The goal of this project is to develop a service architecture for mobile teamwork, providing support for various devices and taking into account diverse connectivity modes. We present the requirements for an access control system that simultaneously supports mobility, collaboration, and peer-to-peer, illustrate our solution, and discuss how it\u00a0\u2026", "num_citations": "53\n", "authors": ["105"]}
{"title": "Semtree: Ontology-based decision tree algorithm for recommender systems\n", "abstract": " Recommender systems play an important role in supporting people when choosing items from an overwhelming huge number of choices. So far, no recommender system makes use of domain knowledge. We are modeling user preferences with a machine learning approach to recommend people items by predicting the item ratings. Specifically, we propose SemTree, an ontology-based decision tree learner, that uses a reasoner and an ontology to semantically generalize item features to improve the effectiveness of the decision tree built. We show that SemTree outperforms comparable approaches in recommending more accurate recommendations considering domain knowledge.", "num_citations": "51\n", "authors": ["105"]}
{"title": "Object-oriented re-architecturing\n", "abstract": " Many organizations face the problem of improving the value of their legacy systems. Modernizing the architecture of old software helps to gain control over maintenance cost, to improve system performance, and it supports moving to a distributed or more efficient environment. We propose a re-architecturing of old procedural software to an object-oriented architecture. To overcome limits of classical reverse engineering approaches building exclusively on information extractable from source code we integrate domain knowledge in the process. The resulting object-oriented software helps reduce future maintenance cost, since modern (and more calculable) maintenance technology can then be applied. In this paper, we point out the basic concepts of the re-architecturing process, the generation of design documents at different levels of abstraction, and the necessary syntactic adaptations of the source code.", "num_citations": "48\n", "authors": ["105"]}
{"title": "Objektorientiertes Reverse Engineering: von klassischer zu objektorientierter Software\n", "abstract": " Die Wartung gro\u00dfer gewachsener Systeme ist ein wichtiger Bereich der Software-Industrie geworden. Heute geht es f\u00fcr Unternehmen meist nicht darum, neue Software-Systeme zu entwickeln, sondern die Lebensdauer existierender Anwendungen zu erh\u00f6hen und deren Wartbarkeit zu verbessern. Objektorientiertes Reverse Engineering erm\u00f6glicht die Umwandlung alter, in prozeduralen Programmiersprachen implementierter Systeme in eine moderne objektorientierte Architektur. Das Buch bietet eine detaillierte Einf\u00fchrung in das Reverse Engineering und zeigt die Verwendung objektorientierter Methoden f\u00fcr die Systemtransformation. Eine praxisbezogene Fallstudie stellt die einzelnen Schritte der Umwandlung eines prozeduralen in ein objektorientiertes System ausf\u00fchrlich dar.", "num_citations": "47\n", "authors": ["105"]}
{"title": "Cocoviz: Towards cognitive software visualizations\n", "abstract": " Understanding software projects is a complex task. There is an increasing need for visualizations that improve comprehensiveness of the evolution of a software system. This paper discusses our recent work in software visualization with respect to metaphors. Our goal is to use simple and well-known graphical elements known from daily life such as houses, spears, or tables to allow a user a quick and intuitive understanding of a given visualization via their proportions. We present a software metrics configurator that handle different metaphors and allows optimizations to their graphical representation. The results so far show that large systems can be visualized effectively with metaphor glyphs, yet more case studies and more metaphor glyphs are required for a better understanding for offering a simple and cognitive visual understanding of a software system.", "num_citations": "47\n", "authors": ["105"]}
{"title": "Evograph: A lightweight approach to evolutionary and structural analysis of large software systems\n", "abstract": " Structural analyses frequently fall short in an adequate representation of historical changes for retrospective analysis. By compounding the two underlying information spaces in a single approach, the comprehension about the interaction between evolving requirements and system development can be improved significantly. We therefore propose a lightweight approach based on release history data and source code changes, which first selects entities with evolutionary outstanding characteristics and then indicates their structural dependencies via commonly used source code entities. The resulting data sets and visualizations aim at a holistic view to point out and assess structural stability, recurring modifications, or changes in the dependencies of the file-sets under inspection. In this paper we describe our approach and its results in terms of the Mozilla case study. Our approach completes typical release history\u00a0\u2026", "num_citations": "47\n", "authors": ["105"]}
{"title": "Updating relational data via SPARQL/update\n", "abstract": " Relational Databases are used in most current enterprise environments to store and manage data. The semantics of the data is not explicitly encoded in the relational model, but implicitly on the application level. Ontologies and Semantic Web technologies provide explicit semantics that allows data to be shared and reused across application, enterprise, and community boundaries. Converting all relational data to RDF is often not feasible, therefore we adopt an ontology-based access to relational databases. While existing approaches focus on read-only access, we present our approach OntoAccess that adds ontology-based write access to relational data. OntoAccess consists of the updateaware RDB to RDF mapping language R3M and algorithms for translating SPARQL/Update operations to SQL. This paper presents the mapping language, the translation algorithms, and a prototype implementation of OntoAccess.", "num_citations": "45\n", "authors": ["105"]}
{"title": "SEON: a pyramid of ontologies for software evolution and its applications\n", "abstract": " The Semantic Web provides a standardized, well-established framework to define and work with ontologies. It is especially apt for machine processing. However, researchers in the field of software evolution have not really taken advantage of that so far. In this paper, we address the potential of representing software evolution knowledge with ontologies and Semantic Web technology, such as Linked Data and automated reasoning. We present Seon, a pyramid of ontologies for software evolution, which describes stakeholders, their activities, artifacts they create, and the relations among all of them. We show the use of evolution-specific ontologies for establishing a shared taxonomy of software analysis services, for defining extensible meta-models, for explicitly describing relationships among artifacts, and for linking data such as code structures, issues (change requests), bugs, and basically any changes\u00a0\u2026", "num_citations": "44\n", "authors": ["105"]}
{"title": "Architecture recovery in ARES\n", "abstract": " Recovering the architecture of legacy systems requires more than just reverse engineering tools to generate some higherlevel descriptions of the system under study. Design decisions and logical groupings of functions have to be balanced with informal domain knowledge, domain standards and coding guidelines of the developers. Therefore, we combine domain aspects with coding aspects and use reverse engineering tools as one means of recovering the requested information to reason about the underlying architecture of the system. This reasoning is an alternating top-down and bottom-up approach. The\u2019architecture recovery process we introduce is one part of the ESPRIT project ARES (Architectural Reasoning for Embedded Systems).\u2019", "num_citations": "44\n", "authors": ["105"]}
{"title": "Web services for groupware in distributed and mobile collaboration\n", "abstract": " While some years ago the focus of many groupware systems has been the support of \"Web computing\", i.e. to support access with Web browsers, the focus today is shifting towards a programmatic access to \"software services\", regardless of their location and the application used to manipulate those services. Whereas the goal of \"Web computing\" has been to support group work on the Web (browser), Web services support for groupware has the goal to provide interoperability between many groupware systems. The contribution is threefold: (i) to present a framework consisting of three levels of Web services for groupware support, (ii) to present a novel Web services management and configuration architecture with the aim of integrating various groupware systems in one overall configurable architecture, and (iii) to provide a use case scenario and preliminary proof-of-concept implementation example. Our overall\u00a0\u2026", "num_citations": "43\n", "authors": ["105"]}
{"title": "Software configuration, distribution, and deployment of web-services\n", "abstract": " Web-Services can be seen as a newly emerging distributed computing model for the Web. They cater for the need to establish business-to-business (B2B) interactions on the Web. Web-Services consider a loosely coupled component model encapsulating business logic and interact with other components using XML protocols. Based on one case study, this paper discusses architectural issues and requirements for software configuration, distribution, and deployment of web-services.", "num_citations": "38\n", "authors": ["105"]}
{"title": "System evolution tracking through execution trace analysis\n", "abstract": " Execution traces produced from instrumented code reflect a system's actual implementation. This information can be used to recover interaction patterns between different entities such as methods, files, or modules. Some solutions for the detection of patterns and their visualization exist, but are limited to small amounts of data and are incapable of comparing data from different versions of a large software system. In this paper, we propose a methodology to analyze and compare the execution traces of different versions of a software system to provide insights into its evolution. We recover high-level module views that facilitate the comprehension of each module's evolution. Our methodology allows us to track the evolution of particular modules and present the findings in three different kinds of visualizations. Based on these graphical representations, the evolution of the concerned modules can be tracked and\u00a0\u2026", "num_citations": "36\n", "authors": ["105"]}
{"title": "Mining evolution data of a product family\n", "abstract": " Diversification of software assets through changing requirements impose a constant challenge on the developers and maintainers of large software systems. Recent research has addressed the mining for data in software repositories of single products ranging from fine- to coarse grained analyses. But so far, little attention has been payed to mining data about the evolution of product families. In this work, we study the evolution and commonalities of three variants of the BSD (Berkeley Software Distribution), a large open source operating system. The research questions we tackle are concerned with how to generate high level views of the system discovering and indicating evolutionary highlights. To process the large amount of data, we extended our previously developed approach for storing release history information to support the analysis of product families. In a case study we apply our approach on data from\u00a0\u2026", "num_citations": "35\n", "authors": ["105"]}
{"title": "Software evolution: analysis and visualization\n", "abstract": " Gaining higher level evolutionary information about large software systems is a key challenge in dealing with increasing complexity and decreasing software quality. Software repositories such as modifications, changes, or release information are rich sources for distinctive kinds of analyses: They reflect the reasons and effects of particular changes made to the software system over a certain period of time. If we can analyze these repositories in an effective way, we get a clearer picture of the status of the software. Software repositories can be analyzed to provide information about the problems concerning a particular feature or a set of features. Hidden dependencies of structurally unrelated but over time logically coupled files exhibit a high potential to illustrate software evolution and possible architectural deterioration. In this tutorial, we describe the investigation of software evolution by taking a step towards\u00a0\u2026", "num_citations": "33\n", "authors": ["105"]}
{"title": "Binding object models to source code: An approach to object-oriented re-architecting\n", "abstract": " Object-oriented re-architecting (OORA) concerns identification of objects in procedural code with the goal to transform a procedural into an object-oriented program. We have developed a method to address the problem of object identification from two different directions: 1) building an object model of the application based on system documentation to ensure the creation of application-semantic classes; and 2) analyzing the source code to identify potential class candidates on the basis of compound data types and data flow analysis. Object model classes are bound to class candidates to prepare a forward biased and thus semantically meaningful program transformation at the source code level. In this paper; we define a similarity measure for classes to enables the binding process. We also describe the constraints and benefits of human intervention in this process. We have applied this method to a real-world\u00a0\u2026", "num_citations": "32\n", "authors": ["105"]}
{"title": "Time variance and defect prediction in software projects\n", "abstract": " It is crucial for a software manager to know whether or not one can rely on a bug prediction model. A wrong prediction of the number or the location of future bugs can lead to problems in the achievement of a project\u2019s goals. In this paper we first verify the existence of variability in a bug prediction model\u2019s accuracy over time both visually and statistically. Furthermore, we explore the reasons for such a high variability over time, which includes periods of stability and variability of prediction quality, and formulate a decision procedure for evaluating prediction models before applying them. To exemplify our findings we use data from four open source projects and empirically identify various project features that influence the defect prediction quality. Specifically, we observed that a change in the number of authors editing a file and the number of defects fixed by them influence the prediction quality. Finally, we\u00a0\u2026", "num_citations": "31\n", "authors": ["105"]}
{"title": "Sofas: A lightweight architecture for software analysis as a service\n", "abstract": " Access to data stored in software repositories by systems such as version control, bug and issue tracking, or mailing lists is essential for assessing the quality of a software system. A myriad of analyses exploiting that data have been proposed throughout the years: source code analysis, code duplication analysis, co-change analysis, bug prediction, or detection of bug fixing patterns. However, easy and straight forward synergies between these analyses rarely exist. To tackle this problem we have developed SOFAS, a distributed and collaborative software analysis platform to enable a seamless interoperation of such analyses. In particular, software analyses are offered as Restful web services that can be accessed and composed over the Internet. SOFAS services are accessible through a software analysis catalog where any project stakeholder can, depending on the needs or interests, pick specific analyses\u00a0\u2026", "num_citations": "31\n", "authors": ["105"]}
{"title": "Supporting continuous integration by mashing-up software quality information\n", "abstract": " Continuous Integration (CI) has become an established best practice of modern software development. Its philosophy of regularly integrating the changes of individual developers with the mainline code base saves the entire development team from descending into Integration Hell, a term coined in the field of extreme programming. In practice CI is supported by automated tools to cope with this repeated integration of source code through automated builds, testing, and deployments. Currently available products, for example, Jenkins-CI, SonarQube or GitHub, allow for the implementation of a seamless CI-process. One of the main problems, however, is that relevant information about the quality and health of a software system is both scattered across those tools and across multiple views. We address this challenging problem by raising awareness of quality aspects and tailor this information to particular stakeholders\u00a0\u2026", "num_citations": "29\n", "authors": ["105"]}
{"title": "Application patterns in re-engineering: identifying and using reusable concepts\n", "abstract": " For a substantial improvement of the reengineering task, identifying the general and recurring high level concepts burried in the source code is essential. However, revealing such software patterns cannot be performed by automatic means only, it requires the management of various uncertainty issues. This paper introduces these patterns and discusses how the uncertainty issues arising during re-engineering can be handled. Furthermore, the paper shows the potential of high-level application patterns for improving the COREM re-engineering methodology.", "num_citations": "27\n", "authors": ["105"]}
{"title": "Collaborative bug triaging using textual similarities and change set analysis\n", "abstract": " Bug triaging assigns a bug report, which is also known as a work item, an issue, a task or simply a bug, to the most appropriate software developer for fixing or implementing it. However, this task is tedious, time-consuming and error-prone if not supported by effective means. Current techniques either use information retrieval and machine learning to find the most similar bugs already fixed and recommend expert developers, or they analyze change information stemming from source code to propose expert bug solvers. Neither technique combines textual similarity with change set analysis and thereby exploits the potential of the interlinking between bug reports and change sets. In this paper, we present our approach to identify potential experts by identifying similar bug reports and analyzing the associated change sets. Studies have shown that effective bug triaging is done collaboratively in a meeting, as it requires\u00a0\u2026", "num_citations": "26\n", "authors": ["105"]}
{"title": "Research Directions in Software Reuse: Where to go from here?\n", "abstract": " Software reuse is no longer in its infancy. We are able to look back at more than 15 years of research and should use the opportunity of such a symposium to critically evaluate the past research in order to identify promising future research areas in software reuse.In this paper, we give a broader view of reuse and some of the so far less-considered areas, which we believe may support software reuse to get off the ground. We mention our ongoing research in software reuse, discussing reuse experiments in the areas of long-term software evolution and component programming.Furthermore, we indicate the critical importance of interactions among the reuse and related communities within software engineering, such as the object-oriented and the software maintenance  communities.", "num_citations": "25\n", "authors": ["105"]}
{"title": "Software visualization with audio supported cognitive glyphs\n", "abstract": " There exist numerous software visualization techniques that aim to facilitate program comprehension. One of the main concerns in every such software visualization is to identify relevant aspects fast and provide information in an effective way. In previous work, we developed a cognitive visualization technique and tool called CocoViz that uses common place metaphors for an intuitive understanding of software structures and evolution. In this paper, we address software comprehension by a combination of visualization and audio. Evolution and structural aspects are annotated with different audio to represent concepts such as design erosion, code smells or evolution metrics. We use audio concepts such as loudness, sharpness, tone pitch, roughness or oscillation and map those to properties of classes and packages. As such we provide an audio annotation of software entities along their version history for software\u00a0\u2026", "num_citations": "24\n", "authors": ["105"]}
{"title": "Recommending method invocation context changes\n", "abstract": " Our investigations of bug fixes in Eclipse showed that a significant amount of bugs were fixed by moving invocations of certain methods into the then or else-part of if-statements with similar conditions. Based on this finding, we leverage such context changes applied in the past to support developers while adding invocations of the same method. In this paper we present ChangeCommander, an Eclipse plugin that implements our approach to recommend insertions of particular if-statements before calling a method. Change-Commander presents context change suggestions by high-lighting affected method invocations in the source code and provides automated code adaptation support.", "num_citations": "23\n", "authors": ["105"]}
{"title": "Towards Semantic Web Engineering: WEESA-Mapping XML Schema to Ontologies.\n", "abstract": " The existence of semantically tagged Web pages is crucial to bring the Semantic Web to life. But it is still costly to develop and maintain Web applications that offer data and meta-data. Several standard Web engineering methodologies exist for designing and implementing Web applications. In this paper we introduce a technique to extend existing Web engineering techniques to develop semantically tagged Web applications. The novelty of this technique is the definition and implementation of a mapping from XML Schema to ontologies that can be used to automatically generate RDF meta-data from XML content documents.", "num_citations": "23\n", "authors": ["105"]}
{"title": "Evaluation of a publish/subscribe system for collaborative and mobile working\n", "abstract": " The MObile Teamwork Infrastructure for Organizations Networking (MOTION) service platform that we have designed and implemented addresses an emerging requirement in the daily business of large, distributed enterprises: support for mobile teamwork. Employees are often on the move and use a wide range of computing devices such as WAP phones, PDAs, notebooks and desktop computers. The service architecture that we have developed supports mobile teamwork by providing multi-device service access, XML meta data for information sharing and locating, and the XML Query Language (XQL) for distributed searches and publish/subscribe. We present the solution that we adopted in our prototype, analyze the shortcomings of this approach and based on our evaluation experiences, list the requirements for a publish-subscribe middleware for collaborative mobile working.", "num_citations": "23\n", "authors": ["105"]}
{"title": "SQA-Mashup: A mashup framework for continuous integration\n", "abstract": " ContextContinuous Integration (CI) has become an established best practice of modern software development. Its philosophy of regularly integrating the changes of individual developers with the master code base saves the entire development team from descending into Integration Hell, a term coined in the field of extreme programming. In practice, CI is supported by automated tools to cope with this repeated integration of source code through automated builds and testing. One of the main problems, however, is that relevant information about the quality and health of a software system is both scattered across those tools and across multiple views.ObjectiveThis paper introduces a quality awareness framework for CI-data and its conceptional model used for the data integration and visualization. The framework called SQA-Mashup makes use of the service-based mashup paradigm and integrates information from\u00a0\u2026", "num_citations": "21\n", "authors": ["105"]}
{"title": "A framework for semi-automated software evolution analysis composition\n", "abstract": " Software evolution data stored in repositories such as version control, bug and issue tracking, or mailing lists is crucial to better understand a software system and assess its quality. A myriad of analyses exploiting such data have been proposed throughout the years. However, easy and straight forward synergies between these analyses rarely exist. To tackle this problem we have investigated the concept of Software Analysis as a Service and devised SOFAS, a distributed and collaborative software evolution analysis platform. Software analyses are offered as services that can be accessed, composed into workflows, and executed over the Internet. This paper presents our framework for composing these analyses into workflows, consisting of a custom-made modeling language and a composition infrastructure for the service offerings. The framework exploits the RESTful nature of our analysis service\u00a0\u2026", "num_citations": "21\n", "authors": ["105"]}
{"title": "An approach for collaborative code reviews using multi-touch technology\n", "abstract": " Code reviews are an effective mechanism to improve software quality, but often fall short in the development of software. To improve the desirability and ease of code reviews, we introduce an approach that explores how multi-touch interfaces can support code reviews and can make them more collaborative. Our approach provides users with features to collaboratively find and investigate code smells, annotate source code and generate review reports using gesture recognition and a Microsoft Surface Table. In a preliminary evaluation, subjects generally liked the prototypical implementation of our approach for performing code review tasks.", "num_citations": "20\n", "authors": ["105"]}
{"title": "Process awareness for distributed software development in virtual teams\n", "abstract": " Organizations increasingly define their software development projects as \"virtual project teams\", where project members from within the organization cooperate with outside experts and therefore build a \"community\", which in many cases operates as a highly distributed team. Process modeling, -composition and -configuration are substantial ingredients for team activities. This paper analyses the needs for process awareness for virtual teams and derives the requirements for location-transparent distributed and mobile collaboration. It describes the design of virtual project teams that contain mobile users, their artifacts, and processes. The paper distills a framework for process aware virtual project teams that goes beyond current technologies such as peer-to-peer, multiple servers and clients, as well as Workflow Management and Groupware systems.", "num_citations": "20\n", "authors": ["105"]}
{"title": "Towards software analysis as a service\n", "abstract": " Throughout the years software engineers have come up with a myriad of specialized tools and techniques that focus on a certain type of analysis, such as metrics extraction, evolution tracking, co-change detection, bug prediction, all the way up to social network analysis of team dynamics. However, easy and straight forward synergies between these analyses/tools rarely exist because of their stand-alone nature, their platform dependence, their different input and output formats and the variety of systems to analyze. This significantly hampers their usage and reduces their acceptance by other researchers and software companies. To overcome this problem we propose a distributed and collaborative software analysis platform to enable a seamless interoperability of software analysis tools across platform, geographical and organizational boundaries. In particular, we devise software analysis tools as services that can\u00a0\u2026", "num_citations": "19\n", "authors": ["105"]}
{"title": "MDS-Views: Visualizing problem report data of large scale software using multidimensional scaling\n", "abstract": " Gaining higher level evolutionary information about large software systems is key a in validating past and adjusting future development processes. In this paper we address the visualization of problem reports by taking advantage of the proximity introduced by changes required to fix a problem. Our analyses are based on modification and problem report data representing the system\u2019s history. For computation of proximity data we applied a standard technique called multidimensional scaling (MDS). Visualization of feature evolution is enabled through the exploitation of proximity among problem reports. Two different views support the assessment of a system design based on historical data. Our approach uncovers hidden dependencies between features and presents them in easy-to-evaluate visual form. Regions of interest can be selected interactively enabling the assessment of feature evolution on an arbitrary level of detail. A visualization of interwoven features can indicate locations of design erosion in the architectural evolution of a software system.", "num_citations": "18\n", "authors": ["105"]}
{"title": "Visual requirements validation: Case study in a CORBA-supported environment\n", "abstract": " We present an approach to requirements validation in which the formal specification of the requirements is directly, interpreted and the results are visually, presented to the customer through a graphical user interface, relying on the customer to visually, validate the specified requirements. The communication between the user interface and the specification interpreter is accomplished through CORBA. The approach supports the cooperation of customers and developers in eliciting and validating the requirements. We present a case study of the application of the technique to the validation of a generic access control component. The use of CORBA has the advantage that any, CORBA-compliant language can be used for the user interface, independently of the implementation of the specification interpreter The contributions of the paper are 1) the presentation of a case stud), of the visual requirement validation\u00a0\u2026", "num_citations": "18\n", "authors": ["105"]}
{"title": "Recovery of architectural structure: A case study\n", "abstract": " Industrial software development is often an evolutionary process. Software products are developed for one specific customer and later on refined for other customers with different requirements in terms of a product family. Refinements happen at the implementation level (algorithms and data structures) and on the architectural level (the overall system structure). Recovery of architectural information is necessary to build up a complete and unambiguous description of the architecture of a system. In this paper, we describe an approach for the recovery of architectural structure that focuses on component and connector identification. We describe different strategies to define components and connectors of the system. The examples given in the paper were developed out of an industrial case study, a real-time Train Control System. The recovered architectural description allows reasoning about the quality of the\u00a0\u2026", "num_citations": "18\n", "authors": ["105"]}
{"title": "Capsule oriented reverse engineering for software reuse\n", "abstract": " Much research effort concerning the reuse of software components has been invested on questions such as classification, attribution and organization of modules in software components libraries. Further problems like the obtaining of reusable components and their interconnection to form new software systems have been discovered. Reverse engineering can be used for different purposes, like maintenance effort reduction, documentation improvement, etc., but also for software reuse. In the process of software reuse, reverse engineering can be used to extract reusable components from existing software systems.             In this paper we provide insights into a reverse engineering method called capsule oriented reverse engineering method (COREM) that realizes the extraction of object similar capsules from existing systems implemented in a procedural language. For this, COREM transforms the original\u00a0\u2026", "num_citations": "18\n", "authors": ["105"]}
{"title": "How high will it be? Using machine learning models to predict branch coverage in automated testing\n", "abstract": " Software testing is a crucial component in modern continuous integration development environment. Ideally, at every commit, all the system's test cases should be executed and moreover, new test cases should be generated for the new code. This is especially true in a Continuous Test Generation (CTG) environment, where the automatic generation of test cases is integrated into the continuous integration pipeline. Furthermore, developers want to achieve a minimum level of coverage for every build of their systems. Since both executing all the test cases and generating new ones for all the classes at every commit is not feasible, they have to select which subset of classes has to be tested. In this context, knowing a priori the branch coverage that can be achieved with test data generation tools might give some useful indications for answering such a question. In this paper, we take the first steps towards the definition\u00a0\u2026", "num_citations": "17\n", "authors": ["105"]}
{"title": "Concept and architecture of an pervasive document editing and managing system\n", "abstract": " Collaborative document processing has been addressed by many approaches so far, most of which focus on document versioning and collaborative editing. We address this issue from a different angle and describe the concept and architecture of a pervasive document editing and managing system. It exploits database techniques and real-time updating for sophisticated collaboration scenarios on multiple devices. Each user is always served with up-to-date documents and can organize his work based on document meta data. For this, we present our conceptual architecture for such a system and discuss it with an example.", "num_citations": "17\n", "authors": ["105"]}
{"title": "Dynamic collaborative business processes within documents\n", "abstract": " Effective collaborate business process support is essential in today's business. In this paper, we address this aspect within documents. Often, such text documents are stored unsystematically in a rather confusing file structure with an inscrutable hierarchy and little access control. Business data, on the other hand, are stored in a systematic way in databases allowing multi-user, multi-site, user-/role-specific controlled access. We store text documents in databases and exploit these database capabilities: colloborative business processes then can be defined per document or any part of a document. In this paper, we present this dynamic collaborative business process concept and the prototype within documents for our database-based collaborative editor. We evaluate the potential of such business processes for the quality of communication and documentation.", "num_citations": "17\n", "authors": ["105"]}
{"title": "Using domain knowledge to improve reverse engineering\n", "abstract": " Integrating application domain knowledge into reverse engineering is an important step to overcome the shortcomings of conventional reverse engineering approaches that are based exclusively on information derivable from source code. In this paper, we show the basic concepts of a program transformation process from a conventional to an object-oriented architecture which incorporates extraneous higher-level knowledge in its process. To which degree this knowledge might stem from some general domain knowledge, and to which extent it needs to be introduced as application dependent knowledge by a human expert is discussed. The paper discusses these issues in the context of the architectural transformation of legacy systems to an object-oriented architecture.", "num_citations": "17\n", "authors": ["105"]}
{"title": "Program transformation to enhance the reuse potential of procedural software\n", "abstract": " Object-oriented concepts seem to be useful concerning the reuse of~ xlsting soRwarc. Therefore a transformation of procedural programs to object-oriented programs becomes an important process to enhance the reuse potentiai of procedural programs. In this paper we describe a program transformation process, which transforms originally procedural systems to object-oriented systems. The objects of the resulting systcrn may then be used for further object-oriented systems engineering, avoiding many problems arising in connection with procedural software reuse (ie module interconnectionl etc.).", "num_citations": "16\n", "authors": ["105"]}
{"title": "Reuse engineering: software construction from reusable components\n", "abstract": " The authors describe a comprehensive approach that supports reuse in the software development process, especially the production of software from reusable components. For this purpose well-known strategies like reverse engineering and design recovery are combined with a generalization mechanism to develop the reuse engineering process. This process includes both the phase of isolating reusable modules from existing software and the phase of retrieving such modules from a software component library and combining them to new software. The definition of a reuse engineering life-cycle, which integrates reuse into the conventional software life-cycle is considered.<>", "num_citations": "16\n", "authors": ["105"]}
{"title": "Software mining studies: Goals, approaches, artifacts, and replicability\n", "abstract": " The mining of software archives has enabled new ways for increasing the productivity in software development: Analyzing software quality, mining project evolution, investigating change patterns and evolution trends, mining models for development processes, developing methods of integrating mined data from various historical sources, or analyzing natural language artifacts in software repositories, are examples of research topics. Software repositories include various data, ranging from source control systems, issue tracking systems, artifact repositories such as requirements, design and architectural documentation, to archived communication between project members. Practitioners and researchers have recognized the potential of mining these sources to support the maintenance of software, to improve their design or architecture, and to empirically validate development techniques or processes. We\u00a0\u2026", "num_citations": "15\n", "authors": ["105"]}
{"title": "Replicating mining studies with SOFAS\n", "abstract": " The replication of studies in mining software repositories (MSR) is essential to compare different mining techniques or assess their findings across many projects. However, it has been shown that very few of these studies can be easily replicated. Their replication is just as fundamental as the studies themselves and is one of the main threats to validity that they suffer from. In this paper, we show how we can alleviate this problem with our SOFAS framework. SOFAS is a platform that enables a systematic and repeatable analysis of software projects by providing extensible and composable analysis workflows. These workflows can be applied on a multitude of software projects, facilitating the replication and scaling of mining studies. In this paper, we show how and to which degree replication can be achieved. We investigated the mining studies of MSR from 2004 to 2011 and found that from 88 studies published in the\u00a0\u2026", "num_citations": "15\n", "authors": ["105"]}
{"title": "Managing uncertainty in an object recovery process\n", "abstract": " Object-oriented concepts facilitate the reusability as well as the maintainability of existing software. Due to the great amount of existing procedural software, object identification in procedural programs is an important approach. The object recovery process for this identification of objects within procedural programs presents several uncertainties and ambiguities, which have to be resolved by acquisition of additional knowledge from the application domain and a human expert. In this paper we show the basic concepts of the object recovery process and describe those uncertainties and ambiguities, as well as our way of managing them in order to identify objects in procedural programs.", "num_citations": "15\n", "authors": ["105"]}
{"title": "CocoViz with ambient audio software exploration\n", "abstract": " For ages we used our ears side by side with our ophthalmic stimuli to gather additional information, leading and supporting us in our visualization. Nowadays numerous software visualization techniques exist that aim to facilitate program comprehension. In this paper we discuss how we can support such software comprehension visualization with environmental audio and lead users to identify relevant aspects. We use cognitive visualization techniques and audio concepts described in our previous work to create an ambient audio software exploration (AASE) out of program entities (packages, classes ...) and their mapped properties. The concepts where implemented in a extended version of our tool called CocoViz. Our first results with the prototype shows that with this combination of visual and aural means we can provide additional information to lead users during program comprehension tasks.", "num_citations": "14\n", "authors": ["105"]}
{"title": "Cocoviz: Supported cognitive software visualization\n", "abstract": " As software evolves and becomes more and more complex, program comprehension arises as a major concern in software projects. The amount of data and the complexity of relationships between the entities are unmanageable for engineers without effective tool support. In this paper, we demonstrate how CocoViz can help understanding software in a quick and intuitive manner. Some of the implemented approaches have been presented independently before[1]. However, in CocoViz we combine them in an intuitive and easy to use manner.", "num_citations": "14\n", "authors": ["105"]}
{"title": "Architectural transformation of legacy systems\n", "abstract": " Based on our approach to convert the architecture of conventionally developed systems to an object-oriented architecture, we present a set of positions concerning architectural transformations of legacy systems. Our claim is, that such a transformation process cannot be conducted in a fully automated way. However, careful division of the transformation work to be done can help to keep the amount of manual intervention limited. in: William Griswold (ed.) 17th International Conference on Software Engineering (ICSE-17) Workshop on Program Transformation for Software Evolution Technical Report Number CS95-418, Seattle, April 1995", "num_citations": "14\n", "authors": ["105"]}
{"title": "Branch coverage prediction in automated testing\n", "abstract": " Software testing is crucial in continuous integration (CI). Ideally, at every commit, all the test cases should be executed, and moreover, new test cases should be generated for the new source code. This is especially true in a Continuous Test Generation (CTG) environment, where the automatic generation of test cases is integrated into the continuous integration pipeline. In this context, developers want to achieve a certain minimum level of coverage for every software build. However, executing all the test cases and, moreover, generating new ones for all the classes at every commit is not feasible. As a consequence, developers have to select which subset of classes has to be tested and/or targeted by test\u2010case generation. We argue that knowing a priori the branch coverage that can be achieved with test\u2010data generation tools can help developers into taking informed decision about those issues. In this paper, we\u00a0\u2026", "num_citations": "13\n", "authors": ["105"]}
{"title": "Rapid multi-purpose, multi-commit code analysis\n", "abstract": " Existing code- and software evolution studies typically operate on the scale of a few revisions of a small number of projects, mostly because existing tools are unsuited for performing large-scale studies. We present a novel approach, which can be used to analyze an arbitrary number of revisions of a software project simultaneously and which can be adapted for the analysis of mixed-language projects. It lays the foundation for building high-performance code analyzers for a variety of scenarios. We show that for one particular scenario, namely code metric computation, our prototype outperforms existing tools by multiple orders of magnitude when analyzing thousands of revisions.", "num_citations": "13\n", "authors": ["105"]}
{"title": "An architectural blueprint for a pluggable version control system for software (evolution) analysis\n", "abstract": " Current version control systems are not built to be systematically analyzed. They have greatly evolved since their first appearance, but their focus has always been towards supporting developers in forward engineering activities. Supporting the analysis of the development history has so far been neglected. A plethora of third party applications have been built to fill this gap. To extract the data needed, they use interfaces that were not built for that. Drawing from our experience in mining and analyzing version control repositories, we propose an architectural blueprint for a plug-in based version control system in which analyses can be directly plugged into it in a flexible and lightweight way, to support both developers and analysts. We show the potential of this approach in three usage scenarios and we also give some examples for these analysis plug-ins.", "num_citations": "13\n", "authors": ["105"]}
{"title": "Towards a generalized payment model for Internet services\n", "abstract": " Prerequisite for the success of new business models in the Internet, such as pay-per-view, will be an efficient and interoperable electronic payment system. Many protocols and frameworks for various business domains exist. However, they are mostly incompatible which makes it hard for service providers to design for change. We investigated several standard payment scenarios and configurations and analyzed shortcomings of existing payment schemes. As a result, we developed expressive, common payment abstractions and came up with a generalized payment model which hides the payment mechanisms used, but offers a common, high-level interface and supports a wide range of business models. In this paper, we present our generalized payment model and its accompanying security model for Internet services. We discuss its abstractions and protocols and evaluate it in an Internet-scale push system.", "num_citations": "13\n", "authors": ["105"]}
{"title": "Object-model driven abstraction-to-code mapping\n", "abstract": " In object-oriented re-architecting, we face the problem of improving the maintainability of procedural source code to facilitate software evolution. We do this by transforming the procedural code into an object-structure employing encapsulation to the legacy data structures and their related procedures. To handle the concept assignment problem, we established a stepwise abstractionto-code mapping via different object models based on criteria such as the kind of information used in the modeling process, model granularity, and model abstraction. This mapping is object-model and thus forward-driven rather than source-code or reverse-driven and therefore enables the specific use of application and domain knowledge. For that, an object-model driven approach promises a high-level semantic class structure for an improved software evolution process. We have applied our approach to a real-world embedded software system to identify potential objects; several results from the case study are given in the paper.", "num_citations": "13\n", "authors": ["105"]}
{"title": "Reverse engineering to recover and describe a system\u2019s architecture\n", "abstract": " The increasing interest in the software architecture of systems stems from the need to generate product families, to facilitate the reuse of components, to better understand systems and to redocument them. This paper introduces our approach to recover and describe a system\u2019s architecture: different aspects of a system (i.e. architectural properties) are recovered and then described. The recovery process focuses on architectural properties, such as safety and variance and their description, but not on the recovery of a complete system\u2019s architecture. Such a property-driven recovery allows to incrementally investigate those aspects of a system that are of special interest for the recovery purpose. Additionally the paper presents our architecture recovery framework and process, and an example illustrating the applicability of our framework.", "num_citations": "13\n", "authors": ["105"]}
{"title": "Evaluating a query framework for software evolution data\n", "abstract": " With the steady advances in tooling to support software engineering, mastering all the features of modern IDEs, version control systems, and project trackers is becoming increasingly difficult. Answering even the most common developer questions can be surprisingly tedious and difficult. In this article we present a user study with 35 subjects to evaluate our quasi-natural language interface that provides access to various facets of the evolution of a software system but requires almost zero learning effort. Our approach is tightly woven into the Eclipse IDE and allows developers to answer questions related to source code, development history, or bug and issue management. The results of our evaluation show that our query interface can outperform classical software engineering tools in terms of correctness, while yielding significant time savings to its users and greatly advancing the state of the art in terms of usability\u00a0\u2026", "num_citations": "12\n", "authors": ["105"]}
{"title": "EvoSpaces: Multi-dimensional navigation spaces for software evolution\n", "abstract": " EvoSpaces is a Swiss-wide research project sponsored by the Hasler foundation. It involves three partners: University of Zurich, University of Lugano and the University of Applied Sciences in Geneva. The overall goal of the project is to explore novel ways to visualize and navigate evolving software systems in a 3D environment. In this paper we briefly describe the particularities of the project and the results obtained so far.", "num_citations": "12\n", "authors": ["105"]}
{"title": "Semantic Clipboard-Semantically Enriched Data Exchange Between Desktop Applications.\n", "abstract": " The operating system clipboard is used to copy and paste data between applications even if the applications are from different vendors. Current clipboards only support the transfer of data or formatted data between applications. The semantics of the data, however, is lost in the transfer. The Semantic Web, on the other hand, provides a common framework that allows data to be shared across application boundaries while preserving the semantics of the data. In this paper we introduce the concept of a Semantic Clipboard and present a prototype implementation that can be used to copy and paste RDF meta-data between desktop applications. The Semantic Clipboard is based on a flexible plugin architecture that enables the easy extension of the clipboard to new ontology vocabularies and target applications. Furthermore, we show how the Semantic Clipboard is used to copy and paste the meta-data from semantically annotated Web pages to a user\u2019s desktop application.", "num_citations": "12\n", "authors": ["105"]}
{"title": "A systematic approach to the development of event based applications\n", "abstract": " We propose a novel framework logic of event consumption and publication (LECAP) for the development of event-based applications. Our approach offers the following advantages over existing approaches: 1) it supports a while-parallel language, 2) the reasoning allows a dynamic (instead of static) binding of programs to events, 3) it is oriented towards stepwise development of systems, and 4) the underlying logic supports the composition of specifications. The event based architectural style has been recognized as fostering the development of large-scale and complex systems by loosely coupling their components. It is therefore increasingly deployed in various environments such as middleware for mobile computing, message oriented middleware, integration frameworks, communication standards, and commercial toolkits. Current approaches to the development of event-based applications are ad hoc and do\u00a0\u2026", "num_citations": "12\n", "authors": ["105"]}
{"title": "Constructing CORBA-supported oracles for testing: a case study in automated software testing\n", "abstract": " As the complexity of applications and therefore of their testing process grows, the importance of automating the testing activity increases. The testing process includes test case generation, test sequencing, oracle construction, test execution and result interpretation. Automatic generation of test cases from formal specifications has received considerable attention. Relatively little work has been reported, however, on constructing oracles for supporting efficient and automatic execution of such test cases. We present a technique for constructing a CORBA-supported VDM oracle for black-box testing starting from a VDM-SL specification. This specification is used to automatically verify the results of operations implemented in a high-level programming language. We present a case study of the technique applied to a Java application for generic access control. The technique is applicable to any CORBA-compliant\u00a0\u2026", "num_citations": "12\n", "authors": ["105"]}
{"title": "Automatic detection and repair recommendation of directive defects in Java API documentation\n", "abstract": " Application Programming Interfaces (APIs) represent key tools for software developers to build complex software systems. However, several studies have revealed that even major API providers tend to have incomplete or inconsistent API documentation. This can severely hamper the API comprehension and, as a consequence, the quality of the software built on them. In this paper, we propose DRONE (Detect and Repair of dOcumentatioN dEfects), a framework to automatically detect and repair defects from API documents by leveraging techniques from program analysis, natural language processing, and constraint solving. Specifically, we target at the directives of API documents, which are related to parameter constraints and exception handling declarations. Furthermore, in presence of defects, we also provide a prototypical repair recommendation system. We evaluate our approach on parts of the well\u00a0\u2026", "num_citations": "11\n", "authors": ["105"]}
{"title": "Reducing redundancies in multi-revision code analysis\n", "abstract": " Software engineering research often requires analyzing multiple revisions of several software projects, be it to make and test predictions or to observe and identify patterns in how software evolves. However, code analysis tools are almost exclusively designed for the analysis of one specific version of the code, and the time and resources requirements grow linearly with each additional revision to be analyzed. Thus, code studies often observe a relatively small number of revisions and projects. Furthermore, each programming ecosystem provides dedicated tools, hence researchers typically only analyze code of one language, even when researching topics that should generalize to other ecosystems. To alleviate these issues, frameworks and models have been developed to combine analysis tools or automate the analysis of multiple revisions, but little research has gone into actually removing redundancies in multi\u00a0\u2026", "num_citations": "11\n", "authors": ["105"]}
{"title": "An empirical validation of the benefits of adhering to the law of demeter\n", "abstract": " The Law of Demeter formulates the rule-of-thumb that modules in object-oriented program code should \"only talk to their immediate friends\". While it is said to foster information hiding for object-oriented software, solid empirical evidence confirming the positive effects of following the Law of Demeter is still lacking. In this paper, we conduct an empirical study to confirm that violating the Law of Demeter has a negative impact on software quality, in particular that it leads to more bugs. We implement an Eclipse plugin to calculate the amount of violations of both the strong and the weak form of the law in five Eclipse sub-projects. Then we discover the correlation between violations of the law and the bug-proneness and perform a logistic regression analysis of three sub-projects. We also combine the violations with other OO metrics to build up a model for predicting the bug-proneness for a given class. Empirical results\u00a0\u2026", "num_citations": "11\n", "authors": ["105"]}
{"title": "Software architecture recovery of embedded software\n", "abstract": " The complexity of embedded software systems has increased substantially in the last years. The concept of software architecture provides methods and notations to handle the increased size and complexity. These concepts provide a higher level of abstraction than common analysis and design methods.The architecture of existing legacy systems is of high interest for the development of successors of such systems. However, architectural information of legacy systems is often not available. The architecture recovery process we discuss is research work within the ESPRIT project ARES (Architectural Reasoning for Embedded Systems). 1", "num_citations": "11\n", "authors": ["105"]}
{"title": "Automated user reviews analyser\n", "abstract": " We present a novel tool, AUREA, that automatically classifies mobile app reviews, filters and facilitates their analysis using fine grained mobile specific topics. We aim to help developers analyse the direct and valuable feedback that users provide through their reviews, in order to better plan maintenance and evolution activities for their apps. Reviews are often difficult to analyse because of their unstructured textual nature and their frequency, moreover only a third of them are informative. We believe that by using our tool, developers can reduce the amount of time required to analyse and understand the issues users encounter and plan appropriate change tasks.", "num_citations": "10\n", "authors": ["105"]}
{"title": "Tracking source code propagation in software systems via release history data and code clone detection\n", "abstract": " According to recent research, code clones constitute a costly overhead in large software systems, which usually contain about 17 to 25% duplicated lines of source code. Thus, reducing the duplicated lines would considerably decrease the maintenance costs. Some of the code clones are created and maintained with clear intention, but usually they are regarded as bad smell. In recent years increased research was done in this field. Different approaches facilitating the detection, maintenance, and even the removal of code clones were proposed. However, all these approaches have some shortcomings. There is also a lack of means to qualitatively describe typical code clones, and very little is known about how code clones evolve over various versions of a software system.In this thesis we propose a Clone Reference Database that addresses some of the current shortcomings by joining and filtering the results of different clone detection tools. Therefore we propose the metrics overlap and confidence to make the results qualitatively assessable. Through a further classification of code clones, which is obtained by linking the clones with extracted language objects, we add more comprehension to the data. Additionally, we introduce metrics to analyze how code clones are affected by evolutionary changes. By means of them and a basic clone tracker we investigate the propagation of clones and clone groups over time. To perform and facilitate the creation and maintenance of the Clone Reference Database, we implemented the Clone Detection Toolbox. We evaluated our approach with seven selected versions of the Mozilla project. The clone\u00a0\u2026", "num_citations": "10\n", "authors": ["105"]}
{"title": "An architecture for an adaptive and collaborative learning management system in aviation security\n", "abstract": " The importance of aviation security has increased dramatically in recent years. Frequently changing regulations and the need to adapt quickly to new and emerging threats are challenges that need to be addressed by airports, security companies and appropriate authorities across the world. Learning management systems (LMS) have been developed as effective tools for enhancing the management, integration and application of knowledge in organizations. In the aviation security domain, we need mechanisms to quickly adapt to new learning content, to different roles ranging from screeners to supervisors, to flexible training scenarios and solid job assessments. For that, a learning system has to be flexible and adaptive both in knowledge, organizational and in collaboration dimensions. Current LMS do not meet these requirements. In this paper we present a software architecture that is apt to support the\u00a0\u2026", "num_citations": "9\n", "authors": ["105"]}
{"title": "Architectural Concerns for Flexible Data Management\n", "abstract": " Evolving database management systems (DBMS) towards more flexibility in functionality, adaptation to changing requirements, and extensions with new or different components, is a challenging task. Although many approaches have tried to come up with a flexible architecture, there is no architectural framework that is generally applicable to provide tailor-made data management and can directly integrate existing application functionality. We discuss an alternative database architecture that enables more lightweight systems by decomposing the functionality into services and have the service granularity drive the functionality. We propose a service-oriented DBMS architecture which provides the necessary flexibility and extensibility for general-purpose usage scenarios. For that we present a generic storage service system to illustrate our approach.", "num_citations": "9\n", "authors": ["105"]}
{"title": "Resolving uncertainties in object-oriented re-architecting of procedural code\n", "abstract": " Conference title IPMU: information processing and management of uncertainty in knowledge-based systems (Paris, 6-10 July 1998)= Traitement d'information et gestion d'incertitudes dans les syst\u00e8mes \u00e0 base de connaissances (fr)", "num_citations": "9\n", "authors": ["105"]}
{"title": "Binding object models to source code: an approach to object-oriented re-architecting\n", "abstract": " Object oriented re-architecting (OORA) concerns identication of objects and the corresponding methods in procedural code with the goal to transform a procedural into an object-oriented program. We have developed a method to address the problem of object identication from two dierent directions: 1) building an object model of the application (ie OMT) based on system documentation to ensure the creation of application-semantic objects; and 2) analyzing the source code to identify potential object candidates on the basis of compound data types and data ow analysis. The object identication process binds object model entities (ie classes) to object candidates derived from the source code to prepare a forward biased and thus semantically meaningful program transformation at the source code level. In this paper, we dene a similarity measure for classes and describe how this measure enables the binding process\u00a0\u2026", "num_citations": "9\n", "authors": ["105"]}
{"title": "Objektorientierte Konzepte in Smalltalk, C++, Objective-C, Eiffel und Modula-3\n", "abstract": " Dieser Artikel untersucht einige weit verbreitete objektorientierte Programmiersprachen hinsichtlich ihrer Umsetzung der zugrundeliegenden objektorientierten Konzepte. Als Basis f\u00fcr einen konsistenten Vergleich wird eine einheitliche (objektorientierte) Terminologie definiert.", "num_citations": "9\n", "authors": ["105"]}
{"title": "User review-based change file localization for mobile applications\n", "abstract": " In the current mobile app development, novel and emerging DevOps practices (e.g., Continuous Delivery, Integration, and user feedback analysis) and tools are becoming more widespread. For instance, the integration of user feedback (provided in the form of user reviews) in the software release cycle represents a valuable asset for the maintenance and evolution of mobile apps. To fully make use of these assets, it is highly desirable for developers to establish semantic links between the user reviews and the software artefacts to be changed (e.g., source code and documentation), and thus to localize the potential files to change for addressing the user feedback. In this paper, we propose RISING (Reviews Integration via claSsification, clusterIng, and linkiNG), an automated approach to support the continuous integration of user feedback via classification, clustering, and linking of user reviews. RISING leverages\u00a0\u2026", "num_citations": "8\n", "authors": ["105"]}
{"title": "Pervasive Software Services for dynamic virtual organizations\n", "abstract": " Information and Communication Technology (ICT) is penetrating deeper into daily life and work of people: mobile communications, portable devices, embedded computing and intelligent systems are major opportunities for creating next generation information systems and infrastructures. Technologies such as Bluetooth, WLAN, or SIP-based broadband networks and 3rd generation mobile phones (UMTS) are offering the infrastructure to conceive information systems as pervasive, meaning that systems are accessible from anywhere, at any time, and with any device. This paper presents our achievements in this area of research based the research prototypes developed in our EU projects MOTION and EasyComp. Further, the paper outlines aspects of pervasive software services for dynamic virtual organizations that are considered in our ongoing project PeSSIFIC to fulfill needs and constraints of\u00a0\u2026", "num_citations": "8\n", "authors": ["105"]}
{"title": "Distributed product development in virtual communities\n", "abstract": " Organizations are increasingly forced to manage and coordinate their product and service development processes, to deliver their products and services as fast as possible, and to involve employees, customers, suppliers, and partners seamlessly in different stages of the processes. These processes have to consider that their participants are more and more on the move or distributed while they are working. Expertise needs to be shared across locations and different mobile devices. This paper defines a framework for distributed and mobile collaboration, defines a set of requirements for virtual communities, and discusses a mobile teamwork support software architecture that has been developed in the EU-project MOTION. The framework together with the architecture enables to enhance current collaboration approaches to include the dimension of mobile participants and virtual communities for distributed product development.", "num_citations": "8\n", "authors": ["105"]}
{"title": "MOTION: a peer-to-peer platform for mobile teamwork support\n", "abstract": " Large, global enterprises are increasingly faced with the problem of supporting employees that are on the move. Employees need to share business documents, locate expertise and knowledge through distributed searches, access effective subscription/notification mechanisms, and they need any time, anywhere access to the company's information resources. We address these problems and requirements in the MObile Teamwork Infrastructure for Organizations Networking (MOTION) project and aim to create an advanced information and communication technology (ICT) infrastructure for mobile teamwork. We give a brief description of the MOTION peer-to-peer platform for mobile teamwork.", "num_citations": "8\n", "authors": ["105"]}
{"title": "Describing software architectures by system structure and properties\n", "abstract": " To support architecture based development, different modeling notations and languages, so called architecture description languages (ADLs), have been designed. To be of help in the development process, software architectures must be described in a complete and consistent manner but without being overloaded with information provided to the system stakeholders. Current architecture description languages provide information about software architectures in a domain independent way. This may lead to inappropriate and incomplete descriptions of software architectures. We introduce a flexible and extensible language called Architecture Structure Description Language (ASDL) developed for describing structural aspects of software architectures and their properties. We thereby focus on the domain of embedded real time systems that have to meet certain timing and safety constraints. The language was\u00a0\u2026", "num_citations": "8\n", "authors": ["105"]}
{"title": "Balancing in reverse engineering and in object-oriented systems engineering to improve reusability and maintainability\n", "abstract": " Whenever a reverse engineering method is applied to an old software system, the results are mainly limited to its degree of automation. Additional domain knowledge via a human expert helps to overcome this limitation. Modernizing old procedural software for object-oriented reuse requires domain knowledge as well us a balancing of the recovered information. We have developed a reverse engineering method for a gradual transition of procedural programs to an object-oriented architecture based on those aspects. This paper describes the balancing of the various generated models in our reverse engineering method and discusses this balancing in comparison to the balancing process in conventional object-oriented systems development. We also point out the links between these two engineering approaches. Furthermore the advantages of our reverse engineering process for reusability as well as\u00a0\u2026", "num_citations": "8\n", "authors": ["105"]}
{"title": "Replicating parser behavior using neural machine translation\n", "abstract": " More than other machine learning techniques, neural networks have been shown to excel at tasks where humans traditionally outperform computers: recognizing objects in images, distinguishing spoken words from background noise or playing \"Go\". These are hard problems, where hand-crafting solutions is rarely feasible due to their inherent complexity. Higher level program comprehension is not dissimilar in nature: while a compiler or program analysis tool can extract certain facts from (correctly written) code, it has no intrinsic 'understanding' of the data and for the majority of real-world problems, a human developer is needed - for example to find and fix a bug or to summarize the bahavior of a method. We perform a pilot study to determine the suitability of neural machine translation (NMT) for processing plain-text source code. We find that, on one hand, NMT is too fragile to accurately tokenize code, while on the\u00a0\u2026", "num_citations": "7\n", "authors": ["105"]}
{"title": "Dependency based approach for software analysis web services replacement\n", "abstract": " The concept of Software as a Service has been recently introduced, allowing software to be accessed, composed into workflows, and executed over the Internet. However, there is no guarantee on the execution reliability of such workflows. In case of component service failure, that particular service has to be replaced quickly to ensure the correct execution of the composite service. While most of the existing replacement approaches require the faulty workflow to be completely re-executed, we advocate that dependencies among component services is vitally important for service replacement. In this paper, we present a dependency-based component service recommendation approach that takes into account the dependencies among the component services, such as input/output, pre and post conditions, and correlation among services. Correlation analysis is a new dimension that we introduce to the service\u00a0\u2026", "num_citations": "7\n", "authors": ["105"]}
{"title": "Distributed and collaborative software analysis\n", "abstract": " Throughout the years software engineers have come up with a myriad of specialized tools and techniques that focus on a certain type of software analysis                such as source code analysis, co-change analysis or bug prediction. However, easy and straight forward synergies between these analyses and tools rarely exist because of their stand-alone nature, their platform dependence, their different input and output formats and the variety of data to analyze. As a consequence, distributed and collaborative software analysis                scenarios and in particular interoperability are severely limited. We describe a distributed and collaborative software analysis platform that allows for a seamless interoperability of software analysis tools across platform, geographical and organizational boundaries. We realize software analysis tools as services that can be accessed and composed over the Internet. These\u00a0\u2026", "num_citations": "7\n", "authors": ["105"]}
{"title": "Composing specifications of event based applications\n", "abstract": " The event based architectural style has been recognized as fostering the development of large-scale and complex systems by loosely coupling their components. It is therefore increasingly deployed in various environments such as middleware for mobile computing, message oriented middleware, integration frameworks, communication standards, and commercial toolkits. The development of applications based on this paradigm is, however, performed in such an ad-hoc manner that it is often difficult to reason about their correctness. This is partly due to the lack of suitable specification and verification techniques. In this paper, we review the existing theory of specifying and verifying such applications, argue that it cannot be applied for the development of large-scale and complex systems, and finally propose a novel approach (LECAP) for the construction of correct event based applications. Our approach is\u00a0\u2026", "num_citations": "7\n", "authors": ["105"]}
{"title": "DPS: An Architectural Style for Development of Secure Software\n", "abstract": " Many claim that software systems must be designed for security. This, however, is far from being an easy task, especially for complex systems. We believe that this difficulty can be alleviated by a set of \u2014preferably rigorous\u2014 principles. We propose an architectural style, the Dual Protection Style (DPS), for constructing secure software. This style results from our experience in designing and implementing a distributed, multi-user, medium sized application. We present the applicability and effectiveness of our DPS style on the basis of a case study of a distributed software platform for virtual and mobile team collaboration called Motion. We further elaborate on the description of this architectural style, its formalization and the formal verification of some of its properties.", "num_citations": "7\n", "authors": ["105"]}
{"title": "The architectural style of component programming\n", "abstract": " Component programming is a multiparadigm approach to software construction based on highly generic components. Because component programming is concerned with source-code components, it is assumed by many to be a low-level approach to software development that affects only the development of source code libraries. On the contrary, this paper shows that the concepts of component programming go beyond library and source code issues and define a new conceptual attempt to software development with generic components. We show that component programming is an architectural style that supports the building of classes of software architectures in a specific domain. Component programming can be applied in the early stages of software development when architectural issues are to be determined. All the benefits of using an architectural style, therefore, can also be gained by using component\u00a0\u2026", "num_citations": "7\n", "authors": ["105"]}
{"title": "A guided mashup framework for rapid software analysis service composition\n", "abstract": " Historical data about software projects is stored in repositories such as version control, bug tracking and mailing lists. Analyzing such data is vital to discover unthought-of-yet-interesting insights of a software project. Even though a wide range of software analysis techniques are already available, integration of such analyses is yet to be systematically addressed. Inspired from the recently introduced concept of Software as a Service, our research group investigated the concept of Software Analysis as a Service (SOFAS), a distributed and collaborative software analysis platform. SOFAS allows software analyses to be accessed, composed into workflows, and executed over the Internet. However, traditional service composition is a complex, time consuming and error-prone process, which requires experts in both composition languages and existing standards. In this paper, we propose a mashup platform to address\u00a0\u2026", "num_citations": "6\n", "authors": ["105"]}
{"title": "Automated comprehension tasks in software exploration\n", "abstract": " Finding issues in software usually requires a series of comprehension tasks. After every task, an engineer explores the results and decides whether further tasks are required. Software comprehension therefore is a combination of tasks and a supported exploration of the results typically in an adequate visualization. In this paper, we describe how we simplify the combination of existing automated procedures to sequentially solve common software comprehension tasks. Beyond that we improve the understanding of the outcomes with interactive and explorative visualization concepts in a time efficient workflow. We validate the presented concept with basic comprehension tasks in an extended CocoViz tool implementation.", "num_citations": "6\n", "authors": ["105"]}
{"title": "Semantic web technologies in software engineering\n", "abstract": " Over the years, the software engineering community has developed various tools to support the specification, development, and maintainance of software. Many of these tools use proprietary data formats to store artifacts which hamper interoperability. However, the Semantic Web provides a common framework that allows data to be shared and reused across application, enterprise, and community boundaries. Ontologies are used define the concepts in the domain of discourse and their relationships and as such provide the formal vocabulary applications use to exchange data. Beside the Web, the technologies developed for the Semantic Web have proven to be useful also in other domains, especially when data is exchanged between applications from different parties. Software engineering is one of these domains in which recent research shows that Semantic Web technologies are able to reduce the barriers of proprietary data formats and enable interoperability.   In this tutorial, we present Semantic Web technologies and their application in software engineering. We discuss the current status of ontologies for software entities, bug reports, or change requests, as well as semantic representations for software and its documentation. This way, architecture, design, code, or test models can be shared across application boundaries enabling a seamless integration of engineering results.", "num_citations": "6\n", "authors": ["105"]}
{"title": "A Tool for Intergrating Object Life Cycle and Business Process Modeling.\n", "abstract": " Although the concept of a business object life cycle is becoming increasingly important in some industries, few business process management tools support modeling and analysis of object life cycles. We present a prototype that implements several techniques for seamless integration of object life cycle and business process modeling.", "num_citations": "6\n", "authors": ["105"]}
{"title": "Supporting mobile users and distributed teamwork\n", "abstract": " Recent years have shown a strong trend toward electronic information management in many fields. The use of office applications generated vast amounts of digital information and global multi-site organizations are increasingly faced with the need for advanced Information and Communication Technology (ICT) facilities for information management and distributed working. We address these requirements and problems in the MObile Teamwork Infrastructure for Organizations Networking (MOTION) 1 project and aim at creating a highly flexible, open and scalable ICT architecture for mobile teamwork support. In this paper, we discuss key concepts, design goals and requirements we have identified to build a component-based mobile teamwork ICT architecture for complex, multi-site, multi-process organizations. We give a brief overview of the MOTION architecture and technologies and introduce the evaluation criteria for the MOTION platform.", "num_citations": "6\n", "authors": ["105"]}
{"title": "Facilitating program comprehension via generic components for state machines\n", "abstract": " Various applications use state transition mechanisms as a major building block. As an example, finite state machines (FSMs) and their graphical counterpart-state transition diagram-are heavily used e.g. for the specification of various kinds of protocols such as network protocols (e.g. TCP/IP), protocols for infrared data transmission, etc. Many embedded systems, such as telephone switching systems and television control, are directly based on state machines. Introducing generic components for state machines can raise the source code abstraction level from \"hard coded\" control flow decisions such as \"switch/case\" and \"if\" to a more flexible implementation model of control flow. The paper shows that it is possible to use statecharts and their advanced mechanisms from specification to implementation of reactive systems. By explicitly modeling states and state transitions the source code is described at a higher\u00a0\u2026", "num_citations": "6\n", "authors": ["105"]}
{"title": "A framework for software architecture recovery\n", "abstract": " The recovery of \u201ehigher-level \u201crepresentations from given source code of an existing software system is important for the development of program families. Therefore, we evaluated current reverse engineering technology to which extent and how architectural elements can be identified in a software system. The architecture recovery framework we discuss in this paper is ongoing research work within the ESPRIT project ARES (Architectural Reasoning for Embedded Systems).", "num_citations": "6\n", "authors": ["105"]}
{"title": "Circadian rhythm of testosterone level in plasma. I. Physiologic 24-hour oscillations of the testosterone level in plasma\n", "abstract": " The testosterone level in plasma is measured in 10 males by radioimmunoassay (RIA) at the following times: 07.00 h, 08.00 h, 09.00 h, 10.00 h, 13.00 h, 16.00 h, 19.00 h, 23.00 h and 03.00 h. A circadian rhythm can be noted. Peak levels are reached between 07.00 h and 10.00 h. At 19.00 h testosterone values reach their minimum and rise at night. In the morning between 07.00 h and 10.00 h testosterone levels seem to have a plateau. Between the morning and the evening the values show great differences.", "num_citations": "6\n", "authors": ["105"]}
{"title": "How to\u201d Make a Bridge to the New Town\u201d Using OntoAccess\n", "abstract": " Business-critical legacy applications often rely on relational databases to sustain daily operations. Introducing Semantic Web technology in newly developed systems is often difficult, as these systems need to run in tandem with their predecessors and cooperatively read and update existing data.               A common pattern is to incrementally migrate data from a legacy system to its successor by running the new system in parallel, with a data bridge in between. Existing approaches that can be deployed as a data bridge in theory, restrict Semantic Web-enabled applications to read legacy data in practice, disallowing update operations completely.               This paper explains how our RDB-to-RDF platform OntoAccess can be used to transition legacy systems into Semantic Web-enabled applications. By means of a case study, we exemplify how we successfully made a bridge between one of our own large\u00a0\u2026", "num_citations": "5\n", "authors": ["105"]}
{"title": "SemClip-Overcoming the Semantic Gap Between Desktop Applications.\n", "abstract": " When copying and pasting data between applications using the operating system clipboard, the semantics of the transfered information is usually lost. Using Semantic Web technologies these semantics can be explicitly defined in a machine process-able way and therefore be preserved during the data transfer. In this paper we introduce SemClip, our implementation of a Semantic Clipboard that enables the exchange of semantically enriched data between desktop applications and show how such a clipboard can be used to copy and paste semantic annotations from Web pages to desktop applications.", "num_citations": "5\n", "authors": ["105"]}
{"title": "Using WEESA-to Semantically Annotate Cocoon Web Applications\n", "abstract": " The Semantic Web is based on the idea that Web applications provide semantically annotated Web pages. This metadata is typically added in the semantic annotation process which is currently not part of the Web engineering process. Web engineering, however, proposes methodologies to design, implement and maintain Web applications but lack semantic annotation. In this paper we show how WEESA, a mapping from XML documents to ontologies, can be used in Apache Cocoon Web applications to semantically annotate Web pages. We introduce Cocoon transformer components that use the WEESA mapping definition to automatically generate RDF meta-data from XML documents. We further show how existing Cocoon Web applications can be extended to Semantic Web applications and discuss the experiences gained in an industry case study.", "num_citations": "5\n", "authors": ["105"]}
{"title": "Constructing deadlock free event-based applications: A rely/guarantee approach\n", "abstract": " We have proposed a formal semantics for a programming language that supports the announcement of events. Based on this semantics, it is clear that event-based systems share some substantial properties with parallel systems. In particular, announcing an event results in the parallel execution of subscribers to this event with the remainder of the announcing program. In this paper, we show how usual concurrency concepts such as synchronization and mutual exclusion can be supported in the stepwise development of event-based applications. The approach in this paper is based on Jones\u2019s rely/guarantee method for the development of interfering programs. We also show how deadlock free event-based applications can be developed. Finally, the paper extends St\u00f8len\u2019s technique of handling auxiliary variables to support the development of more complex event-based applications.", "num_citations": "5\n", "authors": ["105"]}
{"title": "Pattern-Driven Reverse Engineering.\n", "abstract": " A fundamental weakness of conventional reverse engineering approaches is the lack of support in identifying program structures and recurring patterns. The integration of human domain knowledge represented via patterns can significantly improve design recovery results. The recognition of a program\u2019s design leads to recurring patterns that, at present, have to be identified in demanding tasks by a human engineer without automated assistance. In this paper we present extensions to our reverse engineering approach based on various design recovery patterns that can be used in further automating such demanding tasks. The design recovery patterns are defined according to several factors we consider to be essential in the reverse engineering process. Based on these influence factors we show the integration of such patterns in our reverse engineering approach and define the notion of pattern-driven reverse engineering. The implications of pattern-driven reverse engineering and the improvements to be achieved for program understanding are discussed for each kind of patterns in turn. in: Seventh International Conference on Software Engineering and Knowledge Engineering (SEKE\u201995) Rockville, Maryland, June, 1995", "num_citations": "5\n", "authors": ["105"]}
{"title": "Tangible software modeling with multi-touch technology\n", "abstract": " This paper describes a design study that explores how multi-touch devices can provide support for developers when carrying out modeling tasks in software development. We investigate how well a multi-touch augmented approach performs compared to a traditional approach and if this new approach can be integrated into existing software engineering processes. For that, we have implemented a fully-functional prototype, which is concerned with agreeing on a good object-oriented design through the course of a Class Responsibility Collaboration (CRC) modeling session. We describe how multi-touch technology helps with integrating CRC cards with larger design methodologies, without loosing their unique physical interaction aspect. We observed high-potential in augmenting such informal sessions in software engineering with novel user interfaces, such as those provided by multi-touch devices.", "num_citations": "4\n", "authors": ["105"]}
{"title": "Multi-touch collaboration for software exploration\n", "abstract": " Software systems have grown so complex and their design is so intricate that no individual can grasp the whole picture. Touch screen technology combined with 3D software visualization offers a promising way for the software engineers involved in a project to share knowledge about a software system in an intuitive way. In this paper we present first results on how such emerging technologies can be combined to support software exploration tasks, such as identifying high-impact changes or revealing problematic parts of the design. As demonstrated with a scenario, this turns the collaborative environment into a vehicle usable during software reviews.", "num_citations": "4\n", "authors": ["105"]}
{"title": "Peer-to-Peer-Architekturen\n", "abstract": " Dieses Kapitel behandelt anwendungsspezifische und architekturelle Aspekte von Peer-to-Peer-Systemen. Ziel ist es, das Peer-to-Peer-Paradigma in seinen unterschiedlichen Auspr\u00e4gungen anhand weit verbreiteter bzw. technologisch interessanter Systeme darzustellen, daraus architekturelle Muster abzuleiten und dem Leser/der Leserin ein umfassendes Verst\u00e4ndnis dieses Ansatzes zu vermitteln. Mittels dieses Wissens soll es erm\u00f6glicht werden, abzusch\u00e4tzen, ob der Peer-to-Peer-Ansatz f\u00fcr ein konkretes Anwendungsproblem verwendet werden kann.", "num_citations": "4\n", "authors": ["105"]}
{"title": "Mobile and Distributed Collaboration in Virtual Communities\n", "abstract": " Organizations are increasingly forced to manage and coordinate their product and service development processes, to make their products and services available as quickly as possible, and to involve employees, customers, suppliers, and partners in different stages of their businesses. These processes have to consider that their participants are more and more on the move while they are working and that their expertise can be shared across locations and different mobile devices. This paper defines a framework for mobile distributed collaboration, defines a set of requirements for virtual communities, and discusses a mobile teamwork support software architecture that has been developed in an ongoing EU-project. The framework together with the architecture should enable to enhance current collaboration approaches to include the dimension of mobile participants and virtual communities.", "num_citations": "4\n", "authors": ["105"]}
{"title": "Evolution of an organizational Web site: migrating to XML/XSL\n", "abstract": " With the advent of the World Wide Web, many organizational Web sites were initially created by a group of individuals who were interested in this new technology. These people were (and still are) often referred to as Webmasters and designed,the pages according to their taste and picked the information that they found important. Many sites were built without a systematic approach or consideration for future requirements. As the World Wide Web increased in importance, many of these Web sites grew, in an ad-hoc fashion and they became increasingly difficult to manage. Today, Web site design and management are further complicated by new emerging requirements such as multi-lingual and mobile device support. In this paper, we first discuss the evolution of an organizational Web site, give a brief overview of the site's history and discuss the problems the organization faced. We then present some of our\u00a0\u2026", "num_citations": "4\n", "authors": ["105"]}
{"title": "Circadiane Rhythmik des Plasmatestosteronspiegels: I. Physiologische Schwankungen des Plasmatestosteronspiegels innerhalb von 24 h\n", "abstract": " Die Wissenschaft, die sich mit tagesperiodischen, physiologischen Eigenschwingungen des menschlichen Organismus befafit, ist noch jung. Ihr wohl bedeutendster Vertreter, F. Halberg, pragte 1963 fur die endogene Tagesrhythmik den Begriff,, circadian rhythm\". Weitere Bezeichnungen sind,, diurnal variation\" und,, rhytme nycthemeral\". In die deutschsprachige Literatur ist diese Bezeichnung als,, circadiane Rhythmik\" ubernommen worden. kungen des Testosteronspiegels beim Mann noch verneinen, gilt dies heute als gesichert (Burger et al.-1969; Crafts et al.-1968; Dray et al.-1965; Faiman u. Winter-1971; Kobayashi et al.-1966; Nieschlag u. Ismail-1970; Okamoto et al.-1971; Resko u. Eik-Nes-1966; Southren et al.-1965). Die bisher vorliegenden Bestimmungen des Plasmatestosteronspiegels wurden gewohnlich im Abstand von 4 h durchgef~ rt. Das Maximum lag zwischen 07.00 und 10.00 h, wahrend die\u00a0\u2026", "num_citations": "4\n", "authors": ["105"]}
{"title": "Architectural Description\n", "abstract": " A port identifies a point of interaction between the component and its environment, and can represent an interface as simple as a single procedure signature. Alternatively, a port can define a more complex interface, such as a collection of procedure calls that must be invoked in certain specified orders, or an event multicast interface.", "num_citations": "4\n", "authors": ["105"]}
{"title": "Boosting API recommendation with implicit feedback\n", "abstract": " Developers often need to use appropriate APIs to program efciently, but it is usually a difcult task to identify the exact one they need from a vast list of candidates. To ease the burden, a multitude of API recommendation approaches have been proposed. However, most of the currently available API recommenders do not support the effective integration of user feedback into the recommendation loop. In this paper, we propose a framework, BRAID (Boosting RecommendAtion with Implicit FeeDback), which leverages learning-to-rank and active learning techniques to boost recommendation performance. By exploiting user feedback information, we train a learning-to-rank model to re-rank the recommendation results. In addition, we speed up the feedback learning process with active learning. Existing query-based API recommendation approaches can be plugged into BRAID. We select three state-of-the-art API\u00a0\u2026", "num_citations": "3\n", "authors": ["105"]}
{"title": "A middleware platform for the dynamic evolution of distributed component-based systems\n", "abstract": " In this paper, we present a middleware platform that supports the dynamic evolution of distributed component-based systems. It leverages the concept of ontologies to model the context of a system and an intrinsic mechanism is integrated to causally connect the dynamic architecture specification to the running system implementation. The ontological modeling covers both the environmental and the architectural knowledge using semantic data modeling. The intrinsic mechanism can automatically derive a run-time polymorphic architecture object to coordinate the involved components. The ontology based contextual representation and the polymorphic architecture-driven dynamic evolution are the two underpinnings of the platform. A scenario application\u2014including the two primitive evolution actions\u2014with the performance analysis is discussed to illustrate the feasibility.", "num_citations": "3\n", "authors": ["105"]}
{"title": "Of changes and their history: Some ideas for future IDEs\n", "abstract": " Changes are the heartbeat of a software system. Software has to change to reflect the adapting requirements of business, processes, and technology; otherwise it becomes progressively less useful. Because of that, software typically grows and becomes more complex inducing more time and effort for evolving it. Software archives provide rich sources of information about systems and their history of changes. From that we can learn and benefit in steering the evolution of a software system both technically and organizationally. In our research, we have investigated change histories from multiple perspectives: change couplings, change types, developer networks, component dependencies, evolution metrics, etc. Combined with effective visualizations, change histories have shown to be extremely useful for guiding software development. But that information can also be used to reflect how a future IDE might better\u00a0\u2026", "num_citations": "3\n", "authors": ["105"]}
{"title": "An Architecture for a Semantic Portal.\n", "abstract": " Current Web applications provide their information and functionalities to human users only. To make Web applications also accessible for machines, the Semantic Web proposes an extension of the current Web, that describes the semantics of the content and the services explicitly with machine-processable meta-data. In this paper we introduce an architecture of a Semantic Portal that provides a unique front-end to the information and functionalities of individual Semantic Web applications. To realize the portal we use WEESA to semantically annotate Web applications and provide the annotations in a knowledge base (KB) for download and querying. Based on that, the Semantic Harvester collects the KBs from individual Semantic Web applications to build the global KB of the Semantic Portal. Finally, we use Semantic Web services to make the portal a unique interface to the services of the Web applications.", "num_citations": "3\n", "authors": ["105"]}
{"title": "DMC-distributed and mobile collaboration workshop report\n", "abstract": " The increased need for people and organizations to continue collaborating whilst changing physical location and crossing organizational boundaries has resulted in a wave of new supporting technologies, and generated interest in tackling some of the difficult research issues arsing in such a context. The latter was the subject of the Third IEEE International Workshop on Distributed and Mobile Collaboration (DMC) at WETICE 2005, summirized here. The DMC Workshop included 10 full papers on topics grouped into four areas: Web-based collaboration, Formal description and consistency checking of collaborative processes, Models and architectures for collaborative services, and P2P collaborative infrastructures. The discussions at the workshop outlined several important issues regarding the field of distributed collaborative applications.", "num_citations": "3\n", "authors": ["105"]}
{"title": "TWSAPI: A generic teamwork services application programming interface\n", "abstract": " One of the problems faced by large, global organizations and enterprises is to effectively enable their employees to collaborate across locations. People need collaborative work support while they are on the move and have to share business documents and know-how. Although much work has been done in the area of computer supported collaborative work (CSCW) to date, supporting mobility is only recently receiving attention. Hence, most of the existing approaches do not deal with emerging mobile teamwork requirements such as locating business documents and expertise through distributed searches, advanced subscription and notification, community building, and mobile information sharing and access. Furthermore, existing applications and approaches are usually difficult to customize to business-specific processes and requirements. The Mobile Teamwork Infrastructure for Organizations Networking\u00a0\u2026", "num_citations": "3\n", "authors": ["105"]}
{"title": "Application of information visualization to the analysis of software release history\n", "abstract": " We present our experiences in applying information visualization techniques to the study of the evolution of a large telecommunication software system. We used the third dimension to portray the temporal evolution of the system and color to display software attributes. The visualization was surprisingly successful in uncovering interesting and useful patterns in the system\u2019s evolution. To do the visualization, we built a tool that combines off-theshelf components: a database for storing software release data, VRML for displaying and navigating three-dimensional data, and a web browser for the user-interface. The tool is published on the web. The tool is capable of providing effective views of data that are always kept by software development organizations but are often ignored. Information visualization makes it possible to exploit such historical data about past projects to help in the planning stages of future\u00a0\u2026", "num_citations": "3\n", "authors": ["105"]}
{"title": "Circadiane Rhythmik des Plasmatestosteronspiegels: III. Bestimmung des Tagesmaximums von Testosteron im Serum\n", "abstract": " In unserer Untersuchung uber die physiologischen Schwankungen des Plasmatestosteronspiegels innerhalb von 24 h fanden sich die hochsten Werte zwischen 07.00 h und 10.00 h. Dabei lag der Testosteronspiegel auf einem Plateau. Da wir dieses Ergebnis an einem relativ kleinen Patientengut von 10 Patienten gewonnen haben, wollen wir in dieser vorliegenden Arbeit den Serumtestosteronspiegel in der Zeit zwischen 07.00 h und 10.00 h an 50 jungen Mannern untersuchen.", "num_citations": "3\n", "authors": ["105"]}
{"title": "The effect of varicocele on male fertility with particular consideration of progressive motility (author's transl)\n", "abstract": " Two-hundred patients with varicocele were examined for fertility, which was found to have diminished in 75% of the cases because of a decreased sperm count (less than 40 million/ml); 40% of these, the largest group (categorized only with regard to oligospermia), had a sperm count of 21--40 million/ml. The most remarkable finding was restrained fertility in 90% of the cases because of decreased progressive motility (speed of forward progression). Here, the largest group (nearly 50%) was in the category of 21--30%. Decreased progressive motility was mostly combined with a diminished sperm count to an oligoasthenospermia. In 20% of the cases, however, fertility was restrained only by decreased progressive motility in the sense of an asthenospermia. The first effect, due to varicocele, is seen in decreased progressive motility. However, because spermatozoa acquire their progressive motility by means of maturation in the epididymis, the varicocele causes the first damage to the epididymis.", "num_citations": "3\n", "authors": ["105"]}
{"title": "UpLink: a Linked Data editor for RDB-to-RDF data\n", "abstract": " Linked Data builds a machine-processable Web of Data based on a large and growing number of RDF datasets and typed links among them. For the human user, Web-based interfaces were developed to enable browsing and editing Linked Data that is stored as native RDF. However, the majority of data on the current Web is stored in Relational Databases (RDB). This is a challenge for Linked Data browsers and especially for Linked Data editors. In this paper, we present UpLink which is to the best of our knowledge the first Linked Data editor for RDB-to-RDF data, ie, RDF data that is mapped on demand from a RDB. We further present usage scenarios to demonstrate that UpLink supports the basic CRUD operations for editing Linked Data.", "num_citations": "2\n", "authors": ["105"]}
{"title": "Personal Knowledge Mapping with semantic web technologies\n", "abstract": " Semantic Web technologies promise great benefits for Personal Knowledge Management (PKM) and Knowledge Management (KM) in general when data needs to be exchanged or integrated. However, the Semantic Web also introduces new issues rooted in its distributed nature as multiple ontologies exist to encode data in the Personal Information Management (PIM) domain. This poses problems for applications processing this data as they would need to support all current and future PIM ontologies. In this paper, we introduce an approach that decouples applications from the data representation by providing a mapping service which translates Semantic Web data between different vocabularies. Our approach consists of the RDF Data Transformation Language (RDTL) to define mappings between different but related ontologies and the prototype implementation RDFTransformer to apply mappings. This allows the definition of mappings that are more complex than simple one-to-one matches.", "num_citations": "2\n", "authors": ["105"]}
{"title": "Improving abstract syntax tree based source code change detection\n", "abstract": " Changes are a crucial part of the life-cycle of modern software systems. Common versioning systems such as CVS store version histories of source code. Usually, they are not capable of tracking changes on a more sophisticated level. They provide lexical but not syntactical change analysis.The existing Eclipse-plug-in ChangeDistiller bridges this gap by providing a sophisticated analysis of structural source code changes. It uses an abstract syntax tree (AST) representation of subsequent revisions of source code files and compares the trees by using a change detection algorithm for hierarchically structured information. The outcome is an edit script describing the operations that are necessary to transform the original version of the tree into the modified one. We aim at improving the sub-algorithm responsible for matching trees. It yields insufficiencies in terms of matching leaves in general, it often produces sub\u00a0\u2026", "num_citations": "2\n", "authors": ["105"]}
{"title": "Special issue on ubiquitous mobile information and collaboration systems (UMICS)\n", "abstract": " Over the last few years, most business processes have changed on various dimensions (eg, flexibility, interconnectivity, coordination style, autonomy) due to market conditions, organizational models, and usage scenarios of information systems. Frequently, information is relocated within a geographically distributed system according to rules that are only seldom defined as a well codified business process. This creates need for a software infrastructure that enables ubiquitous mobile information and collaboration systems (UMICS). The anywhere/any time/any means paradigm is becoming the major challenge in conceiving, designing, and releasing the next-generation information systems. New technologies, such as wireless local area networks (WLAN) and third-generation (3G) mobile phones, are offering the infrastructure to conceive information systems as ubiquitous information systems, that is, systems that are\u00a0\u2026", "num_citations": "2\n", "authors": ["105"]}
{"title": "Observing the evolution of modification complexity of logically coupled modules\n", "abstract": " When investigating bug report and modification report data, one can identify so-called logical couplings between modules that have many commonalities in their change history. This means that with a certain (usually high) probability, logically coupled modules again will be changed together the next time a certain problem or bug is reported. Our analysis of common change behavior considers the reasons for this logical coupling and, therefore, we have investigated the following questions within the Mozilla case study: is there an increasing complexity in the logically coupled modules? what is the entropy in each of the modules and among modules over time? what is the complexity of modifications for the logically coupled modules over time? First results have shown that the complexity of modifications does not automatically increase, and that the change entropy of modules exhibits a slight decreasing behavior\u00a0\u2026", "num_citations": "2\n", "authors": ["105"]}
{"title": "Towards a software architecture for distributed and mobile collaborative systems\n", "abstract": " Current trends in collaborative business emphasize the importance of business process support within and between organizations. These process participants are increasingly distributed and mobile. It remains a challenge to utilize software as to share and exchange ideas and work on collaborative activities across locations and different mobile devices, while still business process aware. In this paper we develop a five-layer software architecture for distributed and mobile collaborative systems, which provides mobility of context to its group members. This architecture defines a foundation for the flexible integration of collaborative systems (such as workflow management, groupware or business process modeling) with teamwork services that support distributed and mobile collaboration.", "num_citations": "2\n", "authors": ["105"]}
{"title": "Circadiane\u2010Rhythmik des Plasmatestosteronspiegels: II. Der Testosteronspiegel in der ersten und zweiten Tagesh\u00e4lfte\n", "abstract": " Am Vormittag fuhrten wir zwei Untersuchungen durch, und zwar um 07.00 h und um 10.00 h. Wir wahlten diese Zeitpunkte, da sie den Anfang und das Ende des Plateaus markieren, das in der Untersuchung uber die Schwankungen des Plasmatestosteronspiegels innerhalb von 24 h ermittelt wurde.", "num_citations": "2\n", "authors": ["105"]}
{"title": "Circadian rhythm of plasm testosterone levels. II. Testosterone levels during the 1st and 2d half-day\n", "abstract": " Testosterone in plasma is measured in 50 young males in the morning and in the evening by radioimmunoassay. Peaks are found in the morning. At 07, 00 h and 10, 00 h the values lie on a plateau: 91, 77% at 07.00 h and 90, 59% at 10.00 h. The difference is not significant. Significant differences however can be noted in comparison between values in the first and second half-day. The difference between the 07.00 h value and the 16.00 h value amounts to 17, 08%; between the 07.00 h value and the 19.00 h value, to 22, 6%.", "num_citations": "2\n", "authors": ["105"]}
{"title": "DRONE: a tool to detect and repair directive defects in Java APIs documentation\n", "abstract": " Application programming interfaces (APIs) documentation is the official reference of the APIs. Defects in API documentation pose serious hurdles to their comprehension and usage. In this paper, we present DRONE, a tool that can automatically detect the directive defects in APIs documents and recommend repair solutions to fix them. Particularly, DRONE focuses on four defect types related to parameter usage constraints. To achieve this, DRONE leverages techniques from static program analysis, natural language processing and logic reasoning. The implementation is based on the Eclipse-plugin architecture, which provides an integrated user interface. Extensive experiments demonstrate the efficacy of the tool.", "num_citations": "1\n", "authors": ["105"]}
{"title": "Effect size analysis\n", "abstract": " When we seek insight in collected data we are most often forced to limit our measurements to a portion of all individuals that can be hypothetically considered for observation. Nevertheless, as researchers, we want to draw more general conclusions that are valid beyond the restricted subset we are currently analyzing. Statistical significance testing is a fundamental pattern of data analysis that helps us to infer conclusions from a subset about the entire set of possible individuals. However, the outcome of such tests depends on several factors. Software engineering experiments often address similar research questions but vary with respect to those factors, for example, they operate on different sizes or measurements. Hence, the use of statistical significance alone to interpret findings across studies is insufficient. This paper describes how significance testing can be extended by an analysis of the magnitude, i.e., effect\u00a0\u2026", "num_citations": "1\n", "authors": ["105"]}
{"title": "'Semantic Web 2.0'-write-enabling the Web of Data\n", "abstract": " The Semantic Web today is mainly a read-only Web of Data. Many of the data sets that contribute to the Semantic Web are not stored as native RDF, but generated on demand via wrappers. Despite the fact that user contribution is the key success factor in the Web 2.0, current wrapper approaches and standardization efforts still focus on read-only data access. In this paper, we argue that the Semantic Web should learn from the evolution of the Web 2.0 and consider write-enabled semantic data wrappers.", "num_citations": "1\n", "authors": ["105"]}
{"title": "Multi-touch for software exploration\n", "abstract": " The design of software systems is often so intricate that no individual can grasp the whole picture. Multi-Touch screen technology combined with 3D software visualization offers a way for software engineers to interact with a software system in an intuitive way. In this paper we present first results on how such emerging technologies can be used to explore software systems.", "num_citations": "1\n", "authors": ["105"]}
{"title": "A Systematic Approach to the Development of Event Based Applications (Part I)\n", "abstract": " The event based architectural style has been recognized as fostering the development of large-scale and complex systems by loosely coupling their components. It is therefore increasingly deployed in various environments such as middleware for mobile computing, message oriented middleware, integration frameworks, communication standards, and commercial toolkits. The development of applications based on this paradigm is, however, performed in such an ad-hoc manner that it is often difficult to reason about their correctness. This is partly due to the lack of suitable specification and verification techniques. In this paper, we propose a novel framework (LECAP) for the development of event-based applications. Our approach is superior to the existing approaches in many respects: 1) it supports a while-parallel language, 3) the reasoning allows a dynamic (instead of static) binding of programs to events, 5) our approach is oriented towards stepwise development of systems. The paper also presents an example for illustrating the approach.Status: student and regular paper.", "num_citations": "1\n", "authors": ["105"]}
{"title": "Ubiquitous and Mobile Information and Collaboration Systems\n", "abstract": " La presente simulazione \u00e8 stata realizzata sulla base delle regole riportate nel DM 598/2018 e allegata Tabella A. Cineca non si assume alcuna responsabilit\u00e0 in merito all\u2019uso che il diretto interessato o terzi faranno della simulazione. Si specifica inoltre che la simulazione contiene calcoli effettuati con dati e algoritmi di pubblico dominio e deve quindi essere considerata come un mero ausilio al calcolo svolgibile manualmente o con strumenti equivalenti. Informazioni sui dati: vengono considerati tutti i prodotti in stato definitivo. Per i prodotti indicizzati wos/scopus, l\u2019anno di riferimento e la tipologia sono quelli riportati in banca-dati.", "num_citations": "1\n", "authors": ["105"]}
{"title": "Reverse Engineering\n", "abstract": " Mit der zunehmenden Alterung von im praktischen Einsatz befindlichen Systemen ist durch laufende Wartung und Adaption auch deren Gr\u00f6\u00dfe und Komplexit\u00e4t im Laufe der Zeit gestiegen. Gro\u00dfe, gewachsene Applikationen k\u00f6nnen heute nicht mehr einfach durch Neuentwicklung eines \u00e4quivalenten Systems ersetzt werden, da ihre genauen Anforderungen, ihre Funktionsweise u. dgl. \u2014 welche \u00fcber Jahre hinweg gewachsen sind und angepa\u00dft wurden \u2014 vielfach gar nicht mehr explizit bekannt oder identifizierbar sind. Eine vollst\u00e4ndige Neuentwicklung w\u00fcrde f\u00fcr das betroffene Unternehmen daher ein unabsch\u00e4tzbares Risiko darstellen, so da\u00df alternative Methoden zur Erh\u00f6hung der Lebensdauer von gewachsenen Applikationen zunehmend an Bedeutung gewinnen.", "num_citations": "1\n", "authors": ["105"]}
{"title": "Circadian rhythm of plasma testosterone levels. III. Determination of the daily serum testosterone maximum\n", "abstract": " Testosterone levels in plasma in 50 young males are found on a plateau between 07, 00 h and 10, 00 h. As this plateau represents the highest level throughout the day, it is necessary to take blood sample only once during this period. Therefore a statement about endocrine testicle function can be given by only one determination of testosterone between 07, 00 h and 10, 00 h. This faciliates endocrine examination in ambulant patients.", "num_citations": "1\n", "authors": ["105"]}
{"title": "Object-oriented concepts in Smalltalk, C++, Objective-C, Eiffel and Modula-3\n", "abstract": " This paper introduces the reader to object-oriented concepts and surveys several object-oriented programming languages. The object-oriented paradigm has gained wide-spread acceptance in the last decade. Numerous object-oriented languages have been developed and object-oriented features have been added to conventional programming languages. We define a consistent terminology and explain important concepts of objectorientation. We then classify prominent languages (Smalltalk, C++, Objective-C, Eiffel, Modula-3) according to the terminology and concepts.", "num_citations": "1\n", "authors": ["105"]}