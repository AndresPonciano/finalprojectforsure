{"title": "Signature-free asynchronous binary Byzantine consensus with t<n/3, O(n^2) messages, and O(1) expected time\n", "abstract": " This article is on broadcast and agreement in asynchronous message-passing systems made up of n processes, and where up to t processes may have a Byzantine Behavior. Its first contribution is a powerful, yet simple, all-to-all broadcast communication abstraction suited to binary values. This abstraction, which copes with up to t < n/3 Byzantine processes, allows each process to broadcast a binary value, and obtain a set of values such that (1) no value broadcast only by Byzantine processes can belong to the set of a correct process, and (2) if the set obtained by a correct process contains a single value v, then the set obtained by any correct process contains v. The second contribution of this article is a new round-based asynchronous consensus algorithm that copes with up to t < n/3 Byzantine processes. This algorithm is based on the previous binary broadcast abstraction and a weak common coin. In addition to\u00a0\u2026", "num_citations": "64\n", "authors": ["536"]}
{"title": "LSEQ: an adaptive structure for sequences in distributed collaborative editing\n", "abstract": " Distributed collaborative editing systems allow users to work distributed in time, space and across organizations. Trending distributed collaborative editors such as Google Docs, Etherpad or Git have grown in popularity over the years. A new kind of distributed editors based on a family of distributed data structure replicated on several sites called Conflict-free Replicated Data Type (CRDT for short) appeared recently. This paper considers a CRDT that represents a distributed sequence of basic elements that can be lines, words or characters (sequence CRDT). The possible operations on this sequence are the insertion and the deletion of elements. Compared to the state of the art, this approach is more decentralized and better scales in terms of the number of participants. However, its space complexity is linear with respect to the total number of inserts and the insertion points in the document. This makes the overall\u00a0\u2026", "num_citations": "55\n", "authors": ["536"]}
{"title": "Causal consistency: beyond memory\n", "abstract": " In distributed systems where strong consistency is costly when not impossible, causal consistency provides a valuable abstraction to represent program executions as partial orders. In addition to the sequential program order of each computing entity, causal order also contains the semantic links between the events that affect the shared objects--messages emission and reception in a communication channel, reads and writes on a shared register. Usual approaches based on semantic links are very difficult to adapt to other data types such as queues or counters because they require a specific analysis of causal dependencies for each data type. This paper presents a new approach to define causal consistency for any abstract data type based on sequential specifications. It explores, formalizes and studies the differences between three variations of causal consistency and highlights them in the light of PRAM\u00a0\u2026", "num_citations": "41\n", "authors": ["536"]}
{"title": "Crate: Writing stories together with our browsers\n", "abstract": " Real-time collaborative editors are common tools for distributing work across space, time, and organizations. Unfortunately, mainstream editors such as Google Docs rely on central servers and raise privacy and scalability issues. CRATE is a real-time decentralized collaborative editor that runs directly in web browsers thanks to WebRTC. Compared to state-of-the-art, CRATE is the first real-time editor that only requires browsers in order to support collaborative editing and to transparently handle from small to large groups of users. Consequently, CRATE can also be used in massive online lectures, TV shows or large conferences to allow users to share their notes. CRATE's properties rely on two scientific results:(i) a replicated sequence structure with sub-linear upper bound on space complexity; this prevents the editor from running costly distributed garbage collectors,(ii) an adaptive peer sampling protocol; this\u00a0\u2026", "num_citations": "27\n", "authors": ["536"]}
{"title": "Signature-free asynchronous Byzantine systems: from multivalued to binary consensus with O(n^2) messages, and constant time\n", "abstract": " This paper presents a new algorithm that reduces multivalued consensus to binary consensus in an asynchronous message-passing system made up of n processes where up to t may commit Byzantine failures. This algorithm has the following noteworthy properties: it assumes  (and is consequently optimal from a resilience point of view), uses  messages, has a constant time complexity, and uses neither signatures nor additional computational power (such as random numbers, failure detectors, additional scheduling assumption, or additional synchrony assumption). The design of this reduction algorithm relies on two new all-to-all communication abstractions. The first one allows the non-faulty processes to reduce the number of proposed values to c, where c is a small constant. The second communication abstraction allows each non-faulty process to compute a set of (proposed) values satisfying the\u00a0\u2026", "num_citations": "26\n", "authors": ["536"]}
{"title": "Efficiently summarizing data streams over sliding windows\n", "abstract": " Estimating the frequency of any piece of information in large-scale distributed data streams became of utmost importance in the last decade (e.g., in the context of network monitoring, big data, etc.). If some elegant solutions have been proposed recently, their approximation is computed from the inception of the stream. In a runtime distributed context, one would prefer to gather information only about the recent past. This may be led by the need to save resources or by the fact that recent information is more relevant. In this paper, we consider the sliding window model and propose two different (on-line) algorithms that approximate the items frequency in the active window. More precisely, we determine a (\u03b5, \u03b4)-additive-approximation meaning that the error is greater than \u03b5 only with probability \u03b4. These solutions use a very small amount of memory with respect to the size N of the window and the number n of distinct\u00a0\u2026", "num_citations": "26\n", "authors": ["536"]}
{"title": "Evaluating the Condition-Based Approach to Solve Consensus.\n", "abstract": " Several approaches have been proposed to circumvent the impossibility to solve consensus in asynchronous distributed systems prone to process crash failures. Among them, randomization, unreliable failure detectors, and leader oracles have been particularly investigated. Recently a new approach (called \u201ccondition-based\u201d) has been proposed. Let an input vector be a vector whose i-th entry contains the value proposed by process pi. The conditionbased approach consists in stating conditions on input vectors that make consensus solvable despite up to f process crashes. Several conditions have been proposed.(As an example, one of them requires that the greatest value in an input vector appears more than f times.) This paper presents an evaluation of the condition-based approach to solve consensus. It shows that this approach is particularly attractive and very efficient when the probability of process crashes is low (a common fact in practice). In these cases, the probability for the condition-based protocol to terminate is practically equal to 1.", "num_citations": "26\n", "authors": ["536"]}
{"title": "Update consistency for wait-free concurrent objects\n", "abstract": " In large scale systems such as the Internet, replicating data is an essential feature in order to provide availability and fault-tolerance. Attila and Welch proved that using strong consistency criteria such as atomicity is costly as each operation may need an execution time linear with the latency of the communication network. Weaker consistency criteria like causal consistency and PRAM consistency do not ensure convergence. The different replicas are not guaranteed to converge towards a unique state. Eventual consistency guarantees that all replicas eventually converge when the participants stop updating. However, it fails to fully specify the semantics of the operations on shared objects and requires additional non-intuitive and error-prone distributed specification techniques. This paper introduces and formalizes a new consistency criterion, called update consistency, that requires the state of a replicated object to\u00a0\u2026", "num_citations": "21\n", "authors": ["536"]}
{"title": "From<> W to Omega: a Simple Bounded Quiescent Reliable broadcast-based Transformation\n", "abstract": " Failure detectors in the class\u22c4 W ensure that every crashed process is eventually suspected by a correct process, and eventually there is a correct process that is never suspected. Failure detectors in the class \u03a9 ensure that eventually all the processes trust the same correct process. This paper presents a very simple and efficient algorithm that transforms any failure detector of the class\u22c4 W into a failure detector of the class \u03a9. The simplicity of the transformation is due to its modular design\u2014it is based on an underlying reliable broadcast facility. It is quiescent and requires each message to carry only one process identity, in addition to the control information appended to a message by the reliable broadcast mechanism (namely, a sequence number and the identity of its sender).", "num_citations": "21\n", "authors": ["536"]}
{"title": "An adaptive peer-sampling protocol for building networks of browsers\n", "abstract": " Peer-sampling protocols constitute a fundamental mechanism for a number of large-scale distributed applications. The recent introduction of WebRTC facilitated the deployment of decentralized applications over a network of browsers. However, deploying existing peer-sampling protocols on top of WebRTC raises issues about their lack of adaptiveness to sudden bursts of popularity over a network that does not manage addressing or routing. Spray is a novel random peer-sampling protocol that dynamically, quickly, and efficiently self-adapts to the network size. Our experiments show the flexibility of Spray and highlight its efficiency improvements at the cost of small overhead. We embedded Spray in a real-time decentralized editor running in browsers and ran experiments involving up to 600 communicating Web browsers. The results demonstrate that Spray significantly reduces the network traffic according\u00a0\u2026", "num_citations": "18\n", "authors": ["536"]}
{"title": "Low-cost secret-sharing in sensor networks\n", "abstract": " Radio waves are the medium used by sensors to communicate and exchange data. The unconstrained accessibility to any information carried over this medium is a security issue in many sensor-based applications. Ensuring protected wireless communications is a problem that has received a lot of attention in the context of ad hoc networks. However, due to hardware constraints of sensors along with multi-hop communication, most of these solutions turn out to be useless for sensor networks. This paper provides basic building blocks to establish secure communication by exchanging secret keys between neighbor nodes without any use of cryptography methods allowing an gain in efficiency. This paper also proposes a second algorithm that extends the secret key establishment to nodes that are not direct neighbors. Among the interesting features of the proposed algorithms we can note a low overhead and the\u00a0\u2026", "num_citations": "18\n", "authors": ["536"]}
{"title": "Efficient condition-based consensus\n", "abstract": " Efficient Condition-Based Consensus Page 1 Efficient Condition-Based Consensus in Asynchronous Distributed Systems Achour Mostefaoui, Sergio Rajsbaum Michel Raynal and Matthieu Roy mroy@irisa.fr Efficient Condition-Based Consensus \u2013 p.1/25 Page 2 Summary Computation model and the Consensus Problem The Condition-Based approach Definitions, A simple protocol. Efficient protocol for consensus A hierarchy of conditions, A tailored read/write primitive, A generic formula for defining conditions. Efficient Condition-Based Consensus \u2013 p.2/25 Page 3 Computation Model An a priori known set of processes \u00a1\u00a3 \u00a2\u00a5 \u00a4 \u00a1\u00a3 \u00a6\u00a5 \u00a4 \u00a7 \u00a7 \u00a7 \u00a4 \u00a1\u00a9 , Communication via Shared Memory (supposed to be reliable) Asynchronous Model of failures: Fail-stop. At most processes may crash, A correct process is a process that does not crash. Efficient Condition-Based Consensus \u2013 p.3/25 Page 4 The Consensus Problem \u2026", "num_citations": "17\n", "authors": ["536"]}
{"title": "A O(log2(n)) fault-tolerant distributed mutual exclusion algorithm based on open-cube structure\n", "abstract": " A new distributed mutual exclusion algorithm, using a token and based upon an original rooted tree structure, is presented. The rooted tree introduced, named \"open-cube\", has noteworthy stability and locality properties, allowing the proposed algorithm to achieve good performances and high tolerance to node failures: the worst case message complexity per request is, in the absence of node failures, log/sub 2/n+1 where n is the number of nodes, whereas O(log/sub 2/n) extra messages in the average are necessary to tolerate each node failure. This algorithm is a particular instance of a general scheme for token and tree-based distributed mutual exclusion algorithms, previously presented in part by the authors; consequently, its safety and liveness properties are inherited from the general one.< >", "num_citations": "15\n", "authors": ["536"]}
{"title": "Byzantine consensus with few synchronous links\n", "abstract": " This paper tackles the consensus problem in asynchronous systems prone to byzantine failures. One way to circumvent the FLP impossibility result consists in adding synchrony assumptions (deterministic solution). In the context of crash failures (at most t processes may crash), the weakest partially synchronous system model assumes at least one correct process with outgoing links that eventually permit a bounded transmission delay with at least t neighbors (the set of neighbors may change over time).             Aguilera et al. provided the main result for systems where at most t processes may exhibit a byzantine behavior. They assume a correct process with all its outgoing and incoming links eventually timely. This paper considers a system model with at least one correct process connected with x privileged neighbors with eventually timely outgoing and incoming links. In this system model, a byzantine\u00a0\u2026", "num_citations": "14\n", "authors": ["536"]}
{"title": "P-mute-based consensus for asynchronous byzantine systems\n", "abstract": " This paper presents a consensus protocol for asynchronous distributed systems made up of n processes, where up to f<n/4 processes can behave arbitrarily (Byzantine processes). The protocol assumes that the underlying system is equipped with an unreliable failure detector of the class . The failure detectors of the class  ensure that (1) all mute processes are detected (a mute process is a process that, after some time, stops sending protocol messages), and (2) after some unknown but finite time, no correct process is suspected (mute processes are a subset of the Byzantine processes). The proposed protocol enjoys the following properties. It is based on the round coordinator paradigm and its design principle is particularly simple. Its message complexity is O(n2) per round. In addition to a round number, the message size is O(1), except for one message per round (sent by the round coordinator\u00a0\u2026", "num_citations": "14\n", "authors": ["536"]}
{"title": "Shrinking timestamp sizes of event ordering protocols\n", "abstract": " Almost all published work on causal ordering mechanisms assumes theoretically unbounded counters for timestamps, thus ignoring the real world problem that arises if one is actually interested in an operable implementation, since unbounded counters simply cannot be realized. An argument for its justification often encountered states, that the counter size can be chosen such that counters practically do not overflow or wrap around. For example, using matrix timestamps in a distributed computation involving not more than 50 processes and 32 bits per integer, results in a timestamp size of almost 10 K byte. We present a solution, called Factorized Timestamp Approach (FTA) that substantially reduces the amount of piggybacked control information. It is based on introducing the notion of phases in which much smaller timestamps are used. Simulation results given in the paper show the suitability of this approach.", "num_citations": "13\n", "authors": ["536"]}
{"title": "Synchronous byzantine agreement with nearly a cubic number of communication bits\n", "abstract": " This paper studies the problem of Byzantine consensus in a synchronous message-passing system of n processes. The first deterministic algorithm, and also the simplest in its principles, was the Exponential Information Gathering protocol (EIG) proposed by Pease, Shostak and Lamport in [19]. The algorithm requires processes to send exponentially long messages. Many follow-up works reduced the cost of the algorithm. However, they had to either lower the maximum number of faulty processes t from the optimal range t< n/3 to some smaller range of t [4, 11, 18], or increase the maximum worst-case number of rounds needed for termination (the lower bound being t+ 1)[3, 9, 20].", "num_citations": "11\n", "authors": ["536"]}
{"title": "On the Respective Power of \u25caP and \u25caS to Solve One-Shot Agreement Problems\n", "abstract": " Unreliable failure detectors are abstract devices that, when added to asynchronous distributed systems, enable solving distributed computing problems (e.g., consensus) that otherwise would be impossible to solve in these systems. This paper focuses on two classes of failure detectors defined by Chandra and Toueg, namely, the classes denoted diamP (eventually perfect) and diamS (eventually strong). Both classes include failure detectors that eventually detect permanently all process crashes, but while the failure detectors of diamP eventually make no erroneous suspicions, the failure detectors of diamS are only required to eventually not suspect a single correct process. Informally, in a one-shot agreement problem, a new problem instance is created each time the processes propose new values to be decided on (e.g., consensus is one-shot). In such a context, this paper addresses the following question related\u00a0\u2026", "num_citations": "11\n", "authors": ["536"]}
{"title": "On composition and implementation of sequential consistency\n", "abstract": " To implement a linearizable shared memory in synchronous message-passing systems it is necessary to wait for a time linear to the uncertainty in the latency of the network for both read and write operations. Waiting only for one of them suffices for sequential consistency. This paper extends this result to crash-prone asynchronous systems, proposing a distributed algorithm that builds a sequentially consistent shared snapshot memory on top of an asynchronous message-passing system where less than half of the processes may crash. We prove that waiting is needed only when a process invokes a read/snapshot right after a write.               We also show that sequential consistency is composable in some cases commonly encountered: (1) objects that would be linearizable if they were implemented on top of a linearizable memory become sequentially consistent when implemented on top of a sequential\u00a0\u2026", "num_citations": "10\n", "authors": ["536"]}
{"title": "Spray: an Adaptive Random Peer Sampling Protocol\n", "abstract": " The introduction of WebRTC has opened a new playground for large-scale distributed applications consisting of large numbers of directly-communicating web browsers. In this context, gossip-based peer-sampling protocols appear as a particularly promising tool thanks to their inherent ability to build overlay networks that can cope with network dynamics. However, the dynamic nature of browser-to-browser communication combined with the connection establishment procedures  that characterize WebRTC make current peer sampling solutions inefficient or simply unreliable. In this paper, we address the  limitations of current peer-sampling approaches by introducing Spray, a novel peer-sampling protocol designed to avoid the constraints introduced by WebRTC. Unlike most recent peer-sampling approaches, Spray has the ability to adapt its operation to networks that can grow or shrink very rapidly. Moreover, by using only neighbor-to-neighbor interactions, it limits the impact of the threeway connection establishment process that characterizes WebRTC. Our experiments demonstrate the ability of Spray to adapt to dynamic networks and highlight its efficiency improvements with respect to existing protocols.", "num_citations": "8\n", "authors": ["536"]}
{"title": "Breaking the scalability barrier of causal broadcast for large and dynamic systems\n", "abstract": " Many distributed protocols and applications rely on causal broadcast to ensure consistency criteria. However, none of causality tracking state-of-the-art approaches scale in large and dynamic systems. This paper presents a new non-blocking causal broadcast protocol suited for such systems. The proposed protocol outperforms state-of-the-art in size of messages, execution time complexity, and local space complexity. Most importantly, messages piggyback control information the size of which is constant. We prove that for both static and dynamic systems. Consequently, large and dynamic systems can finally afford causal broadcast.", "num_citations": "7\n", "authors": ["536"]}
{"title": "Probabilistic causal message ordering\n", "abstract": " Causal broadcast is a classical communication primitive that has been studied for more then three decades and several implementations have been proposed. The implementation of such a primitive has a non negligible cost either in terms of extra information messages have to carry or in time delays needed for the delivery of messages. It has been proved that messages need to carry a control information the size of which is linear with the size of the system. This problem has gained more interest due to new application domains such that collaborative applications are widely used and are becoming massive and social semantic web and linked-data the implementation of which needs causal ordering of messages. This paper proposes a probabilistic but efficient causal broadcast mechanism for large systems with changing membership that uses few integer timestamps.", "num_citations": "7\n", "authors": ["536"]}
{"title": "Concurrency effects over variable-size identifiers in distributed collaborative editing\n", "abstract": " Distributed collaborative editors such as Google Docs or Etherpad allow to distribute the work across time, space and organizations. In this paper, we focus on distributed collaborative editors based on the Conflict-free Replicated Data Type approach (CRDT). CRDTs encompass a set of well-known data types such as sets, graphs, sequences, etc. CRDTs for sequences model a document as a set of elements (character, line, paragraph, etc.) with unique identifiers, providing two commutative update operations: insert and delete. The identifiers of elements can be either of fixed-size or variable-size. Recently, a strategy for assigning variable-size identifiers called LSEQ has been proposed for CRDTs for sequences. LSEQ lowers the space complexity of variable-size identifiers CRDTs from linear to sub-linear. While experiments show that it works locally, it fails to provide this bound with multiple users and latency. In this paper, we propose h-LSEQ, an improvement of LSEQ that preserves its space complexity among multiple collaborators, regardless of the latency. Ultimately, this improvement allows to safely build distributed collaborative editors based on CRDTs. We validate our approach with simulations involving latency and multiple users.", "num_citations": "7\n", "authors": ["536"]}
{"title": "Causal Broadcast: How to Forget?\n", "abstract": " Causal broadcast constitutes a fundamental communication primitive of many distributed protocols and applications. However, state-of-the-art implementations fail to forget obsolete control information about already delivered messages. They do not scale in large and dynamic systems. In this paper, we propose a novel implementation of causal broadcast. We prove that all and only obsolete control information is safely removed, at cost of a few lightweight control messages. The local space complexity of this protocol does not monotonically increase and depends at each moment on the number of messages still in transit and the degree of the communication graph. Moreover, messages only carry a scalar clock. Our implementation constitutes a sustainable communication primitive for causal broadcast in large and dynamic systems.", "num_citations": "6\n", "authors": ["536"]}
{"title": "Speed for the elite, consistency for the masses: differentiating eventual consistency in large-scale distributed systems\n", "abstract": " Eventual consistency is a consistency model that emphasizes liveness over safety, it is often used for its ability to scale as distributed systems grow larger. Eventual consistency tends to be uniformly applied to an entire system, but we argue that there is a growing demand for differentiated eventual consistency requirements. We address this demand with UPS, a novel consistency mechanism that offers differentiated eventual consistency and delivery speed by working in pair with a two-phase epidemic broadcast protocol. We propose a closed-form analysis of our approach's delivery speed, and we evaluate our complete mechanism experimentally on a simulated network of one million nodes. To measure the consistency trade-off, we formally define a novel and scalable consistency metric that operates at runtime. In our simulations, UPS divides by more than 4 the inconsistencies experienced by a majority of the\u00a0\u2026", "num_citations": "5\n", "authors": ["536"]}
{"title": "Extending the wait-free hierarchy to multi-threaded systems\n", "abstract": " In modern operating systems and programming languages adapted to multicore computer architectures, parallelism is abstracted by the notion of execution threads. Multi-threaded systems have two major specificities: 1) new threads can be created dynamically at runtime, so there is no bound on the number of threads participating in a long-running execution. 2) threads have access to a memory allocation mechanism that cannot allocate infinite arrays. This makes it challenging to adapt some algorithms to multi-threaded systems, especially those that assign one shared register per process.", "num_citations": "4\n", "authors": ["536"]}
{"title": "Towards a computing model for open distributed systems\n", "abstract": " This paper proposes an implementation of the data structure called bag or multiset used by descriptive programming languages (e.g. Gamma, Linda) over an open system. In this model, a succession of \u201dchemical reactions\u201d consumes the elements of the bag and produces new elements according to specific rules. This approach is particularly interesting as it suppresses all unneeded synchronization and reveals all the potential parallelism of a program. An efficient implementation of a bag provides an efficient implementation of the subsequent program. This paper defines a new communication and synchronization model adapted from workqueues used in parallel computing. The proposed model allows to benefit from the potential parallelism offered by this style of programming when only an approximate solution is needed.", "num_citations": "4\n", "authors": ["536"]}
{"title": "Tracking Causal Dependencies in Web Services Orchestrations Defined in ORC\n", "abstract": " This article shows how the operational semantics of a language like ORC can be instrumented so that the execution of a program produces information on the causal dependencies between events. The concurrent semantics we obtain is based on asymmetric labeled event structures. The approach is illustrated using a Web service orchestration instance and the detection of race conditions.", "num_citations": "3\n", "authors": ["536"]}
{"title": "A scalable sequence encoding for collaborative editing\n", "abstract": " Distributed real\u2010time editors made real\u2010time editing easy for millions of users. However, main stream editors rely on Cloud services to mediate sessions raising privacy and scalability issues. Decentralized editors tackle privacy issues, but scalability issues remain. We aim to build a decentralized editor that allows real\u2010time editing anytime, anywhere, whatever is the number of participants. In this study, we propose an approach based on a massively replicated sequence data structure that represents the shared document. We establish an original trade\u2010off on communication, time, and space complexity to maintain this sequence over a network of browsers. We prove a sublinear upper bound on communication complexity while preserving an affordable time and space complexity. To validate this trade\u2010off, we built a full working editor and measured its performance on large\u2010scale experiments involving up till 600\u00a0\u2026", "num_citations": "2\n", "authors": ["536"]}
{"title": "A message-passing and adaptive implementation of the randomized test-and-set object\n", "abstract": " This paper presents a solution to the well-known Test-and-Set operation in asynchronous systems prone to process crashes. Test-and-Set is a synchronization operation that, when invoked by a set of processes, returns \"yes\" to a unique process and returns \"no\" to all the others. Recently many advances in implementing Test and Set objects have been achieved, however all of them uniquely target the shared memory model. In this paper we propose an implementation of a Test-and-Set object for message passing distributed systems. This implementation can be invoked by any number p of processes. It has an expected step complexity in O(p) and an expected message complexity in O(np), where n is the total number of processes in the system. The proposed Test and Set object is built atop a new basic building block that allows to select a winning group among two groups of processes.", "num_citations": "2\n", "authors": ["536"]}
{"title": "D. 1.1\u2013Survey on Weak Consistency Approaches for Large-Scale Systems\n", "abstract": " Distributed systems are often viewed as more difficult to program than sequential systems be- cause they require solving a number of communication issues. Shared objects that can be accessed concurrently by multiple parties can be used as a practical communication abstraction to let pro- cesses enjoy a more general view of the system. A precise specification of these objects is therefore essential to ensure their adoption as well as the reliability of distributed systems. Many models have been proposed to specify shared memory, and several inventories [Mos93, AG96] can be found in the literature. In [Lam86], Lamport defines linearizable registers that ensure that everything appears as if all the operation where executed instantaneously at a point between the moment when the operation is called and the moment when it returns. Sequential consistency [Lam79] is a little weaker: it only guarantees that all the operations appear as totally ordered, and that this order be compatible with the program order, the order in which each process performs its own operations. These strong consistency criteria are very expensive to implement in message-passing systems. In terms of latency, it is necessary to wait for answers for the reads or the writes for sequential consistency [LS88] and for all kinds of operations in the case of linearizability [AW94]. In terms of fault tolerance, strong hypotheses must be respected by the system: it is impossible to resist to partitioning [Bre00, GL02]. Many weaker consistency criteria have been proposed to solve this problem. Among them, PRAM [LS88], causal memory [ANB+95] and eventual consistency [Vog08] are best\u00a0\u2026", "num_citations": "2\n", "authors": ["536"]}
{"title": "Time-Free Authenticated Byzantine Consensus\n", "abstract": " This paper presents a simple protocol that solves the authenticated Byzantine Consensus problem in asynchronous distributed systems. To circumvent the FLP impossibility result in a deterministic way, synchrony assumptions should be added. In the context of Byzantine failures for systems where at most t processes may exhibit a Byzantine behavior and where not all the system is assumed eventually synchronous, Moumen et al. provide the main result. They assume at least one correct process, called 2t-bisource, connected with 2t privileged neighbors with eventually timely outgoing and incoming links. The present paper shows that a deterministic solution for the authenticated byzantine consensus problem is possible if the system model satisfies an additional assumption that does not rely on physical time but on the pattern of messages that are exchanged. The basic message exchange between processes is\u00a0\u2026", "num_citations": "2\n", "authors": ["536"]}
{"title": "Towards the minimal synchrony for byzantine consensus\n", "abstract": " Authentication, Asynchronous Distributed System, Byzantine Process, Consensus, Distributed Algorithm, Eventually Timely Link, Fault-Tolerance, Resilience In the Consensus problem, each process proposes a value, and the non-faulty processes have to eventually decide (termination property) on the same output value (agreement property) that should be a proposed value (validity property). This problem, whose statement is particularly simple, is fundamental in fault-tolerant asynchronous distributed computing as it abstracts several basic agreement problems. Unfortunately, the Consensus problem has no deterministic solution in asynchronous distributed systems where even a single process can crash. A process crashes if it simply stops its execution (fail-stop process). Otherwise a faulty process can exhibit an arbitrary behavior. Such a process is called Byzantine. This bad behavior can be intentional\u00a0\u2026", "num_citations": "2\n", "authors": ["536"]}
{"title": "Single-Write Safe Consensus using Constrained Inputs.\n", "abstract": " Condition-based protocols are implementations of relaxed agreement problems in which termination is guaranteed in predefined scenarios. In a previous work, a tradeoff between communication cost and convergence ratio is identified in the shared memory model. This paper investigates the extremal problem of solving consensus with only a single write operation. We show that this problem has a condition-based solution. Moreover, terminating with a single write can be added to previous condition-based protocols without changing their complexity, making it an early deciding scenario. In the appendix, a proof that this single write approach implies a quadratic number of read operations is given.", "num_citations": "2\n", "authors": ["536"]}
{"title": "Topic 8: Distributed Systems and Algorithms\n", "abstract": " Distributed Computing is becoming more and more led by technological and application advances. Many works consider new computing models compared to the classical closed model with a fixed number of participants and strong hypothesis on communication and structuration. Indeed, it is hard to imagine some application or computational activity and process that falls outside Distributed Computing. Internet and the web (e.g. social networks, clouds) are becoming the main application field for distributed computing. In addition to the classical challenges that developers have to face (asynchrony and failures) they have to deal with load balancing, malicious and selfish behaviors, mobility, heterogeneity and the dynamic nature of participating processes.", "num_citations": "1\n", "authors": ["536"]}