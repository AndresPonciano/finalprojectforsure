{"title": "Improving mapreduce performance through data placement in heterogeneous hadoop clusters\n", "abstract": " MapReduce has become an important distributed processing model for large-scale data-intensive applications like data mining and web indexing. Hadoop-an open-source implementation of MapReduce is widely used for short jobs requiring low response time. The current Hadoop implementation assumes that computing nodes in a cluster are homogeneous in nature. Data locality has not been taken into account for launching speculative map tasks, because it is assumed that most maps are data-local. Unfortunately, both the homogeneity and data locality assumptions are not satisfied in virtualized data centers. We show that ignoring the data-locality issue in heterogeneous environments can noticeably reduce the MapReduce performance. In this paper, we address the problem of how to place data across nodes in a way that each node has a balanced data processing load. Given a dataintensive application\u00a0\u2026", "num_citations": "545\n", "authors": ["505"]}
{"title": "Online optimization for scheduling preemptable tasks on IaaS cloud systems\n", "abstract": " In Infrastructure-as-a-Service (IaaS) cloud computing, computational resources are provided to remote users in the form of leases. For a cloud user, he/she can request multiple cloud services simultaneously. In this case, parallel processing in the cloud system can improve the performance. When applying parallel processing in cloud computing, it is necessary to implement a mechanism to allocate resource and schedule the execution order of tasks. Furthermore, a resource optimization mechanism with preemptable task execution can increase the utilization of clouds. In this paper, we propose two online dynamic resource allocation algorithms for the IaaS cloud system with preemptable tasks. Our algorithms adjust the resource allocation dynamically based on the updated information of the actual task executions. And the experimental results show that our algorithms can significantly improve the performance in the\u00a0\u2026", "num_citations": "410\n", "authors": ["505"]}
{"title": "A novel fault-tolerant scheduling algorithm for precedence constrained tasks in real-time heterogeneous systems\n", "abstract": " Fault-tolerance is an essential requirement for real-time systems, due to potentially catastrophic consequences of faults. In this paper, we investigate an efficient off-line scheduling algorithm generating schedules in which real-time tasks with precedence constraints can tolerate one processor\u2019s permanent failure in a heterogeneous system with fully connected network. The tasks are assumed to be non-preemptable, and each task has two copies scheduled on different processors and mutually excluded in time. In the literature in recent years, the quality of a schedule has been previously improved by allowing a backup copy to overlap with other backup copies on the same processor. However, this approach assumes that tasks are independent of one other. To meet the needs of real-time systems where tasks have precedence constraints, a new overlapping scheme is proposed. We show that, given two tasks, the\u00a0\u2026", "num_citations": "186\n", "authors": ["505"]}
{"title": "Towards energy-efficient scheduling for real-time tasks under uncertain cloud computing environment\n", "abstract": " Green cloud computing has become a major concern in both industry and academia, and efficient scheduling approaches show promising ways to reduce the energy consumption of cloud computing platforms while guaranteeing QoS requirements of tasks. Existing scheduling approaches are inadequate for real-time tasks running in uncertain cloud environments, because those approaches assume that cloud computing environments are deterministic and pre-computed schedule decisions will be statically followed during schedule execution. In this paper, we address this issue. We introduce an interval number theory to describe the uncertainty of the computing environment and a scheduling architecture to mitigate the impact of uncertainty on the task scheduling quality for a cloud data center. Based on this architecture, we present a novel scheduling algorithm (PRS1) that dynamically exploits proactive and\u00a0\u2026", "num_citations": "175\n", "authors": ["505"]}
{"title": "Scheduling security-critical real-time applications on clusters\n", "abstract": " Security-critical real-time applications such as military aircraft flight control systems have mandatory security requirements in addition to stringent timing constraints. Conventional real-time scheduling algorithms, however, either disregard applications' security needs and thus expose the applications to security threats or run applications at inferior security levels without optimizing security performance. In recognition that many applications running on clusters demand both real-time performance and security, we investigate the problem of scheduling a set of independent real-time tasks with various security requirements. We build a security overhead model that can be used to reasonably measure security overheads incurred by the security-critical tasks. Next, we propose a security-aware real-time heuristic strategy for clusters (SAREC), which integrates security requirements into the scheduling for real-time\u00a0\u2026", "num_citations": "170\n", "authors": ["505"]}
{"title": "EAD and PEBD: two energy-aware duplication scheduling algorithms for parallel tasks on homogeneous clusters\n", "abstract": " High-performance clusters have been widely deployed to solve challenging and rigorous scientific and engineering tasks. On one hand, high performance is certainly an important consideration in designing clusters to run parallel applications. On the other hand, the ever increasing energy cost requires us to effectively conserve energy in clusters. To achieve the goal of optimizing both performance and energy efficiency in clusters, in this paper, we propose two energy-efficient duplication-based scheduling algorithms-Energy-Aware Duplication (EAD) scheduling and Performance-Energy Balanced Duplication (PEBD) scheduling. Existing duplication-based scheduling algorithms replicate all possible tasks to shorten schedule length without reducing energy consumption caused by duplication. Our algorithms, in contrast, strive to balance schedule lengths and energy savings by judiciously replicating predecessors\u00a0\u2026", "num_citations": "167\n", "authors": ["505"]}
{"title": "A dynamic and reliability-driven scheduling algorithm for parallel real-time jobs executing on heterogeneous clusters\n", "abstract": " In this paper, a heuristic dynamic scheduling scheme for parallel real-time jobs executing on a heterogeneous cluster is presented. In our system model, parallel real-time jobs, which are modeled by directed acyclic graphs, arrive at a heterogeneous cluster following a Poisson process. A job is said to be feasible if all its tasks meet their respective deadlines. The scheduling algorithm proposed in this paper takes reliability measures into account, thereby enhancing the reliability of heterogeneous clusters without any additional hardware cost. To make scheduling results more realistic and precise, we incorporate scheduling and dispatching times into the proposed scheduling approach. An admission control mechanism is in place so that parallel real-time jobs whose deadlines cannot be guaranteed are rejected by the system. For experimental performance study, we have considered a real world application as well\u00a0\u2026", "num_citations": "154\n", "authors": ["505"]}
{"title": "QoS-aware fault-tolerant scheduling for real-time tasks on heterogeneous clusters\n", "abstract": " Fault-tolerant scheduling plays a significant role in improving system reliability of clusters. Although extensive fault-tolerant scheduling algorithms have been proposed for real-time tasks in parallel and distributed systems, quality of service (QoS) requirements of tasks have not been taken into account. This paper presents a fault-tolerant scheduling algorithm called QAFT that can tolerate one node's permanent failures at one time instant for real-time tasks with QoS needs on heterogeneous clusters. In order to improve system flexibility, reliability, schedulability, and resource utilization, QAFT strives to either advance the start time of primary copies and delay the start time of backup copies in order to help backup copies adopt the passive execution scheme, or to decrease the simultaneous execution time of the primary and backup copies of a task as much as possible to improve resource utilization. QAFT is capable of\u00a0\u2026", "num_citations": "152\n", "authors": ["505"]}
{"title": "An efficient fault-tolerant scheduling algorithm for real-time tasks with precedence constraints in heterogeneous systems\n", "abstract": " In this paper, we investigate an efficient off-line scheduling algorithm in which real-time tasks with precedence constraints are executed in a heterogeneous environment. It provides more features and capabilities than existing algorithms that schedule only independent tasks in real-time homogeneous systems. In addition, the proposed algorithm takes the heterogeneities of computation, communication and reliability into account, thereby improving the reliability. To provide fault-tolerant capability, the algorithm employs a primary-backup copy scheme that enables the system to tolerate permanent failures in any single processor. In this scheme, a backup copy is allowed to overlap with other backup copies on the same processor, as long as their corresponding primary copies are allocated to different processors. Tasks are judiciously allocated to processors so as to reduce the schedule length as well as the reliability\u00a0\u2026", "num_citations": "143\n", "authors": ["505"]}
{"title": "The ${\\schmi g} $-Good-Neighbor Conditional Diagnosability of ${\\schmi k} $-Ary ${\\schmi n} $-Cubes under the PMC Modeland MM* Model\n", "abstract": " The diagnosability of a system is defined as the maximum number of faulty processors that the system can guarantee to identify, which plays an important role in measuring of the reliability of multiprocessor systems. In the work of Peng et al. in 2012, they proposed a new measure for fault diagnosis of systems, namely, g-good-neighbor conditional diagnosability. It is defined as the diagnosability of a multiprocessor system under the assumption that every fault-free node contains at least g fault-free neighbors, which can measure the reliability of interconnection networks in heterogeneous environments more accurately than traditional diagnosability. The k-ary n-cube is a family of popular networks. In this study, we first investigate and determine the R g -connectivity of k-ary n-cube for 0 \u2264 g \u2264 n. Based on this, we determine the g-good-neighbor conditional diagnosability of k-ary n-cube under the PMC model and MM\u00a0\u2026", "num_citations": "128\n", "authors": ["505"]}
{"title": "Fidoop: Parallel mining of frequent itemsets using mapreduce\n", "abstract": " Existing parallel mining algorithms for frequent itemsets lack a mechanism that enables automatic parallelization, load balancing, data distribution, and fault tolerance on large clusters. As a solution to this problem, we design a parallel frequent itemsets mining algorithm called FiDoop using the MapReduce programming model. To achieve compressed storage and avoid building conditional pattern bases, FiDoop incorporates the frequent items ultrametric tree, rather than conventional FP trees. In FiDoop, three MapReduce jobs are implemented to complete the mining task. In the crucial third MapReduce job, the mappers independently decompose itemsets, the reducers perform combination operations by constructing small ultrametric trees, and the actual mining of these trees separately. We implement FiDoop on our in-house Hadoop cluster. We show that FiDoop on the cluster is sensitive to data distribution and\u00a0\u2026", "num_citations": "108\n", "authors": ["505"]}
{"title": "Static security optimization for real-time systems\n", "abstract": " An increasing number of real-time applications like railway signaling control systems and medical electronics systems require high quality of security to assure confidentiality and integrity of information. Therefore, it is desirable and essential to fulfill security requirements in security-critical real-time systems. This paper addresses the issue of optimizing quality of security in real-time systems. To meet the needs of a wide variety of security requirements imposed by real-time systems, a group-based security service model is used in which the security services are partitioned into several groups depending on security types. While services within the same security group provide the identical type of security service, the services in the group can achieve different quality of security. Security services from a number of groups can be combined to deliver better quality of security. In this study, we seamlessly integrate the group\u00a0\u2026", "num_citations": "108\n", "authors": ["505"]}
{"title": "Dynamic, reliability-driven scheduling of parallel real-time jobs in heterogeneous systems\n", "abstract": " In this paper, a heuristic dynamic scheduling scheme for parallel real-time jobs in a heterogeneous system is presented. The parallel real-time jobs studied in this paper are modelled by directed acyclic graphs (DAG). We assume a scheduling environment where parallel real-time jobs arrive at a heterogeneous system following a Poisson process. The scheduling algorithms developed in this paper take the reliability measure into account, in order to enhance the reliability of the heterogeneous system without any additional hardware cost. In addition, scheduling time and dispatch time are both incorporated into our scheduling scheme so as to make the scheduling result more realistic and precise. Admission control is in place so that a parallel real-time job whose deadline cannot be guaranteed is rejected by the system. The performance of the proposed scheme is evaluated via extensive simulations. The simulation\u00a0\u2026", "num_citations": "105\n", "authors": ["505"]}
{"title": "Security-aware resource allocation for real-time parallel jobs on homogeneous and heterogeneous clusters\n", "abstract": " Security is increasingly becoming an important issue in the design of real-time parallel applications, which are widely used in the industry and academic organizations. However, existing resource allocation schemes for real-time parallel jobs on clusters generally do not factor in security requirements when making allocation and scheduling decisions. In this paper, we develop two resource allocation schemes, called task allocation for parallel applications with deadline and security constraints (TAPADS) and security-aware and heterogeneity-aware resource allocation for parallel jobs (SHARP), by taking into account applications' timing and security requirements in addition to precedence constraints. We consider two types of computing platforms: homogeneous clusters and heterogeneous clusters. To facilitate the presentation of the new schemes, we build mathematical models to describe a system framework\u00a0\u2026", "num_citations": "103\n", "authors": ["505"]}
{"title": "Adaptive energy-efficient scheduling for real-time tasks on DVS-enabled heterogeneous clusters\n", "abstract": " Developing energy-efficient clusters not only can reduce power electricity cost but also can improve system reliability. Existing scheduling strategies developed for energy-efficient clusters conserve energy at the cost of performance. The performance problem becomes especially apparent when cluster computing systems are heavily loaded. To address this issue, we propose in this paper a novel scheduling strategy\u2013adaptive energy-efficient scheduling or AEES\u2013for aperiodic and independent real-time tasks on heterogeneous clusters with dynamic voltage scaling. The AEES scheme aims to adaptively adjust voltages according to the workload conditions of a cluster, thereby making the best trade-offs between energy conservation and schedulability. When the cluster is heavily loaded, AEES considers voltage levels of both new tasks and running tasks to meet tasks\u2019 deadlines. Under light load, AEES aggressively\u00a0\u2026", "num_citations": "99\n", "authors": ["505"]}
{"title": "Adsorption of diclofenac onto goethite: adsorption kinetics and effects of pH\n", "abstract": " The adsorption of diclofenac (DCF), one of the widely used non-steroidal anti-inflammatory drugs, onto the surface of goethite was investigated with batch experiments. The adsorption at different pH values (5.3, 7.4, and 10.0) were well fitted with the pseudo-second-order model. The results showed that the adsorption of DCF onto goethite was strongly depended on solution pH. The amount of adsorbed DCF decreased with increasing pH duo to electrostatic repulsive interactions. Fourier transform infrared (FTIR) results indicated that carboxyl group (single bondCOOH) might be involved in the adsorption, and DCF formed bidentate chelate and bridging bidentate complexes on the surface of goethite.", "num_citations": "87\n", "authors": ["505"]}
{"title": "Energy-aware data allocation with hybrid memory for mobile cloud systems\n", "abstract": " Resource scheduling is one of the most important issues in mobile cloud computing due to the constraints in memory, CPU, and bandwidth. High energy consumption and low performance of memory accesses have become overwhelming obstacles for chip multiprocessor (CMP) systems used in cloud systems. In order to address the daunting \u201cmemory wall\u201d problem, hybrid on-chip memory architecture has been widely investigated recently. Due to its advantages in size, real-time predictability, power, and software controllability, scratchpad memory (SPM) is a promising technique to replace the hardware cache and bridge the processor-memory gap for CMP systems. In this paper, we present a novel hybrid on-chip SPM that consists of a static random access memory (RAM), a magnetic RAM (MRAM), and a zero-capacitor RAM for CMP systems by fully taking advantages of the benefits of each type of memory. To\u00a0\u2026", "num_citations": "87\n", "authors": ["505"]}
{"title": "Improving security for periodic tasks in embedded systems through scheduling\n", "abstract": " While many scheduling algorithms for periodic tasks ignore security requirements posed by sensitive applications and are, consequently, unable to perform properly in embedded systems with security constraints, in this paper, we present an approach to scheduling periodic tasks in embedded systems subject to security and timing constraints. We design a necessary and sufficient feasibility check for a set of periodic tasks with security requirements. With the feasibility test in place, we propose a scheduling algorithm, or SASES (security-aware scheduling for embedded systems), which accounts for both security and timing requirements. SASES judiciously distributes slack times among a variety of security services for a set of periodic tasks, thereby optimizing security for embedded systems without sacrificing schedulability. To demonstrate the effectiveness of SASES, we apply the proposed SASES to real-world\u00a0\u2026", "num_citations": "86\n", "authors": ["505"]}
{"title": "Resource allocation robustness in multi-core embedded systems with inaccurate information\n", "abstract": " Multi-core technologies are widely used in embedded systems and the resource allocation is vita to guarantee Quality of Service (QoS) requirements for applications on multi-core platforms. For heterogeneous multi-core systems, the statistical characteristics of execution times on different cores play a critical role in the resource allocation, and the differences between the actual execution time and the estimated execution time may significantly affect the performance of resource allocation and cause system to be less robust. In this paper, we present an evaluation method to study the impacts of inaccurate execution time information to the performance of resource allocation. We propose a systematic way to measure the robustness degradation of the system and evaluate how inaccurate probability parameters may affect the performance of resource allocations. Furthermore, we compare the performance of three widely\u00a0\u2026", "num_citations": "84\n", "authors": ["505"]}
{"title": "An availability-aware task scheduling strategy for heterogeneous systems\n", "abstract": " High availability is a key requirement in the design and development of heterogeneous systems where processors operate at different speeds and are not continuously available for computation. Most existing scheduling algorithms designed for heterogeneous systems do not factor in availability requirements imposed by multiclass applications. To remedy this shortcoming, we investigate in this paper the scheduling problem for multiclass applications running in heterogeneous systems with availability constraints. In an effort to explore this issue, we model each node in a heterogeneous system using the node's computing capability and availability. Multiple classes of tasks are characterized by their execution times and availability requirements. To incorporate availability and heterogeneity into scheduling, we define new metrics to quantify system availability and heterogeneity for multiclass tasks. We then propose a\u00a0\u2026", "num_citations": "84\n", "authors": ["505"]}
{"title": "Data allocation for hybrid memory with genetic algorithm\n", "abstract": " The gradually widening speed disparity between CPU and memory has become an overwhelming bottleneck for the development of chip multiprocessor systems. In addition, increasing penalties caused by frequent on-chip memory accesses have raised critical challenges in delivering high memory access performance with tight power and latency budgets. To overcome the daunting memory wall and energy wall issues, this paper focuses on proposing a new heterogeneous scratchpad memory architecture, which is configured from SRAM, MRAM, and Z-RAM. Based on this architecture, we propose a genetic algorithm to perform data allocation to different memory units, therefore, reducing memory access cost in terms of power consumption and latency. Extensive and experiments are performed to show the merits of the heterogeneous scratchpad architecture over the traditional pure memory system and the\u00a0\u2026", "num_citations": "79\n", "authors": ["505"]}
{"title": "Security-aware optimization for ubiquitous computing systems with SEAT graph approach\n", "abstract": " For ubiquitous computing systems, security has become a new metric that designers should consider throughout the design process, along with other metrics such as performance and energy consumption. A combination of selected cryptographic algorithms for required security services forms a security strategy for the application. In this paper, we propose methods to generate security strategies to achieve the maximal overall security strength while meeting the real-time constraint. In order to express security requirements of an application, we propose a novel graph model called Security-Aware Task (SEAT) graph model to represent real-time constraints and precedence relationships among tasks. Based on the SEAT graph approach, we propose an optimal algorithm, Integer Linear Programming Security Optimization (ILP-SOP). For the special structures such as simple path graph and tree, we propose two\u00a0\u2026", "num_citations": "77\n", "authors": ["505"]}
{"title": "A decentralized approach for mining event correlations in distributed system monitoring\n", "abstract": " Nowadays, there is an increasing demand to monitor, analyze, and control large scale distributed systems. Events detected during monitoring are temporally correlated, which is helpful to resource allocation, job scheduling, and failure prediction. To discover the correlations among detected events, many existing approaches concentrate detected events into an event database and perform data mining on it. We argue that these approaches are not scalable to large scale distributed systems as monitored events grow so fast that event correlation discovering can hardly be done with the power of a single computer. In this paper, we present a decentralized approach to efficiently detect events, filter irrelative events, and discover their temporal correlations. We propose a MapReduce-based algorithm, MapReduce-Apriori, to data mining event association rules, which utilizes the computational resource of multiple\u00a0\u2026", "num_citations": "76\n", "authors": ["505"]}
{"title": "Association of polyfluoroalkyl chemical exposure with serum lipids in children\n", "abstract": " Perfluoroalkyl and polyfluoroalkyl substances (PFASs), as well as polymers of PFASs, have been widely used in commercial applications and have been detected in humans and the environment. Previous epidemiological studies have shown associations between particular PFAS chemicals and serum lipid concentrations in adults, particularly perfluorooctane sulfonic acid (PFOS) and perfluorooctanoic acid (PFOA). There exists, however, limited information concerning the effect of PFASs have on serum lipids among children. In the present cross-sectional study, 225 Taiwanese children (12\u201315\u00a0years of age) were recruited to determine the relationship between serum level PFASs and lipid concentration. Results showed that eight out of ten particular PFASs were detected in the serum of >\u00a094% of the participants. Serum PFOS and perfluorotetradecanoic acid (PFTA) levels were at an order of magnitude higher than\u00a0\u2026", "num_citations": "74\n", "authors": ["505"]}
{"title": "Feedback dynamic algorithms for preemptable job scheduling in cloud systems\n", "abstract": " An infrastructure-as-a-service cloud system provides computational capacities to remote users. Parallel processing in the cloud system can shorten the execution of jobs. Parallel processing requires a mechanism to scheduling the executions order as well as resource allocation. Furthermore, a preemptable scheduling mechanism can improve the utilization of resources in clouds. In this paper, we present a preemptable job scheduling mechanism in cloud system. We propose two feedback dynamic scheduling algorithms for this scheduling mechanism. We compare these two scheduling algorithms in simulations. The results show that the feedback procedure in our algorithms works well in the situation where resource contentions are fierce.", "num_citations": "72\n", "authors": ["505"]}
{"title": "An energy-delay tunable task allocation strategy for collaborative applications in networked embedded systems\n", "abstract": " Collaborative applications with energy and low-delay constraints are emerging in various networked embedded systems like wireless sensor networks and multimedia terminals. Conventional energy-aware task allocation schemes developed for collaborative applications only concentrated on energy savings when making allocation decisions. Consequently, the length of the schedules generated by such allocation schemes could be very long, which is unfavorable or, in some situations, even not tolerated. To remedy this problem, we developed a novel task allocation strategy called balanced energy-aware task allocation (BEATA) for collaborative applications running on heterogeneous networked embedded systems. The BEATA algorithm aims at blending an energy-delay efficiency scheme with task allocations, thereby making the best trade-offs between energy savings and schedule lengths. Aside from that, we\u00a0\u2026", "num_citations": "72\n", "authors": ["505"]}
{"title": "Interactions between air pollution and obesity on blood pressure and hypertension in Chinese children\n", "abstract": " Background: Little information exists regarding the effect of interaction of obesity and long-term air pollution exposure on children\u2019s blood pressure and hypertension in areas with high levels of air pollution. The aim of this study is to assess effect modification by obesity on the association between exposure and blood pressure in Chinese children.   Methods: We studied 9,354 Chinese children, ages 5\u201317 years old, from 24 elementary schools and 24 middle schools in the Seven Northeastern Cities during 2012\u20132013. Four-year average concentrations of particles with an aerodynamic diameter \u226410 \u03bcm (PM10), sulfur dioxide, nitrogen dioxides, and ozone (O3) were measured at the monitoring stations in the 24 districts. We used generalized additive models and two-level logistic regression models to examine the health effects.   Results: Consistent interactions were found between exposure and obesity on blood\u00a0\u2026", "num_citations": "71\n", "authors": ["505"]}
{"title": "Enhancing security of real-time applications on grids through dynamic scheduling\n", "abstract": " Real-time applications with security requirements are emerging in various areas including government, education, and business. However, conventional real-time scheduling algorithms failed to fulfill the security requirements of real-time applications. In this paper we propose a dynamic real-time scheduling algorithm, or SAREG, which is capable of enhancing quality of security for real-time applications running on Grids. In addition, we present a mathematical model to formally describe a scheduling framework, security-sensitive real-time applications, and security overheads. We leverage the model to measure security overheads incurred by security services, including encryption, authentication, integrity check, etc. The SAREG algorithm seamlessly integrates security requirements into real-time scheduling by employing the security overhead model. To evaluate the effectiveness of SAREG, we conducted\u00a0\u2026", "num_citations": "68\n", "authors": ["505"]}
{"title": "Fragrant agarofuran and eremophilane sesquiterpenes in agarwood \u2018Qi-Nan\u2019from Aquilaria sinensis\n", "abstract": " Phytochemical analysis of the high quality Chinese agarwood \u2018Qi-Nan\u2019 originating from Aquilaria sinensis (Lour.) Glig, led to the isolation of four fragrant sesquiterpenes, including an agarofuran 4-hydroxyl-baimuxinol (1) and three eremophilanes, 7\u03b2-H-9(10)-ene-11,12-epoxy-8-oxoeremophilane (2), 7\u03b1-H-9(10)-ene-11,12-epoxy-8-oxoeremophilane (3), neopetasane (4). Among them, compounds 1\u20133 were new compounds. Their structures were elucidated by spectroscopic techniques (UV, IR, 1D and 2D NMR) and MS analyses. Eremophilane sesquiterpenes 2\u20134 showed inhibitory activities against acetylcholinesterase with IC50 value of 274.8, 491.4, and 158.3\u00a0\u03bcM, respectively.", "num_citations": "66\n", "authors": ["505"]}
{"title": "Adsorption of levofloxacin onto goethite: effects of pH, calcium and phosphate\n", "abstract": " Adsorption of levofloxacin (LEV), one of the extensively used antibiotics, onto goethite was investigated using batch experiments. The adsorption of LEV on goethite was pH-dependent. A maximum adsorption was reached at pH 6. Above or below pH 6, the adsorption decreased. In the presence of calcium (Ca2+), a decrease in adsorption was observed, due to probably formation of Ca2+\u2013LEV complexes in solutions. Phosphate also showed a significant inhibition on LEV adsorption over a pH range of 3\u201310. Phosphate competed with LEV for binding sites on the surface of goethite, and the electrostatic competition between LEV and phosphate on goethite surface might be another reason for the decrease in adsorption. These results indicated that Ca2+ and phosphate have a great influence on the distribution of LEV in soils and waters, which will eventually affect its antibacterial activity in the environment.", "num_citations": "66\n", "authors": ["505"]}
{"title": "SAREC: A security-aware scheduling strategy for real-time applications on clusters\n", "abstract": " Security requirements of security-critical real-time applications must be met in addition to satisfying timing constraints. However, conventional real-time scheduling algorithms ignore the applications' security requirements. In recognition that an increasing number of applications running on clusters demand both real-time performance and security, we investigate the problem of scheduling a set of independent real-time tasks with various security requirements. We propose a security overhead model that is capable of measuring security overheads incurred by security-critical tasks. Further, we propose a security-aware scheduling strategy, or SAREC, which integrates security requirements into scheduling for real-time applications by employing our security overhead model. To evaluate the effectiveness of SAREC, we implement a security-aware real-time scheduling algorithm (SAREC-EDF), which incorporates the\u00a0\u2026", "num_citations": "66\n", "authors": ["505"]}
{"title": "Energy-efficient scheduling for parallel applications running on heterogeneous clusters\n", "abstract": " High performance clusters have been widely used to provide amazing computing capability for both commercial and scientific applications. However, huge power consumption has prevented the further application of large-scale clusters. Designing energy-efficient scheduling algorithms for parallel applications running on clusters, especially on the high performance heterogeneous clusters, is highly desirable. In this regard, we propose a novel scheduling strategy called energy efficient task duplication schedule (EETDS for short), which can significantly conserve power by judiciously shrinking communication energy cost when allocating parallel tasks to heterogeneous computing nodes. We present the preliminary simulation results for Gaussian and FFT parallel task models to prove the efficiency of our algorithm.", "num_citations": "64\n", "authors": ["505"]}
{"title": "FiDoop-DP: Data partitioning in frequent itemset mining on hadoop clusters\n", "abstract": " Traditional parallel algorithms for mining frequent itemsets aim to balance load by equally partitioning data among a group of computing nodes. We start this study by discovering a serious performance problem of the existing parallel Frequent Itemset Mining algorithms. Given a large dataset, data partitioning strategies in the existing solutions suffer high communication and mining overhead induced by redundant transactions transmitted among computing nodes. We address this problem by developing a data partitioning approach called FiDoop-DP using the MapReduce programming model. The overarching goal of FiDoop-DP is to boost the performance of parallel Frequent Itemset Mining on Hadoop clusters. At the heart of FiDoop-DP is the Voronoi diagram-based data partitioning technique, which exploits correlations among transactions. Incorporating the similarity metric and the Locality-Sensitive Hashing\u00a0\u2026", "num_citations": "61\n", "authors": ["505"]}
{"title": "Detecting fake news for reducing misinformation risks using analytics approaches\n", "abstract": " Fake news is playing an increasingly dominant role in spreading misinformation by influencing people\u2019s perceptions or knowledge to distort their awareness and decision-making. The growth of social media and online forums has spurred the spread of fake news causing it to easily blend with truthful information. This study provides a novel text analytics\u2013driven approach to fake news detection for reducing the risks posed by fake news consumption. We first describe the framework for the proposed approach and the underlying analytical model including the implementation details and validation based on a corpus of news data. We collect legitimate and fake news, which is transformed from a document based corpus into a topic and event\u2013based representation. Fake news detection is performed using a two-layered approach, which is comprised of detecting fake topics and fake events. The efficacy of the proposed\u00a0\u2026", "num_citations": "59\n", "authors": ["505"]}
{"title": "Sodium tanshinone IIA silate inhibits high glucose-induced vascular smooth muscle cell proliferation and migration through activation of AMP-activated protein kinase\n", "abstract": " The proliferation of vascular smooth muscle cells may perform a crucial role in the pathogenesis of diabetic vascular disease. AMPK additionally exerts several salutary effects on vascular function and improves vascular abnormalities. The current study sought to determine whether sodium tanshinone IIA silate (STS) has an inhibitory effect on vascular smooth muscle cell (VSMC) proliferation and migration under high glucose conditions mimicking diabetes without dyslipidemia, and establish the underlying mechanism. In this study, STS promoted the phosphorylation of AMP-activated protein kinase (AMPK) at T172 in VSMCs. VSMC proliferation was enhanced under high glucose (25 mM glucose, HG) versus normal glucose conditions (5.5 mM glucose, NG), and this increase was inhibited significantly by STS treatment. We utilized western blotting analysis to evaluate the effects of STS on cell-cycle regulatory proteins and found that STS increased the expression of p53 and the Cdk inhibitor, p21, subsequent decreased the expression of cell cycle-associated protein, cyclin D1. We further observed that STS arrested cell cycle progression at the G0/G1 phase. Additionally, expression and enzymatic activity of MMP-2, translocation of NF-\u03baB, as well as VSMC migration were suppressed in the presence of STS. Notably, Compound C (CC), a specific inhibitor of AMPK, as well as AMPK siRNA blocked STS-mediated inhibition of VSMC proliferation and migration. We further evaluated its potential for activating AMPK in aortas in animal models of type 2 diabetes and found that Oral administration of STS for 10 days resulted in activation of AMPK in aortas\u00a0\u2026", "num_citations": "57\n", "authors": ["505"]}
{"title": "Arthpyrones A\u2013C, Pyridone Alkaloids from a Sponge-Derived Fungus Arthrinium arundinis ZSDS1-F3\n", "abstract": " Three new 4-hydroxy-2-pyridone alkaloids, arthpyrones A\u2013C (1\u20133), were isolated from the sponge-derived fungus Arthrinium arundinis ZSDS1-F3. Their structures were elucidated on the basis of spectroscopic analysis, CD spectra, quantum chemical calculation, and X-ray single-crystal diffraction analysis. Compounds 1 and 2 possessed a 2-pyridone core featured with a decalin moiety linked via a carboxide bridge bearing a novel oxabicyclo[3.3.1]nonane ring system rarely discovered in nature. A possible biosynthetic pathway for them was proposed.", "num_citations": "55\n", "authors": ["505"]}
{"title": "Performance evaluation of a new scheduling algorithm for distributed systems with security heterogeneity\n", "abstract": " High quality of security service is increasingly critical for applications running on heterogeneous distributed systems. However, existing scheduling algorithms for heterogeneous distributed systems disregard security requirements of applications. To address this issue, in this paper, we introduce security heterogeneity concept for our scheduling model in the context of distributed systems. Based on the concept, we propose a novel heuristic scheduling algorithm, or SATS, which strives to maximize the probability that all tasks are executed without any risk of being attacked. Extensive experimental studies using real-world traces indicate that the scheduling performance is affected by heterogeneities of security and computational power. Additionally, empirical results demonstrate that with respect to security and performance, the proposed scheduling algorithm outperforms existing approaches under a wide spectrum of\u00a0\u2026", "num_citations": "50\n", "authors": ["505"]}
{"title": "Dynamic load balancing for I/O-intensive tasks on heterogeneous clusters\n", "abstract": " Since I/O-intensive tasks running on a heterogeneous cluster need a highly effective usage of global I/O resources, previous CPU- or memory-centric load balancing schemes suffer significant performance drop under I/O-intensive workload due to the imbalance of I/O load. To solve this problem, we develop two I/O-aware load-balancing schemes, which consider system heterogeneity and migrate more I/O-intensive tasks from a node with high I/O utilization to those with low I/O utilization. If the workload is memory-intensive in nature, the new method applies a memory-based load balancing policy to assign the tasks. Likewise, when the workload becomes CPU-intensive, our scheme leverages a CPU-based policy as an efficient means to balance the system load. In doing so, the proposed approach maintains the same level of performance as the existing schemes when I/O load is low or well balanced\u00a0\u2026", "num_citations": "50\n", "authors": ["505"]}
{"title": "Air pollution associated hypertension and increased blood pressure may be reduced by breastfeeding in Chinese children: the Seven Northeastern Cities Chinese Children's Study\n", "abstract": " BackgroundLittle is known about the association between air pollution and hypertension among children, and no studies report whether breastfeeding modifies this association in children.MethodsNine thousand three hundred fifty-four Chinese children, ages 5\u201317 years old, from 24 elementary schools and 24 middle schools in the Seven Northeastern Cities during 2012\u20132013 were evaluated. The weight, height, and BP were measured. Four-year average concentrations of particles with an aerodynamic diameter of \u2264\u00a010\u00a0\u03bcm (PM10), sulfur dioxide (SO2), nitrogen dioxides (NO2), ozone (O3), and carbon monoxide (CO) were calculated from monitoring stations. Two-level regression analysis was used to examine the effects, controlling for covariates.ResultsThe results showed that associations existed between hypertension and pollutants. The odds ratios for hypertension ranged from 1.12 per 46.3\u00a0\u03bcg/m3 increase\u00a0\u2026", "num_citations": "49\n", "authors": ["505"]}
{"title": "g-Good-neighbor conditional diagnosability measures for 3-ary n-cube networks\n", "abstract": " The diagnosability of a parallel system is defined as the maximum number of faulty processors or nodes that the system can guarantee to identify. In this study, we investigate the g-good-neighbor conditional diagnosability, which indicates that every fault-free node in a system contains at least g fault-free neighbors. Compared with the conventional diagnosability, g-good-neighbor conditional diagnosability improves accuracy in measuring the reliability of interconnection networks in heterogeneous environments. We apply the PMC and MM* models to study the g-good-neighbor conditional diagnosability of 3-ary n-cube networks, which represent a family of popular parallel systems such as IBM's Blue Gene and Cray T3D. The findings made in this study facilitate accurate reliability measurements in modern parallel systems powered by 3-ary n-cube networks. Specifically, our results show that the g-good-neighbor\u00a0\u2026", "num_citations": "48\n", "authors": ["505"]}
{"title": "5\u2009G WiFi Signal-Based Indoor Localization System Using Cluster k-Nearest Neighbor Algorithm\n", "abstract": " Indoor localization based on existent WiFi signal strength is becoming more and more prevalent and ubiquitous. Unfortunately, the WiFi received signal strength (RSS) is susceptible by multipath, signal attenuation, and environmental changes, which is the major challenge for accurate indoor localization. To overcome these limitations, we propose the cluster k-nearest neighbor (KNN) algorithm with 5\u2009G WiFi signal to reduce the environmental interference and improve the localization performance without additional equipment. In this paper, we propose three approaches to improve the performance of localization algorithm. For one thing, we reduce the computation effort based on the coarse localization algorithm. For another, according to the detailed analysis of the 2.4\u2009G and 5\u2009G signal fluctuation, we expand the real-time measurement RSS before matching the fingerprint map. More importantly, we select the\u00a0\u2026", "num_citations": "48\n", "authors": ["505"]}
{"title": "Sodium tanshinone IIA silate inhibits oxygen\u2010glucose deprivation/recovery\u2010induced cardiomyocyte apoptosis via suppression of the NF\u2010\u03baB/TNF\u2010\u03b1 pathway\n", "abstract": " Background and Purpose Inhibition of apoptosis may attenuate the irreversible injury associated with reperfusion. In the current study, we focused on the cytoprotective effects and the underlying mechanism of sodium tanshinone IIA silate (STS) against damage induced by oxygen\u2010glucose deprivation/recovery (OGD/R). in H9c2 cardiomyocytes and the underlying mechanisms. Experimental Approach We used a model of cardiac ischaemia/reperfusion, OGD/R in H9c2 cardiomyocytes, to assess the cardioprotective effects of STS. Apoptosis of cells was measured with H oechst 33342\u2010based fluorescence microscopy, and annexin V\u2010FITC\u2010based flow cytometry. Caspase\u20103 and caspase\u20108 activities and mitochondrial membrane potential were also measured using commercial kits. TNF\u2010\u03b1 in the cell culture supernatant fractions were measured with sandwich elisa, and protein levels assayed using W estern blot. Key\u00a0\u2026", "num_citations": "48\n", "authors": ["505"]}
{"title": "An energy-efficient scheduling algorithm using dynamic voltage scaling for parallel applications on clusters\n", "abstract": " In the past decade cluster computing platforms have been widely applied to support a variety of scientific and commercial applications, many of which are parallel in nature. However, scheduling parallel applications on large scale clusters is technically challenging due to significant communication latencies and high energy consumption. As such, shortening schedule length and conserving energy consumption are two major concerns in designing economical and environmentally friendly clusters. In this paper, we propose an energy-efficient scheduling algorithm (TDVAS) using the dynamic voltage scaling technique to provide significant energy savings for clusters. The TDVAS algorithm aims at judiciously leveraging processor idle times to lower processor voltages (i.e., the dynamic voltage scaling technique or DVS), thereby reducing energy consumption experienced by parallel applications running on clusters\u00a0\u2026", "num_citations": "48\n", "authors": ["505"]}
{"title": "Framework for hyperspectral image processing and quantification for cancer detection during animal tumor surgery\n", "abstract": " Hyperspectral imaging (HSI) is an imaging modality that holds strong potential for rapid cancer detection during image-guided surgery. But the data from HSI often needs to be processed appropriately in order to extract the maximum useful information that differentiates cancer from normal tissue. We proposed a framework for hyperspectral image processing and quantification, which includes a set of steps including image preprocessing, glare removal, feature extraction, and ultimately image classification. The framework has been tested on images from mice with head and neck cancer, using spectra from 450- to 900-nm wavelength. The image analysis computed Fourier coefficients, normalized reflectance, mean, and spectral derivatives for improved accuracy. The experimental results demonstrated the feasibility of the hyperspectral image processing and quantification framework for cancer detection during\u00a0\u2026", "num_citations": "46\n", "authors": ["505"]}
{"title": "Adsorption of humic acid from aqueous solution by hematite: effects of pH and ionic strength\n", "abstract": " Batch experiments were conducted to investigate adsorption of humic acid (HA) on a commercial hematite. The point of zero charge (PZC) and specific surface area of hematite were 9.17\u00a0\u00b1\u00a00.25 and 5.22\u00a0\u00b1\u00a00.04\u00a0m2\u00a0g\u22121, respectively. The concentrations of HA in solutions were quantified by the ultraviolet\u2013visible spectrophotometer, and molecular weight (MW) was determined by E                 2/E                 3 (the ratio of absorbance at 250\u00a0nm (E                 2) and 365\u00a0nm (E                 3)) measurements of HA in solutions. The adsorption of HA on hematite was strongly dependent on solution pH. More HA was adsorbed at acidic conditions, which was also confirmed by Fourier transform infrared spectroscopy (FTIR) measurements. At pH <9, the E                 2/E                 3 of the HA remaining in solution after adsorption was higher than its initial value indicating that higher MW fractions of HA were preferentially\u00a0\u2026", "num_citations": "46\n", "authors": ["505"]}
{"title": "Communication-aware load balancing for parallel applications on clusters\n", "abstract": " Cluster computing has emerged as a primary and cost-effective platform for running parallel applications, including communication-intensive applications that transfer a large amount of data among the nodes of a cluster via the interconnection network. Conventional load balancers have proven effective in increasing the utilization of CPU, memory, and disk I/O resources in a cluster. However, most of the existing load-balancing schemes ignore network resources, leaving an opportunity to improve the effective bandwidth of networks on clusters running parallel applications. For this reason, we propose a communication-aware load-balancing technique that is capable of improving the performance of communication-intensive applications by increasing the effective utilization of networks in cluster environments. To facilitate the proposed load-balancing scheme, we introduce a behavior model for parallel applications\u00a0\u2026", "num_citations": "45\n", "authors": ["505"]}
{"title": "Performance comparisons of load balancing algorithms for I/O-intensive workloads on clusters\n", "abstract": " Load balancing techniques play a critically important role in developing high-performance cluster computing platforms. Existing load balancing approaches are concerned with the effective usage of CPU and memory resources. Due to imbalance in disk I/O resources under I/O-intensive workloads, the previous CPU- or memory-aware load balancing schemes suffer significant performance drop. To remedy this deficiency, in this paper we propose a novel load-balancing algorithm (hereinafter referred to as IOLB) for clusters, which aims at maintaining high resource utilization under a wide range of workload conditions. Specifically, IOLB is conducive to reducing the average slowdown of all parallel jobs submitted to a cluster by balancing load in disk resources. This can, in turn, not only achieve the effective usage of global disk resources but also reduce response times of I/O-intensive parallel jobs. To theoretically\u00a0\u2026", "num_citations": "45\n", "authors": ["505"]}
{"title": "Isomers of perfluorooctanesulfonate (PFOS) in cord serum and birth outcomes in China: Guangzhou Birth Cohort Study\n", "abstract": " Prior investigations on the associations of polyfluoroalkyl substances (PFASs) with fetal growth are mixed. Moreover, little research has accrued pertaining to the association between isomers of PFASs with gestational age and birth weight. To address this gap and present novel information, we conducted a study including 321 pairs of mothers and their infants recruited from Guangzhou, China. High performance liquid chromatography-mass spectrometry was utilized to analyze isomers of perfluorooctanesulfonate (PFOS), perfluorooctanoate (PFOA) along with other PFAS levels in cord serum samples. Mothers' and infants' characteristics were gathered from medical records. The resulting data revealed that higher PFOS, PFOA and isomers of PFOS were associated with lower birth weight. Per ln-unit (ng/mL) increase in cord serum total branched PFOS isomers was associated with a 126.3\u00a0g (95% CI: \u2212\u00a0195.9, \u2212\u00a056.8\u00a0\u2026", "num_citations": "44\n", "authors": ["505"]}
{"title": "Dynamic load balancing for I/O-intensive applications on clusters\n", "abstract": " Load balancing for clusters has been investigated extensively, mainly focusing on the effective usage of global CPU and memory resources. However, previous CPU- or memory-centric load balancing schemes suffer significant performance drop under I/O-intensive workloads due to the imbalance of I/O load. To solve this problem, we propose two simple yet effective I/O-aware load-balancing schemes for two types of clusters: (1) homogeneous clusters where nodes are identical and (2) heterogeneous clusters, which are comprised of a variety of nodes with different performance characteristics in computing power, memory capacity, and disk speed. In addition to assigning I/O-intensive sequential and parallel jobs to nodes with light I/O loads, the proposed schemes judiciously take into account both CPU and memory load sharing in the system. Therefore, our schemes are able to maintain high performance for a\u00a0\u2026", "num_citations": "44\n", "authors": ["505"]}
{"title": "Associations of serum perfluoroalkyl acid levels with T-helper cell-specific cytokines in children: By gender and asthma status\n", "abstract": " Perfluoroalkyl acids (PFAAs) are a group of common chemicals that ubiquitously exist in wildlife and humans. Experimental data suggest that they may alter T-lymphocyte functioning in situ by preferentially enhancing the development of T-helper 2 (TH2)- and inhibiting TH1-lymphocyte development and might increase allergic inflammation, but few human studies have been conducted. To evaluate the association between serum PFAAs concentrations and T-lymphocyte-related immunological markers of asthma in children, and further to assess whether gender modified this association, 231 asthmatic children and 225 non-asthmatic control children from Northern Taiwan were recruited into the Genetic and Biomarker study for Childhood Asthma. Serum concentrations of ten PFAAs and levels of TH1 [interferon (IFN)-\u03b3, interleukin (IL)-2] and TH2 (IL-4 and IL-5) cytokines were measured. The results showed that\u00a0\u2026", "num_citations": "43\n", "authors": ["505"]}
{"title": "Pharmacokinetic study of a novel sonosensitizer chlorin\u2010e6 and its sonodynamic anti\u2010cancer activity in hepatoma\u201022 tumor\u2010bearing mice\n", "abstract": " Purpose The sonodynamically induced anti\u2010tumor effect of chlorin\u2010e6 (Ce6) was studied in mice bearing hepatoma\u201022 solid tumors.  Methods In order to determine the optimum timing of ultrasound exposure after administration of Ce6, the Ce6 concentrations in plasma, skin, muscle and tumor were estimated by measuring the fluorescence intensity of tissue extractions with a fluorescence photometer based on the standard curve. A three\u2010dimensional optical imaging system (IVIS spectrum) was used further to characterize the distribution of Ce6 in H\u201022 tumor. The anti\u2010tumor effects were estimated by measuring tumor size after sonodynamic therapy.  Results Similar pharmacokinetic trends of Ce6 in mice were observed either by fluorescence spectrophotometry or by bio\u2010optical imaging. The results also demonstrated that Ce6 has a preferential localization in tumors, but low accumulation and rapid clearance in\u00a0\u2026", "num_citations": "43\n", "authors": ["505"]}
{"title": "Reliability-driven scheduling for real-time tasks with precedence constraints in heterogeneous systems\n", "abstract": " : Some work has been done in the past in scheduling tasks in real-time distributed systems, considering schedulability as the main objective function to be maximized. Since real-time distributed systems are more complex than centralized systems, the complexity of such system could increase the potential for system failures. This is even more pronounced in a heterogeneous system where processors operate at different speeds and communication channels have different bandwidths. Hence, reliability should also be regarded as the objective function to be maximized. In this paper, we describe a two-phase scheme to determine a scheduling of tasks with precedence constraints that employs a reliability measure as one of the objectives in a real-time and heterogeneous distributed system. We devise a new off-line scheduling of communicating tasks, based on the concept of reliability cost, to schedule real-time tasks for maximized reliability. The simulation results show that, for task graphs with precedence constraints in a heterogeneous distributed system, our heuristic performs significantly better than the two heuristics presented that do not consider reliabiliy cost. Furthermore, the results suggested that higher computational heterogeneity is conducive to improving the schedulability of the reliability cost-driven (RCD) algorithm, while the opposite is true for the two non-RCD algorithms. KEY WORDS: Reliability cost, Real-time, Scheduling, Heterogeneous distributed systems, Performance 1", "num_citations": "43\n", "authors": ["505"]}
{"title": "Efficient parallel skyline evaluation using MapReduce\n", "abstract": " This research develops an advanced two-phase MapReduce solution that is able to efficiently address skyline queries on large datasets. Unlike existing parallel skyline approaches, our scheme considers data partitioning, filtering, and parallel skyline evaluation as a holistic query process. In particular, we apply filtering techniques and angle-based partitioning in the first phase, in which unqualified objects are discarded and the processed objects are partitioned by their angles to the origin.In the second phase, local skyline objects in each partition are calculated in parallel, and global skyline objects are output after a merging skyline process. To improve the parallel local skyline calculation, we propose two partition-aware filtering methods that keep skyline candidates in a balanced manner. The aggressive partition-aware filtering aggressively eliminates objects in the partition with the greatest population of\u00a0\u2026", "num_citations": "42\n", "authors": ["505"]}
{"title": "Real-time fault-tolerant scheduling in heterogeneous distributed systems\n", "abstract": " Some works have been done in addressing real-time fault-tolerant scheduling algorithms. However, they all based on homogeneous distributed systems or multiprocessor systems, which have identical processors. This paper presents two fault-tolerant scheduling algorithms, RTFTNO and RTFTRC, for periodic real-time tasks in heterogeneous distributed systems. Reliability cost, a main performance metric, is applied. RTFTRC algorithm tries to minimize the reliability cost, while RTFTNO does not consider such metric. The results of the performance evaluation for two algorithms are discussed. Simulation experiments show that RTFTRC has better performance than RTFTNO.", "num_citations": "42\n", "authors": ["505"]}
{"title": "Design and analysis of a load balancing strategy in data grids\n", "abstract": " Developing Data Grids has increasingly become a major concern to make Grids attractive for a wide range of data-intensive applications. Storage subsystems are most likely to be a performance bottleneck in Data Grids and, therefore, the focus of this paper is to design and evaluate a data-aware load-balancing strategy to improve the global usage of storage resources in Data Grids. We build a model to estimate the response time of job running at a local site or remote site. In light of this model, we can calculate slowdowns imposed on jobs in a Data Grid environment. Next, we propose a load-balancing strategy that aims to balance load of a Data Grid in such a judicious way that computation and storage resources in each site are simultaneously well utilized. We conduct experiments using a simulated Data Grid to analyze the performance of the proposed strategy. Experimental results confirm that our load\u00a0\u2026", "num_citations": "40\n", "authors": ["505"]}
{"title": "Energy-aware duplication strategies for scheduling precedence-constrained parallel tasks on clusters\n", "abstract": " Optimizing energy consumption has become a major concern in designing economical clusters. Scheduling precedence-constrained parallel tasks on clusters is challenging because of high communication overhead. Although duplication-based strategies are applied to minimize communication overhead, most of them merely consider schedule lengths, completely ignoring energy consumption of clusters. In this regard, we propose two energy-aware duplication scheduling algorithms, called EADUS and TEBUS, to schedule precedence-constrained parallel tasks. Unlike existing duplication-based scheduling algorithms that replicate all possible predecessors of each task, the proposed algorithms judiciously replicate predecessors only if the duplication can help in conserving energy. Our energy-aware scheduling strategies are conducive to balancing the scheduling length and energy consumption of precedence\u00a0\u2026", "num_citations": "40\n", "authors": ["505"]}
{"title": "A dynamic load balancing scheme for I/O-intensive applications in distributed systems\n", "abstract": " In this paper, a new I/O-aware load-balancing scheme is presented to improve overall performance of a distributed system with a general and practical workload including I/O activities. The proposed scheme dynamically detects I/O load imbalance on nodes of a distributed system and determines whether to migrate the I/O requests of some jobs from overloaded nodes to other less- or under-loaded nodes, depending on data migration cost and remote I/O access overhead. Besides balancing I/O load, the scheme judiciously takes into account both CPU and memory load sharing in distributed systems, thereby maintaining the same level of performance as the existing schemes when I/O load is low or well balanced. Results from a trace-driven simulation study show that, compared with the existing schemes that only consider CPU and memory, the proposed scheme reduces the mean slowdown by up to 54.5% (with\u00a0\u2026", "num_citations": "40\n", "authors": ["505"]}
{"title": "Improved read performance in a cost-effective, fault-tolerant parallel virtual file system (ceft-pvfs)\n", "abstract": " Due to the ever-widening performance gap between processors and disks, I/O operations tend to become the major performance bottleneck of data-intensive applications on modern clusters. If all the existing disks on the nodes of a cluster are connected together to establish high performance parallel storage systems, the cluster's overall performance can be boosted at no additional cost. CEFT-PVFS (a RAID 10 style parallel file system that extends the original PVFS), as one such system, divides the cluster nodes into two groups, stripes the data across one group in a round-robin fashion, and then duplicates the same data to the other group to provide storage service of high performance and high reliability. Previous research has shown that the system reliability is improved by a factor of more than 40 with mirroring while maintaining a comparable write performance. This paper presents another benefit of CEFT\u00a0\u2026", "num_citations": "40\n", "authors": ["505"]}
{"title": "Distributed energy-efficient scheduling for data-intensive applications with deadline constraints on data grids\n", "abstract": " Although data duplications may be able to improve the performance of data-intensive applications on data grids, a large number of data replicas inevitably increase energy dissipation in storage resources on the data grids. In order to implement a data grid with high energy efficiency, we address in this study the issue of energy-efficient scheduling for data grids supporting real-time and data-intensive applications. Taking into account both data locations and application properties, we design a novel Distributed Energy-Efficient Scheduler (or DEES for short) that aims to seamlessly integrate the process of scheduling tasks with data placement strategies to provide energy savings. DEES is distributed in the essence - it can successfully schedule tasks and save energy without knowledge of a complete grid state. DEES encompasses three main components: energy-aware ranking, performance-aware scheduling, and\u00a0\u2026", "num_citations": "39\n", "authors": ["505"]}
{"title": "Association of perfluoroalkyl substances exposure with impaired lung function in children\n", "abstract": " Previous studies have demonstrated associations between serum levels of perfluoroalkyl substances (PFASs) and asthma or asthma related-biomarkers. However, no studies have reported a possible relationship between PFASs exposure and lung function among children. The objective of the present study is to test the association between PFASs exposure and lung function in children from a high exposure area by using a cross-sectional case-control study, which included 132 asthmatic children and 168 non-asthmatic controls recruited from 2009 to 2010 in the Genetic and Biomarkers study for Childhood Asthma. Structured questionnaires were administered face-to-face. Lung function was measured by spirometry. Linear regression models were used to examine the influence of PFASs on lung function. The results showed that asthmatics in our study had significantly higher serum PFAS concentrations than\u00a0\u2026", "num_citations": "38\n", "authors": ["505"]}
{"title": "Improving security of real-time wireless networks through packet scheduling [transactions letters]\n", "abstract": " Modern real-time wireless networks require high security level to assure confidentiality of information stored in packages delivered through wireless links. However, most existing algorithms for scheduling independent packets in real-time wireless networks ignore various security requirements of the packets. Therefore, in this paper we remedy this problem by proposing a novel dynamic security-aware packet-scheduling algorithm, which is capable of achieving high quality of security for realtime packets while making the best effort to guarantee realtime requirements (e.g., deadlines) of those packets. We conduct extensive simulation experiments to evaluate the performance of our algorithm. Experimental results show that compared with two baseline algorithms, the proposed algorithm can substantially improve both quality of security and real-time packet guarantee ratio under a wide range of workload characteristics.", "num_citations": "38\n", "authors": ["505"]}
{"title": "An energy-efficient framework for large-scale parallel storage systems\n", "abstract": " Huge energy consumption has become a critical bottleneck for further applying large-scale cluster systems to build new data centers. Among various components of a data center, storage subsystems are one of the biggest consumers of energy. In this paper, we propose a novel buffer-disk based framework for large-scale and energy-efficient parallel storage systems. To validate the efficiency of the proposed framework, a buffer-disk scheduling algorithm is designed and implemented. Our algorithm can provide more opportunities for underlying disk power management schemes to save energy by keeping a large number of idle data disks in sleeping mode as long as possible. The trace-driven simulation results based on a revised disksim simulator show that this new framework can significantly improves the energy efficiency of large-scale parallel storage systems.", "num_citations": "38\n", "authors": ["505"]}
{"title": "PLC-cache: Endurable SSD cache for deduplication-based primary storage\n", "abstract": " Data deduplication techniques improve cost efficiency by dramatically reducing space needs of storage systems. SSD-based data cache has been adopted to remedy the declining I/O performance induced by deduplication operations in the latency-sensitive primary storage. Unfortunately, frequent data updates caused by classical cache algorithms (e.g., FIFO, LRU, and LFU) inevitably slow down SSDs' I/O processing speed while significantly shortening SSDs' lifetime. To address this problem, we propose a new approach-PLC-Cache-to greatly improve the I/O performance as well as write durability of SSDs. PLC-Cache is conducive to amplifying the proportion of the Popular and Long-term Cached (PLC) data, which is infrequently written and kept in SSD cache in a long time period to catalyze cache hits, in an entire SSD written data set. PLC-Cache advocates a two-phase approach. First, non-popular data are\u00a0\u2026", "num_citations": "37\n", "authors": ["505"]}
{"title": "PARM: A power-aware message scheduling algorithm for real-time wireless networks\n", "abstract": " Real-time applications in wireless networks are emerging in multimedia product and design. However, conventional real-time message scheduling algorithms generally do not take energy efficiency into account when making scheduling decisions. In this paper, I address the issue of scheduling real-time messages in wireless networks subject to timing and power constraints. A novel message scheduling scheme, or PARM (Power-aware Real-time Message), is developed to generate optimal schedules that minimize both power consumption and the probability of missing deadlines for real-time messages. With a power-aware scheduling policy in place, the proposed PARM scheme is very energy efficient. In addition, I extended a power consumption model to calculate power consumption rates in accordance to message transmission rates. Experimental results show that PARM significantly improves the performance\u00a0\u2026", "num_citations": "37\n", "authors": ["505"]}
{"title": "A new allocation scheme for parallel applications with deadline and security constraints on clusters\n", "abstract": " Parallel applications with deadline and security constraints are emerging in various areas like education, information technology, and business. However, conventional job schedulers for clusters generally do not take security requirements of realtime parallel applications into account when making allocation decisions. In this paper, we address the issue of allocating tasks of parallel applications on clusters subject to timing and security constraints in addition to precedence relationships. A task allocation scheme, or TAPADS (task allocation for parallel applications with deadline and security constraints), is developed to find an optimal allocation that maximizes quality of security and the probability of meeting deadlines for parallel applications. In addition, we proposed mathematical models to describe a system framework, parallel applications with deadline and security constraints, and security overheads\u00a0\u2026", "num_citations": "37\n", "authors": ["505"]}
{"title": "Delayed consistency model for distributed interactive systems with real-time continuous media\n", "abstract": " The advanced multimedia and high-speed networks make distributed interactive systems more promising and practical. These systems are distributed systems, which allow many clients located in different locations to concurrently explore and interact with each other. The systems can be built either in the local area network (LAN), or the wide area network (WAN), such as the Internet. Operations issued at one site are immediately executed at the local sites for a good response time, and are propagated to other sites. One of the challenging issues raised in the systems is consistency maintenance. Such issue in the discrete interactive media has been studied in many literatures. However, the consistency maintenance scheme for discrete interactive media is not suitable for continuous media domain. This paper illustrates a consistency problem in continuous interactive media by a simple example. The absolute consistency model, a strong requirement, is suitable for LAN and results in a bad responsiveness in WAN. To make the model more practical for WAN, a new consistency model, named delayed consistency model (DCM), is proposed. In this model, if an operation on an object x is issued at site i, every site is required to execute the operation at a specified time. The essential idea behind the proposed model is that other sites are enforced to update the state at a certain amount of time later than site i does. Thus, other sites will finally view the same state of x as that of site i. The DCM model is flexible, since it is unnecessary for all sites to have the identical delayed time. In case that the system is based on a real-time network, another advantage of\u00a0\u2026", "num_citations": "37\n", "authors": ["505"]}
{"title": "Two new anthraquinones with antiviral activities from the barks of Morinda citrifolia (Noni)\n", "abstract": " Two new anthraquinones, 1,3-dihydroxy-5-methoxy-6-methoxymethyl-2-methyl-9,10-anthraquinone (1) and 1,3-dihydroxy-5-methoxy-2,6-bismethoxymethyl-9,10-anthraquinone (2), together with ten known anthraquinone derivatives (3\u201312), three coumarin derivatives (13\u201315), and 6-gingerol (16) were isolated from the barks of Morinda citrifolia (Noni) collected in the Yongxing island of Xisha. The structures of compounds (1\u201316) were determined on the basis of extensive spectroscopic analyses, as well as by comparison with literature reports. The new compounds 1 and 2 were tested for their antiviral, cytotoxic, and antibacterial activities. In the primary bioassays, compounds 1 and 2 displayed weak anti-H1N1 activity with IC50 values of 66.1 and 10.5\u00a0\u03bcM, respectively. In addition, compound 2 showed weak anti-H3N2 activity with IC50 value of 11.5\u00a0\u03bcM, and had weak antimicrobial activity against Staphylococcus\u00a0\u2026", "num_citations": "36\n", "authors": ["505"]}
{"title": "A high-level energy consumption model for heterogeneous data centers\n", "abstract": " Data centers consume anywhere between 1.7% and 2.2% of the United States\u2019 power. A handful of studies focused on ways of predicting power consumption of computing platforms based on performance events counters. Most of existing power-consumption models retrieve performance counters from hardware, which offer accurate measurement of energy dissipation. Although these models were verified on several machines with specific CPU chips, it is difficult to deploy these models into data centers equipped by heterogeneous computing platforms. While models based on resource utilization via OS monitoring tools can be used in heterogeneous data centers, most of these models were linear model. In this paper, we analyze the accuracy of linear models with the SPECpower benchmark results, which is a widely adopted benchmark to evaluate the power and performance characteristics of servers. There are\u00a0\u2026", "num_citations": "36\n", "authors": ["505"]}
{"title": "Phosphorylated SATB1 is associated with the progression and prognosis of glioma\n", "abstract": " Special AT-rich sequence-binding protein 1 (SATB1) is a global chromatin organizer and gene regulator, and high expression of SATB1 is associated with progression and poor prognosis in several malignancies. Here, we examine the expression pattern of SATB1 in glioma. Microarray analysis of 127 clinical samples showed that SATB1 mRNA was expressed at lower levels in highly malignant glioblastoma multiforme (GBM) than in low-grade glioma and normal brain tissue. This result was further confirmed by real-time RT-PCR in the clinical samples, three GBM cell lines, primary SU3 glioma cells and tumor cells harvested by laser-capture microdissection. Consistent with the mRNA levels, SATB1 protein expression was downregulated in high-grade glioma, as shown by western blotting. However, phospho-SATB1 levels showed an opposite pattern, with a significant increase in these tumors\u00a0\u2026", "num_citations": "36\n", "authors": ["505"]}
{"title": "Research on scheduling scheme for Hadoop clusters\n", "abstract": " In this paper, we import a prefetching mechanism into MapReduce model while retaining compatibility with the native Hadoop. Given a data-intensive application running on a Hadoop MapReduce cluster, our approach estimates the execution time of each task and adaptively preloads an amount of data to the memory before the new task is assigned to the computing node. We implement a predictive schedule and prefetching (PSP) mechanism, which is integrated into the native MapReduce runtime system. We also evaluate performance on a 10-node cluster using two popular benchmarks\u2013grep and wordcount. The PSP mechanism reduces the execution time of grep and wordcount up to 28% with an average of 19%. Moreover, the PSP model increases the overall throughput and improves the I/O utilization. Because of the limitation of length, we did not present the experiment result detail in this paper.", "num_citations": "36\n", "authors": ["505"]}
{"title": "Exploiting redundancies to enhance schedulability in fault-tolerant and real-time distributed systems\n", "abstract": " In the past decades, distributed systems have been widely applied to real-time applications, most of which have fault-tolerance requirements to assure high reliability. Due to the stringent space constraints of real-time systems, the issue of schedulability becomes a major concern in the design of fault-tolerant and real-time distributed systems. Most existing real-time and fault-tolerant scheduling algorithms, which are based on the primary-backup scheme for periodic real-time tasks, introduce unnecessary redundancies by aggressively using active-backup copies. To solve this problem, we propose two novel fault-tolerant techniques, which are seamlessly integrated with fixed-priority-based scheduling algorithms. These techniques leverage redundancies to enhance schedulability in fault-tolerant and real-time distributed systems. Our fault-tolerant techniques make use of the primary-backup scheme to tolerate\u00a0\u2026", "num_citations": "36\n", "authors": ["505"]}
{"title": "Design, implementation, and performance evaluation of a cost-effective fault-tolerant parallel virtual file system\n", "abstract": " Fault tolerance is one of the most important issues for parallel file systems. This paper presents the design, implementation and performance evaluation of a cost-effective, faulttolerant parallel virtual file system (CEFT-PVFS) that provides parallel I/O service without requiring any additional hardware by utilizing existing commodity disks on cluster nodes and incorporates fault tolerance in the form of disk mirroring. While mirroring is a straightforward idea, we have implemented this open source system and conducted extensive experiments to evaluate the feasibility, efficiency and scalability of this fault tolerant approach on one of the current largest clusters, where the issues of data consistency and recovery are also investigated. Four mirroring protocols are proposed, reflecting whether the fault-tolerant operations are client driven or server driven; synchronous or asynchronous. Their relative merits are assessed by comparing their write performances, measured in the real systems, and their reliability and availability measures, obtained through analytical modeling. The results indicate that, in cluster environments, mirroring can improve the reliability by a factor of over 40 (4000%) while sacrificing the peak write performance by 33-58% when both systems are of identical sizes (ie, counting the 50% mirroring disks in the mirrored system). In addition, protocols with higher peak write performance are less reliable than those with lower peak write performance, with the latter achieving a higher reliability and availability at the expense of some write bandwidth. A hybrid protocol is proposed to optimize this tradeoff.", "num_citations": "36\n", "authors": ["505"]}
{"title": "Positive associations of serum perfluoroalkyl substances with uric acid and hyperuricemia in children from Taiwan\n", "abstract": " To investigate the risk of hyperuricemia in relation to Perfluoroalkyl substances (PFASs) in children from Taiwan, 225 Taiwanese children aged 12\u201315\u00a0years were recruited from 2009 to 2010. Linear and logistic regression models were employed to examine the influence of PFASs on serum uric acid levels. Findings revealed that eight of ten PFASs analyses were detected in >94% of the participants' serum samples. Multivariate linear regression models revealed that perfluorooctanic acid (PFOA) was positively associated with serum uric acid levels (\u03b2\u00a0=\u00a00.1463, p\u00a0<\u00a00.05). Of all the PFASs analyses, only PFOA showed a significant effect on elevated levels of hyperuricemia (aOR\u00a0=\u00a02.16, 95%CI: 1.29\u20133.61). When stratified by gender, the association between serum PFOA and uric acid levels was only evident among boys (aOR\u00a0=\u00a02.76, 95%CI: 1.37\u20135.56). In conclusion, PFOA was found to be associated with elevated\u00a0\u2026", "num_citations": "35\n", "authors": ["505"]}
{"title": "Clog-free cell filtration using resettable cell traps\n", "abstract": " The separation of cells by filtration through microstructured constrictions is limited by clogging and adsorption, which reduce selectivity and prevent the extraction of separated cells. To address this key challenge, we developed a mechanism for simply and reliably adjusting the cross-section of a microfluidic channel to selectively capture cells based on a combination of size and deformability. After a brief holding period, trapped cells can then be released back into flow, and if necessary, extracted for subsequent analysis. Periodically clearing filter constrictions of separated cells greatly improves selectivity and throughput, and minimizes adsorption of cells to the filter microstructure. This mechanism is capable of discriminating cell-sized polystyrene microspheres with <1 \u03bcm resolution. Rare cancer cells doped into leukocytes can be enriched ~1800\u00d7 with ~90% yield despite a significant overlap in size between these\u00a0\u2026", "num_citations": "35\n", "authors": ["505"]}
{"title": "Scale-RS: An efficient scaling scheme for RS-coded storage clusters\n", "abstract": " It is indispensable to scale erasure-coded storage clusters to meet requirements of increased storage capacity and I/O performance. In this study, we propose an efficient scaling scheme for Reed-Solomon-coded storage clusters called Scale-RS, which has three salient features. First, Scale-RS achieves uniform data distribution by equally placing data blocks among old and new chunks using a transposed data layout. Second, Scale-RS minimizes data movement incurred in the procedures of data redistribution and parity update. Scale-RS not only reaches the lower bound of data migration traffic by transferring necessary data blocks from old data chunks to new chunks, but it also reduces update traffic via generating parity difference blocks from data blocks stored in an individual data chunk. Third, Scale-RS improves the I/O performance of scaled storage clusters in terms of read parallelism and write throughput\u00a0\u2026", "num_citations": "34\n", "authors": ["505"]}
{"title": "A prefetching scheme for energy conservation in parallel disk systems\n", "abstract": " Large-scale parallel disk systems are frequently used to meet the demands of information systems requiring high storage capacities. A critical problem with these large-scale parallel disk systems is the fact that disks consume a significant amount of energy. To design economically attractive and environmentally friendly parallel disk systems, we developed two energy-aware prefetching strategies for parallel disk systems with disk buffers. First, we introduce a new buffer disk architecture that can provide significant energy savings for parallel disk systems while achieving high performance. Second, we design a prefetching approach to utilize an extra disk to accommodate prefetched data sets that are frequently accessed. Third, we develop a second prefetching strategy that makes use of an existing disk in the parallel disk system as a buffer disk. Compared with the first prefetching scheme, the second approach lowers\u00a0\u2026", "num_citations": "34\n", "authors": ["505"]}
{"title": "Cache-efficient memory layout of aggregate data structures\n", "abstract": " We describe an important memory optimization that arises in the presence of aggregate data structures such as arrays and structs in a C/C++ based system design methodology. We present an algorithm for determining an optimized memory layout of such data. Our implementation consists of a pointer analysis and resolution phase, followed by memory layout optimization. Experiments on typical applications from the DSP domain result in up to 44% improvement in memory performance.", "num_citations": "33\n", "authors": ["505"]}
{"title": "Sex-specific difference of the association between ambient air pollution and the prevalence of obesity in Chinese adults from a high pollution range area: 33 communities\u00a0\u2026\n", "abstract": " Experimental data suggests that exposure to airborne fine particulate matter is associated with obesity. There is little supporting epidemiologic evidence of this, however. To evaluate the effects of ambient air pollution on the prevalence of obesity among adults living in a primarily industrial province of northeast China, 24,845 Chinese adults between the ages of 18 and 74 were randomly recruited from 33 communities in 11 districts of three northeastern Chinese cities during 2009. The participants\u2019 weight and height were measured. Three-year (2006\u20132008) average concentrations of particles with an aerodynamic diameter \u226410\u00a0\u03bcm (PM10), sulfur dioxide (SO2), nitrogen dioxide (NO2), and ozone (O3) were calculated from monitoring stations in each of the 11 districts. Two-level logistic regressions models were used to examine the effects of pollutants exposure. Overall, 35.3% (8764) were overweight and 5.8\u00a0\u2026", "num_citations": "31\n", "authors": ["505"]}
{"title": "Fractionation and kinetic processes of humic acid upon adsorption on colloidal hematite in aqueous solution with phosphate\n", "abstract": " Batch experiments were carried out to investigate fractionation and kinetics of humic acid (HA) during adsorption onto hematite and the effect of phosphate. The concentrations and weight-average molecular weight (Mw) of HA in solution were determined by total organic carbon (TOC) analyzer and high-performance size exclusion chromatography (HPSEC). Addition of phosphate (simultaneously or beforehand) decreased HA adsorption due to competition. Fractions of HA with Mw values larger than 4000\u00a0Da were preferably adsorbed. The adsorption kinetics can be described with Pseudo-second order model or Elovich kinetic model. Fractions of HA with relatively low Mw (3000\u20134000\u00a0Da) were quickly adsorbed in the first hour, and then were replaced slowly by larger ones (>5000\u00a0Da). This phenomenon could be explained by fast diffusion of relatively small HA particles from solution to mineral surface, but the\u00a0\u2026", "num_citations": "31\n", "authors": ["505"]}
{"title": "Energy-aware loop parallelism maximization for multi-core DSP architectures\n", "abstract": " With the advance of semiconductor, multi-core architecture is inevitable in today's embedded system design. Nested loops are usually the most critical part in multimedia and high performance DSP (Digital Signal Processing) systems. Hence, maximizing loop parallelism is an important issue to improve the performance of a modern compiler. This paper studies how to maximize the system performance with the consideration of energy reduction for applications with multidimensional nested loops on multi-core DSP architectures. An algorithm, EALPM (Energy-Aware Loop Parallelism Maximization), is proposed in this paper. We implemented a two phase strategy. First, the strategy uses retiming and loop transformation to parallelize nested loops. Then the strategy employs a novel voltage assignment algorithm to reduce total energy consumption. The experimental results show that on average, both performance and\u00a0\u2026", "num_citations": "31\n", "authors": ["505"]}
{"title": "An automatic prefetching and caching system\n", "abstract": " Steady improvements in storage capacities and CPU clock speeds intensify the performance bottleneck at the I/O subsystem of modern computers. Caching data can efficiently short circuit costly delays associated with disk accesses. Recent studies have shown that disk I/O performance gains provided by a cache buffer do not scale with cache size. Therefore, new algorithms have to be investigated to better utilize cache buffer space. Predictive prefetching and caching solutions have been shown to improve I/O performance in an efficient and scalable manner in simulation experiments. However, most predictive prefetching algorithms have not yet been implemented in real-world storage systems due to two main limitations: first, the existing prefetching solutions are unable to self regulate based on changing I/O workload; second, excessive number of unneeded blocks are prefetched. Combined, these drawbacks\u00a0\u2026", "num_citations": "31\n", "authors": ["505"]}
{"title": "Fault-tolerant scheduling based on periodic tasks for heterogeneous systems\n", "abstract": " Most existing real-time fault-tolerant scheduling algorithms for heterogeneous distributed systems can achieve high reliability for non-preemptive and aperiodic tasks. However, the existing scheduling algorithms assume that status of each backup copy is either active or passive. To remedy this deficiency, we propose a novel reliability model tailored for preemptive periodic tasks. Next, we develop two real-time fault-tolerant algorithms (NRFTAHS and RDFTAHS) for heterogeneous distributed systems. NRFTAHS manages to assign tasks in a way to improve system schedulabilties, whereas RDFTAHS aims at boosting system reliability without adding extra hardware. Unlike the existing scheduling schemes, our algorithms consider backup copies in both active and passive forms. Therefore, our approaches are more flexible than the alternative ones. Finally, we quantitatively compare our schemes with two\u00a0\u2026", "num_citations": "31\n", "authors": ["505"]}
{"title": "Solving energy-latency dilemma: task allocation for parallel applications in heterogeneous embedded systems\n", "abstract": " Parallel applications with energy and low-latency constraints are emerging in various networked embedded systems like digital signal processing, vehicle tracking, and infrastructure monitoring. However, conventional energy-driven task allocation schemes for a cluster of embedded nodes only concentrate on energy-saving when making allocation decisions. Consequently, the length of the schedules could be very long, which is unfavorable or in some situations even not tolerated. In this paper, we address the issue of allocating a group of parallel tasks on a heterogeneous embedded system with an objective of energy-saving and short-latency. A novel task allocation strategy, or BEATA (balanced energy-aware task allocation), is developed to find an optimal allocation that minimizes overall energy consumption while confining the length of schedule to an ideal range. Experimental results show that BEATA\u00a0\u2026", "num_citations": "31\n", "authors": ["505"]}
{"title": "Design and synthesis of novel soluble 2, 5-diketopiperazine derivatives as potential anticancer agents\n", "abstract": " Non-protected 2,5-diketopiperazine derivatives have poor solubility thus with negative impact on their bioavailability. In the present study, twenty-one novel soluble mono-protected, and three non-protected 2,5-diketopiperazine derivatives were designed and synthesized. Their anticancer activity to ten cell lines were evaluated by using CCK8 assay, and the results showed that about half of the mono-protected derivatives had broad-spectrum anticancer activity. Among allyl-protected derivatives, compound 4m had strong activity to all the cell lines (IC50\u00a0=\u00a00.5\u20134.5\u00a0\u03bcM), especially to the cancer cell lines U937 (IC50\u00a0=\u00a00.5\u00a0\u03bcM) and K562 (IC50\u00a0=\u00a00.9\u00a0\u03bcM). Compound 4m could become a lead compound for further development for anticancer agents.", "num_citations": "30\n", "authors": ["505"]}
{"title": "Dynamic load balancing for I/O-and memory-intensive workload in clusters using a feedback control mechanism\n", "abstract": " One common assumption of the existing models of load balancing is that the weights of resources and I/O buffer size are statically configured. Though the static configuration of these parameters performs well in a cluster where the workload can be predicted, its performance is poor in dynamic systems where the workload is unknown. In this paper, a new feedback control mechanism is proposed to improve the overall performance of a cluster with I/O-intensive and memory-intensive workload. The mechanism dynamically adjusts the resource weights as well as the I/O buffer size. Results from a trace-driven simulation show that this mechanism is effective in enhancing the performance of a number of existing load-balancing schemes.", "num_citations": "30\n", "authors": ["505"]}
{"title": "A relevant subspace based contextual outlier mining algorithm\n", "abstract": " For high-dimensional and massive data sets, a relevant subspace based contextual outlier detection algorithm is proposed. Firstly, the relevant subspace, which can effectively describe the local distribution of the various data sets, is redefined by using local sparseness of attribute dimensions. Secondly, a local outlier factor calculation formula in the relevant subspace is defined with probability density of local data sets, and the formula can effectively reflect the outlier degree of data object that does not obey the distribution of the local data set in the relevant subspace. Thirdly, attribute dimensions of constituting the relevant subspace and local outlier factor are defined as the contextual information, which can improve the interpretability and comprehensibility of outlier. Fourthly, the selection of N data objects with the greatest local outlier factor value is defined as contextual outliers. In the end, experimental results\u00a0\u2026", "num_citations": "29\n", "authors": ["505"]}
{"title": "Modeling of levofloxacin adsorption to goethite and the competition with phosphate\n", "abstract": " Interaction between various compounds in natural systems may influence the adsorption of these species and their environmental fate. In this work, we studied the interactions between a widely used antibiotic levofloxacin (LEV) and phosphate at the surface of goethite (\u03b1-FeOOH), which was important to better understand the competitive adsorption of antibiotics and oxyanions in natural systems. The presence of phosphate decreased LEV adsorption to goethite significantly over the whole pH range. The other way around, LEV had a little influence on phosphate adsorption. Eight types of LEV\u2013goethite complexes were proposed and modeled in our study. Electrostatic competition was the main reason for the competition of binary components (LEV and phosphate) to goethite surface. Adsorption of single component (LEV or phosphate) to goethite was well predicted using the CD-MUSIC (Charge Distribution Multi\u00a0\u2026", "num_citations": "29\n", "authors": ["505"]}
{"title": "Pre-bud: Prefetching for energy-efficient parallel i/o systems with buffer disks\n", "abstract": " A critical problem with parallel I/O systems is the fact that disks consume a significant amount of energy. To design economically attractive and environmentally friendly parallel I/O systems, we propose an energy-aware prefetching strategy (PRE-BUD) for parallel I/O systems with disk buffers. We introduce a new architecture that provides significant energy savings for parallel I/O systems using buffer disks while maintaining high performance. There are two buffer disk configurations: (1) adding an extra buffer disk to accommodate prefetched data, and (2) utilizing an existing disk as the buffer disk. PRE-BUD is not only able to reduce the number of power-state transitions, but also to increase the length and number of standby periods. As such, PRE-BUD conserves energy by keeping data disks in the standby state for increased periods of time. Compared with the first prefetching configuration, the second configuration\u00a0\u2026", "num_citations": "29\n", "authors": ["505"]}
{"title": "Energy efficient scheduling for parallel applications on mobile clusters\n", "abstract": " During the past decade, cluster computing and mobile communication technologies have been extensively deployed and widely applied because of their giant commercial value. The rapid technological advancement makes it feasible to integrate these two technologies and a revolutionary application called mobile cluster computing is arising on the horizon. Mobile cluster computing technology can further enhance the power of our laptops and mobile devices by running parallel applications. However, scheduling parallel applications on mobile clusters is technically challenging due to the significant communication latency and limited battery life of mobile devices. Therefore, shortening schedule length and conserving energy consumption have become two major concerns in designing efficient and energy-aware scheduling algorithms for mobile clusters. In this paper, we propose two novel scheduling\u00a0\u2026", "num_citations": "29\n", "authors": ["505"]}
{"title": "Dynamic task scheduling with security awareness in real-time systems\n", "abstract": " An increasing number of real-time applications, such as aircraft control and medical electronics systems, require high quality of security to assure confidentiality, authenticity and integrity of information. However, most existing algorithms for scheduling independent tasks in real-time systems do not adequately consider security requirements of real-time tasks. In recognition of this problem we propose a novel dynamic scheduling algorithm with security awareness, which is capable of achieving high quality of security for real-time tasks while improving resource utilization. We have conducted extensive simulation experiments to quantitatively evaluate the performance of our approach. Specifically, experimental results show that compared with three heuristic algorithms, the proposed algorithm can consistently improve overall system performance in terms of quality of security and system guarantee ratio under a wide\u00a0\u2026", "num_citations": "29\n", "authors": ["505"]}
{"title": "Data Grids: Supporting data-intensive applications in wide area networks\n", "abstract": " A data grid is a collection of geographically dispersed storage resources over wide area network. The goal of data grid system is to provide a large virtual storage framework with unlimited power through collaboration among individuals, institutions, and resources. In this study, we first review a number of data grid services such as, to just name a few, metadata service, data access service, and performance measurement service. We then investigate various techniques for boosting the performance of data grid, and these key techniques have fallen into three camps, namely, data replication, scheduling, and data movement. Since security issue becomes one of the prime concerns in grid computing, we review two interesting issues of security in data grid. Finally and importantly, we have identified five interesting open issues, and pointed out some potential solutions to the open problems.", "num_citations": "29\n", "authors": ["505"]}
{"title": "Scalable Kernel Density Estimation-based Local Outlier Detection over Large Data Streams.\n", "abstract": " Local outlier techniques are known to be effective for detecting outliers in skewed data, where subsets of the data exhibit diverse distribution properties. However, existing methods are not well equipped to support modern high-velocity data streams due to the high complexity detection algorithms and their volatility to data updates. To tackle these shortcomings, we propose new local outlier semantics that leverage kernel density estimation (KDE) to effectively detect local outliers from streaming data. A strategy to continuously detect top-N KDE-based local outliers over streams is also designed, called KELOS\u2013the first linear time complexity streaming local outlier detection approach. The first innovation of KELOS is the abstract kernel center-based KDE (aKDE) model. aKDE accurately while efficiently estimates the data density at each point\u2013essential ingredient for local outlier detection. This is based on the observation that a cluster of points close to each other tend to have a similar influence on a target point\u2019s density estimation when used as kernel centers. These points thus can be represented by one abstract kernel center. Next, the KELOS\u2019s inlier pruning strategy early prunes points that have no chance to become top-N outliers. This empowers KELOS to skip the computation of the data density and then the outlier status for every data point. Together aKDE and the inlier pruning strategy eliminate the performance bottleneck of streaming local outlier detection. The experimental evaluation demonstrates that KELOS is up to 3 orders of magnitude faster than existing solutions, while still being highly effective in detecting local outliers from streaming\u00a0\u2026", "num_citations": "27\n", "authors": ["505"]}
{"title": "Adverse drug event detection from electronic health records using hierarchical recurrent neural networks with dual-level embedding\n", "abstract": " Introduction                 Adverse drug event (ADE) detection is a vital step towards effective pharmacovigilance and prevention of future incidents caused by potentially harmful ADEs. The electronic health records (EHRs) of patients in hospitals contain valuable information regarding ADEs and hence are an important source for detecting ADE signals. However, EHR texts tend to be noisy. Yet applying off-the-shelf tools for EHR text preprocessing jeopardizes the subsequent ADE detection performance, which depends on a well tokenized text input.                                               Objective                 In this paper, we report our experience with the NLP Challenges for Detecting Medication and Adverse Drug Events from Electronic Health Records (MADE1.0), which aims to promote deep innovations on this subject. In particular, we have developed rule-based sentence and word tokenization techniques to deal\u00a0\u2026", "num_citations": "27\n", "authors": ["505"]}
{"title": "Effects of natural organic matter with different properties on levofloxacin adsorption to goethite: experiments and modeling\n", "abstract": " Adsorption of levofloxacin (LEV) to goethite in the pH range of 3\u201310, and in the absence or presence of natural organic matter (NOM) represented by nine types of humic acid (HA) and fulvic acid (FA), was studied using batch experiments. The adsorption of LEV to goethite was weak and showed a maximum around pH 5.8. Adding NOM to goethite strongly increased LEV adsorption to goethite, but hardly affected its pH dependency. The adsorption envelopes were well fitted to a linear additive model, in which LEV adsorption to goethite was simulated with the Charge Distribution Multi-Site Complexation (CD-MUSIC) model, and LEV adsorption to NOM was simulated with the Langmuir model. The fitted affinity constants (log K) for LEV adsorption to NOM were significantly and positively correlated with the SUVA (specific ultraviolet absorbance at 280\u202fnm) values of NOM, and negatively correlated with E2/E3\u00a0\u2026", "num_citations": "27\n", "authors": ["505"]}
{"title": "MicroRNA-155 deficiency promotes nephrin acetylation and attenuates renal damage in hyperglycemia-induced nephropathy\n", "abstract": " MiR-155 has been reported to be involved in both innate and adaptive immune responses. But the role of miR-155 in hyperglycemia-induced nephropathy is still unknown. In our current study, 3-month-old male wild-type C57 mice and Mir-155\u2212/\u2212 mice were used to establish hyperglycemia-induced nephropathy. In our hyperglycemia-induced nephropathy model, the expression of podocyte injury marker desmin was markedly increased in the diabetes group when compared with control. Diabetes also significantly decreased the levels of nephrin and acetylated nephrin, whereas the expression of miR-155 was markedly increased in diabetes group when compared with control. MiR-155\u2212/\u2212 mice showed significantly increased expression of nephrin, acetylated nephrin, and Wilm\u2019s tumor-1 protein (WT-1) when compared with wild-type control. MiR-155 deficiency results in significantly decrease in IL-17A\u00a0\u2026", "num_citations": "27\n", "authors": ["505"]}
{"title": "An outlier mining algorithm based on constrained concept lattice\n", "abstract": " Traditional outlier mining methods identify outliers from a global point of view. These methods are inefficient to find locally biased data points (outliers) in low dimensional subspaces. Constrained concept lattices can be used as an effective formal tool for data analysis because constrained concept lattices have the characteristics of high constructing efficiency, practicability and pertinency. In this paper, we propose an outlier mining algorithm that treats the intent of any constrained concept lattice node as a subspace. We introduce sparsity and density coefficients to measure outliers in low dimensional subspaces. The intent of any constrained concept lattice node is regarded as a subspace, and sparsity subspaces are searched by traversing the constrained concept lattice according to a sparsity coefficient threshold. If the intent of any father node of the sparsity subspace is a density subspace according to a density\u00a0\u2026", "num_citations": "27\n", "authors": ["505"]}
{"title": "Energy-aware prefetching for parallel disk systems: Algorithms, models, and evaluation\n", "abstract": " Parallel disk systems consume a significant amount of energy due to the large number of disks. To design economically attractive and environmentally friendly parallel disk systems, in this paper we design and evaluate an energy-aware prefetching strategy for parallel disk systems consisting of a small number of buffer disks and large number of data disks. Using buffer disks to temporarily handle requests for data disks, we can keep data disks in the low-power mode as long as possible. Our prefetching algorithm aims to group many small idle periods in data disks to form large idle periods, which in turn allow data disks to remain in the standby state to save energy. To achieve this goal, we utilize buffer disks to aggressively fetch popular data from regular data disks into buffer disks, thereby putting data disks into the standby state for longer time intervals. A centrepiece in the prefetching mechanism is an energy\u00a0\u2026", "num_citations": "27\n", "authors": ["505"]}
{"title": "DDT, DDD, and DDE in soil of Xiangfen County, China: residues, sources, spatial distribution, and health risks\n", "abstract": " We collected and analyzed 128 surface soil samples from Xiangfen County for dichlorodiphenyltrichloroethane (DDT), dichlorodiphenyldichloroethane (DDD), and dichlorodiphenyldichloroethylene (DDE). Total DDT concentrations (DDTs; sum of p,p\u2032-DDD, p,p\u2032-DDE, and p,p\u2032-DDT) ranged from ND to 427.81\u00a0ng\u00a0g\u22121 (dry weight, dw), with a mean of 40.26\u00a0ng\u00a0g\u22121 (dw). Among the three compounds, p,p\u2032-DDD was the most dominant. The DDTs in Xiangfen County soils mainly originated from historical DDT use, but there were also new inputs likely related to dicofol use. The DDTs in Xiangfen County soils were mainly degraded under anaerobic conditions, and direct degradation to DDD was the main degradation route. Regions with relatively high concentrations of DDTs were mainly located in North and South Xiangfen County. In these regions, many soil samples contained p,p\u2032-DDT as the predominant\u00a0\u2026", "num_citations": "26\n", "authors": ["505"]}
{"title": "Fractionation of humic acid upon adsorption to goethite: Batch and column studies\n", "abstract": " The fractionation and replacement of humic acid (HA) during its interactions with goethite (or goethite-coated sand) were conducted using batch and column experiments. The weight-average molecular weight (Mw) of HA in solutions was determined by a high performance size exclusion chromatography (HPSEC). The E2/E3 (absorbance ratio at 250\u00a0nm and 365\u00a0nm) and specific ultraviolet absorbance (SUVA) of HA at 280\u00a0nm were measured with a UV\u2013visible spectrophotometer and a total organic carbon (TOC) analyzer, respectively. The results indicated that HA adsorption on goethite was a fast process, and HA fractions with higher Mw and lower aromaticity were preferentially adsorbed to goethite. Kinetic experiments demonstrated that HA fractions with relatively higher Mw and aromaticity were firstly adsorbed onto the surface of goethite, and then they were replaced by lower ones in solutions, which were also\u00a0\u2026", "num_citations": "26\n", "authors": ["505"]}
{"title": "Fault-tolerant scheduling for real-time tasks on multiple earth-observation satellites\n", "abstract": " Fault-tolerance plays an important role in improving the reliability of multiple earth-observing satellites, especially in emergent scenarios such as obtaining photographs on battlefields or earthquake areas. Fault tolerance can be implemented through scheduling approaches. Unfortunately, little attention has been paid to fault-tolerant scheduling on satellites. To address this issue, we propose a novel dynamic fault-tolerant scheduling model for real-time tasks running on multiple observation satellites. In this model, the primary-backup policy is employed to tolerate one satellite's permanent failure at one time instant. In the light of the fault-tolerant model, we develop a novel fault-tolerant satellite scheduling algorithm named FTSS. To improve the resource utilization, we apply the overlapping technology that includes primary-backup copy overlapping (i.e., PB overlapping) and backup-backup copy overlapping (i.e., BB\u00a0\u2026", "num_citations": "26\n", "authors": ["505"]}
{"title": "Measuring and analyzing write amplification characteristics of solid state disks\n", "abstract": " Write amplification brings endurance challenges to NAND Flash-based solid state disks (SSDs) such as impacts upon their write endurance and lifetime. A large write amplification degrades program/erase cycles (P/Es) of NAND Flashes and reduces the endurance and performance of SSDs. The write amplification problem is mainly triggered by garbage collections, wear-leveling, metadata updates, and mapping table updates. Write amplification is defined as the ratio of data volume written by an SSD controller to data volume written by a host. In this paper, we propose a four-level model of write amplification for SSDs. The four levels considered in our model include the channel level, chip level, die level, and plane level. In light of this model, we design a method of analyzing write amplification of SSDs to trace SSD endurance and performance by incorporating the Ready/Busy (R/B) signal of NAND Flash. Our\u00a0\u2026", "num_citations": "26\n", "authors": ["505"]}
{"title": "A case study of parallel I/O for biological sequence search on linux clusters\n", "abstract": " In this work, we investigate parallel I/O efficiencies in parallelised BLAST, the most popular tool for searching similarity in biological databases and implement two variations by incorporating the PVFS and CEFT-PVFS parallel I/O facilities. Our goal is to study the performance gain from parallel I/O under the constraints of different numbers of commodity storage devices in a Linux cluster. We also evaluate two read performance optimisation techniques employed in CEFT-PVFS: (1) doubling the degree of parallelism is shown to have comparable read performance with respect to PVFS when both systems have the same number of servers; (2) skipping hot-spot nodes can reduce the performance penalty when I/O workloads are highly imbalanced. The I/O resource contention between multiple applications, running in the same cluster, can degrade the performance of the original parallel BLAST and the PVFS version up\u00a0\u2026", "num_citations": "26\n", "authors": ["505"]}
{"title": "Real-Time scheduling with fault-tolerance in heterogeneous distributed systems\n", "abstract": " BackgroundTwo real time scheduling algorithms, RTFTNO and RTFTRC are presented, which are able to map tasks onto processors and order their execution so that tasks \u2018real time requirements are satisfied and a minimum schedule length is abtained. The reliability cost into the scheduling algorithm in heterogeneous systems are introduced. The RTFTRC algorithm allocates each task to the processor, which gives rise to the minimum reliability cost. This scheme is able to enhance the reliability of the systems without any extra hardware. The RTFTNO algorithm, however, does not take reliability cost into account. Simulation results indicate that under the same workload, the reliability cost generated by the RTFTRC is significantlyless than that generated by the RTFTNO algorithm. In addition, the simulation results show that the schedule length generated by the RTFTRC algorithm is shorter than that generated by\u00a0\u2026", "num_citations": "26\n", "authors": ["505"]}
{"title": "ES-MPICH2: A Message Passing Interface with enhanced security\n", "abstract": " An increasing number of commodity clusters are connected to each other by public networks, which have become a potential threat to security sensitive parallel applications running on the clusters. To address this security issue, we developed a Message Passing Interface (MPI) implementation to preserve confidentiality of messages communicated among nodes of clusters in an unsecured network. We focus on M PI rather than other protocols, because M PI is one of the most popular communication protocols for parallel computing on clusters. Our MPI implementation-called ES-MPICH2-was built based on MPICH2 developed by the Argonne National Laboratory. Like MPICH2, ES-MPICH2 aims at supporting a large variety of computation and communication platforms like commodity clusters and high-speed networks. We integrated encryption and decryption algorithms into the MPICH2 library with the standard\u00a0\u2026", "num_citations": "25\n", "authors": ["505"]}
{"title": "An adaptive energy-conserving strategy for parallel disk systems\n", "abstract": " In the past decade parallel disk systems have been highly scalable and able to alleviate the problem of disk I/O bottleneck, thereby being widely used to support a wide range of data-intensive applications. Optimizing energy consumption in parallel disk systems has strong impacts on the cost of backup power-generation and cooling equipment, because a significant fraction of the operation cost of data centres is due to energy consumption and cooling. Although a variety of parallel disk systems were developed to achieve high performance and energy efficiency, most existing parallel disk systems lack an adaptive way to conserve energy in dynamically changing workload conditions. To solve this problem, we develop an adaptive energy-conserving algorithm, or DCAPS, for parallel disk systems using the dynamic voltage scaling technique that dynamically choose the most appropriate voltage supplies for parallel\u00a0\u2026", "num_citations": "25\n", "authors": ["505"]}
{"title": "Improving reliability and energy efficiency of disk systems via utilization control\n", "abstract": " As disk drives become increasingly sophisticated and processing power increases, one of the most critical issues of designing modern disk systems is data reliability. Although numerous energy saving techniques are available for disk systems, most of energy conservation techniques are not effective in reliability critical environments due to their limitation of ignoring the reliability issue. A wide range of factors affect the reliability of disk systems; the most important factors - disk utilization and ages - are the focus of this study. We build a model to quantify the relationship among the disk age, utilization, and failure probabilities. Observing that the reliability of a disk heavily relies on both disk utilization and age, we propose a novel concept of safe utilization zone, where energy of the disk can be conserved without degrading reliability. We investigate an approach to improving both reliability and energy efficiency of disk\u00a0\u2026", "num_citations": "25\n", "authors": ["505"]}
{"title": "Feminizing/demasculinizing effects of polychlorinated biphenyls on the secondary sexual development of Xenopus laevis\n", "abstract": " We have previously demonstrated that polychlorinated biphenyls (PCBs) have caused phenotypic feminization/demasculinization of gonadal development in Xenopus laevis. Whether PCBs affect secondary sexual development has remained unknown. In this study, X. laevis tadpoles were exposed to Aroclor1254 and PCB3 from stage 46/47 (system of Nieuwkoop and Faber) for up to 1 month postmetamorphosis. After 24 months postmetamorphosis, the degree of secondary sexual development was examined. Male oviducts were observed in some of the PCB-exposed male frogs, but not in control males. These male oviducts had not completely developed in histological structure when compared with mature female oviducts. Larynx weight and width of PCB-exposed males were significantly less than those of control males. Laryngeal histology showed that PCBs inhibited cartilaginous and muscular development of\u00a0\u2026", "num_citations": "25\n", "authors": ["505"]}
{"title": "Towards load balancing support for I/O-intensive parallel jobs in a cluster of workstations\n", "abstract": " While previous CPU- or memory-centric load balancing schemes are capable of achieving the effective usage of global CPU and memory resources in a cluster system, the cluster exhibits significant performance drop under I/O-intensive workload conditions due to the imbalance of I/O load. To tackle this problem, we have developed two simple yet effective I/O-aware load-balancing schemes, which make it possible to balance I/O load by assigning I/O intensive sequential and parallel jobs to nodes with light I/O loads. Moreover, the proposed schemes judiciously take into account both CPU and memory load sharing in the cluster, thereby maintaining a high performance for a wide spectrum of workload. Using a set of real I/O-intensive parallel applications in addition to synthetic parallel jobs, we show that the proposed schemes consistently outperform the existing non-I/O aware load-balancing schemes for a diverse\u00a0\u2026", "num_citations": "25\n", "authors": ["505"]}
{"title": "$ k $ NN-DP: Handling Data Skewness in $ kNN $ Joins Using MapReduce\n", "abstract": " In this study, we discover that the data skewness problem imposes adverse impacts on MapReduce-based parallel kNN-join operations running clusters. We propose a data partitioning approach-called kNN-DP-to alleviate load imbalance incurred by data skewness. The overarching goal of kNN-DP is to equally divide data objects into a large number of partitions, which are processed by mappers and reducers in parallel. At the heart of kNN-DP is a data partitioning module, which dynamically and judiciously partitions data to optimize kNN-join performance by suppressing data skewness on Hadoop clusters. Data partitioning decisions largely depends on data properties (e.g., distributions), the analysis of which is highly expensive for a massive amount of data. To speed up the data-property analysis, we incorporate a sampling technique to profile the data distribution of a small sample dataset representing big\u00a0\u2026", "num_citations": "24\n", "authors": ["505"]}
{"title": "WEC: Improving durability of SSD cache drives by caching write-efficient data\n", "abstract": " Serving as cache disks, flash-based solid-state drives (SSDs) can significantly boost the performance of read-intensive applications. However, frequent data updating, the necessary condition for classical replacement algorithms (e.g., LRU, MQ, LIRS, and ARC) to achieve a high hit rate, makes SSDs wear out quickly. To address this problem, we propose a new approach-write-efficient caching (WEC)-to greatly improve the write durability of SSD cache. WEC is conducive to reducing the total number of writes issued to SSDs while achieving high hit rates. WEC takes two steps to improve write durability and performance of SSD cache. First, WEC discovers write-efficient data, which tend to be active for a long time period and to be frequently accessed. Second, WEC keeps the write-efficient data in SSDs long enough to avoid excessive number of unnecessary updates. Our findings based on a wide range of popular\u00a0\u2026", "num_citations": "24\n", "authors": ["505"]}
{"title": "Performance evaluation of traditional caching policies on a large system with petabytes of data\n", "abstract": " Caching is widely known to be an effective method for improving I/O performance by storing frequently used data on higher speed storage components. However, most existing studies that focus on caching performance evaluate fairly small files populating a relatively small cache. Few reports are available that detail the performance of traditional cache replacement policies on extremely large caches. Do such traditional caching policies still work effectively when applied to systems with petabytes of data? In this paper, we comprehensively evaluate the performance of several cache policies, which include First-In-First-Out (FIFO), Least Recently Used (LRU) and Least Frequently Used (LFU), on the global satellite imagery distribution application maintained by the U.S. Geological Survey (USGS) Earth Resources Observation and Science Center (EROS). Evidence is presented suggesting traditional caching policies\u00a0\u2026", "num_citations": "24\n", "authors": ["505"]}
{"title": "Towards power-efficient smartphones by energy-aware dynamic task scheduling\n", "abstract": " Smartphones are facing a grand challenge in extending their battery life to sustain an increasing level of processing demand while subject to miniaturized form factor. Dynamic Voltage Scaling (DVS) has emerged as a critical technique to leverage power management by lowering the supply voltage and frequency of processors. In this paper, based on the DVS technique, we propose a novel Energy-aware Dynamic Task Scheduling (EDTS) algorithm to minimize total energy consumption for smartphones while satisfying stringent time constraints for applications. This algorithm utilizes the results from a static scheduling algorithm and aggressively reduces energy consumptions on the fly. Experimental results indicate that the EDTS algorithm can significantly reduce energy consumption for smartphones, compared to the critical path scheduling method and the parallelism-based scheduling algorithm.", "num_citations": "24\n", "authors": ["505"]}
{"title": "Compounds from the insect Blaps japanensis with COX-1 and COX-2 inhibitory activities\n", "abstract": " Blapsols A\u2013D (1\u20134), four new compounds possessing a 2,3-dihydrobenzo[b][1,4]dioxin group, together with five known N-acetyldopamine dimers (5\u20139), were isolated from Blaps japanensis. Their structures including the absolute configuration of (+)-1 were determined by means of spectroscopic and X-ray crystallographic methods. Chiral HPLC was used to separate (\u2212)- and (+)-enantiomers of compounds 1\u20134, which were isolated from this insect as racemic mixtures. All the compounds were found to have inhibitory effects towards COX-2 with IC50 values in the range of 1.3\u201317.8\u00a0\u03bcM.", "num_citations": "23\n", "authors": ["505"]}
{"title": "Online data allocation for hybrid memories on embedded tele-health systems\n", "abstract": " The developments of wearable devices such as Body Sensor Networks (BSNs) have greatly improved the capability of tele-health industry. Large amount of data will be collected from every local BSN in real-time. These data is processed by embedded systems including smart phone and tablet before has been transferred to distributed storage systems. Traditional on-chip SRAMs cause critical power leakage issues and occupy relatively large chip areas. Therefore, hybrid memories, which combine volatile memories with non-volatile memories, are widely adopted in reducing the latency and energy cost on multi-core systems. However, most of the current works are about static data allocation for hybrid memories. Those mechanisms cannot achieve better data placement in real-time. Hence, we propose an online hybrid memories placement for embedded tele-health system. Experimental results demonstrate the\u00a0\u2026", "num_citations": "23\n", "authors": ["505"]}
{"title": "Breast tissue classification in digital tomosynthesis images based on global gradient minimization and texture features\n", "abstract": " Digital breast tomosynthesis (DBT) is a pseudo-three-dimensional x-ray imaging modality proposed to decrease the effect of tissue superposition present in mammography, potentially resulting in an increase in clinical performance for the detection and diagnosis of breast cancer. Tissue classification in DBT images can be useful in risk assessment, computer-aided detection and radiation dosimetry, among other aspects. However, classifying breast tissue in DBT is a challenging problem because DBT images include complicated structures, image noise, and out-of-plane artifacts due to limited angular tomographic sampling. In this project, we propose an automatic method to classify fatty and glandular tissue in DBT images. First, the DBT images are pre-processed to enhance the tissue structures and to decrease image noise and artifacts. Second, a global smooth filter based on L0 gradient minimization is applied\u00a0\u2026", "num_citations": "23\n", "authors": ["505"]}
{"title": "HYBUD: An energy-efficient architecture for hybrid parallel disk systems\n", "abstract": " In the past decade parallel disk systems have been highly scalable and able to alleviate the problem of disk I/O bottleneck, thereby being widely used to support a wide range of data-intensive applications. Optimizing energy consumption in parallel disk systems has strong impacts on the cost of backup power-generation and cooling equipment, because a significant fraction of the operation cost of data centres is incurred by energy consumption and cooling. Although flash memory is very energy-efficient compared to disk drives, flash memory is too expensive to use as a major component in large-scale storage systems. In other words, it is not a cost-effective way to make use of large flash memory to build energy-efficient storage systems. To address this problem, in this paper we proposed a hybrid disk architecture or HYBUD that integrates a non-volatile flash memory with buffer disks to build cost-effective and\u00a0\u2026", "num_citations": "23\n", "authors": ["505"]}
{"title": "Daraw: A new write buffer to improve parallel I/O energy-efficiency\n", "abstract": " In the past decades, parallel I/O systems have been used widely to support scientific and commercial applications. New data centers today employ huge quantities of I/O systems, which consume a large amount of energy. Most large-scale I/O systems have an array of hard disks working in parallel to meet performance requirements. Traditional energy conservation techniques attempt to place disks into low-power states when possible. In this paper we propose a novel strategy, which aims to significantly conserve energy while reducing average I/O response times. This goal is achieved by making use of buffer disks in parallel I/O systems to accumulate small writes to form a log, which can be transferred to data disks in a batch way. We develop an algorithm-dynamic request allocation algorithm for writes or DARAW-to energy efficiently allocate and schedule write requests in a parallel I/O system. DARAW is able to\u00a0\u2026", "num_citations": "23\n", "authors": ["505"]}
{"title": "Towards a times-based usage control model\n", "abstract": " Modern information systems require temporal and privilege-consuming usage of digital objects. To meet these requirements, we present a new access control model\u2013Times-based Usage Control (TUCON). TUCON extends traditional and temporal access control models with times-based usage control by defining the maximum times that a privilege can be exercised. When the usage times of a privilege is consumed to zero or the time interval of the usage is expired, the privilege exercised on the object is automatically revoked by the system. Formal definitions of TUCON actions and rules are presented in this paper, and the implementation of TUCON is discussed.", "num_citations": "23\n", "authors": ["505"]}
{"title": "Reliability-driven scheduling of periodic tasks in heterogeneous real-time systems\n", "abstract": " In this paper we comprehensively investigated the issue of reliability-driven real-time scheduling for periodic tasks in heterogeneous systems. First, we built a reliability model in which the concept of reliability cost is introduced in the context of heterogeneous realtime systems. Next, we proposed a novel reliability- driven scheduling algorithm (referred to as Repars) for periodic tasks in heterogeneous systems. Third, after extending the reliability model to meet the needs of our fault-tolerant scheme, we developed a fault-tolerant scheduling algorithm or Refine. Refine aims to enhance system reliability while being able to tolerate one-processor failures in heterogeneous real-time systems. Experimental results showed that Repars is superior to RMFF in terms of both schedulability and reliability. When compared with Repars, Refine significantly reduced the reliability cost by up to 34% with graceful degradation in\u00a0\u2026", "num_citations": "23\n", "authors": ["505"]}
{"title": "Database intrusion detection based on user query frequent itemsets mining with item constraints\n", "abstract": " The paper presents a database intrusion detection algorithm based on user query frequent itemsets with item constraints. Firstly, the paper discusses the method to mine database user query frequent itemsets by using query template. Secondly, the paper discusses the constrained query templates that are used to reduce the number of frequent itemsets and improve system performance. At last, the paper discusses the algorithm design and its application example.", "num_citations": "23\n", "authors": ["505"]}
{"title": "Bidirectional LSTM-CRF for adverse drug event tagging in electronic health records\n", "abstract": " Adverse drug event (ADE) detection is a vital step towards effective pharmacovigilance and prevention of future incidents caused by potentially harmful ADEs. Electronic health records (EHRs) of patients in hospitals contain valuable information regarding the ADEs and hence are an important source for detecting ADE signals. We have developed a deep learning based system that utilizes a three layered deep learning architecture of 1) RNN (bi-directional long short-term memory (bi-LSTM)) for character-level word representation 2) bi-LSTM for context representation and 3) Conditional Random Fields (CRF) for the final output prediction, by integrating them into one deep network architecture. Furthermore, we have developed customized rule-based tokenization techniques for preprocessing text to deal with the noise in the EHR text. In this paper, we share our system architecture and its performance wrt the MADE1. 0 NLP challenge.", "num_citations": "22\n", "authors": ["505"]}
{"title": "LOMA: A local outlier mining algorithm based on attribute relevance analysis\n", "abstract": " In this study, we propose a novel local outlier detection approach - called LOMA - to mining local outliers in high-dimensional data sets. To improve the efficiency of outlier detection, LOMA prunes irrelevance attributes and objects in the data set by analyzing attribute relevance with a sparse factor threshold. Such a pruning technique substantially reduce the size of data sets. The core of LOMA is searching sparse subspace, which implements the particle swarm optimization method in reduced data sets. In the process of searching sparse subspace, we introduce the sparse coefficient threshold to represent sparse degrees of data objects in a subspace, where the data objects are considered as local outliers. The attribute relevance analysis provides a guidance for experts and users to identify useless attributes for detecting outliers. In addition, our sparse-subspace-based outlier algorithm is a novel technique for local\u00a0\u2026", "num_citations": "22\n", "authors": ["505"]}
{"title": "A parallel algorithm for mining constrained frequent patterns using MapReduce\n", "abstract": " Constrained frequent pattern refers to a frequent pattern generated using constrained conditions given by users and has characteristics of stronger pertinence, higher practicability and mining efficiency, etc. With the increasing of datasets, there are defects during the construction of the constrained frequent pattern tree, so that the constrained frequent pattern tree is difficult to apply to massive datasets. In this paper, a parallel mining algorithm of the constrained frequent pattern, called PACFP, is proposed using the MapReduce programming model. First, key steps in the algorithm, such as mapping transaction in datasets to frequent item support count, constructing the constrained frequent pattern tree, generating the constrained frequent pattern, and aggregating frequent patterns, are implemented by three pairs of Map and Reduce functions. Second, migration of data recording is achieved by applying a data\u00a0\u2026", "num_citations": "22\n", "authors": ["505"]}
{"title": "Quantitative wavelength analysis and image classification for intraoperative cancer diagnosis with hyperspectral imaging\n", "abstract": " Complete surgical removal of tumor tissue is essential for postoperative prognosis after surgery. Intraoperative tumor imaging and visualization are an important step in aiding surgeons to evaluate and resect tumor tissue in real time, thus enabling more complete resection of diseased tissue and better conservation of healthy tissue. As an emerging modality, hyperspectral imaging (HSI) holds great potential for comprehensive and objective intraoperative cancer assessment. In this paper, we explored the possibility of intraoperative tumor detection and visualization during surgery using HSI in the wavelength range of 450 nm - 900 nm in an animal experiment. We proposed a new algorithm for glare removal and cancer detection on surgical hyperspectral images, and detected the tumor margins in five mice with an average sensitivity and specificity of 94.4% and 98.3%, respectively. The hyperspectral imaging and\u00a0\u2026", "num_citations": "22\n", "authors": ["505"]}
{"title": "Exploiting redundancies and deferred writes to conserve energy in erasure-coded storage clusters\n", "abstract": " We present a power-efficient scheme for erasure-coded storage clusters---ECS2---which aims to offer high energy efficiency with marginal reliability degradation. ECS2 utilizes data redundancies and deferred writes to conserve energy. In ECS2 parity blocks are buffered exclusively in active data nodes whereas parity nodes are placed into low-power mode. (k + r,\u2009k) RS-coded ECS2 can achieve \u2308(r + 1)/2\u2309-fault tolerance for k active data nodes and r-fault tolerance for all k + r nodes. ECS2 employs the following three optimizing approaches to improve the energy efficiency of storage clusters. (1) An adaptive threshold policy takes system configurations and I/O workloads into account to maximize standby time periods; (2) a selective activation policy minimizes the number of power-transitions in storage nodes; and (3) a region-based buffer policy speeds up the synchronization process by migrating parity blocks in a\u00a0\u2026", "num_citations": "22\n", "authors": ["505"]}
{"title": "Efficient data migration to conserve energy in streaming media storage systems\n", "abstract": " Reducing energy consumption has been an important design issue for large-scale streaming media storage systems. Existing energy conservation techniques are inadequate to achieve high energy efficiency for streaming media computing environments due to high data migration overhead. To address this problem, we propose in this paper a new energy-efficient method called Explicit Energy Saving Disk Cooling or EESDC. EESDC significantly reduces data migration overhead because of two reasons. First, a set of disks referred to Explicit Energy Saving Disks (EESD) is explicitly fixed according to temporal system load. Second, all the migrated data in EESDC directly contribute on extending the idle time of EESD to conserve more energy efficiently. Therefore, the EESDC method is conducive to saving more energy by quickly achieving energy-efficient data layouts without unnecessary data migrations. We\u00a0\u2026", "num_citations": "22\n", "authors": ["505"]}
{"title": "Performance evaluation of energy-efficient parallel I/O systems with write buffer disks\n", "abstract": " In the past decade, parallel disk systems have been developed to address the problem of I/O performance. A critical challenge with modern parallel I/O systems is that parallel disks consume a significant amount of energy in servers and high performance computers. To conserve energy consumption in parallel I/O systems, one can immediately spin down disks when disk are idle; however, spinning down disks might not be able to produce energy savings due to penalties of spinning operations. Unlike powering up CPUs, spinning down and up disks need physical movements. Therefore, energy savings provided by spinning down operations must offset energy penalties of the disk spinning operations. To substantially reduce the penalties incurred by disk spinning operations, we developed a novel approach to conserving energy of parallel I/O systems with write buffer disks, which are used to accumulate small\u00a0\u2026", "num_citations": "22\n", "authors": ["505"]}
{"title": "Improving the performance of I/O-intensive applications on clusters of workstations\n", "abstract": " Load balancing in a workstation-based cluster system has been investigated extensively, mainly focusing on the effective usage of global CPU and memory resources. However, if a significant portion of applications running in the system is I/O-intensive, traditional load balancing policies can cause system performance to decrease substantially. In this paper, two I/O-aware load-balancing schemes, referred to as IOCM and WAL-PM, are presented to improve the overall performance of a cluster system with a general and practical workload including I/O activities. The proposed schemes dynamically detect I/O load imbalance of nodes in a cluster, and determine whether to migrate some I/O load from overloaded nodes to other less- or under-loaded nodes. The current running jobs are eligible to be migrated in WAL-PM only if overall performance improves. Besides balancing I/O load, the scheme judiciously\u00a0\u2026", "num_citations": "22\n", "authors": ["505"]}
{"title": "Mixed bi-subject kinship verification via multi-view multi-task learning\n", "abstract": " Bi-subject kinship verification addresses the problem of verifying whether there exists some kind of kin relationship (i.e., father\u2013son, father-daughter, mother\u2013son and mother\u2013daughter) between a pair of parent\u2013child subjects based purely on their visual appearance. The task is challenging due to the involvement of two different subjects possibly with different genders and ages. In addition, collecting sufficient training samples for each type of kinship is difficult. In this work, we present a novel method to address these issues by considering each type of kin relation verification as one task and learning them at one time in the framework of multi-task learning, by sharing feature sets and useful structures among the tasks.Particularly our contributions are three folds: first, we introduce a new type of learning problem, called mixed bi-subject kinship verification, to the topic of bi-subject kinship verification: instead of simply\u00a0\u2026", "num_citations": "21\n", "authors": ["505"]}
{"title": "Push: A pipelined reconstruction i/of or erasure-coded storage clusters\n", "abstract": " A key design goal of erasure-coded storage clusters is to minimize reconstruction time, which in turn leads to high reliability by reducing vulnerability window size. PULL-Rep and PULL-Sur are two existing reconstruction schemes based on PULL-type transmission, where a rebuilding node initiates reconstruction by sending a set of read requests to surviving nodes to retrieve surviving blocks. To eliminate the transmission bottleneck of replacement nodes in PULL-Rep and mitigate the extra overhead caused by noncontiguous disk access in PULL-Sur, we incorporate PUSH-type transmissions to node reconstruction, where the reconstruction procedure is divided into multiple tasks accomplished by surviving nodes in a pipelining manner. We also propose two PUSH-based reconstruction schemes (i.e., PUSH-Rep and PUSH-Sur), which can not only exploit the I/O parallelism of PULL-Sur, but also maintain\u00a0\u2026", "num_citations": "21\n", "authors": ["505"]}
{"title": "Measuring myofiber orientations from high-frequency ultrasound images using multiscale decompositions\n", "abstract": " High-frequency ultrasound (HFU) has the ability to image both skeletal and cardiac muscles. The quantitative assessment of these myofiber orientations has a number of applications in both research and clinical examinations; however, difficulties arise due to the severe speckle noise contained in the HFU images. Thus, for the purpose of automatically measuring myofiber orientations from two-dimensional HFU images, we propose a two-step multiscale image decomposition method. It combines a nonlinear anisotropic diffusion filter and a coherence enhancing diffusion filter to extract myofibers. This method has been verified by ultrasound data from simulated phantoms, excised fiber phantoms, specimens of porcine hearts, and human skeletal muscles in vivo. The quantitative evaluations of both phantoms indicated that the myofiber measurements of our proposed method were more accurate than other methods\u00a0\u2026", "num_citations": "20\n", "authors": ["505"]}
{"title": "Thermal modeling and analysis of storage systems\n", "abstract": " Recognizing that power and cooling cost for data centers are increasing, we address in this study the thermal impact of storage systems. In the first phase of this work, we generate the thermal profile of a storage server containing three hard disks. The profiling results show that disks have comparable thermal impacts as processing and networking elements to overall storage node temperature. We develop a thermal model to estimate the outlet temperature of a storage server based on processor and disk utilizations. The thermal model is validated against data acquired by an infrared thermometer as well as build-in temperature sensors on disks. Next, we apply the thermal model to investigate the thermal impact of workload management on storage systems. Our study suggests that disk-aware thermal management techniques have significant impacts on reducing cooling cost of storage systems. We further show that\u00a0\u2026", "num_citations": "20\n", "authors": ["505"]}
{"title": "Modeling and improving security of a local disk system for write-intensive workloads\n", "abstract": " Since security is of critical importance for modern storage systems, it is imperative to protect stored data from being tampered with or disclosed. Although an increasing number of secure storage systems have been developed, there is no way to dynamically choose security services to meet disk requests' flexible security requirements. Furthermore, existing security techniques for disk systems are not suitable to guarantee desired response times of disk requests. We remedy this situation by proposing an adaptive strategy (referred to as AWARDS) that can judiciously select the most appropriate security service for each write request, while endeavoring to guarantee the desired response times of all disk requests. To prove the efficiency of the proposed approach, we build an analytical model to measure the probability that a disk request is completed before its desired response time. The model also can be used to\u00a0\u2026", "num_citations": "20\n", "authors": ["505"]}
{"title": "Accumulation of polybrominated diphenyl ethers in the brain compared with the levels in other tissues among different vertebrates from an e-waste recycling site\n", "abstract": " This study aimed to investigate the accumulation of polybrominated diphenyl ethers (PBDEs) in the brain compared with that in other tissues among different vertebrates. We collected mice, chickens, ducks, frogs, and fish from an e-waste recycling region in Taizhou, China, and measured PBDE concentrations in brain, liver and muscle tissues. The levels of PBDE in the tissues of mice, chickens, ducks, frogs and fish ranged 0.45\u2013206, 0.06\u201318.8, 1.83\u2013112, 2.75\u2013108, and 0.02\u201332.0\u00a0ng/g wet weight, respectively. Preferential distribution in the liver and muscle relative to the brain was observed for PBDEs in mice, chickens, ducks and frogs. However, a high retention in the brain compared to the liver and muscle was observed in fish. Comparison of the brain/liver concentration (B/L) ratios revealed differences in PBDEs accumulation in the brain among these vertebrates. PBDEs accumulation in the brain was greatest in\u00a0\u2026", "num_citations": "19\n", "authors": ["505"]}
{"title": "Improving phasor data concentrators reliability for smart grid\n", "abstract": " Phasor data concentrators (PDCs) are the critical components of a wide area monitoring system (WAMS) in the smart grid. They are multi\u2010processor devices employed to collect, concentrate, and synchronize phasor data that is from various phasor measurement units and from other PDCs. Because of their present significance and potential criticality for WAMS, reliability of PDCs has become a high priority problem. In this paper, we first formally model the reliability problem on PDCs. Then, we propose a novel task scheduling algorithm, two\u2010phase heuristic task scheduling, to enhance the reliability of a PDC with real\u2010time constraints of applications. This algorithm seamlessly integrates both tasks scheduling and reliability optimization techniques via appropriately allocate and reallocate tasks to different processors of PDCs. Experimental results show that the proposed algorithm can efficiently guarantee reliability for\u00a0\u2026", "num_citations": "19\n", "authors": ["505"]}
{"title": "An indoor localization of WiFi based on support vector machines\n", "abstract": " The recent growing interest for indoor localization-based services has created a need for more accurate and real-time indoor localization solutions. Indoor localization based on existing WiFi signal strength is becoming increasingly prevalent and ubiquity. In this paper, we utilize the information of the signal strength received from the surrounding access points (APs) to determine the user localization. The propose algorithm based on support vector machines (SVM) algorithm, and comparing with three kernel functions, radial basis function (RBF) performs best of all. Experimental results indicate that the proposed algorithm leads to improvement on localization accuracy.", "num_citations": "19\n", "authors": ["505"]}
{"title": "Interrelation analysis of celestial spectra data using constrained frequent pattern trees\n", "abstract": " Association rule mining, in which generating frequent patterns is a key step, is an effective way of identifying inherent and unknown interrelationships between characteristics of celestial spectra data and its physicochemical properties. In this study, we first make use of the first-order predicate logic to represent knowledge derived from celestial spectra data. Next, we propose a concept of constrained frequent pattern trees (CFP) along with an algorithm used to construct CFPs, aiming to improve the efficiency and pertinence of association rule mining. Finally, we quantitatively evaluate the CPU and I/O performance of our novel interrelation analysis method using a variety of real-world data sets. Our experimental results show that it is practical to study the laws of celestial bodies using our new interrelation analysis method to discover correlations between celestial spectra data characteristics and the physicochemical\u00a0\u2026", "num_citations": "19\n", "authors": ["505"]}
{"title": "An architecture for a scalable, high-performance digital library\n", "abstract": " Requirements for a high-performance, scalable digital library of multimedia data are presented together with a layered architecture for a system that addresses the requirements. The approach is to view digital data as persistent collections of complex objects and to use lightweight object management to manage this data. To scale as the amount of data increases, the object management component is layered over a storage management component. The storage management component supports hierarchical storage, third-party data transfer and parallel input-output. Several issues that arise from the interface between the storage management and object management components are discussed. The authors have developed a prototype of a digital library using this design. Two key components of the prototype are AIM Net and HPSS. AIM Net is a persistent object manager and is a product of Oak Park Research\u00a0\u2026", "num_citations": "19\n", "authors": ["505"]}
{"title": "Eco-storage: A hybrid storage system with energy-efficient informed prefetching\n", "abstract": " In this paper, we present an energy-aware informed prefetching technique called Eco-Storage that makes use of the application-disclosed access patterns to group the informed prefetching process in a hybrid storage system (e.g., hard disk drive and solid state disks). Since the SSDs are more energy efficient than HDDs, aggressive prefetching for the data in the HDD level enables it to have as much standby time as possible in order to save power. In the Eco-Storage system, the application can still read its on-demand I/O reading requests from the hybrid storage system while the data blocks are prefetched in groups from HDD to SSD. We show that these two steps can be handled in parallel to decreases the system\u2019s power consumption. Our Eco-Storage technique differs from existing energy-aware prefetching schemes in two ways. First, Eco-Storage is implemented in a hybrid storage system where the\u00a0\u2026", "num_citations": "18\n", "authors": ["505"]}
{"title": "How reliable are parallel disk systems when energy-saving schemes are involved?\n", "abstract": " Many energy conservation techniques have been proposed to achieve high energy efficiency in disk systems. Unfortunately, growing evidence shows that energy-saving schemes in disk drives usually have negative impacts on storage systems. Existing reliability models are inadequate to estimate reliability of parallel disk systems equipped with energy conservation techniques. To solve this problem, we propose a mathematical model - called MINT - to evaluate the reliability of a parallel disk system where energy-saving mechanisms are implemented. In this paper, we focus on modeling the reliability impacts of two well-known energy-saving techniques - the Popular Disk Concentration technique (PDC) and the Massive Array of Idle Disks (MAID). We started this research by investigating how PDC and MAID affect the utilization and power-state transition frequency of each disk in a parallel disk system. We then\u00a0\u2026", "num_citations": "18\n", "authors": ["505"]}
{"title": "Weighted outlier detection of high-dimensional categorical data using feature grouping\n", "abstract": " We propose a weighted outlier mining method called WATCH to identify outliers in high-dimensional categorical datasets. WATCH is composed of two distinctive modules: 1) feature grouping by the virtue of correlation measurement among features and 2) outlier mining by assigning scores to objects in each feature groups. At the heart of WATCH is the feature grouping module, which groups an array of features into multiple groups to discover various aspects of feature patterns in each group. The outlier mining module detects outliers from high-dimensional categorical datasets. Except for the number of outliers specified by users, WATCH is conducive to bypassing the optimization of any user-given parameter. We implement and evaluate WATCH using synthetic and real-world datasets. Our experimental results show that WATCH is a promising and practical algorithm to detect outliers in high-dimensional\u00a0\u2026", "num_citations": "17\n", "authors": ["505"]}
{"title": "Defending jamming attack in wide-area monitoring system for smart grid\n", "abstract": " Smart Grid is a promising technology to efficiently manage the power use, transmission and production. An efficient and dependable smart power grid relies on the secure and reliable real-time data collection and transmission service provided by an underlying backbone communication network. Cognitive radio network is an emerging wireless communication technology that fits communication needs in smart grid. However, the cognitive radio is vulnerable to jamming attacks that can disturb the real time communication. The loss of the timely information from the remotely distributedly deployed sensors can cause the loss of control of the system. In this paper, we focus on the availability of the communication services provided by the cognitive radio nodes deployed over the smart grid. We consider the jamming attacks to this wireless network. We propose to defeat the jamming attacks by introducing the\u00a0\u2026", "num_citations": "17\n", "authors": ["505"]}
{"title": "ECOS: An energy-efficient cluster storage system\n", "abstract": " Cluster storage systems are essential building blocks for many high-end computing infrastructures. Although energy conservation techniques have been intensively studied in the context of clusters and disk arrays, improving energy efficiency of cluster storage systems remains an open issue. To address this problem, we describe in this paper an approach to implementing an energy-efficient cluster storage system or ECOS for short. ECOS relies on the architecture of cluster storage systems in which each I/O node manages multiple disks - one buffer disk and several data disks. Given an I/O node, the key idea behind ECOS is to redirect disk requests from data disks to the buffer disk. To balance I/O load among I/O nodes, ECOS might redirect requests from one I/O node into the others. Redirecting requests is a driving force of energy saving, and the reason is two-fold. First, ECOS makes an effort to keep buffer disks\u00a0\u2026", "num_citations": "17\n", "authors": ["505"]}
{"title": "Real-time scheduling with quality of security constraints\n", "abstract": " An increasing number of real-time applications such as aircraft control and medical electronics systems require high quality of security to assure confidentiality, authenticity and integrity of information. However, security requirements of real-time tasks were not adequately considered in most existing scheduling algorithms. This paper proposes a novel dynamic scheduling algorithm with security awareness for scheduling independent tasks in real-time systems. Extensive simulation experiments have been conducted to quantitatively evaluate the performance of our approach. Experimental results based on synthetic and real world traces show that compared with three baseline algorithms, the proposed algorithm can consistently improve overall system performance in terms of quality of security and guarantee ratio under a wide range of workload characteristics.", "num_citations": "17\n", "authors": ["505"]}
{"title": "Adaptive preshuffling in Hadoop clusters\n", "abstract": " MapReduce has become an important distributed processing model for large-scale data-intensive applications like data mining and web indexing. Hadoop\u2013an open-source imple- mentation of MapReduce is widely used for short jobs requiring low response time. In this paper, We proposed a new preshuffling strategy in Hadoop to reduce high network loads imposed by shuffle-intensive applications. Designing new shuffling strategies is very appealing for Hadoop clusters where network intercon- nects are performance bottleneck when the clusters are shared among a large number of applications. The network interconnects are likely to become scarce resource when many shuffle-intensive applications are sharing a Hadoop cluster. We implemented the push model along with the preshuffling scheme in the Hadoop system, where the 2-stage pipeline was incorporated with the preshuffling scheme. We\u00a0\u2026", "num_citations": "16\n", "authors": ["505"]}
{"title": "The role of p53 in the response of tumor cells to sonodynamic therapy in vitro\n", "abstract": " p53 plays a pivotal role in apoptosis. In addition, p53 is currently extensively investigated as a promising strategy for highly specific anticancer therapy in chemotherapeutics and photodynamic therapy. However, the role of p53 in the response of tumor cells to sonodynamic therapy treatment is still unclear. In this study, we aim to investigate the activation of p53 in sonodynamic therapy. Three murine tumor models with distinct aggressiveness (S180, H-22 and EAC) were treated with 1.75\u00a0MHz continuous ultrasound at an acoustic intensity (ISATA) of 1.4\u00a0W for 3\u00a0min in the presence of 20\u00a0\u03bcg/ml hematoporphyrin. The DNA fragment and nuclear damage were observed by TUNEL and single cell gel electrophoresis. Western blotting and RT-PCR were used to analyze the expression of p53, PUMA, Bax and Fas. Then we checked the translocation of p53 by confocal microscopy. DNA sequencing was used to determine\u00a0\u2026", "num_citations": "16\n", "authors": ["505"]}
{"title": "Multi-layer prefetching for hybrid storage systems: algorithms, models, and evaluations\n", "abstract": " Parallel storage systems have been highly scalable and widely used in support of data-intensive applications. In future systems with the nature of massive data processing and storing, hybrid storage systems opt for a solution to fulfill a variety of demands such as large storage capacity, high I/O performance and low cost. Hybrid storage systems (HSS) contain both high-end storage components (e.g. solid-state disks and hard disk drives) to guarantee performance, and low-end storage components (e.g. tapes) to reduce cost. In HSS, transferring data back and forth among solid-state disks (SSDs), hard disk drives (HDDs), and tapes plays a critical role in achieving high I/O performance. Prefetching is a promising solution to reduce the latency of data transferring in HSS. However, prefetching in the context of HSS is technically challenging due to an interesting dilemma: aggressive prefetching is required to efficiently\u00a0\u2026", "num_citations": "16\n", "authors": ["505"]}
{"title": "Improving effective bandwidth of networks on clusters using load balancing for communication-intensive applications\n", "abstract": " Clusters have emerged as a primary and cost-effective infrastructure for parallel applications, including communication-intensive applications that transfer a large amount of data among nodes of a cluster via interconnection networks. Conventional load balancers have been proven effective in increasing utilization of CPU, memory, and disk I/O resources in a cluster. However, most of the existing load-balancing schemes ignore network resources, leaving open an opportunity for improving effective bandwidth of networks on clusters running parallel applications. For this reason, we propose a communication-aware load balancing technique that is capable of improving performance of communication-intensive applications by increasing effective utilization of networks in cluster environments. Our load-balancing scheme can make use of an application model to quickly and accurately determine the load induced by a\u00a0\u2026", "num_citations": "16\n", "authors": ["505"]}
{"title": "Database computing in HEP. Progress report\n", "abstract": " The major SSC experiments are expected to produce up to 1 Petabyte of data per year each. Once the primary reconstruction is completed by farms of inexpensive processors. I/O becomes a major factor in further analysis of the data. We believe that the application of database techniques can significantly reduce the I/O performed in these analyses. We present examples of such I/O reductions in prototype based on relational and object-oriented databases of CDF data samples.", "num_citations": "16\n", "authors": ["505"]}
{"title": "QoS promotion in energy-efficient datacenters through peak load scheduling\n", "abstract": " In energy-efficient datacenters, when bursty workloads appear, the additional time overhead required for resource gearing will incur a performance degradation. To alleviate this problem, we propose a Peak Load Scheduling Control (PLSC) method to promote the Quality of Service (QoS) of peak loads for modern energy-efficient datacenters. However, peak loads are usually difficult to identify. To overcome this difficulty, PLSC tracks the number of requests residing in a VM by leveraging a two-tier request queue maintained by it. When the number exceeds the capability of the VM, it means that peak loads appear. In this case, PLSC adds some delay-tolerant requests to the secondary queue. The scheduling of requests in the secondary queue is controlled with a lower priority than that of requests in the primary queue. Sequentially, with critical requests maintained in the primary queue, PLSC shortens the response\u00a0\u2026", "num_citations": "15\n", "authors": ["505"]}
{"title": "Feedback control scheduling in energy-efficient and thermal-aware data centers\n", "abstract": " This paper presents a model-predictive control-based scheduling strategy called ThermoRing to reduce cooling costs in data centers. ThermoRing makes use of an online feedback control mechanism to improve thermal management of energy-efficient clusters in a data center. ThermoRing aims at keeping the maximum inlet temperatures of the nodes under a redline temperature limit with little stability errors. Importantly, the ThermoRing approach is capable of dealing with emergency conditions (e.g., node fan shutdown and unexpected rising task arrival rates) by dynamically balancing load among the nodes. ThermoRing incorporates a heat distribution matrix to model the thermal characteristics of a data center housing cluster. ThermoRing is conducive to thermal management in data centers with high-scheduling performance and stability. Using a real-world online bookstore trace, we conduct extensive\u00a0\u2026", "num_citations": "15\n", "authors": ["505"]}
{"title": "Interface of on line coupling capillary electrophoresis with hydride generation electrothermal atomic absorption spectrometry and its application to arsenic speciation in sediment\n", "abstract": " A novel interface for on line coupling capillary electrophoresis with hydride generation electrothermal atomic absorption spectrometry (CE\u2013HG\u2013ETAAS) has been developed. The interface performance was examined in detail. The technique could be used to convert arsenic compounds from CE separation to corresponding volatile hydrides determined by HG\u2013ETAAS. This paper aims to explore the best condition in the speciation analysis of inorganic arsenic by using CE\u2013HG\u2013ETAAS. The application of the developed CE\u2013HG\u2013ETAAS to inorganic arsenic speciation in sediment was investigated. The detection limits of As(III) and As(V) were 135\u00a0ng/g and 160\u00a0ng/g, respectively. Relative standard deviations of arsenic speciation were better than 2%. The recoveries of As(III) and As(V) in the sample with spiking concentration of 2500\u00a0ng/g As(III) and 5000\u00a0ng/g As(V) were 97.6% and 96.7%, respectively.", "num_citations": "15\n", "authors": ["505"]}
{"title": "High frequency oscillatory ventilation versus conventional ventilation in a newborn piglet model with acute lung injury\n", "abstract": " BACKGROUND: High frequency oscillatory ventilation (HFOV) is considered a protective strategy for human lungs. This study was designed to define microscopic structural features of lung injury following HFOV with a high lung volume strategy in newborn piglets with acute lung injury.METHODS: After acute lung injury with saline lavage, newborn piglets were randomly assigned to 5 study groups (6 in each group): control (no mechanical ventilation), conventional mechanical ventilation for 24 hours, conventional ventilation for 48 hours, HFOV for 24 hours, and HFOV for 48 hours. The right upper lung tissue was divided into the gravitation-dependent and gravitation-nondependent regions after the completion of mechanical ventilation. Under light microscopy, the numbers of polymorphonuclear leukocytes (PMNLs), alveolar macrophages, red blood cells, and hyaline membrane/alveolar edema were assessed in all\u00a0\u2026", "num_citations": "15\n", "authors": ["505"]}
{"title": "Extracting cardiac myofiber orientations from high frequency ultrasound images\n", "abstract": " Cardiac myofiber plays an important role in stress mechanism during heart beating periods. The orientation of myofibers decides the effects of the stress distribution and the whole heart deformation. It is important to image and quantitatively extract these orientations for understanding the cardiac physiological and pathological mechanism and for diagnosis of chronic diseases. Ultrasound has been wildly used in cardiac diagnosis because of its ability of performing dynamic and noninvasive imaging and because of its low cost. An extraction method is proposed to automatically detect the cardiac myofiber orientations from high frequency ultrasound images. First, heart walls containing myofibers are imaged by B-mode high frequency (<20 MHz) ultrasound imaging. Second, myofiber orientations are extracted from ultrasound images using the proposed method that combines a nonlinear anisotropic diffusion filter\u00a0\u2026", "num_citations": "15\n", "authors": ["505"]}
{"title": "Measuring body-cover vibration of vocal folds based on high-frame-rate ultrasonic imaging and high-speed video\n", "abstract": " Vibration of vocal folds is a body-cover layered vibration pattern due to the two-layer tissue structures of vocal folds. A method based on a synchronal imaging system is proposed in order to image and measure the body-cover vibration pattern of vocal folds. This imaging system contains two parts: high-frame-rate ultrasonic imaging part and high-speed video part, which can synchronously image the vibration of the body and cover layers at high speed. Then, image analysis methods are applied to measure the body-cover vibration of vocal folds from both recorded image sequences. We analyze characteristics of body-layer vibration based on the measurements from designed experiments. Moreover, these results meet simulations of a body-cover model.", "num_citations": "15\n", "authors": ["505"]}
{"title": "Energy efficient prefetching with buffer disks for cluster file systems\n", "abstract": " Energy efficient computing is becoming increasingly important as the scale of parallel computing systems is expanding. As the processing power of parallel computing systems has been incremented there has been an increased demand for large scale storage systems to store the output of these parallel computing systems. Data centers are growing at an enormous pace and it is important to investigate a means of managing the energy efficiency of large scale parallel storage systems. To address these issues we introduce EEVFS (Energy Efficient Virtual File System), which is able to manage data placement and disk states to help improve the energy efficiency of a parallel disk system. EEVFS places data on the storage disks in an energy efficient layout and attempts to predict when each disk will be idle for a large period of time, facilitating a state transition into the standby state. EEVFS should also maintain\u00a0\u2026", "num_citations": "15\n", "authors": ["505"]}
{"title": "Research on algorithm of user query frequent itemsets mining\n", "abstract": " An algorithm of mining database user query profiles of transaction level is presented. The algorithm changes the computing method of the support and confidence in association rules mining by adding query structure and attribute relations to the computation. Since there is no causal relationship in the access of attributes in queries, the method is more appropriate to describe user query behaviors than itemsets used by association rules. The method can be used in database intrusion detection system to prevent database from illegal intrusions effectively. Realization, performance and application of the algorithm are discussed in the paper.", "num_citations": "15\n", "authors": ["505"]}
{"title": "Design, synthesis and cytotoxic activities of novel 2, 5-diketopiperazine derivatives\n", "abstract": " A series of novel N-1-monoallylated 2,5-diketopiperazine derivatives were designed, synthesized, and evaluated as cytotoxic agents against eight cancer cell lines by using CCK8 assay. These derivatives were substituted with methoxyphenyl groups at C-6 position, and various long alkyl side chains at C-3-position of the 2,5-diketopiperazine ring. The cytotoxic results showed that 4-methoxyphenyl group was better than 2-methoxyphenyl group as optimal substitutive group, while 3-methoxyphenyl group was not a suitable one. When the number (n value) of the methylene groups for the long alkyl side chain was 3 (compounds 1c and 3c), the derivatives had the strongest cytotoxicities. Compound 3c substituted with 4-methoxyphenyl group and pentylidene side chain exhibited strong activity (IC50\u00a0=\u00a00.36\u20131.9\u00a0\u03bcM) against all cancer cell lines, and could obviously induce apoptosis of cancer cell line U937 at 1.0\u00a0\u03bcM\u00a0\u2026", "num_citations": "14\n", "authors": ["505"]}
{"title": "Reed: A reliable energy-efficient raid\n", "abstract": " Recent studies indicate that the energy cost and carbon footprint of data centers have become exorbitant. It is a demanding and challenging task to reduce energy consumption in large-scale storage systems in modern data centers. Most energy conservation techniques inevitably have adverse impacts on parallel disk systems. To address the reliability issues of energy-efficient parallel disks, we propose a reliable energy-efficient RAID system called REED, which aims at improving both energy efficiency and reliability of RAID systems by seamlessly integrating HDDs and SSDs. At the heart of REED is a high-performance cache mechanism powered by SSDs, which are serving popular data. Under light workload conditions, REED spins down HDDs into the low-power mode, thereby offering energy conservation. Importantly, during an I/O access turbulence (i.e., I/O load is dynamically and frequently changing\u00a0\u2026", "num_citations": "14\n", "authors": ["505"]}
{"title": "Estimation of tissue optical parameters with hyperspectral imaging and spectral unmixing\n", "abstract": " Early detection of oral cancer and its curable precursors can improve patient survival and quality of life. Hyperspectral imaging (HSI) holds the potential for noninvasive early detection of oral cancer. The quantification of tissue chromophores by spectral unmixing of hyperspectral images could provide insights for evaluating cancer progression. In this study, non-negative matrix factorization has been applied for decomposing hyperspectral images into physiologically meaningful chromophore concentration maps. The approach has been validated by computer-simulated hyperspectral images and in vivo tumor hyperspectral images from a head and neck cancer animal model.", "num_citations": "14\n", "authors": ["505"]}
{"title": "Mapping cardiac fiber orientations from high-resolution DTI to high-frequency 3D ultrasound\n", "abstract": " The orientation of cardiac fibers affects the anatomical, mechanical, and electrophysiological properties of the heart. Although echocardiography is the most common imaging modality in clinical cardiac examination, it can only provide the cardiac geometry or motion information without cardiac fiber orientations. If the patient\u2019s cardiac fiber orientations can be mapped to his/her echocardiography images in clinical examinations, it may provide quantitative measures for diagnosis, personalized modeling, and image-guided cardiac therapies. Therefore, this project addresses the feasibility of mapping personalized cardiac fiber orientations to three-dimensional (3D) ultrasound image volumes. First, the geometry of the heart extracted from the MRI is translated to 3D ultrasound by rigid and deformable registration. Deformation fields between both geometries from MRI and ultrasound are obtained after registration. Three\u00a0\u2026", "num_citations": "14\n", "authors": ["505"]}
{"title": "BFEPM: Best fit energy prediction modeling based on CPU utilization\n", "abstract": " Energy cost becomes a major part of data center operational cost. Computer system consume more power when it runs under high workload. Many past studies focused on how to predict power consumption by performance counters. Some models retrieve performance counters from chips. Some models query performance counters from OS. Most of these researches were verified on several machines and claimed their models were accurate under the test. We found different servers have different energy consumption characters even with same CPU. In this paper, we present BFEPM, a best fit energy prediction model. It choose best model based on the power consumption benchmark result. We illustrate how to use benchmark result to find a best fit model. Then we validate the viability and effectiveness of model on all published results. At last, we apply the best fit model on two different machines to estimate the real\u00a0\u2026", "num_citations": "14\n", "authors": ["505"]}
{"title": "Room-temperature ferromagnetism in Fe/Sn-codoped In2O3 powders and thin films\n", "abstract": " Fe/Sn-codoped In 2 O 3 powders and films are prepared by a vacuum annealing process and a pulsed laser deposition technique, respectively. The structural and magnetic properties of the samples are investigated. The obvious room-temperature ferromagnetism is observed in both (In 0.92 Fe 0.05 Sn 0.03) 2 O 3 powders and films, but their magnetic behaviors are very different. The ferromagnetism of the vacuum-annealed powders is partially due to precipitated Fe 3 O 4 impurity. By contrast, the ferromagnetism of the films is intrinsic and does not originate from any magnetic impurity, as confirmed by the extensive x-ray absorption spectroscopy and magnetization studies.", "num_citations": "14\n", "authors": ["505"]}
{"title": "PASS: power-aware scheduling of mixed applications with deadline constraints on clusters\n", "abstract": " Reducing energy consumption has become a pressing issue in cluster computing systems not only for minimizing electricity cost, but also for improving system reliability. Therefore, it is highly desirable to design energy-efficient scheduling algorithms for applications running on clusters. In this paper, we address the problem of non-preemptively scheduling mixed tasks on power-aware clusters. We developed an algorithm called Power Aware Slack Scheduler (PASS) for tasks with different priorities and deadlines. PASS attempts to minimize energy consumption in addition to maximizing the number of tasks completed before their deadlines. To achieve this goal, high-priority tasks are scheduled first in order to meet their deadlines. Moreover, PASS explores slacks into which lowpriority tasks can be inserted so that their deadlines can be guaranteed. The dynamic voltage scaling (DVS) technique is used to reduce energy consumption by exploiting available slacks and adjusting appropriate voltage levels accordingly. Simulation results demonstrate that compared with a well-known energyefficient algorithm-CC-EDF, PASS saves up to 60 percent of energy dissipation. With respect to the number of high-priority tasks meeting deadlines, PASS outperforms the existing approach by over 10 percent without degrading the overall performance. PASS successfully schedules tasks with hard deadlines in a mix of tasks with soft deadlines. In doing so, PASS embraces a new feature that allows clusters to support a variety of real-time applications, making clusters amenable for commercialization.", "num_citations": "14\n", "authors": ["505"]}
{"title": "A security-oriented task scheduler for heterogeneous distributed systems\n", "abstract": " High quality of security is increasingly critical for applications running on heterogeneous distributed systems, where processors operate at different speeds and communication channels have different bandwidths. Although there are a few scheduling algorithms in the literature for heterogeneous distributed systems, they generally do not take into account of security requirements of applications. In this paper, we propose a novel heuristic scheduling algorithm, or SATS, which is conducive to improving security of heterogeneous distributed systems. First, we formalize a concept of security heterogeneity for our scheduling model in the context of distributed systems. Next, we devise the SATS algorithm aiming at scheduling tasks to maximize the probability that all tasks are executed without any risk of being attacked. Empirical results demonstrate that with respect to security and performance, the proposed\u00a0\u2026", "num_citations": "14\n", "authors": ["505"]}
{"title": "Scheduling for improved write performance in a cost-effective, fault-tolerant parallel virtual file system (CEFT-PVFS\n", "abstract": " Without any additional hardware, CEFT-PVFS utilizes the existing disks on each cluster node to provide RAID-10 style parallel I/O service. In CEFT-PVFS, all servers are also computational nodes and can be heavily loaded by different applications running on the cluster, thus potentially degrad-ing the I/O performance. To minimize the degradation, I/O requests can be scheduled on a less loaded server in each mirroring pair. To help define the meaning of \u201cload\u201d in face of multiple resources such as CPU, memory, disk and network, this paper examines the impacts of these resources by measuring ag-gregate I/O throughput of the simplest CEFT-PVFS configurations, under spe-cific and isolated workload stresses. Based on the heuristic rules found from the experimental results, a scheduling algorithm for dynamic load balancing is de-veloped. In a CEFF-PVFS with 16 data servers, we evaluate this algorithm un-der different workloads. The results show that the proposed scheduling algo-rithm significantly improves the overall performance.", "num_citations": "14\n", "authors": ["505"]}
{"title": "Heterogeneous similarity learning for more practical kinship verification\n", "abstract": " Kinship verification via facial images is a relatively new and challenging problem in computer vision. Prior studies in the literature have focused solely on gender-fixed kin relation, i.e., on the question of whether one gender-fixed kin relationship between given subjects can be established. In practice, however, large scale gender annotation is time-consuming and expensive. Instead, we propose in this paper to learn and predict with gender-unknown kin relations. To address this, we present a novel heterogeneous similarity learning (HSL) method. Motivated by the fact that different kinship relations may not only share some common genetic characteristics but also have its own inherited traits from parents to offspring, we aim to learn a similarity function under which the commonality among different kinship relations are captured and the geometry of each relation is preserved, simultaneously. We further derive\u00a0\u2026", "num_citations": "13\n", "authors": ["505"]}
{"title": "Expansion RSS-based indoor localization using 5G WiFi signal\n", "abstract": " Indoor localization based on existent WiFi signal strength is becoming more and more prevalent and ubiquitous. Unfortunately, the WiFi received signal strength (RSS) is susceptible by multipath, signal attenuation and environmental changes, it is the major challenge for accurate indoor localization. In this paper, to overcome these limitations, we propose an indoor localization based on expansion RSS algorithm (ERA) to reduce the environmental interference. In addition, according to the detailed analysis of the 2.4G and 5G signal, we get that 5G WiFi signal is more stable than 2.4G, and experiment indicates the 5G signal is more accurate than 2.4G for indoor localization. Experimental results demonstrate the proposed algorithm exhibits superior performance in terms of localization accuracy and stabilization.", "num_citations": "13\n", "authors": ["505"]}
{"title": "Reliability analysis of an energy-aware raid system\n", "abstract": " We develop a mathematical model - MREED - to quantitatively evaluate the failure rate of energy-efficient parallel storage systems. The Power-Aware Redundant Array of Inexpensive Disk (PARAID) aims to reduce energy use of commodity server-class disks without specialized hardware. The goal of PARAID is to skewed striping pattern to adapt to the system load by changing the number of powered disks. By spinning down disks during light workloads, PARAID can reduce power consumption, while still meeting performance demands. We show that MREED can be used to estimate a five-disk PARAID-0 system. We validate the accuracy of MREED using the DiskSim simulator. Our approach shows that MREED can rely on file access pattern to estimate system utilization correctly. Furthermore, even thought PARAID may achieve reasonable reliability, our model shows that PARAID's reliability is affected by data\u00a0\u2026", "num_citations": "13\n", "authors": ["505"]}
{"title": "Improving network performance through task duplication for parallel applications on clusters\n", "abstract": " While data replication is widely used in clusters to provide fault tolerance, it can heavily stress communication networks and degrade overall performance of parallel applications. The performance degradation is particularly unacceptable with disk-write-intensive applications. As a result, data duplication management for parallel applications running on clusters is a significant and urgent challenge. This paper presents the design, implementation, and evaluation of a network-aware task duplication management system, or TUFF, where redundant data can be regenerated by corresponding duplicate tasks rather than directly replicating through networks. In addition, TUFF is capable of improving availability performance of parallel applications, because TUFF allows two replicas of each I/O-intensive task to be executed on two different nodes. We have implemented and evaluated TUFF using extensive simulations\u00a0\u2026", "num_citations": "13\n", "authors": ["505"]}
{"title": "Underplating of Mesozoic Mantle\u2010derived Magmas in Tongling, Anhui Province: Evidence from Megacrysts and Xenoliths\n", "abstract": " Lithological observations and mineralogical analyses on pyroxene and hornblende megacrysts and pyroxene and hornblende cumulates in xenoliths in the Mesozoic plutons of the Tongling region, Anhui Province, provide evidence for the magmatic underplating of mantle\u2010derived alkali\u2010olivine basalt at circa 140 Ma. The pyroxene and hornblende megacrysts and cumulates were formed through the AFC process at depths ranging from 27 to 35 km.", "num_citations": "13\n", "authors": ["505"]}
{"title": "Maras: Signaling multi-drug adverse reactions\n", "abstract": " There is a growing need for computing-supported methods that facilitate the automated signaling of Adverse Drug Reactions (ADRs) otherwise left undiscovered from the exploding amount of ADR reports filed by patients, medical professionals and drug manufacturers. In this research, we design a Multi-Drug Adverse Reaction Analytics Strategy, called MARAS, to signal severe unknown ADRs triggered by the usage of a combination of drugs, also known as Multi-Drug Adverse Reactions (MDAR). First, MARAS features an efficient signal generation algorithm based on association rule learning that extracts non-spurious MDAR associations. Second, MARAS incorporates contextual information to detect drug combinations that are strongly associated with a set of ADRs. It groups related associations into Contextual Association Clusters (CACs) that then avail contextual information to evaluate the significance of the\u00a0\u2026", "num_citations": "12\n", "authors": ["505"]}
{"title": "Changes of polybrominated diphenyl ether concentrations in ducks with background exposure level and time\n", "abstract": " To reveal what degree bioaccumulation of polybrominated diphenyl ethers (PBDEs) depends on exposure time and other factors, we conducted a semi-field experiment for a year (June 2008\u2013June 2009) in a village in an e-waste recycling site in Taizhou, China. Approximately one hundred of juvenile ducks (Anas domestica Linnaeus) were entrusted to a villager. The ducks lived and forged in a PBDE-polluted pond from the late March to the end of November. Fish and mudsnails that were heavily polluted by PBDEs were main food. In cold days (from December to the middle March), the ducks lived in the villager\u2019 house, and mainly fed on paddy, which contained lower concentrations of PBDEs than fish and mudsnails. The female ducks were sampled for PBDE analysis every three months. We found that the \u2211PBDE concentrations in duck liver, muscle, lung and brain fluctuated greatly with the changes of exposure\u00a0\u2026", "num_citations": "12\n", "authors": ["505"]}
{"title": "Simultaneous analysis of small organic acids and humic acids using high performance size exclusion chromatography\n", "abstract": " An accurate and fast method for simultaneous determination of small organic acids and much larger humic acids was developed using high performance size exclusion chromatography. Two small organic acids, i.e. salicylic acid and 2,3\u2010dihydroxybenzoic acid, and one purified humic acid material were used in this study. Under the experimental conditions, the UV peaks of salicylic acid and 2,3\u2010dihydroxybenzoic acid were well separated from the peaks of humic acid in the chromatogram. Concentrations of the two small organic acids could be accurately determined from their peak areas. The concentration of humic acid in the mixture could then be derived from mass balance calculations. The measured results agreed well with the nominal concentrations. The detection limits are 0.05 mg/L and 0.01 mg/L for salicylic acid and 2,3\u2010dihydroxybenzoic acid, respectively. Applicability of the method to natural samples was\u00a0\u2026", "num_citations": "12\n", "authors": ["505"]}
{"title": "A security middleware model for real-time applications on grids\n", "abstract": " Real-time applications are indispensable for conducting research and business in government, industry, and academic organizations. Recently, real-time applications with security requirements increasingly emerged in large-scale distributed systems such as Grids. However, the complexities and specialties of diverse security mechanisms dissuade users from employing existing security services for their applications. To effectively tackle this problem, in this paper we propose a security middleware (SMW) model from which security-sensitive real-time applications are enabled to exploit a variety of security services to enhance the trustworthy executions of the applications. A quality of security control manager (QSCM), a centerpiece of the SMW model, has been designed and implemented to achieve a flexible trade-off between overheads caused by security services and system performance, especially under\u00a0\u2026", "num_citations": "12\n", "authors": ["505"]}
{"title": "EDOM: Improving energy efficiency of database operations on multicore servers\n", "abstract": " In this paper, we propose a toolkit called EDOM facilitating the evaluation and optimization of energy-efficient multicore-based database systems. The two core components in EDOM are a benchmarking toolkit and a multicore manager to improve energy efficiency of database systems running on multicore servers. We start this study by analyzing the energy efficiency of two popular database operations (i.e., cross join and outer join) processed on multicore processors. We describe the criteria and challenges of building an energy efficiency benchmark for databases on multicore servers. We build a benchmarking toolkit, which is comprised a configuration module, a test driver, and a power monitor. We develop a multicore manager to optimize the number of cores, thereby making good tradeoff between performance and energy efficiency in multicore database servers. At the heart of the multicore manager is a\u00a0\u2026", "num_citations": "11\n", "authors": ["505"]}
{"title": "Two new prenylated phenols from endogenous fungus Pestalotiopsis vaccinii of mangrove plant Kandelia candel (L.) Druce\n", "abstract": " Two new prenylated phenols vaccinol H (1) and vaccinol I (2), together with three known phenols derivatives 3\u20135, one glyceride derivative 6, and ergosterol 7 were isolated from endogenous Pestalotiopsis vaccinii (cgmcc3.9199) of mangrove plant Kandelia candel (L.) Druce (Rhizophoraceae). The new structures of 1 and 2 were determined by spectroscopic analyses and circular dichroism (CD) spectra. Most of the isolated compounds (2\u20136) were tested for their antiviral (EV71), cytotoxic, anti-tuberculosis, and anti-inflammatory effects. Among these compounds, compound 2 exhibited potent COX-2 inhibitory activity with an IC50 value of 16.8\u00a0\u03bcM.", "num_citations": "11\n", "authors": ["505"]}
{"title": "TIGER: Thermal-aware file assignment in storage clusters\n", "abstract": " In this paper, we present a thermal-aware file assignment technique called TIGER for reducing the cooling cost of storage clusters in data centers. We show that peak inlet temperatures of storage nodes depend on not only CPU utilization but also I/O activities, which rely on file assignments in a cluster. The TIGER scheme aims to lower peak inlet temperatures of storage clusters by dynamic thermal management through file placements. TIGER makes use of cross-interference coefficients to estimate the re-circulation of hot air from the outlets to the inlets of data nodes. TIGER first calculates the thresholds of disks in each data node based on its contribution to heat re-circulation in a data center. TIGER undertakes two steps to achieve high I/O performance while reducing cooling cost. First, TIGER assigns groups of files with similar service times to shorten I/O response times. Second, TIGER ensures that load\u00a0\u2026", "num_citations": "11\n", "authors": ["505"]}
{"title": "Selenium speciation in ginger using capillary electrophoresis online coupled with electrothermal atomic absorption spectrometry\n", "abstract": " A novel and sensitive selenium speciation in cultivated ginger rhizomes was developed using capillary electrophoresis coupled with electrothermal atomic absorption spectrometry. Influencing parameters were experimentally investigated. Under optimal conditions, SeMet, SeCys2, SeIV, and SeVI were completely separated when using capillary electrophoresis electrothermal atomic absorption spectrometry. Detection limits of SeMet, SeCys2, SeIV, and SeVI were 1.7, 2.2, 0.89, and 0.97 ng mL\u22121, respectively. The recoveries ranged from 95.6% to 104%. The RSD of peak height was observed to be smaller than 5%. When selenium enrichment was used on ginger, SeMet, SeIV, and SeVI could be detected in the first month; in the second month, the concentration of SeCys2, as well as the concentrations of SeMet, SeIV, and SeVI, could be determined. Ginger absorbs SeO32\u2212 and SeO42\u2212 at different rates; they could\u00a0\u2026", "num_citations": "11\n", "authors": ["505"]}
{"title": "Secure fragment allocation in a distributed storage system with heterogeneous vulnerabilities\n", "abstract": " There is a growing demand for large-scale distributed storage systems to support resource sharing and fault tolerance. Although heterogeneity issues of distributed systems have been widely investigated, little attention has yet been paid to security solutions designed for distributed storage systems with heterogeneous vulnerabilities. This fact motivates us to investigate a fragment allocation scheme called S-FAS to improve security of a distributed system where storage sites have a wide variety of vulnerabilities. In the S-FAS approach, we integrate file fragmentation with the secret sharing technique in a distributed storage system with heterogeneous vulnerabilities. Storage sites in a distributed systems are classified into a variety of different server types based on vulnerability characteristics. Given a file and a distributed system, S-FAS allocates fragments of the file to as many different types of nodes as possible in\u00a0\u2026", "num_citations": "11\n", "authors": ["505"]}
{"title": "Mind: A black-box energy consumption model for disk arrays\n", "abstract": " Energy consumption is becoming a growing concern in data centers. Many energy-conservation techniques have been proposed to address this problem. However, an integrated method is still needed to evaluate energy efficiency of storage systems and various power conservation techniques. Extensive measurements of different workloads on storage systems are often very time-consuming and require expensive equipments. We have analyzed changing characteristics such as power and performance of stand-alone disks and RAID arrays, and then defined MIND as a black box power model for RAID arrays. MIND is devised to quantitatively measure the power consumption of redundant disk arrays running different workloads in a variety of execution modes. In MIND, we define five modes (idle, standby, and several types of access) and four actions, to precisely characterize power states and changes of RAID\u00a0\u2026", "num_citations": "11\n", "authors": ["505"]}
{"title": "Location privacy protection in contention based forwarding for VANETs\n", "abstract": " Compared to traditional wireless network routing protocols, geographic routing provides superior scalability and thus is widely used in vehicular ad hoc networks (VANETs). However, it requires every vehicle to broadcast its location information to its neighboring nodes, and this process will compromise user's location privacy. Existing solutions to this problem can be categorized into two groups: 1) hiding user's location or 2) preserving user's identification information in routing protocols, which drastically reduce network performances. To address this issue, we proposed a dummy-based location privacy protection (DBLPP) routing protocol, in which routing decision is made based upon the dummy distance to the destination (DOD), instead of users' true locations. In this scheme, users' true locations and identification information are preserved, so the user's location privacy is protected. Compared to existing solutions\u00a0\u2026", "num_citations": "11\n", "authors": ["505"]}
{"title": "Finding exact minimal polynomial by approximations\n", "abstract": " We present a new algorithm for reconstructing an exact algebraic number from its approximate value by using an improved parameterized integer relation construction method. Our result is consistent with the existence of error controlling on obtaining an exact rational number from its approximation. The algorithm is applicable for finding exact minimal polynomial of an algebraic number by its approximate root. This also enables us to provide an efficient method of converting the rational approximation representation to the minimal polynomial representation, and devise a simple algorithm to factor multivariate polynomials with rational coefficients.", "num_citations": "11\n", "authors": ["505"]}
{"title": "StReD: A quality of security framework for storage resources in Data Grids\n", "abstract": " Securing storage resources in Grid environments has increasingly become a major concern to make Grids attractive for a wide range of data-intensive applications, because security requirements are often imposed on storage resources to support security-critical applications. However, existing storage systems are unable to dynamically adjust their quality of security to meet the flexible security needs of complex data-intensive applications. To remedy this deficiency, we propose in this paper a quality of security framework, or StReD, for storage resources in Data Grids. In this framework, we integrate a quality of security adaptor with an array of security services. Applications running in the framework are enabled to specify flexible security requirements and the desired response times of disk requests. The framework leverages the adaptor to dynamically control the quality of security for disk requests, thereby achieving\u00a0\u2026", "num_citations": "11\n", "authors": ["505"]}
{"title": "Boosting performance of I/O-intensive workload by preemptive job migrations in a cluster system\n", "abstract": " Load balancing in a cluster system has been investigated extensively, mainly focusing on the effective usage of global CPU and memory resources. However, if a significant portion of applications running in the system is I/O-intensive, traditional load balancing policies that focus on CPU and memory usage may cause the system performance to decrease substantially. To solve this problem, a new I/O-aware load-balancing scheme with preemptive job migration is presented to sustain the high performance of a cluster with a diverse set of workload conditions. The proposed scheme dynamically detects I/O load imbalance on nodes of a cluster, and determines whether to preempt some running jobs on overloaded nodes and migrate them to other less- or under-loaded nodes. Besides balancing I/O load, the scheme takes into account both CPU and memory load sharing in clusters, thereby maintaining the same level\u00a0\u2026", "num_citations": "11\n", "authors": ["505"]}
{"title": "Recovery support for Internet-based real-time collaborative editing systems\n", "abstract": " For reliability purpose, recovery support must be employed in the Internet-based real-time collaborative editing systems. This paper describes a recovery scheme in which each site maintains a local document state (LDS) that is generated periodically. Thus, if a failure occurs in the Internet links or at the site, the site can rejoin the collaborative editing system by loading the LDS instead of obtaining the state from the remote sites. This is a much faster process than the traditional approach of recovery by regaining the system's document state from other peer sites. Consistency between the local state and remote state during the recovery procedure is maintained in the recovery algorithm for which the proof is provided. The performance of our recovery scheme is assessed by generating the elapsed time between a failed site joining and leaving the systems.", "num_citations": "11\n", "authors": ["505"]}
{"title": "Heat capacity experiment for very high resolution tests of the theory of confined materials\n", "abstract": " We report the current status of an experiment to measure the heat capacity of helium confined within a stack of evenly spaced silicon plates at temperatures very close to the superfluid transition. Newly developed high-resolution thermometry has substantially improved our ability to look into regions where three-dimensional crosses over to two-dimensional behaviour and where two-dimensional behaviour dominates. These regions have been of interest to theorists and experimentalists for decades. The main part of the apparatus consists of a high-purity copper calorimeter containing a stack of 408 silicon plates spaced 57 \u03bcm apart and a pair of high-resolution, fast response, paramagnetic salt thermometers. The thermometers have been shown to have a noise level of 10\u221210K with 1 Hz bandwidth. The expected resolution of the heat capacity measurements is 10\u22129 K. To avoid the smearing effects of gravity in the 4\u00a0\u2026", "num_citations": "11\n", "authors": ["505"]}
{"title": "A new sufficient condition for panconnected graphs\n", "abstract": " Let G be a simple graph of order n with independence number alpha. We prove in this paper that if, for any pair of nonadjacent vertices u and v, d(u)+d(v) greater-than-or-equal-to n+1 or \\N(u)and N(v)\\ greater-than-or-equal-to alpha, then G is (4,n-1)-connected unless G is some special graphs. As corollary we investigate edge-pancyclity of graphs.", "num_citations": "11\n", "authors": ["505"]}
{"title": "A literature survey on kinship verification through facial images\n", "abstract": " Kinship verification is an emerging task in computer vision which aims at finding out whether there is a kin relation between given identities through their facial images. Applications of kinship verification include image annotation, children adoption, and social media analysis, etc. However, kinship verification through facial images is challenging because facial images usually contain high intra-variances, which vary from genetic, age and gender difference. Over the past decade, more and more effective methods have emerged. This paper aims at categorizing and evaluating these methods systematically. We attach great importance to the difficulties in practical applications of kinship verification, and review the prominent algorithms from the perspective of learning more efficient models with more diverse kin relations. Then we further show how to develop an efficient and robust kinship verification system. Finally we\u00a0\u2026", "num_citations": "10\n", "authors": ["505"]}
{"title": "Parallel mining of contextual outlier using sparse subspace\n", "abstract": " In this paper, we present a parallel computing solution for an existing outlier mining method (LOMA)\u2013a local outlier detection technique. As datasets increase radically in size, there is a pressing demand to develop highly scalable outlier detection algorithms that leverages modern distributed and parallel computing infrastructures. It is challenging to devise parallel outlier detection techniques, because sharing and accessing global data across multiple computing nodes inevitably impose I/O overheads. To address this concern, we design a parallel LOMA computing framework called PLOMA, which is composed of three modules, namely, parallel data reduction, local sparse-subspace construction, and sparse-subspace validation. The parallel data reduction module exhibits superb efficiency by the virtue of the sampling technology to compute k nearest neighbor. At the heart of PLOMA is a local sparse-subspace\u00a0\u2026", "num_citations": "10\n", "authors": ["505"]}
{"title": "Parallel hierarchical subspace clustering of categorical data\n", "abstract": " Parallel clustering is an important research area of big data analysis. The conventional Hierarchical Agglomerative Clustering (HAC) techniques are inadequate to handle big-scale categorical datasets due to two drawbacks. First, HAC consumes excessive CPU time and memory resources; and second, it is non-trivial to decompose clustering tasks into independent sub-tasks executed in parallel. We solve these two problems by a MapReduce-based hierarchical subspace-clustering algorithm - called PAPU - using LSH-based data partitioning. PAPU is conducive to partitioning a large-scale dataset into multiple independent sub-datasets, into which similar data objects are mapped. Advocating parallel computing, PAPU obtains sub-clusters corresponding to respective attribute subspaces from independent chunks in the local clustering phase. To improve the accuracy of approximated clustering results, PAPU\u00a0\u2026", "num_citations": "10\n", "authors": ["505"]}
{"title": "H2ACO: An optimization approach to scheduling tasks with availability constraint in heterogeneous systems\n", "abstract": " An efficient resource management mechanism is important in a heterogeneous distributed system to discover available resources, to allocate an appropriate subset of resources to applications, and to map data or tasks onto selected resources. The key component, task scheduling, draws our attention. Makespan is the principal concern of many existing researches. But, other QoS requirements are also important in more and more realistic applications. For example Cloud Computing is expected that the service provider is reliable, robust, or highly available. In this study, we develop H2ACO (Hybrid Heuristic-Ant Colony Optimization) which makes a good trade-off between availability and makespans for heterogeneous distributed systems running multiclass applications. H2ACO comprises two key components:(1) an ant optimization algorithm which makes initial scheduling decisions;(2) an availability-aware scheduling mechanism which optimizes initial schedules offered by the first component. The experiment results indicate that compared with two existing solutions (PSO and SSAC), H2ACO significantly improves the availability and performance of multiclass tasks running in heterogeneous systems.", "num_citations": "10\n", "authors": ["505"]}
{"title": "Thermal modeling of hybrid storage clusters\n", "abstract": " There is a lack of thermal models for storage clusters; most existing thermal models do not take into account the utilization of hard drives (HDDs) and solid state disks (SSDs). To address this problem, we build a thermal model for hybrid storage clusters that are comprised of HDDs and SSDs. We start this study by generating the thermal profiles of hard drives and solid state disks. The profiling results show that both HDDs and SSDs have profound impacts on temperatures of storage nodes in a cluster. Next, we build two types of hybrid storage clusters, namely, inter-node and intra-node hybrid storage clusters. We develop a model to estimate the cooling cost of a storage cluster equipped with hybrid storage nodes. The thermal model is validated against data acquired by temperature sensors. Experimental results show that, compared to the HDD-first strategy, the SSD-first strategy is an efficient approach to\u00a0\u2026", "num_citations": "10\n", "authors": ["505"]}
{"title": "Ultrastructural study of alveolar epithelial type II cells by high-frequency oscillatory ventilation\n", "abstract": " Alveolar epithelial type II cells (AECIIs) containing lamellar bodies (LBs) are alveolar epithelial stem cells that have important functions in the repair of lung structure and function after lung injury. The ultrastructural changes in AECIIs after high-frequency oscillatory ventilation (HFOV) with a high lung volume strategy or conventional ventilation were evaluated in a newborn piglet model with acute lung injury (ALI). After ALI with saline lavage, newborn piglets were randomly assigned into five study groups (three piglets in each group), namely, control (no mechanical ventilation), conventional ventilation for 24\u2009h, conventional ventilation for 48\u2009h, HFOV for 24\u2009h, and HFOV for 48\u2009h. The lower tissues of the right lung were obtained to observe the AECII ultrastructure. AECIIs with reduced numbers of microvilli, decreased LBs electron density, and vacuole-like LBs deformity were commonly observed in all five groups. Compared with conventional ventilation groups, the decrease in numbers of microvilli and LBs electron density, as well as LBs with vacuole-like appearance and polymorphic deformity, was less severe in HFOV with high lung volume strategy groups. AECIIs were injured during mechanical ventilation. HFOV with a high lung volume strategy resulted in less AECII damage than conventional ventilation.", "num_citations": "10\n", "authors": ["505"]}
{"title": "A complete algorithm to find exact minimal polynomial by approximations\n", "abstract": " Based on an improved parameterized integer relation construction method, a complete algorithm is proposed for finding an exact minimal polynomial from its approximate root. It relies on a study of the error controlling for its approximation. We provide a sufficient condition on the precision of the approximation, depending only on the degree and the height of its minimal polynomial. Our result is superior to the existent error controlling on obtaining an exact rational or algebraic number from its approximation. Moreover, some applications are presented and compared with the subsistent methods.", "num_citations": "10\n", "authors": ["505"]}
{"title": "Super-resolution reconstruction of deformable tissue from temporal sequence of ultrasound images\n", "abstract": " In this paper, the feasibility of super-resolution reconstruction of the deformable tissue from temporal sequences of ultrasound images is extensively studied. The proposed image observation model integrates the non-rigid motion and imaging formation process into a unified super-resolution frame. To facilitate the motion estimation, Lucas-Kanade optical flow is chosen for non-rigid motion estimation from mathematical point of view. Finally, optical flow based iterative back-projection algorithm is proposed for Super-resolution reconstruction, where flow driven diffusion method is developed to re-estimate the motion in the high-resolution coordinate, yielding accurate dense flow field. The efficiency of the proposed approach is demonstrated by simulated images and ultrasound carotid vessel images. Experimental results are provided and compared with existing super-resolution method, which indicate the proposed\u00a0\u2026", "num_citations": "10\n", "authors": ["505"]}
{"title": "A new camera calibration based on vanishing point\n", "abstract": " Camera calibration is an important issue in machine vision. This paper proposes an improved calibration based on vanishing point to determine camera intrinsic parameters as well as its pose. According to projective geometry constraint, we compute all camera parameters directly by two vanishing points. Compared with existing methods based on vanishing point, the proposed approach decreases variables without increasing the number of images. As a result, the proposed approach reduces errors and simplifies calibration process. In addition, the proposed approach reduces constrains and avoids the correspondences between images and space planes so as to be flexible. Simulations and real image experiments validate the proposed approach and show that it is accurate and robust to noise.", "num_citations": "10\n", "authors": ["505"]}
{"title": "A method of fair use in digital rights management\n", "abstract": " Fair use is a difficult problem to implement in DRM systems due to its vagueness and uncertainty. We propose a fair use mechanism based on rights assertion without limitation, audit logging and misuses trigger, which brings a fair use mechanism nearer to offline world than that of existing DRM systems.", "num_citations": "10\n", "authors": ["505"]}
{"title": "Scheduling of periodic packets in energy-aware wireless networks\n", "abstract": " Existing packets scheduling algorithms designed for energy-efficient wireless networks ignore important features of periodic packets, thereby being inadequate for periodic packets with energy constraints. To remedy this problem, we present in this paper an approach to scheduling periodic packets in wireless networks subject to both timing and energy constraints. We propose a necessary and sufficient feasibility check for a set of periodic packets to be transmitted over a wireless link. Next, we develop an algorithm to schedule periodic packets (or ESPP for short) over a wireless link. The ESPP algorithm aims at minimizing energy dissipation of periodic packets without missing deadlines of periodic packets. We show through simulation studies that ESPP can significantly reduce energy consumption of wireless networks by an average of 46.4% while guaranteeing timing constraints of periodic packets.", "num_citations": "10\n", "authors": ["505"]}
{"title": "Stochastic scheduling with availability constraints in heterogeneous clusters\n", "abstract": " High availability plays an important role in heterogeneous clusters, where processors operate at different speeds and are not continuously available for processing. Existing scheduling algorithms designed for heterogeneous clusters do not factor in availability. We address in this paper the stochastic scheduling problem for heterogeneous clusters with availability constraints. Each node in a heterogeneous cluster is modeled by its speed and availability, and different classes of tasks submitted to the cluster are characterized by their execution times and availability requirements. To incorporate availability and heterogeneity into stochastic scheduling, we introduce metrics to quantify availability and heterogeneity in the context of multiclass tasks. A stochastic scheduling algorithm SSAC (Stochastic Scheduling with Availability Constraints) is then proposed to improve availability of heterogeneous clusters while\u00a0\u2026", "num_citations": "10\n", "authors": ["505"]}
{"title": "A fault-tolerant real-time scheduling algorithm for precedence-constrained tasks in distributed heterogeneous systems\n", "abstract": " In this paper, we propose and evaluate a fault-tolerant real-time scheduling algorithm that can tolerate one processor's permanent fault in a heterogeneous distributed system. Workload in this study consists of a stream of real-time jobs where each job contains multiple precedence-constrained tasks with individual deadlines. A Primary Backup (PB) model is employed, where each real-time task has two copies, ie a primary one and a backup one, that are allocated to two different processors. The backup copy executes only if the primary copy fails due to the failure of its assigned processor. The proposed scheduling algorithm also takes the reliability measure into account, in order to further enhance the reliability of the heterogeneous system. In addition, the detection time for permanent fault is incorporated into the scheduling scheme so as to make the scheduling result more realistic and accurate. Simulation results show that the proposed algorithm provides significantly improved reliability and schedulability.", "num_citations": "10\n", "authors": ["505"]}
{"title": "Breastfeeding modifies the effects of environment tobacco smoke exposure on respiratory diseases and symptoms in Chinese children: the Seven Northeast Cities Study\n", "abstract": " To evaluate the potential effect of interaction between breastfeeding and environmental tobacco smoke (ETS) exposure on respiratory health, we studied 31\u00a0049 children (aged 2\u201314\u00a0years) from 25 districts of seven cities in northeast China. Parents of the children completed standardized questionnaires that characterized the children's histories of respiratory symptoms and illness, feeding methods, ETS exposure, and other associated risk factors. Breastfeeding was defined as having been mainly breastfed for 3\u00a0months or more. The results showed that the association of ETS exposure with childhood respiratory conditions/diseases was modified by breastfeeding, and the association for nonbreastfed children was stronger than that for breastfed children. In particular, for nonbreastfed children, the odds ratios (ORs) for the effect of current ETS exposure asthma was 1.71 (95% CI: 1.43\u20132.05); however, the OR for\u00a0\u2026", "num_citations": "9\n", "authors": ["505"]}
{"title": "Site selective synthesis of cytotoxic 1, 3, 6-trisubstituted 3, 6-diunsaturated (3Z, 6Z)-2, 5-diketopiperazines via a one-pot multicomponent method\n", "abstract": " A one-pot multicomponent approach was established for site selective synthesis of novel 1,3,6-trisubstituted 3,6-diunsaturated (3Z,6Z)-2,5-diketopiperazine derivatives with high stereoselectivity. The computational studies revealed that the steric hindrances between the 2-hydrogen atoms on the aromatic rings and the carbonyl, as well as the steric repulsions between the hydrogen atoms of the CH group in the benzylidene and the CH2 group in the N-alkylative part might be responsible for the Z/E selectivity. Compound (3Z,6Z)-3h (IC50=11\u00a0nM) has a close activity to the positive compound plinabulin (IC50=15\u00a0nM) against the cancer cell line HL60.", "num_citations": "9\n", "authors": ["505"]}
{"title": "Multi-Criteria Optimal Location Query with Overlapping Voronoi Diagrams.\n", "abstract": " This paper presents a novel optimal location selection problem, which can be applied to a wide range of applications. After providing a formal definition of the novel query type, we explore an intuitive approach that sequentially scans all possible object combinations in the search space. Then, we propose an Overlapping Voronoi Diagram (OVD) model that defines OVDs and Minimum OVDs, and construct an algebraic structure under an OVD overlap operation. Based on the OVD model, we design an advanced approach to answer the query. Due to the high complexity of Voronoi diagram overlap computation, we improve the overlap operation by replacing the real boundaries of Voronoi diagrams with their Minimum Bounding Rectangles (MBR). We also propose a cost-bound iterative approach that efficiently processes a large number of Fermat-Weber problems. Our experimental results show that the proposed algorithms can evaluate the novel query type effectively and efficiently.", "num_citations": "9\n", "authors": ["505"]}
{"title": "Global workload characterization of a large scale satellite image distribution system\n", "abstract": " Online content distribution systems, which store incredibly large amounts of information and provide service to large numbers of users, are becoming increasingly commonplace. To fulfill the wide range of requests sent by different users, these systems must ensure efficient handling of massive amount of data. To achieve this goal, the in-depth analysis and comprehensive understanding of user behaviors are critical. However, analyzing the behaviors of worldwide users with different needs is a very challenging task. This is especially true when historical user behaviors evolve over time or may be affected by unpredictable events. In this paper, we present a number of workload characterization techniques applied to one of the world's largest online satellite image distribution systems operated by the U.S. Geological Survey (USGS) and NASA.", "num_citations": "9\n", "authors": ["505"]}
{"title": "A pipelining approach to informed prefetching in distributed multi-level storage systems\n", "abstract": " In this paper, we present an informed prefetching technique called IPODS that makes use of application-disclosed access patterns to prefetch hinted blocks in distributed multi-level storage systems. We develop a prefetching pipeline in IPODS, where an informed prefetching process is divided into a set of independent prefetching steps among multiple storage levels in a distributed system. In the IPODS system, while data blocks are prefetched from hard disks to memory buffers in remote storage servers, data blocks buffered in the servers are prefetched through networks to clients' local cache. We show that these two prefetching steps can be handled in a pipelining manner to improve I/O performance of distributed storage systems. Our IPODS technique differs itself from existing prefetching schemes in two ways. First, IPODS reduces applications' I/O stalls by keeping hinted data in clients' local caches and storage\u00a0\u2026", "num_citations": "9\n", "authors": ["505"]}
{"title": "TRACER: A trace replay tool to evaluate energy-efficiency of mass storage systems\n", "abstract": " Improving energy efficiency of mass storage systems has become an important and pressing research issue in large HPC centers and data centers. New energy conservation techniques in storage systems constantly spring up; however, there is a lack of systematic and uniform way of accurately evaluating energy-efficient storage systems and objectively comparing a wide range of energy-saving techniques. This research presents a new integrated scheme, called TRACER, for evaluating energy-efficiency of mass storage systems and judging energy-saving techniques. The TRACER scheme consists of a toolkit used to measure energy efficiency of storage systems as well as performance and energy metrics. In addition, TRACER contains a novel and accurate workload-control module to acquire power varying with workload modes and I/O load intensity. The workload generator in TRACER facilitates a block-level\u00a0\u2026", "num_citations": "9\n", "authors": ["505"]}
{"title": "TERCOS: A novel technique for exploiting redundancies in fault-tolerant and real-time distributed systems\n", "abstract": " In this paper, we propose a novel fault-tolerant technique, which is seamlessly integrated with fixed-priority-based scheduling algorithm to explore redundancies to enhance schedulability in fault-tolerant and real-time distributed systems. Our fault-tolerant technique makes use of the primary-backup scheme to tolerate permanent hardware failures. Most importantly, the proposed technique (referred to as Tercos) terminates the execution of active backup copies when corresponding primary copies are successfully completed, therefore Tercos can reduce scheduling lengths in fault-free scenario to enhance schedulability by virtue of executing portions of active backup copies in passive forms. Experimental results show that compared with existing algorithm in literature, Tercos can significantly improve schedulability by up to 17.0%(with an average of 9.7%).", "num_citations": "9\n", "authors": ["505"]}
{"title": "Security-driven scheduling for data-intensive applications on grids\n", "abstract": " Security-sensitive applications that access and generate large data sets are emerging in various areas including bioinformatics and high energy physics. Data grids provide such data-intensive applications with a large virtual storage framework with unlimited power. However, conventional scheduling algorithms for data grids are unable to meet the security needs of data-intensive applications. In this paper we address the problem of scheduling data-intensive jobs on data grids subject to security constraints. Using a security- and data-aware technique, a dynamic scheduling strategy is proposed to improve quality of security for data-intensive applications running on data grids. To incorporate security into job scheduling, we introduce a new performance metric, degree of security deficiency, to quantitatively measure quality of security provided by a data grid. Results based on a real-world trace confirm that\u00a0\u2026", "num_citations": "9\n", "authors": ["505"]}
{"title": "Exploiting redundancy to boost performance in a RAID-10 style cluster-based file system\n", "abstract": " While aggregating the throughput of existing disks on cluster nodes is a cost-effective approach to alleviate the I/O bottleneck in cluster computing, this approach suffers from potential performance degradations due to contentions for shared resources on the same node between storage data processing and user task computation. This paper proposes to judiciously utilize the storage redundancy in the form of mirroring existed in a RAID-10 style file system to alleviate this performance degradation. More specifically, a heuristic scheduling algorithm is developed, motivated from the observations of a simple cluster configuration, to spatially schedule write operations on the nodes with less load among each mirroring pair. The duplication of modified data to the mirroring nodes is performed asynchronously in the background. The read performance is improved by two techniques: doubling the degree of\u00a0\u2026", "num_citations": "9\n", "authors": ["505"]}
{"title": "PUMA: Parallel subspace clustering of categorical data using multi-attribute weights\n", "abstract": " There are two main reasons why traditional clustering schemes are incompetent for high-dimensional categorical data. First, traditional methods usually represent each cluster by all dimensions without difference; and second, traditional clustering methods only rely on an individual dimension of projection as an attribute\u2019s weight ignoring relevance among attributes. We solve these two problems by a MapReduce-based subspace clustering algorithm (called PUMA) using multi-attribute weights. The attribute subspaces are constructed in our PUMA by calculating an attribute-value weight based on the co-occurrence probability of attribute values among different dimensions. PUMA obtains sub-clusters corresponding to respective attribute subspaces from each computing node in parallel. Lastly, PUMA measures various scale clusters by applying the hierarchical clustering method to iteratively merge sub-clusters. We\u00a0\u2026", "num_citations": "8\n", "authors": ["505"]}
{"title": "Scalable mining of contextual outliers using relevant subspace\n", "abstract": " In this paper, we propose a scalable mining algorithm to discover contextual outliers using relevant subspaces. We develop the mining algorithm using the MapReduce programming model running on a Hadoop cluster. Relevant subspaces, which effectively capture the local distribution of various datasets, are quantified using local sparseness of attribute dimensions. We design a novel way of calculating local outlier factors in a relevant subspace with the probability density of local datasets; this new approach can effectively reflect the outlier degree of a data object that does not satisfy the distribution of the local dataset in the relevant subspace. Attribute dimensions of a relevant subspace, and local outlier factors are expressed as vital contextual information, which improves the interpretability of outliers. Importantly, the selection of N data objects with the largest local outlier factor value is categorized as contextual\u00a0\u2026", "num_citations": "8\n", "authors": ["505"]}
{"title": "Application of a self-organizing map and positive matrix factorization to investigate the spatial distributions and sources of polycyclic aromatic hydrocarbons in soils from\u00a0\u2026\n", "abstract": " The concentrations of 16 priority polycyclic aromatic hydrocarbons (PAHs) were measured in 128 surface soil samples from Xiangfen County, northern China. The total mass concentration of these PAHs ranged from 52 to 10,524\u00a0ng/g, with a mean of 723\u00a0ng/g. Four-ring PAHs contributed almost 50% of the total PAH burden. A self-organizing map and positive matrix factorization were applied to investigate the spatial distribution and source apportionment of PAHs. Three emission sources of PAHs were identified, namely, coking ovens (21.9%), coal/biomass combustion (60.1%), and anthracene oil (18.0%). High concentrations of low-molecular-weight PAHs were particularly apparent in the coking plant zone in the region around Gucheng Town. High-molecular-weight PAHs mainly originated from coal/biomass combustion around Gucheng Town, Xincheng Town, and Taosi Town. PAHs in the soil of Xiangfen County\u00a0\u2026", "num_citations": "8\n", "authors": ["505"]}
{"title": "aHDFS: An erasure-coded data archival system for hadoop clusters\n", "abstract": " In this paper, we propose an erasure-coded data archival system called aHDFS for Hadoop clusters, where RS(k + r; k) codes are employed to archive data replicas in the Hadoop distributed file system or HDFS. We develop two archival strategies (i.e., aHDFS-Grouping and aHDFS-Pipeline) in aHDFSto speed up the data archival process. aHDFS-Groupinga MapReduce-based data archiving scheme - keeps each mapper's intermediate output Key-Value pairs in a local key-value store. With the local store in place, aHDFS-Grouping merges all the intermediate key-value pairs with the same key into one single key-value pair, followed by shuffling the single Key-Value pair to reducers to generate final parity blocks. aHDFS-Pipeline forms a data archival pipeline using multiple data node in a Hadoop cluster. aHDFS-Pipeline delivers the merged single key-value pair to a subsequent node's local key-value store. Last\u00a0\u2026", "num_citations": "8\n", "authors": ["505"]}
{"title": "DTI template\u2010based estimation of cardiac fiber orientations from 3D ultrasound\n", "abstract": " Purpose: Cardiac muscle fibers directly affect the mechanical, physiological, and pathological properties of the heart. Patient\u2010specific quantification of cardiac fiber orientations is an important but difficult problem in cardiac imaging research. In this study, the authors proposed a cardiac fiber orientation estimation method based on three\u2010dimensional (3D) ultrasound images and a cardiac fiber template that was obtained from magnetic resonance diffusion tensor imaging (DTI).   Methods: A DTI template\u2010based framework was developed to estimate cardiac fiber orientations from 3D ultrasound images using an animal model. It estimated the cardiac fiber orientations of the target heart by deforming the fiber orientations of the template heart, based on the deformation field of the registration between the ultrasound geometry of the target heart and the MRI geometry of the template heart. In the experiments, the animal\u00a0\u2026", "num_citations": "8\n", "authors": ["505"]}
{"title": "Exploiting pipelined encoding process to boost erasure-coded data archival\n", "abstract": " This paper addresses an issue of erasure-coded data archival, where (k + r; k) erasure codes are employed to archive rarely accessed replicas. The traditional synchronous encodingprocess neither leverages the existence of replicas, nor handles encoding operations in a decentralized manner. To overcome these drawbacks, we exploit pipelined encoding processes to boost the data archival performance on storage clusters. First, we propose two data layouts called [D + P] cd  and [3X] cd  by applying a chained-declustering mechanism to both Mirrored RAID-5 and triplication redundancy groups. Second, in light of the [D + P] cd  and [3X] cd  layouts, we design two archiving schemes named DP and 3X, which exhibit the following three salient features: (i) exploiting data locality-two or three local blocks are read by each involved node for encoding; (ii) decentralized computation load-encoding operations are\u00a0\u2026", "num_citations": "8\n", "authors": ["505"]}
{"title": "Analysis and design of fault-tolerant scheduling for real-time tasks on earth-observation satellites\n", "abstract": " Fault-tolerant scheduling is an efficient approach to improving the reliability of multiple earth-observing satellites especially in some emergent scenarios such as obtaining photographs on battlefields or earthquake areas. Unfortunately, little work has been done to deal with the fault-tolerant scheduling on satellites. To address this issue, this paper presents a novel dynamic fault-tolerant scheduling model using primary-backup policy to tolerate one satellite's permanent failure at one time instant. On this basis, we propose a novel fault-tolerant satellite scheduling algorithm named FTSS, in which an overlapping technology is adopted to improve the resource utilization. Besides, the FTSS employs the task merging strategies to further enhance the schedulability. To demonstrate the superiority of our FTSS, we conduct extensive experiments by simulations using real-world satellite parameters from STK to compare FTSS\u00a0\u2026", "num_citations": "8\n", "authors": ["505"]}
{"title": "Thermal Modeling and Analysis of Cloud Data Storage Systems.\n", "abstract": " Abstract\uf020\u2014An explosive increment of data and a variety of data analysis make it indispensable to lower power and cooling costs of cloud datacenters. To address this issue, we investigate the thermal impact of I/O access patterns on data storage systems. Firstly, we conduct some preliminary experiments to study the thermal behavior of a data storage node. The experimental results show that disks have ignorable thermal impacts as processors to outlet temperatures of storage nodes. We raise an approach to model the outlet temperature of a storage node. The thermal models generated by our approach gains a precision error less than 6%. Next, we investigate the thermal impact of data placement strategies on storage systems. We compare the cooling cost of storage systems governed by different data placement schemes. Our study shows that evenly distributing the data leads to highest outlet temperature for the sake of shortest execution time and energy efficiency. According to the energy consumption of various data placement schemes, we propose a thermal-ware energy-efficient data placement strategy. We further show that this work can be extended to analyze the cooling cost of data centers with massive storage capacity.", "num_citations": "8\n", "authors": ["505"]}
{"title": "Peam: Predictive energy-aware management for storage systems\n", "abstract": " This paper presents a novel Predictive Energy-Aware Management (PEAM) system that is able to reduce the energy costs of storage systems by appropriately selecting data transmission methods. In particular, we evaluate the energy costs of three methods (1. transfer data without archiving and compression, 2. archive and transfer data, 3. compress and transfer data) in preliminary experiments. According to the results, we observe that the energy consumption of data transmission greatly varies case by case. We cannot simply apply one method in all cases. Therefore, we design an energy prediction model that can estimate the total energy cost of data transmission by using particular transmission methods. Based on the model, our predictive energy-aware management system can automatically select the most energy efficient method for data transmission. Our experimental results show that our system performs\u00a0\u2026", "num_citations": "8\n", "authors": ["505"]}
{"title": "A message-scheduling scheme for energy conservation in multimedia wireless systems\n", "abstract": " Reducing power consumption of wireless networks has become a major goal in designing modern multimedia wireless systems. In an effort to reduce power consumption, this paper addresses the issue of scheduling real-time messages in multimedia wireless networks subject to both timing and power constraints. A power-consumption model is introduced to calculate power-consumption rates in accordance with message-transmission rates. Next, a new message-scheduling scheme called Power-aware Real-time Message (PARM) is developed to generate message-transmission schedules that minimize power consumption of multimedia wireless-network interfaces and the probability of missing deadlines for real-time messages. With a power-aware scheduling policy in place, the proposed PARM scheme is very energy-efficient. Experimental results based on a wide variety of synthetic workloads and eight real\u00a0\u2026", "num_citations": "8\n", "authors": ["505"]}
{"title": "A simulation framework for energy efficient data grids\n", "abstract": " High performance data grids are increasingly becoming popular platforms to support data-intensive applications. Reducing high energy consumption caused by data grids is a challenging issue. Most previous studies in grid computing focused on performance and reliability without taking energy conservation into account. As such, designing energy-efficient data grid systems became highly desirable. In this paper, we proposed a framework to simulate energy-efficient data grids. We presented an approach to integrate energy-aware allocation strategies into energy-efficient data grids. Our framework aims at simulating a data grid that can conserve energy for data-intensive applications running on data grids.", "num_citations": "8\n", "authors": ["505"]}
{"title": "Design and performance analysis of a hybrid real-time scheduling algorithm with fault-tolerance\n", "abstract": " Many real-time scheduling algorithms with fault-tolerance reported in literature can only schedule tasks with fault-tolerant requirements, the authors present a model of hybrid real-time fault-tolerant scheduling, and propose a hybrid scheduling algorithm for real-time tasks. The static scheduling algorithm, a part of hybrid model can schedule real-time tasks with fault-tolerant requirements together with those without fault-tolerant requirements. An algorithm, which is used to find out the minimal number of processors needed for the real-time tasks, is also presented in this paper, so the performance of the static real-time scheduling algorithm can be simulated and analyzed. In order to enhance the performance of the static real-time scheduling algorithm with fault-tolerance, a dynamic scheduling algorithm is studied. The performance simulation and analysis of the scheduling algorithms are presented, and experiment\u00a0\u2026", "num_citations": "8\n", "authors": ["505"]}
{"title": "High resolution thermometry for the confined helium experiment\n", "abstract": " We report results with a newly designedCu(NH                                    4                 )                   2                                  Br                                    4                                  \u00b72H                                    2                                  O paramagnetic salt high resolution thermometry that will be used in the confined helium experiment to be flown on space Shuttle. The improved thermometry has a fast response time and can measure temperature with a resolution of 0.3 nK in a 10 Hz bandwidth. Our measurements have shown that the effect of cosmic ray heating observed in the lambda point experiment in space can be reduced to a negligible level. The current thermometry appears capable of operating in space at the limit imposed by thermodynamic fluctuations.", "num_citations": "8\n", "authors": ["505"]}
{"title": "A proof-of-concept implementation interfacing an object manager with a hierarchical storage system\n", "abstract": " The feasibility of providing transparent access to a collection of persistent, complex objects was investigated. An architecture for interfacing a persistent store of complex objects to a hierarchical storage system is described. Persistent-object stores support the uniform creation, storage, and access of complex objects, regardless of their lifetimes. In other words, a mechanism is provided by which persistent objects outlive the processes which create them and can be accessed in a uniform manner by other processes. This architecture was validated by implementing a proof-of-concept system and testing the system on two stores of data. These tests indicate that this architecture supports the creation, storage, and access of very large, persistent-object stores.< >", "num_citations": "8\n", "authors": ["505"]}
{"title": "Journal\n", "abstract": " Ethical map reading in neonatal care PriscillaAlderson 17 Debate: More fiddling with the definition of death John MStanley 21 Debate: Reply to JM Stanley: Fiddling and clarity Grant Gillett 23 A classification of clinical paediatric research with analysis of related ethical themes JohnPearn 26 Moral theories: Aquinas's moral theory Ralph Mclnerny 31 Towards a phenomenology of caregiving: growth in thecaregiver is a vital component MichaelEDaly 34 Point of view: Health educators-the new puritans Irma Kurtz 40 Concerning medicine: a poem William GPickering 42 Case conference: Earning his heroin but seeking release while the surgeon advises amputation 43 Book reviews 49", "num_citations": "8\n", "authors": ["505"]}
{"title": "DIVA: Exploration and Validation of Hypothesized Drug\u2010Drug Interactions\n", "abstract": " Adverse reactions caused by drug\u2010drug interactions are a major public health concern. Currently, adverse reaction signals are detected through a tedious manual process in which drug safety analysts review a large number of reports collected through post\u2010marketing drug surveillance. While computational techniques in support of this signal analysis are necessary, alone they are not sufficient. In particular, when machine learning techniques are applied to extract candidate signals from reports, the resulting set is (1) too large in size, i.e., exponential to the number of unique drugs and reactions in reports, (2) disconnected from the underlying reports that serve as evidence and context, and (3) ultimately requires human intervention to be validated in the domain context as a true signal warranting action. In this work, we address these challenges though a visual analytics system, DIVA, designed to align with the drug\u00a0\u2026", "num_citations": "7\n", "authors": ["505"]}
{"title": "Scalable spatiotemporal crowdsourcing for smart cities based on particle filtering\n", "abstract": " In mobile crowdsourcing, workers are financially motivated to perform as many self-selected tasks as possible to maximize their revenue. Unfortunately, the existing task scheduling approaches in mobile crowdsourcing fail to consider task execution duration and do not scale for massive tasks and large geographic areas (eg, a whole city). In this paper, we study on the geo-task scheduling problem (GTS) under the various spatial and temporal constraints in real-world mobile crowdsourcing applications, including task execution duration and task expiration time. Given the location of a worker, the goal of our study is to find an optimal task execution sequence that maximizes the number of tasks that could be finished. Since the exact solution to the maximum task scheduling is computationally intractable, we propose two sub-optimal approaches (LCPF and NUD-IC) based on the particle filtering and the DBSCAN\u00a0\u2026", "num_citations": "7\n", "authors": ["505"]}
{"title": "Towards two-phase scheduling of real-time applications in distributed systems\n", "abstract": " In this work we propose a two-phase scheduling technique (TOPS) for distributed real-time systems. Our TOPS scheduling approach has two distinct phases. The first phase is in charge of producing a scheduling sequence, whereas the second phase aims to dispatch tasks to computing nodes of a distributed system. The second phase also judiciously determines the starting time of each task. One salient feature of our approach lies in high flexibility, which allows system developers to apply multiple policies in each phase. The two phases are independent of one another; therefore, one can change a policy in one phase without configuring another phase. With TOPS in place, we are able to observe the impacts of sorting policies on the performance of scheduling policies. We implement a prototype of TOPS, where the first phase is comprised of three sorting policies, and the second phase consists of two scheduling\u00a0\u2026", "num_citations": "7\n", "authors": ["505"]}
{"title": "Towards transforming FDA adverse event narratives into actionable structured data for improved pharmacovigilance\n", "abstract": " A dverseD rugR eactions (ADRs) are a major cause of morbidity and mortality worldwide, making post-market surveillance of drugs vital for the protection of public health. TheF DAA dverseE ventR eportingS ystem (FAERS) is a surveillance system for online reporting ofA dverseE vent (AE) incidents. Although the FAERS data storage system includes a structural schema, entry of large portions of the AE reports as unstructured free-form narratives is prevalent, impeding the automated monitoring of these reports. To improve the review process by FDA, we have developed theM etaE xtractionF ra mework (MEFA) that supports the automatic extraction of structured\" information categories\" from large narratives. MEFA assembles a rich variety of rule-based and machine learning based information extraction techniques that work with a bank of syntactic, semantic and morphological features. Our experimental study\u00a0\u2026", "num_citations": "7\n", "authors": ["505"]}
{"title": "A new non-MDS RAID-6 code to support fast reconstruction and balanced I/Os\n", "abstract": " RAID-6 is widely applied to tolerate double concurrent disk failures in both disk arrays and storage clusters. Among numerous erasure codes developed to implement RAID-6, Maximum Distance Separable (MDS) Codes are highly popular. Owing to the limitation of parity generating schemes used in MDS codes, RAID-6-based storage systems suffer from unbalance I/Os and low reconstruction performance. Out of consideration for high performance and reliability, we propose a new class of XOR-based RAID-6 code (i.e. -Code), which improves both load balancing and reconstruction performance of the MDS RAID-6 codes. -Code, a very simple yet flexible Non-MDS vertical code, can be easily implemented and deployed in storage systems. -Code's unique features include lowest density code, steady parity chain length and well-balanced computation. We perform theoretical analysis and empirical evaluation\u00a0\u2026", "num_citations": "7\n", "authors": ["505"]}
{"title": "V2-Code: A new non-MDS array code with optimal reconstruction performance for RAID-6\n", "abstract": " RAID-6 is widely used to tolerate concurrent failures of any two disks in both disk arrays and storage clusters. Numerous erasure codes have been developed to implement RAID-6, of which MDS Codes are popular. Due to the limitation of parity generating schemes used in MDS codes, RAID-6-based storage systems suffer from low reconstruction performance. To address this issue, we propose a new class of XOR-based RAID-6 code (i.e., V 2 -Code), which delivers better reconstruction performance than the MDS RAID-6 code at low storage efficiency cost. V 2 -Code, a very simple yet flexible Non-MDS vertical code, can be easily implemented in storage systems. V 2 -Code's unique features include (1) lowest density, (2) steady length of parity chain, and (3) well balanced computation. We perform theoretical analysis and evaluation of the coding scheme under various configurations. The results show that V 2\u00a0\u2026", "num_citations": "7\n", "authors": ["505"]}
{"title": "Improving write performance by enhancing internal parallelism of solid state drives\n", "abstract": " Most researches of Solid State Drives (SSDs) architectures rely on Flash Translation Layer (FTL) algorithms and wear-leveling; however, internal parallelism in Solid State Drives has not been well explored. In this research, we proposed a new strategy to improve SSD write performance by enhancing internal parallelism inside SSDs. A SDRAM buffer is added in the design for buffering and scheduling write requests. Because the same logical block numbers may be translated to different physical numbers at different times in FTL, the on-board SDRAM buffer is used to buffer requests at the lower level of FTL. When the buffer is full, same amount of data will be assigned to each storage package in SSDs to enhance internal parallelism. To accurately evaluate performance, we use both synthetic workloads and real-world applications in experiments. We compare the enhanced internal parallelism scheme with the\u00a0\u2026", "num_citations": "7\n", "authors": ["505"]}
{"title": "Heat-based dynamic data caching: A load balancing strategy for energy-efficient parallel storage systems with buffer disks\n", "abstract": " Performance improvement and energy conservation are two conflicting objectives in large scale parallel storage systems. In this paper, we propose a novel solution to achieve the twin objectives of maximizing performance and minimizing energy consumption of parallel storage systems. Specifically, a buffer-disk based architecture (BUD for short) is designed to conserve energy. A heat-based dynamic data caching strategy is developed to improve performance. The BUD architecture strives to allocate as many requests as possible to buffer disks, thereby keeping a large number of idle data disks in low-power states. This can provide significant opportunities for energy conservation while making buffer disks a potential performance bottleneck. The heat-based data caching strategy aims to achieve good load balancing in buffer disks and alleviate overall performance degradation caused by unbalanced workload. Our\u00a0\u2026", "num_citations": "7\n", "authors": ["505"]}
{"title": "Conserving energy in real-time storage systems with I/O burstiness\n", "abstract": " Energy conservation has become a critical problem for real-time embedded storage systems. Although a variety of approaches for reducing energy consumption have been extensively studied, energy conservation for real-time embedded storage systems is still an open problem. In this article, we propose an energy management strategy, I/O Burstiness for Energy Conservation (IBEC), exploiting the burstiness of real-time embedded storage systems applications. Our approach aims at combining the IBEC energy-management strategy with a Linux-based disk block-scheduling mechanism to conserve the energy of storage systems. Extensive experiments are conducted involving a number of synthetic disk traces as well as real-world data-intensive traces. To evaluate the energy efficiency of IBEC, we compare the performance of IBEC against three existing strategies, namely, PA-EDF, DP-EDF, and EDF. Compared\u00a0\u2026", "num_citations": "7\n", "authors": ["505"]}
{"title": "SHARP: A new real-time scheduling algorithm to improve security of parallel applications on heterogeneous clusters\n", "abstract": " This paper addresses the problem of improving quality of security for real-time parallel applications on heterogeneous clusters. We propose a new security- and heterogeneity-driven scheduling algorithm (SHARP for short), which strives to maximize the probability that parallel applications are executed in time without any risk of being attacked. Because of high security overhead in existing clusters, an important step in scheduling is to guarantee jobs' security requirements while minimizing overall execution times. The SHARP algorithm accounts for security constraints in addition to different processing capabilities of each node in a cluster. We introduce two novel performance metrics, degree of security deficiency and risk-free probability, to quantitatively measure quality of security provided by a heterogeneous cluster. Both security and performance of SHARP are compared with two well-known scheduling\u00a0\u2026", "num_citations": "7\n", "authors": ["505"]}
{"title": "Open issues and challenges in security-aware real-time scheduling for distributed systems\n", "abstract": " Task Scheduling for real-time distributed systems has been investigated extensively in the literature. However, conventional wisdom in dynamic scheduling ignores security requirements in realtime applications. As such, in addition to factoring quality of security in real-time applications running in the system, real-time scheduling algorithms need to be security-aware in nature. In this paper we first identify the open issues and challenges involved in designing and implementing security-aware real-time scheduling schemes, which are intended to consider both security and real-time constraints for distributed systems. Then five approaches towards achieving security aware in real-time scheduling are described: a security-aware architecture, a uniprocessor real-time scheduling algorithm with security awareness (EDF_OPTS) using a preliminary security overhead model and overall system performance metrics, security-aware real-time scheduling for homogeneous and heterogeneous distributed systems, and a feedback control mechanism to improve quality of security and schedulability in run time. Discussions on future security overhead models are also provided. Simulation results show that our EDF_OPTS algorithm significantly improves system performance in terms of quality of security and schedulability over three baseline algorithms under a wide range of workload characteristics.", "num_citations": "7\n", "authors": ["505"]}
{"title": "An energy-aware high performance task allocation strategy in heterogeneous fog computing environments\n", "abstract": " Combining the Internet-of-Things (IoT) technology with cloud computing is a significant alternative for powering the utilization of computing resources in a connected environment. A grand challenge in communications is raised by the emergence of big data, due to the large-sized data transmissions and frequent data exchanges. Applying fog computing is considered an option for resolving the communication challenge. However, a high extent of available heterogeneous computing attached to fog computing servers leads to a restriction of the resource management. This Article addresses the resource management issue by proposing a novel approach - named Energy-aware Fog Resource Optimization (EFRO) model- to optimizing the utilization of connected devices in fog computing. We develop a heuristic algorithm minimizing both energy cost and time consumption in a holistic way. A salient feature of EFRO lies\u00a0\u2026", "num_citations": "6\n", "authors": ["505"]}
{"title": "N-Code: An Optimal RAID-6 MDS Array Code for Load Balancing and High I/O Performance\n", "abstract": " Existing RAID-6 codes are developed to optimize either reads or writes for storage systems. To improve both read and write operations, this paper proposes a novel RAID-6 MDS array code called N-Code. N-Code exhibits three aspects of salient features:(i) read performance. N-Code assigns both horizontal parity chains and horizontal parities across disks, without generating a dedicated parity disk. Such a parity layout not only makes all the disks service normal reads, but also allows continuous data elements to share the same horizontal chain to optimize degraded reads;(ii) write performance. Diagonal parities are distributed across disks in a decentralized manner to optimize partial stripe writes, and horizontal parity chains enable N-Code to reduce I/O costs of partial stripe writes by merging I/O operations; and (iii) balancing performance. Decentralized horizontal/diagonal parities potentially support the I/O\u00a0\u2026", "num_citations": "6\n", "authors": ["505"]}
{"title": "Revisiting updating schemes for erasure-coded in-memory stores\n", "abstract": " Erasure coding has been gradually adopted by existing data-intensive in-memory stores for 'hot' data; small writes lead to expensive updating overheads in such in-memory stores characterized by update-heavy workloads. There is a pressing demand to address the issue of data updates for erasure-coded in-memory stores. We revisit existing updating schemes in erasure-coded storage clusters by investigating the applicability of these updating schemes to erasure-coded in- memory stores. After an intensive analysis, we propose a grouping-update mechanism - GU - to handle small writes in in-memory stores. With GU in place, requests in an updating window are categorized into several updating groups, where multiple small updates in the same stripe can be executed concurrently. Furthermore, we bring forward a hybrid-updating scheme - Hybrid-U - to minimize total updating I/Os over network under common\u00a0\u2026", "num_citations": "6\n", "authors": ["505"]}
{"title": "Comparison of body mass index with abdominal obesity for identifying elevated blood pressure in children and adolescents: The SNEC study\n", "abstract": " Body mass index (BMI) and waist circumference (WC) are two common ways to measure obesity. There is a debate, however, about which of these two measures are more closely associated with elevated blood pressure (BP). The aim of this study is to investigate the prevalence of obesity and whether BMI and WC is better associated with elevated BP in children and adolescents. A representative sample of 8613 Chinese youth aged 7\u201317 years from seven cities in Northeastern China was selected and measurements of height, weight, WC, BP were taken from 2012 to 2013. The average age of the children was 11.3\u00a0\u00b1\u00a02.3\u00a0years. The prevalence of overweight/obese and abdominal obesity in the subjects was 35% and 44.8%, respectively. We found that both BMI and WC were significantly associated with elevated BP. An increase of 1\u00a0kg\u00a0m\u22122 in BMI was associated with a 1.10 (1.08\u20131.12, 95% CI) increased risk of an\u00a0\u2026", "num_citations": "6\n", "authors": ["505"]}
{"title": "Continuous synthesis of ginkgolide B derivatives in a micro-flow system\n", "abstract": " In this study, etherification process of ginkgolide B in a micro-flow system was investigated. With calcium carbonate as an acid-binding agent, the optimal result was obtained in such conditions: residence time 3\u00a0min, temperature 85\u00a0\u00b0C, molar ratio of ginkgolide B to dimethylamino ethyl chloride hydrochloride 1:2, molar ratio of ginkgolide B to potassium iodide 1:0.2, and molar ratio of ginkgolide B to calcium carbonate 1:2.5. Meanwhile, this novel process in MFS could proceed well for the etherification reaction between ginkgolide B and other halides, to afford the target products in moderate yields. Besides, salification reaction was conducted in a valve assisted micromixer by reacting dimethylaminoethyl ginkgolide B with methane sulfonic acid. Compared with conventional drugs, enhanced bioavailability was obtained when nano-scale drugs were dosed.", "num_citations": "6\n", "authors": ["505"]}
{"title": "An indoor localization of WiFi based on branch-bound algorithm\n", "abstract": " Indoor localization based on existing WiFi signal strength is becoming increasingly prevalent. Many indoor localization algorithms have been proposed, such as NN, KNN and WKNN. In this paper, we propose an indoor localization of WiFi based on branch-bound algorithm(ILBBA). The ILBBA consists of offline and online phase. In the offline phase, the received signal strength(RSS) is collected by mobile devices, and is dealt with ILBBA to build fingerprint map; while in the online phase, real-time measured RSS is matched with the fingerprint map. Experimental results indicate that the proposed algorithm achieves high localization accuracy while reducing the computation complexity.", "num_citations": "6\n", "authors": ["505"]}
{"title": "Detection of FasL mRNA, sFasL and their regulatory effect on T lymphocyte subsets in patients with severe acute pancreatitis\n", "abstract": " OBJECTIVE: To investigate the levels of FasL mRNA in peripheral blood mononualear cells (PBMCs), serum soluble Fas ligand (sFasL) and their regulatory effect on T lymphocyte subsets in patients with severe acute pancreatitis (SAP). METHODS: Forty-eight patients with pancreatitis were randomly divided into two groups: 20 cases with SAP and 28 cases with mild acute pancreatitis (MAP). Twenty-eight healthy volunteers were selected as control group. The expression of FasL mRNA in PBMCs was detected by real-time quantitative PCR (qRT-PCR), and serum sFasL was measured by ELISA. T lymphocyte subsets in peripheral blood were detected by flow cytometry. RESULTS: Compared with control group and MAP group, FasL mRNA of PBMCs and serum sFasL increased significantly in SAP group (P< 0.05), a little increase in MAP group, and there was no significant difference between MAP group and control group (P> 0.05). The CD4 (+) T cell ratio, CD4 (+)/CD8 (+) ratio decreased significantly in SAP group (P< 0.05) vs control group and MAP group), and they were found negatively related to FasL mRNA, serum sFasL level. CONCLUSION: The SAP patients showed the significantly increased FasL mRNA of PBMCs and serum sFasL and decreased CD4 (+) T-cell ratio, CD4 (+)/CD8 (+) ratio. FasL may mediate the apoptosis of T lymphocytes.", "num_citations": "6\n", "authors": ["505"]}
{"title": "Performance evaluation of online backup cloud storage\n", "abstract": " Cloud storage provides storage services to users via Internet. They provide lavish interfaces for different applications. Online backup is the most developed application based on cloud storage. Most past studies focus on functional characters and price per GB. But there is not much consideration about performance evaluation. In this paper, the authors present a method to evaluate the performance of different online backup services with clients. Because these clients do not prompt when the download/upload process starts and finishes, the authors capture the packets transferred between clients and the cloud storage provider. The authors evaluate the performance from the view of the end-user, comparing the upload and download speeds of different services. This method can help users find the best provider to accommodate their situation. The authors evaluate the performance of several cloud storage providers by\u00a0\u2026", "num_citations": "6\n", "authors": ["505"]}
{"title": "Evaluation of spatial keyword queries with partial result support on spatial networks\n", "abstract": " Numerous geographic information system applications need to retrieve spatial objects which bear user specified keywords close to a given location. In this research, we present efficient approaches to answer spatial keyword queries on spatial networks. In particular, we formally introduce definitions of Spatial Keyword k Nearest Neighbor (SKkNN) and Spatial Keyword Range (SKR) queries. Then, we present a framework of a spatial keyword query evaluation system which is comprised of Keyword Constraint Filter (KCF), Keyword and Spatial Refinement (KSR), and the spatial keyword ranker. KCF employs an inverted index to calculate keyword relevancy of spatial objects, and KSR refines intermediate results by considering both spatial and keyword constraints with the spatial keyword ranker. In addition, we design novel algorithms for evaluating SKkNN and SKR queries. These algorithms employ the inverted\u00a0\u2026", "num_citations": "6\n", "authors": ["505"]}
{"title": "Simultaneous determination of ciprofloxacin and flumequine in water samples by high performance liquid chromatography\n", "abstract": " In order to meet the field sample measurements and laboratory research, a simple, stable, and popular high performance liquid chromatographic (HPLC) method was established for the determination of the concentrations of two fluoroquinolone antibiotics in water samples simultaneously and rapidly. Thus, it could provide valuable information for other scholars to study the interactions between different antibiotics. Ciprofloxacin (CIP) and flumequine (FLU) were taken as the target contaminants because of their wide application in medical career. Furthermore, this study also investigated the different types of mobile phase, different mobile phase ratios, common ions (Ca2+, Mg2+, Fe3+, Al3+, SO4 (2-) and HCO3 (-)) in water samples and other factors on CIP and FLU measurements with this method. The results showed that triethylamine has obvious effect on improving column efficiency. Low concentrations of ions had little effect on the test, but Fe3+ and Al3+ might cause baseline instability, because Fe3+ and Al3+ may form complexes with the surface hydroxyl groups of the stationary phase or the test components. The results may be referred by other workers for the optimization of the determination conditions.", "num_citations": "6\n", "authors": ["505"]}
{"title": "Case study of visualizing global user download patterns using Google Earth and NASA World Wind\n", "abstract": " Geo-visualization is significantly changing the way we view spatial data and discover information. On the one hand, a large number of spatial data are generated every day. On the other hand, these data are not well utilized due to the lack of free and easily used data-visualization tools. This becomes even worse when most of the spatial data remains in the form of plain text such as log files. This paper describes a way of visualizing massive plain-text spatial data at no cost by utilizing Google Earth and NASA World Wind. We illustrate our methods by visualizing over 170,000 global download requests for satellite images maintained by the Earth Resources Observation and Science (EROS) Center of U.S. Geological Survey (USGS). Our visualization results identify the most popular satellite images around the world and discover the global user download patterns. The benefits of this research are: 1. assisting in\u00a0\u2026", "num_citations": "6\n", "authors": ["505"]}
{"title": "Fuzzy distance-based range queries over uncertain moving objects\n", "abstract": " Data obtained from real world are imprecise or uncertain due to the accuracy of positioning devices, updating protocols or characteristics of applications. On the other hand, users sometimes prefer to qualitatively express their requests with vague conditions and different parts of search region are in-equally important in some applications. We address the problem of efficiently processing the fuzzy range queries for uncertain moving objects whose whereabouts in time are not known exactly, for which the basic syntax is find objects always/sometimes near to the query issuer with the qualifying guarantees no less than a given threshold during a given temporal interval. We model the location uncertainty of moving objects on the utilization of probability density functions and describe the indeterminate boundary of query range with fuzzy set. We present the qualifying guarantee evaluation of objects, and propose\u00a0\u2026", "num_citations": "6\n", "authors": ["505"]}
{"title": "Gene polymorphisms of GSTM_1 and GSTT_1 in the clustering families of hepatocellular carcinoma\n", "abstract": " Objective To investigate the relationship between gene polymorphisms of glutathione-S-transferase M1 (GSTM1) and T1 (GSTT1) and hepatocellular carcinoma (HCC)-clustering family. Methods the genotype of GSTM1 and GSTT1 in the HCC-clustering family and high-incidence pedigrees of HCC were detected with PCR. Results The frequencies of GSTM1 null and GSTT1 null genotype were 68.8% and 47.5% in the group of HCC-clustering family respectively, which were significantly higher than those of the none-clustering HCC family (54.6% and 30.8%) and control group (53.3% and 25.3%). The same tendency was also found between high-incidence pedigrees of HCC and control pedigrees. With the increasing number of HCC patient in familial history, the frequencies of GSTM1 null and GSTT1 null genotype increased too. The risk of HCC increased with the GSTM1 null genotype combined GSTT1 null genotype. Conclusion Gene polymorphisms of GSTM1 and GSTT1 are associated with the susceptibility of HCC-clustering family. GSTM1 null genotype and GSTT1 null genotype are the risk factors in HCC-clustering family.", "num_citations": "6\n", "authors": ["505"]}
{"title": "Improving energy-efficiency of computational grids via scheduling\n", "abstract": " High performance Grid platforms and parallel computing technologies are experiencing their golden age because of the convergence of four critical momentums: high performance microprocessors, high-speed networks, free middleware tools, and highly increased needs of computing capability. We are witnessing the rapid development of computational Grid technologies. Dozens of exciting Grid infrastructures and projects like Grid-tech, Grid Portals, Grid Fora, and Commercial Grid Initiatives are being built all over the world. However, the fast growing power consumption of data centers has caused serious concerns for building more large-scale supercomputers, clusters, and Grids. Therefore, designing energy-efficient computational Grids to make them economically attractive and environmentally friendly for parallel applications becomes highly desirable. Unfortunately, most previous studies in Grid computing\u00a0\u2026", "num_citations": "6\n", "authors": ["505"]}
{"title": "Improving energy efficiency and security for disk systems\n", "abstract": " Improving security and minimizing power consumption are crucial for large-scale data storage systems. Although a handful of studies have been focused on data security and energy efficiency, most of the existing approaches have concentrated on only one of these two metrics. In this paper, we present a new approach to integrating power optimization with security services to enhance the security of energy-efficient large-scale storage systems. In our approach, we make use of the dynamic speed control for power management technique, or DRPM, to conserve energy in secure storage systems. In this study we develop two ways of integrating confidentiality services with the dynamic disk speed control technique. The first strategy - security aggressive in nature - is focused on the improvement of storage system security with less emphasis on energy conservation. The second strategy gives higher priority to energy\u00a0\u2026", "num_citations": "6\n", "authors": ["505"]}
{"title": "The sensitive regions identified by CNOPs of three typhoon events\n", "abstract": " In this paper, several sets of observing system simulation experiments (OSSEs) were designed for three typhoon cases to determine whether or not the additional observation data in the sensitive regions identified by conditional nonlinear optimal perturbations (CNOPs) could improve the short-range forecast of typhoons. The results show that the CNOPs capture the sensitive regions for typhoon forecasts, which implies that conducting additional observation in these specific regions and eliminating initial errors could reduce forecast errors. It is inferred from the results that dropping sondes in the CNOP sensitive regions could lead to improvements in typhoon forecasts.", "num_citations": "6\n", "authors": ["505"]}
{"title": "Reversible logic synthesis with positive/negative control model\n", "abstract": " BackgroundAbstract Based on traditional Toffoli gate, a new reversible network cascade model PNCRC is proposed. The model consists of five line-styles, and it is able to control output of target bits with positive/negative way effectively. A reversible synthesis algorithm corresponding to the proposed model is also designed in this paper. Compared to the previously reported results, some experiments on NCMC Benchmark functions (less than or equal 16 variables) show that PNCRC decrease the number of garbage output and number of reversible gates as a whole.", "num_citations": "6\n", "authors": ["505"]}
{"title": "PTool: A light weight persistent object manager\n", "abstract": " Analyzing, mining and extracting information from data does not require a full featured database, but rather simply the ability to work with persistent data. Advantages of \u2018(light weight\u201d data management include: 1) Light weight software tools allow applications to have high performance, low overhead access to persistent data. 2) Light weight software tools can easily be customized and optimized. We have developed a software tool called PToo1 that provides high performance, low overhead access to persistent data. PToo1 is usually used as a library, which when linked to a C++ application provides persistence for instances of C++ classes which are created using an overloaded\u201cnew\u201d operator.Our primary target applications are scientific computing and data mining. For this reason, PToo1 does not support transactions, back up and recovery, or any of the other functionality usually associated with an object oriented\u00a0\u2026", "num_citations": "6\n", "authors": ["505"]}
{"title": "A novel deep learning method for predictive modeling of microbiome data\n", "abstract": " With the development and decreasing cost of next-generation sequencing technologies, the study of the human microbiome has become a rapid expanding research field, which provides an unprecedented opportunity in various clinical applications such as drug response predictions and disease diagnosis. It is thus essential and desirable to build a prediction model for clinical outcomes based on microbiome data that usually consist of taxon abundance and a phylogenetic tree. Importantly, all microbial species are not uniformly distributed in the phylogenetic tree but tend to be clustered at different phylogenetic depths. Therefore, the phylogenetic tree represents a unique correlation structure of microbiome, which can be an important prior to improve the prediction performance. However, prediction methods that consider the phylogenetic tree in an efficient and rigorous way are under-developed. Here, we\u00a0\u2026", "num_citations": "5\n", "authors": ["505"]}
{"title": "CalmWPC: A buffer management to calm down write performance cliff for NAND flash-based storage systems\n", "abstract": " NAND Flash-based solid state disks (i.e., SSDs) are widely applied in large-scale storage systems. However, NAND Flash is featured with the asymmetric read and write performance, high erase latency, and the limited number of program/erase cycles (P/Es). Under random write-intensive workloads, a garbage collection (i.e., GC) process inside SSDs causes write performance cliff, which causes high latency for I/O access and degrades SSD lifetime. In real-time transactional applications, such large write performance cliff affects the response time of I/O requests, thereby leading to serious critical errors in real-time applications.To handle this issue, we propose a buffer management strategy called CalmWPC to calm down SSD write performance cliff. CalmWPC seamlessly integrates a data cluster-based data management, a historical access-based prediction algorithm, a semantic fingerprint database. The\u00a0\u2026", "num_citations": "5\n", "authors": ["505"]}
{"title": "SmartRec: fast recovery from single failures in heterogeneous RAID-coded storage systems\n", "abstract": " It is not uncommon for reconstruction I/Os to encounter workload fluctuation in heterogeneous RAID-coded storage systems. This paper proposes a heterogeneity-aware single-failure recovery scheme\u2014SmartRec\u2014to tolerate double and multiple disk failures in RAIDs. We start this study by formulating the data recovery problem of single-disk failures in form of an optimization function in the context of online and heterogeneous disk arrays. To take both static heterogeneity associated with disk configurations and dynamic heterogeneity affected by I/O loads into account, SmartRec periodically selects an appropriate reconstruction solution according to up-to-date disk utilization. The appropriate reconstruction solution indicates the amount of data being retrieved across surviving disks and is expected to achieve minimal recovery time, which is induced by both candidate reconstruction sequences and\u00a0\u2026", "num_citations": "5\n", "authors": ["505"]}
{"title": "One Size Does Not Fit All: An Ensemble Approach Towards Information Extraction from Adverse Drug Event Narratives.\n", "abstract": " Recognizing named entities in Adverse Drug Reactions narratives is a fundamental step towards extracting valuable patient information from unstructured text into a structured thus actionable format. This then unlocks advanced data analytics towards intelligent pharmacovigilance. Yet existing biomedical named entity recognition (NER) tools are limited in their ability to identify certain entity types from these domain-specific narratives and result in significant performance differences in terms of accuracy. To address these challenges, we propose an ensemble approach that integrates a rich variety of named entity recognizers to procure the final result. First, one critical problem faced by NER in the biomedical context is that the data is highly skewed. That is, only 1% of words belong to a certain medical entity type, such as, the reason for medication usage compared to all other non-reason words. We propose a balanced, under-sampled bagging strategy that is dependent on the imbalance level to overcome the class imbalance problem. Second, we present an ensemble of heterogeneous recognizers approach that leverages a novel ensemble combiner. Our experimental results show that for biomedical text datasets:(i) a balanced learning environment along with an Ensemble of Heterogeneous Classifiers constantly improves the performance over individual base learners and,(ii) stacking-based ensemble combiner methods outperform simple Majority Voting by 0.30 F-measure.", "num_citations": "5\n", "authors": ["505"]}
{"title": "Endurable SSD-based read cache for improving the performance of selective restore from deduplication systems\n", "abstract": " Deduplication has been commonly used in both enterprise storage systems and cloud storage. To overcome the performance challenge for the selective restore operations of deduplication systems, solid-state-drive-based (ie, SSD-based) read cache can be deployed for speeding up by caching popular restore contents dynamically. Unfortunately, frequent data updates induced by classical cache schemes (eg, LRU and LFU) significantly shorten SSDs\u2019 lifetime while slowing down I/O processes in SSDs. To address this problem, we propose a new solution\u2014LOP-Cache\u2014to greatly improve the write durability of SSDs as well as I/O performance by enlarging the proportion of long-term popular (LOP) data among data written into SSD-based cache. LOP-Cache keeps LOP data in the SSD cache for a long time period to decrease the number of cache replacements. Furthermore, it prevents unpopular or unnecessary data in deduplication containers from being written into the SSD cache. We implemented LOP-Cache in a prototype deduplication system to evaluate its performance. Our experimental results indicate that LOP-Cache shortens the latency of selective restore by an average of 37.3% at the cost of a small SSD-based cache with only 5.56% capacity of the deduplicated data. Importantly, LOP-Cache improves SSDs\u2019 lifetime by a factor of 9.77. The evidence shows that LOP-Cache offers a cost-efficient SSD-based read cache solution to boost performance of selective restore for deduplication systems.", "num_citations": "5\n", "authors": ["505"]}
{"title": "Ress: A reliable energy-efficient storage system\n", "abstract": " Extracting high I/O performance from parallel file systems is no longer the only goal in modern data centres. As issues of the Energy Wall and the Reliability Wall become unavoidable, it is a demanding and challenging task to reduce energy consumption in large-scale storage systems in modern data centres while retaining acceptable systems reliability. Most energy conservation techniques inevitably have adverse impacts on the parallel disk systems. To address the reliability issues of energy-efficient parallel storage systems, we propose a reliable energy-efficient storage system called RESS, which aims at improving both energy efficiency and reliability of parallel storage systems by seamlessly integrating HDDs and SSDs. At the heart of the RESS is a transformative middleware layer, which reorganizes the I/O workload for the underlying parallel file systems. With the help of the middleware layer, RESS can\u00a0\u2026", "num_citations": "5\n", "authors": ["505"]}
{"title": "Secure replica allocation in cloud storage systems with heterogeneous vulnerabilities\n", "abstract": " Highly available cloud storage is often implemented with complex, multi-tiered distributed systems built on top of clusters of commodity servers and disk drives. Storage reliability, security and performance are among the top desired features when clients consider storing data on cloud storage. Although replication improves reliability and performance in cloud storage systems, data replication increases the risk of data storage in an insecure network environment. When a cloud storage scales up, storage nodes are very likely to become heterogeneous in nature. In this study, we propose a secure replica allocation scheme called SecRA to improve security, reliability, and performance of a cloud storage system where storage nodes have a wide variety of vulnerabilities. Our SecRA integrates the techniques of replication and fragmentation with secret sharing in a heterogeneous cloud system, where storage nodes are\u00a0\u2026", "num_citations": "5\n", "authors": ["505"]}
{"title": "MINT: A Reliability Modeling Frameworkfor Energy-Efficient Parallel Disk Systems\n", "abstract": " The Popular Disk Concentration (PDC) technique and the Massive Array of Idle Disks (MAID) technique are two effective energy conservation schemes for parallel disk systems. The goal of PDC and MAID is to skew I/O load toward a few disks so that other disks can be transitioned to low power states to conserve energy. I/O load skewing techniques like PDC and MAID inherently affect reliability of parallel disks, because disks storing popular data tend to have high failure rates than disks storing cold data. To study reliability impacts of energy-saving techniques on parallel disk systems, we develop a mathematical modeling framework called MINT. We first model the behaviors of parallel disks coupled with power management optimization policies. We make use of data access patterns as input parameters to estimate each disk's utilization and power-state transitions. Then, we derive each disk's reliability in terms of\u00a0\u2026", "num_citations": "5\n", "authors": ["505"]}
{"title": "A secure file allocation algorithm for heterogeneous distributed systems\n", "abstract": " In this study we develop a secure allocating processing(SAP) algorithm for the S-FAS scheme [13] to improve the security level and consider its performance using the heterogeneous feature of a large distributed system. The SAP allocation algorithm considers load balancing, delayed effects caused by the workload variance of many consecutive requests, and the heterogeneous feature of the storage nodes in the system. We develop a prototype using the multi-threading technique for the S-FAS scheme with the SAP algorithm to guide the file allocation. We did some experiments and the results show that the proposed solution can not only improve the security level, but also improve the throughput of the distributed storage system with heterogeneous vulnerabilities by using the multi-thread technique.", "num_citations": "5\n", "authors": ["505"]}
{"title": "Obtaining exact interpolation multivariate polynomial by approximation\n", "abstract": " In some fields such as Mathematics Mechanization, automated reasoning and Trustworthy Computing, etc., exact results are needed. Symbolic computations are used to obtain the exact results. Symbolic computations are of high complexity. In order to improve the situation, exact interpolating methods are often proposed for the exact results and approximate interpolating methods for the approximate ones. In this paper, the authors study how to obtain exact interpolation polynomial with rational coefficients by approximate interpolating methods.", "num_citations": "5\n", "authors": ["505"]}
{"title": "Energy conservation for real-time disk systems with I/O burstiness\n", "abstract": " Energy conservation has become a critical problem for real-time embedded storage systems. Although a variety of approaches to reducing energy consumption has been extensively studied, energy conservation for real-time embedded storage systems is still an open problem. In this paper, we propose an energy management strategy (IBEC) using I/O burstiness for real time embedded storage systems. Our approach aims at blending the IBEC energy management strategy with low level disk scheduling mechanism to conserve energy consumed by storage systems. Extensive experiments are conducted involving a number of different load patterns as well as real-world data-intensive applications. To prove the efficiency of IBEC, we compare the performance of IBEC against three existing strategies, namely, PA-EDF, DP-EDF, and EDF. Results demonstratively show that compared with the alternative strategies, IBEC reduces the power consumption of real-time embed disks system by up to 60%.", "num_citations": "5\n", "authors": ["505"]}
{"title": "Adaptive quality of security control in networked parallel disk systems\n", "abstract": " Parallel disk systems, which have been widely used in building networked and data intensive applications, are highly scalable and can alleviate the problem of disk I/O bottleneck. Although a number of parallel disk systems have been developed, the systems lack a means to optimize quality of security for dynamically changing networked environments. We remedy this situation by proposing an adaptive quality of security control scheme for networked parallel disk systems (or ASPAD for short) that makes it possible for networked disk systems to adapt to changing security requirements and workload conditions. ASPAD is carried out in three phases: dynamic data partitioning, response time estimation, and adaptive security quality control. Hence, ASPAD is conducive to adaptively and expeditiously determining security schemes for disk requests in a way to improve security of networked parallel disk systems while\u00a0\u2026", "num_citations": "5\n", "authors": ["505"]}
{"title": "Adjoint matching condition for parameterized discontinuities\u2014A derivation using Lagrangian\u2013form costfunction\n", "abstract": " The generalized adjoint property and adjoint matching condition for systems that contain discontinuous on/off switches are derived by a perturbation analysis of the Lagranging-form costfunction.", "num_citations": "5\n", "authors": ["505"]}
{"title": "Parallel query processing for event store data\n", "abstract": " Enormous data volumes and large, geographically dispersed user communities characterize the next generation of experiments in high energy physics and other scientific disciplines. Parallel processing will be integral to the solution of the information storage and retrieval problems that these experiments will engender. We describe several approaches to parallel query processing that have been implemented in the early stages of the PASS (Petabyte Access and Storage Solutions) project. These have been tested on an object-oriented persistent event store built from Fermilab CDF data, and evaluated on the 128-processor IBM SP-1 at Argonne National Laboratory, as well as on networks of workstations.", "num_citations": "5\n", "authors": ["505"]}
{"title": "Medical entity disambiguation using graph neural networks\n", "abstract": " Medical knowledge bases (KBs), distilled from biomedical literature and regulatory actions, are expected to provide high-quality information to facilitate clinical decision making. Entity disambiguation (also referred to as entity linking) is considered as an essential task in unlocking the wealth of such medical KBs. However, existing medical entity disambiguation methods are not adequate due to word discrepancies between the entities in the KB and the text snippets in the source documents. Recently, graph neural networks (GNNs) have proven to be very effective and provide state-of-the-art results for many real-world applications with graph-structured data. In this paper, we introduce ED-GNN based on three representative GNNs (GraphSAGE, R-GCN, and MAGNN) for medical entity disambiguation. We develop two optimization techniques to fine-tune and improve ED-GNN. First, we introduce a novel strategy to\u00a0\u2026", "num_citations": "4\n", "authors": ["505"]}
{"title": "TIVAN: tissue-specific cis-eQTL single nucleotide variant annotation and prediction\n", "abstract": " Summary           Predicting genetic regulatory variants, most of which locate in non-coding genomic regions, still remain a challenge in genetic research. Among all non-coding regulatory variants, cis-eQTL single nucleotide variants (SNVs) are of particular interest for their crucial role in regulating gene expression. Since different gene expression patterns are believed to contribute to the etiologies of different phenotypes, it is desirable to characterize the impact of cis-eQTL SNVs in a context-specific manner. Though computational methods for predicting the potential of variants being pathogenic or deleterious are well-established, methods for annotating and predicting cis-eQTL SNVs are under-developed. Here, we present TIVAN (TIssue-specific Variant ANnotation and prediction), an ensemble method of decision trees, to predict tissue-specific cis-eQTL SNVs. TIVAN is trained based on a comprehensive\u00a0\u2026", "num_citations": "4\n", "authors": ["505"]}
{"title": "PaRS: A popularity-aware redundancy scheme for in-memory stores\n", "abstract": " In-memory store has become a key component for an increasing number of data-intensive applications like OLTP and OLAP. To be resilient to data loss incurred by transient failures, redundancy strategies are incorporated into in-memory stores. In-memory datasets are characterized by skewed popularity, because they exhibit varied access frequencies (a.k.a., number of accesses). Therefore, it is prudent to apply customized redundancy schemes with dynamic memory efficiency and access parallelisms to different in-memory datasets. In this work, we propose an adaptive redundancy scheme-PaRS-for in-memory datasets. PaRS relies on a re-stripe or replication mechanism to transform involved redundancy groups according to their workload popularity growth. With PaRS in place, a memory-efficient redundancy layout is deployed for data blocks with low access frequencies; a redundancy layout exhibiting high\u00a0\u2026", "num_citations": "4\n", "authors": ["505"]}
{"title": "GreenDB: Energy-efficient prefetching and caching in database clusters\n", "abstract": " In this study, we propose an energy-efficient database system called GreenDB running on clusters. GreenDB applies a workload-skewness strategy by managing hot nodes coupled with a set of cold nodes in a database cluster. GreenDB fetches popular data tables to hot nodes, aiming to keep cold nodes in the low-power mode in increased time periods. GreenDB is conducive to reducing the number of power-state transitions, thereby lowering energy-saving overhead. A prefetching model and an energy saving model are seamlessly integrated into GreenDB to facilitate the power management in database clusters. We quantitatively evaluate GreenDB's energy efficiency in terms of managing, fetching, and storing data. We compare GreenDB's prefetching strategy with the one implemented in Postgresql. Experimental results indicate that GreenDB conserves the energy consumption of the existing solution by up to\u00a0\u2026", "num_citations": "4\n", "authors": ["505"]}
{"title": "Thermal benchmarking and modeling for HPC using big data applications\n", "abstract": " Characterizing thermal profiles of cluster nodes is an integral part of any approach that addresses thermal emergencies in a data center. Most existing thermal models make use of CPU utilization to estimate power consumption, which in turn facilitates outlet-temperature predictions. Such utilization-based thermal models may introduce errors due to inaccurate mappings from system utilization to outlet temperatures. To address this concern in the existing models, we eliminate utilization models as a middleman from the thermal model. In this paper, we propose a thermal model, tModel, that projects outlet temperatures from inlet temperatures as well as directly measured multicore temperatures rather than deploying a utilization model. In the first phase of this work, we perform extensive experimentation by varying applications types, their input data sizes, and cluster sizes. Simultaneously, we collect inlet, outlet, and\u00a0\u2026", "num_citations": "4\n", "authors": ["505"]}
{"title": "Mediar: multi-drug adverse reactions analytics\n", "abstract": " Adverse drug reactions (ADRs) caused by drug-drug interactions (DDI) are a major cause of morbidity and mortality worldwide. There is a growing need for computing-supported methods that facilitate the automated signaling of DDI related ADRs (DIARs) that otherwise would remain undiscovered in millions of ADR reports. In this demonstration, we showcase our MeDIAR technology - an end-to-end DIAR signal generation, exploration and validation solution for pharmaceutical regulatory agencies to detect true DIAR signals from a drug surveillance database. MeDIAR's innovations include an efficient rule-driven learning algorithm for deriving DIAR signals from ADR reports, an innovative scoring methodology based on the proposed contextual association cluster model to rank the generated signals by their importance. Further, these ranked signals are augmented with meta information such as their significance\u00a0\u2026", "num_citations": "4\n", "authors": ["505"]}
{"title": "Doxycycline affects gene expression profiles in aortic tissues in a rat model of vascular calcification\n", "abstract": " Vitamin D3-induced vascular calcification (VC) in rats shares many phenotypical similarities with calcification occurring in human atherosclerosis, diabetes mellitus and chronic kidney disease, thereby it is a reliable model for identifying chemopreventive agents. Doxycycline has been shown to effectively attenuated VC. This study aimed to explore the effects of doxycycline on gene expression profiles in VC rats. The model of VC in rats was established by subcutaneous injection of vitamin D3 for 3\u00a0days. Doxycycline at 120\u00a0mg\u00a0kg\u2212\u00a01\u00a0day\u2212\u00a01 was given via subcutaneous injection for 14\u00a0days. Rat pathological changes, calcium deposition and calcium content in aortic tissues were measured by Hematoxylin\u2013eosin, von Kossa staining and colorimetry, respectively. The gene change profile of aortic tissues after doxycycline treatment was assessed by Gene Microarray analysis using the Agilent Whole Rat Genome Oligo\u00a0\u2026", "num_citations": "4\n", "authors": ["505"]}
{"title": "Wps: A workload-aware placement scheme for erasure-coded in-memory stores\n", "abstract": " Data-intensive applications are increasingly depending on in-memory stores to meet high-I/O-performance requirements. To be resilient to server failures and in turn achieve high availability, both replication and erasure codes are introduced to in-memory stores. Since erasure codes have an advantage of memory efficiency over replication, we focus our work on erasure-coded in-memory stores and investigate placement schemes to address the issue of workload fluctuation. To mitigate the I/O imbalanced incurred by workload skew and maximize the utilization of all nodes, we proposed a Workload-aware Placement Scheme called WPS for Reed-Solomon-coded in-memory stores. WPS accomplishes balanced I/Os as follows: it divides in-memory data blocks into multiple groups based on access characteristics (e.g., popularity), and classifies all nodes into several groups according to nodes' access performance (e\u00a0\u2026", "num_citations": "4\n", "authors": ["505"]}
{"title": "Location\u2010preserved contention\u2010based routing in vehicular ad hoc networks\n", "abstract": " Location privacy protection in vehicular ad hoc networks considers preserving two types of information: the locations and identifications of users. However, existing solutions, which either replace identifications by pseudonyms or hide locations in areas, cannot be directly applied to geographic routing protocols because they degrade network performance. To address this issue, we proposed a location\u2010preserved contention (LPC) based routing protocol, in which greedy forwarding is achieved using dummy distance to the destination information instead of users\u2019 true locations. Unlike the contention\u2010based forwarding protocol, the number of duplicated responses in LPC can be reduced by adjusting the parameter \u03b1, which is a timer scaling factor. To quantify the efficiency of location privacy protection, an entropy\u2010based analytical method is proposed. LPC is compared with existing routing and location privacy\u00a0\u2026", "num_citations": "4\n", "authors": ["505"]}
{"title": "Medicine Sciences and Bioengineering: Proceedings of the 2014 International Conference on Medicine Sciences and Bioengineering (ICMSB2014), Kunming, Yunnan, China, August 16-17\u00a0\u2026\n", "abstract": " This proceedings volume contains selected papers presented at the 2014 International Conference on Medicine Sciences and Bioengineering (ICMSB 2014), held August 16-17, 2014 in Kunming, Yunnan, China. ICMSB2014 was aimed at researchers, engineers, industrial professionals and academics, who were broadly welcomed to present their latest research res", "num_citations": "4\n", "authors": ["505"]}
{"title": "RB-Explorer: An Accurate and Practical Approach to Write Amplification Measurement for SSDs\n", "abstract": " A large write amplification ratio degrades the program/erase cycles (P/Es) of NAND Flashes and reduces the endurance and performance of solid state disks (SSDs). The lack of a practical way to measure write amplification for SSDs motivates us to propose a novel measuring method called RB-Explorer at the SSD level rather than the NAND Flash level. The goal of RB-Explorer is two-fold: (1) to accurately measure the write amplification of SSDs to quantify SSD endurance and (2) to study the impacts of I/O techniques on write amplification of SSDs. RB-Explorer incorporates a Ready/Busy (R/B) signal of one of the NAND Flashes in an SSD in a proposed write amplification model for SSDs with four full-parallelism levels (i.e., the channel, chip, die, and plane levels). RBExplorer takes two steps toward measuring write amplification. First, RB-Explorer quantifies the number of page programs using the low R/B signal\u00a0\u2026", "num_citations": "4\n", "authors": ["505"]}
{"title": "Green synthesis of silver nanoparticles and their application in SERS\n", "abstract": " In the present paper, we have successfully synthesized silver nancomparticles by reducing of silver nitrate in alkaline solution via 60 water bath for 20 minutes with the use of tyrosine, a nontoxic and green macromolecule, as a reducing and stabilizing agent. The formation of silver nanoparticles was observed visually by color change of the solutions (from faint yellow to brown yellow). The morphologies of the Ag NPs were characterized by UV-Vis absorption spectroscopy and transmission electron microscopy (TEM). The UV-Vis absorption peak of silver nanoparticles located at 412 nm. The TEM image of silver nanoparticles indicated that the diameters of nanospheres are mainly in the range 1525 nm. In order to evaluate the SERS activity of the silver nancomparticles, crystal violet and folic acid were used as the Raman probe molecule. The experimental results indicated that there are two ascendancies, firstly, the\u00a0\u2026", "num_citations": "4\n", "authors": ["505"]}
{"title": "Parallel computation of real solving bivariate polynomial systems by zero-matching method\n", "abstract": " We present a new algorithm for solving the real roots of a bivariate polynomial system \u03a3={f (x, y), g (x, y)} with a finite number of solutions by using a zero-matching method. The method is based on a lower bound for the bivariate polynomial system when the system is non-zero. Moreover, the multiplicities of the roots of \u03a3= 0 can be obtained by the associated quotient ring technique and a given neighborhood. From this approach, the parallelization of the method arises naturally. By using a multidimensional matching method this principle can be generalized to the multivariate equation systems.", "num_citations": "4\n", "authors": ["505"]}
{"title": "A qos scheduling scheme with availability constraint in distributed systems\n", "abstract": " An efficient resource management mechanism is important in a heterogeneous system to discover available resources, to allocate an appropriate subset of resources to applications, and to map data or tasks onto selected resources. The key component, tasks scheduling, draws our attention. Make span is the principal concern many existing researches. But, other QoS requirements are also important in more and more realistic applications. Like Grid service it is expected that the service provider be reliable, robust, or highly available. In this study, an existing availability-aware scheduling model called SSAC is investigated first. Then, we proposed an optimization approach to increase the availability and to reduce the make span of tasks running in heterogeneous systems. Three quantitative conditions are used to guide the optimization. Our experimental results show that compared with three existing solutions\u00a0\u2026", "num_citations": "4\n", "authors": ["505"]}
{"title": "New method based on region coarse localization and Chan-Vese model for weld pool edge extraction in MAG welding\n", "abstract": " The welding seam image gathered by an optical system composed of charge-coupled device (CCD) camera and composite filter technology for pipe-line back welding of metal active gas (MAG) is analyzed in a bid to extract the weld pool edge. Considering the effect of initial contour on Chan-Vese model, extract the rectangle representing the coarse location of molten weld pool by using the gray information after Gaussian smoother, and set the initial contour of Chan-Vese model at the center of the rectangle, then use the Chan-Vese model to extract the edge of the weld pool. Compared with the traditional methods, the experimental results show the precision of weld pool extraction is greatly improved.", "num_citations": "4\n", "authors": ["505"]}
{"title": "A Novel Mobility Management Protocol Supporting Network Seamless Roaming.\n", "abstract": " New wireless applications has grown very quickly in recent years. In some cases, several nodes need to move as a whole while the traditional mobile IP can\u2019t support a network roaming together. Improved Mobile IP-Roaming Supported protocol (IMIP-RS) is proposed in this paper. In IMIP-RS, the distance between mobile nodes and the domain agent can be multi-hops while the value in MIP is only 1-hop. It combines handoff and buffer technologies in layer 2 with extended mobile IP technology in layer 3. It allows a roaming net to keep normal communication during fast moving. A demo system is developed and the protocol is verified. Test results indicate that it\u2019s capable of achieving high data throughput, low response time and low packet loss rate. It can work with high quality of service (QoS) during rapid movement.", "num_citations": "4\n", "authors": ["505"]}
{"title": "Preventive effect of Chaenomeles fruits on non-alcoholic steatohepatitis in mice\n", "abstract": " Objective: To investigate the preventive effect of Chaenomeles fruits on non-alcoholic steatohepatitis (NASH) in mice. Methods: NASH model was established by high fat diet feeding combined with hypodermic injection at low dose of CCl4. NASH model group fed high fat diet containing Chaenomeles fruits for 5 consecutive weeks was served as Chaenomeles fruits-intervened group, while the mice in control group were fed normal diet. At the end of experiments, all the mice were sacrificed to analyze ALT, AST, TG and CHO levels in serum. Pathological changes of hepatic tissues were observed under microscope and mRNA expression of genes such as TGF-\u03b2, PD-L1, TLR-2, TLR-4 and IL-1\u03b2 in hepatic tissues was detected by the real time RT-PCR technique. Results: Compared to normal mice, ALT, TG and CHO levels in serum exhibited an obvious increase in NASH mice and a significant reduction in Chaenomeles fruits-intervened NASH mice (P0. 05). Hepatocyte swelling, as well as neutrophilic infiltration and hepatocyte ballooning exhibited a decrease in Chaenomeles fruits-intervened NASH mice. Meanwhile, a significant decrease in hepatic TLR-2, TLR-4, IL-1 \u03b2, TGF-\u03b2 and PD-L1 were also observed in Chaenomeles fruits-intervened NASH mice. Conclusion: Chaenomeles fruits have a significant preventive effect on non-alcoholic steatohepatitis in mice, which is achieved by regulating TLR and death receptor expression and the secretion of inflammatory cytokines.", "num_citations": "4\n", "authors": ["505"]}
{"title": "Efficiency of signal peptide sequence in yeast secretory expression system [J]\n", "abstract": " Yeasts were used for producing recombinant proteins, because of the unique advantages yeast offered as a unicellular eukaryot. It had become very popular for purified with high biological activity of over-production of both intracellular and extracellular recombinant proteins. Signal peptide played an important role in the secretion of protein and could lead to the extracellular secretion of protein, greatly enhanced the amount of protein expression. It had significance in the industrial production of exogenous protein and the purification. This article reviewed the choice of the signal peptide in the yeast expression system, adaptation, codon preference, the application of Secretion enhancer and sub-optimization of several aspects in order to efficiency improve the protein secretion in the yeast system.", "num_citations": "4\n", "authors": ["505"]}
{"title": "The synthesis and biological evaluation of 10-O-dialkylaminoethyl ginkgolide B as platelet-activating factor antagonist\n", "abstract": " Four nitrogen-containing derivatives of ginkgolide B were synthesized to improve the physical\u2013chemical properties and bioavailability of ginkgolide B. The reaction was accomplished with the nitrogen atom as neighboring group participating in the replacement reaction. All of the four compounds were proved to have excellent inhibiting effect on rabbit platelet aggregation induced by platelet-activating factor which is as well as ginkgolide B.", "num_citations": "4\n", "authors": ["505"]}
{"title": "Saha: A scheduling algorithm for security-sensitive jobs on data grids\n", "abstract": " Security-sensitive applications that access and generate large data sets are emerging in various areas such as bioinformatics and high energy physics. Data grids provide data-intensive applications with a large virtual storage framework with unlimited power. However, conventional scheduling algorithms for data grids are inadequate to meet the security needs of data-intensive applications. To remedy this deficiency, we address in this paper the problem of scheduling data-intensive jobs on data grids subject to security constraints. Using a security- and data-aware technique, SAHA (Security-Aware and Heterogeneity-Aware scheduling strategy) is proposed to improve quality of security for data-intensive applications running on data grids. Results based on real-world traces show that the proposed scheduling scheme dramatically improves security and performance over two existing scheduling algorithms", "num_citations": "4\n", "authors": ["505"]}
{"title": "Real-time control and optimization of traffic signal timing transition for emergency vehicle preemption\n", "abstract": " Emergency vehicle (EV) operation has a very important role to play in saving lives and reducing property damage. In order to reduce the response time and the impact of", "num_citations": "4\n", "authors": ["505"]}
{"title": "The discrete representation of continuously moving indeterminate objects\n", "abstract": " To incorporate indeterminacy in spatio-temporal database systems, grey modeling method is used for the calculations of the discrete models of indeterminate two dimension continuously moving objects. The Grey Model GM (1, 1) model generated from the snapshot sequence reduces the randomness of discrete snapshot and generates the holistic measure of object's movements. Comparisons to traditional linear models show that when information is limited this model can be used in the interpolation and near future prediction of uncertain continuously moving spatio-temporal objects.", "num_citations": "4\n", "authors": ["505"]}
{"title": "Uncertain spatio-temporal data model based on grey sets\n", "abstract": " The majority of spatio-temporal DBMS assume objects to be precise, but this simplification can't work in many military, navigation and environmental applications. Many forms of spatio-temporal data can't be measured exactly, and in these kinds of objects exists spatio-temporal indeterminacy. Spatio-temporal uncertainty management is a new topic for researchers on spatio-temporal databases. The current method based on Fuzzy Sets is not well applicable because it imposes strict restrictions on the objects' uncertainty. In this paper, a new abstract model of uncertain spatio-temporal objects is presented. This model is based on the Grey Sets and is more applicable for the presentation and manipulation of partial unknown spatio-temporal objects. This paper first gives the formal definition of uncertain abstract data types based on the Grey Sets, such as the definition of base types, spatial types and spatio-temporal types. Then we take a glimpse at the aspect of uncertain spatio-temporal analysis. Finally, examples of uncertain query is presented.", "num_citations": "4\n", "authors": ["505"]}
{"title": "An approach to satisfying security needs of periodic tasks in high performance embedded systems\n", "abstract": " Existing scheduling algorithms for periodic tasks ignore security requirements posed by sensitive applications and are consequently unable to perform properly in high performance embedded systems with security constraints. In this paper we present an approach to scheduling periodic tasks in high performance embedded systems subject to security and timing constraints. We propose a scheduling algorithm, or SASES (Security-Aware Scheduling for Embedded Systems), which accounts for both security and timing requirements. SASES judiciously distributes slack times among a variety of security services for a set of periodic tasks, thereby optimizing security for high-performance embedded systems without sacrificing schedulability. We show through extensive simulations that SASES is able to maximize security for highperformance embedded systems while guaranteeing timeliness. In particular, SASES significantly improves security over three baseline algorithms by up to 93.4%.", "num_citations": "4\n", "authors": ["505"]}
{"title": "A Feedback control mechanism for balancing I/O-and memory-intensive applications on clusters\n", "abstract": " One common assumption of existing models of load balancing is that the weights of resources and I/O buffer size are statically configured and cannot be adjusted based on a dynamic workload. Though the static configuration of these parameters performs well in a cluster where the workload can be modeled and predicted, its performance is poor in dynamic systems in which the workload is unknown. In this paper, a new feedback control mechanism is proposed to improve overall performance of a cluster with a general and practical workload including I/O-intensive and memory-intensive load. This mechanism is also shown to be effective in complementing and enhancing the performance of a number of existing dynamic load-balancing schemes. To capture the current and past workload characteristics, the primary objectives of the feedback mechanism are:(1) dynamically adjusting the resource weights, which indicate the significance of the resources, and (2) minimizing the number of page faults for memory-intensive jobs while increasing the utilization of the I/O buffers for I/O-intensive jobs by manipulating the I/O buffer size. Results from extensive trace-driven simulation experiments show that compared with a number of schemes with fixed resource weights and buffer sizes, the feedback control mechanism delivers a performance improvement in terms of the mean slowdown by up to 282%(with an average of 125%).", "num_citations": "4\n", "authors": ["505"]}
{"title": "Co-Active: A Workload-Aware Collaborative Cache Management Scheme for NVMe SSDs\n", "abstract": " When it comes to NAND Flash-based solid-state disks (SSDs), cache can narrow the performance gap between user-level I/Os and flash memory. Cache management schemes impose relentless impacts on the endurance and performance of flash memory. A vast majority of existing cache management techniques adopt a passive data-update style (e.g., GCaR, LCR), thereby undermining response times in burst I/O requests-based applications   . To address this issue, we propose a collaborative active write-back cache management scheme, called  Co-Active , customized for I/O access patterns and the usage status of a flash chip. We design a  hot/cold separation  module to determine whether data is cold or hot in workload. When a flash chip is idle, cold and dirty data in the cache is flushed into the idle flash chip to produce clean data. To curtail cache replacement cost, clean data are preferentially evicted amid\u00a0\u2026", "num_citations": "3\n", "authors": ["505"]}
{"title": "Feature grouping-based parallel outlier mining of categorical data using spark\n", "abstract": " This paper proposes a feature-grouping based parallel outlier mining method called POS for high-dimensional categorical datasets. Existing methods of outlier mining are inadequate to deal with datasets which are so voluminous and complex. We solve this problem by proposing a parallel framework using the Spark platform for categorical and mass data. POS is composed of two modules, which are parallel feature grouping, and parallel outlier mining. Additionally, Vertical transformation is utilized to improve the performance of POS. We implement our POS on the Spark platform and evaluate it using synthetic and real-world datasets. Our experimental results confirm that POS is a promising and practical parallel algorithm to mine outliers in high-dimensional categorical datasets because POS achieves high performance in terms of extensibility and scalability.", "num_citations": "3\n", "authors": ["505"]}
{"title": "PRODA: improving parallel programs on GPUs through dependency analysis\n", "abstract": " GPU\u2019s powerful parallel processing capability has been highly recognized throughout the industry; however, GPU computing environments have not yet been widely used in the field of parallel computing. In this study, we develop a method of parallelization of serial programs for GPU computing. In particular, we propose an approach called PRODA to speedup parallel programs on GPUs through dependency analysis. PRODA provides theoretical underpins of task partitioning in parallel programs running in GPU computing environments. At the heart of PRODA is an analyzer for program workflows as well as data and function dependencies in a GPU program. With the dependency analysis in place, PRODA assigns computing tasks to multiple GPU cores in a way to speedup the performance of parallel program on GPUs. An overarching goal of PRODA is to minimize data communication cost between GPUs\u00a0\u2026", "num_citations": "3\n", "authors": ["505"]}
{"title": "Informed prefetching for distributed multi-level storage systems\n", "abstract": " In this paper, we present an informed prefetching technique called IPODS that makes use of application-disclosed access patterns to prefetch hinted blocks in distributed multi-level storage systems. We develop a prefetching pipeline in IPODS, where an informed prefetching process is divided into a set of independent prefetching steps and separated among multiple storage levels in a distributed system. In the IPODS system, while data blocks are prefetched from hard disks to memory buffers in remote storage servers, data blocks buffered in the servers are prefetched through networks to the clients\u2019 local cache. We show that these two prefetching steps can be handled in a pipelining manner to improve I/O performance of distributed storage systems. Our IPODS technique differs from existing prefetching schemes in two ways. First, it reduces applications\u2019 I/O stalls by keeping hinted data in clients\u2019 local\u00a0\u2026", "num_citations": "3\n", "authors": ["505"]}
{"title": "Duofs: An attempt at energy-saving and retaining reliability of storage systems\n", "abstract": " As issues of the Energy Wall and the Reliability Wall become unavoidable, it is a demanding and challenging task to reduce energy consumption in large-scale storage systems in modern data centres while retaining acceptable systems reliability. Most energy conservation techniques inevitably have adverse impacts on the parallel disk systems. To address the reliability issues of energy-efficient parallel storage systems, we propose a reliable energy-efficient storage system called DuoFS, which aims at improving both energy efficiency and reliability of parallel storage systems by seamlessly integrating HDDs and SSDs. With the help of the middleware layer, DuoFS can distribute popular data to SSD-based nodes and put HDD-based nodes into the low-power mode under light workload conditions without modification of the parallel systems.", "num_citations": "3\n", "authors": ["505"]}
{"title": "An efficient parallel approach of parsing and indexing for large-scale XML datasets\n", "abstract": " MapReduce is a widely adopted computing framework for data-intensive applications running on clusters. We propose an approach to exploit data parallelisms in XML processing using MapReduce in Hadoop. Our solution seamlessly integrates data storage, labelling, indexing, and parallel queries to process a massive amount of XML data. Specifically, we introduce an SDN labelling algorithm and a distributed hierarchical index using DHTs, we develop an efficient data retrieval approach called B-SLCA. More importantly, we design an advanced two-phase MapReduce solution that is able to efficiently address the issues of labelling, indexing, and query processing on big XML data. We implemented our solution on a real-world Hadoop cluster processing the real-world datasets. Our experimental results show that SDN outperforms NCIM by up to a factor of 1.36 with an average of 1.17, our BSLCA outperforms\u00a0\u2026", "num_citations": "3\n", "authors": ["505"]}
{"title": "Using provenance to boost the metadata prefetching in distributed storage systems\n", "abstract": " Caching and prefetching are effective approaches to boosting the performance of metadata access in distributed storage systems. Many research efforts have been devoted in developing new metadata prefetching methods by considering past file access patterns. However, the existing methods do not consider the correlations between processes and the corresponding files(e.g. file provenance). Therefore, the methods cannot obtain very rich and accurate correlations, thus decreasing the effectiveness of metadata prefetching. This paper presents a Provenance-based Metadata Prefetching(ProMP) scheme, which considers both provenance and the past file access patterns. Through mining the correlations between processes and corresponding files from provenance and past access history, ProMP can achieve accurate and rich correlation information. ProMP is conducive to employing aggressive metadata\u00a0\u2026", "num_citations": "3\n", "authors": ["505"]}
{"title": "Systems, methods and computer readable storage media storing instructions for automatically segmenting images of a region of interest\n", "abstract": " Systems, methods, and computer-readable storage media relate to segmenting an image series of at least one image of a region of interest of a subject. The methods, systems, and computer readable storage media can automatically segment interior and exterior boundaries relative to the region of interest (eg, epicardial and endocardial boundaries with respect to a right ventricle) from an image series by combining sparse matrix transform, a training model, and a localized region based level set function.", "num_citations": "3\n", "authors": ["505"]}
{"title": "TERN: A self-adjusting thermal model for dynamic resource provisioning in data centers\n", "abstract": " Dynamic resource provisioning becomes a practical approach to achieving high thermal and energy efficiency, improving scalability, and optimizing reliability for e-commercial applications running in modern data centers. In this paper, we propose a self-adjusting model called TERN to predict thermal behaviors of hardware resources for client sessions. Our TERN contains two major components: (1) a resource utilization model being responsible for estimating hardware usage based on the number of running client transactions, and (2) a thermal model that discovers correlation between resource utilization and their temperatures. TERN is conducive to predicting thermal trends of diverse workload conditions with a changing transaction mix. We apply the TPC-W benchmark to characterize the resource demands of each type of transactions. Then, we conduct a thermal profiling study of the benchmark with various\u00a0\u2026", "num_citations": "3\n", "authors": ["505"]}
{"title": "Thermal Modeling and Management of Storage Systems in Data Centers\n", "abstract": " Thermal modeling and management techniques have been widely investigated in recent years. Prior studies show thermal management could increase energy efficiency of data centers. The thermal impacts of CPUs on data storage have been extensively studied; however, disk thermal models are still in their infancy. In our study, we aim at building thermal models that take into account both CPUs and disks. We propose an approach to developing thermal models to estimate a data node\u2019s outlet temperature based on its CPU and disk activities. Integrating our thermal model into an energy consumption model, we can evaluate the total energy cost of a data center. We apply our models to study the impact of various thermal management strategies on energy efficiency.", "num_citations": "3\n", "authors": ["505"]}
{"title": "Mfts: A multi-level fault-tolerant archiving storage with optimized maintenance bandwidth\n", "abstract": " In this paper, we propose a multi-level fault-tolerant storage cluster called MFTS, which provides flexible reliability for a wide variety of applications. MFTS makes use of a reliability upper-bound (i.e., Parameter r) to guide the process of adjusting fault-tolerance levels, i.e., i-erasure(s) and i {1, 2, .. ., r}. In particular, MFTS can map an appropriate coding scheme to an application with individual reliability requirements. MFTS is capable of partitioning multi-level reliable storage using a virtual storage space, thereby adapting to any changing reliability demands of applications. We present the implementation of the MFTS system, which adopts an intersecting zigzag sets code (IZS code) rather than replication or general-purpose erasure codes. Our MFTS has three salient features: partial updates, fast reconstructions, and minimal overhead of fault-tolerance level transitions. To quantify performance optimization in our\u00a0\u2026", "num_citations": "3\n", "authors": ["505"]}
{"title": "\u57fa\u4e8e\u8ddf\u8e2a\u5fae\u5206\u5668\u7684\u6c38\u78c1\u540c\u6b65\u7535\u4e3b\u8f74\u7535\u6d41\u63a7\u5236\u7b97\u6cd5\n", "abstract": " \u6c38\u78c1\u540c\u6b65\u7535\u4e3b\u8f74\u7535\u6d41 PI \u8c03\u8282\u5668\u5b58\u5728\u9636\u8dc3\u54cd\u5e94\u8d85\u8c03\u4e0e\u8ddf\u8e2a\u901f\u5ea6\u4e4b\u95f4\u7684\u77db\u76fe, \u9020\u6210\u7535\u6d41\u8ddf\u8e2a\u8fc7\u7a0b\u51fa\u73b0\u8d85\u8c03, \u589e\u52a0\u4e86 PI \u53c2\u6570\u7684\u6574\u5b9a\u96be\u5ea6. \u5176\u539f\u56e0\u4e3b\u8981\u662f, \u63a7\u5236\u7684 \u201c\u5feb\u901f\u6027\u201d \u4e0e \u201c\u8d85\u8c03\u201d \u4e4b\u95f4\u7684\u77db\u76fe\u662f PI \u8c03\u8282\u5668\u7684\u56fa\u6709\u5c5e\u6027, \u4e3a\u6b64, \u6839\u636e\u81ea\u6297\u6270\u63a7\u5236\u7406\u8bba, \u63d0\u51fa\u91c7\u7528\u8ddf\u8e2a\u5fae\u5206\u5668\u4e3a d \u8f74\u548c q \u8f74\u7535\u6d41\u6307\u4ee4\u5b89\u6392\u8fc7\u6e21\u8fc7\u7a0b\u7684\u65b9\u6cd5, \u4f7f PI \u8c03\u8282\u5668\u5bf9\u8f93\u5165\u7535\u6d41\u9636\u8dc3\u4fe1\u53f7\u7684\u8ddf\u8e2a\u66f4\u52a0\u5e73\u6ed1. \u4eff\u771f\u548c\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e: \u76f8\u6bd4\u4e8e\u91c7\u7528\u79ef\u5206\u5206\u79bb\u8bbe\u8ba1\u7684 PI \u8c03\u8282\u5668, \u8be5\u65b9\u6cd5\u4f7f\u7535\u6d41\u66f4\u5feb\u901f, \u5e73\u6ed1\u5730\u8ddf\u8e2a\u6307\u4ee4\u503c, \u4e14\u8ddf\u8e2a\u8fc7\u7a0b\u65e0\u8d85\u8c03, \u589e\u5f3a\u4e86\u7535\u4e3b\u8f74\u7535\u6d41\u63a7\u5236\u7684\u9c81\u68d2\u6027.", "num_citations": "3\n", "authors": ["505"]}
{"title": "Stability Control for Two-Wheeled Mobile Robot Using Robust Pole-Placement Method\n", "abstract": " In order to guarantee a robotic stability, a robust pole-placement method is proposed in this paper, the proposed method combines a linear quadratic regulator (LQR) into the pole-placement design. Firstly, a mathematical model of Two-Wheeled Mobile Robot (TWMR) is analytically derived from the real TWMR. Secondly, the LQR for the TWMR\u2019s model is designed, and optimal poles can be obtained from the designed LQR. Thirdly, according to the following conditions in selecting best poles: (1) a convergence speed, (2) vibration times, (3) saturation evasion of control inputs to TWMR\u2019s actuators, (4) the ratio of an imaginary part and a real part are carried out near one of selected poles. Ultimately, the robotic stability of the proposed method with the best poles is confirmed by experiment results.", "num_citations": "3\n", "authors": ["505"]}
{"title": "Electroantennogram responses of female Dendrolimus tabulaeformis Tsai et Liu to two volatile enantiomers of Pinus tabulaeformis Carr.\n", "abstract": " Electroantennograms were recorded from female Dendrolimus tabulaeformis Tsai et Liu to serial stimulus doses (50# mu# L, 100# mu# L, 400# mu# L, 800# mu# L, 1 600# mu# L, and 3 200# mu# L) of four monoterpene hydrocarbons (+-# alpha#-pinene,--# alpha#-pinene,--# beta#-pinene, and+-# beta#-pinene), and the saturating dose was tested. Dose-response curves constructed from the EAGs revealed that the saturating dose of--# alpha#-pinene was 1 600# mu# L and that of the other three chemicals was 800# mu# L. The relative volume of the electroantennogram response was higher for+-# alpha#-pinene compared to--# alpha#-pinene, suggesting that greater affinity to receptor molecules for+-# alpha#-pinene than (-)-# alpha#-pinene; on the contrary, response of the moth to the-form of the# beta#-pinene was higher than that to the (+) form, suggesting that+-# beta#-pinene does not bind as efficiently as--# beta#-pinene with the receptor molecules in many of the sensilla. Electroantennogram recording using mixtures of the enantiomers at saturating dose levels showed that the response to the mixture of# alpha#-pinene was almost equal to those of the two forms of# alpha#-pinene, suggesting that the two forms of# alpha#-pinene were detected by the same receptor neurons; and the same for the# beta#-pinene. Discrimination between enantiomers by plant olfactory receptor neurons in the moth suggested that the enantiomeric ratios of volatile compounds might be important in host location of D. tabulaeformis.", "num_citations": "3\n", "authors": ["505"]}
{"title": "Analysis and improvement for forward security digital signature schemes based on n-th root module m\n", "abstract": " Forward security plays an important role in reducing the loss that aroused for the reason of secret keys exposure effectively, which has been becoming a hotspot in the researches of cryptography. It\u2019s found that these existing schemes have security omission and are lack of forward security through the detailed security analysis of forward-secure digital signature schemes based on n-th root module m hard problem. It\u2019s necessary to explain the essential reason that an adversary succeeded in forging the valid signatures based on the class of forward-secure digital signature schemes through the security analysis. In addition, according to the hard problem of digital signature scheme in the finite field, one of the signature schemes was improved by using the information about the current secret key to sign the message. The analysis of security and efficiency shows that the improved scheme has the features of forward-secure and resisting forging attack, as well as higher signing speed. The proposed method is equally applicable to such other digital signature schemes based on n-th root module m hard problem. Moreover, this improved method has guiding significance and prac-tical application values to further optimal design of some special signature schemes such as forward-secure proxy signature scheme, forward-secure group signature scheme, and forward-secure multi-signature scheme etc.[Fund]: \u56fd\u5bb6\u81ea\u7136\u79d1\u5b66\u57fa\u91d1\u8d44\u52a9\u9879\u76ee (60673127);; \u56fd\u5bb6\u9ad8\u6280\u672f\u7814\u7a76\u53d1\u5c55\u8ba1\u5212 (\u201c863\u201d \u8ba1\u5212) \u57fa\u91d1\u8d44\u52a9\u9879\u76ee (2007AA01Z404);; \u6c5f\u82cf\u7701\u79d1\u6280\u652f\u6491\u8ba1\u5212\u57fa\u91d1\u8d44\u52a9\u9879\u76ee (BE2008135);; \u5de5\u4fe1\u90e8\u7535\u5b50\u4fe1\u606f\u4ea7\u4e1a\u53d1\u5c55\u57fa\u91d1\u8d44\u52a9\u9879\u76ee;; \u5357\u4eac\u822a\u7a7a\u822a\u5929\u5927\u5b66\u9752\u5e74\u79d1\u6280\u521b\u65b0\u57fa\u91d1\u8d44\u52a9\u9879\u76ee\u00a0\u2026", "num_citations": "3\n", "authors": ["505"]}
{"title": "Prediction Models for Spatial Data Based on Spatial Autocorrelation [J]\n", "abstract": " Because spatial data have the characteristic of spatial autocorrelation, it makes the MLS (Multivariate Linear Regression) model unfit to spatial prediction. Due to account for spatial information, the SAR (Spatial Auto-Regression) model can be used for spatial prediction, but it is computationally very expensive. We add spatial information into input variables by replacing each input variables with the weighted average of its neighbors and feed the new input variables to a MLS model to estimate model parameters, and then make spatial prediction, where MLS stands for this model. Experimental results show that the MLS model and the SAR model have almost identical effects on spatial prediction, while the MLS model is computationally more efficient than the SAR model.[Fund]: \u56fd\u5bb6\u9ad8\u65b0\u6280\u672f\u7814\u7a76\u53d1\u5c55\u8ba1\u5212 (863) \u57fa\u91d1\u8d44\u52a9\u9879\u76ee (NO2007AA01Z404);; \u56fd\u5bb6\u81ea\u7136\u79d1\u5b66\u57fa\u91d1\u8d44\u52a9\u9879\u76ee (60673127);; \u5357\u4eac\u822a\u7a7a\u822a\u5929\u5927\u5b66\u79d1\u7814\u57fa\u91d1\u8d44\u52a9\u9879\u76ee (S0848-042)", "num_citations": "3\n", "authors": ["505"]}
{"title": "Integrating energy efficiency and security for storage systems\n", "abstract": " Security requirements and power management have become important criteria for data storage systems in today's world of information security. There exist many security approaches and power optimization techniques for storage systems but most of the existing approaches either concentrate on security or power management. Our approach integrates the power optimization with confidentiality services to maintain the secrecy of the data. Several traditional power optimization techniques involve stopping the disk completely when the loads on the storage disks are really low. Our approach makes use of the new evolving technique, Dynamic Speed Control for power management (DRPM), when the idle times between the requests are not very high. There are numerous security services like confidentiality, integrity, authentication and non-repudiation that can be provided to secure the data or information\u00a0\u2026", "num_citations": "3\n", "authors": ["505"]}
{"title": "Security-Aware Cache Management for Cluster Storage Systems\n", "abstract": " Cluster storage systems have emerged as highperformance and cost-effective storage infrastructures for large-scale data-intensive applications. Although a large number of cluster storage systems have been implemented, the existing cluster storage systems lack a means to optimize quality of security in dynamically changing environments. We solve this problem by developing a security-aware cache management mechanism (or CaPaS for short) for cluster storage systems. CaPaS aims at achieving high security and desired performance for data-intensive applications running on clusters. CaPaS is used in combination with a security control mechanism that can adapt to changing security requirements and workload conditions, thereby providing high quality of security for cluster storage systems. CaPaS is comprised of a cache partitioning scheme, a response-time estimator, and an adaptive security quality controller. These three components help in increasing quality of security of cluster storage systems while allowing disk requests to be finished before their desired response times. To prove the efficiency of CaPaS, we simulate a cluster storage system into which CaPaS, eight cryptographic, and seven integrity services are integrated. Empirical results show that CaPaS significantly improves overall performance over two baseline strategies by up to 73%(with an average of 52%).", "num_citations": "3\n", "authors": ["505"]}
{"title": "Integrate port resource to upgrade competition ability of Zhejiang ports [J]\n", "abstract": " As an important component of Shanghai international shipping center, the port groups in Zhejiang Province are required to speed up the integrating of port resource, develope their own advantages to upgrade competition ability. This paper indicates the approach from two points: port resources integrating and management system integrating.", "num_citations": "3\n", "authors": ["505"]}
{"title": "Algorithms of fault-tolerant scheduling in distributed real-time systems\n", "abstract": " BackgroundThis paper proposes two fault-tolerant scheduling algorithms for real-time tasks and proves the correctness of these two scheduling algorithms. One is called backup copies scheduled last (BKCL) and another is called tasks without fault-tolerant requirements scheduled last (NFRL). These two scheduling algorithms can schedule the tasks with the fault-tolerant requirements together with those without fault-tolerant requirements. For the tasks with fault-tolerant requirements, BKCL and NFRL can generate schedules that can tolerate one processor failure. Performance analysis of these two algorithms are presented, each algorithm has advantage under different workload. NFRL is better than that of BKCL when the number of tasks with fault-tolerant requirements is far smaller than that of the tasks without fault-tolerant requirements. And on the other hand, when the number of tasks with fault-tolerant\u00a0\u2026", "num_citations": "3\n", "authors": ["505"]}
{"title": "The PASS project architectural model\n", "abstract": " The PASS project has as its goal the implementation of solutions to the foreseen data access problems of the next generation of scientific experiments. The architectural model results from an evaluation of the operational and technical requirements and is described in terms of an abstract reference model, an implementation model and a discussion of some design aspects. The abstract reference model describes a system that matches the requirements in terms of its components and the mechanisms by which they communicate, but does not discuss policy or design issues that would be necessary to match the model to an ac-tual implementation. Some of these issues are discussed, but more detailed design and simulation work will be necessary before choices can be made.", "num_citations": "3\n", "authors": ["505"]}
{"title": "The PASS project: A progress report\n", "abstract": " The PASS project has as its goal the implementation of solutions to the foreseen data access problems of the next generation of scientific experiments. It is in the process of transitioning from an exploratory phase, where the focus has been on understanding the requirements and available technologies to an implementation phase, where detailed design work is commencing on a common framework for scientific applications. iNTRODUCTION event data (~ 1015bytes), a dilute signal and a large (~ 1000) and geographically dis-The Petabyte Access and Storage Solutions persed user community. Although the origi-(PASS) project [1] has as its goal the imple- nal focus of the PASS project was the mentation of solutions to the foreseen data experiments at the SSCL, its approach is access problems of the next generation of broad enough to encompass many areas of scientific experiments. These are character- scientific computing. Target customers now ized by a very large sample of complex include experiments at RHIC, CEBAF, the B-Factory at SLAC, NASA and govern-", "num_citations": "3\n", "authors": ["505"]}
{"title": "ThermoBench: A thermal efficiency benchmark for clusters in data centers\n", "abstract": " The energy efficiency of a data center depends on the cooling cost of clusters in the data center. Enhancing thermal efficiency of clusters is a practical approach to reducing energy consumption cost, optimizing scalability, and improving reliability. In this paper, we propose ThermoBench to evaluate the thermal efficiency of computing and storage clusters deployed in data centers. We shed light on the criteria, metrics and challenges of developing a thermal efficiency benchmark. We pay particular attention to clusters running scalable client-server enterprise applications in data centers. Because these applications are quite popular in modern data centers, thermal efficiency benchmarks for clusters providing services to these applications become critical. We characterize workload conditions in such a cluster computing environment in forms of client sessions of multiple transactional requests. To resemble real-world\u00a0\u2026", "num_citations": "2\n", "authors": ["505"]}
{"title": "Turbo-gts: A fast framework of optimizing task throughput for large-scale mobile crowdsourcing\n", "abstract": " In mobile crowdsourcing, workers are financially motivated to perform as many self-selected tasks as possible to maximize their revenue. Unfortunately, the existing task scheduling approaches in mobile crowdsourcing fail to consider task execution duration and do not scale for massive tasks and large geographic areas. In this article, we propose a novel framework, Turbo-GTS, in support of large-scale geo-task scheduling, with the objective of identifying an optimal task assignment for each worker to maximize the total number of tasks that can be completed for an entire worker group, given the geographic locations of each task and each worker. Since the exact solution to the geo-task scheduling problem is computationally intractable, we first propose two sub-optimal approaches (least cost neighbor with particle filtering and non-urgency degree particle filtering with iterative clustering) based on particle filtering and\u00a0\u2026", "num_citations": "2\n", "authors": ["505"]}
{"title": "Social relationships classification using social contextual features and SVDD-based metric learning\n", "abstract": " Family relationship is an important concern in image-based social relationships recognition, and there are very limited attempts to tackle diverse social relationships in the literature. In this paper, we propose the problem of social relationships classification in which we aim to model three types of social relationships( e.g., family, colleagues and friends) in the images. To this end, we introduce two types of social contextual features to capture detailed information( e.g., geometry or appearance) in images. Moreover, we present a new Support Vector Data Description-based metric learning( SML) method for social relationships classification. Motivated by the fact that the images are unavoidably degraded by noise due to some variation factors such as illumination and pose, we aim to learn a robust distance metric to suppress noise and model the spatial structure among multiple entities, such that more discriminative\u00a0\u2026", "num_citations": "2\n", "authors": ["505"]}
{"title": "REDUX: Managing Renewable Energy in Data Centers Using Distributed UPS Systems\n", "abstract": " To environmental friendly and energy-efficient data centers, it is prudent to leverage on-site renewable sources like solar and wind. Data centers deploy distributed UPS systems to handle the intermittent nature of renewable energy. We propose a renewable-energy manager called REDUX, which offers a smart way of managing server energy consumption powered by a distributed UPS system and renewable energy. REDUX maintains a desirable balance between renewable-energy utilization and data center performance. REDUX makes judicious use of UPS devices to allocate energy resources when renewable energy generation is low or fluctuate condition. REDUX not only guarantees the stable operation of daily workload, but also reduces the energy cost of data centers by improving power resource utilization. Compared with existing strategies, REDUX demonstrates a prominent capability of mitigating\u00a0\u2026", "num_citations": "2\n", "authors": ["505"]}
{"title": "Improving energy efficiency of database clusters through prefetching and caching\n", "abstract": " The goal of this study is to optimize energy efficiency of database clusters through prefetching and caching strategies. We design a workload-skewness scheme to collectively manage a set of hot and cold nodes in a database cluster system. The prefetching mechanism fetches popular data tables to the hot nodes while keeping unpopular data in cold nodes. We leverage a power management module to aggressively turn cold nodes in the low-power mode to conserve energy consumption. We construct a prefetching model and an energy-saving model to govern the power management module in database lusters. The energy-efficient prefetching and caching mechanism is conducive to cutting back the number of power-state transitions, thereby offering high energy efficiency. We systematically evaluate energy conservation technique in the process of managing, fetching, and storing data on clusters supporting\u00a0\u2026", "num_citations": "2\n", "authors": ["505"]}
{"title": "Thermal-aware job scheduling of mapreduce applications on high performance clusters\n", "abstract": " In this study, we develop a thermal-aware job scheduling strategy called tDispatch tailored for MapReduce applications running on Hadoop clusters. The scheduling idea of tDispatch is motivated by a profiling study of CPU-intensive and I/O-intensive jobs from the perspective of thermal efficiency. More specifically, we investigate the thermal behaviors of these two types of jobs running on a Hadoop cluster by stress testing data nodes through extensive experiments. We show that CPU-intensive and I/O-intensive jobs exhibit various thermal and performance impacts on multicore processors and hard drives of Hadoop cluster nodes. After we quantify the thermal behaviors of Hadoop jobs on the master and data nodes of a cluster, we propose our scheduler to alternatively dispatch CPU-intensive and I/O-intensive jobs. We apply our strategy to several MapReduce applications with different resource consumption\u00a0\u2026", "num_citations": "2\n", "authors": ["505"]}
{"title": "Employing dual-block correlations to reduce the energy consumption of disk drives\n", "abstract": " Achieving high energy efficiency is becoming a very important challenge in designing future storage systems. This paper proposes to incorporate block correlations to perform energy-aware scheduling, thereby significantly improving energy efficiency of disk systems. Since the probability that an access to a file A will be followed by the same file (e.g. file B) that followed the last access to A is very high, we can infer the block correlations between files A and B. For example, block X of file A and block Y of file B may correlate with each other. We discover that energy-saving opportunities occur when the time interval between two accesses of block X and block Y is sufficiently large, and there are only a few sporadic requests distributed between these two accesses. Thus, when there is one access to block X, we can switch the disk drive to the low power state, properly arrange the sporadic requests, and transfer\u00a0\u2026", "num_citations": "2\n", "authors": ["505"]}
{"title": "Pharmacokinetics, Metabolism and Disposition of [14C] XQ-1H After Intravenous Administration to Male Rats\n", "abstract": " Objective: This study describes the in vivo pharmacokinetics and metabolism of [14C]labeled XQ-1H in male rats. Methods: XQ-1H is a methanesulfonate of XQ, 10-O-(N,N-dimethylaminoethyl)-ginkgolide B, a derivative of ginkgolide B (GB) with enhanced water solubility. Since it is very difficult to synthesize radiolabeled GB, the results obtained in this study may provide helpful insight to further ADME investigation of GB and its analogue compounds. After an i.v. administration of [14C]XQ-1H to male rats, XQ (the freebase form of XQ-1H) was extensively hydrolyzed, moderately metabolized, and mainly excreted in feces (71.5% of the dose) via the biliary route. Results: The main enzyme mediated metabolic pathways were mono- and di-demthylation. Using the radiolabel form of XQ-1H, the temporal binding of XQ to red blood cells was observed. Conclusion: Binding of XQ to RBCs may lower the blood\u2019s viscosity and\u00a0\u2026", "num_citations": "2\n", "authors": ["505"]}
{"title": "Towards energy-efficient multicore database systems\n", "abstract": " In this paper, we propose a toolkit called EDOM facilitating the evaluation and optimization of energy-efficient multicore-based database systems. Two core components in EDOM are a benchmarking toolkit and a multicore manager to improve energy efficiency of database systems running on multicore servers. At the heart of the multicore manager is a memory usage model that estimates memory utilization from queries and database characteristics (e.g., table and record size). We make use of the proposed benchmark toolkit to quantitatively evaluate the performance of our novel multicore manager. Our extensive experimental results show that our multicore manager in EDOM provides a simple yet powerful solution for improving energy efficiency of database applications running on multicore servers.", "num_citations": "2\n", "authors": ["505"]}
{"title": "Towards pharmacovigilance using machine learning to identify unknown adverse reactions triggered by drug-drug interaction\n", "abstract": " Adverse Drug Reactions (ADRs) are a major cause of morbidity and mortality in world. There is thus a growing need of methods facilitating the automated detection of drugs-related ADR; especially ADRs that were not known from clinical trials but later arise due to drug-drug interactions. In this research our goal is to discover the severe unknown Adverse Drug Reactions caused by a combination of drugs, also known as Drug-Drug-Interaction. We propose to use Association Rule Mining to find the ADRs caused by using a combination of drugs yet not known to be caused if these drugs were taken individually. For evaluation, we will test out the proposed strategies on real-world medical data extracted from the spontaneous adverse drug reaction reporting system called FAERS. The results mined by our tool will be checked both manually by literature review and then verified by domain experts for interestingness and accuracy.", "num_citations": "2\n", "authors": ["505"]}
{"title": "HcDD: The hybrid combination of disk drives in active storage systems\n", "abstract": " Since large-scale and data-intensive applications have been widely deployed, there is a growing demand for high-performance storage systems to support data-intensive applications. Compared with traditional storage systems, next-generation systems will embrace dedicated processor to reduce computational load of host machines and will have hybrid combinations of different storage devices. The advent of flash-memory-based solid state disk has become a critical role in revolutionizing the storage world. However, instead of simply replacing the traditional magnetic hard disk with the solid state disk, it is believed that finding a complementary approach to corporate both of them is more challenging and attractive. This paper explores an idea of active storage, an emerging new storage configuration, in terms of the architecture and design, the parallel processing capability, the cooperation of other machines in\u00a0\u2026", "num_citations": "2\n", "authors": ["505"]}
{"title": "An efficient I/O-redirection-based reconstruction scheme for erasure-coded storage clusters\n", "abstract": " This paper addresses an I/O interference problem encountered in on-line reconstruction of erasure-coded storage clusters, where user I/Os compete with reconstruction I/Os for both disk and network bandwidth. We propose a redirection scheme called `RAM-RS' to minimize the I/O interference among user and reconstruction requests. RAM-RS redirects user read/writes targeted at failed nodes to an RS-coded RAM region, which is formed by pre-allocated main memory in surviving nodes in the RS-coding manner. The RS-coded RAM region quickly serves all user read/write misses; therefore, a rebuilding node can devote its disk and network bandwidths to the node reconstruction. The RAM region substantially reduces the amount of data rebuilt by the rebuilding node, because (1) missed writes are buffered in the RAM region and (2) missed reads are satisfied by using surviving nodes to co-rebuild failed blocks\u00a0\u2026", "num_citations": "2\n", "authors": ["505"]}
{"title": "TOPS: Two-phase scheduling for distributed real-time systems\n", "abstract": " In this work we propose a two-phase scheduling technique (TOPS) for distributed real-time systems. The first phase of TOPS is in charge of producing a scheduling sequence, whereas the second phase aims to dispatch tasks to computing nodes of a distributed system. The two phases are independent of one another and; therefore, one can change a policy in one phase without configuring another phase. TOPS makes it possible to observe the impacts of sorting policies on the performance of scheduling policies. We implement a TOPS prototype, in which the first phase is comprised of three sorting policies and the second phase consists of two scheduling policies in the second phase. TOPS enables us to discover that combining the EDF (Earliest-Deadline-First) and AEAP (As-Early-As-Possible) policies leads to an optimized performance among all the six candidate algorithms.", "num_citations": "2\n", "authors": ["505"]}
{"title": "iTad: I/O thermal aware data center model\n", "abstract": " With the ever-growing cooling costs of large-scale data centers, thermal management must be adequately addressed. Thermal models can play a critical role in thermal management that helps in reducing cooling costs in data centers. However, existing thermal models for data centers can overload I/O activities. To address this issue, we developed an I/O-aware thermal model called iTad for data centers. The iTad model captures the thermal characteristics of servers in a data center, offering a much finer granularity than the existing models. In addition to CPU workloads, iTad incorporates the I/O load in order to accurately estimate the thermal footprint of the servers with I/O-intensive activities. We validate the accuracy of the iTad model using real-world temperature measurements acquired by an infrared thermometer. Our empirical results show that I/O utilizations have a significant impact on internal temperatures of\u00a0\u2026", "num_citations": "2\n", "authors": ["505"]}
{"title": "iPARAS: incremental construction of parameter space for online association mining\n", "abstract": " Association rule mining is known to be computationally intensive, yet real-time decision-making applications are increasingly intolerant to delays. The state-of-the-art PARAS solution, a parameter space framework for online association mining, enables efficient rule mining by compactly indexing the final ruleset and providing efficient query-time redundancy resolution. Unfortunately, as many association mining models, PARAS was designed for static data. Modern transaction databases undergo regular data updates that quickly invalidating existing rules or introducing new rules for the PARAS index. While reloading the PARAS index from scratch is impractical, as even upon minor data changes, a complete rule inference and redundancy resolution steps would have to be performed. We now propose to tackle this open problem by designing an incremental parameter space construction approach, called iPARAS, that utilizes the previous mining result to minimally adjust the ruleset and associated redundancy relationships. iPARAS features two innovative techniques. First, iPARAS provides an end-to-end solution, composed of three algorithms, to efficiently update the final ruleset in the parameter space. Second, iPARAS designs a compact data structure to maintain the complex redundancy relationships. Overall, iPARAS achieves several times speed-up on parameter space construction for transaction databases comparing to the state-of-the-art online association rule mining system PARAS.", "num_citations": "2\n", "authors": ["505"]}
{"title": "Efficacy of kidney\u2010tonifying traditional C hinese medicine prescriptions in hypoplastic uterus treatment: A systematic review and meta\u2010analysis\n", "abstract": " Aim To review and evaluate the efficacy of kidney\u2010tonifying traditional Chinese medicine prescriptions (KT\u2010TCMP) in hypoplastic uterus (HU) treatment.   Methods We searched MEDLINE, the Cochrane Library, CNKI (China National Knowledge Infrastructure), WANFANG and VIP databases until 14\u2009December 2013 independently with two investigators. Randomized controlled trials (RCT) involving KT\u2010TCMP as a combined or monotherapy in the treatment of HU were reviewed and analyzed. Meta\u2010analysis was performed by Review Manager (version 5.2).   Results Nine RCT of 1745 patients were eligible for this review and meta\u2010analysis, of which eight RCT described the primary outcome of clinical efficacy and three RCT drew the secondary outcome of uterine size. Meta\u2010analyzed \u2018recovery\u2019 clinical efficacy of KT\u2010TCMP in seven RCT was conducted which considered diethylstilbestrol therapy alone as control\u00a0\u2026", "num_citations": "2\n", "authors": ["505"]}
{"title": "Reliability analysis of energy-efficient parallel storage systems\n", "abstract": " Existing reliability models evaluate the lifetime of storage systems well. However, few models aim to analysis parallel storage systems, especially systems equipped with energy-efficient solutions. MREED model provides an inspiring reliability analysis idea for energy-efficient parallel storage systems, especially RAIDs. Unfortunately, the MREED has its disadvantage that it can evaluate RAID-0 only, in which a basic method of data-stripping is applied. In this paper, we extend the MREED model to cover the most energy-efficient RAID setups including RAID-1, which introduces disk-mirroring techniques, and RAID-5, which applies a data-parity techniques based on data-stripping schemes for a data recovery purpose. The MREED is then applied to evaluate an existing well-known power-aware RAID system-PARAID. Experimental results indicate the data locality affection and data parity impaction on the reliability of\u00a0\u2026", "num_citations": "2\n", "authors": ["505"]}
{"title": "Preparation and characterization of monoclonal antibodies against viral hemorrhagic septicemia virus\n", "abstract": " OBJECTIVE: To prepare the monoclonal antibody (mAb) against viral hemorrhagic septicemia virus (VHSV) and analyze the biological properties. METHODS: The BALB/c mice were immunized with the VHSV which was purified by differential centrifugation. Spleen cells of the immune mice were collected and fused with Sp2/0 myeloma cells by hybridoma technology. The indirect ELISA was used to screen hyridoma cells and identify the specificity of mAb. The Western blotting was used to identify antigen site. RESULTS: After three cycle of subcloning with limited dilution method, we obtained a cell strain that secreted mAb against VHSV and was named 4A5. The indirect ELISA showed that the titer of mAb ascites was 10\u207b \u2074;. It belonged to IgG3 subclass \u03ba chain and couldn't react with other fish viruses or fish cell lines in the ELISA except VHSV. Western blotting revealed that mAb 4A5 bound to a 70 kDa of protein band of VHSV as antigen. CONCLUSION: The obtained mAb has a high specificity, which could be used for rapid diagnosis and detection of VHSV in aquaculture.", "num_citations": "2\n", "authors": ["505"]}
{"title": "A Highly Extensible Framework for Molecule Dynamic Simulation on GPUs\n", "abstract": " Molecular dynamics (MD) was widely used in chemistry and bio molecules. Numerous attempts have been made to accelerate MD simulations. CUDA enabled NVIDIA Graphics processing units (GPUs) use as a general purpose parallel computer chips as CPU. But it is not easy to port a program to GPU. We present a highly extensible framework for molecular dynamics simulation. And we discuss how to accelerate the process of port to GPU. We introduce how to find the performance battle and how to port the time costly procedure to GPU. We discuss about how to decrease the memory usage in GPU and how to improve the maintenance of molecular dynamics simulation. At last, we present the performance of linear and parallel simulation with different number of molecules. Source codes can be found at https://github. com/orlandoacevedo/MCGPU.", "num_citations": "2\n", "authors": ["505"]}
{"title": "Multicore-Enabled Smart Storage for Clusters\n", "abstract": " We present a multicore-enabled smart storage for clusters in general and MapReduce clusters in particular. The goal of this research is to improve performance of data-intensive parallel applications on clusters by offloading data processing to multicore processors in storage nodes. Compared with traditional storage devices, next-generation disks will have computing capability to reduce computational load of host processors or CPUs. With the advance of processor and memory technologies, smart storage systems are promising devices to perform complex on-disk operations. The proposed smart storage system can avoid moving a huge amount of data back and forth between storage nodes and computing nodes in a cluster. To enhance the performance of data-intensive applications, we have designed a smart storage system called Multicore-enabled Smart Storage (McSD), in which a multicore processor is\u00a0\u2026", "num_citations": "2\n", "authors": ["505"]}
{"title": "Performance-and cost-aware topology generation based on clustering for application-specific network on chip\n", "abstract": " A clustering-based topology generation approach is proposed to construct Network-on-Chip (NoC) topologies for given applications. By exploiting communication requirements of the given application and characteristics of the router architectures, the approach constructs custom irregular NoC topology in four phases with design constraints specific to the application. Specially, a recursion based link construction algorithm embedded in the topology generation is proposed to construct links between routers. The proposed approach together with the recursive algorithm significantly reduces the network communication latency, power consumption, routers area and resource costs. The evaluation performed on various multimedia benchmark applications confirms the efficiency of the proposed approach. Experimental results show that the approach saves about 60% of the communication latency, power consumption and router area as compared to those using regular Mesh topology. Significant network resource improvement is also achieved. Moreover, the approach performs well for two multimedia applications compared to existing algorithms.", "num_citations": "2\n", "authors": ["505"]}
{"title": "A multiple audio watermarking for database based on blind source separation\n", "abstract": " By introducing speech, a multiple audio watermarking algorithm for database based on blind source separation is presented. The watermarking, a mixture of the speech signals of multiple copyright owners is inserted into database. After multiple watermarking is extracted, the speech signals of copyright owners will be separated by blind source separation algorithm based on maximum signal noise ratio. The speeches are matched by speech recognition technology based on DWT algorithm in order to prove that speeches are owned by multiple copyright owners.", "num_citations": "2\n", "authors": ["505"]}
{"title": "Distribution and Variation of Spring Snow Cover in Laohugou Watershed of the Qilian Mountains\n", "abstract": " In order to understand the physical process of snow cover and its feedback to climate system, it is necessary to study the properties of snow cover. In this paper, the distribution and variation of snow cover in spring in Laohugou watershed of the Qilian Mountains was investigated. The snow cover properties, i. e., snow depth, snow density, snow liquid water content, snow reflectance, snow surface albedo, snow grain size and temperature, were measured using some advanced instruments during the observation. In addition, snow cover profile was measured in snow pits. Snow cover depth measurement found that the spatial distribution of snow cover depth is quite various. The snow cover in shaded area is deeper than that on other slopes. The measured snow spectral reflectance shows a distinct dependence on snow grain size, snow type, snow depth, snow density, snow liquid water content and surface roughness\u00a0\u2026", "num_citations": "2\n", "authors": ["505"]}
{"title": "Geochemical Characteristics and Tectonic Significance of the Shanglueshuiqiao Aluminous A-Type Granites Intrusive in the Ji'an Area, Jilin Province\n", "abstract": " The Shanglueshuiqiao instrusion exposed in Ji'an area of Jilin Province mainly consists of miarolitic K-feldspar granite. The granites in the Shanglueshuiqiao instrusion are characterized by high SiO sub (2)(75. 94%-76. 34%) and TFeO/MgO value(39. 6-66. 1), enrichment in alkali(ALK= 8. 29%-9. 63%) and K (K sub (2) O= 5. 14%-5. 20%, K sub (2) O/Na sub (2) O= 1. 47-1. 68), low CaO and TiO sub (2). On the primitive mantle-normalized spider diagrams, the granites show positive K, Rb and Th anomalies and negative Ba, Sr, Ti, Nb, Ta and P anomalies. Moreover, They have particularly intensive Eu negative anomalies and their chondrite-normalized REE patterns are of the seagull shape. Research on the major and trace elements of these granites indicates that they are aluminous A-type granite. By LA-ICP-MS dating, the Shanglvshuiqiao intrusion was formed in the early Cretaceous(U- Pb age of(117. 8 plus or\u00a0\u2026", "num_citations": "2\n", "authors": ["505"]}
{"title": "Sonodynamic therapy with chlorin e6 for Ehrlich ascites tumor-bearing mice\n", "abstract": " Objective To investigate the biological mechanism of synergetic suppressive effects of ultrasound in combination with chlorine e6 on Ehrlich ascites tumor-bearing mice. Methods Anti-tumor effects were determined by measuring the tumor size after different treatments. The changes of superoxide dismutase, glutathione peroxidase, catalase activities and malonaldehyde (MDA) level after treatment were measured. Results Chlorine e6 alone had almost no inhibitory effect, while ultrasound alone showed a slight anti-tumor effect. An obvious suppression by ultrasound (4 W/cm2, 6 W/cm2) in combination with chlorine e6 (10 mg/kg) was obtained (inhibitory rate 43.3% and 44, 2%, respectively). Superoxide dismutase, glutathione peroxidase and catalase activities were decreased and MDA level was significantly increased in the tumor tissue after treatment. Conclusions The alterations of antioxidant enzyme activities and MDA level suggest that oxidative damage may play an important role for the anti-tumor effect on Ehrlich ascites tumor-bearing mice after chlorin e6-sonodynamic therapy.", "num_citations": "2\n", "authors": ["505"]}
{"title": "Clinical evaluation of tripterygium wilfordii polyglycosidium combined with methotrexate in treating rheumatoid arthritis and its effect on TNF-\u03b1 and IL-6.\n", "abstract": " Objective: To observe the efficacy of tripterygium wilfordii tripterygium wilfordii Subject Category: Organism Names", "num_citations": "2\n", "authors": ["505"]}
{"title": "A reliability model of energy-efficient parallel disk systems with data mirroring\n", "abstract": " In the last decade, parallel disk systems have increasingly become popular for data-intensive applications running on high performance computing platforms. Conservation of energy in parallel disk systems has a strong impact on the cost of cooling equipment and backup power-generation. This is because a significant amount of energy is consumed by parallel disks in high performance computing centres. Although a wide range of energy conservation techniques have been developed for disk systems, most energy saving schemes have adverse impacts on the reliability of parallel disk systems. To address this deficiency, we must focus on reliability analysis for energy-efficient parallel disk systems. In this paper, we make use of a Markov process to develop a quantitative reliability model for energy-efficient parallel disk systems using data mirroring. With the new model in place, a reliability analysis tool is\u00a0\u2026", "num_citations": "2\n", "authors": ["505"]}
{"title": "Improving reliability of energy-efficient parallel storage systems by disk swapping\n", "abstract": " The Popular Disk Concentration (PDC) technique and the Massive Array of Idle Disks (MAID) technique are two effective energy saving schemes for parallel disk systems. The goal of PDC and MAID is to skew I/O load towards a few disks so that other disks can be transitioned to low power states to conserve energy. I/O load skewing techniques like PDC and MAID inherently affect reliability of parallel disks because disks storing popular data tend to have high failure rates than disks storing cold data. To achieve good tradeoffs between energy efficiency and disk reliability, we first present a reliability model to quantitatively study the reliability of energy-efficient parallel disk systems equipped with the PDC and MAID schemes. Then, we propose a novel strategy-disk swapping-to improve disk reliability by alternating disks storing hot data with disks holding cold data. We demonstrate that our disk-swapping strategies\u00a0\u2026", "num_citations": "2\n", "authors": ["505"]}
{"title": "\u65b0\u751f\u513f\u5de6\u5fc3\u5ba4\u5de8\u5927\u6a2a\u7eb9\u808c\u7624 1 \u4f8b\n", "abstract": " %% \u60a3\u513f, \u7537\u6027,! 1, \u56e0\u547c\u5438\u6025\u4fc3, \u53e3\u5468\u53d1\u7ec0\"'\u5165\u9662. \u60a3\u513f\u4e3a\u7b2c! \u80ce\u7b2c! \u4ea7, \u8db3\u6708\u987a\u4ea7\u51fa\u751f, H/Y23 \u8bc4\u5206!.(), V.() \u5747\u4e3a!# \u5206, \u7f8a\u6c34\u6e05\u4eae, \u65e0\u8110\u5e26\u7ed5\u9888, \u80ce\u76d8\u65e0\u5f02\u5e38. \u51fa\u751f\u4f53\u91cd J; V# Y. \u5176\u6bcd\u5b55\u671f\u672a\u884c\u7cfb\u7edf\u4ea7\u79d1\u68c0\u67e5, \u5426\u8ba4\u7ed3\u8282\u6027\u786c\u5316\u75c7\u53ca\u5fc3\u810f\u80bf\u7624, \u5fc3\u810f\u75c5\u5bb6\u65cf\u53f2. \u67e5\u4f53: \u547c\u5438;\" \u6b21 c.(), \u8db3\u6708\u513f\u5916\u8c8c, \u54ed\u58f0, \u53cd\u5e94\u4e00\u822c, \u5168\u8eab\u76ae\u80a4\u7c98\u819c\u672a\u89c1\u76ae\u75b9, \u51fa\u8840\u70b9\u53ca\u7600\u6591\u82b1\u7eb9, \u53e3\u9f3b\u5468\u53ca\u80a2\u7aef\u53d1\u7ec0\u660e\u663e. \u524d\u56df\u5e73\u8f6f,! 6V 9. j! 6V 9.. \u53cc\u4fa7\u773c\u7751\u65e0\u6c34\u80bf, \u77b3\u5b54\u7b49\u5927\u7b49\u5706, \u76f4\u5f84\u7ea6 J.., \u5bf9\u5149\u53cd\u5c04\u7075\u654f, \u80f8\u5ed3\u53cc\u4fa7\u9971\u6ee1, \u4ee5\u5de6\u4fa7\u8f83\u660e\u663e, \u5438\u6c14\u6027\u4e09\u51f9\u5f81\u9633\u6027, \u53cc\u80ba\u547c\u5438\u97f3\u7c97, \u672a\u95fb\u53ca\ue3fe \u97f3. \u5fc3\u5c16\u640f\u52a8\u4f4d\u4e8e\u7b2c\u4e94\u808b\u95f4\u5de6\u9501\u9aa8\u4e2d\u7ebf\u5916# 6V 9., \u5fc3\u7387! J\" \u6b21 c.(), \u5f8b\u9f50, \u5fc3\u524d\u533a\u53ef\u95fb\u53ca\u76bf c; \u7ea7\u6536\u7f29\u671f\u6742\u97f3, \u65e0\u9707\u98a4, \u65e0\u4f20\u5bfc. \u8179\u8f6f, \u672a\u89c1\u80c3\u80a0\u578b, \u809d\u810f\u4e8e\u53f3\u808b\u7f18\u4e0b J 9. \u53ef\u89e6\u53ca, \u8d28\u8f6f, \u813e\u810f\u4e8e\u5de6\u808b\u7f18\u4e0b! 9. \u53ef\u89e6\u53ca, \u8d28\u8f6f. \u56db\u80a2\u808c\u5f20\u529b\u53ef, \u62e5\u62b1, \u63e1\u6301, \u89c5\u98df\u53cd\u5c04\u5b58\u5728.\u5165\u79d1\u540e\u5373\u4e88\u6e05\u7406\u547c\u5438\u9053, \u5438\u6c27\u53ca\u5bf9\u75c7\u6cbb\u7597, \u7d2b\u7ec0\u65e0\u660e\u663e\u7f13\u89e3. \u80f8\u90e8 k \u7ebf\u63d0\u793a\u5fc3\u5f71\u5de8\u5927, \u80ba\u52a8\u8109\u6bb5\u9ad8\u5ea6\u81a8\u9686. \u5fc3\u810f\u5f69\u8d85\u68c0\u67e5\u793a\u5de6\u5ba4\u589e\u5927, \u5de6\u5fc3\u5ba4\u5185\u63a2\u53ca\u4e00\u5f02\u5e38\u56e2\u5757\u6837\u56de\u58f0, \u5927\u5c0f\u7ea6 J;.. jJ!.., \u5360\u636e\u5927\u90e8\u5206\u5de6\u5ba4\u5fc3\u8154, \u56e2\u5757\u56de\u58f0\u8f83\u5747\u5300, \u8f6e\u5ed3\u6e05\u6670, \u538b\u8feb\u5de6\u5ba4\u6d41\u5165\u9053, \u6d41\u51fa\u9053, \u81f4\u4f7f\u72ed\u7a84. \u8d85\u58f0\u68c0\u67e5\u63d0\u793a:? \u5de6\u5ba4\u5b9e\u6027\u5360\u4f4d\u6027\u75c5\u53d8, \u8003\u8651\u4e3a\u7c98\u6db2\u7624;? \u4e8c\u5c16\u74e3\u72ed\u7a84\u4f34\u8fd4\u6d41 (\u4e2d\u5ea6);? \u4e09\u5c16\u74e3\u8fd4\u6d41 (\u8f7b\u5ea6). \u80f8\u90e8 &L \u5e73\u626b\u793a\u5fc3\u810f\u660e\u663e\u589e\u5927, \u5448\u666e\u5927\u578b, \u76f8\u5f53\u4e8e\u5de6\u5fc3\u5ba4\u533a\u57df\u53ef\u89c1\u4e00\u7c7b\u5706\u5f62\u7a0d\u4f4e\u5bc6\u5ea6\u5f71, \u5883\u754c\u53ef\u89c1, \u6700\u5927\u5c42\u9762\u5927\u5c0f\u7ea6\u4e3a Q\".. jJ<.., &L \u503c\u7ea6\u4e3a J a; DP, \u5bc6\u5ea6\u5747\u5300. \u63d0\u793a: \u5de6\u5fc3\u5ba4\u5360\u4f4d\u6027\u75c5\u53d8, \u8003\u8651\u6a2a\u7eb9\u808c\u7624\u53ef\u80fd\u6027\u5927. \u751f\u540e Q 1 \u56e0\u7ecf\u6d4e\u539f\u56e0\u5bb6\u957f\u653e\u5f03\u6cbb\u7597, \u751f\u540e!\" 1 \u6b7b\u4ea1. \u5c38\u4f53\u89e3\u5256\u62a5\u544a:? \u5927\u4f53\u68c0\u67e5\u53ef\u89c1\u5fc3\u810f\u603b\u4f53\u79ef\u4e3a<#.. jV#.. jQV.., \u5de6\u5ba4\u58c1\u8868\u9762\u5448\u9897\u7c92\u72b6\u7a81", "num_citations": "2\n", "authors": ["505"]}
{"title": "Interplay of Security and Reliability using Non-Uniform Checkpoints\n", "abstract": " Real time applications such as military aircraft flight control systems and online banking are critical with respect to security and reliability. In this paper we presented a way to integrate both by considering confidentiality and integrity services for security and nonuniform checkpoint strategy for reliability. The slack exploitation interacts in subtle ways for security in regards to the placement of checkpoint. The checkpoints are placed in to the task at low frequency in the beginning because the slack available can accommodate a large amount of work at risk and the frequency is increased there after considering the slack available. The security is applied to the data in two ways. First method introduces the security for the entire data at once whereas in the second method the data is divided into n uneven sections and each section is separately secured . That is at the start of the task basic security services are considered\u00a0\u2026", "num_citations": "2\n", "authors": ["505"]}
{"title": "Integrating Fault Recovery and Quality of Security in Real-time Systems\n", "abstract": " In the past five years, mandatory security requirements and fault tolerance have become critical criteria for most real-time systems. Although many conventional fault-tolerant or security approaches were investigated and applied to real-time systems, most existing schemes only addressed either security demands ignoring the fault-tolerant requirements or vice versa. To bridge this technology gap in real-time systems, in this paper we propose a way of integrating fault recovery and confidentiality services. The novel integration of security and fault recovery makes it possible to implement next-generation real-time systems with high reliability and quality of security. Experimental results from real-world applications show that our approach can significantly improve security over the conventional approaches by up to 661.56% while providing an efficient means of fault tolerance.", "num_citations": "2\n", "authors": ["505"]}
{"title": "Virtual Memory\n", "abstract": " \u25a1 Implementations\u220e Use \u201cfd\u201d to keep track of the open files of a process\u220e Design two new system calls: mapid_t mmap (fd, addr) and void munmap (mapid_t)\u220e Mmap () system call also populates the s-page table\u220e Design a data structure to keep track of these mappings (need figure out by yourself)\u220e We don\u2019t require that two processes that map the same file see the same data\u220e We do require that mmap ()\u2019ed pages are", "num_citations": "2\n", "authors": ["505"]}
{"title": "Performance analysis of an admission controller for CPU-and I/O-intensive applications in self-managing computer systems\n", "abstract": " With rapid advances in processing power, network bandwidth, and storage capacity, computer systems are increasingly becoming extremely complex. Consequently, it becomes expensive and difficult for human beings to manually manage complex computer systems. This problem can be effectively tackled by self-managing computer systems, which are intended to meet high performance requirements in a dynamic computing environment. In this paper, we develop a performance model for self-manage computer systems under dynamic workload conditions, where both CPU- and I/O-intensive applications are running in the systems. In particular, we design in this paper a 2-dimenssional Markov chain model with two different arrival and service rate of CPU- and I/O-intensive jobs. Importantly, two serving probabilities with respect to CPU-and I/O intensive jobs are derived. To validate the analytical model, we\u00a0\u2026", "num_citations": "2\n", "authors": ["505"]}
{"title": "Integrating a performance model in self-managing computer systems under mixed workload conditions\n", "abstract": " With rapid advances in processing power, network bandwidth, and storage capacity, computer systems are increasingly becoming extremely complex. Consequently, it becomes expensive and difficult for human beings to manually manage complex computer systems. This problem can be effectively tackled by self-managing computer systems, which are intended to meet high performance requirements in a dynamic computing environment. In this paper, we develop a performance model for self-manage computer systems under dynamic workload conditions, where both CPU- and I/O-intensive applications are running in the systems. In particular, we design in this paper a 2-dimensional Markov chain model with two different arrival and service rate of CPU- and I/O-intensive jobs. Importantly, two serving probabilities with respect to CPU- and I/O intensive jobs are derived. To validate the analytical model, we\u00a0\u2026", "num_citations": "2\n", "authors": ["505"]}
{"title": "Research on sampling technology in data mining [J]\n", "abstract": " With the rapid increase of the data and information, usually sampling technology is an effective method with very large dataset, and then the pattern of the whole dataset is obtained. First some conceptions about sample are discussed: large dataset are analyzed and processed by sampling technologies, then the difference between normal sampling technologies and sampling technologies in data mining is studied. Current prevailing sampling technologies are classified, simple random sampling technology and stratified random technology are researched, and the difference of every kind of sampling technology is concluded. In the end, an implementation of sampling technology in data mining is presented.", "num_citations": "2\n", "authors": ["505"]}
{"title": "Postoperative anesthetic management for patients with oral and maxillofacial surgery\n", "abstract": " PURPOSE: To investigate the essentiality of establishing postanesthesia care unit (PACU) in stomatological hospital. METHODS: Patients received intubation anesthesia10months before and after the establishment of PACU were included in this study. The differences in waking time, SpO 2 and postoperative complications were compared. RESULTS: For the patients stay in the PACU group, the time for tube extraction increased significantly (P0. 05), but the side effects after tube extraction decreased significantly (P0. 01). All the patients regained consciousness when they came back from the PACU, and their SpO 2 could keep high even without oxygen. CONCLUSION: It is necessary to establish PACU in stomatological hospital.", "num_citations": "2\n", "authors": ["505"]}
{"title": "Fault-Tolerant Support in Real-Time Collaborative Editing Systems\n", "abstract": " Groupware systems let physically dispersed teams collaborate on common tasks over distance and time. A real-time groupware system requires all users to be present at their respective sites at the same time. A non-real-time groupware system, however, lets users work on common tasks at different times. Real-time collaborative editing systems that enable groups of geographically distributed users to simultaneously view and edit shared documents, make groupware applications more practical. This usefulness becomes even more pronounced when users can use real-time collaborative editing systems on the Internet.", "num_citations": "2\n", "authors": ["505"]}
{"title": "SumRe: Design and Evaluation of a Gist\u2010based Summary Visualization for Incident Reports Triage\n", "abstract": " Incident report triage is a common endeavor in many industry sectors, often coupled with serious public safety implications. For example, at the US Food and Drug Administration (FDA), analysts triage an influx of incident reports to identify previously undiscovered drug safety problems. However, these analysts currently conduct this critical yet error\u2010prone incident report triage using a generic table\u2010based interface, with no formal support. Visualization design, task\u2010characterization methodologies, and evaluation models offer several possibilities for better supporting triage workflows, including those dealing with drug safety and beyond. In this work, we aim to elevate the work of triage through a task\u2010abstraction activity with FDA analysts. Second, we design an alternative gist\u2010based summary of text documents used in triage (SumRe). Third, we conduct a crowdsourced evaluation of SumRe with medical experts\u00a0\u2026", "num_citations": "1\n", "authors": ["505"]}
{"title": "Relation-aware Graph Attention Model With Adaptive Self-adversarial Training\n", "abstract": " This paper describes an end-to-end solution for the relationship prediction task in heterogeneous, multi-relational graphs. We particularly address two building blocks in the pipeline, namely heterogeneous graph representation learning and negative sampling. Existing message passing-based graph neural networks use edges either for graph traversal and/or selection of message encoding functions. Ignoring the edge semantics could have severe repercussions on the quality of embeddings, especially when dealing with two nodes having multiple relations. Furthermore, the expressivity of the learned representation depends on the quality of negative samples used during training. Although existing hard negative sampling techniques can identify challenging negative relationships for optimization, new techniques are required to control false negatives during training as false negatives could corrupt the learning process. To address these issues, first, we propose RelGNN\u2013a message passing-based heterogeneous graph attention model. In particular, RelGNN generates the states of different relations and leverages them along with the node states to weigh the messages. RelGNN also adopts a self-attention mechanism to balance the importance of attribute features and topological features for generating the final entity embeddings. Second, we introduce a parameter free negative sampling technique\u2013adaptive self-adversarial (ASA) negative sampling. ASA reduces the false negative rate by leveraging positive relationships to effectively guide the identification of true negative samples. Our experimental evaluation demonstrates that RelGNN\u00a0\u2026", "num_citations": "1\n", "authors": ["505"]}
{"title": "Knowledge Graph Embedding using Graph Convolutional Networks with Relation-Aware Attention\n", "abstract": " Knowledge graph embedding methods learn embeddings of entities and relations in a low dimensional space which can be used for various downstream machine learning tasks such as link prediction and entity matching. Various graph convolutional network methods have been proposed which use different types of information to learn the features of entities and relations. However, these methods assign the same weight (importance) to the neighbors when aggregating the information, ignoring the role of different relations with the neighboring entities. To this end, we propose a relation-aware graph attention model that leverages relation information to compute different weights to the neighboring nodes for learning embeddings of entities and relations. We evaluate our proposed approach on link prediction and entity matching tasks. Our experimental results on link prediction on three datasets (one proprietary and two public) and results on unsupervised entity matching on one proprietary dataset demonstrate the effectiveness of the relation-aware attention.", "num_citations": "1\n", "authors": ["505"]}
{"title": "A popularity-aware reconstruction technique in erasure-coded storage systems\n", "abstract": " In this study, we develop a novel data reconstruction technique for parallel storage systems housed in modern data centers. We advocate for erasure-coded data storage systems to archive warm data (a.k.a., unpopular data), which attract a limited number of accesses or updates. Different from hot or cold data, warm data have to be treated in a distinctive way to optimize system performance and storage-space utilization. We pay particular attention to efficient data reconstruction in which faulty data nodes are rebuilt while responding to I/O requests. To achieve this goal, we employ two machine-learning algorithms to offer online data reconstruction in erasure coded storage systems. Our data reconstruction technique is conducive to recovering faulty nodes while boosting read performance for requests accessing data residing on the faulty nodes. Our system is reliant on a clustering mechanism to group files into\u00a0\u2026", "num_citations": "1\n", "authors": ["505"]}
{"title": "Criso: An Incremental Scalable and Cost-Effective Network Architecture for Data Centers\n", "abstract": " With the explosive data growth, an enormous number of computing and networking components (e.g., servers, switches, and wires) are continuously being augmented to data centers. Data center networks (DCNs) - maintaining a high network capacity - must be cost efficient, incrementally scalable, and fault-tolerant. To address these challenges, we propose in this study a new type of DCN architecture referred to as  Criso . Different from the existing network architectures,  Criso  is designed hierarchically and recursively by employing two ports servers and commodity switches.  Criso  is constructed based on numerous isomorphic  pod  s, each of which leverages external interfaces supplied by switches to connect with neighboring pods. Additionally, a  pod -based and fault-tolerant routing algorithm is designed to handle multiple failures.  Criso  has an array of promising features, including being cost-efficient and\u00a0\u2026", "num_citations": "1\n", "authors": ["505"]}
{"title": "Modeling energy consumption of virtual machines in dvfs-enabled cloud data centers\n", "abstract": " To cut back energy consumption of virtual-machine-powered data centers, we build an optimization model for virtual machines running in DVFS-enabled cloud data centers. With the model in place, cloud computing systems are equipped to keep track of dynamic power and static power of processors in virtual machines. Unlike existing dynamic voltage and frequency scaling schemes, our solution orchestrates frequency requirements rather than task execution times. The model makes it possible to obtain an optimal frequency ratio, which minimizes energy consumption of virtual machines. As a result, a data center\u2019s energy efficiency is boosted by controlling CPU frequency to meet the optimal frequency ratio. We demonstrate a way of manipulating frequency ratios to pushing up energy efficiency without violating virtual machines\u2019 frequency requirements. The experimental results unveil that our modeling approach\u00a0\u2026", "num_citations": "1\n", "authors": ["505"]}
{"title": "A Dual-Attention Network for Joint Named Entity Recognition and Sentence Classification of Adverse Drug Events\n", "abstract": " An adverse drug event (ADE) is an injury resulting from medical intervention related to a drug. Automatic ADE detection from text is either fine-grained (ADE entity recognition) or coarse-grained (ADE assertive sentence classification), with limited efforts leveraging inter-dependencies among the two granularities. We instead propose a multi-grained joint deep network to concurrently learn the ADE entity recognition and ADE sentence classification tasks. Our joint approach takes advantage of their symbiotic relationship, with a transfer of knowledge between the two levels of granularity. Our dual-attention mechanism constructs multiple distinct representations of a sentence that capture both task-specific and semantic information in the sentence, providing stronger emphasis on the key elements essential for sentence classification. Our model improves state-of-art F1-score for both tasks:(i) entity recognition of ADE words (12.5% increase) and (ii) ADE sentence classification (13.6% increase) on MADE 1.0 benchmark of EHR notes.", "num_citations": "1\n", "authors": ["505"]}
{"title": "HybridGAN: hybrid generative adversarial networks for MR image synthesis\n", "abstract": " In this paper, we propose HybridGAN \u2013 a new medical MR image synthesis methods via generative adversarial learning. Specifically, our synthesizer generates MRI data in a sequential manner: first in order to improve the robustness of image synthesis, an input full-size real MR image is divided into an array of sub-images. Then, to avoid overfitting limited MRI encodings, these sub-images and an unlimited amount of random latent noise vectors become the input of automatic encoder for learning the marginal image distributions of real images. Finally, pseudo patches with constrained noise vectors are put into RU-NET which is a component of our HybridGAN to generate a large number of synthetic MR images. In RU-NET, A SpliceLayer is then employed to fuse sub-images together in an interlaced manner into a full-size image. The experimental results show that HybridGAN can effectively synthesize a large\u00a0\u2026", "num_citations": "1\n", "authors": ["505"]}
{"title": "An Integrated Graph Neural Network for Supervised Non-obvious Relationship Detection in Knowledge Graphs.\n", "abstract": " Non-obvious relationship detection (NORD) in a knowledge graph is the problem of finding hidden relationships between the entities by exploiting their attributes and connections to each other. Existing solutions either only focus on entity attributes or on certain aspects of the graph structural information but ultimately do not provide sufficient modeling power for NORD. In this paper, we propose KGMatcher\u2013an integrated graph neural network-based system for NORD. KGMatcher characterizes each entity by extracting features from its attributes, local neighborhood, and global position information essential for NORD. It supports arbitrary attribute types by providing a flexible interface to dedicated attribute embedding layers. The neighborhood features are extracted by adopting aggregation-based graph layers, and the position information is obtained from sampling-based position aware graph layers. KGMatcher is trained end-to-end in the form of a Siamese network for producing a symmetric scoring function with the goal of maximizing the effectiveness of NORD. Our experimental evaluation with a real-world data set demonstrates KGMatcher\u2019s 6% to 35% improvement in AUC and 3% to 15% improvement in F1 over the state-of-the-art.", "num_citations": "1\n", "authors": ["505"]}
{"title": "Thermal-Efficiency Benchmark on High-Performance Clusters\n", "abstract": " The energy efficiency of a data center depends on the cooling cost of clusters in the data center. Enhancing thermal efficiency of clusters is a practical approach to reducing energy consumption cost, optimizing scalability, and improving reliability. In this paper, we propose ThermoBench to evaluate the thermal efficiency of computing and storage clusters deployed in data centers. We shed light on the criteria and challenges of developing a thermal efficiency benchmark. We pay particular attention on clusters running scalable client-server enterprise applications in data centers. We characterize workload conditions in such a cluster computing environment in forms of client sessions of multiple requests. To resemble real-world applications, ThermoBench makes use of the TPCW benchmark to changes transaction mix and load over time. We apply ThermoBench to evaluate the thermal efficiency of a real-world cluster\u00a0\u2026", "num_citations": "1\n", "authors": ["505"]}
{"title": "TEA: A traffic-efficient erasure-coded archival scheme for in-memory stores\n", "abstract": " To achieve good trade-off between access performance and memory efficiency, it is appropriate to adopt replication and erasure coding to keep popular and unpopular in-memory datasets, respectively. An issue of redundancy transition from replication to erasure coding (aka, erasure-coded archival) should be addressed for unpopular in-memory datasets, since caching workloads exhibit long-tail distributions and most in-memory data are unpopular.", "num_citations": "1\n", "authors": ["505"]}
{"title": "A keyword-aware optimal route query algorithm on large-scale road networks\n", "abstract": " Mobile users prefer to choose personalized travel routes using their mobile terminals. Keyword-aware Optimal Route Query (KORQ) is proposed to meet users' need because it not only considering the length of the route, but also considering the cost of the route and the points of interest covered by the route. As the number of points of interest in road networks increases sharply, the time and space complexity for preprocessing and route expansion rises dramatically, and the state of the art algorithms are not scalable. To address these issues, we propose an algorithm called KORAL, short for Keyword-aware Optimal Route Query Algorithm on Large-scale Road Networks. To reduce the overhead of preprocessing, KORAL partitions the road network into subgraphs, and stores only the information about the routes between subgraphs in preprocessing stages. In the rout expansion stage, KORAL uses a strategy called\u00a0\u2026", "num_citations": "1\n", "authors": ["505"]}
{"title": "Optimizing erasure-coded data archival for replica-based storage clusters\n", "abstract": " For the sake of cost-effectiveness, it is a conventional wisdom to employ (k + r,k) erasure codes to archive rarely accessed replicas, i.e. erasure-coded data archival. Existing researches on erasure-coded data archival optimizations are mainly aimed to reduce archival traffic within storage clusters. Apart from archival traffic, both non-sequential reads and imbalanced loads can deteriorate archival performance. Traditional distributed archival schemes (DArch for short) for randomly distributed replicas tend to suffer from two problems: (i) non-sequential reads because underlying file systems split a data block into multiple smaller data chunks and (ii) imbalanced loads since archival tasks are assigned according to data locality of replicas. To overcome such drawbacks, we incorporate both prefetching mechanism and balancing strategy into erasure-coded archival for replica-based storage clusters, and propose three\u00a0\u2026", "num_citations": "1\n", "authors": ["505"]}
{"title": "Designing a Visual Analytics System for Medication Error Screening and Detection\n", "abstract": " Drug safety analysts at the U.S. Food & Drug Administration analyze medication error reports submitted to the Adverse Event Reporting System (FAERS) to detect and prevent detrimental errors from happening in the future. Currently this review process is time-consuming, involving manual extraction and sense-making of the key information from each report narrative. There is a need for a visual analytics approach that leverages both computational techniques and interactive visualizations to empower analysts to quickly gain insights from reports. To assist analysts responsible for identifying medication errors in these reports, we design an interactive Medication Error Visual analytics (MEV) system. In this paper, we describe the detailed study of the Pharmacovigilance at the FDA and the iterative design process that lead to the final design of MEV technology. MEV a multi-layer treemap based visualization system\u00a0\u2026", "num_citations": "1\n", "authors": ["505"]}
{"title": "MEV: Visual Analytics for Medication Error Detection.\n", "abstract": " To detect harmful medication errors and inform regulatory actions, the US Food & Drug Administration uses the FAERS spontaneous reporting system to collect medication error reports. Drug safety analysts, however, review the submitted report narratives one by one to pinpoint critical medication errors. Based on a formative study of the review process requirements, we design an interactive visual analytics prototype called Medication Error Visual analytics (MEV), to facilitate the medication error review process. MEV visualizes distributions of the reports over multiple data attributes such as products, types of error, etc., to guide analysts towards most concerning medication errors. MEV supports interactive filtering on key data attributes that aim to help analysts hone in on the set of evidential reports. A multi-layer treemap visualizes the count and severity of the errors conveyed in the underlying reports, while the interaction between these layers aid in the analysis of the corresponding data attributes and their relationships. The results of a user study conducted with analysts at the FDA suggests that participants are able to perform the essential screening and review tasks more quickly with MEV and perceive tasks as being easier with MEV than with their existing tool set. Post-study qualitative interviews illustrates analysts\u2019 interest in the use of visual analytics for FAERS reports analysis operations, opportunities for improving the capabilities of MEV, and new directions for analyzing critical spontaneous reports at scale.", "num_citations": "1\n", "authors": ["505"]}
{"title": "Towards thermal-aware Hadoop clusters\n", "abstract": " With the exponential increase in cooling costs of large-scale data centers, thermal management must be adequately addressed. Recent trends have discovered one of the critical reasons behind the temperature rise turns out to be heat re-circulation within data center. In this study, we proposed a new resource- and thermal-aware scheduler in Hadoop clusters; our scheduler aims at minimizing peak inlet temperature across all nodes to reduce power consumption and cooling cost in data centers. The proposed dynamic scheduler makes job scheduling decisions based on current CPU/disk utilization and number of tasks running as well as the feedback given by all slave nodes at run-time. We deploy a thermal model to project respective temperature of each slave node in addition to neighbor\u2019s heat contribution. The thermal-aware scheduler is integrated with the Hadoop\u2019s scheduling mechanism. We test our\u00a0\u2026", "num_citations": "1\n", "authors": ["505"]}
{"title": "DEVES: interactive signal analytics for drug safety\n", "abstract": " Drug-drug interaction related adverse events (DIAE) signals are a major public health issue. Drug safety analysts must sift through thousands of adverse event reports submitted daily to US Food and Drug Administration (FDA) to discover unexpected DIAE signals, which if addressed can lead to life-saving actions. To facilitate the DIAE discovery from these massive data sets, we design several technological innovations that together are integrated into an interactive visual analytics system called DEVES 1. First, our state-of-the-art DIAE mining algorithm efficiently infers potential DIAE signals from these reports, and then ranks them based on their significance score. For interpretability of these inferred DIAE signals, domain knowledge of adverse events and already known drug interactions is extracted from external authoritative data sources and then seamlessly integrated with the inferred signal set. Guided by this\u00a0\u2026", "num_citations": "1\n", "authors": ["505"]}
{"title": "Multi-layered Learning for Information Extraction from Adverse Drug Event Narratives\n", "abstract": " Recognizing named entities in Adverse Drug Reactions narratives is a crucial step towards extracting valuable patient information from unstructured text and transforming the information into an easily processable structured format. This motivates using advanced data analytics to support data-driven pharmacovigilance. Yet existing biomedical named entity recognition (NER) tools are limited in their ability to identify certain entity types from these domain-specific narratives, resulting in poor accuracy. To address this shortcoming, we propose our novel methodology called Tiered Ensemble Learning System with Diversity (TELS-D), an ensemble approach that integrates a rich variety of named entity recognizers to procure the final result. There are two specific challenges faced by biomedical NER: the classes are imbalanced and the lack of a single best performing method. The first challenge is addressed\u00a0\u2026", "num_citations": "1\n", "authors": ["505"]}
{"title": "Deep Learning Strategies for Automatic Detection of Medication and Adverse Drug Events from Electronic Health Records.\n", "abstract": " Background. Detecting the occurrence of adverse drug events (ADEs) and related medical information is an integral step towards the prevention of future critical ADE incidents threatening the public. Electronic health records (EHRs) of patients, a valuable source for potential ADE signals, are unstructured reports comprised of non-medical descriptive text and complex medical terminology 1. Therefore, detecting a complete phrase that represents a named entity signaling an incidence is challenging. Recent research, leveraging popular deep learning approaches for the detection of medical information from EHRs, has outperformed state-of-the-art conditional random fields (CRF) 2. An integration of recurrent neural networks (RNN) with CRF has also shown good performance 3.Objective. Develop deep learning solution that achieves high accuracy in detection of medical entities from EHRs.", "num_citations": "1\n", "authors": ["505"]}
{"title": "Thermal profiling and modeling of hadoop clusters using bigdata applications\n", "abstract": " In this paper, we propose a thermal model called tModel, which projects outlet temperatures from inlet temperatures as well as directly measured multicore temperatures rather than deploying a utilization model. We perform extensive experimentation by varying applications types, their input data sizes, and cluster sizes. We collect inlet, outlet, and multicore temperatures of cluster nodes running a group of big-data applications. The proposed thermal model estimates the outlet air temperature of the nodes to predict cooling costs. We validate the accuracy of our model against data gathered by thermal sensors in our cluster. Our results demonstrate that tModel estimates outlet temperatures of the cluster nodes with much higher accuracy over CPU-utilization based models. We further show that tModel is conducive of estimating the cooling cost of data centers using the predicted outlet temperatures.", "num_citations": "1\n", "authors": ["505"]}
{"title": "Thermal\u2010aware task assignments in high performance computing clusters\n", "abstract": " Cluster\u2010level thermal management has gained much attention over the past decade due to rising cooling costs associated with data centers. In this research, we propose and implement a static scheduler called SSched and a dynamic one named DSched. These 2 algorithms schedule jobs based on CPU and disk temperatures of a Hadoop cluster's nodes. Our schedulers rely on a monitoring mechanism to keep track of CPU and disk utilization, maintaining CPU and disk temperatures below a threshold through thermal\u2010aware scheduling decisions. To facilitate the design of SSched and DSched, we classify jobs into the CPU\u2010intensive and disk\u2010intensive categories. When a job arrives, SSched retrieves the utilization stats from a profiled log, estimates the thermal behavior, and places the job on NodeManager to minimize thermal impacts. Unlike SSched, DSched improves thermal efficiency of Hadoop clusters\u00a0\u2026", "num_citations": "1\n", "authors": ["505"]}
{"title": "Occurrences, Distributions, and Multivariate Analyses of Trace Elements in Agricultural Soils in the Xinzhou Area of Shanxi, China\n", "abstract": " Multivariate and geostatistical analyses were used to assess the trace element contents and distributions in agricultural soils from the Xinzhou area of Shanxi, China, and to identify the sources of the trace elements. Samples with high trace element contents were concentrated in eastern Xinzhou, and the contents decreased east to west. Principal component and redundancy analyses showed that the Co, Cu, Mn, Ni, Se, V, and Zn contents correlated well, suggesting that these elements came from similar parent materials. The contents of these elements also correlated with the soil properties. The Cd and Pb contents were significantly higher in the agricultural soil samples than the background soil profiles (P< 0.05), and increased as the gross domestic product of the area increased but decreased as the distance to the nearest road. Human activities therefore appear to have strongly influenced Cd and Pb distribution patterns. A novel artificial neural network (ANN) model, using environmental input data, was used to predict the Cd and Pb contents of soil on specified test dates. The performances of the ANN method and traditional multilinear regression methods were compared. The ANN model could successfully predict the Cd and Pb content distributions. The ANN model predicted that the Cd and Pb contents of soil will increase by 128% and 25%, respectively, by 2020. The results showed that the economic structure of an area has more effect than the scale of the economy", "num_citations": "1\n", "authors": ["505"]}
{"title": "Miner*: A weighted distance sum based outlier mining system of star spectrum data\n", "abstract": " Existing distance-based outlier mining methods do not consider the impact of each attribute's importance degree, thereby resulting in poor mining accuracies. To address this problem, we propose a new outlier mining algorithm \u2013 Miner* \u2013 that makes use of information entropy and Weighted Distance Sum to substantially improve mining accuracies. Miner* employs information entropy to determine weight values indicating the importance degrees of data attributes. An input dataset is reduced by Miner* through the neighbour-radius-based pruning technologies. Thus, Miner* obtains a candidate outlier set by removing any data objects that are unlikely to be outliers. Miner* calculates the weighted distance sum value Wk of each object in the candidate outlier set; Wk value ranks the top n to be regarded as outliers. Due to the sum of distance, which takes full advantage of the clustering characteristics of the dataset, edge\u00a0\u2026", "num_citations": "1\n", "authors": ["505"]}
{"title": "An efficient etherification of Ginkgol biloba extracts with fewer side effects in a micro-flow system\n", "abstract": " In this study, etherification of ginkgolide B and dimethylaminoethyl chloride hydrochloride was investigated as a model reaction in a micro-flow system (MFS), providing the resulting ethers in high yield with fewer side effects. Meanwhile, this novel process in MFS worked well for other ginkgolides from Ginkgol biloba and halides, giving moderate yields.", "num_citations": "1\n", "authors": ["505"]}
{"title": "Profiling energy usage of web-service applications on clusters\n", "abstract": " Energy saving is rapidly becoming one of the hottest topics in technology field within recent decades. With the development of technology, it brings a sheer increasing trend of data and the growth scale of clusters and data centers. Meanwhile, it also raises another essential issue into the path: energy cost. In this paper, we are diving into this key issue and evaluating energy- efficiency based on TPC-W benchmark: a notable web transaction e-commerce benchmark. We simulate the web transaction with different database sizes and collect the energy data by KILL-A-WATT. Also, we deploy this setup on four different cluster systems: PC nodes and wimpy nodes, and two different heterogeneous systems: using PC as front server and wimpy as Database server, and using wimpy as Web server and PC as Database server. Energy result demonstrates different characteristics among them, which can give lightening advice\u00a0\u2026", "num_citations": "1\n", "authors": ["505"]}
{"title": "Interactive temporal association analytics\n", "abstract": " Traditional temporal association mining systems, once supplied with a specific parameter setting such as time periods of interest, minimum support and confidence, generate the rule set from scratch. This one-at-a-time paradigm forces the analysts to perform successive trial-and-error iterations to finally discover interesting temporal patterns. This process is not only prohibitively time and resource consuming, but also ineffective in providing meaningful feedback for improving the desired rule outcome. In this work, we introduce the first solution to interactively explore temporal associations from evolving data at multiple levels of abstraction, henceforth referred to as temporal association rule analytics (TARA). The offline rule preparation phase of the TARA infrastructure extracts the temporal associations from the raw data and compresses them into a knowledge-rich yet compact evolving parameter space (EPS) structure. The online exploration phase of TARA leverages this EPS structure to offer rich classes of novel exploration operations from parameter recommendations and time-travel queries to the discovery of hidden insights of associations with near instantaneous responsiveness. As demonstrated by our extensive experiments on realworld data sets, TARA accomplishes three to five orders of magnitude improvement over state-of-the art approaches while offering a rich interactive exploration experience.", "num_citations": "1\n", "authors": ["505"]}
{"title": "CoRec: a cooperative reconstruction pattern for multiple failures in erasure-coded storage clusters\n", "abstract": " It is indispensable to speed up a reconstruction process in erasure-coded storage clusters, because a fast data recovery helps to shorten the vulnerability window while improving storage system reliability. To address double- and multiple-node failures, this paper proposes a cooperative reconstruction pattern - CoRec - to minimize reconstruction traffic. CoRec not only enables all rebuilding nodes to collaboratively reconstruct failed blocks but also limits each surviving block to be transferred over network only once. To clarify two CoRec based reconstruction schemes (i.e., CoRec-rn and CoRec-sn), we investigate two alternative reconstruction schemes (i.e., CRec and DRec). We develop reconstruction-time models, which are validated using empirical data, to estimate reconstruction performance of large-scale storage clusters and to pinpoint performance bottlenecks in the reconstruction process. We implement a\u00a0\u2026", "num_citations": "1\n", "authors": ["505"]}
{"title": "MLFS: a multiple layers share file system for cloud computing\n", "abstract": " Cloud computing systems offer computing and storage resources at a low price. The users only pay for it when the VM(short for Virtual Machine) is running. While after VMs shut down, the vendors also need disk space to store multi-gigabyte VM images. Past studies use deduplication to reduce the space requirements, but it needs to calculate hash values of each block and store them. It also causes performance overhead costs to find identical content. In this paper, We propose a multiple layers file sharing system(MLFS) designed for cloud computing. It stores OS data, Application data, and user data in different layers. Multiple users share OS data layers. Application data are constructed according to users' selection, and they are deleted after VM shut down. We compare our solution with ordinary storage systems, storage systems with deduplication, the results show that MLFS can save more space than others\u00a0\u2026", "num_citations": "1\n", "authors": ["505"]}
{"title": "Exploring optimal combination of a file system and an I/O scheduler for underlying solid state disks\n", "abstract": " Performance and energy consumption of a solid state disk (SSD) highly depend on file systems and I/O schedulers in operating systems. To find an optimal combination of a file system and an I/O scheduler for SSDs, we use a metric called the aggregative indicator (AI), which is the ratio of SSD performance value (e.g., data transfer rate in MB/s or throughput in IOPS) to that of energy consumption for an SSD. This metric aims to evaluate SSD performance per energy consumption and to study the SSD which delivers high performance at low energy consumption in a combination of a file system and an I/O scheduler. We also propose a metric called Cemp to study the changes of energy consumption and mean performance for an Intel SSD (SSD-I) when it provides the largest AI, lowest power, and highest performance, respectively. Using Cemp, we attempt to find the combination of a file system and an I/O\u00a0\u2026", "num_citations": "1\n", "authors": ["505"]}
{"title": "\u57fa\u4e8e\u52a8\u6001\u77e9\u9635\u63a7\u5236\u7684\u4e3b\u52a8\u961f\u5217\u7ba1\u7406\u7b97\u6cd5\n", "abstract": " \u9488\u5bf9 Internet \u7cfb\u7edf, \u901a\u8fc7\u5bf9\u6d41\u4f53\u6d41\u6a21\u578b\u7684\u5206\u6790, \u63d0\u51fa\u4e86\u4e00\u4e2a\u65b0\u7684\u9884\u6d4b\u6a21\u578b. \u8be5\u6a21\u578b\u5f62\u5f0f\u7b80\u5355, \u53c2\u6570\u7684\u8ba1\u7b97\u76f8\u5bf9\u5bb9\u6613, \u5e76\u4e14\u80fd\u6839\u636e\u5f53\u524d\u7684\u7f51\u7edc\u60c5\u51b5\u6709\u6548\u7684\u9884\u6d4b\u62e5\u585e\u7a97\u53e3\u7684\u53d8\u5316. \u7ed3\u5408\u52a8\u6001\u77e9\u9635\u63a7\u5236 (DynamicMatrixControl, DMC) \u7406\u8bba, \u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u4e3b\u52a8\u961f\u5217\u7ba1\u7406\u7b97\u6cd5\u2014\u2014\u2014DMCAQM \u7b97\u6cd5, \u7ed9\u51fa\u4e86 DMCAQM \u7684\u8be6\u7ec6\u8bbe\u8ba1\u8fc7\u7a0b, \u7a33\u5b9a\u6027\u5206\u6790\u548c\u53c2\u6570\u9009\u53d6\u539f\u5219. \u5927\u91cf\u4e0d\u540c\u7f51\u7edc\u73af\u5883\u7684\u4eff\u771f\u5b9e\u9a8c\u8868\u660e DMCAQM \u7b97\u6cd5\u662f\u6709\u6548\u7684. \u4e0e PI, RaQ \u548c REM \u7b49\u7b97\u6cd5\u76f8\u6bd4\u8f83, DMCAQM \u6709\u6536\u655b\u901f\u5ea6\u5feb, \u961f\u5217\u6296\u52a8\u5c0f\u7684\u4f18\u70b9. \u540c\u65f6, \u7531\u4e8e DMCAQM \u7684\u91c7\u6837\u95f4\u9694\u76f8\u5bf9\u8f83\u5927, \u800c\u7b97\u6cd5\u5b9e\u73b0\u7b80\u5355, \u6240\u4ee5\u8ba1\u7b97\u91cf\u5c0f, \u5360\u7528\u7684\u8def\u7531\u5668\u8d44\u6e90\u66f4\u5c11.", "num_citations": "1\n", "authors": ["505"]}
{"title": "We didn't start the fire: using an agent-directed thermal simulator to keep servers cool\n", "abstract": " As energy use by datacenters has risen over the years, the costs required to run a datacenter have substantially increased. Several thermal-aware algorithms exist to minimize energy consumption, but comparing these implementations can be difficult. Thermal modelers aid in the juxtaposition of several of these thermal-aware algorithms. Unfortunately, existing thermal modelers can be slow and difficult to use. Agent-Directed Thermal Modeler (ADTM) provides a solution that has a low learning curve and still quickly produces visualizations of a datacenter. The low number of input parameters significantly simplifies the use of ADTM, and its simulation time runs in seconds and minutes rather than hours. The resulting graphical and pictorial output can be used to determine which thermal-aware algorithm works best for a given datacenter.", "num_citations": "1\n", "authors": ["505"]}
{"title": "Energy consumption characteriation of heterogeneous servers\n", "abstract": " Energy and cooling cost is becoming the main cost of data centers. Many studies focused on how to schedule job and migrate Virtual Machine between servers to save energy. An accurate energy consumption model is the basic of energy management. Most past studies show that energy consumption has linear relation with resource utilization. We found that different servers have different energy consumption characters even with same CPU and similar workloads. Most past models were only validated on several servers. These models did not reflect the characters of different kinds of servers in a heterogeneous data center. In this paper, we verified the accuracy of the linear model on 392 servers. The data come from the results of SPECPower_ssj2008 benchmark. The benchmark was released in 2007. There are 392 servers from 26 vendors were tested in the past six years. These servers represent most common\u00a0\u2026", "num_citations": "1\n", "authors": ["505"]}
{"title": "Blood and renal fractalkine expression in patients with lupus nephritis and its significance\n", "abstract": " OBJECTIVE: To investigate the expression of fractalkine (FKN) in the blood and renal tissues of patients with lupus nephritis and explore its significance. METHODS: According to the pathological classification, 48 patients with lupus nephritis were divided into mild group (22 cases) and severe group (26 cases), with 26 healthy subjects as the control group. RT-PCR and enzyme-linked immunosorbent assay were employed to detect the expression of FKN mRNA and protein in the blood of the subjects, and FKN expression and localization in the renal tissue of the patients with lupus nephritis were detected using immunohistochemical staining. RESULTS: The patients in both the mild and severe groups showed significantly increased expression of blood FKN mRNA and protein compared with the normal controls, and the increase was more obvious in severe cases (P< 0.01). In the renal tissues of the patients, FKN was located mainly in the cytoplasm of the glomerular podocytes and renal tubular epithelial, and the number of positive glomerular cells number was significantly greater in severe cases than in the mild cases (P< 0.01); FKN expression in the cortical interstitium did not show a significant difference between the 3 groups. CONCLUSION: FKN expression in the blood and glomeruli of patients with lupus nephritis is related to the severity of renal pathologies.", "num_citations": "1\n", "authors": ["505"]}
{"title": "MO\u2010F\u2010213CD\u201008: Characterization of the Homogeneous Breast Tissue Mixture Approximation for Breast Image Dosimetry\n", "abstract": " Purpose: To characterize the suitability of the use of a homogeneous mixture of adipose and glandular tissue approximation for breast imaging dosimetry. Methods: Fifteen patient breast computed tomography images (BCT) were classified into skin, adipose, and glandular tissue. The segmented breasts underwent simulated mechanical compression to mimic breast compression during mammographic acquisition. Using Monte Carlo simulations representing BCT and mammographic acquisitions, the radiation dose to the voxels representing glandular tissue for both the uncompressed and compressed breasts was estimated. The BCT simulations used both a 49 kVp and 80 kVp tungsten target spectrum, while the mammography simulations used the spectra corresponding to the patient's screening cranio\u2010caudal view mammogram. The simulations were repeated by replacing the adipose and glandular voxels with\u00a0\u2026", "num_citations": "1\n", "authors": ["505"]}
{"title": "Seam extraction method based on Sobel operator and greedy Snake model\n", "abstract": " With the development of welding automation and intelligence, It's very important to accurately extract the edge of welding seam for automatic welding quality control. According to the characteristics of MIG welding, an image sensing system of the welding seam was established. Based on a clearer weld pool image, A new method combined Sobel operator and greedy Snake active model to extract the edge of welding seam was presented. The experimental results show that this method can obtain a more accurate seam edge comparing with Sobel operator method.", "num_citations": "1\n", "authors": ["505"]}
{"title": "Jamming-resilient multi-radio multi-channel multihop wireless network for smart grid\n", "abstract": " For smart grid, an enabler technology is the attack-tolerant two-way communication network. The wireless network plays an essential role in supporting the power scheduling and allocation in smart grid. However, the wireless network is vulnerable to jamming attacks, which potentially endangers the safety of the smart grid. In this paper, we propose a jamming-resilient multi-radio multi-channel multihop (M3) network for smart grid and investigate the throughput limit of the network under jamming attack by formulating the joint routing and scheduling problem and solving it via linear programming (LP). We also apply a machine learningbased dynamic channel assignment algorithm to approximate throughput limit when the adversary can change jamming strategies dynamically. The simulation confirms that our design outperforms the naive approach that relies on random frequency hopping at the link layer.", "num_citations": "1\n", "authors": ["505"]}
{"title": "An energy-efficient spatial window query processing algorithm in wireless sensor networks\n", "abstract": " BackgroundAbstract The energy consumption of existing spatial window query processing algorithms in wireless sensor networks is fairy high. When some sensor nodes fail, the query process of these algorithms is very likely to be interrupted and unable to return query result. An energy-efficient spatial window query processing algorithm called ESA is proposed in this paper. It divides the query region into several grids. Each grid has a cluster node which collects the sensory data in it, aggregates the data to derive partial query result and sends it to the cluster node in the next grid. The above process is repeated until all nodes within the query region are traversed in order to generate the final query result. ESA only requires each node within the query region send data message once, which reduces the data messages. The authors propose two grid dividing and cluster node selection algorithms according to the ESA\u00a0\u2026", "num_citations": "1\n", "authors": ["505"]}
{"title": "Quality of security adaptation in parallel disk systems\n", "abstract": " In the past decade, parallel disk systems have been highly scalable and able to alleviate the problem of disk I/O bottleneck, thereby being widely used to support data-intensive applications. Although a variety of parallel disk systems were developed, most existing disk systems lack a means to adaptively control the quality of security for dynamically changing workloads. We address this gap in disk technology by designing, implementing, and evaluating a quality of security control framework for parallel disk systems, or ASPAD for short, that makes it possible for parallel disk systems to adapt to changing security requirements and workload conditions. The ASPAD framework comprises four major components, namely, a security service middleware, a dynamic data-partitioning mechanism, a response time estimator, and an adaptive security quality controller. The framework is conducive to adaptively and expeditiously\u00a0\u2026", "num_citations": "1\n", "authors": ["505"]}
{"title": "CaPaS: an optimal security-aware cache replacement algorithm for cluster storage systems\n", "abstract": " In this paper, we introduce a novel dynamic cache management approach, i.e., a cache partitioning system (CaPaS), to optimise security levels in contemporary cluster storage systems for data-intensive applications with acceptable disk response times. CaPaS utilises an adaptive security control mechanism to adjust for varying workload conditions initiated by client-issued disk requests as well as security requirements and contains a cache partitioning scheme, a response-time estimator, and an adaptive security quality controller. The CaPaS algorithm solves a non-linear optimisation problem to increase the quality of security of disk requests in cluster storage systems while ensuring the disk requests to be completed within their desired response times. The efficiency of the proposed algorithm has been tested with the newly defined performance indicators on a cluster storage system including CaPaS, eight\u00a0\u2026", "num_citations": "1\n", "authors": ["505"]}
{"title": "Detecting simultaneous integer relations for several real vectors\n", "abstract": " An algorithm which either finds an nonzero integer vector  for given  real -dimensional vectors  such that  or proves that no such integer vector with norm less than a given bound exists is presented in this paper. The cost of the algorithm is at most  exact arithmetic operations in dimension  and the least Euclidean norm  of such integer vectors. It matches the best complexity upper bound known for this problem. Experimental data show that the algorithm is better than an already existing algorithm in the literature. In application, the algorithm is used to get a complete method for finding the minimal polynomial of an unknown complex algebraic number from its approximation, which runs even faster than the corresponding \\emph{Maple} built-in function.", "num_citations": "1\n", "authors": ["505"]}
{"title": "Combined application of cavitron ultrasonic surgical aspirator and vascular exclusion in anatomical hemi-hepatectomy [J]\n", "abstract": " Objective To explore the applied experience of cavitron ultrasonic surgical aspirator (CUSA) and hepatic vascular exclusion in anatomical hemi-hepatectomy. Methods From January 2007 to January 2009, combined uses of CUSA and vascular exclusion technique (hemi-hepatic pedicle exclusion with/or selective hepatic vein occlusion) were carried on the dissectional half liver excision for 18 cases of hepatocellular carcinoma (HCC). Results The median intraoperative blood loss was 450ml (250-1 500 ml), and 88.9% of the patients (16/18) didn\u2032 t need perioperative blood transfusion. The postoperative complication occurred in 38.8% of the patients (7/18) with pleural effusion most common, no death case was oberserved during perioperative period. Conclusion Combined application of CUSA and vascular exclusion technique allow anatomical hemi-hepatectomy to be done safely and might gain improved surgical outcome of HCC.", "num_citations": "1\n", "authors": ["505"]}
{"title": "Prediction of Successfulness of Transcervical Resection of Endometrium for Dysfunctional Uterine bleeding [J]\n", "abstract": " Objective: To investigate the effectiveness of transcervical resection of endometrium (TCRE) in the treatment of dysfunctional uterine bleeding and to identify the possible predictive factors for a successful outcome. Methods: 36 patients with intractable dysfunctional uterine bleeding who were treated with TCRE from 2007.6~ 2009.6 were followed up for 6 month and their clinical data were retrospectively reviewed, including age, depth of uterine cavity, partum time, duration of disease and degree of anemia. All these factors were evaluated by Logistic analysis. Results: The overall improvement rate (amenorrhea or hypomenorrhea) was 91.7% at 3-month follow-up and 88.9% at 6-month follow-up; Multiple logistic regression analysis showed that age and depth of uterine cavity were two important factors for the outcome. Conclusions: TCRE is an effective treatment for intractable dysfunctional uterine bleeding. Increased age and a shorter depth of uterine cavity are two predictive factors for a successful outcome.", "num_citations": "1\n", "authors": ["505"]}
{"title": "An efficient approach for computing distance between two quadratic surfaces\n", "abstract": " In computer-aided design systems and virtual reality, the computation of distance between two objects is required. The problem of distance computation has been well studied for polyhedral objects in the past years. However, the curve surfaces of objects are often approximated by polyhedral, suffering from accuracy problem due to approximation errors. In order to improve the accuracy, the surfaces of objects are approximated by piecewise quadratic surfaces, and the conditional relative extremum is calculated with Lagrange multiplier, which results in solving a system of two bivariate polynomials with high degree. In this paper, an efficient approach is presented, yielding a system of two bivariate polynomial with degree 6. Compared with the other bivariate polynomials arising from distance computation for two quadratic surfaces, the degree of polynomials from our approach is the lowest and the computation\u00a0\u2026", "num_citations": "1\n", "authors": ["505"]}
{"title": "Can We Improve Energy Efficiency of Secure Disk Systems without Modifying Security Mechanisms?\n", "abstract": " Improving energy efficiency of security-aware storage systems is challenging, because security and energy efficiency are often two conflicting goals. The first step toward making the best tradeoffs between high security and energy efficiency is to profile encryption algorithms to decide if storage systems would be able to produce energy savings for security mechanisms. We are focused on encryption algorithms rather than other types of security services, because encryption algorithms are usually computation-intensive. In this study, we used the XySSL libraries and profiled operations of several test problems using Conky - a lightweight system monitor that is highly configurable. Using our profiling techniques we concluded that although 3DES is much slower than AES encryption,it more likely to save energy in security-aware storage systems using 3DES than AES. The CPU is the bottleneck in 3DES, allowing us to\u00a0\u2026", "num_citations": "1\n", "authors": ["505"]}
{"title": "An Energy-Efficient Reliability Model for Parallel Disk Systems\n", "abstract": " In the last decade, parallel disk systems have increasingly become popular for data-intensive applications running on high-performance computing platforms. Conservation of energy in parallel disk systems has a strong impact on the cost of cooling equipment and backup power-generation. This is because a significant amount of energy is consumed by parallel disks in high-performance computing centers. Although a wide range of energy conservation techniques have been developed for disk systems, most energy saving schemes have adverse impacts on the reliability of parallel disk systems. To address this deficiency, we must focus on reliability analysis for energy-efficient parallel disk systems. In this paper, we make use of a Markov process to develop a quantitative reliability model for energy-efficient parallel disk systems using data mirroring. With the new model in place, a reliability analysis tool is\u00a0\u2026", "num_citations": "1\n", "authors": ["505"]}
{"title": "Reversible network iterative construct method based on the cascade operation\n", "abstract": " This paper presents an algorithm of iterative construct reversible network by cascade operation. The cascade operation was implemented with Boolean permutation. We proposed two important decision condition of Boolean permutation, and changed to choose balance function of suffice Boolean permutation condition for the problem of construct reversible network. The result of algorithm analysis show that it is can be implemented fleetly.", "num_citations": "1\n", "authors": ["505"]}
{"title": "Energy efficient and reliable storage disks\n", "abstract": " Computer hard disks have different failure probability rates that are a function of age and utilization. In this paper the relationship between the disk age, utilization, and failure probabilities are determined. This relationship is used to estimate a safe utilization zone for a disk dependent on its age. Results prove that when disks are operated in safe utilization zones the probability of failure is minimised drastically. Energy consumption is reduced by operating the disks at three power modes: Active, Idle and Sleep. We considered a storage system organized using RAID 1 for the experiments. In RAID 1 data is mirrored to the backup disks from the primary disks. Traditional methods wake up the backup disks when the utilization of the primary disks exceeds 100 percent or both the disks are always active to balance the load between the disks. These methods consume a massive amount of energy. Hence, we designed a\u00a0\u2026", "num_citations": "1\n", "authors": ["505"]}
{"title": "Stochastic scheduling for multiclass applications with availability requirements in heterogeneous clusters\n", "abstract": " High availability plays an important role in heterogeneous clusters, where processors operate at different speeds and are not continuously available for processing. Existing scheduling algorithms designed for heterogeneous clusters do not factor in availability. We address in this paper the stochastic scheduling problem for heterogeneous clusters with availability constraints. Each node in a heterogeneous cluster is modeled by its speed and availability, and different classes of tasks submitted to the cluster are characterized by their execution times and availability requirements. To incorporate availability and heterogeneity into stochastic scheduling, we introduce metrics to quantify availability and heterogeneity in the context of multiclass tasks. A stochastic scheduling algorithm SSAC (stochastic scheduling with availability constraints) is then proposed to improve availability of heterogeneous clusters while\u00a0\u2026", "num_citations": "1\n", "authors": ["505"]}
{"title": "Network structure cascade for reversible logic\n", "abstract": " A reversible logic function maps each of the 2m input patterns to a unique output pattern. The network cascade structure problem is to realize a reversible function by a cascade of primitive reversible gates. We present a method that synthesizes a network with family of Toffoli gates. The cascade algorithm finds cascade of Toffoli gates with no backtracking and minimal look-ahead, and apply transformations that reduce the number of gates in the network. We have synthesized all three input and output reversible functions and compare our results to the other optimal results. We also present the results of applying our synthesis method to obtain networks for number of benchmark function.", "num_citations": "1\n", "authors": ["505"]}
{"title": "An improved density-based spatial clustering algorithm with sampling\n", "abstract": " DBSCAN is one of the effective spatial clustering algorithms, which can discover clusters of any arbitrary shape and handle the noise effectively. However, it has also several disadvantages. First, it is based on only spatial attributes without considering non-spatial attributes in the databases. Second, when DBSCAN handles large-scale spatial databases, it requires large volume of memory support and I/O cost. In this paper, an improved density-based spatial clustering algorithm with sampling (IDBSCAS) is developed, which not only clusters large-scale spatial databases effectively, but also considers spatial attributes and non-spatial attributes. Experimental results of 2-D spatial datasets show that the new algorithm is feasible and efficient.", "num_citations": "1\n", "authors": ["505"]}
{"title": "An intrusion detection method based on clustering multidimensional sets\n", "abstract": " Most of clustering methods focus on single-dimensional or inter-dimensional data. The paper extends the concept of single-dimensional set to multidimensional set, which is a kind of set whose element is also a single-dimensional set. The paper first presents the definition and similarity model of multidimensional set, whose distance space is proved to be a metric space. Then a database anomaly detection algorithm MSDensity is presented, which defines distance between queries by their results and looks on their results as multidimensional sets based on duple identifiers and querying attributes. For the main intention of users is to get data in database, result sets of queries can describe the actions of users more accurately. And since a metric index tree can be used for detection algorithm, a faster speed for detecting real-time query can be acquired and the experiment results also show it", "num_citations": "1\n", "authors": ["505"]}
{"title": "AWARDS: an adaptive write strategy for secure local disk systems\n", "abstract": " Since security is of critical importance for modern storage systems, it is imperative to protect stored data from being tampered or disclosed. Although an increasing number of secure storage systems have been developed, there is no way to dynamically choose security services to meet disk requests' flexible security requirements. Furthermore, existing security techniques for disk systems are not suitable to guarantee desired response times of disk requests. We remedy this situation by proposing an adaptive strategy (referred to as AWARDS) that can judiciously select the most appropriate security service for each write request while endeavoring to guarantee the desired response times of all disk requests. Experimental results show that AWARDS significantly improves security and overall performance over an existing scheme by up to 325.0% and 358.9% (with averages of 199.3% and 213.4%)", "num_citations": "1\n", "authors": ["505"]}
{"title": "The Topological Relations Analysis for Indeterminate Regions Evolving with Time\n", "abstract": " The topic of uncertainty management is a new issue in spatiotemporal database research. Some efforts have already been made on the indeterminacy representation models, while the area of topological relations models for indeterminate spatiotemporal objects remain untouched. The goals of these models are to provide a set of Joint Exclusive and Pair wise Disjoint topological relations for uncertain spatiotemporal objects. This paper presents a topological relations model for indeterminate evolving 2D regions. It checks the correspondence between 3d topological relations and spatiotemporal relations, provides restrictions to make the 3d relation model fitful for spatiotemporal objects. Then it extends Egg/Yolk model to the third dimension that can describe the approximate topological relations for indeterminate evolving regions. The result is a collection of relations clusters which have different spatiotemporal nature.", "num_citations": "1\n", "authors": ["505"]}
{"title": "Improving the performance of communication-intensive parallel applications executing on clusters\n", "abstract": " Summary form only given. Clusters have emerged as a primary and cost-effective infrastructure for parallel applications, including communication-intensive applications that transfer a large amount of data among nodes of a cluster via the interconnection network. Conventional load balancers have been proven effective in increasing the utilization of CPU, memory, and disk I/O resources in a cluster. However, most of the existing load balancing schemes ignore network resources, leaving open the opportunity for significant performance bottleneck to form for communication-intensive parallel applications due to unevenly distributed communication load. To remedy this problem, we propose a communication-aware load balancing technique that is capable of improving the performance of communication-intensive applications by increasing the effective utilization of network resources in clusters. To facilitate the\u00a0\u2026", "num_citations": "1\n", "authors": ["505"]}
{"title": "Dynamic I/O-aware load balancing and resource management for clusters\n", "abstract": " In the last decade, clusters have become increasingly popular as powerful and cost-effective platforms for executing parallel and distributed applications. Dynamic load balancing techniques have been investigated to achieve efficient utilizations of resources on clusters. Many load balancing polices achieve high system performance by increasing the utilization of CPU or memory resources. However, these load-balancing policies suffer significant performance drop on clusters when workload comprises a large number of data-intensive applications, and when disk-or network-I/O resources exhibit imbalanced load. This is because in modern cluster systems, the performance gap between CPU and I/O subsystems is rapidly growing. Therefore, any dynamic load balancing scheme has to be \u201cI/O-aware\u201d in order to sustain high performance in this new application environment.", "num_citations": "1\n", "authors": ["505"]}
{"title": "Scheduling for improved write performance in a cost-effective, fault-tolerant parallel virtual file system\n", "abstract": " Without any additional hardware, CEFT-PVFS utilizes the existing disks on each cluster node to provide RAID-10 style parallel I/O service. In CEFT-PVFS, all servers are also computational nodes and can be heavily loaded by different applications running on the cluster, thus potentially degrading the I/O performance. To minimize the degradation, I/O requests can be scheduled on a less loaded server in each mirroring pair. To help define the meaning of \u201cload\u201d in face of multiple resources such as CPU, memory, disk and network, this paper examines the impacts of these resources by measuring aggregate I/O throughput of the simplest CEFT-PVFS configurations, under specific and isolated workload stresses. Based on the heuristic rules found from the experimental results, a scheduling algorithm for dynamic load balancing is developed. In a CEFF-PVFS with 16 data servers, we evaluate this algorithm under different workloads. The results show that the proposed scheduling algorithm significantly improves the overall performance.", "num_citations": "1\n", "authors": ["505"]}
{"title": "Oil-gas exploration prospect at depth of Paleozoic group in Baohai Bay Basin\n", "abstract": " After the source rocks had deposited in Paleozoic area, the Bohai Bay Basin had undergone several complicated tectonic change, and the source rocks experienced such actions as inhomogenous uplift, deformation, burial, and magma effect resulting in a discontinuity and in stages for the generation and evolution of hydrocarbon. Aiming at this problem, the burial and heating history of source rocks in the basin was researched. The result showed that the heating temperature increased from Caledonian to Himalayan epoch in a 'pulse' way, resulting in an increase of maturation of organic matter, causing several times of hydrocarbon generation. The hydrocarbon generation and evolution occurred mainly in the Indo-China epoch, Yenshanian epoch, and the late Himalayan epoch, with the late Himalayan epoch being the most significant. Hence there is a good prospect for oil-gas exploration at depth in Bohai Bay Basin. 6 refs., 4 figs., 2 tabs.", "num_citations": "1\n", "authors": ["505"]}
{"title": "Performance Evaluation of Parallel I/O in Cluster Environments\n", "abstract": " Clusters have been increasingly widely used for scientific and commercial applications. In a cluster environment, scientific application distributed their data across multiple computation nodes. In order to improve the performance of the clusters, many issues in parallel I/O have to be judiciously investigated. These issues include: parallel file systems, access patterns, low-level I/O interface, scientific data libraries, and data management. In this paper, we address the bottleneck and performance factors of parallel I/O in a cluster environment. Our experiment shows that network is one of the potential bottlenecks in cluster-based parallel I/O. Furthermore, the performance of the distributed RAID5, which is built on the network block device (NBD) installed on the clusters in our department, is evaluated and compared with single disk I/O. The experiment results confirm that, in most situations, the performance of distributed RAID is noticeably better than that of single disk system. Lastly, the experiment results indicate that file size and block size have significant impact on the performance of both single disk system and distributed RAID on clusters.", "num_citations": "1\n", "authors": ["505"]}
{"title": "FORMAL SPECIFICATION OF DATA FLOW DIAGRAMS [J]\n", "abstract": " he attributed diagraph is presented to specify the structure and properties of data flow diagrams (DFD), and a binary relation called the edge (flow) composition relation is proposed as the base on which the notion of balance between a DFD and its child DFD is formally defined. By using the above-mentioned approach, this paper provides a formal specification of DFD which is stronger than those found in the literature. Moreover, this approach applies to different sorts of DFD, including DeMarco DFD, DFD for real-time systems and so on.", "num_citations": "1\n", "authors": ["505"]}