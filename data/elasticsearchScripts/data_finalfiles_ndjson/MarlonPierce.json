{"title": "Apache airavata: a framework for distributed applications and computational workflows\n", "abstract": " In this paper, we introduce Apache Airavata, a software framework to compose, manage, execute, and monitor distributed applications and workflows on computational resources ranging from local resources to computational grids and clouds. Airavata builds on general concepts of service-oriented computing, distributed messaging, and workflow composition and orchestration. This paper discusses the architecture of Airavata and its modules, and illustrates how the software can be used as individual components or as an integrated solution to build science gateways or general-purpose distributed application and workflow management systems.", "num_citations": "155\n", "authors": ["898"]}
{"title": "Integrating AJAX approach into GIS visualization web services\n", "abstract": " As the Web platform continues to mature, we see an increasing number of amazing technologies that take Geographic Information Systems (GIS) visualization applications to new levels of power and usability. By integrating new powerful technologies into GIS systems, we get higher performance results with additional functionalities. The most recent development capturing the attention of the browser based application developers is AJAX (Asynchronous JavaScript and XML). In this paper we present a generic and performance efficient framework for integrating AJAX models into the browser based GIS Visualization Web Services systems.", "num_citations": "108\n", "authors": ["898"]}
{"title": "The Open Grid Computing Environments collaboration: portlets and services for science gateways\n", "abstract": " We review the efforts of the Open Grid Computing Environments collaboration. By adopting a general three\u2010tiered architecture based on common standards for portlets and Grid Web services, we can deliver numerous capabilities to science gateways from our diverse constituent efforts. In this paper, we discuss our support for standards\u2010based Grid portlets using the Velocity development environment. Our Grid portlets are based on abstraction layers provided by the Java CoG kit, which hide the differences of different Grid toolkits. Sophisticated services are decoupled from the portal container using Web service strategies. We describe advance information, semantic data, collaboration, and science application services developed by our consortium. Copyright \u00a9 2006 John Wiley & Sons, Ltd.", "num_citations": "106\n", "authors": ["898"]}
{"title": "Science gateways today and tomorrow: positive perspectives of nearly 5000 members of the research community\n", "abstract": " Science gateways are digital interfaces to advanced technologies that support science/engineering research/education. Frequently implemented as Web and mobile applications, they provide access to community resources such as software, data, collaboration tools, instrumentation, and high\u2010performance computing. We anticipate opportunities for growth within a fragmented community. Through a large\u2010scale survey, we measured the extent and characteristics of the gateway community (reliance on gateways and nature of existing resources) to understand useful services and support for builders and users. We administered an online survey to nearly 29,000 principal investigators, senior administrators, and people with gateway affiliations. Nearly 5000 respondents represented diverse expertise and geography. The majority of researchers/educators indicated that specialized online resources were important to\u00a0\u2026", "num_citations": "88\n", "authors": ["898"]}
{"title": "Interoperable Web services for computational portals\n", "abstract": " Computational web portals are designed to simplify access to diverse sets of high performance computing resources, typically through an interface to computational Grid tools. An important shortcoming of these portals is their lack of interoperable and reusable services. This paper presents an overview of research efforts undertaken by our group to build interoperating portal services around a Web Services model. We present a comprehensive view of an interoperable portal architecture, beginning with core portal services that can be used to build Application Web Services, which in turn may be aggregated and managed through portlet containers.", "num_citations": "82\n", "authors": ["898"]}
{"title": "Apache Airavata: design and directions of a science gateway framework\n", "abstract": " This paper provides an overview of the Apache Airavata software system for science gateways. Gateways use Airavata to manage application and workflow executions on a range of backend resources (grids, computing clouds, and local clusters). Airavata's design goal is to provide component abstractions for major tasks required to provide gateway application management. Components are not directly accessed but are instead exposed through a client Application Programming Interface. This design allows gateway developers to take full advantage of Airavata's capabilities, and Airavata developers (including those interested in middleware research) to modify Airavata's implementations and behavior. This is particularly important as Airavata evolves to become a scalable, elastic \"platform as a service\" for science gateways. We illustrate the capabilities of Airavata through the discussion of usage vignettes. As an\u00a0\u2026", "num_citations": "71\n", "authors": ["898"]}
{"title": "Building grid portal applications from a web service component architecture\n", "abstract": " This work describes an approach to building Grid applications based on the premise that users who wish to access and run these applications prefer to do so without becoming experts on Grid technology. We describe an application architecture based on wrapping user applications and application workflows as Web services and Web service resources. These services are visible to the users and to resource providers through a family of Grid portal components that can be used to configure, launch, and monitor complex applications in the scientific language of the end user. The applications in this model are instantiated by an application factory service. The layered design of the architecture makes it possible for an expert to configure an application factory service with a custom user interface client that may be dynamically loaded into the portal.", "num_citations": "68\n", "authors": ["898"]}
{"title": "A web based conversational case-based recommender system for ontology aided metadata discovery\n", "abstract": " Locating resources of interest in a large resource-intensive environment is a challenging problem. In this paper we present research on addressing this problem through the development of a recommender system to aid in metadata discovery. Our recommender approach uses conversational case-based reasoning (CCBR), with semantic Web markup languages providing a standard form for case representation. We present our initial efforts in designing and developing ontologies for an Earthquake Simulation Grid, to use these to guide case retrieval, discuss how these are exploited in a prototype application, and identify future steps for this approach.", "num_citations": "68\n", "authors": ["898"]}
{"title": "Path-integral Monte Carlo simulation of the second layer of 4 He adsorbed on graphite\n", "abstract": " We have developed a path-integral Monte Carlo method for simulating helium films and apply it to the second layer of helium adsorbed on graphite. We use helium-helium and helium-graphite interactions that are found from potentials which realistically describe the interatomic interactions. The Monte Carlo sampling is over both particle positions and permutations of particle labels. From the particle configurations and static structure factor calculations, we find that this layer possesses, in order of increasing density, a superfluid liquid phase, a 7\u00d7 7 commensurate solid phase that is registered with respect to the first layer, and an incommensurate solid phase. By applying the Maxwell construction to the dependence of the low-temperature total energy on the coverage, we are able to identify coexistence regions between the phases. From these, we deduce an effectively zero-temperature phase diagram. Our phase\u00a0\u2026", "num_citations": "60\n", "authors": ["898"]}
{"title": "Grid portal architectures for scientific applications\n", "abstract": " Computational scientists often develop large models and codes intended to be used by larger user communities or for repetitive tasks such as parametric studies. Lowering the barrier of entry for access to these codes is often a technical and sociological challenge. Portals help bridge the gap because they are well known interfaces enabling access to a large variety of resources, services, applications, and tools for private, public, and commercial entities, while hiding the complexities of the underlying software systems to the user. This paper presents an overview of the current state-of-the-art in grid portals, based on a component approach that utilizes portlet frameworks and the most recent Grid standards, the Web Services Resource Framework and a summary of current DOE portal efforts.", "num_citations": "58\n", "authors": ["898"]}
{"title": "Web service infrastructure for chemoinformatics\n", "abstract": " The vast increase of pertinent information available to drug discovery scientists means that there is a strong demand for tools and techniques for organizing and intelligently mining this information for manageable human consumption. At Indiana University, we have developed an infrastructure of chemoinformatics Web services that simplifies the access to this information and the computational techniques that can be applied to it. In this paper, we describe this infrastructure, give some examples of its use, and then discuss our plans to use it as a platform for chemoinformatics application development in the future.", "num_citations": "53\n", "authors": ["898"]}
{"title": "Fault tolerant high performance information services for dynamic collections of grid and web services\n", "abstract": " E-Science Semantic Grids can often be thought of as a dynamic collection of semantic subgrids where each subgrid is a collection of a modest number of services that are assembled for specific tasks. We define a Gaggle as a modest number of managed and actively interacting Grid/Web Services, where services are put together for particular functionality. The information management requirements in Gaggles include both the management of large amounts of relatively static services and associated semantic information as well as the management of multiple dynamic regions (sessions or subgrids) where the semantic information is changing frequently. We design a hybrid, fault tolerant, and high performance Information Service supporting both the scalability of large amounts of relatively slowly varying data and a high performance rapidly updated Information Service for dynamic regions. We use the two Web\u00a0\u2026", "num_citations": "51\n", "authors": ["898"]}
{"title": "Phase Diagram of Second Layer of H 4 e Adsorbed on Graphite\n", "abstract": " Using realistic helium-helium and helium-graphite interactions and the path integral Monte Carlo method, we are able to identify gas, superfluid liquid, commensurate-solid, and incommensurate-solid phases, and the coexistence regions between them, for the second layer of 4 He on graphite. The phase boundaries and the specific heat are in good agreement with experiment. The appearance and disappearance of superfluidity with increasing coverage can be explained by the growth of coexistence phases, as was observed by torsional oscillator experiments.", "num_citations": "51\n", "authors": ["898"]}
{"title": "A framework for secure end-to-end delivery of messages in publish/subscribe systems\n", "abstract": " In this paper, we present a framework for the secure end-to-end delivery of messages in distributed messaging infrastructures based on the publish/subscribe paradigm. The framework enables authorized publishing and consumption of messages. Brokers, which constitute individual nodes within the messaging infrastructure, also ensure that the dissemination of content is enabled only for authorized entities. The framework includes strategies to cope with attack scenarios such as denial of service attacks and replay attacks. Finally, we include experimental results from our implementation", "num_citations": "50\n", "authors": ["898"]}
{"title": "eSports: collaborative and synchronous video annotation system in grid computing environment\n", "abstract": " We designed eSports - a collaborative and synchronous video annotation platform, which is to be used in Internet scale cross-platform grid computing environment to facilitate computer supported cooperative work (CSCW) in education settings such as distance sport coaching, distance classroom etc. Different from traditional multimedia annotation systems, eSports provides the capabilities to collaboratively and synchronously play and archive real time live video, to take snapshots, to annotate video snapshots using whiteboard and to play back the video annotations synchronized with original video streams. eSports is designed based on the grid based collaboration paradigm $the shared event model using NaradaBrokering, which is a publish/subscribe based distributed message passing and event notification system. In addition to elaborate the design and implementation of eSports, we analyze the potential use\u00a0\u2026", "num_citations": "50\n", "authors": ["898"]}
{"title": "Building and applying geographical information system Grids\n", "abstract": " We discuss the development and application of Web\u2010service\u2010based geographical information system (GIS) Grids. Following the WS\u2010I+ approach of building Grids on Web service standards, we have developed data Grid components for archival and real\u2010time data, map generating services that can be used to build user interfaces, information services for storing both stateless and stateful metadata, and service orchestration and management tools. Our goal is to support dynamically assembled Grid service collections that combine both GIS services with more traditional Grid capabilities such as file transfer and remote code execution. We are applying these tools to problems in earthquake modeling and forecasting, but we are attempting to build general purpose tools by using and extending appropriate standards. Copyright \u00a9 2008 John Wiley & Sons, Ltd.", "num_citations": "49\n", "authors": ["898"]}
{"title": "Monolayer Solid H 4 e Clusters on Graphite\n", "abstract": " In order to resolve the controversy about the low-density region of the phase diagram of the 4 He monolayer on graphite, we have undertaken a path integral Monte Carlo study of the system. We provide direct evidence that the low-density monolayer possesses solid clusters and a low-density vapor as opposed to the most recent proposal that the system is in a superfluid phase. We further establish that the rounded heat-capacity peaks observed at low densities are caused by the melting of such solid clusters and are not associated with the suggested superfluid transition.", "num_citations": "48\n", "authors": ["898"]}
{"title": "Community science exemplars in SEAGrid Science Gateway: Apache Airavata based implementation of advanced infrastructure\n", "abstract": " We describe the science discovered by some of the community of researchers using the SEAGrid Science gateway. Specific science projects to be discussed include calcium carbonate and bicarbonate hydrochemistry, mechanistic studies of redox proteins and diffraction modeling of metal and metal-oxide structures and interfaces. The modeling studies involve a variety of ab initio and molecular dynamics computational techniques and coupled execution of a workflows using specific set of applications enabled in the SEAGrid Science Gateway. The integration of applications and resources that enable workflows that couple empirical, semi-empirical, ab initio DFT, and Moller-Plesset perturbative models and combine computational and visualization modules through a single point of access is now possible through the SEAGrid gateway. Integration with the Apache Airavata infrastructure to gain a sustainable and\u00a0\u2026", "num_citations": "43\n", "authors": ["898"]}
{"title": "The gateway computational web portal\n", "abstract": " In this paper we describe the basic services and architecture of Gateway, a commodity\u2010based Web portal that provides secure remote access to unclassified Department of Defense computational resources.  The portal consists of a dynamically generated, browser\u2010based user interface supplemented by client applications and a distributed middle tier, WebFlow. WebFlow provides a coarse\u2010grained approach to accessing both stand\u2010alone and Grid\u2010enabled back\u2010end computing resources. We describe in detail the implementation of basic portal features such as job submission, file transfer, and job monitoring and discuss how the portal addresses security requirements of the deployment centers. Finally, we outline future plans, including integration of Gateway with Department of Defense testbed Grids. Copyright \u00a9 2002 John Wiley & Sons, Ltd.", "num_citations": "43\n", "authors": ["898"]}
{"title": "Role of substrate corrugation in helium monolayer solidification\n", "abstract": " We investigate the first layer of helium adsorbed on graphite with path-integral Monte Carlo, examining the role of substrate corrugations on the phase diagram. When no corrugations are present, the equilibrium state of the system is a liquid phase, with solidification occurring only under compression but before layer promotion. We determine the solid-liquid coexistence region and compare our results to recent Green\u2019s-function Monte Carlo calculations on the same system. When substrate corrugations are included, we find that the equilibrium phase is the 3\u00d7 3 commensurate solid phase that is well known from experiment. The melting behavior, heat capacity, and single-particle binding energy are determined and compared to experiment. We further find that for densities below the commensurate coverage, the low-temperature phase of the system consists of solid clusters in coexistence with coalesced vacancies\u00a0\u2026", "num_citations": "42\n", "authors": ["898"]}
{"title": "iSERVO: Implementing the International Solid Earth Research Virtual Observatory by integrating computational grid and geographical information web services\n", "abstract": " We describe the goals and initial implementation of the International Solid Earth Virtual Observatory (iSERVO). This system is built using a Web Services approach to Grid computing infrastructure and is accessed via a component-based Web portal user interface. We describe our implementations of services used by this system, including Geographical Information System (GIS)-based data grid services for accessing remote data repositories and job management services for controlling multiple execution steps. iSERVO is an example of a larger trend to build globally scalable scientific computing infrastructures using the Service Oriented Architecture approach. Adoption of this approach raises a number of research challenges in millisecond-latency message systems suitable for internet-enabled scientific applications. We review our research in these areas.", "num_citations": "41\n", "authors": ["898"]}
{"title": "Building the polargrid portal using web 2.0 and opensocial\n", "abstract": " Science requires collaboration. In this paper, we investigate the feasibility of coupling current social networking techniques to science gateways to provide a scientific collaboration model. We are particularly interested in the integration of local and third party services, since we believe the latter provide more long-term sustainability than gateway-provided service instances alone. Our prototype use case for this study is the PolarGrid portal, in which we combine typical science portal functionality with widely used collaboration tools. Our goal is to determine the feasibility of rapidly developing a collaborative science gateway that incorporates third-party collaborative services with more typical science gateway capabilities. We specifically investigate Google Gadget, OpenSocial, and related standards.", "num_citations": "40\n", "authors": ["898"]}
{"title": "XML metadata services\n", "abstract": " As service\u2010oriented architecture principles have gained importance, an emerging need has appeared for methodologies to locate desired services that provide access to their capability descriptions. These services must typically be assembled into short\u2010term service collections that, together with code execution services, are combined into a meta\u2010application to perform a particular task. To address the metadata requirements of these problems, we introduce a hybrid Information Service to manage both stateless and stateful (transient) metadata. We leverage the two widely used Web Service standards: Universal Description, Discovery and Integration (UDDI) and Web Services Context (WS\u2010Context), in our design. We describe our approach and experiences when designing \u2018semantics\u2019. We report the results from a prototype of the system that is applied to a mobile environment for optimizing Web Service\u00a0\u2026", "num_citations": "40\n", "authors": ["898"]}
{"title": "Grid services for earthquake science\n", "abstract": " We describe an information system architecture for the ACES (Asia\u2013Pacific Cooperation for Earthquake Simulation) community. It addresses several key features of the field\u2014simulations at multiple scales that need to be coupled together; real\u2010time and archival observational data, which needs to be analyzed for patterns and linked to the simulations; a variety of important algorithms including partial differential equation solvers, particle dynamics, signal processing and data analysis; a natural three\u2010dimensional space (plus time) setting for both visualization and observations; the linkage of field to real\u2010time events both as an aid to crisis management and to scientific discovery. We also address the need to support education and research for a field whose computational sophistication is rapidly increasing and spans a broad range. The information system assumes that all significant data is defined by an XML layer\u00a0\u2026", "num_citations": "40\n", "authors": ["898"]}
{"title": "Developing GIS visualization web services for geophysical applications\n", "abstract": " The Open Geospatial Consortium (OGC) defines a number of standards (both for data models and for online services) that have been widely adopted in the Geographical Information System (GIS) community. In this paper we will describe our group's efforts to implement GIS services according to OGC standard specifications in accordance with the Web Services approach. This paper focuses on the Web Map Service (WMS), which we are coupling to problems in computational geophysics. Through the use of Web Services, we are able to integrate GIS services with other families of services, including information, data management, and remote application execution and management. We also describe WMS client building efforts that are suitable for integration with computational Web portals.To be able to interact with non-Web Service versions of WMS, we have built bridging service for our extended WMS. Since Web Service oriented WMS has a different request/response paradigm from non-Web Service versions, we have extended cascading WMS by adding request handler functionality. This kind of WMS behaves like both a cascading WMS and a proxy to handle different types of requests to overcome interoperability problems between different WMS systems.", "num_citations": "39\n", "authors": ["898"]}
{"title": "Twitter bootstrap and AngularJS: Frontend frameworks to expedite science gateway development\n", "abstract": " Science gateways provide user-centric views to cyberinfrastructure resources, simplifying usage and enabling a richer user experience. To enable the goals of a science gateway and the communities of scientists it supports, gateway developers need to be able to spend more time on designing and developing the user experience and less time on wrestling with the underlying technology (such as HTML5, CSS, and JavaScript). In this poster, we describe our experiences using Twitter Bootstrap and AngularJS frameworks to address this balance between design and implementation, empowering developers to create better styled and easily maintainable websites.", "num_citations": "38\n", "authors": ["898"]}
{"title": "SERVOGrid complexity computational environments (CCE) integrated performance analysis\n", "abstract": " In this paper we describe the architecture and initial performance analysis results of the SERVOGrid complexity computational environments (CCE). The CCE architecture is based on a lightly coupled, service oriented architecture approach that is suitable for distributed applications that are tolerant of Internet latencies. CCE focuses on integrating diverse Web and grid services for coupling scientific applications to geographical information systems. The services and coupling/orchestrating infrastructure are mapped to problems in geophysical data mining, pattern informatics, and multiscale geophysical simulation.", "num_citations": "38\n", "authors": ["898"]}
{"title": "High\u2010performance hybrid information service architecture\n", "abstract": " We introduce a distributed high\u2010performance Information Service Architecture, which forms a metadata replica hosting system to manage both highly dynamic small\u2010scale metadata and relatively large static metadata associated with Grid/Web Services. We present an empirical evaluation of the proposed architecture and investigate its practical usefulness. The results demonstrate that the proposed system achieves high performance and fault tolerance with negligible processing overheads. The results also indicate that efficient decentralized hybrid Information Service Architectures can be built by utilizing publish\u2010subscribe\u2010based messaging schemes. Copyright \u00a9 2010 John Wiley & Sons, Ltd.", "num_citations": "36\n", "authors": ["898"]}
{"title": "BioDrugScreen: a computational drug design resource for ranking molecules docked to the human proteome\n", "abstract": " BioDrugScreen is a resource for ranking molecules docked against a large number of targets in the human proteome. Nearly 1600 molecules from the freely available NCI diversity set were docked onto 1926 cavities identified on 1589 human targets resulting in >3 million receptor\u2013ligand complexes requiring >200 000 cpu-hours on the TeraGrid. The targets in BioDrugScreen originated from Human Cancer Protein Interaction Network, which we have updated, as well as the Human Druggable Proteome, which we have created for the purpose of this effort. This makes the BioDrugScreen resource highly valuable in drug discovery. The receptor\u2013ligand complexes within the database can be ranked using standard and well-established scoring functions like AutoDock, DockScore, ChemScore, X-Score, GoldScore, DFIRE and PMF. In addition, we have scored the complexes with more intensive GBSA and\u00a0\u2026", "num_citations": "35\n", "authors": ["898"]}
{"title": "Advances in cheminformatics methodologies and infrastructure to support the data mining of large, heterogeneous chemical datasets\n", "abstract": " In recent years, there has been an explosion in the availability of publicly accessible chemical information, including chemical structures of small molecules, structure-derived properties and associated biological activities in a variety of assays. These data sources present us with a significant opportunity to develop and apply computational tools to extract and understand the underlying structureactivity relationships. Furthermore, by integrating chemical data sources with biological information (protein structure, gene expression and so on), we can attempt to build up a holistic view of the effects of small molecules in biological systems. Equally important is the ability for non-experts to access and utilize state of the art cheminformatics method and models. In this review we present recent developments in cheminformatics methodologies and infrastructure that provide a robust, distributed approach to mining large and\u00a0\u2026", "num_citations": "34\n", "authors": ["898"]}
{"title": "The QuakeSim project: Web services for managing geophysical data and applications\n", "abstract": " We describe our distributed systems research efforts to build the \u201ccyberinfrastructure\u201d components that constitute a geophysical Grid, or more accurately, a Grid of Grids. Service-oriented computing principles are used to build a distributed infrastructure of Web accessible components for accessing data and scientific applications. Our data services fall into two major categories: Archival, database-backed services based around Geographical Information System (GIS) standards from the Open Geospatial Consortium, and streaming services that can be used to filter and route real-time data sources such as Global Positioning System data streams. Execution support services include application execution management services and services for transferring remote files. These data and execution service families are bound together through metadata information and workflow services for service orchestration\u00a0\u2026", "num_citations": "34\n", "authors": ["898"]}
{"title": "The apache airavata application programming interface: overview and evaluation with the UltraScan science gateway\n", "abstract": " We present an overview of the Apache Airavata Application Programming Interface (API), describe the design choices and implementation details, and describe how API methods map to the UltraScan Science Gateway use case. The Airavata API is designed to standardize access to Airavata services that provide gateways with scientific application metadata and execution management. The API also represents an important milestone in the development of Science Gateway Platform as a Service (SciGaP), a hosted, multi-tenanted gateway service based on open source Airavata software. The UltraScan gateway is a production XSEDE gateway that has been using Airavata services for over three years through customized interfaces and represents a stringent test of the API design and implementation.", "num_citations": "33\n", "authors": ["898"]}
{"title": "A credential store for multi-tenant science gateways\n", "abstract": " Science Gateways bridge multiple computational grids and clouds, acting as overlay cyber infrastructure. Gateways have three logical tiers: a user interfacing tier, a resource tier and a bridging middleware tier. Different groups may operate these tiers. This introduces three security challenges. First, the gateway middleware must manage multiple types of credentials associated with different resource providers. Second, the separation of the user interface and middleware layers means that security credentials must be securely delegated from the user interface to the middleware. Third, the same middleware may serve multiple gateways, so the middleware must correctly isolate user credentials associated with different gateways. We examine each of these three scenarios, concentrating on the requirements and implementation of the middleware layer. We propose and investigate the use of a Credential Store to solve\u00a0\u2026", "num_citations": "33\n", "authors": ["898"]}
{"title": "UAVSAR observations of triggered slip on the Imperial, Superstition Hills, and East Elmore Ranch Faults associated with the 2010 M 7.2 El Mayor\u2010Cucapah earthquake\n", "abstract": " The 4 April 2010 M 7.2 El Mayor\u2010Cucapah earthquake that occurred in Baja California, Mexico and terminated near the U.S. Mexican border caused slip on the Imperial, Superstition Hills, and East Elmore Ranch Faults. The pattern of slip was observed using radar interferometry from NASA's Uninhabited Aerial Vehicle Synthetic Aperture Radar (UAVSAR) instrument collected on 20\u201321 October 2009 and 12\u201313 April 2010. Right\u2010lateral slip of 36\u2009\u00b1\u20099 and 14\u2009\u00b1\u20092 mm occurred on the Imperial and Superstition Hills Faults, respectively. Left\u2010lateral slip of 9\u2009\u00b1\u20092 mm occurred on the East Elmore Ranch Fault. The widths of the zones of displacement increase northward suggesting successively more buried fault motion to the north. The observations show a decreasing pattern of slip northward on a series of faults in the Salton Trough stepping between the El Mayor\u2010Cucapah rupture and San Andreas Fault. Most of\u00a0\u2026", "num_citations": "33\n", "authors": ["898"]}
{"title": "Open grid computing environments: advanced gateway support activities\n", "abstract": " We describe three case studies for providing advanced support for TeraGrid Science Gateways as part of our participation in the Advanced User Support (AUS) team. These case studies include providing workflow support, robust job management, and mass job submission to existing gateways targeting computational chemistry, biophysics, and bioinformatics, respectively. Selected tools from the Open Grid Computing Environments and other projects were used, demonstrating the need for flexibility when integrating tools from multiple software providers into specific gateways' software stacks.", "num_citations": "33\n", "authors": ["898"]}
{"title": "Cyberinfrastructure and Web 2.0.\n", "abstract": " We review the emergence of a diverse collection of modern Internetscale programming approaches, collectively known as Web 2.0, and compare these to the goals of cyberinfrastructure and e-Science. e-Science has had success following the Enterprise development model, which emphasizes sophisticated XML formats, WSDL and SOAP-based Web Services, complex server-side programming tools and models, and qualities of service such as security, reliability, and addressing. Unfortunately, these approaches have limits on deployment and sustainability, as the standards and implementations are difficult to adopt and require developers and support staff with a high degree of specialized expertise. In contrast, Web 2.0 applications have demonstrated that simple approaches such as (mostly) stateless HTTP-based services operating on URLs, simple XML network message formats, and easy to use, high level network programming interfaces can be combined to make very powerful applications. Moreover, these network applications have the very important advantage of enabling \u201cdo it yourself\u201d Web application development, which favors general programming knowledge over expertise in specific tools. We may conservatively forecast that the Web 2.0 approach will supplement existing cyberinfrastructure to enable broader outreach. Potentially, however, this approach may transform e-Science endeavors, enabling domain scientists to participate more directly as codevelopers of cyberinfrastructure rather than serving merely as customers.", "num_citations": "33\n", "authors": ["898"]}
{"title": "Message-based cellular peer-to-peer grids: foundations for secure federation and autonomic services\n", "abstract": " We examine the creation of peer-to-peer Grids in which autonomous Grid components (Gridlets) may be federated into dynamic Grid collections. We examine two important aspects of these systems: federated security and autonomic considerations. As we discuss, both may be implemented using a messaging system as a substrate. Messaging systems provide the means of bridging Gridlet realms, organizing access control areas, and providing autonomic building blocks like discovery, reliability, resilience, and robustness of the peer-to-peer Grid.", "num_citations": "33\n", "authors": ["898"]}
{"title": "VLab: collaborative Grid services and portals to support computational material science\n", "abstract": " We present the initial architecture and implementation of VLab, a Grid and Web\u2010Service\u2010based system for enabling distributed and collaborative computational chemistry and material science applications for the study of planetary materials. The requirements of VLab include job preparation and submission, job monitoring, data storage and analysis, and distributed collaboration. These components are divided into client entry (input file creation, visualization of data, task requests) and back\u2010end services (storage, analysis, computation). Clients and services communicate through NaradaBrokering, a publish/subscribe Grid middleware system that identifies specific hardware information with topics rather than IP addresses. We describe three aspects of VLab in this paper: (1) managing user interfaces and input data with JavaBeans and Java Server Faces; (2) integrating Java Server Faces with the Java CoG Kit; and\u00a0\u2026", "num_citations": "31\n", "authors": ["898"]}
{"title": "OGC compatible geographical information systems web services\n", "abstract": " The Open Geospatial Consortium (OGC) defines a number of standards, both for data models and for online services, that has been widely adopted in the Geographical Information System (GIS) community. This has lead to a number of software development efforts, online data archives, and application communities. We survey these in the first part of this report. We furthermore find that the OGC standards are very compatible with Web Services standards, although they are not technically implemented this way. We therefore, in the second part of this report, describe our group's efforts to reimplement OGC standard services as web services. We focus particularly on the Web Map Service.We also have built bridging services that allow our Web Service compatible WMS to interact with non-Web Service versions of WMS. Cascading WMS is the key point in our proposed solution for the interoperability problems in the GIS WMS services. Since Web Service oriented WMS has different request response paradigm from non-Web Service versions, we have extended cascading WMS by adding request handler functionality. This kind of WMS behaves like both a cascading WMS and a proxy to handle different types of requests to overcome interoperability problems between different WMS systems.", "num_citations": "31\n", "authors": ["898"]}
{"title": "Using service-based GIS to support earthquake research and disaster response\n", "abstract": " Service-based geographic information system (GIS) technologies can enable an open-architecture cyberinfrastructure to provide standards-compliant data products and computing services for both earthquake research and disaster planning and response. Here, a service-based GIS framework is evaluated using examples from two earthquake science projects: QuakeSim and E-Decider.", "num_citations": "30\n", "authors": ["898"]}
{"title": "Algorithms and the Grid\n", "abstract": " We review the impact of Grid Computing and Web Services on scientific computing, stressing the importance of the \u201cdata-deluge\u201d that is driven by deployment of new instruments, sensors and satellites. This implies the need to integrate the naturally distributed data sources with large simulation engines offering parallel low latency communication and so to integrate parallel and Grid computing paradigms. We start with an overview of these and the evolving service architectures. We illustrate the identified areas of interest for Algorithms and the Grid with the specific example of SERVOGrid that supports earthquake science research. We comment on the appropriate messaging infrastructure for Grids and data assimilation and contrast it with MPI.", "num_citations": "30\n", "authors": ["898"]}
{"title": "Biovlab-microarray: Microarray data analysis in virtual environment\n", "abstract": " Microarray technology is a high-throughput experimental technique that can measure expression levels of hundreds of thousands of genes simultaneously. To interpret massive data from gene-expression microarray experiments, biologists encounter computational and analytical challenges. This is especially challenging for small research labs that lack local computing and bioinformatics expertise. Here, we introduce a virtual analysis system for microarray gene expression data in computing clouds with flexible and configurable GUI workflow engine so that biologists are able to analyze the data in many angles without worrying about computational and bioinformatics issues.", "num_citations": "30\n", "authors": ["898"]}
{"title": "Implementing a caching and tiling map server: a web 2.0 case study\n", "abstract": " We describe our efforts to build a caching and tiling map server that greatly improves the performance and interactivity of traditional geographic map servers. We have used this system to integrate and effectively federate 15 Indiana county map servers with Google map images and state-wide ortho-photography data. Our approach is an example of the so-called Web 2.0 style of development, in which we integrate external, third party services into a higher level service. This approach also allows for lightweight client development using relatively simple JavaScript programming libraries. We demonstrate this by building a Google Map client interface to our tile server. Finally, we discuss our initial efforts to make collaborative clients using a shared event model that captures and broadcasts browser events to other, listening browsers.", "num_citations": "30\n", "authors": ["898"]}
{"title": "Real time streaming data grid applications\n", "abstract": " We review several aspects of building real-time streaming data Grid applications. Building on general purpose messaging system software (NaradaBrokering) and generalized collaboration services (GlobalMMCS), we are developing a diverse set of interoperable capabilities. These include dynamic information systems for managing short-lived collaborative service collections (\u201cgaggles\u201d), stream filters to support the integration of Geographical Information Systems services with data analysis applications, streaming video to support collaborative geospatial maps with time-dependent data, and video stream playback and annotation services to enable scientific collaboration.", "num_citations": "30\n", "authors": ["898"]}
{"title": "Grids for the GiG and real time simulations\n", "abstract": " We study the current architecture of the grid and Web services and that of the global information grid (GiG) with the Network Centric Operations and Warfare (NCOW) from the Department of Defense. We compare the GiG core enterprise services with those being developed for Grids (the open grid services architecture) and Web Services (so called WS-* specifications), identifying both similarities and differences. We discuss both modeling and simulation with HLA (high level architecture) and broad defense NCOW applications. We illustrate this analysis with an open geospatial community (OGC) compatible set of geographical information system grid services. We illustrate the use of grids to efficiently support realtime simulation by an application of grids to audio-video conferencing.", "num_citations": "30\n", "authors": ["898"]}
{"title": "Grids challenged by a Web 2.0 and multicore sandwich\n", "abstract": " We discuss the application of Web 2.0 to support scientific research (e\u2010Science) and related \u2018e\u2010more or less anything\u2019 applications. Web 2.0 offers interesting technical approaches (protocols, message formats, and programming tools) to build core e\u2010infrastructure (cyberinfrastructure) as well as many interesting services (Facebook, YouTube, Amazon S3/EC2, and Google maps) that can add value to e\u2010infrastructure projects. We discuss why some of the original Grid goals of linking the world's computer systems may not be so relevant today and that interoperability is needed at the data and not always at the infrastructure level. Web 2.0 may also support Parallel Programming 2.0\u2014a better parallel computing software environment motivated by the need to run commodity applications on multicore chips. A \u2018Grid on the chip\u2019 will be a common use of future chips with tens or hundreds of cores. Copyright \u00a9 2008 John\u00a0\u2026", "num_citations": "29\n", "authors": ["898"]}
{"title": "Swarm: Scheduling large-scale jobs over the loosely-coupled hpc clusters\n", "abstract": " Compute-intensive scientific applications are heavily reliant on the available quantity of computing resources. The Grid paradigm provides a large scale computing environment for scientific users. However, conventional Grid job submission tools do not provide a high-level job scheduling environment for these users across multiple institutions. For extremely large number of jobs, a more scalable job scheduling framework that can leverage highly distributed clusters and supercomputers is required. In this paper, we propose a high-level job scheduling Web service framework, Swarm. Swarm is developed for scientific applications that must submit massive number of high-throughput jobs or workflows to highly distributed computing clusters. The Swarm service itself is designed to be extensible, lightweight, and easily installable on a desktop or small server. As a Web service, derivative services based on Swarm can\u00a0\u2026", "num_citations": "29\n", "authors": ["898"]}
{"title": "Quakesim and the solid earth research virtual observatory\n", "abstract": " We are developing simulation and analysis tools in order to develop a solid Earth Science framework for understanding and studying active tectonic and earthquake processes. The goal of QuakeSim and its extension, the Solid Earth Research Virtual Observatory (SERVO), is to study the physics of earthquakes using state-of-the-art modeling, data manipulation, and pattern recognition technologies. We are developing clearly defined accessible data formats and code protocols as inputs to simulations, which are adapted to high-performance computers. The solid Earth system is extremely complex and nonlinear, resulting in computationally intensive problems with millions of unknowns. With these tools it will be possible to construct the more complex models and simulations necessary to develop hazard assessment systems critical for reducing future losses from major earthquakes. We are using Web (Grid\u00a0\u2026", "num_citations": "29\n", "authors": ["898"]}
{"title": "Information services for dynamically assembled semantic grids\n", "abstract": " Many large semantic systems can be described as semantic grids of semantic grids with large amounts of relatively static services and associated semantic information combined with multiple dynamic regions (sessions or subgrids) where the semantic information is changing rapidly. We design a hybrid Information Service supporting both the scalability of large amounts of relatively slowly varying data and a high performance rapidly updated information service for dynamic regions. We use the two Web service standards UDDI and WS-Context in our system.", "num_citations": "29\n", "authors": ["898"]}
{"title": "Building messaging substrates for web and grid applications\n", "abstract": " Grid application frameworks have increasingly aligned themselves with the developments in Web services. Web services are currently the most popular infrastructure based on service-oriented architecture (SOA) paradigm. There are three core areas within the SOA framework: (i) a set of capabilities that are remotely accessible, (ii) communications using messages and (iii) metadata pertaining to the aforementioned capabilities. In this paper, we focus on issues related to the messaging substrate hosting these services; we base these discussions on the NaradaBrokering system. We outline strategies to leverage capabilities available within the substrate without the need to make any changes to the service implementations themselves. We also identify the set of services needed to build Grids of Grids. Finally, we discuss another technology, HPSearch, which facilitates the administration of the substrate and the\u00a0\u2026", "num_citations": "29\n", "authors": ["898"]}
{"title": "Science gateways: the long road to the birth of an institute\n", "abstract": " Nowadays, research in various disciplines is enhanced via computational methods, cutting-edge technologies and diverse resources including computational infrastructures and instruments. Such infrastructures are often complex and researchers need means to conduct their research in an efficient way without getting distracted with information technology nuances. Science gateways address such demands and offer user interfaces tailored to a specific community. Creators of science gateways face a breadth of topics and manifold challenges, which necessitate close collaboration with the domain specialists but also calling in experts for diverse aspects of a science gateway such as project management, licensing, team composition, sustainability, HPC, visualization, and usability specialists. The Science Gateway Community Institute tackles the challenges around science gateways to support domain specialists and developers via connecting them to diverse experts, offering consultancy as well as providing a software collaborative, which contains ready-to-use science gateway frameworks and science gateway components.", "num_citations": "28\n", "authors": ["898"]}
{"title": "An overview of the XSEDE extended collaborative support program\n", "abstract": " The Extreme Science and Engineering Discovery Environment (XSEDE) is a flagship cyberinfrastructure project funded by the US National Science Foundation (NSF). XSEDE\u2019s Extended Collaborative Support Services (ECSS) program is a significant component of the XSEDE effort, dedicated to extended engagements with our user community which transform their research. We describe the organization, operation and some highlights of the program in this submission.", "num_citations": "28\n", "authors": ["898"]}
{"title": "Cyberaide javascript: A javascript commodity grid kit\n", "abstract": " In this paper, we describe a service oriented architecture and Grid abstraction framework that allows us to access Grids through JavaScript. Obviously, such a framework integrates well with other Web 2.0 technologies. The framework consists of two parts. A client Application Programming Interface (API) to access the Grid via JavaScript and a mediator service and API through which the Grid access is channeled. The framework uses commodity Web service standards and provides extended functionality such as asynchronous task management, file transfer, and workflow management based on our previous work. The availability of our framework simplifies not only the development of new services, but also the development of advanced client side Grid applications that can be accessed through Web browsers. We demonstrate this ability by providing an example that integrates a variety of useful services to be\u00a0\u2026", "num_citations": "28\n", "authors": ["898"]}
{"title": "Managing dynamic metadata as context\n", "abstract": " As the amount of metadata describing services and their access frequencies increased in P2P/Grid Computing Environments, there is an emerging need for Information Services to make such metadata available. The metadata describing services might include frequently changing information, so it presents a dynamic behavior. We use context as metadata to capture such frequently changing dynamic information. Here, context information can be used not only for discovering services, but also by services after they have been discovered. In this paper, we are interested in providing and managing context information parts of which is likely to be changed very frequently. We describe our initial efforts in building Fault Tolerant and High Performance Information Systems (FTHPIS) to make both dynamic and static context information available.", "num_citations": "28\n", "authors": ["898"]}
{"title": "Community organizations: changing the culture in which research software is developed and sustained\n", "abstract": " Software is the key crosscutting technology that enables advances in mathematics, computer science, and domain-specific science and engineering to achieve robust simulations and analysis for science, engineering, and other research fields. However, software itself has not traditionally received focused attention from research communities; rather, software has evolved organically and inconsistently, with its development largely as by-products of other initiatives. Moreover, challenges in scientific software are expanding due to disruptive changes in computer hardware, increasing scale and complexity of data, and demands for more complex simulations involving multiphysics, multiscale modeling and outer-loop analysis. In recent years, community members have established a range of grass-roots organizations and projects to address these growing technical and social challenges in software productivity, quality\u00a0\u2026", "num_citations": "27\n", "authors": ["898"]}
{"title": "Using Web 2.0 for scientific applications and scientific communities\n", "abstract": " Web 2.0 approaches are revolutionizing the Internet, blurring lines between developers and users and enabling collaboration and social networks that scale into the millions of users. As discussed in our previous work, the core technologies of Web 2.0 effectively define a comprehensive distributed computing environment that parallels many of the more complicated service\u2010oriented systems such as Web service and Grid service architectures. In this paper we build upon this previous work to discuss the applications of Web 2.0 approaches to four different scenarios: client\u2010side JavaScript libraries for building and composing Grid services; integrating server\u2010side portlets with \u2018rich client\u2019 AJAX tools and Web services for analyzing Global Positioning System data; building and analyzing folksonomies of scientific user communities through social bookmarking; and applying microformats and GeoRSS to problems in\u00a0\u2026", "num_citations": "27\n", "authors": ["898"]}
{"title": "Information services for grid/web service oriented architecture (soa) based geospatial applications\n", "abstract": " Geographical Information Systems (GIS) presents data-intensive environment for acquiring, processing and sharing geo-data among interested parties. In order to serve geographical information to users in such environment, Service Oriented Architecture", "num_citations": "27\n", "authors": ["898"]}
{"title": "Interoperability and semantics for heterogeneous earthquake science data\n", "abstract": " We propose to define, design, develop, deploy, and test a data semantics based system to provide interoperability for heterogeneous data in the earthquake science domain. We focus on the database management aspects of the work, including modeling the meaning of the data, providing for web service based access to heterogeneous data sources to scientists to be used in simulations and model development, data mining, etc.", "num_citations": "26\n", "authors": ["898"]}
{"title": "Integrating apache airavata with docker, marathon, and mesos\n", "abstract": " Science Gateways provide scientists with tools for creating, executing, and monitoring scientific experiments on multiple resource infrastructures. Apache Airavata abstracts interactions between gateways and distributed computing infrastructures like Extreme Science and Engineering Discovery Environment, international grids, and campus clusters. Airavata consists of several component services such as the API server, Orchestrator, Workflow Interpreter, Credential Store, and Application Factory. In addition, Airavata uses third party software, including RabbbitMQ for messaging, MySQL for production database management, and Apache Zookeeper for internal communications. In this paper, we discuss our initial experiences with leveraging open source technologies to manage Airavata and its dependent components to deploy, detect, and restart failed components in an auto\u2010scaling platform. Such capabilities will\u00a0\u2026", "num_citations": "25\n", "authors": ["898"]}
{"title": "GridFTP and parallel TCP support in naradabrokering\n", "abstract": " Many of the key features of file transfer mechanisms like reliable file transferring and parallel transferring are developed as part of the service. It makes very hard to re\u2013use the same code for the different systems. We are trying to overcome this disadvantage by decoupling useful features of file transfer mechanisms from the implementation of the service and protocol, and instead placed into the messaging substrate. We may thus treat file transfer operations as a specific usage case for a more general messaging environment. This will allow us to provide file transfer quality of service to other file transfer tools that does not have same features.", "num_citations": "25\n", "authors": ["898"]}
{"title": "Potential for a large earthquake near Los Angeles inferred from the 2014 La Habra earthquake\n", "abstract": " Tectonic motion across the Los Angeles region is distributed across an intricate network of strike\u2010slip and thrust faults that will be released in destructive earthquakes similar to or larger than the 1933\u2009M6.4 Long Beach and 1994\u2009M6.7 Northridge events. Here we show that Los Angeles regional thrust, strike\u2010slip, and oblique faults are connected and move concurrently with measurable surface deformation, even in moderate magnitude earthquakes, as part of a fault system that accommodates north\u2010south shortening and westerly tectonic escape of northern Los Angeles. The 28 March 2014 M5.1 La Habra earthquake occurred on a northeast striking, northwest dipping left\u2010lateral oblique thrust fault northeast of Los Angeles. We present crustal deformation observation spanning the earthquake showing that concurrent deformation occurred on several structures in the shallow crust. The seismic moment of the\u00a0\u2026", "num_citations": "24\n", "authors": ["898"]}
{"title": "Apache airavata as a laboratory: architecture and case study for component-based gateway middleware\n", "abstract": " Science gateways are more than user interfaces to computational grids and clouds. Gateways are middleware in their own right, providing flexible, lightweight federations of heterogenous collections of computing resources (such as campus clusters, supercomputers, computational clouds), all of which remain challenges for many alternative middleware approaches. Gateways also are notable for providing science application-centric interfaces to computing resources rather than resource-centric views. An important challenge for science gateway research is to generalize specific science gateway strategies, defining a reference architecture that emcompasses major gateway capabilities while enabling implementation flexibility. Such a reference architecture should also enable\" platform as a service\" approaches that provide hosted versions of common gateway capabilities. In this paper, we summarize the Apache\u00a0\u2026", "num_citations": "24\n", "authors": ["898"]}
{"title": "Web 2.0 for Grids and e-Science\n", "abstract": " Web 2.0-style services and capabilities collectively define a comprehensive\\break distributed computing environment that may be considered an alternative or supplement to existing Grid computing approaches for e-Science. Web 2.0 is briefly summarized as building upon network-enabled, stateless services with simple message formats and message exchange patterns to build rich client interfaces, mash-ups (custom, composite, Web applications), and online communities. In this chapter, we review several of our activities in these areas: service architectures for chemical informatics; Web 2.0 approaches for managing real-time data from online experiments; management and federation of digital entities and their metadata obtained from multiple services; and the use of tagging and social bookmarking to foster scientific networking at minority serving institutions. We conclude with a discussion of further research\u00a0\u2026", "num_citations": "24\n", "authors": ["898"]}
{"title": "Supporting cloud computing with the virtual block store system\n", "abstract": " The fast development of cloud computing systems stimulates the needs for a standalone block storage system to provide persistent block storage services to virtual machines maintained by clouds. This paper presents the Virtual Block Store (VBS) System, a standalone block storage system built on the basis of LVM, iSCSI, and Xen hypervisor, which can provide basic block storage services such as volume creation and attachment. The concept and functional interface of VBS are based on Amazon Elastic Block Store (EBS) service; moreover, VBS works independently with an existing LVM volume server and Xen nodes, and thus can be easily extended to support other types of volume servers and virtual machine managers, or integrated with various cloud computing systems. Preliminary I/O benchmark results are presented and analyzed, indicating that a VBS volume can provide throughput that is similar to an ATA\u00a0\u2026", "num_citations": "23\n", "authors": ["898"]}
{"title": "Enabling large scale scientific computations for expressed sequence tag sequencing over grid and cloud computing clusters\n", "abstract": " Compute-intensive biological applications are heavily reliant on the availability of computing resources. Grid based HPC clusters and emerging Cloud computing clusters provide a large scale computing environment for scientific users. However, large scale biological application often involves various types of computational tasks which can benefit from different types of computing clusters. Therefore, a high level job scheduling environment which integrates the Grid style HPC clusters and the Cloud computing clusters and manages jobs accordingly based on the characteristics of the jobs is required. In this paper, we propose a Web service framework for high-level job scheduling\u2013Swarm. Swarm is developed for scientific applications that must submit massive number of high-throughput jobs or workflows to highly distributed computing clusters. Swarm allows the users to submit jobs to both Grid HPC and Cloud computing clusters. The Swarm service itself is designed to be extensible, lightweight, and easily installable on a desktop or a small server. As a Web service, derivative services based on Swarm can be straightforwardly integrated with Web portals and science gateways. This paper provides the motivation for this research, the architecture of the Swarm framework, and a performance evaluation of the system prototype.", "num_citations": "23\n", "authors": ["898"]}
{"title": "Virtual laboratory for planetary materials: System service architecture overview\n", "abstract": " This paper brings an overall view of the service-oriented architecture (SOA) used in VLab, a system aimed to handle concurrent calculations of geo-materials participating in extensive workflows. We recap the algorithms of physical importance that underly the system requirements. The system architecture then emerges naturally. A usage view diagram is shown and thoroughly discussed. We also show how analysis tools are integrated in the SOA.", "num_citations": "23\n", "authors": ["898"]}
{"title": "Supporting science gateways using apache airavata and scigap services\n", "abstract": " The Science Gateways Platform as a service (SciGaP. org) project provides a rapid development and stable hosting platform for a wide range of science gateways that focus on software as a service. Based on the open source Apache Airavata project, SciGaP services include user management, workflow execution management, computational experiment archiving and access, and sharing services that allow users to share results and other digital artifacts. SciGaP services are multi-tenanted, with clients accessing services through a well-defined, programming language-independent API. SciGaP services can be integrated into web, mobile, and desktop clients. To simplify development for new clients, SciGaP includes the PGA, a generic PHP-based gateway client for SciGaP services that also acts as a reference implementation of the API. Several example gateways using these services are summarized.", "num_citations": "22\n", "authors": ["898"]}
{"title": "Indiana university pervasive technology institute\n", "abstract": " Six research centers are formally affiliated with PTI, as follows:\u2022 UITS Research Technologies (RT) Division. The Research Technologies Division develops, delivers, and supports cyberinfrastructure for IU and for scholars, educators, clinicians, engineers, and artists throughout the United States. UITS Research Technologies (RT) is affiliated with PTI and OVPIT, and is a division of UITS.\u2022 Center for Applied Cybersecurity Research (CACR)(Von Welch, Director). CACR leads the creation of IT security policy, security tools, and secure applications in critical areas of cyberinfrastructure, including health. CACR is affliated with PTI, the IU Maurer School of Law, and OVPIT.\u2022 Data to Insight Center (D2I)(Beth Plale, Director). D2I focuses on the life cycle of digital data while furthering tools for discovering and gaining insight from the vast quantities of data now produced in digital form. D2I is affiliated with the IU School of Informatics, Computing & Engineering; OVPIT and UITS; and works closely with the IU Libraries.\u2022 Digital Science Center (DSC)(Geoffrey C. Fox, Director) DSC advances cloud computing and network science, with a focus on developing human-centered interfaces to cyberinfrastructure. DSC is a research center of the IU School of Informatics, Computing, and Engineering and is affiliated with PTI.", "num_citations": "22\n", "authors": ["898"]}
{"title": "Automatic task re-organization in MapReduce\n", "abstract": " MapReduce is increasingly considered as a useful parallel programming model for large-scale data processing. It exploits parallelism among execution of primitive map and reduce operations. Hadoop is an open source implementation of MapReduce that has been used in both academic research and industry production. However, its implementation strategy that one map task processes one data block limits the degree of concurrency and degrades performance because of inability to fully utilize available resources. In addition, its assumption that task execution time in each phase does not vary much does not always hold, which makes speculative execution useless. In this paper, we present mechanisms to dynamically split and consolidate tasks to cope with load balancing and break through the concurrency limit resulting from fixed task granularity. For single-job systems, two algorithms are proposed for\u00a0\u2026", "num_citations": "22\n", "authors": ["898"]}
{"title": "Implementing a Prototype of the Security Framework for Distributed Brokering Systems.\n", "abstract": " Security is an important element of any system design. Entities supported by a system need to securely interact with each other. The problem gets even more complex in the context of a distributed system, where the underling infrastructure of messaging nodes, which we call \u201cbrokers,\u201d needs to carry these interactions securely. Furthermore, it is entirely possible that some brokers communicate with each other over communication channels that do not encrypt network traffic. Thus, even if two entities are connected to brokers, and they have secure communications channels with their brokers, when their communications traverse over insecure channels, the security of their interactions is compromised.In [1] we presented a security framework that is appropriate for distributed brokering systems. The framework provided for secure communications over insecure links, and ensured that only authorized entities are allowed to view entity interactions. In this paper, we present our prototype implementation of this framework. The paper presents implementation details of key components within the system. We have also performed a series of experiments that would affect the design of components within the system, as well as the encryption strategies chosen by entities within the system.", "num_citations": "22\n", "authors": ["898"]}
{"title": "VLAB: Web services, portlets, and workflows for enabling cyber-infrastructure in computational mineral physics\n", "abstract": " Virtual organizations are rapidly changing the way scientific communities perform research. Web-based portals, environments designed for collaboration and sharing data, have now become the nexus of distributed high performance computing. Within this paper, we address the infrastructure of the Virtual Laboratory for Earth and Planetary Materials (VLab), an organization dedicated to using quantum calculations to solve problems in mineral physics. VLab provides a front-end portal, accessible from a browser, for scientists to submit large-scale simulations and interactively analyze their results. The cyber-infrastructure of VLab concentrates on scientific workflows, portal development, responsive user-interfaces and automatic generation of web services, all necessary to ensure a maximum degree of flexibility and ease of use for both the expert scientist and the layperson.", "num_citations": "21\n", "authors": ["898"]}
{"title": "Management of real\u2010time streaming data Grid services\n", "abstract": " We discuss our message\u2010based approach to managing real\u2010time data streams and building higher level services to produce and consume them. Our messaging system acts as a substrate that can be used to provide qualities of service to various streaming applications ranging from audio\u2013video collaboration systems to sensor Grids. The messaging substrates are composed of distributed, hierarchically arranged message broker networks. Services such as filters are deployed along the edges of the network. We discuss the role of management systems for both broker networks and filter services: broker network topologies must be created and maintained, and distributed filters must be arranged in appropriate sequences. These managed broker networks may be applied to a wide range of problems. We discuss applications to audio\u2013video collaboration in some detail and also describe applications to streaming\u00a0\u2026", "num_citations": "20\n", "authors": ["898"]}
{"title": "The science gateways community institute at two years\n", "abstract": " The Science Gateways Community Institute was one of the first two software institutes funded by the National Science Foundation's Office of Advanced Cyberinfrastructure in August, 2016. The structure of and services offered by the institute were developed as a result of seven years of planning grants that funded focus groups, a 5000-person survey and the development of a strategic plan. Now two years in, we provide an overview of the institute's service offerings and their usage, reflect on the experiences of some early clients, review our approaches to metrics and evaluation, and describe some lessons learned. We also describe the lightweight, adaptive management approach employed by the institute.", "num_citations": "19\n", "authors": ["898"]}
{"title": "Scientific data management in the cloud: A survey of technologies, approaches and challenges\n", "abstract": " Experimental sciences create vast amounts of data. In astronomy, data produced by the Pan-STARRS project (Pan-STARRS project, 2010; Jedicke, Magnier, Kaiser, & Chambers, 2006) is expected to result in more than a petabyte of images every year. In high-energy physics, the Large Hadron Collider will generate 50\u2013100 petabytes of data each year, with about 20\u00a0PB of that data being stored and processed on a worldwide federation of national grids linking 100,000 CPUs (Large Hadron Collider project, 2010; Massimo Lammana, 2004).             Cloud computing is immensely appealing to the scientific community, who increasingly see it as being part of the solution to cope with burgeoning data volumes. Cloud computing enables economies-of-scale in facility design and hardware construction. Groups of users are allowed to host, process, and analyze large volumes of data from various sources. There are\u00a0\u2026", "num_citations": "19\n", "authors": ["898"]}
{"title": "Implementing geographical information system grid services to support computational geophysics in a service-oriented environment\n", "abstract": " Observatory (SERVO)\u2019s Complexity Computational Environment. We base our design on a globally scalable distributed \u201ccyber-infrastructure,\u201d or Grid, built around a Web Services-based approach consistent with the extended Web Service Interoperability (WS-I+) model. In order to investigate problems in earthquake modeling and forecasting, we need to programmatically couple numerical simulation codes and data assimilation and mining tools to online observational data sets, including GPS stations, fault data, and seismic activity catalogs.", "num_citations": "19\n", "authors": ["898"]}
{"title": "Designing ontologies and distributed resource discovery services for an earthquake simulation grid\n", "abstract": " Locating resources is a fundamental problem within large scale distributed environments. An effective way of solving this problem is providing and managing metadata about resources. In this paper, we describe an initial ontology design and the architecture of a distributed information system that we are implementing. We introduce an efficient notification based caching mechanism to make metadata available in open hypermedia peer-to-peer systems.", "num_citations": "19\n", "authors": ["898"]}
{"title": "A security framework for distributed brokering systems\n", "abstract": " Loosely coupled, globally scalable distributed systems, including both peer-to-peer systems and computational grids, rely on the transmission of messages and events that may transverse many point-topoint connections and may need to reach several destinations. The identity of entities, the authorization to send or receive certain messages, and the privacy and integrity of those messages must all be established. In this paper we present a system design that addresses the security requirements for messaging systems that employ the generalized topic-based publish/subscribe paradigm. In particular, we address initial authentication and maintenance of identity, scalable topic security, and message-level security that protects messages over multiple hops with varying underlying transport security. We also review several potential forms of attacks on the system and the steps we take to thwart such attacks.", "num_citations": "19\n", "authors": ["898"]}
{"title": "Quantum films adsorbed on graphite: Third and fourth helium layers\n", "abstract": " Using a path-integral Monte Carlo method for simulating superfluid quantum films, we investigate helium layers adsorbed on a substrate consisting of graphite plus two solid helium layers. The solid helium layers are modeled first as inert, with paths frozen at equilibrated positions, and then as active, with second-layer atoms included in the Monte Carlo updating. In both cases, we observe the formation of as many as three well defined additional layers above the first two and determine the layer promotion density by calculating the density profile and through a calculation of the chemical potential. For liquid layers adsorbed onto the inert solids, we find self-bound liquid phases in both the third and fourth layers and determine the equilibrium density. In the third layer at coverages below equilibrium, we find liquid droplets and a metastable uniform liquid phase and determine the spinodal point that separates these\u00a0\u2026", "num_citations": "18\n", "authors": ["898"]}
{"title": "Collective collaborative tagging system\n", "abstract": " Currently in the Internet many collaborative tagging sites exist, but there is the need for a service to integrate the data from the multiple sites to form a large and unified set of collaborative data from which users can have more accurate and richer information than from a single site. In our paper, we have proposed a collective collaborative tagging (CCT) service architecture in which both service providers and individual users can merge folksonomy data (in the form of keyword tags) stored in different sources to build a larger, unified repository. We have also examined a range of algorithms that can be applied to different problems in folksonomy analysis and information discovery. These algorithms address several common problems for online systems: searching, getting recommendations, finding communities of similar users, and finding interesting new information by trends. Our contributions are to (a) systematically\u00a0\u2026", "num_citations": "17\n", "authors": ["898"]}
{"title": "Building problem solving environments with application web service toolkits\n", "abstract": " Application portals, or Problem Solving Environments (PSEs), provide user environments that simplify access and integrate various distributed computational services for scientists working on particular classes of problems. Specific application portals are typically built on common sets of core services, so reusability of these services is a key problem in PSE development. In this paper we address the reusability problem by presenting a set of core services built using the Web services model and application metadata services that can be used to build science application front ends out of these core services.", "num_citations": "17\n", "authors": ["898"]}
{"title": "The GenApp framework integrated with Airavata for managed compute resource submissions\n", "abstract": " A new framework (GenApp) for rapid generation of scientific applications running on a variety of systems including science gateways has recently been developed. This framework currently builds a GUI and/or web\u2010based user interface for a variety of target environments on a collection of executable modules. The method for execution of modules has limited framework restrictions: primarily the requirement of wrapping the application to accept input and output formatted in JavaScript Object Notation (JSON). Initial implementation supports direct execution on a user's workstation, a web server, or a compute resource accessible from the web server. After a successful initial workshop utilizing the framework to create a web\u2010based user interface wrapping a scientific software suite, it was discovered that long\u2010running jobs would sometimes fail, because of the loss of a Transmission Control Protocol (TCP) connection\u00a0\u2026", "num_citations": "16\n", "authors": ["898"]}
{"title": "A scripting based architecture for management of streams and services in real-time grid applications\n", "abstract": " Recent specifications such as WS-management and WS-distributed management have stressed the importance of management of resources and services and propose methods towards querying Web services to gather the meta-data associated with these services. Management often entails system setup, querying system metadata, manipulation of system parameters at runtime and taking actions based on the system parameters to tune system performance. Real-time applications require rapid deployment of application components and demand results in real time. In this paper we present the HPSearch system which enables dynamic management of the system including both streams and Web services, and rapid deployment of applications via a scripting interface. We illustrate the functioning of the system by modeling a data streaming application and rapidly deploying the system and application components.", "num_citations": "16\n", "authors": ["898"]}
{"title": "Interacting data services for distributed earthquake modeling\n", "abstract": " We present XML schemas and our design for related data services for describing faults and surface displacements, which we use within earthquake modeling codes. These data services are implemented using a Web services approach and are incorporated in a portal architecture with other, general purpose services for application and file management. We make use of many Web services standards, including WSDL and SOAP, with specific implementations in Java. We illustrate how these data models and services may be used to build distributed, interacting applications through data flow.", "num_citations": "16\n", "authors": ["898"]}
{"title": "Incorporating an XML Matching Engine in Distributed Brokering Systems.\n", "abstract": " As systems such as peer-to-peer, Web Services, and Grid systems proliferate the Internet there have also been a significant increase in the number of devices that are networked to the Internet. The XML markup language has been used increasingly for data interchange between applications and entities. More recently XML based standards have been proposed by the W3C to support the Web Services concept where XML has been used to describe services, and carry invocations to these services. The XML matching problem for distributed brokering systems is an important one to deal with issues that arise as the system scale and complexity of interactions between entities increases. In this paper, we present our approach to the XML matching problem in distributed brokering systems. We base our investigations in the context of the NaradaBrokering system.", "num_citations": "16\n", "authors": ["898"]}
{"title": "Ground deformation data from GEER investigations of Ridgecrest earthquake sequence\n", "abstract": " Following the Ridgecrest earthquake sequence, consisting of an \u00a06.4 foreshock and \u00a07.1 mainshock along with many other events, the Geotechnical Extreme Events Reconnaissance association deployed a team to gather perishable data. The team focused their efforts on documenting ground deformations including surface fault rupture south of the Naval Air Weapons Station China Lake, and liquefaction features in Trona and Argus. The team published a report within two weeks of the \u00a07.1 mainshock. This article presents data products gathered by the team, which are now published and publicly accessible. The data products presented herein include ground\u2010based observations using Global Positioning System trackers, digital cameras, and hand\u2010measuring devices, as well as unmanned aerial vehicle\u2010based imaging products using Structure from Motion to create point clouds and digital surface\u00a0\u2026", "num_citations": "15\n", "authors": ["898"]}
{"title": "Social networking for scientists using tagging and shared bookmarks: a Web 2.0 application\n", "abstract": " Web-based social networks, online personal profiles, keyword tagging, and online bookmarking are staples of Web 2.0-style applications. In this paper we report our investigation and implementation of these capabilities as a means for creating communities of like-minded faculty and researchers, particularly at minority serving institutions. Our motivating problem is to provide outreach tools that broaden the participation of these groups in funded research activities, particularly in cyberinfrastructure and e-science. In this paper, we discuss the system design, implementation, social network seeding, and portal capabilities. Underlying our system, and folksonomy systems generally, is a graph- based data model that links external URLs, system users, and descriptive tags. We conclude with a survey of the applicability of clustering and other data mining techniques to these folksonomy graphs.", "num_citations": "15\n", "authors": ["898"]}
{"title": "Architecture, performance, and scalability of a real-time global positioning system data grid\n", "abstract": " We describe the architecture of our real time SensorGrid system, which supports the real-time message routing and processing of Global Positioning System data. The current system processes 1\u00a0Hz position data from 85 stations in Southern and Central California. Our system is built on a computer network-enabled, topic-based publish/subscribe system and is extensible to other data sources. In order to determine the performance and the upper limits of scalability, we have conducted and present here a set of systematic test evaluations of our implementation. Through these tests, we are able to show that performance does not degrade over time, that the system will handle up to 1000 simultaneous data providers or data consumers with a single message broker, and that multiple message brokers can be linked to provide scalability beyond 1000 providers or consumers.", "num_citations": "15\n", "authors": ["898"]}
{"title": "High performance data streaming in service architecture\n", "abstract": " Applications dealing with large data sets obtained via simulation or actual real-time sensor networks are increasing in abundance. The data obtained from real-time sources may contain certain discrepancies which arise from the dynamic nature of the source. Furthermore, certain computations may not require all the data and hence this data must be filtered before it can be processed. By installing adaptive filters that can be controlled in real-time, we can filter out only the relevant parts of the data thereby improving the overall computation speed. In this paper we present an architecture that links these distributed filters to achieve high throughput dataflow for real-time streaming and high-performance applications.", "num_citations": "15\n", "authors": ["898"]}
{"title": "A Batch Script Generator Web Service for Computational Portals.\n", "abstract": " Web services have begun to receive a great amount of attention as the appropriate backbone for business-to-business interactions. Web services essentially do not present new concepts for distributed computing but rather implement important simplifying, standards-compliant ways for entities to find and invoke the appropriate remote service. These have important implications to the field of computational, or science, portals. We examine the basic web services architecture from the perspective of these portals.", "num_citations": "15\n", "authors": ["898"]}
{"title": "Gathering requirements for advancing simulations in HPC infrastructures via science gateways\n", "abstract": " Compute-intensive simulations are often based on complex scientific theories and necessitate high-performance computing (HPC) infrastructures to deliver results in reasonable time. While domain researchers are experts in their field and apply sophisticated theoretical models in computational simulations, they are not necessarily also HPC experts or IT specialists in general. Thus, they appreciate easy-to-use solutions tailored to their research, which hide the complex underlying computing and data infrastructures. Science gateways form such end-to-end solutions and their development for compute-intensive simulations necessitates expertise to connect HPC research infrastructures including grid and cloud infrastructures to support with the efficient access to such resources. HPC experts and IT specialists fulfilling this task may have only rudimentary knowledge about the research domain of a simulation. Thus, it\u00a0\u2026", "num_citations": "14\n", "authors": ["898"]}
{"title": "Management of Real-Time Streaming Data Grid Services\n", "abstract": " We discuss the architectural and management support for real time data stream applications, both in terms of lower level messaging and higher level service, filter and session structures. In our approach, messaging systems act as a Grid substrate that can provide qualities of service to various streaming applications ranging from audio-video collaboration to sensor grids. The messaging substrate is composed of distributed, hierarchically arranged message brokers that form networks. We discuss approaches to managing systems for both broker networks and application filters: broker network topologies must be created and maintained, and distributed filters must be arranged in appropriate sequences. These managed broker networks may be applied to a wide range of problems. We discuss applications to audio/video collaboration in some detail and also describe applications to streaming Global\u00a0\u2026", "num_citations": "14\n", "authors": ["898"]}
{"title": "The gateway computational web portal: Developing web services for high performance computing\n", "abstract": " We describe the Gateway computational web portal, which follows a traditional three-tiered approach to portal design. Gateway provides a simplified, ubiquitously available user interface to high performance computing and related resources. This approach, while successful for straightforward applications, has limitations that make it difficult to support loosely federated, interoperable web portal systems. We examine the emerging standards in the so-called web services approach to business-to-business electronic commerce for possible solutions to these shortcomings and outline topics of research in the emerging area of computational grid web services.", "num_citations": "14\n", "authors": ["898"]}
{"title": "Who cares about science gateways? a large-scale survey of community use and needs\n", "abstract": " With the rise of science gateway use in recent years, we anticipate there are additional opportunities for growth, but the field is currently fragmented. We describe our efforts to measure the extent and characteristics of the gateway community through a large-scale survey. Our goal was to understand what type of support services might be provided to the gateway community.", "num_citations": "13\n", "authors": ["898"]}
{"title": "Building a distributed block storage system for cloud infrastructure\n", "abstract": " The development of cloud infrastructures has stimulated interest in virtualized block storage systems, exemplified by Amazon Elastic Block Store (EBS), Eucalyptus\u00e2\u20ac\u2122 EBS implementation, and the Virtual Block Store (VBS) system. Compared with other solutions, VBS is designed for flexibility, and can be extended to support various Virtual Machine Managers and Cloud platforms. However, due to its single-volume-server architecture, VBS has the problem of single point of failure and low scalability. This paper presents our latest improvements to VBS for solving these problems, including a new distributed architecture based on the Lustre file system, new workflows, better reliability and scalability, and read-only volume sharing. We call this improved implementation VBS-Lustre. Preliminary tests show that VBS-Lustre can provide both better throughput and higher scalability in multiple attachment scenarios than\u00a0\u2026", "num_citations": "13\n", "authors": ["898"]}
{"title": "Web 2.0 for e-science environments\n", "abstract": " We examine the potential impact of Web 2.0 approaches to e-science and Grid computing. We provide an analysis of Web service and Grid computing core concepts, which we then map to corresponding concepts in Web 2.0 systems. As we show, Web 2.0, taken collectively, must be viewed as a comprehensive distributed computing approach. We then examine social bookmarking and tagging as an exemplary Web 2.0 service. Tagged bookmarks can be used to build up keyword-based profiles that can be used in collaborator matchmaking services. To be professionally useful to researchers and faculty, these tools need to provide interfaces to scholarly articles for bookmarking. This introduces another level of Web 2.0 service, the semantic research grid, which we overview. We conclude with a discussion of the need for building hybrid Web Service/Web 2.0 systems.", "num_citations": "13\n", "authors": ["898"]}
{"title": "Grids for real time data applications\n", "abstract": " We describe our work in building support for streaming data services for Geographical Information System Grid services. We examine how streaming approaches may be used to increase data service performance for transporting XML messages. Similarly, streaming versions of traditional static map services may be combined with general audio/video session management capabilities to build collaborative, annotatable shared maps. Distributed services linked through messaging substrates require information and broker management capabilities, and we describe our research here. Finally, we discuss efficient XML representation techniques that can be used to increase performance of Web Services and support Web enabled devices.", "num_citations": "13\n", "authors": ["898"]}
{"title": "Implementing GIS Grid Services for the International Solid Earth Research Virtual Observatory\n", "abstract": " We describe our continuing work on implementing Open GIS Consortium (OGC) compatible Grid Services for the International Solid Earth Research Virtual Observatory. Our initial efforts focused on collecting Earthquake and GPS data from various sources, converting them to GML and enabling query capabilities using pure Web Services approach. We have extended this work by creating Web Services implementations of OGC-Web Feature Service and OGC-Web Map Service for serving GML-formatted data. We also describe a Fault Tolerant High Performance Information System (FTHPIS) to tie these services together.", "num_citations": "13\n", "authors": ["898"]}
{"title": "Using keycloak for gateway authentication and authorization\n", "abstract": " Establishing users\u2019 identities before they access research infrastructure resources is a key feature of science gateways. With many science gateways now relying on general purpose gateway platform services, the challenges of managing identity-derived features have expanded to include authorization between science gateway tenants, middleware, and third party identity provider services. The latter include campus identity management systems. This paper examines the use of Keycloak as an implementation of an identity management system for Apache Airavata middleware, replacing our previous WSO2 Identity Server-based implementation. This effort raises larger issues that software-as-a-service communities should consider when embedding dependencies on third party software and services, including developing selection criteria and future-proofing   systems.", "num_citations": "12\n", "authors": ["898"]}
{"title": "Designing a road map for geoscience workflows\n", "abstract": " Advances in geoscience research and discovery are fundamentally tied to data and computation, but formal strategies for managing the diversity of models and data resources in the Earth sciences have not yet been resolved or fully appreciated. The U.S. National Science Foundation (NSF) EarthCube initiative (http://earthcube.ning.com), which aims to support community\u2010guided cyberinfrastructure to integrate data and information across the geosciences, recently funded four community development activities: Geoscience Workflows; Semantics and Ontologies; Data Discovery, Mining, and Integration; and Governance. The Geoscience Workflows working group, with broad participation from the geosciences, cyberinfrastructure, and other relevant communities, is formulating a workflows road map (http://sites.google.com/site/earthcubeworkflow/). The Geoscience Workflows team coordinates with each of the other\u00a0\u2026", "num_citations": "12\n", "authors": ["898"]}
{"title": "Virtual laboratory for planetary materials (VLab) an updated overview of system service architecture\n", "abstract": " In this paper we review the main features and illustrate the use of VLab, a Science Gateway that provides Cyber-infrastructure (CI) for distributed first principles computations in materials science. The VLab CI includes Web Services running in different computers, controlled from a Web Portal running predefined, distributed, and interactive workflows by multiple users. Currently, in addition to simple electronic structure calculations, it supports calculations of materials properties important for mineral physics that require substantial number of tasks, such as, thermodynamic and thermal elastic properties. VLab uses the Quantum ESPRESSO software for first principles computations. Here, we show details of the task distribution in batch system using a\" bag of tasks\" approach. We also explain VLab's approach to interactive user tools, including interactive image plots developed for thermodynamic properties, pressure\u00a0\u2026", "num_citations": "12\n", "authors": ["898"]}
{"title": "Generative topographic mapping by deterministic annealing\n", "abstract": " Generative Topographic Mapping (GTM) is an important technique for dimension reduction which has been successfully applied to many fields. However the usual Expectation-Maximization (EM) approach to GTM can easily get stuck in local minima and so we introduce a Deterministic Annealing (DA) approach to GTM which is more robust and less sensitive to initial conditions so we do not need to use many initial values to find good solutions. DA has been very successful in clustering, hidden Markov Models and Multidimensional Scaling but typically uses a fixed cooling schemes to control the temperature of the system. We propose a new cooling scheme which can adaptively adjust the choice of temperature in the middle of process to find better solutions. Our experimental measurements suggest that deterministic annealing improves the quality of GTM solutions.", "num_citations": "12\n", "authors": ["898"]}
{"title": "Analysis of streaming GPS measurements of surface displacement through a web services environment\n", "abstract": " We present a method for performing mode classification of real-time streams of GPS surface position data. Our approach has two parts: an algorithm for robust, unconstrained fitting of hidden Markov models (HMMs) to continuous-valued time series, and SensorGrid technology that manages data streams through a series of filters coupled with a publish/subscribe messaging system. The SensorGrid framework enables strong connections between data sources, the HMM time series analysis software, and users. We demonstrate our approach through a Web portal environment through which users can easily access data from the SCIGN and SOPAC GPS networks in Southern California, apply the analysis method, and view results. Ongoing real-time mode classifications of streaming GPS data are displayed in a map-based visualization interface", "num_citations": "12\n", "authors": ["898"]}
{"title": "Making scientific applications as web services\n", "abstract": " This article discusses the general architecture of science portal-service systems and illustrates with a simple example how you could build a constituent service out of a particular application. To make the presentation concrete, we develop a simple wrapper application for a code, Disloc (authored by A. Donnellan of the NASA jet Propulsion Laboratory), which is used in earthquake simulation to calculate surface displacements of observation stations for a given underground fault. Disloc's fast calculation is a particularly useful characteristic because we can provide it as an anonymous service and not have to worry about computer accounts, allocations, and scheduling.", "num_citations": "12\n", "authors": ["898"]}
{"title": "Managing authentication and authorization in distributed science gateway middleware\n", "abstract": " Establishing users\u2019 identities and determining their permissions before they access research infrastructure resources are key features of science gateways. With many science gateways now relying on general purpose gateway platform services, the challenges of managing identity-derived features have expanded to include network-based authentication and authorization scenarios that connect science gateway tenants, science gateway platform middleware, and third party identity provider services, including campus identity management systems. This paper examines both architectural and implementation considerations for integrating these services. We provide a summary case study that further shows how end-to-end authentication and authorization can be provided between gateways, campus authentication systems, science gateway middleware, and campus computing resources. We conclude with\u00a0\u2026", "num_citations": "11\n", "authors": ["898"]}
{"title": "Automated estimation and tools to extract positions, velocities, breaks, and seasonal terms from daily GNSS measurements: illuminating nonlinear salton trough deformation\n", "abstract": " This paper describes the methods used to estimate positions, velocities, breaks, and seasonal terms from daily Global Navigation Satellite System (GNSS) measurements. Break detection and outlier removal have been automated so that decades of daily measurements from thousands of stations can be processed in a few hours. New measurements are added, and parameters are updated every week. Model parameters allow separation of interseismic, annual, coseismic, and postseismic signals. Tools available through GeoGateway (http://geo-gateway.org) allow rapid visualization and analysis of these terms for results that can be subsetted in time or space. Results show highly variable and nonlinear motion for GPS stations in southern California. The variable motion is related to seasonal motions, distributed tectonic motion, earthquakes, and postseismic motions that can continue for years. In some areas\u00a0\u2026", "num_citations": "11\n", "authors": ["898"]}
{"title": "Science gateways: Sustainability via on-campus teams\n", "abstract": " The challenges for creators of specific science gateways are manifold, and the expertise needed for well-designed science gateways is very diverse. The sustainability of science gateways is crucial to serve communities effectively, efficiently and reliably. One measure to achieve greater sustainability of science gateways is establishing on-campus teams. Researchers are served more efficiently since the support by experienced developers reduces individual project investments, and a team can bring the diversity of required expertise for a well-designed science gateway. This paper goes into detail about the challenges and the benefits of on-campus groups and of sharing resources across a campus. We provide four successful cases, describe the services of the Science Gateways Community Institute (SGCI) to support the process in building such groups, and recommend strategies for using free campus resources.", "num_citations": "11\n", "authors": ["898"]}
{"title": "Apache Airavata security manager: Authentication and authorization implementations for a multi-tenant escience framework\n", "abstract": " eScience middleware frameworks integrating multiple virtual organizations must incorporate comprehensive user identity and access management solutions. In this paper we examine usage patterns for these systems and map the patterns to widely used security standards and approaches. We focus on science gateways, a class of distributed system cyberinfrastructure. Science gateways are end user environments that provide access to a wide range of academic and commercial computing and storage resources for virtual organizations. Successful gateways focus on specific scientific communities and domains, but they build on many reusable features that can be provided by general purpose hosted platform services that can support multiple tenants. Providing a security framework for identity and access management for such hosted service removes the burden for each gateway to handle its user identity\u00a0\u2026", "num_citations": "11\n", "authors": ["898"]}
{"title": "A high throughput workflow environment for cosmological simulations\n", "abstract": " The next generation of wide-area sky surveys offer the power to place extremely precise constraints on cosmological parameters and to test the source of cosmic acceleration. These observational programs will employ multiple techniques based on a variety of statistical signatures of galaxies and large-scale structure. These techniques have sources of systematic error that need to be understood at the percent-level in order to fully leverage the power of next-generation catalogs. Simulations of large-scale structure provide the means to characterize these uncertainties. We are using XSEDE resources to produce multiple synthetic sky surveys of galaxies and large-scale structure in support of science analysis for the Dark Energy Survey. In order to scale up our production to the level of fifty 10 10-particle simulations, we are working to embed production control within the Apache Airavata workflow environment. We\u00a0\u2026", "num_citations": "11\n", "authors": ["898"]}
{"title": "Distributed web security for science gateways\n", "abstract": " Science gateways broaden and simplify access to cyberinfrastructure (CI) by providing advanced interfaces to collaboration, analysis, data management, and other tools for students and researchers. As these science gateway interfaces to cyberinfrastructure grow in popularity, web portal developers adopt ad hoc approaches to the security challenges of authentication, authorization, and delegation. Science gateways integrate cyberinfrastructure resources on the researcher's behalf, ie, accessing data, compute cycles, instruments, and other valuable resources. Resource access often requires use of the researcher's security credentials, in some cases exposing the researcher's long-lived password to potential compromise at the science gateway. There is no standard approach for a researcher to control and limit a science gateway's access to his or her resources. Thus, researchers are required to accept\u00a0\u2026", "num_citations": "11\n", "authors": ["898"]}
{"title": "Cyberinfrastructure Software Sustainability and Reusability: Report from an NSF-funded workshop held 27 & 28 March 2009\n", "abstract": " The National Science Foundation's strategy for 21st century innovation depends on creation of scientific and engineering software. During March of 2009, Indiana University hosted an NSF-funded workshop to examine issues related to creating and maintaining this type of software. This report reflects the activities, discussion, and consensus of the two-day workshop and subsequent research and writing on specific points raised at the workshop.", "num_citations": "11\n", "authors": ["898"]}
{"title": "Application web services\n", "abstract": " This report gives an overview of web services, with a particular focus on how to deploy and use an application as a web service. This is a work in progress and part of the proposed Application Metadata Working Group [1] and the Grid Computing Environments Research Group [2] of the Global Grid Forum, so revisions and refinement will occur.An application here means specifically some code developed by the scientific community. Examples would be finite element codes, grid generation codes, and visualization tools. These might be written in Fortran or C, may be parallelized with MPI, and so on. From the point of view of the portal interactions, these details are unimportant in our approach. We will treat all these applications as black boxes and will describe here how to wrap these applications in XML proxies. The wrappers can then be converted into Java data classes for manipulation by services. No modification of the application source code is required. We refer to this as proxy wrapping, as distinguished from the direct service wrapping one might generate with a tool such as SWIG.", "num_citations": "11\n", "authors": ["898"]}
{"title": "E-decider: Using earth science data and modeling tools to develop decision support for earthquake disaster response\n", "abstract": " Earthquake Data Enhanced Cyber-Infrastructure for Disaster Evaluation and Response (E-DECIDER) is a NASA-funded project developing new capabilities for decision making utilizing remote sensing data and modeling software to provide decision support for earthquake disaster management and response. E-DECIDER incorporates the earthquake forecasting methodology and geophysical modeling tools developed through NASA\u2019s QuakeSim project. Remote sensing and geodetic data, in conjunction with modeling and forecasting tools allows us to provide both long-term planning information for disaster management decision makers as well as short-term information following earthquake events (i.e. identifying areas where the greatest deformation and damage has occurred and emergency services may need to be focused). This in turn is delivered through standards-compliant web services for\u00a0\u2026", "num_citations": "10\n", "authors": ["898"]}
{"title": "A Web services-based universal approach to heterogeneous fault databases\n", "abstract": " QuakeSim is a Web browser-based problem-solving environment that provides a set of links between newly available resources from NASA's Earth-observing systems, high-performance simulations, automated data mining, and more traditional tools. It's the first Web services-based, interoperable environment for creating large-scale forward models of earthquake processes. A Web services-based portal provides global access to geologic reference models of faults and fault data, simple analysis tools, new parallel forward models, and visualization support. QuakeTables, a database system for handling both real and simulated data, provides input for earthquake simulation tools using fault data. Later, it will include other types of earthquake data as well. This article describes our Web-based universal approach to heterogeneous earthquake databases using QuakeTables to demonstrate the design, development, and\u00a0\u2026", "num_citations": "10\n", "authors": ["898"]}
{"title": "Building problem-solving environments with application web service toolkits\n", "abstract": " Application portals, or Problem-Solving Environments (PSEs), provide user environments that simplify access and integrate various distributed computational services for scientists working on particular classes of problems. Specific application portals are typically built on common sets of core services, so reusability of these services is a key problem in PSE development. In this paper we address the reusability problem by presenting a set of core services built using the Web services model and application metadata services that can be used to build science application front ends out of these core services and the management of multiple versions of services.", "num_citations": "10\n", "authors": ["898"]}
{"title": "Developing a secure grid computing environment shell engine: containers and services\n", "abstract": " We describe the design and features of our Grid Computing Environments Shell system, or GCEShell. We view computing Grids as providing essentially a globally scalable distributed operating system that exposes low level programming APIs. From these system-level commands we may build a higher level library of more user-friendly shell commands, which may in turn be programmed through scripts. The GCEShell consists of a shell engine that serves as a container environment for managing GCEShell commands, which are client implementations for remote Web Service/Open Grid Service Architecture services that resemble common UNIX shell operations.", "num_citations": "10\n", "authors": ["898"]}
{"title": "Management of data streams for a real time flood simulation\n", "abstract": " We examine the challenge of coupling applications to real-time data sources in a Grid environment. Such problems are important to the emerging field of Grid-based emergency planning and crisis response, in which realtime data sources must be coupled to modeling applications to provide timely forecasting to emergency planners and responders. In this paper we present a Grid-based scripting workflow system that is capable of managing both streaming data sources and service-based applications. We apply this system to flood modeling codes coupled to simulated NEXRAD Doppler Radar data.", "num_citations": "10\n", "authors": ["898"]}
{"title": "The online knowledge center: Building a component based portal\n", "abstract": " This paper presents an overview of the Online Knowledge Center (OKC) web portal. The OKC is built around a portlet/container architecture: a central control portal is composed of several portlets that can deliver both local content and content from remote servers. The modular structure allows us to develop sophisticated portal components independently and plug them into the portal container using well defined XML interfaces. We describe problems we have discovered with this architecture and extensions and solutions that we are implementing. We also describe two advanced services that can be plugged into the overall framework: XML message-based newsgroups and hybrid structured/unstructured data searches.", "num_citations": "10\n", "authors": ["898"]}
{"title": "Cyberinfrastructure, cloud computing, science gateways, visualization, and cyberinfrastructure ease of use\n", "abstract": " Computers accelerate our ability to achieve scientific breakthroughs. As technology evolves and new research needs come to light, the role for cyberinfrastructure as \u201cknowledge\u201d infrastructure continues to expand. In essence, cyberinfrastructure can be thought of as the integration of supercomputers, data resources, visualization, and people that extends the impact and utility of information technology. This chapter discusses cyberinfrastructure, the related topics of science gateways and campus bridging, and identifies future challenges and opportunities in cyberinfrastructure.", "num_citations": "9\n", "authors": ["898"]}
{"title": "Django content management system evaluation and integration with apache airavata\n", "abstract": " Apache Airavata is an open-source software framework that enables scientific researchers to compose, manage, execute and monitor large-scale applications and workflows on distributed computing resources. Airavata is currently leveraged by many science gateways to perform computations on shared clusters. Currently, Gateway Administrators managing content on their websites will require the assistance of the Airavata Developer Team to make the slightest of change to their website. This paper will overcome this challenge by presenting the benefits of integrating a content management system. It will also briefly evaluate various options available for choosing a Content Management Platform which complies with the Airavata Architecture Standards. This feature will enable researchers with minimal web design knowledge to easily manage content across their gateway. It is also poised to drastically increase the\u00a0\u2026", "num_citations": "9\n", "authors": ["898"]}
{"title": "Authentication and authorization considerations for a multi-tenant service\n", "abstract": " Distributed cyberinfrastructure requires users (and machines) to perform some sort of authentication and authorization (together simply known as\\emph {auth}). In the early days of computing, authentication was performed with just a username and password combination, and this is still prevalent today. But during the past several years, we have seen an evolution of approaches and protocols for auth: Kerberos, SSH keys, X. 509, OpenID, API keys, OAuth, and more. Not surprisingly, there are trade-offs, both technical and social, for each approach.", "num_citations": "9\n", "authors": ["898"]}
{"title": "Authoring a science gateway cookbook\n", "abstract": " Over the last fifteen years, science gateways have proven to be fertile ground for cyberinfrastructure research, while at the same time dramatically increasing the usage and accessibility of cyberinfrastructure to scientists and educators. Gateway developers, however, still face many challenges in building and operating these complex infrastructures that address the dynamic and emerging challenges of computational infrastructure. Through the XSEDE Science Gateway Program, we propose to solicit information on the knowledge, experience, and software from widely used science gateways. We will compile the information into a \u201cScience Gateway Cookbook\u201d which will democratize the experiences in developing, operating, and sustaining science gateways. We hope this will be a good literature reference and also avoid some repetition in the development process.", "num_citations": "9\n", "authors": ["898"]}
{"title": "Dynamic resource-critical workflow scheduling in heterogeneous environments\n", "abstract": " Effective workflow scheduling is a key but challenging issue in heterogeneous environments due to the heterogeneity and dynamism. Based on the observations that not all tasks can run on all resources and acquired data transferring and queuing for a resource can be concurrent, we propose a dynamic resource-critical workflow scheduling algorithm which take into consideration the environmental heterogeneity and dynamism. We evaluate its performance by simulations and show that it outperforms another selected widely used approach.", "num_citations": "9\n", "authors": ["898"]}
{"title": "The problem solving environments of teraGrid, science gateways, and the intersection of the two\n", "abstract": " Problem solving environments (PSEs) are increasingly important for scientific discovery. Today's most challenging problems often require multi-disciplinary teams, the ability to analyze very large amounts of data, and the need to rely on infrastructure built by others rather than reinventing solutions for each science team. The TeraGrid Science Gateways program recognizes these challenges and works with science teams to harness high-end resources that significantly extend a PSE's functionality.", "num_citations": "9\n", "authors": ["898"]}
{"title": "Scalable, fault-tolerant management of grid services\n", "abstract": " The service-oriented architecture has come a long way in solving the problem of reusability of existing software resources. Grid applications today are composed of a large number of loosely coupled services. While this has opened up new avenues for building large, complex applications, it has made the management of the application components a nontrivial task. Use of services existing on different platforms, implemented in different languages and presence of variety of network constraints further complicates management. This paper investigates problems that emerge when there is a need to uniformly manage a set of distributed services. We present a scalable, fault-tolerant management framework. Our empirical evaluation shows that the architecture adds an acceptable number of additional resources for providing scalable, fault-tolerant management framework.", "num_citations": "9\n", "authors": ["898"]}
{"title": "Managing Grid messaging middleware\n", "abstract": " Management in distributed systems has gained much importance in recent years. With the increasing complexity of applications, there is a need for effective management of components of the application. As application components span different administrative domains, differing security policies restrict access to these components. The problem gets more complicated in a dynamic environment where application components and the environment is in a constant state of flux, so that failure is the norm. In this paper we explore the issues related to management in dynamic and heterogeneous environments. We propose a scalable, fault-tolerant and Web services - compliant management architecture that addresses these issues of management and also illustrate the functioning of our framework with respect to the NaradaBrokering messaging middleware", "num_citations": "9\n", "authors": ["898"]}
{"title": "Grid-based collaboration in interactive data language applications\n", "abstract": " Interactive Data Language (IDL) is an array-oriented data analysis and visualization application, which is widely used in research, commerce, and education. It is meaningful to make user IDL applications collaborative between computers over networks, using a common message broker as the underlying communication system. In order to achieve the global collaboration, we have brought together in the research a Grid-based collaboration paradigm, a shared event model, different implementing structures, methodologies and technologies. We have succeeded in our prototype codes, and we are currently working on a real life IDL application package to make it collaborative. At the same time, we are trying to find better structures and methods for the collaboration in general user IDL applications.", "num_citations": "9\n", "authors": ["898"]}
{"title": "Illuminating Earth's interior through advanced computing\n", "abstract": " Today's computational strategies for modeling Earth's interior structure and dynamics come from high-performance computing systems in the US and others such as the Japanese Earth Simulator. Modeling efforts currently underway focus on problems such as geodynamo and earthquake modeling. Space-based measurement and observational technologies are revolutionizing our understanding of the solid Earth and revealing subtle changes that occur on regional and global scales. Understanding these complex processes requires large global data sets and sophisticated computational models coupled with the necessary associated computational infrastructure. The authors discuss how the rapidly increasing availability of data and a more robust and pervasive computational infrastructure could combine to give us new opportunities to understand this complex system.", "num_citations": "9\n", "authors": ["898"]}
{"title": "Web Service Robust GridFTP.\n", "abstract": " In this paper, we discuss reliable and secure file transfer middleware called NaradaBrokering. It is our goal to show that reliability features can be decoupled from the implementation of the service and protocol, and instead placed into the messaging substrate. This will allow us to provide file transfer quality of service comparable to GridFTP in other file transfer tools (such as normal FTP, SCP, HTTP uploads, and similar mechanisms).", "num_citations": "9\n", "authors": ["898"]}
{"title": "Distributed Object\u2010Based Grid Computing Environments\n", "abstract": " This chapter contains sections titled:   Introduction   Deployment and Use of Computing Portals   Computing Portal Services   Grid Portal Architecture   Application Descriptors   Sample Service Implementations   Kerberos Security Requirements in Multitiered Architectures   Summary and Future Work   References", "num_citations": "9\n", "authors": ["898"]}
{"title": "Science gateways-leveraging modeling and simulations in HPC infrastructures via increased usability\n", "abstract": " Modeling and simulations, which necessitate HPC infrastructures, are often based on complex scientific theories and involve interdisciplinary research teams. IT specialists support with the efficient access to HPC infrastructures. They design, implement and configure the simulations and models reflecting the sophisticated theoretical models and approaches developed and applied by domain researchers. Roles in such interdisciplinary teams may overlap dependent on the knowledge and experience with computational resources and/or the research domain. Bioinformaticians, for example, are in general trained to act as IT specialists, while having also a good knowledge about biology and chemistry to support the user community competently. Domain researchers are mainly not IT specialists and the requirement to employ HPC infrastructures via command line often forms a huge hurdle for them. Thus, there is the\u00a0\u2026", "num_citations": "8\n", "authors": ["898"]}
{"title": "SQMD: Architecture for scalable, distributed database system built on virtual private servers\n", "abstract": " Many scientific fields routinely generate huge datasets. In many cases, these datasets are not static but rapidly grow in size. Handling these types of datasets, as well as allowing sophisticated queries necessitates scalable distributed database systems, in which scientists are efficiently able to search the datasets. In this paper we present the architecture, implementation and performance analysis of a scalable, distributed database system built on software based virtualization environments. The system architecture makes use of a software partitioning of the database based on data clustering, SQMD (single query multiple database) mechanism, a Web service interface, and virtualization software technologies. The system allows uniform access to concurrently distributed databases, using the SQMD mechanism based on the publish/subscribe paradigm. We highlight the scalability of our architecture by applying it to a\u00a0\u2026", "num_citations": "8\n", "authors": ["898"]}
{"title": "GTLAB: Grid Tag Libraries Supporting Workflows within Science Gateways\n", "abstract": " Portlet-based grid portals have become a crucial part of the cyberinfrastructure by providing component-based problem solving environments for scientists. Although portals aim to provide user-friendly environments with easy-to-use interfaces, the development of portals and their portlet components is time consuming. We aim to provide reusable components for rapid portlet development. Our approach grid tag libraries and beans (GTLAB), encapsulates common grid operations with reusable XML tags. GTLAB also provides a way for creating composite tasks that models the requirements of computational science portals. In previous work, we have introduced grid tags libraries for the Globus toolkit. In this study, we extend GTLAB to support widely used Condor DAGMan and Taverna workflows for the grid community. These extended tags demonstrate that large workflows can be integrated within grid portlets without\u00a0\u2026", "num_citations": "8\n", "authors": ["898"]}
{"title": "Scalable, fault-tolerant management in a service oriented architecture\n", "abstract": " The service-oriented architecture has come a long way in solving the problem of reusability of existing software resources. Grid applications today are composed of a large number of loosely coupled services. While this has opened up new avenues for building large, complex applications, it has made the management of the application components a non-trivial task. Management is further complicated when services exist on different platforms, are written in different languages, present in varying administrative domains restricted by firewalls and are susceptible to failure. This paper investigates problems that emerge when there is a need to uniformly manage a set of distributed services. We present a scalable, fault-tolerant management framework. Our empirical evaluation shows that the architecture adds an acceptable number of additional resources making the approach feasible.", "num_citations": "8\n", "authors": ["898"]}
{"title": "Providing Portlet-Based Client Access to CIMA-Enabled Crystallographic Instruments, Sensors, and Data\n", "abstract": " The Common Instrument Middleware Architecture (CIMA) project, supported by the NSF Middleware Initiative, aims at making scientific instruments and sensors remotely accessible by providing a general solution for services and user interfaces to remotely access data from instruments and to remotely monitor experiments. X-ray crystallography is one of several motivating applications for the development of CIMA. Data such as CCD frames and sensor readings may be accessed by portals through middleware services as they are being acquired or through persistent archives. CIMA software may be used to federate online instruments in multiple labs, so this project must also address problems in data management and data sharing. This paper describes a collaboration between the CIMA and the Open Grid Computing Environments (OGCE) project to enable remote users to monitor instruments and interact with\u00a0\u2026", "num_citations": "8\n", "authors": ["898"]}
{"title": "Designing Grid Tag Libraries and Grid Beans\n", "abstract": " We present a detailed description of the implementation of a library of Grid tag libraries and Grid beans for Grid Web portal development. Grid tags provide Java Server Faces (JSF) custom components for Grid services. They enable the definition of attributes to the Grid service parameters in a dynamic way embedded into JSF view pages. In addition, Grid beans provide client proxies to the Grid services. Grid tags and beans together provide a platform to develop Grid portlets easily. In addition to standard Grid job submission and remote file operation tags, we also provide management and monitoring capabilities for Grid tasks. This system can persistently store bean features and job parameters, which results in a permanent storage for archiving and reference.", "num_citations": "8\n", "authors": ["898"]}
{"title": "Automating metadata Web service deployment for problem solving environments\n", "abstract": " XML-based metadata information services are a crucial core service needed by problem solving environments built over emerging service-based, globally scaled distributed systems, as envisioned by the Open Grid Services Architecture and the Semantic Web. Developing user interfaces and service bindings for manipulating instances of particular schemas is thus extremely important and needs to be made as simple as possible. In this paper we describe procedures for automating the creation of Web service environments that can be used to simplify the creation and deployment of schema-based metadata services.", "num_citations": "8\n", "authors": ["898"]}
{"title": "Targeted high\u2010resolution structure from motion observations over the Mw 6.4 and 7.1 ruptures of the Ridgecrest earthquake sequence\n", "abstract": " We carried out six targeted structure from motion surveys using small uninhabited aerial systems over the \u00a06.4 and 7.1 ruptures of the Ridgecrest earthquake sequence in the first three months after the events. The surveys cover approximately 500 \u00d7 500\u00a0m areas just south of Highway 178 with an average ground sample distance of 1.5\u00a0cm. The first survey took place five days after the \u00a06.4 foreshock on 9 July 2019. The final survey took place on 27 September 2019. The time between surveys increased over time, with the first five surveys taking place in the first month after the earthquake. Comparison of imagery from before and after the \u00a07.1 earthquake shows variation in slip on the main rupture and a small amount of distributed slip across the scene. Cracks can be observed and mapped in the high\u2010resolution imagery, which show en echelon cracking, fault splays, and a northeast\u2010striking conjugate fault\u00a0\u2026", "num_citations": "7\n", "authors": ["898"]}
{"title": "Jetstream\u2014Early operations performance, adoption, and impacts\n", "abstract": " Jetstream is a first of its kind system for the NSF \u2014 a distributed production cloud resource. We review the purpose for creating Jetstream, discuss Jetstream's key characteristics, describe our experiences from the first year of maintaining an OpenStack\u2010based cloud environment, and share some of the early scientific impacts achieved by Jetstream users. Jetstream offers a unique capability within the XSEDE\u2010supported US national cyberinfrastructure, delivering interactive virtual machines (VMs) via the Atmosphere interface. As a multi\u2010region deployment that operates as an integrated system, Jetstream is proving effective in supporting modes and disciplines of research traditionally underrepresented on larger XSEDE\u2010supported clusters and supercomputers. Already, Jetstream has been used to perform research and education in biology, biochemistry, atmospheric science, earth science, and computer science.", "num_citations": "7\n", "authors": ["898"]}
{"title": "Fracture Advancing Step Tectonics Observed in the Yuha Desert and Ocotillo, CA, Following the 2010 Mw7.2 El Mayor\u2010Cucapah Earthquake\n", "abstract": " Uninhabited aerial vehicle synthetic aperture radar (UAVSAR) observations 2009\u20132017 of the Yuha Desert area and Global Positioning System (GPS) time series encompassing the region reveal a northward migrating pattern of deformation following the 4 April 2010 Mw7.2 El Mayor\u2010Cucapah (EMC) earthquake. The north end of the EMC rupture exhibits an asymmetric pattern of deformation that is substantial and smooth northeast of the rupture and limited but with surface fracturing slip northwest. The earthquake triggered ~1\u00a0cm of surface coseismic slip at the Yuha fault, which continued to slip postseismically. 2.5\u00a0cm of Yuha fault slip occurred by the time of the 15 June 2010 Mw5.7 Ocotillo aftershock and 5\u00a0cm of slip occurred by 2017 following a logarithmic afterslip decay 16\u2010day timescale. The Ocotillo aftershock triggered 1.4\u00a0cm of slip on a northwest trend extending to the Elsinore fault and by 7\u00a0years after the\u00a0\u2026", "num_citations": "7\n", "authors": ["898"]}
{"title": "GSoC 2015 student contributions to GenApp and Airavata\n", "abstract": " GenApp generates applications on an extensible set of target languages for scientific modules. GenApp utilizes JavaScript object notation (JSON) format for all definition files. To create an application, definition files are created for global directives, menu, and modules. Target languages have definition files detailing the steps\u2010mapping code fragments to output. Modules must be wrapped to accept and produce JSON as defined in the module's definition file.\u00a0Execution models are not defined by GenApp; they are included in target language code fragments. Previously, GenApp included target languages of HTML5/PHP, Qt3/C++, and Qt4/C++ with execution models of direct local execution, a web server, or a web server accessible resource. A Google Summer of Code (GSoC) 2014 student demonstrated Airavata\u2010managed execution in GenApp's current target languages. Subsequently, Airavata's API and GenApp\u00a0\u2026", "num_citations": "7\n", "authors": ["898"]}
{"title": "Science Gateway Operational Sustainability: Adopting a Platform-as-a Service Approach\n", "abstract": " Science Gateways provide a crucial user and sciencecentric point of entry to the complex collection of enabling digital resources commonly referred to as cyberinfrastructure (CI). Over the past fifteen years, Science Gateways have proven to be much more than just fertile ground for distributed computing research\u037e they have dramatically increased cyberinfrastructure usage and accessibility for scientists and educators around the world. Gateways enable scientists unfamiliar with high performance computing to incorporate sophisticated analysis, computational modeling, and simulation techniques into their research. It is now clear that Science Gateways are an essential catalyst for efficiently turning the investment made in cyberinfrastructure into global scientific discovery.These are measurable assertions. Over the past 43 months, the CIPRES Science Gateway has made it possible for more than 7,000 biologists to run phylogenetic analyses on XSEDE computing resources, enabling more than 600 peerreviewed publications. In 2012, the UltraScan Science Gateway supported the data analysis needs of over 120 scientists from more than 50 institutions, playing a significant role in increasing the usage and sophistication of analytical ultracentrifugation experiments worldwide. The new Neuroscience Gateway (NSG) registered 100+ users within the first few months of friendly production release in late 2012, and its users consumed more than 250,000 core hours on XSEDE resources by September 2013. The Computational Chemistry Grid Gateway (GridChem) has provided access to computational chemistry tools for more than 800 users, enabling\u00a0\u2026", "num_citations": "7\n", "authors": ["898"]}
{"title": "Enabling dark energy survey science analysis with simulations on xsede resources\n", "abstract": " Upcoming wide-area sky surveys offer the power to test the source of cosmic acceleration by placing extremely precise constraints on existing cosmological model parameters. These observational surveys will employ multiple tests based on statistical signatures of galaxies and larger-scale structures such as clusters of galaxies. Simulations of large-scale structure provide the means to maximize the power of sky survey tests by characterizing key sources of systematic uncertainties. We describe an XSEDE program to produce multiple synthetic sky surveys of galaxies and large-scale cosmic structure in support of science analysis for the Dark Energy Survey. We explain our Airavata-enabled methods and report extensions to our workflow processing over the last year. We highlight science analysis focused on counts of clusters of galaxies.", "num_citations": "7\n", "authors": ["898"]}
{"title": "Message exchanges for web service-based mapping services\n", "abstract": " The Open Geospatial Consortium (OGC)[1] defines a number of standards, both for data models and for online services, that has been widely adopted in the Geographical Information System (GIS) community. This has lead to a number of software development efforts, online data archives, and application communities. The emergence of Web Service technique overcomes the shortcoming of traditional Distributed Object technique and provides the interoperable capability of cross-platform and cross-language in distributed net environment. GIS services will be implemented more extensively by using Web Service approach. A spatial data infrastructure lets many GIS vendors share data stores and applications in a distributed environment. GIS basically involves the integration of data and services from multiple sources from different vendors. The Web services architecture establishes a standard interconnection rules between services and information clients that nicely support the dynamic integration of data, which is the key to creating a spatial data infrastructure. By introducing Web Services, distributed GIS services from different vendors can be dynamically integrated into the GIS applications using the interoperable standard communication protocols of the Web Services. To be able to benefit from the Web Services in the GIS applications, all the service providers should provide their services as Web Services. General acceptance from the vendors increases the interoperability and enhances the GIS applications. We find that the OGC standards are very compatible with Web Services standards, although they are not technically implemented this\u00a0\u2026", "num_citations": "7\n", "authors": ["898"]}
{"title": "Developing a Web Service-Compatible Map Server for Geophysical Applications\n", "abstract": " The Open Geospatial Consortium (OGC) defines a number of standards (both for data models and for online services) that have been widely adopted in the Geographical Information System (GIS) community. In this paper we will describe our group's efforts to implement GIS services according to OGC standard specifications in accordance with the Web Services approach. This paper focuses on the Web Map Service (WMS), which we are coupling to problems in computational geophysics. Through the use of Web Services, we are able to integrate GIS services with other families of services, including information, data management, and remote application execution and management. We also describe WMS client building efforts that are suitable for integration with computational Web portals.To be able to interact with non-Web Service versions of WMS, we also have built bridging service for our extended WMS. Since Web Service oriented WMS has a different request/response paradigm from non-Web Service versions, we have extended cascading WMS by adding request handler functionality. This kind of WMS behaves like both a cascading WMS and a proxy to handle different types of requests to overcome interoperability problems between different WMS systems.", "num_citations": "7\n", "authors": ["898"]}
{"title": "Complexity Computational Environments (CCE) Architecture\n", "abstract": " This document outlines the Complexity Computational Environment (CCE) architectural approach and is closely connected to the \u201cCoupling Methodologies\u201d paper [Parker2004]. We briefly summarize the material and conclusions in the first section of the paper, but we will not duplicate the extensive discussions there. The Coupling Methodologies document should be read in conjunction with the current document.The remainder of this architectural document is devoted to a discussion of general approaches and solutions to the requirements identified in [Parker2004] and through team meetings. The general requirements and a summary of solutions are shown in Table 1.", "num_citations": "7\n", "authors": ["898"]}
{"title": "An extensible django-based web portal for apache airavata\n", "abstract": " The Apache Airavata science gateway middleware project has developed a new web frontend for the middleware\u2019s API based on the Django web framework and the Vue. js JavaScript framework. This new frontend has been designed to be a framework, called the Airavata Django Portal Framework (ADPF) that science gateway developers can use to customize and extend the user interface to add domain specific UI metaphors and to add gateway-specific user workflows. There are three main modes of extensibility: 1) custom scientific application execution configuration, 2) custom application results analysis, and 3) wholly custom user workflows. These modes of extensibility come out of the project\u2019s experience working with science gateways over the years. This new framework has been put into production for the 30+ science gateways hosted by the Science Gateways as a Platform (SciGaP) project at Indiana\u00a0\u2026", "num_citations": "6\n", "authors": ["898"]}
{"title": "Evaluating NextCloud as a file storage for apache airavata\n", "abstract": " Science gateways enable researchers from broad communities to access advanced computing and storage resources. The researchers analyze large amounts of data using the compute resources and the generated results, usually files are saved in the storage. Consider a scenario where a researcher has large output data files of historically run experiments on an external server. If the researcher wants to move the data to the gateway storage, then the only way to do it is through data transfer. This task would be cumbersome and time consuming. The paper discusses an approach through which historic or any data existing on a different server or in a cloud storage (Google Drive) or in an object storage (Amazon S3) can be ingested into the existing gateway without actually transferring it to the server. We discuss about a software called NextCloud and how it can be used as a gateway storage by integrating it with\u00a0\u2026", "num_citations": "6\n", "authors": ["898"]}
{"title": "Science gateways incubator: Software sustainability meets community needs\n", "abstract": " The main goal of the US Science Gateways Community Institute (SGCI) is to serve science gateways to achieve sustainability and growth. Science gateways allow science and engineering communities to access shared data, software, computing services, instruments, educational materials, and other resources specific to their disciplines. Thus, science gateways are a subgroup of scientific software and the means for addressing software sustainability are also suitable for science gateways and vice versa, e.g., best practices for software engineering. Since science gateways are tailored to specific communities, understanding users' requirements is critical for sustainability. SGCI consists of five service areas that closely interact with each other. The Incubator acknowledges the value of business strategy to inform well-designed science gateways and offers two main types of services: individualized consultancy\u00a0\u2026", "num_citations": "6\n", "authors": ["898"]}
{"title": "Advantages to geoscience and disaster response from QuakeSim implementation of interferometric radar maps in a GIS database system\n", "abstract": " High-resolution maps of earth surface deformation are available in public archives for scientific interpretation, but are primarily available as bulky downloads on the internet. The NASA uninhabited aerial vehicle synthetic aperture radar (UAVSAR) archive of airborne radar interferograms delivers very high resolution images (approximately seven meter pixels) making remote handling of the files that much more pressing. Data exploration requiring data selection and exploratory analysis has been tedious. QuakeSim has implemented an archive of UAVSAR data in a web service and browser system based on GeoServer (                   http://geoserver.org                                    ). This supports a variety of services that supply consistent maps, raster image data and geographic information systems (GIS) objects including standard earthquake faults. Browsing the database is supported by initially displaying GIS\u00a0\u2026", "num_citations": "6\n", "authors": ["898"]}
{"title": "Cyberinfrastructure, science gateways, campus bridging, and cloud computing\n", "abstract": " BackgroundThe evolution of cyberinfrastructure as a concept spans some three decades. The earliest references in 1976 (Sorkin, 2006) and in a Clarke and Hunker press briefing (1998) mention \u201ccyber-infrastructure\u201d in the context of cyber threats and cybersecurity.", "num_citations": "6\n", "authors": ["898"]}
{"title": "Integrating science gateways with xsede security: A survey of credential management approaches\n", "abstract": " We present a survey of credential management approaches for science gateways to integrate with the X. 509 security infrastructure used by XSEDE.", "num_citations": "6\n", "authors": ["898"]}
{"title": "Ultrascan solution modeler: integrated hydrodynamic parameter and small angle scattering computation and fitting tools\n", "abstract": " UltraScan Solution Modeler (US-SOMO) processes atomic and lower-resolution bead model representations of biological and other macromolecules to compute various hydrodynamic parameters, such as the sedimentation and diffusion coefficients, relaxation times and intrinsic viscosity, and small angle scattering curves, that contribute to our understanding of molecular structure in solution. Knowledge of biological macromolecules' structure aids researchers in understanding their function as a path to disease prevention and therapeutics for conditions such as cancer, thrombosis, Alzheimer's disease and others. US-SOMO provides a convergence of experimental, computational, and modeling techniques, in which detailed molecular structure and properties are determined from data obtained in a range of experimental techniques that, by themselves, give incomplete information. Our goal in this work is to develop\u00a0\u2026", "num_citations": "6\n", "authors": ["898"]}
{"title": "UltraScan gateway enhancements: in collaboration with TeraGrid advanced user support\n", "abstract": " The Ultrascan gateway provides a user friendly web interface for evaluation of experimental analytical ultracentrifuge data using the UltraScan modeling software. The analysis tasks are executed on the TeraGrid and campus computational resources. The gateway is highly successful in providing the service to end users and consistently listed among the top five gateway community account usage. This continued growth and challenges of sustainability needed additional support to revisit the job management architecture.", "num_citations": "6\n", "authors": ["898"]}
{"title": "The Quakesim portal and services: new approaches to science gateway development techniques\n", "abstract": " Traditional techniques in building science portals and gateways are being challenged by new techniques such as Web 2.0 and Cloud Computing. This paper discusses some of our efforts to evaluate these techniques as we evolve the QuakeSim architecture. We believe that architecturally both traditional and newer approaches for Gateways are very similar; thus, giving us a path for moving to hybrid approaches. In this paper, we specifically evaluate techniques for building interactive user interfaces that rely on remote services; architectural approaches for managing massive job submissions that can include both parallel and serial jobs; and an architectural prototype for building component\u2010based containers compatible with emerging standards. Copyright \u00a9 2009 John Wiley & Sons, Ltd.", "num_citations": "6\n", "authors": ["898"]}
{"title": "Streaming Data Services to Support Archival and Real-Time Geographical Information System Grids\n", "abstract": " We describe our efforts to build a Web Services based architecture to support access to both real-time and archived geographic data in Geographical Information System (GIS) Grids. We have built and tested Web Service version of OGC Web Feature Service (WFS) that can be used to provide archived geospatial data to various clients. Due to several performance issues described in this paper we have also built a streaming version of Web Feature Service for large data sets where high performance is desired. We also describe our work building a Sensor Filter Grid to process and serve real-time GPS messages over publish/subscribe messaging middleware. We describe several filters built for this purpose and discuss initial performance results. As an example of how we can couple scientific simulation codes with our Grid architecture we describe coupling of a scientific data analysis application with GPS streams.", "num_citations": "6\n", "authors": ["898"]}
{"title": "A Retrospective on the Development of Web Service Specifications\n", "abstract": " Web Services have gained considerable traction over the past several years, and are being increasingly leveraged within the academic, business and research communities. The Service Oriented Architecture (SOA) model engendered within Web Services provides a simple and flexible framework for building sophisticated applications. A slew of specifications addressing several core areas\u2013such as reliable messaging, addressing, security etc\u2013within", "num_citations": "6\n", "authors": ["898"]}
{"title": "An XML Based System for Dynamic Message Content Creation, Delivery, and Control\n", "abstract": " We describe the design and implementation of an XML messaging system for creating, delivering and managing general purpose XML messages. We describe message composition wizards, a multipurpose delivery system implementation, and message access role definitions. This system may be used as the foundation for both human readable messaging (such as newsgroupss and registration systems) as well as event-driven application-to-application systems.", "num_citations": "6\n", "authors": ["898"]}
{"title": "Custos: Security middleware for science gateways\n", "abstract": " Science gateways represent potential targets for cybersecurity threats to users, scientific research, and scientific resources. In this paper, we introduce Custos, a software framework that provides common security operations for science gateways, including user identity and access management, gateway tenant profile management, resource secrets management, and groups and sharing management. The goals of the Custos project are to provide these services to a wide range of science gateway frameworks, providing the community with an open source, transparent, and reviewed code base for common security operations; and to operate trustworthy security services for the science gateway community using this software base. To accomplish these goals, we implement Custos using a scalable microservice architecture that can provide highly available, fault tolerant operations. Custos exposes these services\u00a0\u2026", "num_citations": "5\n", "authors": ["898"]}
{"title": "Virtual Clusters in the Jetstream Cloud: A story of elasticized HPC\n", "abstract": " We discuss our work providing resources for batch computing via the Jetstream cloud, in the form of SLURM clusters. While these are mainly used by science gateways, there have been a few used in the more traditional commandline manner. The flexible nature of these has also lent itself well to educational work, and has provided the basis for a very successful series of tutorials and workshops. This paper discusses the technical evolution of the Virtual Cluster product, and gives an overview of the science enabled. We discuss the challenges in supporting an ecosystem of these virtual clusters, and in supporting research on cloud resources in general.", "num_citations": "5\n", "authors": ["898"]}
{"title": "Using the Jetstream research cloud to provide science gateway resources\n", "abstract": " We describe the use of the Jetstream research-cloud, a purpose-built system with the goal of supporting \"long-tail\" research by providing a flexible, on-demand research infrastructure, to provide scalable back-end resources for science gateways. In addition to providing cloud-like resources for on-demand science, Jetstream offers the capability to instantiate long-running clusters which support science gateways. Science gateways are web-based systems built on computationalinfrastructure which provide commonly-used tools to a community of users. We created a persistent clusteron the Jetstream system which is connected to the SEAGrid science gateway and provides additional compute resources for a variety of quantum chemistry calculations. We discussthe further application of toolkits provided by the Extreme Science and Engineering Discovery Environment (XSEDE) tobuild general-purpose clusters on the\u00a0\u2026", "num_citations": "5\n", "authors": ["898"]}
{"title": "Anatomy of the SEAGrid Science Gateway\n", "abstract": " The SEAGrid science gateway provides scientists and educators with user interfaces and tools for conducting computational chemistry, material science, and engineering experiments online using XSEDE and campus computing resources. This paper describes the architecture of the recently completed technology refresh for the gateway, replacing its desktop user interface, adding a web browser user interface, using Apache Airavata middleware for job management, and providing enhanced data search and feature extraction capabilities. These introduce several challenges, particularly in providing unified authentication and authorization mechanisms to middleware services for the desktop and web clients, and in extending Apache Airavata middleware with new components. Access, authentication, and authorization problems were solved by using standard-based approaches (OAuth2, XACML) that were\u00a0\u2026", "num_citations": "5\n", "authors": ["898"]}
{"title": "A distributed approach to computational earthquake science: Opportunities and challenges\n", "abstract": " Advances in understanding earthquakes require the integration of models and multiple distributed data products. Increasingly, data are acquired through large investments, and utilizing their full potential requires a coordinated effort by many users, independent researchers, and groups who are often distributed both geographically and by expertise.", "num_citations": "5\n", "authors": ["898"]}
{"title": "A federated approach to information management in grids\n", "abstract": " We propose a novel approach to managing information in grids. The proposed approach is an add-on information system that provides unification and federation of grid information services. The system interacts with local information services and assembles their metadata instances under one hybrid architecture to provide a common query/publish interface to different kinds of metadata. The system also supports interoperability of major grid information services by providing federated information management. We present the semantics and architectural design for this system. We introduce a prototype implementation and present its evaluation. As the results indicate, the proposed system achieves unification and federation of custom implementations of grid information services with negligible processing overheads.", "num_citations": "5\n", "authors": ["898"]}
{"title": "Open community development for science gateways with apache rave\n", "abstract": " Science gateways enable researchers and students to use distributed scientific computing infrastructure (cyberinfrastructure) through Web browsers and Web-enabled desktop clients. This paper describes the use of the open source, open community Apache Rave project as the basis for developing science gateways. Building on Apache Shindig (for OpenSocial Gadgets) and Apache Wookie (for W3C Widgets), Rave provides an out-of-the box deployment that can be used to host reusable social Web components. Rave is based on the Spring MVC framework and so can also be extensively customized or extended with (for example) custom database back-ends and authentication modules. In this paper we consider Rave as a development platform for science gateways and discuss how the source code may be extended through three use cases that focus on gateway security requirements. A major consideration of\u00a0\u2026", "num_citations": "5\n", "authors": ["898"]}
{"title": "Science gateways: Harnessing clouds and software services for science\n", "abstract": " Nancy Wilkins-Diehr e pursuit of science has evolved over hundreds of years from the development of the scientific method to the use of empirical methods. is evolution continues today at an increasingly rapid pace. Scientific pursuit has always been marked by advances in technology. Increasingly powerful microscopes and telescopes have led to new discoveries and theories; access to sensor data improves the ability to analyze and monitor events and understand complex phenomena, such as climate change, and advances in sequencing technologies will very soon result in personalized medicine. e evolution of science with technology continues today as well. e 1970s and 1980s saw the significant development of computational power. Computer simulations were considered a third pillar of science in addition to theory and experiment. One of the biggest impacts in modern times has been the release of the\u00a0\u2026", "num_citations": "5\n", "authors": ["898"]}
{"title": "Improving usability and accessibility of cheminformatics tools for chemists through cyberinfrastructure and education\n", "abstract": " Some of the latest trends in cheminformatics, computation, and the world wide web are reviewed with predictions of how these are likely to impact the field of cheminformatics in the next five years. The vision and some of the work of the Chemical Informatics and Cyberinfrastructure Collaboratory at Indiana University are described, which we base around the core concepts of e-Science and cyberinfrastructure that have proven successful in other fields. Our chemical informatics cyberinfrastructure is realized by building a flexible, generic infrastructure for cheminformatics tools and databases, exporting\" best of breed\" methods as easily-accessible web APIs for cheminformaticians, scientists, and researchers in other disciplines, and hosting a unique chemical informatics education program aimed at scientists and cheminformatics practitioners in academia and industry.", "num_citations": "5\n", "authors": ["898"]}
{"title": "Implementation, performance, and science results from a 30.7 tflops ibm bladecenter cluster\n", "abstract": " This paper describes Indiana University's implementation, performance testing, and use of a large high performance computing system. IU's Big Red, a 20.48 TFLOPS IBM e1350 BladeCenter cluster, appeared in the 27th Top500 list as the 23rd fastest supercomputer in the world in June 2006. In spring 2007, this computer was upgraded to 30.72 TFLOPS. The e1350 BladeCenter architecture, including two internal networks accessible to users and user applications and two networks used exclusively for system management, has enabled the system to provide good scalability on many important applications while being well manageable. Implementing a system based on the JS21 Blade and PowerPC 970MP processor within the US TeraGrid presented certain challenges, given that Intel\u2010compatible processors dominate the TeraGrid. However, the particular characteristics of the PowerPC have enabled it to be\u00a0\u2026", "num_citations": "5\n", "authors": ["898"]}
{"title": "Building a Grid Portal for Teragrid\u2019s Big Red\n", "abstract": " We describe the Big Red Portal, which builds on the Open Grid Computing Environment (OGCE) portal software. In addition to standard OGCE capabilities, this portal includes MEME job submission and job dashboard portlets that are built using OGCE and related portlet libraries. To simplify the development of such portlets in the future, we introduce an XML tag library approach that encapsulates common Grid operations for rapid development", "num_citations": "5\n", "authors": ["898"]}
{"title": "Optimizing web service messaging performance using a context store for static data\n", "abstract": " The performance and efficiency of Web Service messaging can be greatly increased by removing the redundant parts of SOAP messages. This paper describes our research work in optimizing SOAP message contents. This area is particularly important to those applications that are physically constrained mobile computing environments. The redundant or static parts of the SOAP message may be treated as metadata and stored in shared metadata space. We integrate our optimized SOAP messaging system with our information management research framework. We evaluate our approach by testing the performance of the resulting system. The empirical result shows that we save on average 83% of message size and on average 41% of transit time.", "num_citations": "5\n", "authors": ["898"]}
{"title": "A grid framework for visualization services in the Earth sciences\n", "abstract": " Scientific visualization is an ingredient essential to understanding the large amounts of data generated from large-scale numerical simulations, laboratory experiments and geological surveys. Visualization forms an integral component of any complete framework, together with services to handle mathematical and statistical analysis, storage, feature extraction, and other functions. To support rapid and seamless collaborations and communication between researchers across geographically disparate regions necessitates a distributed infrastructure that supports redundancy, fault tolerance, and most importantly, ease of use. We describe herein an architecture based on Naradabrokering, a publish/subscribe framework that supports the above requirements. We have implemented an initial version of this architecture and describe some initial experiments.", "num_citations": "5\n", "authors": ["898"]}
{"title": "An Architecture for Supporting Information in Dynamically Assembled Semantic Grids\n", "abstract": " Many large semantic systems can be described as Semantic Grids of Semantic Grids with large amounts of relatively static services and associated semantic information combined with multiple dynamic regions (sessions or subgrids) where the semantic information is changing rapidly. We design a hybrid Information Service supporting both the scalability of large amounts of relatively slowly varying data and a high performance rapidly updated Information Service for dynamic regions. We use the two web service standards UDDI and WS-Context in our system. We report initial results from a prototype that is applied to sensor and collaboration grids.", "num_citations": "5\n", "authors": ["898"]}
{"title": "Designing a Grid Computing Environment Shell Engine.\n", "abstract": " We describe the design and features of our Grid Computing Environments Shell system, or GCEShell. We view computing Grids as providing essentially a globally scalable distributed operating system that exposes low level programming APIs. From these system-level commands we may build a higher level library of more user-friendly shell commands, which may in turn be programmed through scripts. The GCEShell consists of a shell engine that serves as a container environment for managing GCEShell commands, which are client implementations for remote Web Service/Open Grid Service Architecture services that resemble common UNIX shell operations.", "num_citations": "5\n", "authors": ["898"]}
{"title": "Design of a Hybrid Search in the Online Knowledge Center\n", "abstract": " A hybrid search in the Online Knowledge Center enables search for the content of linked documents in the metadata. In this paper, we present design issues for the combined search of unstructured data linked in semistructured data. We describe the problems of the initial design for the metadata storage and inquiry performance, and suggest a solution under a specific environment\u2013the newsgroup service of the Online Knowledge Center system.", "num_citations": "5\n", "authors": ["898"]}
{"title": "Applications of E-DECIDER decision support tools for disaster response and recovery\n", "abstract": " In this chapter we describe E-DECIDER (Emergency Data Enhanced Cyber-Infrastructure for Disaster Evaluation and Response) and provide example of applications to earthquake, tsunami, and fire events. This decision support system transforms and distributes remote sensing, deformation modeling, critical infrastructure information, and aftershock forecasting data products. E-DECIDER uses damage functions based on Hazards United States (HAZUS) loss estimation software to estimate damage and loss. We have developed a suite of web services and map data products enabling decision makers to identify areas where likely deformation and damage has occurred, locate at risk critical infrastructure, and determine likelihood of aftershock hazard. We also discuss development and use of our tools and methodologies in partnership with the California Earthquake Clearinghouse, the California Office of Emergency Services (CalOES) and FEMA. We are currently working on transitioning of these capabilities to operational status with our stakeholder partners.", "num_citations": "4\n", "authors": ["898"]}
{"title": "QuakeSim: Integrated modeling and analysis of geologic and remotely sensed data\n", "abstract": " The QuakeSim Project improves understanding of earthquake processes by integrating model applications and various heterogeneous data sources within a web services environment. The project focuses on the earthquake cycle and related crustal deformation. Spaceborne GPS and Interferometric Synthetic Aperture data provide information on near-term crustal deformation, while paleoseismic geologic data provide longer-term information on earthquake fault processes. These data sources are integrated into QuakeSim's QuakeTables database and are accessible by users or various model applications. An increasing amount of UAVSAR data is being added to the QuakeTables database through a map browsable interface. Model applications can retrieve data from QuakeTables or remotely served GPS velocity data services or users can manually input parameters into the models. Pattern analysis of GPS and\u00a0\u2026", "num_citations": "4\n", "authors": ["898"]}
{"title": "Integrating chemistry scholarship with web architectures, grid computing and semantic web\n", "abstract": " A chemist given a compound would be interested in knowing the experiments performed using the compound, journals containing the compound and also molecular properties of the compound. If there is a way to integrate this data, it would enhance the chemist's knowledge about a given compound. The Object Reuse and Exchange (ORE) specification may provide a solution to this problem. ORE is a model proposed by the digital libraries community to aggregate resources on the web. OREChem is a research project funded by Microsoft External Research that aims to apply and extend ORE to enable the integration of experimental, bibliographical and molecular properties data. OREChem targets crystallography as its primary application domain. This effort will design a prototypical, semantic-based eScience infrastructure for chemistry and chemical informatics. In this paper we describe how we have used REST\u00a0\u2026", "num_citations": "4\n", "authors": ["898"]}
{"title": "Quakesim: Web services, portals, and infrastructure for geophysics\n", "abstract": " We discuss significant recent updates and revisions to the QuakeSim portal and Web services, which provide access to geophysical applications, data sets, and real time sensor data. These new developments include a) significant updates to the Web portal, b) a revision of Web services to better encapsulate applications, c) additional services for generating keyhole markup language markups of maps, and d) support for real-time GLOBAL POSITIONING Data.", "num_citations": "4\n", "authors": ["898"]}
{"title": "Building QuakeSim portlets with GTLAB\n", "abstract": " The QuakeSim portal is a problem solving environment to develop a solid Earth science framework for modelling and understanding earthquakes. In this study, we proposed an evolutionary approach to allow TeraGrid usage in addition to our own clusters for QuakeSim portal. Our approach is based on our Grid Tag Libraries and Beans (GTLAB) libraries, which encapsulate common Grid operations with reusable XML tags. GTLAB enables rapid development of grid portlets rather than typical portlet development techniques. Although it adds a new layer to programming stack, our experiments show that the performance delay is tolerable in Web applications.", "num_citations": "4\n", "authors": ["898"]}
{"title": "Building a sensor grid for real time global positioning system data\n", "abstract": " We describe the architecture of our streaming sensor grid system. Using a topic-based publish/subscribe methodology, we are able to build a scalable system for managing real-time data streams produced by the California Real Time GPS Network. The architecture is based on atomic, extensible elements called filters that receive, modify, and republish 1 Hz GPS data streams in our deployment. Our filter approach can be extended to include sophisticated data analysis and event detection applications.", "num_citations": "4\n", "authors": ["898"]}
{"title": "QuakeSim: Enabling Model Interactions in Solid Earth Science Sensor Webs\n", "abstract": " QuakeSim is problem-solving environment for understanding earthquake processes through the integration QuakeSim: of multiscale models and data. The goal of QuakeSim is to substantially improve earthquake forecasts, which will ultimately lead to mitigation of damage from this natural hazard. Improved earthquake forecasting is dependent on measurement of surface deformation as well as analysis of geological and seismological data. Space-borne technologies, in the form of continuous GPS networks and InSAR satellites, are the key contributors to measuring surface deformation. We are expanding our QuakeSim Web Services environment to integrate, via Ontolody-based Federation, both real-time and archival sensor data with high-performance computing applications for data mining and assimilation. We are federating sensor data sources, with a focus on InSAR and GPS data, for an improved modeling\u00a0\u2026", "num_citations": "4\n", "authors": ["898"]}
{"title": "Grid portal system based on GPIR\n", "abstract": " Grid portal is the bridge between Grid and user. In this paper a Grid portal system is set up based on GPIR of GridPort. The Grid portal system provides an efficient means to user for utilizing grid resources, and provides advantaged condition for achieving effective information of database. The user can customize the application by portlet framework. In this paper we also review multiple choices for portal technology and explain why we choose GPIR.", "num_citations": "4\n", "authors": ["898"]}
{"title": "A PERMIS-based Authorization Solution between Portlets and Back-end Web Services\n", "abstract": " A portal is a Web-based application that acts as an entry point to distributed resources. Individual portlets in a portal can be used to integrate information from a variety of back-end Web services. However, when Web services are deployed, they are available to unintended clients not related to the portal so a general solution for authorizing access to them is needed that is integrated with the portal\u2019s own authentication and authorization mechanisms. This paper investigates the feasibility of an implementation of a general purpose solution for authorization between portlets and their back end Web services based on Privilege and Role Management Infrastructure Standards (PERMIS) which uses Web services security standards such as WS-Security and SAML. This solution is also appropriate for authorization across organizational boundaries supporting the inclusion of service resources to a portal which are contributed by many different organizations. A motivating example of instrument sharing based on the CIMA remote instrument access protocol is presented.", "num_citations": "4\n", "authors": ["898"]}
{"title": "Web service grids for iSERVO\n", "abstract": " This presentation describes the Web Service architecture possible for the International Solid Earth Research Virtual Observatory iSERVO and which has been prototyped in the USA SERVOGrid project led by JPL. We describe Grids built from Web Services and how they provide support for building virtual organizations harmonized by community resources such as data bases, sensors and computers. These shared resources are supplemented by the interactive workgroups with real time tools such as shared applications and audio-video conferencing. Grid technology provides a service level Internet that provides high quality of service including security and fault tolerance on top of a typically incoherent but high volume background of ordinary internet applications. One architects SERVOGrid as a Grid of Grids building it in terms of computing, sensor, database, visualization and GIS (Geographical Information\u00a0\u2026", "num_citations": "4\n", "authors": ["898"]}
{"title": "Scientific Applications as Web Services: A Simple Guide\n", "abstract": " We have discussed in several columns Grid technology and its use in e-Science (large scale distributed scientific research). Here we make the ideas more concrete by describing how one can \u201cconvert\u201d(build from scratch) a scientific resource (program) as a web service. Modern Grids are built on top of web services with interesting refinements captured as OGSA\u2013Open Grid Service Architecture. The approach here can easily be extended to be OGSA (with its initial OGSI standard) compliant [3].Web-enabled applications in support of e-business and e-commerce are an everyday fact of life: customizable information portals like Yahoo, online ordering systems like Amazon, and web auctions like E-bay are familiar to everyone. The potential for webenabling science applications has attracted a lot of attention from the scientific community as well. Numerous browser-based computing portal systems and problem solving environments have been built since the late \u201890s, and a comprehensive review may be found in [1]. Various commodity technologies from the world of electronic commerce, including CGI-based Perl and Python scripts, Java applets and servlets, CORBA, and most recently, Web Services, have all been brought to bear on the science portal/service problem.", "num_citations": "4\n", "authors": ["898"]}
{"title": "Towards dependable grid and web services\n", "abstract": " Remote method invocations have been used in distributed systems for quite some time. Frameworks such as CORBA from the Object Management Group (OMG)[1] have had schemes in place to facilitate invocations on remote objects for more than a decade. There also has been support for remote invocations in programming languages, a case in point being the Java Remote Method Invocation (RMI) Framework [2]. In these cases we could think of the remote object as providing a service comprising a set of functions. The provider exposes the service's capability through an appropriate description language, which comprises the function names, the number and type arguments that a given service function takes and finally the return type that would be returned upon completion of the invocation.The underlying principle for Grid Services [3] and Web Services [4] is similar to what existed in these earlier systems. The\u00a0\u2026", "num_citations": "4\n", "authors": ["898"]}
{"title": "Automating metadata web service deployment for problem solving environments\n", "abstract": " XML-based metadata information services are a crucial core service needed by Problem Solving Environments built over emerging service-based, globally-scaled distributed systems, as envisioned by the Open Grid Services Architecture and the Semantic Web. Developing user interfaces and services bindings for manipulating instances of particular schemas is thus extremely important and needs to be made as simple as possible. In this paper we describe procedures for automating the creation of Web Service environments that can be used to simplify the creation and deployment of schema-based metadata services.", "num_citations": "4\n", "authors": ["898"]}
{"title": "Federated Grids and their Security\n", "abstract": " We examine issues involved in creating \u201cvirtual Grids\u201d out of specific Grid installations. We see it as inevitable that Grids will be established as islands of resource collections that will need to be federated in lightweight manners. These islands of resources may result from a number of reasons. First, a group may set up a Grid of resources that it owns and directly controls but must overcome sociological and/or organizational barriers for interoperating with other Grid installations, even when the same software is used. Second, we see the emergence of Grids built out of differing substrate technologies with perhaps incompatible communication systems.As a specific example of the first case, we think of a Grid as a single installation of Globus software on some specific resources. For example, the Community Grids Lab may install Globus software on all of its Linux and Solaris servers. The CGL sets up a Grid consisting of resources that it owns and has direct control over. We then must negotiate with other Grid operators (such as in the Computer Science department) about federating these Grids. Currently this is an all-or-nothing affair, but in this white paper we examine some possibilities for adding more fine-grained control.", "num_citations": "4\n", "authors": ["898"]}
{"title": "LSU computational system biology gateway for education\n", "abstract": " Science gateways are a mechanism for delivering scientific software as a service, especially when the software requires high performance computing (HPC) resources to run effectively. The existence of a science gateway eliminates the user's need to learn to work with HPC systems and to manage software installations and updates. With well-designed user interfaces, users can more quickly become effective users of scientific applications and can manage information needed for replicating, modifying, and sharing results. All of these efficiency gains enable users to focus more on their research. In addition, science gateways are being identified as an effective educational tool, a tool to be used in classroom environments as a method to get students quickly into research on domain specific questions. In the absence of a science gateway, students are likely to need a considerable time to learn to work with HPC\u00a0\u2026", "num_citations": "3\n", "authors": ["898"]}
{"title": "A new science gateway to provide decision support on carbon capture and storage technologies\n", "abstract": " Carbon dioxide capture and storage (CCS) is a promising technology for mitigating climate change, and its implementation is considered critical to meeting threshold targets for global warming in the 21st century. We have developed a new science gateway application for the successful modeling software known as SimCCS that is used for evaluating complex, integrated CCS infrastructure. Using the Apache Airavata middleware and high-performance computing resources made available by the Extreme Science and Engineering Discovery Environment, we built the SimCCS Gateway to expand the tool's scalability for decision support and risk assessment. Case studies developed for evaluating a proposed CCS technology at Duke Energy's Gibson Station coal-fired power plant in southwest Indiana demonstrate its improved ability in data analysis as well as risk assessment at various uncertainty levels. Further\u00a0\u2026", "num_citations": "3\n", "authors": ["898"]}
{"title": "Using a Science Gateway to Deliver SimVascular Software as a Service for Classroom Instruction\n", "abstract": " SimVascular (http://www. simvascular. org) is open source software enabling users to construct image-based, patient-specific anatomic models and perform realistic blood flow simulation useful in disease research, medical device design, and surgical planning. The software consists of two core executables: a front-end application and a flow solver. The front-end application enables users to create patient-specific anatomic models from imaging data, generate finite-element meshes, prescribe boundary conditions, and set up an analysis. The finite-element based blood flow solver utilizes MPI and is massively scalable. SimVascular has been successfully integrated into graduate level courses on cardiovascular modeling at multiple institutions including Stanford, UC Berkeley, Purdue, and Marquette to introduce state-of-the-art modeling to the students and provide a basis for hands-on projects. While the front-end\u00a0\u2026", "num_citations": "3\n", "authors": ["898"]}
{"title": "Towards a science gateway reference architecture\n", "abstract": " Science gateways have been developed over the last twenty years and have grown into a large community of practice, as evidenced by international workshops and conferences. Because of the diversity of approaches to creating science gateways and the always changing landscape of technologies, the community lacks a common definition for the term \u201cscience gateway\u201d itself and common terminology for describing the common components of a gateway architecture. Instead, a wide range of definitions and understandings exist and are used in different communities; this is evident, for example, in discussions whether science gateways are the same as virtual research environments. This paper attempts to address these issues by focusing on how science gateways support scientific research and considering the consequences on cyberinfrastructure.", "num_citations": "3\n", "authors": ["898"]}
{"title": "Radar determination of fault slip and location in partially decorrelated images\n", "abstract": " Faced with the challenge of thousands of frames of radar interferometric images, automated feature extraction promises to spur data understanding and highlight geophysically active land regions for further study. We have developed techniques for automatically determining surface fault slip and location using deformation images from the NASA Uninhabited Aerial Vehicle Synthetic Aperture Radar (UAVSAR), which is similar to satellitebased SAR but has more mission flexibility and higher resolution (pixels are approximately 7 m). This radar interferometry provides a highly sensitive method, clearly indicating faults slipping at levels of 10 mm or less. But interferometric images are subject to decorrelation between revisit times, creating spots of bad data in the image. Our method begins with freely available data products from the UAVSAR mission, chiefly unwrapped interferograms, coherence images, and\u00a0\u2026", "num_citations": "3\n", "authors": ["898"]}
{"title": "Pervasive Technology Institute Annual Report: Research Innovations and Advanced Cyberinfrastructure Services in Support of IU Strategic Goals During FY 2017\n", "abstract": " Pervasive\u200b \u200bTechnology\u200b \u200bInstitute\u200b \u200bAnnual Report:\u200b \u200bResearch\u200b \u200bInnovations\u200b \u200band\u200b \u200bAdvanced Cyberi Page 1 Pervasive\u200b \u200bTechnology\u200b \u200bInstitute\u200b \u200bAnnual Report:\u200b \u200bResearch\u200b \u200bInnovations\u200b \u200band\u200b \u200bAdvanced Cyberinfrastructure\u200b \u200bServices\u200b \u200bin\u200b \u200bSupport\u200b \u200bof\u200b \u200bIU Strategic\u200b \u200bGoals\u200b \u200bduring\u200b \u200bFY\u200b \u200b2017 Craig\u200b \u200bA.\u200b \u200bStewart Beth\u200b \u200bPlale Von\u200b \u200bWelch Marlon\u200b \u200bPierce Geoffrey\u200b \u200bFox Thomas\u200b \u200bG.\u200b \u200bDoak David\u200b \u200bY.\u200b \u200bHancock Robert\u200b \u200bHenschel Matthew\u200b \u200bR.\u200b \u200bLink Therese\u200b \u200bMiller Eric\u200b \u200bA.\u200b \u200bWernert Michael\u200b \u200bJ.\u200b \u200bBoyles Ben\u200b \u200bFulton Le\u200b \u200bMai\u200b \u200bWeakley Robert\u200b \u200bJ.\u200b \u200bPing Tassie\u200b \u200bGniady Winona\u200b \u200bSnapp-Childs Indiana\u200b\u200bUniversity \u200b\u200bPTI\u200b\u200bTechnical\u200b\u200bReport\u200b\u200bPTI-TR17-010 Last\u200b\u200brevised\u200b\u200bJuly\u200b\u200b31,\u200b\u200b2017 Citation: Stewart,\u200b\u200bCA,\u200b\u200bPlale,\u200b\u200bB.,\u200b\u200bWelch,\u200b\u200bV.,\u200b\u200bPierce,\u200b\u200bM.,\u200b\u200bFox,\u200b\u200bG.,\u200b\u200bHancock,\u200b\u200bDY,\u200b\u200bHenschel,\u200b\u200bR.,\u200b\u200b\u2026", "num_citations": "3\n", "authors": ["898"]}
{"title": "GeoGateway: A system for analysis of UAVSAR data products\n", "abstract": " GeoGateway is a web-enabled map-based system for analysis, modeling, and response of geodetic imaging products for studying earthquakes and crustal deformation. The system provides a data product search and analysis gateway for scientific discovery, field use, and disaster response. To be effective users require data overlay and visualization, interactive analysis features, and data product download. The data products of focus in this project are NASA's UAVSAR and spaceborne interferometric radar, (InSAR), geologic earthquake faults, Global Positioning System (GPS) position time series, and seismicity.", "num_citations": "3\n", "authors": ["898"]}
{"title": "Patching it up, pulling it forward\n", "abstract": " An important reason for making any software open source is to encourage code and other community contributions, resulting in more diverse developer communities coalescing around valuable software efforts. We believe the full picture of open developer communities is underappreciated by scientific and cyberinfrastructure open source software efforts. Free and open source licensing is popular in scientific and cyberinfrastructure software, and Web-based tools for source code management (such as GitHub and Bitbucket) are in common use, but community building efforts and associated governance models that foster these communities need improvement. We propose here a simple mechanism to address this problem: developers should be given incentives to submit patches and to make other measurable contributions to code bases that they use but are not otherwise connected to, and projects should be given incentives to accept these outside contributions. As an example implementation, we outline a contest system with small monetary rewards for individuals and recognition for both individuals and projects. The goal is to change the mindset of scientific and cyberinfrastructure developers, converting them from passive downstream users to active contributors. We hypothesize that this easily measurable concrete action will contribute to the sustainability of many projects and also create a more flexible scientific workforce. Building this effort on currently available, federally funded software will establish a foundation of public data that can be used to verify our hypothesis. More broadly, the effort will demonstrate the benefits for scientific and\u00a0\u2026", "num_citations": "3\n", "authors": ["898"]}
{"title": "Multihazard simulation and cyberinfrastructure\n", "abstract": " The integration of multihazard simulations and remotely sensed observations is providing enormous benefits to earthquake and tsunami research. Integrating data and models through cyberinfrastructure is enabling understanding of earthquake and tsunami generation mechanisms in the Asia Pacific region and improving assessment strategies for mitigating risk. Earthquake rupture processes occur on all scales from microns to global and from sub-seconds to millions of years. Earthquakes cause damage, but also generate tsunamis, which create additional damage. Remotely sensed observations coupled with geologic field measurements and simulations contribute to our understanding of earthquake processes, which is necessary for mitigating loss of life and property from these damaging events. Remotely sensed observations play a unique role in the mitigation of natural hazards. Measurements of surface\u00a0\u2026", "num_citations": "3\n", "authors": ["898"]}
{"title": "Web services for dynamic coloring of UAVSAR images\n", "abstract": " QuakeSim has implemented a service-based Geographic Information System to enable users to access large amounts of Uninhabited Aerial Vehicle Synthetic Aperture Radar (UAVSAR) data through an online interface. The QuakeSim Interferometric Synthetic Aperture Radar (InSAR) profile tool calculates radar-observed displacement (from an unwrapped interferogram product) along user-specified lines. Pre-rendered thumbnails with InSAR fringe patterns are used to display interferogram and unwrapped phase images on a Google Map in the InSAR profile tool. One challenge with this tool lies in the user visually identifying regions of interest when drawing the profile line. This requires that the user correctly interpret the InSAR imagery, which currently uses fringe patterns. The mapping between pixel color and pixel value is not a one-to-one relationship from the InSAR fringe pattern, and it causes difficulty\u00a0\u2026", "num_citations": "3\n", "authors": ["898"]}
{"title": "Cloud computing for geodetic imaging data processing, analysis, and modeling\n", "abstract": " Geodetic imaging data from Interferometric Synthetic Aperture Radar (InSAR) are used to measure crustal deformation related to tectonic motions and displacements on earthquake faults. NASA's UAVSAR project and related efforts are creating large catalogs of data products. The user base of these data products is also growing, introducing the need for downstream tools to support computationally expensive individual research as well as access to voluminous and heterogeneous data products. Bundling data inside a virtual machine becomes impractical for load balancing and on-demand auto scaling. A possible solution is to separate the application services from the data service. The Amazon public cloud would be utilized for computation and analysis and private data would be served from a private cloud through Open Geospatial Consortium (OGC) cascading services. We are using Amazon's Elastic Compute\u00a0\u2026", "num_citations": "3\n", "authors": ["898"]}
{"title": "Sustainable cyberinfrastructure software through open governance\n", "abstract": " Sustainable software depends on communities who are invested in the software\u2019s success. These communities need rules that guide their interactions, that encourage participation, that guide discussions, and that lead to resolutions and decisions--we refer to these rules as a community\u2019s governance. Open governance provides well-defined mechanisms executed through open communications that allow stakeholders from diverse and even competing backgrounds to interact in neutral forums in a collaborative manner encouraging growth and transforming passive users into active stakeholders. Our position is that cyberinfrastructure software sustainability benefits from these open governance methods.Software sustainability has many aspects. As a first principle, the software must obviously fulfill a need for a community of users. In addition, some portion of the project\u2019s members must acquire funding to develop and improve the software, to fix bugs, and to maintain compatibility with new computing platforms, with compilers, with run time environments, etc. The software needs to be well-engineered, documented, and supported so that it can survive the departure of early developers and add new developers. All these activities are performed by the project stakeholders. Greater diversity of stakeholders increases the resiliency and sustainability of the project in the face of uncertain funding and developer turnover, but this diversity also increases the likelihood of conflicts. Projects must therefore have well defined governance to balance the need for attracting new committers with the dangers of community splintering.", "num_citations": "3\n", "authors": ["898"]}
{"title": "Transitioning BioVLab cloud workbench to a science gateway\n", "abstract": " BioVLab gateway is built upon Open Gateway Computing Environments and is currently used as reconfigurable cloud computing workbench. In this talk, we will discuss the new directions towards a TeraGrid Science Gateway and experiences and technical challenges in migrating a Cloud workbench Grid based science gateway.", "num_citations": "3\n", "authors": ["898"]}
{"title": "Cloud computing and spatial cyberinfrastructure\n", "abstract": " In this perspectives paper, we review the current state of Cyberinfrastructure and illustrate opportunities that we see if Cloud Computing strategies are adopted. In summary, Cloud Computing provides elastically provisioned computing, software, and service infrastructure, typically implemented on a foundation of virtual machine and virtual data storage technologies. This elasticity allows users to outsource their computing infrastructure, growing or shrinking it as necessary. Commercial investments in Cloud infrastructure make it likely that these systems will dominate large-scale computing hardware and software in the next decade. Furthermore, open source Cloud software makes it possible for universities and research laboratories to investigate and build open-architecture clouds for scientific computing and other uses. Given these general advantages, we consider the applicability of the approach to scientific computing generally and Spatial Cyberinfrastructure specifically through two case studies (flood modeling and radar image processing). We map these projects\u2019 requirements to both infrastructure and runtime capabilities typically provided by Clouds. Based on these case studies, we discuss gaps and research opportunities in Cloud Computing from the geospatial point of view. Our preliminary conclusion from this review is that Spatial Cyberinfrastructure\u2019s requirements are a good match for many common capabilities of Clouds, warranting a larger scale investigation and research by the community.\\body", "num_citations": "3\n", "authors": ["898"]}
{"title": "Open grid computing environment's workflow suite for e-science projects\n", "abstract": " E-Science users will want to construct, share, execute and monitor sequence of tasks. These tasks may execute on machines ranging from their local workstations to high-end, grid-enabled compute resources. Often, these tasks are legacy applications written in various programming and scripting languages and are designed to be run in a single user environment rather than as a Web application. These tasks often need to be tied together into composite applications that need to span multiple computing resources. The majority of the scientific experiments in E-Science involve orchestrating multiple tasks in the correct fashion to produce scientific computational experiments. Scientific workflows have proven to be a coherent and abstract framework that is capable of capturing such scientific experiments and hence have gained popularity among the scientific community. Many of the current E-Science projects have\u00a0\u2026", "num_citations": "3\n", "authors": ["898"]}
{"title": "QuakeSim: Efficient Modeling of Sensor Web Data in a Web Services Environment\n", "abstract": " QuakeSim is a project to develop a modeling environment for studying earthquake processes using a Web services environment. In order to model interseismic processes multiple data types must be ingested including spaceborne GPS and InSAR data, geological fault data, and seismicity data. QuakeSim federates data from these multiple sources and integrates the databases with modeling applications. Because the models are complex and compute intensive we are using the Columbia computer located at NASA Ames to integrate and run software programs to improve our understanding of the solid Earth and earthquake processes. The complementary software programs are used to simulate interacting earthquake fault systems, model nucleation and slip on faults, and calculate run-up and inundation from tsunamis generated by offshore earthquakes. QuakeSim also applies pattern recognition techniques to real\u00a0\u2026", "num_citations": "3\n", "authors": ["898"]}
{"title": "Building a Grid of Grids: messaging substrates and information management\n", "abstract": " This article reviews our efforts to build science application Grids [1] using Web Service Architecture [2] principles. We review several aspects of the problem, including a) designing and integrating families of Grid Web Services; b) Grid messaging substrates, and c) developing client (\u201crequester agent\u201d) managing environments such as computing Web portals. The merger of Grid and Web Service standards first introduced by the Open Grid Service Architecture (OGSA)[3] opened up the possibility for creating and integrating disparate Grid families that formerly used incompatible technologies. As we outline in the following review, Web Services provide a unifying architecture for diverse Grid family groups. We may begin to think of Grids as collections of services assembled for specific tasks. These services include not only traditional Grid tasks such as accessing remote high performance computing resources, but also information, collaboration, and semantic services.", "num_citations": "3\n", "authors": ["898"]}
{"title": "Matchmaking scientific workflows in grid environments\n", "abstract": " 2Department of Computer Science 3School of Informatics Indiana University Bloomington, IN 47404 gongy@ indiana. edu, mpierce@ cs. indiana. edu, and gcf@ indiana. edu Abstract In this paper we analyze the scientific workflow matchmaking problem in Grid environments and combine workflow mapping and scheduling. Based on the characteristics of Grids, a new resource model is proposed. Motivated by the observations that not all jobs can run on all resources and that resource-critical jobs should be considered with their ancestor and descendant jobs when mapping, a novel resource-critical algorithm is designed based on a new Grid resource model. By means of experiments, it is shown to have good performance.", "num_citations": "3\n", "authors": ["898"]}
{"title": "Integrating geographical information systems and grid applications\n", "abstract": " We store information gathered from users\u2019 interactions with the portal interface in a generic, recursively defined XML data structure. Typically we store input parameters and choices made by the user so that we can recover and reload these later. We also use this for monitoring remote workflows. We have devoted considerable effort into developing WS-Context to support the generalization of this initial simple service.", "num_citations": "3\n", "authors": ["898"]}
{"title": "Grid Technology Overview and Status\n", "abstract": " This white paper summarizes the current state of Grid technologies [Foster99A][Foster2004A][GGF-A][Berman03A][GapAnalysis] with particular attention to their possible relevance to DoD applications. In Section 2, we describe different types of Grids and contrast their use and implementation with clusters and massively parallel systems. A more extensive survey of such styles of Grids can be found in [GapAnalysis]. Section 3 summarizes the technologies divided into different classes. Section 4 describes the concept of \u201cGrids of Grids\u201d that is analogous to the well known \u201cSystem of Systems\u201d. This concept expresses a hierarchical system model where we do not build a single monolithic system or grid but rather stitch together a system from component subsystems or subgrids that need not be architecturally homogeneous.The review is reasonably general but there are particular comments on the work of Anabas Inc. and the Community Grids Laboratory as these highlight particular prototype opportunities. There is also special references to some existing DoD related Grid activities such as the work linking HLA and Web service technologies [XMSF1].", "num_citations": "3\n", "authors": ["898"]}
{"title": "Grid Application Areas within DoD\n", "abstract": " We divide DoD applications into broad categories and describe the possible relevance of Grid technologies. We build on an earlier report [DoDescience] produced with DoD HPCMP support. The current state of the Grid is discussed in [Foster99A][GGF-A][Berman03A] and [GapAnalysis]. There are discussions of a service-oriented architecture for DoD applications [Lau04][Birman05] and the major DoD Network centric computing and Global Information Grid activities. Currently a systematic examination of modern Grid technologies for DoD does not seem to be available. We note that the applications have many overlaps in possible relevant Grid technologies; this is to be expected as Grids and the Service architecture are meant to encourage re-use of services across both DoD domains and between DoD and non-DoD domains. One of our goals is to develop a more precise analysis of DoD requirements from a broad (unclassified) view so as to identify where DoD can take advantage of Grid and Web service activities.", "num_citations": "3\n", "authors": ["898"]}
{"title": "Messaging in Web service Grid with applications to geographical information systems\n", "abstract": " Several efforts to design globally distributed computing systems have converged to the principles of message-centric, service-oriented architectures. As realized through several Web Service specifications, these provide the scaling, robustness, and reliability for delivering distributed capabilities that collectively form virtual organizations. Service architectures are based a clean separation between service implementations and their communication patterns. In this article, we examine several consequences of this separation. First, services should exist on a general purpose, software messaging substrate. Services (and their containers) inherit various qualities of service directly from this substrate: we implement message level security, reliability, events, and notifications in the message routing middleware. Second, all communications involving services should be treated as messages. This applies not only to remote\u00a0\u2026", "num_citations": "3\n", "authors": ["898"]}
{"title": "QuakeTables: The Fault Database for QuakeSim\n", "abstract": " The QuakeSim project will provide the first web-services based, interoperable environment for doing large-scale forward models for earthquake processes. Through a web-services based portal, QuakeSim provides global access to geologic reference models of faults and fault data, simple analysis tools, new parallel forward models, and visualization support. The database system for this project must manage a variety of types of earthquake science data and information, including real and simulated data, and pre-existing structured collections containing\" validated\" data from official sources such as US and California Geological Surveys, and\" non-validated\" data sets such as Virtual California. The fault database component of QuakeSim is called QuakeTables. QuakeTables was developed using a basic public domain database management system (DBMS), MySQL, to be ported to a more fully functional relational\u00a0\u2026", "num_citations": "3\n", "authors": ["898"]}
{"title": "NaradaBrokering as Middleware Fabric for Grid-based Remote Visualization Services\n", "abstract": " Remote Visualization Services (RVS) have tended to rely on approaches based on the client server paradigm. The simplicity in these approaches is offset by problems such as single-point-of-failures, scaling and availability. Furthermore, as the complexity, scale and scope of the services hosted on this paradigm increase, this approach becomes increasingly unsuitable.", "num_citations": "3\n", "authors": ["898"]}
{"title": "A multi-party implementation of ws-secureconversation\n", "abstract": " Grid computing is an emergent computing paradigm focusing on solving the problems resource sharing in heterogeneous environments of science, engineer and commerce [1, 2, 3]. It has made significant progresses in large scale data management and access, resource naming and discovery, information services, as well as building innovative grid services to integrate existing applications. Security has been one of the most important areas in grids. Researchers on security have been isolating typical grids usage scenarios [4], identifying unique security requirements [5], and proposing efficient schemes of authentication and authorization [6, 7]. Whereas transport and network level protocols like SSL [8] and IPSec [9] provides working solutions to client-server model, they are not sufficient to meet more complicated requirements in grids. In its recent movement, grids have adopted Web services technology [1] to deal with environmental heterogeneity and to enhance service and application interoperability. As SOAP 1.2 [10] becomes widely accepted as the XML messaging standard, the limits of traditional solutions are further recognized. Group communication and its security have been thought essential to grids [5]. They have witnessed an increased interest as the popularity and diversity of collaborative applications continue to grow. Scientific cooperation in grids [2], peerto-peer online sessions [11], audio-video conferences [12], all of them use, or can benefit from using, group communications. Although the threats to the group communication are similar to those to unicast applications, because of its broad scope, approaches to solving the\u00a0\u2026", "num_citations": "3\n", "authors": ["898"]}
{"title": "Improving access to geodetic imaging crustal deformation data using GeoGateway\n", "abstract": " GeoGateway (http://geo-gateway. org) is a web-based interface for analysis and modeling of geodetic imaging data and to support response to related disasters. Geodetic imaging data product currently supported by GeoGateway include Global Navigation Satellite System (GNSS) daily position time series and derived velocities and displacements and airborne Interferometric Synthetic Aperture Radar (InSAR) from NASA\u2019s UAVSAR platform. GeoGateway allows users to layer data products in a web map interface and extract information from various tools. Extracted products can be downloaded for further analysis. GeoGateway includes overlays of California fault traces, seismicity from user selected search parameters, and user supplied map files. GeoGateway also provides earthquake nowcasts and hazard maps as well as products created for related response to natural disasters. A user guide is present in the\u00a0\u2026", "num_citations": "2\n", "authors": ["898"]}
{"title": "Integrated Model of Models for Global Flood Alerting\n", "abstract": " A dramatic increase in frequency of minor to major flooding since 2000 has caused significant economic losses across the world. To mitigate and recover from these losses, actions have been taken to build resilient communities and infrastructures, specifically, by providing situational awareness in near real-time about flood impacts to enhance response and recovery efforts. Several hydrologic and hydraulic flood models are available at various spatial and temporal resolutions to forecast flood events at regional to global scale. Given the global coverage of two operational flood models\u2013GloFAS (Global Flood Awareness System) and GFMS (Global Flood Monitoring System), the purpose of this project is to implement a Model of Models (MoM) approach to integrate the outputs from these two models to classify flood severity at watershed level worldwide, and send alerts based on severity similar to the USGS PAGER (used for severity alerting and impact analysis for earthquakes) to flood impacted communities. The alerts containing flood impacts and severity information will be disseminated through the DisasterAWARE platform, operated by the Pacific Disaster Center (PDC), that provides global multi-hazard alerting and Situational Awareness information to the emergency management community and public. The current version of the MoM approach was implemented for a case study flood event that occurred during January and February of 2020 in South and Central Africa. The findings of the case study event reveal that the approach is effective in identifying potential flood impact areas and the spatio-temporal variation of flood severity, flood depth\u00a0\u2026", "num_citations": "2\n", "authors": ["898"]}
{"title": "Integrating Science Gateways with Secure Cloud Computing Resources: An Examination of Two Deployment Patterns and Their Requirements\n", "abstract": " This paper examines scenarios in which science gateways can facilitate access to cloud computing resources to support scientific research using regulated or protected data stored on clouds. Specifically, we discuss the use of science gateways to access Controlled Unclassified Information (CUI), a US regulatory standard that covers a broad range of US federal government-owned or regulated data, and that also provides a useful proxy for other types of sensitive data, such as private sector intellectual property. We focus on the impact of CUI requirements on science gateway platforms that can be used to create and manage science gateway instances. Gateway platforms are centrally operated by gateway platform providers who create and control gateway instances on behalf of gateway providers. Broadly, platforms operate following either a multi-tenant or else a multi-instance pattern. Multi-tenanted science\u00a0\u2026", "num_citations": "2\n", "authors": ["898"]}
{"title": "DisasterAWARE\u2013A Global Alerting Platform for Flood Events\n", "abstract": " The rising number of flooding events combined with increased urbanization is contributing to significant economic losses due to damages to structures and infrastructures. From a risk reduction and resilience perspective, it is not only essential to forecast flood risk and potential impacts, but also to disseminate the information to stakeholders on the ground for rapid implementation of mitigation and response measures. This paper provides (i) an introduction to DisasterAWARE\u00ae, a global alerting system, that is used to disseminate flood risk information to stakeholders across the globe, and (ii) a discussion of the models implemented using earth observation data (Synthetic Aperture Radar and optical imagery) for near real-time assessment of flood severity and potential flood impacts to infrastructures. While the models are still in their nascent stage, a case study implementation of the models for the 2020 flooding event in Africa is presented to showcase the model integration with DisasterAWARE\u00ae.", "num_citations": "2\n", "authors": ["898"]}
{"title": "Toward Interoperable Cyberinfrastructure: Common Descriptions for Computational Resources and Applications\n", "abstract": " The user-facing components of the Cyberinfrastructure (CI) ecosystem, science gateways and scientific workflow systems, share a common need of interfacing with physical resources (storage systems and execution environments) to manage data and execute codes (applications). However, there is no uniform, platform-independent way to describe either the resources or the applications. To address this, we propose uniform semantics for describing resources and applications that will be relevant to a diverse set of stakeholders. We sketch a solution to the problem of a common description and catalog of resources: we describe an approach to implementing a resource registry for use by the community and discuss potential approaches to some long-term challenges. We conclude by looking ahead to the application description language.", "num_citations": "2\n", "authors": ["898"]}
{"title": "Building a science gateway for processing and modeling sequencing data via Apache Airavata\n", "abstract": " The amount of DNA sequencing data has been exponentially growing during the past decade due to advances in sequencing technology. Processing and modeling large amounts of sequencing data can be computationally intractable for desktop computing platforms. High performance computing (HPC) resources offer advantages in terms of computing power, and can be a general solution to these problems. Using HPCs directly for computational needs requires skilled users who know their way around HPCs and acquiring such skills take time. Science gateways acts as the middle layer between users and HPCs, providing users with the resources to accomplish compute-intensive tasks without requiring specialized expertise. We developed a web-based computing platform for genome biologists by customizing the PHP Gateway for Airavata (PGA) framework that accesses publicly accessible HPC resources via\u00a0\u2026", "num_citations": "2\n", "authors": ["898"]}
{"title": "Science Gateways Bootcamp: Strategies for Developing, Operating and Sustaining Science Gateways\n", "abstract": " Science Gateways Bootcamp: Strategies for Developing, Operating and Sustaining Science Gateways Page 1 Award Number ACI-1547611 Sandra Gesing, Michael Zentner, Juliana Casavan, Betsy Hillery, Mihaela Vorvoreanu, Randy Heiland, Suresh Marru, Marlon Pierce, Nayiri Mullinix, Nancy Maron sandra.gesing@nd.edu 16 October 2017 IWSG-A, Brisbane, Australia Science Gateways Bootcamp: Strategies for Developing, Operating and Sustaining Science Gateways Page 2 Science Gateways Survey 2014 2 What services would be helpful? \u2022 sent out to 29,000 persons \u2022 4,957 responses from across domains \u2022 52% from life, physical or mathematical sciences \u2022 32% from computer and information sciences or engineering \u2022 45% develop data collections \u2022 44% develop data analysis tools Proposed Service % Interest Evaluation, impact analysis, website analytics 72% Adapting technologies 67% Web/visual/\u2026", "num_citations": "2\n", "authors": ["898"]}
{"title": "Combined UAVSAR and GPS Estimates of Fault Slip for the M 6.0 South Napa Earthquake\n", "abstract": " Combined UAVSAR and GPS Estimates of Fault Slip for the M 6.0 South Napa Earthquake Andrea Donnellan, Jay Parker, Brian Hawkins, Scott Hensley, Cathleen Jones, Susan Owen, Angelyn Moore Jet Propulsion Laboratory, California Institute of Technology Marlon Pierce, Jun Wang Indiana University John Rundle University of California, Davis The South Napa to Santa Rosa area has been observed with NASA's UAVSAR since late 2009 as part of an experiment to monitor areas identified as having a high probability of an earthquake. The M 6.0 South Napa earthquake occurred on 24 August 2014. The area was flown 29 May 2014 preceeding the earthquake, and again on 29 August 2014, five days after the earthquake. The UAVSAR results show slip on a single fault at the south end of the rupture near the epicenter of the event. The rupture branches out into multiple faults further north near the Napa area. A\u00a0\u2026", "num_citations": "2\n", "authors": ["898"]}
{"title": "Genapp module execution and airavata integration\n", "abstract": " A new framework (GenApp) for rapid generation of scientific applications running on a variety of systems including science gateways has recently been developed. This framework builds a user interface for a variety of target environments on a collection of executable modules. The method for execution of the modules is unrestricted by the framework. Initial implementation supports direct execution, and not queue managed submission, on a user's workstation, a web server, or a compute resource accessible from the web server. After a successful workshop, it was discovered that long running jobs would sometimes fail, due to the loss of a TCP connection. This precipitated an improvement to the execution method with the bonus of easily allowing multiple web clients to attach to the running job. Finally, to support a diversity of queue managed compute resources, a Google Summer of Code project was completed to\u00a0\u2026", "num_citations": "2\n", "authors": ["898"]}
{"title": "US-SOMO cluster methods: year one perspective\n", "abstract": " UltraScan Solution Modeler (US-SOMO) computes hydrodynamic parameters and small-angle scattering data from biological macromolecular structural representations and compares them with experimental data for structural determination and validation. At XSEDE 12, a GUI integrated gateway was introduced to offload large computations to various HPC resources. The gateway was directly integrated into the Qt/GUI based software to allow the users a seamless experience. The software is available as source code or precompiled for Apple Mac OSX, MS-Windows and Linux. Current cluster resources include TACC Lonestar and Stampede, SDSC Trestles and a 256 CPU cluster local to the University of Texas Health Science Center at San Antonio. The simplicity of design allowed the implementation of a new method of modeling small angle scattering data that provided new scientific insights and was presented\u00a0\u2026", "num_citations": "2\n", "authors": ["898"]}
{"title": "Science gateways and the importance of sustainability\n", "abstract": " This fundamental impact extends to the scientific realm as well. Modern science now depends on the Web. Truly impactful websites are created by scientists all the time. Some are developed to fulfill the needs of small research teams. Others are built to address the needs of a large community. Most are completely open and publicly accessible. Increasingly, they are accessible via mobile devices. We call these Web and mobile interfaces science gateways.Formally, a science gateway is a communitydeveloped set of tools, applications, and data collections that are integrated through a portal or a suite of applications [Wilkins-Diehr 2007]. Science gateways enable entire communities of users with a common scientific goal to use digital resources through a single interface, even when such resources are geographically distributed. The digital resources in this context could be anything from a highly tuned parallel application running on a supercomputer to a catalogued and cross-referenced data collection with built in analysis capabilities to a forum for sharing and rating educational course content and usercontributed analysis tools. Science gateways provide value-added interfaces to access these shared resources.", "num_citations": "2\n", "authors": ["898"]}
{"title": "Web service andworkflow abstractions to large scale nuclear physics calculations\n", "abstract": " This paper discusses the web service and scientific workflow abstractions to next generation ab initio computational nuclear physics resources as part of the Leadership Class Configuration Interaction (LCCI) Environment. These abstractions will rapidly and efficiently involve new collaborators and graduate students in productive research. The workflow infrastructure democratizes the access to the nuclear physics simulations executing on remote supercomputing resources. The paper focuses on employing an open community based workflow system in developing and deploying LCCI infrastructures. The paper also emphasizes on the enhancements made to infrastructure to add advanced workflow capabilities providing greater flexibility in handling parametric sweeps and provenance aware workflows. The paper discusses on how the provenance integration will not only capture execution trace but dynamically\u00a0\u2026", "num_citations": "2\n", "authors": ["898"]}
{"title": "Investigating the use of gadgets, widgets, and opensocial to build science gateways\n", "abstract": " Many science applications require more and more computing power as the amount of input data keeps increasing. To simplify using large-scale clusters and complicated application codes, and to facilitate cross-disciplinary collaboration, there has been substantial research and development work on Web-based science gateways. With numerous gateways needing to be developed for many different scientific domains, there has also been a long-standing need for reusable codes and extensible component models. During the previous decade, the component model for many gateways was the Java portlet. To overcome some of the port let model's limitations, new gateways take a different approach that utilizes modern Web technologies. In this paper, we examine the use of new standards such as Open Social, Gadgets, and W3C Widgets to build science gateway user interfaces. These standards overcome many\u00a0\u2026", "num_citations": "2\n", "authors": ["898"]}
{"title": "AVATS: Audio-video and textual synchronization\n", "abstract": " In this paper, we explain the architecture and provide implementation details of a synchronous collaborative tool we created using a lightweight Web 2.0 mash-up development methodology. This approach allowed us to put together a client interface with reasonable capabilities, scalability, and robustness rapidly. The rapid development of this tool also allowed us to perform thorough testing and incorporation of the system in a live, production environment in a relatively short amount of time.", "num_citations": "2\n", "authors": ["898"]}
{"title": "Unified Data Access/query over Integrated Data-views for Decision Making in Geographic Information Systems\n", "abstract": " Geographic information is critical for building disaster planning, crisis management, and early-warning systems. Decision making in geographic information systems (GIS) increasingly relies on analyses of spatial data in map-based formats. Maps are complex structures composed of layers created from distributed heterogeneous data belonging to the separate organizations. This chapter presents a distributed service architecture for managing the production of knowledge from distributed collections of observations and simulation data through integrated data-views. Integrated views are defined by a federation service (\u201cfederator\u201d) located on top of the standard service components. Common GIS standards enable the construction of this system. However, compliance requirements for interoperability, such as XML-encoded data and domain specific data characteristics, have costs and performance overhead. The\u00a0\u2026", "num_citations": "2\n", "authors": ["898"]}
{"title": "Information federation in Grids\n", "abstract": " Independent grid projects have developed their own solutions to information services. These solutions are not interoperable with each other, target vastly different systems and address diverse sets of requirements. To address these challenges, we designed a novel architecture for a grid information service that provides unification, federation and interoperability of major grid information services. The proposed approach forms an add-on information system that interacts with the local information services and assembles their metadata instances. We introduce a prototype implementation and present its evaluation. The results indicate that the proposed approach achieves unification and federation of custom implementations of grid information services with negligible processing overheads.", "num_citations": "2\n", "authors": ["898"]}
{"title": "Special Issue Editorial Introduction: Grids and Geospatial Information Systems\n", "abstract": " Grids and Geospatial Information Systems (GIS) are both based on distributed service architectures and have complementary capabilities. GIS systems provide a comprehensive set of services for managing maps, geospatial data sets, and geospatial information that can be applied to areas ranging from access to scientific data by researchers to disaster planning and emergency management. The data and information focus of GIS are being augmented with the computational and virtual organization capabilities of Grid computing by many projects, including the ones by the contributors to this special issue. This editorial introduction serves as an overview of the issues discussed at the GIS\u2010Grid Workshop in the Open Grid Forum and the follow\u2010on papers of this special issue. Copyright \u00a9 2008 John Wiley & Sons, Ltd.", "num_citations": "2\n", "authors": ["898"]}
{"title": "Modeling and on-the-fly solutions for solid earth sciences: Web services and data portal for earthquake early warning system\n", "abstract": " We report on a unified on-the-fly, Web services-based observation/analysis/modeling environment for crustal deformation and natural hazards research, intended as a plug-in service for early warning systems, transfer of rapid information to civilian decision makers and the media, and educational purposes. We demonstrate an early warning system for a large earthquake in southern California using the components developed under several NASA-funded projects, including real-time GPS network infrastructure, Geophysical Resources Web Services, and GPS Explorer data portal with its on-the-fly earthquake modeling software. We generate an on-the-fly earthquake fault model based on simulated real-time (dynamic and coseismic) displacements computed by the GPS network, and viewable through GPS Explorer. Our objective is to demonstrate an operational service that could be transitioned to appropriate\u00a0\u2026", "num_citations": "2\n", "authors": ["898"]}
{"title": "Distributed high performance grid information service\n", "abstract": " We introduce a distributed high performance Grid Information Service Architecture, which forms a metadata replica hosting system to manage both highly-dynamic, small-scale and relatively-large, static metadata associated to Grid/Web Services. We present an empirical evaluation of the proposed architecture and investigate its practical usefulness. The results demonstrate that the proposed system achieves high-performance and fault-tolerance with negligible processing overheads. The results also indicate that efficient decentralized Grid Information Service Architectures can be built by utilizing publish-subscribe based messaging schemes.", "num_citations": "2\n", "authors": ["898"]}
{"title": "JavaScript Grid Abstractions\n", "abstract": " In this paper, we describe a Grid abstraction framework that allows access to the Grid infrastructure using JavaScript while leveraging the power of current Grid middleware and upperware toolkits such as the Globus Toolkit and the Java Commodity Grid (CoG) Kit. The system is heavily based on Web 2.0 technologies and allows accessing the Grid through a Service-Oriented Architecture. An application interface in JavaScript is provided to enable developers to access Grid services from JavaScript. Moreover, our framework includes additional services to enable the creation of advanced Grid services. The availability of our framework simplifies not only the development of new services but also the development of advanced client side Grid applications. We demonstrate this ability while providing a mechanism to develop Grid workflows through advanced services and a graphical user interface defined in JavaScript. Overall, Grid developers will have another tool at their disposal that projects a simpler way to distribute and maintain software while at the same time being able to deliver quickly advanced interfaces and social services for the scientific community.", "num_citations": "2\n", "authors": ["898"]}
{"title": "Architecture for high-performance web service communications using an information service.\n", "abstract": " It is critical to address potential performance problems of XML-based SOAP to design a Web Service communication framework for mobile devices, as the mobile computing environment is physically constrained to limited computing power and network bandwidth. In this paper, we describe a Web Service communication framework for mobile computing, which optimizes SOAP message contents. The performance and efficiency of Web Service messaging can be significantly improved by removing the redundant or unchanging parts of SOAP messages. This paper shows that the redundant or static parts of a SOAP message may be treated as metadata and stored in a shared metadata space, for which we integrate our optimized Web Service communication framework with an information service. We evaluate our architecture through a benchmark testing of the resulting system. The empirical result shows that we save on average 83% of message size and on average 41% of transit time.", "num_citations": "2\n", "authors": ["898"]}
{"title": "Web Service Information Systems and Applications\n", "abstract": " As the Service Oriented Architecture (SOA) principles have gained importance, an emerging need has appeared for methodologies to locate desired services that provide access to their capability descriptions. Also, as these services interact with each other within a workflow session to produce a common functionality such as earthquake prediction [PI], another emerging need has also appeared for storing, querying, and sharing the resulting metadata needed to describe session state information.In SOA-based Grids, Information Services support the discovery and handling of both static and session-related, transitory metadata associated to services. Here, we discuss the limitations in existing Information Services and introduce a novel system as a solution. We design a hybrid Information Service supporting both large amounts of relatively slowly varying data and rapidly updated, dynamically generated information.", "num_citations": "2\n", "authors": ["898"]}
{"title": "Building sensor filter grids: Information architecture for the data deluge\n", "abstract": " We discuss a general architectural approach to knowledge and information management and delivery in distributed systems. Our approach is based on the recognition that time-stamped, streaming information message units form the core of seemingly disparate systems that range from online sensors and scientific instruments to Web information retrieval. Globally distributable grid services manage these information streams. Geographical information system services provide exemplary realizations of this picture and may be used as a model for other scientific domains. With this unified architecture in place, we may begin to consider the problems of information integration as equivalent to sensor federation.", "num_citations": "2\n", "authors": ["898"]}
{"title": "Instantiations of shared event model in grid-based collaboration\n", "abstract": " The Internet is a global infrastructure that brings resources and people together. Diverse fields are prospering on it, such as Grid computing and collaboration. We demonstrate the Grid-based Collaboration idea by making three interface applications collaborative between computers over networks, using a common message broker as the underlying communication system. To achieve the global collaboration, we have brought together in the research a Grid-based Collaboration paradigm, a Shared Event model, different implementing structures, methodologies and technologies. We describe the applications\u2019 event structures in messages coordinating the Grid-base collaboration. We further abstract the collaboration of the applications to be collaboration between paradigms with message as the glue or the key, and point out the implications from this.", "num_citations": "2\n", "authors": ["898"]}
{"title": "The QuakeSim Project: numerical simulations for active tectonic processes.\n", "abstract": " In order to develop a solid earth science framework for understanding and studying of active tectonic and earthquake processes, this task develops simulation and analysis tools to study the physics of earthquakes using state-of-the art modeling, data manipulation, and pattern recognition technologies. We develop clearly defined accessible data formats and code protocols as inputs to the simulations. these are adapted to high-performance computers because the solid earth system is extremely complex and nonlinear resulting in computationally intensive problems with millions of unknowns. With these tools it will be possible to construct the more complex models and simulations necessary to develop hazard assessment systems critical for reducing future losses from major earthquakes.", "num_citations": "2\n", "authors": ["898"]}
{"title": "A Java-based Web Interface to Matlab\n", "abstract": " This paper discusses the development of an alternative method for deploying Matlab applications over the Web. The system developed here aims at overcoming many of the limitations of the Matlab Web Server, resulting in a more interactive online Matlab experience. Using the MATLAB-Java interface available in the recent releases of MATLAB, our system provides the web interface through the use of Java Servlets and custom Java classes. As shown in Fig. 1, a multithreaded socket is used to start a new Matlab process for every user that logs into the system. Once the Matlab process for a user has been started, all communication between the user and Matlab process is facilitated by the servlet and the Java socket opened by Matlab. This allows each user to have a workspace that is preserved until hisher Matlab process exits. This also has the advantage that no additional server-side programming is needed specifically to save user data and have a unique identifier to associate it with the user.Descriptors:", "num_citations": "2\n", "authors": ["898"]}
{"title": "Online Knowledge Center Tools for Metadata Management\n", "abstract": " We describe the design and implementation of an XML metadata management system for creating, delivering and managing general metadata. We describe message composition wizards, a multipurpose delivery system implementation, and message access role definitions. This system may be used as the foundation for both human readable messaging (such as newsgroups and citation management systems) as well as eventdriven application-to-application systems. We describe in detail the design of an Access Control System.", "num_citations": "2\n", "authors": ["898"]}
{"title": "Developing Secure Web Services for Computational Portals.\n", "abstract": " Computational web portals provide uniform access to remote computational resources--hardware, software, and data--by hiding the complexity of the heterogeneous, distributed, high performance computing back end. These portal services may be implemented in a programming-language and platform independent way using a Web services approach. However, security in Web services for distributed computing systems is an open issue involving multiple security mechanisms and competing standards. In this paper we present an implementation of a flexible, message-based security system that can be bound to multiple mechanism and multiple message formats.", "num_citations": "2\n", "authors": ["898"]}
{"title": "An Architecture for e-Science and its Implications\n", "abstract": " We describe Peer-to-Peer Grids built around Integration of technologies from the peer-to-peer and Grid fields. We focus on the role of a powerful event services using uniform XML interfaces and application level routing. We describe a research system Narada and compare with JXTA (Peer-to-Peer) and JMS (Java Message Service) giving some initial performance results.1 e-ScienceOver the last decade or so, there has been dramatic progress in the application of computing to scientific and engineering research. There were several major initiatives such as the HPCC (High Performance Computing and Communications) program and the set of NSF Grand Challenge projects, which largely focused on this. The parallel computing emphasis of the early nineties has shifted with newer programs such as ITR (Information Technology Research) from NSF. The new centerpiece is research in", "num_citations": "2\n", "authors": ["898"]}
{"title": "SERVOGrid Technical Documentation\n", "abstract": " Geographical Information Systems (GIS) introduce methods and environments to visualize, manipulate, and analyze geospatial data. The nature of the geographical applications requires seamless integration and sharing of spatial data from a variety of providers. Interoperability of services across organizations and providers is a main goal for GIS and also Grid computing [Berman2003, Foster2004].To solve the interoperability problems, the Open Geospatial Consortium (OGC) has introduced standards by publishing specifications for the GIS services. OGC is a non-profit, international standards organization that is leading the development of standards for geographic data related operations and services. OGC has variety of contributors from different areas such as private industry and academia to create open and extensible software application programming interfaces for GIS [gis].", "num_citations": "2\n", "authors": ["898"]}
{"title": "Clustering Analysis Methods for GNSS Observations: A Data-Driven Approach to Identifying California's Major Faults\n", "abstract": " We present a data-driven approach to clustering or grouping Global Navigation Satellite System (GNSS) stations according to their observed velocities, displacements or other selected characteristics. Clustering GNSS stations has the potential for identifying useful scientific information, and is a necessary initial step in other analysis, such as detecting aseismic transient signals (Granat et. al., 2013). Desired features of the data can be selected for clustering, including some subset of displacement or velocity components, uncertainty estimates, station location, and other relevant information. Based on those selections, the clustering procedure autonomously groups the GNSS stations according to a selected clustering method. We have implemented this approach as a Python application, allowing us to draw upon the full range of open source clustering methods available in Python\u2019s scikit-learn package (Pedregosa et\u00a0\u2026", "num_citations": "1\n", "authors": ["898"]}
{"title": "The Quakes Concept for Observing and Mitigating Natural Disasters\n", "abstract": " Geodetic imaging is useful for measuring topography and motions of the Earth's surface. Geodetic imaging measurements can be used, for example, to measure earthquakes, landslides, debris flows, wildfire extent, volcanos, and anthropogenic changes such as fluid withdrawal from aquifers. Different geodetic measurements sample different parts of the spatio-temporal deformation field. Combining the measurements and analysis improves understanding of a broad range of Earth surface processes. Here we describe a concept to Quantify Uncertainty and Kinematics of Earth Systems (QUAKES) that combines radar interferometry and optical imaging into one airborne platform and the analysis system required to analyze and model the data.", "num_citations": "1\n", "authors": ["898"]}
{"title": "The distant reader: Tool for reading\n", "abstract": " The Distant Reader science gateway can be used to automatically create and analyze text corpora at a scale of thousands of user-supplied documents. These processing steps are deployed on a dynamic virtual cluster deployed on XSEDE's Jetstream academic cloud computing resource and are accessed through a Web interface. The science gateway uses Apache Airavata middleware to manage the interactions between the Web interface and the virtual clusters. The gateway leverages the Science Gateway Platform as a service (SciGaP) infrastructure at Indiana University, which provides user authentication, authorization, and identity management as well as access to the Distant Reader tools. The Distant Reader is designed to assist in the process of using & understanding corpora--reading.", "num_citations": "1\n", "authors": ["898"]}
{"title": "Interactwel science gateway for adaptation planning in food-energy-water sectors of local communities\n", "abstract": " Since their inception in mid 2000s, adoption of Science Gateways as interfaces and conduits for digital infrastructure needed in science and engineering research and education has significantly increased. This trend has also driven changes in the types of services and resources that are now being expected from the Science Gateways by a growing group of diverse end users. In this poster, we present a novel Science Gateway, InterACTWEL (Interactive Adaptation and Collaboration Tool for managing Water, Energy and Land), which serves as a research cyberinfrastructure as well as an applied decision support system for adaptive natural resources management in interdependent food, energy, and water sectors. End users of this gateway include not only interdisciplinary technical and social science researchers, but also public and private sectoral stakeholders. The gateway is a collaboration between Oregon\u00a0\u2026", "num_citations": "1\n", "authors": ["898"]}
{"title": "Science Gateway Implementation at the University of South Dakota: Applications in Research and Education\n", "abstract": " Science Gateways are virtual environments that accelerate scientific discovery by enabling scientific communities to more easily and effectively utilize distributed computing and data resources. Successful Science Gateways provide access to sophisticated and powerful resources, while shielding their users from the underlying complexities. Here we present work completed by the University of South Dakota (USD) Research Computing Group in conjunction with the Science Gateways Community Institute (SGCI)[1] and Indiana University on setting up a Science Gateway to access USD's high-performance computing resources. These resources are now available to both faculty and students and allow ease of access and use of USD's distributed computing and data resources. The implementation of this gateway project has been multifaceted and has included placement of federated user login, user facilitation and\u00a0\u2026", "num_citations": "1\n", "authors": ["898"]}
{"title": "Cyberinfrastructure as a platform to facilitate effective collaboration between institutions and support collaboratories\n", "abstract": " Researchers, scientists, engineers, granting agencies, and increasingly complex research problems have given rise to the scientific\" collaboratory\" large organizations that span many institutions, with individual members working together to explore a particular phenomenon. These organizations require computational resources in order to support analyses and to provide platforms where the collaborators can interact. The XSEDE Community Infrastructure (XCI) group assists campuses in using their own resources and promotes the sharing of those resources in order to create collaboratories improving use of the nation's collective cyberinfrastructure. Currently XCI provides toolkits and training, and collaborates with organizations such as ACI-REF, XSEDE Campus Champions, and the Open Science Grid to identify tools and best practices that support the community. This paper discusses the progress in and barriers\u00a0\u2026", "num_citations": "1\n", "authors": ["898"]}
{"title": "Sharpening peripheral dose gradient via beam number enhancement from patient head tilt for stereotactic brain radiosurgery\n", "abstract": " Sharp dose fall-off is the hallmark of brain radiosurgery for the purpose of delivering high dose radiation to the target while minimizing peripheral dose to regional normal brain tissue. In this study, a technique was developed to enhance the peripheral dose gradient by magnifying the total number of beams focused toward each isocenter through pre-programmed patient head tilting. This technique was tested in clinical settings on a dedicated brain radiosurgical system (GKPFX, Gamma Knife Perfexion, Elekta Oncology) by comparing dosimetry as well as delivery efficiency for 20 radiosurgical cases previously treated with the system. The 3-fold beam number enhancement (BNE) treatment plans were found to produce nearly identical target volume coverage (absolute value< 0.5%, P> 0.2) and dose conformity (BNE CI= 1.41\u00b10.22 versus 1.41\u00b10.11, P> 0.99) as the original treatment plans. The total beam-on time for\u00a0\u2026", "num_citations": "1\n", "authors": ["898"]}
{"title": "CTSC Recommended Security Practices for Thrift Clients: Case Study-Evernote\n", "abstract": " The Science Gateway Platform (SciGaP,\u200b scigap. org\u200b) will provide services to help communities create Science Gateways. SciGaP (via Apache Airavata) will use the Apache Thrift framework (\u200b thrift. apache. org\u200b), a languageindependent, richly typed interface definition language (IDL) to generate both client and server software development kits (SDKs). Thrift takes a departure from many public services in that it is not a RESTful (\u200b http://en. wikipedia. org/wiki/Representational_state_transfer\u200b) API.", "num_citations": "1\n", "authors": ["898"]}
{"title": "Chaining Data and Visualization Web Services for Decision Making in Information Systems\n", "abstract": " Decision making in information systems increasingly relies on analyses of data in visual formats which are created from distributed heterogeneous data belonging to the separate organizations. This paper presents distributed service architecture for creating and managing the production of knowledge from distributed collections of data sources through integrated dataviews. Web Services provide key low level capability but do not define an information or data architecture. These are left to domain specific capabilities metadata and domain specific common data model. Datasets are considered to be defined with domain specific spatial and non-spatial attributes for displaying and querying. We propose blueprint architecture and define the principles and requirements for general information systems domains.", "num_citations": "1\n", "authors": ["898"]}
{"title": "Designing a Roadmap for Workflow Cyberinfrastructure in the Geosciences: From Big Data to the Long Tail\n", "abstract": " Scientific activities can be seen as collections of interdependent steps represented as workflows. Gathering and analyzing data, coordinating computational experiments, and publishing results and data products are organized activities traditionally captured in research notebooks. Today we have the ability to digitally codify much of these activities, particularly for computational experiments, using workflow technologies. Workflows may be used to execute enormous computations, to combine distributed data and computing resources in novel ways, and to guide scientists through complex processes. When combined with metadata and provenance-capturing capabilities, workflows allow reproducibility of results, increased efficiency, and enhanced publications. The challenge before us is to make these tools ubiquitously available, enhanced, and adopted for the geosciences. The EarthCube Workflows Community\u00a0\u2026", "num_citations": "1\n", "authors": ["898"]}
{"title": "E-DECIDER: Earthquake Disaster Decision Support and Response Tools-Development and Experiences\n", "abstract": " Earthquake Data Enhanced Cyber-Infrastructure for Disaster Evaluation and Response (E-DECIDER) is a NASA-funded project developing new capabilities for decision-making utilizing remote sensing data and modeling software to provide decision support for earthquake disaster management and response. The overall goal of the project is to deliver these capabilities as standards-compliant Geographical Information System (GIS) data products through a web portal/web services infrastructure that will allow easy use by decision-makers; this design ensures that the system will be readily supportable and extensible in the future. E-DECIDER is incorporating the earthquake forecasting methodology developed through NASA's QuakeSim project, as well as other QuakeSim geophysical modeling tools. Remote sensing and geodetic data, in conjunction with modeling and forecasting tools, will allow us to provide both\u00a0\u2026", "num_citations": "1\n", "authors": ["898"]}
{"title": "A Concept for the One Degree Imager (ODI) Data Reduction Pipeline and Archiving System\n", "abstract": " The One Degree Imager (ODI), currently being built by the WIYN Observatory, will provide tremendous possibilities for conducting diverse scientific programs. ODI will be a complex instrument, using non-conventional Orthogonal Transfer Array (OTA) detectors. Due to its large field of view, small pixel size, use of OTA technology, and expected frequent use, ODI will produce vast amounts of astronomical data. If ODI is to achieve its full potential, a data reduction pipeline must be developed. Long-term archiving must also be incorporated into the pipeline system to ensure the continued value of ODI data.", "num_citations": "1\n", "authors": ["898"]}
{"title": "Gateway Hosting at Indiana University\n", "abstract": " The gateway hosting service at Indiana University provides science gateways and portals with hosting resources to facilitate the use of computation resources and storage within the TeraGrid. This service is designed with high availability in mind and is deployed across the Indianapolis and Bloomington campuses with redundant network, power, and storage. The service uses OpenVZ [1] to give each gateway or portal its own virtual environment while making the most efficient use of the hardware and administrative resources. OpenVZ\u2019s user beancounter quota system and fair-share scheduling for processes and I/O allows fair distribution of resource between virtual machines while allowing full utilization of the hardware. The ability to do live migration allows kernel updates without service interruption. Indiana University\u2019s research network provides multiple low latency high bandwidth connections between campuses, other TeraGrid resource providers, and the Internet at large. The service is in use by a variety of projects such as FlyBase and TeraGrid Information Services and, since the service was put into production in August 2008, there have been 5.37 hours of down time.", "num_citations": "1\n", "authors": ["898"]}
{"title": "Principles and experiences: building a hybrid metadata service for Service Oriented Architecture based grid applications\n", "abstract": " To link multiple varying Grids together, there is a need for an Information System which will act as a translator for accessing information from other Grid\u2019s Information Services. This study discusses principles and experiences in building a novel architecture of a Hybrid Service, which provides unification, federation and interoperability of different XML metadata services, and presents a performance evaluation of the prototype implementation. The results indicate that the Hybrid Service achieves information integration with negligible processing overheads while preserving persistency of information.", "num_citations": "1\n", "authors": ["898"]}
{"title": "Architecture for scalable, distributed database system built on multicore servers\n", "abstract": " Many scientific fields routinely generate huge datasets. In many cases, these datasets are not static but rapidly grow in size. Handling these types of datasets, as well as allowing sophisticated queries necessitates efficient distributed database systems that allow geographically dispersed users to access resources and to use machines simultaneously in anytime and anywhere. In this paper we present the architecture, implementation and performance analysis of a scalable, distributed database system built on multicore systems. The system architecture makes use of a software partitioning of the database based on data clustering, termed the SQMD (Single Query Multiple Database) mechanism, a web service interface and multicore server technologies. The system allows uniform access to concurrently distributed databases over multicore servers, using the SQMD mechanism based on the publish/subscribe paradigm. We highlight the scalability of our software and hardware architecture by applying it to a database of 17 million chemical structures. In addition to simple identifier based retrieval, we will present performance results for shape similarity queries, which is extremely, time intensive with traditional architectures.", "num_citations": "1\n", "authors": ["898"]}
{"title": "Grids meet too much computing, too much data and never too much simplicity\n", "abstract": " Grids are taking too long to solve the wrong problem at the wrong point in stack with a complexity that makes friendly usability difficult. We furthermore observe that Grids (as envisioned c. 2001) are being pressured by both emerging new computing resources (multicore, cell processors, GPUs, reconfigurable computing, etc) and alternative approaches to service architectures (collectively, Web 2.0). We thus believe it is time to reappraise Grids\u2014both the nature of the resources that they aggregate and the middleware that glues these resources together.", "num_citations": "1\n", "authors": ["898"]}
{"title": "GPS Sensor Web Time Series Analysis Using SensorGrid Technology\n", "abstract": " We present a method for performing signal detection and classification on real-time streams of GPS sensor web data. Our approach has two parts. The first is a hidden Markov model fitting methodology that enables us to robustly describe the statistics of the data. The second is the SensorGrid technology which allows us to manage the data streams through a series of filters tied together with a publish/subscribe messaging system. In this framework, the HMM algorithm is viewed as a filter. The sensor web data we use in this work comes from the Southern California Integrated GPS Network (SCIGN), which produces a number of data products. In this work, we use the real-time (1Hz for most stations) three-dimensional position information. This data is collected from a system which is not only noisy but also poorly understood; driving forces on the system derive not only from the physical processes of the solid earth but\u00a0\u2026", "num_citations": "1\n", "authors": ["898"]}
{"title": "Collaboration entities on deterministic finite automata\n", "abstract": " We have developed several types of collaborative applications. They are realizations of the Shared Event Model in Grid-base Collaboration, and examples of Peerto- Peer Grid computing. Each application type consists of collaboration entities, and they play different roles in collaboration. These entities are finite automaton-based in a collaboration session; in essence, they are just deterministic finite automata in the session. Intuitively, the entities in collaboration collaborate on events to keep showing the same output displays at each step, with one entity in controlling by capturing events, generating and sending out event messages to the others through a message broker, and the others in responding by rendering the received event messages. Specifically, they collaborate to share a common finite automaton in their respective instantiations, and reach a common state of the finite automaton at any collaboration\u00a0\u2026", "num_citations": "1\n", "authors": ["898"]}
{"title": "Thin Client Collaboration Web Services\n", "abstract": " In this paper we introduce some collaboration applications, and the needs in changing them to Web Services. We propose and describe the idea of Thin Client Collaboration Web Services, and explore some potential scenarios of this idea in which it shows its merit and the freedom resulted in collaboration. Such a Web Service has two sets of ports: Userfacing Input/Output ports and Resource-facing Input/Output ports. The user-facing I/O contacts a Web Service viewer, and the resource-facing I/O contacts a collaboration application. Hence, the role of the Web Service is to transcode in both directions between the two sets of ports with respect to displays and events, so that the user accesses the Web Service viewer as if the collaboration application itself. We use three collaborative applications as resources, and projects in SVG as the demonstration of our initial effort in the implementation of a General Thin Client\u00a0\u2026", "num_citations": "1\n", "authors": ["898"]}
{"title": "GlobalMMCS collaborative clients and services for portals\n", "abstract": " GlobalMMCS is a scalable, integrated and service-oriented collaboration system, which can support conferencing, instant message and whiteboard. This paper describes our work on building an integrated collaborative portal to GlobalMMCS services. Java Media Framework (JMF), a platform-independent multimedia programming framework is used to develop a high efficient conferencing client named Global-MMCS AVPortlet. A collaborative GUI container called XGSP node manager is able to incorporate different applications including this AVPortlet. And a JSP based web portal is also built to support highlevel session management and collaboration control.", "num_citations": "1\n", "authors": ["898"]}
{"title": "Smart Mining of Drug Discovery Information: 1. A web service and workflow infrastructure\n", "abstract": " The vast increase of pertinent information available to drug discovery scientists means that there is strong demand for tools and techniques for organizing and intelligently mining this information for manageable human consumption. At Indiana University, we are developing techniques for \u201csmart mining\u201d of this information, based on web services, workflows, and a variety of client interfaces. In this paper, we introduce our model and describe how workflows of web services can be used to achieve the first steps of this vision, including bridging chemical and biological information.", "num_citations": "1\n", "authors": ["898"]}
{"title": "Complexity Computational Environment: Data Assimilation SERVOGrid\n", "abstract": " We are using Web (Grid) service technology to demonstrate the assimilation of multiple distributed data sources (a typical data gridproblem) into a major parallel high-performance computing earthquake forecasting code. Such a linkage of Geoinformatics with Geocomplexity demonstrates the value of the Solid Earth Research Virtual Observatory (SERVO) Grid concept, and advance Grid technology by building the first real-time large-scale data assimilation grid Here we develop the next steps for both the SERVO concept and the identified need for a Solid Earth problem-solving environment. We use a challenging motivating problem of importance to NASA namely integrating NASA space geodetic observations with numerical simulations of a changing earth.", "num_citations": "1\n", "authors": ["898"]}
{"title": "Demonstrating NaradaBrokering as a Middleware Fabric for Grid-based Remote Visualization Services\n", "abstract": " Remote Visualization Services (RVS) have tended to rely on approaches based on the client server paradigm. Here we demonstrate our approach-based on a distributed brokering infrastructure, NaradaBrokering [1]-that relies on distributed, asynchronous and loosely coupled interactions to meet the requirements and constraints of RVS. In our approach to RVS, services advertise their capabilities to the broker network that manages these service advertisements. Among the services considered within our system are those that perform graphic transformations, mediate access to specialized datasets and finally those that manage the execution of specified tasks. There could be multiple instances of each of these services and the system ensures that load for a given service is distributed efficiently over these service instances.", "num_citations": "1\n", "authors": ["898"]}
{"title": "the Solid Earth Research Virtual Observatory\n", "abstract": " Under the auspices of NASA we are developing the Solid Earth Research Virtual Observatory (SERVO). The initial focus of the observatory is spaced-based observational data, ground-based sensor data (GPS, seismicity), simulation data, and published/historical fault measurements, coupled with earthquake fault and tectonic modeling and pattern recognition software. This observatory will enable investigators to seamlessly merge multiple data sets and models, and create new queries. In the SERVO framework, simulation data will be archived together with analysis/animation tools and the original simulation code. Observational data, which is heterogeneous and distributed in nature, will be accessible through cooperative federated databases. SERVO will include tools for visualization, datamining and pattern recognition, with data fusion into a web services (portal) based Problem Solving Environment (PSE\u00a0\u2026", "num_citations": "1\n", "authors": ["898"]}
{"title": "Access Control System Using Web Services for XML Messaging Systems.\n", "abstract": " We describe the design of an Access Control System using Web Services for information and content management. In this paper we described the solution for control mechanism of the information systems which have unique message id, requesting and giving permissions to different channels, and accessibility of the user to the specific channels by giving permissions to the user to use XML Messaging Systems using Web Services. This paper presents an overview of the research efforts undertaken by our group to build access control services around a Web Services model.", "num_citations": "1\n", "authors": ["898"]}
{"title": "The Solid Earth Research Virtual Observatory: A web-based system for modeling multi-scale earthquake processes\n", "abstract": " We are building a new Problem Solving Environment for use by the seismological, crustal deformation, and tectonics communities for developing an understanding of active tectonic and earthquake processes. The top-level operational architecture of our solid earth research virtual observatory (SERVO) shows science users interacting with interface programs as well as modeling, simulation, and analysis tools. The general architecture follows the\" Web Services\" model being developed by business interests, but is applied to scientific applications and supporting software resources (such as databases). The system is divided into three tiers: a user interface layer (implemented as a browser interface), a system resource layer, and a middle control layer that maintains proxies (or brokers) to the system resources. The middle tier provides a uniform interface to the resource layer. Following the Web Services approach, we\u00a0\u2026", "num_citations": "1\n", "authors": ["898"]}
{"title": "An Open Source Managed File Transfer Framework for Science Gateways\n", "abstract": " Abstract\u200b\u2014Managed File Transfer (MFT) systems are cyberinfrastructure that provide higher level functionalities on top of basic point-to-point data transfer protocols such as FTP, HTTP, and SCP. This paper presents an open source MFT system that incorporates science gateway requirements. We describe the system requirements, system architecture, and core capabilities.", "num_citations": "1\n", "authors": ["898"]}
{"title": "A Web based CCBR Recommender System for Ontology aided Metadata Discovery\n", "abstract": " We introduce a web based Conversational Case-Based Reasoning Recommender system utilizing semantic web markup languages as standard way of case representation and focusing particularly in metadata discovery within resource-intensive environments. We present our initial efforts in designing and developing ontologies for an Earthquake Simulation Grid. We describe implementation details of our application. We discuss our methodology in creating the RDF representation of the CBR cases.", "num_citations": "1\n", "authors": ["898"]}
{"title": "Performance Measurements for NaradaBrokering enhanced GridFTP\n", "abstract": " In this paper, we discuss reliable and secure file transfer middleware called NaradaBrokering. It is our goal to show that reliability features can be decoupled from the implementation of the service and protocol, and instead placed into the messaging substrate. This will allow us to provide file transfer quality of service comparable to GridFTP in other file transfer tools (such as normal FTP, SCP, HTTP uploads, and similar mechanisms).", "num_citations": "1\n", "authors": ["898"]}
{"title": "The Solid Earth Research Virtual Observatory: Web Services for Managing Geophysical Data and Applications\n", "abstract": " We describe our distributed systems research efforts to build the \u201ccyberinfrastructure\u201d components that constitute a geophysical Grid, or more accurately, a Grid of Grids. Service-oriented computing principles are used to build a distributed infrastructure of Web accessible components for accessing data and scientific applications. Our data services fall into two major categories: archival, database-backed services based around Geographical Information System (GIS) standards, and streaming services that can be used to filter and route real-time data sources such as Global Positioning System data streams. Execution support services include application execution management services and services for transferring remote files. These data and execution service families are bound together through metadata information and workflow services for service orchestration. Users may access the system through the QuakeSim scientific Web portal, which is built using a portlet component approach.", "num_citations": "1\n", "authors": ["898"]}