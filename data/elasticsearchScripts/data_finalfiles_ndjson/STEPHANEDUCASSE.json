{"title": "Object-oriented reengineering patterns\n", "abstract": " The documentation is missing or obsolete, and the original developers have departed. Your team has limited understanding of the system, and unit tests are missing for many, if not all, of the components. When you fix a bug in one place, another bug pops up somewhere else in the system. Long rebuild times make any change difficult. All of these are signs of software that is close to the breaking point. Many systems can be upgraded or simply thrown away if they no longer serve their purpose. Legacy software, however, is crucial for operations and needs to be continually available and upgraded. How can you reduce the complexity of a legacy system sufficiently so that it can continue to be used and adapted at acceptable cost? Based on the authors' industrial experiences, this book is a guide on how to reverse engineer legacy systems to understand their problems, and then reengineer those systems to meet new demands. Patterns are used to clarify and explain the process of understanding large code bases, hence transforming them to meet new requirements. The key insight is that the right design and organization of your system is not something that can be evident from the initial requirements alone, but rather as a consequence of understanding how these requirements evolve.* Describes how to reverse engineer a monolithic system to understand how it really works and how to identify potential problems.* Includes reengineering patterns that tackle well-known reengineering techniques often encountered in object-oriented programming, such as introducing polymorphism, factoring out common behavior, detecting duplicated code, and\u252c\u00e1\u0393\u00c7\u00aa", "num_citations": "643\n", "authors": ["54"]}
{"title": "Semantic clustering: Identifying topics in source code\n", "abstract": " Many of the existing approaches in Software Comprehension focus on program structure or external documentation. However, by analyzing formal information the informal semantics contained in the vocabulary of source code are overlooked. To understand software as a whole, we need to enrich software analysis with the developer knowledge hidden in the code naming. This paper proposes the use of information retrieval to exploit linguistic information found in source code, such as identifier names and comments. We introduce Semantic Clustering, a technique based on Latent Semantic Indexing and clustering to group source artifacts that use similar vocabulary. We call these groups semantic clusters and we interpret them as linguistic topics that reveal the intention of the code. We compare the topics to each other, identify links between them, provide automatically retrieved labels, and use a visualization to\u252c\u00e1\u0393\u00c7\u00aa", "num_citations": "616\n", "authors": ["54"]}
{"title": "Polymetric views-a lightweight visual approach to reverse engineering\n", "abstract": " Reverse engineering software systems has become a major concern in software industry because of their sheer size and complexity. This problem needs to be tackled since the systems in question are of considerable worth to their owners and maintainers. In this article, we present the concept of a polymetric view, a lightweight software visualization technique enriched with software metrics information. Polymetric views help to understand the structure and detect problems of a software system in the initial phases of a reverse engineering process. We discuss the benefits and limits of several predefined polymetric views we have implemented in our tool CodeCrawler. Moreover, based on clusters of different polymetric views, we have developed a methodology which supports and guides a software engineer in the first phases of a reverse engineering of a large software system. We have refined this methodology by\u252c\u00e1\u0393\u00c7\u00aa", "num_citations": "543\n", "authors": ["54"]}
{"title": "Traits: Composable units of behaviour\n", "abstract": " Despite the undisputed prominence of inheritance as the fundamental reuse mechanism in object-oriented programming languages, the main variants\u0393\u00c7\u00f6single inheritance, multiple inheritance, and mixin inheritance\u0393\u00c7\u00f6all suffer from conceptual and practical problems. In the first part of this paper, we identify and illustrate these problems. We then present traits, a simple compositional model for structuring object-oriented programs. A trait is essentially a group of pure methods that serves as a building block for classes and is a primitive unit of code reuse. In this model, classes are composed from a set of traits by specifying glue code that connects the traits together and accesses the necessary state. We demonstrate how traits overcome the problems arising from the different variants of inheritance, we discuss how traits can be implemented effectively, and we summarize our experience applying traits to refactor\u252c\u00e1\u0393\u00c7\u00aa", "num_citations": "537\n", "authors": ["54"]}
{"title": "Finding refactorings via change metrics\n", "abstract": " Reverse engineering is the process of uncovering the design and the design rationale from a functioning software system. Reverse engineering is an integral part of any successful software system, because changing requirements lead to implementations that drift from their original design. In contrast to traditional reverse engineering techniques ---which analyse a single snapshot of a system--- we focus the reverse engineering effort by determining where the implementation has changed. Since changes of object-oriented software are often phrased in terms of refactorings, we propose a set of heuristics for detecting refactorings by applying lightweight, object-oriented metrics to successive versions of a software system. We validate our approach with three separate case studies of mature object-oriented software systems for which multiple versions are available. The case studies suggest that the heuristics support\u252c\u00e1\u0393\u00c7\u00aa", "num_citations": "416\n", "authors": ["54"]}
{"title": "How developers drive software evolution\n", "abstract": " As systems evolve their structure change in ways not expected upfront. As time goes by, the knowledge of the developers becomes more and more critical for the process of understanding the system. That is, when we want to understand a certain issue of the system we ask the knowledgeable developers. Yet, in large systems, not every developer is knowledgeable in all the details of the system. Thus, we would want to know which developer is knowledgeable in the issue at hand. In this paper we make use of the mapping between the changes and the author identifiers (e.g., user names) provided by versioning repositories. We first define a measurement for the notion of code ownership. We use this measurement to define the ownership map visualization to understand when and how different developers interacted in which way and in which part of the system. We report the results we obtained on several large\u252c\u00e1\u0393\u00c7\u00aa", "num_citations": "224\n", "authors": ["54"]}
{"title": "Recovering high-level views of object-oriented applications from static and dynamic information\n", "abstract": " Recovering architectural documentation from code is crucial to maintaining and re-engineering software systems. Reverse engineering and program understanding approaches are often limited by the fact that: 1) they propose a fixed set of predefined views, and 2) they consider either purely static or purely dynamic views of the application. In this paper we present an environment supporting the generation of tailorable views of object-oriented systems from both static and dynamic information. Our approach is based on the combination of user-defined queries which allow an engineer to create high-level abstractions and to produce views using these abstractions.", "num_citations": "220\n", "authors": ["54"]}
{"title": "Yesterday's weather: Guiding early reverse engineering efforts by summarizing the evolution of changes\n", "abstract": " Knowing where to start reverse engineering a large software system, when no information other than the system's source code itself is available, is a daunting task. Having the history of the code (i.e., the versions) could be of help if this would not imply analyzing a huge amount of data. We present an approach for identifying candidate classes for reverse engineering and reengineering efforts. Our solution is based on summarizing the changes in the evolution of object-oriented software systems by defining history measurements. Our approach, named Yesterday's Weather, is an analysis based on the retrospective empirical observation that classes which changed the most in the recent past also suffer important changes in the near future. We apply this approach on two case studies and show how we can obtain an overview of the evolution of a system and pinpoint its classes that might change in the next versions.", "num_citations": "183\n", "authors": ["54"]}
{"title": "Moose: an extensible language-independent environment for reengineering object-oriented systems\n", "abstract": " Surprising as it may seem, many of the early adopters of the object-oriented paradigm already face a number of problems typically encountered in large-scale legacy systems. The reengineering of those systems often poses problems because of the considerable size and complexity of such systems. In the context of the FAMOOS project we have developed a language independent environment called Moose which can deal with that complexity. This paper describes the architecture of Moose, the tools which have been developed around it and the industrial experiences we have obtained.", "num_citations": "178\n", "authors": ["54"]}
{"title": "Modeling history to analyze software evolution\n", "abstract": " The histories of software systems hold useful information when reasoning about the systems at hand or when reasoning about general laws of software evolution. Over the past 30 years, research has been increasingly spent on understanding software evolution. However, the approaches developed so far do not rely on an explicit meta\u0393\u00c7\u00c9model and, thus, they make it difficult to reuse or compare their results. We argue that there is a need for an explicit meta\u0393\u00c7\u00c9model for software evolution analysis. We present a survey of the evolution analyses and deduce a set of requirements that an evolution meta\u0393\u00c7\u00c9model should have. We define Hismo, a meta\u0393\u00c7\u00c9model in which history is modeled as an explicit entity. Hismo adds a time layer on top of structural information, and provides a common infrastructure for expressing and combining evolution analyses and structural analyses. We validate the usefulness of our meta\u0393\u00c7\u00c9model by\u252c\u00e1\u0393\u00c7\u00aa", "num_citations": "176\n", "authors": ["54"]}
{"title": "The class blueprint: visually supporting the understanding of glasses\n", "abstract": " Understanding source code is an important task in the maintenance of software systems. Legacy systems are not only limited to procedural languages, but are also written in object-oriented languages. In such a context, understanding classes is a key activity as they are the cornerstone of the object-oriented paradigm and the primary abstraction from which applications are built. Such an understanding is however difficult to obtain because of reasons such as the presence of late binding and inheritance. A first level of class understanding consists of the understanding of its overall structure, the control flow among its methods, and the accesses on its attributes. We propose a novel visualization of classes called class blueprint that is based on a semantically enriched visualization of the internal structure of classes. This visualization allows a software engineer to build a first mental model of a class that he validates via\u252c\u00e1\u0393\u00c7\u00aa", "num_citations": "156\n", "authors": ["54"]}
{"title": "Classbox/J: Controlling the scope of change in Java\n", "abstract": " Unanticipated changes to complex software systems can introduce anomalies such as duplicated code, suboptimal inheritance relationships and a proliferation of run-time downcasts. Refactoring to eliminate these anomalies may not be an option, at least in certain stages of software evolution. Classboxes are modules that restrict the visibility of changes to selected clients only, thereby offering more freedom in the way unanticipated changes may be implemented, and thus reducing the need for convoluted design anomalies. In this paper we demonstrate how classboxes can be implemented in statically-typed languages like Java. We also present an extended case study of Swing, a Java GUI package built on top of AWT, and we document the ensuing anomalies that Swing introduces. We show how Classbox/J, a prototype implementation of classboxes for Java, is used to provide a cleaner implementation of Swing\u252c\u00e1\u0393\u00c7\u00aa", "num_citations": "152\n", "authors": ["54"]}
{"title": "Understanding software evolution using a combination of software visualization and software metrics\n", "abstract": " Coping with huge amounts of data is one of the major problems in the context of software evolution. Current approaches reduce this complexity by filtering out irrelevant information. In this paper we propose an approach based on a combination of software visualization and software metrics, as software visualization is apt for complexity reduction and metrics introduce the possibility to qualify evolution. We discuss a simple and effective way to visualize the evolution of software systems which helps to recover the evolution of object oriented software systems. In addition we define a vocabulary that qualifies some specific situations that occurs when considering system evolution.", "num_citations": "150\n", "authors": ["54"]}
{"title": "Insights into system-wide code duplication\n", "abstract": " Duplication of code is a common phenomenon in the development and maintenance of large software systems. The detection and removal of duplicated code has become a standard activity during the refactoring phases of a software life-cycle. However, code duplication identification tends to produce large amounts of data making the understanding of the duplication situation as a whole difficult. Reengineers can easily lose sight of the forest for the trees. There is a need to support a qualitative analysis of the duplicated code. We propose a number of visualizations of duplicated source elements that support reengineers in answering questions, e.g., which parts of the system are connected by copied code or which parts of the system are copied the most.", "num_citations": "149\n", "authors": ["54"]}
{"title": "A component model for field devices\n", "abstract": " Component-based software development is becoming mainstream for conventional applications. However, components can be difficult to deploy in embedded systems because of non-functional requirements. Pecos is a collaborative project between industrial and research partners that seeks to enable component-based technology for a class of embedded systems known as \u0393\u00c7\u00a3field devices\u0393\u00c7\u00a5. In this paper we introduce a component model for field devices that captures a range of non-functional properties and constraints.", "num_citations": "147\n", "authors": ["54"]}
{"title": "Enriching reverse engineering with semantic clustering\n", "abstract": " Understanding a software system by just analyzing the structure of the system reveals only half of the picture, since the structure tells us only how the code is working but not what the code is about. What the code is about can be found in the semantics of the source code: names of identifiers, comments etc. In this paper, we analyze how these terms are spread over the source artifacts using latent semantic indexing, an information retrieval technique. We use the assumption that parts of the system that use similar terms are related. We cluster artifacts that use similar terms, and we reveal the most relevant terms for the computed clusters. Our approach works at the level of the source code which makes it language independent. Nevertheless, we correlated the semantics with structural information and we applied it at different levels of abstraction (e.g. classes, methods). We applied our approach on three large case\u252c\u00e1\u0393\u00c7\u00aa", "num_citations": "134\n", "authors": ["54"]}
{"title": "Distribution map\n", "abstract": " Understanding large software systems is a challenging task, and to support it many approaches have been developed. Often, the result of these approaches categorize existing entities into new groups or associates them with mutually exclusive properties. In this paper we present the distribution map as a generic technique to visualize and analyze this type of result. Our technique is based on the notion of focus, which shows whether a property is well-encapsulated or cross-cutting, and the notion of spread, which shows whether the property is present in several parts of the system. We present a basic visualization and complement it with measurements that quantify focus and spread. To validate our technique we show evidence of applying it on the result sets of different analysis approaches. As a conclusion we propose that the distribution map technique should belong to any reverse engineering toolkit", "num_citations": "133\n", "authors": ["54"]}
{"title": "On the effectiveness of clone detection by string matching\n", "abstract": " Although duplicated code is known to pose severe problems for software maintenance, it is difficult to identify in large systems. Many different techniques have been developed to detect software clones, some of which are very sophisticated, but are also expensive to implement and adapt. Lightweight techniques based on simple string matching are easy to implement, but how effective are they? We present a simple string\u0393\u00c7\u00c9based approach which we have successfully applied to a number of different languages such COBOL, JAVA, C++, PASCAL, PYTHON, SMALLTALK, C and PDP\u0393\u00c7\u00c911 ASSEMBLER. In each case the maximum time to adapt the approach to a new language was less than 45 minutes. In this paper we investigate a number of simple variants of string\u0393\u00c7\u00c9based clone detection that normalize differences due to common editing operations, and assess the quality of clone detection for very different case\u252c\u00e1\u0393\u00c7\u00aa", "num_citations": "127\n", "authors": ["54"]}
{"title": "Using dynamic information for the iterative recovery of collaborations and roles\n", "abstract": " Modeling object-oriented applications using collaborations and roles is now well accepted. Collaboration-based or role-based designs decompose an application into tasks performed by a subset of the applications' classes. Collaborations provide a larger unit of understanding and reuse than classes, and are an important aid in the maintenance and evolution of the software. This kind of design information is lost, however, at the implementation level, making it hard to maintain and evolve an existing software application. The extraction of collaborations from code is therefore an important issue in design recovery. In this paper we propose an iterative approach which uses dynamic information to support the recovery and understanding of collaborations. We describe a tool we have developed to support our approach and demonstrate its use on a case study.", "num_citations": "117\n", "authors": ["54"]}
{"title": "A categorization of classes based on the visualization of their internal structure: the class blueprint\n", "abstract": " The reengineering and reverse engineering of software systems is gaining importance in software industry, because the accelerated turnover in software industry, because the accelerated turnover in software companies creates legacy systems in a shorter period of time. Especially understanding classes is a key activity in object-oriented programming, since classes represent the primary abstractions from which applications are built. The main problem of this task is to quickly grasp the purpose of a class and its inner structure. To help the reverse engineers in their first contact with a foreign system, we propose a categorization of classes based on the visualization of their internal structure. The contributions of this paper are a novel categorization of classes and a visualization of the which we call the class blueprint. We have validated the categorization on several case studies, two of which we present here.", "num_citations": "116\n", "authors": ["54"]}
{"title": "Characterizing the evolution of class hierarchies\n", "abstract": " Analyzing historical information can show how a software system evolved into its current state, which parts of the system are stable and which have changed more. However, historical analysis implies processing a vast amount of information making the interpretation of the results difficult. To address this issue, we introduce the notion of the history of source code artifacts as a first class entity and define measurements, which summarize the evolution of such entities. We use these measurements to define rules by which to detect different characteristics of the evolution of class hierarchies. Furthermore, we discuss the results we obtained by visualizing them using a polymetric view. We apply our approach on two large open source case studies and classify their class hierarchies based on their history.", "num_citations": "112\n", "authors": ["54"]}
{"title": "Correlating features and code using a compact two-sided trace analysis approach\n", "abstract": " Software developers are constantly required to modify and adapt application features in response to changing requirements. The problem is that just by reading the source code, it is difficult to determine how classes and methods contribute to the runtime behavior of features. Moreover, dependencies between system features are not obvious, consequently software maintenance operations often result in unintended side effects. To tackle these problems, we propose a compact feature-driven approach (i.e., summarized trace information) based on dynamic analysis to characterize features and computational units of an application. We extract execution traces to achieve an explicit mapping between features and classes using two complementary perspectives. We apply our approach to two case studies and we report our findings.", "num_citations": "110\n", "authors": ["54"]}
{"title": "Software quality metrics aggregation in industry\n", "abstract": " With the growing need for quality assessment of entire software systems in the industry, new issues are emerging. First, because most software quality metrics are defined at the level of individual software components, there is a need for aggregation methods to summarize the results at the system level. Second, because a software evaluation requires the use of different metrics, with possibly widely varying output ranges, there is a need to combine these results into a unified quality assessment. In this paper we derive, from our experience on real industrial cases and from the scientific literature, requirements for an aggregation method. We then present a solution through the Squale model for metric aggregation, a model specifically designed to address the needs of practitioners. We empirically validate the adequacy of Squale through experiments on Eclipse. Additionally, we compare the Squale model to both\u252c\u00e1\u0393\u00c7\u00aa", "num_citations": "106\n", "authors": ["54"]}
{"title": "Why unified is not universal\n", "abstract": " UML is currently embraced as \u0393\u00c7\u00a3the\u0393\u00c7\u00a5 standard in object-oriented modeling languages, the recent work of OMG on the Meta Object Facility (MOF) being the most noteworthy example. We welcome these standardisation efforts, yet warn against the tendency to use UML as the panacea for all exchange standards. In particular, we argue that UML is not sufficient to serve as a tool-interoperability standard for integrating round-trip engineering tools, because one is forced to rely on UML\u0393\u00c7\u00d6s built-in extension mechanisms to adequately model the reality in source-code. Consequently, we propose an alternative meta-model (named FAMIX), which serves as the tool interoperability standard within the FAMOOS project and which includes a number of constructive suggestions that we hope will influence future releases of the UML and MOF standards.", "num_citations": "103\n", "authors": ["54"]}
{"title": "Evaluating message passing control techniques in Smalltalk\n", "abstract": " In a language like Smalltalk in which objects communicate only via message passing, message passing control is a fundamental tool for the analysis of object behavior (trace, spying) or for the definition of new semantics (asynchronous messages, proxy,...). Different techniques exist, from the well known approach based on the specialization of the doesNotUnderstand: method to the exploitation the method lookup algorithm done by the virtual machine. Until now no comparison between these techniques has been made. In this article we compare the different techniques taking into account the reflective aspects used, the scope, the limit and the cost of the control.", "num_citations": "102\n", "authors": ["54"]}
{"title": "Untangling fine-grained code changes\n", "abstract": " After working for some time, developers commit their code changes to a version control system. When doing so, they often bundle unrelated changes (e.g., bug fix and refactoring) in a single commit, thus creating a so-called tangled commit. Sharing tangled commits is problematic because it makes review, reversion, and integration of these commits harder and historical analyses of the project less reliable. Researchers have worked at untangling existing commits, i.e., finding which part of a commit relates to which task. In this paper, we contribute to this line of work in two ways: (1) A publicly available dataset of untangled code changes, created with the help of two developers who accurately split their code changes into self contained tasks over a period of four months; (2) a novel approach, EpiceaUntangler, to help developers share untangled commits (aka. atomic commits) by using fine-grained code change\u252c\u00e1\u0393\u00c7\u00aa", "num_citations": "100\n", "authors": ["54"]}
{"title": "Classboxes: Controlling visibility of class extensions\n", "abstract": " A class extension is a method that is defined in a module, but whose class is defined elsewhere. Class extensions offer a convenient way to incrementally modify existing classes when subclassing is inappropriate. Unfortunately existing approaches suffer from various limitations. Either class extensions have a global impact, with possibly negative effects for unexpected clients, or they have a purely local impact, with negative results for collaborating clients. Furthermore, conflicting class extensions are either disallowed, or resolved by linearization, with consequent negative effects. To solve these problems we present classboxes, a module system for object-oriented languages that provides for method addition and replacement. Moreover, the changes made by a classbox are only visible to that classbox (or classboxes that import it), a feature we call local rebinding. To validate the model we have implemented it in the\u252c\u00e1\u0393\u00c7\u00aa", "num_citations": "99\n", "authors": ["54"]}
{"title": "Applying traits to the smalltalk collection classes\n", "abstract": " Traits are a programming language technology that promote the reuse of methods between unrelated classes. This paper reports on a refactoring of the Smalltalk collections classes using traits. The original collection classes contained much duplication of code; traits let us remove all of it. We also found places where the protocols of the collections lacked uniformity; traits allowed us to correct these non-uniformities without code duplication.Traits also make it possible to reuse fragments of collection code outside of the existing hierarchy; for example, they make it easy to convert other collection-like things into true collections. Our refactoring reduced the number of methods in the collection classes by approximately 10 per cent. More importantly, understandability maintainability and reusability of the code were significantly improved.", "num_citations": "80\n", "authors": ["54"]}
{"title": "Seaside: A flexible environment for building dynamic web applications\n", "abstract": " Page-centric Web development structures an application into individual scripts, each responsible for processing a user request and generating a response. Although software developers have long considered go-to statements harmful, they are still present in today's mainstream frameworks, and they hamper the reuse of pages in different parts of the application. In this article, after briefly discussing the key challenges of modern Web application development, we present Seaside, a highly dynamic framework for developing Web applications in Smalltalk. The Seaside framework provides a uniform, pure object-oriented view for Web applications. Exploiting Smalltalk's reflective features, Seaside reintroduces procedure call abstraction in a client-server context. Furthermore, there's no need to recompile and restart Seaside application servers after each modification. Web developers debug and update applications on\u252c\u00e1\u0393\u00c7\u00aa", "num_citations": "77\n", "authors": ["54"]}
{"title": "Stateful traits and their formalization\n", "abstract": " Traits offer a fine-grained mechanism to compose classes from reusable components while avoiding problems of fragility brought by multiple inheritance and mixins. Traits as originally proposed are stateless, that is, they contain only methods, but no instance variables. State can only be accessed within stateless traits by accessors, which become required methods of the trait. Although this approach works reasonably well in practice, it means that many traits, viewed as software components, are artificially incomplete, and classes that use such traits may contain significant amounts of boilerplate glue code. We present an approach to stateful traits that is faithful to the guiding principle of stateless traits: the client retains control of the composition. Stateful traits consist of a minimal extension to stateless traits in which instance variables are purely local to the scope of a trait, unless they are explicitly made accessible by\u252c\u00e1\u0393\u00c7\u00aa", "num_citations": "76\n", "authors": ["54"]}
{"title": "Classboxes: A minimal module model supporting local rebinding\n", "abstract": " Classical module systems support well the modular development of applications but do not offer the ability to add or replace a method in a class that is not defined in that module. On the other hand, languages that support method addition and replacement do not provide a modular view of applications, and their changes have a global impact. The result is a gap between module systems for object-oriented languages on one hand, and the very desirable feature of method addition and replacement on the other hand. To solve these problems we present classboxes, a module system for object-oriented languages that provides method addition and replacement. Moreover, the changes made by a classbox are only visible to that classbox (or classboxes that import it), a feature we call local rebinding. To validate the model, we have implemented it in the Squeak Smalltalk environment, and performed\u252c\u00e1\u0393\u00c7\u00aa", "num_citations": "74\n", "authors": ["54"]}
{"title": "Seaside\u0393\u00c7\u00f4a multiple control flow web application framework\n", "abstract": " Developing web applications is difficult since (1) the client-server relationship is asymmetric: the server cannot update clients but only responds to client requests and (2) the navigation facilities of web browsers lead to a situation where servers cannot control the state of the clients. Page-centric web application frameworks fail to offer adequate solutions to model control flow at a high-level of abstraction. Developers have to work manually around the shortcomings of the HTTP protocol. Some approaches offer better abstractions by composing an application out of components, however they still fail to offer modeling control flow at a high level. Continuation-based approaches solve this problem by providing the facilities to model a control flow over several pages with one piece of code. However combining multiple flows inside the same page is difficult.This article presents Seaside. Seaside is a framework which combines an objectoriented approach with a continuation-based one. A Seaside application is built out of components (ie, objects) and the logic of the application benefits from the continuation-based program flow infrastructure. Seaside offers a unique way to have multiple control flows on a page, one for each component. This enables the developer to write components that are highly reusable and that can be used to compose complex web applications with higher quality in less time.", "num_citations": "71\n", "authors": ["54"]}
{"title": "Executable connectors: Towards reusable design elements\n", "abstract": " The decomposition of a software application into components and connectors at the design stage has been promoted as a way to describe and reason about complex software architectures. There is, however, surprisingly little language support for this decomposition at implementation level. Interaction relationships which are identified at design time are lost as they get spread out into the participating entities at implementation. In this paper, we propose first-class connectors in an object-oriented language as a first step towards making software architecture more explicit at implementation level. Our connectors are run-time entities which control the interaction of components and can express a rich repertoire of interaction relationships. We show how connectors can be reused and how they enhance the reuse of components.", "num_citations": "71\n", "authors": ["54"]}
{"title": "How do developers react to api evolution? the pharo ecosystem case\n", "abstract": " Software engineering research now considers that no system is an island, but it is part of an ecosystem involving other systems, developers, users, hardware, ... When one system (e.g., a framework) evolves, its clients often need to adapt. Client developers might need to adapt to functionalities, client systems might need to be adapted to a new API, client users might need to adapt to a new User Interface. The consequences of such changes are yet unclear, what proportion of the ecosystem might be expected to react, how long might it take for a change to diffuse in the ecosystem, do all clients react in the same way? This paper reports on an exploratory study aimed at observing API evolution and its impact on a large-scale software ecosystem, Pharo, which has about 3,600 distinct systems, more than 2,800 contributors, and six years of evolution. We analyze 118 API changes and answer research questions\u252c\u00e1\u0393\u00c7\u00aa", "num_citations": "67\n", "authors": ["54"]}
{"title": "The squale model\u0393\u00c7\u00f6A practice-based industrial quality model\n", "abstract": " ISO 9126 promotes a three-level model of quality (factors, criteria, and metrics) which allows one to assess quality at the top level of factors and criteria. However, it is difficult to use this model as a tool to increase software quality. In the Squale model, we add practices as an intermediate level between metrics and criteria. Practices abstract away from raw information (metrics, tool reports, audits) and provide technical guidelines to be respected. Moreover, practice marks are adjusted using formulae to suit company development habits or exigences: for example bad marks are stressed to point to places which need more attention. The Squale model has been developed and validated over the last couple of years in an industrial setting with Air France-KLM and PSA Peugeot-Citroen.", "num_citations": "67\n", "authors": ["54"]}
{"title": "Analyzing software evolution through feature views\n", "abstract": " Features encapsulate the domain knowledge of a software system and thus are valuable sources of information for a reverse engineer. When analyzing the evolution of a system, we need to know how and which features were modified to recover both the change intention and extent, namely which source artifacts are affected. Typically, the implementation of a feature crosscuts a number of source artifacts. To obtain a mapping between features and the source artifacts, we exercise the features and capture their execution traces. However, this results in large traces that are difficult to interpret. To tackle this issue we compact the traces into simple sets of source artifacts that participate in a feature's runtime behavior. We refer to these compacted traces as feature views. Within a feature view, we partition the source artifacts into disjoint sets of characterized software entities. The characterization defines the level of\u252c\u00e1\u0393\u00c7\u00aa", "num_citations": "67\n", "authors": ["54"]}
{"title": "Using concept analysis to detect co-change patterns\n", "abstract": " Software systems need to change over time to cope with new requirements, and due to design decisions, the changes happen to crosscut the system's structure. Understanding how changes appear in the system can reveal hidden dependencies between different entities of the system. We propose the usage of concept analysis to identify groups of entities that change in the same way and in the same time. We apply our approach at different levels of abstraction (ie, method, class, package) and we detect fine grained changes (ie, statements were added in a class, but no method was added there). Concept analysis is a technique that identifies entities that have the same properties, but it requires manual inspection due to the large number of candidates it detects. We propose a heuristic that dramatically eliminate the false positives. We apply our approach on two case studies and we show how we can identify\u252c\u00e1\u0393\u00c7\u00aa", "num_citations": "66\n", "authors": ["54"]}
{"title": "Squeak par l'exemple\n", "abstract": " Ce livre est disponible en libre t\u251c\u2310l\u251c\u2310chargement depuis http://scg. unibe. ch/SBE/FrenchBook. L\u0393\u00c7\u00d6\u251c\u2310dition originale de ce livre est disponible depuis http://scg. unibe. ch/SBE/Book sous le titre Squeak par l\u0393\u00c7\u00d6exemple, ISBN 978-3-9523341-3-3. La premi\u251c\u00bfre \u251c\u2310dition a \u251c\u2310t\u251c\u2310 publi\u251c\u2310 en Avril 2008 par Square Bracket Associates, Suisse (SquareBracketAssociates. org). Vous pouvez vous procurer une copie \u251c\u00e1 l\u0393\u00c7\u00d6adresse: SqueakByExample. org/fr.", "num_citations": "63\n", "authors": ["54"]}
{"title": "SmartInspect: solidity smart contract inspector\n", "abstract": " Solidity is a language used for smart contracts on the Ethereum blockchain. Smart contracts are embedded procedures stored with the data they act upon. Debugging smart contracts is a really difficult task since once deployed, the code cannot be reexecuted and inspecting a simple attribute is not easily possible because data is encoded. In this paper, we address the lack of inspectability of a deployed contract by analyzing contract state using decompilation techniques driven by the contract structure definition. Our solution, SmartInspect, also uses a mirror-based architecture to represent locally object responsible for the interpretation of the contract state. SmartInspect allows contract developers to better visualize and understand the contract stored state without needing to redeploy, nor develop any ad-hoc code.", "num_citations": "58\n", "authors": ["54"]}
{"title": "Modularization metrics: Assessing package organization in legacy large object-oriented software\n", "abstract": " There exist many large object-oriented software systems consisting of several thousands of classes that are organized into several hundreds of packages. In such software systems, classes cannot be considered as units for software modularization. In such context, packages are not simply classes containers, but they also play the role of modules: a package should focus to provide well identified services to the rest of the software system. Therefore, understanding and assessing package organization is primordial for software maintenance tasks. Although there exist a lot of works proposing metrics for the quality of a single class and/or the quality of inter-class relationships, there exist few works dealing with some aspects for the quality of package organization and relationship. We believe that additional investigations are required for assessing package modularity aspects. The goal of this paper is to provide a\u252c\u00e1\u0393\u00c7\u00aa", "num_citations": "58\n", "authors": ["54"]}
{"title": "The FAMOOS Object-Oriented Reengineering Handbook\n", "abstract": " BORIS Deutsch English Fran\u251c\u00baais Login BORIS Bern Open Repository and Information System University of Bern Home Statistics The FAMOOS Object-Oriented Reengineering Handbook Ducasse, St\u251c\u2310phane; Demeyer, Serge (eds.) (1999). The FAMOOS Object-Oriented Reengineering Handbook. University of Bern Full text not available from this repository. (Request a copy) Official URL: http://scg.unibe.ch/archive/papers/Duca99xFamoosHa... Item Type: Book (Edited Volume) Division/Institute: 08 Faculty of Science > Institute of Computer Science (INF) (SCG) UniBE Contributor: Ducasse, Stephane Subjects: 000 Computer science, knowledge & systems 500 Science > 510 Mathematics Publisher: University of Bern Language: English Submitter: Manuela Bamert Date Deposited: 13 Dec 2017 09:05 Last Modified: 13 Dec 2017 :: \u0393\u00c7\u00aa", "num_citations": "58\n", "authors": ["54"]}
{"title": "Squeak by example\n", "abstract": " Squeak is a modern open-source development environment for the classic Smalltalk-80 programming language. This book, intended for both students and developers, will guide you gently through the language and tools by means of a series of examples and exercises. We are making this book available to you under the Creative Commons Attribution-ShareAlike 3.0 license. You can either download the PDF for free from SqueakByExample. org, or you can buy a softcover copy from lulu. com.(You can also pay for the PDF download from lulu. com, if you would like to make a contribution to this effort.) Additional material is available from the book's web page at SqueakByExample. org.", "num_citations": "57\n", "authors": ["54"]}
{"title": "High-level polymetric views of condensed run-time information\n", "abstract": " Understanding the run-time behavior of object-oriented legacy systems is a complex task due to factors such as late binding and polymorphism. Current approaches extract and use information from the complete execution trace of a system. The sheer size and complexity of such traces make their handling, storage, and analysis difficult. Current software systems which run almost nonstop do not permit such a full analysis. In this paper we present a lightweight approach based on the extraction of a condensed amount of information, e.g., measurements, that does not require a full trace. Using this condensed information, we propose a visualization approach which allows us to identify and understand certain aspects of the objects' lifetime such as their role played in the creation of other objects and the communication architecture they support.", "num_citations": "57\n", "authors": ["54"]}
{"title": "A reflective model for first class dependencies\n", "abstract": " We propose a reflective model to express and to automatically manage dependencies between objects. This model describes reflective facilities which enable the changing of language semantics. Although the importance of inter-object dependencies is well accepted, there is only limited object-oriented language support for their specification and implementation. In response to this lack of expressiveness of object models, the FLO language integrates dependency management into the object oriented paradigm. Dependencies are described as first class objects and FLO automatically maintains the consistency of the dependency graph. In this paper, we first show how a user can declare dependencies and how the system maintains the consistency of the graph of expressed dependencies. In a second part, we focus on the implementation of this management by controlling the messages sent to linked objects. In\u252c\u00e1\u0393\u00c7\u00aa", "num_citations": "57\n", "authors": ["54"]}
{"title": "Object-oriented legacy system trace-based logic testing\n", "abstract": " When reengineering legacy systems, it is crucial to assess if the legacy behavior has been preserved or how it changed due to the reengineering effort. Ideally if a legacy system is covered by tests, running the tests on the new version can identify potential differences or discrepancies. However, writing tests for an unknown and large system is difficult due to the lack of internal knowledge. It is especially difficult to bring the system to an appropriate state. Our solution is based on the acknowledgment that one of the few trustable piece of information available when approaching a legacy system is the running system itself. Our approach reifies the execution traces and uses logic programming to express tests on them. Thereby it eliminates the need to programatically bring the system in a particular state, and handles the test-writer a high-level abstraction mechanism to query the trace. The resulting system, called\u252c\u00e1\u0393\u00c7\u00aa", "num_citations": "56\n", "authors": ["54"]}
{"title": "Package surface blueprints: Visually supporting the understanding of package relationships\n", "abstract": " Large object-oriented applications are structured over large number of packages. Packages are important but complex structural entities that may be difficult to understand since they play different development roles (i.e., class containers, code ownership basic structure, architectural elements...). Maintainers of large applications face the problem of understanding how packages are structured in general and how they relate to each others. In this paper, we present a compact visualization, named Package Surface Blueprint, that qualifies the relationships that a package has with its neighbours. A Package Surface Blueprint represents packages around the notion of package surfaces: groups of relationships according to the packages they refer to. We present two specific views one stressing the references made by a package and another showing the inheritance structure of a package. We applied the visualization on\u252c\u00e1\u0393\u00c7\u00aa", "num_citations": "54\n", "authors": ["54"]}
{"title": "Visual detection of duplicated code\n", "abstract": " Code duplication is considered as bad practice that complicates the maintenance and evolution of software. Detecting duplicated code is a difficult task because of the large amount of data to be checked and the fact that a priori it is unknown which code part has been duplicated. In this paper, we present a tool called DUPLOC that supports code duplication detection in a visual and exploratory or an automatic way.", "num_citations": "52\n", "authors": ["54"]}
{"title": "Meta-environment and executable meta-language using Smalltalk: an experience report\n", "abstract": " Object-oriented modelling languages such as EMOF are often used to specify domain specific meta-models. However, these modelling languages lack the ability to describe behavior or operational semantics. Several approaches have used a subset of Java mixed with OCL as executable meta-languages. In this experience report we show how we use Smalltalk as an executable meta-language in the context of the Moose reengineering environment. We present how we implemented EMOF and its behavioral aspects. Over the last decade we validated this approach through incrementally building a meta-described reengineering environment. Such an approach bridges the gap between a code-oriented view and a meta-model driven one. It avoids the creation of yet another language and reuses the infrastructure and run-time of the underlying implementation language. It offers an uniform way of letting\u252c\u00e1\u0393\u00c7\u00aa", "num_citations": "51\n", "authors": ["54"]}
{"title": "Sub-method reflection\n", "abstract": " Reflection has proved to be a powerful feature to support the design of development environments and to extend languages. However, the granularity of structural reflection stops at the method level. This is a problem since without sub-method reflection developers have to duplicate efforts, for example to introduce transparently pluggable type-checkers or fine-grained profilers. In this paper we present Persephone, an efficient implementation of a sub-method meta-object protocol (MOP) based on AST annotations and dual methods (a compiled method and its meta-object) that reconcile AST expressiveness with bytecode execution. We validate the MOP by presenting TreeNurse, a method instrumentation framework and TypePlug, an optional, pluggable type system which is based on Persephone.", "num_citations": "50\n", "authors": ["54"]}
{"title": "Runtime bytecode transformation for Smalltalk\n", "abstract": " Transforming programs to alter their semantics is of wide interest, for purposes as diverse as off-the-shelf component adaptation, optimization, trace generation, and experimentation with new language features. The current wave of interest in advanced technologies for better separation of concerns, such as aspect-oriented programming, is a solid testimony of this fact. Strangely enough, almost all proposals are formulated in the context of Java, in which tool providers encounter severe restrictions due to the rigidity of the environment. This paper presents BYTESURGEON, a library to transform binary code in Smalltalk. BYTESURGEON takes full advantage of the flexibility of the Squeak environment to enable bytecode transformation at runtime, thereby allowing dynamic, on-the-fly modification of applications. BYTESURGEON operates on bytecode in order to cope with situations where the source code is not\u252c\u00e1\u0393\u00c7\u00aa", "num_citations": "49\n", "authors": ["54"]}
{"title": "Butterflies: A visual approach to characterize packages\n", "abstract": " Understanding sets of classes, or packages, is an important activity in the development and reengineering of large object-oriented systems. Packages represent the coarse grained structure of an application. They are artefacts to deploy and structure software, and therefore more than a simple generalization of classes. The relationships between packages and their contained classes are key in the decomposition of an application and its (re)-modularisation. However, it is difficult to quickly grasp the structure of a package and to understand how a package interacts with the rest of the system. We tackle this problem using butterfly visualizations, i.e., dedicated radar charts built from simple package metrics based on a language-independent meta-model. We illustrate our approach on two applications and show how we can retrieve the relevant characteristics of packages", "num_citations": "49\n", "authors": ["54"]}
{"title": "Component-based software engineering\n", "abstract": " On behalf of the Organizing Committee I am pleased to present the proceedings of the 2005 Symposium on Component-Based Software Engineering (CBSE). CBSE is concerned with the development of software-intensive systems from reusable parts (components), the development of reusable parts, and system maintenance and improvement by means of component replacement and customization. CBSE 2005,\u0393\u00c7\u00a3Software Components at Work,\u0393\u00c7\u00a5 was the eighth in a series of events that promote a science and technology foundation for achieving predictable quality in software systems through the use of software component technology and its associated software engineering practices. We were fortunate to have a dedicated Program Committee comprised of 30 internationally recognized researchers and industrial practitioners. We received 91 submissions and each paper was reviewed by at least three Program\u252c\u00e1\u0393\u00c7\u00aa", "num_citations": "49\n", "authors": ["54"]}
{"title": "Metrics, Do they really help?\n", "abstract": " Maturing a well designed framework requires a set of software metrics to steer the iterative development process. Based on a case study of the VisualWorks/Smalltalk framework for user-interface building, we conclude that today\u0393\u00c7\u00d6s size and inheritance metrics are not reliable to detect problems but are useful in measuring stability. We expect that this work will contribute to the application of metrics as a project management tool.", "num_citations": "49\n", "authors": ["54"]}
{"title": "Identifying cycle causes with enriched dependency structural matrix\n", "abstract": " Dependency structure matrix (DSM) has been successfully applied to identify software dependencies among packages and subsystems. A number of algorithms were proposed to compute the matrix so that it highlights patterns and problematic dependencies between subsystems. However, existing DSM implementations often miss important information to fully support reengineering effort. For example, they do not clearly qualify and quantify problematic relationships, information which is crucial to support remediation tasks.In this paper we present enriched DSM (eDSM) where cells are enriched with contextual information about (i) the type of dependencies (inheritance, class reference...), (ii) the proportion of referencing entities, (iii) the proportion of referenced entities. We distinguish independent cycles and stress potentially simple fixes for cycles using coloring information. This work is language independent and\u252c\u00e1\u0393\u00c7\u00aa", "num_citations": "45\n", "authors": ["54"]}
{"title": "Towards automatically improving package structure while respecting original design decisions\n", "abstract": " Recently, there has been an important progress in applying search-based optimization techniques to the problem of software re-modularization. Yet, a major part of the existing body of work addresses the problem of modularizing software systems from scratch, regardless of the existing packages structure. This paper presents a novel multi-objective optimization approach for improving existing packages structure. The optimization approach aims at increasing the cohesion and reducing the coupling and cyclic connectivity of packages, by modifying as less as possible the existing packages organization. Moreover, maintainers can specify several constraints to guide the optimization process with regard to extra design factors. To this contribution, we use the Non-Dominated Sorting Genetic Algorithm (NSGA-II). We evaluate the optimization approach through an experiment covering four real-world software systems\u252c\u00e1\u0393\u00c7\u00aa", "num_citations": "44\n", "authors": ["54"]}
{"title": "Supporting simultaneous versions for software evolution assessment\n", "abstract": " When reengineering software systems, maintainers should be able to assess and compare multiple change scenarios for a given goal, so as to choose the most pertinent one. Because they implicitly consider one single working copy, revision control systems do not scale up well to perform simultaneous analyses of multiple versions of systems. We designed Orion, an interactive prototyping tool for reengineering, to simulate changes and compare their impact on multiple versions of software source code models. Our approach offers an interactive simulation of changes, reuses existing assessment tools, and has the ability to hold multiple and branching versions simultaneously in memory. Specifically, we devise an infrastructure which optimizes memory usage of multiple versions for large models. This infrastructure uses an extension of the FAMIX source code meta-model but it is not limited to source code analysis\u252c\u00e1\u0393\u00c7\u00aa", "num_citations": "44\n", "authors": ["54"]}
{"title": "Object-oriented encapsulation for dynamically typed languages\n", "abstract": " Encapsulation in object-oriented languages has traditionally been based on static type systems. As a consequence, dynamically-typed languages have only limited support for encapsulation. This is surprising, considering that encapsulation is one of the most fundamental and important concepts behind object-oriented programming and that it is essential for writing programs that are maintainable and reliable, and that remain robust as they evolve.", "num_citations": "43\n", "authors": ["54"]}
{"title": "Inter-language reflection: A conceptual model and its implementation\n", "abstract": " Meta programming is the act of reasoning about a computational system. For example, a program in Prolog can reason about a program written in Smalltalk. Reflection is a more powerful form of meta programming where the same language is used to reason about, and act upon, itself in a causally connected way. Thus on the one hand we have meta programming that allows different languages or paradigms to be used, but without causal connection, while on the other hand we have reflection that offers causal connection but only for a single language. This paper combines both and presents inter-language reflection that allows one language to reason about and change in a causally connected way another language and vice versa. The fundamental aspects of inter-language reflection and the language symbiosis used therein, are discussed. Moreover the implementation of two symbiotic reflective languages is\u252c\u00e1\u0393\u00c7\u00aa", "num_citations": "41\n", "authors": ["54"]}
{"title": "Analyzing feature traces to incorporate the semantics of change in software evolution analysis\n", "abstract": " Many of the approaches that analyze software evolution consider a static perspective of a system. Static analysis approaches focus on the evolution of static software entities such as packages, classes and methods. Without knowledge of the roles software entities play in system features, it is difficult to interpret the motivation behind changes and extensions in the code. To tackle this problem, we propose an approach to software evolution analysis that exploits the relationships between features and software entities. Our definition of a feature is a unit of observable behavior of a software system. We define history measurements that summarize the evolution of software entities from a feature perspective. We show how we use our feature perspective of software evolution to interpret modifications and extensions to the code. We apply our approach on two case studies and discuss our findings.", "num_citations": "41\n", "authors": ["54"]}
{"title": "The moose reengineering environment\n", "abstract": " This article presents the Moose Reengineering Environment, a language independent tool environment to reverse engineer, ie, understand, and reengineer software systems, as well as the tools which have been developed around it and the experience, both academic and industrial, we have obtained.", "num_citations": "40\n", "authors": ["54"]}
{"title": "How do developers react to API evolution? A large-scale empirical study\n", "abstract": " Software engineering research now considers that no system is an island, but it is part of an ecosystem involving other systems, developers, and users. When a framework or a library evolves, its clients often must adapt. For example, client developers might need to adapt to functionalities, client systems might need to be adapted to a new API, and client users might need to adapt to a new user interface. The consequences of these changes are yet unclear: what proportion of the ecosystem might be expected to react, how long might it take for a change to diffuse in the ecosystem, do all clients react in the same way? This paper reports an exploratory study aimed at observing API evolution and its impact on a large software ecosystem, Pharo, which has about 3600 distinct systems, and 6 years of evolution. We analyze 118 API changes in the context of method replacement and suggestion, and answer\u252c\u00e1\u0393\u00c7\u00aa", "num_citations": "39\n", "authors": ["54"]}
{"title": "CodeCrawler-An Extensible and Language Independent 2D and 3D Software Visualization Tool.\n", "abstract": " CodeCrawler is an extensible and language independent software visualization tool. It has been validated in several industrial case studies over the past years. CodeCrawler enables the fast exploration of new visualization ideas. It implements and visualizes polymetric views, visualizations of software enriched with information such as software metrics and other source code semantics. It provides a rich set of views that can be customized using a large set of metrics. While CodeCrawler is mainly targeted at visualizing object-oriented software, in its latest implementation it has become a general information visualization tool.", "num_citations": "38\n", "authors": ["54"]}
{"title": "Aspectmaps: A scalable visualization of join point shadows\n", "abstract": " When using Aspect-Oriented Programming, it is sometimes difficult to determine at which join point an aspect executes. Similarly, when considering one join point, knowing which aspects will execute there and in what order is non-trivial. This makes it difficult to understand how the application will behave. A number of visualizations have been proposed that attempt to provide support for such program understanding. However, they neither scale up to large code bases nor scale down to understanding what happens at a single join point. In this paper, we present Aspect Maps -- a visualization that scales in both directions, thanks to a multi-level selective structural zoom. We show how the use of Aspect Maps allows for program understanding of code with aspects, revealing both a wealth of information of what can happen at one particular join point as well as allowing to see the \"big picture\" on a larger code base. We\u252c\u00e1\u0393\u00c7\u00aa", "num_citations": "37\n", "authors": ["54"]}
{"title": "Taking an object-centric view on dynamic information with object flow analysis\n", "abstract": " A large body of research analyzes the runtime execution of a system to extract abstract behavioral views. Those approaches primarily analyze control flow by tracing method execution events or they analyze object graphs of heap memory snapshots. However, they do not capture how objects are passed through the system at runtime. We refer to the exchange of objects as the object flow, and we claim that it is necessary to analyze object flows if we are to understand the runtime of an object-oriented application. We propose and detail object flow analysis, a novel dynamic analysis technique that takes this new information into account. To evaluate its usefulness, we present a visual approach that allows a developer to study classes and components in terms of how they exchange objects at runtime. We illustrate our approach on three case studies.", "num_citations": "37\n", "authors": ["54"]}
{"title": "The meta in meta-object architectures\n", "abstract": " Behavioral reflection is crucial to support for example functional upgrades, on-the-fly debugging, or monitoring critical applications. However the use of reflective features can lead to severe problems due to infinite meta-call recursion even in simple cases. This is especially a problem when reflecting on core language features since there is a high chance that such features are used to implement the reflective behavior itself. In this paper we analyze the problem of infinite meta-object call recursion and solve it by providing a first class representation of meta-level execution: at any point in the execution of a system it can be determined if we are operating on a meta-level or base level so that we can prevent infinite recursion. We present how meta-level execution can be represented by a meta-context and how reflection becomes context-aware. Our solution makes it possible to freely apply behavioral reflection\u252c\u00e1\u0393\u00c7\u00aa", "num_citations": "37\n", "authors": ["54"]}
{"title": "Rule-based Assessment of Test Quality.\n", "abstract": " With the success of agile methodologies more and more projects develop large test suites to ensure that the system is behaving as expected. Not only do tests ensure correctness, but they also offer a live documentation for the code. However, as the system evolves, the tests need to evolve as well to keep up with the system, and as the test suite grows larger, the effort invested into maintaining tests is a significant activity. In this context, the quality of tests becomes an important issue, as developers need to assess and understand the tests they have to maintain. In this paper we present TestLint, an approach together with an experimental tool for qualifying tests. We define a set of criteria to determine test quality, and we evaluate our approach on a large sample of unit tests found in open-source projects.", "num_citations": "37\n", "authors": ["54"]}
{"title": "Stateful traits\n", "abstract": " Traits offer a fine-grained mechanism to compose classes from reusable components while avoiding problems of fragility brought by multiple inheritance and mixins. Traits as originally proposed are stateless, that is, they contain only methods, but no instance variables. State can only be accessed within traits by accessors, which become required methods of the trait. Although this approach works reasonably well in practice, it means that many traits, viewed as software components, are artificially incomplete, and classes that use such traits may contain significant amounts of boilerplate glue code. Although these limitations are largely mitigated by proper tool support, we seek a cleaner solution that supports stateful traits. The key difficulty is how to handle conflicts that arise when composed traits contribute instance variables whose names clash. We present a solution that is faithful to the guiding principle of\u252c\u00e1\u0393\u00c7\u00aa", "num_citations": "36\n", "authors": ["54"]}
{"title": "A group based approach for coordinating active objects\n", "abstract": " Although coordination of concurrent objects is a fundamental aspect of object-oriented concurrent programming, there is only little support for its specification and abstraction at the language level. This is a problem because coordination is often buried in the code of the coordinated objects, leading to a lack of abstraction and reuse. Here we present CoLaS, a coordination model and its implementation based on the notion of Coordination Groups. By clearly identifying and separating the coordination from the coordinated objects CoLaS provides a better abstraction and reuse of the coordination and the coordinated objects. Moreover CoLaS\u0393\u00c7\u00d6s high dynamicity provides better support for coordination of active objects.", "num_citations": "36\n", "authors": ["54"]}
{"title": "Composable encapsulation policies\n", "abstract": " Given the importance of encapsulation to object-oriented programming, it is surprising to note that mainstream object-oriented languages offer only limited and fixed ways of encapsulating methods. Typically one may only address two categories of clients, users and heirs, and one must bind visibility and access rights at an early stage. This can lead to inflexible and fragile code as well as clumsy workarounds. We propose a simple and general solution to this problem in which encapsulation policies can be specified separately from implementations. As such they become composable entities that can be reused by different classes. We present a detailed analysis of the problem with encapsulation and visibility mechanisms in mainstream OO languages, we introduce our approach in terms of a simple model, and we evaluate how our approach compares with existing approaches. We also assess the impact of\u252c\u00e1\u0393\u00c7\u00aa", "num_citations": "35\n", "authors": ["54"]}
{"title": "Unanticipated integration of development tools using the classification model\n", "abstract": " The increasing complexity of software development spawns lots of specialised tools to edit code, employ UML schemes, integrate documentation, and so on. The problem is that the tool builders themselves are responsible for making their tools interoperable with other tools or development environments. Because they cannot anticipate all other tools they can integrate with, a lot of tools cannot co-operate. This paper introduces the classification model, a lightweight integration medium that enables unrelated tools that were not meant to be integrated to cooperate easily. Moreover, the tool integration is done by a tool integrator, and not by the tool builder. To validate this claim, we show how to integrate several third-party tools using the classification model, and how it forms the foundation for the StarBrowser, a Smalltalk browser integrating different tools.", "num_citations": "35\n", "authors": ["54"]}
{"title": "Preliminary steps towards modeling blockchain oriented software\n", "abstract": " Even though blockchain is mostly popular for its cryptocurrency, smart contracts have become a very prominent blockchain application. Smart contracts are like classes that can be called by client applications outside the blockchain. Therefore it is possible to develop blockchain-oriented software (BOS) that implements part of the business logic in the blockchain by using smart contracts. Currently, there is no design standard to model BOS. Since modeling is an important part of designing a software, developers may struggle to plan their BOS. In this paper, we show three complementary modeling approaches based on well-known software engineering models and apply them to a BOS example. Our goal is to start the discussion on specialized blockchain modeling notations.", "num_citations": "34\n", "authors": ["54"]}
{"title": "Zero-overhead metaprogramming: Reflection and metaobject protocols fast and without compromises\n", "abstract": " Runtime metaprogramming enables many useful applications and is often a convenient solution to solve problems in a generic way, which makes it widely used in frameworks, middleware, and domain-specific languages. However, powerful metaobject protocols are rarely supported and even common concepts such as reflective method invocation or dynamic proxies are not optimized. Solutions proposed in literature either restrict the metaprogramming capabilities or require application or library developers to apply performance improving techniques. For overhead-free runtime metaprogramming, we demonstrate that dispatch chains, a generalized form of polymorphic inline caches common to self-optimizing interpreters, are a simple optimization at the language-implementation level. Our evaluation with self-optimizing interpreters shows that unrestricted metaobject protocols can be realized for the first time\u252c\u00e1\u0393\u00c7\u00aa", "num_citations": "34\n", "authors": ["54"]}
{"title": "Read-only execution for dynamic languages\n", "abstract": " Supporting read-only and side effect free execution has been the focus of a large body of work in the area of statically typed programming languages. Read-onlyness in dynamically typed languages is difficult to achieve because of the absence of a type checking phase and the support of an open-world assumption in which code can be constantly added and modified. To address this issue, we propose Dynamic Read-Only references (DRO) that provide a view on an object where this object and its object graph are protected from modification. The read-only view dynamically propagates to aggregated objects, without changing the object graph itself; it acts as a read-only view of complex data structures, without making them read-only globally. We implement dynamic read-only references by using smart object proxies that lazily propagate the read-only view, following the object graph and driven by control\u252c\u00e1\u0393\u00c7\u00aa", "num_citations": "33\n", "authors": ["54"]}
{"title": "Identifying traits with formal concept analysis\n", "abstract": " Traits are basically mixins or interfaces but with method bodies. In languages that support traits, classes are composed out of traits. There are two main advantages with traits. Firstly, decomposing existing classes into traits from which they can be recomposed improves the factoring of hierarchies. Secondly it increases the library reuse potential by providing more reusable traits. Identifying traits and decomposing class hierarchies into traits is therefore an important and challenging task to facilitate maintainability and evolution. In this paper we present how we use Formal Concept Analysis to identify traits in inheritance hierarchies. Our approach is two-staged: first we identify within a hierarchy maximal groups of methods that have a set of classes in common, second we cluster cohesive groups of methods based on method invocations as potential traits. We applied our approach on two significant hierarchies and\u252c\u00e1\u0393\u00c7\u00aa", "num_citations": "33\n", "authors": ["54"]}
{"title": "OpenSpaces: an object-oriented framework for reconfigurable coordination spaces\n", "abstract": " Tuple spaces have turned out to be one of the most fundamental abstractions for coordinating communicating agents. At the same time, researchers continue to propose new variants of tuple spaces, since no one approach seems to be universally applicable to all problem domains. Some models offer a certain configurability, but existing approaches generally stop at a fixed set of configuration options and static configuration at instantiation time. We argue that a more open approach is needed, and present OpenSpaces, an object-oriented framework that supports static configurability through subclassing across several dimensions, as well as dynamic configurability of policies through run-time composition. We introduce OpenSpaces by showing how it can be used to instantiate a typical application, and we present an overview of the framework, implemented in Smalltalk, detailing the various degrees of\u252c\u00e1\u0393\u00c7\u00aa", "num_citations": "33\n", "authors": ["54"]}
{"title": "Tool support for refactoring duplicated OO code\n", "abstract": " Code duplication is an important problem in application maintenance. Tools exist that support code duplication detection. However, few of them propose a solution for the problem, ie refactorings. We propose an approach that uses the information given by code duplication detection to guide the refactorings of OO applications.", "num_citations": "33\n", "authors": ["54"]}
{"title": "Tracing vs. partial evaluation: Comparing meta-compilation approaches for self-optimizing interpreters\n", "abstract": " Tracing and partial evaluation have been proposed as meta-compilation techniques for interpreters to make just-in-time compilation language-independent. They promise that programs executing on simple interpreters can reach performance of the same order of magnitude as if they would be executed on state-of-the-art virtual machines with highly optimizing just-in-time compilers built for a specific language. Tracing and partial evaluation approach this meta-compilation from two ends of a spectrum, resulting in different sets of tradeoffs. This study investigates both approaches in the context of self-optimizing interpreters, a technique for building fast abstract-syntax-tree interpreters. Based on RPython for tracing and Truffle for partial evaluation, we assess the two approaches by comparing the impact of various optimizations on the performance of an interpreter for SOM, an object-oriented dynamically-typed\u252c\u00e1\u0393\u00c7\u00aa", "num_citations": "32\n", "authors": ["54"]}
{"title": "Using Smalltalk as a reflective executable meta-language\n", "abstract": " Object-oriented meta-languages such as MOF or EMOF are often used to specify domain specific languages. However, these meta-languages lack the ability to describe behavior or operational semantics. Several approaches have used a subset of Java mixed with OCL as executable meta-languages. In this paper, we report our experience of using Smalltalk as an executable meta-language. We validated this approach in incrementally building over the last decade, Moose, a meta-described reengineering environment. The reflective capabilities of Smalltalk support a uniform way of letting the developer focus on his tasks while at the same time allowing him to meta-describe his domain model. The advantage of our approach is that the developer uses the same tools and environment he uses for his regular tasks.", "num_citations": "32\n", "authors": ["54"]}
{"title": "Oopal: integrating array programming in object-oriented programming\n", "abstract": " Array programming shines in its ability to express computations at a high-level of abstraction, allowing one to manipulate and query whole sets of data at once. This paper presents the OPA model that enhances object-oriented programming with array programming features. The goal of OPA is to determine a minimum set of modifications that must be made to the traditional object model in order to take advantage of the possibilities of array programming. It is based on a minimal extension of method invocation and the definition of a kernel of methods implementing fundamental array programming operations. The OPA model presents a generalization of traditional message passing in the sense that a message can be send to an entire set of objects. The model is validated in FS, a new scripting language.", "num_citations": "32\n", "authors": ["54"]}
{"title": "Domain specific warnings: Are they any better?\n", "abstract": " Tools to detect coding standard violations in source code are commonly used to improve code quality. One of their original goals is to prevent bugs, yet, a high number of false positives is generated by the rules of these tools, i.e., most warnings do not indicate real bugs. There are empirical evidences supporting the intuition that the rules enforced by such tools do not prevent the introduction of bugs in software. This may occur because the rules are too generic and do not focus on domain specific problems of the software under analysis. We underwent an investigation of rules created for a specific domain based on expert opinion to understand if such rules are worthwhile enforcing in the context of defect prevention. In this paper, we performed a systematic study to investigate the relation between generic and domain specific warnings and observed defects. From our experiment on a real case, long term evolution\u252c\u00e1\u0393\u00c7\u00aa", "num_citations": "31\n", "authors": ["54"]}
{"title": "Ring: a unifying meta-model and infrastructure for Smalltalk source code analysis tools\n", "abstract": " Source code management systems record different versions of code. Tool support can then compute deltas between versions. To ease version history analysis we need adequate models to represent source code entities. Now naturally the questions of their definition, the abstractions they use, and the APIs of such models are raised, especially in the context of a reflective system which already offers a model of its own structure.We believe that this problem is due to the lack of a powerful code meta-model as well as an infrastructure. In Smalltalk, often several source code meta-models coexist: the Smalltalk reflective API coexists with the one of the Refactoring engine or distributed versioning system such as Monticello or Store. While having specific meta-models is an adequate engineered solution, it multiplies meta-models and it requires more maintenance efforts (e.g., duplication of tests, transformation between\u252c\u00e1\u0393\u00c7\u00aa", "num_citations": "30\n", "authors": ["54"]}
{"title": "Efficient retrieval and ranking of undesired package cycles in large software systems\n", "abstract": " Many design guidelines state that a software system architecture should avoid cycles between its packages. Yet such cycles appear again and again in many programs. We believe that the existing approaches for cycle detection are too coarse to assist the developers to remove cycles from their programs. In this paper, we describe an efficient algorithm that performs a fine-grained analysis of the cycles among the packages of an application. In addition, we define a metric to rank cycles by their level of undesirability, prioritizing the cycles that seems the more undesired by the developers. Our approach is validated on two large and mature software systems in Java and Smalltalk.", "num_citations": "30\n", "authors": ["54"]}
{"title": "Visually supporting source code changes integration: the torch dashboard\n", "abstract": " Automatic and advanced merging algorithms help programmers to merge their modifications in main development repositories. However, there is little support to help release masters (integrators) to take decisions about the integration of published merged changes into the system release. Most of the time, the release master has to read all the changed code, check the diffs to build an idea of a change, and read unchanged code to understand the context of some changes. Such a task can be overwhelming. In this paper we present a dashboard to support integrators getting an overview of proposed changes in the context of object-oriented programming. Our approach named Torch characterizes changes based on structural information, authors and symbolic information. It mixes text-based diff information with visual representation and metrics characterizing the changes. We describe our experiment applying it to\u252c\u00e1\u0393\u00c7\u00aa", "num_citations": "30\n", "authors": ["54"]}
{"title": "Squeak: Learn programming with robots\n", "abstract": " Are you completely new to programming? Do you want to have fun learning to program? Squeak: Learn Programming with Robots will teach you core programming concepts based on simple, visual problems that involve manipulation of robots, or\" turtles.\" You will learn basic programming concepts like loops, abstractions, composition, and conditionals. Each chapter is structured so that it can be turned into a one-or two-hour lab session. And while the structured content explains solid principles of object-oriented programming, you\u0393\u00c7\u00d6ll just have fun going through the sequence of easy examples with the turtle. And be sure to check out BotsInc, the companion learning environment for this book.", "num_citations": "30\n", "authors": ["54"]}
{"title": "An empirical model for continuous and weighted metric aggregation\n", "abstract": " It is now understood that software metrics alone are not enough to characterize software quality. To cope with this problem, most of advanced and/or industrially validated quality models aggregate software metrics: for example, cyclomatic complexity is combined with test coverage to stress the fact that it is more important to cover complex methods than accessors. Yet, aggregating and weighting metrics to produce quality indexes is a difficult task. Indeed, certain weighting approaches may lead to abnormal situations where a developer increasing the quality of a software component seeing the overall quality degrade. Finally, mapping combinations of metric values to quality indexes may be a problem when using thresholds. In this paper, we present the problems we faced when designing the Squale quality model, then we present an empirical solution based on weighted aggregations and on continuous functions\u252c\u00e1\u0393\u00c7\u00aa", "num_citations": "29\n", "authors": ["54"]}
{"title": "Symbiotic reflection between an object-oriented and a logic programming language\n", "abstract": " Meta-programming is the act of using one system or language to reason about another one. Reflection describes systems that have access to and change a causally connected representation of themselves, hence leading to self-extensible systems. Up to now, most of the reflective languages have been implemented in the same paradigm. In this paper, we propose symbiotic reflection as a way to integrate a meta-programming language with the object-oriented language it reasons about and is implemented in. New to this approach is that any element of the implementation language can be reasoned about and acted upon (not only the self representation), and that both languages are of different paradigms. Moreover, every language implementer that is faced with the problem of allowing the base language to access the underlying meta-language has to solve the problem of enabling entity transfer between both worlds. We propose a uniform schema, called upping/downing, to this problem that avoid explicit wrapping or typechecking. We illustrate this with SOUL (the Smalltalk Open Unification Language), a logic programming language in symbiotic reflection with the object-oriented programming language Smalltalk. We show how SOUL does logic reasoning directly on Smalltalk objects, and how to use this to implement type snooping. The contributions of this paper are:(1) the definition of symbiotic reflection,(2) a schema for enabling entities transfer between multiple paradigms,(3) examples of symbiotic reflection.", "num_citations": "29\n", "authors": ["54"]}
{"title": "Generating a catalog of unanticipated schemas in class hierarchies using formal concept analysis\n", "abstract": " ContextInheritance is the cornerstone of object-oriented development, supporting conceptual modeling, subtype polymorphism and software reuse. But inheritance can be used in subtle ways that make complex systems hard to understand and extend, due to the presence of implicit dependencies in the inheritance hierarchy.ObjectiveAlthough these dependencies often specify well-known schemas (i.e., recurrent design or coding patterns, such as hook and template methods), new unanticipated dependency schemas arise in practice, and can consequently be hard to recognize and detect. Thus, a developer making changes or extensions to an object-oriented system needs to understand these implicit contracts defined by the dependencies between a class and its subclasses, or risk that seemingly innocuous changes break them.MethodTo tackle this problem, we have developed an approach based on Formal\u252c\u00e1\u0393\u00c7\u00aa", "num_citations": "27\n", "authors": ["54"]}
{"title": "Magritte\u0393\u00c7\u00f4a meta-driven approach to empower developers and end users\n", "abstract": " Model-driven engineering is a powerful approach to build large-scale applications. However, an application\u0393\u00c7\u00d6s metamodel often remains static after the initial development phase and cannot be changed unless a new development effort occurs. Yet, end users often need to rapidly adapt their applications to new needs. In many cases, end users would know how to make the required adaptations, if only the application would let them do so. In this paper we present how we built a runtime-dynamic meta-environment into Smalltalk\u0393\u00c7\u00d6s reflective language model. Our solution offers the best of both worlds: developers can develop their applications using the same tools they are used to and gain the power of meta-programming. We show in particular that our approach is suitable to support end user customization without writing new code: the adaptive model of Magritte not only describes existing classes, but also lets\u252c\u00e1\u0393\u00c7\u00aa", "num_citations": "27\n", "authors": ["54"]}
{"title": "Ethereum query language\n", "abstract": " Blockchains store a massive amount of heterogeneous data which will only grow in time. When searching for data on the Ethereum platform, one is required to either access the records (blocks) directly by using a unique identifier, or sequentially search several records to find the desired information. Therefore, we propose the Ethereum Query Language (EQL), a query language that allows users to retrieve information from the blockchain by writing SQL-like queries. The queries provide a rich syntax to specify data elements to search information scattered through several records. We claim that EQL makes it easier to search, acquire, format, and present information from the blockchain.", "num_citations": "26\n", "authors": ["54"]}
{"title": "Mining system specific rules from change patterns\n", "abstract": " A significant percentage of warnings reported by tools to detect coding standard violations are false positives. Thus, there are some works dedicated to provide better rules by mining them from source code history, analyzing bug-fixes or changes between system releases. However, software evolves over time, and during development not only bugs are fixed, but also features are added, and code is refactored. In such cases, changes must be consistently applied in source code to avoid maintenance problems. In this paper, we propose to extract system specific rules by mining systematic changes over source code history, i.e., not just from bug-fixes or system releases, to ensure that changes are consistently applied over source code. We focus on structural changes done to support API modification or evolution with the goal of providing better rules to developers. Also, rules are mined from predefined rule patterns\u252c\u00e1\u0393\u00c7\u00aa", "num_citations": "25\n", "authors": ["54"]}
{"title": "A framework to compare alert ranking algorithms\n", "abstract": " To improve software quality, rule checkers statically check if a software contains violations of good programming practices. On a real sized system, the alerts (rule violations detected by the tool) may be numbered by the thousands. Unfortunately, these tools generate a high proportion of \"false alerts\", which in the context of a specific software, should not be fixed. Huge numbers of false alerts may render impossible the finding and correction of \"true alerts\" and dissuade developers from using these tools. In order to overcome this problem, the literature provides different ranking methods that aim at computing the probability of an alert being a \"true one\". In this paper, we propose a framework for comparing these ranking algorithms and identify the best approach to rank alerts. We have selected six algorithms described in literature. For comparison, we use a benchmark covering two programming languages (Java and\u252c\u00e1\u0393\u00c7\u00aa", "num_citations": "25\n", "authors": ["54"]}
{"title": "Dynamic web development with seaside\n", "abstract": " Seaside is the open source framework of choice for developing sophisticated and dynamic web applications. Seaside uses the power of objects to master the web. With Seaside web applications is as simple as building desktop applications. Seaside lets you build highly dynamic and interactive web applications. Seaside supports agile development through interactive debugging and unit testing. Seaside is based on Smalltalk, a proven and robust language implemented by different vendors. Seaside is now available for all the major Smalltalk including Pharo, Squeak, GNU Smalltalk, Cincom Smalltalk, GemStone Smalltalk, and VA Smalltalk.", "num_citations": "25\n", "authors": ["54"]}
{"title": "Capturing how objects flow at runtime\n", "abstract": " Most of today\u0393\u00c7\u00d6s dynamic analysis approaches are based on method traces. However, in the case of objectorientation understanding program execution by analyzing method traces is complicated because the behavior of a program depends on the sharing and the transfer of object references (aliasing). We argue that trace-based dynamic analysis is at a too low level of abstraction for objectoriented systems. We propose a new approach that captures the life cycle of objects by explicitly taking into account object aliasing and how aliases propagate during the execution of the program. In this paper, we present in detail our new meta-model and discuss future tracks opened by it.", "num_citations": "24\n", "authors": ["54"]}
{"title": "Dimensions of reengineering environment infrastructures\n", "abstract": " Over the last decade many research groups and commercial companies have been developing reengineering environments. However, many design decisions such as support for multiple models, incremental loading of information, tool integration, entity grouping, and their impacts on the underlying meta\u0393\u00c7\u00c9model and resulting environment have remained implicit. Based on the experience accumulated while developing the Moose reengineering environment and on a survey of reengineering environments, we present a design space defined by a set of criteria that makes explicit the different options and especially their dependencies and trade\u0393\u00c7\u00c9offs. Using this design space, developers of future environments should have a better understanding of the problems they face and the impact of design choices. Copyright \u252c\u2310 2003 John Wiley & Sons, Ltd.", "num_citations": "24\n", "authors": ["54"]}
{"title": "PECOS in a Nutshell\n", "abstract": " Software is more and more becoming the major cost factor for embedded devices. In fact, software accounts for more than 50 percent of the development costs of such a device. The PECOS (PErvasive Component Systems) project seeks to overcome this by providing a component-based technology for the development of a specific class of embedded systems known as\u0393\u00c7\u00a5 field devices\u0393\u00c7\u00a5. It takes into account the specific properties of this application area. Therefore the PECOS project has developed a component model, a composition language, and tools for field device software development which help to overcome the shortcomings of the current practice. The PECOS approach covers the whole software life-cycle of a field device. It defines a detailed software process which coordinates all development steps from requirements specification to deployment.The PECOS project consortium consists of four partners: ABB Corporate Research Centre in Ladenburg, Research Centre for Information Technologies (FZI), the Software Composition Group at the University of Bern (SCG), and Object Technology International (OTI). The roles of the partners within the project has been the following. ABB acted as main contractor, project coordinator and user in the project: ABB\u0393\u00c7\u00d6s Instruments Business Unit is developing a large number of different field devices and aims at introducing component based technology in their production. In addition, ABB has got expert knowledge in the field device domain and has carried out a number of case studies within the project. FZI and SCG have been charged with the research part of the project, which concerned the PECOS\u252c\u00e1\u0393\u00c7\u00aa", "num_citations": "24\n", "authors": ["54"]}
{"title": "Beyond language independent object-oriented metrics: Model independent metrics\n", "abstract": " Software Metrics have become essential in software engineering for several reasons, among which quality assessment and reengineering. In the context of the European Esprit Project FAMOOS, whose main goal was to provide methodologies for the reengineering of large industrial software systems, we have developed the Moose Reengineering Environment, based on the language independent FAMIX metamodel. Moose includes a metrics engine which supports language independent metrics, since coping with software written in different implementation languages was one of the project\u0393\u00c7\u00d6s main constraints. Our current research is pushing us towards the development and implementation of a metametamodel, which would include our metamodel and allow for several extension in different research directions, among which concept analysis, knowledge management and software evolution. In this article we want to present our current and future work for the transition from language independent to domain independent metrics.", "num_citations": "24\n", "authors": ["54"]}
{"title": "Test case selection in industry: An analysis of issues related to static approaches\n", "abstract": " Automatic testing constitutes an important part of everyday development practice. Worldline, a major IT company, is creating more and more tests to ensure the good behavior of its applications and gains in efficiency and quality. But running all these tests may take hours. This is especially true for large systems involving, for example, the deployment of a web server or communication with a database. For this reason, tests are not launched as often as they should be and are mostly run at night. The company wishes to improve its development and testing process by giving to developers rapid feedback after a change. An interesting solution is to reduce the number of tests to run by identifying only those exercising the piece of code changed. Two main approaches are proposed in the literature: static and dynamic. The static approach creates a model of the source code and explores it to find links between\u252c\u00e1\u0393\u00c7\u00aa", "num_citations": "23\n", "authors": ["54"]}
{"title": "Visually characterizing source code changes\n", "abstract": " Revision Control Systems (e.g., SVN, Git, Mercurial) include automatic and advanced merging algorithms that help developers to merge their modifications with development repositories. While these systems can help to textually detect conflicts, they do not help to identify the semantic consequences of a change. Unfortunately, there is little support to help release masters (integrators) to take decisions about the integration of changes into the system release. Most of the time, the release master needs to read all the modified code, check the diffs to build an idea of a change, and dig for details from related unchanged code to understand the context and potential impact of some changes. As a result, such a task can be overwhelming. In this article we present a visualization tool to support integrators of object-oriented programs in comprehending changes. Our approach named Torch characterizes changes based on\u252c\u00e1\u0393\u00c7\u00aa", "num_citations": "23\n", "authors": ["54"]}
{"title": "Representing code history with development environment events\n", "abstract": " Modern development environments handle information about the intent of the programmer: for example, they use abstract syntax trees for providing high-level code manipulation such as refactorings; nevertheless, they do not keep track of this information in a way that would simplify code sharing and change understanding. In most Smalltalk systems, source code modifications are immediately registered in a transaction log often called a ChangeSet. Such mechanism has proven reliability, but it has several limitations. In this paper we analyse such limitations and describe scenarios and requirements for tracking fine-grained code history with a semantic representation. We present Epicea, an early prototype implementation. We want to enrich code sharing with extra information from the IDE, which will help understanding the intention of the changes and let a new generation of tools act in consequence.", "num_citations": "23\n", "authors": ["54"]}
{"title": "Efficient proxies in Smalltalk\n", "abstract": " A proxy object is a surrogate or placeholder that controls access to another target object. Proxy objects are a widely used solution for different scenarios such as remote method invocation, future objects, behavioral reflection, object databases, inter-languages communications and bindings, access control, lazy or parallel evaluation, security, among others.", "num_citations": "23\n", "authors": ["54"]}
{"title": "Introducing knowledge in the process of supervised classification of activities of Daily Living in Health Smart Homes\n", "abstract": " Telemedicine and Telemonitoring of elderly people is an actual challenge that is explored to prevent some problems linked to the constant growing of the mean age of the population. It requires to recognize the behavior and the actions of a person inside his own home with non-intrusive sensors and to process data to check the evolution of the person. Activities of Daily Living can be learned and automatically recognized using supervised classification on sensor data. This paper presents the results of the study of prior introduction, in Support Vector Machine, to improve this automatic recognition of Activities of Daily Living. We started from a set of data acquired in daily life during an experimentation in the Health Smart Home of the TIMC-IMAG Lab. From this restricted set of data, we obtained models for seven activities of Daily Living and test, with leave-one-out method, the performance of this classification. This first\u252c\u00e1\u0393\u00c7\u00aa", "num_citations": "23\n", "authors": ["54"]}
{"title": "Squale\u0393\u00c7\u00f4software quality enhancement\n", "abstract": " The Squale project was born from industrial effort to control software quality. Its goals are to refine and enhance Qualixo model, a software-metric based quality model already used by large companies in France (Air France-KLM, PSA Peugeot-Citroen) and to support the estimation of return on investment produced by software quality. Qualixo model is a software quality model based on the aggregation of software metrics into higher level indicators called practices, criterias and factors. The coordination of Squale is carried out by Qualixo.", "num_citations": "22\n", "authors": ["54"]}
{"title": "How developers develop features\n", "abstract": " Software systems are typically developed by teams of developers, with responsibilities for different parts of the code. Knowledge of how the developers collaborate, and how their responsibilities are distributed over the software artifacts is a valuable source of information when reverse engineering a system. Determining which developers are responsible for which software artifacts (e.g., packages or classes) is just one perspective. In this paper we complement the static perspective with the dynamic perspective of a system in terms of its features. We want to extract information about which developers are responsible for which features. To achieve these two perspectives, we correlate developer responsibilities both with a structural view of the system and with a feature view. We identify which developers are responsible for which features, and whether the responsibilities correspond with structural source code artifacts\u252c\u00e1\u0393\u00c7\u00aa", "num_citations": "22\n", "authors": ["54"]}
{"title": "Adding state and visibility control to traits using lexical nesting\n", "abstract": " Traits are reusable building blocks that can be composed to share methods across unrelated class hierarchies. Original traits are stateless and cannot express visibility control for methods. Two extensions, stateful traits and freezable traits, have been proposed to overcome these limitations. However, these extensions introduce complexity and have not yet been combined to simultaneously add both state and visibility control to traits.               This paper revisits the addition of state and visibility control to traits. Rather than extending the original traits model with additional operations, we allow traits to be lexically nested within other modules. Traits can then have (shared) state and visibility control by hiding variables or methods in their lexical scope. Although the Traits\u0393\u00c7\u00d6 \u0393\u00c7\u00a3flattening property\u0393\u00c7\u00a5 has to be revisited, the combination of traits with lexical nesting results in a simple and expressive trait model. We discuss\u252c\u00e1\u0393\u00c7\u00aa", "num_citations": "21\n", "authors": ["54"]}
{"title": "Identifying entities that change together\n", "abstract": " 1 Software system need to change over time to cope with the new requirements. Furthermore, due to design decisions, the new requirements happen to crosscut the system\u0393\u00c7\u00d6s structure. Understanding how changes appear in the system can reveal hidden dependencies between different parts of the system. We propose to group entities that change together according to a logical expression that specifies the change condition. Furthermore, we can group entities at different levels of abstraction (ie, method, class, package). Our approach is based on an explicit history meta model that centers around the notion of history and which enables the definition of historical measurements which summarize the changes. We apply our approach on two large case studies and show how we can identify groups of related entities and detect bad smells.", "num_citations": "21\n", "authors": ["54"]}
{"title": "Understanding classes using X-Ray views\n", "abstract": " Understanding the internal workings of classes is a key prerequisite to maintaining an object-oriented software system. Unfortunately, classical editing and browsing tools offer mainly linear and textual views of classes and their implementation. These views fail to expose the semantic relationships between the internal parts of a class. We propose XRay views\u0393\u00c7\u00f6a technique based on Concept Analysis\u0393\u00c7\u00f6which reveal the internal relationships between groups of methods and attributes of a class. XRay views are composed out of elementary collaborations between attributes and methods and help the engineer to build a mental model of how a class works internally. In this paper we present XRay views, and illustrate the approach by applying it to three Smalltalk classes: OrderedCollection, Scanner, and UIBuilder.", "num_citations": "21\n", "authors": ["54"]}
{"title": "Composition languages for black-box components\n", "abstract": " Supporting reuse of existing pieces of code is one of the main goals of software engineering. In the name of reuse, modulebased programming languages came to be, only to be surpassed by object-oriented technology. With the same motivation component-based solutions are overtaking objectoriented solutions. However, the delegation-only focus of component-based programming risks of resulting in the same problems that modular-based approaches ran into. To counter this, we claim that one of the important problems that should be addressed by component languages is the composition of components. More specifically, we see component languages where components are black-box abstractions, and with (one or more) composition languages to glue them together. As an example we show a functional (Piccola) and a logic (QSoul) composition approach.", "num_citations": "21\n", "authors": ["54"]}
{"title": "Towards a methodology for the understanding of object-oriented systems\n", "abstract": " La phase de compr\u251c\u2310hension et d\u0393\u00c7\u00d6analyse (reverse engineering) lors de la r\u251c\u2310tro-conception d\u0393\u00c7\u00d6applications \u251c\u00e1 objets rencontre les probl\u251c\u00bfmes typiques des grands syst\u251c\u00bfmes (large scale systems), \u251c\u00e1 savoir le manque de vue d\u0393\u00c7\u00d6ensemble et la n\u251c\u2310cessit\u251c\u2310 de se focaliser sur les parties int\u251c\u2310ressantes. Afin d\u0393\u00c7\u00d6aider cette t\u251c\u00f3che, nous avons propos\u251c\u2310 une approche hybride combinant l\u0393\u00c7\u00d6attrait de la visualisation avec celui des m\u251c\u2310triques. Cependant, notre approche manquait d\u0393\u00c7\u00d6une m\u251c\u2310thodologie qui guide le r\u251c\u2310tro-concepteur. Dans cet article, nous pr\u251c\u2310sentons une premi\u251c\u00bfre m\u251c\u2310thodologie que nous avons \u251c\u2310labor\u251c\u2310e et valid\u251c\u2310e au cours de nos exp\u251c\u2310riences industrielles.", "num_citations": "21\n", "authors": ["54"]}
{"title": "Dynamic type inference to support object-oriented reengineering in Smalltalk\n", "abstract": " Type information is a crucial information to support object-oriented reengineering. In a dynamically typed language like Smalltalk standard static type inference is a complex and heavily computational task. In this paper, we report how we use message passing control and compiler extension to support dynamic inference type in Smalltalk.", "num_citations": "21\n", "authors": ["54"]}
{"title": "Clustered serialization with fuel\n", "abstract": " Serializing object graphs is an important activity since objects should be stored and reloaded on different environments. There is a plethora of frameworks to serialize objects based on recursive parsing of the object graphs. However such approaches are often too slow. Most approaches are limited in their provided features. For example, several serializers do not support class shape changes, global references, transient references or hooks to execute something before or after being stored or loaded. Moreover, to be faster, some serializers are not written taking into account the object-oriented paradigm and they are sometimes even implemented in the Virtual Machine hampering code portability. VM-based serializers such as ImageSegment are difficult to understand, maintain, and fix. For the final user, it means a serializer which is difficult to customize, adapt or extend to his own needs.", "num_citations": "20\n", "authors": ["54"]}
{"title": "User-changeable visibility: Resolving unanticipated name clashes in traits\n", "abstract": " A trait is a unit of behaviour that can be composed with other traits and used by classes. Traits offer an alternative to multiple inheritance. Conflict resolution of traits, while flexible, does not completely handle accidental method name conflicts: if a trait with method m is composed with another trait defining a different method m then resolving the conflict may prove delicate or infeasible in cases where both versions of m are still needed. In this paper we present freezeable traits, which provide an expressive composition mechanism to support unanticipated method composition conflicts. Our solution introduces private trait methods and lets the class composer change method visibility at composition time (from public to private and vice versa). Moreover two class composers may use different composition policies for the same trait, something which is not possible in mainstream languages. This approach respects the two\u252c\u00e1\u0393\u00c7\u00aa", "num_citations": "20\n", "authors": ["54"]}
{"title": "Domain-specific program checking\n", "abstract": " Lint-like program checkers are popular tools that ensure code quality by verifying compliance with best practices for a particular programming language. The proliferation of internal domain-specific languages and models, however, poses new challenges for such tools. Traditional program checkers produce many false positives and fail to accurately check constraints, best practices, common errors, possible optimizations and portability issues particular to domain-specific languages. We advocate the use of dedicated rules to check domain-specific practices. We demonstrate the implementation of domain-specific rules, the automatic repair of violations, and their application to two case-studies: (1) Seaside defines several internal DSLs through a creative use of the syntax of the host language; and (2) Magritte adds meta-descriptions to existing code by means of special methods. Our empirical validation\u252c\u00e1\u0393\u00c7\u00aa", "num_citations": "19\n", "authors": ["54"]}
{"title": "SmallWiki: a meta-described collaborative content management system\n", "abstract": " Wikis are often implemented using string-based approaches to parse and generate their pages. While such approaches work well for simple wikis, they hamper the customization and adaptability of wikis to the variety of end-users when more sophisticated needs are required (ie, different output formats, user-interfaces, wiki management, security policies,...). In this paper we present SmallWiki, the second version of a fully object-oriented implementation of a wiki. SmallWiki is implemented with objects from the top to the bottom and it can be customized easily to accommodate new needs. In addition, SmallWiki is based on a powerful meta-description called Magritte that allows one to create user-interface elements declaratively.", "num_citations": "19\n", "authors": ["54"]}
{"title": "Non-functional requirements in a component model for embedded systems\n", "abstract": " In this paper we describe an interesting context to study formal methods for component systems: embedded devices. The context of embedded devices is highly constrained by the physical requirements the devices have to adhere to. As a result, component models for embedded devices are not general purpose but geared towards these constrained contexts. In this paper we give the concrete setting of the Pecos project (a project with as goal component engineering for embedded devices). We describe the Pecos component model, and show possibilities where we think formal verification could be useful. We would like to use this as a very concrete example to discuss formal verification techniques.", "num_citations": "19\n", "authors": ["54"]}
{"title": "Understanding Object-Oriented Programs through Declarative Event Analysis\n", "abstract": " An essential aspect of understanding a software application is understanding how components in an application interact to ensure a certain functionality. We are developing a tool in which dynamic information is used to aid in this task: tracing events from program executions can help to recover design artifacts such as use-cases and scenarios, and to extract information about run-time instances and their interaction protocols-information which can not be easily derived through a static analysis of the code. We believe that a good tool for program understanding should allow an engineer to formulate hypotheses about the structure of the software, and to conrm or reject hypotheses based on evidence from the source code. One such tool is described by Murphy in MN97. It allows an engineer to dene a high-level model of the software system and a mapping of the source-code onto this model. Areexion model'is then computed which shows how close the high-level model comes to describing the source code. This allows the engineer to iteratively rene the high-level model, so that it better reects the implementation. Our tool development is inspired by the work of Murphy MN97 in using static information to compute'reexion models'. Our aim is to allow an engineer to make queries depending on his strategy for understanding the code and on the aspect he is particularly interested in. Each query about an hypothesis gives a view of the software system, and dierent views can also be combined to get a better understanding of the software YHC97. Our approach can be summarized as follows:Instrument a program to capture method invocations To generate\u252c\u00e1\u0393\u00c7\u00aa", "num_citations": "19\n", "authors": ["54"]}
{"title": "Bootstrapping reflective systems: The case of pharo\n", "abstract": " Bootstrapping is a technique commonly known by its usage in language definition by the introduction of a compiler written in the same language it compiles. This process is important to understand and modify the definition of a given language using the same language, taking benefit of the abstractions and expression power it provides. A bootstrap, then, supports the evolution of a language. However, the infrastructure of reflective systems like Smalltalk includes, in addition to a compiler, an environment with several self-references. A reflective system bootstrap should consider all its infrastructural components. In this paper, we propose a definition of bootstrap for object-oriented reflective systems, we describe the architecture and components it should contain and we analyze the challenges it has to overcome. Finally, we present a reference bootstrap process for a reflective system and Hazelnut, its implementation\u252c\u00e1\u0393\u00c7\u00aa", "num_citations": "18\n", "authors": ["54"]}
{"title": "Package fingerprints: A visual summary of package interface usage\n", "abstract": " ContextObject-oriented languages such as Java, Smalltalk, and C++ structure their programs using packages. Maintainers of large systems need to understand how packages relate to each other, but this task is complex because packages often have multiple clients and play different roles (class container, code ownership, etc.). Several approaches have been proposed, among which the use of cohesion and coupling metrics. Such metrics help identify candidate packages for restructuring; however, they do not help maintainers actually understand the structure and interrelationships between packages.ObjectivesIn this paper, we use pre-attentive processing as the basis for package visualization and see to what extent it could be used in package understanding.MethodWe present the Package Fingerprint, a 2D visualization of the references made to and from a package. The proposed visualization offers a\u252c\u00e1\u0393\u00c7\u00aa", "num_citations": "18\n", "authors": ["54"]}
{"title": "Package reference fingerprint: a rich and compact visualization to understand package relationships\n", "abstract": " Object-oriented languages such as Java, Smalltalk, and C+ + structure their programs using packages, allowing classes to be organized into named abstractions. Maintainers of large applications need to understand how packages are structured and how they relate to each other, but this task is very complex because packages often have multiple clients and different roles (class container, code ownership...). Cohesion and coupling are still among the most used metrics, because they help identify candidate packages for restructuring; however, they do not help maintainers understand the structure and interrelationships between packages. In this paper, we present the package fingerprint, a 2D visualization of the references made to and from a package. The proposed visualization offers a semantically rich, but compact and zoomable visualization centered on packages. We focus on two views (incoming and\u252c\u00e1\u0393\u00c7\u00aa", "num_citations": "18\n", "authors": ["54"]}
{"title": "Fuel: A fast general purpose object graph serializer\n", "abstract": " Because objects need to be stored and reloaded on different environments, serializing object graphs is a very important activity. There is a plethora of serialization frameworks with different requirements and design trade\u0393\u00c7\u00c9offs. Most of them are based on recursive parsing of the object graphs, an approach which often is too slow. In addition, most of them prioritize a language\u0393\u00c7\u00c9agnostic format instead of speed and language\u0393\u00c7\u00c9specific object serialization. For the same reason, such serializers usually do not support features such as class\u0393\u00c7\u00c9shape changes, global references or executing pre and post load actions. Looking for speed, some frameworks are partially implemented at Virtual Machine (VM) level, hampering code portability and making them difficult to understand, maintain and extend.In this paper, we present Fuel, a general\u0393\u00c7\u00c9purpose object serializer based on these principles: (1) speed, through a compact binary\u252c\u00e1\u0393\u00c7\u00aa", "num_citations": "17\n", "authors": ["54"]}
{"title": "Reconsidering classes in procedural object-oriented code\n", "abstract": " Object-oriented software may show signs of procedural thinking because of lack of design or due to design erosion over a period of time. We refer to such a software as procedural object-oriented code. Huge classes, scarce class hierarchies and absence of classes for domain entities are hallmarks of procedural object-oriented code. Due to huge investments in such systems, software restructuring becomes necessary. To support code modularization, it is important to identify useful domain abstractions. In this paper, we present a tool-assisted technique to identify useful abstractions and class hierarchies in procedural object-oriented code. During this task, principal classes (draft classes) are identified. Afterwards, composition and association relationships are inferred for principal classes. Lastly, Formal Concept Analysis (FCA) is used to analyze hierarchical relationships between methods and attributes within\u252c\u00e1\u0393\u00c7\u00aa", "num_citations": "17\n", "authors": ["54"]}
{"title": "GUI migration using MDE from GWT to Angular 6: An industrial case\n", "abstract": " During the evolution of an application, it happens that developers must change the programming language. In the context of a collaboration with Berger-Levrault, a major IT company, we are working on the migration of a GWT application to Angular. We focus on the GUI aspect of this migration which, even if both frameworks are web Graphical User Interface (GUI) frameworks, is made difficult because they use different programming languages and different organization schema. Such migration is complicated by the fact that the new application must be able to mimic closely the visual aspect of the old one so that the users of the application are not disrupted. We propose an approach in four steps that uses a meta-model to represent the GUI at a high abstraction level. We evaluated this approach on an application comprising 470 Java (GWT) classes representing 56 pages. We are able to model all the web pages of\u252c\u00e1\u0393\u00c7\u00aa", "num_citations": "16\n", "authors": ["54"]}
{"title": "Traits at work: the design of a new trait-based stream library\n", "abstract": " Recent years saw the development of a composition mechanism called traits. Traits are pure units of behavior that can be composed to form classes or other traits. The trait composition mechanism is an alternative to multiple or mixin inheritance in which the composer has full control over the trait composition.To evaluate the expressiveness of traits, some hierarchies were refactored, showing code reuse. However, such large refactorings, while valuable, may not exhibit all possible composition problems, since the hierarchies were previously expressed using single inheritance and following certain patterns.This paper presents our work on designing and implementing a new trait-based stream library named Nile. It evaluates how far traits enable reuse, what problems can be encountered when building a library using traits from scratch and compares the traits solution to alternative composition mechanisms. Nile's\u252c\u00e1\u0393\u00c7\u00aa", "num_citations": "16\n", "authors": ["54"]}
{"title": "Object-oriented reengineering\n", "abstract": " The ability to reengineer object-oriented legacy systems has become a vital matter in today\u0393\u00c7\u00d6s software industry. Early adopters of the object-oriented programming paradigm are now facing the problems of transforming their object-oriented \u0393\u00c7\u00a3legacy\u0393\u00c7\u00a5 systems into full-fledged frameworks.", "num_citations": "16\n", "authors": ["54"]}
{"title": "Type-check elimination: Two object-oriented reengineering patterns\n", "abstract": " In reengineering an object-oriented system, we want to benefit from the expertise developed in earlier efforts. It is therefore essential to have a way to communicate expertise at different levels: from knowledge about how to approach a system to be reengineered, to knowledge about improving code by eliminating 'bad' style. In this paper, we propose to use a pattern form to communicate knowledge about reengineering. A reengineering pattern connects an observable problem in the code to a reengineering goal: it describes the process of going from the existing legacy solution causing or aggravating the problem to a new refactored solution which meets the reengineering goal. It thus gives a method which is appropriate for a specific problem, rather than proposing a general methodology, and makes reference to the appropriate tools or techniques for obtaining the refactored solution. In this paper, we discuss the\u252c\u00e1\u0393\u00c7\u00aa", "num_citations": "16\n", "authors": ["54"]}
{"title": "Why FAMIX and not UML\n", "abstract": " UML is currently embraced as\u0393\u00c7\u00d6 the\u0393\u00c7\u00d6standard in object-oriented modeling languages, the recent work of OMG on the Meta Object Facility (MOF) being the most noteworthy example. We welcome these standardisation efforts, yet warn against the tendency to use UML as the panacea for all exchange standards. In particular, we argue that UML is not sufficient to serve as a toolinteroperability standard for integrating round-trip engineering tools, because one is forced to rely on UML\u0393\u00c7\u00d6s built-in extension mechanisms to adequately model the reality in source-code. Consequently, we propose an alternative meta-model (named FAMIX), which serves as the tool interoperability standard within the FAMOOS project and which includes a number of constructive suggestions that we hope will influence future releases of the UML and MOF standards.", "num_citations": "16\n", "authors": ["54"]}
{"title": "Explicit connectors for coordination of active objects\n", "abstract": " The trend to interconnect software systems increased the pressure on object oriented (OO) programming languages to include concurrency control features. Thread packages that are not integrated into programming languages tend to be hard to use [Lea97]. Thus for example JAVA, a recent OO programming language introduces a small and consistent set of object synchronization primitives. However, Bloom [Blo79] already pointed out the need of factoring out synchronization code (in non OO context). This was also reflected in OO synchronization approaches like the generic synchronization policies [McH94] or the D-language [LK97]. Such approaches feature separation of concerns and high level synchronization abstractions instead of built-in primitives. However their declarations affect only single class declarations therefore they do not cover the field of multi-object synchronization, where different kind of objects share resources concurrently. The management of such dependencies between otherwise independent objects is called coordination. Our FLO/C model is situated in this context: we want to introduce an OO model that factors out high-level coordination abstractions. Our model is situated in the same area as the synchronizers of Agha and Fr\u251c\u2555lund [FA93]. We both use rules to enforce interaction behavior. However, in FLO/C the rules are supported by explicit coordinator objects that allow us to achieve run-time flexibility like the dynamic exchange of coordination policies.Instantiating coordination in specialized objects has a tradition in the domain of software architecture design. There the distinction between components and\u252c\u00e1\u0393\u00c7\u00aa", "num_citations": "16\n", "authors": ["54"]}
{"title": "AspectMaps: Extending Moose to visualize AOP software\n", "abstract": " When using aspect-oriented programming the application implicitly invokes the functionality contained in the aspects. Consequently program comprehension of such a software is more intricate. To alleviate this difficulty we developed the AspectMaps visualization and tool. AspectMaps extends the Moose program comprehension and reverse engineering platform with support for aspects, and is implemented using facilities provided by Moose. In this paper we present the AspectMaps tool, and show how it can be used by performing an exploration of a fairly large aspect-oriented application. We then show how we extended the FAMIX meta-model family that underpins Moose to also provide support for aspects. This extension is called ASPIX, and thanks to this enhancement Moose can now also treat aspect-oriented software. Finally, we report on our experiences using some of the tools in Moose; Mondrian to\u252c\u00e1\u0393\u00c7\u00aa", "num_citations": "15\n", "authors": ["54"]}
{"title": "Redesigning with traits: the nile stream trait-based library\n", "abstract": " Recently, traits have been proposed as a single inheritance backward compatible solution in which the composing entity has the control over the trait composition. Traits are fine-grained units used to compose classes, while avoiding many of the problems of multiple inheritance and mixin-based approaches.", "num_citations": "15\n", "authors": ["54"]}
{"title": "Uniform and safe metaclass composition\n", "abstract": " In pure object-oriented languages, classes are objects, instances of other classes called metaclasses. In the same way as classes define the properties of their instances, metaclasses define the properties of classes. It is therefore very natural to wish to reuse class properties, utilizing them amongst several classes. However this introduced metaclass composition problems, i.e., code fragments applied to one class may break when used on another class due to the inheritance relationship between their respective metaclasses.Numerous approaches have tried to solve metaclass composition problems, but they always resort to an ad-hoc manner of handling conflicting properties, alienating the meta-programmer. We propose a uniform approach that represents class properties as traits, groups of methods that act as a unit of reuse from which classes are composed. Like all the other classes in the system, metaclasses\u252c\u00e1\u0393\u00c7\u00aa", "num_citations": "15\n", "authors": ["54"]}
{"title": "Coordinating open distributed systems\n", "abstract": " Open Distributed Systems are the dominating intellectual issue of the end of this century. Figuring out how to build those systems will become a central issue in distributed system research in the next future. Although CORBA seems to provide all the necessary support to construct those systems, it provides a very limited support to the evolution of requirements in those systems. The main problem is that the description of the elements from which systems are built, and the way in which they are composed are mixed into the application code, making them difficult to understand, modify and customize. We think that a solution to this problem goes through the introduction of the so called coordination models and languages into the CORBA model. We propose in this paper the introduction of our object coordination model called CoLaS into the CORBA model.", "num_citations": "15\n", "authors": ["54"]}
{"title": "Message passing abstractions as elementary bricks for design pattern implementation: An experiment\n", "abstract": " Design patterns (DPs) are becoming increasingly popular as a way to describe solutions to general design problems [GHJV94]. Most design pattern authors consider that DPs should stay independent of the implementation language to keep their abstraction. However, the problems that occur during DP implementation in traditional object-oriented languages - loss of the DP, class proliferation, increased code complexity and impossibility to reuse the DP implementation lead - to the question of providing language support for DPs in languages themselves.", "num_citations": "15\n", "authors": ["54"]}
{"title": "Are the gas prices oracle reliable? a case study using the ethgasstation\n", "abstract": " The Ethereum Blockchain is a distributed database that records all transactions and smart-contracts created on the platform. In Ethereum blockchain, the user needs to set a Gas price to get a transaction recorded. To have the transaction recorded, the Gas price has to be greater than or equal to the lowest Ethereum transaction fees. To help the users and smart contracts to set the right Gas price, the Gas Oracle categorizes the gas price into categories based on the interval of time the user might be willing to wait and for each of them suggests a gas price to set. The paper aims to verify the hypothesis that the predictions made by the EtherGasStation Oracle have a margin of error greater than the margin of error declared by it (2 %). We collected data in two-months time from the EthGasStation Oracle which predict the Gas Price every time that 100 blocks are added to the Ethereum Blockchain. In the same time frame\u252c\u00e1\u0393\u00c7\u00aa", "num_citations": "14\n", "authors": ["54"]}
{"title": "Recording and replaying system specific, source code transformations\n", "abstract": " During its lifetime, a software system is under continuous maintenance to remain useful. Maintenance can be achieved in activities such as adding new features, fixing bugs, improving the system's structure, or adapting to new APIs. In such cases, developers sometimes perform sequences of code changes in a systematic way. These sequences consist of small code changes (e.g., create a class, then extract a method to this class), which are applied to groups of related code entities (e.g., some of the methods of a class). This paper presents the design and proof-of-concept implementation of a tool called MacroRecorder. This tool records a sequence of code changes, then it allows the developer to generalize this sequence in order to apply it in other code locations. In this paper, we discuss MACRORECORDER's approach that is independent of both development and transformation tools. The evaluation is based on\u252c\u00e1\u0393\u00c7\u00aa", "num_citations": "14\n", "authors": ["54"]}
{"title": "OZONE: Layer Identification in the presence of Cyclic Dependencies\n", "abstract": " A layered software architecture helps in understanding the role of software entities (e.g. packages or classes) in a system and, hence, the impact of changes on these entities. However, the computation of an optimal layered organization in the presence of cyclic dependencies is difficult. In this paper, we present an approach that (i) provides a strategy supporting the automated detection of cyclic dependencies, (ii) proposes heuristics to break cyclic dependencies, and (iii) computes an organization of software entities in multiple layers even in the presence of cyclic dependencies. Our approach performs better than the other existing approaches in terms of accuracy and interactivity, and it supports human inputs and constraints. In this paper, we present this approach and compare it to existing solutions. We applied our approach on two large software systems to identify package layers and the results are manually\u252c\u00e1\u0393\u00c7\u00aa", "num_citations": "14\n", "authors": ["54"]}
{"title": "Characterizing the functional roles of classes and methods by analyzing feature traces\n", "abstract": " Software developers are often faced with the task of maintaining or extending large and complex applications, with which they are unfamiliar. Typically change requests and bug reports are expressed in terms of system features. Much of the maintenance effort is spent trying to identify which classes and methods provide functionality to individual features. To tackle this problem, we propose an approach based on dynamic analysis that exploits the relationships between features and software entities. Our definition of a feature is a unit of observable behavior of a software system. We apply our approach to large open source application and identify the key classes and methods which provide functionality for individual features.", "num_citations": "14\n", "authors": ["54"]}
{"title": "Reusing and composing tests with traits\n", "abstract": " Single inheritance often forces developers to duplicate code and logic. This widely recognized situation affects both business code and tests. In a large and complex application whose classes implement many groups of methods (protocols), duplication may also follow the application\u0393\u00c7\u00d6s idiosyncrasies, making it difficult to specify, maintain, and reuse tests. The research questions we faced are (i) how can we reuse test specifications across and within complex inheritance hierarchies, especially in presence of orthogonal protocols; (ii) how can we test interface behavior in a modular way; (iii) how far can we reuse and parametrize composable tests.               In this paper, we compose tests out of separately specified behavioral units of reuse \u0393\u00c7\u00f6traits. We propose test traits, where: (i) specific test cases are composed from independent specifications; (ii) executable behavior specifications may be reused\u252c\u00e1\u0393\u00c7\u00aa", "num_citations": "13\n", "authors": ["54"]}
{"title": "Creating sophisticated development tools with OmniBrowser\n", "abstract": " Smalltalk is not only an object-oriented programming language; it is also known for its extensive integrated development environment supporting interactive and dynamic programming. While the default tools are adequate for browsing the code and developing applications, it is often cumbersome to extend the environment to support new language constructs or to build additional tools supporting new ways of navigating and presenting source code. In this paper, we present the OmniBrowser, a browser framework that supports the definition of browsers based on an explicit metamodel. With OmniBrowser a domain model is described in a graph and the navigation in this graph is specified in its associated metagraph. We present how new browsers are built from predefined parts and how new tools are easily described. The browser framework is implemented in the Squeak Smalltalk environment. This paper shows\u252c\u00e1\u0393\u00c7\u00aa", "num_citations": "13\n", "authors": ["54"]}
{"title": "Meta-driven browsers\n", "abstract": " Smalltalk is not only an object-oriented programming language; it is also known for its extensive integrated development environment supporting interactive and dynamic programming. While the default tools are adequate for browsing the code and developing applications, it is often cumbersome to extend the environment to support new language constructs or to build additional tools supporting new ways of navigating and presenting source code. In this paper, we present the OmniBrowser, a browser framework that supports the definition of browsers based on an explicit metamodel. With OmniBrowser a domain model is described in a graph and the navigation in this graph is specified in its associated metagraph. We present how new browsers are built from predefined parts and how new tools are easily described. The browser framework is implemented in the Squeak Smalltalk environment. This paper\u252c\u00e1\u0393\u00c7\u00aa", "num_citations": "13\n", "authors": ["54"]}
{"title": "Run-time information visualization for understanding object-oriented systems\n", "abstract": " Understanding object-oriented legacy systems is a complex task exacerbated by the presence of late binding and polymorphism. Moreover, the metaphor of message sending and the anthropomorphism promoted by object-oriented languages makes it difficult to statically identify the precise role the objects play at run-time. We propose a lightweight visualization approach enriched with run-time information which allows us to identify precise aspects of the objects lifetime such as the role played in the creation of other objects and the communication architecture they support. Our approach not only supports the run-time understanding of an application but also allows one to evaluate test understanding and test coverage.", "num_citations": "13\n", "authors": ["54"]}
{"title": "Recovering the evolution of object oriented software systems using a flexible query engine\n", "abstract": " Since software systems must evolve to cope with changing demands, the investment of time and effort won\u0393\u00c7\u00d6t cease after first delivery. Developers that join a project later in the development cycle may have a hard time to understand the structure of complex systems. Moreover they may not know about concepts that emerged from earlier implementations. We therefore want to find out what exactly happens during evolution of software systems. We developed a method based on simple metric heuristics to detect changes between different versions of a software system. With our query-based approach we can measure overall changes in terms of removals and additions in the code. We are also able to detect different kinds of refactorings like restructuring in the class hierarchy and moved features between entities. Historical information about code size and changes in the code structure helps us to find interesting patterns and to discover unknown relationships and dependencies among source code entities. i", "num_citations": "13\n", "authors": ["54"]}
{"title": "Understanding software evolution using a flexible query engine\n", "abstract": " One of the main problems which arises in the field of software evolution is the sheer amount of information to be dealt with. Compared to reverse engineering where the main goal is the main understanding of one single system. In the field of software evolution this information is multiplied by the number of versions of the system one wants to understand. To counter this problem we have come up with a flexible query engine which can perform queries on the different versions of a system. In this paper we give an outlook on our current work in the field of software evolution and focus particularly on the concepts behind the query engine we have built.", "num_citations": "13\n", "authors": ["54"]}
{"title": "Smartanvil: Open-source tool suite for smart contract analysis\n", "abstract": " Smart contracts are new computational units with special properties: they act as classes with aspectual concerns; their memory structure is more complex than mere objects; they are obscure in the sense that, once they are deployed, it is difficult to access their internal state; they reside in an append-only chain. There is a need to support the building of new generation tools to help developers. Such support should tackle several important aspects:(1) the static structure of the contract,(2) the object nature of published contracts, and (3) the overall data chain composed of blocks and transactions. In this chapter, we present SmartAnvil, an open platform to build software analysis tools around smart contracts. We illustrate the general components, and we focus on three important aspects: support for static analysis of Solidity smart contracts, deployed smart contract binary analysis through inspection, and blockchain\u252c\u00e1\u0393\u00c7\u00aa", "num_citations": "12\n", "authors": ["54"]}
{"title": "Recommending source code locations for system specific transformations\n", "abstract": " From time to time, developers perform sequences of code transformations in a systematic and repetitive way. This may happen, for example, when introducing a design pattern in a legacy system: similar classes have to be introduced, containing similar methods that are called in a similar way. Automation of these sequences of transformations has been proposed in the literature to avoid errors due to their repetitive nature. However, developers still need support to identify all the relevant code locations that are candidate for transformation. Past research showed that these kinds of transformation can lag for years with forgotten instances popping out from time to time as other evolutions bring them into light. In this paper, we evaluate three distinct code search approaches (\u0393\u00c7\u00a3structural\u0393\u00c7\u00a5, based on Information Retrieval, and AST based algorithm) to find code locations that would require similar transformations. We validate\u252c\u00e1\u0393\u00c7\u00aa", "num_citations": "12\n", "authors": ["54"]}
{"title": "Mercury: Properties and design of a remote debugging solution using reflection\n", "abstract": " Remote debugging facilities are a technical necessity for devices that lack appropriate input/output interfaces (display, keyboard, mouse) for programming (e.g., smartphones, mobile robots) or are simply unreachable for local development (e.g., cloud-servers). Yet remote debugging solutions can prove awkward to use due to re-deployments. Empirical studies show us that on average 10.5 minutes per coding hour (over five 40-hour work weeks per year) are spent for redeploying applications (including re-deployments during debugging). Moreover current solutions lack facilities that would otherwise be available in a local setting because it is difficult to reproduce them remotely. Our work identifies three desirable properties that a remote debugging solution should exhibit, namely: run-time evolution, semantic instrumentation and adaptable distribution. Given these properties we propose and validate Mercury, a remote debugging model based on reflection. Mercury supports run-time evolution through a causally connected remote meta-level, semantic instrumentation through the reification of the underlying execution environment and adaptable distribution through a modular architecture of the debugging middleware.", "num_citations": "12\n", "authors": ["54"]}
{"title": "Dr. Geo II: Adding interactivity planes in interactive dynamic geometry\n", "abstract": " Interactive geometry environments support the creation and exploitation of interactive geometric sketches. However, such environments are often driven in a rigid manner, following a well specified construction path. This rigidity is not always compatible with: i. the internal cognitive representation of the learner about the geometric domain and ii. the way a geometric sketch is used in a paper-pen environment. This rigidity is therefore a source of internal tension for the learner and it can reduce the pedagogical added value of the interactive geometry environments. We think additional interactive planes to manipulate a geometric sketch differently can help the learner. We have developed DR. Geo II, an interactive geometry framework that is able to receive additional interactive planes such as a free sketching and a command-based one. We have experimented it in a junior high school class and we report here our first\u252c\u00e1\u0393\u00c7\u00aa", "num_citations": "12\n", "authors": ["54"]}
{"title": "Logic and trace-based object-oriented application testing\n", "abstract": " Due to the size and the extreme complexity of legacy systems, it is nearly impossible to write from scratch tests before refactoring them. In addition object-oriented legacy systems present specific requirements to test them. Indeed late-binding allow subclasses to change fundamental aspects of the superclass code and in particular call flows. Moreover Object-oriented programming promotes a distribution of the responsibilities to multiple entities leading to complex scenario to be tested. In such a context one of the few trustable source of information is the execution of the application itself. Traditional forward engineering approaches such as unit testing do not really provide adequate solution to this problem. Therefore there is a need for a more expressive way of testing the execution of object-oriented applications. We propose to represent the trace of object-oriented applications as logic facts and express tests over the trace. This way complex sequences of message exchanges, sequence matching, or expression of negative information are expressed in compact form. We validated our approach by implementing TestLog a prototype tool and testing the Moose reengineering environment and a meta-interpreter.", "num_citations": "12\n", "authors": ["54"]}
{"title": "Solidity parsing using smacc: Challenges and irregularities\n", "abstract": " Solidity is a language used to implement smart contracts on a blockchain platform. Since its initial conception in 2014, Solidity has evolved into one of the major languages for the Ethereum platform as well as other blockchain technologies. Due to its popularity, there are many tools specifically designed to handle smart contracts written in Solidity. However, there is a lack of tools for Pharo to handle Solidity contracts. Therefore, we implemented a parser using SmaCC to serve as a base for further developing Solidity support in Pharo. In this paper, we describe the parser creation, the irregularities we found in the Solidity grammar specification, and common practices on how to adapt the grammar to an LR type parser. Our experiences with parsing the Solidity language using SmaCC may help other developers trying to convert similar grammars.", "num_citations": "11\n", "authors": ["54"]}
{"title": "Resolving cyclic dependencies between packages with enriched dependency structural matrix\n", "abstract": " Dependency structural matrix (DSM) is an approach originally developed for process optimization. It has been successfully applied to identify software dependencies among packages and subsystems. A number of algorithms have been proposed to compute the matrix so that it highlights patterns and problematic dependencies between subsystems. However, existing DSM implementations often miss important information to fully support reengineering effort. For example, they do not clearly qualify and quantify problematic relationships, information that is crucial to support remediation tasks. We propose enriched DSM (eDSM), which provides small\u0393\u00c7\u00c9multiple views and micro\u0393\u00c7\u00f4macro\u0393\u00c7\u00c9readings by adding fine\u0393\u00c7\u00c9grained information in each cell of the matrix. Each cell is enriched with contextual information about (i) the type of dependencies (inheritance, class reference, etc.), (ii) the proportion of referencing entities, and\u252c\u00e1\u0393\u00c7\u00aa", "num_citations": "11\n", "authors": ["54"]}
{"title": "Software evolution from the field: an experience report from the Squeak maintainers\n", "abstract": " Over the last few years, we actively participated in the maintenance and evolution of Squeak, an open-source Smalltalk. The community is constantly faced with the problem of enabling changes while at the same time preserving compatibility. In this paper we describe the current situation, the problems that faced the community and we outline the improvements that have been introduced. We also identify some areas where problems continue to exist and propose these as potential problems to addressed by the research community.", "num_citations": "11\n", "authors": ["54"]}
{"title": "Des techniques de contr\u251c\u2524le de l'envoi de messages en Smalltalk\n", "abstract": " BORIS Deutsch English Fran\u251c\u00baais Login BORIS Bern Open Repository and Information System University of Bern Home Statistics Des techniques de contr\u251c\u2524le de l'envoi de messages en Smalltalk Ducasse, St\u251c\u2310phane (1997). Des techniques de contr\u251c\u2524le de l'envoi de messages en Smalltalk (Technical Report). Universit\u251c\u00f1t Bern [img] Text Duca97eMessagePassing.pdf - Published Version Restricted to registered users only Available under License Publisher holds Copyright. Download (286kB) | Request a copy Item Type: Report (Report) Division/Institute: 08 Faculty of Science > Institute of Computer Science (INF) 08 Faculty of Science > Institute of Computer Science (INF) > Software Composition Group (SCG) UniBE Contributor: Ducasse, Stephane Subjects: 000 Computer science, knowledge & systems 500 Science > 510 Mathematics Series: Technical Report Publisher: Universit\u251c\u00f1t Bern Language: French Submitter: : ::'\u0393\u00c7\u00aa", "num_citations": "11\n", "authors": ["54"]}
{"title": "Sista: Saving optimized code in snapshots for fast start-up\n", "abstract": " Modern virtual machines for object-oriented languages such as Java HotSpot, Javascript V8 or Python PyPy reach high performance through just-in-time compilation techniques, involving on-the-fly optimization and deoptimization of the executed code. These techniques require a warm-up time for the virtual machine to collect information about the code it executes to be able to generate highly optimized code. This warm-up time required before reaching peak performance can be considerable and problematic. In this paper, we propose an approach, Sista (Speculative Inlining SmallTalk Architecture) to persist optimized code in a platform-independent representation as part of a snapshot. After explaining the overall approach, we show on a large set of benchmarks that the Sista virtual machine can reach peak performance almost immediately after start-up when using a snapshot where optimized code was persisted.", "num_citations": "10\n", "authors": ["54"]}
{"title": "Virtualization support for dynamic core library update\n", "abstract": " Dynamically updating language runtime and core libraries such as collections and threading is challenging since the update mechanism uses such libraries at the same time that it modifies them. To tackle this challenge, we present Dy-namic Core Library Update (DCU) as an extension of Dy-namic Software Update (DSU) and our approach based on a virtualization architecture. Our solution supports the up-date of core libraries as any other normal library, avoiding the circular dependencies between the updater and the core libraries. Our benchmarks show that there is no evident per-formance overhead in comparison with a default execution. Finally, we show that our approach can be applied to real life scenario by introducing a critical update inside a web application with 20 simulated concurrent users.", "num_citations": "10\n", "authors": ["54"]}
{"title": "Towards fully reflective environments\n", "abstract": " Modern development environments promote live programming (LP) mechanisms because it enhances the development experience by providing instantaneous feedback and interaction with live objects. LP is typically supported with advanced reflective techniques within dynamic languages. These languages run on top of Virtual Machines (VMs) that are built in a static manner so that most of their components are bound at compile time. As a consequence, VM developers are forced to work using the traditional edit-compile-run cycle, even when they are designing LP-supporting environments. In this paper we explore the idea of bringing LP techniques to the VM domain for improving their observability, evolution and adaptability at run-time. We define the notion of fully reflective execution environments (EEs), systems that provide reflection not only at the application level but also at the level of the VM. We\u252c\u00e1\u0393\u00c7\u00aa", "num_citations": "10\n", "authors": ["54"]}
{"title": "Supporting streams of changes during branch integration\n", "abstract": " When developing large applications, integrators face the problem of integrating changes between branches or forks. While version control systems provide support for merging changes, this support is mostly text-based, and does not take the program entities into account. Furthermore, there exists no support for assessing which other changes a particular change depends on have to be integrated. Consequently, integrators are left to perform a manual and tedious comparison of the changes within the sequence of their branch and to successfully integrate them.In this paper, we present an approach that analyzes changes within a sequence of changes (stream of changes): such analysis identifies and characterizes dependencies between the changes. The approach identifies changes as autonomous, only used by others, only using other changes, or both. Such a characterization aims at easing the integrator's work\u252c\u00e1\u0393\u00c7\u00aa", "num_citations": "10\n", "authors": ["54"]}
{"title": "Seamless composition and reuse of customizable user interfaces with Spec\n", "abstract": " Implementing UIs is often a tedious task. To address this, UI Builders have been proposed to support the description of widgets, their location, and their logic. A missing aspect of UI Builders is however the ability to reuse and compose widget logic. In our experience, this leads to a significant amount of duplication in UI code. To address this issue, we built Spec: a UIBuilder for Pharo with a focus on reuse. With Spec, widget properties are defined declaratively and attached to specific classes known as composable classes. A composable class defines its own widget description as well as the model-widget bridge and widget interaction logic. This paper presents Spec, showing how it enables seamless reuse of widgets and how these can be customized. After presenting Spec and its implementation, we discuss how its use in Pharo 2.0 has cut in half the amount of lines of code of six of its tools, mostly through reuse\u252c\u00e1\u0393\u00c7\u00aa", "num_citations": "10\n", "authors": ["54"]}
{"title": "Multiple viewpoints architecture extraction\n", "abstract": " A software system's architecture, its elements and the way they interact, constitute valuable assets for comprehending the system. Many approaches have been developed to help comprehending software systems in different manners. Most of them focus on structural aspects. We believe offering multiple views of the same system, using domain knowledge helps understanding a software system as whole. To correlate domain information and existing software systems, different viewpoints are considered and modelled. Viewpoints guide the extraction of architectural views, the later representing different system facets. We propose a recursive framework, an approach that expresses domain knowledge as viewpoints to guide the extraction process. It provides multiple architectural views according to multiple given viewpoints.", "num_citations": "10\n", "authors": ["54"]}
{"title": "Seaside\u0393\u00c7\u00f6Advanced Composition and Control Flow for Dynamic Web Applications\n", "abstract": " Page-centric Web application frameworks fail to offer adequate solutions to model composition and control flow. Seaside allows Web applications to be developed in the same way as desktop applications. Control flow is modelled as a continuous piece of code, and components may be composed, configured and nested as one would expect from traditional user interface frameworks.", "num_citations": "10\n", "authors": ["54"]}
{"title": "Reengineering object-oriented applications\n", "abstract": " Reengineering object-oriented applications is becoming a vital activity in today industry where the developer turnover drains the system oral memory out of the systems themselves and where applications should constantly evolve to meet new requirements. This document summarizes the research effort led on reverse engineering and reengineering object-oriented legacy systems. It includes (1) the definition of a suitable meta-model for reengineering, FAMIX. This meta-model, even if flat, supports both reverse engineering and code refactoring analysis,(2) the presentation of a reengineering platform, MOOSE,(3) the evalution of software metrics for reengineer,(4) the definition of simple visual techniques to support large system understanding or finer grain code element,(5) the identification and cure support for duplicated code,(6) the use of dynamic information to support composable views and collaboration extraction, and (7) the identification of reengineer patterns. Keywords. Meta-Modeling, Language Independence, Reengineering, Reverse Engineering, Code Duplication, Reengineering Patterns, Program Traces, Dynamic Information, Program Visualization, Software Metrics, Refactorings, Interexchange Format, CODECRAWLER, FAMIX, MOOSE, FAMOOS, Smalltalk, Java, C++.Classification: 68-02 Research Exposition, 68N30 Mathematical aspects of software engineering (specification, verification, metrics, requirements, etc.)[New MSC2000 code] 68U35 Information systems (hypertext navigation, interfaces, decision support, etc.)[New MSC2000 code] ACM: D. 2 Software Evolution D. 2 Software Engineering, D. 2.2 Tools and Techniques\u252c\u00e1\u0393\u00c7\u00aa", "num_citations": "10\n", "authors": ["54"]}
{"title": "Why FAMIX and not UML? UML Shortcomings for Coping with Round-trip Engineering\n", "abstract": " [Note that this report will appear in the UML'99 Conference Proceedings, published by Springer-Verlag in the LNCS series.] Abstract: UML is currently embraced as\u0393\u00c7\u00d6 the\u0393\u00c7\u00d6standard in object-oriented modeling languages, the recent work of OMG on the Meta Object Facility (MOF) being the most noteworthy example. We welcome these standardisation efforts, yet warn against the tendency to use UML as the panacea for all exchange standards. In particular, we argue that UML is not sufficient to serve as a toolinteroperability standard for integrating round-trip engineering tools, because one is forced to rely on UML\u0393\u00c7\u00d6s built-in extension mechanisms to adequately model the reality in source-code. Consequently, we propose an alternative meta-model (named FAMIX), which serves as the tool interoperability standard within the FAMOOS project and which includes a number of constructive suggestions that we hope will influence future releases of the UML and MOF standards.", "num_citations": "10\n", "authors": ["54"]}
{"title": "What are the testing habits of developers? A case study in a large IT company\n", "abstract": " Tests are considered important to ensure the good behavior of applications and improve their quality. But development in companies also involves tight schedules, old habits, less-trained developers, or practical difficulties such as creating a test database. As a result, good testing practices are not always used as often as one might wish. With a major IT company, we are engaged in a project to understand developers testing behavior, and whether it can be improved. Some ideas are to promote testing by reducing test session length, or by running automatically tests behind the scene and send warnings to developers about the failing ones. Reports on developers testing habits in the literature focus on highly distributed open-source projects, or involve students programmers. As such they might not apply to our industrial, closed source, context. In this paper, we take inspiration from experiments of two papers of the\u252c\u00e1\u0393\u00c7\u00aa", "num_citations": "9\n", "authors": ["54"]}
{"title": "CodeCritics applied to database schema: Challenges and first results\n", "abstract": " Relational databases (DB) play a critical role in many information systems. For different reasons, their schemas gather not only tables and columns but also views, triggers or stored functions (i.e., fragments of code describing treatments). As for any other code-related artefact, software quality in a DB schema helps avoiding future bugs. However, few tools exist to analyse DB quality and prevent the introduction of technical debt. Moreover, these tools suffer from limitations like the difficulty to deal with some entities (e.g., functions) or dependencies between entities. This paper presents research issues related to assessing the software quality of a DB schema by adapting existing source code analysis research to database schemas. We present preliminary results that have been validated through the implementation of DBCritics, a prototype tool to perform static analysis on the SQL source code of a database schema\u252c\u00e1\u0393\u00c7\u00aa", "num_citations": "9\n", "authors": ["54"]}
{"title": "Identifying the exact fixing actions of static rule violation\n", "abstract": " We study good programming practices expressed in rules and detected by static analysis checkers such as PMD or FindBugs. To understand how violations to these rules are corrected and whether this can be automated, we need to identify in the source code where they appear and how they were fixed. This presents some similarities with research on understanding software bugs, their causes, their fixes, and how they could be avoided. The traditional method to identify how a bug or a rule violation were fixed consists in finding the commit that contains this fix and identifying what was changed in this commit. If the commit is small, all the lines changed are ascribed to the fixing of the rule violation or the bug. However, commits are not always atomic, and several fixes and even enhancements can be mixed in a single one (a large commit). In this case, it is impossible to detect which modifications contribute to which\u252c\u00e1\u0393\u00c7\u00aa", "num_citations": "9\n", "authors": ["54"]}
{"title": "Experiments with a fast object swapper\n", "abstract": " In object-oriented systems, runtime memory is composed of an object graph in which objects refer to other objects. This graph of objects evolves while the system is running. Graph exporting and swapping are two important object graph operations. Exporting refers to copying the graph to some other memory so that it can be loaded by another system. Swapping refers to moving the graph to a secondary memory (e.g., a hard disk) to temporary release part of the primary memory. While exporting and swapping are achieved in different ways, each of them faces a common and central problem which is the speed of the approach in presence of large object graphs. Nevertheless, most of the existing solutions do not address well this issue. Another challenge is to deal with extremely common situations where objects outside the exported/swapped graph point to objects inside the graph. To correctly load back an exported subgraph, it is necessary to compute and export extra information that is not explicit in the object subgraph. This extra information is needed because certain objects may require to be reinitialized or recreated, to run specific code before or after the loading, to be updated to a new class definition, etc. In this paper, we present most of the general problems of object exporting and swapping. As a case of study, we present an analysis of ImageSegment, a fast solution to export and swap object graphs, developed by Dan Ingalls. ImageSegment addresses the speed problems in an efficient way, as shown by the results of several benchmarks we have conducted using Pharo Smalltalk. However, ImageSegment is not a panacea since it still\u252c\u00e1\u0393\u00c7\u00aa", "num_citations": "9\n", "authors": ["54"]}
{"title": "Software system understanding via architectural views extraction according to multiple viewpoints\n", "abstract": " Changes and evolution of software systems constantly generate new challenges for the recovery of software systems architectures. A system\u0393\u00c7\u00d6s architecture, together with its elements and the way they interact, constitute valuable assets for understanding the system. We believe that offering multiple architectural views of a given system, using domain and pattern knowledge enhance understanding of the software system as a whole. To correlate different sources of information and existing software system, different viewpoints are considered. Viewpoints enable one to model such information and guide the extraction algorithms to extract multiple architectural views. We propose a recursive framework, an approach that expresses different kinds of information as viewpoints to guide the extraction process. These multiple viewpoints models improve the consideration of architectural, conceptual, and structural\u252c\u00e1\u0393\u00c7\u00aa", "num_citations": "9\n", "authors": ["54"]}
{"title": "Object flow analysis: Taking an object-centric view on dynamic analysis\n", "abstract": " To extract abstract views of the behavior of an object-oriented system for reverse engineering, a body of research exists that analyzes a system's runtime execution. Those approaches primarily analyze the control flow by tracing method execution events. However, they do not capture information flows. We address this problem by proposing a novel dynamic analysis technique named Object Flow Analysis, which complements method execution tracing with an accurate analysis of the runtime flow of objects. To exemplify the usefulness of our analysis we present a visual approach that allows a system engineer to study classes and components in terms of how they exchange objects at runtime. We illustrate and validate our approach on two case studies.", "num_citations": "9\n", "authors": ["54"]}
{"title": "Chronia: Visualizing how developers change software systems\n", "abstract": " To understand a certain issue of the system we want to ask the knowledgeable developers. Yet, in large systems, not every developer is knowledgeable in all the details of the system. Thus, we would want to know which developer is knowledgeable in the issue at hand. In this paper we present the Chronia tool that implements the Ownership Map visualization to understand when and how different developers interacted in which way and in which part of the system", "num_citations": "9\n", "authors": ["54"]}
{"title": "Coordination of active objects by means of explicit connectors\n", "abstract": " Although coordination of multiple activities is a fundamental goal of object-oriented concurrent programming languages, there is only limited support for its specification and abstraction at the language level. This leads to a mismatch between conceptional designs, using high-level abstractions, and the implementation, using the low-level coordination constructs. Often coordination is hard-wired into the components they coordinate, which leads to evolution, maintenance and composibility problems. We propose a model called FLO/c that relies on the notion of connectors. A connector is an entity that enforces the coordination of the entities it coordinates. This model supports a clear separation between the coordinated active objects and their coordination. An active object only defines specific domain information and a connector only defines coordination between a group of active objects (its participants). The\u252c\u00e1\u0393\u00c7\u00aa", "num_citations": "9\n", "authors": ["54"]}
{"title": "Using restructuring transformations to reengineer object-oriented systems\n", "abstract": " Applying object-oriented design methods and languages does not guarantee that the resulting software systems will be flexible and adaptable. The industrial partners in the FAMOOS project have learned this lesson the hard way: they are now faced with large and rigid software systems that hamper them in meeting a diverse and evolving set of customer requirements. Object-oriented frameworks are touted as a promising solution, but it is unclear how to transform object-oriented legacy systems into frameworks. This paper proposes an approach\u0393\u00c7\u00f6ie, a methodology and tools\u0393\u00c7\u00f6for re-engineering object-oriented systems towards frameworks by means of high-level and low-level restructuring transformations that detect and resolve architectural and detailed design anomalies, and improve application flexibility and adaptability.", "num_citations": "9\n", "authors": ["54"]}
{"title": "Rotten green tests\n", "abstract": " Unit tests are a tenant of agile programming methodologies, and are widely used to improve code quality and prevent code regression. A green (passing) test is usually taken as a robust sign that the code under test is valid. However, some green tests contain assertions that are never executed. We call such tests Rotten Green Tests. Rotten Green Tests represent a case worse than a broken test: they report that the code under test is valid, but in fact do not test that validity. We describe an approach to identify rotten green tests by combining simple static and dynamic call-site analyses. Our approach takes into account test helper methods, inherited helpers, and trait compositions, and has been implemented in a tool called DrTest. DrTest reports no false negatives, yet it still reports some false positives due to conditional use or multiple test contexts. Using DrTest we conducted an empirical evaluation of 19,905 real\u252c\u00e1\u0393\u00c7\u00aa", "num_citations": "8\n", "authors": ["54"]}
{"title": "Pillar: A versatile and extensible lightweight markup language\n", "abstract": " There is a plethora of languages to write documentation and documents. From extremely powerful and complex such as LATEX to extremely simple such as Markdown. In this technical article we present Pillar a versatile and extensible lightweight markup language. Pillar's document model and open architecture support exporting from Pillar to various formats such as ASCIIDoc, HTML, LATEX and Markdown. Pillar is currently used to write books, documentation, websites and slide decks (through Beamer and DeckJS). Pillar specially shines when advanced features are needed such as multiple exports (eg, a printed book and web pages), internal references (eg, links to figures with captions) and content generation (eg, to give an up-to-date code size of a documented software).", "num_citations": "8\n", "authors": ["54"]}
{"title": "Practical validation of bytecode to bytecode JIT compiler dynamic deoptimization\n", "abstract": " Speculative inlining in just-in-time compilers enables many performance optimizations. However, it also introduces significant complexity. The compiler optimizations themselves, as well as the deoptimization mechanism are complex and error prone. To stabilize our bytecode to bytecode just-in-time compiler, we designed a new approach to validate the correctness of dynamic deoptimization. The approach consists of the symbolic execution of an optimized and an unop-timized bytecode compiled method side by side, deoptimizing the abstract stack at each deoptimization point (where dynamic deoptimization is possible) and comparing the deoptimized and unoptimized abstract stack to detect bugs. The implementation of our approach generated tests for several hundred thousands of methods, which are now available to be run automatically after each commit.", "num_citations": "8\n", "authors": ["54"]}
{"title": "Automatic detection of system-specific conventions unknown to developers\n", "abstract": " In Apache Ant, a convention to improve maintenance was introduced in 2004 stating a new way to close files instead of the Java generic InputStream.close(). Yet, six years after its introduction, this convention was still not generally known to the developers. Two existing solutions could help in these cases. First, one can deprecate entities, but, in our example, one can hardly deprecate Java\u0393\u00c7\u00d6s method. Second, one can create a system-specific rule to be automatically enforced. In a preceding publication, we showed that system-specific rules are more likely to be noticed by developers than generic ones. However, in practice, developers rarely create specific rules. We therefore propose to free the developers from the need to create rules by automatically detecting such conventions from source code repositories. This is done by mining the change history of the system to discover similar changes being applied over\u252c\u00e1\u0393\u00c7\u00aa", "num_citations": "8\n", "authors": ["54"]}
{"title": "Efficient retrieval and ranking of undesired package cycles in large software systems\n", "abstract": " Many design guidelines state that a software system architecture should avoid cycles between its packages. Yet such cycles appear again and again in many programs. We believe that the existing approaches for cycle detection are too coarse to assist developers to remove cycles from their programs. In this paper, we describe an efficient algorithm that performs a fine-grained analysis of cycles among application packages. In addition, we define multiple metrics to rank cycles by their level of undesirability, prioritizing cycles that are the more undesired by developers. We compare these multiple ranking metrics on four large and mature software systems in Java and Smalltalk.", "num_citations": "8\n", "authors": ["54"]}
{"title": "Meta-models and infrastructure for smalltalk omnipresent history\n", "abstract": " Source code management systems record different versions of code. Tool support can then compute deltas between versions. However there is little out of the box support to be able to perform queries and analysis over the complete history: for example tools have to build their own infrastructure to identify slices of changes and their differences since the beginning of the project. We believe that this is due to the lack of a powerful code meta-model as well as an infrastructure. For example, in Smalltalk often several source code meta-models coexist: the Smalltalk reflective API coexists with the one of the Refactoring engine or distributed versioning system such as Monticello. While having specific meta-models is an adequate engineered solution, it multiplies meta-models and it requires more maintenance efforts (eg, duplication of tests, transformation between models), and more importantly navigation tool reuse when meta-models do not offer polymorphic APIs. As a first step to solve this problem, this article presents several source code models that could be used to support several activities and proposes an unified and layered approach to be the foundation for building an infrastructure for omnipresent version browsing.", "num_citations": "8\n", "authors": ["54"]}
{"title": "Object-oriented reengineering patterns\u0393\u00c7\u00f6an overview\n", "abstract": " Successful software systems must be prepared to evolve or they will die. Although object-oriented software systems are built to last, over time they degrade as much as any legacy software system. As a consequence, one must invest in reengineering efforts to keep further development costs down. Even though software systems and their business contexts may differ in countless ways, the techniques one uses to understand, analyze and transform these systems tend to be very similar. As a consequence, one may identify various reengineering patterns that capture best practice in reverse- and re-engineering object-oriented legacy systems. We present a brief outline of a large collection of these patterns that have been mined over several years of experience with object-oriented legacy systems, and we indicate how some of these patterns can be supported by appropriate tools.", "num_citations": "8\n", "authors": ["54"]}
{"title": "A top-down program comprehension strategy for packages\n", "abstract": " Understanding packages is an important activity in the reengineering of large object-oriented systems. The relationships between packages and their contained classes can affect the cost of modifying the system. The main problem of this task is to quickly grasp the structure of a package and how it interacts with the rest of the system. In this paper we present a top-down program comprehension strategy based on polymetric views, radar charts, and software metrics. We illustrate this approach on two applications and show how we can retrieve the important characteristics of packages.", "num_citations": "8\n", "authors": ["54"]}
{"title": "The class blueprint-A visualization of the internal structure of classes\n", "abstract": " Understanding classes is a key activity in object-oriented programming, since classes represent the primary abstractions from which applications are built. The main problem of this task is to quickly grasp the purpose and inner structure of a class. In this paper we discuss the class blueprint, a visualization of the inner structure of classes, first presented in [15].", "num_citations": "8\n", "authors": ["54"]}
{"title": "Object and dependency oriented programming in FLO\n", "abstract": " The flo language integrates management of inter-object dependencies into the object oriented paradigms. In this paper, we focus on the use of reactive dependencies (links) in object-oriented knowledge representation. In particular, we present different meta-links (links between links) and show how the FLO links allow one to design some composition relationships.", "num_citations": "8\n", "authors": ["54"]}
{"title": "Dynamic software update from development to production\n", "abstract": " Abstract Dynamic Software Update (DSU) solutions update applications while they are executing. These solutions are typically used in production to minimize application downtime, or in integrated development environments to provide live programming support. Each of these scenarios presents different challenges, forcing existing solutions to be designed with only one of these use cases in mind. For example, DSUs for live programming typically do not implement safe point detection or instance migration, while production DSUs require manual generation of patches and lack IDE integration. Also, these solutions have limited ability to update themselves or the language core libraries, and some of them present execution penalties outside the update window.We propose a DSU (gDSU) that works for both live programming and production environments. Our solution implements safe update point detection using call stack manipulation and a reusable instance migration mechanism to minimize manual intervention in patch generation. Moreover, it also offers updates of core language libraries and the update mechanism itself. This is achieved by the incremental copy of the modified objects and an atomic commit operation.", "num_citations": "7\n", "authors": ["54"]}
{"title": "Smartinspect: Smart contract inspection technical report\n", "abstract": " Smart contracts are embedded procedures stored with the data they act upon. Debugging deployed Smart Contracts is a difficult task since once deployed, the code cannot be reexecuted and inspecting a simple attribute is not easily possible because data is encoded. In this technical report, we present SmartInspect to address the lack of inspectability of a deployed contract. Our solution analyses the contract state by using decompilation techniques and a mirror-based architecture to represent the object responsible for interpreting the contract state. SmartInspect allows developers and also end-users of a contract to better visualize and understand the contract stored state without needing to redeploy, nor develop any ad-hoc code.", "num_citations": "7\n", "authors": ["54"]}
{"title": "Analysis and exploration for new generation debuggers\n", "abstract": " Locating and fixing bugs is well-known to be a time consuming task. Advanced approaches such as object-centric or back-in-time debuggers have been proposed in the literature. still in many scenarios developers are left alone with generic tools such as manual breakpoints and execution stepping that, while usable, cannot adapt to specific debugging scenarios to make the life of developers easier. In this position paper we explore several advanced on-line debugging techniques such as contextual breakpoints and on-line execution comparison, that could help developers solve complex debugging scenarios. We analyse the open research challenges these techniques pose, as well as the underlying mechanisms they require. We present early but promising prototypes we built using the Pharo programming language. We finally identify future research paths by analysing existing research and connecting it to the\u252c\u00e1\u0393\u00c7\u00aa", "num_citations": "7\n", "authors": ["54"]}
{"title": "Virtual smalltalk images: Model and applications\n", "abstract": " Reflective architectures are a powerful solution for code browsing, debugging or in-language process handling. However, these reflective architectures show some limitations in edge cases of self-modification and self-monitoring. Modifying the modifier process or monitoring the monitor process in a reflective system alters the system itself, leading to the impossibility to perform some of those tasks properly. In this paper we analyze the problems of reflective architectures in the context of image based object-oriented languages and solve them by providing a first-class representation of an image: a virtualized image.We present Oz, our virtual image solution. In Oz, a virtual image is represented by an object space. Through an object space, an image can manipulate the internal structure and control the execution of other images. An Oz object space allows one to introspect and modify execution information such as processes, contexts, existing classes and objects. We show how Oz solves the edge cases of reflective architectures by adding a third participant, and thus, removing the selfmodification and self-observation constraints.", "num_citations": "7\n", "authors": ["54"]}
{"title": "Evolving a reflective language: lessons learned from implementing traits\n", "abstract": " Traits are method groups that can be used to compose classes. They do not have a runtime existence and are conceptually folded into the classes that use them. Traits have been implemented in different languages. While implementing them in Smalltalk, our first reflex was to take advantage of the fact that traits are not run-time entities: we optimized the implementation for space and hence shared methods between traits and classes. However, by doing so we broke the introspective API of Smalltalk.", "num_citations": "7\n", "authors": ["54"]}
{"title": "Aspect mining in procedural object oriented code\n", "abstract": " Although object-oriented programming promotes reusable and well factored entity decomposition, industrial software often shows traces of lack of object-oriented design and procedural thinking. This results in domain entity scattered and tangled code. This is often true in data intensive applications. Aspect mining techniques search for various patterns of scattered and tangled code pertaining to crosscutting concerns. However, in the presence of non-abstracted domain logic, the crosscutting concerns identified are inaccurately related to aspects since lack of 00 abstraction introduces false positives. This paper identifies the difficulty of identifying crosscutting concerns in systems lacking elementary object-oriented structure. It presents an approach classifying various crosscutting concerns. We report our experience on an industrial software system.", "num_citations": "7\n", "authors": ["54"]}
{"title": "How developers drive software evolution\n", "abstract": " As software systems grow, reverse engineering is becoming an increasingly important task. The larger the system grows the more complex it becomes and the more effort must be put in to understand it. Consequently, the knowledge of the developers becomes more and more critical for the process of understanding the system. However, in large systems not all developers know about the entire system. Thus, to make the best use of developer knowledge, we need to know which developer is knowledgeable in which part of it.This thesis aims to provide a lightweight approach to understand how developers changed the system, when and where they worked and which developer owned which part of the system. To answer them, we define the Ownership Map visualization based on the notion of code ownership and measurements. We semantically group files and identify behavioral patterns of the developer\u0393\u00c7\u00d6s work", "num_citations": "7\n", "authors": ["54"]}
{"title": "Evolution-enriched detection of god classes\n", "abstract": " Current approaches for automatic detection of design problems are not accurate enough because they analyze only a single version of a system and consequently they miss essential information as design problems appear and evolve over time. Our approach is to use the historical information of the suspected flawed structure to increase the accuracy of the automatic problem detection. Our means is to define measurements which summarize how persistent the problem was and how much maintenance effort was spent on the suspected structure. We apply our approach on a large scale case study and show how it improves the accuracy of the detection of God Classes and additionally how it adds valuable semantical information about the evolution of flawed design structures.Introduction. Various analysis approaches [4][8] have been developed to automatically detect where the object-oriented design problems are located, yet these approaches only make use of the information found in the last version of the system (ie, the version which is maintained). For example, we look for improper distribution of functionality among classes of a system without asking whether or not it raised maintenance problems in the past. We argue that the evolution information of the problematic classes over their life-time can give useful information to system maintainers. We propose a new approach which enriches the design problems detection by combining the analysis based on a single version with the information related to the evolution of suspected flawed classes over time. We show how we apply our approach when detecting one of the most well known design\u252c\u00e1\u0393\u00c7\u00aa", "num_citations": "7\n", "authors": ["54"]}
{"title": "R\u251c\u2310ification des sch\u251c\u2310mas de conception: une exp\u251c\u2310rience.\n", "abstract": " Alors m\u251c\u00acme que les sch\u251c\u2310mas de conception sont devenus un moyen populaire afin de d\u251c\u2310crire des solutions \u251c\u00e1 des probl\u251c\u00bfmes de conception, la question de savoir si les sch\u251c\u2310mas doivent \u251c\u00actre int\u251c\u2310gr\u251c\u2310s dans les langages (r\u251c\u2310ification, constructeurs) reste pos\u251c\u2310e. Dans cet article apr\u251c\u00bfs avoir identifi\u251c\u2310 les probl\u251c\u00bfmes li\u251c\u2310s \u251c\u00e1 l\u0393\u00c7\u00d6impl\u251c\u2310mentation des sch\u251c\u2310mas de conception et pr\u251c\u2310sent\u251c\u2310 certaines approches, nous montrons comment les connecteurs du langage FLO permettent une repr\u251c\u2310sentation et impl\u251c\u2310mentation de certains sch\u251c\u2310mas. Ensuite, l\u0393\u00c7\u00d6\u251c\u2310valuation de cette approche montre qu\u0393\u00c7\u00d6elle offre une meilleure int\u251c\u2310gration que les solutions bas\u251c\u2310es sur l\u0393\u00c7\u00d6introduction de nouvelles instructions dans le langage gr\u251c\u00f3ce \u251c\u00e1 la composition d\u0393\u00c7\u00d6abstractions \u251c\u2310l\u251c\u2310mentaires de l\u0393\u00c7\u00d6envoi de messages.ABSTRACT. Although design patterns are becoming increasingly popular as a way to describe solutions to general design problems, question about their integration in language (reification or language support) stays an open question. In this article, after identifying the implementation problems and presenting some approaches, we show how FLO\u0393\u00c7\u00d6s connectors allows for the representation and implementation of some design patterns. Thus the evaluation of this approach outlines the fact that such an approach by composing elementary message passing abstractions offers a better integration than the approaches based on construct introduction in the language.", "num_citations": "7\n", "authors": ["54"]}
{"title": "Instance migration in dynamic software update\n", "abstract": " Nowadays, there are more and more applications that need to run uninterruptedly. This need requires minimizing the downtime to add new features or fix bugs. Dynamic Software Update (DSU) solutions allow updating applications while they are executing. A common concern in all DSU solutions is the migration of the application's state. This migration should guarantee the coherence of the state between versions by either adding, removing, preserving or transforming state. In an object-oriented environment, this state is represented by instances. In this paper, we analyse the features that a DSU solution should have with the objective to understand the operations a DSU should provide. Our analysis focuses on the migration of instances. Then, we identify the Meta-Object Protocol (MOP) that a programming language should expose to support these operations. We scope our proposal to DSU solutions for class\u252c\u00e1\u0393\u00c7\u00aa", "num_citations": "6\n", "authors": ["54"]}
{"title": "Pragmas: Literal messages as powerful method annotations\n", "abstract": " Often tools need to be extended at runtime depending on the availability of certain features. Simple registration mechanisms can handle such a situation: It often boils down to represent an action and describe such action with some metadata. However, ad-hoc registration mechanisms have some drawbacks: they are often not uniform and do not fit well with code navigability. In addition, metadata is not automatically synchronized with the data or behavior it describes. In this article we present the notion of pragmas, method annotations, as it was introduced in VisualWorks and now it is an important extensibility mechanism of Pharo. We present some examples of pragmas within Pharo.", "num_citations": "6\n", "authors": ["54"]}
{"title": "Enterprise Pharo: a Web Perspective\n", "abstract": " \" Enterprise Pharo is the third volume of the series, following Pharo by Example and Deep into Pharo. It covers enterprise libraries and frameworks, and in particular those useful for doing web development. The book is structured in five parts. The first part talks about simple web applications, starting with a minimal web application in chapter 1 on Teapot and then a tutorial on building a more complete web application in chapter 2. Part two deals with HTTP support in Pharo, talking about character encoding in chapter 3, about using Pharo as an HTTP Client (chapter 4) and server (chapter 5), and about using WebSockets (chapter 6). In the third part we discuss the handling of data for the application. Firstly we treat data that is in the form of comma-separated values (CSV) in chapter 7. Secondly and thirdly, we treat JSON (chapter 8) and its Smalltalk counterpart STON (chapter 9). Fourthly, serialization and deserialization of object graphs with Fuel is treated in chapter 10. Lastly, we discuss the Voyage persistence framework and persisting to MongoDB databases in chapter 11. Part four deals with the presentation layer. Chapter 12 shows how to use Mustache templates in Pharo, and chapter 13 talks about programmatic generation of CSS files. The documentation of applications could be written in Pillar, which is presented in chapter 14. How to generate PDF files from the application with Artefact is shown in chapter 15. The fifth part deals with deploying the web application. This is explained in chapter 16 that talks not only about how to build and run the application, but also other important topics like monitoring.\"--Open Textbook Library.", "num_citations": "6\n", "authors": ["54"]}
{"title": "OrionPlanning: Improving modularization and checking consistency on software architecture\n", "abstract": " Many techniques have been proposed in the literature to support architecture definition, conformance, and analysis. However, there is a lack of adoption of such techniques by the industry. Previous work have analyzed this poor support. Specifically, former approaches lack proper analysis techniques (e.g., detection of architectural inconsistencies), and they do not provide extension and addition of new features. In this paper, we present ORIONPLANNING, a prototype tool to assist refactorings at large scale. The tool provides support for model-based refactoring operations. These operations are performed in an interactive visualization. The contributions of the tool consist in: (i) providing iterative modifications in the architecture, and (ii) providing an environment for architecture inspection and definition of dependency rules. We evaluate ORIONPLANNING against practitioners' requirements on architecture definition\u252c\u00e1\u0393\u00c7\u00aa", "num_citations": "6\n", "authors": ["54"]}
{"title": "Handles: Behavior-propagating first class references for dynamically-typed languages\n", "abstract": " Controlling object graphs and giving specific semantics to references (such as read-only, ownership, scoped sharing) have been the focus of a large body of research in the context of static type systems. Controlling references to single objects and to graphs of objects is essential to build more secure systems, but is notoriously hard to achieve in the absence of static type systems. In this article we embrace this challenge by proposing a solution to the following question: What is an underlying mechanism that can support the definition of properties (such as revocable, read-only, lent) at the reference level in the absence of a static type system? We present handles: first-class references that propagate behavioral change dynamically to the object subgraph during program execution. In this article we describe handles and show how handles support the implementation of read-only references and revocable references\u252c\u00e1\u0393\u00c7\u00aa", "num_citations": "6\n", "authors": ["54"]}
{"title": "Software integration questions: A quantitative survey\n", "abstract": " Software is in constant evolution. In a software project, code changes represent bug fixes, enhancements, new features and adaptations due to changing domains. The evolution of a project codebase is usually managed in a revision control system that supports branches. Developers perform code changes in a branch and sometimes such changes are merged into other branch. This activity is called integration. Integration of changes poses substantial challenges. We conducted a survey to evaluate a catalogue of 46 questions about integration. For each question, the participants had to rank the importance and the support that current tools offer. In a period of 5 months we received the responses of 42 developers who integrate changes on very diverse software projects.", "num_citations": "6\n", "authors": ["54"]}
{"title": "Language-side foreign function interfaces with nativeboost\n", "abstract": " Foreign-Function-Interfaces (FFIs) are a prerequisite for close system integration of a high-level language. With FFIs the high-level environment interacts with low-level functions allowing for a unique combination of features. This need to interconnect high-level (Objects) and low-level (C functions) has a strong impact on the implementation of a FFI: it has to be flexible and fast at the same time.", "num_citations": "6\n", "authors": ["54"]}
{"title": "Marea: An efficient application-level object graph swapper\n", "abstract": " During the execution of object-oriented applications, several millions of objects are created, used and then collected if they are not referenced. Prob- lems appear when objects are unused but cannot be garbage-collected because they are still referenced from other objects. This is an issue because those ob- jects waste primary memory and applications use more primary memory than they actually need. We claim that relying on the operating system's (OS) virtual memory is not always enough since it cannot take into account the domain and structure of applications. At the same time, applications have no easy way to parametrize nor cooperate with memory management. In this paper, we present Marea, an efficient application-level object graph swapper for object-oriented programming languages. Its main goal is to offer the programmer a novel so- lution to handle application-level memory. Developers can instruct our system to release primary memory by swapping out unused yet referenced objects to secondary memory. Our approach has been qualitatively and quantitatively val- idated. Our experiments and benchmarks on real-world applications show that Marea can reduce the memory footprint between 23% and 36%.", "num_citations": "6\n", "authors": ["54"]}
{"title": "Interop\u251c\u2310rabilit\u251c\u2310 des syst\u251c\u00bfmes d'information: approches dirig\u251c\u2310es par les mod\u251c\u00bfles\n", "abstract": " Les systemes d\u0393\u00c7\u00d6information sont de plus en plus souvent construitsa partir de l\u0393\u00c7\u00d6agr\u251c\u2310gation de systemes informatiques qu\u0393\u00c7\u00d6il convient de maintenir et faire \u251c\u2310voluer avec agilit\u251c\u2310 et sans entropie non contr\u251c\u2524l\u251c\u2310e. Ceci n\u0393\u00c7\u00d6est pas sans poser des problemes d\u0393\u00c7\u00d6interop\u251c\u2310rabilit\u251c\u2310! L\u0393\u00c7\u00d6ing\u251c\u2310nierie dirig\u251c\u2310e par les modeles (IDM) a entre autres objectifs d\u0393\u00c7\u00d6apporter des solutions aux difficult\u251c\u2310s d\u0393\u00c7\u00d6interop\u251c\u2310rabilit\u251c\u2310 entre les systemes. Cet article est le r\u251c\u2310sum\u251c\u2310 des r\u251c\u2310flexions men\u251c\u2310es au sein de l\u0393\u00c7\u00d6action sp\u251c\u2310cifique \u252c\u00bdInterop\u251c\u2310rabilit\u251c\u2310 des Systemes d\u0393\u00c7\u00d6Information et ing\u251c\u2310nierie des modeles: quels d\u251c\u2310fis, quelles solutions?\u252c\u2557 soutenue par inforsid. Nous proposons une synthese d\u0393\u00c7\u00d6un ensemble d\u0393\u00c7\u00d6approches bas\u251c\u2310es sur l\u0393\u00c7\u00d6IDM et l\u0393\u00c7\u00d6ing\u251c\u2310nierie des connaissances r\u251c\u2310pondanta des problemes du monde industriel pos\u251c\u2310s par l\u0393\u00c7\u00d6interop\u251c\u2310rabilit\u251c\u2310. De nombreuses questions et limites ont \u251c\u2310t\u251c\u2310 soulev\u251c\u2310es lors de nos rencontres qui sont ici \u251c\u2310galement rapport\u251c\u2310es dans cet article.ABSTRACT. Information systems are more and more often based on aggregation of other systems that must be maintained and evolved in an agile way and with no entropy creation. This is not without interoperability problems! Among others, the aim of Model-Driven Engineering (MDE) is to provide solutions for interoperability issues between systems. This paper summarizes thoughts that have come up from the specific action\u0393\u00c7\u00a5 Interoperability of information systems and model-driven engineering: What challenges? What solutions?\u0393\u00c7\u00a5 supported by inforsid. We propose a summary of approaches that are based on MDE and knowledge engineering and that tackle interoperability issues in the industry. Open questions and limitations\u252c\u00e1\u0393\u00c7\u00aa", "num_citations": "6\n", "authors": ["54"]}
{"title": "Towards structural decomposition of reflection with mirrors\n", "abstract": " Mirrors are meta-level entities introduced to decouple reflection from the base-level system. Current mirror-based systems focus on functional decomposition of reflection. In this paper we advocate that mirrors should also address structural decomposition. Mirrors should not only be the entry points of reflective behavior but also be the storage entities of metainformation. This decomposition can help resolve issues in terms of resource constraints (eg embedded systems and robotics) or security. Indeed, structural decomposition enables discarding meta-information.", "num_citations": "6\n", "authors": ["54"]}
{"title": "Visualizing objects and memory usage\n", "abstract": " Most of the current garbage collector implementations work by reachability. This means they only take care of the objects that nobody else points to. As a consequence, there are objects which are not really used but are not garbage collected because they are still referenced. Such unused but reachable objects create memory leaks. This is a problem because applications use much more memory than what is actually needed. In addition, they may get slower and crash. It is important to understand which parts of the system are instantiated but also which are used or unused. There is a plethora of work on runtime information or class instantiation visualizations but none of them show whether instances are actually used. Such information is important to identify memory leaks. In this paper, we present some visualizations that show used/unused objects in object-oriented applications. For this, we use Distribution Map which is a visualization showing spread and focus of properties across systems. We extend Distribution Maps to represent the way classes are used or not, since we distinguish between a class that just has instances from one that has used instances. To identify unused objects, we modified the Pharo Virtual Machine.", "num_citations": "6\n", "authors": ["54"]}
{"title": "Higher order messaging\n", "abstract": " We introduce Higher Order Messaging, a higher order programming mechanism for dynamic object-oriented languages. Higher Order Messages allow user-defined message dispatch mechanism to be expressed using an optimally compact syntax that is a natural extension of plain messaging and also have a simple conceptual model. They can be implemented without extending the base language and operate through language bridges.", "num_citations": "6\n", "authors": ["54"]}
{"title": "The lan-simulation: A research and teaching example for refactoring\n", "abstract": " The notion of refactoring \u0393\u00c7\u00f6- transforming the source-code of an object-oriented program without changing its external behaviour \u0393\u00c7\u00f6- has been studied intensively within the last decade. This diversity has created a plethora of toy-examples, cases and code snippets, which make it hard to assess the current state-of-the-art. Moreover, due to this diversity, there is currently no accepted way of teaching good refactoring practices, despite the acknowledgment in the software engineering body of knowledge. Therefore, this paper presents a common example \u0393\u00c7\u00f6- the LAN simulation \u0393\u00c7\u00f6- which has been used by a number of European Universities for both research and teaching purposes.", "num_citations": "6\n", "authors": ["54"]}
{"title": "Moose\u0393\u00c7\u00f6a Language-Independent Reengineering Environment\n", "abstract": " Aging software systems are difficult and expensive to maintain. Moose is a language-independent environment that supports a wide range of tools to visualise, analyse and manipulate complex software systems.", "num_citations": "6\n", "authors": ["54"]}
{"title": "Traits: The formal model\n", "abstract": " Traits are reusable units of behaviour that provide a level of structuring for object-oriented programs above the level of methods but below the level of classes. Structuring classes with single-inheritance alone can lead to duplicated code when different branches of the hierarchy need to use the same feature. Multiple-inheritance and mixins alleviate this problem, but lead to other difficulties in the face of evolution: changes to classes or mixins can break code lower in the hierarchy in unexpected ways.Traits solve both problems by factoring out shared behaviour as sets of methods that do not depend on state. Trait composition is symmetric and conflicts must be managed explicitly; this means that changes in the components do not lead to unexpected side effects. This paper presents a formal model of traits, and defines some basic properties of traits and classes. We also model the internal dependencies created by\u252c\u00e1\u0393\u00c7\u00aa", "num_citations": "6\n", "authors": ["54"]}
{"title": "Retro-Conception d\u0393\u00c7\u00d6Applicationa Objets Reengineering Object-Oriented Applications\n", "abstract": " La r\u251c\u2310-ing\u251c\u2310nierie des applications est devenue une activit\u251c\u2310 vitale pour l\u0393\u00c7\u00d6industrie dans un contexte ou les changements d\u0393\u00c7\u00d6emplois appauvrissent les applications en d\u251c\u2310truisant la connaissance orale d\u251c\u2310tenue par les d\u251c\u2310veloppeurs et ou les applications doivent constamment \u251c\u2310voluer afin de satisfaire de nouveaux besoins. Ce document r\u251c\u2310sume un effort de recherche sur la r\u251c\u2310tro-conception et la r\u251c\u2310ing\u251c\u2310nierie des applications orient\u251c\u2310e objets. Il d\u251c\u2310crit (1) la d\u251c\u2310finition d\u0393\u00c7\u00d6un m\u251c\u2310ta-modele adapt\u251c\u2310a la r\u251c\u2310-ing\u251c\u2310nierie, FAMIX. Ce m\u251c\u2310ta-modele permet non seulement des op\u251c\u2310rations de r\u251c\u2310tro-conception mais aussi l\u0393\u00c7\u00d6expression de transformation de code (refactorings),(2) la pr\u251c\u2310sentation d\u0393\u00c7\u00d6une plateforme de r\u251c\u2310-ing\u251c\u2310nierie, MOOSE, qui sert de basea un grand nombre de nos travaux,(3) l\u0393\u00c7\u00d6\u251c\u2310valuation de m\u251c\u2310triques logicielles pour la r\u251c\u2310-ing\u251c\u2310nierie,(4) la d\u251c\u2310finition de techniques visuelles pour la compr\u251c\u2310hension de tres grandes applications et de classes,(5) l\u0393\u00c7\u00d6identification de code dupliqu\u251c\u2310 de maniere ind\u251c\u2310pendante des langages et des solutions pour le traiter,(6) le m\u251c\u2310lange d\u0393\u00c7\u00d6information dynamiques et statiques pour la g\u251c\u2310n\u251c\u2310ration de vues composables et d\u0393\u00c7\u00d6information de collaboration et (7) l\u0393\u00c7\u00d6identification de patterns de r\u251c\u2310-ing\u251c\u2310nierie.", "num_citations": "6\n", "authors": ["54"]}
{"title": "Experiences in Object-Oriented Re-Engineering\n", "abstract": " The ability to reengineer object-oriented systems has become a vital matter in today\u0393\u00c7\u00d6s software industry. Early adopters of the object-oriented programming paradigm are now facing the problem of transforming their object-oriented \u0393\u00c7\u00fflegacy\u0393\u00c7\u00d6 systems into full-fledged frameworks. Dealing with programs exceeding 10,000 lines of badly documented code definitely requires support from methodologies as well as tools.", "num_citations": "6\n", "authors": ["54"]}
{"title": "Protocol for managing dependencies between objects by controlling generic function invocation\n", "abstract": " The design of programming environments, hypertexts, graphical interfaces, and communications between processes all require the representation and management of dependencies between entities (dependencies between an object and its views, liaison between menu and text selection) KR91, San89, CMP91, Rum92]. Consequently object systems allying objects and constraints have been developed MGZ92, FBMB90, Ilo91]. For this approach, we need information on object's structures, which goes against principles of object encapsulation Wil91], and does not allow expression of event-based actions. The standard daemon and active value mechanisms allow implementation of certain dependencies, however there is also a di usion of information and it is not easy to de ne new dependencies FPT89].In a class-instance model, we allow a programmer to express dependencies between his previously de ned objects. For this, we propose a protocol to model and manage dependencies. It is based on an object representation of dependencies (the links) and the control of function calls. This protocol is then an over system of an object system which is not modi ed by adjunction of dependencies.", "num_citations": "6\n", "authors": ["54"]}
{"title": "Analysing microsoft access projects: building a model in a partially observable domain\n", "abstract": " Due to the technology evolution, every IT Company migrates their software systems at least once. Reengineering tools build system models which are used for running software analysis. These models are traditionally built from source code analysis and information accessible by data extractors (that we call such information observable). In this article we present the case of Microsoft Access projects and how this kind of project is partially observable due to proprietary storing formats. We propose a novel approach for building models that allows us to overcome this problem by reverse engineering the development environment runtime through the usage of Microsoft COM interface. We validate our approach and implementation by fully replicating 10 projects, 8 of them industrial, based only on our model information. We measure the replication performance by measuring the errors during the process and\u252c\u00e1\u0393\u00c7\u00aa", "num_citations": "5\n", "authors": ["54"]}
{"title": "A new modular implementation for stateful traits\n", "abstract": " The term traits is overloaded in the literature. In this work we refer to traits as the stateless model and implementation described in Schaerli et al. articles.Traits provide a flexible way to support multiple inheritance code reuse in the context of a single inheritance language. The Pharo programming language includes the second implementation of stateless traits based on the original version of Schaerli's one. Even if it is the second iteration of such an implementation, it presents several limitations. First, it does not support state in traits. Second, its implementation is monolithic i.e., it is deeply coupled with the rest of the language kernel: it cannot be loaded nor unloaded. Furthermore, trait support impacts all classes, even classes not using traits. In addition, while the development tools include full support to work with classes, trait support is more limited because classes and traits do not present the same Metaobject\u252c\u00e1\u0393\u00c7\u00aa", "num_citations": "5\n", "authors": ["54"]}
{"title": "Recommendations for evolving relational databases\n", "abstract": " Relational databases play a central role in many information systems. Their schemas contain structural and behavioral entity descriptions. Databases must continuously be adapted to new requirements of a world in constant change while: (1) relational database management systems (RDBMS) do not allow inconsistencies in the schema; (2) stored procedure bodies are not meta-described in RDBMS such as PostgreSQL that consider their bodies as plain text. As a consequence, evaluating the impact of an evolution of the database schema is cumbersome, being essentially manual. We present a semi-automatic approach based on recommendations that can be compiled into a SQL patch fulfilling RDBMS constraints. To support recommendations, we designed a meta-model for relational databases easing computation of change impact. We performed an experiment to validate the approach by\u252c\u00e1\u0393\u00c7\u00aa", "num_citations": "5\n", "authors": ["54"]}
{"title": "The Spec UI Framework\n", "abstract": " Spec is a framework in Pharo for describing user interfaces. It allows for the construction of a wide variety of UIs; from small windows with a few buttons up to complex tools like a debugger. Indeed multiple tools in Pharo are written in Spec, eg, the Watchpoint window, Komitter, Change Sorter, Critics Browser, and the Pharo 3 debugger.The fundamental principle behind Spec is reuse of user interface logic and visual composition. User interfaces are built by reusing and composing existing user interfaces, configuring them as needed. This principle starts from the most primitive elements of the UI: widgets such as buttons and labels are in themselves complete UIs that can be reused, configured, and opened in their own window. These elements can be combined to form more complex UIs that again can be reused as part of a bigger UI, and so on. This is somewhat similar to how the different tiles on the cover of this book are combined. Smaller tiles configured with different colors or patterns join to form bigger rectangular shapes that are a part of an even bigger floor design.", "num_citations": "5\n", "authors": ["54"]}
{"title": "Spec: A Framework for the Specification and Reuse of UIs and their Models\n", "abstract": " Implementing UIs is often a tedious task. To address this, UI Builders have been proposed to support the description of widgets, their location, and their logic. A missing aspect of UI Builders is however the ability to reuse and compose widget logic. In our experience, this leads to a significant amount of duplication in UI code. To address this issue, we built Spec: a UIBuilder for Pharo with a focus on reuse. With Spec, widget properties are defined declaratively and attached to specific classes known as composable classes. A composable class defines its own widget description as well as the model-widget bridge and widget interaction logic. This paper presents Spec, showing how it enables seamless reuse of widgets and how these can be customized. After presenting Spec and its implementation, we discuss how its use in Pharo 2.0 has cut in half the amount of lines of code of six of its tools, mostly through reuse\u252c\u00e1\u0393\u00c7\u00aa", "num_citations": "5\n", "authors": ["54"]}
{"title": "Problems and challenges when building a manager for unused objects\n", "abstract": " Large object-oriented applications may occupy hundreds of megabytes or even gigabytes of memory. During program execution, a large graph of objects is created and constantly changed. Most object runtimes support some kind of automatic memory management based on garbage collectors (GC) whose idea is the automatic destruction of unreferenced objects. However, there are referenced objects which are not used for a long period of time or that are used just once. These are not garbage-collected because they are still reachable and might be used in the future. Due to these unused objects, applications use much more resources than they actually need. In this paper we present the challenges and possible approaches towards an unused object manager for Pharo. The goal is to use less memory by swapping out the unused objects to secondary memory and only leaving in primary memory only those objects which are needed and used. When one of the unused objects is needed, it is brought back into primary memory.", "num_citations": "5\n", "authors": ["54"]}
{"title": "Identifying cycle causes with cycletable\n", "abstract": " Identifying and understanding cycles in large applica- tions is a challenging task. In this paper we present Cy- cleTable which displays both direct and indirect references. It shows how minimal cycles are intertwined through shared edges and allows the reengineer to devise simple strategies to remove them.", "num_citations": "5\n", "authors": ["54"]}
{"title": "iSTOA: Artefacts for mathematical interactive learning exercises\n", "abstract": " In primary schools, mathematics teachers use support tools to introduce new concepts. The objective of these tools is to reinforce a mental representation of the newly introduced concept. Tools can be physical objects or paper- pen based. We call these tools artefacts. In computer assisted environments, such artefacts are not always clearly present, those environments focus on the nature of the exercises (drills, quiz). To realise environments in closer relation to classroom teaching, we propose to analyse and categorise such artefacts: we used pedagogical literature and we extracted artefacts used in teaching multiplication. We present our infrastructure and a list of artefacts in the multiplication realm.", "num_citations": "5\n", "authors": ["54"]}
{"title": "De l'importance des plans d'interaction dans la g\u251c\u2310om\u251c\u2310trie interactive\n", "abstract": " Les environnements de g\u251c\u2310om\u251c\u2310trie interactive permettent cr\u251c\u2310ations et explorations de figures g\u251c\u2310om\u251c\u2310triques. Ceux-ci imposent cependant \u251c\u00e1 l'apprenant un formalisme fort lors de la construction d'une figure. Cette rigidit\u251c\u2310 n'est pas toujours compatible avec la repr\u251c\u2310sentation cognitive de l'ap- prenant du domaine d'apprentissage. Elle est donc source de tensions internes chez celui-ci et peut r\u251c\u2310duire la port\u251c\u2310e p\u251c\u2310dagogique de ces environnements. Nous pensons que des plans d'interaction suppl\u251c\u2310mentaires pour manipuler diff\u251c\u2310remment une m\u251c\u00acme figure g\u251c\u2310om\u251c\u2310trique peuvent aider l'appre- nant. Nous avons ainsi d\u251c\u2310velopp\u251c\u2310 un framework de g\u251c\u2310om\u251c\u2310trie interactive permettant l'ajout de tels plans puis nous avons exp\u251c\u2310riment\u251c\u2310 son utilisation dans une classe de 3e .", "num_citations": "5\n", "authors": ["54"]}
{"title": "Reflective Programming and Open Implementations\n", "abstract": " It has been shown that programming with metaclasses is of great bene t [KAJ+93][Zim96][BGL98]. An interesting use of metaclasses is the assignment of speci c properties to classes. For example, a class can be abstract, have a unique instance, trace messages received by its instances, de ne pre-post conditions on its methods, forbid rede nition of some particular methods... These properties can be implemented using metaclasses, allowing thereby the customization of the classes behavior [LC96].From an architectural point of view, using metaclasses organizes applications into abstraction levels. Each level describes and controls the level immediately below to which it is causally connected [Mae87]. Rei ed classes communicate with other objects including their own instances. Thus, classes can send messages to their instances and instances can send messages to their classes. Such message sending is named inter-level communication [MMC95].", "num_citations": "5\n", "authors": ["54"]}
{"title": "De l'enseignement de concepts informatiques\n", "abstract": " Le cours de technologie en coll\u251c\u00bfge peut \u251c\u00actre un terrain propice \u251c\u00e1 l'utilisation de nouvelles technologies lorsque celles-ci sont utilis\u251c\u2310es de mani\u251c\u00bfre ad\u251c\u2310quate. Cependant, mettre des ordinateurs dans les classes et l'acc\u251c\u00bfs \u251c\u00e1 Internet ne sont que des solutions quantitatives alors que la solution est qualitative. Comme le faisait remarquer Alan Kay, le cr\u251c\u2310ateur de Smalltalk, ce n'est pas parce que l'on met un piano dans chaque classe de cours que l'on sollicite des vocations de pianistes, en particulier lorsque les enseignants ne sont pas eux-m\u251c\u00acmes musiciens ou sensibilis\u251c\u2310s \u251c\u00e1 la musique. Cette triste mais \u251c\u2310vidente constatation trouve son \u251c\u2310cho dans les cours de technologie de coll\u251c\u00bfge. Dans cet article nous pr\u251c\u2310sentons comment nous avons utilis\u251c\u2310 une approche bas\u251c\u2310e sur une tortue en Smalltalk afin d'enseigner des concepts informatiques de programmation. Nous abordons le contexte et les motivations qui nous ont pouss\u251c\u2310 \u251c\u00e1 d\u251c\u2310finir ce cours. Nous pr\u251c\u2310sentons ensuite notre approche, et montrons un exemple d'interrogation, puis les r\u251c\u2310sultats de l'apprentissage par les \u251c\u2310l\u251c\u00bfves. Nous expliquons aussi comment nous avons int\u251c\u2310gr\u251c\u2310 l'utilisation d'un site web collaboratif comme m\u251c\u2310dium pour la pr\u251c\u2310sentation des r\u251c\u2310sultats. Nous finissons par une \u251c\u2310valuation compl\u251c\u00bfte de l'approche et donnons des informations pratiques.", "num_citations": "5\n", "authors": ["54"]}
{"title": "Transform Conditionals to Polymorphism.\n", "abstract": " Conditionals\u0393\u00c7\u00f6ie, switch statements, nested ifs\u0393\u00c7\u00f6that are used to simulate polymorphism hamper evolution and flexibility of applications. The reengineering patterns presented in this paper show you how to transform conditionals in object-oriented code to improve the flexibility of application.", "num_citations": "5\n", "authors": ["54"]}
{"title": "Type-check elimination: Two reengineering patterns\n", "abstract": " Whereas a design pattern describes and discusses a solution to a design problem, a reengineering pattern describes how to go from an existing solution to a better solution. In the context of a project developing a methodology for reengineering object-oriented legacy systems to frameworks, we are working on a pattern language for reengineering. In this paper we highlight the structure of a reengineering pattern and present two simple, related patterns1.", "num_citations": "5\n", "authors": ["54"]}
{"title": "A reflexive and automated approach to syntactic pattern matching in code transformations\n", "abstract": " Empowering software engineers often requires to let them write code transformations. However existing automated or tool-supported approaches force developers to have a detailed knowledge of the internal representation of the underlying tool. While this knowledge is time consuming to master, the syntax of the language, on the other hand, is already well known to developers and can serve as a strong foundation for pattern matching. Pattern languages with metavariables (that is variables holding abstract syntax subtrees once the pattern has been matched) have been used to help programmers define program transformations at the language syntax level. The question raised is then the engineering cost of metavariable support. Our contribution is to show that, with a GLR parser, such patterns with metavariables can be supported by using a form of runtime reflexivity on the parser internal structures. This\u252c\u00e1\u0393\u00c7\u00aa", "num_citations": "4\n", "authors": ["54"]}
{"title": "Implementing modular class-based reuse mechanisms on top of a single inheritance VM\n", "abstract": " Code reuse is a good strategy to avoid code duplication and speed up software development. Existing object-oriented programming languages propose different ways of combining existing and new code such as eg, single inheritance, multiple inheritance, Traits or Mixins. All these mechanisms present advantages and disadvantages and there are situations that require the use of one over the other. To avoid the complexity of implementing a virtual machine (VM), many of these mechanisms are often implemented on top of an existing high-performance VM, originally meant to run a single inheritance object-oriented language. These implementations require thus a mapping between the programming model they propose and the execution model provided by the VM. Moreover, reuse mechanisms are not usually composable, nor it is easy to implement new ones for a given language.", "num_citations": "4\n", "authors": ["54"]}
{"title": "End-user abstractions for meta-control: Reifying the reflectogram\n", "abstract": " Reflective facilities in OO languages are used both for implementing language extensions (such as AOP frameworks) and for supporting new programming tools and methodologies (such as object-centric debugging and message-based profiling). Yet controlling the runtime behavior of these reflective facilities introduces several challenges, such as computational overhead, the possibility of meta-recursion and an unclean separation of concerns between base and meta-level. In this paper we present five dimensions of meta-level control from related literature that try to remedy these problems. These dimensions are namely: temporal and spatial control, placement control, level control and identity control. We then discuss how these dimensions interact with language semantics in class-based OO languages in terms of: scoping, inheritance and first-class entities. We argue that the reification of the descriptive notion\u252c\u00e1\u0393\u00c7\u00aa", "num_citations": "4\n", "authors": ["54"]}
{"title": "Do Tools Support Code Integration? A Survey.\n", "abstract": " Integrating changes made by other developers is a difficult and tedious process. To understand how to help integrators, we first need to know the main questions they ask themselves while integrating and then relate these questions to the tool support that is needed. With this information, researchers and tool developers will be able to focus on the important questions that have little tool support. In this paper, we report on a 2-step study. In the first step, we did an open call to integrators. We ask them to list questions they ask themselves when they integrate a change. In the second step, based on the questions gathered during the first step and a literature survey, we built a list of 46 questions and run a survey to rank the importance of each question and if the level of tool support was adequate. We present the results we collected. Additionally, we present a taxonomy of the questions according to the kind of information that tools need to answer such questions.We found out that some questions like \u0393\u00c7\u00a3Who is the author of this changed code?\u0393\u00c7\u00a5 are important and have good tool support whereas others like \u0393\u00c7\u00a3Do all the changes within the commit belong together?(Can we split the commit?)\u0393\u00c7\u00a5 are moderately to extremely important and have no tool support.", "num_citations": "4\n", "authors": ["54"]}
{"title": "A bootstrapping infrastructure to build and extend pharo-like languages\n", "abstract": " Bootstrapping is well known in the context of compilers, where a bootstrapped compiler can compile its own source code. Bootstrapping is a beneficial engineering practice because it raises the level of abstraction of a program making it easier to understand, optimize, evolve, etc. Bootstrapping a reflective object-oriented language is however more challenging, as we need also to initialize the runtime of the language with its initial objects and classes besides writing its compiler. In this paper, we present a novel bootstrapping infrastructure for Pharo-like languages that allows us to easily extend and modify such languages. Our bootstrapping process relies on a first-class runtime. A first-class runtime is a meta-object that represents a program\u0393\u00c7\u00d6s runtime and provides a MOP to easily load code into it and manipulate its objects. It decouples the virtual machine (VM) and language concerns by introducing a clear VM\u252c\u00e1\u0393\u00c7\u00aa", "num_citations": "4\n", "authors": ["54"]}
{"title": "The Package Blueprint: Visually analyzing and quantifying packages dependencies\n", "abstract": " Large object-oriented applications are structured over many packages. Packages are important but complex structural entities that are difficult to understand since they act as containers of classes, which can have many dependencies with other classes spread over multiple packages. However to be able to take decisions (e.g. refactoring and/or assessment decisions), maintainers face the challenges of managing (sorting, grouping) the massive amount of dependencies between classes spread over multiple packages. To help maintainers, there is a need for at the same time understanding, and quantifying, dependencies between classes as well as understanding how packages as containers of such classes depend on each other.In this paper, we present a visualization, named Package Blueprint, that reveals in detail package internal structure, as well as the dependencies between an observed package and its\u252c\u00e1\u0393\u00c7\u00aa", "num_citations": "4\n", "authors": ["54"]}
{"title": "Benzo: Reflective glue for low-level programming\n", "abstract": " The goal of high-level low-level programming is to bring the abstraction capabilities of high-level languages to the system programming domain, such as virtual machines (VMs) and language runtimes. However, existing solutions are bound to compilation time and expose limited possibilities to be changed at runtime and from language-side. They do not fit well with fully reflective languages and environments. We propose Benzo1, a lightweight framework for high- level low-level programming that allows developers to generate and execute at runtime low-level code (assembly). It promotes the implementation, and dynamic modification, of system components with high-level language tools outperforming existing dynamic solutions. Since Benzo is a general framework we choose three applications that cover an important range of the spectrum of system programming for validating the infrastructure: a For- eign Function Interface (FFI), primitives instrumentation and a just-in-time bytecode compiler (JIT). With Benzo we show that these typical VM-level components are feasible as reflective language-side implementations. Due to its unique combination of high-level reflection and low-level programming, Benzo shows better performance for these three applications than the comparable high-level implementations.", "num_citations": "4\n", "authors": ["54"]}
{"title": "Object Graph Isolation with Proxies\n", "abstract": " More and more software systems are now made of multiple collaborating third-party components. Enabling fine-grained control over the communication between components becomes a major requirement. While software isolation has been studied for a long time in operating systems (OS), most programming languages lack support for isolation. In this context we explore the notion of proxy. A proxy is a surrogate for another object that controls access to this object. We are particularly interested in generic proxy implementations based on language-level reflection. We present an analysis that shows how these reflective proxies can propagate a security policy thanks to the transitive wrapping mechanism. We present a prototype implementation that support transitive wrapping and allows a fine-grained control over an isolated object graph.", "num_citations": "4\n", "authors": ["54"]}
{"title": "Object swapping challenges: an evaluation of imagesegment\n", "abstract": " In object-oriented systems, runtime memory is composed of an object graph in which objects refer to other objects. This graph of objects evolves while the system is running. Graph exporting and swapping are two important object graph operations. Exporting refers to copying the graph to some other memory so that it can be loaded by another system. Swapping refers to moving the graph to a secondary memory (e.g., a hard disk) to temporary release part of the primary memory (e.g., RAM).Exporting and swapping are achieved in different ways and the speed in the presence of large object graphs is critical. Nevertheless, most of the existing solutions do not address well this issue. Another challenge is to deal with common situations where objects outside the exported/swapped graph point to objects inside the graph. To correctly load back an exported subgraph, it is necessary to compute and export extra\u252c\u00e1\u0393\u00c7\u00aa", "num_citations": "4\n", "authors": ["54"]}
{"title": "Mod\u251c\u00bfles de mesure de la qualit\u251c\u2310 des logiciels\n", "abstract": " De mani\u251c\u00bfre g\u251c\u2310n\u251c\u2310rale, un logiciel de qualit\u251c\u2310 s'entend comme un logiciel capable de r\u251c\u2310pondre parfaitement aux attentes du client, le tout sans d\u251c\u2310faut d'ex\u251c\u2310cution. Ainsi, on d\u251c\u2310termine la qualit\u251c\u2310 logicielle comme un ensemble de r\u251c\u00bfgles et de principes \u251c\u00e1 suivre au cours du d\u251c\u2310veloppement d'une application afin de concevoir un logiciel r\u251c\u2310pondant \u251c\u00e1 ces attentes1 [ABDT04]. La NASA par exemple, a d\u251c\u2310termin\u251c\u2310 un ensemble de proc\u251c\u2310dures, d'instructions de travail et de r\u251c\u00bfgles pour s'assurer que chaque \u251c\u2310tape du d\u251c\u2310veloppement s'effectue de mani\u251c\u00bfre ad\u251c\u2310quate2 [EBM06]. La qualit\u251c\u2310 d'un logiciel se refl\u251c\u00bfte non seule- ment dans les processus de d\u251c\u2310veloppement mais aussi dans la qualit\u251c\u2310 des \u251c\u2310l\u251c\u2310ments qui le constituent, la documentation, la pr\u251c\u2310sence de tests..... Mesurer la qualit\u251c\u2310 d'un logiciel consiste alors \u251c\u00e1 d\u251c\u2310terminer son ad\u251c\u2310quation par rapport aux objectifs de d\u251c\u2310part et aux standards de programmation. Il faut donc d\u251c\u2310finir pr\u251c\u2310cis\u251c\u2310ment ce que l'application doit faire et comment elle doit le faire, tant d'un point de vue fonctionnel que d'un point de vue technique. Une fois ces objectifs fix\u251c\u2310s, on peut alors appliquer un ensemble de r\u251c\u00bfgles et de mesures afin de calculer la diff\u251c\u2310rence entre objectifs attendus et r\u251c\u2310alisation obtenue. Obtenir une mesure de la qualit\u251c\u2310 permet \u251c\u00e1 la fois d'avoir une image pr\u251c\u2310cise du logiciel mesur\u251c\u2310 mais aussi de d\u251c\u2310terminer le comportement de celui-ci dans le temps : quels sont les risques de bogues, les \u251c\u2310ventuelles failles s\u251c\u2310curitaires, les difficult\u251c\u2310s de maintenance, les freins \u251c\u00e1 l'\u251c\u2310volution, la viabilit\u251c\u2310 \u251c\u00e1 long terme, etc. Un des objectifs de la mesure de la qualit\u251c\u2310 logicielle consiste \u251c\u00e1 sensibiliser les \u251c\u2310quipes de d\u251c\u2310veloppement sur leur\u252c\u00e1\u0393\u00c7\u00aa", "num_citations": "4\n", "authors": ["54"]}
{"title": "Matrice de d\u251c\u2310pendances enrichie\n", "abstract": " Les matrices de d\u251c\u2310pendance (DSM-Dependency Structure Matrix), d\u251c\u2310velopp\u251c\u2310es dans le cadre de l\u0393\u00c7\u00d6optimisation de processus, ont fait leurs preuves pour identifier les d\u251c\u2310pendances logicielles entre des packages ou des sous-syst\u251c\u00bfmes. Il existe plusieurs algorithmes pour structurer une matrice de fa\u251c\u00baon \u251c\u00e1 ce qu\u0393\u00c7\u00d6elle refl\u251c\u00bfte l\u0393\u00c7\u00d6architecture des \u251c\u2310l\u251c\u2310ments analys\u251c\u2310s et mette en \u251c\u2310vidence des cycles entre les sous-syst\u251c\u00bfmes. Cependant, les impl\u251c\u2310mentations de matrices de d\u251c\u2310pendance existantes manquent d\u0393\u00c7\u00d6informations importantes pour apporter une r\u251c\u2310elle aide au travail de r\u251c\u2310ing\u251c\u2310nierie. Par exemple, le poids des relations qui posent probl\u251c\u00bfme ainsi que leur type ne sont pas clairement pr\u251c\u2310sent\u251c\u2310s. Ou encore, des cycles ind\u251c\u2310pendants sont fusionn\u251c\u2310s. Il est \u251c\u2310galement difficile d\u0393\u00c7\u00d6obtenir une visualisation centr\u251c\u2310e sur un package. Dans ce papier, nous am\u251c\u2310liorons les matrices de d\u251c\u2310pendance en ajoutant des informations sur (i) le type de r\u251c\u2310f\u251c\u2310rences,(ii) le nombre d\u0393\u00c7\u00d6entit\u251c\u2310s r\u251c\u2310f\u251c\u2310ren\u251c\u00baantes,(iii) le nombre d\u0393\u00c7\u00d6entit\u251c\u2310s r\u251c\u2310f\u251c\u2310renc\u251c\u2310es. Nous distinguons \u251c\u2310galement les cycles ind\u251c\u2310pendants. Ce travail a \u251c\u2310t\u251c\u2310 impl\u251c\u2310ment\u251c\u2310 dans l\u0393\u00c7\u00d6environnement de r\u251c\u2310ing\u251c\u2310nierie open-source Moose. Il a \u251c\u2310t\u251c\u2310 appliqu\u251c\u2310 \u251c\u00e1 des \u251c\u2310tudes de cas complexes comme le framework Morphic UI contenu dans les environnements Smalltalk open-source Squeak et Pharo. Les r\u251c\u2310sultats obtenus ont \u251c\u2310t\u251c\u2310 appliqu\u251c\u2310s dans l\u0393\u00c7\u00d6environnement de programmation Pharo et ont men\u251c\u2310 \u251c\u00e1 des am\u251c\u2310liorations.", "num_citations": "4\n", "authors": ["54"]}
{"title": "Mining and classification of diverse crosscutting concerns\n", "abstract": " Crosscutting concerns appear in software system due to the inherent inadequacy of OOP mechanisms to capture them in suitable encapsulating units. This results in scattered and tangled code. One more form of scattering and tangling may result from the absence of OOP abstractions for domain entities of a software. These non-encapsulated domain entities end up scattered and tangled, appearing as crosscutting concerns in code. Aspect mining techniques automate the task of search for possible aspects in the code and falsely attribute all the crosscutting code to aspects even when these scattered concerns point to the absence of a domain abstraction. This paper discusses the application of aspect mining in the presence crosscutting code originating from the absence of aspects and OOP abstractions. A roadmap of a possible solution is provided to distinguish these two types of code scattering.", "num_citations": "4\n", "authors": ["54"]}
{"title": "Being a long-living software mayor\u0393\u00c7\u00f6the simcity metaphor to explain the challenges behind software evolution\n", "abstract": " When explaining the true dynamics of legacy systems, we are often short of good metaphors that provoke on the audience the correct understanding of the situation. While war stories are entertaining and fun, the audience often summarizing them as that the original developers were not good and that they would not do the same mistakes. Sometimes managers miss the point that a software system is a living organism for which caretakers are important and that such a system can simply die. We propose to use the SimCity game as a metaphor to explain the challenges of maintaining or making a system evolves.", "num_citations": "4\n", "authors": ["54"]}
{"title": "Mise en symbiose des traits et des classboxes. Application \u251c\u00e1 l expression des collaborations.\n", "abstract": " The trait model is complementary to class inheritance and allows collections of methods to be reused by several classes. The classbox model allows a collection of classes to be locally extended with variables and/or methods addition. This paper describes a symbiosis of these two models: classes can be locally extended by using a trait. It is illustrated by an efficient implementation of the collaboration model where a collaboration is represented by aa classbox and a role by a trait.R\u251c\u00ebSUM\u251c\u00eb. Le mod\u251c\u00bfle des traits propose un compl\u251c\u2310ment \u251c\u00e1 l\u0393\u00c7\u00d6h\u251c\u2310ritage des classes permettant la r\u251c\u2310utilisation d\u0393\u00c7\u00d6une collection de m\u251c\u2310thodes par diff\u251c\u2310rentes classes. Le mod\u251c\u00bfle des classboxes permet l\u0393\u00c7\u00d6extension locale d\u0393\u00c7\u00d6une collection de classes par l\u0393\u00c7\u00d6ajout de variables et/ou de m\u251c\u2310thodes d\u0393\u00c7\u00d6instance. Cet article pr\u251c\u2310sente une symbiose de ces deux mod\u251c\u00bfles: permettre l\u0393\u00c7\u00d6extension locale d\u0393\u00c7\u00d6une classe par l\u0393\u00c7\u00d6utilisation d\u0393\u00c7\u00d6un trait et au del\u251c\u00e1, proposer une r\u251c\u2310alisation du mod\u251c\u00bfle des collaborations pour lequel une collaboration est assimil\u251c\u2310e \u251c\u00e1 un classbox et un r\u251c\u2524le \u251c\u00e1 un trait.", "num_citations": "4\n", "authors": ["54"]}
{"title": "Learning Programming in Squeak\n", "abstract": " \u0393\u00f9\u00aa Add Bot. Add a new robot in the current area. Once this button pressed the user is asked to give a name for the newly created bot. This name is also used as a variable to send messages to the robot using a robot Controller (see Figure 1.8). A robot appears on the starting place (the red tile) of the board.", "num_citations": "4\n", "authors": ["54"]}
{"title": "SUnit explained\n", "abstract": " SUnit is a minimal yet powerful framework that supports the creation of tests. SUnit is the mother of unit test frameworks. SUnit was developed originally by Kent Beck and extended by Joseph Pelrine and others over several iterations to take into account the notion of resources that we will illustrate later. The interest in SUnit is not limited to Smalltalk or Squeak. Indeed, legions of developers understood the power of unit testing and now versions of SUnit exist in nearly any language including Java, Python, Perl, Oracle and many others [4]. The current version of SUnit is 3.1. The official web site of SUnit is< http://sunit. sourceforge. net/>.Testing and building test suites is not new and everybody knows that tests are a good way to catch errors. eXtreme Programming, by putting testing in the core of its methodology, is shedding a new light on testing, an often disliked discipline. The Smalltalk community has a long tradition of testing due to the incremental development supported by its programming environment. However, once you write tests in a workspace or as example methods there is no easy way to keep track of them and to automatically run them and tests that you cannot automatically run are of little interests. Moreover, having examples often does not inform the reader of expected results, since much of the logic is left unspecified. SUnit is interesting because it allows you to structure tests, describe the context of tests and to run them automatically. In less than two minutes you can write tests using SUnit instead of writing small code snippets and get all the advantage of stored and automatically executable tests.", "num_citations": "4\n", "authors": ["54"]}
{"title": "'Interview during Demo': a Sample Reverse Engineering Pattern\n", "abstract": " Since object-oriented programming is usually associated with iterative development, reverse engineering must be considered an essential facet of the object-oriented paradigm. This paper introduces a reverse engineering pattern language, which explains how to reverse engineer an object-oriented software system and includes a sample of the pattern \u0393\u00c7\u00a3 Interview During Demo\u0393\u00c7\u00a5, telling how one might obtain an initial guess for system scenario\u0393\u00c7\u00d6s.", "num_citations": "4\n", "authors": ["54"]}
{"title": "Supporting evolution recovery: a query-based approach\n", "abstract": " As software industry is shifting its focus from monolithic application development towards the use of frameworks and system families because of the higher reusability, the understanding of the evolution of a software system has grown in importance. The major problem which in this context is the management of the huge quantity of information in a meaningful way. We are currently exploring recovery of evolution information by means of queries over several versions of a system. This paper describes our approach and focuses on the advantages and drawbacks, as well as our future work in the area of software evolution.", "num_citations": "4\n", "authors": ["54"]}
{"title": "NewWave: Workflow engine\n", "abstract": " An ever-increasing demand for information systems in the last few decades brought many new opportunities but also presented new challenges for companies in the landscape of doing business globally. In these terms, software systems need to adapt almost instantaneously to new requirements, opportunities, and customer expectations. Process-aware systems have become integral part in business information system solutions, finding their place at different locations. This paper presents a workflow engine - NewWave, created with the goal to enable an extensible workflow management system, to facilitate easy specification and implementation of application business logic with focus on simplicity and immediate feedback. Through seamless integration with Pharo applications, libraries, tools, and leveraging Pharo's live environment, the NewWave enables users to create dynamically adaptable process models to\u252c\u00e1\u0393\u00c7\u00aa", "num_citations": "3\n", "authors": ["54"]}
{"title": "An interdisciplinary model for graphical representation\n", "abstract": " The paper questions whether data-driven and problem-driven models are sufficient for a software to automatically represent a meaningful graphical representation of scientific findings. The paper presents descriptive and prescriptive case studies to understand the benefits and the shortcomings of existing models that aim to provide graphical representations of data-sets. First, the paper considers data-sets coming from the field of software metrics and shows that existing models can provide the expected outcomes for descriptive scientific studies. Second, the paper presents data-sets coming from the field of human mobility and sustainable development, and shows that a more comprehensive model is needed in the case of prescriptive scientific fields requiring interdisciplinary research. Finally, an interdisciplinary problem-driven model is proposed to guide the software users, and specifically scientists, to\u252c\u00e1\u0393\u00c7\u00aa", "num_citations": "3\n", "authors": ["54"]}
{"title": "Preserving instance state during refactorings in live environments\n", "abstract": " An important activity of software evolution consists in applying refactorings to enhance the quality of the code without changing its behaviour. Having a proper refactoring tool is a must-to in any professional development environment. In addition, live programming allows faster development than the usual edit-compile-debug process. During live programming sessions, the developer can directly manipulate instances and modify the state of the running program. However, when a complex refactoring is performed, instances may be corrupted (i.e., their state is lost). For example, when pushing an instance variable to a superclass there is a moment where the superclass does not have yet acquired the new instance variable and the subclass does not have it any more. It means that the value assigned to this instance variable in existing instances is lost after the refactoring. This problem is not anecdotal since 36% of the\u252c\u00e1\u0393\u00c7\u00aa", "num_citations": "3\n", "authors": ["54"]}
{"title": "Sindarin: A versatile scripting api for the pharo debugger\n", "abstract": " Debugging is one of the most important and time consuming activities in software maintenance, yet mainstream debuggers are not well-adapted to several debugging scenarios. This has led to the research of new techniques covering specific families of complex bugs. Notably, recent research proposes to empower developers with scripting DSLs, plugin-based and moldable debuggers. However, these solutions are tailored to specific use-cases, or too costly for one-time-use scenarios. In this paper we argue that exposing a debugging scripting interface in mainstream debuggers helps in solving many challenging debugging scenarios. For this purpose, we present Sindarin, a scripting API that eases the expression and automation of different strategies developers pursue during their debugging sessions. Sindarin provides a GDB-like API, augmented with AST-bytecode-source code mappings and object-centric\u252c\u00e1\u0393\u00c7\u00aa", "num_citations": "3\n", "authors": ["54"]}
{"title": "Ptm: State-aware transactional live programming\n", "abstract": " Live programming environments, such as Pharo, allow developers to modify the code and application state while the application is running. This allows a faster development cycle compared with the edit-compile-debug process. Pharo implements simple yet powerful mechanisms to migrate the application state after each change. It allows developers to modify both methods and classes. However, modifying classes with existing instances could lead to an inconsistent application state, because eg, new instance variables are left uninitialized or with obsolete state. As these modifications are applied while the live application is running, a na\u251c\u00bbve development session may break the application. This requires special care from the developer (ie, staging, sequencing, and doing intermediate changes) to keep the coherence of application state. We propose a novel tool (PTm) that allows the developer to scope her changes isolating them from the running application. For this, PTm creates an alternative environment with all the classes, methods and instances that are modified. The developer uses this environment to execute her code isolated from the running application, to validate it without affecting the running environment. Finally, the developer decides to safely discard her changes or to apply them atomically in the running application.", "num_citations": "3\n", "authors": ["54"]}
{"title": "Smacc: a Compiler-Compiler\n", "abstract": " Note that there is another version of SmaCC that John Brant ported later on to github (https://github. com/j-brant/SmaCC). It is now also part of Moose http://moosetechnology. com. The difference between them is that the Moose version uses different tools to load the parser and scanner. In the future, we hope that these versions will be unified.", "num_citations": "3\n", "authors": ["54"]}
{"title": "Access control to reflection with object ownership\n", "abstract": " Reflection is a powerful programming language feature that enables language extensions, generic code, dynamic analyses, development tools, etc. However, uncontrolled reflection breaks object encapsulation and considerably increases the attack surface of programs e.g., malicious libraries can use reflection to attack their client applications. To bring reflection and object encapsulation back together, we use dynamic object ownership to design an access control policy to reflective operations. This policy grants objects full reflective power over the objects they own but limited reflective power over other objects. Code is still able to use advanced reflective operations but reflection cannot be used as an attack vector anymore.", "num_citations": "3\n", "authors": ["54"]}
{"title": "Code transformation by direct transformation of asts\n", "abstract": " Software evolves to be adapted to the environment, due to bugs, new features and design changes. Code transformations can be done manually, but that is a tedious and error-prone task. Therefore automated tools are used to assist developers in this maintenance operation.", "num_citations": "3\n", "authors": ["54"]}
{"title": "Reifying the reflectogram: Towards explicit control for implicit reflection\n", "abstract": " Reflective facilities in OO languages are used both for implementing language extensions (such as AOP frameworks) and for supporting new programming tools and methodologies (such as object-centric debugging and message-based profiling). Yet controlling the run-time behavior of these reflective facilities introduces several challenges, such as computational overhead, the possibility of metarecursion and an unclean separation of concerns between base and meta-level. In this paper we present five dimensions of meta-level control from related literature that try to remedy these problems. These dimensions are namely: temporal and spatial control, placement control, level control and identity control. We argue that the reification of the descriptive notion of the reflectogram, can unify the control of meta-level execution in all these five dimensions. We present a model for the reification of the reflectogram and\u252c\u00e1\u0393\u00c7\u00aa", "num_citations": "3\n", "authors": ["54"]}
{"title": "An extensible constraint-based type inference algorithm for object-oriented dynamic languages supporting blocks and generic types\n", "abstract": " Dynamically typed languages promote flexibility and agile programming. Still, their lack of type information hampers program understanding and limits the possibilities of programming tools such as automatic refactorings, automated testing framework, and program navigation. In this paper we present an extensible constraint-based type inference algorithm for object-oriented dynamic languages, focused on providing type information which is useful for programming tools. The algorithm is able to infer types for small industrial-like programs, including advanced features like blocks and generic types. Although it is still an early version, its highly extensible and configurable structure make our solution a useful test bench for further investigation.", "num_citations": "3\n", "authors": ["54"]}
{"title": "Waterfall: Primitives generation on the fly\n", "abstract": " Modern languages are typically supported by managed runtimes (Virtual Machines). Since VMs have to deal with many concepts such as memory management, abstract execution model and scheduling, they tend to be very complex. Additionally, VMs have to meet strong performance requirements. This demand of performance is one of the main reasons why many VMs are built statically. Thus, design decisions are frozen at compile time preventing changes at runtime. One clear example is the impossibility to dynamically adapt or change primitives of the VM once it has been compiled. In this work we present a toolchain that allows for altering and configuring components such as primitives and plug-ins at runtime. The main contribution is Waterfall, a dynamic and reflective translator from Slang, a restricted subset of Smalltalk, to native code. Waterfall generates primitives on demand and executes them on the fly. We validate our approach by implementing dynamic primitive modification and runtime customization of VM plug-ins.", "num_citations": "3\n", "authors": ["54"]}
{"title": "Handling exceptions\n", "abstract": " Modern programming languages, including Smalltalk offer a dedicated exception-handling mechanism that greatly simplifies the way in which exceptional situations are signaled and handled. Before the development of the ANSI Smalltalk standard in 1996, several exception handling mechanisms existed, mostly incompatible with each other. Pharo\u0393\u00c7\u00d6s exception handling follows the ANSI standard, with some embellishments; we present it in this chapter from a user perspective.The basic idea behind exception handling is that client code does not clutter the main logic flow with checks for error codes, but specifies instead an exception handler to \u0393\u00c7\u00a3catch\u0393\u00c7\u00a5 exceptions. When something goes wrong, instead of returning an error code, the method that detects the exceptional situation interrupts the main flow of execution by signaling an exception. This does", "num_citations": "3\n", "authors": ["54"]}
{"title": "Semantics and security issues in javascript\n", "abstract": " There is a plethora of research articles describing the deep semantics of JavaScript. Nevertheless, such articles are often difficult to grasp for readers not familiar with formal semantics. In this report, we propose a digest of the semantics of JavaScript centered around security concerns. This document proposes an overview of the JavaScript language and the misleading semantic points in its design. The first part of the document describes the main characteristics of the language itself. The second part presents how those characteristics can lead to problems. It finishes by showing some coding patterns to avoid certain traps and presents some ECMAScript 5 new features.", "num_citations": "3\n", "authors": ["54"]}
{"title": "Bootstrapping a smalltalk\n", "abstract": " Smalltalk is a reflective system. It means that it is defined in itself in a causally connected way. Traditionally, Smalltalk systems evolved by modifying and cloning what is called an image (a chunk of memory containing all the objects at a given point in time). During the evolution of the system, objects representing it are modified. However, such an image modification and cloning poses several problems: (1) There is no operational machine-executable algorithm that allows one to build a system from scratch. A system object may be modified but it may be difficult to reproduce its exact state before the changes. Therefore it is difficult to get a reproducible process. (2) As a consequence, certain classes may not have been initialized since years. (3) Finally, since the system acts as a living system, it is not simple to evolve the kernel for introducing new abstractions without performing some kind of brain surgery on oneself. There is a need to have a step by step process to build Smalltalk kernels from scratch. In this paper, after an analysis of past and current practices to mutate or generate kernels, we describe a kernel bootstrap process step-by-step. First the illusion of the existence of a kernel is created via stubs objects. Second the classes and meta-classes hierarchy are generated. Code is compiled and finally information needed by the virtual machine and execution are generated and installed.", "num_citations": "3\n", "authors": ["54"]}
{"title": "Efficient Proxies in Smalltalk\n", "abstract": " A proxy object is a surrogate or placeholder that controls access to another target object. Proxy objects are a widely used solution for different scenarios such as remote method invocation, future objects, behavioral reflection, object databases, inter-languages communications and bindings, access control, lazy or parallel evaluation, security, among others. Most proxy implementations support proxies for regular objects but they are unable to create proxies for classes or methods. Proxies can be complex to install, have a significant overhead, be limited to certain type of classes, etc. Moreover, most proxy implementations are not stratified at all and there is no separation between proxies and handlers. In this paper, we present Ghost, a uniform, light-weight and stratified general purpose proxy model and its Smalltalk implementation.Ghost supports proxies for classes or methods. When a proxy takes the place of a class it intercepts both, messages received by the class and lookup of methods for messages received by instances. Similarly, if a proxy takes the place of a method, then the method execution is intercepted too.", "num_citations": "3\n", "authors": ["54"]}
{"title": "Cycles Assessment with CycleTable\n", "abstract": " Understanding the package organization of a large application is a challenging and critical task since it allows developers to better maintain the application. Several approaches show in different ways software structure. Fewer show modularity issues at the package level. We focus on modularity issues due to cyclic dependencies between packages. Most approaches detect Strongly Connected Components (SCC) in a graph of dependencies. However, SCC detection does not allow one to easily understand and remove cyclic dependencies in legacy software displaying dozens of packages all dependent on each other.This paper presents i) a heuristic to focus on shared dependencies between cycles in SCC and ii) CycleTable, a visualization showing interesting dependencies to efficiently remove cycles in the system. This visualization is completed with enriched cells, small views displaying the internals of a dependency [LDDB09]. We performed i) a case study which shows that the shared dependency heuristic highlights dependencies to be removed, and ii) a comparative study which shows that CycleTable is useful for the task of breaking cycles in a SCC compared to a normal node-link representation.", "num_citations": "3\n", "authors": ["54"]}
{"title": "Beeeye: A framework for constructing architectural views\n", "abstract": " We believe that offering means for defining and building multiple architectural views of a given system enhances the understanding of the system as a whole. BeeEye is a generic and open framework for architecture reconstruction, which allows to construct architectural views using different (possibly combined) viewpoints and perspectives. The framework follows a model-driven approach where viewpoints and views (abstract and concrete) are models that are defined, constructed and used.", "num_citations": "3\n", "authors": ["54"]}
{"title": "Practices in the Squale Quality Model (Squale Deliverable 1.3)\n", "abstract": " This document presents the Squale Software Quality Model as defined by Qualixo. It first reviews existing quality models and presents the Squale model with its particularity, namely a practice layer. Then it reviews in details an instance of this Squale Model with its Factors, Criteria and Practices, giving precise definitions and description1. Finally, it discusses possible future enhancements of this model like new practices or its agreement with the program life-cycle and the change of needs during this life cycle.", "num_citations": "3\n", "authors": ["54"]}
{"title": "Introduction to the smalltalk special issue\n", "abstract": " Editorial: Introduction to the Smalltalk special issue: Computer Languages, Systems and Structures: Vol 32, No 2-3 ACM Digital Library home ACM home Google, Inc. (search) Advanced Search Browse About Sign in Register Advanced Search Journals Magazines Proceedings Books SIGs Conferences People More Search ACM Digital Library SearchSearch Advanced Search Computer Languages, Systems and Structures Periodical Home Latest Issue Archive Authors Affiliations Award Winners More HomeBrowse by TitlePeriodicalsComputer Languages, Systems and StructuresVol. , No. -3Editorial: Introduction to the Smalltalk special issue article Editorial: Introduction to the Smalltalk special issue Share on Authors: Serge Stinckwich Universite de Caen, GREYC, Campus Cote de Nacre, boulevard du Marechal Juin, BP 5186, 14032 Caen, France. Universite de Caen, GREYC, Campus Cote de Nacre, boulevard , , :\u0393\u00c7\u00aa", "num_citations": "3\n", "authors": ["54"]}
{"title": "Design and Implementation of a Backward-In-Time Debugger\n", "abstract": " Design and Implementation of a Backward-In-Time Debugger Page 1 \u252c\u2310 Marcus Denker Design and Implementation of a Backward-In-Time Debugger Christoph Hofer Marcus Denker Stephane Ducasse Page 2 \u252c\u2310 Marcus Denker Roadmap > Problem > Unstuck: A new Debugger for Squeak > Implementation > Lessons Learned > Future work Page 3 \u252c\u2310 Marcus Denker Problem > Debugger: Snapshot of state at time of error > Cause for errors is in the past \u0393\u00c7\u00f6 Who assigned *that* value? > very incomplete history available \u0393\u00c7\u00f6 guess were to set breakpoint, rerun Page 4 \u252c\u2310 Marcus Denker Example Foo>>initialize var1 := 0. var2 := ''. Foo>>start self beforeBar. self bar. self moreBar. Foo>>beforeBar var1 = 0 ifTrue: [ var2 := nil.] Foo>>bar ...... Foo>>moreBar var2 size > 0 ifTrue:[ ^var2 at: 1]. ^'' Page 5 \u252c\u2310 Marcus Denker Stack Trace > Squeak Debugger > Shows stack trace \u0393\u00c7\u00f6 methods not returned \u0393\u00c7\u00f6 old state lost Page 6 \u252c\u2310 > > : \u0393\u00c7\u00aa", "num_citations": "3\n", "authors": ["54"]}
{"title": "Applying RMA for Scheduling Field Device Components\n", "abstract": " PECOS is a collaborative project between industrial and research partners that seeks to enable component-based technology for a class of embedded systems known as \u0393\u00c7\u00a3field devices\u0393\u00c7\u00a5. Results so far include a component model for field devices and a composition language for specifying connections between software components. Here we investigate the application of Rate Monotonic Analysis (RMA) to the problem of generating real-time schedules for compositions of field device components.", "num_citations": "3\n", "authors": ["54"]}
{"title": "Iterative recovery of collaborations and roles in dynamically typed objectoriented languages\n", "abstract": " Modelling object-oriented applications using collaborations and roles is well accepted. Collaboration-based or role-based designs decompose an application into tasks performed by a subset of the applications\u0393\u00c7\u00d6 classes. Collaborations provide a larger unit of understanding and reuse than classes, and can be an important aid in the maintenance and evolution of the software. The extraction of roles and collaborations is therefore an important issue in design recovery. Collaborations and roles are, however, not explicitly supported at source code level. Furthermore, in dynamically typed object-oriented languages, the absence of types makes the extraction of roles from the source code difficult. In this paper we present a simple approach to support the recovery of roles and collaborations. We have developed a tool which uses an execution trace of a program to find meaningful collaborations and to identify the roles that classes play in these collaborations.", "num_citations": "3\n", "authors": ["54"]}
{"title": "Decomposing god classes at siemens\n", "abstract": " A group of developers at Siemens Digital Industry Division approached our team to help them restructure a large legacy system. Several problems were identified, including the presence of God classes (big classes with thousands of lines of code and hundred of methods). They had tried different approaches considering the dependencies between the classes, but none were satisfactory. Through interaction during the last three years with a lead software architect of the project, we designed a software visualization tool and an accompanying process that allows her to propose a decomposition of a God Class in a matter of one or two hours even without prior knowledge of the class (although actually implementing the decomposition in the source code could take a week of work). In this paper, we present the process that was formalized to decompose God Classes and the tool that was designed. We give details on the\u252c\u00e1\u0393\u00c7\u00aa", "num_citations": "2\n", "authors": ["54"]}
{"title": "Lowcode: Extending Pharo with C Types to Improve Performance\n", "abstract": " The highly dynamic nature of Smalltalk provides a high degree of flexibility, but at the expense of performance. On the other hand, static system programming languages such as C are really fast, but less flexible and harder to use than Smalltalk. Our hypothesis is that by mixing the concepts of these two worlds in a single programming environment, we are able to have improved performance and a high level of flexibility at the same time.", "num_citations": "2\n", "authors": ["54"]}
{"title": "Clustering technique for conceptual clusters\n", "abstract": " Clustering aims to classify elements into groups called classes or clusters. Clustering is used in reverse-engineering to help to understand legacy software. It is also a technic used in re-engineering to propose gatherings of software entities to engineers who can then accept them or not. This paper presents a Pharo implementation of an iterative and semi-automatic method for clustering. Our method proposes, to an end-user, clusters that are based on domain information and structural information. The method presented in this paper has been applied in an industrial project of architecture migration. We show that this method helps engineers to cluster software elements into domain concepts. The clustering gives a result of 56% of precision and 79% of recall after the automated part in a high level clustering. A deeper clustering gives a result of 51% of precision and 52% of recall.", "num_citations": "2\n", "authors": ["54"]}
{"title": "Test selection with moose in industry: Impact of granularity\n", "abstract": " Automatic testing constitutes an important part of everyday development practice. Worldline, a major IT company, is creating more and more tests to ensure the good behaviour of its applications and gain in efficiency and quality. But running all these tests may take hours. For this reason tests are not launched as often as they should and are mostly run at night. The company wishes to improve its development and testing process by giving rapid feedback to developers after a change. An interesting solution is to reduce the number of tests to run by identifying only those exercising the piece of code changed. Two main approaches are proposed in the literature: static and dynamic. The static approach creates a model of the source code and explores it to find links between changed methods and tests. The dynamic approach records invocations of methods during the execution of test scenarios. Moose, a tool allowing to\u252c\u00e1\u0393\u00c7\u00aa", "num_citations": "2\n", "authors": ["54"]}
{"title": "Telescope: a high-level model to build dynamic visualizations\n", "abstract": " In this paper, we introduce Telescope, a high-level abstract model to create powerful, dynamic visualizations.", "num_citations": "2\n", "authors": ["54"]}
{"title": "Deltaimpactfinder: Assessing semantic merge conflicts with dependency analysis\n", "abstract": " In software development, version control systems (VCS) provide branching and merging support tools. Such tools are popular among developers to concurrently change a code-base in separate lines and reconcile their changes automatically afterwards. However, two changes that are correct independently can introduce bugs when merged together. We call semantic merge conflicts this kind of bugs.", "num_citations": "2\n", "authors": ["54"]}
{"title": "Zero-Overhead Metaprogramming\n", "abstract": " Runtime metaprogramming enables many useful applications and is often a convenient solution to solve problems in a generic way, which makes it widely used in frameworks, middleware, and domain-specific languages. However, powerful metaobject protocols are rarely supported and even common concepts such as reflective method invocation or dynamic proxies are not optimized. Solutions proposed in literature either restrict the metaprogramming capabilities or require application or library developers to apply performance improving techniques. For overhead-free runtime metaprogramming, we demonstrate that dispatch chains, a generalized form of polymorphic inline caches common to self-optimizing interpreters, are a simple optimization at the language-implementation level. Our evaluation with self-optimizing interpreters shows that unrestricted metaobject protocols can be realized for the first time without runtime overhead, and that this optimization is applicable for just-in-time compilation of interpreters based on meta-tracing as well as partial evaluation. In this context, we also demonstrate that optimizing common reflective operations can lead to significant performance improvements for existing applications.", "num_citations": "2\n", "authors": ["54"]}
{"title": "Extended results of Tornado: A Run-Fail-Grow approach for Dynamic Application Tayloring\n", "abstract": " Producing a small deployment version of an application is a challenge because static abstractions such as packages cannot anticipate the use of their parts. As such, an application often occupies more memory than ac- tually needed. To solve this problem we propose Tornado, a technique to dynamically tailor applications to only embed code (classes and methods) they use. Tornado uses a run-fail-grow approach to prepare an application for deployment. It launches minimal version of an application and installs a minimal set of statements that will start the user's application. This ap- plication is run and these statements are executed. When the application fails because there are classes or methods missing, the necessary code is installed. The application is executed until it reaches a stable point, allow- ing possibly human interaction for applications with UIs. Thus, Tornado creates minimal memory footprint versions of applications by tailoring the whole application's code, including run-time and third party libraries. We used Tornado to tailor two different applications. We succeeded to tailor a hello world application to occupy 1% of its original size. We also experimented with a Seaside web application tailoring in one case only the application's and framework's code and the whole application's code in the other case. In this latter example, we reached memory savings of about 97%. In this report we present an overview on Tornado, and we give details of the results we obtained.", "num_citations": "2\n", "authors": ["54"]}
{"title": "Safejs: Hermetic sandboxing for javascript\n", "abstract": " Isolating programs is an important mechanism to support more secure applications. Isolating program in dynamic languages such as JavaScript is even more challenging since reflective operations can circumvent simple mechanisms that could protect program parts. In this article we present SafeJS, an approach and implementation that offers isolation based on separate sandboxes and control of information exchanged between them. In SafeJS, sandboxes based on web workers do not share any data. Data exchanged between sandboxes is solely based on strings. Using different policies, this infrastructure supports the isolation of the different scripts that usually populate web pages. A foreign component cannot modify the main DOM tree in unexpected manner. Our SafeJS implementation is currently being used in an industrial setting in the context of the Resilience FUI 12 project.", "num_citations": "2\n", "authors": ["54"]}
{"title": "Mod\u251c\u00bfles de mesure de la qualit\u251c\u2310 des logiciels\n", "abstract": " De mani\u251c\u00bfre g\u251c\u2310n\u251c\u2310rale, un logiciel de qualit\u251c\u2310 s\u0393\u00c7\u00d6 entend comme un logiciel capable de r\u251c\u2310pondre parfaitement aux attentes du client, le tout sans d\u251c\u2310faut d\u0393\u00c7\u00d6ex\u251c\u2310cution. Ainsi, on d\u251c\u2310termine la qualit\u251c\u2310 logicielle comme un ensemble de r\u251c\u00bfgles et de principes \u251c\u00e1 suivre au cours du d\u251c\u2310veloppement d\u0393\u00c7\u00d6une application afin de concevoir un logiciel r\u251c\u2310pondant \u251c\u00e1 ces attentes 1 [ABDT04]. La NASA par exemple, a d\u251c\u2310termin\u251c\u2310 un ensemble de proc\u251c\u2310dures, d\u0393\u00c7\u00d6instructions de travail et de r\u251c\u00bfgles pour s\u0393\u00c7\u00d6 assurer que chaque \u251c\u2310tape du d\u251c\u2310veloppement s\u0393\u00c7\u00d6 effectue de mani\u251c\u00bfre ad\u251c\u2310quate 2 [EBM06]. La qualit\u251c\u2310 d\u0393\u00c7\u00d6un logiciel se refl\u251c\u00bfte non seulement dans les processus de d\u251c\u2310veloppement mais aussi dans la qualit\u251c\u2310 des \u251c\u2310l\u251c\u2310ments qui le constituent, la documentation, la pr\u251c\u2310sence de tests..... Mesurer la qualit\u251c\u2310 d\u0393\u00c7\u00d6un logiciel consiste alors \u251c\u00e1 d\u251c\u2310terminer son ad\u251c\u2310quation par rapport aux objectifs de d\u251c\u2310part et aux standards de programmation. Il faut donc d\u251c\u2310finir pr\u251c\u2310cis\u251c\u2310ment ce que l\u0393\u00c7\u00d6application doit faire et comment elle doit le faire, tant d\u0393\u00c7\u00d6un point de vue fonctionnel que d\u0393\u00c7\u00d6un point de vue technique. Une fois ces objectifs fix\u251c\u2310s, on peut alors appliquer un ensemble de r\u251c\u00bfgles et de mesures afin de calculer la diff\u251c\u2310rence entre objectifs attendus et r\u251c\u2310alisation obtenue. Obtenir une mesure de la qualit\u251c\u2310 permet \u251c\u00e1 la fois d\u0393\u00c7\u00d6avoir une image pr\u251c\u2310cise du logiciel mesur\u251c\u2310 mais aussi de d\u251c\u2310terminer le comportement de celui-ci dans le temps: quels sont les risques de bogues, les \u251c\u2310ventuelles failles s\u251c\u2310curitaires, les difficult\u251c\u2310s de maintenance, les freins \u251c\u00e1 l\u0393\u00c7\u00d6\u251c\u2310volution, la viabilit\u251c\u2310 \u251c\u00e1 long terme, etc. Un des objectifs de la mesure de la qualit\u251c\u2310 logicielle consiste \u251c\u00e1 sensibiliser les \u251c\u2310quipes de d\u251c\u2310veloppement sur leur\u252c\u00e1\u0393\u00c7\u00aa", "num_citations": "2\n", "authors": ["54"]}
{"title": "Construire un service Rest avec Pharo et Seaside-Rest\n", "abstract": " Construire un service Rest avec Pharo et Seaside-Rest Toggle navigation English fran\u251c\u00baais Aide | Contact | \u251c\u00c7 Propos | Ouvrir une session Portail HAL | Pages Pro Chercheurs EN / FR Toggle navigation Voir le document Accueil de LillOA Liste des unit\u251c\u2310s Centre de Recherche en Informatique, Signal et Automatique de Lille (CRIStAL) - UMR 9189 Voir le document Accueil de LillOA Liste des unit\u251c\u2310s Centre de Recherche en Informatique, Signal et Automatique de Lille (CRIStAL) - UMR 9189 Voir le document Construire un service Rest avec Pharo et ... BibTeX CSV Excel RIS Type de document : Compte-rendu et recension critique d'ouvrage URL permanente : http://hdl.handle.net/20.500./27254 Titre : Construire un service Rest avec Pharo et Seaside-Rest Auteur(s) : Auverlot, Olivier [Auteur] Laboratoire d'Informatique Fondamentale de Lille [LIFL] Ducasse, St\u251c\u2310phane [Auteur] Analyses and Languages Constructs for -[] : -\u0393\u00c7\u00aa", "num_citations": "2\n", "authors": ["54"]}
{"title": "BLOC: a Trait-Based Collections Library\u0393\u00c7\u00f4a Preliminary Experience Report\n", "abstract": " A trait is a programming construct which provides code reusability. Traits are groups of methods that can be reused orthogonally from inheritance. Traits offer a solution to the problems of multiple inheritance by providing a behavior-centric modularity. Since traits offer an alternative to traditional inheritance-based code reuse, a couple of questions arise. For example, what is a good granularity for a Trait enabling reuse as well as plug ease? How much reuse can we expect on large existing inheritance-based hierarchies? In this paper we take as case study the Smalltalk Collection hierarchy and we start rewriting it from scratch using traits from the beginning. We show how such library can be built using traits and we report such a preliminary experience. Since the Collection library is large, we focused and built the main classes of the library with Traits and report problems we encountered and how we solved them. Results of this experience are positive and show that we can build new collections based on the traits used to define the new library kernel.", "num_citations": "2\n", "authors": ["54"]}
{"title": "The squale model\n", "abstract": " ISO 9126 promotes a three-level model of quality (factors, criteria, and metrics) which allows one to assess quality at the top level of factors and criteria. However, it is difficult to use this model as a tool to increase software quality. In the Squale model, we add practices as an intermediate level between metrics and criteria. Practices abstract away from raw information (metrics, tool reports, audits) and provide technical guidelines to be respected. Moreover, practice marks are adjusted using formulae to suit company development habits or exigences: for example bad marks are stressed to point to places which need more attention. The Squale model has been developed and validated over the last couple of years in an industrial setting with Air France-KLM and PSA Peugeot-Citro\u251c\u00bdn.", "num_citations": "2\n", "authors": ["54"]}
{"title": "Tackling software navigation issues of the smalltalk ide\n", "abstract": " The IDE used in most Smalltalk dialects, including Pharo, Squeak and Cincom Smalltalk, did not evolve significantly over the last years, if not to say decades. For other languages, for instance Java, the available IDEs made tremendous progress as Eclipse and Net-Beans illustrate. While the Smalltalk IDE served as an exemplar for many years, other IDEs caught up or even overtook the erstwhile leader in terms of feature-richness, usability and code navigation facilities. In this paper we first analyze the difficulty of software navigation in the Smalltalk IDE and second illustrate with concrete examples the features we added to the Smalltalk IDE to fill the gap to modern IDEs and to provide novel, improved means to navigate source space. We show that thanks to the agility and dynamics of Smalltalk, we are able to extend and enhance with reasonable effort the Smalltalk IDE to better support software navigation, program\u252c\u00e1\u0393\u00c7\u00aa", "num_citations": "2\n", "authors": ["54"]}
{"title": "Putting traits in perspective\n", "abstract": " Traits have been proposed as a mechanism to compose and share behavioral units between distinct class hierarchies. Several versions have been developed and they have been used to build complex libraries. This keynote puts in perspective the current versions and stress their relationships and limits.", "num_citations": "2\n", "authors": ["54"]}
{"title": "Surgical Information to Detect Design Problems with MOOSE.\n", "abstract": " The quality attributes, such as understandability and modularity manifest their importance in the later part of the software life where a lot of resources are required to maintain or reuse software whose quality has been marred by the urgencies of time to market. In this position paper, we present and analyze an existing system meant to be reused on various product lines. We intend to use the MOOSE framework to precisely identify the needs of a reengineer in terms of code-smells, visualization and metrics. In this position paper, we discuss some of the limitations of the existing software system and inadequacy of existing toolkits to automate the task of detection of these limitations. We intend to discuss the appropriateness of MOOSE as a remedy to these deficiencies.", "num_citations": "2\n", "authors": ["54"]}
{"title": "2nd workshop on object-oriented language engineering for the post-java era: back to dynamicity\n", "abstract": " This report covers the activities of the 2nd workshop on \u0393\u00c7\u00a3Object-Oriented Language Engineering for the Post-Java Era\u0393\u00c7\u00a5. We describe the motivation that led to the organisation of a second edition of the workshop. Relevant organisational aspects are mentioned. The main part of the report consists of a summary of Dave Thomas\u0393\u00c7\u00d6s invited talk, and a recount of the presentations by the authors of position papers. Comments given along the way by the participants are included. Finally, some pointers to related work and events are given.", "num_citations": "2\n", "authors": ["54"]}
{"title": "Object Encapsulation for Dynamically Typed Languages\n", "abstract": " Encapsulation mechanisms in object-oriented languages have traditionally been based on static type systems. As a consequence, dynamically-typed languages have only limited support for encapsulation. This is surprising, considering that encapsulation is one of the most fundamental and important concepts behind object-oriented programming and that it is essential for writing programs that are maintainable and reliable, and that remain robust as they evolve.In this paper we describe the problems that are caused by insufficient encapsulation mechanisms and then present a simple and uniform approach that solves these problems by bringing state of the art encapsulation features to dynamically typed languages. We provide a detailed discussion of our design rationales and compare them and their consequences to the encapsulation approaches used for statically typed languages.", "num_citations": "2\n", "authors": ["54"]}
{"title": "Object-oriented language engineering for the post-java era\n", "abstract": " This report covers the activities of the workshop on \u0393\u00c7\u00a3Object-Oriented Language Engineering for the Post-Java Era\u0393\u00c7\u00a5. We describe the context that led to submission of the workshop proposal, the organisation of the workshop and the results presented at the workshop.", "num_citations": "2\n", "authors": ["54"]}
{"title": "Adding Dynamic Interfaces to Smalltalk\n", "abstract": " The term Interface is central to object-oriented methodologies [Reen96] and object foundation [Abad96], and has been recently popularised by COM and Java. Smalltalk had interfaces implicitly from its beginning. However, since Smalltalk does not have interfaces as first-class objects, they cannot be conversed with, referred to, or reflected upon. Because interfaces has proven to be extremely useful in supporting program understanding and facilitating the transition from a conceptual design to a concrete implementation, the lack of explicit interfaces in Smalltalk deprives Smalltalk developers of such an important and useful tool.Since a fundamental feature of Smalltalk is that just about everything in the language is an implementation feature, explicit interfaces can be added to Smalltalk using Smalltalk itself with relative ease. However, since Smalltalk is not merely a language but a live, dynamic environment, adding static interfaces would lead to an ad-hoc solution. Moreover, because Smalltalk is also an environment, every solution which extends Smalltalk with interfaces has to integrate them into the Smalltalk IDE as well. On top of", "num_citations": "2\n", "authors": ["54"]}
{"title": "Applying experiences with declarative codifications of software architectures on cod\n", "abstract": " This position paper presents some preliminary work we made for applying declaractive component oriented design in the context of embedded devices. We quickly describes COMES the model we develop and present how logic rules can be used to describe architectures.", "num_citations": "2\n", "authors": ["54"]}
{"title": "Reverse Engineering based on Metrics and Program Visualization\n", "abstract": " BORIS Deutsch English Fran\u251c\u00baais Login BORIS Bern Open Repository and Information System University of Bern Home Statistics Reverse Engineering based on Metrics and Program Visualization Ducasse, St\u251c\u2310phane; Lanza, Michele; Demeyer, Serge (1999). Reverse Engineering based on Metrics and Program Visualization. Lecture notes in computer science(1743), pp. 168-169. Springer [img] Text Seiten aus 10.1007_3-540-46589-8.pdf - Published Version Restricted to registered users only Available under License Publisher holds Copyright. Download (116kB) Item Type: Conference or Workshop Item (Speech) Division/Institute: 08 Faculty of Science > Institute of Computer Science (INF) 08 Faculty of Science > Institute of Computer Science (INF) > Software Composition Group (SCG) UniBE Contributor: Ducasse, Stephane and Lanza, Michele Subjects: 000 Computer science, knowledge & systems 500 Science > \u0393\u00c7\u00aa", "num_citations": "2\n", "authors": ["54"]}
{"title": "Two Reengineering Patterns: Eliminating Type Checking\n", "abstract": " A reengineering pattern describes how to go from an existing legacy solution to a new refactored solution. In this paper we discuss the role of reengineering patterns and contrast them with design patterns and antipatterns. We then highlight the structure of a reengineering pattern and present two simple, related patterns for type-check elimination.", "num_citations": "2\n", "authors": ["54"]}
{"title": "Architectural Extraction in Reverse Engineering by Prototyping: An Experiment\n", "abstract": " In this workshop proposal we present a prototype approach to help the extraction of architectural information in the re-engineering process. Commonly, the re-engineering life-cycle has been de ned as a succession of the following tasks: analysis of requirements, model capture (understanding the sys tem), problem detection, problem analysis, reorganisation and change propagation [1]. We have evaluated the bene t of a prototyping approach with a focus on model capture. Although prototyping is a known approach to evaluate the application feasibility, costs, comparison and validation of choices, we focus in this paper on the aspects of prototyping that are helpful for re-engineering. In the following sections we rst present the problem, and afterwards we present our proposal to solve this problem: a pattern describing how to use prototyping to extract architectural information from a legacy system.", "num_citations": "2\n", "authors": ["54"]}
{"title": "Concurrent Programming in Pharo\n", "abstract": " This book describes the low-level abstractions available in Pharo for concur-rent programming. It explains pedagogically different aspects. Now, if youhappen to create many green threads (called Process in Pharo) we suggestthat you have a look at TaskIt. TaskIt is an extensible library to manage con-current processing at a higher-level of abstractions. You should definitivelyhave a look at it.", "num_citations": "1\n", "authors": ["54"]}
{"title": "Software Migration: A Theoretical Framework (A Grounded Theory approach on Systematic Literature Review)\n", "abstract": " Software migration has been a research subject for a long time. Major research and industrial implementations were conducted, shaping not only the techniques available nowadays, but also a good part of Software evolution jargon. To understand systematically the literature and grasp the major concepts is challenging and time-consuming. Even more, research evolves, and it does based on the assumption that many words (such as migration) have a single well-known meaning that we all share. Since since these words meanings are rarely explicit, and their usage heterogeneous, these words end up polluted with multiple and many times opposite or incompatible meanings. In our quest to understand, share and contribute in this domain, we recognize this situation as a problem. To tackle down this problem we propose a taxonomy on the sub- ject as a theoretical framework grounded on a systematic literature review. In this study we contribute a bottom-up taxonomy that links from the object of a migration to the procedure nature migration, passing by migration drivers, objectives and approaches. We contribute a classification of all our readings, and a list of research directions discovered on the process of this study.", "num_citations": "1\n", "authors": ["54"]}
{"title": "Empirical study of programming to an interface\n", "abstract": " A popular recommendation to programmers in object-oriented software is to \"program to an interface, not an implementation\" (PTI). Expected benefits include increased simplicity from abstraction, decreased dependency on implementations, and higher flexibility. Yet, interfaces must be immutable, excessive class hierarchies can be a form of complexity, and \"speculative generality\" is a known code smell. To advance the empirical knowledge of PTI, we conducted an empirical investigation that involves 126 Java projects on GitHub, aiming to measuring the decreased dependency benefits (in terms of cochange).", "num_citations": "1\n", "authors": ["54"]}
{"title": "Exposing Test Analysis Results with DrTests\n", "abstract": " Tests are getting the cornerstone of continuous development process and software evolution. Tests are the new gold. To improve test quality, a plethora of analyses is proposed such as test smells, mutation testing, test coverage. The problem is that each analysis often needs a particular way to expose its results to the developer. There is a need for an architecture supporting test running and analysis in a modular and extensible way. In this article we present an extensible plugin-based architecture to run and report test results. DrTests is a new test browser that implements such pluginbased architecture. DrTests supports the execution of rotten tests, comments to tests, coverage and profiling tests.", "num_citations": "1\n", "authors": ["54"]}
{"title": "Exposing Test Analysis Results with DrTests\n", "abstract": " Tests are getting the cornerstone of continuous development process and software evolution. Tests are the new gold. To improve test quality, a plethora of analyses is proposed such as test smells, mutation testing, test coverage. The problem is that each analysis often needs a particular way to expose its results to the developer. There is a need for an architecture supporting test running and analysis in a modular and extensible way. In this article we present an extensi-ble plugin-based architecture to run and report test results. DrTests is a new test browser that implements such plugin-based architecture. DrTests supports the execution of rotten tests, comments to tests, coverage and profiling tests.", "num_citations": "1\n", "authors": ["54"]}
{"title": "Challenges in Debugging Bootstraps of Reflective Kernels\n", "abstract": " The current explosion of embedded systems (i.e., IoT, Edge Computing) implies the need for generating tailored and customized software for these systems. Instead of using specific runtimes (e.g., MicroPython, eLua, mRuby), we advocate that bootstrapping specific language kernels is a promising higher-level approach because the process takes advantage of the generated language abstractions, easing the task for a language developer. Nevertheless, bootstrapping language kernels is still challenging because current debugging tools are not suitable for fixing the possible failures that occur during the process. In this paper, we take the Pharo bootstrap process as an example to analyse the different challenges a language developer faces. We propose a taxonomy of failures appearing during bootstrap and their causes. Based on this analysis, we identify future research directions: (1) prevention measures based on the reification of implicit virtual machine contracts, and (2) hybrid debugging tools that unify the debugging of high-level code from the bootstrapped language with low-level code from the virtual machine.", "num_citations": "1\n", "authors": ["54"]}
{"title": "Illicium A modular transpilation toolchain from Pharo to C\n", "abstract": " The Pharo programming language runs on the OpenSmalltalk-VM. This Virtual Machine (VM) is mainly written in Slang, a subset of the Smalltalk language dedicated to VM development. Slang is transpiled to C using the Slang-to-C transpiler. The generated C is then compiled to produce the VM exe-cutable binary code. Slang is a powerful dialect for generating C because it benefits from the tools of the Smalltalk environment, including a simulator that runs and debugs the VM. However, the Slang-to-C transpiler is often too permissive. For example, the Slang-to-C transpiler generates invalid C code from some Smalltalk concepts it does not support. This makes the Slang code hard to debug as the errors are caught very late during the development process, which is worsen by the loss of the mapping between the generated C code and Slang. The Slang-to-C transpiler is also hard to extend or adapt to modify part of the translation process. In this paper we present Illicium, a new modular transpila-tion toolchain based on a subset of Pharo targeting C through AST transformations. This toolchain translates the Pharo AST into a C AST to generate C code. Using ASTs as source and target artifacts enables analysis, modification and validation at different levels during the translation process. The main translator is split into smaller and replaceable translators to increase modularity. Illicium also allows the possibility to introduce new translators and to chain them together, increasing reusability. To evaluate our approach, we show with a use case how to extend the transpilation process with a translation that requires changes not considered in the original\u252c\u00e1\u0393\u00c7\u00aa", "num_citations": "1\n", "authors": ["54"]}
{"title": "Pharo with Style\n", "abstract": " Programming is a lot more than just writing algorithms or programs. Programming is all about communication. Communication with others: the other programmers that will participate to your development effort but also with yourself. Indeed finding good names is a really important task because using the right name often opens the door to new spaces where your design can bloom and expand.", "num_citations": "1\n", "authors": ["54"]}
{"title": "Rotten Green Tests A First Analysis\n", "abstract": " Unit tests are a tenant of agile programming methodologies, and are widely used to improve code quality and prevent code regression. A passing (green) test is usually taken as a robust sign that the code under test is valid. However, we have noticed that some green tests contain assertions that are never executed; these tests pass not because they assert properties that are true, but because they assert nothing at all. We call such tests Rotten Green Tests. Rotten Green Tests represent a worst case: they report that the code under test is valid, but in fact do nothing to test that validity, beyond checking that the code does not crash. We describe an approach to identify rotten green tests by combining simple static and dynamic analyses. Our approach takes into account test helper methods, inherited helpers, and trait compositions, and has been implemented in a tool called DrTest. We have applied DrTest to several test suites in Pharo 7.0, and identified many rotten tests, including some that have been \" sleeping \" in Pharo for at least 5 years.", "num_citations": "1\n", "authors": ["54"]}
{"title": "2018 IEEE 1st International Workshop on Blockchain Oriented Software Engineering (IWBOSE)\n", "abstract": " The workshop aims at gathering together researchers from the academia and from the industry to focus on the new challenges posed by the new software technology supporting the various Blockchains infrastructure. The Workshop\u0393\u00c7\u00d6s goal is to gather together practitioners and researchers to discuss on progresses on the research and on the practical usage of Blockchain technologies and smart contracts, focusing on the application and definition of software engineering principles and practices specific for such software technology, and for the technologies relying on it. Motivations for this workshop are the ever-increasing interest both in the research community and in the industry on Blockchain and smart contracts principles and applications, being the management of cryptocurrencies the most popular topic. These novelties call for specific tools, paradigms, principles, approaches and research to deal with it and for a specific Blockchain Oriented Software Engineering (BOSE)[1].The Workshop features six accepted papers, three focusing on Smart Contracts and three focusing on Bockchain and ICO (Initial Coin Offers), where security patterns in Solidity, the inspection of Smart Contracts, their velnerabilities are analized altogether with Property-Based Testing for Blockchain and extended analysis of the success factors of ICOs.", "num_citations": "1\n", "authors": ["54"]}
{"title": "Fully reflective execution environments: Virtual machines for more flexible software\n", "abstract": " VMs are complex pieces of software that implement programming language semantics in an efficient, portable, and secure way. Unfortunately, mainstream VMs provide applications with few mechanisms to alter execution semantics or memory management at run time. We argue that this limits the evolvability and maintainability of running systems for both, the application domain, e.g., to support unforeseen requirements, and the VM domain, e.g., to modify the organization of objects in memory. This work explores the idea of incorporating reflective capabilities into the VM domain and analyzes its impact in the context of software adaptation tasks. We characterize the notion of a fully reflective VM, a kind of VM that provides means for its own observability and modifiability at run time. This enables programming languages to adapt the underlying VM to changing requirements. We propose a reference architecture for\u252c\u00e1\u0393\u00c7\u00aa", "num_citations": "1\n", "authors": ["54"]}
{"title": "Scoped Extension Methods in Dynamically-Typed Languages\n", "abstract": " Context. An extension method is a method declared in a package other than the package of its host class. Thanks to extension methods, developers can adapt to their needs classes they do not own: adding methods to core classes is a typical use case. This is particularly useful for adapting software and therefore to increase reusability. Inquiry. In most dynamically-typed languages, extension methods are globally visible. Because any developer can define extension methods for any class, naming conflicts ocur: if two developers define an extension method with the same signature in the same class, only one extension method is visible and overwrites the other. Similarly, if two developers each define an extension method with the same name in a class hierarchy, one overrides the other. To avoid such \" accidental overrides \" , some dynamically-typed languages limit the visibility of an extension method to a particular scope. However, their semantics have not been fully described and compared. In addition, these solutions typically rely on a dedicated and slow method lookup algorithm to resolve conflicts at runtime. Approach. In this article, we present a formalization of the underlying models of Ruby refinements, Groovy categories, Classboxes, and Method Shelters that are scoping extension method solutions in dynamically-typed languages. Knowledge. Our formal framework allows us to objectively compare and analyze the shortcomings of the studied solutions and other different approaches such as MultiJava. In addition, language designers can use our formal framework to determine which mechanism has less risk of \" accidental overrides \"\u252c\u00e1\u0393\u00c7\u00aa", "num_citations": "1\n", "authors": ["54"]}
{"title": "Turning function calls into animations\n", "abstract": " Animated transitions are an integral part of modern interaction frameworks. With the increasing number of animation scenarios, they have grown in range of animatable features. Yet not all transitions can be smoothed: programming systems limit the flexibility of frameworks for animating new things, and force them to expose low-level details to programmers. We present an ongoing work to provide system-wide animation of objects, by introducing a delay operator. This operator turns setter function calls into animations. It offers a coherent way to express animations across frameworks, and facilitates the animation of new properties.", "num_citations": "1\n", "authors": ["54"]}
{"title": "Phorms: Pattern Combinator Library for Pharo\n", "abstract": " Pattern matching is a common mechanism to provide analysis and transformation of data structures. Such an approach basically checks whether the containing elements of a data structure are constituents of a pattern, described by the developer. This paper is a step towards having seamless object-oriented pattern matching, which would be applicable to any object in Pharo. We present a pattern matching library, called Phorms, which enables users to compose patterns using the syntax of the Pharo programming language. In this library, patterns are objects and therefore can be inspected and debugged using existing Pharo tools. Our solution is extensible unlike The Rewrite Engine--Pharo's current pattern matching facilities. Moreover, by treating patterns as first class objects, our library provides more flexibility in the pattern matching process.", "num_citations": "1\n", "authors": ["54"]}
{"title": "Reifying the reflectogram\n", "abstract": " Reflective facilities in OO languages are used both for implementing language extensions (such as AOP frameworks) and for supporting new programming tools and methodologies (such as objectcentric debugging and message-based profiling). Yet controlling the run-time behavior of these reflective facilities introduces several challenges, such as computational overhead, the possibility of metarecursion and an unclean separation of concerns between base and meta-level. In this paper we present five dimensions of meta-level control from related literature that try to remedy these problems. These dimensions are namely: temporal and spatial control, placement control, level control and identity control. We argue that the reification of the descriptive notion of the reflectogram, can unify the control of meta-level execution in all these five dimensions. We present a model for the reification of the reflectogram and validate our approach through a prototype implementation in the Pharo programming environment. Finally we detail a case-study on run-time tracing illustrating our approach.", "num_citations": "1\n", "authors": ["54"]}
{"title": "R\u251c\u2310cuperation de Composants \u251c\u00e1 partir d\u0393\u00c7\u00d6un syst\u251c\u00bfme patrimonial\n", "abstract": " De nombreuses techniques ont \u251c\u2310t\u251c\u2310 d\u251c\u2310velopp\u251c\u2310es dans le contexte de la r\u251c\u2310tro-ing\u251c\u2310nierie de systeme patrimonial. Une de ces techniques, appel\u251c\u2310e component recovery, permet l\u0393\u00c7\u00d6extraction de composanta partir du code source. Afin d\u0393\u00c7\u00d6assurer une modernisation efficace, les composants se doivent d\u0393\u00c7\u00d6\u251c\u00actre bien d\u251c\u2310finis. Les composants possedent tres souvent des informations sur le domaine d\u0393\u00c7\u00d6application du systeme, informations qui sont r\u251c\u2310cup\u251c\u2310r\u251c\u2310esa travers des entrevues avec les experts du domaines. Ainsi, ces experts et ing\u251c\u2310nieurs doivent tre inclus dans la d\u251c\u2310marche de r\u251c\u2310tro-ing\u251c\u2310nierie afin de fournir leurs connaissances aux techniques de r\u251c\u2310tro-ing\u251c\u2310nierie. Notre pr\u251c\u2310sentation montre la d\u251c\u2310marche que nous avons imagin\u251c\u2310e afin de r\u251c\u2310cup\u251c\u2310rer des composants,a la fois m\u251c\u2310tier et respectant la d\u251c\u2310finition d\u0393\u00c7\u00d6un composant,a partir d\u0393\u00c7\u00d6un code source patrimonial. Ce code patrimonial est celui d\u0393\u00c7\u00d6une application critique, temps r\u251c\u2310\u251c\u2310l, embarqu\u251c\u2310e et \u251c\u2310crite en Ada.", "num_citations": "1\n", "authors": ["54"]}
{"title": "Ghost: A Uniform and General-Purpose Proxy Implementation\n", "abstract": " A proxy object is a surrogate or placeholder that controls access to another target object. Proxy objects are a widely used solution for different scenarios such as remote method invocation, future objects, behavioral reflection, object databases, inter-languages communications and bindings, access control, lazy or parallel evaluation, security, among others. Most proxy implementations support proxies for regular objects but are unable to create proxies for objects with an important role in the runtime infrastructure such as classes or methods. Proxies can be complex to install, they can have a significant overhead, they can be limited to certain kind of classes, etc. Moreover, proxy implementations are often not stratified and they do not have a clear separation between proxies (the objects intercepting messages) and handlers (the objects handling interceptions). In this paper, we present Ghost: a uniform and general-purpose proxy implementation for the Pharo programming language. Ghost provides low memory consuming proxies for regular objects as well as for classes and methods. When a proxy takes the place of a class, it intercepts both the messages received by the class and the lookup of methods for messages received by its instances. Similarly, if a proxy takes the place of a method, then the method execution is intercepted too.", "num_citations": "1\n", "authors": ["54"]}
{"title": "Visualization of Practices and Metrics (Workpackage 1.2)\n", "abstract": " Measuring applications is a challenge and one of the goal of the Squale project is to propose a sound quality model. Now presenting the results of such analysis is also a challenge since it is complex to output and present to the user for the following rea- sons: first a lot of data should be presented and at different audience. Second displaying information is one aspect another one is navigating the information. Finally it is im- portant not to overwhelm the users with too much visualizations. This workpackage presents a state of the art in terms of software visualization approaches that are specif- ically designed to display metrics. In addition it sets up the context for the application of such visualization to practices.", "num_citations": "1\n", "authors": ["54"]}
{"title": "Guidage macroscopique de l'apprentissage\n", "abstract": " Notre approche s\u0393\u00c7\u00d6 appuie sur les r\u251c\u2310seaux notionnels, les \u251c\u2310tayages p\u251c\u2310dagogiques, les traces d\u0393\u00c7\u00d6objets et l\u0393\u00c7\u00d6inf\u251c\u2310rence sur celles-ci. Leur utilisation conjointe permet la description du domaine, la mod\u251c\u2310lisation de l\u0393\u00c7\u00d6apprenant et son pilotage par l\u0393\u00c7\u00d6EIAH. Nous pr\u251c\u2310sentons cette approche dans iSTOA. net.", "num_citations": "1\n", "authors": ["54"]}
{"title": "A Group Based Approach for Coordinating Active Objects\n", "abstract": " We propose in this thesis the use of active objects and coordination models and languages for the specification and construction of concurrent object-oriented systems. Active objects are objects integrating concurrency and coordination models and languages are models and languages that specify the way the active objects composing the systems are glued together. Our approach is based on the definition of a coordination model and language called CoLaS for the specification of the coordination aspect in concurrent object-oriented systems based on active objects. The CoLaS coordination model and language introduces a high level coordination abstraction called Coordination Group that allows programmers to design, to specify, to implement and to validate the coordination of groups of collaborating active objects in concurrent object-oriented systems.", "num_citations": "1\n", "authors": ["54"]}
{"title": "Safe and explicit composition of class properties\n", "abstract": " As object-oriented programmers, we are trained to capture common properties of objects in classes that can be reused. Similarly, we would like to capture common properties of classes in metaclass properties that can be reused. This goal has led researchers to propose models based on explicit metaclasses, but this has opened Pandora\u0393\u00c7\u00d6s box leading to metaclass composition problems. Numerous approaches have been proposed to fix the problem of metaclass composition, but the composition of conflicting properties was always resolved in an adhoc manner. Our approach uses traits, groups of methods that act as a unit of reuse from which classes are composed, and represent metaclass properties as traits. Metaclasses are then composed from these traits. This solution supports the reuse of metaclass properties, and their safe and automatic composition based on explicit conflict resolution. The paper compares existing models for composing metaclass properties, discusses traits and our solution, and shows some concrete examples implemented in the Smalltalk environment Squeak.", "num_citations": "1\n", "authors": ["54"]}
{"title": "Special Section on the International Conference on Software Maintenance\n", "abstract": " [Front cover] Page 1 IEEE TRANSACTIONS ON SOFTWARE ENGINEERING A publication of the IEEE Computer Society VOLUME 35 NUMBER 4 IESEDJ (ISSN 0098-5589) Editorial: New Associate Editors Introduction J. Kramer ............................................................................................................................................................................ 449 SPECIAL SECTION ON THE INTERNATIONAL CONFERENCE ON SOFTWARE MAINTENANCE Guest Editors\u0393\u00c7\u00d6 Introduction to the Special Section from the International Conference on Software Maintenance G. Canfora, L. Tahvildari, and HA M\u251c\u255dller .......................................................................................................................... 450 Recomputing Coverage Information to Assist Regression Testing PK Chittimalli and MJ Harrold ......................................................................................................................................... 452 How Software Developers Use Tagging to Support Reminding and Refinding M.-A. Storey, J. Ryall\u0393\u00c7\u00aa", "num_citations": "1\n", "authors": ["54"]}
{"title": "Object-Oriented Software Reengineering\n", "abstract": " Object-Oriented Software Reengineering Page 1 Object-Oriented Software Reengineering Dr. S. Demeyer Dr. S. Ducasse Prof. Dr. O. Nierstrasz Wintersemester 1998/1999 Page 2 Table of Contents ii. February 5, 1999 Table of Contents Table of Contents ii 1. Object-Oriented Software Reengineering 1 Goals of this course 2 Course Overview 3 What is a Legacy System? 4 Software Maintenance 5 Why is Software Maintenance Expensive? 6 Lehman\u0393\u00c7\u00d6s Laws 7 Factors Affecting Maintenance 8 Maintainability Metrics 9 Definitions 10 Tools Architectures 11 Reverse and Re-engineering 12 Goals of Reverse Engineering 13 Reverse Engineering Techniques 14 Goals of Reengineering 15 Reengineering Techniques 16 Architectural Problems 17 Refactoring Opportunities 18 Summary 19 2. Metrics 20 Why Measure Software? 21 What is a Metric? 22 GQM 23 Metrics assumptions 24 Cost estimation objectives 25 26 cost -3\u0393\u00c7\u00aa", "num_citations": "1\n", "authors": ["54"]}
{"title": "Architectural Extraction in Reverse Engineering by Prototyping: An Experiment\n", "abstract": " In this workshop proposal we present a prototype approach to help the extraction of architectural information in the re-engineering process. Commonly, the re-engineering life-cycle has been dened as a succession of the following tasks: analysis of requirements, model capture understanding the sys tem, problem detection, problem analysis, reorganisation and change propagation 1. We haveevaluated the benet of a prototyping approach with a focus on model capture. Although prototyping is a known approach to evaluate the application feasibility, costs, comparison and validation of choices, we focus in this paper on the aspects of prototyping that are helpful for re-engineering. In the followingsections we rst present the problem, and afterwards we present our proposal to solve this problem: a pattern describing how to use prototyping to extract architectural information from a legacy system.", "num_citations": "1\n", "authors": ["54"]}