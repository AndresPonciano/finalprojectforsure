{"title": "Approximate computing: An emerging paradigm for energy-efficient design\n", "abstract": " Approximate computing has recently emerged as a promising approach to energy-efficient design of digital systems. Approximate computing relies on the ability of many systems and applications to tolerate some loss of quality or optimality in the computed result. By relaxing the need for fully precise or completely deterministic operations, approximate computing techniques allow substantially improved energy efficiency. This paper reviews recent progress in the area, including design of approximate arithmetic blocks, pertinent error and quality measures, and algorithm-level techniques for approximate computing.", "num_citations": "932\n", "authors": ["517"]}
{"title": "New metrics for the reliability of approximate and probabilistic adders\n", "abstract": " Addition is a fundamental function in arithmetic operation; several adder designs have been proposed for implementations in inexact computing. These adders show different operational profiles; some of them are approximate in nature while others rely on probabilistic features of nanoscale circuits. However, there has been a lack of appropriate metrics to evaluate the efficacy of various inexact designs. In this paper, new metrics are proposed for evaluating the reliability as well as the power efficiency of approximate and probabilistic adders. Reliability is analyzed using the so-called sequential probability transition matrices (SPTMs). Error distance (ED) is initially defined as the arithmetic distance between an erroneous output and the correct output for a given input. The mean error distance (MED) and normalized error distance (NED) are then proposed as unified figures that consider the averaging effect of multiple\u00a0\u2026", "num_citations": "466\n", "authors": ["517"]}
{"title": "Design and analysis of approximate compressors for multiplication\n", "abstract": " Inexact (or approximate) computing is an attractive paradigm for digital processing at nanometric scales. Inexact computing is particularly interesting for computer arithmetic designs. This paper deals with the analysis and design of two new approximate 4-2 compressors for utilization in a multiplier. These designs rely on different features of compression, such that imprecision in computation (as measured by the error rate and the so-called normalized error distance) can meet with respect to circuit-based figures of merit of a design (number of transistors, delay and power consumption). Four different schemes for utilizing the proposed approximate compressors are proposed and analyzed for a Dadda multiplier. Extensive simulation results are provided and an application of the approximate multipliers to image processing is presented. The results show that the proposed designs accomplish significant reductions in\u00a0\u2026", "num_citations": "385\n", "authors": ["517"]}
{"title": "A low-power, high-performance approximate multiplier with configurable partial error recovery\n", "abstract": " Approximate circuits have been considered for error-tolerant applications that can tolerate some loss of accuracy with improved performance and energy efficiency. Multipliers are key arithmetic circuits in many such applications such as digital signal processing (DSP). In this paper, a novel approximate multiplier with a lower power consumption and a shorter critical path than traditional multipliers is proposed for high-performance DSP applications. This multiplier leverages a newly-designed approximate adder that limits its carry propagation to the nearest neighbors for fast partial product accumulation. Different levels of accuracy can be achieved through a configurable error recovery by using different numbers of most significant bits (MSBs) for error reduction. The approximate multiplier has a low mean error distance, i.e., most of the errors are not significant in magnitude. Compared to the Wallace multiplier, a 16\u00a0\u2026", "num_citations": "296\n", "authors": ["517"]}
{"title": "Approximate XOR/XNOR-based adders for inexact computing\n", "abstract": " Power dissipation has become a significant issue for integrated circuit design in nanometric CMOS technology. To reduce power consumption, approximate implementations of a circuit have been considered as a potential solution for applications in which strict exactness is not required. In inexact computing, power reduction is achieved through the relaxation of the often demanding requirement of accuracy. In this paper, new approximate adders are proposed for low-power imprecise applications. These adders are based on XOR/XNOR gates with multiplexers implemented by pass transistors. The proposed approximate XOR/XNOR-based adders (AXAs) are evaluated and compared with respect to energy consumption, delay, area and power delay product (PDP) with an accurate full adder. The metric of error distance is used to evaluate the reliability of the approximate designs. Simulation by Cadence's Spectre in\u00a0\u2026", "num_citations": "241\n", "authors": ["517"]}
{"title": "A system architecture solution for unreliable nanoelectronic devices\n", "abstract": " The shrinking of electronic devices will inevitably introduce a growing number of defects and even make these devices more sensitive to external influences. It is, therefore, likely that the emerging nanometer-scale devices will eventually suffer from more errors than classical silicon devices in large scale integrated circuits. In order to make systems based on nanometer-scale devices reliable, the design of fault-tolerant architectures will be necessary. Initiated by von Neumann, the NAND multiplexing technique, based on a massive duplication of imperfect devices and randomized imperfect interconnects, had been studied in the past using an extreme high degree of redundancy. In this paper, this NAND multiplexing is extended to a rather low degree of redundancy, and the stochastic Markov nature in the heart of the system is discovered and studied, leading to a comprehensive fault-tolerant theory. A system\u00a0\u2026", "num_citations": "241\n", "authors": ["517"]}
{"title": "Toward hardware-redundant, fault-tolerant logic for nanoelectronics\n", "abstract": " This article provides an overview of several logic redundancy schemes, including von Neumann's multiplexing logic, N-tuple modular redundancy, and interwoven redundant logic. We discuss several important concepts for redundant nanoelectronic system designs based on recent results. First, we use Markov chain models to describe the error-correcting and stationary characteristics of multiple-stage multiplexing systems. Second, we show how to obtain the fundamental error bounds by using bifurcation analysis based on probabilistic models of unreliable gates. Third, we describe the notion of random interwoven redundancy. Finally, we compare the reliabilities of quadded and random interwoven structures by using a simulation-based approach. We observe that the deeper a circuit's logical depth, the more fault-tolerant the circuit tends to be for a fixed number of faults. For a constant gate failure rate, a circuit's\u00a0\u2026", "num_citations": "177\n", "authors": ["517"]}
{"title": "A comparative review and evaluation of approximate adders\n", "abstract": " As an important arithmetic module, the adder plays a key role in determining the speed and power consumption of a digital signal processing (DSP) system. The demands of high speed and power efficiency as well as the fault tolerance nature of some applications have promoted the development of approximate adders. This paper reviews current approximate adder designs and provides a comparative evaluation in terms of both error and circuit characteristics. Simulation results show that the equal segmentation adder (ESA) is the most hardware-efficient design, but it has the lowest accuracy in terms of error rate (ER) and mean relative error distance (MRED). The error-tolerant adder type II (ETAII), the speculative carry select adder (SCSA) and the accuracy-configurable approximate adder (ACAA) are equally accurate (provided that the same parameters are used), however ETATII incurs the lowest power-delay\u00a0\u2026", "num_citations": "166\n", "authors": ["517"]}
{"title": "A review, classification, and comparative evaluation of approximate arithmetic circuits\n", "abstract": " Often as the most important arithmetic modules in a processor, adders, multipliers, and dividers determine the performance and energy efficiency of many computing tasks. The demand of higher speed and power efficiency, as well as the feature of error resilience in many applications (e.g., multimedia, recognition, and data analytics), have driven the development of approximate arithmetic design. In this article, a review and classification are presented for the current designs of approximate arithmetic circuits including adders, multipliers, and dividers. A comprehensive and comparative evaluation of their error and circuit characteristics is performed for understanding the features of various designs. By using approximate multipliers and adders, the circuit for an image processing application consumes as little as 47% of the power and 36% of the power-delay product of an accurate design while achieving similar image\u00a0\u2026", "num_citations": "158\n", "authors": ["517"]}
{"title": "Design of approximate radix-4 booth multipliers for error-tolerant computing\n", "abstract": " Approximate computing is an attractive design methodology to achieve low power, high performance (low delay) and reduced circuit complexity by relaxing the requirement of accuracy. In this paper, approximate Booth multipliers are designed based on approximate radix-4 modified Booth encoding (MBE) algorithms and a regular partial product array that employs an approximate Wallace tree. Two approximate Booth encoders are proposed and analyzed for error-tolerant computing. The error characteristics are analyzed with respect to the so-called approximation factor that is related to the inexact bit width of the Booth multipliers. Simulation results at 45 nm feature size in CMOS for delay, area and power consumption are also provided. The results show that the proposed 16-bit approximate radix-4 Booth multipliers with approximate factors of 12 and 14 are more accurate than existing approximate Booth\u00a0\u2026", "num_citations": "157\n", "authors": ["517"]}
{"title": "Approximate radix-8 booth multipliers for low-power and high-performance operation\n", "abstract": " The Booth multiplier has been widely used for high performance signed multiplication by encoding and thereby reducing the number of partial products. A multiplier using the radix-    (or modified Booth) algorithm is very efficient due to the ease of partial product generation, whereas the radix-    Booth multiplier is slow due to the complexity of generating the odd multiples of the multiplicand. In this paper, this issue is alleviated by the application of approximate designs. An approximate   -bit adder is deliberately designed for calculating the sum of    and    of a binary number. This adder requires a small area, a low power and a short critical path delay. Subsequently, the   -bit adder is employed to implement the less significant section of a recoding adder for generating the triple multiplicand with no carry propagation. In the pursuit of a trade-off between accuracy and power consumption, two signed  \u00a0\u2026", "num_citations": "144\n", "authors": ["517"]}
{"title": "Reliability evaluation of logic circuits using probabilistic gate models\n", "abstract": " Logic circuits built using nanoscale technologies have significant reliability limitations due to fundamental physical and manufacturing constraints of their constituent devices. This paper presents a probabilistic gate model (PGM), which relates the output probability to the error and input probabilities of an unreliable logic gate. The PGM is used to obtain computational algorithms, one being approximate and the other accurate, for the evaluation of circuit reliability. The complexity of the approximate algorithm, which does not consider dependencies among signals, increases linearly with the number of gates in a circuit. The accurate algorithm, which accounts for signal dependencies due to reconvergent fanouts and/or correlated inputs, has a worst-case complexity that is exponential in the numbers of dependent reconvergent fanouts and correlated inputs. By leveraging the fact that many large circuits consist of\u00a0\u2026", "num_citations": "144\n", "authors": ["517"]}
{"title": "A defect-and fault-tolerant architecture for nanocomputers\n", "abstract": " Both von Neumann's NAND multiplexing, based on a massive duplication of imperfect devices and randomized imperfect interconnects, and reconfigurable architectures have been investigated to come up with solutions for integrations of highly unreliable nanometre-scale devices. In this paper, we review these two techniques, and present a defect-and fault-tolerant architecture in which von Neumann's NAND multiplexing is combined with a massively reconfigurable architecture. The system performance of this architecture is evaluated by studying its reliability, ie the probability of system survival. Our evaluation shows that the suggested architecture can tolerate a device error rate of up to 10\u2212 2, with multiple redundant components; the structure is efficiently robust against both permanent and transient faults for an ultra-large integration of highly unreliable nanometre-scale devices.", "num_citations": "137\n", "authors": ["517"]}
{"title": "A stochastic computational approach for accurate and efficient reliability evaluation\n", "abstract": " Reliability is fast becoming a major concern due to the nanometric scaling of CMOS technology. Accurate analytical approaches for the reliability evaluation of logic circuits, however, have a computational complexity that generally increases exponentially with circuit size. This makes intractable the reliability analysis of large circuits. This paper initially presents novel computational models based on stochastic computation; using these stochastic computational models (SCMs), a simulation-based analytical approach is then proposed for the reliability evaluation of logic circuits. In this approach, signal probabilities are encoded in the statistics of random binary bit streams and non-Bernoulli sequences of random permutations of binary bits are used for initial input and gate error probabilities. By leveraging the bit-wise dependencies of random binary streams, the proposed approach takes into account signal correlations\u00a0\u2026", "num_citations": "131\n", "authors": ["517"]}
{"title": "Design and evaluation of multiple valued logic gates using pseudo N-type carbon nanotube FETs\n", "abstract": " Multiple valued logic (MVL) circuits are particularly attractive for nanoscale implementation as advantages in information density and operating speed can be harvested using emerging technologies. In this paper, a new family of MVL gates is proposed for implementation using carbon nanotube field-effect transistors (CNTFETs). The proposed designs use pseudo N-type CNTFETs and no resistor is utilized for their operation. This approach exploits threshold voltage control of the P-type and N-type transistors, while ensuring correct MVL operation for both ternary and quaternary logic gates. This paper provides a detailed assessment of several figures of merit, such as static power consumption, switching power consumption, propagation delay and the power-delay product (PDP). Compared with resistor-loaded designs, the proposed pseudo-NCNTFET MVL gates show advantages in circuit area, power consumption\u00a0\u2026", "num_citations": "105\n", "authors": ["517"]}
{"title": "An analytical framework for evaluating the error characteristics of approximate adders\n", "abstract": " Approximate adders have been considered as a potential alternative for error-tolerant applications to trade off some accuracy for gains in other circuit-based metrics, such as power, area and delay. Existing approximate adder designs have shown substantial advantages in improving many of these operational features. However, the error characteristics of the approximate adders still remain an issue that is not very well understood. A simulation-based method requires both programming efforts and a time-consuming execution for evaluating the effect of errors. This method becomes particularly expensive when dealing with various sizes and types of approximate adders. In this paper, a framework based on analytical models is proposed for evaluating the error characteristics of approximate adders. Error features such as the error rate and the mean error distance are obtained using this framework without developing\u00a0\u2026", "num_citations": "95\n", "authors": ["517"]}
{"title": "Faults, error bounds and reliability of nanoelectronic circuits\n", "abstract": " This paper is concerned with faults, error bounds and reliability modeling of nanotechnology-based circuits. First, we briefly review failure mechanisms and fault models in nanoelectronics. Second, reliability functions based on probabilistic models are developed for unreliable logic gates. We then show that fundamental gate error bounds for general probabilistic computation can be derived using the nonlinear mapping functions constructed from the gate models. Finally, an analytical approach is proposed for estimating reliabilities of nanoelectronic circuits. This approach is based on the probabilistic modeling of unreliable logic gates and interconnects. In spite of the approximations used in probabilistic modeling, our study suggests that the proposed approach provides a simple and efficient way to model the reliability of nanoelectronic circuits.", "num_citations": "79\n", "authors": ["517"]}
{"title": "Stochastic Boolean networks: an efficient approach to modeling gene regulatory networks\n", "abstract": " Various computational models have been of interest due to their use in the modelling of gene regulatory networks (GRNs). As a logical model, probabilistic Boolean networks (PBNs) consider molecular and genetic noise, so the study of PBNs provides significant insights into the understanding of the dynamics of GRNs. This will ultimately lead to advances in developing therapeutic methods that intervene in the process of disease development and progression. The applications of PBNs, however, are hindered by the complexities involved in the computation of the state transition matrix and the steady-state distribution of a PBN. For a PBN with n genes and N Boolean networks, the complexity to compute the state transition matrix is O(nN 22n) or O(nN 2                     n                   ) for a sparse matrix. This paper presents a novel implementation of PBNs based on the notions of stochastic logic and stochastic computation\u00a0\u2026", "num_citations": "75\n", "authors": ["517"]}
{"title": "A comparative evaluation of approximate multipliers\n", "abstract": " A multiplier has a significant impact on the speed and power dissipation of an arithmetic processor. Precise results are not always required in many algorithms, such as those for classification and recognition in data processing. Moreover, many errors do not make an obvious difference in applications such as image processing due to the perceptual limitations of human beings. Error-tolerant algorithms and applications have promoted the development of approximate multipliers to tradeoff accuracy for speed, implementation area and/or power efficiency. This paper briefly reviews the current designs of approximate multipliers and provides a comparative evaluation of their error and circuit characteristics. Image sharpening is performed using the considered approximate multipliers to assess their performance in such applications.", "num_citations": "71\n", "authors": ["517"]}
{"title": "Low-power approximate multipliers using encoded partial products and approximate compressors\n", "abstract": " Approximate computing has been considered to improve the accuracy-performance tradeoff in error-tolerant applications. For many of these applications, multiplication is a key arithmetic operation. Given that approximate compressors are a key element in the design of power-efficient approximate multipliers, we first propose an initial approximate 4:2 compressor that introduces a rather large error to the output. However, the number of faulty rows in the compressor's truth table is significantly reduced by encoding its inputs using generate and propagate signals. Based on this improved compressor, two 4 \u00d7 4 multipliers are designed with different accuracies and then are used as building blocks for scaling up to 16 \u00d7 16 and 32\u00d732 multipliers. According to the mean relative error distance (MRED), the most accurate of the proposed 16 \u00d7 16 unsigned designs has a 44% smaller power-delay product (PDP) compared to\u00a0\u2026", "num_citations": "64\n", "authors": ["517"]}
{"title": "Stochastic computational models for accurate reliability evaluation of logic circuits\n", "abstract": " As reliability becomes a major concern with the continuous scaling of CMOS technology, several computational methodologies have been developed for the reliability evaluation of logic circuits. Previous accurate analytical approaches, however, have a computational complexity that generally increases exponentially with the size of a circuit, making the evaluation of large circuits intractable. This paper presents novel computational models based on stochastic computation, in which probabilities are encoded in the statistics of random binary bit streams, for the reliability evaluation of logic circuits. A computational approach using the stochastic computational models (SCMs) accurately determines the reliability of a circuit with its precision only limited by the random fluctuations inherent in the representation of random binary bit streams. The SCM approach has a linear computational complexity and is therefore\u00a0\u2026", "num_citations": "61\n", "authors": ["517"]}
{"title": "Approximate compressors for error-resilient multiplier design\n", "abstract": " Approximate circuit design is an innovative paradigm for error-resilient image and signal processing applications. Multiplication is often a fundamental function for many of these applications. In this paper, three approximate compressors are proposed with an accuracy constraint for the partial product reduction (PPR) in a multiplier. Both approximation and truncation are considered in the approximate multiplier design. An image sharpening algorithm is then investigated as an application of the proposed multiplier designs. Extensive simulation results show that the proposed designs achieve significant reductions in area and power while achieving a high signal-to-noise ratio (SNR > 35 dB), compared to their exact counterparts as well as other approximate multipliers.", "num_citations": "59\n", "authors": ["517"]}
{"title": "A stochastic computational multi-layer perceptron with backward propagation\n", "abstract": " Stochastic computation has recently been proposed for implementing artificial neural networks with reduced hardware and power consumption, but at a decreased accuracy and processing speed. Most existing implementations are based on pre-training such that the weights are predetermined for neurons at different layers, thus these implementations lack the ability to update the values of the network parameters. In this paper, a stochastic computational multi-layer perceptron (SC-MLP) is proposed by implementing the backward propagation algorithm for updating the layer weights. Using extended stochastic logic (ESL), a reconfigurable stochastic computational activation unit (SCAU) is designed to implement different types of activation functions such as the tanh and the rectifier function. A triple modular redundancy (TMR) technique is employed for reducing the random fluctuations in stochastic computation. A\u00a0\u2026", "num_citations": "58\n", "authors": ["517"]}
{"title": "Transmission gate-based approximate adders for inexact computing\n", "abstract": " Power dissipation has become a significant concern for integrated circuit design in nanometric CMOS technology. To reduce power consumption, approximate implementations of a circuit have been considered as a potential solution for applications in which strict exactness is not required. In approximate computing, power reduction is achieved through the relaxation of the often demanding requirement of accuracy. In this paper, new approximate adders are proposed for low-power imprecise applications by using logic reduction at the gate level as an approach to relaxing numerical accuracy. Transmission gates are utilized in the designs of two approximate full adders with reduced complexity. A further positive feature of the proposed designs is the reduction of the critical path delay. The approximate adders show advantages in terms of power dissipation over accurate and recently proposed approximate adders\u00a0\u2026", "num_citations": "57\n", "authors": ["517"]}
{"title": "A survey of coarse-grained reconfigurable architecture and design: Taxonomy, challenges, and applications\n", "abstract": " As general-purpose processors have hit the power wall and chip fabrication cost escalates alarmingly, coarse-grained reconfigurable architectures (CGRAs) are attracting increasing interest from both academia and industry, because they offer the performance and energy efficiency of hardware with the flexibility of software. However, CGRAs are not yet mature in terms of programmability, productivity, and adaptability. This article reviews the architecture and design of CGRAs thoroughly for the purpose of exploiting their full potential. First, a novel multidimensional taxonomy is proposed. Second, major challenges and the corresponding state-of-the-art techniques are surveyed and analyzed. Finally, the future development is discussed.", "num_citations": "54\n", "authors": ["517"]}
{"title": "Towards accurate and efficient reliability modeling of nanoelectronic circuits\n", "abstract": " The emergence of nanoelectronic devices which rely on fundamentally unreliable physics calls for reliability evaluation techniques and practical design-for-reliability solutions. This paper reviews a method that uses probabilistic gate models (PGMs) for reliability estimation and improves upon this method to enable the accurate evaluation of reliabilities of circuits. When applied to large, complex circuits, however, this and other accurate methods lead to long execution times. To simplify reliability analysis, this paper leverages the fact that many large circuits consist of common logic modules. The overall circuit reliability estimation can be made on the basis of accurate PGM-based reliabilities of individual modules. This technique significantly reduces the PGM method\u2019s complexity, making it suitable for practical design-for-reliability applications. Results from the use of this technique on benchmark circuits indicate that\u00a0\u2026", "num_citations": "48\n", "authors": ["517"]}
{"title": "Energy efficient stochastic computing with Sobol sequences\n", "abstract": " Energy efficiency presents a significant challenge for stochastic computing (SC) due to the long random binary bit streams required for accurate computation. In this paper, a type of low discrepancy (LD) sequences, the Sobol sequence, is considered for energy-efficient implementations of SC circuits. The use of Sobol sequences improves the output accuracy of a stochastic circuit with a reduced sequence length compared to the use of another type of LD sequences, the Halton sequence, and conventional linear feedback shift register (LFSR)-generated pseudorandom sequence. The use of Sobol sequences leads to a similar or higher accuracy than using Halton sequences for basic arithmetic operations. Sobol sequence generators cost less energy than the Halton counterparts when multiple random sequences are required in a circuit, thus the use of Sobol sequences can lead to a higher energy efficiency in an\u00a0\u2026", "num_citations": "46\n", "authors": ["517"]}
{"title": "Design and evaluation of an approximate Wallace-Booth multiplier\n", "abstract": " Approximate or inexact computing has recently attracted considerable attention due to its potential advantages with respect to high performance and low power consumption. This paper presents the design of an approximate multiplier; this approximate multiplier consists of an approximate Booth encoder, an approximate 4-2 compressor and an approximate tree structure. The approximate design is implemented and verified for 8\u00d78, 16\u00d716 and 32\u00d732-bit signed multiplication schemes targeting applications in embedded systems. Simulation results at 45 nm technology are provided and discussed. Compared with an exact Wallace-Booth multiplier as well as other approximate multipliers found in the technical literature, the proposed approximate scheme achieves significant improvements in power consumption, delay and combined metrics. These results show the viability of the proposed design.", "num_citations": "45\n", "authors": ["517"]}
{"title": "On the design of approximate restoring dividers for error-tolerant applications\n", "abstract": " This paper proposes several designs of approximate restoring dividers; two different levels of approximation (cell and array levels) are employed. Three approximate subtractor cells are utilized for integer subtraction as basic step of division; these cells tend to mitigate accuracy in subtraction with other metrics, such as circuit complexity and power dissipation. At array level, exact cells are either replaced or truncated in the approximate divider designs. A comprehensive evaluation of approximation at both cell- and array (divider) levels is pursued using error analysis and HSPICE simulation; different circuit metrics including complexity and power dissipation are evaluated. Different applications are investigated by utilizing the proposed approximate arithmetic circuits. The simulation results show that with extensive savings for power dissipation and circuit complexity, the proposed designs offer better error tolerant\u00a0\u2026", "num_citations": "43\n", "authors": ["517"]}
{"title": "Design of approximate unsigned integer non-restoring divider for inexact computing\n", "abstract": " This paper proposes several approximate divider designs; two different levels of approximation (cell and array levels) are investigated for non-restoring division. Three approximate subtractor cells are proposed and designed for the basic subtraction; these cells mitigate accuracy in subtraction with other metrics, such as circuit complexity and power dissipation. At array level, by considering the exact cells, both replacement and truncation schemes are introduced for approximate array divider design. A comprehensive evaluation of approximation at both cell and divider level is pursued. Different circuit metrics including complexity and power dissipation are evaluated by HSPICE simulation. Mean error distance (MED), normalized error distance (NED) and MED-power product (MPP) are provided to substantiate the accuracy and power trade-off of inexact computing. Different applications in image processing are\u00a0\u2026", "num_citations": "43\n", "authors": ["517"]}
{"title": "A stochastic approach for the analysis of dynamic fault trees with spare gates under probabilistic common cause failures\n", "abstract": " A redundant system usually consists of primary and standby modules. The so-called spare gate is extensively used to model the dynamic behavior of redundant systems in the application of dynamic fault trees (DFTs). Several methodologies have been proposed to evaluate the reliability of DFTs containing spare gates by computing the failure probability. However, either a complex analysis or significant simulation time are usually required by such an approach. Moreover, it is difficult to compute the failure probability of a system with component failures that are not exponentially distributed. Additionally, probabilistic common cause failures (PCCFs) have been widely reported, usually occurring in a statistically dependent manner. Failure to account for the effect of PCCFs overestimates the reliability of a DFT. In this paper, stochastic computational models are proposed for an efficient analysis of spare gates and\u00a0\u2026", "num_citations": "43\n", "authors": ["517"]}
{"title": "Design of a nonvolatile 7T1R SRAM cell for instant-on operation\n", "abstract": " Energy consumption is a major concern in nanoscale CMOS ICs; the power-Off operational mode and low-voltage circuits have been proposed to alleviate energy dissipation. Static random access memories (SRAMs) are widely used in today's chips; nonvolatile SRAMs (NVSRAMs) have been proposed to preserve data, while providing fast power- On/Off speeds. Nonvolatile operation is usually accomplished by the use of a resistive RAM circuit (hence referred to as RRAM); the utilization of a RRAM with an SRAMs not only enables chips to achieve low energy consumption for nonvolatile operation, but it also permits to restore data when a restore on power-up is performed (this operation is also commonly referred to as \u201cInstant-on\u201d). This paper presents a novel NVSRAM circuit for \u201cInstant-on\u201d operation and evaluates its performance at nanometric feature sizes. The proposed memory cell consists of a SRAM core\u00a0\u2026", "num_citations": "42\n", "authors": ["517"]}
{"title": "On the reliability of computational structures using majority logic\n", "abstract": " The importance of the reliability of majority-based structures stems from their use in both conventional fault-tolerant architectures and emerging nanoelectronic systems. In this paper, analytical models are developed in order to gain a better understanding of the reliability of majority logic in these contexts. A minimally biased input scenario for  N -input majority gates (  N  odd) occurs when only a minimal majority of the inputs are in consensus. In a tree of gates with these inputs, this paper determines 1) that any nonzero error rate of the majority gates and/or of its initial inputs will result in an unreliable output and 2) that the use of majority gates with a larger number of inputs leads to a less reliable structure. These results are extended to  N -input minority gates for odd  N . Although these findings are based on tree structures, their implications to circuit design are explored by investigating several fault-tolerant and\u00a0\u2026", "num_citations": "41\n", "authors": ["517"]}
{"title": "Low-power approximate unsigned multipliers with configurable error recovery\n", "abstract": " Approximate circuits have been considered for applications that can tolerate some loss of accuracy with improved performance and/or energy efficiency. Multipliers are key arithmetic circuits in many of these applications including digital signal processing (DSP). In this paper, a novel approximate multiplier with a low power consumption and a short critical path is proposed for high-performance DSP applications. This multiplier leverages a newly designed approximate adder that limits its carry propagation to the nearest neighbors for fast partial product accumulation. Different levels of accuracy can be achieved by using either OR gates or the proposed approximate adder in a configurable error recovery circuit. The approximate multipliers using these two error reduction strategies are referred to as AM1 and AM2, respectively. Both AM1 and AM2 have a low mean error distance, i.e., most of the errors are not\u00a0\u2026", "num_citations": "40\n", "authors": ["517"]}
{"title": "A fault-tolerant technique using quadded logic and quadded transistors\n", "abstract": " Advances in CMOS technology have made digital circuits and systems very sensitive to manufacturing variations, aging, and/or soft errors. Fault-tolerant techniques using hardware redundancy have been extensively investigated for improving reliability. Quadded logic (QL) is an interwoven redundant logic technique that corrects errors by switching them from critical to subcritical status; however, QL cannot correct errors in the last one or two layers of a circuit. In contrast to QL, quadded transistor (QT) corrects errors while performing the function of a circuit. In this brief, a technique that combines QL with QT is proposed to take advantage of both techniques. The proposed quadded logic with quadded transistor (QLQT) technique is evaluated and compared with other fault-tolerant techniques, such as triple modular redundancy and triple interwoven redundancy, using stochastic computational models. Simulation\u00a0\u2026", "num_citations": "38\n", "authors": ["517"]}
{"title": "An efficient application mapping approach for the co-optimization of reliability, energy, and performance in reconfigurable NoC architectures\n", "abstract": " In this paper, an efficient application mapping approach is proposed for the co-optimization of reliability, communication energy, and performance (CoREP) in network-on-chip (NoC)-based reconfigurable architectures. A cost model for the CoREP is developed to evaluate the overall cost of a mapping. In this model, communication energy and latency (as a measure of performance) are first considered in energy latency product (ELP), and then ELP is co-optimized with reliability by a weight parameter that defines the optimization priority. Both transient and intermittent errors in NoC are modeled in CoREP. Based on CoREP, a mapping approach, referred to as priority and ratio oriented branch and bound (PRBB), is proposed to derive the best mapping by enumerating all the candidate mappings organized in a search tree. Two techniques, branch node priority recognition and partial cost ratio utilization, are adopted\u00a0\u2026", "num_citations": "37\n", "authors": ["517"]}
{"title": "A design approach for compressor based approximate multipliers\n", "abstract": " Approximate computing is best suited for error resilient applications, such as signal processing and multimedia. Approximate computing reduces accuracy, but it still provides meaningful and faster results with usually lower power consumption, this is particularly attractive for arithmetic circuits. In this paper, a new design approach is proposed to exploit the partitions of partial products using recursive multiplication for compressor-based approximate multipliers. Four multiplier designs are proposed using 4:2 approximate compressors. Extensive simulation results show that the proposed designs achieve significant accuracy improvement together with power and delay reductions compared to previous approximate designs. An image processing application is also presented to show the efficiency of the proposed designs.", "num_citations": "37\n", "authors": ["517"]}
{"title": "Improving the accuracy and hardware efficiency of neural networks using approximate multipliers\n", "abstract": " Improving the accuracy of a neural network (NN) usually requires using larger hardware that consumes more energy. However, the error tolerance of NNs and their applications allow approximate computing techniques to be applied to reduce implementation costs. Given that multiplication is the most resource-intensive and power-hungry operation in NNs, more economical approximate multipliers (AMs) can significantly reduce hardware costs. In this article, we show that using AMs can also improve the NN accuracy by introducing noise. We consider two categories of AMs: 1) deliberately designed and 2) Cartesian genetic programing (CGP)-based AMs. The exact multipliers in two representative NNs, a multilayer perceptron (MLP) and a convolutional NN (CNN), are replaced with approximate designs to evaluate their effect on the classification accuracy of the Mixed National Institute of Standards and Technology\u00a0\u2026", "num_citations": "34\n", "authors": ["517"]}
{"title": "A stochastic approach for the analysis of fault trees with priority AND gates\n", "abstract": " Dynamic fault tree (DFT) analysis has been used to account for dynamic behaviors such as the sequence-dependent, functional-dependent, and priority relationships among the failures of basic events. Various methodologies have been developed to analyze a DFT; however, most methods require a complex analytical procedure or a significant simulation time for an accurate analysis. In this paper, a stochastic computational approach is proposed for an efficient analysis of the top event's failure probability in a DFT with priority AND (PAND) gates. A stochastic model is initially proposed for a two-input PAND gate, and a successive cascading model is then presented for a general multiple-input PAND gate. A stochastic approach using the proposed models provides an efficient analysis of a DFT compared to an accurate analysis or algebraic approach. The accuracy of a stochastic analysis increases with the length of\u00a0\u2026", "num_citations": "34\n", "authors": ["517"]}
{"title": "Stochastic multiple-valued gene networks\n", "abstract": " Among various approaches to modeling gene regulatory networks (GRNs), Boolean networks (BNs) and its probabilistic extension, probabilistic Boolean networks (PBNs), have been studied to gain insights into the dynamics of GRNs. To further exploit the simplicity of logical models, a multiple-valued network employs gene states that are not limited to binary values, thus providing a finer granularity in the modeling of GRNs. In this paper, stochastic multiple-valued networks (SMNs) are proposed for modeling the effects of noise and gene perturbation in a GRN. An SMN enables an accurate and efficient simulation of a probabilistic multiple-valued network (as an extension of a PBN). In a k-level SMN of n genes, it requires a complexity of O(nLk n ) to compute the state transition matrix, where L is a factor related to the minimum sequence length in the SMN for achieving a desired accuracy. The use of randomly\u00a0\u2026", "num_citations": "33\n", "authors": ["517"]}
{"title": "A high-performance and energy-efficient FIR adaptive filter using approximate distributed arithmetic circuits\n", "abstract": " In this paper, a fixed-point finite impulse response adaptive filter is proposed using approximate distributed arithmetic (DA) circuits. In this design, the radix-8 Booth algorithm is used to reduce the number of partial products in the DA architecture, although no multiplication is explicitly performed. In addition, the partial products are approximately generated by truncating the input data with an error compensation. To further reduce hardware costs, an approximate Wallace tree is considered for the accumulation of partial products. As a result, the delay, area, and power consumption of the proposed design are significantly reduced. The application of system identification using a 48-tap bandpass filter and a 103-tap high-pass filter shows that the approximate design achieves a similar accuracy as its accurate counterpart. Compared with the state-of-the-art adaptive filter using bit-level pruning in the adder tree (referred to\u00a0\u2026", "num_citations": "30\n", "authors": ["517"]}
{"title": "A true random number generator based on parallel STT-MTJs\n", "abstract": " Random number generators are an essential part of cryptographic systems. For the highest level of security, true random number generators (TRNG) are needed instead of pseudorandom number generators. In this paper, the stochastic behavior of the spin transfer torque magnetic tunnel junction (STT-MTJ) is utilized to produce a TRNG design. A parallel structure with multiple MTJs is proposed that minimizes device variation effects. The design is validated in a 28-nm CMOS process with Monte Carlo simulation using a compact model of the MTJ. The National Institute of Standards and Technology (NIST) statistical test suite is used to verify the randomness quality when generating encryption keys for the Transport Layer Security or Secure Sockets Layer (TLS/SSL) cryptographic protocol. This design has a generation speed of 177.8 Mbit/s, and an energy of 0.64 pJ is consumed to set up the state in one MTJ.", "num_citations": "29\n", "authors": ["517"]}
{"title": "Design, evaluation and fault-tolerance analysis of stochastic FIR filters\n", "abstract": " Stochastic computing utilizes compact arithmetic circuits that can potentially lower the implementation cost in silicon area. In addition, stochastic computing provides inherent fault tolerance at the cost of a less efficient signal encoding. Finite impulse response (FIR) filters are key elements in digital signal processing (DSP) due to their linear phase-frequency response. In this article, we consider the problem of implementing FIR filters using the stochastic approach. Novel stochastic FIR filter designs based on multiplexers are proposed and compared to conventional binary designs implemented using Synopsys tools with a 28-nm cell library. Silicon area, power and maximum clock frequency are obtained to evaluate the throughput per area (TPA) and the energy per operation (EPO). For equivalent filtering performance, the stochastic FIR filters underperform in terms of TPA and EPO compared to the conventional\u00a0\u2026", "num_citations": "29\n", "authors": ["517"]}
{"title": "Reliability modeling of nanoelectronic circuits\n", "abstract": " Reliability and its modeling have become critical issues for nanotechnology-based circuits. This paper considers the use of probabilistic models of unreliable logic gates to estimate the reliability of nanoelectronic circuits and derive fundamental error bounds for logic gates. Two methods are experimentally contrasted with respect to accuracy and computational complexity.", "num_citations": "29\n", "authors": ["517"]}
{"title": "Fault-tolerant architectures for nanoelectronic and quantum devices\n", "abstract": " The progress in CMOS technology has entered the sub-micron realm, and the technology will approach its limits within about 15 years. Already various novel information processing devices, based on quantum mechanical effects at the nanometer scale, have been widely investigated and some have been successfully demonstrated at the circuit level. This advance in nanoelectronic devices has also motivated efforts in the research of nanoelectronic and quantum computer architectures. Due to the components' poor reliabilities, these architectures will have to be robust against device and interconnect failures. In order to avoid power dissipation problems, the components will have to be applied in the quantum mechanical domain, while due to potential problems in interconnects, the components should be locally interconnected only. This dissertation is devoted to pursuing solutions to architectural issues that come up when designing a nanoelectronic computer. It explores the possibility of building viable and reliable computer systems from novel nanoelectronic and quantum devices. In particular, parallel processor architectures that are fault-tolerant and locally-coupled have been researched. Chapter 1 presents an introduction to the issues that play a role in nanoelectronics, in contrast with microelectronics, and discusses implications for nanocomputer architectures. A brief review of the current status in nanoelectronics and recent progress in nanoarchitecture research is presented in Chapter 2. Chapter 3 describes research on fault-tolerant architectures. We review von Neumann's NAND multiplexing technique and extended his study from a\u00a0\u2026", "num_citations": "29\n", "authors": ["517"]}
{"title": "A hardware-efficient logarithmic multiplier with improved accuracy\n", "abstract": " Logarithmic multipliers take the base-2 logarithm of the operands and perform multiplication by only using shift and addition operations. Since computing the logarithm is often an approximate process, some accuracy loss is inevitable in such designs. However, the area, latency, and power consumption can be significantly improved at the cost of accuracy loss. This paper presents a novel method to approximate log 2 N that, unlike the existing approaches, rounds N to its nearest power of two instead of the highest power of two smaller than or equal to N. This approximation technique is then used to design two improved 16\u00d716 logarithmic multipliers that use exact and approximate adders (ILM-EA and ILM-AA, respectively). These multipliers achieve up to 24.42% and 9.82% savings in area and power-delay product, respectively, compared to the state-of-the-art design in the literature with similar accuracy. The\u00a0\u2026", "num_citations": "28\n", "authors": ["517"]}
{"title": "A transistor-level stochastic approach for evaluating the reliability of digital nanometric CMOS circuits\n", "abstract": " Over the last few decades, most quantitative measures of VLSI performance have improved by many orders of magnitude, this has been achieved by the unabated scaling of the sizes of MOSFETs. However, scaling also exacerbates noise and reliability issues, thus posing new challenges in circuit design. Reliability becomes a major concern due to many and often correlated factors, such as parameter variations and soft errors. Existing reliability evaluation tools focus on algorithmic development at the logic level that usually uses a constant error rate for gate failure and thus leads to approximations in the assessment of a VLSI circuit. This paper proposes a more accurate and scalable approach that utilizes a transistor-level stochastic analysis for digital fault modeling. It accounts for very detailed measures, including the probability of failure of individual transistors, the topology of logic gates, timing sequences and\u00a0\u2026", "num_citations": "28\n", "authors": ["517"]}
{"title": "Asynchronous stochastic Boolean networks as gene network models\n", "abstract": " Logical models have widely been used to gain insights into the biological behavior of gene regulatory networks (GRNs). Most logical models assume a synchronous update of the genes' states in a GRN. However, this may not be appropriate, because each gene may require a different period of time for changing its state. In this article, asynchronous stochastic Boolean networks (ASBNs) are proposed for investigating various asynchronous state-updating strategies in a GRN. As in stochastic computation, ASBNs use randomly permutated stochastic sequences to encode probability. Investigated by several stochasticity models, a GRN is considered to be subject to noise and external perturbation. Hence, both stochasticity and asynchronicity are considered in the state evolution of a GRN. As a case study, ASBNs are utilized to investigate the dynamic behavior of a T helper network. It is shown that ASBNs are efficient\u00a0\u2026", "num_citations": "26\n", "authors": ["517"]}
{"title": "A stochastic approach for the reliability evaluation of multi-state systems with dependent components\n", "abstract": " A multi-state system (MSS) employs more than two discrete states to indicate different performance rates. Methods using a universal generating function (UGF) and Monte Carlo (MC) simulation are primary approaches for the reliability analysis of an MSS. However, these approaches incur a large computational overhead because the number of system states increases significantly with the number of components in an MSS. In this paper, stochastic multi-valued (SMV) models are proposed for evaluating the reliability of an MSS with dependent multi-state components (MSCs). The performance rates and their corresponding probabilities of the MSCs are simultaneously encoded in multi-valued non-Bernoulli sequences using permutations of fixed numbers of 1\u202fs and 0\u202fs. The sequences are then processed by logic gates. The effectiveness of the proposed approach is demonstrated via a comparative evaluation of a\u00a0\u2026", "num_citations": "25\n", "authors": ["517"]}
{"title": "Adaptive approximation in arithmetic circuits: A low-power unsigned divider design\n", "abstract": " Many approximate arithmetic circuits have been proposed for high-performance and low-power applications. However, most designs are either hardware-efficient with a low accuracy or very accurate with a limited hardware saving, mostly due to the use of a static approximation. In this paper, an adaptive approximation approach is proposed for the design of a divider. In this design, division is computed by using a reduced-width divider and a shifter by adaptively pruning the input bits. Specifically, for a 2n/n division 2k/k bits are selected starting from the most significant `1' in the dividend/divisor. At the same time, redundant least significant bits (LSBs) are truncated or if the number of remaining LSBs is smaller than 2k for the dividend or k for the divisor, `0's are appended to the LSBs of the input. To avoid overflow, a 2(k + 1)/(k + 1) divider is used to compute the division of the 2k-bit dividend and the k-bit divisor, both\u00a0\u2026", "num_citations": "24\n", "authors": ["517"]}
{"title": "Reliability and criticality analysis of communication networks by stochastic computation\n", "abstract": " Reliability is an important feature in the design and maintenance of a large-scale network. In this article, the reliability of information transmission between a transmitter and a receiver (i.e., a two-terminal network) is considered as a generalized connectivity framework of terminal nodes. As network complexity increases, existing approaches to reliability analysis are encountering significant challenges. In this article, stochastic computational models are presented to efficiently analyze the reliability and criticality of a two-terminal network. Non-Bernoulli sequences with fixed numbers of 1s and 0s are utilized to encode the signal probabilities, and improve computational efficiency and accuracy. Both unidirectional and bidirectional links are considered for the probabilistic information transition process by imperfect links. Imperfect nodes are also modeled by the stochastic model of an imperfect unidirectional link. Non\u00a0\u2026", "num_citations": "24\n", "authors": ["517"]}
{"title": "A fault tolerant NoC architecture using quad-spare mesh topology and dynamic reconfiguration\n", "abstract": " Network-on-Chip (NoC) is widely used as a communication scheme in modern many-core systems. To guarantee the reliability of communication, effective fault tolerant techniques are critical for an NoC. In this paper, a novel fault tolerant architecture employing redundant routers is proposed to maintain the functionality of a network in the presence of failures. This architecture consists of a mesh of 2\u00a0\u00d7\u00a02 router blocks with a spare router placed in the center of each block. This spare router provides a viable alternative when a router fails in a block. The proposed fault-tolerant architecture is therefore referred to as a quad-spare mesh. The quad-spare mesh can be dynamically reconfigured by changing control signals without altering the underlying topology. This dynamic reconfiguration and its corresponding routing algorithm are demonstrated in detail. Since the topology after reconfiguration is consistent with the\u00a0\u2026", "num_citations": "24\n", "authors": ["517"]}
{"title": "Approximate arithmetic circuits: A survey, characterization, and recent applications\n", "abstract": " Approximate computing has emerged as a new paradigm for high-performance and energy-efficient design of circuits and systems. For the many approximate arithmetic circuits proposed, it has become critical to understand a design or approximation technique for a specific application to improve performance and energy efficiency with a minimal loss in accuracy. This article aims to provide a comprehensive survey and a comparative evaluation of recently developed approximate arithmetic circuits under different design constraints. Specifically, approximate adders, multipliers, and dividers are synthesized and characterized under optimizations for performance and area. The error and circuit characteristics are then generalized for different classes of designs. The applications of these circuits in image processing and deep neural networks indicate that the circuits with lower error rates or error biases perform better in\u00a0\u2026", "num_citations": "23\n", "authors": ["517"]}
{"title": "Majority-based spin-CMOS primitives for approximate computing\n", "abstract": " Promising for digital signal processing applications, approximate computing has been extensively considered to tradeoff limited accuracy for improvements in other circuit metrics such as area, power, and performance. In this paper, approximate arithmetic circuits are proposed by using emerging nanoscale spintronic devices. Leveraging the intrinsic current-mode thresholding operation of spintronic devices, we initially present a hybrid spin-CMOS majority gate design based on a composite spintronic device structure consisting of a magnetic domain wall motion stripe and a magnetic tunnel junction. We further propose a compact and energy-efficient accuracy-configurable adder design based on the majority gate. Unlike most previous approximate circuit designs that hardwire a constant degree of approximation, this design is adaptive to the inherent resilience in various applications to different degrees of accuracy\u00a0\u2026", "num_citations": "23\n", "authors": ["517"]}
{"title": "Toward energy-efficient stochastic circuits using parallel Sobol sequences\n", "abstract": " Stochastic computing (SC) often requires long stochastic sequences and, thus, a long latency to achieve accurate computation. The long latency leads to an inferior performance and low energy efficiency compared with most conventional binary designs. In this paper, a type of low-discrepancy sequences, the Sobol sequence, is considered for use in SC. Compared to the use of pseudorandom sequences generated by linear feedback shift registers (LFSRs), the use of Sobol sequences improves the accuracy of stochastic computation with a reduced sequence length. The inherent feature in Sobol sequence generators enables the parallel implementation of random number generators with an improved performance and hardware efficiency. In particular, the underlying theory is formulated and circuit design is proposed for an arbitrary level of parallelization in a power of 2. In addition, different strategies are\u00a0\u2026", "num_citations": "23\n", "authors": ["517"]}
{"title": "Algorithm and design of a fully parallel approximate coordinate rotation digital computer (CORDIC)\n", "abstract": " This paper proposes a new approximate scheme for coordinate rotation digital computer (CORDIC) design. This scheme is based on modifying the existing Para-CORDIC architecture with an approximation that is inserted in multiple parts and made possible by relaxing the CORDIC algorithm itself. A fully parallel approximate CORDIC (FPAX-CORDIC) scheme is proposed. This scheme avoids the memory register of Para-CORDIC and makes the generation of the rotation direction fully parallel. A comprehensive analysis and the evaluation of the error introduced by the approximation together with different circuit-related metrics are pursued using HSPICE as the simulation tool. This error analysis also combines existing figures of merit for approximate computing (such as the Mean Error Distance (MED) and MED Power Product (MPP)) with CORDIC specific parameters. It is shown that a good agreement between\u00a0\u2026", "num_citations": "22\n", "authors": ["517"]}
{"title": "A multi-objective model oriented mapping approach for NoC-based computing systems\n", "abstract": " In this paper, a multi-objective, i.e., reliability, communication energy, performance, co-optimization model oriented mapping approach is proposed to find optimal mappings when applications are mapped onto network-on-chip (NoC) based reconfigurable architectures. A co-optimization model, defined as reliability efficiency model (REM), is developed to evaluate the overall reliability efficiency of a mapping. In REM, reliability efficiency is defined as the reliability profit at the same energy latency product. Based on REM, a mapping approach, referred to as priority and compensation factor oriented branch and bound (PCBB), is introduced to figure out the best mapping pattern. Two techniques, priority allocation and compensation factor utilization, are adopted to make a tradeoff between search efficiency and accuracy. Experimental results show that the proposed approach has three major contributions compared to\u00a0\u2026", "num_citations": "22\n", "authors": ["517"]}
{"title": "Stochastic circuit design and performance evaluation of vector quantization for different error measures\n", "abstract": " Vector quantization (VQ) is a general data compression technique that has a scalable implementation complexity and potentially a high compression ratio. In this paper, a novel implementation of VQ using stochastic circuits is proposed and its performance is evaluated against conventional binary designs. The stochastic and binary designs are compared for the same compression quality, and the circuits are synthesized for an industrial 28-nm cell library. The effects of varying the sequence length of the stochastic representation are studied with respect to throughput per area (TPA) and energy per operation (EPO). The stochastic implementations are shown to have higher EPOs than the conventional binary implementations due to longer latencies. When a shorter encoding sequence with 512 bits is used to obtain a lower quality compression measured by the L 1 -norm, squared L 2 -norm, and third-law errors, the\u00a0\u2026", "num_citations": "21\n", "authors": ["517"]}
{"title": "Identification of potential drug targets in cancer signaling pathways using stochastic logical models\n", "abstract": " The investigation of vulnerable components in a signaling pathway can contribute to development of drug therapy addressing aberrations in that pathway. Here, an original signaling pathway is derived from the published literature on breast cancer models. New stochastic logical models are then developed to analyze the vulnerability of the components in multiple signalling sub-pathways involved in this signaling cascade. The computational results are consistent with the experimental results, where the selected proteins were silenced using specific siRNAs and the viability of the cells were analyzed 72 hours after silencing. The genes elF4E and NFkB are found to have nearly no effect on the relative cell viability and the genes JAK2, Stat3, S6K, JUN, FOS, Myc, and Mcl1 are effective candidates to influence the relative cell growth. The vulnerabilities of some targets such as Myc and S6K are found to vary\u00a0\u2026", "num_citations": "21\n", "authors": ["517"]}
{"title": "Design, evaluation and application of approximate high-radix dividers\n", "abstract": " Approximate high radix dividers (HR-AXDs) are proposed and investigated in this paper. High-radix division is reviewed and inexact computing is introduced at different levels. Design parameters such as number of bits (N) and radix (r) are considered in the analysis; the replacement of exact cells with inexact cells in a binary signed-digit adder is introduced by utilizing different replacement schemes. Cell truncation and error compensation are also proposed to further extend inexact computation. Circuit-level performance and the error characteristics of the inexact high radix dividers are analyzed for the proposed designs. The combined assessment of the normal error distance, power dissipation, and delay is investigated and applications of approximate high-radix dividers are treated in detail. The simulation results show that the proposed approximate dividers offer extensive saving in terms of power dissipation\u00a0\u2026", "num_citations": "20\n", "authors": ["517"]}
{"title": "Reliability evaluation of phased-mission systems using stochastic computation\n", "abstract": " A phased-mission system (PMS) usually consists of several nonoverlapping phases of tasks. All phases are required to be accomplished sequentially for a successful mission. Different features must be considered in the reliability evaluation of a PMS, including the dependence among the phases with respect to a common component and the different system topologies for the phases. To overcome the limitation of existing approaches, a stochastic computational approach is proposed for efficiently analyzing the reliability of a nonrepairable PMS. Stochastic logic models are proposed to analyze the common components in the different phases. In the stochastic analysis, the signal probabilities of the basic components are encoded as non-Bernoulli sequences of random permutations with fixed numbers of 1s and 0s. Thus, the proposed stochastic approach can be used to evaluate a PMS under any distribution. Based\u00a0\u2026", "num_citations": "20\n", "authors": ["517"]}
{"title": "Macromodeling a phase change memory (PCM) cell by HSPICE\n", "abstract": " This paper presents a HSPICE macromodel of a phase change memory (PCM) cell. The model simulates not only the resistance change by phase (as corresponding to the two states, amorphous and crystalline), but also the temperature profile, the crystalline fraction during the programming and the drift behavior in resistance and threshold voltage. The proposed macromodel (consisting of two models) generates the IV and RI plots of a PCM cell at a very small error compared with experimental data. The electrical-based modeling by HSPICE allows to fully characterize the holding voltage and the continuous behavior of the PCM resistance, while assessing the impact of the programming time. Furthermore, the proposed model takes into account the drift behavior of few parameters when the PCM is not been programmed or read, making the model more realistic. Selection of the parameters is based on operational\u00a0\u2026", "num_citations": "20\n", "authors": ["517"]}
{"title": "Scalable construction of approximate multipliers with formally guaranteed worst case error\n", "abstract": " Approximate computing exploits the fact that many applications are inherently error resilient. In order to reduce power consumption, approximate circuits such as multipliers have been employed in these applications. However, most current approximate multipliers are based on ad hoc circuit structures and, for automated circuit approximation methods, large efficient designs are difficult to find due to the increased search space. Moreover, existing design methods do not typically provide sufficient formal guarantees in terms of error if large approximate multipliers are constructed. To address these challenges, this brief introduces a general and efficient method for constructing large high-quality approximate multipliers with respect to the objectives formulated in terms of the power-delay product and a provable error bound. This is demonstrated by means of a comparative evaluation of approximate 16-bit multipliers\u00a0\u2026", "num_citations": "19\n", "authors": ["517"]}
{"title": "Stochastic analysis of multiplex Boolean networks for understanding epidemic propagation\n", "abstract": " Many large systems are not isolated but rather an integration of several parallel systems, referred to as multiplex networks. Aiming to improve the evaluation efficiency of a simulation-based approach, stochastic computational models are proposed for multiplex Boolean networks with non-Bernoulli sequences encoding signal probabilities. Then, the epidemic spreading process consisting of awareness diffusion on the virtual contact layer and epidemic spreading via physical contacts, is further considered. Given the impacts of nodes in the virtual contact layer, several benchmarks are used to test the average infection probability. The computational results indicate that a node with a larger spreading degree is likely to be an effective target for affecting the average infection probability, which extends the scope of existing observations, although the network topology also plays an important role in determining the\u00a0\u2026", "num_citations": "19\n", "authors": ["517"]}
{"title": "Design of approximate high-radix dividers by inexact binary signed-digit addition\n", "abstract": " Approximate high radix dividers (HR-AXDs) are proposed and investigated in this paper. High-radix division is reviewed and inexact computing is introduced at different levels. Design parameters such as number of bits (N) and radix (r) are considered in the analysis; the replacement schemes with inexact cells and truncation schemes of exact cells in the binary signed-digit adder array is introduced. Circuit-level performance and the error characteristics of the inexact high radix dividers are analyzed for the proposed designs. The combined assessment of the normal error distance, power dissipation and delay is investigated and applications of approximate high-radix dividers are treated in detail. The simulation results show that the proposed approximate dividers offer extensive saving in terms of power dissipation, circuit complexity and delay, while only incurring in a small degradation in accuracy thus making them\u00a0\u2026", "num_citations": "19\n", "authors": ["517"]}
{"title": "A memristor-based tcam (ternary content addressable memory) cell\n", "abstract": " This paper presents a Ternary Content Addressable Memory (TCAM) cell that employs memristors as storage element. The TCAM cell requires two memristors in series to perform the traditional memory operations (read and write) as well as the search and matching operations for TCAM; this memory cell is analyzed with respect to different features (such as memristance range and voltage threshold) of the memristors to process fast and efficiently the ternary data. A comprehensive simulation based assessment of this cell is pursued by HSPICE. Comparison with other memristor-based CAMs as well as CMOS-based TCAMs shows that the proposed cell offers significant advantages in terms of power dissipation, reduced transistor count and search/match operation performance.", "num_citations": "19\n", "authors": ["517"]}
{"title": "Gradient descent using stochastic circuits for efficient training of learning machines\n", "abstract": " Gradient descent (GD) is a widely used optimization algorithm in machine learning. In this paper, a novel stochastic computing GD circuit (SC-GDC) is proposed by encoding the gradient information in stochastic sequences. Inspired by the structure of a neuron, a stochastic integrator is used to optimize the weights in a learning machine by its \u201cinhibitory\u201d and \u201cexcitatory\u201d inputs. Specifically, two AND (or XNOR) gates for the unipolar representation (or the bipolar representation) and one stochastic integrator are, respectively, used to implement the multiplications and accumulations in a GD algorithm. Thus, the SC-GDC is very area- and power-efficient. As per the formulation of the proposed SC-GDC, it provides unbiased estimate of the optimized weights in a learning algorithm. The proposed SC-GDC is then used to implement a least-mean-square algorithm and a softmax regression. With a similar accuracy, the proposed\u00a0\u2026", "num_citations": "18\n", "authors": ["517"]}
{"title": "On quantum and classical computing with arrays of superconducting persistent current qubits\n", "abstract": " A superconducting qubit (or quantum bit), which consists of a micrometer-sized loop with three or four Josephson junctions, has two persistent currents of opposite direction as its two states. The states of the qubits, manipulated with magnetic fields and measured with a SQUID, can be brought into quantum coherence to perform quantum computing. Classical bits can also be obtained from these superconducting loops by increasing its critical current, making it possible to base a processor array architecture on these cubits (quantum bits used in a classical way). Such a classical computer might also serve as pre and post processor for the quantum computing performed in the heart of the array. Because classical and quantum computing based on the same device can be studied now simultaneously, architecture of arrays of qubits and cubits seems a good vehicle for studying the quantum computer paradigm\u00a0\u2026", "num_citations": "18\n", "authors": ["517"]}
{"title": "An improved logarithmic multiplier for energy-efficient neural computing\n", "abstract": " Multiplication is the most resource-hungry operation in neural networks (NNs). Logarithmic multipliers (LMs) simplify multiplication to shift and addition operations and thus reduce the energy consumption. Since implementing the logarithm in a compact circuit often introduces approximation, some accuracy loss is inevitable in LMs. However, this inaccuracy accords with the inherent error tolerance of NNs and their associated applications. This article proposes an improved logarithmic multiplier (ILM) that, unlike existing designs, rounds both inputs to their nearest powers of two by using a proposed nearest-one detector (NOD) circuit. Considering that the output of the NOD uses a one-hot representation, some entries in the truth table of a conventional adder cannot occur. Hence, a compact adder is designed for the reduced truth table. The 8x8 ILM achieves up to 17.48 percent saving in power consumption compared\u00a0\u2026", "num_citations": "17\n", "authors": ["517"]}
{"title": "Approximate arithmetic circuits: Design and evaluation\n", "abstract": " Arithmetic circuits are important computing modules in a processor. They play a key role in the performance and the energy consumption of many image processing applications. In this chapter, a classification is presented for the current designs of approximate arithmetic circuits including adders, multipliers, and dividers. To understand the features of various designs, a comparative evaluation of their error and circuit characteristics is performed. The accuracy of approximate arithmetic circuits is evaluated by carrying out Monte Carlo simulations. The circuit measurements are assessed by synthesizing approximate designs in an STM CMOS 28 nm process. The simulation and synthesis results show the trade-offs of approximate arithmetic circuits between accuracy and hardware efficiency.", "num_citations": "17\n", "authors": ["517"]}
{"title": "Feedback-based low-power soft-error-tolerant design for dual-modular redundancy\n", "abstract": " Triple-modular redundancy (TMR), which consists of three identical modules and a voting circuit, is a common architecture for soft-error tolerance. However, the original TMR suffers from two major drawbacks: the large area overhead and the vulnerability of the voter. In order to overcome these drawbacks, we propose a new complementary dual-modular redundancy (CDMR) scheme for mitigating the effect of soft errors. Inspired by the Markov random field (MRF) theory, a two-stage voting system is implemented in CDMR, including a first-stage optimal MRF structure and a second-stage high-performance merging unit. The CDMR scheme can reduce the voting circuit area by 20% while saving the area of one redundant module, achieving at least 26% error-rate reduction at an ultralow supply voltage of 0.25 V with 8.33% faster timing compared to previous voter designs.", "num_citations": "17\n", "authors": ["517"]}
{"title": "A flexible energy-and reliability-aware application mapping for NoC-based reconfigurable architectures\n", "abstract": " This paper proposes a flexible energy- and reliability-aware application mapping approach for network-on-chip (NoC)-based reconfigurable architecture. A parameterized cost model is first developed by combining energy and reliability with a weight parameter that defines the optimization priority. Using this model, the overall mapping cost could be evaluated. Subsequently, a mapping method using branch and bound with a partial cost ratio is employed to find the best mapping by enumerating all the possible patterns organized in a search tree. To improve the search efficiency, nonoptimal mappings are discarded at early stages using the partial cost ratio. Using the proposed approach, applications can be mapped onto most NoC topologies and running with various routing algorithms when considering both energy and reliability. Other state-of-the-art works have also done substantial research for the same topic\u00a0\u2026", "num_citations": "17\n", "authors": ["517"]}
{"title": "From massively parallel image processors to fault-tolerant nanocomputers\n", "abstract": " Parallel processors such as SIMD computers have been successfully used in various areas of high performance image and data processing. Due to their characteristics of highly regular structures and mainly local interconnections, SIMD or SIMD-like architectures have been proposed for a large-scale integration of recently developed quantum and nanoelectronic devices. In this paper, we present a fault-tolerant technique suitable for an implementation in nanoelectronics, the triplicated interwoven redundancy (TIR). The TIR is a general class of triple modular redundancy (TMR), but implemented with random interconnections. A prototype structure for an image processor is proposed for the implementation of the TIR technique and a simulation based reliability model is used to investigate its fault-tolerance. The TIR is extended to higher orders, namely, the N-tuple interwoven redundancy (NIR), to achieve higher\u00a0\u2026", "num_citations": "17\n", "authors": ["517"]}
{"title": "A survey of stochastic computing neural networks for machine learning applications\n", "abstract": " Neural networks (NNs) are effective machine learning models that require significant hardware and energy consumption in their computing process. To implement NNs, stochastic computing (SC) has been proposed to achieve a tradeoff between hardware efficiency and computing performance. In an SC NN, hardware requirements and power consumption are significantly reduced by moderately sacrificing the inference accuracy and computation speed. With recent developments in SC techniques, however, the performance of SC NNs has substantially been improved, making it comparable with conventional binary designs yet by utilizing less hardware. In this article, we begin with the design of a basic SC neuron and then survey different types of SC NNs, including multilayer perceptrons, deep belief networks, convolutional NNs, and recurrent NNs. Recent progress in SC designs that further improve the hardware\u00a0\u2026", "num_citations": "16\n", "authors": ["517"]}
{"title": "A stochastic-computing based deep learning framework using adiabatic quantum-flux-parametron superconducting technology\n", "abstract": " The Adiabatic Quantum-Flux-Parametron (AQFP) superconducting technology has been recently developed, which achieves the highest energy efficiency among superconducting logic families, potentially 10 4 -10 5  gain compared with state-of-the-art CMOS. In 2016, the successful fabrication and testing of AQFP-based circuits with the scale of 83,000 JJs have demonstrated the scalability and potential of implementing large-scale systems using AQFP. As a result, it will be promising for AQFP in high-performance computing and deep space applications, with Deep Neural Network (DNN) inference acceleration as an important example. Besides ultra-high energy efficiency, AQFP exhibits two unique characteristics: the deep pipelining nature since each AQFP logic gate is connected with an AC clock signal, which increases the difficulty to avoid RAW hazards; the second is the unique opportunity of true random\u00a0\u2026", "num_citations": "15\n", "authors": ["517"]}
{"title": "An area and energy efficient design of domain-wall memory-based deep convolutional neural networks using stochastic computing\n", "abstract": " With recent trend of wearable devices and Internet of Things (IoTs), it becomes attractive to develop hardware-based deep convolutional neural networks (DCNNs) for embedded applications, which require low power/energy consumptions and small hardware footprints. Recent works demonstrated that the Stochastic Computing (SC) technique can radically simplify the hardware implementation of arithmetic units and has the potential to satisfy the stringent power requirements in embedded devices. However, in these works, the memory design optimization is neglected for weight storage, which will inevitably result in large hardware cost. Moreover, if conventional volatile SRAM or DRAM cells are utilized for weight storage, the weights need to be re-initialized whenever the DCNN platform is re-started. In order to overcome these limitations, in this work we adopt an emerging non-volatile Domain-Wall Memory (DWM\u00a0\u2026", "num_citations": "15\n", "authors": ["517"]}
{"title": "A stochastic computational approach for the analysis of fuzzy systems\n", "abstract": " Fault tree analysis (FTA) has been widely utilized as a reliability evaluation technique for complex systems, such as nuclear power plants and aerospace systems. However, it is hard to obtain the crisp failure probabilities of basic events, owning to the insufficient information about some complex engineering systems. Hence, fuzzy set theory and fuzzy arithmetic operation (FAO) have been used as effective methods to analyze system reliability. However, it is cumbersome to evaluate complex systems based on FAO. To improve the evaluation efficiency, stochastic computational models are proposed in this paper to perform reliability analysis of a fuzzy system. Due to the features of Gaussian distribution in stochastic computation, a basic event's failure possibility given by a fuzzy number is transformed into the expected value of it. The standard deviation of stochastic computational results gives the spread of the fuzzy\u00a0\u2026", "num_citations": "15\n", "authors": ["517"]}
{"title": "Two approximate voting schemes for reliable computing\n", "abstract": " This paper relies on the principles of inexact computing to alleviate the issues arising in static masking by voting for reliable computing in the nanoscales. Two schemes that utilize in different manners approximate voting, are proposed. The first scheme is referred to as inexact double modular redundancy (IDMR). IDMR does not resort to triplication, thus saving overhead due to modular replication. This scheme is crudely adaptive in its operation, i.e., it allows a threshold to determine the validity of the module outputs. IDMR operates by initially establishing the difference between the values of the outputs of the two modules; only if the difference is below a preset threshold, then the voter calculates the average value of the two module outputs. The second scheme (ITDMR) combines IDMR with TMR (triple modular redundancy) by using novel conditions in the comparison of the outputs of the three modules. Within an\u00a0\u2026", "num_citations": "15\n", "authors": ["517"]}
{"title": "A 6.0\u201313.5 GHz alias-locked loop frequency synthesizer in 130 nm CMOS\n", "abstract": " A 6.0-13.5 GHz alias-locked loop (ALL) frequency synthesizer is designed and simulated in 130 nm CMOS. Using an aliasing divider, the ALL architecture makes it possible to create high-speed frequency synthesis circuits without relying on a traditional divider clocked at  fVCO  in the feedback path. In this implementation, a new architecture of high frequency ring oscillator is proposed with a feedforward path and selectable modes of operation for different frequency ranges. This ring oscillator provides both a high oscillating frequency and a wide tuning range. Simulation results have shown that the design synthesizes the desired frequencies and consumes 30.01 mW @ 13.0 GHz with a 1.2 V power supply.", "num_citations": "15\n", "authors": ["517"]}
{"title": "An energy-efficient and noise-tolerant recurrent neural network using stochastic computing\n", "abstract": " Recurrent neural networks (RNNs) are widely used to solve a large class of recognition problems, including prediction, machine translation, and speech recognition. The hardware implementation of RNNs is, however, challenging due to the high area and energy consumption of these networks. Recently, stochastic computing (SC) has been considered for implementing neural networks and reducing the hardware consumption. In this paper, we propose an energy-efficient and noise-tolerant long short-term memory-based RNN using SC. In this SC-RNN, a hybrid structure is developed by utilizing SC designs and binary circuits to improve the hardware efficiency without significant loss of accuracy. The area and energy consumption of the proposed design are between 1.6%-2.3% and 6.5%-11.2%, respectively, of a 32-bit floating-point (FP) implementation. The SC-RNN requires significantly smaller area and lower\u00a0\u2026", "num_citations": "14\n", "authors": ["517"]}
{"title": "An energy-efficient online-learning stochastic computational deep belief network\n", "abstract": " Deep neural networks (DNNs) are effective machine learning models to solve a large class of recognition problems, including the classification of nonlinearly separable patterns. The training of DNNs is, however, particularly difficult due to the large size and high energy consumption of the networks. Recently, stochastic computation (SC) has been considered to implement DNNs to reduce the hardware cost. However, it requires a large number of random number generators (RNGs) and long stochastic sequences that lower the energy efficiency of the network. To overcome these limitations, we propose the design of an energy-efficient deep belief network (DBN) with online learning capacity based on stochastic computation. In the SC-DBN, a reconfigurable structure is utilized to implement the fast greedy learning algorithm and an adaptive moment estimation (ADAM) circuit is designed to improve the speed of the\u00a0\u2026", "num_citations": "14\n", "authors": ["517"]}
{"title": "Introduction to approximate computing\n", "abstract": " Approximate computing has emerged as a new paradigm for energy-efficient design of circuits and systems. This paper presents a brief introduction to approximate computing as well as to the challenges faced by approximate computing with respect to its prospects for applications in energy-efficient and error-resilient computing systems.", "num_citations": "14\n", "authors": ["517"]}
{"title": "Matrix multiplication by an inexact systolic array\n", "abstract": " Different schemes for approximate computing of matrix multiplication (MM) in systolic arrays are presented in this manuscript. Inexact full adder cells are utilized in a processing element (PE) for the Baugh-Wooley multiplier and/or the final adder as circuits implementing the two computational steps required for MM. An extensive analysis and simulation-based assessment of three inexact schemes for the PE are pursued with respect to circuit level performance (such as delay, power consumption and number of transistors) and figures of merit of approximate computing (such as the error distance). The execution of MM in each PE results in an inexact computation affecting only the outputs of the same columns, so the extension of inexact computation to a systolic array can also be performed with very limited error. The discrete cosine transform as application of the proposed inexact systolic arrays, is evaluated\u00a0\u2026", "num_citations": "14\n", "authors": ["517"]}
{"title": "Gene perturbation and intervention in context-sensitive stochastic Boolean networks\n", "abstract": " In a gene regulatory network (GRN), gene expressions are affected by noise, and stochastic fluctuations exist in the interactions among genes. These stochastic interactions are context dependent, thus it becomes important to consider noise in a context-sensitive manner in a network model. As a logical model, context-sensitive probabilistic Boolean networks (CSPBNs) account for molecular and genetic noise in the temporal context of gene functions. In a CSPBN with n genes and k contexts, however, a computational complexity of O(nk 222n ) (or O(nk 2                     n                   )) is required for an accurate (or approximate) computation of the state transition matrix (STM) of the size (2                     n                    \u2219 k) \u00d7 (2                     n                    \u2219 k) (or 2                     n                    \u00d7 2                     n                   ). The evaluation of a steady state distribution (SSD) is more challenging. Recently, stochastic Boolean networks (SBNs\u00a0\u2026", "num_citations": "14\n", "authors": ["517"]}
{"title": "Design and evaluation of a hybrid memory cell by single-electron transfer\n", "abstract": " This paper presents the characterization and design of a static random access memory (SRAM) cell at nanoscale ranges. The proposed SRAM cell incorporates a single-electron (SE) turnstile and an SE transistor/MOS circuit in its operation, hence the hybrid nature. Differently from previous cells, the hybrid circuit is utilized to sense (measure) on a voltage basis the presence of at least an electron as stored in memory, while the turnstile enables the SE transfer in and out of the storage node. The two memory operations (read and write) are facilitated by utilizing these hybrid circuits; moreover, the proposed SRAM cell shows compatibility with MOSFET technology. HSPICE simulation shows that the proposed SRAM cell operates correctly at 45 and 32 nm with good performance in terms of propagation delay, signal integrity, area, stability, and power consumption. The extension of the aforementioned hybrid design to a\u00a0\u2026", "num_citations": "14\n", "authors": ["517"]}
{"title": "An energy-efficient stochastic computational deep belief network\n", "abstract": " Deep neural networks (DNNs) are effective machine learning models to solve a large class of recognition problems, including the classification of nonlinearly separable patterns. The applications of DNNs are, however, limited by the large size and high energy consumption of the networks. Recently, stochastic computation (SC) has been considered to implement DNNs to reduce the hardware cost. However, it requires a large number of random number generators (RNGs) that lower the energy efficiency of the network. To overcome these limitations, we propose the design of an energy-efficient deep belief network (DBN) based on stochastic computation. An approximate SC activation unit (A-SCAU) is designed to implement different types of activation functions in the neurons. The A-SCAU is immune to signal correlations, so the RNGs can be shared among all neurons in the same layer with no accuracy loss. The\u00a0\u2026", "num_citations": "13\n", "authors": ["517"]}
{"title": "A multi-accuracy-level approximate memory architecture based on data significance analysis\n", "abstract": " Approximate memory is a promising technology for emerging recognition, mining and vision applications. These applications require the processing of large volumes of data to achieve energy-efficiency with negligible accuracy loss. This paper proposes a multi-level approximate memory architecture based on data significance analysis. In this architecture, a memory array is divided into several separated banks with different predefined accuracy levels. A key novelty of this work is the design of a memory controller that distributes data to the memory banks according to the results of data significance analysis. When applied to a DCT (Discrete Cosine Transform) processing module, the proposed approximate memory controller can achieve over 60% power saving with onchip memory model of multiple supply voltage SRAM banks, at the cost of a marginal output PSNR (Peak Signal to Noise Ratio) degradation of 3.34\u00a0\u2026", "num_citations": "13\n", "authors": ["517"]}
{"title": "Design and reliability analysis of multiple valued logic gates using carbon nanotube FETs\n", "abstract": " With emerging nanometric technologies, multiple valued logic (MVL) circuits have attracted significant attention due to advantages in information density and operating speed. In this paper, a pseudo complementary MVL design is initially proposed for implementations using carbon nanotube field effect transistors (CNTFETs). This design utilizes no resistors in its operation. To account for the properties and fabrication non-idealities of CNTFETs, a transistor-level reliability analysis is proposed to accurately estimate the error rates of MVL gates. This approach considers gate structures and their operation, so it yields a more realistic framework than a logic-level analysis of reliability. To achieve scalability, stochastic computational models are developed to accurately and efficiently analyze MVL gates; the extension of these models to circuits is briefly discussed.", "num_citations": "13\n", "authors": ["517"]}
{"title": "Logic-in-memory with a nonvolatile programmable metallization cell\n", "abstract": " This paper introduces two new cells for logic-in-memory (LiM) operation. The first novelty of these cells is the resistive random access memory configuration that utilizes a programmable metallization cell as nonvolatile element. CMOS transistors and ambipolar transistors are used as processing and control elements for the logic operations of the LiM cells. The first cell employs ambipolar transistors and CMOS in its logic circuit (7T2A1P), while the second LiM cell uses only MOSFETs (9T1P) to implement logic functions, such as AND, OR, and XOR. The operational mode of the proposed cells is voltage-based, which is much different from the previous designs in which a LiM cell operates on a current mode. Extensive simulation results using HSPICE are provided for the evaluation of these cells; comparison shows that the proposed two cells outperform previous LiM cells in metrics, such as logic operation delays\u00a0\u2026", "num_citations": "12\n", "authors": ["517"]}
{"title": "Cell design and comparative evaluation of a novel 1T memristor-based memory\n", "abstract": " CMOS is expected to soon meet the end of the Semiconductor Industry Technology Roadmap. This paper investigates the memristor as a post-CMOS component for memory design. The proposed cell requires one transistor and one memristor (i.e. 1T1M); this cell employs novel read and write mechanisms for improved performance. Initially, it is shown that differently from previous designs, the proposed scheme accomplishes a read operation that does not affect the memory state; this cell is assessed with respect to different parameters as related to its design (such as applied write voltage, memristor range and size). It is shown that at array-level, the write operation may still incur in a state change due to voltage degradation. A detailed assessment of the relationship between a linear array size (as dimension of a square memory array) and the cell parameters, is pursued. Moreover, a comparison with a DRAM cell (i\u00a0\u2026", "num_citations": "12\n", "authors": ["517"]}
{"title": "Analysis of error masking and restoring properties of sequential circuits\n", "abstract": " Scaling of CMOS technology into nanometric feature sizes has raised concerns for the reliable operation of logic circuits, such as in the presence of soft errors. This paper deals with the analysis of the operation of sequential circuits. As the feedback signals in a sequential circuit can be logically masked by specific combinations of primary inputs, the cumulative effects of soft errors can be eliminated. This phenomenon, referred to as error masking, is related to the presence of so-called restoring inputs and/or the consecutive presence of specific inputs in multiple clock cycles (equivalent to a synchronizing sequence in switching theory). In this paper, error masking is extensively analyzed using the operations of state transition matrices (STMs) and binary decision diagrams (BDDs) of a finite state machine (FSM) model. The characteristics of state transitions with respect to correlations between the restoring inputs and\u00a0\u2026", "num_citations": "12\n", "authors": ["517"]}
{"title": "A fault-tolerant technique for nanocomputers: NAND multiplexing\n", "abstract": " In order to make systems based on nanometerscale devices reliable, the design of fault-tolerant architectures will be necessary. This paper presents a novel fault-tolerant technique for future nanocomputers, NAND multiplexing. Initiated by von Neumann, the NAND multiplexing technique, based on a massive duplication of imperfect devices and randomized imperfect interconnect, had been studied with an extreme high degree of redundancy (A 4333). In this paper, the NAND multiplexing is extended to rather low degree of redundancy, leading it to a comprehensive fault-tolerant theory. The stochastic Markov nature in the heart of the system is discovered, and the characteristics of such a Markov chain are exploited. This fault-tolerant technique is potentially useful for future nanoelectronics.", "num_citations": "12\n", "authors": ["517"]}
{"title": "High performance CNN accelerators based on hardware and algorithm co-optimization\n", "abstract": " Convolutional neural networks (CNNs) have been widely used in image classification and recognition due to their effectiveness; however, CNNs use a large volume of weight data that is difficult to store in on-chip memory of embedded designs. Pruning can compress the CNN model at a small accuracy loss; however, a pruned CNN model operates slower when implemented on a parallel architecture. In this paper, a hardware-oriented CNN compression strategy is proposed; a deep neural network (DNN) model is divided into \u201cno-pruning layers (   -layers)\u201d and \u201cpruning layers (   -layers)\u201d. A    -layer has a regular weights distribution for parallel computing and high performance. A    -layer is irregular due to pruning, but it generates a high compression ratio. Uniform and incremental quantization schemes are used to achieve a tradeoff between compression ratio and processing efficiency at a small loss in accuracy. A\u00a0\u2026", "num_citations": "11\n", "authors": ["517"]}
{"title": "Low-power unsigned divider and square root circuit designs using adaptive approximation\n", "abstract": " In this paper, an adaptive approximation approach is proposed for the design of a divider and a square root (SQR) circuit. In this design, the division/SQR is computed by using a reduced-width divider/SQR circuit and a shifter by adaptively pruning some insignificant input bits. Specifically, for a 2n/n division, 2k and k (k <; n) consecutive bits are selected starting from the most significant `1' in the dividend and divisor, respectively. At the same time, redundant least significant bits (LSBs) are truncated or if the number of remaining bits after pruning is smallerthan the number of bits to be kept, `0's are appended to the LSBs of the inputs. To avoid overflow, a 2(k + 1)/(k + 1) divider is used to compute the 2k/k division. Finally, an error correction circuit is proposed to recover the error caused by the shifter using OR gates. For a 2n-bit approximate SQR circuit, similar pruning schemes are used to obtain a 2k-bit radicand. A 2k\u00a0\u2026", "num_citations": "11\n", "authors": ["517"]}
{"title": "Characterizing approximate adders and multipliers optimized under different design constraints\n", "abstract": " Taking advantage of the error resilience in many applications as well as the perceptual limitations of humans, numerous approximate arithmetic circuits have been proposed that trade off accuracy for higher speed or lower power in emerging applications that exploit approximate computing. However, characterizing the various approximate designs for a specific application under certain performance constraints becomes a new challenge. In this paper, approximate adders and multipliers are evaluated and compared for a better understanding of their characteristics when the implementations are optimized for performance or power. Although simple truncation can effectively reduce the hardware of an arithmetic circuit, it is shown that some other designs perform better in speed, power and power-delay product. For instance, many approximate adders have a higher performance than a truncated adder. A truncated\u00a0\u2026", "num_citations": "11\n", "authors": ["517"]}
{"title": "A VLSI architecture for enhancing the fault tolerance of NoC using quad-spare mesh topology and dynamic reconfiguration\n", "abstract": " Effective fault tolerant techniques are crucial for a Network-on-Chip (NoC) to achieve reliable communication. In this paper, a novel VLSI architecture employing redundant routers is proposed to enhance the fault tolerance of an NoC. The NoC mesh is divided into blocks of 2\u00d72 routers with a spare router placed in the center. The proposed fault-tolerant architecture, referred to as a quad-spare mesh, can be dynamically reconfigured by changing control signals without altering the underlying topology. This dynamic reconfiguration and its corresponding routing algorithm are demonstrated in detail. Experimental results show that the proposed design achieves significant improvements on reliability compared with those reported in the literature.", "num_citations": "10\n", "authors": ["517"]}
{"title": "On quantum computing with macroscopic Josephson qubits\n", "abstract": " The achievements of quantum computation theory, e.g. Shor's factoring algorithm, motivate efforts to realize quantum computers. Among systems proposed for quantum computing, macroscopic superconducting circuits of Josephson junctions appear promising for integration in electronic circuits and large-scale applications. Recently, a superconducting tunnel junction circuit was designed and a sufficiently high quality factor of quantum coherence has been obtained. This indicates that decoherence need not be among the obstacles in building quantum computers with macroscopic Josephson circuits. In this paper we present the setup of some elementary quantum logic with macroscopic Josephson qubits, strengthened by some simulation work, and then study the feasibility of implementing Shor's quantum factoring algorithm on them. It is shown that it would be eventually possible to build a 2-dimensional\u00a0\u2026", "num_citations": "10\n", "authors": ["517"]}
{"title": "Approximate leading one detector design for a hardware-efficient Mitchell multiplier\n", "abstract": " We propose two approximate leading one detector (LOD) designs and an approximate adder (for summing two logarithms) that can be used to improve the hardware efficiency of the Mitchell logarithmic multiplier. The first LOD design uses a single fixed value to approximate the `d' least significant bits (LSBs). For d=16 this design reduces the hardware cost by 19.91% compared to the conventional 32-bit Mitchell multiplier and by 15.19% when compared to a recent design in the literature. Our design is smaller by 32.33% and more energy-efficient by 56.77% with respect to a conventional Mitchell design. The second design partitions the `d' bits into smaller fields and increases the accuracy by using a multiplexing scheme that selects a closer approximation to the actual input value. This design reduces the hardware cost by 17.98% compared to the original Mitchell multiplier and by 13.15% when compared to the\u00a0\u2026", "num_citations": "9\n", "authors": ["517"]}
{"title": "Variation-resilient true random number generators based on multiple STT-MTJs\n", "abstract": " In the Internet of Things era, security concerns may require a cryptography system in every connected device. True random number generators (TRNGs) are preferred instead of pseudorandom number generators in the cryptography systems to achieve a higher level of security. For on-chip applications, we seek scalable and CMOS-compatible devices and designs for TRNGs. In this paper, the stochastic behavior of the spin transfer torque magnetic tunnel junction (STT-MTJ) is utilized for the source of randomness. However, variations and correlations exist in MTJs due to fabrication limitations, so TRNG designs based on a single MTJ have to be postprocessed or tracked in real time to ensure an acceptable level of randomness. Two novel designs are proposed in this paper, which can produce random sequences with high variation resilience. The first design uses a parallel structure to minimize variation effects\u00a0\u2026", "num_citations": "9\n", "authors": ["517"]}
{"title": "Design and comparative evaluation of a PCM-based CAM (content addressable memory) cell\n", "abstract": " This paper presents the design of a content addressable memory (CAM) cell. This cell utilizes a phase change memory (PCM) as a storage element and an ambipolar transistor for data comparison; the operation of the ambipolar transistor is controlled by voltage at the polarity gate. A memory core consisting of a CMOS transistor and a PCM is employed (1T1P). For the search operation, the data in the 1T1P memory core are read and its values are established by using a differential sense amplifier. The proposed CAM cell is simulated and compared with other nonvolatile CAM cells by using emerging technologies (such as MTJ and memristor). The simulation results show that as the proposed CAM cell operates on a voltage basis, it offers significant advantages in terms of power delay product for the search operation and reduced circuit complexity (in terms of lower transistor and storage element counts) compared\u00a0\u2026", "num_citations": "9\n", "authors": ["517"]}
{"title": "Efficient fault-tolerant topology reconfiguration using a maximum flow algorithm\n", "abstract": " With an increasing number of processing elements (PEs) integrated on a single chip, fault-tolerant techniques are critical to ensure the reliability of such complex systems. In current reconfigurable architectures, redundant PEs are utilized for fault tolerance. In the presence of faulty PEs, the physical topologies of various chips may be different, so the concept of virtual topology from network embedding problem has been used to alleviate the burden for the operating systems. With limited hardware resources, how to reconfigure a system into the most effective virtual topology such that the maximum repair rate can be reached presents a significant challenge. In this article, a new approach using a maximum flow (MF) algorithm is proposed for an efficient topology reconfiguration in reconfigurable architectures. In this approach, topology reconfiguration is converted into a network flow problem by constructing a directed\u00a0\u2026", "num_citations": "9\n", "authors": ["517"]}
{"title": "Minimizing the number of process corner simulations during design verification\n", "abstract": " Integrated circuit designs need to be verified in simulation over a large number of process corners that represent the expected range of transistor properties, supply voltages, and die temperatures. Each process corner can require substantial simulation time. Unfortunately, the required number of corners has been growing rapidly in the latest semiconductor technologies. We consider the problem of minimizing the required number of process corner simulations by iteratively learning a model of the output functions in order to confidently estimate key maximum and/or minimum properties of those functions. Depending on the output function, the required number of corner simulations can be reduced by factors of up to 95%.", "num_citations": "9\n", "authors": ["517"]}
{"title": "A system-level scheme for resistance drift tolerance of a multilevel phase change memory\n", "abstract": " This paper presents a system-level scheme to alleviate the effect of resistance drift in a multilevel phase change memory (PCM) for data integrity. In this paper, novel criteria of separation of the PCM resistance for multilevel cell storage and selection of the threshold resistances between levels are proposed by using a median based method based on a row of PCM cells as reference. The threshold resistances found by the proposed scheme drift with time, thus providing an efficient and viable approach when the number of levels increases. A detailed analysis of the proposed level separation and threshold resistance selection is pursued. The impact of different parameters (such as the write region and the number of cell in a row) is assessed with respect to the generation of the percentage accuracy. The proposed approach results in a substantial improvement in performance compared with existing schemes found in\u00a0\u2026", "num_citations": "9\n", "authors": ["517"]}
{"title": "Design and evaluation of two MTJ-based content addressable non-volatile memory cells\n", "abstract": " This paper proposes two non-volatile content addressable memory (CAM) cells using magnetic tunneling junction (MTJ) devices and nanoscaled CMOS transistors. The first novelty of the proposed non-volatile cells is that their operation and comparison outcome are voltage-based, hence requiring no current sensor. Two types of MTJ CAM cell are proposed; each of them utilizes two MTJs in a voltage divider arrangement. They differ in the number of required transistors, i.e. the first is a NOR type cell requiring six MOSFETs, while the second is a NAND type cell requiring five MOSFETs. Performance metrics (as related to search delay, power dissipation and static noise margin) as well as variation to process, voltage and temperature (PVT) are assessed by simulation at different feature sizes of the MOSFETs. The simulation results show that the proposed designs significantly improve in terms of search delay and\u00a0\u2026", "num_citations": "9\n", "authors": ["517"]}
{"title": "A Study on Fault-Tolerant Circuits Using Redundancy.\n", "abstract": " System reliability has been playing an important role in commercial, aerospace and realMtime systems as well as generalMpurpose computer systems [1]. The use of faultMtolerant techniques has been crucial in the design of reliable systems. Recent development of nanometreMscale electronics has raised the issue of faultMtolerance to future computer systems based on nanometreMscale devices [2]. Due to the manufacturM ing process and external influences, more and more defects and faults will inevitably be brought in with the shrinking of electronic devices. Future nanoelecM tronic systems therefore have to be able to tolerate a large number of faults.FaultMtolerant approaches have been of interest since the commencement of the first generation of elecM tronic computers when computers were constructed from such unreliable components as vacuum tubes. In the 1950s von Neumann initiated the study of usM ing redundant components to obtain reliable synthesis from unreliable components, namely, the multiplexing technique [3]. In his construction, von Neumann conM sidered two sets of basic logic circuits, the Majority", "num_citations": "9\n", "authors": ["517"]}
{"title": "A stochastic analysis of competing failures with propagation effects in functional dependency gates\n", "abstract": " Various dynamic gates have been utilized to model behaviors in dynamic fault trees (DFTs). For the functional dependency relationship among different components, a functional dependency (FDEP) gate models the scenario that the failure of some trigger events may result in the failures of other components. Conventionally, dependent relationships are modeled by an OR gate for systems with a perfect fault coverage. However, this is usually inaccurate, due to the effect of different types of failures, including local and propagated failures. A propagated failure originating from a component may affect the status of other dependent components. However, whether this occurs or not is determined by the failure order of the trigger and dependent events. A conventional DFT analysis incurs a high computational complexity for this scenario. In this article, a stochastic analysis is performed for an FDEP gate under imperfect\u00a0\u2026", "num_citations": "8\n", "authors": ["517"]}
{"title": "Evaluating data resilience in cnns from an approximate memory perspective\n", "abstract": " Due to the large volumes of data that need to be processed, efficient memory access and data transmission are crucial for high-performance implementations of convolutional neural networks (CNNs). Approximate memory is a promising technique to achieve efficient memory access and data transmission in CNN hardware implementations. To assess the feasibility of applying approximate memory techniques, we propose a framework for the data resilience evaluation (DRE) of CNNs and verify its effectiveness on a suite of prevalent CNNs. Simulation results show that a high degree of data resilience exists in these networks. By scaling the bit-width of the first five dominant data subsets, the data volume can be reduced by 80.38% on average with a 2.69% loss in relative prediction accuracy. For approximate memory with random errors, all the synaptic weights can be stored in the approximate part when the error rate\u00a0\u2026", "num_citations": "8\n", "authors": ["517"]}
{"title": "DPALS: A dynamic programming-based algorithm for two-level approximate logic synthesis\n", "abstract": " Approximate circuit design is an emerging paradigm in which a designer deliberately changes the specified Boolean function to reduce area, delay, and/or power consumption of a circuit. This paper focuses on the synthesis of approximate logic circuits (or ALS) under a given error constraint. In particular, we consider ALS for a two-level design under an error rate constraint. A dynamic programming-based algorithm is proposed to find a nearly optimal approximate function by identifying the most promising set of cubes to be added to the on-set of the original function. Then, an off-the-shelf two-level logic synthesis tool is applied to further optimize the sum-of-product (SOP) expression. The experimental results show that the literal reduction is close to the optimal solution when the error rate constraint is tight and that more than 50% literal reduction is achieved for error rate below 0.8% for an 8-bit adder and a square\u00a0\u2026", "num_citations": "8\n", "authors": ["517"]}
{"title": "Design and evaluation of stochastic FIR filters\n", "abstract": " The compact arithmetic units in stochastic computing can potentially lower the implementation cost with respect to silicon area and power consumption. In addition, stochastic computing provides inherent tolerance of transient errors at the cost of a less efficient signal encoding. In this paper, a novel FIR filter design using the stochastic approach based on multiplexers are proposed. The required stochastic sequence length is determined for different signal resolutions by matching the performance of the proposed FIR filter with that of the conventional binary design. Silicon area, power and maximum clock frequency are obtained to evaluate the throughput per area (TPA) and the energy per operation (EPO). For equivalent filtering performance, the stochastic FIR filter underperforms in terms of TPA and EPO compared to the conventional binary design, albeit with some advantages in circuit area and power\u00a0\u2026", "num_citations": "8\n", "authors": ["517"]}
{"title": "Stochastic circuit design and performance evaluation of vector quantization\n", "abstract": " Vector quantization (VQ) is a general data compression technique that has a scalable implementation complexity and potentially a high compression ratio. In this paper, a novel implementation of VQ using stochastic circuits is proposed and its performance is evaluated. The stochastic and binary designs are compared for the same compression quality and the circuits are synthesized for an industrial 28-nm cell library. The effects of varying the sequence length of the stochastic design are studied with respect to the performance metric of throughput per area (TPA). When a shortened 512-bit encoding sequence is used to obtain a lower quality compression, the TPA is about 2.60 times that of the binary implementation with the same quality as that of the stochastic implementation measured by the L 1  norm error (i.e., the first-order error). Thus, the stochastic implementation outperforms the conventional binary design\u00a0\u2026", "num_citations": "8\n", "authors": ["517"]}
{"title": "A memristor-based memory cell with no refresh\n", "abstract": " This paper analyzes and improves the performance of a hybrid memory cell consisting of a memristor and ambipolar transistors. This work extends a previous design by efficiently biasing the memristor (as controlled by the ambipolar transistors), such that no refresh operation is now required. By utilizing macroscopic models, the features of the cell are characterized for the memory operations and no modification is needed to the cell circuit other than the memristor biasing scheme. A detailed treatment of the memory cell with respect to the new biasing scheme of the memristor is provided. Simulation results show that the proposed memory cell has superior performance compared with the previous memristor-based cell.", "num_citations": "8\n", "authors": ["517"]}
{"title": "On the reliable performance of sequential adders for soft computing\n", "abstract": " Addition is a significant operation in soft computing, several sequential adder designs have been proposed in the technical literature. These adders show different operational profiles, some of them are inspired by biological networks or the probabilistic nature of nanometric devices (such as the Lower-part OR Adder (LOA) and the Probabilistic Full Adder (PFA)). This paper deals with the reliability assessment and comparison of these sequential adder implementations. A new metric referred to as the mean error distance (MED) is proposed as a unified figure for evaluating the reliability of both probabilistic and deterministic adders. Reliability is analyzed using the so-called sequential probability transition matrices (S-PTMs) with respect also to error masking (as occurring due to the sequential nature of the addition process). A baseline sequential adder implementation, referred to as the Lower-bit Ignored Adder (LIA\u00a0\u2026", "num_citations": "8\n", "authors": ["517"]}
{"title": "A robust wire crossing design for thermostability and fault tolerance in quantum\u2013dot cellular automata\n", "abstract": " Quantum-dot cellular automata (QCA) present an unconventional computing model in the nanometer regime. The applications in QCA require complex wire crossings between intersectional wires. The existing wire crossing schemes show low fault tolerance or thermal instability. In this paper, a robust wire crossing scheme is proposed by using two opposite clock zones and redundant cells. The thermostability and fault tolerance are illustrated by using statistical analysis and fault simulations with regard to cell undeposition. This paper also presents a new signal distribution network (SDN) using the proposed wire crossings. The layouts of an XOR gate and a full adder are investigated to show the scalability of the proposed designs to circuits for logic functions with various number of inputs. For the proposed wire crossing and SDN, the circuitries of metal wires to provide the electric fields for driving the involved cells\u00a0\u2026", "num_citations": "7\n", "authors": ["517"]}
{"title": "Automatic selection of process corner simulations for faster design verification\n", "abstract": " Integrated circuit designs are verified in simulation over a set of process corners, which are combinations of expected transistor properties, power supply voltages, and die temperatures. The simulation time per corner can be long and semiconductor processes can have more than 1000 corners. Simulation is thus a serious bottleneck in design verification. We propose an algorithm that selects the smallest number of process corner simulations that are required to estimate minimum and/or maximum values of the output functions that model circuit behavior. Using our best corner selection algorithm, the required number of process corner simulations is reduced by an average of 79% (a speed-up of 4.71) with respect to a set of 46 output functions from nine industrial benchmark circuits.", "num_citations": "7\n", "authors": ["517"]}
{"title": "A novel approach using a minimum cost maximum flow algorithm for fault-tolerant topology reconfiguration in NoC architectures\n", "abstract": " An approach using a minimum cost maximum flow algorithm is proposed for fault-tolerant topology reconfiguration in a Network-on-Chip system. Topology reconfiguration is converted into a network flow problem by constructing a directed graph with capacity constraints. A cost factor is considered to differentiate between processing elements. This approach maximizes the use of spare cores to repair faulty systems, with minimal impact on area, throughput and delay. It also provides a transparent virtual topology to alleviate the burden for operating systems.", "num_citations": "7\n", "authors": ["517"]}
{"title": "On the nonvolatile performance of flip-flop/SRAM cells with a single MTJ\n", "abstract": " In this brief, three nonvolatile flip-flop (FF)/SRAM cells that utilize a single magnetic tunneling junction (MTJ) as nonvolatile resistive element are proposed. These cells have the same core (i.e., 6T) but they employ different numbers of MOSFETs to implement the so-called instantly ON, normally OFF mode of operation. The additional transistors are utilized for the restore operation to ensure that the data stored in the nonvolatile circuitry can be written back into the FF core once the power is made available. These three cells (7T, 9T, and 11T) are extensively analyzed in terms of their operations in 32 nm technology, such as operational delays (for the write, read, and restore operations), the static noise margin (SNM), critical charge and process variations (in both the MOSFETs and the resistive element). Simulation results show that an increase in the number of MOSFETs in the cells causes improvements in critical\u00a0\u2026", "num_citations": "7\n", "authors": ["517"]}
{"title": "Introduction to dynamic stochastic computing\n", "abstract": " Stochastic computing (SC) is an old but reviving computing paradigm for its simple data path that can perform various arithmetic operations. It allows for low power implementation, which would otherwise be complex using the conventional positional binary coding. In SC, a number is encoded by a random bit stream of '0's and '1's with an equal weight for every bit. However, a long bit stream is usually required to achieve a high accuracy. This requirement inevitably incurs a long latency and high energy consumption in an SC system. In this article, we present a new type of stochastic computing that uses dynamically variable bit streams, which is, therefore, referred to as dynamic stochastic computing (DSC). In DSC, a random bit is used to encode a single value from a digital signal. A sequence of such random bits is referred to as a dynamic stochastic sequence. Using a stochastic integrator, DSC is well suited for\u00a0\u2026", "num_citations": "6\n", "authors": ["517"]}
{"title": "Profile-based output error compensation for approximate arithmetic circuits\n", "abstract": " Truncation is one of the most commonly used approaches for circuit-level approximate computing. This paper proposes a scheme for error compensation of arithmetic circuits in which a so-called padding is utilized to compensate at the output for the truncated bits of the input operands. Compensation relies on adjusting the output results of an arithmetic circuit; the padding takes a value determined by utilizing statistical information based on profiling an arithmetic circuit to reduce the average signed difference between the inexact and exact values and so the mean square error. An extensive analysis and simulation-based evaluation of error metrics are performed on signed truncated adders, multipliers and dividers; an excellent agreement is found. Additional design metrics such as power consumption and circuit complexity are also assessed. Different applications of approximate arithmetic circuits with the proposed\u00a0\u2026", "num_citations": "6\n", "authors": ["517"]}
{"title": "Achieving flexible global reconfiguration in nocs using reconfigurable rings\n", "abstract": " The communication behaviors in NoCs of chip-multiprocessors exhibit great spatial and temporal variations, which introduce significant challenges for the reconfiguration in NoCs. Existing reconfigurable NoCs are still far from ideal reconfiguration scenarios, in which globally reconfigurable interconnects can be immediately reconfigured to provide bandwidths on demand for varying traffic flows. In this paper, we propose a hybrid NoC architecture that globally reconfigures the ring-based interconnect to adapt to the varying traffic flows with a high flexibility. The ring-based interconnect has the following advantages. First, it includes horizontal rings and vertical rings, which can be dynamically combined or split to provide low-latency channels for heavy traffic flows. Second, each combined ring connects a number of nodes, thereby improving both the utilization of each ring and the probability to reuse previous\u00a0\u2026", "num_citations": "6\n", "authors": ["517"]}
{"title": "A novel heuristic search method for two-level approximate logic synthesis\n", "abstract": " Recently, much attention has been paid to approximate computing, a novel design paradigm for error-tolerant applications. It can significantly reduce area, power, and delay of circuits by introducing an acceptable amount of error. In this paper, we propose a new heuristic method for two-level approximate logic synthesis. The problem is to identify an approximate sum-of-product (SOP) expression under a given error rate (ER) constraint so that it has the fewest literals. The basic idea of our method is to find an optimal set of input combinations for 0-to-1 output complement (SICC). For this purpose, we first identify all prime SICCs, which are fundamental SICCs in the sense that the optimal SICC is very likely to be a union of a subset of the prime SICCs. Then, we search among all subsets of the prime SICCs the optimal subset, which leads to a final good approximate SOP. We further propose four speed-up techniques\u00a0\u2026", "num_citations": "6\n", "authors": ["517"]}
{"title": "Hardware ODE solvers using stochastic circuits\n", "abstract": " A novel ordinary differential equation (ODE) solver is proposed by using a stochastic integrator to implement the accumulative function of the Euler method. We show that a stochastic integrator is an unbiased estimator for a Euler numerical solution. Unlike in conventional stochastic circuits, in which long stochastic bit streams are required to produce a result with a high accuracy, the proposed stochastic ODE solver provides an estimate of the solution for every bit in the stochastic bit stream, thus significantly reducing the latency and energy consumption of the circuit. Complex ODE solvers are constructed for solving nonhomogeneous ODEs, systems of ODEs and higher-order ODEs. Experimental results show that the stochastic ODE solvers provide very accurate solutions compared to their binary counterparts, with on average an energy saving of 46% (up to 74%), 8\u00d7 throughput per area (up to nearly 12\u00d7) and a\u00a0\u2026", "num_citations": "6\n", "authors": ["517"]}
{"title": "A novel gate grading approach for soft error tolerance in combinational circuits\n", "abstract": " Continuous reduction in the minimum feature size of semiconductor devices and the supply voltages in advanced VLSI logic circuits has made those circuits more susceptible to soft errors. Hence, several fault tolerance techniques have been proposed in the literature to protect combinational circuits against single event transients (SETs). These fault tolerance techniques are based mainly on hardware redundancy and therefore they come at the cost of significant area and power overhead. In this paper, a novel gate grading approach is proposed to prioritize gates based on their influence on the circuit's reliability. Specifically, different masking factors are taken into account and the gates with the lowest masking capabilities are identified so that they can be hardened first. Since the gates with higher priorities affect the circuit's reliability more significantly, protecting those gates increases the circuit's reliability with the\u00a0\u2026", "num_citations": "6\n", "authors": ["517"]}
{"title": "A ternary content addressable cell using a single phase change memory (PCM)\n", "abstract": " This paper presents the novel design of a Ternary Content Addressable Memory (TCAM); different from existing designs found in the technical literature, this cell utilizes a single Phase Change Memory (PCM) as storage element and ambipolarity for comparison. A memory core consisting of a CMOS transistor and a PCM is employed (1T1P); for the search operation, the data in the 1T1P memory core is read and its value is established using two differential sense amplifiers. Compared with other non-volatile memory cells using emerging technologies (such as PCM-based, and memristor-based), simulation results show that the proposed non-volatile TCAM cell offer significant advantages in terms of power dissipation, PDP for the search operation, write time and reduced circuit complexity (in terms of lower counts in transistors and storage elements).", "num_citations": "6\n", "authors": ["517"]}
{"title": "On the restore operation in MTJ-based nonvolatile SRAM cells\n", "abstract": " This brief investigates the Restore mechanism of a nonvolatile static random access memory (NVSRAM) cell that utilizes two magnetic tunneling junctions (MTJs) as nonvolatile resistive elements and a 6T SRAM core. Two cells are proposed by employing different mechanisms for the Restore operation once the power is reestablished. The proposed cells use the bitline and supply as mechanisms to initiate the Restore operation, so connecting the two MTJs to different nodes of the NVSRAM circuitry. The cells are extensively analyzed in terms of their operations with respect to different figures of merit, such as operational delays (for the Write, Read, and Restore operations), the static noise margin, power consumption, critical charge, and process variations (in both the MOSFETs and the resistive elements). Simulation results show that the cell with the MTJs connected to the supply offers the best performance in terms\u00a0\u2026", "num_citations": "6\n", "authors": ["517"]}
{"title": "FDSOI SRAM cells for low power design at 22nm technology node\n", "abstract": " The silicon-on-insulator (SOI) MOSFET is considered as an alternative to the bulk (silicon-based MOSFET in CMOS circuits for applications requiring low-voltage and low-power operation. Fully depleted SOI (FDSOI) benefits from a high current driven ability; so, this technology preserves advantageous features, such as steep sub threshold characteristics and small short channel effects. This paper presents a comprehensive assessment of different SRAM (Static Random Access Memory) cells utilizing different numbers of transistors (i.e. 8 and 9). These cells are evaluated by HSPICE for different performance metrics (such as write/read delay, stability, critical charge, power consumption and tolerance to voltage threshold variation) at the 22nm technology node.", "num_citations": "6\n", "authors": ["517"]}
{"title": "HSPICE macromodel of a programmable metallization cell (PMC) and its application to memory design\n", "abstract": " This paper presents a new HSPICE macromodel of a Programmable Metalization Cell (PMC). The electrical characteristics of a PMC are simulated by using a geometric model that considers the vertical and lateral growth/disolution of the metallic filament. The selection of the parameters is based on operational features, so the electrical characterization of the PMC is simple, easy to simulate and intuitive. The IV and RV plots of a PMC are generated at a very small error compared with experimental data; the proposed model also shows a small error for the relationship between the switching time and the pulse amplitude. The use of a PMC as resistive element in a crossbar memory is also presented; it is shown that a PMC-based crossbar offers substantial improvements over other resistive technologies.", "num_citations": "6\n", "authors": ["517"]}
{"title": "A hybrid memory cell using Single-Electron transfer\n", "abstract": " This paper presents the characterization and design of a Static Random Access Memory (SRAM) cell at nano scale ranges. The proposed SRAM cell incorporates a Single-Electron (SE) turnstile and a Single-Electron Transistor (SET)/MOS circuit in its operation, hence its hybrid nature. Differently from previous cells, the hybrid circuit is utilized to sense (measure) on a voltage-basis the presence of at least an electron as stored in memory, while the turnstile enables the single electron transfer in and out of the storage node. The two memory operations (read and write) are facilitated by utilizing these hybrid circuits; moreover the proposed SRAM cell shows compatibility with MOSFET technology. HSPICE simulation shows that the proposed SRAM cell operates correctly at 45 and 32 nm with good performance in terms of propagation delay, signal integrity, stability and power consumption.", "num_citations": "6\n", "authors": ["517"]}
{"title": "A review of the status of research and training into architectures for nanoelectronic and nanophotonic systems in the European research area\n", "abstract": " This report provides information on the status of European research into architectures for future nanoelectronic systems and, to a lesser degree, nanophotonic systems. Some information is provided on similar research in the USA and in the Pacific Rim. It is evident that many of the innovative ideas on nanoelectronic architectures in the last few years have come from the USA, but nanophotonic innovations seem to be evenly balanced between the three regions. There are signs that new device ideas are needed, because high-level architectural and system considerations suggest that many existing devices will fail to develop into useful systems. Responses to a questionnaire, and discussions with experts, suggest that there is sufficient experience at an intermediate/high level to provide adequate training in this area, although there is a shortage of European students. Summer schools, and possibly an architectural\u00a0\u2026", "num_citations": "6\n", "authors": ["517"]}
{"title": "Novel computing architecture on arrays of Josephson persistent current bits\n", "abstract": " A superconducting qubit (or quantum bit), which consists of a micrometer-sized loop with three Josephson junctions, has two persistent currents of opposite direction as its two states. The states of the qubit can be brought into quantum coherence to perform quantum computing. Classical bits can also be obtained from these superconducting loops, making it possible to base a classical computer architecture. We study a novel computing structure based on these Josephson Persistent Current (PC) Bits, starting from elementary logic gates to a Random Access Memory (RAM). The investigation shows that the Josephson PC Bit technology would not surpass semiconductor technology in term of the device density, while it is a promising candidate for unltra-fast memory, which can be integrated with other technologies. The classical computer might also serve as pre and post processor for the quantum computing performed in the heart of the array. The Josephson PC circuits, therefore, seems a good vehicle for the study of the quantum computer paradigm.", "num_citations": "6\n", "authors": ["517"]}
{"title": "Design and evaluation of an fpga-based hardware accelerator for deflate data decompression\n", "abstract": " Data compression is an important technique for coping with the rapidly increasing volumes of data being transmitted over the Internet. The Deflate lossless data compression standard is used in several popular compressed file formats including the PNG image format and the ZIP and GZIP file formats. Consequently, several implementations of hardware accelerators for Deflate have been proposed. The recent availability of distributed field-programmable gate arrays (FPGAs) in the Internet cloud and the growing demand for decompressing compressed data that is streamed from remote servers make FPGA-based decompression accelerators commercially attractive. This paper describes an efficient implementation of the Deflate decompression algorithm using high-level synthesis from designs, specified in C++, down to optimized implementations for a Xilinx Virtex UltraScale+ class FPGA. When decompressing the\u00a0\u2026", "num_citations": "5\n", "authors": ["517"]}
{"title": "Approximate reliability of multi-state two-terminal networks by stochastic analysis\n", "abstract": " Reliability is an important feature in the design and maintenance of a large-scale system. Usually, for a two-terminal network reliability is a measure for the connectivity between the source and sink nodes. Various approaches have been presented to evaluate system reliability; however, they become cumbersome or prohibitive due to the large computational complexity, especially when multiple states are considered for nodes. In this study, a stochastic approach is presented for estimating corresponding reliability. Randomly permuted sequences with fixed numbers of multiple values are generalized from non-Bernoulli binary sequences to model the multi-state property. State probabilities are represented by randomly permuted sequences to improve both computational efficiency and accuracy. Stochastic models are then constructed for arcs and nodes with different capacities. The proposed stochastic analysis is\u00a0\u2026", "num_citations": "5\n", "authors": ["517"]}
{"title": "A fully parallel approximate CORDIC design\n", "abstract": " This paper proposes a new approximate scheme for a coordinate rotation digital computer (CORDIC) design; this scheme is based on modifying the existing Para-CORDIC architecture with multiple approximations. These approximations make possible a relaxation of the CORDIC algorithm itself, such that a fully parallel approximate CORDIC (FPAX-CORDIC) scheme is designed. This scheme avoids the memory register of Para-CORDIC and makes fully parallel the generation of the rotation direction. A comprehensive analysis and the evaluation of the error introduced by the approximations together with different circuit-related metrics are pursued using HSPICE as simulation tool. The error analysis of this paper combines existing figures of merit for approximate computing (such as the Mean Error Distance (MED)) with CORDIC-specific parameters; a good agreement between expected and simulated error values\u00a0\u2026", "num_citations": "5\n", "authors": ["517"]}
{"title": "Adaptive filter design using stochastic circuits\n", "abstract": " This paper proposes the design of an adaptive filter in stochastic circuits. The proposed circuit requires lower area and power than a conventional stochastic implementation. In the proposed design, the stochastic multiplier is implemented by an XNOR gate, as in a conventional scheme. However, the stochastic adder based on a multiplexer is not a very efficient implementation due to the three required stochastic number generators (SNGs) and the iterative operation required in the adaptive filter. Thus, a novel stochastic adder using a counter and a post processing unit is proposed. This adder avoids the use of SNGs, therefore it incurs a smaller area and power, while operating faster than the conventional (multiplexer-based) stochastic adder. In terms of accuracy and hardware efficiency, simulation results show that the adaptive filter using the proposed stochastic design outperforms the conventional stochastic\u00a0\u2026", "num_citations": "5\n", "authors": ["517"]}
{"title": "Reliability-aware mapping for various NoC topologies and routing algorithms under performance constraints\n", "abstract": " The flexibility of manycore systems to extensive applications is achieved by reconfiguring the interconnections between processing elements (PEs) and the function of PEs. The efficiency of the system is crucially determined by the mapping technique of applications. In this paper, a highly flexible reliability-aware application mapping approach is proposed for manycore network-on-chip (NoC) systems. A reliability cost model (RCM) is first presented to measure the reliability cost for a mapping pattern. This model uses the binary number 0/1 to model the reliability cost of each communication path. The overall reliability cost of a mapping pattern is evaluated by taking the cost of each path as a discrete random variable. Based on RCM, a mapping method called reliability cost ratio based branch and bound (RCRBB) is used. With this method, the best mapping among all the possible patterns is found efficiently\u00a0\u2026", "num_citations": "5\n", "authors": ["517"]}
{"title": "An approximate voting scheme for reliable computing\n", "abstract": " This paper relies on the principles of inexact computing to alleviate the issues arising in static masking by voting for reliable computing. A scheme that utilizes approximate voting is proposed; it is referred to as inexact double modular redundancy (IDMR). IDMR does not resort to triplication, thus saving overhead due to modular replication; moreover, this scheme is adaptive in its operation, i.e., it allows a threshold to determine the validity of the module outputs. IDMR operates by initially establishing the difference between the values of the outputs of the two modules; only if the difference is below a preset threshold, then the voter calculates the average value of the two module outputs. An extensive analysis of the voting circuits and an application to image processing are presented.", "num_citations": "5\n", "authors": ["517"]}
{"title": "Quantum cellular nonlinear networks using Josephson circuits\n", "abstract": " Quantum cellular nonlinear networks (CNNs) using superconducting circuits of Josephson junctions are proposed as an implementation of a massively parallel computing architecture. The quantum CNN architecture presents a novel computing. paradigm, other than quantum computing and classical computing based on binary logic, for the use of Josephson circuits. Some issues in actual implementation are tentatively discussed.", "num_citations": "5\n", "authors": ["517"]}
{"title": "Non-Volatile Approximate Arithmetic Circuits Using Scalable Hybrid Spin-CMOS Majority Gates\n", "abstract": " In the nanoscale era, leakage/static power dissipation has become an inevitable and important issue for CMOS devices. To alleviate this issue, we propose to use spintronic devices with near-zero leakage power and non-volatility as key components in arithmetic circuits for error-resilient applications. To this end, spintronic threshold devices are first utilized to construct highly-scalable majority gates (MGs) based on spin-CMOS technology. These MGs are then used in the design of compressors for constructing multipliers and accumulators. For an MG-based compressor, the truth table of a conventional compressor is transformed to ensure that the outputs depend only on the number of input \u201c1\u201ds. To synthesize and optimize the MG-based circuits, a heuristic majority-inverter graph (HMIG) is further proposed for the design of an accurate and two approximate non-volatile 4\u20132 compressors (denoted as MG-EC, MG\u00a0\u2026", "num_citations": "4\n", "authors": ["517"]}
{"title": "Leveraging spintronic devices for efficient approximate logic and stochastic neural networks\n", "abstract": " ITRS has identified nano-magnet based spintronic devices as promising post-CMOS technologies for information processing and data storage due to their ultra-low switching energy, non-volatility, superior endurance, excellent retention time, high integration density and compatibility with CMOS technology. As for data storage, spintronic memory has been widely accepted as a universal high performance next-generation non-volatile memory candidate. As for information processing, spintronic computing remains complementary in its features to CMOS technology. In this paper, we present two innovative spintronic computing primitives, ie spintronic approximate logic and spintronic stochastic neural network, which both leverage the intrinsic spintronic device physics to achieve much more compact and efficient designs than CMOS counterparts. In spintronic approximate logic, we employ the intrinsic current-mode\u00a0\u2026", "num_citations": "4\n", "authors": ["517"]}
{"title": "Approximate analysis of multi-state weighted k-out-of-n systems applied to transmission lines\n", "abstract": " Multi-state weighted k-out-of-n systems are widely applied in various scenarios, such as multiple line (power/oil transmission line) transmission systems where the capability of fault tolerance is desirable. However, the complex operating environment and the dynamic features of load demands influence the evaluation of system reliability. In this paper, a stochastic multiple-valued (SMV) approach is proposed to efficiently predict the reliability of two models of systems with non-repairable components and dynamically repairable components. The weights/performances and reliabilities of multi-state components (MSCs) are represented by stochastic sequences consisting of a fixed number of multi-state values with the positions being randomly permutated. Using stochastic sequences with L multiple values, linear computational complexities with parameters n and L are required by the SMV approach to compute the reliability of different multi-state k-out-of-n systems at a reasonable accuracy, compared to the complexities of universal generating functions (UGF) and fuzzy universal generating functions (FUGF) that increase exponentially with the value of n. The analysis of two benchmarks shows that the proposed SMV approach is more efficient than the analysis using UGF or FUGF. View Full-Text", "num_citations": "4\n", "authors": ["517"]}
{"title": "Naturally random\n", "abstract": " Novel electronic devices are actively sought to complement and eventually replace complementary metal\u2013oxide\u2013semiconductor (CMOS) technology. Carbon nanotubes1 and silicon nanowires2 may extend the life of conventional transistor structures by reducing the feature size to a few nanometres, whereas spintronic and other unconventional devices have the potential to further enhance the performance and energy efficiency of electronic circuits in the \u2018beyond CMOS\u2019era3. None of these devices, however, require a radically different computing architecture. As a result, circuits and systems built from such devices will be likely to suffer from the same problems\u2014imposed by manufacturing variability, reliability and, eventually, fundamental physical limits\u2014as conventional architectures. These limitations could be circumvented by inventing technologies for implementing novel computing paradigms, such as those\u00a0\u2026", "num_citations": "4\n", "authors": ["517"]}
{"title": "Robust HSPICE modeling of a single electron turnstile\n", "abstract": " This paper presents a novel HSPICE circuit model for designing and simulating a single-electron (SE) turnstile, as applicable at the nanometric feature sizes. The proposed SE model consists of two nearly similar parts whose operations are independent of each other; this disjoint feature permits the accurate and reliable modeling of the sequential transfer of electrons through the turnstile in the storage node (modeled on a voltage level basis). It therefore avoids the transient (current-based) nature of a previous model, thus ensuring robustness in simulated operation. The model has been simulated and results show that it can robustly operate at 32 and 45\u00a0nm with excellent stability in its operation. Extensive simulation results are presented to substantiate the advantages of using the proposed model with respect to changes in the circuit model parameters as related to capacitances, feature size and voltages.", "num_citations": "4\n", "authors": ["517"]}
{"title": "A hybrid non-volatile SRAM cell with concurrent SEU detection and correction\n", "abstract": " This paper presents a hybrid non-volatile (NV) SRAM cell with a new scheme for SEU tolerance. The proposed NVSRAM cell consists of a 6T SRAM core and a Resistive RAM (RRAM), made of a 1T and a Programmable Metallization Cell (PMC). The proposed cell has concurrent error detection (CED) and correction capabilities; CED is accomplished using a dual-rail checker, while correction is accomplished by utilizing the restore operation; data from the non-volatile memory element is copied back to the SRAM core. The dual-rail checker utilizes two XOR gates each made of 2 inverters and 2 ambipolar transistors, hence, it has a hybrid nature. Extensive simulation results are provided. The simulation results show that the proposed scheme is very efficient in terms of numerous figures of merit such as delay and circuit complexity and thus applicable to integrated circuits such as FPGAs requiring secure on-chip non\u00a0\u2026", "num_citations": "4\n", "authors": ["517"]}
{"title": "Hybrid partial product-based high-performance approximate recursive multipliers\n", "abstract": " In this brief, hybrid partial product-based building blocks are proposed by considering the probability distribution of the input operands. An efficient hardware implementation of approximate 4x4 multipliers is achieved while maintaining a required accuracy. Moreover, high-performance approximate NOR-based half adder (NxHA) and full adder (NxFA) cells are proposed for use in a 4x4 multiplier. Three different strategies (Ax8-1/2/3) are further proposed and analyzed for utilizing the 4x4 multipliers when designing larger multipliers. Ax8-2 provides the best trade-off among the designs with a moderate MRED. A reduction of 30% and 17% in the MRED is achieved compared to previous best energy-optimized and MRED-optimized designs. Among the designs with higher MREDs, Ax8-3 exhibits the smallest MRED and PDP. Moreover, it shows an improvement of 7% to 28% in delay compared to existing approximate\u00a0\u2026", "num_citations": "3\n", "authors": ["517"]}
{"title": "Low-power approximate logarithmic squaring circuit design for DSP applications\n", "abstract": " The squaring function is widely used in Digital Signal Processing (DSP). There are many DSP applications with noisy inputs for which simplifying approximations of the squaring function implementation have a minor impact on the output quality, while permitting significant reductions in the hardware cost. This article proposes a Low-Error Squaring Function (LESF) and its low-power hardware implementation. Unlike the existing logarithmic squaring functions, LESF benefits from a double-sided error distribution and, consequently, error cancellation in larger calculations. LESF approximates a base-2 logarithmic function with a piecewise linear polynomial, i.e.   . Since input  in this sum is a constant, LESF replaces the conventional full-adder with a compact specialized adder for hardware efficiency. Our simulation results show that the 16-bit LESF is 23.23% more accurate (assuming the mean relative\u00a0\u2026", "num_citations": "3\n", "authors": ["517"]}
{"title": "High-Throughput FPGA-Based Hardware Accelerators for Deflate Compression and Decompression Using High-Level Synthesis\n", "abstract": " The Deflate compression algorithm provides one of the most widely used solutions for lossless data compression. Field-programmable gate arrays (FPGAs) are commonly used to implement hardware accelerators that speed up computation-intensive applications. In this article, FPGA-based accelerators for Deflate compression and decompression are described. These accelerators were specified in C++ and synthesized using Vivado High-Level Synthesis (HLS) for a Xilinx Virtex UltraScale+ series FPGA and a system clock frequency of 250 MHz. The proposed compressor processes data at a fixed input throughput of 4.0 GB/s and achieves a geometric mean compression ratio of 1.92 on the Calgary corpus benchmark files using static Huffman encoding. While not the first compressor synthesized using high-level synthesis, our design achieves a 25% greater throughput and an 11% greater compression ratio than\u00a0\u2026", "num_citations": "3\n", "authors": ["517"]}
{"title": "Expression-based analyses indicate a central role for hypoxia in driving tumor plasticity through microenvironment remodeling and chromosomal instability\n", "abstract": " Can transcriptomic alterations drive the evolution of tumors? We asked if changes in gene expression found in all patients arise earlier in tumor development and can be relevant to tumor progression. Our analyses of non-mutated genes from the non-amplified regions of the genome of 158 triple-negative breast cancer (TNBC) cases identified 219 exclusively expression-altered (EEA) genes that may play important role in TNBC. Phylogenetic analyses of these genes predict a \u201cpunctuated burst\u201d of multiple gene upregulation events occurring at early stages of tumor development, followed by minimal subsequent changes later in tumor progression. Remarkably, this punctuated burst of expressional changes is instigated by hypoxia-related molecular events, predominantly in two groups of genes that control chromosomal instability (CIN) and those that remodel tumor microenvironment (TME). We conclude that\u00a0\u2026", "num_citations": "3\n", "authors": ["517"]}
{"title": "Special session paper: An efficient hardware design for cerebellar models using approximate circuits\n", "abstract": " The superior controllability of the cerebellum has motivated extensive interest in the development of computational cerebellar models. Many models have been applied to the motor control and image stabilization in robots. Often computationally complex, cerebellar models have rarely been implemented in dedicated hardware. Here, we propose an efficient hardware design for cerebellar models using approximate circuits with a small area and a low power. Leveraging the inherent error tolerance in the cerebellum, approximate adders and multipliers are carefully evaluated for implementations in an adaptive filter based cerebellar model to achieve a good tradeoff in accuracy and hardware usage. A saccade system, whose vestibulo-ocular reflex (VOR) is controlled by the cerebellum, is simulated to show the applicability and effectiveness of the proposed design. Simulation results show that the approximate\u00a0\u2026", "num_citations": "3\n", "authors": ["517"]}
{"title": "Design and analysis of an approximate 2D convolver\n", "abstract": " This paper proposes a two-dimensional (2D) convolver in which both approximate circuit- and algorithm-level techniques are utilized in the design. Truncation is used as circuit techniques, while bit-width reduction is utilized at the algorithm level. These different techniques are related to the configuration of the convolver by which its operation can be configured to meet different and often contrasting figures of merit. Circuit-level simulation (using HSPICE) and an extensive evaluation of different error metrics, generic metrics such as the mean error distance (MED) and the peak signal noise ratio (PSNR) for image convolution are performed. A detailed error analysis is also presented to substantiate the simulation results. Convolution for image processing (Gaussian smoothing) is treated in detail to show the effectiveness of the proposed approach. The design, the analysis and the simulation results show that the\u00a0\u2026", "num_citations": "3\n", "authors": ["517"]}
{"title": "Design of a hybrid non-volatile SRAM cell for concurrent SEU detection and correction\n", "abstract": " This paper presents a hybrid non-volatile (NV) SRAM cell with a new scheme for soft error tolerance. The proposed cell consists of a 6\u00a0T SRAM core, a resistive RAM made of a transistor and a Programmable Metallization Cell. An additional transistor and a transmission gate are utilized for selecting a memory cell in the NVSRAM array. Concurrent error detection (CED) and correction capabilities are provided by connecting the NVSRAM array with a dual-rail checker; CED is accomplished using a dual-rail checker, while correction is accomplished by utilizing the restore operation, such that data from the non-volatile memory element is copied back to the SRAM core. The simulation results show that the proposed scheme is very efficient in terms of numerous figures of merit.", "num_citations": "3\n", "authors": ["517"]}
{"title": "Circuits for a Perpendicular Magnetic Anisotropic (PMA) Racetrack Memory\n", "abstract": " This paper deals with a so-called racetrack memory (also commonly known as a domain-wall memory). Novel circuits for implementing the write, the read, and the shift operations of a Perpendicular Magnetic Anisotropic (PMA) based racetrack cell are initially introduced; the proposed circuits are very efficient in terms of numerous figures of merit, such as delay, power dissipation, and power delay product (PDP). These circuits also allow an efficient implementation of array-level operations of a racetrack memory. An extensive simulation-based analysis is also presented; features such as variations and SEU tolerance in the operation of a PMA-based racetrack memory are considered. This analysis shows that a racetrack memory has great potential due to the significant advantages that it offers for non-volatile storage.", "num_citations": "3\n", "authors": ["517"]}
{"title": "HSPICE macromodel of a PMA racetrack memory\n", "abstract": " This paper introduces the HSPICE macromodel of a racetrack memory (also commonly known as a domain-wall memory). MATLAB is used to generate the HSPICE code and different features of a perpendicular magnetic anisotropy (PMA) racetrack memory are evaluated. The proposed model simulates the write, the read and the shift operations of a racetrack memory. A good agreement between the simulation results obtained from the proposed model and experimental data is achieved.", "num_citations": "3\n", "authors": ["517"]}
{"title": "A Comparative study of Approximate Adders and Multipliers\n", "abstract": " A Comparative Study of Approximate Adders and Multipliers Page 1 A Comparative Study of Approximate Adders and Multipliers Honglan Jiang*, Cong Liu*, Naman Maheshwari#, Fabrizio Lombardi \u00a7 and Jie Han* * Department of Electrical and Computer Engineering University of Alberta, Edmonton, AB, Canada, # Department of Electrical and Electronics Engineering, Birla Institute of Technology and Science, Pilani, Rajasthan, India and \u00a7 Department of Electrical and Computer Engineering, Northeastern University, Boston, USA. Page 2 \u2751 Motivation and Introduction \u2751 Review and Classification of Approximate Adders \u2751 Comparison of the Approximate Adders \u2751 Error Characteristics \u2751 Circuit Characteristics \u2751 Review and Classification of Approximate Multipliers \u2751 Comparison of the Approximate Multipliers \u2751 Error Characteristics \u2751 Circuit Characteristics \u2751 Conclusion Outline 1 Page 3 \u2751 The physical dimensions \u2026", "num_citations": "3\n", "authors": ["517"]}
{"title": "Dynamic stochastic computing for digital signal processing applications\n", "abstract": " Stochastic computing (SC) utilizes a random binary bit stream to encode a number by counting the frequency of 1's in the stream (or sequence). Typically, a small circuit is used to perform a bit-wise logic operation on the stochastic sequences, which leads to significant hardware and power savings. Energy efficiency, however, is a challenge for SC due to the long sequences required for accurately encoding numbers. To overcome this challenge, we consider to use a stochastic sequence to encode a continuously variable signal instead of a number to achieve higher accuracy, higher energy efficiency and greater flexibility. Specifically, one single bit is used to encode a sample from a signal for efficient processing. This type of sequences encodes constantly variable values, so it is referred to as dynamic stochastic sequences (DSS's). The DSS enables the use of SC circuits to efficiently perform tasks such as\u00a0\u2026", "num_citations": "2\n", "authors": ["517"]}
{"title": "Serial concatenated convolutional code encoder in quantum-dot cellular automata\n", "abstract": " Quantum-dot cellular automata (QCA) are a prospective nanotechnology with striking performance for complementing complementary metal oxide semiconductor (CMOS) based integrated circuit technique. For applications in communications, serial concatenated convolutional codes (SCCCs) have been investigated due to their negligible error floor for deep space communication. Using a combination of top-down and bottom-up approaches, we design and implement an SCCC encoder in QCA technology. In this work, a Bose\u2013Chaudhuri\u2013Hocquenghem (BCH) code encoder with the ability for correcting burst errors, a pseudo random interleaver for permuting signal bits, and a convolutional code encoder for correcting random errors are logically connected in series for composing the SCCC encoder. Specifically, inspired by the idea for a divider design, a layout for (n, k, t) BCH code encoders is proposed and\u00a0\u2026", "num_citations": "2\n", "authors": ["517"]}
{"title": "A Lifetime Reliability-Constrained Runtime Mapping for Throughput Optimization in Many-Core Systems\n", "abstract": " Due to technology scaling, lifetime reliability is becoming one of the major design constraints in the performance optimization of future many-core systems. Given a lifetime reliability constraint, the existing lifetime-constrained runtime mapping schemes often lead to low throughput because of the requirement to map all applications to compact regions. In this paper, we propose a runtime application mapping scheme that exploits a borrowing strategy to improve the throughput of many-core systems given a lifetime constraint. First, we propose using different strategies for mapping communication-intensive applications and computation-intensive applications. The lifetime reliability constraint can be relaxed in the local time scale when the communication requirement is high. The throughput is improved because the communication distance of communication-intensive applications is optimized while the waiting time of\u00a0\u2026", "num_citations": "2\n", "authors": ["517"]}
{"title": "An efficient hardware design for cerebellar models using approximate circuits: special session paper\n", "abstract": " The superior controllability of the cerebellum has motivated extensive interest in the development of computational cerebellar models. Many models have been applied to the motor control and image stabilization in robots. Often computationally complex, cerebellar models have rarely been implemented in dedicated hardware. Here, we propose an efficient hardware design for cerebellar models using approximate circuits with a small area and a low power. Leveraging the inherent error tolerance in the cerebellum, approximate adders and multipliers are carefully evaluated for implementations in an adaptive filter based cerebellar model to achieve a good tradeoff in accuracy and hardware usage. A saccade system, whose vestibulo-ocular reflex (VOR) is controlled by the cerebellum, is simulated to show the applicability and effectiveness of the proposed design. Simulation results show that the approximate\u00a0\u2026", "num_citations": "2\n", "authors": ["517"]}
{"title": "Approximate Computing with Approximate Circuits: Methodologies and Applications\n", "abstract": " \u2013A set of language annotations that provide the necessary syntax and semantics for approximate hardware design and reuse in Verilog. Axilog\u2019s language semantics and the Relaxability Inference Analysis are independent of the approximate synthesis, ie Axilog can be used with virtually any approximate synthesis tool.", "num_citations": "2\n", "authors": ["517"]}
{"title": "SRAM memory margin probability failure estimation using Gaussian Process regression\n", "abstract": " Estimating the failure probabilities of SRAM memory cells using Monte Carlo or Importance Sampling techniques is expensive in the number of SPICE simulations needed. This paper presents a methodology for estimating the dynamic margin failure probabilities by building a surrogate model of the dynamic margin using Gaussian Process regression. Additive kernel functions that can extrapolate the margin values from the simulated samples are presented. These proposed kernel functions decrease the out-of-sample error of the surrogate model for a 6T cell by 32% compared with a six-dimensional universal kernel such as a Radial-Basis-Function kernel (RBF). Finally, the failure probability values predicted by a surrogate model built using 1250 SPICE simulations are reported and compared with Monte Carlo analysis with 10 6  samples. The results show a relative error of 30% at 0.4V (predicted value of 4\u00d710 -6\u00a0\u2026", "num_citations": "2\n", "authors": ["517"]}
{"title": "A design of a non-volatile PMC-based (programmable metallization cell) register file\n", "abstract": " This paper presents the design of a non-volatile register file using cells made of a SRAM and a Programmable Metallization Cell (PMC). The proposed cell is a symmetric 8T2P (8-transistors, 2PMC) design; it utilizes three control lines to ensure the correctness in its operations (ie Write, Read, Store and Restore). Simulation results using HSPICE are provided for the cell as well as the register file array (both one-and two-dimensional schemes). At cell level, it is shown that the off-state resistance has a limited effect on the Read time, because in the proposed circuit the transistor connecting the PMCs to the SRAM is off. While having no significant effect on the Store time, the time of the Restore operation depends on the value of the off-state resistance, ie an increase in off-state PMC resistance causes an increase in Restore time. Comparison between non-volatile register files utilizing either PMCs, or Phase Change\u00a0\u2026", "num_citations": "2\n", "authors": ["517"]}
{"title": "On the drift behaviors of a phase change memory (PCM) cell\n", "abstract": " This paper presents a HSPICE macromodel of a phase change memory (PCM) by considering the phenomenon of drift behavior as leading to incorrect operation. The model simulates the behavior due to the drift in the resistance and threshold voltage when the cell is not been read or programmed. It considers not only the resistance change by phase (as corresponding to the two phases, amorphous and crystalline), but also the temperature, the crystalline fraction and the continuous profile of the resistance. This electrical based modeling by HSPICE allows to fully characterizing the holding voltage and the continuous behavior of the PCM resistance, while assessing the impact of the programming time of the drifted parameters. The proposed macromodel generates the I-V and R-I plots of a PCM cell at a very small error compared with experimental data. A detailed sensitivity analysis of the electrical parameters of\u00a0\u2026", "num_citations": "2\n", "authors": ["517"]}
{"title": "A PCM-based TCAM cell using NDR\n", "abstract": " This paper presents a new design of a ternary content addressable memory (TCAM) cell. This design exploits two emerging technology devices: a phase change memory (PCM) as storage element and a negative differential resistance (NDR) device as control element. The PCM stores a multi-value resistance to account for the ternary nature of the equality function to be performed in a TCAM. The CMOS-NDR device uses a macroscopic model made of three transistors to exhibit a very high peak-to-valley current ratio, a single symmetric peak and excellent switching speed. The CMOS-NDR device is embedded in the cell such that specific operational points are placed on the I-V curve for generating the match/mismatch outcome. A common-source amplifier with source degeneration is used for decoding the PCM. Extensive simulation results at nanoscale feature sizes (45, 32 and 22 nm) are presented. These results\u00a0\u2026", "num_citations": "2\n", "authors": ["517"]}
{"title": "A Logarithmic Floating-Point Multiplier for the Efficient Training of Neural Networks\n", "abstract": " The development of important applications of increasingly large neural networks (NNs) is spurring research that aims to increase the power efficiency of the arithmetic circuits that perform the huge amount of computation in NNs. The floating-point (FP) representation with a large dynamic range is usually used for training. In this paper, it is shown that the FP representation is naturally suited for the binary logarithm of numbers. Thus, it favors a design based on logarithmic arithmetic. Specifically, we propose an efficient hardware implementation of logarithmic FP multiplication that uses simpler operations to replace complex multipliers for the training of NNs. This design produces a double-sided error distribution that mitigates the accumulative effect of errors in iterative operations, so it is up to 45% more accurate than a recent logarithmic FP design. The proposed multiplier also consumes up to 23.5\u00d7 less energy and 10.7\u00d7 smaller area compared to exact FP multipliers. Benchmark NN applications, including a 922-neuron model for the MNIST dataset, show that the classification accuracy can be slightly improved using the proposed multiplier, while achieving up to 2.4\u00d7 less energy and 2.8\u00d7 smaller area with a better performance.", "num_citations": "1\n", "authors": ["517"]}
{"title": "Exploiting asymmetry in eDRAM errors for redundancy-free error-tolerant design\n", "abstract": " For some applications, errors have a different impact on data and memory systems depending on whether they change a zero to a one or the other way around; for an unsigned integer, a one to zero (or zero to one) error reduces (or increases) the value. For some memories, errors are also asymmetric; for example, in a DRAM, retention failures discharge the storage cell. The tolerance of such asymmetric errors would result in a robust and efficient system design. Error Control Codes (ECCs) are one common technique for memory protection against these errors by introducing some redundancy in memory cells. In this paper, the asymmetry in the errors in Embedded DRAMs (eDRAMs) is exploited for error-tolerant designs without using any ECC or parity, which are redundancy-free in terms of memory cells. A model for the impact of retention errors and refresh time of eDRAMs on the False Positive rate or False\u00a0\u2026", "num_citations": "1\n", "authors": ["517"]}
{"title": "Design and Analysis of Majority Logic Based Approximate Radix-4 Booth Encoders\n", "abstract": " Approximate computing at the nanoscale provides a new approach for low power design for error-tolerant applications. Many emerging nanotechnologies are based on majority logic (ML) and therefore the 3-input majority gate has been used as the basic building block in digital circuit design. In this paper, we consider the design of approximate radix-4 Booth multipliers based on ML. In particular, an approximate partial product encoder and an approximate correction term encoder are proposed. A new metric referred to as the influence factor is defined and used to assess the approximate radix-4 Booth algorithm for different sizes of multipliers. The proposed designs are evaluated using hardware metrics as well as error metrics. It is shown that they offer superior performance. Image processing as a case study of error-tolerant applications are also presented to show the validity of the proposed designs.", "num_citations": "1\n", "authors": ["517"]}
{"title": "Spintronic solutions for stochastic computing\n", "abstract": " With the rising requirements of computation efficiencies for artificial intelligence applications, the conventional deterministic computation approach has shown many bottlenecks in developing large scale deep learning algorithms. Especially for Bayesian inference problems with uncertainty and incompleteness, it usually requires many sampling operations which largely degrade the inference efficiencies. In this chapter, a spintronic devices based stochastic computing method is presented for efficient Bayesian inference. Stochastic computing is regarded as a promising approach to improve the area and energy efficiencies with simplified arithmetic operations. Spintronic devices are utilized to realize efficient sampling operations to overcome the inference efficiencies in terms of power, area and speed. The intrinsic randomness existing in switching process of spintronic device is exploited to realize stochastic\u00a0\u2026", "num_citations": "1\n", "authors": ["517"]}
{"title": "Approximate arithmetic circuits and their applications\n", "abstract": " The demand of higher speed and power efficiency, as well as the feature of error resilience in many applications (e.g., multimedia, recognition and data analytics), have driven the development of approximate computing circuits. Often as the most important arithmetic modules in a processor, adders, multipliers and dividers determine the performance and energy efficiency of many computing tasks. In this talk, a review and classification are presented for the current designs of approximate arithmetic circuits including adders, multipliers and dividers. A comparative evaluation of their error and circuit characteristics is performed for understanding the features of various designs. Image processing and cerebellar models are considered to show the effectiveness of the approximate arithmetic circuits in improving the energy efficiency and performance of computation-intensive applications.", "num_citations": "1\n", "authors": ["517"]}
{"title": "A probabilistic error model and framework for approximate booth multipliers\n", "abstract": " Approximate computing is a paradigm for high performance and low power design by compromising computational accuracy. In this paper, the structure of an approximate modified radix-4 Booth multiplier is analyzed. A probabilistic error model is proposed to facilitate the evaluation of the approximate multiplier for errors from the approximate radix-4 Booth encoding, the approximate regular partial product array, and the approximate 4-2 compressor. The normalized mean error distances (NMEDs) of 8-bit and 16-bit approximate designs are found by utilizing the proposed model. The results from the error model and the corresponding analytical framework are close to those found by simulation, thus confirming the validity of the proposed approach.", "num_citations": "1\n", "authors": ["517"]}
{"title": "A non-volatile low-power TCAM design using racetrack memories\n", "abstract": " This paper proposes a design of a Ternary Content Addressable Memory (TCAM) cell using racetrack memories (RMs) for non-volatile operation. Four RMs are utilized as storage elements and CMOS transistors are used as control elements for executing the write and search operations. The search operation of the TCAM cell utilizes novel circuits to read the RMs and compare data at cell and array levels. A simulation-based analysis shows that this cell has a high critical charge (so tolerant to a single event upset, SEU) and operates at a low CMOS feature size; the analysis is pursued at cell and array levels. A comparison with other non-volatile TCAM cells shows that the write/search delays and the read operating voltage of the proposed RM-based TCAM cell are superior to PCM (Phase Change Memory) and NAND Flash based TCAM cells.", "num_citations": "1\n", "authors": ["517"]}
{"title": "Designs of PMC-based non-volatile memory circuits for data restoring\n", "abstract": " This paper presents two circuits for implementing the restore operation of a non-volatile (NV) memory cell in which data from a programmable metallization cell (PMC) can be copied (restored) into a static random access memory (SRAM). In the first proposed design, a transmission gate is added to each row of cells of the memory array in which a concurrent error detection (CED) circuit is also present. When a mismatch between the data stored in the SRAM and the PMC is detected, the restore operation starts for a single cell. For the second proposed design, a tri-state inverter is added to control the restore operation. This design requires a larger circuit complexity compared to the first design, but performance is substantially improved; moreover, all cells of a memory array can be simultaneously restored, thus suitable for restarting with power-on. A comparison of these designs with a previous scheme is also pursued\u00a0\u2026", "num_citations": "1\n", "authors": ["517"]}
{"title": "An enhanced HSPICE macromodel of a PCM cell with threshold switching and recovery behavior\n", "abstract": " This paper proposes a new macromodel that takes into account the threshold switching and the resistance recovery processes in addition to the drift behavior of a Phase Change Memory (PCM). Simulation results are provided for both DC and drift behaviors; they show that the proposed macromodel is very accurate at a small error when compared with data from experimental devices. A sensitivity analysis of the macromodel is also performed to show its operation with respect to parameter variations. The model is suitable for circuit design based on PCM devices.", "num_citations": "1\n", "authors": ["517"]}
{"title": "Toward Intracellular Delivery and Drug Discovery: Stochastic Logic Networks as Efficient Computational Models for Gene Regulatory Networks\n", "abstract": " Biological functions are regulated through the interactions among genes, proteins and other molecules in a cell. Among various approaches to modeling gene regulatory networks (GRNs), Boolean networks (BNs) and its probabilistic extension, probabilistic Boolean networks (PBNs), have been effective means; in particular, PBNs consider molecular and genetic noise, so they provide significant insights into the understanding of the dynamics of GRNs. The applications of PBNs, however, are hindered by the complexities involved in the computation of the state transition matrix and steady-state distribution of a PBN. This chapter discusses stochastic logic networks as computationally efficient gene network models. Initially, stochastic Boolean networks (SBNs) are presented as a novel implementation of PBNs. SBNs are based on the notions of stochastic logic and stochastic computation. To further exploit the\u00a0\u2026", "num_citations": "1\n", "authors": ["517"]}
{"title": "On the effects of intra-gate resistive open defects in gates at nanoscaled CMOS\n", "abstract": " This paper presents a detailed characterization of the effects of intra-gate resistive open defects on nanoscaled CMOS gates as causing faults with timing and pattern sequence dependency. The values of the least detectable resistance are established for different feature sizes using HSPICE. It is found that as the feature size is reduced, the value of the least detectable resistance increases in the presence of a fault resulting in a delay of less than one nanosecond. The use of a low voltage testing technique is investigated for the detection of these faults. Finally, an analytical model that takes into account the gate current is proposed, this model considers the pronounced effect of the gate current at a decreasing feature size, while incurring in a small error compared with simulation results.", "num_citations": "1\n", "authors": ["517"]}
{"title": "Modeling errors in synthesized tile sets for template manufacturing by DNA self-assembly\n", "abstract": " This paper presents a detailed analytical framework for errors in DNA self-assembly using synthesized tile sets for template manufacturing. Previous works have shown that due to the smaller cardinality of the employed tile set, a synthesized aggregate has a higher (lower) error rate than a non-synthesized aggregate at high (low) tile concentration; moreover, in the former type of aggregate errors are clustered rather than random. Two novel phenomena referred to as propagation and closing are considered in detail and the analysis of this paper shows that the reported difference in errors between aggregates is caused by these phenomena. A new Markov model is presented and solved; this model confirms that, as reported in the technical literature, a cluster of erroneous tiles is more likely to be generated in a synthesized aggregate with a slower growth speed than the error-free aggregate.", "num_citations": "1\n", "authors": ["517"]}