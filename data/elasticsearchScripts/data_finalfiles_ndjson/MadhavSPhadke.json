{"title": "Quality engineering using robust design\n", "abstract": " From the Publisher: Phadke was trained in robust design techniques by Genichi Taguchi, the mastermind behind Japanese quality manufacturing technologies and the father of Japanese quality control. Taguchi's approach is currently under consideration to be adopted as a student protocol with the US govrnment. The foreword is written by Taguchi. This book offers a complete blueprint for structuring projects to achieve rapid completion with high engineering productivity during the research and development phase to ensure that high quality products can be made quickly and at the lowest possible cost. Some topics covered are: orthogonol arrays, how to construct orthogonal arrays, computer-aided robutst design techniques, dynamic systems design methods, and more.", "num_citations": "6247\n", "authors": ["1031"]}
{"title": "Taguchi's parameter design: a panel discussion\n", "abstract": " It is more than a decade since Genichi Taguchi's ideas on quality improvement were inrroduced in the United States. His parameter-design approach for reducing variation in products and processes has generated a great deal of interest among both quality practitioners and statisticians. The statistical techniques used by Taguchi to implement parameter design have been the subject of much debate, however, and there has been considerable research aimed at integrating the parameter-design principles with well-established statistical techniques. On the other hand, Taguchi and his colleagues feel that these research efforts by statisticians are misguided and reflect a lack of understanding of the engineering principles underlying Taguchi's methodology. This panel discussion provides a forum for a technical discussion of these diverse views. A group of practitioners and researchers discuss the role of parameter\u00a0\u2026", "num_citations": "932\n", "authors": ["1031"]}
{"title": "Quality engineering through design optimization\n", "abstract": " A survey done by J. M. Juran[1] showed that the Japanese yields of LSI chips are higher than those of the American and European manufacturers by a factor of two to three. Another study made by K. B. Clark[2] showed that the design and development cycle for a specific product was about 30 months for one American electronics company while it was only about 18 months for the Japanese manufacturer of the same product. Clark defines the development cycle as the time taken from the beginning of the product design until the high volume production starts. He observed that the design transfer from development organization to the manufacturing organization was smooth for the Japanese company while for the American company it took several iterations.", "num_citations": "346\n", "authors": ["1031"]}
{"title": "Off\u2010line quality control in integrated circuit fabrication using experimental design\n", "abstract": " In this paper we describe the off\u2010line quality control method and its application in optimizing the process for forming contact windows in 3.5\u2010\u03bcm complementary metal\u2010oxide semiconductor circuits. The off\u2010line quality control method is a systematic method of optimizing production processes and product designs. It is widely used in Japan to produce high\u2010quality products at low cost. The key steps of off\u2010line quality control are: (i) Identify important process factors that can be manipulated and their potential working levels; (ii) perform fractional factorial experiments on the process using orthogonal array designs; (iii) analyze the resulting data to determine the optimum operating levels of the factors (both the process mean and the process variance are considered in this analysis; (iv) conduct an additional experiment to verify that the new factor levels indeed improve the quality control.", "num_citations": "237\n", "authors": ["1031"]}
{"title": "Quality engineering using design of experiments\n", "abstract": " The Webster\u2019s dictionary defines quality control as \u201can aggregate of activities (as design analysis and statistical sampling with inspection for defects) designed to ensure adequate quality in manufactured products.\u201d This is a passive definition in that it concerns only with \u2018adequate quality\u2019 and makes no mention of an effort to constantly improve the quality. In this paper by quality control we also mean an active effort to improve the quality.", "num_citations": "153\n", "authors": ["1031"]}
{"title": "Optimization of product and process design for quality and cost\n", "abstract": " Robust product and process design is an important technique for achieving high quality at low cost. It involves making the product's function much less sensitive to various sources of noise such as manufacturing variation, environmental variation and deterioration. This is a problem in optimization involving minimization of the mean square loss resulting from the deviation of the product's function from its target. Here we show that the optimization can be carried out in two steps: first maximize a quantity called signal\u2010to\u2010noise ratio (S/N) and then bring the performance on target by special adjustment parameters. The two\u2010step procedure works for a wide variety of product functions and makes the optimization process more efficient and practical compared to the direct minimization of the quadratic loss function.", "num_citations": "110\n", "authors": ["1031"]}
{"title": "Modeling of continuous stochastic processes from discrete observations with application to sunspots data\n", "abstract": " Discretization of a continuous autoregressive moving average process at an equispaced sampling interval results in a discrete autoregressive moving average process. The relationship between the continuous and the discrete parameters yields a simple method of maximum likelihood estimation of the continuous parameters from a discretely sampled data. A technique is described for modeling of continuous processes from discrete observations and is illustrated with analysis of the yearly Wolfer's sunspot numbers data.", "num_citations": "108\n", "authors": ["1031"]}
{"title": "Design optimization case studies\n", "abstract": " Designing high quality products at low cost is an economic and technological challenge to the engineer. A systematic and efficient way to meet this challenge is a new method of design optimization for performance, quality, and cost. The method, called \u201crobust design,\u201d has been found effective in many areas of engineering design. In this paper, the basic concepts of robust design will be discussed and two applications will be described in detail. The first application illustrates how, with a very small number of experiments, highly valuable information can be obtained about a large number of variables for improving the life of router bits used for cutting printed wiring boards from panels. The second application shows the optimization of a differential operational amplifier circuit to minimize the dc offset voltage by moving the center point of the design, which does not add to the cost of making the circuit.", "num_citations": "101\n", "authors": ["1031"]}
{"title": "Identification of multiinput-multioutput transfer function and noise model of a blast furnace from closed-loop data\n", "abstract": " A procedure is described for the identification of multiinput-multioutput transfer function and the disturbance model from closed-loop data. The basic step of the identification procedure is to obtain a multivariate time series model for the input and the output series. A new method-viz., the method of successive orthogonalization is given for the modeling of multiple time series. Real data on closed-loop operation of a blast furnace are analyzed.", "num_citations": "92\n", "authors": ["1031"]}
{"title": "Digital multimedia watermarking for source identification\n", "abstract": " A system and method for communicating a device's capabilities uses a digital watermark embedded in content data. The watermark includes parameters concerning a source unit's communications capabilities. The watermark is embedded within content data, such as multimedia data, of a data packet. A destination unit, upon receiving the data packet detects if a watermark is present, and if so extracts the source's capability parameters from the watermark. The destination unit then negotiates with the source unit to use certain capabilities based on the source capability information contained in the watermark.", "num_citations": "81\n", "authors": ["1031"]}
{"title": "Computation of the exact likelihood function of multivariate moving average models\n", "abstract": " SUMMARY           This paper proposes three methods for computing the exact likelihood function of multivariate moving average models. Each method utilizes the structure of the covariance matrix in a different way. Formulae for operation counts of the three algorithms are given as a guide in selecting the best method for a given problem. Monte Carlo simulations are performed to compare the mean squared errors of parameter estimates obtained by maximizing the exact likelihood function versus those obtained by maximizing various approximate forms of the likelihood function.", "num_citations": "80\n", "authors": ["1031"]}
{"title": "Quality practices in Japan\n", "abstract": " We recently visited Japan to learn about training in quality improvement methods in Japanese industry and about how these methods were used in product and process design. We met with designers, trainers, and quality professionals from seven high-technology manufacturing companies and three trade and professional organizations. In this paper, we discuss what we learned on the following aspects of quality practice in Japan: training and education in quality improvement methods in industry, use of statistical methods in product and process design, key elements of their product realization process, and efforts to promote quality by individual companies as well as by the industry as a whole.", "num_citations": "43\n", "authors": ["1031"]}
{"title": "Some empirical models for the Los Angeles photochemical smog data\n", "abstract": " This paper presents (i) an empirico-mechanistic model which describes the dependence of CO, NO, NO2, and O3 on total hydrocarbons, traffic, wind speed, inversion base height, and solar radiation as well as the photochemical reactions associated with these pollutants; (ii) a detailed study of weather conditions when the instantaneous daily maximum O3 exceeds the L.A. County alert level of 50 pphm; and (iii) regression models for the prediction of daily maximum O3 values.", "num_citations": "43\n", "authors": ["1031"]}
{"title": "Computer design of a vibration-free face-milling cutter\n", "abstract": " A method is developed to choose the blade spacing for a face-milling cutter that will minimize vibration. When the dynamic frequency response of a machine-tool-workpiece system is known, a special-purpose cutter can be designed to minimize the relative cutter-workpiece vibration for a particular cutting speed. When the dynamic system response is unknown the design method is limited to a general-purpose cutter to avoid resonant excitation over a broad frequency range. A nonlinear least-squares method is used to choose the blade angles for both cases. Experimental results using a general-purpose cutter with unequal blade spacing showed an appreciable reduction in noise and vibration compared to a similar cutter with equal blade spacing.", "num_citations": "41\n", "authors": ["1031"]}
{"title": "Selection of quality characteristics and s/n ratios for robust design\n", "abstract": " Designing high-quality products at low cost is an economic and technological challenge to the engineer. A systematic and efficient way to meet this challenge is a new method of design optimization for performance, quality, and cost. The method, called \u201crobust design,\u201d has been found effective in many areas of engineering design: product design, manufacturing process design, system design, material composition, etc. The goal of robust design is to reduce the sensitivity of a product's or process's function to various sources of disturbance, such as the environmental variation, deterioration of parts, and manufacturing variation. It involves 1) selecting an appropriate quality characteristic, 2) selecting an appropriate objective function, called the Signal-to-Noise Ratio, to be maximized, 3) evaluating the objective function, and 4) maximizing the objective function with respect to a number of decision variables called control fac-tors. The product and process development efficiency, the unit manufacturing cost, the quality of the product and the time taken for a new product introduction depend on all of these four aspects. In this paper, we will describe the various considerations involved in the first two aspects and illustrate them with practical examples. Also, we will show how proper selection of quality characteristics and objective functions can facilitate parallel development of subsystems and still ensure effective system integration.2) the manufacturing cost, and 3) the development cost low. Engineers who design the product and the manufacturing process play a major role in controlling these costs. Optimizing the product and process designs through\u00a0\u2026", "num_citations": "35\n", "authors": ["1031"]}
{"title": "Some thoughts about problem solving in a DMAIC framework\n", "abstract": " This paper explores the iterative nature of problem solving in the context of a complex system issue involving the interplay of hardware and software on a diesel engine. The case study illustrates how application of TRIZ and parameter design methodologies can greatly enhance and accelerate the problem-solving process. Slow- and high-amplitude oscillation of the entire vehicle powertrain under steady pedal position at idle is called \"ringing\", and similar behaviour under cruise-control conditions is called \"hitching\". TRIZ (a Russian acronym for Theory of Inventive Problem Solving) Anticipatory Failure Determination was used to discover root cause. Dr. Taguchi's parameter design was then used to find the appropriate levels for a variety of software variables to virtually eliminate the \"hitching\" condition. The use of TRIZ and robust engineering methods up-front in the design process, and the distinction between Six\u00a0\u2026", "num_citations": "25\n", "authors": ["1031"]}
{"title": "MULTIPLE TIME-SERIES MODELING AND SYSTEM IDENTIFICATION WITH APPLICATIONS.\n", "abstract": " Definitions and general assumptions are given in section 2. 2. Following Rozanov [3l.] and Hannan [l5], we regard the spectral density matrix or the autocovariance function as the fundamental property of a stationary time series. Sections 2. 3, 2. 4 and 2.5 discuss the different infinite moving average representations of a given stationary time series. In section 2.3, the concept of two sided discrete filter is introduced, the uniqueness properties of the canonical models are studied in section 2.4, while in section 2. 5 we give the triangular factorization of the spectral density matrix. The overview of the proposed modeling method is given in section 2. 6, whereas the steps of model specification, maximum likelihood estimation and diagnostic checking are detailed in sections 2.7, 2.8 and", "num_citations": "22\n", "authors": ["1031"]}
{"title": "Computer design of a minimum vibration face milling cutter using an improved cutting force model\n", "abstract": " An improved cutting force model is integrated in the design of a minimum vibration face milling cutter. The cutting force of a blade is approximated by a rectangular pulse whose height is governed by the blade spacing. Specific examples of a special purpose and a general purpose cutter are given and their performances are evaluated.", "num_citations": "21\n", "authors": ["1031"]}
{"title": "An expert system for experimental design in off\u2010line quality control\n", "abstract": " Robust design is an efficient method for designing high quality products at low cost. The method examines the effect of a large number of design factors on the variability of a product's response due to various sources of disturbance. This effect can be observed efficiently by studying a large number of variables simultaneously through balanced, orthogonal array experiments, and by analyzing the resulting data using variance decomposition methods. In this paper we describe an expert system prototype for designing efficient experiments. Given the information on various parameters and their levels, the system designs an experiment using orthogonal arrays. This expert system is implemented in Prolog, which is a logic programming language for artificial intelligence research and expert systems development. The system was implemented under the P\u2010Shell knowledge programming environment on UNIX.", "num_citations": "19\n", "authors": ["1031"]}
{"title": "Macro-quality with micro-money\n", "abstract": " Small though it is, a microchip requires a large number of specifications to govern its design, manufacturing, and operation.", "num_citations": "12\n", "authors": ["1031"]}
{"title": "Quality evaluation plan using adaptive Kalman filtering\n", "abstract": " An important function of the Bell Laboratories Quality Assurance Center and the Western Electric Quality Assurance Directorate is to audit the quality of the products manufactured and the services provided by the Western Electric Company to determine if the intended quality standards are met. Until the sixth period of 1980, the t\u2010rate system was used to make inference on the product quality. Starting the seventh period of 1980, the Quality Measurement Plan (QMP) has been implemented. The QMP is based on an empirical Bayes model of the audit\u2010sampling process using the current and the preceding five periods of data. Because it ignores the time order of the data, it is slow in responding to drifts in the process mean. The Quality Evaluation Plan (QEP) has been designed to take into account the time order of the data and to be more sensitive to drifts in the process mean. In this paper we present the Quality\u00a0\u2026", "num_citations": "11\n", "authors": ["1031"]}
{"title": "Identification of papermaking process from closed loop data by bivariate time series analysis\n", "abstract": " The data used by Tee and Wu [5] for identification of the transfer function and the noise of a Fourdrinier paper machine are reanalyzed taking into account the feedback of the skilled operator. The identification procedure consists of fitting a bivariate time series to the input and output observations. The transfer function and the noise of the paper machine as well as those of the skilled operator are obtained by simple manipulations of the fitted bivariate model. The resulting model is physically interpreted and an attempt is made to locate the primary source of disturbance.", "num_citations": "9\n", "authors": ["1031"]}
{"title": "Evaluation of coated abrasive grain geometry and wear via continuous time series models\n", "abstract": " The coated abrasive profiles are characterized using the second order continuous autoregressive model. Based on a two sided moving average representation of this model, expressions are derived to calculate the geometry (apex angle, base width and orientation) of an average grain. Experimental results and analysis for six new and one worn coated abrasive are presented; and the capability of the grain geometry parameters to quantize wear is discussed.", "num_citations": "8\n", "authors": ["1031"]}
{"title": "Iterative Modeling of Interior Ballistics of Small Arms\n", "abstract": " CLASSICAL interior ballistic models were solely con-cerned with the development of pressure as determined by the burning law of propellant and the volume behind the projectile. Lagrange1 first drew attention to the fluid dynamic aspects of interior ballistics. Since then, many investigators2\" 6 have attempted analytical and numerical solutions for the Lagrange ballistic problem. Much of the work has been confined to the application of an assumed propellant burning rate to large caliber weapons using extruded propellant.The objective of this paper is to introduce the iterative model building approach as a methodology to build an adequate interior ballistic model. A 5.56 mm weapon using nitrocellulose ammunition is considered. First, a model based upon one-dimensional Lagrangean fluid dynamic theory is formulated. An iterative scheme to improve the burning rate equation, which is the only unknown in the\u00a0\u2026", "num_citations": "5\n", "authors": ["1031"]}
{"title": "Method and apparatus for rapid approximation of system model\n", "abstract": " Systems, methods, apparatus and mechanisms that iteratively generate one or more equations (conforming to one or more functions or functions types) of increasing complexity (eg, degree or order) to provide one or more corresponding approximations of a System Under Study (SUS), where each approximation or \u201cfit\u201d provides additional information about the SUS and where the various equations may be summed to provide a final \u201cfit\u201d having an adequate level of accuracy.", "num_citations": "4\n", "authors": ["1031"]}
{"title": "The Development & Application of Robust Design Methods-Taguchi's Impact in the United States\n", "abstract": " Under thesponsorship of theQualityAssuranceManagement Cornrnittee, which ischaired by Dr, RoshanChaddhaof BellCommunicationsResearch, several sessions were heldat the GLPBECOM and lnternational CommunicationsConferenceswhich he! ped expose many engtneers to Dr. Taguchi'sphilosophyon quaHty. in November 1984Taguchi and Phadke presenteda paperat GLOBECOM covering many of thebasicideasof robust design. This paperatso. gavea bread overview of off-1ine qualitycontrol. he interestinthissubicct led to a special one-day tutorial on DesignToolsfor Qualityand Productivityat the 198S GLOBECOM by Phadke and RativKeny. Thistutorialcovered many of Taguchi'sideasand how to apply them to engineering design problerns, Panicipantscame from nine different", "num_citations": "4\n", "authors": ["1031"]}
{"title": "Statistical evaluation of trends in ambient concentrations of nitric oxide in Los Angeles\n", "abstract": " The aerometric data on nitric oxide at several air monitoring sites in Los Angeles County for the period of 1959-1974 are statistically analyzed to determine trends in the concen-tration levels. Time series and intervention techniques are used to filter out the effects of seasonality, serial correlations, and short-term trends in weather variables. The ambient impacts of the 1966 and 1971 automobile exhaust programs are evaluated in terms of the trend parameters.The effectiveness of a pollution control measure may be a posteriori judged by the step changes and trends inducedin the pollutant concentration. Such information is vital for future policy decisions. Graphical techniques may be used to obtain preliminary estimates of the control effects. Results of such analyses for various atmospheric contaminants in Los", "num_citations": "4\n", "authors": ["1031"]}
{"title": "Investigation of spiking in electron beam welding using stationary stochastic models\n", "abstract": " The spiking phenomenon in electron beam welding is characterized using the second-order continuous autoregressive model. The model parameters are then physically interpreted in terms of the random fluctuation in the beam power and the diffusion of heat energy in the plates being welded; and a mechanistic model is proposed for the spiking phenomenon. Finally, regression models are obtained to relate the spiking behavior to the accelerating voltage, the beam current, and the welding speed.", "num_citations": "4\n", "authors": ["1031"]}
{"title": "Los Angeles Aerometric Data on Oxides of Nitrogen: 1957-1972\n", "abstract": " A research project has been underway to perform statistical analysis of the aerometric data, extending from January T955 to December 1972, and assembled by the Los Angeies County Air Pollution Control District, Two series of reports are being issued under this project, The first series reports the statistical findings as well as the development of new techniques in the analysis of the pollutant data (see references__ _ [l],[2] and [3]). The second series presents aerometric data for individual pollutants in an organized form. Aerometric data on ozone and carbon monoxide are given in [4] and [5], respectiveiy. This report presents data on nitric oxide (NO), nirtogen dioxide (N02) and total oxides of nitrogen*(NOX) at the seven monitoring stations: Downtown Los Angeles, West Los Angeles, Burbank, Pasadena, Azusa, Lennox and Long Beach, in the Los Angeles Basin Area. This report contains thirty five tables and four\u00a0\u2026", "num_citations": "4\n", "authors": ["1031"]}
{"title": "Utilizing design of experiments to reduce IT system testing cost\n", "abstract": " Orthogonal arrays are a powerful tool in quality and statistics. This paper shows new applications for improving testing effectiveness and efficiency in a multi-parameter environment, which is commonly encountered in today's software and systems. Unique aspects of this paper are applications in diverse areas - telecommunications, defense, automotive, information technology, and financial systems.", "num_citations": "3\n", "authors": ["1031"]}
{"title": "System, method and apparatus for securely distributing content\n", "abstract": " System, method and apparatus for securely distributing content via an encrypted file wherein a Publisher Key (PK) associated with an authorized publisher enables presentation of the content by the authorized user via a Limited Capability Viewer (LCV), the LCV lacking the capability to forward, print, copy or otherwise disseminate the content to be presented. Various embodiments provided enhanced user authentication or authorization, VPN functions, collaboration techniques, automatic distribution of licenses, watermarking of documents, rules pertaining to content transfer between secure and insecure domains and combinations thereof.", "num_citations": "3\n", "authors": ["1031"]}
{"title": "Optimizing video compression using robust parameter design\n", "abstract": " Modern military communications systems require the transmission of full motion video over a hostile battlefield environment. In order to operate over a limited channel bandwidth, the video information must be compressed several orders of magnitude. Recent advances in Internet telephony and high definition television (HDTV) have made real time video compression a reality. The H.263 video compression standard investigated by this project, takes advantage of image redundancies in both space and time. However, this standard was designed for a benign commercial environment. Using it effectively in a military environment requires additional parameter optimization. Through a series of L/sub 86/ parameter design experiments, a strategy was developed which identified the H.263 video codec parameters that had the greatest impact on both video quality and transmitted bitrate. Using Taguchi experiment\u00a0\u2026", "num_citations": "3\n", "authors": ["1031"]}
{"title": "Taguchi's parameter design: a panel discussion\n", "abstract": " Taguchi's parameter design: a panel discussion: Technometrics: Vol 34, No 2 ACM Digital Library home ACM home Google, Inc. (search) Advanced Search Browse About Sign in Register Advanced Search Journals Magazines Proceedings Books SIGs Conferences People More Search ACM Digital Library SearchSearch Advanced Search Technometrics Periodical Home Latest Issue Archive Authors Affiliations Award Winners More HomeBrowse by TitlePeriodicalsTechnometricsVol. , No. Taguchi's parameter design: a panel discussion article Taguchi's parameter design: a panel discussion Share on Authors: Bovas Abraham profile image Bovas Abraham View Profile , Jock Mackay profile image Jock MacKay View Profile , George Edward Pelham Box profile image George Box View Profile , Raghu N Kacker profile image Raghu N. Kacker View Profile , Thomas J Lorenzen profile image Thomas J. Lorenzen View \u2026", "num_citations": "3\n", "authors": ["1031"]}
{"title": "Software reliability through design of experiments\n", "abstract": " A product has high reliability if it consistently delivers the target function every time it is used, under all operating conditions, and throughout its intended life. Such a product has low operating/usage cost. To make a product successful in the global market place, the product must have high reliability, low cost (development, manufacturing, and delivery), and short cycle time. This can be achieved through (1) high engineering productivity and (2) value based phase-gate management.Product/system development has three distinct phases: systems engineering, detailed design, and validation. During systems engineering the product is broken down into modules that can be predictably developed. Individual modules are designed and created during detailed design. These modules are integrated and tested during the validation phase. Testing is needed at various stages during systems engineering, detailed design\u00a0\u2026", "num_citations": "2\n", "authors": ["1031"]}
{"title": "Improving engine control reliability through software optimization\n", "abstract": " This paper discusses optimization of software control strategy for eliminating \"hitching\" and \"ringing\" in a diesel engine powertrain. Slow- and high-amplitude oscillation of the entire vehicle powertrain under steady pedal position at idle is called \"ringing\", and similar behavior under cruisecontrol conditions is called \"hitching\". The intermittent nature of these conditions posed a particular challenge in arriving at proper design alternatives. Zero-point-proportional dynamic S/N ratio was used to quantify vibration and tracking accuracy under six driving conditions, which represented noise factors. An L1 8 orthogonal array explored combinations of six software strategy control factors associated with controlling fuel delivery to the engine. The result was between 4 and 10 dB improvement in vibration reduction, resulting in virtual elimination of the hitching condition. As a result of this effort, a 12 Repair/1000 vehicle reliability\u00a0\u2026", "num_citations": "2\n", "authors": ["1031"]}
{"title": "Off-line quality control in integrated circuit fabrication using experimental design\n", "abstract": " Off-line quality control is a systematic method of optimizing production processes and product designs. It is widely used in Japan to produce high quality products at low cost. The method was introduced to us by Professor Genichi Taguchi who is a Deming-award winner and a former Director of the Japanese Academy of Quality. In this paper we will i) describe the off-line quality control method, and ii) document our efforts to optimize the process for forming contact windows in 3.5 Aim CMOS circuits fabricated in the Murray Hill Integrated Circuit Design Capability Laboratory. In the fabrication of integrated circuits it is critically important to produce contact windows of size very near the target dimension. Windows which are too small or too large lead to loss of yield. The off-line quality control method has improved both the process quality and productivity. The variance of the window size has been reduced by a factor of\u00a0\u2026", "num_citations": "2\n", "authors": ["1031"]}
{"title": "Maximum Likelihood Estimation of Multivariate Autoregressive-Moving Average Models.\n", "abstract": " Algorithms for computing the exact likelihood function of n successive observation vectors from an s-variate autoregressive moving average process of order p, q are developed. A quasi-Newton method is used to maximize the likelihood function with respect to the parameters of the process. Monte Carlo simulations are performed to compare the parameter estimates obtained by maximizing the exact likelihood function versus those obtained by maximizing various approximate forms of the likelihood function. AuthorDescriptors:", "num_citations": "2\n", "authors": ["1031"]}
{"title": "Optimization of a diesel engine software control strategy\n", "abstract": " This paper discusses optimization of software control strategy for eliminating \u201chitching\" and \u201cringing\u201d in a diesel engine powertrain. Slow-and high-amplitude oscillation of the entire vehicle powertrain under steady pedal position at idle is called\" ringing,\" and similar behavior under cruise-control conditions is called\" hitching.\" The intermittent nature of these conditions posed a particular challenge in arriving at proper design alternatives.Zero-point-proportional dynamic S/N ratio was used to quantify vibration and tracking accuracy under six driving conditions, which represented noise factors. An L18 orthogonal array explored combinations of six software strategy control factors associated with controlling fuel delivery to the engine. The result was between 4 and 10 dB improvement in vibration reduction, resulting in virtual elimination of the hitching condition. As a result of this effort, a 12 repair per thousand vehicle reliability (eight million dollar warranty) problem was eliminated.", "num_citations": "1\n", "authors": ["1031"]}