{"title": "SecureUML: A UML-based modeling language for model-driven security\n", "abstract": " We present a modeling language for the model-driven development of secure, distributed systems based on the Unified Modeling Language (UML). Our approach is based on role-based access control with additional support for specifying authorization constraints. We show how UML can be used to specify information related to access control in the overall design of an application and how this information can be used to automatically generate complete access control infrastructures. Our approach can be used to improve productivity during the development of secure distributed systems and the quality of the resulting systems.", "num_citations": "1088\n", "authors": ["1588"]}
{"title": "Model driven security: From UML models to access control infrastructures\n", "abstract": " We present a new approach to building secure systems. In our approach, which we call Model Driven Security, designers specify system models along with their security requirements and use tools to automatically generate system architectures from the models, including complete, configured access control infrastructures. Rather than fixing one particular modeling language for this process, we propose a general schema for constructing such languages that combines languages for modeling systems with languages for modeling security. We present several instances of this schema that combine (both syntactically and semantically) different UML modeling languages with a security modeling language for formalizing access control requirements. From models in the combined languages, we automatically generate access control infrastructures for server-based applications, built from declarative and programmatic\u00a0\u2026", "num_citations": "682\n", "authors": ["1588"]}
{"title": "OFMC: A symbolic model checker for security protocols\n", "abstract": " We present the on-the-fly model checker OFMC, a tool that combines two ideas for analyzing security protocols based on lazy, demand-driven search. The first is the use of lazy data types as a simple way of building efficient on-the-fly model checkers for protocols with very large, or even infinite, state spaces. The second is the integration of symbolic techniques and optimizations for modeling a lazy Dolev\u2013Yao intruder whose actions are generated in a demand-driven way. We present both techniques, along with optimizations and proofs of correctness and completeness.               Our tool is state of the art in terms of both coverage and performance. For example, it finds all known attacks and discovers a new one in a test suite of 38 protocols from the Clark/Jacob library in a few seconds of CPU time for the entire suite. We also give examples demonstrating how our tool scales to, and finds errors in, large\u00a0\u2026", "num_citations": "600\n", "authors": ["1588"]}
{"title": "An information-theoretic model for adaptive side-channel attacks\n", "abstract": " We present a model of adaptive side-channel attacks which we combine with information-theoretic metrics to quantify the information revealed to an attacker. This allows us to express an attacker's remaining uncertainty about a secret as a function of the number of side-channel measurements made. We present algorithms and approximation techniques for computing this measure. We also give examples of how they can be used to analyze the resistance of hardware implementations of cryptographic functions to both timing and power attacks.", "num_citations": "408\n", "authors": ["1588"]}
{"title": "Distributed usage control\n", "abstract": " Using a server-side architecture to connect specialized enforcement mechanisms with usage control requirements and policies.", "num_citations": "318\n", "authors": ["1588"]}
{"title": "An on-the-fly model-checker for security protocol analysis\n", "abstract": " We introduce the on-the-fly model-checker OFMC, a tool that combines two methods for analyzing security protocols. The first is the use of lazy data-types as a simple way of building an efficient on-the-fly model checker for protocols with infinite state spaces. The second is the integration of symbolic techniques for modeling a Dolev-Yao intruder, whose actions are generated in a demand-driven way. We present experiments that demonstrate that our tool is state-of-the-art, both in terms of coverage and performance, and that it scales well to industrial-strength protocols.", "num_citations": "234\n", "authors": ["1588"]}
{"title": "A formal analysis of 5G authentication\n", "abstract": " Mobile communication networks connect much of the world's population. The security of users' calls, SMSs, and mobile data depends on the guarantees provided by the Authenticated Key Exchange protocols used. For the next-generation network (5G), the 3GPP group has standardized the 5G AKA protocol for this purpose. We provide the first comprehensive formal model of a protocol from the AKA family: 5G AKA. We also extract precise requirements from the 3GPP standards defining 5G and we identify missing security goals. Using the security protocol verification tool Tamarin, we conduct a full, systematic, security evaluation of the model with respect to the 5G security goals. Our automated analysis identifies the minimal security assumptions required for each security goal and we find that some critical security goals are not met, except under additional assumptions missing from the standard. Finally, we make\u00a0\u2026", "num_citations": "231\n", "authors": ["1588"]}
{"title": "A policy language for distributed usage control\n", "abstract": " We present the Obligation Specification Language (OSL), a policy language for distributed usage control. OSL supports the formalization of a wide range of usage control requirements. We also present translations between OSL and two rights expression languages (RELs) from the DRM area. These translations make it possible to use DRM mechanisms to enforce OSL policies. Furthermore, the translations enhance the interoperability of DRM mechanisms and allow us to apply OSL-specific monitoring and analysis tools to the RELs.", "num_citations": "207\n", "authors": ["1588"]}
{"title": "Model driven security for process-oriented systems\n", "abstract": " Model Driven Architecture is an approach to increasing the quality of complex software systems based on creating high-level system models and automatically generating system architectures from the models. We show how this paradigm can be specialized to what we call Model Driven Security. In our specialization, a designer builds a system model along with security requirements, and automatically generates from this a complete, configured security infrastructure. We propose a modular approach to constructing modeling languages supporting this process, which combines languages for modeling system design with languages for modeling security. We present an application to constructing systems from process models, where we combine a UML-based process design language with a security modeling language for formalizing access control requirements. From models in the combined language, we\u00a0\u2026", "num_citations": "197\n", "authors": ["1588"]}
{"title": "On obligations\n", "abstract": " Access control is concerned with granting access to sensitive data based on conditions that relate to the past or present, so-called provisions. Expressing requirements from the domain of data protection necessitates extending this notion with conditions that relate to the future. Obligations, in this sense, are concerned with commitments of the involved parties. At the moment of granting access, adherence to these commitments cannot be guaranteed. An example is the requirement \u201cdo not re-distribute data\u201d, where the actions of the involved parties may not even be observable. We provide a formal framework that allows us to precisely specify data protection policies. A syntactic classification of formulas gives rise to natural and intuitive formal definitions of provisions and obligations. Based on this classification, we present different mechanisms for checking adherence to agreed upon commitments.", "num_citations": "176\n", "authors": ["1588"]}
{"title": "Sok: Secure data deletion\n", "abstract": " Secure data deletion is the task of deleting data irrecoverably from a physical medium. In the digital world, data is not securely deleted by default; instead, many approaches add secure deletion to existing physical medium interfaces. Interfaces to the physical medium exist at different layers, such as user-level applications, the file system, the device driver, etc. Depending on which interface is used, the properties of an approach can differ significantly. In this paper, we survey the related work in detail and organize existing approaches in terms of their interfaces to physical media. We further present a taxonomy of adversaries differing in their capabilities as well as a systematization for the characteristics of secure deletion approaches. Characteristics include environmental assumptions, such as how the interface's use affects the physical medium, as well as behavioural properties of the approach such as the deletion\u00a0\u2026", "num_citations": "161\n", "authors": ["1588"]}
{"title": "Secure neighborhood discovery: A fundamental element for mobile ad hoc networking\n", "abstract": " Pervasive computing systems will likely be deployed in the near future, with the proliferation of wireless devices and the emergence of ad hoc networking as key enablers. Coping with mobility and the volatility of wireless communications in such systems is critical. Neighborhood discovery (ND) - the discovery of devices directly reachable for communication or in physical proximity - becomes a fundamental requirement and building block for various applications. However, the very nature of wireless mobile networks makes it easy to abuse ND and thereby compromise the overlying protocols and applications. Thus, providing methods to mitigate this vulnerability and secure ND is crucial. In this article we focus on this problem and provide definitions of neighborhood types and ND protocol properties, as well as a broad classification of attacks. Our ND literature survey reveals that securing ND is indeed a difficult and\u00a0\u2026", "num_citations": "160\n", "authors": ["1588"]}
{"title": "Automated analysis of security-design models\n", "abstract": " We have previously proposed SecureUML, an expressive UML-based language for constructing security-design models, which are models that combine design specifications for distributed systems with specifications of their security policies. Here, we show how to automate the analysis of such models in a semantically precise and meaningful way. In our approach, models are formalized together with scenarios that represent possible run-time instances. Queries about properties of the security policy modeled are expressed as formulas in UML\u2019s Object Constraint Language. The policy may include both declarative aspects, i.e., static access-control information such as the assignment of users and permissions to roles, and programmatic aspects, which depend on dynamic information, namely the satisfaction of authorization constraints in a given scenario. We show how such properties can be evaluated, completely\u00a0\u2026", "num_citations": "154\n", "authors": ["1588"]}
{"title": "ARPKI: Attack resilient public-key infrastructure\n", "abstract": " We present ARPKI, a public-key infrastructure that ensures that certificate-related operations, such as certificate issuance, update, revocation, and validation, are transparent and accountable. ARPKI is the first such infrastructure that systematically takes into account requirements identified by previous research. Moreover, ARPKI is co-designed with a formal model, and we verify its core security property using the Tamarin prover. We present a proof-of-concept implementation providing all features required for deployment. ARPKI efficiently handles the certification process with low overhead and without incurring additional latency to TLS.", "num_citations": "136\n", "authors": ["1588"]}
{"title": "Monitoring metric first-order temporal properties\n", "abstract": " Runtime monitoring is a general approach to verifying system properties at runtime by comparing system events against a specification formalizing which event sequences are allowed. We present a runtime monitoring algorithm for a safety fragment of metric first-order temporal logic that overcomes the limitations of prior monitoring algorithms with respect to the expressiveness of their property specification languages. Our approach, based on automatic structures, allows the unrestricted use of negation, universal and existential quantification over infinite domains, and the arbitrary nesting of both past and bounded future operators. Furthermore, we show how to use and optimize our approach for the common case where structures consist of only finite relations, over possibly infinite domains. We also report on case studies from the domain of security and compliance in which we empirically evaluate the presented\u00a0\u2026", "num_citations": "131\n", "authors": ["1588"]}
{"title": "A probabilistic approach to hybrid role mining\n", "abstract": " Role mining algorithms address an important access control problem: configuring a role-based access control system. Given a direct assignment of users to permissions, role mining discovers a set of roles together with an assignment of users to roles. The results should closely agree with the direct assignment. Moreover, the roles should be understandable from the business perspective in that they reflect functional roles within the enterprise. This requires hybrid role mining methods that work with both direct assignments and business information from the enterprise.", "num_citations": "119\n", "authors": ["1588"]}
{"title": "A decade of model-driven security\n", "abstract": " In model-driven development, system designs are specified using graphical modeling languages like UML and system artifacts such as code and configuration data are automatically generated from the models. Model-driven security is a specialization of this paradigm, where system designs are modeled together with their security requirements and security infrastructures are directly generated from the models. Over the past decade, we have explored different facets of model-driven security. This research includes different modeling languages, code generators, model analysis tools, and even model transformations. For example, in multi-tier systems, we used model transformations to transform a security policy, formulated for a system's data model, to a security policy governing the behavior of the system's graphical user interface. In this paper, we survey progress made, tool support, and case studies, which attest\u00a0\u2026", "num_citations": "113\n", "authors": ["1588"]}
{"title": "Provably repairing the ISO/IEC 9798 standard for entity authentication\n", "abstract": " We formally analyze the family of entity authentication protocols defined by the ISO/IEC 9798 standard and find numerous weaknesses, both old and new, including some that violate even the most basic authentication guarantees. We analyze the cause of these weaknesses, propose repaired versions of the protocols, and provide automated, machine-checked proofs of their correctness. From an engineering perspective, we propose two design principles for security protocols that suffice to prevent all the weaknesses. Moreover, we show how modern verification tools can be used for the falsification and certified verification of security standards. Based on our findings, the ISO working group responsible for the ISO/IEC 9798 standard has released an updated version of the standard.", "num_citations": "109\n", "authors": ["1588"]}
{"title": "Data node encrypted file system: Efficient secure deletion for flash memory\n", "abstract": " We propose the Data Node Encrypted File System (DNEFS), which uses on-the-fly encryption and decryption of file system data nodes to efficiently and securely delete data on flash memory systems. DNEFS is a generic modification of existing flash file systems or controllers that enables secure data deletion while preserving the underlying systems\u2019 desirable properties: application-independence, fine-grained data access, wear-levelling, and efficiency.", "num_citations": "106\n", "authors": ["1588"]}
{"title": "Policy monitoring in first-order temporal logic\n", "abstract": " We present an approach to monitoring system policies. As a specification language, we use an expressive fragment of a temporal logic, which can be effectively monitored. We report on case studies in security and compliance monitoring and use these to show the adequacy of our specification language for naturally expressing complex, realistic policies and the practical feasibility of monitoring these policies using our monitoring algorithm.", "num_citations": "105\n", "authors": ["1588"]}
{"title": "Model checking security protocols\n", "abstract": " The formal analysis of security protocols is a prime example of a domain where model checking has been successfully applied. Although security protocols are typically small, analysis by hand is difficult as a protocol should work even when arbitrarily many runs are interleaved and in the presence of an adversary. Specialized model-checking techniques have been developed that address both the problems of unbounded, interleaved runs and a prolific, highly nondeterministic adversary. These techniques have been implemented in model-checking tools that now scale to protocols of realistic size and can be used to aid protocol design and standardization.           In this chapter, we provide an overview of the main applications of model checking in security protocol analysis. We explain the central concepts involved in the analysis of security protocols: the abstraction of messages, protocols as role automata, the\u00a0\u2026", "num_citations": "103\n", "authors": ["1588"]}
{"title": "Enforceable security policies revisited\n", "abstract": " We revisit Schneider\u2019s work on policy enforcement by execution monitoring. We overcome limitations of Schneider\u2019s setting by distinguishing between system actions that are controllable by an enforcement mechanism and those actions that are only observable, that is, the enforcement mechanism sees them but cannot prevent their execution. For this refined setting, we give necessary and sufficient conditions on when a security policy is enforceable. To state these conditions, we generalize the standard notion of safety properties. Our classification of system actions also allows one, for example, to reason about the enforceability of policies that involve timing constraints. Furthermore, for different specification languages, we investigate the decision problem of whether a given policy is enforceable. We provide complexity results and show how to synthesize an enforcement mechanism from an enforceable policy.", "num_citations": "103\n", "authors": ["1588"]}
{"title": "Qubos: Deciding Quantified Boolean Logic Using Propositional Satisfiability Solvers\n", "abstract": " We describe Qubos (QUantified BOolean Solver), a decision procedure for quantified Boolean logic. The procedure is based on non-clausal simplification techniques that reduce formulae to a propositional clausal form after which off-the-shelf satisfiability solvers can be employed. We show that there are domains exhibiting structure for which this procedure is very effective and we report on experimental results.", "num_citations": "102\n", "authors": ["1588"]}
{"title": "The AVISS security protocol analysis tool\n", "abstract": " We introduce AVISS, a tool for security protocol analysis that supports the integration of back-ends implementing different search techniques, allowing for their systematic and quantitative comparison and paving the way to their effective interaction. As a significant example, we have implemented three back-ends, and used the AVISS tool to analyze and find flaws in 36 protocols, including 31 problems in the Clark-Jacob\u2019s protocol library and a previously unreported flaw in the Denning-Sacco protocol.", "num_citations": "99\n", "authors": ["1588"]}
{"title": "MONPOLY: Monitoring usage-control policies\n", "abstract": " Determining whether the usage of sensitive, digitally stored data complies with regulations and policies is a growing concern for companies, administrations, and end users alike. Classical examples of policies used for protecting and preventing the misuse of data are history-based access-control policies like the Chinese-wall policy and separation-of-duty constraints. Other policies from more specialized areas like banking involve retention, reporting, and transaction requirements. Simplified examples from this domain are that financial reports must be approved at most a week before they are published and that transactions over $10,000 must be reported within two days.", "num_citations": "97\n", "authors": ["1588"]}
{"title": "Cryptographically sound theorem proving\n", "abstract": " We describe a faithful embedding of the Dolev-Yao model of Backes, Pfitzmann, and Waidner (CCS 2003) in the theorem prover Isabelle/HOL. This model is cryptographically sound in the strong sense of blackbox reactive simulatability/UC, which essentially entails the preservation of arbitrary security properties under active attacks and in arbitrary protocol environments. The main challenge in designing a practical formalization of this model is to cope with the complexity of providing such strong soundness guarantees. We reduce this complexity by abstracting the model into a sound, light-weight formalization that enables both concise property specifications and efficient application of our proof strategies and their supporting proof tools. This yields the first tool-supported framework for symbolically verifying security protocols that enjoys the strong cryptographic soundness guarantees provided by reactive\u00a0\u2026", "num_citations": "97\n", "authors": ["1588"]}
{"title": "On the definition of role mining\n", "abstract": " There have been many approaches proposed for role mining. However, the problems solved often differ due to a lack of consensus on the formal definition of the role mining problem. In this paper, we provide a detailed analysis of the requirements for role mining, the existing definitions of role mining, and the methods used to assess role mining results. Given basic assumptions on how access-control configurations are generated, we propose a novel definition of the role mining problem that fulfills the requirements that real-world enterprises typically have. In this way, we recast role mining as a prediction problem.", "num_citations": "94\n", "authors": ["1588"]}
{"title": "Multi-assignment clustering for boolean data\n", "abstract": " Conventional clustering methods typically assume that each data item belongs to a single cluster. This assumption does not hold in general. In order to overcome this limitation, we propose a generative method for clustering vectorial data, where each object can be assigned to multiple clusters. Using a deterministic annealing scheme, our method decomposes the observed data into the contributions of individual clusters and infers their parameters.", "num_citations": "93\n", "authors": ["1588"]}
{"title": "Runtime Monitoring of Metric First-order Temporal Properties\n", "abstract": " We introduce a novel approach to the runtime monitoring of complex system properties. In particular, we present an online algorithm for a safety fragment of metric first-order temporal logic that is considerably more expressive than the logics supported by prior monitoring methods. Our approach, based on automatic structures, allows the unrestricted use of negation, universal and existential quantification over infinite domains, and the arbitrary nesting of both past and bounded future operators. Moreover, we show how to optimize our approach for the common case where structures consist of only finite relations, over possibly infinite domains. Under an additional restriction, we prove that the space consumed by our monitor is polynomially bounded by the cardinality of the data appearing in the processed prefix of the temporal structure being monitored.", "num_citations": "93\n", "authors": ["1588"]}
{"title": "Automated symbolic proofs of observational equivalence\n", "abstract": " Many cryptographic security definitions can be naturally formulated as observational equivalence properties. However, existing automated tools for verifying the observational equivalence of cryptographic protocols are limited: they do not handle protocols with mutable state and an unbounded number of sessions. We propose a novel definition of observational equivalence for multiset rewriting systems. We then extend the Tamarin prover, based on multiset rewriting, to prove the observational equivalence of protocols with mutable state, an unbounded number of sessions, and equational theories such as Diffie-Hellman exponentiation. We demonstrate its effectiveness on case studies, including a stateful TPM protocol.", "num_citations": "91\n", "authors": ["1588"]}
{"title": "Labelled propositional modal logics: Theory and practice\n", "abstract": " We show how labelled deductive systems can be combined with a logical framework to provide a natural deduction implementation of a large and well-known class of propositional modal logics (including K, D, T, B, S4, S4.2, KD45, S5). Our approach is modular and based on a separation between a base logic and a labelling algebra, which interact through a fixed interface. While the base logic stays fixed, different modal logics are generated by plugging in appropriate algebras. This leads to a hierarchical structuring of modal logics with inheritance of theorems. Moreover, it allows modular correctness proofs, both with respect to soundness and completeness for semantics, and faithfulness and adequacy of the implementation. We also investigate the tradeoffs in possible labelled presentations: we show that a narrow interface between the base logic and the labelling algebra supports modularity and provides an\u00a0\u2026", "num_citations": "91\n", "authors": ["1588"]}
{"title": "A calculus for and termination of rippling\n", "abstract": " Rippling is a type of rewriting developed for inductive theorem proving that uses annotations to direct search. Rippling has many desirable properties: for example, it is highly goal directed, usually involves little search, and always terminates. In this paper we give a new and more general formalization of rippling. We introduce a simple calculus for rewriting annotated terms, close in spirit to first-order rewriting, and prove that it has the formal properties desired of rippling. Next we develop criteria for proving the termination of such annotated rewriting, and introduce orders on annotated terms that lead to termination. In addition, we show how to make rippling more flexible by adapting the termination orders to the problem domain. Our work has practical as well as theoretical advantages: it has led to a very simple implementation of rippling that has been integrated in the Edinburgh CLAM system.", "num_citations": "88\n", "authors": ["1588"]}
{"title": "Multi-assignment clustering for boolean data\n", "abstract": " We propose a probabilistic model for clustering Boolean data where an object can be simultaneously assigned to multiple clusters. By explicitly modeling the underlying generative process that combines the individual source emissions, highly structured data are expressed with substantially fewer clusters compared to single-assignment clustering. As a consequence, such a model provides robust parameter estimators even when the number of samples is low. We extend the model with different noise processes and demonstrate that maximum-likelihood estimation with multiple assignments consistently infers source parameters more accurately than single-assignment clustering. Our model is primarily motivated by the task of role mining for role-based access control, where users of a system are assigned one or more roles. In experiments with real-world access-control data, our model exhibits better generalization performance than state-of-the-art approaches.", "num_citations": "87\n", "authors": ["1588"]}
{"title": "Metalogical frameworks\n", "abstract": " In computer science we speak of implementing a logic; this is done in a programming language, such as Lisp, called here the implementation language. We also reason about the logic, as in understanding how to search for proofs; these arguments are expressed in the metalanguage and conducted in the metalogic of the object language being implemented. We also reason about the implementation itself, say to know it is correct; this is done in a programming logic. How do all these logics relate? This paper considers that question and more. We show that by taking the view that the metalogic is primary, these other parts are related in standard ways. The metalogic should be suitably rich so that the object logic can be presented as an abstract data type, and it must be suitably computational (or constructive) so that an instance of that type is an implementation. The data type abstractly encodes all that is relevant for metareasoning, ie, not only the term constructing functions but also the principles for reasoning about terms and computing with them. Our work can also be seen as an approach to the task of finding a generic way to present logics and their implementations, which is for example the goal of the Edinburgh Logical Frameworks (ELF) effort. This approach extends well beyond proof-construction and includes compu-tational metatheory as well.", "num_citations": "87\n", "authors": ["1588"]}
{"title": "Monitoring security policies with metric first-order temporal logic\n", "abstract": " We show the practical feasibility of monitoring complex security properties using a runtime monitoring approach for metric first-order temporal logic. In particular, we show how a wide variety of security policies can be naturally formalized in this expressive logic, ranging from traditional policies like Chinese Wall and separation of duty to more specialized usage-control and compliance requirements. We also explain how these formalizations can be directly used for monitoring and experimentally evaluate the performance of the resulting monitors.", "num_citations": "83\n", "authors": ["1588"]}
{"title": "Algorithms for monitoring real-time properties\n", "abstract": " We present and analyze monitoring algorithms for a safety fragment of metric temporal logics, which differ in their underlying time model. The time models considered have either dense or discrete time domains and are point-based or interval-based. Our analysis reveals differences and similarities between the time models for monitoring and highlights key concepts underlying our and prior monitoring algorithms.", "num_citations": "81\n", "authors": ["1588"]}
{"title": "Mechanisms for usage control\n", "abstract": " Usage control is a generalization of access control that also addresses how data is used after it is released. We present a formal model for different mechanisms that can enforce usage control policies on the consumer side.", "num_citations": "81\n", "authors": ["1588"]}
{"title": "Lazy infinite-state analysis of security protocols\n", "abstract": " Security protocols are used to exchange information in a Distributed system with the aim of providing security guarantees. We Present an approach to modeling security protocols using lazy data types in a higher-order functional programming language. Our approach supports the formalization of protocol models in a natural and high-level way, and the automated analysis of safety properties using infinite-state model checking, where the model is explicitly constructed in a demand-driven manner. We illustrate these ideas with an extended example: modeling and checking the Needham-Schroeder public-key authentication protocol.", "num_citations": "76\n", "authors": ["1588"]}
{"title": "Modeling and analyzing security in the presence of compromising adversaries\n", "abstract": " We present a framework for modeling adversaries in security protocol analysis, ranging from a Dolev-Yao style adversary to more powerful adversaries who can reveal different parts of principals\u2019 states during protocol execution. Our adversary models unify and generalize many existing security notions from both the computational and symbolic settings. We extend an existing symbolic protocol-verification tool with our adversary models, resulting in the first tool that systematically supports notions such as weak perfect forward secrecy, key compromise impersonation, and adversaries capable of state-reveal queries. In case studies, we automatically find new attacks and rediscover known attacks that previously required detailed manual analysis.", "num_citations": "75\n", "authors": ["1588"]}
{"title": "Natural deduction for non-classical logics\n", "abstract": " We present a framework for machine implementation of families of non-classical logics with Kripke-style semantics. We decompose a logic into two interacting parts, each a natural deduction system: a base logic of labelled formulae, and a theory of labels characterizing the properties of the Kripke models. By appropriate combinations we capture both partial and complete fragments of large families of non-classical logics such as modal, relevance, and intuitionistic logics. Our approach is modular and supports uniform proofs of soundness, completeness and proof normalization. We have implemented our work in the Isabelle Logical Framework.", "num_citations": "75\n", "authors": ["1588"]}
{"title": "SECFUZZ: Fuzz-testing security protocols\n", "abstract": " We propose a light-weight, yet effective, technique for fuzz-testing security protocols. Our technique is modular, it exercises (stateful) protocol implementations in depth, and handles encrypted traffic. We use a concrete implementation of the protocol to generate valid inputs, and mutate the inputs using a set of fuzz operators. A dynamic memory analysis tool monitors the execution as an oracle to detect the vulnerabilities exposed by fuzz-testing. We provide the fuzzer with the necessary keys and cryptographic algorithms in order to properly mutate encrypted messages. We present a case study on two widely used, mature implementations of the Internet Key Exchange (IKE) protocol and report on two new vulnerabilities discovered by our fuzz-testing tool. We also compare the effectiveness of our technique to two existing model-based fuzz-testing tools for IKE.", "num_citations": "74\n", "authors": ["1588"]}
{"title": "A class of probabilistic models for role engineering\n", "abstract": " Role Engineering is a security-critical task for systems using role-based access control (RBAC). Different role-mining approaches have been proposed that attempt to automatically infer appropriate roles from existing user-permission assignments. However, these approaches are mainly combinatorial and lack an underlying probabilistic model of the domain. We present the first probabilistic model for RBAC. Our model defines a general framework for expressing user permission assignments and can be specialized to different domains by limiting its degrees of freedom with appropriate constraints. For one practically important instance of this framework, we show how roles can be inferred from data using a state-of-the-art machine-learning algorithm. Experiments on both randomly generated and real-world data provide evidence that our approach not only creates meaningful roles but also identifies erroneous user\u00a0\u2026", "num_citations": "70\n", "authors": ["1588"]}
{"title": "Monitoring of temporal first-order properties with aggregations\n", "abstract": " In system monitoring, one is often interested in checking properties of aggregated data. Current policy monitoring approaches are limited in the kinds of aggregations they handle. To rectify this, we extend an expressive language, metric first-order temporal logic, with aggregation operators. Our extension is inspired by the aggregation operators common in database query languages like SQL. We provide a monitoring algorithm for this enriched policy specification language. We show that, in comparison to related data processing approaches, our language is better suited for expressing policies, and our monitoring algorithm has competitive performance.", "num_citations": "68\n", "authors": ["1588"]}
{"title": "Firewall conformance testing\n", "abstract": " Firewalls are widely used to protect networks from unauthorised access. To ensure that they implement an organisation\u2019s security policy correctly, they need to be tested. We present an approach that addresses this problem. Namely, we show how an organisation\u2019s network security policy can be formally specified in a high-level way, and how this specification can be used to automatically generate test cases to test a deployed system. In contrast to other firewall testing methodologies, such as penetration testing, our approach tests conformance to a specified policy. Our test cases are organisation-specific \u2014 i.e.\u00a0they depend on the security requirements and on the network topology of an organisation \u2014 and can uncover errors both in the firewall products themselves and in their configuration.", "num_citations": "67\n", "authors": ["1588"]}
{"title": "Synthesis of programs in computational logic\n", "abstract": " Since the early days of programming and automated reasoning, researchers have developed methods for systematically constructing programs from their specifications. Especially the last decade has seen a flurry of activities including the advent of specialized conferences, such as LOPSTR, covering the synthesis of programs in computational logic. In this paper we analyze and compare three state-of-the-art methods for synthesizing recursive programs in computational logic. The three approaches are constructive/deductive synthesis, schema-guided synthesis, and inductive synthesis. Our comparison is carried out in a systematic way where, for each approach, we describe the key ideas and synthesize a common running example. In doing so, we explore the synergies between the approaches, which we believe are necessary in order to achieve progress over the next decade in this field.", "num_citations": "67\n", "authors": ["1588"]}
{"title": "Hardware verification using monadic second-order logic\n", "abstract": " We show how the second-order monadic theory of strings can be used to specify hardware components and their behavior. This logic admits a decision procedure and counter-model generator based on canonical automata for formulas. We have used a system implementing these concepts to verify, or find errors in, a number of circuits proposed in the literature. The techniques we use make it easier to identify regularity in circuits, including those that are parameterized or have parameterized behavioral specifications. Our proofs are semantic and do not require lemmas or induction as would be needed when employing a conventional theory of strings as a recursive data type.", "num_citations": "67\n", "authors": ["1588"]}
{"title": "Automated complexity analysis based on ordered resolution\n", "abstract": " We define order locality to be a property of clauses relative to a term ordering. This property generalizes the subformula property for proofs where the terms appearing in proofs can be bounded, under the given ordering, by terms appearing in the goal clause. We show that when a clause set is order local, then the complexity of its ground entailment problem is a function of its structure (e.g., full versus Horn clauses), and the ordering used. We prove that, in many cases, order locality is equivalent to a clause set being saturated under ordered resolution. This provides a means of using standard resolution theorem provers for testing order locality and transforming non-local clause sets into local ones. We have used the Saturate system to automatically establish complexity bounds for a number of nontrival entailment problems relative to complexity classes which include polynomial and exponential time and co-NP.", "num_citations": "66\n", "authors": ["1588"]}
{"title": "Secure data deletion from persistent media\n", "abstract": " Secure deletion is the task of deleting data irrecoverably from a physical medium. In this work, we present a general approach to the design and analysis of secure deletion for persistent storage that relies on encryption and key wrapping. We define a key disclosure graph that models the adversarial knowledge of the history of key generation and wrapping. We introduce a generic update function and prove that it achieves secure deletion of data against a coercive attacker; instances of the update function implement the update behaviour of all arborescent data structures including B-Trees, extendible hash tables, linked lists, and others. We implement a B-Tree instance of our solution. Our implementation is at the block-device layer, allowing any block-based file system to be used on top of it. Using different workloads, we find that the storage and communication overhead required for storing and retrieving B-Tree\u00a0\u2026", "num_citations": "64\n", "authors": ["1588"]}
{"title": "Bounded model construction for monadic second-order logics\n", "abstract": " The monadic logics M2L-Str and WS1S have been successfully used for verification, although they are nonelementary decidable. Motivated by ideas from bounded model checking, we investigate procedures for bounded model construction for these logics. The problem is, given a formula \u03c6 and a bound k, does there exist a word model for \u03c6 of length k. We give a bounded model construction algorithm for M2L-Str that runs in a time exponential in k. For WS1S, we prove a negative result: bounded model construction is as hard as validity checking, i.e., it is nonelementary. From this, negative results for other monadic logics, such as S1S, follow. We present too preliminary tests using a SAT-based implementation of bounded model construction; for certain problem classes it can find counter-examples substantially faster than automata-based decision procedures.", "num_citations": "64\n", "authors": ["1588"]}
{"title": "Difference unification\n", "abstract": " We extend previous work on difference identification and reduction as a technique for automated reasoning. We generalize unification so that terms are made equal not only by finding substitutions for variables but also by hiding term structure. This annotation of structural differences serves to direct rippling, a kind of rewriting designed to remove structural differences in a controlled way. On the technical side, we give a rule-based algorithm for difference unification, and analyze its correctness, completeness, and complexity. On the practical side, we present a novel search strategy (called left-first search) for applying these rules in an efficient way. Finally, we show how this algorithm can be used in new ways to direct rippling and how it can play an important role in theorem proving and other kinds of automated reasoning.", "num_citations": "62\n", "authors": ["1588"]}
{"title": "On purpose and by necessity: compliance under the GDPR\n", "abstract": " The European General Data Protection Regulation (GDPR) gives primacy to purpose: Data may be collected and stored only when (i) end-users have consented, often explicitly, to the purposes for which that data is collected, and (ii) the collected data is actually necessary for achieving these purposes. This development in data protection regulations begets the question: how do we audit a computer system\u2019s adherence to a purpose?                 We propose an approach that identifies a purpose with a business process, and show how formal models of interprocess communication can be used to audit or even derive privacy policies. Based on this insight, we propose a methodology for auditing GDPR compliance. Moreover, we show how given a simple interprocess dataflow model, aspects of GDPR compliance can be determined algorithmically.", "num_citations": "61\n", "authors": ["1588"]}
{"title": "Developing topology discovery in Event-B\n", "abstract": " We present a formal development in Event-B of a distributed topology discovery algorithm. Distributed topology discovery is at the core of several routing algorithms and is the problem of each node in a network discovering and maintaining information on the network topology. One of the key challenges in developing this algorithm is specifying the problem itself. We provide a specification that includes both safety properties, formalizing invariants that should hold in all system states, and liveness properties that characterize when the system reaches stable states. We prove these properties by appropriately combining proofs of invariants, event refinement, event convergence, and deadlock freedom. The combination of these features is novel and should be useful for formalizing and developing other kinds of semi-reactive systems, which are systems that react to, but do not modify, their environment. Our entire\u00a0\u2026", "num_citations": "59\n", "authors": ["1588"]}
{"title": "Automata based symbolic reasoning in hardware verification\n", "abstract": " We present a new approach to hardware veri cation based on describing circuits in Monadic Second-order Logic (M2L). We show how to use this logic to represent generic designs like n-bit adders, which are parameterized in space, and sequential circuits, where time is an unbounded parameter. M2L admits a decision procedure, implemented in the Mona tool 17], which reduces formulas to canonical automata. The decision problem for M2L is non-elementary decidable and thus unlikely to be usable in practice. However, we have used Mona to automatically verify, or nd errors in, a number of circuits studied in the literature. Previously published machine proofs of the same circuits are based on deduction and may involve substantial interaction with the user. Moreover, our approach is orders of magnitude faster for the examples considered. We show why the underlying computations are feasible and how our use of Mona generalizes standard BDD-based hardware reasoning.", "num_citations": "59\n", "authors": ["1588"]}
{"title": "Obstruction-free authorization enforcement: Aligning security and business objectives\n", "abstract": " Access control is fundamental in protecting information systems but it can also pose an obstacle to achieving business objectives. We analyze this tradeoff and its avoidance in the context of systems modeled as workflows restricted by authorization constraints, including those specifying Separation of Duty (SoD) and Binding of Duty (BoD). To begin with, we present a novel approach to scoping authorization constraints within workflows with loops and conditional execution. We formalize workflows, authorization constraints, and their enforcement using the process algebra CSP and visualize our constraints by extending the workflow modeling language BPMN. Afterwards, we consider enforcement's effects on business objectives. We identify the notion of obstruction, which generalizes deadlock within a system where access control is enforced, and we formulate the existence of an obstruction-free enforcement\u00a0\u2026", "num_citations": "58\n", "authors": ["1588"]}
{"title": "CDiff: a new reduction technique for constraint-based analysis of security protocols\n", "abstract": " We introduce CDiff, a new technique for reducing search when model-checking security protocols. Our technique is based on eliminating certain kinds of redundancies that arise in the search space when using symbolic exploration methods, in particular methods that employ constraints to represent and manipulate possible messages from an active intruder. Formally, we prove that CDiff terminates and is correct and complete, in that it preserves the set of reachable states so that all state-based properties holding before reduction (such as the intruder discovering a secret on the network) hold after reduction. Practically, we have integrated this technique into OFMC, a state-of-the-art model-checker, and demonstrated its effectiveness by extensive experimentation. Our results show that CDiff substantially reduces search and considerably improves the performance of OFMC, enabling its application to a wider class of\u00a0\u2026", "num_citations": "56\n", "authors": ["1588"]}
{"title": "A theoretical and empirical investigation of search in imperfect information games\n", "abstract": " We examine search algorithms for games with imperfect information. We first investigate Monte Carlo sampling, showing that for very simple game trees the chance of finding an optimal strategy rapidly approaches zero as size of the tree increases. We identify the reasons for this sub-optimality, and show that the same problems occur in Bridge, a popular real-world imperfect information game. We then analyse the complexity of the underlying problem, proving it to be NP-complete and describing several polynomial time heuristics. We evaluate these heuristics theoretically and experimentally, demonstrating that they significantly out-perform Monte Carlo sampling. Indeed, on a set of Bridge problems drawn from a definitive expert text, our heuristics consistently identify strategies as good as, or superior to, the expert solutions \u2013 the first time a game-general tree search algorithm has been capable of such performance.", "num_citations": "54\n", "authors": ["1588"]}
{"title": "Role mining with probabilistic models\n", "abstract": " Role mining tackles the problem of finding a role-based access control (RBAC) configuration, given an access-control matrix assigning users to access permissions as input. Most role-mining approaches work by constructing a large set of candidate roles and use a greedy selection strategy to iteratively pick a small subset such that the differences between the resulting RBAC configuration and the access control matrix are minimized. In this article, we advocate an alternative approach that recasts role mining as an inference problem rather than a lossy compression problem. Instead of using combinatorial algorithms to minimize the number of roles needed to represent the access-control matrix, we derive probabilistic models to learn the RBAC configuration that most likely underlies the given matrix. Our models are generative in that they reflect the way that permissions are assigned to users in a given RBAC\u00a0\u2026", "num_citations": "53\n", "authors": ["1588"]}
{"title": "Know your enemy: Compromising adversaries in protocol analysis\n", "abstract": " We present a symbolic framework, based on a modular operational semantics, for formalizing different notions of compromise relevant for the design and analysis of cryptographic protocols. The framework\u2019s rules can be combined to specify different adversary capabilities, capturing different practically-relevant notions of key and state compromise. The resulting adversary models generalize the models currently used in different domains, such as security models for authenticated key exchange. We extend an existing security-protocol analysis tool, Scyther, with our adversary models. This extension systematically supports notions such as weak perfect forward secrecy, key compromise impersonation, and adversaries capable of state-reveal queries. Furthermore, we introduce the concept of a protocol-security hierarchy, which classifies the relative strength of protocols against different adversaries. In case studies, we\u00a0\u2026", "num_citations": "51\n", "authors": ["1588"]}
{"title": "Finding optimal strategies for imperfect information games\n", "abstract": " We examine three heuristic algorithms for games with imperfect information: Monte-carlo sampling, and two new algorithms we call vector minimaxing and payoffreduction minimaxing. We compare these algorithms theoretically and experimentally, using both simple game trees and a large database of problems from the game of Bridge. Our experiments show that the new algorithms both out-perform Monte-carlo sampling, with the superiority of payoff-reduction minimaxing being especially marked. On the Bridge problem set, for example, Monte-carlo sampling only solves 66% of the problems, whereas payoff-reduction minimaxing solves over 95%. This level of performance was even good enough to allow us to discover five errors in the expert text used to generate the test database.", "num_citations": "51\n", "authors": ["1588"]}
{"title": "Difference matching\n", "abstract": " Difference matching is a generalization of first-order matching where terms are made identical both by variable instantiation and by structure hiding. After matching, the hidden structure may be removed by a type of controlled rewriting, called rippling, that leaves the rest of the term unaltered. Rippling has proved highly successful in inductive theorem proving. Difference matching allows us to use rippling in other contexts, e.g., equational, inequational, and propositional reasoning. We present a difference matching algorithm, its properties, several applications, and suggest extensions.", "num_citations": "51\n", "authors": ["1588"]}
{"title": "Short paper: Detection of GPS spoofing attacks in power grids\n", "abstract": " Power companies are deploying a multitude of sensors to monitor the energy grid. Measurements at different locations should be aligned in time to obtain the global state of the grid, and the industry therefore uses GPS as a common clock source. However, these sensors are exposed to GPS time spoofing attacks that cause misaligned aggregated measurements, leading to inaccurate monitoring that affects power stability and line fault contingencies. In this paper, we analyze the resilience of phasor measurement sensors, which record voltages and currents, to GPS spoofing performed by an adversary external to the system. We propose a solution that leverages the characteristics of multiple sensors in the power grid to limit the feasibility of such attacks. In order to increase the robustness of wide-area power grid monitoring, we evaluate mechanisms that allow collaboration among GPS receivers to detect spoofing\u00a0\u2026", "num_citations": "50\n", "authors": ["1588"]}
{"title": "Complexity analysis based on ordered resolution\n", "abstract": " We define order locality to be a property of clauses relative to a term ordering. This property is a kind of generalization of the subformula property for proofs where terms arising in proofs are bounded, under the given ordering, by terms appearing in the goal clause. We show that when a clause set is order local, then the complexity of its ground entailment problem is a function of its structure (e.g., full versus Horn clauses), and the ordering used. We prove that, in many cases, order locality is equivalent to a clause set being saturated under ordered resolution. This provides a means of using standard resolution theorem provers for testing order locality and transforming non-local clause sets into local ones. We have used the Saturate system to automatically establish complexity bounds for a number of nontrivial entailment problems relative to complexity classes which include polynomial and exponential time and co-NP.", "num_citations": "50\n", "authors": ["1588"]}
{"title": "Cutoff bounds for consensus algorithms\n", "abstract": " Consensus algorithms are fundamental building blocks for fault-tolerant distributed systems and their correctness is critical. However, there are currently no fully-automated methods for their verification. The main difficulty is that the algorithms are parameterized: they should work for any given number of processes. We provide an expressive language for consensus algorithms targeting the benign asynchronous setting. For this language, we give algorithm-dependent cutoff bounds. A cutoff bound B reduces the parameterized verification of consensus to a setting with B processes. For the algorithms in our case studies, we obtain bounds of 5 or 7, enabling us to model check them efficiently. This is the first cutoff result for fault-tolerant distributed systems.", "num_citations": "49\n", "authors": ["1588"]}
{"title": "On the semantics of Alice&Bob specifications of security protocols\n", "abstract": " In the context of security protocols, the so-called Alice&Bob notation is often used to describe the messages exchanged between honest principals in successful protocol runs. While intuitive, this notation is ambiguous in its description of the actions taken by principals, in particular with respect to the conditions they must check when executing their roles and the actions they must take when the checks fail.In this paper, we investigate the semantics of protocol specifications in Alice&Bob notation. We provide both a denotational and an operational semantics for such specifications, rigorously accounting for these conditions and actions. Our denotational semantics is based on a notion of incremental symbolic runs, which reflect the data possessed by principals and how this data increases monotonically during protocol execution. We contrast this with a standard formalization of the behavior of principals, which directly\u00a0\u2026", "num_citations": "49\n", "authors": ["1588"]}
{"title": "Topology dynamics and routing for predictable mobile networks\n", "abstract": " Predictable mobile networks are dynamic in terms of the mobility and connectivity of the network nodes. However, in contrast to mobile ad-hoc networks, their dynamics are mostly predictable, as the name suggests. Currently, no adequate topology model exists for such networks. Moreover, routing protocols based on either static or mobile ad-hoc topology models do not exploit this predictability and thus are too inefficient for use in some application areas. We present a model that formalizes predictable dynamic topologies as sequences of static snapshots. We use this model to design and prove the correctness of a protocol based on link-state routing, whose performance is superior to its static and ad-hoc counterparts. Our routing protocol accounts for occurrences of additional, unpredictable changes, as well as their interaction with predictable changes. As an application area, we focus on routing in spacecraft\u00a0\u2026", "num_citations": "44\n", "authors": ["1588"]}
{"title": "Combining WS1S and HOL\n", "abstract": " We investigate the combination of the weak second-order monadic logic of one successor (WS1S) with higher-order logic (HOL). We show how these two logics can be combined, how theorem provers based on them can be safely integrated, and how the result can be used. In particular, we present an embedding of the semantics of WS1S in HOL that provides a basis for coupling the MONA system, a decision procedure for WS1S, with an implementation of HOL in the Isabelle system. Afterwards, we describe methods that reduce problems formalized in HOL to problems in the language of WS1S. We present applications to arithmetic reasoning and proving properties of parameterized sequential systems.", "num_citations": "43\n", "authors": ["1588"]}
{"title": "CryptHOL: Game-based proofs in higher-order logic\n", "abstract": " Game-based proofs are a well-established paradigm for structuring security arguments and simplifying their understanding. We present a novel framework, CryptHOL, for rigorous game-based proofs that is supported by mechanical theorem proving. CryptHOL is based on a new semantic domain with an associated functional programming language for expressing games. We embed our framework in the Isabelle/HOL theorem prover and, using the theory of relational parametricity, we tailor Isabelle\u2019s existing proof automation to game-based proofs. By basing our framework on a conservative extension of higher-order logic and providing automation support, the resulting proofs are trustworthy and comprehensible, and the framework is extensible and widely applicable. We evaluate our framework by formalising different game-based proofs from the literature and comparing the results with existing formal\u00a0\u2026", "num_citations": "42\n", "authors": ["1588"]}
{"title": "Optimal workflow-aware authorizations\n", "abstract": " Balancing protection and empowerment is a central problem when specifying authorizations. The principle of least privilege, the classical approach to balancing these two conflicting objectives, says that users shall only be authorized to execute the tasks necessary to complete their job. However, when there are multiple authorization policies satisfying least privilege, which one should be chosen?", "num_citations": "42\n", "authors": ["1588"]}
{"title": "Strong invariants for the efficient construction of machine-checked protocol security proofs\n", "abstract": " We embed an operational semantics for security protocols in the interactive theorem prover Isabelle/HOL and derive two strong protocol-independent invariants. These invariants allow us to reason about the possible origin of messages and justify a local typing assumption for the otherwise untyped protocol variables. The two rules form the core of a theory that is well-suited for interactively constructing natural, human-readable, correctness proofs. Moreover, we develop an algorithm that automatically generates proof scripts based on these invariants. Both interactive and automatic proof construction are faster than competing approaches. Moreover, we have strong correctness guarantees since all proofs, including those deriving the underlying theory from the semantics, are machine checked.", "num_citations": "42\n", "authors": ["1588"]}
{"title": "Constraint differentiation: Search-space reduction for the constraint-based analysis of security protocols\n", "abstract": " We introduce constraint differentiation, a powerful technique for reducing search when model-checking security protocols using constraint-based methods. Constraint differentiation works by eliminating certain kinds of redundancies that arise in the search space when using constraints to represent and manipulate the messages that may be sent by an active intruder. We define constraint differentiation in a general way, independent of the technical and conceptual details of the underlying constraint-based method and protocol model. Formally, we prove that constraint differentiation terminates and is correct, under the assumption that the original constraint-based approach has these properties. Practically, as a concrete case study, we have integrated this technique into OFMC, a state-of-the-art model-checker for security protocol analysis, and demonstrated its effectiveness by extensive experimentation. Our results\u00a0\u2026", "num_citations": "42\n", "authors": ["1588"]}
{"title": "Algebraic intruder deductions\n", "abstract": " Many security protocols fundamentally depend on the algebraic properties of cryptographic operators. It is however difficult to handle these properties when formally analyzing protocols, since basic problems like the equality of terms that represent cryptographic messages are undecidable, even for relatively simple algebraic theories. We present a framework for security protocol analysis that can handle algebraic properties of cryptographic operators in a uniform and modular way. Our framework is based on two ideas: the use of modular rewriting to formalize a generalized equational deduction problem for the Dolev-Yao intruder, and the introduction of two parameters that control the complexity of the equational unification problems that arise during protocol analysis by bounding the depth of message terms and the operations that the intruder can perform when analyzing messages. We motivate the different\u00a0\u2026", "num_citations": "42\n", "authors": ["1588"]}
{"title": "Reflective metalogical frameworks\n", "abstract": " A metalogical framework is a logic with an associated methodology that is used to represent other logics and to reason about their metalogical properties. We propose that logical frameworks can be good metalogical frameworks when their theories always have initial models and they support reflective and parameterized reasoning.We develop this thesis both abstractly and concretely. Abstractly, we formalize our proposal as a set of requirements and explain how any logic satisfying these requirements can be used for metalogical reasoning. Concretely, we present membership equational logic as a particular metalogic that satisfies these requirements. Using membership equational logic, and its realization in the Maude system, we show how reflection can be used for different, nontrivial kinds of formal metatheoretic reasoning. In particular, one can prove metatheorems that relate theories or establish properties of\u00a0\u2026", "num_citations": "42\n", "authors": ["1588"]}
{"title": "Scalable offline monitoring\n", "abstract": " We propose an approach to monitoring IT systems offline, where system actions are logged in a distributed file system and subsequently checked for compliance against policies formulated in an expressive temporal logic. The novelty of our approach is that monitoring is parallelized so that it scales to large logs. Our technical contributions comprise a formal framework for slicing logs, an algorithmic realization based on MapReduce, and a high-performance implementation. We evaluate our approach analytically and experimentally, proving the soundness and completeness of our slicing techniques and demonstrating its practical feasibility and efficiency on real-world logs with 400 GB of relevant\u00a0data.", "num_citations": "41\n", "authors": ["1588"]}
{"title": "Monitoring compliance policies over incomplete and disagreeing logs\n", "abstract": " When monitoring system behavior to check compliance against a given policy, one is sometimes confronted with incomplete knowledge about system events. In IT systems, such incompleteness may arise from logging infrastructure failures and corrupted log files, or when the logs produced by different system components disagree on whether actions took place. In this paper, we present a policy language with a three-valued semantics that allows one to explicitly reason about incomplete knowledge and handle disagreements. Furthermore, we present a monitoring algorithm for an expressive fragment of our policy language. We illustrate through examples how our approach extends compliance monitoring to systems with logging failures and disagreements.", "num_citations": "41\n", "authors": ["1588"]}
{"title": "Labelled modal logics: Quantifiers\n", "abstract": " In previous work we gave an approach, based on labelled natural deduction, for formalizing proof systems for a large class of propositional modal logics that includes K, D, T, B, S4, S4.2, KD45, and S5. Here we extend this approach to quantified modal logics, providing formalizations for logics with varying, increasing, decreasing, or constant domains. The result is modular with respect to both properties of the accessibility relation in the Kripke frame and the way domains of individuals change between worlds. Our approach has a modular metatheory too; soundness, completeness and normalization are proved uniformly for every logic in our class. Finally, our work leads to a simple implementation of a modal logic theorem prover in a standard logical framework.", "num_citations": "41\n", "authors": ["1588"]}
{"title": "Mining ABAC rules from sparse logs\n", "abstract": " Different methods have been proposed to mine attribute-based access control (ABAC) rules from logs. In practice, these logs are sparse in that they contain only a fraction of all possible requests. However, for sparse logs, existing methods mine and validate overly permissive rules, enabling privilege abuse. We define a novel measure, reliability, that quantifies how overly permissive a rule is and we show why other standard measures like confidence and entropy fail in quantifying overpermissiveness. We build upon state-of-the-art subgroup discovery algorithms and our new reliability measure to design Rhapsody, the first ABAC mining algorithm with correctness guarantees: Rhapsody mines a rule if and only if the rule covers a significant number of requests, its reliability is above a given threshold, and there is no equivalent shorter rule. We evaluate Rhapsody on different real-world scenarios using logs from\u00a0\u2026", "num_citations": "40\n", "authors": ["1588"]}
{"title": "Design, analysis, and implementation of ARPKI: an attack-resilient public-key infrastructure\n", "abstract": " The current Transport Layer Security (TLS) Public-Key Infrastructure (PKI) is based on a weakest-link security model that depends on over a thousand trust roots. The recent history of malicious and compromised Certification Authorities has fueled the desire for alternatives. Creating a new, secure infrastructure is, however, a surprisingly challenging task due to the large number of parties involved and the many ways that they can interact. A principled approach to its design is therefore mandatory, as humans cannot feasibly consider all the cases that can occur due to the multitude of interleavings of actions by legitimate parties and attackers, such as private key compromises (e.g., domain, Certification Authority, log server, other trusted entities), key revocations, key updates, etc. We present ARPKI, a PKI architecture that ensures that certificate-related operations, such as certificate issuance, update, revocation, and\u00a0\u2026", "num_citations": "40\n", "authors": ["1588"]}
{"title": "Labelled deduction\n", "abstract": " Labelled deduction is an approach to providing frameworks for presenting and using different logics in a uniform and natural way by enriching the language of a logic with additional information of a semantic proof-theoretical nature. Labelled deduction systems often possess attractive properties, such as modularity in the way that families of related logics are presented, parameterised proofs of metatheoretic properties, and ease of mechanisability. It is thus not surprising that labelled deduction has been applied to problems in computer science, AI, mathematical logic, cognitive science, philosophy and computational linguistics-for example, formalizing and reasoning about dynamicstate oriented'properties such as knowledge, belief, time, space, and resources.", "num_citations": "40\n", "authors": ["1588"]}
{"title": "Rewriting logic as a metalogical framework\n", "abstract": " A metalogical framework is a logic with an associated methodology that is used to represent other logics and to reason about their metalogical properties. We propose that logical frameworks can be good metalogical frameworks when their logics support reflective reasoning and their theories always have initial models.               We present a concrete realization of this idea in rewriting logic. Theories in rewriting logic always have initial models and this logic supports reflective reasoning. This implies that inductive reasoning is valid when proving properties about the initial models of theories in rewriting logic, and that we can use reflection to reason at the metalevel about these properties. In fact, we can uniformly reflect induction principles for proving metatheorems about rewriting logic theories and their parameterized extensions. We show that this reflective methodology provides an effective framework for\u00a0\u2026", "num_citations": "40\n", "authors": ["1588"]}
{"title": "Predictable mobile routing for spacecraft networks\n", "abstract": " In predictable mobile networks, network nodes move in a predictable way and therefore have dynamically changing but predictable connectivity. We have developed a model that formalizes predictable dynamic topologies as sequences of static snapshots. We use this model to design and evaluate a predictable mobile-routing protocol based on link-state routing, whose performance is superior to its static and ad hoc counterparts. Our routing protocol accounts for occurrences of additional, unpredictable changes, as well as their interaction with predictable changes. We evaluate our protocol using simulations based on randomly generated topologies and spacecraft-network scenarios. In both cases, we show that our protocol outperforms traditional routing protocols and is well suited for routing in next-generation space networks.", "num_citations": "38\n", "authors": ["1588"]}
{"title": "Dynamic enforcement of abstract separation of duty constraints\n", "abstract": " Separation of Duties (SoD) aims to prevent fraud and errors by distributing tasks and associated privileges among multiple users. Li and Wang proposed an algebra (SoDA) for specifying SoD requirements, which is both expressive in the requirements it formalizes and abstract in that it is not bound to any specific workflow model. In this paper, we both generalize SoDA and map it to enforcement mechanisms. First, we increase SoDA\u2019s expressiveness by extending its semantics to multisets. This better suits policy enforcement over workflows, where users may execute multiple tasks. Second, we further generalize SoDA to allow for changing role assignments. This lifts the strong restriction that authorizations do not change during workflow execution. Finally, we map SoDA terms to CSP processes, taking advantage of CSP\u2019s operational semantics to provide the critical link between abstract specifications of\u00a0\u2026", "num_citations": "38\n", "authors": ["1588"]}
{"title": "Modeling human errors in security protocols\n", "abstract": " Many security protocols involve humans, not machines, as endpoints. The differences are critical: humans are not only computationally weaker than machines, they are naive, careless, and gullible. In this paper, we provide a model for formalizing and reasoning about these inherent human limitations and their consequences. Specifically, we formalize models of fallible humans in security protocols as multiset rewrite theories. We show how the Tamarin tool can then be used to automatically analyze security protocols involving human errors. We provide case studies of authentication protocols that show how different protocol constructions and features differ in their effectiveness with respect to different kinds of fallible humans. This provides a starting point for a fine-grained classification of security protocols from a usable-security perspective.", "num_citations": "37\n", "authors": ["1588"]}
{"title": "Java bytecode verification by model checking\n", "abstract": " Verification plays a central role in the security of Java bytecode: the Java bytecode verifier performs a static analysis to ensure that bytecode loaded over a network has certain security related properties. When this is the case, the bytecode can be efficiently interpreted without runtime security checks. Our research concerns the theoretical foundations of bytecode verification and alternative approaches to specifying and checking security properties. This is important as currently the \u201csecurity policy\u201d for Java bytecode is given informally by a natural language document [LY96] and the bytecode verifier itself is a closed system (part of the Java virtual machine). We believe that there are advantages to more formal approaches to security. A formal approach can disambiguate the current policy and provide a basis for verification tools. It can also help expose bugs or weaknesses that can corrupt Java security [MF97\u00a0\u2026", "num_citations": "37\n", "authors": ["1588"]}
{"title": "The MonPoly Monitoring Tool.\n", "abstract": " MonPoly is a monitoring tool for checking logs against formulas of metric first-order temporal logic. We provide here an overview of the tool, including its usage and history.", "num_citations": "36\n", "authors": ["1588"]}
{"title": "How to evaluate the security of real-life cryptographic protocols?\n", "abstract": " Governments and international standards bodies have established certification procedures for security-critical technologies, such as cryptographic algorithms. Such standards have not yet been established for cryptographic protocols and hence it is difficult for users of these protocols to know whether they are trustworthy. This is a serious problem as many protocols proposed in the past have failed to achieve their stated security properties. In this paper, we propose a framework for certifying cryptographic protocols. Our framework specifies procedures for both protocol designers and evaluators for certifying protocols with respect to three different assurance levels. This framework is being standardized as ISO/IEC 29128 in ISO/IEC JTC1 SC27/WG3, in which three of the authors are project co-editors. As a case study in the application of our proposal, we also present the plan for the open evaluation of entity\u00a0\u2026", "num_citations": "36\n", "authors": ["1588"]}
{"title": "Code generation for Event-B\n", "abstract": " We present an approach to generating program code from Event-B models that is correct-by-construction. Correctness is guaranteed by the combined use of well-definedness restrictions, refinement, and assertions. By enforcing the well-definedness of the translated model, we prevent runtime errors that originate from semantic differences between the target language and Event-B, such as different interpretations of the range of integer values. Using refinement, we show that the generated code correctly implements the original Event-B model. We provide a simple yet powerful scheduling language that allows one to specify an execution sequence of the model\u2019s guarded events where assertions are used to express properties established by the event execution sequence, which are necessary for well-definedness and refinement proofs.", "num_citations": "35\n", "authors": ["1588"]}
{"title": "Experience with FS0 as a Framework Theory\n", "abstract": " Feferman has proposed a system, FSo, as an alternative framework for encoding logics and also for reasoning about those encodings. We have implemented a version of this framework and performed experi-ments that show that it is practical. Specifically, we describe a formal-isation of predicate calculus and the development of an admissible rule that manipulates formulae with bound variables. This application will be of interest to researchers working with frameworks that use mecha-nisms based on substitution in the lambda calculus to implement variable binding and substitution in the declared logic directly. We suggest that meta-theoretic reasoning, even for a theory using bound variables, is not as difficult as is often supposed, and leads to more powerful ways of reasoning about the encoded theory.", "num_citations": "35\n", "authors": ["1588"]}
{"title": "Developing security protocols by refinement\n", "abstract": " We propose a development method for security protocols based on stepwise refinement. Our refinement strategy guides the transformation of abstract security goals into protocols that are secure when operating over an insecure channel controlled by a Dolev-Yao-style intruder. The refinement steps successively introduce local states, an intruder, communication channels with security properties, and cryptographic operations realizing these channels. The abstractions used provide insights on how the protocols work and foster the development of families of protocols sharing a common structure and properties. In contrast to post-hoc verification methods, protocols are developed together with their correctness proofs. We have implemented our method in Isabelle/HOL and used it to develop different entity authentication and key transport protocols.", "num_citations": "34\n", "authors": ["1588"]}
{"title": "Metareasoning about security protocols using distributed temporal logic\n", "abstract": " We introduce a version of distributed temporal logic for rigorously formalizing and proving metalevel properties of different protocol models, and establishing relationships between models. The resulting logic is quite expressive and provides a natural, intuitive language for formalizing both local (agent specific) and global properties of distributed communicating processes. Through a sequence of examples, we show how this logic may be applied to formalize and establish the correctness of different modeling and simplification techniques, which play a role in building effective protocol tools.", "num_citations": "34\n", "authors": ["1588"]}
{"title": "Securing the distribution and storage of secrets with trusted platform modules\n", "abstract": " We present a protocol that allows servers to securely distribute secrets to trusted platforms. The protocol maintains the confidentiality of secrets in the face of eavesdroppers and careless users. Given an ideal (tamper-proof) trusted platform, the protocol can even withstand attacks by dishonest users. As an example of its use, we present an application to secure document processing.", "num_citations": "33\n", "authors": ["1588"]}
{"title": "The Boyer-Moore prover and Nuprl: An experimental comparison\n", "abstract": " We use an example to compare the Boyer-Moore Theorem Prover and the Nuprl Proof Development System. The respective machine veri cations of a version of Ramsey's theorem illustrate similarities and di erences between the two systems. The proofs are compared using both quantitative and non-quantitative measures, and we examine di culties in making such comparisons.", "num_citations": "33\n", "authors": ["1588"]}
{"title": "A term equality problem equivalent to graph isomorphism\n", "abstract": " We demonstrate that deciding if two terms containing otherwise uninterpreted associative, commutative, and associative-commutative function symbols and commutative variable-binding operators are equal is polynomially equivalent to determining if two graphs are isomorphic. The reductions we use provide insight into this result and suggest polynomial time special cases.", "num_citations": "32\n", "authors": ["1588"]}
{"title": "On secure data deletion\n", "abstract": " Secure data deletion is the task of deleting data from a physical medium, such as a hard drive, phone, or blackboard, so that the data is irrecoverable. This irrecoverability distinguishes secure deletion from regular file deletion, which deletes unneeded data only to reclaim resources. Users securely delete data to prevent adversaries from gaining access to it. In this article, we explore approaches to securely delete digital data, describe different adversaries' capabilities, and show how secure deletion approaches can be integrated into systems at different interface levels to protect against specific adversaries.", "num_citations": "31\n", "authors": ["1588"]}
{"title": "Automatically deriving information-theoretic bounds for adaptive side-channel attacks\n", "abstract": " We present a model of adaptive attacks which we combine with information-theoretic metrics to quantify the information revealed to an adaptive adversary. This enables us to express an adversary's remaining uncertainty about a secret as a function of the number of interactions with the system under attack. We present algorithms and approximation methods for computing this function. The main application area for our approach is the analysis of side-channels in cryptographic algorithms and we give examples of how it can be used to characterize the vulnerability of hardware implementations to timing and power attacks. We also show the generality of our approach by using it to quantify the information leaked by a security protocol.", "num_citations": "31\n", "authors": ["1588"]}
{"title": "Degrees of security: Protocol guarantees in the face of compromising adversaries\n", "abstract": " We present a symbolic framework, based on a modular operational semantics, for formalizing different notions of compromise relevant for the analysis of cryptographic protocols. The framework\u2019s rules can be combined in different ways to specify different adversary capabilities, capturing different practically-relevant notions of key and state compromise. We have extended an existing security-protocol analysis tool, Scyther, with our adversary models. This is the first tool that systematically supports notions such as weak perfect forward secrecy, key compromise impersonation, and adversaries capable of state-reveal queries. We also introduce the concept of a protocol-security hierarchy, which classifies the relative strength of protocols against different forms of compromise. In case studies, we use Scyther to automatically construct protocol-security hierarchies that refine and correct relationships between\u00a0\u2026", "num_citations": "31\n", "authors": ["1588"]}
{"title": "Verification of combinational logic in Nuprl\n", "abstract": " We present a case study of hardware specification and verification in the Nuprl Proof Development System. Within Nuprl we have built a specialized environment consisting of tactics, definitions, and theorems for specifying and reasoning about hardware. Such reasoning typically consists of term-rewriting, case-analysis, induction, and arithmetic reasoning. We have built tools that provide high-level assistance for these tasks.             The hardware component that we have proven is the front end of a floating-point adder/subtractor. This component, the MAEC (Mantissa Adjuster and Exponent Calculator), has 5459 transistors and has been proven down to the transistor level. As the circuit has 116 inputs and 107 outputs, verification by traditional methods such as case analysis would have been a practical impossibility.", "num_citations": "31\n", "authors": ["1588"]}
{"title": "A complete characterization of secure human-server communication\n", "abstract": " Establishing a secure communication channel between two parties is a nontrivial problem, especially when one or both are humans. Unlike computers, humans cannot perform strong cryptographic operations without supporting technology, yet this technology may itself be compromised. We introduce a general communication topology model to facilitate the analysis of security protocols in this setting. We use it to completely characterize all topologies that allow secure communication between a human and a remote server via a compromised computer. These topologies are relevant for a variety of applications, including online banking and Internet voting. Our characterization can serve to guide the design of novel solutions for applications and to quickly exclude proposals that cannot possibly offer secure communication.", "num_citations": "29\n", "authors": ["1588"]}
{"title": "Applied information security: a hands-on approach\n", "abstract": " This book explores fundamental principles for securing IT systems and illustrates them with hands-on experiments that may be carried out by the reader using accompanying software. The experiments highlight key information security problems that arise in modern operating systems, networks, and web applications. The authors explain how to identify and exploit such problems and they show different countermeasures and their implementation. The reader thus gains a detailed understanding of how vulnerabilities arise and practical experience tackling them. After presenting the basics of security principles, virtual environments, and network services, the authors explain the core security principles of authentication and access control, logging and log analysis, web application security, certificates and public-key cryptography, and risk management. The book concludes with appendices on the design of related courses, report templates, and the basics of Linux as needed for the assignments. The authors have successfully taught IT security to students and professionals using the content of this book and the laboratory setting it describes. The book can be used in undergraduate or graduate laboratory courses, complementing more theoretically oriented courses, and it can also be used for self-study by IT professionals who want hands-on experience in applied information security. The authors' supporting software is freely available online and the text is supported throughout with exercises.", "num_citations": "29\n", "authors": ["1588"]}
{"title": "A model-driven methodology for developing secure data-management applications\n", "abstract": " We present a novel model-driven methodology for developing secure data-management applications. System developers proceed by modeling three different views of the desired application: its data model, security model, and GUI model. These models formalize respectively the application's data domain, authorization policy, and its graphical interface together with the application's behavior. Afterwards a model-transformation function lifts the policy specified by the security model to the GUI model. This allows a separation of concerns where behavior and security are specified separately, and subsequently combined to generate a security-aware GUI model. Finally, a code generator generates a multi-tier application, along with all support for access control, from the security-aware GUI model. We report on applications built using our approach and the associated tool.", "num_citations": "28\n", "authors": ["1588"]}
{"title": "Improving the security of cryptographic protocol standards\n", "abstract": " Despite being carefully designed, cryptographic protocol standards often turn out to be flawed. Integrating unambiguous security properties, clear threat models, and formal methods into the standardization process can improve protocol security.", "num_citations": "28\n", "authors": ["1588"]}
{"title": "A metamodel-based approach for analyzing security-design models\n", "abstract": " We have previously proposed an expressive UML-based language for constructing and transforming security-design models, which are models that combine design specifications for distributed systems with specifications of their security policies. Here we show how the same framework can be used to analyze these models: queries about properties of the security policy modeled are expressed as formulas in UML\u2019s Object Constraint Language and evaluated over the metamodel of the security-design language. We show how this can be done in a semantically precise and meaningful way and demonstrate, through examples, that this approach can be used to formalize and check non-trivial security properties of security-design models. The approach and examples presented have been implemented and checked in the SecureMOVA tool.", "num_citations": "28\n", "authors": ["1588"]}
{"title": "Relating strand spaces and distributed temporal logic for security protocol analysis\n", "abstract": " In previous work, we introduced a version of distributed temporal logic that is well-suited both for verifying security protocols and as a metalogic for reasoning about, and relating, different security protocol models. In this paper, we formally investigate the relationship between our approach and strand spaces, which is one of the most successful and widespread formalisms for analyzing security protocols. We define translations between models in our logic and strand-space models of security protocols, and we compare the results obtained with respect to the level of abstraction that is inherent in each of the formalisms. This allows us to clarify different aspects of strand spaces that are often left implicit, as well as pave the way to transfer results, techniques and tools across the two approaches.", "num_citations": "28\n", "authors": ["1588"]}
{"title": "Specifying and analyzing security automata using CSP-OZ\n", "abstract": " Security automata are a variant of B\u00fcchi automata used to specify security policies that can be enforced by monitoring system execution. In this paper, we propose using CSP-OZ, a specification language combining Communicating Sequential Processes (CSP) and Object-Z (OZ), to specify security automata, formalize their combination with target systems, and analyze the security of the resulting system specifications. We provide theoretical results relating CSP-OZ specifications and security automata and show how refinement can be used to reason about specifications of security automata and their combination with target systems. Through a case study, we provide evidence for the practical usefulness of this approach. This includes the ability to specify concisely complex operations and complex control, support for structured specifications, refinement, and transformational design, as well as automated, tool\u00a0\u2026", "num_citations": "27\n", "authors": ["1588"]}
{"title": "Verified bytecode model checkers\n", "abstract": " We have used Isabelle/HOL to formalize and prove correct an approach to bytecode verification based on model checking that we have developed for the Java Virtual Machine. Our work builds on, and extends, the formalization of the Java Virtual Machine and data flow analysis framework of Pusch and Nipkow. By building on their framework, we can reuse their results that relate the run-time behavior of programs with the existence of well-typings for the programs. Our primary extensions are to handle polyvariant data flow analysis and its realization as temporal logic model checking. Aside from establishing the correctness of our model-checking approach, our work contributes to understanding the interrelationships between classical data flow analysis and program analysis based on model checking.", "num_citations": "27\n", "authors": ["1588"]}
{"title": "Maude versus Haskell: an experimental comparison in security protocol analysis\n", "abstract": " We compare two executable languages: the rewriting logic based specification language Maude and the higher-order, lazy, functional programming language Haskell. We compare these languages experimentally on a problem in modeling and reasoning about a security protocol for authentication. We explore differences in how models can be formalized and analyzed, as well as performance and tool use.", "num_citations": "27\n", "authors": ["1588"]}
{"title": "Failure-aware runtime verification of distributed systems\n", "abstract": " Prior runtime-verification approaches for distributed systems are limited as they do not account for network failures and they assume that system messages are received in the order they are sent. To overcome these limitations, we present an online algorithm for verifying observed system behavior at runtime with respect to specifications written in the real-time logic MTL that efficiently handles out-of-order message deliveries and operates in the presence of failures. Our algorithm uses a three-valued semantics for MTL, where the third truth value models knowledge gaps, and it resolves knowledge gaps as it propagates Boolean values through the formula structure. We establish the algorithm's soundness and provide completeness guarantees. We also show that it supports distributed system monitoring, where multiple monitors cooperate and exchange their observations and conclusions.", "num_citations": "26\n", "authors": ["1588"]}
{"title": "Deconstructing alice and bob\n", "abstract": " Alice&Bob\u2013notation is a simple notation for describing security protocols as sequences of message exchanges. We show that, despite the fact that Alice&Bob\u2013notation does not include explicit control flow constructs, it is possible to make some of these aspects explicit when producing formal protocol models without having to resort to more expressive protocol description languages. We introduce a notion of incremental symbolic run to formally handle message forwarding and conditional abortion. In incremental symbolic runs, we use variables to represent messages that the principals cannot read, and we characterize each of the execution steps in order to build a collection of symbolic subruns of increasing lengths, reflecting the data possessed by the principals up to that point in the execution. We contrast this with the simpler (more standard) approach based on formalizing the behavior of principals by directly\u00a0\u2026", "num_citations": "26\n", "authors": ["1588"]}
{"title": "Scalable offline monitoring of temporal specifications\n", "abstract": " We propose an approach to monitoring IT systems offline where system actions are logged in a distributed file system and subsequently checked for compliance against policies formulated in an expressive temporal logic. The novelty of our approach is that monitoring is parallelized so that it scales to large logs. Our technical contributions comprise a formal framework for slicing logs, an algorithmic realization based on MapReduce, and a high-performance implementation. We evaluate our approach analytically and experimentally, proving the soundness and completeness of our slicing techniques and demonstrating its practical feasibility and efficiency on real-world logs with 400\u00a0GB of relevant data.", "num_citations": "25\n", "authors": ["1588"]}
{"title": "Efficient construction of machine-checked symbolic protocol security proofs\n", "abstract": " We embed an untyped security protocol model in the interactive theorem prover Isabelle/HOL and derive a theory for constructing proofs of secrecy and authentication properties. Our theory is based on two key ingredients. The first is an inference rule for enumerating the possible origins of messages known to the intruder. The second is a class of protocol-specific invariants that formalize type assertions about variables in protocol specifications. The resulting theory is well suited for interactively constructing human-readable, protocol security proofs. We additionally give an algorithm that automatically generates Isabelle/HOL proof scripts based on this theory. We provide case studies showing that both interactive and automatic proof construction are efficient. The resulting proofs provide strong correctness guarantees since all proofs, including those deriving our theory from the security protocol model, are machine\u00a0\u2026", "num_citations": "25\n", "authors": ["1588"]}
{"title": "User-level secure deletion on log-structured file systems\n", "abstract": " Deleting a file from a storage medium serves two purposes: it reclaims storage resources and ensures that any sensitive information contained in the file becomes inaccessible. When done for the latter purpose, it is critical that the file is securely deleted, meaning that its content does not persist on the storage medium after deletion. Secure deletion is the act of deleting data from a storage medium such that the data is afterwards irrecoverable from the storage medium. The time between deleting data and it becoming irrecoverable is called the deletion latency.", "num_citations": "25\n", "authors": ["1588"]}
{"title": "Automatic generation of smart, security-aware GUI models\n", "abstract": " In many software applications, users access application data using graphical user interfaces (GUIs). There is an important, but little explored, link between visualization and security: when the application data is protected by an access control policy, the GUI should be aware of this and respect the policy. For example, the GUI should not display options to users for actions that they are not authorized to execute on application data. Taking this idea one step further, the application GUI should not just be security-aware, it should also be smart. For example, the GUI should not display options to users for opening other widgets when these widgets will only display options for actions that the users are not authorized to execute on application data. We establish this link between visualization and security using a model-driven development approach. Namely, we define and implement a many-models-to-model\u00a0\u2026", "num_citations": "25\n", "authors": ["1588"]}
{"title": "Cardinality estimators do not preserve privacy\n", "abstract": " Cardinality estimators like HyperLogLog are sketching algorithms that estimate the number of distinct elements in a large multiset. Their use in privacy-sensitive contexts raises the question of whether they leak private information. In particular, can they provide any privacy guarantees while preserving their strong aggregation properties? We formulate an abstract notion of cardinality estimators, that captures this aggregation requirement: one can merge sketches without losing precision. We propose an attacker model and a corresponding privacy definition, strictly weaker than differential privacy: we assume that the attacker has no prior knowledge of the data. We then show that if a cardinality estimator satisfies this definition, then it cannot have a reasonable level of accuracy. We prove similar results for weaker versions of our definition, and analyze the privacy of existing algorithms, showing that their average privacy loss is significant, even for multisets with large cardinalities. We conclude that strong aggregation requirements are incompatible with any reasonable definition of privacy, and that cardinality estimators should be considered as sensitive as raw data. We also propose risk mitigation strategies for their real-world applications.", "num_citations": "24\n", "authors": ["1588"]}
{"title": "Alethea: A provably secure random sample voting protocol\n", "abstract": " In random sample voting, only a randomly chosen subset of all eligible voters are selected to vote. This poses new security challenges for the voting protocol used. In particular, one must ensure that the chosen voters were randomly selected while preserving their anonymity. Moreover, the small number of selected voters leaves little room for error and only a few manipulations of the votes may significantly change the outcome. We propose Alethea, the first random sample voting protocol that satisfies end-to-end verifiability and receipt-freeness. Our protocol makes explicit the distinction between human voters and their devices. This allows for more fine-grained statements about the required capabilities and trust assumptions of each agent than is possible in previous work. We define new security properties related to the randomness and anonymity of the sample group and the probability of undetected\u00a0\u2026", "num_citations": "24\n", "authors": ["1588"]}
{"title": "Optimal security-aware query processing\n", "abstract": " Security-Aware Query Processing is the problem of computing answers to queries in the presence of access control policies. We present general impossibility results for the existence of optimal algorithms for Security-Aware Query Processing and classify query languages for which such algorithms exist. In particular, we show that for the relational calculus there are no optimal algorithms, whereas optimal algorithms exist for some of its fragments, such as the existential fragment. We also establish relationships between two different models of Fine-Grained Access Control, called Truman and Non-Truman models, which have been previously presented in the literature as distinct. For optimal Security-Aware Query Processing, we show that the Non-Truman model is a special case of the Truman model for boolean queries in the relational calculus, moreover the two models coincide for more powerful languages, such\u00a0\u2026", "num_citations": "24\n", "authors": ["1588"]}
{"title": "Monitoring usage-control policies in distributed systems\n", "abstract": " We have previously presented a monitoring algorithm for compliance checking of policies formalized in an expressive metric first-order temporal logic. We explain here the steps required to go from the original algorithm to a working infrastructure capable of monitoring an existing distributed application producing millions of log entries per day. The main challenge is to correctly and efficiently monitor the trace interleavings obtained by totally ordering actions that happen at the same time. We provide solutions based on formula transformations and monitoring representative traces. We also report, for the first time, on statistics on the performance of our monitor on real-world data, providing evidence of its suitability for nontrivial applications.", "num_citations": "24\n", "authors": ["1588"]}
{"title": "BAP: Broadcast authentication using cryptographic puzzles\n", "abstract": " We present two broadcast authentication protocols based on delayed key disclosure. Our protocols rely on symmetric-key cryptographic primitives and use cryptographic puzzles to provide efficient broadcast authentication in different application scenarios, including those with resource-constrained wireless devices such as sensor nodes. The strong points of the protocols proposed are that one protocol allows instantaneous message origin authentication, whereas the other has low communication overhead. In addition to formalizing and analyzing these specific protocols, we carry out a general analysis of broadcast authentication protocols based on delayed key disclosure. This analysis uncovers fundamental limitations of this class of protocols in terms of the required accuracy of message propagation time estimations, if the protocols are to guarantee security and run efficiently.", "num_citations": "24\n", "authors": ["1588"]}
{"title": "Towards an awareness-based semantics for security protocol analysis\n", "abstract": " We report on work-in-progress on a new semantics for analyzing security protocols that combines complementary features of security logics and inductive methods. We use awareness to model the agents' resource-bounded reasoning and, in doing so, capture a more appropriate notion of belief than those usually considered in security logics. We also address the problem of modeling interleaved protocol executions, adapting ideas from inductive methods for protocol verification. The result is an intuitive, but expressive, doxastic logic for formalizing and reasoning about attacks. As a case study, we use awareness to characterize, and demonstrate the existence of, a man-in-the-middle attack upon the Needham-Schroeder Public Key protocol. This is, to our knowledge, not only the first doxastic analysis of this attack but also the first practical application of an awareness logic. Even though defining the awareness sets\u00a0\u2026", "num_citations": "24\n", "authors": ["1588"]}
{"title": "Monitoring data usage in distributed systems\n", "abstract": " IT systems manage increasing amounts of sensitive data and there is a growing concern that they comply with policies that regulate data usage. In this paper, we use temporal logic to express policies and runtime monitoring to check system compliance. While well-established methods for monitoring linearly ordered system behavior exist, a major challenge is monitoring distributed and concurrent systems where actions are locally observed in the different system parts. These observations can only be partially ordered, while policy compliance may depend on the actions' actual order of appearance. Technically speaking, it is in general intractable to check compliance of partially ordered traces. We identify fragments of our policy specification language for which compliance can be checked efficiently, namely, by monitoring a single representative trace in which the observed actions are totally ordered. Through a case\u00a0\u2026", "num_citations": "23\n", "authors": ["1588"]}
{"title": "Dynamic enforcement of abstract separation of duty constraints\n", "abstract": " Separation of Duties (SoD) aims at preventing fraud and errors by distributing tasks and associated authorizations among multiple users. Li and Wang [2008] proposed an algebra (SoDA) for specifying SoD requirements, which is both expressive in the requirements it formalizes and abstract in that it is not bound to a workflow model. In this article, we bridge the gap between the specification of SoD constraints modeled in SoDA and their enforcement in a dynamic, service-oriented enterprise environment. We proceed by generalizing SoDA's semantics to traces, modeling workflow executions that satisfy the respective SoDA terms. We then refine the set of traces induced by a SoDA term to also account for a workflow's control-flow and role-based authorizations. Our formalization, which is based on the process algebra CSP, supports the enforcement of SoD on general workflows and handles changing role\u00a0\u2026", "num_citations": "23\n", "authors": ["1588"]}
{"title": "Refining key establishment\n", "abstract": " We use refinement to systematically develop a family of key establishment protocols using a theorem prover. Our development spans four levels of abstraction: abstract security properties, message-less guard protocols, protocols communicating over channels with security properties, and protocols secure with respect to a Dolev-Yao intruder. The protocols we develop are Needham-Schroeder Shared Key, the core of Kerberos 4 and 5, and Denning Sacco, and include realistic features such as key confirmation, replay caches, and encrypted tickets. Our development highlights that message-less guard protocols provide a fundamental abstraction for bridging the gap between security properties and message-based protocol descriptions. It also shows that the refinement approach presented in [SB10] can be applied, with minor adaption, to families of key establishment protocols and that it scales to protocols of\u00a0\u2026", "num_citations": "23\n", "authors": ["1588"]}
{"title": "A modular presentation of modal logics in a logical framework\n", "abstract": " We present a theoretical and practical approach to the modular natural deduction presentation of modal logics and their implementation in a logical framework. Our work treats a large and well-known class of modal logics (including K, D, T, B, S4, S4: 2, KD45, S5) in a uniform way with respect to soundness and completeness for semantics, and faithfulness and adequacy of the implementation. Moreover, it results in a pleasingly simple and usable implementation of these logics. 1 Introduction Logical Frameworks such as the Edinburgh LF [8] and Isabelle [11] have been proposed as a solution to the problem of the explosion of logics and specialized provers for them. However, it is also acknowledged that this solution is not perfect: these frameworks are best suited for encodingwell-behaved'natural deduction formalisms with metatheories that don't deviate too far from the metatheory of the framework logic. Modal logics, in particular, are considered difficult to implement (eg [2, x4. 4.1...", "num_citations": "23\n", "authors": ["1588"]}
{"title": "Internet backbones in space\n", "abstract": " Several \"NewSpace\" companies have launched the first of thousands of planned satellites for providing global broadband Internet service. The resulting low-Earth-orbit (LEO) constellations will not only bridge the digital divide by providing service to remote areas, but they also promise much lower latency than terrestrial fiber for long-distance routes. We show that unlocking this potential is non-trivial: such constellations provide inherently variable connectivity, which today's Internet is ill-suited to accommodate. We therefore study cost-performance tradeoffs in the design space for Internet routing that incorporates satellite connectivity examining four solutions ranging from naively using BGP to an ideal, clean-slate design. We find that the optimal solution is provided by a path-aware networking architecture in which end-hosts obtain information and control over network paths. However, a pragmatic and more\u00a0\u2026", "num_citations": "22\n", "authors": ["1588"]}
{"title": "Symbolically analyzing security protocols using tamarin\n", "abstract": " During the last three decades, there has been considerable research devoted to the symbolic analysis of security protocols and existing tools have had considerable success both in detecting attacks on protocols and showing their absence. Nevertheless, there is still a large discrepancy between the symbolic models that one specifies on paper and the models that can be effectively analyzed by tools.", "num_citations": "22\n", "authors": ["1588"]}
{"title": "Decentralized composite access control\n", "abstract": " Formal foundations for access control policies with both authority delegation and policy composition operators are partial and limited. Correctness guarantees cannot therefore be formally stated and verified for decentralized composite access control systems, such as those based on XACML 3. To address this problem we develop a formal policy language BelLog that can express both delegation and composition operators. We illustrate, through examples, how BelLog can be used to specify practical policies. Moreover, we present an analysis framework for reasoning about BelLog policies and we give decidability and complexity results for policy entailment and policy containment in BelLog.", "num_citations": "21\n", "authors": ["1588"]}
{"title": "Separation of duties as a service\n", "abstract": " We introduce the concept of Separation of Duties (SoD) as a Service, an approach to enforcing SoD requirements on workflows and thereby preventing fraud and errors. SoD as a Service facilitates a separation of concern between business experts and security professionals. Moreover, it allows enterprises to address the need for internal controls and to quickly adapt to organizational, regulatory, and technological changes. In this paper, we describe an implementation of SoD as a Service, which extends a widely used, commercial workflow system, and discuss its performance. We present a drug dispensation workflow deployed in a hospital as case study to demonstrate the feasibility and benefits of our proof-of-concept implementation.", "num_citations": "21\n", "authors": ["1588"]}
{"title": "A new method for bounding the complexity of modal logics\n", "abstract": " We present a new proof-theoretic approach to bounding the complexity of the decision problem for propositional modal logics. We formalize logics in a uniform way as sequent systems and then restrict the structural rules for particular systems. This, combined with an analysis of the accessibility relation of the corresponding Kripke structures, yields decision procedures with bounded space requirements. As examples we give O(n log n) space procedures for the modal logics K and T.", "num_citations": "21\n", "authors": ["1588"]}
{"title": "Monitoring the GDPR\n", "abstract": " The General Data Protection Regulation (GDPR) has substantially strengthened the requirements for data processing systems, requiring audits at scale. We show how and to what extent these audits can be automated. We contribute an analysis of which parts of the GDPR can be monitored, a formalisation of these parts in metric first-order temporal logic, and an application of the MonPoly system to automatically audit these parts. We validate our ideas on a case study using log data from industry, detecting actual violations. Altogether, we demonstrate both in theory and practice how to automate GDPR compliance checking.", "num_citations": "20\n", "authors": ["1588"]}
{"title": "Model-driven development of a secure ehealth application\n", "abstract": " We report on our use of ActionGUI to develop a secure eHealth application based on the NESSoS eHealth case study. ActionGUI is a novel model-driven methodology with an associated tool for developing secure data-management applications with three distinguishing features. First, it enables a model-based separation of concerns, where behavior and security are modeled individually and subsequently combined. Second, it supports model-based quality assurance checks, where the properties proven about the models transfer to the generated applications. Finally, for data-management applications, the ActionGUI tool automatically generates complete, ready-to-deploy, security-aware, web applications. We explain these features in the context of the eHealth application.", "num_citations": "20\n", "authors": ["1588"]}
{"title": "Distributed temporal logic for the analysis of security protocol models\n", "abstract": " The distributed temporal logic DTL is an expressive logic, well suited for formalizing properties of concurrent, communicating agents. We show how DTL can be used as a metalogic to reason about and relate different security protocol models. This includes reasoning about model simplifications, where models are transformed to have fewer agents or behaviors, and verifying model reductions, where to establish the validity of a property it suffices to consider its satisfaction on only a subset of models. We illustrate how DTL can be used to formalize security models, protocols, and properties, and then present three concrete examples of metareasoning. First, we prove a general theorem about sufficient conditions for data to remain secret during communication. Second, we prove the equivalence of two models for guaranteeing message-origin authentication. Finally, we relate channel-based and intruder-centric models\u00a0\u2026", "num_citations": "20\n", "authors": ["1588"]}
{"title": "Keeping data secret under full compromise using porter devices\n", "abstract": " We address the problem of confidentiality in scenarios where the attacker is not only able to observe the communication between principals, but can also fully compromise the communicating parties (their devices, not only their long term secrets) after the confidential data has been exchanged. We formalize this problem and explore solutions that provide confidentiality after the full compromise of devices and user passwords. We propose two new solutions that use explicit key deletion and forward-secret protocols combined with key storage on porter devices. Our solutions provide the users with control over their privacy. We analyze the proposed solutions using an automatic verification tool. We also implement a prototype using a mobile phone as a porter device to illustrate how the solution can be realized on modern platforms.", "num_citations": "20\n", "authors": ["1588"]}
{"title": "Logical frameworks\n", "abstract": " One way to define a logic is to specify a language and a deductive system. For example, the language of first-order logic consists of the syntactic categories of terms and formulae, and its deductive system establishes which formulae are theorems. Typically we have a specific language in mind for a logic, but some flexibility about the kind of deductive system we use; we are able to select from, e.g., a Hilbert calculus, a sequent calculus, or a natural deduction calculus. A logical framework is an abstract characterization of one of these kinds of deductive system that we can use to formalize particular examples. Thus a logical framework for natural deduction should allow us to formalize natural deduction for a wide range of logics from, e.g., propositional logic to intuitionistic type-theories or classical higher-order logic.", "num_citations": "20\n", "authors": ["1588"]}
{"title": "Optimal play against best defence: Complexity and heuristics\n", "abstract": " We investigate the best defence model of an imperfect information game. In particular, we prove that finding optimal strategies for this model is NP-complete in the size of the game tree. We then introduce two new heuristics for this problem and show that they outperform previous algorithms. We demonstrate the practical use and effectiveness of these heuristics by testing them on random game trees and on a hard set of problems from the game of Bridge. For the Bridge problem set, our heuristics actually outperform the human experts who produced the model solutions.", "num_citations": "20\n", "authors": ["1588"]}
{"title": "Distance bounding protocol with minimal variance processing\n", "abstract": " The method for communicating between a first device and a second device, the first and second devices being structured and configured for communicating via a communication channel by exchanging messages, comprises the steps of", "num_citations": "19\n", "authors": ["1588"]}
{"title": "Information Security and Cryptography\n", "abstract": " \u2022 Bleichenbacher\u2019s 1-Million-Chosen-Ciphertext Attack against schemes that implement the RSA encryption standard PKCS# 1 is discussed in detail in Chapter 3. This attack proves that adaptively-chosen-ciphertext attacks can be a real danger in practice.\u2022 In Chapter 9 on provably secure encryption we have added typical security proofs for public-key encryption schemes that resist adaptively-chosenciphertext attacks. Two prominent examples are studied\u2013Boneh\u2019s simple-OAEP, or SAEP for short, and Cramer-Shoup\u2019s public key encryption.\u2022 Security proofs in the random oracle model are now included. Full-domainhash RSA signatures and SAEP serve as examples.", "num_citations": "19\n", "authors": ["1588"]}
{"title": "Timing-sensitive information flow analysis for synchronous systems\n", "abstract": " Timing side channels are a serious threat to the security of cryptographic algorithms. This paper presents a novel method for the timing-sensitive analysis of information flow in synchronous hardware circuits. The method is based on a parameterized notion of confidentiality for finite transition systems that allows one to model information leakage in a fine-grained way. We present an efficient decision procedure for system security and apply it to discover timing leaks in nontrivial hardware implementations of cryptographic algorithms.", "num_citations": "19\n", "authors": ["1588"]}
{"title": "A higher-order interpretation of deductive tableau\n", "abstract": " Abstract The Deductive Tableau of Manna and Waldinger is a formal system with an associated methodology for synthesizing functional programs by existence proofs in classical first-order theories. We reinterpret the formal system in a setting that is higher-order in two respects: higher-order logic is used to formalize a theory of functional programs and higher-order resolution is used to synthesize programs during proof. Their synthesis methodology can be applied in our setting as well as new methodologies that take advantage of these higher-order features. The reinterpretation gives us a framework for directly formalizing and implementing the Deductive Tableau system in standard theorem provers that support the kinds of higher-order reasoning listed above. We demonstrate this, as well as a new development methodology, within a conservative extension of higher-order logic in the Isabelle system. We report too\u00a0\u2026", "num_citations": "19\n", "authors": ["1588"]}
{"title": "Structural and behavioral modeling with monadic logics\n", "abstract": " Logic offers the possibility of modeling and reasoning about hardware and software. But which logic? We propose monadic logics of strings and trees as good candidates for many kinds of discrete systems. These logics are natural, decidable, yet substantially more expressive, extensions of Boolean logic. We motivate their applicability through examples.", "num_citations": "19\n", "authors": ["1588"]}
{"title": "Networking in Heaven as on Earth\n", "abstract": " The Internet will undergo a major transformation as satellite-based Internet service providers start to disrupt the market. Constellations of hundreds to thousands of satellites promise to offer low-latency Internet to even the most remote areas. We anticipate exciting business and research opportunities.", "num_citations": "18\n", "authors": ["1588"]}
{"title": "Labelled tableaux for distributed temporal logic\n", "abstract": " The distributed temporal logic DTL is a logic for reasoning about temporal properties of discrete distributed systems from the local point of view of the system's agents, which are assumed to execute sequentially and to interact by means of synchronous event sharing. We present a sound and complete labelled tableaux system for full DTL. To achieve this, we first formalize a labelled tableaux system for reasoning locally at each agent and afterwards we combine the local systems into a global one by adding rules that capture the distributed nature of DTL. We also provide examples illustrating the use of DTL and our tableaux system.", "num_citations": "18\n", "authors": ["1588"]}
{"title": "Verification of a signature architecture with HOL-Z\n", "abstract": " We report on a case study in using HOL-Z, an embedding of Z in higher-order logic, to specify and verify a security architecture for administering digital signatures. We have used HOL-Z to formalize and combine both data-oriented and process-oriented architectural views. Afterwards, we formalized temporal requirements in Z and carried out verification in higher-order logic.               The same architecture has been previously verified using the SPIN model checker. Based on this, we provide a detailed comparison of these two different approaches to formalization (infinite state with rich data types versus finite state) and verification (theorem proving versus model checking). Contrary to common belief, our case study suggests that Z is well suited for temporal reasoning about process models with rich data. Moreover, our comparison highlights the advantages of this approach and provides evidence that, in the\u00a0\u2026", "num_citations": "18\n", "authors": ["1588"]}
{"title": "A formal analysis of the CORBA security service\n", "abstract": " We give a formal specification and analysis of the security service of CORBA, the Common Object Request Broker Architecture specified by the Object Management Group, OMG. In doing so, we tackle the problem of how one can apply lightweight formal methods to improve the precision and aid the analysis of a substantial, committee-designed, informal specification. Our approach is scenario-driven: we use representative scenarios to determine which parts of the informal specification should be formalized and verify the resulting formal specification against these scenarios. For the formalization, we have speci.ed a significant part of the security service\u2019s data-model using the formal language Z. Through this process, we have been able to sharpen the OMG-specification, uncovering a number of errors and omissions.", "num_citations": "18\n", "authors": ["1588"]}
{"title": "Formalizing constructive cryptography using CryptHOL\n", "abstract": " Computer-aided cryptography increases the rigour of cryptographic proofs by mechanizing their verification. Existing tools focus mainly on game-based proofs, and efforts to formalize composable frameworks such as Universal Composability have met with limited success. In this paper, we formalize an instance of Constructive Cryptography, a generic theory allowing for clean, composable cryptographic security statements. Namely, we extend CryptHOL, a framework for game-based proofs, with an abstract model of Random Systems and provide proof rules for their equality and composition. We formalize security as a special kind of system construction in which a complex system is built from simpler ones. As a simple case study, we formalize the construction of an information-theoretically secure channel from a key, a random function, and an insecure channel.", "num_citations": "17\n", "authors": ["1588"]}
{"title": "Runtime verification of temporal properties over out-of-order data streams\n", "abstract": " We present a monitoring approach for verifying systems at runtime. Our approach targets systems whose components communicate with the monitors over unreliable channels, where messages can be delayed or lost. In contrast to prior works, whose property specification languages are limited to propositional temporal logics, our approach handles an extension of the real-time logic MTL with freeze quantifiers for reasoning about data values. We present its underlying theory based on a new three-valued semantics that is well suited to soundly and completely reason online about event streams in the presence of message delay or loss. We also evaluate our approach experimentally. Our prototype implementation processes hundreds of events per second in settings where messages are received out of order.", "num_citations": "17\n", "authors": ["1588"]}
{"title": "Monitors for usage control\n", "abstract": " Distributed usage control is concerned with controlling how data may or may not be used after it has been given away. One strategy for enforcing usage control requirements is based on monitoring data usage and reacting to policy violations by imposing penalties. We show how to implement monitors for usage control requirements using runtime verification technology.", "num_citations": "17\n", "authors": ["1588"]}
{"title": "Extracting circuits from constructive proofs\n", "abstract": " We lay a foundation for using constructive type theory as a tool for combining hardware synthesis and verification. Specifically, we specialize the proofs-as-programs paradigm for the Nuprl constructive type theory to\" proofs-as-circuits\", whereby representations of circuits can be automatically synthesized from constructive proofs. We use a limited form of syntactic reflection to guarantee that synthesized objects correspond to circuits; the soundness of the type theory guarantees that these objects meet their stated behavioral specifications. our approach allows the modular construction of combinational and parameterized combinational circuits in parallel with their proofs of correctness.", "num_citations": "17\n", "authors": ["1588"]}
{"title": "Securing databases from probabilistic inference\n", "abstract": " Databases can leak confidential information when users combine query results with probabilistic data dependencies and prior knowledge. Current research offers mechanisms that either handle a limited class of dependencies or lack tractable enforcement algorithms. We propose a foundation for Database Inference Control based on ProbLog, a probabilistic logic programming language. We leverage this foundation to develop Angerona, a provably secure enforcement mechanism that prevents information leakage in the presence of probabilistic dependencies. We then provide a tractable inference algorithm for a practically relevant fragment of ProbLog. We empirically evaluate Angerona's performance showing that it scales to relevant security-critical problems.", "num_citations": "16\n", "authors": ["1588"]}
{"title": "Strong and provably secure database access control\n", "abstract": " Existing SQL access control mechanisms are extremely limited. Attackers can leak information and escalate their privileges using advanced database features such as views, triggers, and integrity constraints. This is not merely a problem of vendors lagging behind the state-of-the-art. The theoretical foundations for database security lack adequate security definitions and a realistic attacker model, both of which are needed to evaluate the security of modern databases. We address these issues and present a provably secure access control mechanism that prevents attacks that defeat popular SQL database systems.", "num_citations": "16\n", "authors": ["1588"]}
{"title": "FAST: an efficient decision procedure for deduction and static equivalence\n", "abstract": " Message deducibility and static equivalence are central problems in symbolic security protocol analysis. We present FAST, an efficient decision procedure for these problems under subterm-convergent equational theories. FAST is a C++ implementation of an improved version of the algorithm presented in our previous work. This algorithm has a better asymptotic complexity than other algorithms implemented by existing tools for the same task, and FAST's optimizations further improve these complexity results. We describe here the main ideas of our implementation and compare its performance with competing tools. The results show that our implementation is significantly faster: for many examples, FAST terminates in under a second, whereas other tools take several minutes.", "num_citations": "16\n", "authors": ["1588"]}
{"title": "Bytecode verification by model checking\n", "abstract": " Java bytecode verification is traditionally performed by using dataflow analysis. We investigate an alternative based on reducing bytecode verification to model checking. First, we analyze the complexity and scalability of this approach. We show experimentally that, despite an exponential worst-case time complexity, model checking type-correct bytecode using an explicit-state on-the-fly model checker is feasible in practice, and we give a theoretical account why this is the case. Second, we formalize our approach using Isabelle/HOL and prove its correctness. In doing so we build on the formalization of the Java Virtual Machine and dataflow analysis framework of Pusch and Nipkow and extend it to a more general framework for reasoning about model-checking-based analysis. Overall, our work constitutes the first comprehensive investigation of the theory and practice of bytecode verification by model checking.", "num_citations": "16\n", "authors": ["1588"]}
{"title": "An environment for automated reasoning about partial functions\n", "abstract": " We report on a new environment developed and implemented inside the Nuprl type theory that facilitates proving theorems about partial functions. It is the first such automated type-theoretic account of partiality. We demonstrate that such an environment can be used effectively for proving theorems about computability and for developing partial programs with correctness proofs. This extends the well-known proofs as programs paradigm to partial functions.", "num_citations": "16\n", "authors": ["1588"]}
{"title": "Analyzing first-order role based access control\n", "abstract": " We propose FORBAC, an extension of Role-Based Access Control (RBAC) based on first-order logic. FORBAC is expressive enough to formalize a wide range of access control policies. However, it is simple enough so that relevant policy analysis queries can be analyzed in NP, which we argue is a natural complexity class for this problem. To analyze queries efficiently, we reduce them to the problem of satisfiability modulo appropriate theories, and use off-the-shelf SMT solvers. We evaluate FORBAC's expressiveness and our approach to policy analysis in a case study, analyzing access control in a European bank.", "num_citations": "15\n", "authors": ["1588"]}
{"title": "Actor key compromise: Consequences and countermeasures\n", "abstract": " Despite Alice's best efforts, her long-term secret keys may be revealed to an adversary. Possible reasons include weakly generated keys, compromised key storage, subpoena, and coercion. However, Alice may still be able to communicate securely with other parties, depending on the protocol used. We call the associated property resilience against Actor Key Compromise (AKC). We formalise this property in a symbolic model and identify conditions under which it can and cannot be achieved. In case studies that include TLS and SSH, we find that many protocols are not resilient against AKC. We implement a concrete AKC attack on the mutually authenticated TLS protocol.", "num_citations": "15\n", "authors": ["1588"]}
{"title": "Semi-valid input coverage for fuzz testing\n", "abstract": " We define semi-valid input coverage (SVCov), the first coverage criterion for fuzz testing. Our criterion is applicable whenever the valid inputs can be defined by a finite set of constraints. SVCov measures to what extent the tests cover the domain of semi-valid inputs, where an input is semi-valid if and only if it satisfies all the constraints but one.", "num_citations": "15\n", "authors": ["1588"]}
{"title": "Logic frameworks for logic programs\n", "abstract": " We show how logical frameworks can provide a basis for logic program synthesis. With them, we may use first-order logic as a foundation to formalize and derive rules that constitute program development calculi. Derived rules may be in turn applied to synthesize logic programs using higher-order resolution during proof that programs meet their specifications. We illustrate this using Paulson's Isabelle system to derive and use a simple synthesis calculus based on equivalence preserving transformations.", "num_citations": "15\n", "authors": ["1588"]}
{"title": "Refining security protocols\n", "abstract": " We propose a development method for security protocols based on stepwise refinement. Our refinement strategy transforms abstract security goals into protocols that are secure when operating over an insecure channel controlled by a Dolev-Yao-style intruder. As intermediate levels of abstraction, we employ messageless guard protocols and channel protocols communicating over channels with security properties. These abstractions provide insights on why protocols are secure and foster the development of families of protocols sharing common structure and properties. We have implemented our method in Isabelle/HOL and used it to develop different entity authentication and key establishment protocols, including realistic features such as key confirmation, replay caches, and encrypted tickets. Our development highlights that guard protocols and channel protocols provide fundamental abstractions for bridging\u00a0\u2026", "num_citations": "14\n", "authors": ["1588"]}
{"title": "Greedily computing associative aggregations on sliding windows\n", "abstract": " We present an algorithm for combining the elements of subsequences of a sequence with an associative operator. The subsequences are given by a sliding window of varying size. Our algorithm is greedy and computes the result with the minimal number of operator applications.", "num_citations": "14\n", "authors": ["1588"]}
{"title": "Model-driven development of security-aware GUIs for data-centric applications\n", "abstract": " In this tutorial we survey a very promising instance of model-driven security: the full generation of security-aware graphical user interfaces (GUIs) from models for data-centric applications with access control policies. We describe the modeling concepts and languages employed and how model transformation can be used to automatically lift security policies from data models to GUI models. We work through a case study where we generate a security-aware GUI for a chatroom application. We also present a toolkit that supports the construction of security, data, and GUI models and generates complete, deployable, web applications from these models.", "num_citations": "14\n", "authors": ["1588"]}
{"title": "Cryptographically-sound protocol-model abstractions\n", "abstract": " We present a formal theory for cryptographically-sound theorem proving. Our starting point is the Backes-Pfitzmann-Waidner (BPW) model, which is a symbolic protocol model that is cryptographically sound in the sense of blackbox reactive simulatability. To achieve cryptographic soundness, this model is substantially more complex than standard symbolic models and the main challenge in formalizing and using this model is overcoming this complexity. We present a series of cryptographically-sound abstractions of the original BPW model that bring it much closer to standard Dolev-Yao style models. We present a case study showing that our abstractions enable proofs of complexity comparable to those based on more standard models. Our entire development has been formalized in Isabelle/HOL.", "num_citations": "14\n", "authors": ["1588"]}
{"title": "Formalizing and analyzing sender invariance\n", "abstract": " In many network applications and services, agents that share no secure channel in advance may still wish to communicate securely with each other. In such settings, one often settles for achieving security goals weaker than authentication, such as sender invariance. Informally, sender invariance means that all messages that seem to come from the same source actually do, where the source can perhaps only be identified by a pseudonym. This implies, in particular, that the relevant parts of messages cannot be modified by an intruder.             In this paper, we provide the first formal definition of sender invariance as well as a stronger security goal that we call strong sender invariance. We show that both kinds of sender invariance are closely related to, and entailed by, weak authentication, the primary difference being that sender invariance is designed for the context where agents can only be identified\u00a0\u2026", "num_citations": "14\n", "authors": ["1588"]}
{"title": "Bytecode model checking: An experimental analysis\n", "abstract": " Java bytecode verification is traditionally performed by a polynomial time data flow algorithm. We investigate an alternative based on reducing bytecode verification to model checking. Despite an exponential worst case time complexity, model checking type-correct bytecode is polynomial in practice when carried out using an explicit state, on the- fly model checker like Spin. We investigate this theoretically and experimentally and explain the practical advantages of this alternative.", "num_citations": "14\n", "authors": ["1588"]}
{"title": "Program development schemata as derived rules\n", "abstract": " We show how the formalization and application of schemata for program development can be reduced to the formalization and application of derived rules of inference. We formalize and derive schemata as rules in theories that axiomatize program data and programs themselves. We reduce schema-based program development to ordinary theorem proving, where higher-order unification is used to apply rules. Conceptually, our formalization is simple and unifies divergent views of schemata, program synthesis, and program transformation. Practically, our formalization yields a simple methodology for carrying out development using existing logical frameworks; we illustrate this in the domain of logic program synthesis and transformation using the Isabelle logical framework.", "num_citations": "14\n", "authors": ["1588"]}
{"title": "The research value of publishing attacks\n", "abstract": " Security research can be improved by more effectively sharing what is learned from attacks on information systems.", "num_citations": "13\n", "authors": ["1588"]}
{"title": "Abstract data types in event-B-an application of generic instantiation\n", "abstract": " Integrating formal methods into industrial practice is a challenging task. Often, different kinds of expertise are required within the same development. On the one hand, there are domain engineers who have specific knowledge of the system under development. On the other hand, there are formal methods experts who have experience in rigorously specifying and reasoning about formal systems. Coordination between these groups is important for taking advantage of their expertise. In this paper, we describe our approach of using generic instantiation to facilitate this coordination. In particular, generic instantiation enables a separation of concerns between the different parties involved in developing formal systems.", "num_citations": "13\n", "authors": ["1588"]}
{"title": "Specifying access control in Event-B\n", "abstract": " We investigate the idea of developing access control systems in Event-B by specifying separately the \"insecure\" target system and the security authorisation, then combining them together in order to construct a secure system. This is based on the work by Basin et. al. [6] where the chosen language is CSP-OZ. Moreover, in order to verify the secure system against some safety temporal properties, we propose an approach of constructing several abstract models corresponding to these properties, and using refinement to prove that the final system satisfies these properties.", "num_citations": "13\n", "authors": ["1588"]}
{"title": "Building theories in Nuprl\n", "abstract": " This paper provides an account of how mathematical knowledge is represented, reasoned about, and used computationally in a mechanized constructive theorem proving environment. We accomplish this by presenting a particular theory developed in the Nuprl proof development system: finite set theory culminating in Ramsey's theorem. We believe that this development is interesting as a case study in the relationship between constructive mathematics and computer science. Moreover, the aspects we emphasize \u2014 the high-level development of definitions and lemmas, the use of tactics to automate reasoning, and the use of type theory as a programming logic \u2014 are not restricted in relevance to this particular theory, and indicate the promise of our approach for other branches of constructive mathematics.", "num_citations": "13\n", "authors": ["1588"]}
{"title": "The cyber security body of knowledge\n", "abstract": " The CyBOK project would like to understand how the CyBOK is being used and its uptake. The project would like organisations using, or intending to use, CyBOK for the purposes of education, training, course development, professional development etc. to contact it at contact@ cybok. org to let the project know how they are using CyBOK.", "num_citations": "12\n", "authors": ["1588"]}
{"title": "Formal system modelling using abstract data types in Event-B\n", "abstract": " We present a formal modelling approach using Abstract Data Types (ADTs) for developing large-scale systems in Event-B. The novelty of our approach is the combination of refinement and instantiation techniques to manage the complexity of systems under development. With ADTs, we model system components on an abstract level, specifying only the necessary properties of the components. At the same time, we postpone the introduction of their concrete definitions to later development steps. We evaluate our approach using a largescale case study in train control systems. The results show that our approach helps reduce system details during early development stages and leads to simpler and more automated proofs.", "num_citations": "12\n", "authors": ["1588"]}
{"title": "Secure deletion on log-structured file systems\n", "abstract": " We address the problem of secure data deletion on log-structured file systems. We focus on the YAFFS file system, widely used on Android smartphones. We show that these systems provide no temporal guarantees on data deletion and that deleted data still persists for nearly 44 hours with average phone use and indefinitely if the phone is not used after the deletion. Furthermore, we show that file overwriting and encryption, methods commonly used for secure deletion on block-structured file systems, do not ensure data deletion in log-structured file systems. We propose three mechanisms for secure deletion on log-structured file systems. Purging is a user-level mechanism that guarantees secure deletion at the cost of negligible device wear. Ballooning is a user-level mechanism that runs continuously and gives probabilistic improvements to secure deletion. Zero overwriting is a kernel-level mechanism that guarantees immediate secure deletion without device wear. We implement these mechanisms on Nexus One smartphones and show that they succeed in secure deletion and neither prohibitively reduce the longevity of the flash memory nor noticeably reduce the device's battery lifetime. These techniques provide mobile phone users more confidence that data they delete from their phones are indeed deleted.", "num_citations": "12\n", "authors": ["1588"]}
{"title": "A monad-based modeling and verification toolbox with application to security protocols\n", "abstract": " We present an advanced modeling and verification toolbox for functional programs with state and exceptions. The toolbox integrates an extensible, monad-based, component model, a monad-based Hoare logic and weakest pre-condition calculus, and proof systems for temporal logic and bisimilarity. It is implemented in Isabelle/HOL using shallow embeddings and incorporates as much modeling and reasoning power as possible from Isabelle/HOL. We have validated the toolbox\u2019s usefulness in a substantial security protocol verification project.", "num_citations": "12\n", "authors": ["1588"]}
{"title": "Structuring metatheory on inductive definitions\n", "abstract": " We examine a problem for machine supported metatheory. There are true statements about a theory that are true of some (but only some) extensions; however, standard theory-structuring facilities do not support selective inheritance. We use the example of the deduction theorem for modal logic and show how a statement about a theory can explicitly formalize the closure conditions extensions should satisfy for it to remain true. We show how metatheories based on inductive definitions allow theories and general metatheorems to be organized this way and report on a case study using the theory FS0.", "num_citations": "12\n", "authors": ["1588"]}
{"title": "Modeling a hardware synthesis methodology in Isabelle\n", "abstract": " Formal Synthesis is a methodology developed at Kent for combining circuit design and verification. We have reinterpreted this methodology in Isabelle\u2019s theory of higher-order logic so that circuits are synthesized using higher-order resolution. Our interpretation simplifies and extends Formal Synthesis both conceptually and in implementation. It also supports integration of this development style with other synthesis methodologies and leads to techniques for developing new classes of circuits, e.g., recursive descriptions of parameterized circuits.", "num_citations": "12\n", "authors": ["1588"]}
{"title": "Generic system support for deductive program development\n", "abstract": " We report on a case study in using logical frameworks to support the formalization of programming calculi and their application to deduction-based program synthesis. Within a conservative extension of higher-order logic implemented in the Isabelle system, we derived rules for program development that can simulate those of the deductive tableau proposed by Manna and Waldinger. We have used the resulting theory to synthesize a library of verified programs, focusing on sorting algorithms. Our experience suggests that the methodology we propose is well suited both to implement and use programming calculi, extend them, partially automate them, and even formally reason about their correctness.", "num_citations": "12\n", "authors": ["1588"]}
{"title": "Termination orderings for rippling\n", "abstract": " Rippling is a special type of rewriting developed for inductive theorem proving. Bundy et. al. have shown that rippling terminates by providing a well-founded order for the annotated rewrite rules used by rippling. Here, we simplify and generalize this order, thereby enlarging the class of rewrite rules that can be used. In addition, we extend the power of rippling by proposing new domain dependent orders. These extensions elegantly combine rippling with more conventional term rewriting. Such combinations offer the flexibility and uniformity of conventional rewriting with the highly goal directed nature of rippling. Finally, we show how our orders simplify implementation of provers based on rippling.", "num_citations": "12\n", "authors": ["1588"]}
{"title": "SoK: Delegation and Revocation, the Missing Links in the Web's Chain of Trust\n", "abstract": " The ability to quickly revoke a compromised key is critical to the security of any public-key infrastructure. Regrettably, most traditional certificate revocation schemes suffer from latency, availability, or privacy problems. These problems are exacerbated by the lack of a native delegation mechanism in TLS, which increasingly leads domain owners to engage in dangerous practices such as sharing their private keys with third parties. We analyze solutions that address the longstanding delegation and revocation shortcomings of the web PKI, with a focus on approaches that directly affect the chain of trust (i.e., the X.509 certification path). For this purpose, we propose a 19-criteria framework for characterizing revocation and delegation schemes. We also show that combining short-lived delegated credentials or proxy certificates with an appropriate revocation system would solve several pressing problems.", "num_citations": "11\n", "authors": ["1588"]}
{"title": "Election security and economics: it\u2019s all about eve\n", "abstract": " A system\u2019s security must be understood with respect to the capabilities and behaviors of an adversary Eve. It is often assumed in security analysis that Eve acts as maliciously as possible. From an economic perspective, Eve tries to maximize her utility in a game with other participants. The game\u2019s rules are determined by the system and its security mechanisms, but Eve can invent new ways of interacting with participants. We show that Eve can be used as an interface to explore the interplay between security and economics in the domain of elections. Through examples, we illustrate how reasoning from both disciplines may be combined to explicate Eve\u2019s motives and capabilities and how this analysis could be used for reasoning about the security and performance of elections. We also point to future research directions at the intersection of these disciplines.", "num_citations": "11\n", "authors": ["1588"]}
{"title": "From Dolev-Yao to strong adaptive corruption: Analyzing security in the presence of compromising adversaries\n", "abstract": " We formalize a hierarchy of adversary models for security protocol analysis, ranging from a Dolev-Yao style adversary to more powerful adversaries who can reveal different parts of principals' states during protocol execution. We define our hierarchy by a modular operational semantics describing adversarial capabilities. We use this to formalize various, practically-relevant notions of key and state compromise. Our semantics can be used as a basis for protocol analysis tools. As an example, we extend an existing symbolic protocol-verification tool with our adversary models. The result is the first tool that systematically supports notions such as weak perfect forward secrecy, key compromise impersonation, and adversaries capable of so-called strong corruptions and state-reveal queries. As further applications, we use our model hierarchy to relate different adversarial notions, gaining new insights on their relative strengths, and we use our tool to find new attacks on protocols.", "num_citations": "11\n", "authors": ["1588"]}
{"title": "Two approaches to an information security laboratory\n", "abstract": " How can a laboratory-based course in Information Security be designed? We will present two approaches, one based on conflict, the other on review. The Conflict-Based Approach is popular and well-documented and here we just briefly recall its main features. The Review-Based Approach is less common and only partially documented. We have designed and held a reviewbased course that we present in detail as an exemplary realization of this approach. Finally, we compare and contrast both approaches, as well as the skills they convey. the conflict-based approachOver the past decade, various institutions have developed and offered so-called hacker labs. These labs emphasize real-time attack and defense activities. 2, 3, 5 We call this the Conflict-Based Approach. It is typically structured into four phases: 1. Knowledge acquisition: The students acquire the necessary offensive and defensive skills and\u00a0\u2026", "num_citations": "11\n", "authors": ["1588"]}
{"title": "Monte-carlo sampling in games with imperfect information: Empirical investigation and analysis\n", "abstract": " We investigate Monte-carlo sampling in games with imperfect information. We show that for very simple game trees the chance of nding the optimal strategy with Monte-carlo sampling rapidly approaches zero as the number of moves in the game increases. We explain this sub-optimality by identifying the di erent kinds of errors that can arise, and by analysing their interplay. We also relate our test results to real games, suggesting why the error rates observed in practice may not be so high.", "num_citations": "11\n", "authors": ["1588"]}
{"title": "Adding metatheoretic facilities to first-order theories\n", "abstract": " Generic proof systems like Isabelle provide some limited but useful metatheoretic facilities for declared logics; in particular, users can prove simple derived rules and also \u2018solve\u2019 formulae that contain metavariables\u2014a technique useful for program synthesis. We show how an arbitrary first-order theory can be conservatively extended to provide similar facilities, without a supporting metatheory, and examine what the limitations of this approach are.", "num_citations": "11\n", "authors": ["1588"]}
{"title": "Formally verified synthesis of combinational CMOS circuits\n", "abstract": " We present a system for simultaneously synthesizing and proving correct CMOS implementations of combinational circuits. Our system, developed within the Nuprl proof development system is based on a set of transformation rules that generate CMOS implementations from their logical specifications. Our research differs from previous work in three important ways: our rules are rigorously proven with respect to a formal transistor model, our transformation rules admit the synthesis of both pass transistor and series/parallel networks, and our implementation produces a human readable proof along with each circuit it synthesizes.", "num_citations": "11\n", "authors": ["1588"]}
{"title": "Igloo: Soundly linking compositional refinement and separation logic for distributed system verification\n", "abstract": " Lighthouse projects like CompCert, seL4, IronFleet, and DeepSpec have demonstrated that full system verification is feasible by establishing a refinement between an abstract system specification and an executable implementation. Existing approaches however impose severe restrictions on the abstract system specifications due to their limited expressiveness or versatility, or on the executable code due to their use of suboptimal code extraction or inexpressive program logics. We propose a novel methodology that combines the compositional refinement of event-based models of distributed systems with the verification of full-fledged program code using expressive separation logics, which support features of realistic programming languages like heap data structures and concurrency. Our main technical contribution is a formal framework that soundly relates event-based system models to program specifications in\u00a0\u2026", "num_citations": "10\n", "authors": ["1588"]}
{"title": "Large-scale system development using abstract data types and refinement\n", "abstract": " We present a formal modelling approach using Abstract Data Types (ADTs) for large-scale system development in Event-B. The novelty of our approach is the combination of refinement and instantiation techniques to manage the complexity of systems under development. With ADTs, we model system components on an abstract level, specifying just their necessary properties, and we postpone the introduction of their concrete definitions to later development steps. As the ADTs are incrementally instantiated and become more concrete, behavioural details of systems are expanded via refinement in a manner consistent with the ADTs' transformation. We evaluate this approach using a large-scale case study in train control systems. The results show that our approach helps reduce system details during early development stages and leads to simpler and more automated proofs.", "num_citations": "10\n", "authors": ["1588"]}
{"title": "Efficient decision procedures for message deducibility and static equivalence\n", "abstract": " We consider two standard notions in formal security protocol analysis: message deducibility and static equivalence under equational theories. We present new polynomial-time algorithms for deciding both notions under subterm convergent equational theories and under a theory representing symmetric encryption with the prefix property. For these equational theories, polynomial-time algorithms for the decision problems associated to both notions are well-known (although this has not been proven for static equivalence under the prefix theory). However, our algorithms have a significantly better asymptotic complexity than existing approaches.             As an application, we use our algorithm for static equivalence to discover off-line guessing attacks on the Kerberos protocol when implemented using a symmetric encryption scheme for which the prefix property holds.", "num_citations": "10\n", "authors": ["1588"]}
{"title": "Controlling access to documents: A formal access control model\n", "abstract": " Current access-control systems for documents suffer from one or more of the following limitations: they are coarse-grained, limited to XML documents, or unable to maintain control over copies of documents once they are released by the system. We present a formal model of a system that overcomes all of these restrictions. It is very fine-grained, supports a general class of documents, and provides a foundation for usage control.", "num_citations": "10\n", "authors": ["1588"]}
{"title": "Equality of terms containing associative-commutative functions and commutative binding operators is isomorphism complete\n", "abstract": " We demonstrate that deciding if two terms containing otherwise uninterpreted associative, commutative, and associative-commutative function symbols and commutative variable-binding operators are equal is polynomially equivalent to determining if two graphs are isomorphic. The reductions we use provide insight into this result and suggest polynomial time special cases.", "num_citations": "10\n", "authors": ["1588"]}
{"title": "Building problem-solving environments in constructive type theory\n", "abstract": " We have developed powerful environments within the Nuprl Proof Development System for problem solving in diverse domains. Definitions, proofs, and programs are constructed naturally and at a high-level in these environments, with decision procedures and other tactics providing a degree of automation approaching that found in more specialized theorem provers. Our environments have a wide range of applications that include: Ramsey theory, hardware specification and verification, combinational logic synthesis from proofs, CMOS circuit synthesis from boolean expressions, recursion theory, and partial program development. Several of these applications establish new theorem proving paradigms.", "num_citations": "10\n", "authors": ["1588"]}
{"title": "The EMV standard: Break, fix, verify\n", "abstract": " EMV is the international protocol standard for smartcard payment and is used in over 9 billion cards worldwide. Despite the standard\u2019s advertised security, various issues have been previously uncovered, deriving from logical flaws that are hard to spot in EMV\u2019s lengthy and complex specification, running over 2,000 pages.We formalize a comprehensive symbolic model of EMV in Tamarin, a state-of-the-art protocol verifier. Our model is the first that supports a fine-grained analysis of all relevant security guarantees that EMV is intended to offer. We use our model to automatically identify flaws that lead to two critical attacks: one that defrauds the cardholder and a second that defrauds the merchant. First, criminals can use a victim\u2019s Visa contactless card to make payments for amounts that require cardholder verification, without knowledge of the card\u2019s PIN. We built a proof-of-concept Android application and\u00a0\u2026", "num_citations": "9\n", "authors": ["1588"]}
{"title": "In the nick of time: Proactive prevention of obligation violations\n", "abstract": " We present a system model, an enforcement mechanism, and a policy language for the proactive enforcement of timed provisions and obligations. Our approach improves upon existing formalisms in two ways: (1) we exploit the target system's existing functionality to avert policy violations proactively, rather than compensate for them reactively, and, (2) instead of requiring the manual specification of remedial actions in the policy, we automatically deduce required actions directly from the policy. As a policy language, we employ timed dynamic condition response (DCR) processes. DCR primitives declaratively express timed provisions and obligations as causal relationships between events, and DCR states explicitly represent pending obligations. As key technical results, we show that enforceability of DCR policies is decidable, we give a sufficient polynomial time verifiable condition for a policy to be enforceable\u00a0\u2026", "num_citations": "9\n", "authors": ["1588"]}
{"title": "Verifying a signature architecture: a comparative case study\n", "abstract": " We report on a case study in applying different formal methods to model and verify an architecture for administrating digital signatures. The architecture comprises several concurrently executing systems that authenticate users and generate and store digital signatures by passing security relevant data through a tightly controlled interface. The architecture is interesting from a formal-methods perspective as it involves complex operations on data as well as process coordination and hence is a candidate for both data-oriented and process-oriented formal methods.               We have built and verified two models of the signature architecture using two representative formal methods. In the first, we specify a data model of the architecture in Z that we extend to a trace model and interactively verify by theorem proving. In the second, we model the architecture as a system of communicating processes that we verify by\u00a0\u2026", "num_citations": "9\n", "authors": ["1588"]}
{"title": "Theorem Proving in Higher Order Logics\n", "abstract": " Theorem Proving in Higher Order Logics (TPHOLs 2003) held September 8\u201312, 2003 in Rome, Italy. TPHOLs covers all aspects of theorem proving in higher order logics as well as related topics in theorem proving and verification. TPHOLs 2003 was co-located with TABLEAUX, the International Conference on Automated Reasoning with Analytic Tableaux and Related Methods, and with Calculemus, the Symposium on the Integration of Symbolic Computation and Mechanized Reasoning.There were 50 papers submitted to TPHOLs in the full research category, each of which was refereed by at least 3 reviewers, selected by the program committee. Of these submissions, 21 were accepted for presentation at the conference and publication in this volume. In keeping with tradition, TPHOLs 2003 also offered a venue for the presentation of work in progress, where researchers invite discussion by means of a brief preliminary talk and then discuss their work at a poster session. A supplementary proceedings containing associated papers for work in progress was published by the computer science department at the Universit\u00e4t Freiburg.", "num_citations": "9\n", "authors": ["1588"]}
{"title": "Automating meta-theory creation and system extension\n", "abstract": " In this paper we describe a first experiment with a new approach for building theorem provers that can formalize themselves, reason about themselves, and safely extend themselves with new inference procedures. Within the GETFOL system we have built a pair of functions that operate between the system's implementation and a theory about this implementation. The first function lifts the actual inference rules to axioms that comprise a theory of GETFOL's inference capabilities. This allows us to turn the prover upon itself whereby we may formally reason about its inference rules and derive new rules. The second function flattens new rules back into the underlying system. This provides a novel means of safe system self-extension and an efficient way of executing derived rules.", "num_citations": "9\n", "authors": ["1588"]}
{"title": "Fixing the achilles heel of e-voting: The bulletin board\n", "abstract": " The results of electronic elections should be verifiable so that any cheating is detected. To support this, many protocols employ an electronic bulletin board (BB) for publishing data that can be read by participants and used for verifiability checks. We demonstrate that the BB is itself a security-critical component that has often been treated too casually in previous designs and analyses. In particular, we present novel attacks on the e-voting protocols Belenios, Civitas, and Helios that violate some of their central security claims under realistic system assumptions. These attacks were outside the scope of prior security analyses as their verifiability notions assume an idealized BB.To enable the analysis of protocols under realistic assumptions about the BB, we introduce a new verifiability definition applicable to arbitrary BBs. We identify a requirement, called final-agreement, and formally prove that it is sufficient and, in\u00a0\u2026", "num_citations": "8\n", "authors": ["1588"]}
{"title": "Test execution checkpointing for web applications\n", "abstract": " Test isolation is a prerequisite for the correct execution of test suites on web applications. We present Test Execution Checkpointing, a method for efficient test isolation. Our method instruments web applications to support checkpointing and exploits this support to isolate and optimize tests. We have implemented and evaluated this method on five popular PHP web applications. The results show that our method not only provides test isolation essentially for free, it also reduces testing time by 44% on average.", "num_citations": "8\n", "authors": ["1588"]}
{"title": "Refining authenticated key agreement with strong adversaries\n", "abstract": " We develop a family of key agreement protocols that are correct by construction. Our work substantially extends prior work on developing security protocols by refinement. First, we strengthen the adversary by allowing him to compromise different resources of protocol participants, such as their long-term keys or their session keys. This enables the systematic development of protocols that ensure strong properties such as perfect-forward secrecy. Second, we broaden the class of protocols supported to include those with non-atomic keys and equationally defined cryptographic operators. We use these extensions to develop key agreement protocols including signed Diffie-Hellman and the core of IKEv1 and SKEME.", "num_citations": "8\n", "authors": ["1588"]}
{"title": "Access control synthesis for physical spaces\n", "abstract": " Access-control requirements for physical spaces, like office buildings and airports, are best formulated from a global viewpoint in terms of system-wide requirements. For example, \"there is an authorized path to exit the building from every room.\" In contrast, individual access-control components, such as doors and turnstiles, can only enforce local policies, specifying when the component may open. In practice, the gap between the system-wide, global requirements and the many local policies is bridged manually, which is tedious, error-prone, and scales poorly. We propose a framework to automatically synthesize local access control policies from a set of global requirements for physical spaces. Our framework consists of an expressive language to specify both global requirements and physical spaces, and an algorithm for synthesizing local, attribute-based policies from the global specification. We empirically\u00a0\u2026", "num_citations": "8\n", "authors": ["1588"]}
{"title": "Security testing beyond functional tests\n", "abstract": " We present a theory of security testing based on the basic distinction between system specifications and security requirements. Specifications describe a system\u2019s desired behavior over its interface. Security requirements, in contrast, specify desired properties of the world the system lives in. We propose the notion of a security rationale, which supports reductive security arguments for deriving a system specification and assumptions on the system\u2019s environment sufficient for fulfilling stated security requirements. These reductions give rise to two types of tests: those that test the system with respect to its specification and those that test the validity of the assumptions about the adversarial environment. It is the second type of tests that distinguishes security testing from functional testing and defies systematization and automation.", "num_citations": "8\n", "authors": ["1588"]}
{"title": "Consensus refined\n", "abstract": " Algorithms for solving the consensus problem are fundamental to distributed computing. Despite their brevity, their ability to operate in concurrent, asynchronous, and failure-prone environments comes at the cost of complex and subtle behaviors. Accordingly, understanding how they work and proving their correctness is a non-trivial endeavor where abstraction is immensely helpful. Moreover, research on consensus has yielded a large number of algorithms, many of which appear to share common algorithmic ideas. A natural question is whether and how these similarities can be distilled and described in a precise, unified way. In this work, we combine stepwise refinement and lockstep models to provide an abstract and unified view of a sizeable family of consensus algorithms. Our models provide insights into the design choices underlying the different algorithms, and classify them based on those choices. All our\u00a0\u2026", "num_citations": "8\n", "authors": ["1588"]}
{"title": "Alice and Bob meet equational theories\n", "abstract": " Cryptographic protocols are the backbone of secure communication over open networks and their correctness is therefore crucial. Tool-supported formal analysis of cryptographic protocol designs increases our confidence that these protocols achieve their intended security guarantees. We propose a method to automatically translate text-book style Alice&Bob protocol specifications into a format amenable to formal verification using existing tools. Our translation supports specification modulo equational theories, which enables the faithful representation of algebraic properties of a large class of cryptographic operators.", "num_citations": "8\n", "authors": ["1588"]}
{"title": "LTL is closed under topological closure\n", "abstract": " We constructively prove that for every LTL formula \u03c6, the smallest safety property containing the property expressed by \u03c6 is also expressible in LTL. It immediately follows that LTL admits the safety-liveness decomposition: any property expressed by an LTL formula is equivalent to the intersection of a safety property and a liveness property, both of them expressible in LTL. Our proof is based on constructing a minimal deterministic counter-free B\u00fcchi automaton that recognizes the smallest safety property containing the property expressed by \u03c6.", "num_citations": "8\n", "authors": ["1588"]}
{"title": "Implementing modal and relevance logics in a logical framework\n", "abstract": " We present a framework for machine imple-mentation of both partial and complete frag-ments of large families of non-classical logics such as modal, relevance, and intuitionistic logics. We decompose a logic into two interacting parts, each a natural deduction system: a base logic of labelled formulae, and a theory of labels characterizing the properties of the Kripke models. Our approach is modular and supports uniform proofs of correctness and proof normalization. We have implemented our work in the Isabelle LogicalFramework.", "num_citations": "8\n", "authors": ["1588"]}
{"title": "Some normalization properties of martin-l\u00f6f's type theory, and applications\n", "abstract": " For certain kinds of applications of type theories, the faithfulness of formalization in the theory depends on intensional, or structural, properties of objects constructed in the theory. For type theories such as LF, such properties can be established via an analysis of normal forms and types. In type theories such as Nuprl or Martin-L\u00f6f's polymorphic type theory, which are much more expressive than LF, the underlying programming language is essentially untyped, and terms proved to be in types do not necessarily have normal forms. Nevertheless, it is possible to show that for Martin-L\u00f6f's type theory, and a large class of extensions of it, a sufficient kind of normalization property does in fact hold in certain well-behaved subtheories. Applications of our results include the use of the type theory as a logical framework in the manner of LF, and an extension of the proofs-as-programs paradigm to the synthesis of verified\u00a0\u2026", "num_citations": "8\n", "authors": ["1588"]}
{"title": "Privacy-preserving openid connect\n", "abstract": " OpenID Connect is the most widely used Internet protocol for delegated authentication today. It provides single sign-on functionality for users who use their account with an identity provider to authenticate to different services, called relying parties. Unfortunately OpenID Connect is not privacy-friendly: the identity provider learns with each use which relying party the user logs in to. This necessitates a high degree of trust in the identity provider, and is especially problematic when the relying parties' identity reveals sensitive information. We present two extensions to OpenID Connect that address this privacy concern. We first present a simple extension that prevents the identity provider from learning to which relying parties its users log in, and we further extend this solution to also prevent colluding relying parties from tracking users. We give formal security proofs for both standard OpenID Connect and our extensions\u00a0\u2026", "num_citations": "7\n", "authors": ["1588"]}
{"title": "Information-flow control for database-backed applications\n", "abstract": " Securing database-backed applications requires tracking information across the application program and the database together, since securing each component in isolation may still result in an overall insecure system. Current research extends language-based techniques with models capturing the database's behavior. This research, however, relies on simplistic database models, which ignore security-relevant features that may leak sensitive information. We propose a novel security monitor for database-backed applications. Our monitor tracks fine-grained dependencies between variables and database tuples by leveraging database theory concepts like disclosure lattices and query determinacy. It also accounts for a realistic database model that supports security-critical constructs like triggers and dynamic policies. The monitor automatically synthesizes program-level code that replicates the behavior of\u00a0\u2026", "num_citations": "7\n", "authors": ["1588"]}
{"title": "Modal specifications of trace-based security properties\n", "abstract": " We introduce a multi-modal logic that combines complementary features of authentication logics and trace-based approaches. Our logic contains two kinds of modalities: implicit belief, which formalizes the view of an external agent reasoning about interleaved protocol executions, and explicit belief, which uses awareness to model the resource-bounded reasoning of the agents involved in the executions. We employ these modalities to formalize extensional and intensional specifications of protocols and their properties, and use these formalizations to characterize and reason about attacks. As an example, we consider the Needham-Schroeder Public Key protocol and use our logic to demonstrate the existence of the well-known man-in-the-middle attack, and also show the equivalence of our modal specification to one based on an interleaved trace semantics.1. INTRODUCTION Security protocols describe how agents should exchange messages to achieve security goals such as confidentiality and integrity of data, or authentication of the identity of agents in a network. A number of approaches have been proposed for rigorously analyzing security protocols. Some of these are based on specialized security logics, such as the foundational BAN logic for authentication protocols [6] and its extensions, eg [1, 4, 7, 13, 20, 21]. These logics work by formalizing the doxastic or epistemic reasoning of agents executing a protocol, and security properties are formalized and reasoned about in terms of the way the beliefs or the knowledge of the agents evolve as messages are exchanged. Although effective for finding some kinds of flaws, the logics' semantics\u00a0\u2026", "num_citations": "7\n", "authors": ["1588"]}
{"title": "B2M: A semantic based tool for BLIF hardware descriptions\n", "abstract": " BLIF is a hardware description language designed for the hierarchical description of sequential circuits. We give a denotational semantics for BLIF-MV, a popular dialect of BLIF, that interprets hardware descriptions in WS1S, the weak monadic second-order logic of one successor. We show how, using a decision procedure for WS1S, our semantics provides a simple but e.ective basis for diverse kinds of symbolic reasoning about circuit descriptions, including simulation, equivalence testing, and the automatic veri.cation of safety properties. We illustrate these ideas with the B2M tool, which compiles circuit descriptions down to WS1S formulae and analyzes them using the MONA system.", "num_citations": "7\n", "authors": ["1588"]}
{"title": "Decision procedures for inductive boolean functions based on alternating automata\n", "abstract": " We show how alternating automata provide decision procedures for the equivalence of inductively defined Boolean functions that are useful for reasoning about parameterized families of circuits. We use alternating word automata to formalize families of linearly structured circuits and alternating tree automata to formalize families of tree structured circuits. We provide complexity bounds and show how our decision procedures can be implemented using BDDs. In comparison to previous work, our approach is simpler, yields better complexity bounds, and, in the case of tree structured families, is more general.", "num_citations": "7\n", "authors": ["1588"]}
{"title": "A topography of labelled modal logics\n", "abstract": " Labelled Deductive Systems provide a general method for representing logics in a modular and transparent way. A Labelled Deductive System consists of two parts, a base logic and a labelling algebra, which interact through a fixed interface. The labelling algebra can be viewed as an independent parameter: the base logic stays fixed for a given class of related logics from which we can generate the one we want by plugging in the appropriate algebra. Our work identifies an important property of the structured presentation of logics, their combination, and extension. Namely, there is tension between modularity and extensibility: a narrow interface between the base logic and labelling algebra can limit the degree to which we can make use of extensions to the labelling algebra. We illustrate this in the case of modal logics and apply simple results from proof theory to give examples.", "num_citations": "7\n", "authors": ["1588"]}
{"title": "Generalized rewriting in type theory\n", "abstract": " While type theories such as Nuprl are expressive logics for theorem proving, they present di culties for designers of term rewriting systems. The two most serious di culties are: 1) They do not provide a global equality. Instead users rewrite over arbitrary user-de ned relations. 2) Each rewrite step must be proved valid. In general, these proofs cannot be recursively generated. We have overcome these di culties and designed a package for the Nuprl system that works well in practice. Our solution is an extensible set of functions for directing and validating relational inferences. The heart of our package is a set of operators that use a user-supplied lemma database to create new rewrites from old ones. These routines place no restrictions on relations; a rewrite's success depends on the strength of the database. Overall, the package allows rewrites to be pieced together in numerous ways, providing the user with a tool to construct sophisticated rewrite strategies.", "num_citations": "7\n", "authors": ["1588"]}
{"title": "A spectral analysis of noise: a comprehensive, automated, formal analysis of Diffie-Hellman protocols\n", "abstract": " The Noise specification describes how to systematically construct a large family of Diffie-Hellman based key exchange protocols, including the secure transports used by WhatsApp, Lightning, and WireGuard. As the specification only makes informal security claims, earlier work has explored which formal security properties may be enjoyed by protocols in the Noise framework, yet many important questions remain open.", "num_citations": "6\n", "authors": ["1588"]}
{"title": "Differential privacy with partial knowledge\n", "abstract": " Differential privacy offers formal quantitative guarantees for algorithms over datasets, but it assumes attackers that know and can influence all but one record in the database. This assumption often vastly overapproximates the attackers' actual strength, resulting in unnecessarily poor utility. Recent work has made significant steps towards privacy in the presence of partial background knowledge, which can model a realistic attacker's uncertainty. Prior work, however, has definitional problems for correlated data and does not precisely characterize the underlying attacker model. We propose a practical criterion to prevent problems due to correlations, and we show how to characterize attackers with limited influence or only partial background knowledge over the dataset. We use these foundations to analyze practical scenarios: we significantly improve known results about the privacy of counting queries under partial knowledge, and we show that thresholding can provide formal guarantees against such weak attackers, even with little entropy in the data. These results allow us to draw novel links between k-anonymity and differential privacy under partial knowledge. Finally, we prove composition results on differential privacy with partial knowledge, which quantifies the privacy leakage of complex mechanisms. Our work provides a basis for formally quantifying the privacy of many widely-used mechanisms, e.g. publishing the result of surveys, elections or referendums, and releasing usage statistics of online services.", "num_citations": "6\n", "authors": ["1588"]}
{"title": "Fail-secure access control\n", "abstract": " Decentralized and distributed access control systems are subject to communication and component failures. These can affect access decisions in surprising and unintended ways, resulting in insecure systems. Existing analysis frameworks however ignore the influence of failure handling in decision making. Thus, it is currently all but impossible to derive security guarantees for systems that may fail. To address this, we present (1) a model in which the attacker can explicitly induce failures,(2) failure-handling idioms, and (3) a method and an associated tool for verifying fail-security requirements, which describe how access control systems should handle failures. To illustrate these contributions, we analyze the consequences of failure handling in the XACML 3 standard and other domains, revealing security flaws.", "num_citations": "6\n", "authors": ["1588"]}
{"title": "Symbolic probabilistic analysis of off-line guessing\n", "abstract": " We introduce a probabilistic framework for the automated analysis of security protocols. Our framework provides a general method for expressing properties of cryptographic primitives, modeling an attacker more powerful than conventional Dolev-Yao attackers. It allows modeling equational properties of cryptographic primitives as well as property statements about their weaknesses, e.g. primitives leaking partial information about messages or the use of weak random generation algorithms. These properties can be used to automatically find attacks and estimate their success probability. Existing symbolic methods can neither model such properties nor find such attacks. We show that the probability estimates we obtain are negligibly different from those yielded by a generalized random oracle model based on sampling terms into bitstrings while respecting the stipulated properties of cryptographic primitives\u00a0\u2026", "num_citations": "6\n", "authors": ["1588"]}
{"title": "Evaluation of ISO/IEC 9798 protocols\n", "abstract": " This report provides a security evaluation of the authentication protocol families described in parts 2, 3, and 4 of the ISO-IEC 9798 standard. Our analysis includes formal models of the protocols and their security properties, an analysis of existing attacks and evaluations, a security analysis of the formal protocol models, and a list of recommendations.", "num_citations": "6\n", "authors": ["1588"]}
{"title": "Logging and log analysis\n", "abstract": " Operating systems and applications typically come with mechanisms for reporting errors as well as security-relevant actions such as users logging on and off. These events are reported as entries in log files. The objective of logging is to make these events transparent and comprehensible. The log files can be used to analyze and optimize services as well as to detect and diagnose security breaches.           Many logging mechanisms are not configured optimally in practice. Important messages go undetected because of the large number of log entries that are triggered by irrelevant events. Users and administrators often do not even know where to search for specific log files and how to configure the associated logging mechanisms.           There are a number of tools available that support administrators with the task of keeping track of log files. Particularly important are tools that analyze the log files. These files\u00a0\u2026", "num_citations": "6\n", "authors": ["1588"]}
{"title": "A Labeled Tableaux System for the Distributed Temporal Logic DTL\n", "abstract": " DTL is a distributed temporal logic for reasoning about temporal properties of distributed systems from the local point of view of the system's agents, which are assumed to execute sequentially and to interact by means of synchronous event sharing. We present a sound and complete labeled tableaux system for future-time DTL. To achieve this, we first formalize a labeled tableaux system for reasoning locally at each agent, which provides a system for full future-time LTL, and afterwards we combine the local systems into a global one by adding rules that capture the distributed nature of DTL.", "num_citations": "6\n", "authors": ["1588"]}
{"title": "Towards a metalogic for security protocol analysis\n", "abstract": " Many security protocols have been proposed to help build secure distributed systems. Given how difficult it is for humans to predict all possible ways for distributed computation to proceed, it is not so surprising that attacks have been found on many protocols that were originally believed to be secure. Due to the subtlety of the problem, the use of formal methods for analyzing security protocols has been gaining popularity. These include approaches based on process algebras, eg [5, 14, 20, 25], which support elegant models but lack a suitable logical language to express protocol properties; model-checking and related techniques, such as [2, 3, 11, 22, 26], which are suitable for automation but rely on simplifying assumptions (to yield finite models) and hence are difficult to use reliably on different applications; specialpurpose epistemic logics like BAN, eg [10], which provide for high-level knowledge-based formalizations of protocols and their properties, but whose semantics is complex, restricted, or simply lacking; and inductive theorem proving, like [24], which are general, but require time consuming interactive theorem proving by experienced researchers.In this paper, we report on our work-in-progress on the formalization of a suitable version of temporal logic for communicating agents which provides both an object level tool, where we can specify and reason about specific protocols, and a metalevel tool for the compared analysis of security protocol models and properties. Our starting point is the work of [15, 17], which focus on the expressibility of properties from the local point of view of each agent, and that we extend in order to express also\u00a0\u2026", "num_citations": "6\n", "authors": ["1588"]}
{"title": "Strategies explained\n", "abstract": " For many problem-solving tasks, it is important not only to produce solutions, but also to justify any solutions with explanations. In this paper, we describe how we are addressing this question within the framework of our research on computer game-playing. We build on the computer Bridge system Finesse, which nds optimal strategies for single-suit Bridge problems. To explain Finesse's strategies, we have developed an approach based on three distinct steps. First, we identify from a strategy the possible sequences of MAX plays that need to be explained. Second, we remove from consideration move sequences or game situations that would be considered too simple to explain to human players. Third, we produce natural English text with the aid of both game-general and game-specic patterns and idioms that can explain each MAX and MIN move. We demonstrate the eectiveness of this approach by comparing automatically generated explanations against those found in an expert Bridge text.", "num_citations": "6\n", "authors": ["1588"]}
{"title": "Deriving and applying logic program transformers\n", "abstract": " We present a methodology for logic program development based on the use of verified transformation templates. We use the Isabelle Logical Framework to formalize transformation templates as inference rules. We derive these rules in higher-order logic and afterwards use higher-order unification to apply them to develop programs in a deductive synthesis style. Our work addresses the pragmatics of template formalization and application as well as which theories and semantics of programs and data we require to derive templates.", "num_citations": "6\n", "authors": ["1588"]}
{"title": "Isawhelk: Whelk interpreted in Isabelle\n", "abstract": " The Whelk logic has been proposed as a foundation for logic program synthesis. Here, I interpret the rules of Whelk as rules of rst-order logic and derive them in Isabelle. Theoretically, this provides a means to understand the meta-theory behind Whelk, and its correctness. The interpretation suggests simpli cations, corrections, and extensions. Practically, it provides a way to construct logic programs from proofs of their correctness by applying the formalized proof rules using higher-order resolution.", "num_citations": "6\n", "authors": ["1588"]}
{"title": "A recursion planning analysis of inductive completion\n", "abstract": " We use the AI proof planning techniques of {\\it recursion analysis} and {\\it rippling} as tools to analyze so-called {\\it inductionless induction} proof techniques. Recursion analysis chooses induction schemas and variables and rippling controls rewriting in explicit induction proofs. They provide a basis for explaining the success and failure of inductionless induction, both in deduction of critical pairs and in their simplification. Furthermore, these explicit induction techniques motivate and provide insight into advancements in inductive completion algorithms and suggest directions for further improvements. Our study includes an experimental comparison of Clam, an explicit induction theorem prover, with an implementation of Huet and Hullot's inductionless induction.", "num_citations": "6\n", "authors": ["1588"]}
{"title": "Formal verification of secure forwarding protocols\n", "abstract": " Today\u2019s Internet is built on decades-old networking protocols that lack scalability, reliability, and security. In response, the networking community has developed path-aware Internet architectures that solve these issues while simultaneously empowering end hosts. In these architectures, autonomous systems construct authenticated forwarding paths based on their routing policies. Each end host then selects one of these authorized paths and includes it in the packet header, thus allowing routers to efficiently determine how to forward the packet. A central security property of these architectures is path authorization, requiring that packets can only travel along authorized paths. This property protects the routing policies of autonomous systems from malicious senders.The fundamental role of packet forwarding in the Internet and the complexity of the authentication mechanisms employed call for a formal analysis. In this\u00a0\u2026", "num_citations": "5\n", "authors": ["1588"]}
{"title": "Dispute resolution in voting\n", "abstract": " In voting, disputes arise when a voter claims that the voting authority is dishonest and did not correctly process his ballot while the authority claims to have followed the protocol. A dispute can be resolved if any third party can unambiguously determine who is right. We systematically characterize all relevant disputes for a generic, practically relevant, class of voting protocols. Based on our characterization, we propose a new definition of dispute resolution for voting that accounts for the possibility that both voters and the voting authority can make false claims and that voters may abstain from voting.A central aspect of our work is timeliness: a voter should possess the evidence required to resolve disputes no later than the election's end. We characterize what assumptions are necessary and sufficient for timeliness in terms of a communication topology for our voting protocol class. We formalize the dispute resolution\u00a0\u2026", "num_citations": "5\n", "authors": ["1588"]}
{"title": "The next 700 policy miners: A universal method for building policy miners\n", "abstract": " A myriad of access control policy languages have been and continue to be proposed. The design of policy miners for each such language is a challenging task that has required specialized machine learning and combinatorial algorithms. We present an alternative method, universal access control policy mining (Unicorn). We show how this method streamlines the design of policy miners for a wide variety of policy languages including ABAC, RBAC, RBAC with user-attribute constraints, RBAC with spatio-temporal constraints, and an expressive fragment of XACML. For the latter two, there were no known policy miners until now. To design a policy miner using Unicorn, one needs a policy language and a metric quantifying how well a policy fits an assignment of permissions to users. From these, one builds the policy miner as a search algorithm that computes a policy that best fits the given permission assignment. We\u00a0\u2026", "num_citations": "5\n", "authors": ["1588"]}
{"title": "Deciding safety and liveness in TPTL\n", "abstract": " We show that deciding whether a TPTL formula describes a safety property is EXPSPACE-complete. Moreover, deciding whether a TPTL formula describes a liveness property is in 2-EXPSPACE. Our algorithms for deciding these problems extend those presented by Sistla [1] to decide the corresponding problems for LTL.", "num_citations": "5\n", "authors": ["1588"]}
{"title": "On real-time monitoring with imprecise timestamps\n", "abstract": " Existing real-time monitoring approaches assume traces with precise timestamps. Their correctness is thus indefinite when monitoring the behavior of systems with imprecise clocks. We address this problem for a metric temporal logic: We identify classes of formulas for which we can leverage existing monitors to correctly reason about observed system traces.", "num_citations": "5\n", "authors": ["1588"]}
{"title": "Technology Transfer\n", "abstract": " This chapter presents our experience of knowledge and technology transfer within the context of the DEPLOY project. In particular, we describe some of the challenges that we faced over the course of the project and the decisions that we made, along with their justification. We also summarise the lessons learned and what we would do differently in future technology transfer projects.", "num_citations": "5\n", "authors": ["1588"]}
{"title": "SSG: A model-based development environment for smart, security-aware GUIs\n", "abstract": " We present a development environment for automatically building smart, security-aware GUIs following a model-based approach. Our environment consists of a number of plugins that have been developed using the Eclipse framework and includes three model editors, a model-transformation tool, and a code generator.", "num_citations": "5\n", "authors": ["1588"]}
{"title": "Automatic generation of security-aware GUI models\n", "abstract": " In typical software applications, users access application data using GUI widgets. There is an important, but little explored, link between visualization and security: when the application data is protected by an access-control policy, the application GUI should be aware of and respect this policy. For example, a widget should not give users options to execute actions on the application data that they are not authorized to execute. However, GUI designers are not (and usually should not be) aware of the application data security policy. To solve this problem, we define in this paper a many-models-to-model transformation that, given a security-aware data model and a GUI model, makes the GUI model also security-aware.", "num_citations": "5\n", "authors": ["1588"]}
{"title": "Automated reasoning for security protocol analysis\n", "abstract": " Experience over the past 20 years has shown that, even assuming perfect cryptography, the design of security protocols (or cryptographic protocols, as they are sometimes called) is highly error-prone and that conventional validation techniques based on informal arguments or testing are not up to the task. It is now widely recognized that only formal analysis can provide the level of assurance required by both the developers and the users of the protocols. Work in this direction initially started in the security community, but recently there has been a tremendous progress thanks to contributions from different automated reasoning communities, such as automated deduction, model checking, and artificial intelligence. Moreover, there has been another wave of progress in foundations for analyzing protocols and their properties by applying nonclassical logics, such as epistemic and belief logics. A large number of formal\u00a0\u2026", "num_citations": "5\n", "authors": ["1588"]}
{"title": "Structuring metatheory on inductive definitions\n", "abstract": " We examine a problem in formal metatheory: if theories are structured hierarchically, there are metatheorems which hold in only some extensions. We illustrate this using modal logics and the deduction theorem. We show how statements of metatheorems in such hierarchies can take account of possible theory extensions; i.e. a metatheorem formalizes not only the theory in which it holds, but also under what extensions, both to the language and proof system, it remains valid. We show that FS 0, a system for formal metamathematics, provides a basis for organizing theories this way, and we report on our practical experience.", "num_citations": "5\n", "authors": ["1588"]}
{"title": "A calculus for rippling\n", "abstract": " We present a calculus for rippling, a special type of rewriting using annotations. These annotations guide the derivation towards a particular goal. Although it has been suggested that rippling can be implemented directly via first-order term rewriting, we demonstrate that this is not possible. We show how a simple change to subterm replacement and matching gives a calculus for implementing rippling. This calculus also allows us to combine rippling with conventional term rewriting. Such a combination offers the flexibility and uniformity of conventional rewriting with the highly goal-directed nature of rippling. The calculus we present here is implemented and has been integrated into the Edinburgh CLAM proof-planning system.", "num_citations": "5\n", "authors": ["1588"]}
{"title": "A recursion planning analysis of inductive completion\n", "abstract": " We use the AI proof planning techniques ofrecursion analysis andrippling as tools to analyze so-calledinductionless induction proof techniques. Recursion analysis chooses induction schemas and variables and rippling controls rewriting in explicit induction proofs. They provide a basis for explaining the success and failure of inductionless induction, both in deduction of critical pairs and in their simplification. Furthermore, these explicit induction techniques motivate and provide insight into advancements in inductive completion algorithms and suggest directions for further improvements. Our study includes an experimental comparison of Clam, an explicit induction theorem prover, with an implementation of Huet and Hullot's inductionless induction.", "num_citations": "5\n", "authors": ["1588"]}
{"title": "User account access graphs\n", "abstract": " The primary authentication method for a user account is rarely the only way to access that account. Accounts can often be accessed through other accounts, using recovery methods, password managers, or single sign-on. This increases each account's attack surface, giving rise to subtle security problems. These problems cannot be detected by considering each account in isolation, but require analyzing the links between a user's accounts. Furthermore, to accurately assess the security of accounts, the physical world must also be considered. For example, an attacker with access to a physical mailbox could obtain credentials sent by post.", "num_citations": "4\n", "authors": ["1588"]}
{"title": "From natural projection to partial model checking and back\n", "abstract": " Specification decomposition is a theoretically interesting and practically relevant problem for which two approaches were independently developed by the control theory and verification communities: natural projection and partial model checking. In this paper we show that, under reasonable assumptions, natural projection reduces to partial model checking and, when cast in a common setting, the two are equivalent. Aside from their theoretical interest, our results build a bridge whereby the control theory community can reuse algorithms and results developed by the verification community. In addition, we present an algorithm and a tool for the partial model checking of finite-state automata that can be used as an alternative to natural projection.", "num_citations": "4\n", "authors": ["1588"]}
{"title": "Exploring website location as a security indicator\n", "abstract": " Authenticating websites is an ongoing problem for users. Recent proposals have suggested strengthening current server authentication methods by incorporating website location as a comprehensible additional trust factor. In this work, we explore users' acceptance of location information and how it affects decision-making for security and privacy. We conducted a series of qualitative interviews to learn how location can be integrated into users' decision-making for security, and we designed a security indicator to alert the user to changes in website locations. We evaluated our tool in a 44-participant user study and found that users were less likely to perform security-sensitive tasks when alerted to location changes. Our results suggest that website location can be used as an effective indicator for users' security assessments.", "num_citations": "4\n", "authors": ["1588"]}
{"title": "Methods for secure distance bounding/ranging between two devices\n", "abstract": " A method for communicating between a first device and a second device is shown. The devices are structured and configured for communicating via a communication channel by exchanging messages. The method comprises:", "num_citations": "4\n", "authors": ["1588"]}
{"title": "Event-B \u306b\u3088\u308b\u5217\u8eca\u76e3\u8996\u30b7\u30b9\u30c6\u30e0\u306e\u30e2\u30cb\u30bf\u30ea\u30f3\u30b0\u8981\u4ef6\u306e\u691c\u8a3c\n", "abstract": " \u8ad6\u6587\u6284\u9332\u672c\u7a3f\u3067\u306f, \u5217\u8eca\u76e3\u8996\u30b7\u30b9\u30c6\u30e0\u306e\u4ed5\u69d8\u3092\u5f62\u5f0f\u624b\u6cd5 Event-B \u306b\u3088\u3063\u3066\u691c\u8a3c\u3057\u305f\u30b1\u30fc\u30b9\u30b9\u30bf\u30c7\u30a3\u306b\u3064\u3044\u3066\u5831\u544a\u3059\u308b. \u5217\u8eca\u76e3\u8996\u30b7\u30b9\u30c6\u30e0\u3068\u306f, \u4fe1\u53f7\u6a5f\u306a\u3069\u306e\u8a2d\u5099\u306e\u72b6\u614b\u30c7\u30fc\u30bf\u3092\u53d7\u4fe1\u3057, \u305d\u308c\u3089\u72b6\u614b\u30c7\u30fc\u30bf\u306b\u57fa\u3065\u3044\u3066\u5217\u8eca\u904b\u884c\u72b6\u6cc1\u3092\u30e2\u30cb\u30bf\u8868\u793a\u3059\u308b\u30b7\u30b9\u30c6\u30e0\u3067\u3042\u308b. \u672c\u30b1\u30fc\u30b9\u30b9\u30bf\u30c7\u30a3\u3067\u306f, \u4e0e\u3048\u3089\u308c\u305f\u4ed5\u69d8\u306b\u57fa\u3065\u3044\u3066 Event-B \u30e2\u30c7\u30eb\u3092\u4f5c\u6210\u3057, \u4ed5\u69d8\u304c\u6d3b\u6027\u306b\u95a2\u3059\u308b\u6027\u8cea\u3092\u6e80\u305f\u3059\u3053\u3068\u3068, \u4e0e\u3048\u3089\u308c\u305f\u4ed5\u69d8\u306b\u77db\u76fe\u306e\u306a\u3044\u3053\u3068\u3092\u691c\u8a3c\u3057\u305f. Event-B \u30e2\u30c7\u30eb\u3092\u4f7f\u3063\u305f\u6d3b\u6027\u691c\u8a3c\u306e\u305f\u3081\u306b\u306f, \u30d0\u30ea\u30a2\u30f3\u30c8\u306a\u3069, \u7279\u5b9a\u306e\u6761\u4ef6\u3092\u6e80\u305f\u3059\u8ad6\u7406\u5f0f\u3092\u767a\u898b\u7684\u306b\u4f5c\u6210\u3059\u308b\u5fc5\u8981\u304c\u3042\u308b. \u672c\u7a3f\u3067\u306f, \u5bfe\u8c61\u306e\u5217\u8eca\u76e3\u8996\u30b7\u30b9\u30c6\u30e0\u306b\u304a\u3044\u3066\u4e0a\u8a18\u8ad6\u7406\u5f0f\u3092\u4f5c\u6210\u3059\u308b\u65b9\u6cd5\u3092\u63d0\u6848\u3059\u308b. \u307e\u305f\u4ed5\u69d8\u306e\u77db\u76fe\u691c\u8a3c\u3067\u306f, \u30ea\u30d5\u30a1\u30a4\u30e1\u30f3\u30c8\u306b\u57fa\u3065\u304f\u5f93\u6765\u306e\u624b\u6bb5\u3067\u306f\u691c\u8a3c\u4e0d\u53ef\u80fd\u306a, \u5916\u5ef6\u7684\u304b\u3064\u90e8\u5206\u7684\u306b\u4e0e\u3048\u3089\u308c\u305f\u4ed5\u69d8\u3068\u5185\u5305\u7684\u306b\u4e0e\u3048\u3089\u3048\u305f\u4ed5\u69d8\u3068\u306e\u9593\u306e\u77db\u76fe\u691c\u8a3c\u65b9\u6cd5\u3092\u63d0\u6848\u3059\u308b. \u3053\u308c\u3089\u306e\u63d0\u6848\u65b9\u6cd5\u306f, \u672c\u7a3f\u3067\u5bfe\u8c61\u3068\u3057\u305f\u5217\u8eca\u76e3\u8996\u30b7\u30b9\u30c6\u30e0\u306b\u9650\u3089\u305a, \u4efb\u610f\u306e\u30b7\u30b9\u30c6\u30e0\u306b\u5bfe\u3057\u3066\u5fdc\u7528\u304c\u898b\u8fbc\u3081\u308b.", "num_citations": "4\n", "authors": ["1588"]}
{"title": "Evaluation of iso/iec 9798 protocols: Version 2.0\n", "abstract": " This report provides a security evaluation of the authentication protocol families described in parts 2, 3, and 4 of the ISO-IEC 9798 standard. Our analysis includes formal models of the protocols and their security properties, an analysis of existing attacks and evaluations, a security analysis of the formal protocol models, and a list of recommendations.", "num_citations": "4\n", "authors": ["1588"]}
{"title": "ZISC Annual Report 2008-2009\n", "abstract": " In this report, we cover the activities of the Zurich Information Security Center from September 1st, 2008 through August 31st, 2009. The ZISC currently consists of seven associates: four ETH groups and three industry partners (see Appendix A). It has been in operation for six years now. Last year we celebrated our fifth anniversary and produced a brochure covering our activities over the first five years. In this report, we review our activities of the past year. The main pillars of the ZISC are research and education. On the research front, we have six ongoing projects. All of the projects have produced excellent results and we mention just a few highlights here.\u2022 In the project on Device Identification, Boris Danev and Srdjan Capkun have shown that they can effectively determine the identity of different classes of wireless devices based on their signal features. This ability to fingerprint signals means that devices, such as\u00a0\u2026", "num_citations": "4\n", "authors": ["1588"]}
{"title": "Distributed usage control\n", "abstract": " Distributed usage control is concerned with controlling how data may or may not be used after it has been given away. One strategy for enforcing usage control requirements is based on monitoring data usage and reacting to policy violations by imposing penalties. We show how to implement monitors for usage control requirements using runtime verification technology. 1", "num_citations": "4\n", "authors": ["1588"]}
{"title": "A formal analysis of a digital signature architecture\n", "abstract": " We report on a case study in applying formal methods to model and validate an architecture for administrating digital signatures. We use a process-oriented modeling language to model a signature system implemented on top of a secure operating system. Afterwards, we use the Spin model checker to validate access control and integrity properties. We describe here our modeling approach and the benefits gained from our analysis.", "num_citations": "4\n", "authors": ["1588"]}
{"title": "A recipe for the complexity analysis of non-classical logics\n", "abstract": " David Basin & Luca Vigan\u00f2, A recipe for the complexity analysis of non-classical logics - PhilPapers Sign in | Create an account PhilPapers PhilPeople PhilArchive PhilEvents PhilJobs PhilPapers home Syntax Advanced Search Syntax Advanced Search Syntax Advanced Search A recipe for the complexity analysis of non-classical logics David Basin & Luca Vigan\u00f2 In Dov M. Gabbay & Maarten de Rijke (eds.), Frontiers of Combining Systems. Research Studies Press. pp. 2--57 (2000) Abstract This article has no associated abstract. (fix it) Keywords No keywords specified (fix it) Categories Nonclassical Logics in Logic and Philosophy of Logic (categorize this paper) Buy the book Find it on Amazon.com Options Edit this record Mark as duplicate Export citation Find it on Scholar Request removal from index Revision history Download options PhilArchive copy Upload a copy of this paper Check publisher's policy Papers \u2026", "num_citations": "4\n", "authors": ["1588"]}
{"title": "Modeling a hardware synthesis methodology in Isabelle\n", "abstract": " Formal Synthesis is a methodology developed at the university of Kent for combining circuit design and verification, where a circuit is constructed from a proof that it meets a given formal specification. We have reinterpreted this methodology in ISABELLE'S theory of higher-order logic so that circuits are incrementally built during proofs using higher-order resolution. Our interpretation simplifies and extends Formal Synthesis both conceptually and in implementation. It also supports integration of this development style with other proof-based synthesis methodologies and leads to techniques for developing new classes of circuits, e.g., recursive descriptions of parametric designs.", "num_citations": "4\n", "authors": ["1588"]}
{"title": "Modal logics K, T, K4, S4: Labelled proof systems and new complexity results\n", "abstract": " David Basin, Sean Matthews & Luca Vigano, Modal logics K, T, K4, S4: Labelled proof systems and new complexity results - PhilPapers Sign in | Create an account PhilPapers PhilPeople PhilArchive PhilEvents PhilJobs PhilPapers home Syntax Advanced Search Syntax Advanced Search Syntax Advanced Search Modal logics K, T, K4, S4: Labelled proof systems and new complexity results David Basin, Sean Matthews & Luca Vigano Bulletin of Symbolic Logic 5 (1):91-93 (1999) Abstract This article has no associated abstract. (fix it) Keywords No keywords specified (fix it) Categories Proof Theory in Logic and Philosophy of Logic Science, Logic, and Mathematics (categorize this paper) Options Edit this record Mark as duplicate Export citation Find it on Scholar Request removal from index Revision history Download options PhilArchive copy Upload a copy of this paper Check publisher's policy Papers currently \u2026", "num_citations": "4\n", "authors": ["1588"]}
{"title": "Formalization of the development process\n", "abstract": " Software development encompasses many phases including requirements engineering, specification, design, implementation, verification or testing, and maintenance. In this chapter we concentrate on the intermediate tasks: the transition from requirements specification to verified design and design optimization, in particular, techniques for developing correct designs as opposed to ad hoc ora posteriorimethods in which a postulated design is later verified or tested.", "num_citations": "4\n", "authors": ["1588"]}
{"title": "Logical framework based program development\n", "abstract": " We propose a methodology for formalizing and using logical frameworks for program development. Calculi for program transformation and synthesis are implemented in a logic, such as first-order logic, by formally deriving proof rules. The derived rules are then applied using higher-order resolution to simultaneously develop programs with their correctness proofs and this development is partially automated by calculus specific tactics. We have applied this approach, using the Isabelle system, to develop hardware descriptions, and functional and logic programs. l. FORMAL DEVELOPMENT FROM FOUNDATIONSWe propose a methodology for formalizing and using calculi for program development. It is based on using a logical framework to formally derive the proof rules of the calculi. Programs are constructed semi-automatically by tactics, which apply the proof rules using higher-order resolution. Resolution'solves'\u00a0\u2026", "num_citations": "4\n", "authors": ["1588"]}
{"title": "Card Brand Mixup Attack: Bypassing the {PIN} in non-Visa Cards by Using Them for Visa Transactions\n", "abstract": " Most EMV transactions require online authorization by the card issuer. Namely, the merchant's payment terminal sends an authorization request to the card issuer over a payment network, typically operated by the company that brands the card such as Visa or Mastercard. In this paper we show that it is possible to induce a mismatch between the card brand and the payment network, from the terminal's perspective. The resulting card brand mixup attack has serious security consequences. In particular, it enables criminals to use a victim's Mastercard contactless card to pay for expensive goods without knowing the card's PIN. Concretely, the attacker fools the terminal into believing that the card being used is a Visa card and then applies the recent PIN bypass attack that we reported on Visa. We have built an Android application and successfully used it to carry out this attack for transactions with both Mastercard debit and credit cards, including a transaction for over 400 USD with a Maestro debit card. Finally, we extend our formal model of the EMV contactless protocol to machine-check fixes to the issues found.", "num_citations": "3\n", "authors": ["1588"]}
{"title": "Human errors in secure communication protocols\n", "abstract": " We propose a formal model to analyze security protocols with human interaction. We model humans with no knowledge about the protocol and allow an adversary to perform an attack which covers all human errors. We then consider two types of countermeasures. The first type expresses that a human has at least some knowledge about the protocol and will do the known parts correctly. The second type of countermeasures changes a given protocol to be more robust against attacks, such that stronger security properties are achieved with the same assumptions on the human. Further, we introduce hierarchies to compare the human knowledge necessary in different security protocols to achieve the security goals.", "num_citations": "3\n", "authors": ["1588"]}
{"title": "Midpoints versus endpoints: From protocols to firewalls\n", "abstract": " Today\u2019s protocol specifications only define the behaviour of principals representing communication endpoints. But in addition to endpoints, networks contain midpoints, which are machines that observe or filter traffic between endpoints. In this paper, we explain why midpoints should handle protocols differently from endpoints and thus midpoint specifications are needed. With a case study, using the TCP protocol and three different firewalls as midpoints, we illustrate the consequences of the current lack of protocol specifications for midpoints, namely that the same protocol is implemented differently by the different firewalls. We then propose a solution to the problem: We give an algorithm that generates a midpoint automaton from specifications of endpoint automata. We prove that the resulting midpoint automata are correct in that they forward only those messages that could have resulted from protocol\u00a0\u2026", "num_citations": "3\n", "authors": ["1588"]}
{"title": "A formal data-model of the CORBA security service\n", "abstract": " We use the formal language Z to specify and analyze the security service of CORBA. In doing so, we tackle the problem of how one can apply lightweight formal methods to improve the precision and aid the analysis of a substantial, informal specification. Our approach is scenario-driven: we use representative scenarios to determine which parts of the informal specification should be formalized and then verify the formal specification against the requirements of these scenarios.", "num_citations": "3\n", "authors": ["1588"]}
{"title": "Formale Analyse des CORBA Sicherheitsdienstes\n", "abstract": " Dabei spielt Sicherheit in verteilten Systemen, wie man sie in multinationalen Firmen, in Banken und Versicherungen sowie im E-Commerce vorfindet, eine immer gr\u00f6\u00dfer werdende Rolle. Bei solchen Systemen m\u00fcssen Sicherheitseigenschaften wie die Integrit\u00e4t und Vertraulichkeit von Daten oder die Nicht-Abstreitbarkeit von Aktionen gew\u00e4hrleistet sein. In gro\u00dfen verteilten Systemen ist es nicht immer m\u00f6glich, genau anzugeben, welche Eigenschaften ben\u00f6tigt werden und wie die Sicherheitsmechanismen einer konkreten Anwendung auszusehen haben. Diese Arbeit soll dazu beitragen, ein besseres Verst\u00e4ndnis davon zu erhalten, was Sicherheit in verteilten Informationssystemen bedeutet.", "num_citations": "3\n", "authors": ["1588"]}
{"title": "Scoped metatheorems\n", "abstract": " Proof development systems traditionally structure theories hierarchically: Theorems established in a subtheory hold in all supertheories. While often effective, this is sometimes too restrictive as there are certain facts that are true of some but not all extensions. We present a solution where instead of first formalizing a theory and then establishing facts, we parameterize each statement with its scope of application. We present this idea abstractly and consider concrete implementations based on parameterized inductive definitions.", "num_citations": "3\n", "authors": ["1588"]}
{"title": "Labelled quantified modal logics\n", "abstract": " We present an approach to providing natural deduction style proof systems for a large class of quantified modal logics with varying, increasing, decreasing or constant domains of quantification. The systems we develop are modular both in the behavior of the accessibility relation and quantification relative to the semantics, and in the proofs of soundness and completeness relative to that semantics. Our systems also provide the basis of simple implementations of quantified modal logics in a standard logical framework theorem prover.", "num_citations": "3\n", "authors": ["1588"]}
{"title": "Monte-carlo sampling in games with incomplete information: empirical investigation and analysis\n", "abstract": " We investigate Monte-carlo sampling in games with incomplete information. We show that even for very simple game trees the chance of nding the optimal strategy with Monte-carlo sampling rapidly approaches zero as the number of moves in the game increases. We explain this sub-optimality by identifying the di erent kinds of errors that can arise and by analysing their interplay. We also relate our test results to real games, suggesting why the error rates observed in practice may not be so high. c Ian Frank", "num_citations": "3\n", "authors": ["1588"]}
{"title": "A Theory of Black-Box Tests\n", "abstract": " The purpose of testing a system with respect to a requirement is to refute the hypothesis that the system satisfies the requirement. We build a theory of tests and refutation based on the elementary notions of satisfaction and refinement. We use this theory to characterize the requirements that can be refuted through black-box testing and, dually, verified through such tests. We consider refutation in finite time and obtain the finite falsifiability of hyper-safety temporal requirements as a special case. We extend our theory with computational constraints and separate refutation from enforcement in the context of temporal hyper-properties. Overall, our theory provides a basis to analyze the scope and reach of black-box tests and to bridge results from diverse areas including testing, verification, and enforcement.", "num_citations": "2\n", "authors": ["1588"]}
{"title": "Runtime verification over out-of-order streams\n", "abstract": " We present an approach for verifying systems at runtime. Our approach targets distributed systems whose components communicate with monitors over unreliable channels, where messages can be delayed, reordered, or even lost. Furthermore, our approach handles an expressive specification language that extends the real-time logic MTL with freeze quantifiers for reasoning about data values. The logic\u2019s main novelty is a new three-valued semantics that is well suited for runtime verification as it accounts for partial knowledge about a system\u2019s behavior. Based on this semantics, we present online algorithms that reason soundly and completely about streams where events can occur out of order. We also evaluate our algorithms experimentally. Depending on the specification, our prototype implementation scales to out-of-order streams with hundreds to thousands of events per second.", "num_citations": "2\n", "authors": ["1588"]}
{"title": "Tests and Refutation\n", "abstract": " The purpose of testing a system with respect to a requirement is to refute the hypothesis that the system satisfies the requirement. We build a theory of tests and refutation based on the elementary notions of satisfaction and refinement. We use this theory to characterize the requirements that can be refuted through black-box testing and, dually, verified through such tests. We consider refutation in finite time and obtain the well-known finite falsifiability of hyper-safety temporal requirements as a special case. We extend our theory with computational constraints and separate refutation from enforcement in the context of temporal hyper-properties. Overall, our theory provides a basis to analyze the scope and reach of black-box tests and to bridge results from areas including testing, verification, and enforcement.", "num_citations": "2\n", "authors": ["1588"]}
{"title": "Semantic vacuity\n", "abstract": " The vacuous satisfaction of a temporal formula with respect to a model has been extensively studied in the literature. Although a universally accepted definition of vacuity does not yet exist, all existing proposals generalize, in one way or another, the antecedent failure of an implication to the syntax of a temporal logic. They are therefore syntactic: whether a model vacuously satisfies a formula is affected by semantics-preserving changes to the formula. This leads to inconsistent and counter-intuitive results. We propose an alternative: a semantic definition of vacuity for LTL where either two semantically equivalent LTL formulas are both satisfied vacuously in a model, or neither of them are. Our definition is based on a syntactic-invariant separation of LTL formulas, which gives rise to an algorithm for detecting semantic vacuity using trap properties. We also propose an alternative algorithm for Buchi automata, which can\u00a0\u2026", "num_citations": "2\n", "authors": ["1588"]}
{"title": "Anchored LTL separation\n", "abstract": " Gabbay's separation theorem is a fundamental result for linear temporal logic (LTL). We show that separating a restricted class of LTL formulas, called anchored LTL, is elementary if and only if the translation from LTL to the linear temporal logic with only future temporal connectives is elementary. To prove this result, we define a canonical separation for LTL, and establish a correspondence between a canonical separation of anchored LTL formulas and the \u03c9-automata that recognize these formulas.", "num_citations": "2\n", "authors": ["1588"]}
{"title": "Detecting, Understanding, and Fixing Control-Flow Errors in Business Process Models\n", "abstract": " Business process management targets the continuous optimization of business processes within an organization using information systems. This management discipline uses business process models as central artifacts in numerous use cases including simulation, specification and code generation of an IT solution, or the direct execution of a business process model on a workflow engine.Business process models frequently contain control-flow errors, such as deadlocks. These errors have severe consequences on the executability of the business process model: A control-flow error can lead to unexpected results, cause runtime exceptions, or completely block the process execution. Being able to detect these errors automatically during the modeling of the process allows companies to save time and money.", "num_citations": "2\n", "authors": ["1588"]}
{"title": "Development of a network topology discovery algorithm\n", "abstract": " Topology discovery is a distributed algorithm that is at the core of several routing algorithms, such as link-state routing. It is the problem of each node in the network discovering and maintening information on the network topology. The problem is challenging as the network can change rapidly, indeed more rapidly than the nodes can track and account for the changes.The topology discovery algorithm we develop generalizes of the\" master and dog\" paradigm. Here is the story. A master rides a motorbike while his dog, running behind him, tries to get to him. If the master reduces the speed of the motorbike, then the dog come a bit closer to him. However, if the master accelerates, then the distance between the two increases. But, certainly enough, if the master stops for a sufficiently long period of time then the dog will reach eventually his master.", "num_citations": "2\n", "authors": ["1588"]}
{"title": "The z specification language and the proof environment isabelle/hol-z\n", "abstract": " The Z Specification Language and the Proof Environment Isabelle/HOL-Z - Research Collection Header Upper Right Menu Log in de jump to https://www.ethz.ch Research Collection Toggle navigation Upper Right Menu Login Help Help Language Deutsch Toggle navigation Search View Item Home Journal Contributions Journal Article View Item Home Journal Contributions Journal Article View Item Research Collection Navigational link Search The Z Specification Language and the Proof Environment Isabelle/HOL-Z Mendeley CSV RIS BibTeX Thumbnail Metadata only Author Basin, David Kuruma, Hironobu Nakajima, Shin Wolff, Burkhart Show all Date 2007 Type Journal Article ETH Bibliography yes Altmetrics Publication status published Journal / series Computer Software (Journal of the Japanese Society for Software Science and Technology) Volume 24 (2) Pages / Article No. 21 - 26 Publisher Iwanami \u2026", "num_citations": "2\n", "authors": ["1588"]}
{"title": "Verteilte Nutzungskontrolle\n", "abstract": " Strategien. Eine Strategie besteht darin, die Menge anfallender pers\u00f6nlicher Daten zu minimieren und m\u00f6glichst anonym zu bleiben. Dies ist jedoch h\u00e4ufig nicht m\u00f6glich, etwa beim Einkaufen bei Online-Shops oder bei elektronischen Beh\u00f6rdeng\u00e4ngen, beim Verwenden von Mobiltelefonen oder Kreditkarten, oder bei der Beanspruchung medizinischer Leistungen. Weiterhin versprechen personalisierte Suchmaschinen viele Vorteile, bieten aber auch potenziell die M\u00f6glichkeit der Erstellung sehr detaillierter Nutzerprofile. Eine zweite Strategie besteht deshalb darin, die Verwendung der einmal angefallenen pers\u00f6nlichen Daten zu kontrollieren. Gesetze regeln, was mit pers\u00f6nlichen Daten geschehen darf, aber bisweilen werden diese Gesetze von den involvierten Informationssystemen und deren Benutzern nicht oder nur ungen\u00fcgend befolgt (was nicht gezwungenermassen in b\u00f6ser Absicht geschehen muss). Die Disziplin der Verteilten Nutzungskontrolle befasst sich mit der technischen Umsetzung dieser zweiten Strategie, also damit, wie kontrolliert werden kann, was mit Daten geschieht, nachdem sie weitergegeben worden sind. Offensichtlich ist der Anwendungsbereich der Verteilten Nutzungskontrolle nicht auf den Datenschutz beschr\u00e4nkt, sondern umfasst unter anderem auch intellektuelles Eigentum und Amts-oder Firmengeheimnisse.", "num_citations": "2\n", "authors": ["1588"]}
{"title": "Special Issue of the Journal of Automated Reasoning on\" Automated Reasoning for Security Protocol Analysis\"\n", "abstract": " Special Issue of the Journal of Automated Reasoning on \"Automated Reasoning for Security Protocol Analysis\" IRIS nascondi/visualizza icone a destra nascondi/visualizza menu in alto Aiuto Sfoglia Scorri i prodotti per: Autore Titolo Riviste Serie Login IRIS IRIS Fondazione Bruno Kessler Catalogo Ricerca FBK 7 Curatele 7.1 Curatela Special Issue of the Journal of Automated Reasoning on \"Automated Reasoning for Security Protocol Analysis\" Italiano Italiano Italiano Italiano English English Special Issue of the Journal of Automated Reasoning on \"Automated Reasoning for Security Protocol Analysis\" / Armando A.; Basin D.; Cuellar J.; Rustinowitch M.; Vigan\u00f2 L.. - In: JOURNAL OF AUTOMATED REASONING. - ISSN 0168-7433. - 36(2006). Scheda prodotto non validato Attenzione! I dati visualizzati non sono stati sottoposti a validazione da parte di FBK. Scheda breve Scheda completa Titolo: Special Issue of the \u2026", "num_citations": "2\n", "authors": ["1588"]}
{"title": "Konflikt oder Review: Zwei Ans\u00e4tze f\u00fcr Labors in angewandter Informationssicherheit\n", "abstract": " Gerade in der Informationssicherheit ist neben den theoretischen Grundlagen die Auseinandersetzung mit realit\u00e4tsnahen Situationen wichtig. In der Diskussion mit anderen Studierenden oder Tutoren ergeben sich neue Probleme und L\u00f6sungsans\u00e4tze, und bei der Arbeit mit der konkreten Technik zeigt sich, dass die Sicherheit eines Systems h\u00e4ufig von unscheinbaren Details abh\u00e4ngt. Diese Details k\u00f6nnen erhebliche Sicherheitsm\u00e4ngel verursachen, und es ist schwierig, sie alle in der Theorie zu erfassen.", "num_citations": "2\n", "authors": ["1588"]}
{"title": "The next 700 synthesis calculi\n", "abstract": " Over the last decade I have worked with colleagues on different projects to develop, implement, and automate the use of calculi for program synthesis and transformation. These projects had different motivations and goals and differed too in the kinds of programs synthesized (e.g., functional programs, logic programs, and even circuit descriptions). However, despite their differences they were all based on three simple ideas. First, calculi can be formally derived in a rich enough logic (e.g., higher-order logic). Second, higher-order resolution is the central mechanism used to synthesize programs during proofs of their correctness. And third, synthesis proofs have a predictable form and can be partially or completely automated. In the talk I explain these ideas and illustrate the general methodology employed.", "num_citations": "2\n", "authors": ["1588"]}
{"title": "A conservative extension of first-order logic and its applications to theorem proving\n", "abstract": " We define a weak second-order extension of first-order logic. We prove a second-order cut elimination theorem for this logic and use this to prove a conservativity and a realisability result. We give applications to formal program development and theorem proving, in particular, in modeling techniques in formal metatheory.", "num_citations": "2\n", "authors": ["1588"]}
{"title": "Some normalization properties of Martin-L of's type theory, and applications\n", "abstract": " For certain kinds of applications of type theories, the faithfulness of formalization in the theory depends on intensional, or structural, properties of objects constructed in the theory. For type theories such as LF, such properties can be established via an analysis of normal forms and types. In type theories such as Nuprl or Martin-L of's polymorphic type theory, which are much more expressive than LF, the underlying programming language is essentially untyped, and terms proved to be in types do not necessarily have normal forms. Nevertheless, it is possible to show that for Martin-L of's type theory, and a large class of extensions of it, a su cient kind of normalization property does in fact hold in certain well-behaved subtheories. Applications of our results include the use of the type theory as a logical framework in the manner of LF, and an extension of the proofs-as-programs paradigm to the synthesis of veri ed computer hardware. For the latter application we point out some advantages to be gained by working in a more expressive type theory.", "num_citations": "2\n", "authors": ["1588"]}
{"title": "Abstract Modeling of System Communication in Constructive Cryptography using CryptHOL\n", "abstract": " Proofs in simulation-based frameworks have the greatest rigor when they are machine checked. But the level of details in these proofs surpasses what the formal-methods community can handle with existing tools. Existing formal results consider streamlined versions of simulation-based frameworks to cope with this complexity. Hence, a central question is how to abstract details from composability results and enable their formal verification.In this paper, we focus on the modeling of system communication in composable security statements. Existing formal models consider fixed communication patterns to reduce the complexity of their proofs. However, as we will show, this can affect the reusability of security statements. We propose an abstract approach to modeling system communication in Constructive Cryptography that avoids this problem. Our approach is suitable for mechanized verification and we use\u00a0\u2026", "num_citations": "1\n", "authors": ["1588"]}
{"title": "Symbolic analysis of identity-based protocols\n", "abstract": " We show how the Tamarin tool can be used to model and reason about security protocols using identity-based cryptography, including identity-based encryption and signatures. Although such protocols involve rather different primitives than conventional public-key cryptography, we illustrate how suitable abstractions and Tamarin\u2019s support for equational theories can be used to model and analyze realistic industry protocols, either finding flaws or gaining confidence in their security with respect to different classes of adversaries. Technically, we propose two models of identity-based cryptography. First, we formalize an abstract model, based on simple equations, in which verification of realistic protocols is feasible. Second, we formalize a more precise model, leveraging Tamarin\u2019s support for bilinear pairing and exclusive-or. This model is much closer to practical realizations of identity-based cryptography, but\u00a0\u2026", "num_citations": "1\n", "authors": ["1588"]}
{"title": "ActionGUI semantics\n", "abstract": " In this technical report we provide the formal account of our ActionGUI methodology, including the semantics of the modeling languages that we use, the definition of our many-models-to-models transformation, and the proof of its correctness.", "num_citations": "1\n", "authors": ["1588"]}
{"title": "Checking System Compliance by Slicing and Monitoring Logs\n", "abstract": " It is a growing concern of companies and end users whether the agents of an IT system, i.e., its processes and users, comply with security policies, which, e.g., stipulate how sensitive data must and must not be used by the agents. We present a scalable solution for compliance checking based on monitoring the agents' behavior, where policies are specied in an expressive temporal logic and the system actions are logged. In particular, our solution utilizes the MapReduce framework to parallelize the process of monitoring the logged actions. We also provide the theoretical underpinnings of our solution as a theoretical framework for slicing logs, i.e., the reorganization of the logged actions into parts that can be analyzed independently of each other. We present orthogonal methods for generating such slices and provide means to combine these methods. Finally, we report on a real-world case study, which demonstrates the feasibility and the scalability of our monitoring solution.", "num_citations": "1\n", "authors": ["1588"]}
{"title": "Constructing mid-points for two-party asynchronous protocols\n", "abstract": " Communication protocols describe the steps that the communication end-points must take in order to achieve a common goal. In practice, networks often contain mid-points, which can relay, redirect, or filter messages exchanged by the end-points. A mid-point can enforce a communication protocol: it forwards the messages that conform to the protocol, and drops them otherwise. Protocol specifications typically define only the end-points\u2019 behavior. Implementing a mid-point that enforces a protocol is nontrivial: the mid-point\u2019s behavior depends on the end-point\u2019s behavior, and also on the behavior of the communication environment in which the protocol executes.             We present a process algebraic framework that takes as input the formal specifications of the protocol and the environment and outputs a specification for a mid-point that enforces the protocol. We prove that the mid-point specifications\u00a0\u2026", "num_citations": "1\n", "authors": ["1588"]}
{"title": "Security Principles\n", "abstract": " Our objective in writing this book is to help readers improve their understanding of information security by carrying out hands-on experiments where they apply and deepen their knowledge. We will not cover all the related theory and assume that the reader has a basic knowledge of cryptography and information security, perhaps from other courses or books. Nevertheless, we will summarize some of the more central notions that are relevant for the experiments.           This first chapter is cross-cutting in that we summarize principles that are relevant for the coming chapters. We present 12 security principles that provide guidelines on how to incorporate security into system design. The principles are stated as generally as possible and should help the reader to discover commonalities among the more concrete design practices presented in the subsequent chapters.", "num_citations": "1\n", "authors": ["1588"]}
{"title": "In-depth fuzz testing of IKE implementations\n", "abstract": " The correctness of security protocols can be proved using formal models. Typically, a security protocol is proven correct at a high level of abstraction, hiding away the implementation details. To execute the protocol on a real system, software engineers take up the task to implement the protocol. Programming is an error-prone activity: despite the fact that a security protocol is proven correct, its implementation may have vulnerabilities, which can be exploited by attackers. In this work we consider the problem of testing security protocol implementations for vulnerabilities, assuming that a formal model of the protocol is given. Finding security vulnerabilities is nontrivial. Even if a system correctly implements the model and behaves as expected when it performs intended tasks, ie tasks that are specified in the model, it is difficult to check that the implementation does not exhibit any additional behaviors, ie behaviors that are not specified in the model. Behaviors that are unintentionally implemented in the system can be dangerous and may introduce vulnerabilities in the system. When programmers implement the protocol, they need to consider how the system handles unexpected events, eg how the system reacts when the disk is full or how to handle malformed input. Such unexpected events are the low-level details that are typically abstracted away in the formal model. We can virtually split the program into two parts:(1) functional part which handles the expected behavior of the system, and (2) error handling part which implements how the program handles unexpected events. The top 4 most dangerous software errors listed at the Common Weakness\u00a0\u2026", "num_citations": "1\n", "authors": ["1588"]}
{"title": "ZISC Annual Report 2009\u20132010\n", "abstract": " In this report, we cover the activities of the Zurich Information Security Center from September 1st, 2009 through August 31st, 2010. The ZISC currently consists of seven associates: four ETH groups and three industry partners (see Appendix A). It has been in operation for seven years now, with its founding in September 2003. In this report, we review our activities of the past year. The main pillars of the ZISC are research and education. On the research front, we have one project that successfully completed with a PhD thesis (Methods for Evaluating Anomaly Detection Systems), five ongoing projects as well as three new projects. All of the projects have produced excellent results and we mention just a few highlights here.\u2022 In the project on Device Identification, Boris Danev and Srdjan Capkun have demonstrated that wireless devices present unique identities based on stable characteristics extracted from their\u00a0\u2026", "num_citations": "1\n", "authors": ["1588"]}
{"title": "Increasing the efficiency of next-generation space operations by exploiting predictability\n", "abstract": " From a mobile networking perspective, spacecraft networks are characterized by the predictability of node movement and communication opportunities. We show that payload data throughput, spacecraft commanding, and mission autonomy can be enhanced by using a predicable mobile routing protocol. We validate our claims through realistic network simulations in the context of a complex communication infrastructure for a next-generation Mars mission. Moreover, we propose routing protocol enhancements that also takes intermittently connected links into account as they occur in delay-tolerant networking. Finally, we analyze the operational impact and capabilities of the routing protocol on spacecraft commanding and operations.", "num_citations": "1\n", "authors": ["1588"]}
{"title": "Automatic generation of smart&secGUIs from security design models\n", "abstract": " Model-Driven Architecture (MDA) holds the promise of reducing system development time while improving the quality of the resulting products. It is argued that the construction of models during requirements analysis and system design will improve the quality of the resulting systems by providing a foundation for early analysis and fault detection. Moreover, the models constructed in the analysis and design phases will serve as specifications for the later development phases and, when they are sufficiently formal, they will also provide the basis for refinement down to code through well-defined model transformation functions. Model-Driven Security (MDS) is a recently proposed specialization of the MDA approach. Here,\u201cdesigners specify system models along with their security requirements and use tools to automatically generate system architectures from the models, including complete, configured access control infrastructures.\u201d It is argued that this approach \u201cbridges the gap between security analysis and the integration of access control mechanisms into end systems. Moreover, it integrates security models with system design models and thus yields a new kind of model, security design models.\u201d Recent investigations have shown that security policies can be integrated into system design models and that the resulting security design models can be used as a basis for generating systems along with their security infrastructures. Indeed, reports of successful implementations of security design models in real industrial projects and several illustrative modeling examples can be found in literature. This thesis presents a contribution to this research field\u00a0\u2026", "num_citations": "1\n", "authors": ["1588"]}
{"title": "\u4ed5\u69d8\u8a18\u8ff0\u8a00\u8a9e Z \u3068\u8a3c\u660e\u74b0\u5883 Isabelle/HOL-Z\n", "abstract": " Z \u8a18\u6cd5 (\u4ee5\u4e0b Z) \u306f\u5f62\u5f0f\u624b\u6cd5\u306e\u4ee3\u8868\u4f8b\u3068\u3057\u3066\u5e38\u306b\u7d39\u4ecb\u3055\u308c\u308b\u5f62\u5f0f\u4ed5\u69d8\u8a00\u8a9e\u3067\u3042\u308b. \u30bd\u30d5\u30c8\u30a6\u30a7\u30a2\u306e\u4ed5\u69d8\u3092\u6570\u5b66\u7684\u306a\u610f\u5473\u3092\u6301\u3064\u8a18\u6cd5\u3067\u53b3\u5bc6\u306b\u8868\u73fe\u3059\u308b\u3053\u3068\u3092\u76ee\u7684\u3068\u3057\u3066, 1980 \u5e74\u4ee3\u306b Oxford \u5927\u5b66\u304c\u4e2d\u5fc3\u3068\u306a\u3063\u3066\u958b\u767a\u3055\u308c\u305f. \u305d\u306e\u540d\u79f0\u304b\u3089\u308f\u304b\u308b\u901a\u308a, \u5f53\u521d\u306f\u30b7\u30b9\u30c6\u30e0\u4ed5\u69d8\u306e\u8a18\u6cd5\u3068\u3057\u3066\u7528\u3044\u3089\u308c\u305f. \u4ee3\u8868\u7684\u306a\u4e8b\u4f8b\u3068\u3057\u3066, Oxford \u5927\u5b66\u3068 IBM \u793e\u304c\u884c\u3063\u305f IBM CICS \u306e\u4ed5\u69d8\u8a18\u8ff0\u304c\u3042\u308b. \u3053\u306e\u6210\u529f\u306b\u3088\u3063\u3066, 1992 \u5e74\u306b\u82f1\u56fd\u306e Queen\u2019s Award for Technological Achievement \u3092\u53d7\u8cde\u3057\u305f. \u305d\u306e\u5f8c, VDM-SL \u3068\u540c\u69d8\u306b ISO \u6a19\u6e96\u3068\u306a\u3063\u305f [15].Z \u306f\u4ed5\u69d8\u8a18\u8ff0\u306b\u4e3b\u773c\u304c\u7f6e\u304b\u308c\u3066\u3044\u305f\u304c, Z \u306e\u610f\u5473\u8ad6\u3092\u9ad8\u968e\u8ad6\u7406 (HOL) \u306b\u3088\u3063\u3066\u8868\u73fe\u3059\u308b\u3053\u3068\u304c\u53ef\u80fd\u3067\u3042\u308b. \u305d\u306e\u7d50\u679c, Z \u3067\u66f8\u304b\u308c\u305f\u4ed5\u69d8\u8a18\u8ff0\u3092\u89e3\u6790\u3059\u308b\u30c4\u30fc\u30eb\u3092\u4f5c\u6210\u3059\u308b\u3053\u3068\u304c\u3067\u304d\u308b. \u305f\u3068\u3048\u3070, ProofPower [20] \u306a\u3089\u3073\u306b\u672c\u7a3f\u3067\u7d39\u4ecb\u3059\u308b Isabelle/HOL-Z [4] \u306a\u3069\u304c\u3042\u308b. \u3053\u306e\u3088\u3046\u306a\u30c4\u30fc\u30eb\u3092\u7528\u3044\u308b\u3053\u3068\u3067, \u4ed5\u69d8\u306e\u6027\u8cea\u3084\u30ea\u30d5\u30a1\u30a4\u30f3\u30e1\u30f3\u30c8\u95a2\u4fc2\u306e\u691c\u8a3c\u3092\u884c\u3046\u3053\u3068\u304c\u53ef\u80fd\u306b\u306a\u3063\u305f.", "num_citations": "1\n", "authors": ["1588"]}
{"title": "Usage control\n", "abstract": " Computer systems play an increasingly prominent role in our daily lives. Interacting with these systems often involves disclosing personal data, ie, data that can be traced back to particular individuals, collected in different contexts. For example, healthcare providers, insurance companies, and tax o ces collect personal data explicitly. The use of credit or loyalty cards, as well as Internet shopping, leave implicitly created digital footprints. So does the use of mobile phones (tra c data) and the coming generation of motor vehicles (location data and sensed driving behavior). Moreover, public security concerns have led to increased monitoring of public spaces where personal data (images and contexts) is gathered without direct interaction with computerized services. The looming reality of ubiquitous computing will further increase the amount of personal data collected, and enhanced network capabilities give rise to\u00a0\u2026", "num_citations": "1\n", "authors": ["1588"]}
{"title": "Theorem Proving in Higher Order Logics: 16th International Conference, TPHOLs 2003, Rom, Italy, September 8-12, 2003, Proceedings\n", "abstract": " This volume constitutes the proceedings of the16th International Conference on Theorem Proving in Higher Order Logics (TPHOLs 2003) held September 8\u201312, 2003 in Rome, Italy. TPHOLs covers all aspects of theorem proving in higher order logics as well as related topics in theorem proving and veri? cation. TPHOLs 2003 was co-located with TABLEAUX, the International Con-rence on Automated Reasoning with Analytic Tableaux and Related Methods, and with Calculemus, the Symposium on the Integration of Symbolic Compu-tion and Mechanized Reasoning. There were 50 papers submitted to TPHOLs in the full research category, each of which was refereed by at least 3 reviewers, selected by the program c-mittee. Ofthesesubmissions, 21wereacceptedforpresentationattheconference and publication in this volume. In keeping with tradition, TPHOLs 2003 also o? ered a venue for the presentation of work in progress, where researchers-vite discussion by means of a brief preliminary talk and then discuss their work at a poster session. A supplementary proceedings containing associated papers for work in progress was published by the computer science department at the Universit \u0308 at Freiburg. The organizers are grateful to Jean-Raymond Abrial, Patrick Lincoln, and Dale Miller for agreeing to give invited talks at TPHOLs 2003. The TPHOLs conference traditionally changes continent each year in order to maximize the chances that researchers from around the world can attend.", "num_citations": "1\n", "authors": ["1588"]}
{"title": "Verteidigung gegen SQL-Injection-Angriffe\n", "abstract": " SQL-Injections sind eine Art von Angriff gegen Datenbank-basierte Applikationen. Erfolgreiche Angriffe k\u00f6nnen es einem Angreifer erm\u00f6glichen, z. B. in eine Web-Applikation mit Zugriffsschutz unerlaubt einzuloggen, private Informationen aus einer Datenbank zu ermitteln oder Daten in einer Datenbank zu manipulieren.", "num_citations": "1\n", "authors": ["1588"]}
{"title": "Decision procedures for inductive Boolean functions based on alternating automata\n", "abstract": " We show how alternating automata provide decision procedures for the equality of inductively defined Boolean functions and present applications to reasoning about parameterized families of circuits. We use alternating word automata to formalize families of linearly structured circuits and alternating tree automata to formalize families of tree structured circuits. We provide complexity bounds for deciding the equality of function (or circuit) families and show how our decision procedures can be implemented using BDDs. In comparison to previous work, our approach is simpler, has better complexity bounds, and, in the case of tree-structured families, is more general.", "num_citations": "1\n", "authors": ["1588"]}
{"title": "Proceedings of 1st ACM Workshop on Formal Methods in Security Engineering (FMSE), affiliated with ACM CCS'03, Washington DC\n", "abstract": " Proceedings of 1st ACM Workshop on Formal Methods in Security Engineering (FMSE) , affiliated with ACM CCS'03, Washington DC - CISPA CISPA Home About Browse Data Privacy Policy Impressum Login Proceedings of 1st ACM Workshop on Formal Methods in Security Engineering (FMSE) , affiliated with ACM CCS'03, Washington DC Backes, Michael and Basin, David and Waidner, Michael (2003) Proceedings of 1st ACM Workshop on Formal Methods in Security Engineering (FMSE) , affiliated with ACM CCS'03, Washington DC ACM. Full text not available from this repository. Item Type: Book Additional Information: pub_id: 425 Bibtex: backes03proceedingsb URL date: None Divisions: Michael Backes (InfSec) Depositing User: Sebastian Weisgerber Date Deposited: 26 Jul 2017 10:31 Last Modified: 28 Sep 2018 12:38 URI: https://publications.cispa.saarland/id/eprint/760 Actions Actions (login required) View \u2026", "num_citations": "1\n", "authors": ["1588"]}
{"title": "Access Control and Security Policies\n", "abstract": " A subject may only have access to personal data if this access is necessary to perform its current task, and only if the subject is authorized to perform this task. In addition, the purpose of its current task must correspond to the purposes for which the personal data was obtained or consent must be given by the data subjects.", "num_citations": "1\n", "authors": ["1588"]}
{"title": "Payo-reduction minimaxing\n", "abstract": " We describe payo-reduction minimaxing, a new search algorithm for games with incomplete information. We formalise this algorithm and present results that show it dramatically outperforms the major competing algorithm: Monte-carlo sampling. On simple game trees where Monte-carlo sampling is never able to identify an optimal strategy, payo-reduction minimaxing has a success rate of up to 40%. Payo-reduction minimaxing is designed for incomplete information games in which the opponent is assumed to know the state of the world. This is exactly the situation found in expert analysis of the game of Bridge. We analyse further simple game trees on which Monte-carlo sampling has same success rate as it does for Bridge (about 65%). On these trees, payo-reduction minimaxing has the even better success rate of 93%. c Ian Frank", "num_citations": "1\n", "authors": ["1588"]}
{"title": "Beyond the finite in automatic hardware verification\n", "abstract": " We present a new approach to hardware verification based on describing circuits in Monadic Second-order Logic MSL. We show how to use this logic to represent generic designs like n-bit adders, which are parameterized in space, and sequential circuits, where time is an unbounded parameter. MSL admits a decision procedure, implemented in the MONA tool, which reduces formulas to canonical automata. The decision problem for MSL is non-elementary decidable and thus unlikely to be usable in practice. However, we have used MONA to automatically verify, or find errors in, a number of circuits studied in the literature. Previously published machine proofs of the same circuits are based on deduction and may involve substantial interaction with the user. Moreover, our approach is orders of magnitude faster for the examples considered. We show why the underlying computations are feasible and how our use of MONA generalizes standard BDD-based hardware reasoning.", "num_citations": "1\n", "authors": ["1588"]}
{"title": "On the expresiveness of a message sequence formalism for security protocols\n", "abstract": " We investigate the semantics and expressive power of protocol descriptions based on message sequences. In the context of security protocols, this notation is often called Alice&Bob notation and it describes the sequence of messages exchanged between honest principals in a successful protocol run. While intuitive, this notation is ambiguous in its description of the actions taken by principals, in particular with respect to the conditions they must check when executing their roles and the actions they must take when the checks fail.We provide both an operational and a denotational semantics for this notation that rigorously accounts for these conditions and actions. Our operational semantics is in terms of the spi calculus with pattern matching. Our denotational semantics is based on a new notion, called incremental symbolic run, that reflects the data possessed by principals and how this data increases monotonically\u00a0\u2026", "num_citations": "1\n", "authors": ["1588"]}