{"title": "Model checking and modular verification\n", "abstract": " We describe a framework for compositional verification of finite-state processes. The framework is based on two ideas: a subset of the logic CTL for which satisfaction is preserved under composition, and a preorder on structures which captures the relation between a component and a system containing the component. Satisfaction of a formula in the logic corresponds to being below a particular structure (a tableau for the formula) in the preorder. We show how to do assume-guarantee-style reasoning within this framework. Additionally, we demonstrate efficient methods for model checking in the logic and for checking the preorder in several special cases. We have implemented a system based on these methods, and we use it to give a compositional verification of a CPU controller.", "num_citations": "702\n", "authors": ["1612"]}
{"title": "Model checking and modular verification\n", "abstract": " We describe a framework for compositional verification of finite state processes. The framework is based on two ideas: a subset of the logic CTL for which satisfaction is preserved under composition; and a preorder on structures which captures the relation between a component and a system containing the component. Satisfaction of a formula in the logic corresponds to being below a particular structure (a tableau for the formula) in the preorder. We show how to do assume-guarantee style reasoning within this framework. In addition, we demonstrate efficient methods for model checking in the logic and for checking the preorder in several special cases. We have implemented a system based on these methods, and we use it to give a compositional verification of a CPU controller.", "num_citations": "216\n", "authors": ["1612"]}
{"title": "\u201d Have I Written Enough Properties?\u201d-A Method of Comparison Between Specification and Implementation\n", "abstract": " This work presents a novel approach for evaluatingthe quality of the model checkingpro cess. Given a model of a design (or implementation) and a temporal logic formula that describes a specification, model checkingde termines whether the model satisfies the specification. Assume that all specification formulas were successfully checked for the implementation. Are we sure that the implementation is correct? If the specification is incomplete, we may fail to find an error in the implementation. On the other hand, if the specification is complete, then the model checkingpro cess can be stopped without adding more specification formulas. Thus, knowingwh ether the specification is complete may both avoid missed implementation errors and save precious verification time.               The completeness of a specification with respect to a given implementation is determined as follows. The specification formula is first\u00a0\u2026", "num_citations": "146\n", "authors": ["1612"]}
{"title": "Bounded model checking of concurrent programs\n", "abstract": " We propose a SAT-based bounded verification technique, called TCBMC, for threaded C programs. Our work is based on CBMC, which models sequential C programs in which the number of executions for each loop and the depth of recursion are bounded.               The novelty of our approach is in bounding the number of context switches allowed among threads. Thus, we obtain an efficient modeling that can be sent to a SAT solver for property checking. We also suggest a novel technique for modeling mutexes and Pthread conditions in concurrent programs. Using this bounded technique, we can detect bugs that invalidate safety properties. These include races and deadlocks, the detection for which is crucial for concurrent programs.", "num_citations": "142\n", "authors": ["1612"]}
{"title": "Achieving scalability in parallel reachability analysis of very large circuits\n", "abstract": " This paper presents a scalable method for parallel symbolic reachability analysis on a distributed-memory environment of workstations. Our method makes use of an adaptive partitioning algorithm which achieves high reduction of space requirements. The memory balance is maintained by dynamically repartitioning the state space throughout the computation. A compact BDD representation allows coordination by shipping BDDs from one machine to another, where different variable orders are allowed. The algorithm uses a distributed termination protocol with none of the memory modules preserving a complete image of the set of reachable states. No external storage is used on the disk; rather, we make use of the network which is much faster.               We implemented our method on a standard, loosely-connected environment of workstations, using a high-performance model checker. Our initial\u00a0\u2026", "num_citations": "117\n", "authors": ["1612"]}
{"title": "Enhanced vacuity detection in linear temporal logic\n", "abstract": " One of the advantages of temporal-logic model-checking tools is their ability to accompany a negative answer to a correctness query with a counterexample to the satisfaction of the specification in the system. On the other hand, when the answer to the correctness query is positive, most model-checking tools provide no witness for the satisfaction of the specification. In the last few years there has been growing awareness of the importance of suspecting the system or the specification of containing an error also in cases where model checking succeeds. In particular, several works have recently focused on the detection of the vacuous satisfaction of temporal logic specifications. For example, when verifying a system with respect to the specification \u03d5\u2009=\u2009G(req \u2192Fgrant) (\u201cevery request is eventually followed by a grant\u201d), we say that \u03d5 is satisfied vacuously in systems in which requests are never sent. Current\u00a0\u2026", "num_citations": "106\n", "authors": ["1612"]}
{"title": "Simulation-based minimization\n", "abstract": " We present a minimization algorithm that receives a Kripke structure M and returns the smallest structure that is simulation equivalent to M. The simulation equivalence relation is weaker than bisimulation but stronger than the simulation preorder. It strongly preserves ACTL and LTL (as sublogics of ACTL*).We show that every structure M has a unique-up-to-isomorphism reduced structure that is simulation equivalent to M and smallest in size. Our Minimizing Algorithm constructs this reduced structure. It first constructs the quotient structure for M, then eliminates transitions to little brothers, and finally deletes unreachable states.Since the first step of the algorithm is based on the simulation preorder over M, it has maximal space requirements. To reduce them, we present the Partitioning Algorithm, which constructs the quotient structure for M without ever building the simulation preorder. The Partitioning Algorithm has\u00a0\u2026", "num_citations": "104\n", "authors": ["1612"]}
{"title": "Network grammars, communication behaviors and automatic verification\n", "abstract": " A typical distributed algorithm for communicating processes is designed to be applicable to a family of networks with similar topology. Such a topology has some finite number of process types and different number of processes. A few examples are: choosing a leader in a ring (of any size)[L], mutual exclusion (in a ring)[D], distributed termination detection (in any connected network [F], or in a ring [FRS]). An algorithm of this kind can be described by associating with each process type a program with a specified set of communication ports, together with rules to combine processes of these types (by pairing ports) to admissible networks.In many cases, the program of each of the processes is finite-state. Thus, application of such an algorithm to a specific network is also a finite-state program. Hence, an algorithm of this kind can be viewed as an infinite family of finite-state programs. Automatic verification of finite-state\u00a0\u2026", "num_citations": "104\n", "authors": ["1612"]}
{"title": "An efficient decision procedure for the theory of fixed-sized bit-vectors\n", "abstract": " In this paper we describe a decision procedure for the core theory of fixed-sized bit-vectors with extraction and composition that can readily be integrated into Shostak's procedure for deciding combinations of theories. Inputs to the solver are unquantified bit-vector equations t=u and the algorithm returns true if t=u is valid in the bit-vector theory, false if t=u is unsatisfiable, and a system of solved equations otherwise. The time complexity of the solver is   , where t is the length of the bit-vector term t and n denotes the number of bits on either side of the equation. Then, the solver for the core bit-vector theory is extended to handle other bit-vector operations like bitwise logical operations, shifting, and arithmetic interpretations of bit-vectors. We develop a BDD-like data-structure called bit-vector BDDs to represent bit-vectors, various operations on bit-vectors, and a solver on bit-vector BDDs.", "num_citations": "102\n", "authors": ["1612"]}
{"title": "Monotonic abstraction-refinement for CTL\n", "abstract": " The goal of this work is to improve the efficiency and effectiveness of the abstraction-refinement framework for CTL over the 3-valued semantics. We start by proposing a symbolic (BDD-based) approach for this framework. Next, we generalize the definition of abstract models in order to provide a monotonic abstraction-refinement framework. To do so, we introduce the notion of hyper-transitions. For a given set of abstract states, this results in a more precise abstract model in which more CTL formulae can be proved or disproved.               We suggest an automatic construction of an initial abstract model and its successive refined models. We complete the framework by adjusting the BDD-based approach to the new monotonic framework. Thus, we obtain a monotonic, symbolic framework that is suitable for both verification and falsification of full CTL.", "num_citations": "97\n", "authors": ["1612"]}
{"title": "A proof rule for fair termination of guarded commands\n", "abstract": " We present a proof rule for fairly terminating guarded commands based on a well-foundedness argument. The rule is applied to several examples, and proved to be sound and (semantically) complete w.r.t. an operational semantics of computation trees. The rule is related to another rule suggested by Lehmann, Pnueli, and Stavi (in \u201cProc. Internat. Colloq. Automata Lang. and Programming, '81,\u201d Acre, July 1981), by showing that the (semantic) completeness of the LPS-rule follows from the completeness or ours.", "num_citations": "86\n", "authors": ["1612"]}
{"title": "Distributed symbolic model checking for \u03bc-calculus\n", "abstract": " In this paper we propose a distributed symbolic algorithm for model checking of propositional \u03bc-calculus formulas. \u03bc-calculus is a powerful formalism and many problems like (fair) CTL and LTL model checking can be solved using the \u03bc-calculus model checking. Previous works on distributed symbolic model checking were restricted to reachability analysis and safety properties. This work thus significantly extends the scope of properties that can be verified for very large designs.               The algorithm distributively evaluates subformulas. It results in sets of states which are evenly distributed among the processes.We show that this algorithm is scalable, and thus can be implemented on huge distributed clusters of computing nodes. In this way, the memory modules of the computing nodes collaborate to create a very large store, thus enables the checking of much larger designs. We formally prove the\u00a0\u2026", "num_citations": "83\n", "authors": ["1612"]}
{"title": "Memory efficient all-solutions SAT solver and its application for reachability analysis\n", "abstract": " This work presents a memory-efficient All-SAT engine which, given a propositional formula over sets of important and non-important variables, returns the set of all the assignments to the important variables, which can be extended to solutions (satisfying assignments) to the formula. The engine is built using elements of modern SAT solvers, including a scheme for learning conflict clauses and non-chronological backtracking. Re-discovering solutions that were already found is avoided by the search algorithm itself, rather than by adding blocking clauses. As a result, the space requirements of a solved instance do not increase when solutions are found. Finding the next solution is as efficient as finding the first one, making it possible to solve instances for which the number of solutions is larger than the size of the main memory.             We show how to exploit our All-SAT engine for performing image computation\u00a0\u2026", "num_citations": "79\n", "authors": ["1612"]}
{"title": "Modular model checking of software\n", "abstract": " This work presents a modular approach to temporal logic model checking of software.             Model checking is a method that automatically determines whether a finite state system satisfies a temporal logic specification. Model checking algorithms have been successfully used to verify complex systems. However, their use is limited by the high space requirements needed to represent the verified system.             When hardware designs are considered, a typical solution is to partition the design into units running in parallel, and handle each unit separately. For software systems such a solution is not always feasible. This is because a software system might be too large to fit into memory even when it consists of a single sequential unit.             To avoid the high space requirements for software we suggest to partition the program text into sequentially composed subprograms. Based on this partition, we present a\u00a0\u2026", "num_citations": "78\n", "authors": ["1612"]}
{"title": "Fairness and hyperfairness in multi-party interactions\n", "abstract": " In this paper, a new fairness notion is proposed for languages withmulti-party interactions as the sole interprocess synchronization and communication primitive. The main advantage of this fairness notion is the elimination of starvation occurring solely due to race conditions (i.e., ordering of independent actions). Also, this is the first fairness notion for such languages which is fully adequate with respect to the criteria presented in [2]. The paper defines the notion, proves its properties, and presents examples of its usefulness.", "num_citations": "76\n", "authors": ["1612"]}
{"title": "Interpolation-sequence based model checking\n", "abstract": " SAT-based model checking is the most widely used method for verifying industrial designs against their specification. This is due to its ability to handle designs with thousands of state elements and more. The main drawback of using SAT-based model checking is its orientation towards \u00bfbug-hunting\u00bf rather than full verification of a given specification. Previous works demonstrated how Unbounded Model Checking can be achieved using a SAT solver. In this work we present a novel SAT-based approach to full verification. The approach combines BMC with interpolation-sequence in order to imitate BDD-based Symbolic Model Checking. We demonstrate the usefulness of our method by applying it to industrial-size hardware designs from Intel. Our method compares favorably with McMillan's interpolation based model checking algorithm.", "num_citations": "66\n", "authors": ["1612"]}
{"title": "A game-based framework for CTL counterexamples and 3-valued abstraction-refinement\n", "abstract": " This work exploits and extends the game-based framework of CTL model checking for counterexample and incremental abstraction-refinement. We define a game-based CTL model checking for abstract models over the 3-valued semantics, which can be used for verification as well as refutation. The model checking may end with an indefinite result, in which case we suggest a new notion of refinement, which eliminates indefinite results of the model checking. This provides an iterative abstraction-refinement framework. It is enhanced by an incremental algorithm, where refinement is applied only where indefinite results exist and definite results from prior iterations are used within the model checking algorithm. We also define the notion of annotated counterexamples, which are sufficient and minimal counterexamples for full CTL. We present an algorithm that uses the game board of the model checking game\u00a0\u2026", "num_citations": "59\n", "authors": ["1612"]}
{"title": "3-valued abstraction: More precision at less cost\n", "abstract": " This paper investigates both the precision and the model checking efficiency of abstract models designed to preserve branching time logics w.r.t. a 3-valued semantics. Current abstract models use ordinary transitions to over approximate the concrete transitions, while they use hyper transitions to under approximate the concrete transitions. In this work, we refer to precision measured w.r.t. the choice of abstract states, independently of the formalism used to describe abstract models. We show that current abstract models do not allow maximal precision. We suggest a new class of models and a construction of an abstract model which is most precise w.r.t. any choice of abstract states. As before, the construction of such models might involve an exponential blowup, which is inherent by the use of hyper transitions. We therefore suggest an efficient algorithm in which the abstract model is constructed during model\u00a0\u2026", "num_citations": "56\n", "authors": ["1612"]}
{"title": "Static analysis for state-space reductions preserving temporal logics\n", "abstract": " In this paper we present two methods that use static analysis of parallel programs to create reduced models for them. Our algorithms examine the control-flow graph of a program (the syntax) and create a smaller transition system than would have been created otherwise. The smaller transition system is equivalent to the original transition system of the program with respect to temporal logic specifications.               The two methods are orthogonal in their approach. The first, called path reduction, reduces the state-space by compressing computation paths. This method reduces the number of steps each computation takes. The second method, called dead variable reduction, reduces according to the variable domains. It identifies classes of equivalent states which differ only on variable values (and not the program counter) and uses a representative for each class. We also consider a refinement of the dead\u00a0\u2026", "num_citations": "56\n", "authors": ["1612"]}
{"title": "Scalable distributed on-the-fly symbolic model checking\n", "abstract": " This paper presents a scalable method for parallel symbolic on-the- fly model checking on a distributed-memory environment of workstations. Our method combines a parallel version of an on-the-fly model checker for safety properties with a scalable scheme for reachability analysis. The extra load of storage required for counter example generation is evenly distributed among the processes by our memory balancing. For the sake of scalability, at no point during computation the memory of a single process contains all the data from any of the cycles. The counter example generation is thus performed through collaboration of the parallel processes. We develop a method for the counter example generation keeping a low peak memory requirement during the backward step and the computation of the inverse transition relation. We implemented our method on a standard, loosely-connected environment of\u00a0\u2026", "num_citations": "56\n", "authors": ["1612"]}
{"title": "Learning to order BDD variables in verification\n", "abstract": " The size and complexity of software and hardware systems have significantly increased in the past years. As a result, it is harder to guarantee their correct behavior. One of the most successful methods for automated verification of finite-state systems is model checking. Most of the current model-checking systems use binary decision diagrams (BDDs) for the representation of the tested model and in the verification process of its properties. Generally, BDDs allow a canonical compact representation of a boolean function (given an order of its variables). The more compact the BDD is, the better performance one gets from the verifier. However, finding an optimal order for a BDD is an NP-complete problem. Therefore, several heuristic methods based on expert knowledge have been developed for variable ordering.", "num_citations": "51\n", "authors": ["1612"]}
{"title": "First-order-CTL model checking\n", "abstract": " This work presents a first-order model checking procedure that verifies systems with large or even infinite data spaces with respect to first-order CTL specifications. The procedure relies on a partition of the system variables into control and data. While control values are expanded into BDD-representations, data values enter in form of their properties relevant to the verification task. The algorithm is completely automatic. If the algorithm terminates, it has generated a first-order verification condition on the data space which characterizes the system\u2019s correctness. Termination can be guaranteed for a class that properly includes the data-independent systems, defined in [10].               This work improves [5], where we extended explicit model checking algorithms. Here, both the control part and the first-order conditions are represented by BDDs, providing the full power of symbolic model checking for control aspects\u00a0\u2026", "num_citations": "51\n", "authors": ["1612"]}
{"title": "Achieving speedups in distributed symbolic reachability analysis through asynchronous computation\n", "abstract": " This paper presents a novel BDD-based distributed algorithm for reachability analysis which is completely asynchronous. Previous BDD-based distributed schemes are synchronous: they consist of interleaved rounds of computation and communication, in which the fastest machine (or one which is lightly loaded) must wait for the slowest one at the end of each round.               We make two major contributions. First, the algorithm performs image computation and message transfer concurrently, employing non-blocking protocols in several layers of the communication and the computation infrastructures. As a result, regardless of the scale and type of the underlying platform, the maximal amount of resources can be utilized efficiently. Second, the algorithm incorporates an adaptive mechanism which splits the workload, taking into account the availability of free computational power. In this way, the computation\u00a0\u2026", "num_citations": "48\n", "authors": ["1612"]}
{"title": "Simulation based minimization\n", "abstract": " This work presents a minimization algorithm. The algorithm receives a Kripke structure M and returns the smallest structure that is simulation equivalent to M. The simulation equivalence relation is weaker than bisimulation but stronger than the simulation preorder. It strongly preserves ACTL and LTL (as sub-logics of ACTL*).               We show that every structure M has a unique up to isomorphism reduced structure that is simulation equivalent to M and smallest in size.               We give a Minimizing Algorithm that constructs the reduced structure. It first constructs the quotient structure for M, then eliminates transitions to little brothers and finally deletes unreachable states.               The first step has maximal space requirements since it is based on the simulation preorder over M. To reduce these requirements we suggest the Partitioning Algorithm which constructs the quotient structure for M without ever building\u00a0\u2026", "num_citations": "47\n", "authors": ["1612"]}
{"title": "When not losing is better than winning: Abstraction and refinement for the full \u03bc-calculus\n", "abstract": " This work presents a novel game-based approach to abstraction-refinement for the full \u03bc-calculus, interpreted over 3-valued semantics.A novel notion of non-losing strategy is introduced and exploited for refinement. Previous works on refinement in the context of 3-valued semantics require a direct algorithm for solving a 3-valued model checking game. This was necessary in order to have the information needed for refinement available on one game board. In contrast, while still considering a 3-valued model checking game, here we reduce the problem of solving the game to solving two 2-valued model checking (parity) games. In case the result is indefinite (don\u2019t know), the corresponding non-losing strategies, when combined, hold all the information needed for refinement. This approach is beneficial since it can use any solver for 2-valued parity games. Thus, it can take advantage of newly developed such\u00a0\u2026", "num_citations": "46\n", "authors": ["1612"]}
{"title": "Lazy abstraction and SAT-based reachability in hardware model checking\n", "abstract": " In this work we present a novel lazy abstraction-refinement technique for hardware model checking, integrated with the SAT-based algorithm IC3. In contrast to most SAT-based model checking algorithms, IC3 avoids unrolling of the transition relation. Instead, it applies local checks, while computing over-approximated sets of reachable states. We find IC3 most suitable for lazy abstraction, since each one of its local checks requires different information from the checked model. Similarly to IC3, our algorithm obtains a series of over-approximated sets of states. However, when constructing the series, different abstractions are used for different sets. If an abstract counterexample is obtained, we either find a corresponding concrete one, or apply refinement to eliminate all counterexamples of the same length. Refinement makes the abstractions more precise as needed, and where needed. After refinement, the\u00a0\u2026", "num_citations": "45\n", "authors": ["1612"]}
{"title": "A game-based framework for CTL counterexamples and 3-valued abstraction-refinement\n", "abstract": " This work exploits and extends the game-based framework of CTL model checking for counterexample and incremental abstraction-refinement. We define a game-based CTL model checking for abstract models over the 3-valued semantics, which can be used for verification as well as refutation. The model checking process of an abstract model may end with an indefinite result, in which case we suggest a new notion of refinement, which eliminates indefinite results of the model checking. This provides an iterative abstraction-refinement framework. This framework is enhanced by an incremental algorithm, where refinement is applied only where indefinite results exist and definite results from prior iterations are used within the model checking algorithm. We also define the notion of annotated counterexamples, which are sufficient and minimal counterexamples for full CTL. We present an algorithm that uses the game\u00a0\u2026", "num_citations": "40\n", "authors": ["1612"]}
{"title": "Don\u2019t know in the \u03bc-calculus\n", "abstract": " This work presents game-based model checking for abstract models with respect to specifications in \u03bc-calculus, interpreted over a 3-valued semantics. If the model checking result is indefinite (don\u2019t know), the abstract model is refined, based on an analysis of the cause for this result. For finite concrete models our abstraction-refinement is fully automatic and guaranteed to terminate with a definite result true or false.", "num_citations": "40\n", "authors": ["1612"]}
{"title": "A work-efficient distributed algorithm for reachability analysis\n", "abstract": " This work presents a novel distributed, symbolic algorithm for reachability analysis that can effectively exploit, \u201cas needed\u201d, a large number of machines working in parallel. The novelty of the algorithm is in its dynamic allocation and reallocation of processes to tasks and in its mechanism for recovery, from local state explosion. As a result, the algorithm is work-efficient: it utilizes only those resources that are actually needed. In addition, its high adaptability makes it suitable for exploiting the resources of very large and heterogeneous distributed, non-dedicated environments. Thus, it has the potential of verifying very large systems.               We implemented our algorithm in a tool called Division. Our preliminary experimental results show that the algorithm is indeed work-efficient. Although that the goal of this research is to check larger models, the results also indicate the potential to obtain high speedups\u00a0\u2026", "num_citations": "38\n", "authors": ["1612"]}
{"title": "Proving termination of Prolog programs\n", "abstract": " The paper presented two kinds of proof rules to prove B-termination, the kind of termination obtained by the combination of backtracking and recursion as displayed by Prolog. The first kind of rule takes into account the context of the whole program and is based on a tree oriented operational semantics. The second kind is more compositional, dealing with separate procedures in a context independent way. It is based on a stream oriented semantics.             We would like to stress that such proof rules may be successfully used for defining other search strategies than the actual one used by prolog. An interesting question is to define in this way a probabilistic backtracking search strategy.", "num_citations": "37\n", "authors": ["1612"]}
{"title": "Selective quantitative analysis and interval model checking: Verifying different facets of a system\n", "abstract": " In this work we propose a verification methodology consisting of selective quantitative timing analysis and interval model checking. Our methods can aid not only in determining if a system works correctly, but also in understanding how well the system works. The seleptive quantitative algorithms compute minimum and maximum delays over a selected subset of system executions. A linear-time temporal logic (LTL) formula is used to select either infinite paths or finite intervals over which the computation is performed. We show how tableaux for LTL formulas can be used for selecting either paths or intervals and also for model checking formulas interpreted over paths or intervals.             To demonstrate the usefulness of our methods we have verified a complex and realistic distributed real-time system: Our tool has been able to analyze the system and to compute the response time of the various components\u00a0\u2026", "num_citations": "32\n", "authors": ["1612"]}
{"title": "A framework for translating models and specifications\n", "abstract": " The reasons for translating a description of a model in one notation into another are reviewed. This includes both translating entire models and describing different aspects of a system using different notations.               In order to demonstrate the ideas, the VeriTech framework for translation is described. A system being analyzed is seen as a collection of versions, along with a description of how the versions are related. The versions are given in different notations connected through a core notation by compilers from and to the notations of existing tools and specification methods. The reasons that translations cannot always be exact are analyzed, based on experience with over ten separate compiler translations among formal methods notations. Additional information gathered during translation is described, to facilitate optimizations, error tracing, and analysis.               The concept is presented of a faithful\u00a0\u2026", "num_citations": "31\n", "authors": ["1612"]}
{"title": "What if model checking must be truly symbolic\n", "abstract": " There are many methodologies whose main concern is reducing the complexity of a verification problem to be ultimately able to apply model checking. Here we propose to use a model-checking like procedure which operates on a small, truly symbolic description of the model. We do so by exploiting systematically the separation between the (small) control part and the (large) data part of systems which often occurs in practice. By expanding the control part, we get an intermediate description of the system which already allows our symbolic model checking procedure to produce meaningful results but which is still small enough to allow model checking to be performed.", "num_citations": "31\n", "authors": ["1612"]}
{"title": "A synthesis of two approaches for verifying finite state concurrent systems\n", "abstract": " Finite state concurrent systems arise in many applications. Both sequential circuits and communication protocols can be viewed as implementing such systems at some level of abstraction. When the number of system states is large, correctness may become a major problem. Two techniques have shown promise for automatically verifying this type of program. The first approach is based on temporal logic model checking and is used in the CTL verifier ([6],[7]) developed at CMU. The second approach is based on showing containment between between automata and is used by the COSPAN system developed at Bell laboratories ([1],[13]). Although the two verification systems have the same basic goal, they differ significantly in the way they attempt to achieve this goal.The CTL model checker determines whether a formula of the propositional, branching-time logic CTL is true in some state of a labelled state-transition\u00a0\u2026", "num_citations": "30\n", "authors": ["1612"]}
{"title": "The modular framework of computer-aided verification\n", "abstract": " The state explosion problem arises in systems composed of many loosely coupled components. The size of such a system may grow as the product of the sizes of its components. Thus, space requirement might become too large for a model checking procedure to be applicable. Obviously, state explosion affects the time-complexity as well. The pre-verified component methodology refers to the verification of systems containing an already verified component, that avoids redoing the component's proof. When verifying a specific system, it should be possible to exploit the pre-verification of the component. As a result, the average verification time-complexity over the set of systems containing this preverified component should be reduced.It seems natural to consider the use of compositional reasoning as a solution to the state explosion problem. Exploiting the modular structure of a system, a compositional verification\u00a0\u2026", "num_citations": "29\n", "authors": ["1612"]}
{"title": "A work-efficient distributed algorithm for reachability analysis\n", "abstract": " This work presents a novel distributed symbolic algorithm for reachability analysis that can effectively exploit, as needed, a large number of machines working in parallel. The novelty of the algorithm is in its dynamic allocation and reallocation of processes to tasks and in its mechanism for recovery from local state explosion. As a result, the algorithm is work-efficient: it utilizes only those resources that are actually needed. In addition, its high adaptability makes it suitable for exploiting the resources of very large and heterogeneous distributed, nondedicated environments. Thus, it suitable for verifying very large systems. We implemented our algorithm in a tool called Division. Our experimental results show that the algorithm is indeed work-efficient. Although the goal of this research is to check larger models, the results also indicate that the algorithm can obtain high speedups, because communication\u00a0\u2026", "num_citations": "28\n", "authors": ["1612"]}
{"title": "Combining symmetry reduction and under-approximation for symbolic model checking\n", "abstract": " This work presents a collection of methods, integrating symmetry reduction, under- approximation, and symbolic model checking in order to reduce space and time for model checking. The main goal of this work is falsification. However, under certain conditions our methods provide verification as well.               We first present algorithms that perform on-the-fly model checking for temporal safety properties, using symmetry reduction. We then extend these algorithms for checking liveness properties as well.               Our methods are fully automatic. The user should supply some basic information about the symmetry in the verified system. However, the methods are robust and work correctly even if the information supplied by the user is incorrect. Moreover, the methods return correct results even in case the computation of the symmetry reduction has not been completed due to memory or time explosion\u00a0\u2026", "num_citations": "27\n", "authors": ["1612"]}
{"title": "Verification of temporal properties\n", "abstract": " The paper presents a relatively complete deductive system for proving branching time temporal properties of reactive programs. No deductive system for verifying branching time temporal properties has been presented before. Our deductive system enjoys the following advantages. First, given a well-formed specification there is no need to translate it into a normal-form specification since the system can handle any well-formed specification. Second, given a specification to be verified, the proof rule to be applied is easily determined according to the top level operator of the specification. Third, the system reduces temporal verification to assertional reasoning rather than to temporal reasoning.", "num_citations": "27\n", "authors": ["1612"]}
{"title": "Abstraction and refinement in model checking\n", "abstract": " In this paper we survey abstraction and refinement in model checking. We restrict the discussion to existential abstraction which over-approximates the behaviors of the concrete model. The logics preserved under this abstraction are the universal fragments of branching-time temporal logics as well as linear-time temporal logics. For simplicity of presentation, we also restrict the discussion to abstraction functions, rather then abstraction relations. Thus, every concrete state is represented by exactly one abstract state. An abstract state then represents a set of concrete states, which is disjoint from the sets represented by other abstract states.", "num_citations": "25\n", "authors": ["1612"]}
{"title": "Multi-valued model checking games\n", "abstract": " This work extends the game-based framework of \u03bc-calculus model checking to the multi-valued setting. In multi-valued model checking a formula is interpreted over a Kripke structure defined over a lattice. The value of the formula is also an element of the lattice. We define a new game for this problem and derive from it a direct model checking algorithm that handles the multi-valued structure without any reduction. We investigate the properties of the new game, both independently, and in comparison to the automata-based approach. We show that the usual resemblance between the two approaches does not hold in the multi-valued setting and show how it can be regained by changing the nature of the game.", "num_citations": "25\n", "authors": ["1612"]}
{"title": "Fair termination of communicating processes\n", "abstract": " Fairness has become one of the main issues in the theory of non-determinism and concurrency. Recently, the problem of proof rules for fair termination of programs (and some of its variants) has attracted considerable attention ([AO83],[APS82],[GFK83],[GFMR81],[LPS81],[P83]). However, though the main interest and motivation for the consideration of fair termination stems from concurrency, almost all of the recent results are formulated in terms of nondeterministic programs. The main reason for this is the elegance of formalisms for structured nondeterminism, such as Guarded Commands [DIJ76], and their convenience for syntax directed proofs. Other attempts use transition-systems as the program model, and temporal logic as the underlying reasoning formalism ([QS82],[P83]), thereby giving up the structured, syntax-directed, approach.", "num_citations": "25\n", "authors": ["1612"]}
{"title": "Automatic refinement and vacuity detection for symbolic trajectory evaluation\n", "abstract": " Symbolic Trajectory Evaluation (STE) is a powerful technique for model checking. It is based on 3-valued symbolic simulation, using 0,1 and X (\u201dunknown\u201d). The X value is used to abstract away parts of the circuit. The abstraction is derived from the user\u2019s specification. Currently the process of abstraction and refinement in STE is performed manually. This paper presents an automatic refinement technique for STE. The technique is based on a clever selection of constraints that are added to the specification so that on the one hand the semantics of the original specification is preserved, and on the other hand, the part of the state space in which the \u201dunknown\u201d result is received is significantly decreased or totally eliminated. In addition, this paper raises the problem of vacuity of passed and failed specifications. This problem was never discussed in the framework of STE. We describe when an STE specification\u00a0\u2026", "num_citations": "22\n", "authors": ["1612"]}
{"title": "Making predicate abstraction efficient\n", "abstract": " In this paper we consider techniques to identify and remove redundant predicates during predicate abstraction. We give three criteria for identifying redundancy. A predicate is redundant if any of the following three holds (i) the predicate is equivalent to a propositional function of other predicates. (ii) removing the predicate preserves safety properties satisfied by the abstract model (iii) removing it preserves bisimulation equivalence. We also show how to efficiently remove the redundant predicates once they are identified. Experimental results are included to demonstrate the effectiveness of our methods.", "num_citations": "22\n", "authors": ["1612"]}
{"title": "A scalable parallel algorithm for reachability analysis of very large circuits\n", "abstract": " This paper presents a scalable method for parallelizing symbolic reachability analysis on a distributed-memory environment of workstations. We have developed an adaptive partitioning algorithm that significantly reduces space requirements. The memory balance is maintained by dynamically repartitioning the state space throughout the computation. A compact BDD representation allows coordination by shipping BDDs from one machine to another. This representation allows for different variable orders in the sending and receiving processes. The algorithm uses a distributed termination protocol, with none of the memory modules preserving a complete image of the set of reachable states. No external storage is used on the disk. Rather, we make use of the network, which is much faster.               We implemented our method on a standard, loosely-connected environment of workstations, using a high\u00a0\u2026", "num_citations": "22\n", "authors": ["1612"]}
{"title": "Highlevel verification of control intensive systems using predicate abstraction\n", "abstract": " Predicate abstraction has been widely used for model checking hardware/software systems. However, for control intensive systems, existing predicate abstraction techniques can potentially result in a blowup of the size of the abstract model. We deal with this problem by retaining important control variables in the abstract model. By this method we avoid having to introduce an unreasonable number of predicates to simulate the behavior of the control variables.             We also show how to improve predicate abstraction by extracting useful information from a high level representation of hardware/software systems. This technique works by first extracting relevant branch conditions. These branch conditions are used to invalidate spurious abstract counterexamples through a new counterexample-based lazy refinement algorithm. Experimental results are included to demonstrate the effectiveness of our methods.", "num_citations": "20\n", "authors": ["1612"]}
{"title": "Intertwined forward-backward reachability analysis using interpolants\n", "abstract": " In this work we develop a novel SAT-based verification approach which is based on interpolation. The novelty of our approach is in extracting interpolants in both forward and backward manner and exploiting them for an intertwined approximated forward and backward reachability analysis. Our approach is also mostly local and avoids unrolling of the checked model as much as possible. This results in an efficient and complete SAT-based verification algorithm.               We implemented our algorithm and compared it with both McMillan\u2019s interpolation-based algorithm and with IC3, on real-life industrial designs as well as on examples from the HWMCC\u201911 benchmark. In many cases, our algorithm outperformed both methods.", "num_citations": "19\n", "authors": ["1612"]}
{"title": "3-valued circuit SAT for STE with automatic refinement\n", "abstract": " Symbolic Trajectory Evaluation (STE) is a powerful technique for hardware model checking. It is based on a 3-valued symbolic simulation, using 0,1 and X (\u201dunknown\u201d), where the X is used to abstract away values of the circuit nodes.               Most STE tools are BDD-based and use a dual rail representation for the three possible values of circuit nodes. SAT-based STE tools typically use two variables for each circuit node, to comply with the dual rail representation.               In this work we present a novel 3-valued Circuit SAT-based algorithm for STE. The STE problem is translated into a Circuit SAT instance. A solution for this instance implies a contradiction between the circuit and the STE assertion. An unSAT instance implies either that the assertion holds, or that the model is too abstract to be verified. In case of a too abstract model, we propose a refinement automatically.               We implemented our 3\u00a0\u2026", "num_citations": "19\n", "authors": ["1612"]}
{"title": "Combining symmetry reduction and under-approximation for symbolic model checking\n", "abstract": " This work presents a collection of methods that integrate symmetry reduction and under-approximation with symbolic model checking in order to reduce space and time. The main objective of these methods is falsification. However, under certain conditions, they can provide verification as well.               We first present algorithms that use symmetry reduction to perform on-the-fly model checking for temporal safety properties. These algorithms avoid building the orbit relation and choose representatives on-the-fly while computing the reachable states. We then extend these algorithms to check liveness properties as well. In addition, we introduce an iterative on-the-fly algorithm that builds subsets of the orbit relation rather than the full relation.               Our methods are fully automatic once the user supplies some basic information about the symmetry in the verified system. Moreover, the methods are robust and\u00a0\u2026", "num_citations": "19\n", "authors": ["1612"]}
{"title": "How linear can branching-time be?\n", "abstract": " We suggest a new characterization that draws finer lines between branching-time and linear-time formulas of the logic CTL*. We define three types of linearity, strong linearity, sub-linearity and equi-linearity, each of which contains all LTL formulas. We prove that these notions are distinct. Moreover, strong linearity implies sub-linearity which implies equi-linearity. We investigate these notions over Kripke structures with and without fairness and show that they do not coincide. We give a syntactic characterization for linear \u2200CTL* formulas. Finally, we discuss the practical implication of the new characterization.", "num_citations": "19\n", "authors": ["1612"]}
{"title": "A synthesis of two approaches for verifying finite state concurrent systems\n", "abstract": " The paper provides a synthesis between two main approaches to automatic verification of finite-state systems: temporal logic model checking and language containment of automata on infinite tapes. A new branching-time temporal logic is suggested, in which automata on infinite tapes are used to define new temporal operators. Each such operator defines a set of acceptable computation paths. Path quantifiers are used to specify whether all paths or some path from a state should be in some acceptable set. The logic is very powerful and includes both linear-time and branching-time temporal logics. We give an efficient model checking procedure that checks whether a finite-state system satisfies its specification, given by a formula of the new logic. Our procedure is linear in the size of the system and a low level polynomial in the size of the specification.", "num_citations": "19\n", "authors": ["1612"]}
{"title": "Automated circular assume-guarantee reasoning\n", "abstract": " Model checking is a successful approach for verifying hardware and software systems. Despite its success, the technique suffers from the state explosion problem which arises due to the large state space of real-life systems. One solution to the state explosion problem is compositional verification, that aims to decompose the verification of a large system into the more manageable verification of its components. To account for dependencies between components, assume-guarantee reasoning defines rules that break-up the global verification of a system into local verification of individual components, using assumptions about the rest of the system. In recent years, compositional techniques have gained significant successes following a breakthrough in the ability to automate assume-guarantee reasoning. However, automation has been restricted to simple acyclic assume-guarantee rules. In this work, we\u00a0\u2026", "num_citations": "17\n", "authors": ["1612"]}
{"title": "Finding security vulnerabilities in a network protocol using parameterized systems\n", "abstract": " This paper presents a novel approach to automatically finding security vulnerabilities in the routing protocol OSPF \u2013 the most widely used protocol for Internet routing. We start by modeling OSPF on (concrete) networks with a fixed number of routers in a specific topology. By using the model checking tool CBMC, we found several simple, previously unpublished attacks on OSPF.               In order to search for attacks in a family of networks with varied sizes and topologies, we define the concept of an abstract network which represents such a family. The abstract network  has the property that if there is an attack on  then there is a corresponding attack on each of the (concrete) networks represented by\u00a0.               The attacks we have found on abstract networks reveal security vulnerabilities in the OSPF protocol, which can harm routing in huge networks with complex topologies. Finding such attacks directly\u00a0\u2026", "num_citations": "16\n", "authors": ["1612"]}
{"title": "Efficient automatic STE refinement using responsibility\n", "abstract": " Symbolic Trajectory Evaluation (STE) is a powerful technique for hardware model checking. It is based on 3-valued symbolic simulation, using 0,1, and X (\u201cunknown\u201d). X is used to abstract away values of circuit nodes, thus reducing memory and runtime of STE runs. The abstraction is derived from a given user specification.               An STE run results in \u201cpass\u201d (1), if the circuit satisfies the specification, \u201cfail\u201d (0) if the circuit falsifies it, and \u201cunknown\u201d (X), if the abstraction is too coarse to determine either of the two. In the latter case, refinement is needed: The X values of some of the abstracted inputs should be replaced. The main difficulty is to choose an appropriate subset of these inputs that will help to eliminate the \u201cunknown\u201d STE result, while avoiding an unnecessary increase in memory and runtime. The common approach to this problem is to manually choose these inputs.               This work suggests a\u00a0\u2026", "num_citations": "16\n", "authors": ["1612"]}
{"title": "Compositional verification and 3-valued abstractions join forces\n", "abstract": " Two of the most promising approaches to fighting the state explosion problem are abstraction and compositional verification. In this work we join their forces to obtain a novel fully automatic compositional technique that can determine the truth value of the full \u03bc-calculus with respect to a given system.               Given a system , we view each component  as an abstraction  of the global system. The abstract component  is defined using a 3-valued semantics so that whenever a \u03bc-calculus formula \u03d5 has a definite value (true or false) on , the same value holds also for . Thus, \u03d5 can be checked on either  or  (or both), and if any of them returns a definite result, then this result holds also for . If both checks result in an indefinite value, the composition of the components needs to be considered. However, instead of constructing the composition of  and , our approach\u00a0\u2026", "num_citations": "16\n", "authors": ["1612"]}
{"title": "Applying software model checking techniques for behavioral UML models\n", "abstract": " This work presents a novel approach for the verification of Behavioral UML models, by means of software model checking.             We propose adopting software model checking techniques for verification of UML models. We translate UML to verifiable C code which preserves the high level structure of the models, and abstracts details that are not needed for verification. We combine of static analysis and bounded model checking for verifying LTL safety properties and absence of livelocks.             We implemented our approach on top of the bounded software model checker CBMC. We compared it to an IBM research tool that verifies UML models via a translation to IBM\u2019s hardware model checker RuleBasePE. Our experiments show that our approach is more scalable and more robust for finding long counterexamples. We also demonstrate the usefulness of several optimizations that we introduced into our tool.", "num_citations": "14\n", "authors": ["1612"]}
{"title": "Modular minimization of deterministic finite-state machines\n", "abstract": " This work presents a modular technique for minimizing a deterministic finite-state machine (FSM) while preserving its equivalence to the original system. Being modular, the minimization technique should consume less time and space. Preserving equivalence, the resulting minimized model can be employed in both temporal logic model checking and sequential equivalence checking, thus reducing their time and space consumption. As deterministic FSMs are commonly used for modeling hardware designs, our approach is suitable for formal verification of such designs. We develop a new BDD framework for the representation and manipulation of functions and show how our minimization technique can be effectively implemented within this framework.", "num_citations": "14\n", "authors": ["1612"]}
{"title": "Computer Aided Verification: 9th International Conference, CAV'97, Haifa, Israel, June 22-25, 1997, Proceedings\n", "abstract": " This book constitutes the strictly refereed proceedings of the 9th International Conference on Computer Aided Verification, CAV'97, held in Haifa, Israel, in June 1997. The volume presents 34 revised full papers selected from a total of 84 submissions. Also included are 7 invited contributions as well as 12 tool descriptions. The volume is dedicated to the theory and practice of computer aided formal methods for software and hardware verification, with an emphasis on verification tools and algorithms and the techniques needed for their implementation. The book is a unique record documenting the recent progress in the area.", "num_citations": "14\n", "authors": ["1612"]}
{"title": "Multi-valued model checking games\n", "abstract": " This work extends the game-based framework of \u03bc-calculus model checking to the multi-valued setting. In multi-valued model checking a formula is interpreted over a Kripke structure defined over a lattice. The value of the formula is also an element of the lattice. This problem has many applications in verification, such as handling abstract or partial models, analyzing systems in the presence of inconsistent views, and performing temporal logic query checking. We define a new game for the multi-valued model checking problem of the full \u03bc-calculus, and demonstrate how to derive from it a direct model checking algorithm for its alternation-free fragment. The algorithm handles the multi-valued structure without any reduction. We investigate the properties of the new game, both independently, and in comparison to the automata-based approach. We show that the usual resemblance between the automata-based and\u00a0\u2026", "num_citations": "13\n", "authors": ["1612"]}
{"title": "A framework for compositional verification of multi-valued systems via abstraction-refinement\n", "abstract": " We present a framework for fully automated compositional verification of \u03bc-calculus specifications over multi-valued systems, based on multi-valued abstraction and refinement.               Multi-valued models are widely used in many applications of model checking. They enable a more precise modeling of systems by distinguishing several levels of uncertainty and inconsistency. Successful verification tools such as STE (for hardware) and YASM (for software) are based on multi-valued models.               Our compositional approach model checks individual components of a system. Only if all individual checks return indefinite values, the parts of the components which are responsible for these values, are composed and checked. Thus the construction of the full system is avoided. If the latter check is still indefinite, then a refinement is needed.               We formalize our framework based on bilattices, consisting of a\u00a0\u2026", "num_citations": "13\n", "authors": ["1612"]}
{"title": "Applicability of fair simulation\n", "abstract": " In this paper we compare four notions of fair simulation: direct [9], delay [12], game [19], and exists [16]. Our comparison refers to three main aspects: The time complexity of constructing the fair simulation, the ability to use it for minimization, and the relationship between the fair simulations and universal branching-time logics. We developed a practical application that is based on this comparison. The application is a new implementation for the assume-guarantee modular framework presented By Grumberg at al. in [ACM Transactions on Programming Languages and Systems (TOPLAS), 16 (1994) 843]. The new implementation significantly improves the complexity of the framework.", "num_citations": "13\n", "authors": ["1612"]}
{"title": "Scalable distributed on-the-fly symbolic model checking\n", "abstract": " This paper presents a scalable method for parallel symbolic on-the-fly model checking in a distributed memory environment. Our method combines a scheme for on-the-fly model checking for safety properties with a scheme for scalable reachability analysis. We suggest an efficient, BDD-based algorithm for a distributed construction of a counterexample. The extra memory requirement for counterexample generation is evenly distributed among the processes by a memory balancing procedure. At no point during computation does the memory of a single process contain all the data. This enhances scalability. Collaboration between the parallel processes during counterexample generation reduces memory utilization for the backward step. We implemented our method on a standard, loosely- connected environment of workstations, using a high-performance model checker. Our initial performance evaluation\u00a0\u2026", "num_citations": "13\n", "authors": ["1612"]}
{"title": "The design and verification of finite state hardware controllers\n", "abstract": " In this section we show how SML can be used to construct a simple DMA controller. In the next section we show how our model checking program can be used to guarantee that our DMA design meets certain timing properties expressed in the logic CI \u2018L. Direct memory access (DM A) is a technique that permits blocks of data to be transferred directly from an I/O peripheral to main memory without using any of the CPU\u2019s data or address registers. With this technique (which is sometimes called cycle stealing) the DMA peripheral can execute a memory access at any time that the CPU is not using the memory. Moreover, the CPU will be able to continue with its normal operations until it reaches a point where it needs to make a memory access but a DMA operation is still in progress. Our design for a DMA controller is loosely based on one that is described in [8]. Although it is probably much simpler than most actual DMA\u00a0\u2026", "num_citations": "13\n", "authors": ["1612"]}
{"title": "2-Valued and 3-Valued Abstraction-Refinement in Model Checking.\n", "abstract": " This paper presents two frameworks for abstraction-refinement in model checking. The first is the CounterExample-Guided Abstraction-Refinement (CEGAR) which can verify universal fragments of temporal logics and is based on a 2-valued semantics of temporal logics. The other is the Three-valued Abstraction-Refinement (TVAR) and is based on a 3-valued semantics of these logics. We also present an application of the 3-valued framework for fully automatic compositional model checking. Based on this and other successful applications of the 3-valued framework we conclude that the additional power it provides is worth the extra efforts of having non-standard definitions and algorithms.", "num_citations": "12\n", "authors": ["1612"]}
{"title": "A new approach to bounded model checking for branching time logics\n", "abstract": " Bounded model checking (BMC) is a technique for overcoming the state explosion problem which has gained wide industrial acceptance. Bounded model checking is typically applied only for linear-time properties, with a few exceptions, which search for a counter-example in the form of a tree-like structure with a pre-determined shape. We suggest a new approach to bounded model checking for universal branching-time logic, in which we encode an arbitrary graph and allow the SAT solver to choose both the states and edges of the graph. This significantly reduces the size of the counter-example produced by BMC.               A dynamic completeness criterion is presented which can be used to halt the bounded model checking when it becomes clear that no counter-example can exist. Thus, verification of the checked property can also be achieved. Experiments show that our approach outperforms another\u00a0\u2026", "num_citations": "12\n", "authors": ["1612"]}
{"title": "Translating natural language system specifications into temporal logic via DRT\n", "abstract": " In the past several years an automatic verification technique for finite-state concurrent (software and hardware) systems has been developed. By this technique, behavioral specifications of a system, expressed in a propositional temporal logic, are algorithmically checked against a model of the system. A recognized problem of this approach is making the formalism, in which specificatoins are expressed, more convenient. This paper describes a method for automatically translating natural language specifications into temporal logic, via an intermediate representation in DRT. Using this method, users may express complex specifications in relatively free natural language, while ensuring that they are correctly translated into temporal logic and subsequently verified. We describe an implementation of this method ina unification-based grammar formalism, CUF. This paper describes an application of computational linguistic methods to the domain of verification of computer systems (both software and hardware). We present a method for automatically translating natural language (NL) behavioral specifications of computer systems into temporal logic (TL), for which tools for automatic formal verification are well-developed. The method presented here has been implemented.", "num_citations": "12\n", "authors": ["1612"]}
{"title": "The model checking problem for concurrent systems with many similar processes\n", "abstract": " 1. INTRODUCTION In [CGB] we addressed the problem of devising an appropriate logic for reasoning about concurrent systems with many identical processes. The logic that we proposed is based on computation trees and is called indexed CTL* or ICI~*. It includes all of CTL*(ICES],[EC],[EH]) with the exception of the next-time operator and can, therefore, handle both linear and branching time properties with equal facility. In addition, our logic permits formulas of the form Af (i) and Vfi (i) where f (i) is a formula of our logic. All of the atomic propositions that appear within the subformula f (i) must be subscripted by i. A formula of our logic is said to be closed if all indexed propositions are within the scope of either a A or i", "num_citations": "12\n", "authors": ["1612"]}
{"title": "Efficient Craig interpolation for linear Diophantine (dis) equations and linear modular equations\n", "abstract": " The use of Craig interpolants has enabled the development of powerful hardware and software model checking techniques. Efficient algorithms are known for computing interpolants in rational and real linear arithmetic. We focus on subsets of integer linear arithmetic. Our main results are polynomial time algorithms for obtaining interpolants for conjunctions of linear Diophantine equations, linear modular equations (linear congruences), and linear Diophantine disequations. We also present an interpolation result for conjunctions of mixed integer linear equations. We show the utility of the proposed interpolation algorithms for discovering modular/divisibility predicates in a counterexample guided abstraction refinement (CEGAR) framework. This has enabled verification of simple programs that cannot be checked using existing CEGAR based model checkers.", "num_citations": "11\n", "authors": ["1612"]}
{"title": "E cient generation of counterexamples and witnesses in symbolic model checking\n", "abstract": " Model checking is an automatic technique for verifying sequential circuit designs and protocols. An e cient search procedure is used to determine whether or not the speci cation is satis ed. If it is not satis ed, our technique will produce a counterexample execution trace that shows the cause of the problem. Although nding counterexamples is extremely important, there is no description of how to do this in the literature on model checking. We describe an e cient algorithm to produce counterexamples and witnesses for symbolic model checking algorithms. This algorithm is used in the SMV model checker and works quite well in practice. We also discuss how to extend our technique to more complicated speci cations. This extension makes it possible to nd counterexamples for veri cation procedures based on showing language containment between various types of!-automata.", "num_citations": "11\n", "authors": ["1612"]}
{"title": "Automated circular assume-guarantee reasoning with N-way decomposition and alphabet refinement\n", "abstract": " In this work we develop an automated circular reasoning framework that is applicable to systems decomposed into multiple components. Our framework uses a family of circular assume-guarantee rules for which we give conditions for soundness and completeness. The assumptions used in the rules are initially approximate and their alphabets are automatically refined based on the counterexamples obtained from model checking the rule premises. A key feature of the framework is that the compositional rules that are used change dynamically with each iteration of the alphabet refinement, to only use assumptions that are relevant for the current alphabet, resulting in a smaller number of assumptions and smaller state spaces to analyze for each premise. Our preliminary evaluation of the proposed approach shows promising results compared to 2-way and monolithic verification.", "num_citations": "10\n", "authors": ["1612"]}
{"title": "Identification of missing properties in model checking\n", "abstract": " A method for verification includes providing an implementation model, which defines model states of a target system and model transitions between the model states, and providing a specification of the target system, including properties that the system is expected to obey. A tableau is created from the specification, the tableau defining tableau states with tableau transitions between the tableau states in accordance with the properties. The tableau transitions are compared to the model transitions to determine whether a discrepancy exists therebetween.", "num_citations": "10\n", "authors": ["1612"]}
{"title": "Abstractions and reductions in model checking\n", "abstract": " We introduce the basic concepts of temporal logic model checking and its state explosion problem. We then focus on abstraction, which is one of the major methods for overcoming this problem. We distinguish between weak and strong preservations of properties by a given abstraction. We show how abstract models preserving ACTL* can be defined with human aid or automatically. When the abstraction is too coarse, we show how refinement can be applied to produce a more precise abstract model. Abstract interpretation is then introduced and applied in order to construct abstract models that are more precise and allow more ACTL properties to be proven. Finally, we show how to define abstract models that preserve ECTL* and full CTL*.", "num_citations": "10\n", "authors": ["1612"]}
{"title": "Selective quantitative analysis and interval model checking: Verifying different facets of a system\n", "abstract": " In this work we propose a verification methodology consisting of selective quantitative timing analysis and interval model checking. Our methods can aid not only in determining if a system works correctly, but also in understanding how well the system works. The selective quantitative algorithms compute minimum and maximum delays over a selected subset of system executions. A linear-time temporal logic (LTL) formula is used to select either infinite paths or finite intervals over which the computation is performed. We show how tableau for LTL formulas can be used for selecting either paths or intervals and also for model checking formulas interpreted over paths or intervals.               To demonstrate the usefulness of our methods we have verified a complex and realistic distributed real-time system. Our tool has been able to analyze the system and to compute the response time of the various components\u00a0\u2026", "num_citations": "10\n", "authors": ["1612"]}
{"title": "Modular abstractions for verifying real-time distributed systems\n", "abstract": " In this work we present a verification methodology for real-time distributed systems, based on their modular decomposition into processes. Given a distributed system, each of its components is reduced by abstracting away from details that are irrelevant for the required specification. The abstract components are then composed to form an abstract system to which a model checking procedure is applied. The abstraction relation and the specification language guarantee that if the abstract system satisfies a specification, then the original system satisfies it as well.               The specification languageRTL is a branching-time version of the real-time temporal logicTPTL presented in Alur and Henzinger [1]. Its model checking is linear in the size of the system and exponential in the size of the formula. Two notions of abstraction for real-time systems are introduced, each preserving a sublanguage ofRTL.", "num_citations": "10\n", "authors": ["1612"]}
{"title": "Program composition and modular verification\n", "abstract": " Program composition and modularity have proven themselves as an important approach for simplifying the design and verification of large programs.             The contributions of this paper include:                                                                1.                                         A proposal of a modular and complete proof system for fair termination of a parallel-composed program.                                                                        2.                                         A proposal of a proof system for union and superposition.                                                                             Modular termination proof systems that have been suggested before are defined for models with an unfair scheduler. The proof approach presented in them fails to be complete in a model with a fair scheduler. The main idea suggested here which allows for the development of a modular and complete proof system for fair termination is a new program property, called gapped-termination.", "num_citations": "10\n", "authors": ["1612"]}
{"title": "Verifying behavioral UML systems via CEGAR\n", "abstract": " This work presents a novel approach for applying abstraction and refinement in the verification of behavioral UML models.                 The Unified Modeling Language (UML) is a widely accepted modeling language for embedded and safety critical systems. As such the correct behavior of systems represented as UML models is crucial. Model checking is a successful automated verification technique for checking whether a system satisfies a desired property. Nevertheless, its applicability is often impeded by its high time and memory requirements. A successful approach to avoiding this limitation is CounterExample-Guided Abstraction-Refinement (CEGAR). We propose a CEGAR-like approach for UML systems. We present a model-to-model transformation that generates an abstract                   UML system from a given concrete one, and formally prove that our transformation creates an over-approximation\u00a0\u2026", "num_citations": "9\n", "authors": ["1612"]}
{"title": "Compositional verification and 3-valued abstractions join forces\n", "abstract": " Two of the most promising approaches to fighting the state explosion problem are abstraction and compositional verification. In this work, we join their forces to obtain a novel fully automatic compositional technique that can determine the truth value of the full \u03bc-calculus with respect to a given system. Given a system M= M 1\u2016 M 2, we view each component M i as an abstraction M i\u2191 of the global system. The abstract component M i\u2191 is defined using a 3-valued semantics so that whenever a \u03bc-calculus formula \u03c6 has a definite value (true or false) on M i\u2191, the same value holds also for M. Thus, \u03c6 can be checked on either M 1\u2191 or M 2\u2191(or both), and if any of them returns a definite result, then this result holds also for M. If both checks result in an indefinite value, the composition of the components needs to be considered. However, instead of constructing the composition of M 1\u2191 and M 2\u2191, our approach identifies\u00a0\u2026", "num_citations": "9\n", "authors": ["1612"]}
{"title": "Automatic verification of sequential circuit designs\n", "abstract": " Temporal logic model checking is a method for automatically deciding if a sequential circuit satisfies its specifications. In this approach, the circuit is modelled as a state transition system, and specifications are given by temporal logic formulas. Efficient search algorithms are used to determine if the specifications are satisfied or not. The procedure has been used successfully in the past to find subtle errors in a number of non-trivial circuit designs. Recentlv. the size of the circuits that can be handled bv this technique has increased dramatically. It is now possible to verify transition systems that are many orders of magnitude larger than was previously the case. In this paper, we describe some of the techniques that have made this increase possible. These techniques are based on the use of binary decision diagrams to represent transition svstems and sets of states.", "num_citations": "9\n", "authors": ["1612"]}
{"title": "3-valued abstraction for (bounded) model checking\n", "abstract": " Model Checking is the problem of verifying that a given model satisfies a specification, given in a formal specification language. Abstraction is one of the most successful approaches to avoiding the state explosion problem in model checking. It simplifies the model being checked, in order to save memory and time.               3-valued abstraction is a strong type of abstraction that can be used for both verification and refutation. For hardware verification, 3-valued abstraction can be obtained by letting state variables and inputs range over the ternary domain 0,1,X, where X stands for \u201cunknown\u201d. X is used to abstract away parts of the circuit that are irrelevant for the property being checked. For 3-valued abstractions, checking an abstract model may result in 1 or 0, indicating that the checked property holds or fails, respectively, on the original model. Alternatively, model checking may result in X, indicating that it is\u00a0\u2026", "num_citations": "8\n", "authors": ["1612"]}
{"title": "Veritech: a framework for translating among model description notations\n", "abstract": " The reasons for translating a description of a model in one notation into another are reviewed. Such model descriptions are used as input to formal verification tools or as design-level descriptions for protocols or hardware. Translations are used to produce input to a different tool to verify properties not verified in the source model, and to connect notations that have no associated verification tool to those that do.               The VeriTech framework for translation is described. A system being analyzed is seen as a collection of versions, along with a characterization of how the versions are related, and properties known to be true of each version. The versions are given in different notations connected through a core notation by compilers from and to the notations of existing tools and specification methods. The reasons that translations cannot always be exact are analyzed. To facilitate optimizations during\u00a0\u2026", "num_citations": "8\n", "authors": ["1612"]}
{"title": "Software safety and security: Tools for analysis and verification\n", "abstract": " Recent decades have seen major advances in methods and tools for checking the safety and security of software systems. Automatic tools can now detect security flaws not only in programs of the order of a million lines of code, but also in high-level protocol descriptions. There has also been something of a breakthrough in the area of operating system verification. This book presents the lectures from the NATO Advanced Study Institute on Tools for Analysis and Verification of Software Safety and Security; a summer school held at Bayrischzell, Germany, in 2011. This Advanced Study Institute was divided into three integrated modules: Foundations of Safety and Security, Applications of Safety Analysis and Security Analysis. Subjects covered include mechanized game-based proofs of security protocols, formal security proofs, model checking, using and building an automatic program verifier and a hands-on introduction to interactive proofs. Bringing together many leading international experts in the field, this NATO Advanced Study Institute once more proved invaluable in facilitating the connections which will influence the quality of future research and the potential to transfer research into practice. This book will be of interest to all those whose work depends on the safety and security of software systems.", "num_citations": "7\n", "authors": ["1612"]}
{"title": "Translations between textual transition systems and Petri nets\n", "abstract": " Translations between models expressed in textual transition systems and those expressed in structured Petri net notation are presented, in both directions. The translations are structure-preserving, meaning that the hierarchical structure of the systems is preserved. Furthermore, assuming non-finite data has been abstracted out of the textual transition system, then translating one model to another and then back results in a model which is identical to the original one, up to renaming and the form of Boolean expressions. Due to inherent differences between the two notations, however, some additional information is required in order to obtain this identity. The information is collected during the translation in one direction and is used in the translation back.               Our translation is also semantics-preserving. That is, the original model and the translated model are bisimulation equivalent, assuming non-finite\u00a0\u2026", "num_citations": "7\n", "authors": ["1612"]}
{"title": "Infinite trees, markings, and well-foundedness\n", "abstract": " A necessary and sufficient condition for a given marked tree to have no infinite paths satisfying a given formula is presented. The formulas are taken from a language introduced by Harel, covering a wide scale of properties of infinite paths, including most of the known notions of fairness. This condition underlies a proof rule for proving that a nondeterministic program has no infinite computations satisfying a given formula, interpreted over state sequences. We also show two different forms of seemingly more natural necessary and sufficient conditions to be inadequate.", "num_citations": "7\n", "authors": ["1612"]}
{"title": "Tools and Algorithms for the Construction and Analysis of Systems: 13th International Conference, TACAS 2007 Held as Part of the Joint European Conferences on Theory and\u00a0\u2026\n", "abstract": " This book constitutes the refereed proceedings of the 13th International Conference on Tools and Algorithms for the Construction and Analysis of Systems, TACAS 2007, held in Braga, Portugal. Coverage includes software verification, probabilistic model checking and markov chains, automata-based model checking, security, software and hardware verification, decision procedures and theorem provers, as well as infinite-state systems.", "num_citations": "6\n", "authors": ["1612"]}
{"title": "Applicability of fair simulation\n", "abstract": " In this paper we compare among four notions of fair simulation: direct [6], delay [7], game [10], and exists [9]. Our comparison refers to three main aspects: The time complexity of constructing the fair simulation, the ability to use it for minimization, and the relationship between the fair simulations and universal branching-time logics.               Based on our comparison we derive several practical implications: We develop an efficient approximated minimization algorithm for the direct/delay simulations. In addition, we suggest a new implementation for the assume-guarantee modular framework presented in [9]. The new implementation, significantly improves the complexity of the framework.", "num_citations": "6\n", "authors": ["1612"]}
{"title": "Analyzing internet routing security using model checking\n", "abstract": " The goal of this work is to enhance Internet security by applying formal analysis of traffic attraction attacks on the BGP routing protocol. BGP is the sole protocol used throughout the Internet for inter-domain routing, hence its importance. In attraction attacks an attacker sends false routing advertisements to gain attraction of extra traffic in order to increase its revenue from customers, drop, tamper, or snoop on the packets. Such attacks are most common on the inter-domain routing.               We use model checking to perform exhaustive search for attraction attacks on BGP. This requires substantial reductions due to scalability issues of the entire Internet topology. Therefore, we propose static methods to identify and automatically reduce Internet fragments of interest, prior to using model checking.               We developed a method, called BGP-SA, for BGP Security Analysis, which extracts and reduces fragments\u00a0\u2026", "num_citations": "5\n", "authors": ["1612"]}
{"title": "Hybrid bdd and all-sat method for model checking\n", "abstract": " We present a new hybrid BDD and SAT-based algorithm for model checking. Our algorithm is based on backward search, where each pre-image computation consists of an efficient All-SAT procedure. The All-SAT procedure exploits a graph representation of the model to dynamically prune the search space, thus preventing unnecessary search in large sub-spaces, and for identifying independent sub-problems. Apart from the SAT mechanisms, BDD structures are used for storing the input to, and output of the pre-image computation. In this way, our hybrid approach enjoys the benefits of both worlds: on the one hand, basing the pre-image computation on SAT technology avoids expensive BDD quantification operations and the corresponding state space blow up. On the other hand, our model checking framework still enjoys the advantages of symbolic space reduction in holding intermediate images\u00a0\u2026", "num_citations": "5\n", "authors": ["1612"]}
{"title": "Verifying very large industrial circuits using 100 processes and beyond\n", "abstract": " Recent advances in scheduling and networking have cleared the way for efficient exploitation of large-scale distributed computing platforms, such as computational grids and huge clusters. Such infrastructures hold great promise for the highly resource-demanding task of verifying and checking large models, given that model checkers would be designed with a high degree of scalability and flexibility in mind.               In this paper we focus on the mechanisms required to execute a high-performance, distributed, symbolic model checker on top of a large-scale distributed environment. We develop a hybrid algorithm for slicing the state space and dynamically distribute the work among the worker processes. We show that the new approach is faster, more effective, and thus much more scalable than previous slicing algorithms. We then present a checkpoint-restart module that has very low overhead. This module\u00a0\u2026", "num_citations": "5\n", "authors": ["1612"]}
{"title": "Formal black-box analysis of routing protocol implementations\n", "abstract": " The Internet infrastructure relies entirely on open standards for its routing protocols. However, the majority of routers on the Internet are closed-source. Hence, there is no straightforward way to analyze them. Specifically, one cannot easily identify deviations of a router's routing functionality from the routing protocol's standard. Such deviations (either deliberate or inadvertent) are particularly important to identify since they may degrade the security or resiliency of the network. A model-based testing procedure is a technique that allows to systematically generate tests based on a model of the system to be tested; thereby finding deviations in the system compared to the model. However, applying such an approach to a complex multi-party routing protocol requires a prohibitively high number of tests to cover the desired functionality. We propose efficient and practical optimizations to the model-based testing procedure that are tailored to the analysis of routing protocols. These optimizations allow to devise a formal black-box method to unearth deviations in closed-source routing protocols' implementations. The method relies only on the ability to test the targeted protocol implementation and observe its output. Identification of the deviations is fully automatic. We evaluate our method against one of the complex and widely used routing protocols on the Internet -- OSPF. We search for deviations in the OSPF implementation of Cisco. Our evaluation identified numerous significant deviations that can be abused to compromise the security of a network. The deviations were confirmed by Cisco. We further employed our method to analyze the OSPF\u00a0\u2026", "num_citations": "4\n", "authors": ["1612"]}
{"title": "A framework for compositional verification of multi-valued systems via abstraction-refinement\n", "abstract": " We present a framework for fully automated compositional verification of \u03bc-calculus specifications over multi-valued systems, based on abstraction and refinement.In a multi-valued model of a system, both the system transitions and the state labels are assigned values from a lattice. We formalize our framework based on bilattices, consisting of a truth lattice and an information lattice. Formulas are interpreted on the truth lattice. The information lattice determines how definite the value is, in terms of the concrete system being modeled.Our compositional approach views each component as an abstraction of the entire system and checks it separately. Only if all individual checks return indefinite values, the parts of the components which are responsible for these values, are composed and checked. If the latter check is still indefinite, a refinement of the multi-valued system is needed. Refinement is aimed at increasing the\u00a0\u2026", "num_citations": "4\n", "authors": ["1612"]}
{"title": "Verifying very large industrial circuits using 100 processes and beyond\n", "abstract": " Recent advances in scheduling and networking have paved the way for efficient exploitation of large-scale distributed computing platforms such as computational grids and huge clusters. Such infrastructures hold great promise for the highly resource-demanding task of verifying and checking large models, given that model checkers would be designed with a high degree of scalability and flexibility in mind.         In this paper we focus on the mechanisms required to execute a high-performance, distributed, symbolic model checker on top of a large-scale distributed environment. We develop a hybrid algorithm for slicing the state space and dynamically distribute the work among the worker processes. We show that the new approach is faster, more effective, and thus much more scalable than previous slicing algorithms. We then present a checkpoint-restart module that has very low overhead. This module can be used\u00a0\u2026", "num_citations": "4\n", "authors": ["1612"]}
{"title": "Automated Technology for Verification and Analysis: Third International Symposium, ATVA 2005, Taipei, Taiwan, October 4-7, 2005, Proceedings\n", "abstract": " The Automated Technology for Veri? cation and Analysis (ATVA) international symposium series was initiated in 2003, responding to a growing interest in formal veri? cation spurred by the booming IT industry, particularly hardware design and manufacturing in East Asia. Its purpose is to promote research on automated veri? cation and analysis in the region by providing a forum for int-action between the regional and the international research/industrial commu-ties of the? eld. ATVA 2005, the third of the ATVA series, was held in Taipei, Taiwan, October 4\u20137, 2005. The main theme of the symposium encompasses-sign, complexities, tools, and applications of automated methods for veri? cation and analysis. The symposium was co-located and had a two-day overlap with FORTE 2005, which was held October 2\u20135, 2005. We received a total of 95 submissions from 17 countries. Each submission was assigned to three Program Committee members, who were helped by their subreviewers, for rigorous and fair evaluation. The? nal deliberation by the P-gram Committee was conducted over email for a duration of about 10 days after nearly all review reports had been collected. In the end, 33 papers were-lectedforinclusionintheprogram. ATVA2005hadthreekeynotespeechesgiven respectively by Amir Pnueli (joint with FORTE 2005), Zohar Manna, and Wo-gang Thomas. The main symposium was preceded by a tutorial day, consisting of three two-hour lectures given also by the keynote speakers.", "num_citations": "4\n", "authors": ["1612"]}
{"title": "A complete rule for equifair termination\n", "abstract": " The notion of equifairness, strengthening the familiar notion of fairness, is introduced as a scheduling policy of nondeterminism and concurrency. Under this notion, it is infinitely often the case that the number of selections of each of a family of infinitely often jointly enabled processes is equal. A proof rule for proving equifair termination is introduced and proved to be semantically complete.", "num_citations": "4\n", "authors": ["1612"]}
{"title": "Model Checking Techniques for Behavioral UML Models\n", "abstract": " The Unified Modeling Language (UML) is a widely accepted modeling language for embedded and safety critical systems. As such the correct behavior of systems represented as UML models is crucial. Model checking is a successful automated verification technique for checking whether a system satisfies a desired property. In this thesis, we present several approaches to enhancing model checking to behavioral UML systems.The applicability of model checking is often impeded by its high time and memory requirements. The first approach we propose aim at avoiding this limitation by adopting software model checking techniques for verification of UML models. We translate UML to verifiable C code which preserves the high level structure of the models, and abstracts details that are not needed for verification. We combine static analysis and bounded model checking for verifying LTL safety properties and absence of livelocks. We implemented our approach on top of the bounded software model checker CBMC. We compared it to an IBM research tool that verifies UML models via a translation to IBM\u2019s hardware model checker RuleBasePE. Our experiments show that our approach is more scalable and more robust for finding long counterexamples. We also demonstrate the usefulness of several optimizations that we introduced into our tool.", "num_citations": "3\n", "authors": ["1612"]}
{"title": "Learning-based compositional model checking of behavioral UML systems\n", "abstract": " This work presents a novel approach for applying compositional model checking of behavioral UML models, based on learning. The Unified Modeling Language (UML) is a widely accepted modeling language for embedded and safety critical systems. As such the correct behavior of systems represented as UML models is crucial. Model checking is a successful automated verification technique for checking whether a system satisfies a desired property. However, its applicability is often impeded by its high time and memory requirements. A successful approach to tackle this limitation is compositional model checking. Recently, great advancements have been made in this direction via automatic learning-based Assume-Guarantee reasoning.               In this work we propose a framework for automatic Assume-Guarantee reasoning for behavioral UML systems. We apply an off-the-shelf learning algorithm for\u00a0\u2026", "num_citations": "3\n", "authors": ["1612"]}
{"title": "Abstraction-Refinement and Modularity in mu-Calculus Model Checking\n", "abstract": " Model checking is an automated technique for checking whether or not a given system model fulfills a desired property, described as a temporal logic formula. Yet, as real models tend to be very big, model checking encounters the state-explosion problem, which refers to its high space requirements. Two of the most successful approaches to fighting the state-explosion problem in model checking are abstraction and compositional model checking. Abstractions hide certain details of the system in order to result in a smaller model. In some cases the abstraction is too coarse, resulting in an inconclusive model checking result. Thus, the abstract model is refined by adding more details into it, making it more similar to the concrete model. Iterating this process is called abstraction-refinement. In compositional model checking, on the other hand, one tries to verify parts of the system separately in order to avoid the construction of the entire system.In this research, we investigate abstraction-refinement and compositional techniques for specifications in the mu-calculus, which is a powerful formalism for expressing properties of transition systems using fixpoint operators. Our work exploits and extends the game-based approach to mu-calculus model checking, in which the model checking problem is formulated as a game between a verifier and a falsifier. We develop novel abstraction-refinement schemes for the mu-calculus, based on a 3-valued semantics. The 3-valued semantics allows an abstract model to be used for verification as well as falsification, unlike traditional abstraction which is only used for verification. We investigate both the efficiency and the\u00a0\u2026", "num_citations": "3\n", "authors": ["1612"]}
{"title": "Bounded model-checking for branching-time logic\n", "abstract": " The model-checking problem is the problem of determining, given a design and a specification, whether the design satisfies the specification or not. Model-checking is computationally difficult because of the state-space explosion problem: the number of states in the design increases exponentially with the number of variables. One method that has gained industrial acceptance due to its ability to handle large designs is bounded model-checking (BMC), a technique for finding bugs with respect to a given specification through the use of a SAT solver.BMC is typically applied only to the class of linear-time specifications, which talk about distinct computations of the program. However, many interesting properties cannot be expressed in linear-time logic, and require branching-time logic, which talks about the computation tree of the program. Previous attempts to extend the BMC approach to universal branching-time logic have searched for a counter-example with a pre-determined shape: the edges of the counter-example were selected based on worst-case analysis of the specification, and the SAT solver only had to assign the states. We suggest a new approach, in which we allow the SAT solver to choose both the states and the edges of the counter-example. This significantly reduces the size of the counter-example produced by BMC, and allows us to handle more complex specifications. We also present a dynamic completeness criterion which can be used to halt the bounded model-checking when it becomes clear that no counter-example to the specification can exist in the model. Thus, in addition to finding bugs (if they exist), our technique can\u00a0\u2026", "num_citations": "3\n", "authors": ["1612"]}
{"title": "Checking for fair simulation in models with Buchi fairness constraints\n", "abstract": " Many approaches to overcoming the problem of high space requirements in model checking are based on the {\\em simulation preorder}. This preorder relates the system model to some reduced model, provided that the reduced model contains all the behaviors of the system model. Reduction techniques often add unrealistic behaviors to the reduced model. Fairness constraints can then be added to exclude these behaviors from consideration during verification. The simulation preorder, in its original form, does not handle fairness constraints.{\\em Fair simulation preorders} that extend the simulation preorder by referring only to the fair behaviors of the models are therefore desirable. A definition of fair simulation was introduced in\\cite {FairSim}. The definition is accompanied by an algorithm for checking fair simulation in models with fairness constraints. In this work we suggest an improved algorithm for computing the fair simulation preorder. Our algorithm is significantly simpler than the one in\\cite {FairSim} and therefore can be easily implemented. It has the same time complexity as the previous algorithm, and a better space complexity. Furthermore, it provides a counterexample in case the reduced model does not contain all the fair behaviors of the system model. Our algorithm is based on a game characterization of the fair simulation preorder. It works in time complexity of  and space complexity of , where  is the product of the model sizes.", "num_citations": "3\n", "authors": ["1612"]}
{"title": "Program composition via unification\n", "abstract": " Program composition and compositional proof systems have proven themselves important for simplifying the design and the verification of programs. The paper extends work presented in ICALP'91 and presents a version of the jigsaw program composition operator previously defined in [FFG90, FFG91]. Here, the jigsaw operator is defined as the unification of its components by their most general unifier. The jigsaw operator generalizes and unifies the traditional sequential and parallel program composition operators and the newly proposed union and superposition operators. We consider a family of frameworks each consisting of a programming language, a specification language and a compositional syntax-directed proof system. We present syntactic rules to augment any given framework in the family with the jigsaw operator. The augmented framework is syntax-directed and compositional. Moreover, it is\u00a0\u2026", "num_citations": "3\n", "authors": ["1612"]}
{"title": "Checking and Abstraction\n", "abstract": " We describe a method for using abstraction to reduce the complexity of temporal logic model checking. The basis of this method is a way of constructing an abstract model of a program without ever examining the corresponding unabstracted model. We show how this abstract model can be used to verify properties of the original program. We have implemented a system based on these techniques, and we demonstrate their practicality using a number of examples, including a pipelined ALU circuit with over 101300 states.", "num_citations": "3\n", "authors": ["1612"]}
{"title": "A complete proof rule for strong equifair termination\n", "abstract": " The notion of equifairness, strengthening the familiar notion of fairness, is introduced as a scheduling policy of non-determinism and concurrency. Under this notion, it is infinitely often the case that the number of selections of each of a family of infinitely-often jointly-enabled processes is equal. A proof rule for proving strong equifair-termination is introduced, applied to examples and shown to be (semantically) complete.", "num_citations": "3\n", "authors": ["1612"]}
{"title": "Learning-Based Compositional Model Checking of Behavioral UML Systems.\n", "abstract": " This work presents a novel approach for applying compositional model checking of behavioral UML models, based on learning. The Unified Modeling Language (UML) is a widely accepted modeling language for embedded and safety critical systems. As such the correct behavior of systems represented as UML models is crucial. Model checking is a successful automated verification technique for checking whether a system satisfies a desired property. However, its applicability is often impeded by its high time and memory requirements. A successful approach to tackle this limitation is compositional model checking. Recently, great advancements have been made in this direction via automatic learning-based Assume-Guarantee reasoning.In this work we propose a framework for automatic Assume-Guarantee reasoning for behavioral UML systems. We apply an off-the-shelf learning algorithm for incrementally generating environment assumptions that guarantee satisfaction of the property. A unique feature of our approach is that the generated assumptions are UML state machines. Moreover, our Teacher works at the UML level: all queries from the learning algorithm are answered by generating and verifying behavioral UML systems.", "num_citations": "2\n", "authors": ["1612"]}
{"title": "Sat-based model checking: Interpolation, ic3, and beyond\n", "abstract": " SAT-based model checking is currently one of the most successful approaches to checking very large systems. In its early days, SAT-based (bounded) model checking was mainly used for bug hunting. The introduction of interpolation and IC3\\PDR enable efficient complete algorithms that can provide full verification as well.", "num_citations": "2\n", "authors": ["1612"]}
{"title": "Learning to order BDD variables in verification\n", "abstract": " The size and complexity of software and hardware systems have significantly increased in the past years. As a result, it is harder to guarantee their correct behavior. One of the most successful methods for automated verification of finite-state systems is model checking. Most of the current model-checking systems use binary decision diagrams (BDDs) for the representation of the tested model and in the verification process of its properties. Generally, BDDs allow a canonical compact representation of a boolean function (given an order of its variables). The more compact the BDD is, the better performance one gets from the verifier. However, finding an optimal order for a BDD is an NP-complete problem. Therefore, several heuristic methods based on expert knowledge have been developed for variable ordering. We propose an alternative approach in which the variable ordering algorithm gains' ordering experience\u00a0\u2026", "num_citations": "2\n", "authors": ["1612"]}
{"title": "Automated and interactive theorem proving\n", "abstract": " The idea of mechanizing reasoning is an old dream that can be traced at least back to Leibniz. Since about 1950, there has been considerable research on having computers perform logical reasoning, either completely autonomously (automated theorem proving) or in cooperation with a person (interactive theorem proving). Both approaches have achieved notable successes. For example, several open mathematical problems such as the Robbins Conjecture have been settled by automated theorem provers, while interactive provers have been applied to formalization of non-trivial mathematics and the verification of complex computer systems. However, it can be difficult for a newcomer to gain perspective on the field, since it has already fragmented into various special subdisciplines. The aim of these lectures will be to give a broad overview that tries to establish some such perspective. I will cover a range of topics from Boolean satisfiability checking (SAT), several approaches to first-order automated theorem proving, special methods for equations, decision procedures for important special theories, and interactive proof. I will not say much in detail about applications, but will give some suitable references for those interested.", "num_citations": "2\n", "authors": ["1612"]}
{"title": "Formal Logical Methods for System Security and Correctness\n", "abstract": " Offers information in the field of proof technology in connection with secure and correct software. This title shows that methods of correct-by-construction program and process synthesis allow a high level programming method more amenable to security and reliability analysis and guarantees.", "num_citations": "2\n", "authors": ["1612"]}
{"title": "Test sequence generation and model checking using dynamic transition relations\n", "abstract": " The task of finding a set of test sequences that provides good coverage of industrial circuits is infeasible because of the size of the circuits. For small critical subcircuits of the design, however, designers can create a set of test sequences that achieve good coverage. These sequences cannot be used on the full design because the inputs to the subcircuit may not be accessible. In this work we present an efficient test generation algorithm that receives a test sequence created for the subcircuit and finds a test sequence for the full design that reproduces the given sequence on the subcircuit. The algorithm uses a new technique called dynamic transition relations to increase its efficiency  .               The most common and most expensive step in our algorithm is the computation of the set of predecessors of a set of states. To make this computation more efficient we exploit a partitioning of the transition relation into a\u00a0\u2026", "num_citations": "2\n", "authors": ["1612"]}
{"title": "Which Branching\u2010Time Properties are Effectively Linear?\n", "abstract": " We characterize three successively more restrictive classes of \u2018effectively linear\u2019 CTL* formulas, with and without fairness: the equi\u2010linear formulas, which do not distinguish among models with the same language, the sub\u2010linear formulas, which are preserved under model language inclusion and the strong linear formulas, which are characterized by a given \u03c9\u2010regular language. Moreover, strong linearity characterizes those CTL* formulas equivalent to LTL formulas. This taxonomy helps to clarify the expressive distinctions between CTL*, LTL and \u03c9\u2010regular languages. It has also practical implications. Verification tools based on language inclusion can handle any CTL* formula which is equi\u2010linear, for purposes of model checking, and sub\u2010linear for purposes of abstraction. Furthermore, minimization techniques that preserve the subset of CTL* which consists of only effectively linear formulas, result in smaller\u00a0\u2026", "num_citations": "2\n", "authors": ["1612"]}
{"title": "Static analysis for state-space reductions preserving temporal logics\n", "abstract": " In this paper we present two methods that use static analysis of parallel programs to create reduced models for them. Our algorithms examine the control-flow graph of a program (the syntax) and create a smaller transition system than would have been created otherwise. The smaller transition system is equivalent to the original transition system of the program with respect to temporal logic specifications. The two methods are orthogonal in their approach. The first, called {\\em path reduction}, reduces the state-space by compressing computation paths. This method reduces the number of steps each computation takes. The second method, called {\\em dead variable reduction}, reduces according to the variable domains. It identifies classes of equivalent states which differ only on variable values (and not the program counter) and uses a representative for each class. Our target is not only to be able to reduce according to both approaches, but also to find out which approach is more useful. Our algorithms are based on syntactic manipulation of expressions, thus enabling us to handle programs with variables over finite as well as infinite domains. Both methods can easily be combined with either explicit state or symbolic methods (and with each other). We used the Murphi verifier to test the amount of reduction achieved by both methods. We let Murphi perform a DFS search and compared the sizes of the original and reduced transition systems, for several examples and according to both reductions. The results show that path reduction gives significant reductions, while the effects of dead-variable reduction are less impressive. We discuss the\u00a0\u2026", "num_citations": "2\n", "authors": ["1612"]}
{"title": "Logic for Computer Science\n", "abstract": " Paper submission: Send 12 copies of an extended abstract (not a full paper) to the program chair to be received by December 13, 1995. This deadline is firm; late submissions will not be considered. Authors without access to copiers may submit a single copy. Authors will be notified of acceptance or rejection by March 7, 1996. Accepted papers in a specified format for the proceedings will be due May 7, 1996.", "num_citations": "2\n", "authors": ["1612"]}
{"title": "Applying machine learning for identifying attacks at run-time\n", "abstract": " With the increase in malicious activity over the Internet, it has become extremely important to build tools for automatic detection of such activity. There have been attempts to use machine learning to detect network attacks, but the difficulty in obtaining positive (attack) examples, led to using one-class methods for anomaly detection. In this work we present a novel framework for using multi-class learning to induce a real-time attack detector. We designed a network simulator that is used to produce network activity. The simulator includes an attacker that stochastically violates the normal activity, yielding positive as well as negative examples. We have also designed a set of features that withstand changes in the network topology. Given the set of tagged feature vectors, we can then apply a learning algorithm to produce a multi-class attack detector. In addition, our framework allows the user to define a cost matrix for specifying the cost for each type of detection error. Our framework was tested in a wide variety of network topologies and succeeded to detect attacks with a high accuracy. We have also shown that our system is capable of handling a transfer learning setup, where the detector is learned on one network topology but is used on another topology from the same family. Another setup we tested is dynamic networks in which changes take place in the topologies. Finally, we also referred to choosing the router (s) which should be chosen to record the traffic and transfer this information to the detector, in order to achieve high performances.% hat will act as monitor (s) and predict the tag of the run (normal, attacked, etc...). We anticipate the presented\u00a0\u2026", "num_citations": "1\n", "authors": ["1612"]}
{"title": "Multi-Valued Abstraction and Compositional Model Checking\n", "abstract": " We present a framework for fully automated compositional verification of mu-calculus specifications over multi-valued systems, based on multi-valued abstraction and refinement.Multi-valued models are widely used in many applications of model checking. They enable a more precise modeling of systems by distinguishing several levels of uncertainty and inconsistency. Successful verification tools such as STE (for hardware) and YASM (for software) are based on multi-valued models.", "num_citations": "1\n", "authors": ["1612"]}
{"title": "Languages: From Formal to Natural: Essays Dedicated to Nissim Francez on the Occasion of His 65th Birthday\n", "abstract": " The symposium \u201cLanguages: From Formal to Natural,\u201d celebrating the 65th birthday of Nissim Francez, was held on May 24\u201325, 2009 at the Technion, Haifa. The symposium consisted of two parts, a verification day and a language day, and covered all areas of Nissim\u2019s past and present research interests, areas which he has inspiringly influenced and to which he has contributed so much. This volume comprises several papers presented at the symposium, as well as additional articles that were contributed by Nissim\u2019s friends and colleagues who were unable to attend the event. We thank the authors for their contributions. We are also grateful to the reviewers for their dedicated and timely work. Nissim Francez was born on January 19, 1944. In 1962 he started his mathematical education at the Hebrew University. He received a BSc in Mathematics in 1965, and, after four years of military service, started his MSc\u00a0\u2026", "num_citations": "1\n", "authors": ["1612"]}
{"title": "Hybrid BDD and All-SAT Method for Model Chcking and Other Applications\n", "abstract": " We present a new hybrid BDD and SAT-based algorithm for model checking. Our algorithm is based on backward search, where each pre-image computation consists of an efficient All-SAT procedure. The All-SAT procedure exploits a graph representation of the model to dynamically prune the search space, thus preventing unnecessary search in large sub-spaces, and for identifying independent sub-problems. Apart from the SAT mechanisms, BDD structures are used for storing the input to, and output of the pre-image computation. In this way, our hybrid approach enjoys the benefits of both worlds: on the one hand, basing the pre-image computation on SAT technology avoids expensive BDD quantification operations and the corresponding state space blow up. On the other hand, our model checking framework still enjoys the advantages of symbolic space reduction in holding intermediate images. Furthermore, our All-SAT analyzes the model and avoids redundant exploration of sub-spaces that are completely full with solutions, paying in these cases for the instantiation of a single assignment only.", "num_citations": "1\n", "authors": ["1612"]}
{"title": "Modular minimization of finite state machines\n", "abstract": " This work presents a modular technique for minimizing a nitestate machine (FSM) while preserving its equivalence to the original system. Being modular, the minimization technique should consume less time and space. Preserving equivalence, the resulting minimized model can be employed in both temporal logic model checking and sequential equivalence checking, thus reducing their time and space consumption.Most systems have a natural modular structure, and we suggest using this structure in the minimization of their model. The complexity of minimizing a single module can be exponentially smaller than that of minimizing the entire system.(The actual reduction in complexity depends on the module connectivity to the other parts of the system.) Thus the method has great potential. This modular algorithm has been implemented on an Intel system in Intel Haifa, and it has been tested on real hardware designs.", "num_citations": "1\n", "authors": ["1612"]}
{"title": "Syntax-directed model checking of sequential programs\n", "abstract": " This work presents a syntax-directed, modular approach to temporal logic model checking of sequential programs.In contrast to hardware designs, the models of software systems might be too large to fit into memory even when they consist of a single sequential unit. Furthermore, even when the model can be held in memory, model checking might exceed the memory capacity of the computer. To avoid the high space requirements for software we therefore suggest to partition the text of a sequential program into sequentially composed sub-programs. Based on this partition, we present a model-checking algorithm for sequential programs that arrives at its conclusion by examining each sub-program in separation. The novelty of our approach is that it uses a decomposition of the program in which the interconnection between parts is sequential and not parallel. We handle each part separately, while keeping all other\u00a0\u2026", "num_citations": "1\n", "authors": ["1612"]}
{"title": "Faithful Translations Among Models and Specifications in VeriTech\n", "abstract": " Numerous translations exist between the design notations of formal methods tools, usually between two speci c notations. VeriTech is a general framework for translating among formal veri cation tools. The notation of each component tool is translated to a core representation, and the core is translated to each component. For any translation it is important that the translation preserves a similar modular structure of the notations for expressing models. Even more importantly, and sometimes in con ict with the rst goal, it is vital that the properties true of the semantic interpretations of the source and the translated notations are closely related.The core design language CDL is described as a collection of transitions organized into modules that encourages maintaining modular structure. Key issues in translating among models with inconsistent features are described, leading to models that are closely related, but do not always preserve either the structure or the correctness of properties in a simple way. The concept is presented of a faithful relation among models and families of properties true of those models. In this framework families of properties are provided with uniform transformations, in addition to the translations of the models. This framework is shown appropriate for common instances of relations among translations previously treated in an ad hoc way. Furthermore, it allows expressing connections among models where one is neither a re nement nor an abstraction of the other.", "num_citations": "1\n", "authors": ["1612"]}
{"title": "Infinite trees, markings and well foundedness\n", "abstract": " A necessary and sufficient condition for a given marked tree to have no infinite paths satisfying a given formula is presented. The formulas are taken from a language introduced by Harel, covering a wide scale of properties of infinite paths, including most of the known notions of fairness. This condition underlies a proof rule for proving that a nondeterministic program has no infinite computations satisfying a given formula, interpreted over state sequences. We also show two different forms of seemingly more natural necessary and sufficient conditions to be inadequate.", "num_citations": "1\n", "authors": ["1612"]}