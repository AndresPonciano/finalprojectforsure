{"title": "Semantics with applications\n", "abstract": " This book is written out of a tradition that places special emphasis on the following three approaches to semantics:\u2013operational semantics,\u2013denotational semantics, and\u2013axiomatic semantics.It is therefore beyond the scope of this introductory book to cover other approaches such as algebraic semantics, game semantics, and evolving algebras. We strongly believe that semantics has an important role to play in the future development of software systems and domain-specific languages (and hence is not confined to the enormous task of specifying \u201creal life\u201d languages such as C++, Java or C#). We have therefore found the need for an introductory book that", "num_citations": "936\n", "authors": ["1602"]}
{"title": "Abstract interpretation: a semantics-based tool for program analysis\n", "abstract": " Desirable mathematical background for this chapter includes o basic concepts such as lattices, complete partial orders, homomorphisms, etc. o the elements of domain theory, eg as in the chapter by Abramsky or the books| Schmidt, 1986] or| Nielson, 1992a]. o the elements of denotational semantics, eg as in the chapter by Tennent or the books| Schmidt, 1986] or| Nielson, 1992a]. o interpretations as used in logic.There will be some use of structural operational semantics| Kahn, 1987],| Plotkin, 1981|,| Nielson, 1992a], for example deduction rules for a program's semantics and type system. The use of category theory will be kept to a minimum but would be a useful background for the domain-related parts of Section 3.", "num_citations": "267\n", "authors": ["1602"]}
{"title": "Two-level functional languages\n", "abstract": " One of the characteristics of the functional programming style is the use of higher-order functions. This two-edged sword facilitates the reuse of function definitions and their properties, while reducing implementation efficiency. Efficient implementation of functional languages has been sought for a long time, and many techniques have been developed to improve the overall performance of naive implementations. Most of the techniques do not establish the theoretical soundness of the implementation, however. The main aim of the work presented in this book is to address the efficient implementation problem while ensuring that the development is provably correct. One reason for poor implementation efficiency is that, when generating code for a higher-order function, it is impossible to make any assumption about its arguments and optimize the code accordingly. The authors observe that a higher-order function is a\u00a0\u2026", "num_citations": "247\n", "authors": ["1602"]}
{"title": "Static validation of security protocols\n", "abstract": " We methodically expand protocol narrations into terms of a process algebra in order to specify some of the checks that need to be made in a protocol. We then apply static analysis technology to develop an automatic validation procedure for protocols. Finally, we demonstrate that these techniques suffice to identify several authentication flaws in symmetric and asymmetric key protocols such as Needham\u2013Schroeder symmetric key, Otway\u2013Rees, Yahalom, Andrew Secure RPC, Needham\u2013Schroeder asymmetric key, and Beller\u2013Chang\u2013Yacobi MSR.", "num_citations": "173\n", "authors": ["1602"]}
{"title": "Higher-order concurrent programs with finite communication topology\n", "abstract": " Concurrent ML (CML) is an extension of the functional language Standard ML (SML) with primitives for the dynamic creation of processes and channels and for the communication of values over channels. Because of the powerful abstraction mechanisms the communication topology of a given program may be very complex and therefore an efficient implementation may be facilitated by knowledge of the topology.", "num_citations": "170\n", "authors": ["1602"]}
{"title": "Infinitary control flow analysis: a collecting semantics for closure analysis\n", "abstract": " Defining the collecting semantics is usually the first crucial step in adapting the general methodology of abstract interpretation to the semantic framework or programming language at hand. In this paper we show how to define a collecting semantics for control flow analysis: due to the generality of the formulation we need to appeal to coinduction (or greatest fixed points) in order to define the analysis. We then prove the semantic soundness of the collecting semantics and that all totally deterministic instantiations have a least solution; this incorporates k-CFA, polymorphic splitting and a new class of uniform-k-CFA analyses.", "num_citations": "162\n", "authors": ["1602"]}
{"title": "Automatic validation of protocol narration\n", "abstract": " We perform a systematic expansion of protocol narrations into terms of process algebra in order to make precise some of the detailed checks that need to be made in a protocol. We then apply static analysis technology to develop an automatic validation procedure for protocols. Finally, we demonstrate that these techniques suffice for identifying a number of authentication flaws in symmetric key protocols such as Needham-Schroeder, Otway-Rees, Yahalom and Andrew Secure RPC.", "num_citations": "140\n", "authors": ["1602"]}
{"title": "Static analysis for the \u03c0-calculus with applications to security\n", "abstract": " Control Flow Analysis is a static technique for predicting safe and computable approximations to the set of values that the objects of a program may assume during its execution. We present an analysis for the \u03c0-calculus that shows how names will be bound to actual channels at run time. The result of our analysis establishes a super-set of the set of channels to which a given name may be bound and of the set of channels that may be sent along a given channel. Besides a set of rules that permits one to validate a given solution, we also offer a constructive procedure that builds solutions in low polynomial time. Applications of our analysis include establishing two simple security properties of processes. One example is that P has no leaks: P offers communication to the external environment through public channels only and confines its secret channels within itself. The other example is connected to the no read-up/no\u00a0\u2026", "num_citations": "123\n", "authors": ["1602"]}
{"title": "Control flow analysis for the \u03c0-calculus\n", "abstract": " Control Flow Analysis is a static technique for predicting safe and computable approximations to the set of values that the objects of a program may assume during its execution. We present an analysis for the \u03c0-calculus that shows how names will be bound to actual channels at run time. The formulation of the analysis requires no extensions to the \u03c0-calculus, except for assigning \u201cchannels\u201d to the occurrences of names within restrictions, and assigning \u201cbinders\u201d to the occurrences of names within input prefixes.             The result of our analysis establishes a super-set of the set of names to which a given name may be bound and of the set of names that may be sent along a given channel. Applications of our analysis include establishing simple security properties of processes. One example is that P has no leaks, i.e. P offers communication through public channels only, and confines its secret names within itself.", "num_citations": "122\n", "authors": ["1602"]}
{"title": "Automatic binding time analysis for a typed \u03bb-calculus\n", "abstract": " A binding time analysis imposes a distinction between the computations to be performed early (e.g. at compile-time) and those to be performed late (e.g. at run-time). For the \u03bb-calculus this distinction is formalized by a two-level \u03bb-calculus. We present an algorithm for static analysis of the binding times of a typed \u03bb-calculus with products, sums, lists and general recursive types. Given partial information about the binding times of some of the subexpressions it will complete that information such that (i) early bindings may be turned into late bindings but not vice versa, (ii) the resulting two-level \u03bb-expression reflects our intuition about binding times, e.g. that early bindings are performed before late bindings, and (iii) as few changes as possible have been made compared with the initial binding information. The results can be applied in the implementation of functional languages and in semantics directed compiling.", "num_citations": "120\n", "authors": ["1602"]}
{"title": "Flow Logic: a multi-paradigmatic approach to static analysis\n", "abstract": " Flow logic is an approach to static analysis that separates the specification of when an analysis estimate is acceptable for a program from the actual computation of the analysis information. It allows one not only to combine a variety of programming paradigms but also to link up with state-of-the-art developments in classical approaches to static analysis, in particular data flow analysis, constraint-based analysis and abstract interpretation. This paper gives a tutorial on flow logic and explains the underlying methodology; the multi-paradigmatic approach is illustrated by a number of examples including functional, imperative, object-oriented and concurrent constructs.", "num_citations": "112\n", "authors": ["1602"]}
{"title": "A denotational framework for data flow analysis\n", "abstract": " It is shown how to express data flow analysis in a denotational framework by means of abstract interpretation. A continuation style formulation naturally leads to the MOP (Meet Over all Paths) solution, whereas a direct style formulation leads to the MFP (Maximal Fixed Point) solution.", "num_citations": "112\n", "authors": ["1602"]}
{"title": "Two-level semantics and abstract interpretation\n", "abstract": " Two-level semantics is a variant of Scott/Strachey denotational semantics in which the concept of binding time is treated explicitly. This is done by formally distinguishing between those computations that take place at run-time and those that take place at compile-time.Abstract interpretation is concerned with the (preferably automatic) analysis of programs. The main purpose of these analyses is to find information that may assist in the efficient implementation of the programs. Abstract interpretation is thus related to data flow analysis, partial evaluation and other program analysis methods. Its unique flavour is the insistence on formal proofs of correctness and the methods used to establish these.This paper develops a theory of abstract interpretation for two-level denotational definitions. There are three ingredients in this. First a framework for proving the correctness of analyses is developed. This may also be used to\u00a0\u2026", "num_citations": "106\n", "authors": ["1602"]}
{"title": "Validating firewalls in mobile ambients\n", "abstract": " The ambient calculus is a calculus of computation that allows active processes (mobile ambients) to move between sites. A firewall is said to be protective whenever it denies entry to attackers not possessing the required passwords. We devise a polynomial time algorithm for rejecting proposed firewalls that are not guaranteed to be protective. This is based on a control flow analysis for recording what processes may turn up inside what other processes; in particular, we develop a syntaxdirected system for specifying the acceptability of an analysis, we prove that all acceptable analyses are semantically sound, and we demonstrate that each process admits a least analysis.", "num_citations": "100\n", "authors": ["1602"]}
{"title": "Type and effect systems: behaviours for concurrency\n", "abstract": " Concurrent and distributed processes occur everywhere: in embedded systems, in information networks and databases, and in the form of applets roaming around on the World-Wide-Web. This book presents and develops state-of-the-art validation techniques for detecting safety violations; the focus is on the correctness of techniques that suffice for fully automatic validation of key components of such systems. It builds on and extends the notion of types, popular in many sequential programming languages as a technique for catching certain kinds of errors already at program development time, by incorporating behaviours (or structured effects) that are able to track the information flow in the presence of procedures, channel based communication, and the dynamic creation of network topologies. The technical development is performed for a language based on Concurrent ML.", "num_citations": "95\n", "authors": ["1602"]}
{"title": "A Succinct Solver for ALFP.\n", "abstract": " We develop a solver algorithm which allows to efficiently compute the stable model of a very expressive fragment of predicate logic. The succinct formulation of the algorithm is due to the disciplined use of continuations and memoisation. This facilitates giving a precise characterisation of the behaviour of the solver and to develop a complexity calculation which allows to obtain its formal complexity. Practical experiments on a control-flow analysis of the ambient calculus show that the solver frequently performs better than the worst-case complexity estimates.", "num_citations": "92\n", "authors": ["1602"]}
{"title": "From CML to process algebras\n", "abstract": " Reppy's language CML extends Standard ML of Milner et al. with primitives for communication. It thus inherits a notion of strong polymorphic typing and may be equipped with a structural operational semantics. As a first step we formulate an effect system for statically expressing the communication behaviours of CML programs as these are not reflected in the types. As a second step we adapt the structural operational semantics of CML so as to incorporate behaviours. We then show how types and behaviours evolve in the course of computation: types may decrease and behaviours may loose alternatives as well as decrease. As the syntax of behaviours is rather similar to that of a process algebra our main result may therefore be viewed as regarding the semantics of a process algebra as an abstraction of the semantics of an underlying programming language. This establishes a new kind of connection\u00a0\u2026", "num_citations": "91\n", "authors": ["1602"]}
{"title": "Abstract interpretation of mobile ambients\n", "abstract": " We demonstrate that abstract interpretation is useful for analysing calculi of computation such as the ambient calculus (which is based on the \u03c0-calculus); more importantly, we show that the entire development can be expressed in a constraint-based formalism that is becoming exceedingly popular for the analysis of functional and object-oriented languages.               The first step of the development is an analysis for counting occurrences of processes inside other processes (for which we show semantic correctness and that solutions constitute a Moore family); the second step is a previously developed control ow analysis that we show how to induce from the counting analysis (and its properties are derived from those of the counting analysis using general results).", "num_citations": "90\n", "authors": ["1602"]}
{"title": "Two-level semantics and code generation\n", "abstract": " We present a two-level denotational metalanguage that is suitable for defining the semantic of PASCAL-like languages. The two levels allow for an explicit distinction between computations taking place at compile-time and computations taking place at run-time. While this distinction is perhaps not absolutely necessary for describing the input-output semantics of programming languages, it is necessary when issues like data flow analysis and code generation are considered. For an example stack-machine we show how to generate code for the run-time computations and still perform the compile-time computations. Based on an example it is argued that compiler-tricks like the use of activation records suggest how to cope with certain syntactic restrictions in the metalanguage. The correctness of the code generation is proved using Kripke-like relations and using a modified machine that can be made to loop when a\u00a0\u2026", "num_citations": "88\n", "authors": ["1602"]}
{"title": "The typed \u03bb-calculus with first-class processes\n", "abstract": " We extend the typed \u03bb-calculus with CCS- or CSP-like processes and allow these to be first-class citizens just as functions are first-class citizens in functional languages. The main novel feature of the language is the use of types to record the communication possibilities possessed by processes and in this we give up the causality between communications, i.e. the types do not model whether or not one communication may take place before another. In analogy with the semantics of the \u03bb-calculus, and of CCS, we develop a structural operational semantics for the language. We then prove that the operational semantics preserves the types and we use this to give examples of \u2018errors\u2019 that cannot arise for well-typed programs.", "num_citations": "85\n", "authors": ["1602"]}
{"title": "Shape analysis for mobile ambients\n", "abstract": " The ambient calculus is a calculus of computation that allows active processes to move between sites. We present an analysis inspired by state-of-the-art pointer analyses that safety and accurately predicts which processes may turn up at what sites during the execution of a composite system. The analysis models sets of processes by sets of regular tree grammars enhanced with context-dependent counts, and it obtains its precision by combining a powerful redex materialisation with a strong redex reduction (in the manner of the strong updates performed in pointer analyses). The underlying ideas are flexible and scale up to general tree structures admitting powerful restructuring operations.", "num_citations": "82\n", "authors": ["1602"]}
{"title": "Static analysis of processes for no read-up and no write-down\n", "abstract": " We study a variant of the no read-up/no write-down security property of Bell and LaPadula for processes in the \u03c0-calculus. Once processes are given levels of security clearance, we statically check that a process at a high level never sends names to processes at a lower level. The static check is based on a Control Flow Analysis for the \u03c0-calculus that establishes a super-set of the set of names to which a given name may be bound and of the set of names that may be sent and received along a given channel, taking into account its directionality. The static check is shown to imply the natural dynamic condition.", "num_citations": "70\n", "authors": ["1602"]}
{"title": "Where can an insider attack?\n", "abstract": " By definition an insider has better access, is more trusted, and has better information about internal procedures, high-value targets, and potential weak spots in the security, than an outsider. Consequently, an insider attack has the potential to cause significant, even catastrophic, damage to the targeted organisation. While the problem is well recognised in the security community as well as in law-enforcement and intelligence communities, the main resort still is to audit log files after the fact. There has been little research into developing models, automated tools, and techniques for analysing and solving (parts of) the problem. In this paper we first develop a formal model of systems, that can describe real-world scenarios. These high-level models are then mapped to acKlaim, a process algebra with support for access control, that is used to study and analyse properties of the modelled systems. Our analysis of\u00a0\u2026", "num_citations": "69\n", "authors": ["1602"]}
{"title": "Validating firewalls using flow logics\n", "abstract": " The ambient calculus is a calculus of computation that allows active processes to communicate and to move between sites. A site is said to be a protective firewall whenever it denies entry to all attackers not possessing the required passwords. We devise a computationally sound test for validating the protectiveness of a proposed firewall and show how to perform the test in polynomial time. The first step is the definition of a flow logic for analysing the flow of control in mobile ambients; it amounts to a syntax-directed specification of the acceptability of a control flow estimate. The second step is to define a hardest attacker and to determine whether or not there exists a control flow estimate that shows the inability of the hardest attacker to enter; if such an estimate exists, then none of the infinitely many attackers can enter unless they contain at least one of the passwords, and consequently the firewall cannot contain any\u00a0\u2026", "num_citations": "68\n", "authors": ["1602"]}
{"title": "Program transformations in a denotational setting\n", "abstract": " Program transformations are frequently performed by optimizing compilers, and the correctness of applying them usually depends on data flow information. For language-to-same-language transformations, it is shown how a denotational setting can be useful for validating such program transformations. Strong equivalence is obtained for transformations that exploit information from a class of forward data flow analyses, whereas only weak equivalence is obtained for transformations that exploit information from a class of backward data flow analyses. To obtain strong equivalence, both the original and the transformed program must be data flow analysed, but consideration of a transformation-exploiting liveness of variables indicates that a more satisfactory approach may be possible.", "num_citations": "66\n", "authors": ["1602"]}
{"title": "Quantitative verification and synthesis of attack-defence scenarios\n", "abstract": " Attack-defence trees are a powerful technique for formally evaluating attack-defence scenarios. They represent in an intuitive, graphical way the interaction between an attacker and a defender who compete in order to achieve conflicting objectives. We propose a novel framework for the formal analysis of quantitative properties of complex attack-defence scenarios, using an extension of attack-defence trees which models temporal ordering of actions and allows explicit dependencies in the strategies adopted by attackers and defenders. We adopt a game-theoretic approach, translating attack-defence trees to two-player stochastic games, and then employ probabilistic model checking techniques to formally analyse these models. This provides a means to both verify formally specified security properties of the attack-defence scenarios and, dually, to synthesise strategies for attackers or defenders which guarantee or\u00a0\u2026", "num_citations": "63\n", "authors": ["1602"]}
{"title": "Normalizable horn clauses, strongly recognizable relations, and spi\n", "abstract": " We exhibit a rich class of Horn clauses, which we call , whose least models, though possibly infinite, can be computed effectively. We show that the least model of an  clause consists of so-called strongly recognizable relations and present an exponential normalization procedure to compute it. In order to obtain a practical tool for program analysis, we identify a restriction of  clauses, which we call , where the least models can be computed in polynomial time. This fragment still allows to express, e.g., Cartesian product and transitive closure of relations. Inside , we exhibit a fragment  where normalization is even cubic. We demonstrate the usefulness of our approach by deriving a cubic control-flow analysis for the Spi calculus [1] as presented in [14].", "num_citations": "60\n", "authors": ["1602"]}
{"title": "A calculus for control flow analysis of security protocols\n", "abstract": " The design of a process calculus for analysing security protocols is governed by three factors: expressing the security protocol in a precise and faithful manner, accommodating the variety of attack scenarios, and utilising the strengths (and limit the weaknesses) of the underlying analysis methodology. We pursue an analysis methodology based on control flow analysis in flow logic style, whose ability to analyse a variety of security protocols we have shown previously [7]. This paper develops a calculus, LySans, which allows for much greater control and clarity in the description of attack scenarios, gives a more flexible format for expressing protocols, and at the same time allows one to circumvent some of the \u2018false positives\u2019 arising in [7].", "num_citations": "59\n", "authors": ["1602"]}
{"title": "Zigbee-2007 security essentials\n", "abstract": " ZigBee is a fairly new but promising standard for wireless networks due to its low resource requirements. As in other wireless network standards, security is an important issue and each new version of the ZigBee Specification enhances the level of the ZigBee security. In this paper, we present the security essentials of the latest ZigBee Specification, ZigBee-2007. We explain the key concepts, protocols, and computations. In addition, we formulate the protocols using standard protocol narrations. Finally, we identify the key challenges to be considered for consolidating ZigBee.", "num_citations": "56\n", "authors": ["1602"]}
{"title": "Relational analysis of correlation\n", "abstract": " In service-oriented computing, correlations are used to determine links between service providers and users. A correlation contains values for some variables received in a communication. Subsequent messages will only be received when they match the values of the correlation. Correlations allow for the implementation of sessions, local shared memory, gradually provided input, or input provided in arbitrary order \u2013 thus presenting a challenge to static analysis.               In this work, we present a static analysis in relational form of correlations. It is defined in terms of a fragment of the process calculus COWS that itself builds on the Fusion Calculus. The analysis is implemented and practical experiments allow us to automatically establish properties of the flow of information between services.", "num_citations": "56\n", "authors": ["1602"]}
{"title": "Control flow analysis for bioambients\n", "abstract": " This paper presents a static analysis for investigating properties of biological systems specified in BioAmbients. We exploit the control flow analysis to decode the bindings of variables induced by communications and to build a relation of the ambients that can interact with each other. We eventually apply our analysis to an example of gene regulation by positive feedback taken from the literature.", "num_citations": "55\n", "authors": ["1602"]}
{"title": "Systematic realisation of control flow analyses for CML\n", "abstract": " We present a methodology for the systematic realisation of control flow analyses and illustrate it for Concurrent ML. We start with an abstract specification of the analysis that is next proved semantically sound with respect to a traditional small-step operational semantics; this result holds for terminating w well as non-terminating programs. The analysis is defined coinductively and it is shown that all programs have a least analysis result (that is indeed the best one). To realise the analysis we massage the specification in three stages:(i) to explicitly record reachability of subexpressions,(ii) to be defined in a syntax-directed manner, and (iii) to generate a set of constraints that subsequently can be solved by standard techniques. We prove equivalence results between the different versions of the analysis; in particular it follows that the least solution to the constraints generated will be the least analysis result also to the\u00a0\u2026", "num_citations": "55\n", "authors": ["1602"]}
{"title": "Static analysis for secrecy and non-interference in networks of processes\n", "abstract": " We introduce the \u03bdSPI-calculus that strengthens the notion of \u201cperfect symmetric cryptography\u201d of the spi-calculus by taking time into account. This involves defining an operational semantics, defining a control flow analysis (CFA) in the form of a flow logic, and proving semantic correctness. Our first result is that secrecy in the sense of Dolev-Yao can be expressed in terms of the CFA. Our second result is that also non-interference in the sense of Abadi can be expressed in terms of the CFA; unlike Abadi we find the non-interference property to be an extension of the Dolev-Yao property.", "num_citations": "54\n", "authors": ["1602"]}
{"title": "Strictness analysis and denotational abstract interpretation\n", "abstract": " A theory of abstract interpretation (P. Cousot and R. Cousot, in \u201cConf. Record, 4th ACM Symposium on Principles of Programming Languages,\u201d 1977) is developed for a typed \u03bb-calculus. The typed \u03bb-calculus may be viewed as the \u201cstatic\u201d part of a two-level denotational metalanguage for which abstract interpretation was developed by Nielson, 1984, Nielson, 1986a, Nielson, 1986b). The present development relaxes a condition imposed there and this sufices to make the framework applicable to strictness analysis for the \u03bb-calculus. This shows the possibility of a general theory for the analysis of functional programs and it gives more insight into the relative precision of the various analyses. In particular it is shown that a collecting (static; P. Cousot and R. Cousot, in \u201cConf. Record, 6th ACM Symposium on Principles of Programming Languages,\u201d 1979) semantics exists, thus answering a problem left open by G. L. Burn\u00a0\u2026", "num_citations": "54\n", "authors": ["1602"]}
{"title": "Pareto efficient solutions of attack-defence trees\n", "abstract": " Attack-defence trees are a promising approach for representing threat scenarios and possible countermeasures in a concise and intuitive manner. An attack-defence tree describes the interaction between an attacker and a defender, and is evaluated by assigning parameters to the nodes, such as probability or cost of attacks and defences. In case of multiple parameters most analytical methods optimise one parameter at a time, e.g., minimise cost or maximise probability of an attack. Such methods may lead to sub-optimal solutions when optimising conflicting parameters, e.g., minimising cost while maximising probability.                 In order to tackle this challenge, we devise automated techniques that optimise all parameters at once. Moreover, in the case of conflicting parameters our techniques compute the set of all optimal solutions, defined in terms of Pareto efficiency. The developments are carried out\u00a0\u2026", "num_citations": "53\n", "authors": ["1602"]}
{"title": "Bounded fixed-point iteration\n", "abstract": " In the context of abstract interpretation we study the number of times a functional needs to be unfolded in order to give the least fixed point. For the cases of total or monotone functions we obtain an exponential bound and in the case of strict and additive (or distributive) functions we obtain a quadratic bound. These bounds are shown to be tight. Specializing the case of strict and additive functions to functionals of a form that would correspond to iterative programs we show that a linear bound is tight. This is related to several analyses studied in the literature (including strictness analysis).", "num_citations": "52\n", "authors": ["1602"]}
{"title": "Tensor products generalize the relational data flow analysis method\n", "abstract": " Tensor Products Generalize the Relational Data Flow Analysis Method \u2014 DTU Research Database Skip to main navigation Skip to search Skip to main content DTU Research Database Logo About DTU Orbit Home Profiles Research Units Research Output Activities Projects Prizes Press / Media Search by expertise, name or affiliation Tensor Products Generalize the Relational Data Flow Analysis Method Flemming Nielson Research output: Chapter in Book/Report/Conference proceeding \u203a Article in proceedings \u203a Research \u203a peer-review Overview Original language English Title of host publication Proc. Fourth Hungarian Computer Science Conference Publication date 1985 Pages 211-225 Publication status Published - 1985 Event 4th Hungarian Computer Science Conference - Gy\u00f6r, Hungary Duration: 8 Jul 1985 \u2192 10 Jul 1985 Conference Conference 4th Hungarian Computer Science Conference Country \u2026", "num_citations": "51\n", "authors": ["1602"]}
{"title": "Abstract interpretation using domain theory.\n", "abstract": " British Library EThOS: Abstract interpretation using domain theory. New search | Advanced search | Search results Login / Register | About | Help | FAQ | Follow dividing line Use this URL to cite or link to this record in EThOS: https://ethos.bl.uk/OrderDetails.do?uin=uk.bl.ethos.350060 Title: Abstract interpretation using domain theory. Author: Nielson, Flemming ISNI: 0000 0001 Date of Award: 1984 Availability of Full Text: Access from EThOS: Immediate download. Please login to continue. Abstract: No abstract available Supervisor: Not available Sponsor: Not available Qualification Name: Thesis (Ph.D.) Qualification Level: Doctoral EThOS ID: uk.bl.ethos.350060 DOI: Not available Keywords: Computer software & programming Share: Terms and Conditions | Notice and Takedown Policy | Privacy Policy | Sitemap | \u2026", "num_citations": "45\n", "authors": ["1602"]}
{"title": "Strong abstract interpretation using power domains\n", "abstract": " Using a suitable notion of powerdomain we extend Abstract Interpretation to deal with partial functions so that non-termination is regarded as a specific value. We use this to validate a data flow analysis aimed at justifying when call-by-name can be implemented as call-by-value.", "num_citations": "44\n", "authors": ["1602"]}
{"title": "Control-flow analysis in cubic time\n", "abstract": " It is well-known that context-independent control flow analysis can be performed in cubic time for functional and object-oriented languages. Yet recent applications of control flow analysis to calculi of computation (like the \u03c0-calculus and the ambient calculus) have reported considerably higher complexities. In this paper we introduce two general techniques, the use of Horn clauses with sharing and the use of tiling of Horn clauses, for reducing the worst-case complexity of analyses. Applying these techniques to the \u03c0-calculus and the ambient calculus we reduce the complexity from O(n               5) to O(n               3) in both cases.", "num_citations": "43\n", "authors": ["1602"]}
{"title": "The succinct solver suite\n", "abstract": " The Succinct Solver Suite offers two analysis engines for solving data and control flow problems expressed in clausal form in a large fragment of first order logic. The solvers have proved to be useful for a variety of applications including security properties of Java Card byte-code, access control features of Mobile and Discretionary Ambients, and validation of protocol narrations formalised in a suitable process algebra. Both solvers operate over finite domains although they can cope with regular sets of trees by direct encoding of the tree grammars; they differ in fine details about the demands on the universe and the extent to which universal quantification is allowed. A number of transformation strategies, mainly automatic, have been studied aiming on the one hand to increase the efficiency of the solving process, and on the other hand to increase the ease with which users can develop analyses. The results\u00a0\u2026", "num_citations": "42\n", "authors": ["1602"]}
{"title": "The logic of XACML\n", "abstract": " We study the international standard XACML 3.0 for describing security access control policies in a compositional way. Our main contributions are (i) to derive a logic that precisely captures the intentions of the standard, (ii) to formally define a semantics for the XACML 3.0 component evaluation, and (iii) to define a semantics for the XACML 3.0 standard combining operators. To guard against modeling artefacts we provide an alternative lattice based way of characterizing the policy combining operators and we formally prove the equivalence of these approaches thereby increasing our faith in either one. We then discuss several ways of extending XACML: one direction is to extend XACML with new combining operators, and another direction is to incorporate the notion of conflict into XACML. We conclude by discussing the possibility of analysing XACML policies for gaps and conflicts.", "num_citations": "41\n", "authors": ["1602"]}
{"title": "Cryptographic analysis in cubic time\n", "abstract": " The spi-calculus is a variant of the polyadic \u03c0-calculus that admits symmetric cryptography and that admits expressing communication protocols in a precise though still abstract way. This paper shows that context-independent control flow analysis can be calculated in cubic time despite the fact that the spi-calculus operates over an infinite universe of values. Our approach is based on Horn Clauses with Sharing and we develop transformations to pass from the infinite to the finite and to deal with the polyadic nature of input and output. We prove that this suffices for obtaining a cubic time implementation without sacrificing precision and without making simplifying assumptions on the nature of keys.", "num_citations": "40\n", "authors": ["1602"]}
{"title": "Spatial analysis of bioambients\n", "abstract": " Programming language technology can contribute to the development and understanding of Systems Biology by providing formal calculi for specifying and analysing the dynamic behaviour of biological systems. Our focus is on BioAmbients, a variation of the ambient calculi developed for modelling mobility in computer systems. We present a static analysis for capturing the spatial structure of biological systems and we illustrate it on a few examples.", "num_citations": "36\n", "authors": ["1602"]}
{"title": "Abstract interpretation of mobile ambients\n", "abstract": " We show how abstract interpretation can be expressed in a constraint-based formalism that is becoming increasingly popular for the analysis of functional and object-oriented languages. This is illustrated by developing analyses for the ambient calculus.The first step of the development constructs an analysis for counting occurrences of processes inside other processes; we show that the analysis is semantically correct and that the set of acceptable solutions constitutes a Moore family. The second step considers a previously developed control flow analysis and shows how to induce it from the counting analysis; we show that its properties can be derived from those of the counting analysis using general results about abstract interpretation for constraint-based analyses.", "num_citations": "36\n", "authors": ["1602"]}
{"title": "Polymorphic subtyping for effect analysis: The static semantics\n", "abstract": " The integration of polymorphism (in the style of the ML let-construct), subtyping, and effects (modelling assignment or communication) into one common type system has proved remarkably difficult. One line of research has succeeded in integrating polymorphism and subtyping; adding effects in a straightforward way results in a semantically unsound system. Another line of research has succeeded in integrating polymorphism, effects, and subeffecting; adding subtyping in a straight-forward way invalidates the construction of the inference algorithm. This paper integrates all of polymorphism, effects, and subtyping into an annotated type and effect system for Concurrent ML and shows that the resulting system is a conservative extension of the ML type system.", "num_citations": "36\n", "authors": ["1602"]}
{"title": "Security for mobility\n", "abstract": " We show how to use static analysis to provide information about security issues related to mobility. First the syntax and semantics of Mobile Ambients is reviewed and we show how to obtain a so-called 0CFA analysis that can be implemented in polynomial time. Next we consider discretionary access control where we devise Discretionary Ambients, based on Safe Ambients, and we adapt the semantics and 0CFA analysis; to strengthen the analysis we incorporate context-sensitivity to obtain a 1CFA analysis. This paves the way for dealing with mandatory access control where we express both a Bell-LaPadula model for confidentiality as well as a Biba model for integrity. Finally, we use Boxed Ambients as a means for expressing cryptographic key exchange protocols and we adapt the operational semantics and the 0CFA analysis.", "num_citations": "34\n", "authors": ["1602"]}
{"title": "Automatic complexity analysis\n", "abstract": " We consider the problem of automating the derivation of tight asymptotic complexity bounds for solving Horn clauses. Clearly, the solving time crucially depends on the \u201csparseness\u201d of the computed relations. Therefore, our asymptotic runtime analysis is accompanied by an asymptotic sparsity calculus together with an asymptotic sparsity analysis. The technical problem here is that least fixpoint iteration fails on asymptotic complexity expressions: the intuitive reason is that O(1)+ srO(1) = O(1) but O(1) + \u22ef + O(1) may return any value.", "num_citations": "33\n", "authors": ["1602"]}
{"title": "Flow logics for constraint based analysis\n", "abstract": " Flow logic offers a compact and versatile notation for expressing the acceptability of solutions to program analysis problems. In contrast to previous logical formulations of program analysis it aims at integrating existing approaches to data flow analysis and control flow analysis. It is able to deal with a broad variety of language paradigms, program properties, kinds of formal semantics, and methods used for computing the best solution. In this paper we illustrate how a compositional flow logic (in \u201csuccinct\u201d form) can be systematically transformed into an efficient exhaustive procedure for computing the best solution of a set of constraints generated. This involves transformations to attribute grammars and to specifications of the (\u201cverbose\u201d) form used in control flow analysis.", "num_citations": "33\n", "authors": ["1602"]}
{"title": "Interprocedural control flow analysis\n", "abstract": " Control Flow Analysis is a widely used approach for analysing functional and object oriented programs. Once the applications become more demanding also the analysis needs to be more precise in its ability to deal with mutable state (or side-effects) and to perform polyvariant (or context-sensitive) analysis. Several insights in Data Flow Analysis and Abstract Interpretation show how to do so for imperative programs but the techniques have not had much impact on Control Flow Analysis. We show how to incorporate a number of key insights from Data Flow Analysis (involving such advanced interprocedural techniques as call strings and assumption sets) into Control Flow Analysis (using Abstract Interpretation to induce the analyses from a collecting semantics).", "num_citations": "32\n", "authors": ["1602"]}
{"title": "Flow logic for Dolev\u2013Yao secrecy in cryptographic processes\n", "abstract": " We introduce the \u03bdspi-calculus that strengthens the notion of \u201cperfect symmetric cryptography\u201d of the spi-calculus by making encryption history dependent. We give our calculus an operational and a static semantics. The latter is a control flow analysis (CFA), defined in the form of a flow logic, and it is proved semantically correct. We then apply our CFA to check security properties; in particular, we show that secrecy \u00e0 la Dolev\u2013Yao can be expressed in terms of the CFA.", "num_citations": "31\n", "authors": ["1602"]}
{"title": "Flow logic and operational semantics\n", "abstract": " Flow logic is a \u201cfast prototyping\u201d approach to program analysis that shows great promise of being able to deal with a wide variety of languages and calculi for computation. However, seemingly innocent choices in the flow logic as well as in the operational semantics may inhibit proving the analysis correct. Our main conclusion is that environment based semantics is more flexible than either substitution based semantics or semantics making use of structural congruences (like alpha-renaming).", "num_citations": "31\n", "authors": ["1602"]}
{"title": "The logic of XACML\n", "abstract": " We study the international standard XACML 3.0 for describing security access control policy in a compositional way. Our main contribution is to derive a logic that precisely captures the idea behind the standard and to formally define the semantics of the policy combining algorithms of XACML. To guard against modelling artefacts we provide an alternative way of characterizing the policy combining algorithms and we formally prove the equivalence of these approaches. This allows us to pinpoint the shortcoming of previous approaches to formalization based either on Belnap logic or on -algebra.", "num_citations": "30\n", "authors": ["1602"]}
{"title": "Type and behaviour reconstruction for higher-order concurrent programs\n", "abstract": " In this paper we develop a sound and complete type and behaviour inference algorithm for a fragment of CML (Standard ML with primitives for concurrency). Behaviours resemble terms of a process algebra and yield a concise representation of the communications taking place during execution; types are mostly as usual except that function ypes and \u2018delayed communication types\u2019 are labelled by behaviours expressing the communications that will take place if the function is applied or the delayed action is activated. The development of the present paper improves a previously published algorithm in achieving completeness as well as soundness; this is due to an alternative strategy for generalising over types and behaviours.", "num_citations": "30\n", "authors": ["1602"]}
{"title": "A formal type system for comparing partial evaluators\n", "abstract": " A Formal Type System for Comparing Partial Evaluators \u2014 DTU Research Database Skip to main navigation Skip to search Skip to main content DTU Research Database Logo About DTU Orbit Home Profiles Research Units Research Output Activities Projects Prizes Press / Media Search by expertise, name or affiliation A Formal Type System for Comparing Partial Evaluators Flemming Nielson, D. Bj\u00f8rner (Editor), ND Jones (Editor), AP Ershov (Editor) Research output: Chapter in Book/Report/Conference proceeding \u203a Article in proceedings \u203a Research \u203a peer-review Overview Original language English Title of host publication Proc. Partial Evaluation and Mixed Computation Publisher North-Holland Publication date 1988 Pages 349-384 Publication status Published - 1988 Event Proc. Partial Evaluation and Mixed Computation - Duration: 1 Jan 1988 \u2192 \u2026 Conference Conference Proc. Partial Evaluation and Mixed \u2026", "num_citations": "30\n", "authors": ["1602"]}
{"title": "Sandboxing in myKlaim\n", "abstract": " The /spl mu/Klaim calculus is a process algebra designed to study the programming of distributed systems consisting of a number of locations each having their own tuple space and collection of mobile processes. Previous work has explored how to incorporate a notion of capabilities to be enforced dynamically by means of a reference monitor. Our first contribution is to describe a sandboxing semantics for the remote evaluation of mobile code; we then develop a succinct flow logic for statically guaranteeing the properties enforced by the reference monitor and hence for dispensing with the overhead of a dynamic reference monitor. Our second contribution is an extension of the calculus to interact with an environment; processes enter the system from the environment and we develop an entry-condition that is sufficient for ensuring that the resulting system continues to guarantee the properties that would otherwise\u00a0\u2026", "num_citations": "29\n", "authors": ["1602"]}
{"title": "Static analysis for systems biology\n", "abstract": " This paper shows how static analysis techniques can help understanding biological systems. Based on a simple example will illustrate the outcome of performing three different analyses extracting information of increasing precision. We conclude by reporting on the potential impact and exploitation of these techniques in systems biology.", "num_citations": "28\n", "authors": ["1602"]}
{"title": "A secure key establishment protocol for ZigBee wireless sensor networks\n", "abstract": " ZigBee is a wireless sensor network standard that defines network and application layers on top of IEEE 802.15.4's physical and medium access control layers. In the latest version of ZigBee, enhancements are prescribed for the security sublayer but we show in this paper that problems persist. In particular, we show that the end-to-end application key establishment protocol is flawed and we propose a secure protocol instead. We do so by using formal verification techniques based on static program analysis and process algebras. We present a way of using formal methods in wireless network security, and propose a secure key establishment protocol for ZigBee networks.", "num_citations": "27\n", "authors": ["1602"]}
{"title": "Securing statically-verified communications protocols against timing attacks\n", "abstract": " We present a federated analysis of communication protocols which considers both security properties and timing. These are not entirely independent observations of a protocol; by using timing observations of an executing protocol it is possible to calculate encryption keys which were intended to be secret or to deduce derived information about the nature of the communication even in the presence of unbreakable encryption. Our analysis is based on expressing the protocol as a high-level model and deriving from this process calculus models analysable by the Imperial PEPA Compiler and the LySatool.", "num_citations": "27\n", "authors": ["1602"]}
{"title": "Multi-level lambda-calculi: an algebraic description\n", "abstract": " Two-level \u03bb-calculi have been heavily utilised for applications such as partial evaluation, abstract interpretation and code generation. Each of these applications pose different demands on the exact details of the two-level structure and the corresponding inference rules. We therefore formulate a number of existing systems in a common framework. This is done in such a way as to conceal those differences between the systems that are not essential for the multi-level ideas (like whether or not one restricts the domain of the type environment to the free identifiers of the expression) and thereby to reveal the deeper similarities and differences. In their most general guise the multi-level \u03bb-calculi defined here allow multi-level structures that are not restricted to (possibly finite) linear orders and thereby generalise previous treatments in the literature.", "num_citations": "27\n", "authors": ["1602"]}
{"title": "Constraints for polymorphic behaviours of concurrent ML\n", "abstract": " We present a type and behaviour reconstruction algorithm for Standard ML with concurrency. The behaviours express the communication effects during execution and resemble terms of a process algebra. The algorithm uses unification for the (essentially) free algebra of types and algebraic reconstruction for collecting constraints for the non-free algebra of behaviours. The algorithm and the statement and proof of soundness are designed so as to make no assumptions on the existence of \u201cprincipal\u201d be-haviours as these are unlikely to exist. The main complication is that the notion of expansiveness does not suffice for a sufficiently general treatment of the polymorphic let-construct.", "num_citations": "27\n", "authors": ["1602"]}
{"title": "Control flow analysis can find new flaws too\n", "abstract": " A previous study [6] showed how control flow analysis can be applied to analyse key distribution protocols based on symmetric key cryptography. We have extended both the theoretical treatment and our fully automatic verifier to deal with protocols based on asymmetric cryptography. This paper reports on the application of our technique\u2013exemplified on the Beller-Chang-Yacobi MSR protocol, which uses both symmetric and asymmetric cryptography\u2013and show how we discover an undocumented flaw.", "num_citations": "26\n", "authors": ["1602"]}
{"title": "Strictness and totality analysis\n", "abstract": " We define a novel inference system for strictness and totality analysis for the simplytyped lazy lambda-calculus with constants and fixpoints. Strictness information identifies those terms that definitely denote bottom (i.e. do not evaluate to WHNF) whereas totality information identifies those terms that definitely do not denote bottom (i.e. do evaluate to WHNF). The analysis is presented as an annotated type system allowing conjunctions only at \u201ctop-level\u201d. We give examples of its use and prove the correctness with respect to a natural-style operational semantics.", "num_citations": "26\n", "authors": ["1602"]}
{"title": "Abstract interpretation of denotational definitions\n", "abstract": " Abstract interpretation is a framework for describing data flow analyses and for proving their correctness. Traditionally the framework is developed for flow chart languages, but this paper extends the applicability of the idea to a wide class of languages that have a denotational semantics. The main idea is to study a denotational metalanguage with two kinds of types: one kind describes compile-time entities and another describes run-time entities. The run-time entities will be interpreted differently so as to obtain different semantics from the same denotational definition: the standard semantics is the ordinary semantics, an approximating semantics describes a data flow analysis and the collecting semantics is a convenient tool in relating the previous two semantics.", "num_citations": "26\n", "authors": ["1602"]}
{"title": "Expected forms of data flow analyses\n", "abstract": " A previous paper developed a general denotational framework for specification of data flow analyses and for proofs of correctness (using abstract interpretation). In particular, the method of \"inducing\" specifies new data flow analyses that as precisely as possible approximate given data flow analyses. However, from a practical point of view the induced versions of the functionals are \"too precise\" and this motivates a study of \"expected forms\" (or \"normal forms\"). This paper suggests such forms and shows the correctness of systematically using them.", "num_citations": "26\n", "authors": ["1602"]}
{"title": "Formal security analysis of the MaCAN protocol\n", "abstract": " Embedded real-time network protocols such as the CAN bus cannot rely on off-the-shelf schemes for authentication, because of the bandwidth limitations imposed by the network. As a result, both academia and industry have proposed custom protocols that meet such constraints, with solutions that may be deemed insecure if considered out of context. MaCAN is one such compatible authentication protocol, proposed by Volkswagen Research and a strong candidate for being adopted by the automotive industry.                 In this work we formally analyse MaCAN with ProVerif, an automated protocol verifier. Our formal analysis identifies two flaws in the original protocol: one creates unavailability concerns during key establishment, and the other allows re-using authenticated signals for different purposes. We propose and analyse a modification that improves its behaviour while fitting the constraints of CAN\u00a0\u2026", "num_citations": "25\n", "authors": ["1602"]}
{"title": "From CML to its process algebra\n", "abstract": " Reppy's language CML extends Standard ML of Milner et al. with primitives for communication. It thus inherits a notion of strong polymorphic typing and may be equipped with a structural operational semantics. As a first step we formulate an effect system for statically expressing the communication behaviours of CML programs as these are not reflected in the types. As a second step we adapt the structural operational semantics of CML so as to incorporate behaviours. We then show how types and behaviours evolve in the course of computation: types may decrease and behaviours may lose prefixes as well as decrease. As the syntax of behaviours is rather similar to that of a process algebra our main result may therefore be viewed as regarding the semantics of a process algebra as an abstraction of the semantics of an underlying programming language. This establishes a new kind of connection between \u201crealistic\u00a0\u2026", "num_citations": "25\n", "authors": ["1602"]}
{"title": "Effect-driven QuickChecking of compilers\n", "abstract": " How does one test a language implementation with QuickCheck (aka. property-based testing)? One approach is to generate programs following the grammar of the language. But in a statically-typed language such as OCaml too many of these candidate programs will be rejected as ill-typed by the type checker. As a refinement Pa\u0142ka et al. propose to generate programs in a goal-directed, bottom-up reading up of the typing relation. We have written such a generator. However many of the generated programs has output that depend on the evaluation order, which is commonly under-specified in languages such as OCaml, Scheme, C, C++, etc. In this paper we develop a type and effect system for conservatively detecting evaluation-order dependence and propose its goal-directed reading as a generator of programs that are independent of evaluation order. We illustrate the approach by generating programs to test\u00a0\u2026", "num_citations": "24\n", "authors": ["1602"]}
{"title": "Annotated type and effect systems\n", "abstract": " Program analysis offers static techniques for predicting safe and computable approximations to the set of values or behaviors arising dynamically during computation; this may be used to validate program transformations or to generate more efficient code. The flowbased approach includes the traditional data-flow analysis techniques for mainly imperative languages, but also the control-flow analysis techniques developed for functional and object-oriented languages. The model-based approach includes the parameterized denotational semantics techniques developed for functional and imperative languages, but also more generally the use of mathematical modeling in the abstract interpretation of imperative, functional, concurrent, and logic languages. The inference-based approach includes general logical techniques touching upon program verification techniques, but also annotated type and effect systems\u00a0\u2026", "num_citations": "24\n", "authors": ["1602"]}
{"title": "The tensor product in Wadler's analysis of lists\n", "abstract": " We consider abstract interpretation (in particular strictness analysis) for pairs and lists. We begin by reviewing the well-known fact that the best known description of a pair of elements is obtained using the tensor product rather than the cartesian product. We next present a generalisation of Wadler's strictness analysis for lists using the notion of open set. Finally, we illustrate the intimate connection between the case analysis implicit in Wadler's strictness analysis and the precision that the tensor product allows for modelling the inverse cons operation.", "num_citations": "24\n", "authors": ["1602"]}
{"title": "Set-pi: Set membership p-calculus\n", "abstract": " Communication protocols often rely on stateful mechanisms to ensure certain security properties. For example, counters and timestamps can be used to ensure authentication, or the security of communication can depend on whether a particular key is registered to a server or it has been revoked. ProVerif, like other state of the art tools for protocol analysis, achieves good performance by converting a formal protocol specification into a set of Horn clauses, that represent a monotonically growing set of facts that a Dolev-Yao attacker can derive from the system. Since this set of facts is not state-dependent, the category of protocols of our interest cannot be precisely analysed by such tools, as they would report false attacks due to the over-approximation. In this paper we present Set-\u03c0, an extension of the Applied \u03c0-calculus that includes primitives for handling databases of objects, and propose a translation from Set-\u03c0\u00a0\u2026", "num_citations": "23\n", "authors": ["1602"]}
{"title": "Static and dynamic processor allocation for higher-order concurrent languages\n", "abstract": " Starting from the process algebra for Concurrent ML we develop two program analyses that facilitate the intelligent placement of processes on processors. Both analyses are obtained by augmenting an inference system for counting the number of channels created, the number of input and output operations performed, and the number of processes spawned by the execution of a Concurrent ML program. One analysis provides information useful for making a static decision about processor allocation; to this end it accumulates the communication cost for all processes with the same label. The other analysis provides information useful for making a dynamic decision about processor allocation; to this end it determines the maximum communication cost among processes with the same label. We prove the soundness of the inference system and the two analyses and demonstrate how to implement them; the latter\u00a0\u2026", "num_citations": "23\n", "authors": ["1602"]}
{"title": "Finiteness conditions for fixed point iteration\n", "abstract": " This paper provides a link between the formulation of static program analyses using the framework of abstract interpretation (popular for functional languages and using the more classical framework of data flow anlysis (popular for imperative languages).  In particular we show how the classical notions of fastness, rapidity and k-boundedness carry over to the abstract interpretation framework and how this may be used to bound the number of times a functional should be unfolded in order to yield the fixed point.  This is supplemented with a number of results on how to calculate the bounds for iterative forms (as for tail recursion), for linear forms (as for one nested recursive call), and for primitive recursive forms.  In some cases this improves the \u201cworst case\u201d  results of, but more importantly it gives much better\u201caverage case\u201d results.", "num_citations": "23\n", "authors": ["1602"]}
{"title": "Bisimulations meet PCTL equivalences for probabilistic automata\n", "abstract": " Probabilistic automata (PAs) have been successfully applied in formal verification of concurrent and stochastic systems. Efficient model checking algorithms have been studied, where the most often used logics for expressing properties are based on probabilistic computation tree logic (PCTL) and its extension PCTL^*. Various behavioral equivalences are proposed, as a powerful tool for abstraction and compositional minimization for PAs. Unfortunately, the equivalences are well-known to be sound, but not complete with respect to the logical equivalences induced by PCTL or PCTL*. The desire of a both sound and complete behavioral equivalence has been pointed out by Segala in 1995, but remains open throughout the years. In this paper we introduce novel notions of strong bisimulation relations, which characterize PCTL and PCTL* exactly. We extend weak bisimulations that characterize PCTL and PCTL* without next operator, respectively. Further, we also extend the framework to simulation preorders. Thus, our paper bridges the gap between logical and behavioral equivalences and preorders in this setting.", "num_citations": "22\n", "authors": ["1602"]}
{"title": "Code generation from two-level denotational meta-languages\n", "abstract": " The use of a two-level meta-language in denotational language definitions makes it possible to distinguish between compile-time entities and run-time entities. This is important for language specification and it allows one to formalize Tennents [18] informal distinction between static expressions and expressions. The automatic generation of compilers also benefits from an explicit distinction between run-time and compile-time in the language specification. A theory of abstract interpretation has been developed for the meta-language", "num_citations": "22\n", "authors": ["1602"]}
{"title": "Static analysis of a model of the LDL degradation pathway\n", "abstract": " BioAmbients is a derivative of mobile ambients that has shown promise of describing interesting features of the behaviour of biological systems. As for other ambient calculi static program analysis can be used to compute safe approximations of the behaviour of system models. We use these tools to model and analyse the production of cholesterol in living cells and show that we are able to pinpoint the difference in behaviour between models of healthy systems and models of mutated systems giving rise to known diseases.", "num_citations": "21\n", "authors": ["1602"]}
{"title": "Pragmatic aspects of two-level denotational meta-languages\n", "abstract": " This work is part of a research project on automatic generation of optimazing compilers from denotational language definitions. The novel aspect of our approach is that we are based on a two-level meta-language allowing us to distinguish between compile-time and run-time, and thereby to formalize e.g. the distinction between \"static expression procedures\" and \"expression procedures\" of Tennent (1981). In this paper we discuss some of the problems encountered when writing denotational definitions using a two-level meta-language. We consider the meta-language TMLS introduced in Nielson (1986a) as well as its restricted version TMLSC developed in Nielson and Nielson (1986) for automatic code generation. Based on an example we argue that rewriting a language definition using TMLS in TMLSC really means introducing some notion of activation record. This observation may pave the way for a\u00a0\u2026", "num_citations": "21\n", "authors": ["1602"]}
{"title": "A monotone framework for CCS\n", "abstract": " The calculus of communicating systems, CCS, was introduced by Robin Milner as a calculus for modelling concurrent systems. Subsequently several techniques have been developed for analysing such models in order to get further insight into their dynamic behaviour.In this paper we present a static analysis for approximating the control structure embedded within the models. We formulate the analysis as an instance of a monotone framework and thus draw on techniques that often are associated with the efficient implementation of classical imperative programming languages.We show how to construct a finite automaton that faithfully captures the control structure of a CCS model. Each state in the automaton records a multiset of the enabled actions and appropriate transfer functions are developed for transforming one state into another. A classical worklist algorithm governs the overall construction of the\u00a0\u2026", "num_citations": "20\n", "authors": ["1602"]}
{"title": "Pathway analysis for BioAmbients\n", "abstract": " Systems Biology aims for a holistic understanding of biological processes. In order to make this understanding operational and testable it can be recorded into formal process calculus models. This is a difficult task, however, because such formal models and their, often infinitely many, consequences are hard to enumerate and understand. In this paper we define a pathway analysis, based on static analysis techniques from programming languages, and show how it can be used to establish useful, finite, approximations to the set of causal consequences of models. The Pathway Analysis can be used to great advantage in all phases of the modelling approach \u2013 serving as the basis of debugging during model development, postdiction during model validation, and, finally, prediction during model guided drug design.", "num_citations": "20\n", "authors": ["1602"]}
{"title": "Modal abstractions of concurrent behaviour\n", "abstract": " We present a novel algorithm for the automatic construction of modal transition systems as abstractions of concurrent processes. Modal transition systems are recognised as valuable abstractions for model checking because they allow for the deduction of safety as well as liveness properties. However, the issue of effectively creating these abstractions from specification languages such as process algebras is a missing link that prevents their more widespread usage for model checking of concurrent systems. Our algorithm is based on static analysis and uses a lattice of intervals to express simultaneous over- and under-approximations to the set of process actions available in a particular state. We obtain an abstraction that is 3-valued in both states and transitions and that naturally integrates with model checking approaches for modal transition systems.", "num_citations": "20\n", "authors": ["1602"]}
{"title": "Polymorphic subtyping for effect analysis: The algorithm\n", "abstract": " We study an annotated type and effect system that integrates let-polymorphism, effects, and subtyping into an annotated type and effect system for a fragment of Concurrent ML. First we define a type inference algorithm and then construct procedures for constraint normalisation and simplification. Next these algorithms are proved syntactically sound with respect to the annotated type and effect system.", "num_citations": "20\n", "authors": ["1602"]}
{"title": "Transformations on higher-order functions\n", "abstract": " Traditional functional languages do not have an explicit distinction between binding times. It arises implicitly, however, as typically one instantiates a higher-order function with the known arguments whereas the unknown arguments still are to be taken as parameters. The distinction between \u2018Itnouln\u2019and \u2018un~% nozv7t\u2019is closely related to the distinction between binding times, eg the distinction between compile-time and run-time. We shall therefore use a combination of polymorphic type inference and binding time analysis to obtain the required information.Following the current trend in the implementation of functional languages we shall then transform the run-time level (not the compile-time level) of the program into categorical combinators. At this stage we have a natural distinction between two kinds of program transformations: partial evaZ-uation which involves the compile-time level of our notation and algebraic\u00a0\u2026", "num_citations": "20\n", "authors": ["1602"]}
{"title": "Enforcing availability in failure-aware communicating systems\n", "abstract": " Choreographic programming is a programming-language design approach that drives error-safe protocol development in distributed systems. Motivated by challenging scenarios in Cyber-Physical Systems (CPS), we study how choreographic programming can cater for dynamic infrastructures where the availability of components may change at runtime. We introduce the Global Quality Calculus (), a process calculus featuring novel operators for multiparty, partial and collective communications; we provide a type discipline that controls how partial communications refer only to available components; and we show that well-typed choreographies enjoy progress.", "num_citations": "19\n", "authors": ["1602"]}
{"title": "ML with Concurrency: Design, Analysis, Implementation, and Application\n", "abstract": " Both functional and concurrent programming are relatively new paradigms with great promise. In this book, a survey is provided of extensions to Standard ML, one of the most widely used functional languages, with new primitives for concurrent programming. Computer scientists and graduate students will find this a valuable guide to this topic.", "num_citations": "19\n", "authors": ["1602"]}
{"title": "Modelling and analysis of smart grid: A stochastic model checking case study\n", "abstract": " Cyber-physical systems integrate information and communication technology functions to the physical elements of a system for monitoring and controlling purposes. The conversion of traditional power grid into a smart grid, a fundamental example of a cyber-physical system, raises a number of issues that require novel methods and applications. In this context, an important issue is the verification of certain quantitative properties of the system. In this paper, we consider a specific Chinese Smart Grid implementation as a case study and address the verification problem for performance and energy consumption. We employ stochastic model checking approach and present our modelling and analysis study using PRISM model checker.", "num_citations": "19\n", "authors": ["1602"]}
{"title": "Communication analysis for Concurrent ML\n", "abstract": " Concurrent ML (CML) is an extension of the functional language Standard ML (SML) with primitives for dynamic creation of processes and channels and for communication of values over channels. Because of the powerful abstraction mechanisms, the communication topology of a given program may be very complex and therefore an efficient implementation may be facilitated by knowledge of the topology.             This paper presents a framework for analyzing the communication topology of CML programs. We proceed by extending a polymorphic type system for SML to deduce not only the types of CML programs but also their communication behaviors expressed as terms in a process algebra. This involves a syntactic ordering for expressing when one behavior has more communication possibilities than another. We then provide an annotated version of the published operational semantics for CML and we\u00a0\u2026", "num_citations": "19\n", "authors": ["1602"]}
{"title": "XACML 3.0 in answer set programming\n", "abstract": " We present a systematic technique for transforming XACML 3.0 policies in Answer Set Programming (ASP). We show that the resulting logic program has a unique answer set that directly corresponds to our formalisation of the standard semantics of XACML 3.0 from [9]. We demonstrate how our results make it possible to use off-the-shelf ASP solvers to formally verify properties of access control policies represented in XACML, such as checking the completeness of a set of access control policies and verifying policy properties.", "num_citations": "18\n", "authors": ["1602"]}
{"title": "Eureka definitions for free! or disagreement points for fold/unfold transformations\n", "abstract": " The fold/unfold framework of Burstall and Darlington is a very powerful framework for transforming function definitions in the form of recursion equation schemes. This may be used to transform a function so as to improve the efficiency of its implementation. However, for this to work the user must supply so-called Eureka definitions and it may require some ingenuity to construct these. This paper shows that a class of these Eureka definitions can be derived in a rather systematic way.", "num_citations": "18\n", "authors": ["1602"]}
{"title": "Towards a denotational theory of abstract interpretation\n", "abstract": " Towards a Denotational Theory of Abstract Interpretation \u2014 Welcome to DTU Research Database Skip to main navigation Skip to search Skip to main content Welcome to DTU Research Database Home Welcome to DTU Research Database Logo About DTU Orbit Home Profiles Research Units Research output Activities Projects Prizes Press / Media Search by expertise, name or affiliation Towards a Denotational Theory of Abstract Interpretation Flemming Nielson Research output: Chapter in Book/Report/Conference proceeding \u203a Book chapter \u203a Research \u203a peer-review Overview Original language English Title of host publication Abstract Interpretation of Declarative Languages Publication date 1987 Pages 219-245 Publication status Published - 1987 Access to Document http://www2.imm.dtu.dk/pubdb/p.php?1568 Cite this APA Author BIBTEX Harvard Standard RIS Vancouver Nielson, F. (1987). Towards a \u2026", "num_citations": "18\n", "authors": ["1602"]}
{"title": "A flow-sensitive analysis of privacy properties\n", "abstract": " In this paper we consider service oriented architectures where many components interact with one another using a wireless network. We are interested in questions like: ldr Can I be sure that I do not get unsolicited information from some service? - unless I give my permission? ldr Can I be sure that information I send to some service never is leaked to another service? - unless I give my permission? We shall develop a static program analysis for the pi- calculus and show how it can be used to give privacy guarantees like the ones requested above. The analysis records the explicit information flow of the system and keeps track of, not only the potential configurations of the system, but also the order in which they may be encountered.", "num_citations": "17\n", "authors": ["1602"]}
{"title": "Data flow analysis for CCS\n", "abstract": " Data Flow Analysis as expressed by Monotone Frameworks is often associated with classical imperative programming languages and has played a crucial role in the efficient implementation of these languages. Robin Milner\u2019s Calculus of Communicating Systems, CCS, is concerned with modelling concurrent systems and has mainly been analysed using types and control flow analyses. In the present paper we present an instance of a Monotone Framework together with a novel worklist algorithm for more precisely approximating the flow-sensitive control structure of even infinitary processes expressed in CCS.", "num_citations": "17\n", "authors": ["1602"]}
{"title": "Static validation of a voting protocol\n", "abstract": " The desired security properties of electronic voting protocols include verifiability, accuracy, democracy and fairness. In this paper we use a static program analysis tool to validate these properties for one of the classical voting protocols under appropriate assumptions. The protocol is formalised in an extension of the LySa process calculus with blinding signatures. The analysis, which is fully automatic, pinpoints previously undiscovered flaws related to verifiability and accuracy and we suggest modifications of the protocol needed for validating these properties.", "num_citations": "17\n", "authors": ["1602"]}
{"title": "Behaviour analysis and safety conditions: a case study in CML\n", "abstract": " We describe a case study where novel program analysis technology has been used to pinpoint a subtle bug in a formally developed control program for an embedded system. The main technology amounts to first defining a process algebra (called behaviours) suited to the programming language used (in our case CML) and secondly to devise an annotated type and effect system for extracting behaviours from programs in a such a manner that an automatic inference algorithm can be developed. The case study is a control program developed for the \u201cKarlsruhe Production Cell\u201d and our analysis of the behaviours shows that one of the safety conditions fails to hold.", "num_citations": "17\n", "authors": ["1602"]}
{"title": "Content dependent information flow control\n", "abstract": " Information flow control extends access control by not only regulating who is allowed to access what data but also the subsequent use of the data. Applications within communications systems require such information flow control to be dependent on the actual contents of the data.We develop a combined Hoare logic and type system for enforcing content dependent information flow policies dealing with both integrity and confidentiality. We establish the soundness of the Hoare logic with respect to an instrumented operational semantics and illustrate the development on a running example. We also argue that a well-established approach to non-interference fails to distinguish between integrity and confidentiality.The development is performed for programs written in a concurrent language with synchronous communication and separate data domains.", "num_citations": "16\n", "authors": ["1602"]}
{"title": "Security analysis using flow logics\n", "abstract": " Security. Originated in the 70\u2019s, security of computer systems became soon an essential requirement for many applications, especially in the last decade, due to the widespread diffusion of distributed systems and networks. Mobility is really shaping these systems, leading to new scenarios in which security problems become more and more urgent. The software executed on a computer needs not to be produced for it anymore, as it can also be downloaded from a server, somewhere on the net. Consequently, each computational environment offers a general and distributed platform to programs that can be concurrently executed by users either locally or remotely. This makes it mandatory to fix precise policies for access rights to obtain non-interference and the protection of private information. Moreover, it is necessary to face up to the heterogeneity of administration domains and untrustability of connections, due to geographic distribution: communications between nodes have to be guaranteed, both by making it possible to identify partners during the sessions and by preserving the secrecy and integrity of the data exchanged. To this end specifications for message exchange, called security protocols, are defined on the basis of cryptographic algorithms. Even though carefully designed, protocols may have flaws, allowing malicious agents or intruders to violate security. An intruder, gaining some control over the communication network, is able to intercept or forge or invent messages to convince agents to reveal sensitive information or to believe it is one of the legitimate agents in the session. Cryptography can minimize possible malicious effects.", "num_citations": "16\n", "authors": ["1602"]}
{"title": "Flow logic for process calculi\n", "abstract": " Flow Logic is an approach to statically determining the behavior of programs and processes. It borrows methods and techniques from Abstract Interpretation, Data Flow Analysis and Constraint Based Analysis while presenting the analysis in a style more reminiscent of Type Systems. Traditionally developed for programming languages, this article provides a tutorial development of the approach of Flow Logic for process calculi based on a decade of research. We first develop a simple analysis for the \u03c0-calculus; this consists of the specification, semantic soundness (in the form of subject reduction and adequacy results), and a Moore Family result showing that a least solution always exists, as well as providing insights on how to implement the analysis. We then show how to strengthen the analysis technology by introducing reachability components, interaction points, and localized environments, and finally, we\u00a0\u2026", "num_citations": "15\n", "authors": ["1602"]}
{"title": "Topology-dependent abstractions of broadcast networks\n", "abstract": " Broadcast semantics poses significant challenges over point-to-point communication when it comes to formal modelling and analysis. Current approaches to analysing broadcast networks have focused on fixed connectivities, but this is unsuitable in the case of wireless networks where the dynamically changing network topology is a crucial ingredient. In this paper we develop a static analysis that automatically constructs an abstract transition system, labelled by actions and connectivity information, to yield a mobility-preserving finite abstraction of the behaviour of a network expressed in a process calculus with asynchronous local broadcast. Furthermore, we use model checking based on a 3-valued temporal logic to distinguish network behaviour which differs under changing connectivity patterns.", "num_citations": "15\n", "authors": ["1602"]}
{"title": "Discretionary information flow control for interaction-oriented specifications\n", "abstract": " This paper presents an approach to specify and check discretionary information flow properties of concurrent systems. The approach is inspired by the success of the interaction-oriented paradigm to concurrent systems (cf. choreographies, behavioural types, protocols,...) in providing behavioural guarantees of global properties such as deadlock-absence. We show how some information flow properties are easier to formalise and check on a global interaction-oriented description of a concurrent system rather than on a local process-oriented description of the components of the system. We use a simple choreography description language adapted from the literature of choreographies and session types. We provide a generic method to instrument the semantics with information flow annotations. Policies are used to specify the admissible flows of information. The main contribution of the paper is a sound type\u00a0\u2026", "num_citations": "14\n", "authors": ["1602"]}
{"title": "Model checking is static analysis of modal logic\n", "abstract": " Flow Logic is an approach to the static analysis of programs that has been developed for functional, imperative and object-oriented programming languages and for concurrent, distributed, mobile and cryptographic process calculi. In this paper we extend it to deal with modal logics and prove that it can give an exact characterisation of the semantics of formulae in a modal logic. This shows that model checking can be performed by means of state-of-the-art approaches to static analysis and allow us to conclude that the problems of model checking and static analysis are reducible to each other. In terms of computational complexity we show that model checking by means of static analysis gives the same complexity bounds as are known for traditional approaches to model checking.", "num_citations": "14\n", "authors": ["1602"]}
{"title": "Information flow analysis for VHDL\n", "abstract": " We describe a fragment of the hardware description language VHDL that is suitable for implementing the Advanced Encryption Standard algorithm. We then define an Information Flow analysis as required by the international standard Common Criteria. The goal of the analysis is to identify the entire information flow through the VHDL program. The result of the analysis is presented as a non-transitive directed graph that connects those nodes (representing either variables or signals) where an information flow might occur. We compare our approach to that of Kemmerer and conclude that our approach yields more precise results.", "num_citations": "14\n", "authors": ["1602"]}
{"title": "Experiments with succinct solvers\n", "abstract": " The Succinct Solver of Nielson and Seidl is based on the Alternation-free Least Fixed Point Logic and it is implemented in SML using a combination of recursion, continuations, prefix trees and memoisation. It is known that the actual formulation of the analysis has a great impact on the execution time of the solver and the aim of this note is to provide some insight into which formulations are better than others. The experiments addresses three general issues:(i) the order of the parameters of relations,(ii) the order of conjuncts in preconditions and (iii) the use of memoisation. The experiments are performed for Control Flow Analyses for Discretionary Ambients.", "num_citations": "14\n", "authors": ["1602"]}
{"title": "Operational semantics of termination types\n", "abstract": " In principle termination analysis is easy: find a well-founded ordering and prove that calls decrease with respect to the ordering. We show how to embed termination information into a polymorphic type system for an eager higher-order functional language allowing multiple-argument functions and algebraic data types. The well-founded orderings are defined by pattern matching against the definition of the algebraic data types.We prove that the analysis is semantically sound with respect to a big-step (or natural) operational semantics. We compare our approach based on operational semantics to one based on denotational semantics and we identify the need for extending the semantic universe with new constructs whose sole purpose is to facilitate the proof. For dealing with partial correctness it suffices to consider approximations that are less defined than the desired fixed points; for dealing with total correctness\u00a0\u2026", "num_citations": "14\n", "authors": ["1602"]}
{"title": "Combining static analysis and runtime checking in security aspects for distributed tuple spaces\n", "abstract": " Enforcing security policies to distributed systems is difficult, in particular, to a system containing untrusted components. We designed AspectKE*, an aspect-oriented programming language based on distributed tuple spaces to tackle this issue. One of the key features in AspectKE* is the program analysis predicates and functions that provide information on future behavior of a program. With a dual value evaluation mechanism that handles results of static analysis and runtime values at the same time, those functions and predicates enable the users to specify security policies in a uniform manner. Our two-staged implementation strategy gathers fundamental static analysis information at load-time, so as to avoid performing all analysis at runtime. We built a compiler for AspectKE*, and successfully implemented security aspects for a distributed chat system and an electronic healthcare record workflow system.", "num_citations": "13\n", "authors": ["1602"]}
{"title": "Static analysis of topology-dependent broadcast networks\n", "abstract": " Broadcast semantics poses significant challenges over point-to-point communication when it comes to formal modelling and analysis. Current approaches to analysing broadcast networks have focused on fixed connectivities, but this is unsuitable in the case of wireless networks where the dynamically changing network topology is a crucial ingredient. In this paper, we develop a static analysis that automatically constructs an abstract transition system, labelled by actions and connectivity information, to yield a mobility-preserving finite abstraction of the behaviour of a network expressed in a process calculus with asynchronous local broadcast. Furthermore, we use model checking based on a 3-valued temporal logic to distinguish network behaviour which differs under changing connectivity patterns.", "num_citations": "13\n", "authors": ["1602"]}
{"title": "Flow logic for imperative objects\n", "abstract": " We develop a control flow analysis for the Imperative Object Calculus. We prove the correctness with respect to two Structural Operational Semantics that differ in minor technical ways, and we show that the proofs deviate in major ways as regards their use of proof techniques like coinduction and Kripke-logical relations.", "num_citations": "13\n", "authors": ["1602"]}
{"title": "Prescriptive frameworks for multi-level lambda-calculi\n", "abstract": " Two-level A-calculi have been heavily utilised for applications such as partial evaluation, abstract interpretation and code generation. Each of these applications pose different demands on the exact details of the twolevel structure and the corresponding inference rules. In a previous paper we have developed a descriptive framework for characterizing the key ingredients used in the various applications. Based on the insights offered by this characterisation we now develop a prescriptive framework that offers firm guidelines on what we regard as \"good\" definitions of multi-level lambda-calculi.", "num_citations": "13\n", "authors": ["1602"]}
{"title": "Semantic foundations of data flow analysis\n", "abstract": " Abstract Interpretation (P. Cousot, R. Cousot and others) is a method for program analysis that is able to describe many data flow analyses. We investigate and weaken the assumptions made in abstract interpretation and express abstract interpretation within Denotational Semantics. As an example we specify constant propagation.", "num_citations": "13\n", "authors": ["1602"]}
{"title": "Disjunctive information flow for communicating processes\n", "abstract": " The security validation of practical computer systems calls for the ability to specify and verify information flow policies that are dependent on data content. Such policies play an important role in concurrent, communicating systems: consider a scenario where messages are sent to different processes according to their tagging. We devise a security type system that enforces content-dependent information flow policies in the presence of communication and concurrency. The type system soundly guarantees a compositional noninterference property. All theoretical results have been formally proved in the Coq proof assistant\u00a0[9].", "num_citations": "12\n", "authors": ["1602"]}
{"title": "Analysis of security protocols by annotations\n", "abstract": " The trend in Information Technology is that distributed systems and networks are becoming increasingly important, as most of the services and opportunities that characterise the modern society are based on these technologies. Communication among agents over networks has therefore acquired a great deal of research interest. In order to provide effective and reliable means of communication, more and more communication protocols are invented, and for most of them, security is a significant goal. It has long been a challenge to determine conclusively whether a given protocol is secure or not. The development of formal techniques, eg control flow analyses, that can check various security properties, is an important tool to meet this challenge. This dissertation contributes to the development of such techniques. In this dissertation, security protocols are modelled in the process calculus LYSA. A variety of interesting security properties that protocols are often expected to have are formalised: authentication, confidentiality, freshness, absence of simple and complex type flaws. Those security properties are explicitly specified as annotations embedded in the LYSA syntax. Finally, a number of automatic techniques for the analysis of system behaviour are developed. These techniques are specified as control flow analyses and are, therefore, guaranteed to terminate. The perspectives for the analysis techniques are discussed. Thus the dissertation marks a step forward both for scientists, who gain a general framework for the study of several interesting security properties, and developers, who get a collection of tools that can validate protocols with\u00a0\u2026", "num_citations": "12\n", "authors": ["1602"]}
{"title": "Static validation of licence conformance policies\n", "abstract": " Policy conformance is a security property gaining importance due to commercial interest like Digital Rights Management. It is well known that static analysis can be used to validate a number of more classical security policies, such as discretionary and mandatory access control policies, as well as communication protocols using symmetric and asymmetric cryptography. In this work we show how to develop a Flow Logic for validating the conformance of client software with respect to a licence conformance policy. Our approach is sufficiently flexible that it extends to fully open systems that can admit new services on the fly.", "num_citations": "12\n", "authors": ["1602"]}
{"title": "Succinct solvers\n", "abstract": " We develop a solver algorithm which allows to eciently compute the optimal model of a very expressive fragment of predicate logic. The succinct formulation of the algorithm is due to the disciplined use of continuations and memoisation. This facilitates giving a precise characterisation of the behaviour of the solver and to develop a complexity calculation which allows to obtain its formal complexity. Practical evaluations on a control-flow analysis of the ambient calculus shows a good match between theory and practice.", "num_citations": "12\n", "authors": ["1602"]}
{"title": "Semantics-directed program analysis: A tool-maker's perspective\n", "abstract": " Developing a tool kit for program analysis requires a general metalanguage (or user interface) in which to specify the program analyses, and many past and current approaches are semantics-directed in the sense that they attempt to exploit the structure of the semantics of the program. In this paper we take a tool-maker's perspective at an approach based on two-level semantics, focusing on the flexible way to incorporate and combine a repertoire of program analyses. We conclude by identifying a number of key considerations for the design of semantics-directed frameworks or tool kits for program analysis.", "num_citations": "12\n", "authors": ["1602"]}
{"title": "Polymorphic subtyping for effect analysis: The dynamic semantics\n", "abstract": " We study an annotated type and effect system that integrates let-polymorphism, effects, and subtyping into an annotated type and effect system for a fragment of Concurrent ML. First a small-step operational semantics is defined and next the annotated type and effect system is proved semantically sound. This provides insights into the rule for generalisation in the annotated type and effect system.", "num_citations": "12\n", "authors": ["1602"]}
{"title": "Model checking exact cost for attack scenarios\n", "abstract": " Attack trees constitute a powerful tool for modelling security threats. Many security analyses of attack trees can be seamlessly expressed as model checking of Markov Decision Processes obtained from the attack trees, thus reaping the benefits of a coherent framework and a mature tool support. However, current model checking does not encompass the exact cost analysis of an attack, which is standard for attack trees.                 Our first contribution is the logic erPCTL with cost-related operators. The extended logic allows to analyse the probability of an event satisfying given cost bounds and to compute the exact cost of an event. Our second contribution is the model checking algorithm for erPCTL. Finally, we apply our framework to the analysis of attack trees.", "num_citations": "11\n", "authors": ["1602"]}
{"title": "Context dependent analysis of bioambients\n", "abstract": " BioAmbients is a derivative of mobile ambients that has shown promise of describing interesting features of the behaviour of biological systems. The technical contribution of this paper is to extend the Flow Logic approach to static analysis with a couple of new techniques in order to give precise information about the behaviour of systems written in BioAmbients. Applying the development to a simple model of a cell releasing nutrients from food compunds we illustrate how the proposed analysis does indeed improve on previous efforts.", "num_citations": "11\n", "authors": ["1602"]}
{"title": "Behavior analysis for validating communication patterns\n", "abstract": " behaviors               ; these can be viewed as a kind of causal constraints or as a kind of process algebra terms. We present a system that infers behaviors from a useful fragment of Concurrent ML programs; it is based on previously developed theoretical results and forms the core of a system available on the Internet. By means of a case study, used as a benchmark in the literature, we shall see that the system facilitates the validation of certain safety conditions for reactive programs.", "num_citations": "11\n", "authors": ["1602"]}
{"title": "Using transformations in the implementation of higher-order functions\n", "abstract": " Traditional functional languages do not have an explicit distinction between binding times. It arises implicitly, however, as one typically instantiates a higher-order function with the arguments that are known, whereas the unknown arguments remain to be taken as parameters. The distinction between \u2018known\u2019 and \u2018unknown\u2019 is closely related to the distinction between binding times like \u2018compile-time\u2019 and \u2018run-time\u2019. This leads to the use of a combination of polymorphic type inference and binding time analysis for obtaining the required information about which arguments are known.Following the current trend in the implementation of functional languages we then transform the run-time level of the program (not the compile-time level) into categorical combinators. At this stage we have a natural distinction between two kinds of program transformations: partial evaluation, which involves the compile-time level of our\u00a0\u2026", "num_citations": "11\n", "authors": ["1602"]}
{"title": "Process-local static analysis of synchronous processes\n", "abstract": " We develop a modular approach to statically analyse imperative processes communicating by synchronous message passing. The approach is modular in that it only needs to analyze one process at a time, but will in general have to do so repeatedly. The approach combines lattice-valued regular expressions to capture network communication with a dedicated shuffle operator for composing individual process analysis results. We present both a soundness proof and a prototype implementation of the approach for a synchronous subset of the Go programming language. Overall our approach tackles the combinatorial explosion of concurrent programs by suitable static analysis approximations, thereby lifting traditional sequential analysis techniques to a concurrent setting.", "num_citations": "10\n", "authors": ["1602"]}
{"title": "A parametric abstract domain for lattice-valued regular expressions\n", "abstract": " We present a lattice-valued generalization of regular expressions as an abstract domain for static analysis. The parametric abstract domain rests on a generalization of Brzozowski derivatives and works for both finite and infinite lattices. We develop both a co-inductive, simulation algorithm for deciding ordering between two domain elements and a widening operator for the domain. Finally we illustrate the domain with a static analysis that analyses a communicating process against a lattice-valued regular expression expressing the environment\u2019s network communication.", "num_citations": "10\n", "authors": ["1602"]}
{"title": "Hoare logic for disjunctive information flow\n", "abstract": " Information flow control extends access control by not only regulating who is allowed to access what data but also the subsequent use of the data accessed. Applications within communication networks require such information flow control to depend on the actual data. For a concurrent language with synchronous communication and separate data domains we develop a Hoare logic for enforcing disjunctive information flow policies. We establish the soundness of the Hoare logic with respect to an operational semantics and illustrate the development on a running example.", "num_citations": "10\n", "authors": ["1602"]}
{"title": "Probabilistic analysis of the quality calculus\n", "abstract": " We consider a fragment of the Quality Calculus, previously introduced for defensive programming of software components such that it becomes natural to plan for default behaviour in case the ideal behaviour fails due to unreliable communication.               This paper develops a probabilistically based trust analysis supporting the Quality Calculus. It uses information about the probabilities that expected input will be absent in order to determine the trustworthiness of the data used for controlling the distributed system; the main challenge is to take accord of the stochastic dependency between some of the inputs. This takes the form of a relational static analysis dealing with quantitative information.", "num_citations": "10\n", "authors": ["1602"]}
{"title": "Safety versus security in the quality calculus\n", "abstract": " Safety and security are both needed for ensuring that cyber-physical systems live up to expectations, but often an intelligent trade-off is called for, because sometimes it is impossible to obtain optimal safety at the same time as optimal security. In the context of the Quality Calculus we develop a type system for checking the extent to which safety and security goals have been met.             Safety goals include showing that certain error configurations are in fact not reachable and hence do not require intelligent error handling.             Security goals include showing that highly trusted communications can only be performed in highly trusted contexts. This is potentially too demanding and the Quality Calculus is therefore extended with a primitive for endorsing data to a higher trust level (accepting violations of the explicit flow) and for temporarily asserting a higher trust in the context (accepting violations of the implicit\u00a0\u2026", "num_citations": "10\n", "authors": ["1602"]}
{"title": "Performance evaluation of security protocols specified in LySa\n", "abstract": " We use a special operational semantics which drives us in inferring quantitative measures on system describing cryptographic protocols. The transitions of the system carry enhanced labels. We assign rates to transitions by only looking at these labels. The rates reflect the distributed architecture running applications and the use of possibly different cryptosystems. We then map transition systems to Markov chains and evaluate performance of systems, using standard tools.", "num_citations": "10\n", "authors": ["1602"]}
{"title": "Termination analysis based on operational semantics\n", "abstract": " In principle termination analysis is easy: find a well-founded partial order and prove that calls decrease with respect to this order. In practice this often requires an oracle (or a theorem prover) for determining the well-founded order and this oracle may not be easily implementable. Our approach circumvents some of these problems by exploiting the inductive definition of algebraic data types and using pattern matching as in functional languages. We develop a termination analysis for a higher-order functional language; the analysis incorporates and extends polymorphic type inference and axiomatizes a class of well-founded partial orders for multiple-argument functions (as in Standard ML and Miranda). Semantics is given by means of operational (natural-style) semantics and soundness is proved; this involves making extensions to the semantic universe and we relate this to the techniques of denotational semantics. For dealing with the partiality aspects of the soundness proof, it suffices to incorporate approximations to the desired fixed points; for dealing with the totality aspects of the soundness proof, we also have to incorporate functions that are forced to terminate (in a way that might violate the monotonicity of denotational semantics).", "num_citations": "10\n", "authors": ["1602"]}
{"title": "Inference systems for binding time analysis\n", "abstract": " We consider the problem of introducing a distinction between binding times (eg compiletime and run-time) into functional languages. It is well-known that such a distinction is important for the e cient implementation of imperative languages 1] and more recent results show that the performance of functional languages may be improved by using binding time information (eg 11, 6]).There are several approaches to the speci cation of binding time analysis. Some approaches are based on variants of abstract interpretation (eg 2, 3, 5]), others are based on projection analysis (eg 7]) and yet others (eg 9, 10]) use non-standard type systems and develop corresponding type inference algorithms. In this paper we shall take a logical approach and aim at constructing an algorithm for generating a set of constraints to be solved. In this way we will be able to make full use of substitutions as in ordinary type inference 8]| this is contrary to other algorithms (eg 9]) where extra recursive calls have to be performed.", "num_citations": "10\n", "authors": ["1602"]}
{"title": "Context information for lazy code generation\n", "abstract": " Functional languages like Miranda and Haskell employ a non-strict semantics. This is important for the functional programming style as it allows one to compute with infinite data structures. However, a straightforward implementation of the language will result in a rather inefficient implementation and therefore it is often combined with strictness analysis. A sticky version of the analysis is used to collect the information and annotate the program so that the information can be used by the subsequent passes of the compiler. The strictness analysis and its correctness properties are well understood by means of abstract interpretation whereas its sticky version is more subtle.\u2014The purpose of the present paper is therefore to investigate how far one can go without introducing a sticky version of the analysis and thereby avoid the correctness problems connected with it.", "num_citations": "10\n", "authors": ["1602"]}
{"title": "Correctness of code generation from a two-level meta-language\n", "abstract": " We present a two-level denotational metalanguage suitable for defining programming languages with procedures as second class citizens. Code generation is developed for a slight restriction of this metalanguage and this generalizes previous algebraic approaches. This paper focuses on the correctness proof of the code generation; in particular the method used for directly proving equivalence between an operational and a denotational semantics and the modification of Reynolds' idea of a relational functor.", "num_citations": "10\n", "authors": ["1602"]}
{"title": "Secure information release in timed automata\n", "abstract": " One of the key demands of cyberphysical systems is that they meet their safety goals. Timed automata has established itself as a formalism for modeling and analyzing the real-time safety aspects of cyberphysical systems. Increasingly it is also demanded that cyberphysical systems meet a number of security goals for confidentiality and integrity. Notions of security based on Information flow control, such as non-interference, provide strong guarantees that no information is leaked; however, many cyberphysical systems leak intentionally some information in order to achieve their purposes.                 In this paper, we develop a formal approach of information flow for timed automata that allows intentional information leaks. The security of a timed automaton is then defined using a bisimulation relation that takes account of the non-determinism and the clocks of timed automata. Finally, we define an algorithm that\u00a0\u2026", "num_citations": "9\n", "authors": ["1602"]}
{"title": "Denial-of-service security attack in the continuous-time world\n", "abstract": " Hybrid systems are integrations of discrete computation and continuous physical evolution. The physical components of such systems introduce safety requirements, the achievement of which asks for the correct monitoring and control from the discrete controllers. However, due to denial-of-service security attack, the expected information from the controllers is not received and as a consequence the physical systems may fail to behave as expected. This paper proposes a formal framework for expressing denial-of-service security attack in hybrid systems. As a virtue, a physical system is able to plan for reasonable behavior in case the ideal control fails due to unreliable communication, in such a way that the safety of the system upon denial-of-service is still guaranteed. In the context of the modeling language, we develop an inference system for verifying safety of hybrid systems, without putting any\u00a0\u2026", "num_citations": "9\n", "authors": ["1602"]}
{"title": "Strictness and totality analysis\n", "abstract": " We define a novel inference system for strictness and totality analysis for the simply-typed lazy lambda-calculus with constants and fixpoints. Strictness information identifies those terms that definitely denote bottom (i.e. do not evaluate to WHNF) whereas totality information identifies those terms that definitely do not denote bottom (i.e. do evaluate to WHNF). The analysis is presented as an annotated type system allowing conjunctions at \u201ctop-level\u201d only. We give examples of its use and prove the correctness with respect to a natural-style operational semantics.", "num_citations": "9\n", "authors": ["1602"]}
{"title": "Model checking multivariate state rewards\n", "abstract": " We consider continuous stochastic logics with state rewards that are interpreted over continuous time Markov chains. We show how results from multivariate phase type distributions can be used to obtain higher-order moments for multivariate state rewards (including covariance). We also generalise the treatment of eventuality to unbounded path formulae. For all extensions we show how to obtain closed form definitions that are straightforward to implement and we illustrate our development on a small example.", "num_citations": "8\n", "authors": ["1602"]}
{"title": "Protocol stacks for services\n", "abstract": " We show how to model service-oriented applications using process algebras such that, on the one hand, we can achieve a certain level of abstraction without being overwhelmed by the underlying implementation details and, on the other hand, we respect the concrete industrial standards used for implementing the service-oriented applications. By doing so, we will be able to not only reason about applications at different levels of abstractions, but also to build a bridge between the views of researchers on formal methods and developers in industry. We apply our approach to an industrial case study taken from the EU funded project SENSORIA.", "num_citations": "8\n", "authors": ["1602"]}
{"title": "Cryptographic pattern matching\n", "abstract": " We construct a language extension for process calculi for modelling the exchange of cryptographically composed data. More specifically, we devise a succinct syntax for terms and patterns that captures the intention behind perfect cryptography. The proposed language extension is independent of the choice of process calculus and is applicable to any calculus that supports exchange of data. Initially we restrict the model to symmetric cryptography, but we also show how it can be extended with support for asymmetric encryption and digital signatures.", "num_citations": "8\n", "authors": ["1602"]}
{"title": "Locality-based security policies\n", "abstract": " Information flow security provides a strong notion of end-to-end security in computing systems. However sometimes the policies for information flow security are limited in their expressive power, hence complicating the matter of specifying policies even for simple systems. These limitations often become apparent in contexts where confidential information is released under specific conditions.             We present a novel policy language for expressing permissible information flow under expressive constraints on the execution traces for programs. Based on the policy language we propose a security condition shown to be a generalized intransitive non-interference condition. Furthermore a flow-logic based static analysis is presented and shown capable of guaranteeing the security of programs analysed.", "num_citations": "8\n", "authors": ["1602"]}
{"title": "Forced transformation of occam programs\n", "abstract": " One way of exploiting parallelism is to convert existing sequential solutions in such a way that the available parallelism is used. This may be done by program transformations as specified by certain laws of the programming language, in this case Occam. The contribution of the paper is to propose a technique that may be used to direct which laws to apply at which points to obtain improved efficiency (and to avoid undoing improvements made in the past).", "num_citations": "8\n", "authors": ["1602"]}
{"title": "2-level \u03bb-lifting\n", "abstract": " The process of \u03bb-lifting (or bracket abstraction) translates expressions in a typed \u03bb-calculus into expressions in a typed combinator language. This is of interest because it shows that the \u03bb-calculus and the combinator language are equally expressive (as the translation from combinators to \u03bb-expressions is rather trivial). This paper studies the similar problems for 2-level \u03bb-calculi and 2-level combinator languages. The 2-level nature of the type system enforces a formal distinction between binding times, e.g. between computations at compile-time and computations at run-time. In this setting the natural formulations of 2-level \u03bb-calculi and 2-level combinator languages turn out not to be equally expressive. The translation into 2-level \u03bb-calculus is straight-forward but the 2-level \u03bb-calculus is too powerful for \u03bb-lifting to succeed. We then develop a restriction of the 2-level \u03bb-calculus for which \u03bb-lifting succeeds and\u00a0\u2026", "num_citations": "8\n", "authors": ["1602"]}
{"title": "Static analysis for proactive security\n", "abstract": " We reflect on current problems and practices in system security, distinguishing between reactive security\u00a0\u2013\u00a0which deals with vulnerabilities as they are being exploited\u00a0\u2013\u00a0and proactive security\u00a0\u2013\u00a0which means to make vulnerabilities un-exploitable by removing them from a system entirely. Then we argue that static analysis is well poised to support approaches to proactive security, since it is sufficiently expressive to represent many vulnerabilities yet sufficiently efficient to detect vulnerabilities prior to system deployment. We further show that static analysis interacts well with both confidentiality and integrity aspects and discuss what security assurances it can attain. Next we argue that security models such as those for access control can also be statically analyzed to support proactive security of such models. Finally, we identify research problems in static analysis whose solutions would stand to improve the\u00a0\u2026", "num_citations": "7\n", "authors": ["1602"]}
{"title": "Information flow for timed automata\n", "abstract": " One of the key demands of cyberphysical systems is that they meet their safety goals. Timed Automata has established itself as a formalism for modelling and analysing the real-time safety aspects of cyberphysical systems. Increasingly it is also demanded that cyberphysical systems meet a number of security goals for confidentiality and integrity. Information Flow Control is an approach to ensuring that there are no flows of information that violate the stated security policy.                 We develop a language based approach to the modelling and analysis of timed systems that allows to incorporate considerations of information flow control. We define a type system for information flow that takes account of the non-determinism and clocks of timed systems. The adequacy of the type system is ensured by means of a non-interference result.", "num_citations": "7\n", "authors": ["1602"]}
{"title": "Availability by design: a complementary approach to denial-of-service\n", "abstract": " In computer security, a Denial-of-Service (DoS) attack aims at making a resource unavailable. DoS attacks to systems of public concern occur increasingly and have become infamous on the Internet, where they have targeted major corporations and institutions, thus reaching the general public. There exist various practical techniques to face DoS attacks and mitigate their effects, yet we witness the successfulness of many.", "num_citations": "7\n", "authors": ["1602"]}
{"title": "Explicit versus symbolic algorithms for solving ALFP constraints\n", "abstract": " ALFP, Alternation-free Least Fixed Point logic, has successfully been used as an intermediate language in the implementation of static analysis and model checking problems. Clearly different analysis problems may give rise to ALFP clauses with different characteristics. There are also different approaches to solving ALFP clauses and some of those are better suited for certain kinds of clauses than others. The aim of this paper is to present two algorithms, one that is based on differential worklists and one based on BDD's, and experiment with them.", "num_citations": "7\n", "authors": ["1602"]}
{"title": "Relational analysis for delivery of services\n", "abstract": " Many techniques exist for statically computing properties of the evolution of processes expressed in process algebras. Static analysis has shown how to obtain useful results that can both be checked and computed in polynomial time. In this paper we develop a static analysis in relational form which substantially improves the precision of the results obtained while being able to deal with the full generality of the syntax of processes. The analysis reveals a feasible complexity for practical examples and gives rise to a fast prototype. We use this prototype to automatically prove the correct delivery of messages for the implementation of an accident service, which is based on multiplexed communication, a crucial feature of global computing applications.", "num_citations": "7\n", "authors": ["1602"]}
{"title": "Layered predicates\n", "abstract": " We review the concept of logical relations and how they interact with structural induction; furthermore we give examples of their use, and of particular interest is the combination with the PER-idea (partial equivalence relations). This is then generalized to Kripke-logical relations; the major application is to show that in combination with the PER-idea this solves the problem of establishing a substitution property in a manner conducive to structural induction. Finally we introduce the concept of Kripke-layered predicates; this allows a modular definition of predicates and supports a methodology of \u201cproofs in stages\u201d where each stage focuses on only one aspect and thus is more manageable. All of these techniques have been tested and refined in \u201crealistic applications\u201d that have been documented elsewhere.", "num_citations": "7\n", "authors": ["1602"]}
{"title": "Future-dependent flow policies with prophetic variables\n", "abstract": " Content-dependency often plays an important role in the information flow security of real world IT systems. Content-dependency gives rise to informative policies and permissive static enforcement, and sometimes avoids the need for downgrading. We develop a static type system to soundly enforce future-dependent flow policies---policies that can depend on not only the current values of variables, but also their final values. The final values are referred to using what we call prophetic variables, just as the initial values can be referenced using logical variables in Hoare logic. We develop and enforce a notion of future-dependent security for open systems, in the spirit of\" non-deducibility on strategies\". We also illustrate our approach in scenarios where future-dependency has advantages over present-dependency and avoids mixtures of upgradings and downgradings.", "num_citations": "6\n", "authors": ["1602"]}
{"title": "Recursive advice for coordination\n", "abstract": " Aspect-oriented programming is a programming paradigm that is often praised for the ability to create modular software and separate cross-cutting concerns. Recently aspects have been also considered in the context of coordination languages, offering similar advantages. However, introducing aspects makes analyzing such languages more difficult due to the fact that aspects can be recursive \u2014 advice from an aspect must itself be analyzed by aspects \u2014 as well as being simultaneously applicable in concurrent threads. Therefore the problem of reachability of various states of a system becomes much more challenging. This is important since ensuring that a system does not contain errors is often equivalent to proving that some states are not reachable.             In this paper we show how to solve these challenges by applying a successful technique from the area of software model checking, namely\u00a0\u2026", "num_citations": "6\n", "authors": ["1602"]}
{"title": "Characteristics of key update strategies for wireless sensor networks\n", "abstract": " Wireless sensor networks offer the advantages of simple and low-resource communication. Challenged by this simplicity and low-resources, security is of particular importance in many cases such as transmission of sensitive data or strict requirements of tamper-resistance. Updating the security keys is one of the essential points in security, which restrict the amount of data that may be exposed when a key is compromised. In this paper, we investigate key update methods that may be used in wireless sensor networks, and benefiting from stochastic model checking we derive characteristics of these methods in security perspective.", "num_citations": "6\n", "authors": ["1602"]}
{"title": "Finiteness conditions for strictness analysis\n", "abstract": " We give upper bounds on the number of times the fixed point operator needs to be unfolded for strictness analysis of functional languages with lists. This extends previous work both in the syntax-directed nature of the approach and in the ability to deal with Wadler's method for analysing lists. Limitations of the method are indicated.", "num_citations": "6\n", "authors": ["1602"]}
{"title": "Time dependent policy-based access control\n", "abstract": " Access control policies are essential to determine who is allowed to access data in a system without compromising the data's security. However, applications inside a distributed environment may require those policies to be dependent on the actual content of the data, the flow of information, while also on other attributes of the environment such as the time. In this paper, we use systems of Timed Automata to model distributed systems and we present a logic in which one can express time-dependent policies for access control. We show how a fragment of our logic can be reduced to a logic that current model checkers for Timed Automata such as UPPAAL can handle and we present a translator that performs this reduction. We then use our translator and UPPAAL to enforce time-dependent policy-based access control on an example application from the aerospace industry.", "num_citations": "5\n", "authors": ["1602"]}
{"title": "Modelling and Analysing Socio-Technical Systems.\n", "abstract": " Modeling and Analysing Socio-Technical Systems Page 1 Modeling and Analysing Socio-Technical Systems Zaruhi Aslanyan, Marieta G. Ivanova, Flemming Nielson, Christian W. Probst DTU Compute, Technical University of Denmark STPIS 2015, poster session 09th June 2015 Page 2 The Challenge Organisations are complex socio-technical systems They consist of a mixture of physical infrastructure, human actors, policies and processes Attacks exploit vulnerabilities on all different levels Many risk assessment methods abstract away the internal structure and ignore human factors Marieta G. Ivanova (DTU) Socio-Technical System Attacks STPIS 2015 Analyse the security properties of the model Marieta G. Ivanova (DTU) Socio-Technical System Attacks STPIS 2015 09.06.2015 3 / 9 Page 4 Use Case Scenario Attack goal: \u2026", "num_citations": "5\n", "authors": ["1602"]}
{"title": "Klaim-db: A modeling language for distributed database applications\n", "abstract": " We present the modelling language, Klaim-DB, for distributed database applications. Klaim-DB borrows the distributed nets of the coordination language Klaim but essentially re-incarnates the tuple spaces of Klaim as databases, and provides high-level language abstractions for the access and manipulation of structured data, with integrity and atomicity considerations. We present the formal semantics of Klaim-DB and illustrate the use of the language in a scenario where the sales from different branches of a chain of department stores are aggregated from their local databases. It can be seen that raising the abstraction level and encapsulating integrity checks (concerning the schema of tables, etc.) in the language primitives for database operations benefit the modelling task considerably.", "num_citations": "5\n", "authors": ["1602"]}
{"title": "Galois connections for flow algebras\n", "abstract": " We generalise Galois connections from complete lattices to flow algebras. Flow algebras are algebraic structures that are less restrictive than idempotent semirings in that they replace distributivity with monotonicity and dispense with the annihilation property; therefore they are closer to the approach taken by Monotone Frameworks and other classical analyses. We present a generic framework for static analysis based on flow algebras and program graphs. Program graphs are often used in Model Checking to model concurrent and distributed systems. The framework allows to induce new flow algebras using Galois connections such that correctness of the analyses is preserved. The approach is illustrated for a mutual exclusion algorithm.", "num_citations": "5\n", "authors": ["1602"]}
{"title": "AspectKE*: security aspects with program analysis for distributed systems\n", "abstract": " Enforcing security policies to distributed systems is dif\ufb01cult, in particular, when a system contains untrusted components. We designed AspectKE*, a distributed AOP language based on a tuple space, to tackle this issue. In AspectKE*, aspects can enforce access control policies that depend on future behavior of running processes. One of the key language features is the predicates and functions that extract results of static program analysis, which are useful for de\ufb01ning security aspects that have to know about future behavior of a program. AspectKE* also provides a novel variable binding mechanism for pointcuts, so that pointcuts can uniformly specify join points based on both static and dynamic information about the program. Our implementation strategy performs fundamental static analysis at load-time, so as to retain runtime overheads minimal. We implemented a compiler for AspectKE*, and demonstrate usefulness of AspectKE* through a security aspect for a distributed chat system.", "num_citations": "5\n", "authors": ["1602"]}
{"title": "Aspects with program analysis for security policies\n", "abstract": " Enforcing security policies to IT systems, especially for a mobile distributed system, is challenging. As society becomes more IT-savvy, our expectations about security and privacy evolve. This is usually followed by changes in regulation in the form of standards and legislation. In many cases, small modification of the security requirement might lead to substantial changes in a number of modules within a large mobile distributed system. Indeed, security is a crosscutting concern which can spread to many business modules within a system, and is difficult to be integrated in a modular way.This dissertation explores the principles of adding challenging security policies to existing systems with great flexibility and modularity. The policies concerned cover both classical access control and explicit information flow policies. We built our solution by combining aspect-oriented programming techniques with static program analysis techniques. The former technique can separate security concerns out of the main logic, and thus improves system modularity. The latter can analyze the system behavior, and thus helps detect software bugs or potential malicious code.", "num_citations": "5\n", "authors": ["1602"]}
{"title": "A scalable inclusion constraint solver using unification\n", "abstract": " We describe a parameterized framework with which users can take advantage of unification over analysis variables to implement efficient or precise analyses, or even both. To be illustrative we instantiate the framework with reaching definition analysis and conduct a systematic evaluation of performance and precision of the analysis. We compare our result with that of a state-of-the-art solver, the Succinct Solver and show our solver is at least 10-times faster than the Succinct Solver. On some benchmarks linearity is reached by the use of unification. Although the result of unification is often imprecise, a heuristic study is conducted to detect where the loss of precision may happen. We apply the heuristics on benchmarks and achieve not only efficient but also precise analysis.", "num_citations": "5\n", "authors": ["1602"]}
{"title": "06161 Working Groups' Report: The Challlenge of Combining Simulation and Verification\n", "abstract": " Simulation has found widespread use for experimentation and exploration of the possible impacts of a variety of conditions on a system. In contrast, formal verification is concerned with proving or disproving the correctness of a system with respect to a certain property, using mathematical and logical methods.", "num_citations": "5\n", "authors": ["1602"]}
{"title": "Analyzing for absence of timing leaks in VHDL\n", "abstract": " Analyzing for Absence of Timing Leaks in VHDL \u2014 DTU Research Database Skip to main navigation Skip to search Skip to main content DTU Research Database Logo About DTU Orbit Home Profiles Research Units Research Output Activities Projects Prizes Press / Media Search by expertise, name or affiliation Analyzing for Absence of Timing Leaks in VHDL Terkel Kristian Tolstrup, Flemming Nielson Research output: Chapter in Book/Report/Conference proceeding \u203a Article in proceedings \u203a Research \u203a peer-review Overview Original language English Title of host publication WITS'06 Publication date 2006 Publication status Published - 2006 Event 6th International Workshop on Issues in Theory of Security - Vienna, Austria Duration: 25 Mar 2006 \u2192 26 Mar 2006 Conference number: 6 Workshop Workshop 6th International Workshop on Issues in Theory of Security Number 6 Country Austria City Vienna Period 25/\u2026", "num_citations": "5\n", "authors": ["1602"]}
{"title": "On evaluating the performance of security protocols\n", "abstract": " We use an enhanced operational semantics to infer quantitative measures on systems describing cryptographic protocols. System transitions carry enhanced labels. We assign rates to transitions by only looking at these labels. The rates reflect the distributed architecture running applications and the use of possibly different crypto-systems. We then map transition systems to Markov chains and evaluate performance of systems, using standard tools.", "num_citations": "5\n", "authors": ["1602"]}
{"title": "Strictness and totality analysis\n", "abstract": " We define a novel inference system for strictness and totality analysis for the simply-typed lazy lambda-calculus with constants and fixpoints. Strictness information identifies those terms that definitely denote bottom (ie do not evaluate to WHNF) whereas totality information identifies those terms that definitely do not denote bottom (ie do evaluate to WHNF). The analysis is presented as an annotated type system allowing conjunctions at? top-level? only. We give examples of its use and prove the correctness with respect to a natural-style operational semantics.", "num_citations": "5\n", "authors": ["1602"]}
{"title": "Timing leaks and coarse-grained clocks\n", "abstract": " Timing-based side-channel attacks have matured from an academic exercise to a powerful attack vector in the hand of real-world adversaries. A widely deployed countermeausure against such attacks is to reduce the accuracy of the clocks that are available to adversaries. While a number of high-profile attacks show that this mitigation can be side-stepped, there has not been a principled analysis of the degree of security it provides until now. In this paper, we perform the first information-flow analysis with respect to adversaries with coarse-grained clocks. To this end, we define an adversary model that is parametric in the granularity of the clock and connect it with a system model based on timed automata. We present algorithms for translating such a system to an information-theoretic channel, which enables us to analyze the leakage using standard techniques from quantitative information-flow analysis. We use our\u00a0\u2026", "num_citations": "4\n", "authors": ["1602"]}
{"title": "How to trust the re-use of data\n", "abstract": " Research in natural sciences and life sciences involve carrying out experiments to collect data as well as carrying out analysis to interpret the data. Increasingly data is being made available to other scientists in big databases. The scientific process builds on the idea that research results can be independently validated by other researchers. However, the concern about the correct re-use of data is also increasing. As illustrated by a currently evolving case of alleged scientific mispractice there is a need to support a reliable re-use of data. To solve this challenge we introduce an enriched coordination language based on Klaim, that can model the coordination of the re-use of data in the research community. We define the formal semantics of our language and develop a static analysis that can be used to check whether we have a trustable re-use of\u00a0data.", "num_citations": "4\n", "authors": ["1602"]}
{"title": "The guided system development framework: Modeling and verifying communication systems\n", "abstract": " In a world that increasingly relies on the Internet to function, application developers rely on the implementations of protocols to guarantee the security of data transferred. Whether a chosen protocol gives the required guarantees, and whether the implementation does the same, is usually unclear. The Guided System Development framework contributes to more secure communication systems by aiding the development of such systems. The framework features a simple modelling language, step-wise refinement from models to implementation, interfaces to security verification tools, and code generation from the verified specification. The refinement process carries thus security properties from the model to the implementation. Our approach also supports verification of systems previously developed and deployed. Internally, the reasoning in our framework is based on the Beliefs and Knowledge tool, a\u00a0\u2026", "num_citations": "4\n", "authors": ["1602"]}
{"title": "Quantitative modelling and analysis of a Chinese smart grid: a stochastic model checking case study\n", "abstract": " Cyber-physical systems integrate information and communication technology with the physical elements of a system, mainly for monitoring and controlling purposes. The conversion of traditional power grid into a smart grid, a fundamental example of a cyber-physical system, raises a number of issues that require novel methods and applications. One of the important issues in this context is the verification of certain quantitative properties of the system. In this paper, we consider a specific Chinese smart grid implementation as a case study and address the verification problem for performance and energy consumption. We employ stochastic model checking approach and present our modelling and analysis study using PRISM model checker.", "num_citations": "4\n", "authors": ["1602"]}
{"title": "The stochastic quality calculus\n", "abstract": " We introduce the Stochastic Quality Calculus in order to model and reason about distributed processes that rely on each other in order to achieve their overall behaviour. The calculus supports broadcast communication in a truly concurrent setting. Generally distributed delays are associated with the outputs and at the same time the inputs impose constraints on the waiting times. Consequently, the expected inputs may not be available when needed and therefore the calculus allows to express the absence of data.               The communication delays are expressed by general distributions and the resulting semantics is given in terms of Generalised Semi-Markov Decision Processes. By restricting the distributions to be continuous and by allowing truly concurrent communication we eliminate the non-determinism and arrive at Generalised Semi-Markov Processes (GSMPs); further restriction to exponential\u00a0\u2026", "num_citations": "4\n", "authors": ["1602"]}
{"title": "Lazy mobile intruders\n", "abstract": " We present a new technique for analyzing platforms that execute potentially malicious code, such as web-browsers, mobile phones, or virtualized infrastructures. Rather than analyzing given code, we ask what code an intruder could create to break a security goal of the platform. To avoid searching the infinite space of programs that the intruder could come up with (given some initial knowledge) we adapt the lazy intruder technique from protocol verification: the code is initially just a process variable that is getting instantiated in a demand-driven way during its execution. We also take into account that by communication, the malicious code can learn new information that it can use in subsequent operations, or that we may have several pieces of malicious code that can exchange information if they \u201cmeet\u201d. To formalize both the platform and the malicious code we use the mobile ambient calculus, since it\u00a0\u2026", "num_citations": "4\n", "authors": ["1602"]}
{"title": "Qualitative and quantitative security analyses for zigbee wireless sensor networks\n", "abstract": " Wireless sensor networking is a challenging and emerging technology that will soon become an inevitable part of our modern society. Today wireless sensor networks are broadly used in industrial and civilian application areas including environmental monitoring, surveillance tasks, healthcare applications, home automation, and traffic control. The challenges for research in this area are due to the unique features of wireless sensor devices such as low processing power and associated low energy. On top of this, wireless sensor networks need secure communication as they operate in open fields or unprotected environments and communicate on broadcasting technology. As a result, such systems have to meet a multitude of quantitative constraints (eg timing, power consumption, memory usage, communication bandwidth) as well as security requirements (eg authenticity, confidentiality, integrity). One of the main challenges arise in dealing with the security needs of such systems where it is less likely that absolute security guarantees can be sustained-because of the need to balance security against energy consumption in wireless sensor network standards like ZigBee. This dissertation builds on existing methods and techniques in different areas and brings them together to create an efficient verification system. The overall ambition is to provide a wide range of powerful techniques for analyzing models with quantitative and qualitative security information. We stated a new approach that first verifies low level security protocol s in a qualitative manner and guarantees absolute security, and then takes these verified protocols as actions of scenarios\u00a0\u2026", "num_citations": "4\n", "authors": ["1602"]}
{"title": "Enforcing Mandatory Access Control in Distributed Systems using Aspect-Orientation\n", "abstract": " The inclusion of security policies in distributed systems requires special care. We consider here a multilevel access control policy, the Bell-LaPadula model, and how to incorporate it in a distributed programming environment based on the coordination paradigm. Aspect orientation has proved to be a flexible and adaptable way to deal with security policies in such environments. One such design focuses on avoiding future misuses of data rather than misuses based on past performance. We scrutinize this design, point out some flaws when trying to capture Bell-LaPadula and extend the framework for being able to propose a new design that elegantly captures the intentions of the Bell-LaPadula multilevel access control policy.", "num_citations": "4\n", "authors": ["1602"]}
{"title": "Static analysis for blinding\n", "abstract": " The classical key distribution protocols are based on symmetric and asymmetric encryption as well as digital signatures. Protocols with different purposes often requires different cryptographic primitives, an example is electronic voting protocols which are often based on the cryptographic operation blinding. In this paper we study the theoretical foundations for one of the successful approaches to validating cryptographic protocols and we extend it to handle the blinding primitive. Our static analysis approach is based on Flow Logic; this gives us a clean separation between the specification of the analysis and its realisation in an automatic tool. We concentrate on the former in the present paper and provide the semantic foundation for our analysis of protocols using blinding - also in the presence of malicious attackers.", "num_citations": "4\n", "authors": ["1602"]}
{"title": "Data Structures in the succinct Solver (V1. 0)\n", "abstract": " Data Structures in the Succinct Solver (V1.0) \u2014 Welcome to DTU Research Database Skip to main navigation Skip to search Skip to main content Welcome to DTU Research Database Home Welcome to DTU Research Database Logo About DTU Orbit Home Profiles Research Units Research output Activities Projects Prizes Press / Media Search by expertise, name or affiliation Data Structures in the Succinct Solver (V1.0) Hong Yan Sun, Hanne Riis Nielson, Flemming Nielson Research output: Book/Report \u203a Report Overview Original language English Publication status Published - 2002 Access to Document http://www.imm.dtu.dk/pubdb/p.php?1966 Cite this APA Author BIBTEX Harvard Standard RIS Vancouver Sun, HY, Nielson, HR, & Nielson, F. (2002). Data Structures in the Succinct Solver (V1.0). http://www.imm.dtu.dk/pubdb/p.php?1966 Sun, Hong Yan ; Nielson, Hanne Riis ; Nielson, Flemming. / Data \u2026", "num_citations": "4\n", "authors": ["1602"]}
{"title": "Polymorphic subtyping for behaviour analysis\n", "abstract": " The integration of polymorphism (in the style of the ML let-construct), subtyping, and e ects (modelling assignment or communication) into one common type system has proved remarkably di cult. This paper presents a type system for Concurrent ML that extends the ML type system in a conservative way and that employs all these features; and in addition causality information has been incorporated into the e ects (which may therefore be termed behaviours).", "num_citations": "4\n", "authors": ["1602"]}
{"title": "Lightweight information flow\n", "abstract": " We develop a type system for identifying the information flow between variables in a program in the Guarded Commands language. First we characterise the types of information flow that may arise between variables in a non-deterministic program: explicit, implicit, bypassing, correlated or sanitised. Next we allow to specify security policies in a number of traditional ways based on mandatory access control: defining a security lattice, working with components or decentralised labels, both as pertains to confidentiality and integrity. Offending information flows are those identified by the type system and that violate the security policy; a program is sufficiently secure if it contains only acceptable information flows.", "num_citations": "3\n", "authors": ["1602"]}
{"title": "Iterated process analysis over lattice-valued regular expressions\n", "abstract": " We present an iterated approach to statically analyze programs of two processes communicating by message passing. Our analysis operates over a domain of lattice-valued regular expressions, and computes increasingly better approximations of each process's communication behavior. Overall the work extends traditional semantics-based program analysis techniques to automatically reason about message passing in a manner that can simultaneously analyze both values of variables as well as message order, message content, and their interdependencies.", "num_citations": "3\n", "authors": ["1602"]}
{"title": "Stochastic model checking of the stochastic quality calculus\n", "abstract": " The Quality Calculus uses quality binders for input to express strategies for continuing the computation even when the desired input has not been received. The Stochastic Quality Calculus adds generally distributed delays for output actions and real-time constraints on the quality binders for input. This gives rise to Generalised Semi-Markov Decision Processes for which few analytical techniques are available.               We restrict delays on output actions to be exponentially distributed while still admitting real-time constraints on the quality binders. This facilitates developing analytical techniques based on stochastic model checking and we compute closed form solutions for a number of interesting scenarios. The analyses are applied to the design of an intelligent smart electrical meter of the kind to be installed in European households by 2020.", "num_citations": "3\n", "authors": ["1602"]}
{"title": "Belief Bisimulation for Hidden Markov Models\n", "abstract": " This paper establishes connections between logical equivalences and bisimulation relations for hidden Markov models (HMM). Both standard and belief state bisimulations are considered.             We also present decision algorithms for the bisimilarities. For standard bisimilarity, an extension of the usual partition refinement algorithm is enough. Belief bisimilarity, being a relation on the continuous space of belief states, cannot be described directly. Instead, we show how to generate a linear equation system in time cubic in the number of states.", "num_citations": "3\n", "authors": ["1602"]}
{"title": "Verification of Stochastic Process Calculi\n", "abstract": " Stochastic process calculi represent widely accepted formalisms within Computer Science for modelling nondeterministic stochastic systems in a compositional way. Similar to process calculi in general, they are suited for modelling systems in a hierarchical manner, by explicitly specifying subsystems as well as their interdependences and communication channels. Stochastic process calculi incorporate both the quantified uncertainty on probabilities or durations of events and nondeterministic choices between several possible continuations of the system behaviour. Modelling of a system is often performed with the purpose to verify the system. In this dissertation it is argued that the verification techniques that have their origin in the analysis of programming code with the purpose to deduce the properties of the code's execution, ie Static Analysis techniques, are transferable to stochastic process calculi. The description of a system in the syntax of a particular stochastic process calculus can be analysed in a compositional way, without expanding the state space by explicitly resolving all the interdependencies between the subsystems which may lead to the state space explosion problem. In support of this claim we have developed analysis methods that belong to a particular type of Static Analysis {Data Flow/Pathway Analysis. These methods have previously been applied to a number of non-stochastic process calculi. In this thesis we are lifting them to the stochastic calculus of Interactive Markov Chains (IMC). We have devised the Pathway Analysis of IMC that is not only correct in the sense of overapproximating all possible behaviour scenarios, as\u00a0\u2026", "num_citations": "3\n", "authors": ["1602"]}
{"title": "Designing, Capturing and Validating History-Sensitive Security Policies for Distributed Systems.\n", "abstract": " We consider the use of Aspect-oriented techniques as a flexible way to deal with security policies in distributed systems. We follow the approach of attaching security policies to the relevant locations that must be governed by them, and then combining them at runtime according to the interactions that happen. Recent work suggests using Aspects in this way to analyse the future behaviour of programs and to make access control decisions based on this; this gives the flavour of dealing with information flow rather than mere access control. We show in this paper that it is beneficial to augment this approach with history-based components, as is traditional in reference-monitorbased approaches to mandatory access control. Our developments are performed in an Aspect-oriented coordination language, aiming to describe the Bell-LaPadula policy as elegantly as possible. Furthermore, the resulting language has the capability of combining both historysensitive and future-sensitive policies, providing even more flexibility and power. Moreover, we propose a global Logic for reasoning about the systems designed with this language. We show how the Logic can be used to validate the combination of security policies in a distributed system, either with or without exploring the entire state space.", "num_citations": "3\n", "authors": ["1602"]}
{"title": "History-sensitive versus future-sensitive approaches to security in distributed systems\n", "abstract": " We consider the use of aspect-oriented techniques as a flexible way to deal with security policies in distributed systems. Recent work suggests to use aspects for analysing the future behaviour of programs and to make access control decisions based on this; this gives the flavour of dealing with information flow rather than mere access control. We show in this paper that it is beneficial to augment this approach with history-based components as is the traditional approach in reference monitor-based approaches to mandatory access control. Our developments are performed in an aspect-oriented coordination language aiming to describe the Bell-LaPadula policy as elegantly as possible. Furthermore, the resulting language has the capability of combining both history- and future-sensitive policies, providing even more flexibility and power.", "num_citations": "3\n", "authors": ["1602"]}
{"title": "Pathway analysis for IMC\n", "abstract": " We present the ongoing work on the pathway analysis of a stochastic calculus. Firstly we present a particular stochastic calculus that we have chosen for our modeling-the Interactive Markov Chains calculus, IMC for short. After that we specify a few restrictions that we have introduced into the syntax of IMC in order to make our analysis feasible. Finally we describe the analysis itself together with several theoretical results that we have proved for it.The IMC calculus has been introduced by Holger Hermanns in the 90\u2019s as an orthogonal extension of Continuous Time Markov Chains (CTMC) and a process algebra (see [BH01]). We have adopted the syntax of IMC with a few minor changes (see Table 1). Small Latin letters denote actions that IMC processes are able to execute, capital Latin letters indicate process identifiers and Greek letters correspond to positive real numbers standing for delays during which IMC processes are stuck, ie do nothing. Delay durations are not fixed but are exponentially distributed with rates equal to the corresponding numbers. If the rate of some delay is equal to \u03bb, then it\u2019s average duration will be 1/\u03bb and it\u2019s variation-1/\u03bb2. One difference with respect to [BH01] is that all summands in the sum construct are\u201d guarded\u201d either by actions or delay rates (see rule (2) in the Table 1). This is why we use the name guarded IMC or IMCG. Another difference is that all actions and delay rates are decorated with labels from a predefined label set. Labels do not have any semantic meaning but are useful for our analysis.", "num_citations": "3\n", "authors": ["1602"]}
{"title": "What is a free name in a process algebra?\n", "abstract": " There are two popular approaches to specifying the semantics of process algebras: labelled transition semantics and reaction semantics. While the notion of free name is rather unproblematic for labelled transition semantics this is not so for reaction semantics in the presence of a structural congruence for unfolding recursive declarations.We show that the standard definition of free name is not preserved under the structural congruence. We then develop a fixed point approach to the set of free names and show that it is invariant under the structural congruence.", "num_citations": "3\n", "authors": ["1602"]}
{"title": "Heuristics for safety and security constraints\n", "abstract": " The flow logic approach to static analysis amounts to specifying the admissibility of solutions to analysis problems; when specified using formulae in stratified alternation-free least fixed point logic one may use efficient algorithms for computing the least admissible solutions. We extend this scenario to validate the fulfilment of safety and security constraints on admissible solutions; the modified development produces a least solution together with a boolean value indicating whether or not the constraints are validated or violated.The main contribution is the development of a deterministic heuristics for obtaining a solution that is close to the least solution while enforcing the safety or security constraints. We illustrate it on the Bell-LaPadula mandatory access control policy where the heuristics is used to suggest modifications to the security annotations of entities in order for the security policy to hold.", "num_citations": "3\n", "authors": ["1602"]}
{"title": "Types from control flow analysis\n", "abstract": " Control flow analysis is a powerful method for analysing which functions are applied to which arguments. However, many users find the information more understandable if the information is presented in the form of types rather than sets of function abstractions. We therefore show how to translate the result of the control flow analysis into the syntax of types (to be called observed types).               To compare our approach with the more traditional approach using type systems (to be called inferred types) we develop the subtyping relations in both approaches; in particular we show that covariant subtyping is the appropriate choice for observed types whereas contravariant subtyping is appropriate choice for inferred types. This serves as a technical underpinning of our main thesis that observed types should merely record how the entity has been used in the program at hand whereas inferred types should\u00a0\u2026", "num_citations": "3\n", "authors": ["1602"]}
{"title": "Static validation of voting protocols\n", "abstract": " Previous studies have shown that language based technologies can be used to automatically validate classical protocols. In this thesis we shall apply these methods to a different type of protocols; namely electronic voting protocols.We shall study three voting protocols; FOO92, Sensus and E-vox. These are modelled in the process calculus LYSA and validated using the corresponding analysis. However, as the protocols utilise cryptographic operations which are not incorporated into LYSA, we shall extend the calculus and the analysis. This extension is proven sound with respect to the semantics and the corresponding implementation is proven sound with respect to the analysis.", "num_citations": "3\n", "authors": ["1602"]}
{"title": "Extended features in the Succinct Solver (V2. 0)\n", "abstract": " We describe the new features extended in the Succinct Solver (V2. 0) and the techniques developed for supporting these features in this report. The Succinct Solver developed by Nielson and Seidl incorporates state-ofthe-art approaches to constraint solving. It is used to solve static analysis problems specified in Alternation-free Least Fixpoint Logic (ALFP). The major new feature in the version V2. 0 is to allow using structured terms freely, hence the universe is potentially infinite. To do so we first transform the clause containing structured terms into the equivalent clause with only simple terms as arguments of predicates, via explicit unifications, in the preprocessing stage. In the solving stage we expand the universe dynamically, and we use continuations to resolve the computations that were suspended due to the lack of information about the whole universe. Once a new ground term is added to the universe, the continuations are resumed. Moreover, we extend the solver to allow querying old results while solving new clauses, and provide more flexible user interfaces.", "num_citations": "3\n", "authors": ["1602"]}
{"title": "Hardest attackers\n", "abstract": " Most interesting properties of computer systems are inherently undecidable yet static analysis allows to automatically validate systems against such properties by making sure to always \u201cerr on the safe side\u201d. We take this idea one step further by identifying \u201chardest attackers\u201d in such a way that if the static analysis is able to demonstrate protection against the \u201chardest attacker\u201d then the system is manifestly protected against all of the infintely many attackers.The overall approach. Consider a computer system that is to be protected against hostile elements in its execution environment. This may be done by restricting access to key components to agents knowing a set of agreed passwords or to agents knowing a set of secret keys (assuming classical symmetric cryptography). Determining whether or not the system fulfills its intentions is usually an undecidable property\u2014intuitively because (i) there is an infinity of attackers that do not know the passwords or secret keys, and (ii) even in the presence of a single attacker the success of penetration somehow involves the halting problem and therefore is likely to be undecidable.", "num_citations": "3\n", "authors": ["1602"]}
{"title": "Strictness and totality analysis\n", "abstract": " We define a novel inference system for strictness and totality analysis for the simply-typed lazy lambda-calculus with constants and fixpoints. Strictness information identifies those terms that definitely denote bottom (ie do not evaluate to WHNF) whereas totality information identifies those terms that definitely do not denote bottom (ie do evaluate to WHNF). The analysis is presented as an annotated type system allowing conjunctions only at\" top-level\u201d. We give examples of its use and prove the correctness with respect to a natural-style operational semantics.", "num_citations": "3\n", "authors": ["1602"]}
{"title": "Functional completeness of the mixed \u03bb-calculus and combinatory logic\n", "abstract": " Functional completeness of the combinatory logic means that every \u03bb-expression may be translated into an equivalent combinator expression and this is the theoretical basis for the implementation of functional languages on combinator-based abstract machines. To obtain efficient implementations it is important to distinguish between early and late binding times. i.e. to distinguish between compile-time and run-time computations. We therefore introduce a two-level version of the \u03bb-calculus where this distinction is made in an explicit way. Turning to the combinatory logic we only wish to generate combinator-code for the run-timecomputations. The two-level version of the combinatory logic therefore will be a mixed \u03bb-calculus and combinatory logic. A previous paper has shown that (a natural formulation of) the mixed \u03bb-calculus and combinatory logic is not functionally complete but only corresponds to a strict subset of\u00a0\u2026", "num_citations": "3\n", "authors": ["1602"]}
{"title": "Flow Logic\n", "abstract": " Flow Logic Page 1 ' & $ % Flow Logic a unifying approach to static analysis Hanne Riis Nielson Acknowledgements: Aarhus F. Nielson, K. Gasser, R. Hansen, J. Jensen London C. Hankin Pisa C. Bodei, P. Degano Trier H. Seidl cOHRN-2001 1 Page 2 ' & $ % Static Analysis A compile-time technique for predicting safe and computable approximations to the set of values or behaviours arising dynamically at run-time. Applications in optimising compilers and software validation: \u2022 justify the applicability of transformations \u2022 provide warnings about suspicious aspects \u2022 give performance guarantees cOHRN-2001 2 Page 3 ' & $ % The nature of approximation Exact answers: Approximate answers: the property holds the property does not hold under approx. over approx. ' & $ % ' & $ % ' & $ % /\\ /\\ /\\ /\\ /\\ /\\ /\\ /\\ /\\ /\\ /\\n /\\ /\\ /\\ /\\ /\\n /\\ /\\n /\\ /\\ /\\ /\\n /\\ /\\ cOHRN-2001 3 Page 4 ' & $ % Approaches to static analysis \u2022 data flow analysis \u2022 \u2026", "num_citations": "3\n", "authors": ["1602"]}
{"title": "Adaptive security policies\n", "abstract": " We develop an approach to security of adaptive agents that is based on respecting the local security policies of agents rather than imposing a global security policy on all agents. In short, an agent can be assured, that it will not be able to observe any violation of its own security policy due to the changing presence of other agents in its environment. The development is performed for a version of Dijkstra\u2019s Guarded Commands with relocation primitives, channel based communication, and explicit non-determinism. At the technical level a type system enforces local security policies whereas a reference monitor ensures that relocation is permissible with local security of all agents.", "num_citations": "2\n", "authors": ["1602"]}
{"title": "Secure guarded commands\n", "abstract": " We develop a lightweight approach to information flow control that interacts with the use of cryptographic schemes. The language is a version of Dijkstra\u2019s Guarded Commands language extended with parallelism, communication and symmetric cryptography. Information flow is modelled using security labels that are sets of hashed symmetric keys expressing the capabilities needed for access to data. In essence, encryption is used to encapsulate the protection offered by the information flow policy. We develop a type system aimed at tracking explicit, implicit, bypassing and correlation flows arising due to the parallel processes and the internal non-determinism inherent in Guarded Commands. The development is facilitated by the parallel processes having disjoint memories and is illustrated on a multiplexer scenario previously addressed using content-dependent information flow policies.", "num_citations": "2\n", "authors": ["1602"]}
{"title": "Concurrency\n", "abstract": " So far we have been looking at individual programs running on their own. In this chapter we will illustrate how to deal with concurrently running programs that may communicate with one another. Our main focus will be on defining the semantics.", "num_citations": "2\n", "authors": ["1602"]}
{"title": "Atomistic Galois insertions for flow sensitive integrity\n", "abstract": " Several program verification techniques assist in showing that software adheres to the required security policies. Such policies may be sensitive to the flow of execution and the verification may be supported by combinations of type systems and Hoare logics. However, this requires user assistance and to obtain full automation we shall explore the over-approximating nature of static analysis.We demonstrate that the use of atomistic Galois insertions constitutes a stable framework in which to obtain sound and fully automatic enforcement of flow sensitive integrity. The framework is illustrated on a concurrent language with local storage and polyadic synchronous communication.", "num_citations": "2\n", "authors": ["1602"]}
{"title": "A Theory of Available-by-Design Communicating Systems\n", "abstract": " Choreographic programming is a programming-language design approach that drives error-safe protocol development in distributed systems. Starting from a global specification (choreography) one can generate distributed implementations. The advantages of this top-down approach lie in the correctness-by-design principle, where implementations (endpoints) generated from a choreography behave according to the strict control flow described in the choreography, and do not deadlock. Motivated by challenging scenarios in Cyber-Physical Systems (CPS), we study how choreographic programming can cater for dynamic infrastructures where not all endpoints are always available. We introduce the Global Quality Calculus (), a variant of choreographic programming for the description of communication systems where some of the components involved in a communication might fail. GCq features novel operators for multiparty, partial and collective communications. This paper studies the nature of failure-aware communication: First, we introduce  syntax, semantics and examples of its use. The interplay between failures and collective communications in a choreography can lead to choreographies that cannot progress due to absence of resources. In our second contribution, we provide a type system that ensures that choreographies can be realized despite changing availability conditions. A specification in  guides the implementation of distributed endpoints when paired with global (session) types. Our third contribution provides an endpoint-projection based methodology for the generation of failure-aware distributed processes. We\u00a0\u2026", "num_citations": "2\n", "authors": ["1602"]}
{"title": "Analysis of security protocols in embedded systems\n", "abstract": " This thesis was prepared at DTU Compute, the Department of Applied Mathematics and Computer Science of the Technical University of Denmark, in partial fulfilment of the requirements for acquiring the Ph. D. degree in Computer Science.", "num_citations": "2\n", "authors": ["1602"]}
{"title": "Factorization of behavioral integrity\n", "abstract": " We develop a bisimulation-based nonintereference property that describes the allowed dependencies between communication behaviors of different integrity levels. The property is able to capture all possible combinations of integrity levels for the \u201cpresence\u201d and \u201ccontent\u201d of actual communications. Channels of low presence integrity and high content integrity can be used to model the effect of Message Authentication Codes or the consequence of Denial of Service Attacks. In case the distinction between \u201cpresence\u201d and \u201ccontent\u201d is deliberately blurred, the noninterference property specialises to a classical process-algebraic property (called SBNDC). A compositionality result is given to facilitate a structural approach to the analysis of concurrent systems.", "num_citations": "2\n", "authors": ["1602"]}
{"title": "A framework for hybrid systems with denial-of-service security attack\n", "abstract": " Hybrid systems are integrations of discrete computation and continuous physical evolution. The physical components of such systems introduce safety requirements, the achievement of which asks for the correct monitoring and control from the discrete controllers. However, due to denial-of-service security attack, the expected information from the controllers is not received and as a consequence the physical systems may fail to behave as expected. This paper proposes a formal framework for expressing denial-of-service security attack in hybrid systems. As a virtue, a physical system is able to plan for reasonable behavior in case the ideal control fails due to unreliable communication, in such a way that the safety of the system upon denial-of-service is still guaranteed. In the context of the modeling language, we develop an inference system for verifying safety of hybrid systems, without putting any assumptions on how the environments behave. Based on the inference system, we implement an interactive theorem prover and have applied it to check an example taken from train control system.", "num_citations": "2\n", "authors": ["1602"]}
{"title": "ICT-powered Health Care Processes\n", "abstract": " The efficient use of health care ressources requires the use of Information and Communication Technology (ICT). During a treatment process, patients have often been tested and partially treated with different diagnoses in mind before the precise diagnosis is identified. To use ressources well it becomes necessary to adapt the prescribed treatments to make use of the tests and partial treatments already performed, rather than always starting from square one. We propose to facilitate this through the design of declarative process models accounting for the involvement of distributed groups of medical specialists and the adaptation of treatments, and through the evaluation of the trustworthiness of models taking account of test results and actual treatments compared to the clinical guidelines.", "num_citations": "2\n", "authors": ["1602"]}
{"title": "Layered fixed point logic\n", "abstract": " We present a logic for the specification of static analysis problems that goes beyond the logics traditionally used. Its most prominent feature is the direct support for both inductive computations of behaviors as well as co-inductive specifications of properties. Two main theoretical contributions are a Moore Family result and a parametrized worst case time complexity result. We show that the logic and the associated solver can be used for rapid prototyping of analyses and illustrate a wide variety of applications within Static Analysis, Constraint Satisfaction Problems and Model Checking. In all cases the complexity result specializes to the worst case time complexity of the classical methods.", "num_citations": "2\n", "authors": ["1602"]}
{"title": "Model checking as static analysis: revisited\n", "abstract": " We show that the model checking problem of the \u03bc-calculus can be viewed as an instance of static analysis. We propose Succinct Fixed Point Logic (SFP) within our logical approach to static analysis as an extension of Alternation-free Least Fixed Logic (ALFP). We generalize the notion of stratification to weak stratification and establish a Moore Family result for the new logic as well. The semantics of the \u03bc-calculus is encoded as the intended model of weakly stratified clause sequences in SFP.", "num_citations": "2\n", "authors": ["1602"]}
{"title": "Static analysis of IMC\n", "abstract": " Process algebras formalism is highly suitable for producing succinct descriptions of reactive concurrent systems. Process algebras allow to represent them in a compositional way, as processes that run in parallel and interact, for example, through synchronisation or message passing. On the other hand, checking properties on process algebraic descriptions is often hard, while \u201cunfolding\u201d them into the Labelled Transition Systems can lead to the infamous state space explosion problem.In this work we use a subtype of Data Flow Analysis on systems defined by finite-state process algebras with CSP-type synchronisation \u2013 in particular, on our variant of IMC with a more permissive syntax, i.e. with a possibility to start a bounded number of new processes. We prove that the defined Pathway Analysis captures all the properties of the systems, i.e. is precise. The results of the Pathway Analysis can be therefore used as an\u00a0\u2026", "num_citations": "2\n", "authors": ["1602"]}
{"title": "Fixpoints vs Moore Families\n", "abstract": " Model checking and static analysis are both successful approaches to the analysis of IT systems and it has been shown that many static analyses can be reduced to model checking. Recent results show that CTL model checking can be reduced to static analysis and that the set of satisfying states of a CTL formula can be described as the least element in a Moore family of acceptable sets of states for the static analysis. Turning the attention to the \u00b5-calculus we are able to generalise this result to the alternation-free fragment whereas even for the fragment of alternation depth 2 we show that the fixed point characterisation cannot be recast as a Moore family property.", "num_citations": "2\n", "authors": ["1602"]}
{"title": "Position paper: A generic approach for security policies composition\n", "abstract": " When modelling access control in distributed systems, the problem of security policies composition arises. Much work has been done on different ways of combining policies, and using different logics to do this. In this paper, we propose a more general approach based on a 4-valued logic, that abstracts from the specific setting, and groups together many of the existing ways for combining policies. Moreover, we propose going one step further, by twisting the 4-valued logic and obtaining a more traditional approach that might therefore be more appropriate for analysis.", "num_citations": "2\n", "authors": ["1602"]}
{"title": "Distributed security in closed distributed systems\n", "abstract": " The goal of the present thesis is to discuss, argue and conclude about ways to provide security to the information travelling around computer systems consisting of several known locations.", "num_citations": "2\n", "authors": ["1602"]}
{"title": "The logic of xacml-extended\n", "abstract": " We study the international standard XACML 3.0 for describing security access control policy in a compositional way. Our main contribution is to derive a logic that precisely captures the idea behind the standard and to formally define the semantics of the policy combining algorithms of XACML. To guard against modelling artefacts we provide an alternative way of characterizing the policy combining algorithms and we formally prove the equivalence of these approaches. This allows us to pinpoint the shortcoming of previous approaches to formalization based either on Belnap logic or on D-algebra.", "num_citations": "2\n", "authors": ["1602"]}
{"title": "Reachability for finite-state process algebras using Static Analysis\n", "abstract": " In this work we present an algorithm for solving the reachability problem in finite systems that are modelled with process algebras. Our method uses Static Analysis, in particular, Data Flow Analysis, of the syntax of a process algebraic system with multi-way synchronisation. The results of the Data Flow Analysis are used in order to \u201ccut off\u201d some of the branches in the reachability analysis that are not important for determining, whether or not a state is reachable. In this way, it is possible for our reachability algorithm to avoid building large parts of the system altogether and still solve the reachability problem in a precise way.", "num_citations": "2\n", "authors": ["1602"]}
{"title": "Controlling Modelling Artifacts\n", "abstract": " When analysing the performance of a complex system, we typically build abstract models that are small enough to analyse, but still capture the relevant details of the system. But it is difficult to know whether the model accurately describes the real system, or if its behaviour is due to modelling artifacts that were inadvertently introduced. In this paper, we propose a novel methodology to reason about modelling artifacts, given a detailed model and a high-level (more abstract) model of the same system. By a series of automated abstraction steps, we lift the detailed model to the same state space as the high-level model, so that they can be directly compared. There are two key ideas in our approach - a temporal abstraction, where we only look at the state of the system at certain observable points in time, and a spatial abstraction, where we project onto a smaller state space that summarises the possible configurations of\u00a0\u2026", "num_citations": "2\n", "authors": ["1602"]}
{"title": "Modal abstractions of concurrent behavior\n", "abstract": " We present an effective algorithm for the automatic construction of finite modal transition systems as abstractions of potentially infinite concurrent processes. Modal transition systems are recognized as valuable abstractions for model checking because they allow for the validation as well as refutation of safety and liveness properties. However, the algorithmic construction of finite abstractions from potentially infinite concurrent processes is a missing link that prevents their more widespread usage for model checking of concurrent systems. Our algorithm is a worklist algorithm using concepts from abstract interpretation and operating upon mappings from sets to intervals in order to express simultaneous over- and underapproximations of the multisets of process actions available in a particular state. We obtain a finite abstraction that is 3-valued in both states and transitions and that supports the definition of a 3-valued\u00a0\u2026", "num_citations": "2\n", "authors": ["1602"]}
{"title": "From explicit to symbolic types for communication protocols in CCS\n", "abstract": " We study communication protocols having several rounds and expressed in value passing CCS. We develop a type-based analysis for providing an explicit record of all communications and show the usual subject reduction result. Since the explicit records can be infinitely large, we also develop a type-based analysis for providing a finite, symbolic record of all communications. We show that it correctly approximates the explicit record and prove an adequacy result for it.", "num_citations": "2\n", "authors": ["1602"]}
{"title": "Analysing protocol stacks for services\n", "abstract": " We show an approach, CaPiTo, to model service-oriented applications using process algebras such that, on the one hand, we can achieve a certain level of abstraction without being overwhelmed by the underlying implementation details and, on the other hand, we respect the concrete industrial standards used for implementing the service-oriented applications. By doing so, we will be able to not only reason about applications at different levels of abstractions, but also to build a bridge between the views of researchers on formal methods and developers in industry. We apply our approach to the financial case study taken from Chapter 0-3. Finally, we develop a static analysis to analyse the security properties as they emerge at the level of concrete industrial protocols.", "num_citations": "2\n", "authors": ["1602"]}
{"title": "Iterative specialisation of horn clauses\n", "abstract": " We present a generic algorithm for solving Horn clauses through iterative specialisation. The algorithm is generic in the sense that it can be instantiated with any decidable fragment of Horn clauses, resulting in a solution scheme for general Horn clauses that guarantees soundness and termination, and furthermore, it presents sufficient criteria for completeness. We then demonstrate the use of the framework, by creating an instance of it, based on the decidable class , capable of solving a non-trivial protocol analysis problem based on the Yahalom protocol.", "num_citations": "2\n", "authors": ["1602"]}
{"title": "Trustworthy Global Computing\n", "abstract": " This volume contains the proceedings of the fourth edition of the International Symposium on Trustworthy Global Computing (TGC 2008) that was held in Barcelona, Spain, November 3-4, 2008. The Symposium on Trustworthy Global Computing is an international annual venue dedicated to safe and reliable computation in global computers. It focuses on providing frameworks, tools, and protocols for constructing well-behaved applications and on reasoning rigorously about their behavior and properties. The related models of computation incorporate code and data mobility over distributed networks with highly dynamic topologies and heterogeneous devices.This volume contains one invited paper from Gianluigi Zavattaro and coauthors, as well as the revised versions of the 12 contributed papers; these versions take into account both the referees\u2019 reports and the discussions that took place during the symposium\u00a0\u2026", "num_citations": "2\n", "authors": ["1602"]}
{"title": "Polymorphic subtyping for side effects\n", "abstract": " The integration of polymorphism (in the style of the ML let-construct), subtyping, and effects (modelling assignment or communication) into one common type system has proved remarkably difficult. This paper presents a type system for (a core subset of) Concurrent~ ML that extends the ML type system in a conservative way and that employs all these features; and in addition causality information has been incorporated into the effects (which may therefore be termed\" behaviours\").", "num_citations": "2\n", "authors": ["1602"]}
{"title": "Perspectives on program analysis\n", "abstract": " eing analysed. On the negative side, the semantic correctness of the analysis is seldom established and therefore there is often no formal justification for the program transformations for which the information is used. The semantics based approach [1; 5] is often based on domain theory in the form of abstract domains modelling sets of values, projections, or partial equivalence relations. The approach tends to focus more directly on discovering the extensional properties of interest: for constant propagation it might operate on sets of values with constancy corresponding to singletons, and for neededness analysis it might perform a strictness analysis and use the strictness information for neededness (or make use of the\" absence\" notion from projection analysis and attempt to discover the di# erence). On the positive side, this usually gives rise to provably correct analyses, although there are sometimes complications (due to deciding what information to stick onto the", "num_citations": "2\n", "authors": ["1602"]}
{"title": "Iterative Algorithms for Fixed Point Comutation\n", "abstract": " We compare two algorithms for computing fixed points of functionals of the kind arising in static program analysis. One is a rather direct calculation of the iterands, whereas the other employs the technique of iterative squaring. To give meaningful results about the time and space requirements we need to be more specific about the form of the functionals and the properties of the functions upon which the functionals operate. In this paper we consider functionals in iterative versus (two kinds of) primitive recursive forms, and functions that are monotone versus completely additive.", "num_citations": "2\n", "authors": ["1602"]}
{"title": "Comments on Georgeff's \u201ctransformations and reduction strategies for typed lambda expressions\u201d\n", "abstract": " In his recent paper, Georgeff [1] considers the evaluation of lambda expres sions (with reducing reflexive types) on a variant of Landin's SECD machine. It is observed that for so-called simple expressions the SECD machine will construct stack-like environment structures, whereas, in general, they are tree-like. Georgeff then explores the idea of transforming any (typed) lambda expression into simple form and then using the SECD machine for these expressions. However, such transformations might be undesirable if the language is going to be interpreted directly. This leads Georgeff to modify the SECD machine such that it constructs stack-like environments for all expressions. Briefly, the idea in this modification is to let the machine construct over- applied closures for function-valued expressions in operand positions and to let it apply the closure in situ in the case of function-valued expressions in operator positions\u00a0\u2026", "num_citations": "2\n", "authors": ["1602"]}
{"title": "Towards viewing nondeterminism as abstract interpretation\n", "abstract": " Towards Viewing Nondeterminism as Abstract Interpretation \u2014 Welcome to DTU Research Database Skip to main navigation Skip to search Skip to main content Welcome to DTU Research Database Home Welcome to DTU Research Database Logo About DTU Orbit Home Profiles Research Units Research output Activities Projects Prizes Press / Media Search by expertise, name or affiliation Towards Viewing Nondeterminism as Abstract Interpretation Flemming Nielson Research output: Chapter in Book/Report/Conference proceeding \u203a Article in proceedings \u203a Research \u203a peer-review Overview Original language English Title of host publication Proc. Foundations of Software Technology and Theoretical Computer Science Publication date 1983 Publication status Published - 1983 Event Proc. Foundations of Software Technology and Theoretical Computer Science - Duration: 1 Jan 1983 \u2192 \u2026 Conference \u2026", "num_citations": "2\n", "authors": ["1602"]}
{"title": "Enforcing globally dependent flow policies in message-passing systems\n", "abstract": " The flow of information in a computing system is a crucial indicator for the security of the system. In a system of multiple message-passing processes, the flow of information could depend on the states of different processes. We devise a type-based verification technique for flow policies with such multi-process (global) dependencies, to provide confidentiality guarantees. In this technique, the confidentiality requirements for the presence and content of messages are dealt with separately. We develop a pair of synergetic static analyses to over-approximate the potential sets of values of the variables depended upon by the flow policies \u2013 covering global value correspondence between the variables of different processes. We significantly improve the permissiveness of security typing by exploiting information about which variables are live, and by specializing the flow policies using the conditional expressions of\u00a0\u2026", "num_citations": "1\n", "authors": ["1602"]}
{"title": "Program Graphs\n", "abstract": " Sometimes we need to be very precise about the behaviour of our programs \u2013 there may be constructs in our programming language that are subtle or novel. Semantics is the part of Computer Science that deals with formalising the behaviour of programs.", "num_citations": "1\n", "authors": ["1602"]}
{"title": "Multi-valued Logic for Static Analysis and Model Checking\n", "abstract": " We extend Alternation-Free Least Fixed Point Logic to be based on Belnap logic, while maintaining the close correspondence between static analysis and model checking pioneered by Bernhard Steffen, and opening up for handling access control policies central to the construction of secure IT systems.", "num_citations": "1\n", "authors": ["1602"]}
{"title": "Towards static analysis of policy-based self-adaptive computing systems\n", "abstract": " For supporting the design of self-adaptive computing systems, the PSCEL language offers a principled approach that relies on declarative definitions of adaptation and authorisation policies enforced at runtime. Policies permit managing system components by regulating their interactions and by dynamically introducing new actions to accomplish task-oriented goals. However, the runtime evaluation of policies and their effects on system components make the prediction of system behaviour challenging. In this paper, we introduce the construction of a flow graph that statically points out the policy evaluations that can take place at runtime and exploit it to analyse the effects of policy evaluations on the progress of system components.", "num_citations": "1\n", "authors": ["1602"]}
{"title": "Limitations of non-interference\n", "abstract": " We show that non-interference falls short of providing a convincing semantic characterisation of information flow policies for confidentiality and integrity and motivate an approach based on instrumented semantics.Introduction. We have been working with Airbus on developing security policies for dealing with the challenges of communication between security domains subject to strict safety concerns, and in the course of this work we have uncovered a limitation of non-interference in establishing convincing semantic characterisations of the required security policies. In this paper we illustrate this limitation on an utterly simple example and discuss ways of providing alternate semantic characterisations more acceptable to our industrial partners.", "num_citations": "1\n", "authors": ["1602"]}
{"title": "Pareto efficient solutions of attack trees\n", "abstract": " Nowadays IT systems rarely work in isolation; they rather cooperate with each other, communicating in an interconnected world. In this growing global computing environment security has become one of the main issues. The continued integration and cooperation of distributed components creates new security problems. Formal methods are necessary to face the complexity of these new scenarios and to study their security properties and threats. Attack trees are a well-known formal yet graphical approach for describing threats on systems and representing the possible attacks.The first graphical representation for analysing the safety of a system, called fault trees, was introduced in early 1980\u2019s. Fault trees represent a failure of a system in terms of the failure of its components [1]. Inspired by fault trees researchers adopted a similar approach to security. In 1991, Weiss presented threat logic trees as a formal attack\u00a0\u2026", "num_citations": "1\n", "authors": ["1602"]}
{"title": "Pushdown systems for monotone frameworks\n", "abstract": " Monotone frameworks is one of the most successful frameworks for intraprocedural data flow analysis extending the traditional class of bitvector frameworks (like live variables and available expressions). Weighted pushdown systems is similarly one of the most general frameworks for interprocedural analysis of programs. However, it makes use of idempotent semirings to represent the sets of properties and unfortunately they do not admit analyses whose transfer functions are not strict (e.g., classical bitvector frameworks). This motivates the development of algorithms for backward and forward reachability of pushdown systems using sets of properties forming so-called flow algebras that weaken some of the assumptions of idempotent semirings. In particular they do admit the bitvector frameworks, monotone frameworks, as well as idempotent semirings. We show that the algorithms are sound under mild assumptions on the flow algebras, mainly that the set of properties constitutes a join semi-lattice, and complete provided that the transfer functions are suitably distributive (but not necessarily strict).", "num_citations": "1\n", "authors": ["1602"]}
{"title": "Lattice based Least Fixed Point Logic\n", "abstract": " As software systems become more complex, there is an increasing need for new static analyses. Thanks to the declarative style, logic programming is an attractive formalism for specifying them. However, prior work on using logic programming for static analysis focused on analyses defined over some powerset domain, which is quite limiting. In this paper we present a logic that lifts this restriction, called Lattice based Least Fixed Point Logic (LLFP), that allows interpretations over any complete lattice satisfying Ascending Chain Condition. The main theoretical contribution is a Moore Family result that guarantees that there always is a unique least solution for a given problem. Another contribution is the development of solving algorithm that computes the least model of LLFP formulae guaranteed by the Moore Family result.", "num_citations": "1\n", "authors": ["1602"]}
{"title": "Key update assistant for resource-constrained networks\n", "abstract": " Key update is a challenging task in resource-constrained networks where limitations in terms of computation, memory, and energy restrict the proper use of security mechanisms. We present an automated tool that computes the optimal key update strategy for any given resource-constrained network. We developed a push-button solution - powered by stochastic model checking - that network designers can easily benefit from, and it paves the way for consumers to set up key update related security parameters. Key Update Assistant, as we named it, runs necessary model checking operations and determines the optimal key update strategy that satisfies given security and performance requirements.", "num_citations": "1\n", "authors": ["1602"]}
{"title": "Modelling chinese smart grid: a Stochastic Model Checking Case Study\n", "abstract": " Cyber-physical systems integrate information and communication technology functions to the physical elements of a system for monitoring and controlling purposes. The conversion of traditional power grid into a smart grid, a fundamental example of a cyber-physical system, raises a number of issues that require novel methods and applications. In this context, an important issue is the verification of certain quantitative properties of the system. In this technical report, we consider a specific Chinese Smart Grid implementation and try to address the verification problem for certain quantitative properties including performance and battery consumption. We employ stochastic model checking approach and present our modelling and analysis study using PRISM model checker.", "num_citations": "1\n", "authors": ["1602"]}
{"title": "Key Update Strategies for Wireless Sensor Networks\n", "abstract": " Wireless sensor networks offer the advantages of simple and low-resource communication. Challenged by this simplicity and low-resources, security is of particular importance in many cases such as transmission of sensitive data or strict requirements of tamper-resistance. Updating the security keys is one of the essential points in security, which restrict the amount of data that may be exposed when a key is compromised. In this paper, we investigate key update methods that may be used in wireless sensor networks, and benefiting from stochastic model checking we derive characteristics of these methods in security perspective.", "num_citations": "1\n", "authors": ["1602"]}
{"title": "A Succinct Approach to Static Analysis and Model Checking\n", "abstract": " In a number of areas software correctness is crucial, therefore it is often desirable to formally verify the presence of various properties or the absence of errors. This thesis presents a framework for concisely expressing static analysis and model checking problems. The framework facilitates rapid prototyping of new analyses and consists of variants of ALFP logic and associated solvers.First, we present a Lattice based Least Fixed Point Logic (LLFP) that allows interpretations over complete lattices satisfying Ascending Chain Condition. We establish a Moore Family result for LLFP that guarantees that there always is single best solution for a problem under consideration. We also develop a solving algorithm, based on a differential worklist, that computes the least solution guaranteed by the Moore Family result.", "num_citations": "1\n", "authors": ["1602"]}
{"title": "Lazy mobile intruders (extended version)\n", "abstract": " We present a new technique for analyzing platforms that execute potentially malicious code, such as web-browsers, mobile phones, or virtualized infrastructures. Rather than analyzing given code, we ask what code an intruder could create to break a security goal of the platform. To avoid searching the infinite space of programs that the intruder could come up with (given some initial knowledge) we adapt the lazy intruder technique from protocol verification: the code is initially just a process variable that is getting instantiated in a demand-driven way during its execution. We also take into account that by communication, the malicious code can learn new information that it can use in subsequent operations, or that we may have several pieces of malicious code that can exchange information if they \u201cmeet\u201d. To formalize both the platform and the malicious code we use the mobile ambient calculus, since it provides a small, abstract formalism that models the essence of mobile code. We provide a decision procedure for security against arbitrary intruder processes when the honest processes can only perform a bounded number of steps and without path constraints in communication. We show that this problem is NP-complete.", "num_citations": "1\n", "authors": ["1602"]}
{"title": "Model checking as static analysis\n", "abstract": " This thesis was prepared at the Department of Informatics and Mathematical Modelling at the Technical University of Denmark in fulfilment of the requirements for acquiring a PhD degree in Informatics.", "num_citations": "1\n", "authors": ["1602"]}
{"title": "Logics and Models for Stochastic Analysis Beyond Markov Chains\n", "abstract": " This thesis was prepared at the department of Informatics and Mathematical Modelling at the Technical University of Denmark in partial fulfilment of the requirements for acquiring a Ph. D. degree in Informatics. The Ph. D. study has been carried out under the supervision of Associate Professor Bo Friis Nielsen (Technical University of Denmark) and Professor Flemming Nielson (Technical University of Denmark) in the period from November 2009 to October 2012, and was partially supplied by MT-LAB, a VKR Centre of Excellence.", "num_citations": "1\n", "authors": ["1602"]}
{"title": "A Stochastic Broadcast Pi-Calculus\n", "abstract": " In this paper we propose a stochastic broadcast PI-calculus which can be used to model server-client based systems where synchronization is always governed by only one participant. Therefore, there is no need to determine the joint synchronization rates. We also take immediate transitions into account which is useful to model behaviors with no impact on the temporal properties of a system. Since immediate transitions may introduce non-determinism, we will show how these non-determinism can be resolved, and as result a valid CTMC will be obtained finally. Also some practical examples are given to show the application of this calculus.", "num_citations": "1\n", "authors": ["1602"]}
{"title": "The Guided System Development Framework\n", "abstract": " The Service-Oriented Computing paradigm has had significant influence on the Internet. With the emergence of this paradigm, it is important to provide tools that help developers designing and verifying such systems. In this article, we present the Guided System Development (GSD) Framework that aids and guides the developer on the specification of the system being developed, on choosing the appropriate standard protocols suites that achieve the required security properties, on providing an implementation of the specified system, and also on allowing the verification of its security properties.", "num_citations": "1\n", "authors": ["1602"]}
{"title": "Quantitative security analysis of zigbee key updates\n", "abstract": " ZigBee wireless sensor network standard addresses a significant need in many application areas. ZigBee is a low-rate standard in terms of cost, power consumption, range, and bandwidth. However, security is still very important, and it is a challenging task to provide secure networking with very limited resources. Essentially, security relies heavily on encryption which is mainly employed in confidentiality and integrity. Therefore, updating the encryption key, namely the key update, is a crucial operation. Besides, in a low-rate environment such as ZigBee, there is a trade-off between security and cost since key update is a costly operation (in terms of computation, power consumption, etc.). Choosing the appropriate key update strategy and relevant security parameters is a serious problem. Nevertheless, it is difficult to see how different key update strategies balance this trade-off. Unfortunately, the ZigBee Specification does not give any advice on this-it merely states that the keys shall be updated and leaves the rest to the implementations. In this work, we address the gaps in the ZigBee specification, propose methods to fulfil these gaps, investigate relations between different configurable aspects and key update methods, take the probabilistic model checking approach and derive conclusions to assist the security policies/implementations, and present a novel usage of the probabilistic model checking in network security.", "num_citations": "1\n", "authors": ["1602"]}
{"title": "From generic to specific: off-line optimization for a general constraint solver\n", "abstract": " A general constraint solver simplifies the implementation of program analyses because constraint generation can then be separated from constraint solving. In return, a general solver often needs to sacrifice performance for generality. We describe a strategy that given a set of constraints first performs off-line optimizations (performed before the execution of the solver) which enable a solver to find (potential) equivalences between analysis variables so as to reduce the problem space and thus improve performance. The idea is that different analyses use different subsets of constraints. As a result, a specific property may hold for the subsets and a specific optimization can be conducted on the constraints.", "num_citations": "1\n", "authors": ["1602"]}
{"title": "Active evaluation contexts for reaction semantics\n", "abstract": " In the context of process algebras it is customary to define semantics in the form of a reaction relation supported by a structural congruence relation. Recently process algebras have grown more expressive in order to meet the modelling demands of fields as diverse as business modelling and systems biology. This leads to combining various features, such as general choice and parallelism that were previously studied separately, and it often becomes difficult to define the reaction semantics. We present a general approach based on active evaluation contexts that allows the reaction semantics to be easily constructed.", "num_citations": "1\n", "authors": ["1602"]}
{"title": "Model-based Verification of Service-oriented Systems\n", "abstract": " Background. To ensure high quality, software systems have to be checked against their requirements. In the majority of cases in mainstream software development, this is done through testing after the systems have been implemented. However, for safety-critical systems or massively used components, where failure would be intolerable formal verification techniques like simulation, model checking, or theorem proving are increasingly employed. Service-oriented systems pose new challenges for verification. Due to their dynamic and distributed nature, testing is much more difficult. For example, integration testing, making sure that different components interact correctly, is impossible at design time if the components are not known in advance. This puts greater emphasis on formal verification, eg, based on interface specifications of components rather than their implementation. A variety of languages, calculi\u00a0\u2026", "num_citations": "1\n", "authors": ["1602"]}
{"title": "Observation Predicated in Flow Logic\n", "abstract": " Motivated by the connection between strong and soft type systems we explore flow analyses with hard constraints on the admissible solutions. We show how to use observation predicates and formula rearrangements to map flow analyses with hard constraints into more traditional flow analyses in such a way that the hard constraints are satisfied exactly when the observation predicates report no violations. The development is carried out in a large fragment of a first order logic with negation and also takes care of the transformations necessary in order to adhere to the stratification restrictions inherent in Alternation-free Least Fixed Point Logic and similar formalisms such as Datalog.", "num_citations": "1\n", "authors": ["1602"]}
{"title": "Abstract interpretation of mobile ambients\n", "abstract": " We show how abstract interpretation can be expressed in a constraint-based formalism that is becoming increasingly popular for the analysis of functional and object-oriented languages. This is illustrated by developing analyses for the ambient calculus. The first step of the development constructs an analysis for counting occurrences of processes inside other processes; we show that the analysis is semantically correct and that the set of acceptable solutions constitutes a Moore family. The second step considers a previously developed control ow analysis and shows how to induce it from the counting analysis; we show that its properties can be derived from those of the counting analysis using general results about abstract interpretation for constraint-based analyses. cO 2003 Elsevier Science BV All rights reserved.", "num_citations": "1\n", "authors": ["1602"]}
{"title": "Automatic Validation of Protocol Narration\n", "abstract": " We perform a systematic expansion of protocol narrations into terms of a process algebra in order to make precise some of the detailed checks that need to be made in a protocol. We then apply static analysis technology to develop an automatic validation procedure for protocols. Finally, we demonstrate that these techniques suffice for identifying a number of authentication flaws in symmetric key protocols such as Needham-Schroeder, Otway-Rees, Yahalom and Andrew Secure RPC.", "num_citations": "1\n", "authors": ["1602"]}
{"title": "Multi-Level Languages: a Descriptive Framework\n", "abstract": " Two-level lambda-calculi have been utilised for applications such as partial evalu-ation, abstract interpretation and code generation. Each of these applications pose different demands on the exact details of the two-level structure and the corresponding inference rules. We therefore formulate a number of existing systems in a common framework so as to conceal those differences between the systems that are not essential for the multi-level ideas, and so as to reveal the deeper similarities and differences. The multi-level lambda-calculi defined here allow multi-level structures that are not restricted to the (possibly finit) linear orders found in most of the literature. Finally, we generalise our approach so as to be applicable to a much wider class of programming languages.", "num_citations": "1\n", "authors": ["1602"]}
{"title": "Theoretical Aspects of Semantics-Based Language Implementation\n", "abstract": " This paper is one of a collection of papers submitted by the author for the Danish degree doctor scientarum (dr. scient.) and is written so as to comply with the regulations for that degree. A Danish version of this paper may be found elsewhere. Section 2 gives a short overview of the subject area of my work. Based on this Section 3 then gives a guided tour of the papers. It stresses the motivation for the individual papers, summarises the main insights gained, explains the main relationships and differ-ences between individual papers and contains comparisons with the literature\". It will emerge from this that an initially rather wide outlook has succesively been narrowed so as to obtain results for a class of programming languages rather than just individual toy languages. Section 4 then contains a more detailed discussion of some of the more profound decisions made about the techniques to use and the directions in\u00a0\u2026", "num_citations": "1\n", "authors": ["1602"]}
{"title": "Program transformations in a denotational setting\n", "abstract": " Program transformations are frequently performed by optimizing compilers and the correctness of applying them usually depends on data flow information. For source-to-source transformations it is shown how a denotational setting can be useful for validating such program transformations.Strong equivalence is obtained for transformations that exploit forward data flow information, whereas weak equivalence is obtained for transformations that exploit backward data flow information. To obtain strong equivalence both the original and the transformed program must be data flow analysed, but consideration of a transformation exploiting liveness of variables indicates that a more satisfactory approach may be possible.", "num_citations": "1\n", "authors": ["1602"]}
{"title": "Benign Interaction of Security Domains\n", "abstract": " Whenever data is communicated outside a security domain there is the risk that it may influence data coming back in a way that is not permitted by the security domain. This may arise when different security domains relate to different parallel processes that exchange information through communication. We provide general definitions of the demands on the communication and sanitisation primitives so as to mitigate the risk. For interesting instantiations of these definitions we provide algorithms for checking that the demands have been met. The development is illustrated by a worked example dealing with the outsourcing of data management to the cloud.", "num_citations": "0\n", "authors": ["1602"]}
{"title": "Security through Analysis and Verification (Dagstuhl Seminar 00501)\n", "abstract": " Security has increasing relevance and importance for real life applications such as Internet transactions, electronic commerce, electronic voting and smart cards thereby stressing the need for appropriate checking measures. Techniques from program verification and program logics have already proven their worth for the machine-assisted validation of secure communication protocols. This seminar emanates from recent applications of program analysis which allow fully automatic validation of systems against certain types of attack. It took place from 10. December 2000 to 15. December 2000 and comprised a number of talks, as indicated by the following abstracts, informal discussions as well as a discussion in plenum forming the basis for this report.The nature of security. Security has many facets: confidentiality, integrity, authentication, watermarking, prevention of denial of service, auditing etc. It emerged quite clearly during the seminar that there is no clear consensus about the precise definition of many of these concepts. There was agreement that to the extent possible one should try to reconcile and clarify the differences, possibly in the form of defining a formal language or logic for security requirements. During the discussions it became clear that confidentiality, as in certified mail, was a hard concept to capture precisely, despite the fact that consideration of information flow (both forward and backward) account for many ingredients of integrity and secrecy.", "num_citations": "0\n", "authors": ["1602"]}
{"title": "Program Analysis (an Appetizer)\n", "abstract": " This book is an introduction to program analysis that is meant to be considerably more elementary than our advanced book Principles of Program Analysis (Springer, 2005). Rather than using flow charts as the model of programs, the book follows our introductory book Formal Methods an Appetizer (Springer, 2019) using program graphs as the model of programs. In our experience this makes the underlying ideas more accessible to our computer science and computer engineering students on the master course 02242: Program Analysis at The Technical University of Denmark. Here we have gradually replaced our use of the more elementary parts of Principles of Program Analysis with material from the current book.", "num_citations": "0\n", "authors": ["1602"]}
{"title": "Timed Automata for Security of Real-Time Systems\n", "abstract": " This thesis was prepared at the department of Applied Mathematics and Computer Science at the Technical University of Denmark in fulfillment of the requirements for acquiring a PhD degree in Computer Science.", "num_citations": "0\n", "authors": ["1602"]}
{"title": "Procedures\n", "abstract": " Procedures (or functions) are found in most programming languages and provide a means for reusing code in a number of programming tasks. In this chapter we will illustrate how to add procedures to the Guarded Commands language. Our focus will be on defining the semantics of procedures (as opposed to reasoning about them).", "num_citations": "0\n", "authors": ["1602"]}
{"title": "Model Checking\n", "abstract": " Model checking is an approach to finding properties of programs. It can be fully automated but its efficiency is usually not as good as that of program analysis. The gain is that the precision is closer to that of program verification.", "num_citations": "0\n", "authors": ["1602"]}
{"title": "Guarded Commands\n", "abstract": " Programs are written in programming languages and in this chapter we are going to show how we can construct program graphs for all programs in a programming language. The programming language will be the (probably unfamiliar) language of Guarded Commands introduced by Dijkstra in 1975.", "num_citations": "0\n", "authors": ["1602"]}
{"title": "Language-Based Security\n", "abstract": " Security is becoming increasingly important and formal methods offer powerful techniques for ensuring it. There are three important components in security: Confidentiality, meaning that private data is not made public data; Integrity, meaning that trusted data is not influenced by dubious data; Availability, meaning that data is not inaccessible when needed. In this chapter we show how formal methods can be used to ensure that programs preserve confidentiality and integrity.", "num_citations": "0\n", "authors": ["1602"]}
{"title": "Program Verification\n", "abstract": " It is essential that programs are correct \u2013 meaning that their behaviour is as we intend. For example, a sorting routine should indeed sort the array given as input. To verify the correctness of programs one often writes invariants at various points in the program and checks their correctness. In this chapter we will illustrate this approach \u2013 working directly on program graphs.", "num_citations": "0\n", "authors": ["1602"]}
{"title": "Modelling and Verifying Communication Failure of Hybrid Systems in HCSP\n", "abstract": " Hybrid systems are dynamic systems with interacting discrete computation and continuous physical processes. They have become ubiquitous in our daily life, e.g. automotive, aerospace and medical systems, and in particular, many of them are safety-critical. For a safety-critical hybrid system, the physical process evolves continuously with respect to time, and the discrete controller monitors and controls the physical process in a correct way such that the whole system satisfies the given safety requirements. The safety of hybrid systems depends heavily on the control from the controllers. However, in the presence of communication failure, the expected control from the controller will get lost and as a consequence the physical process cannot behave as expected. In this paper, we mainly consider the communication failure caused by the non-engagement of one party in communication action, i.e. the\u00a0\u2026", "num_citations": "0\n", "authors": ["1602"]}
{"title": "A Coordination Language for Databases\n", "abstract": " We present a coordination language for the modeling of distributed database applications. The language, baptized Klaim-DB, borrows the concepts of localities and nets of the coordination language Klaim but re-incarnates the tuple spaces of Klaim as databases. It provides high-level abstractions and primitives for the access and manipulation of structured data, with integrity and atomicity considerations. We present the formal semantics of Klaim-DB and develop a type system that avoids potential runtime errors such as certain evaluation errors and mismatches of data format in tables, which are monitored in the semantics. The use of the language is illustrated in a scenario where the sales from different branches of a chain of department stores are aggregated from their local databases. Raising the abstraction level and encapsulating integrity checks in the language primitives have benefited the modeling task considerably.", "num_citations": "0\n", "authors": ["1602"]}
{"title": "of host publication: Revised Selected Papers of the 10th International Symposium on Trustworthy Global Computing\n", "abstract": " Disjunctive Information Flow for Communicating Processes The security validation of practical computer systems calls for the ability to specify and verify information flow policies that are dependent on data content. Such policies play an important role in concurrent, communicating systems: consider a scenario where messages are sent to different processes according to their tagging. We devise a security type system that enforces content-dependent information flow policies in the presence of communication and concurrency. The type system soundly guarantees a compositional noninterference property. All theoretical results have been formally proved in the Coq proof assistant [9].", "num_citations": "0\n", "authors": ["1602"]}
{"title": "of host publication: Proceedings of th 20th European Symposium on Research in Computer Security-ESORICS\n", "abstract": " Factorization of Behavioral Integrity We develop a bisimulation-based nonintereference property that describes the allowed dependencies between communication behaviors of different integrity levels. The property is able to capture all possible combinations of integrity levels for the \u201cpresence\u201d and \u201ccontent\u201d of actual communications. Channels of low presence integrity and high content integrity can be used to model the effect of Message Authentication Codes or the consequence of Denial of Service Attacks. In case the distinction between \u201cpresence\u201d and \u201ccontent\u201d is deliberately blurred, the noninterference property specialises to a classical process-algebraic property (called SBNDC). A compositionality result is given to facilitate a structural approach to the analysis of concurrent systems.", "num_citations": "0\n", "authors": ["1602"]}
{"title": "A calculus of quality for robustness against unreliable communication-DTU Orbit (11/01/2016)\n", "abstract": " A calculus of quality for robustness against unreliable communication A main challenge in the development of distributed systems is to ensure that the components continue to behave in a reasonable manner even when communication becomes unreliable. We propose a process calculus, the Quality Calculus, for programming software components where it becomes natural to plan for default behaviour in case the ideal behaviour fails due to unreliable communication and thereby to increase the quality of service offered by the system. The development is facilitated by a SAT-based robustness analysis to determine whether or not the code is vulnerable to unreliable communication. The framework is illustrated on the design of a fragment of a wireless sensor network, and is substantiated by formal proofs of correctness of the analysis, which relate the original reduction semantics of the calculus to a new semantics with explicit substitutions.", "num_citations": "0\n", "authors": ["1602"]}
{"title": "Trust-Based Enforcement of Security Policies\n", "abstract": " Two conflicting high-level goals govern the enforcement of security policies, abridged in the phrase \u201chigh security at a low cost\u201d. While these drivers seem irreconcilable, formal modelling languages and automated verification techniques can facilitate the task of finding the right balance. We propose a modelling language and a framework in which security checks can be relaxed or strengthened to save resources or increase protection, on the basis of trust relationships among communicating parties. Such relationships are automatically derived through a reputation system, hence adapt dynamically to the observed behaviour of the parties and are not fixed a priori. In order to evaluate the impact of the approach, we encode our modelling language in StoKlaim, which enables verification via the dedicated statistical model checker SAM. The overall approach is applied to a fragment of a Wireless Sensor Network, where there is a clear tension between devices with limited resources and the cost for securing the communication.", "num_citations": "0\n", "authors": ["1602"]}
{"title": "Verification of Stateful Protocols-Set-Based Abstractions in the Applied Pi-Calculus\n", "abstract": " Verification of Stateful Protocols - Set-Based Abstractions in the Applied Pi-Calculus \u2014 Welcome to DTU Research Database Skip to main navigation Skip to search Skip to main content Welcome to DTU Research Database Home Welcome to DTU Research Database Logo About DTU Orbit Home Profiles Research Units Research output Activities Projects Prizes Press / Media Search by expertise, name or affiliation Verification of Stateful Protocols - Set-Based Abstractions in the Applied Pi-Calculus Alessandro Bruni, Sebastian Alexander M\u00f6dersheim, Flemming Nielson, Hanne Riis Nielson Department of Applied Mathematics and Computer Science Research output: Chapter in Book/Report/Conference proceeding \u203a Article in proceedings \u203a Research \u203a peer-review Overview Original language English Title of host publication Proceedings of the 19th Nordic Conference on Secure IT Systems, NordSec 2014 Publisher \u2026", "num_citations": "0\n", "authors": ["1602"]}
{"title": "Availability by Design\n", "abstract": " Availability is \u201cthe property of being accessible and usable upon demand by an authorised entity\u201d[1], and its absence is termed Denial-of-Service (DoS) or unavailability. DoS typically occurs when the resources of a target server are exhausted, preventing a given service to be offered to clients and often leading to the paralysis of an entire system, with a domino effect. Our proposal aims at preventing such effect through a defensive programming style. Despite availability has received lesser attention than confidentiality and integrity, with which it forms the so-called CIA properties [2], DoS attacks to systems of public concern occur increasingly and have become infamous on the Internet, the distributed system par excellence. Besides active attackers, limited resources or optimistic assumptions about the environment can be source of unavailability, suggesting that cryptography is not the ultimate solution. We claim that\u00a0\u2026", "num_citations": "0\n", "authors": ["1602"]}
{"title": "Design-efficiency in Security\n", "abstract": " In this document, we present our applied results on balancing security and performance using a running example, which is based on sensor networks. These results are forming a basis for a new approach to balance security and performance, and therefore provide design-efficiency of key updates. We employ probabilistic model checking approach and present our modelling and analysis study using PRISM model checker.", "num_citations": "0\n", "authors": ["1602"]}
{"title": "Reachability for Finite-state Process Algebras Using Horn Clauses\n", "abstract": " In this work we present an algorithm for solving the reachability problem in finite systems that are modelled with process algebras. Our method is based on Static Analysis, in particular, Data Flow Analysis, of the syntax of a process algebraic system with multi-way synchronisation. The results of the Data Flow Analysis are used in order to build a set of Horn clauses whose least model corresponds to an overapproximation of the reachable states. The computed model can be refined after each transition, and the algorithm runs until either a state whose reachability should be checked is encountered or it is not in the least model for all constructed states and thus is definitely unreachable. The advantages of the algorithm are that in many cases only a part of the Labelled Transition System will be built which leads to lower time and memory consumption. Also, it is not necessary to save all the encountered states which\u00a0\u2026", "num_citations": "0\n", "authors": ["1602"]}
{"title": "of host publication: Theories of Programming and Formal Methods: Essays Dedicated to Jifeng He on the Occasion\n", "abstract": " Safety versus Security in the Quality Calculus Safety and security are both needed for ensuring that cyber-physical systems live up to expectations, but often an intelligent trade-off is called for, because sometimes it is impossible to obtain optimal safety at the same time as optimal security. In the context of the Quality Calculus we develop a type system for checking the extent to which safety and security goals have been met. Safety goals include showing that certain error configurations are in fact not reachable and hence do not require intelligent error handling. Security goals include showing that highly trusted communications can only be performed in highly trusted contexts. This is potentially too demanding and the Quality Calculus is therefore extended with a primitive for endorsing data to a higher trust level (accepting violations of the explicit flow) and for temporarily asserting a higher trust in the context (accepting violations of the implicit flow). This is illustrated on a worked example taken from the automotive sector and we conclude with a discussion of the theoretical properties of the type system.", "num_citations": "0\n", "authors": ["1602"]}
{"title": "Roadmap Document on Stochastic Analysis\n", "abstract": " This document was prepared as part of the MT-LAB research centre. The research centre studies the Modelling of Information Technology and is a VKR Centre of Excellence funded for five years by the VILLUM Foundation. You can read more about MT-LAB at its webpage www.MT-LAB.dk. The goal of the document is to serve as an introduction to new PhD students addressing the research goals of MT-LAB. As such it aims to provide an overview of a number of selected approaches to the modelling of stochastic systems. It should be readable not only by computers scientists with a background in formal methods but also by PhD students in stochastics that are interested in understanding the computer science approach to stochastic model checking. We have no intention of being encyclopedic in our treatment of the approaches or the literature. Rather we have made the selection of material based on the competences of the groups involved in or closely affiliated to MT-LAB, so as to ease the task of the PhD students in navigating an otherwise vast amount of literature. We have decided to publish the document in case other young researchers may find it helpful. The list of authors reflect those that have at times played a significant role in the production of the document.", "num_citations": "0\n", "authors": ["1602"]}
{"title": "LBTool: A stochastic toolkit for leave-based key updates\n", "abstract": " Quantitative techniques have been successfully employed in verification of information and communication systems. However, the use of such techniques are still rare in the area of security. In this paper, we present a toolkit that implements transient analysis on a key update method for wireless sensor networks. The analysis aims to find out the probability of a network key being compromised at a specific time point, which result in fluctuations over time for a specific key update method called Leave-based key update. For such a problem, the use of current tools is limited in many ways such as rapidly constructing a compact formal model, computing the time point where the risk is maximum, or terminating the transient analysis after the fluctuations disappear and system stabilizes. Our toolkit, LBTool, is not only resolving the above-mentioned issues, but also demonstrating how to construct models in an analytical way\u00a0\u2026", "num_citations": "0\n", "authors": ["1602"]}
{"title": "A generic approach for security policies composition: position paper\n", "abstract": " When modelling access control in distributed systems, the problem of security policies composition arises. Much work has been done on different ways of combining policies, and using different logics to do this. In this paper, we propose a more general approach based on a 4-valued logic, that abstracts from the specific setting, and groups together many of the existing ways for combining policies. Moreover, we propose going one step further, by twisting the 4-valued logic and obtaining a more traditional approach that might therefore be more appropriate for analysis.", "num_citations": "0\n", "authors": ["1602"]}
{"title": "XACML 3.0 in Answer Set Programming\n", "abstract": " We present a systematic technique for transforming XACML 3.0 policies in Answer Set Programming (ASP). We show that the resulting logic program has a unique answer set that directly corresponds to our formalisation of the standard semantics of XACML 3.0 from Ramli et. al. We demonstrate how our results make it possible to use off-the-shelf ASP solvers to formally verify properties of access control policies represented in XACML, such as checking the completeness of a set of access control policies and verifying policy properties.", "num_citations": "0\n", "authors": ["1602"]}
{"title": "CaPiTo: protocol stacks for services\n", "abstract": " Abstract CaPiTo allows the modelling of service-oriented applications using process algebras at three levels of abstraction. The abstract level focuses on the key functionality of the services; the plug-in level shows how to obtain security using standardised protocol stacks; finally, the concrete level allows to consider how security is obtained using asymmetric and symmetric cryptographic primitives. The CaPiTo approach therefore caters for a variety of developers that need to cooperate on designing and implementing service-oriented applications. We show how to formally analyse CaPiTo specifications for ensuring the absence of security flaws. The method used is based on static analysis of the corresponding LySa specifications. We illustrate the development on two industrial case studies; one taken from the banking sector and the other a single sign-on protocol.", "num_citations": "0\n", "authors": ["1602"]}
{"title": "Modelling Chinese Smart Grid\n", "abstract": " The towers are equipped with sensors such that each tower is data-\u2010wise connected to its closest two neighbours (solid lines) and less closer two other neighbours (dashed lines) as shown in Figure 1. The latter connection is considered as a back-\u2010up link and obviously it is more costly. A bone node needs to increase its RF power to 20dBm if it uses the back-\u2010up links.", "num_citations": "0\n", "authors": ["1602"]}
{"title": "Alejandro Mario Hernandez-DTU Orbit (24/02/2018)\n", "abstract": " Distributed security in closed distributed systems The goal of the present thesis is to discuss, argue and conclude about ways to provide security to the information travelling around computer systems consisting of several known locations. When developing software systems, security of the information managed by these plays an important role in their design. There should always exist techniques for ensuring that the required security properties are met. This has been thoroughly investigated through the years, and many varied methodologies have come through. In the case of distributed systems, there are even harder issues to deal with. Many approaches have been taken towards solving security problems, yet many questions remain unanswered. Most of these problems are related to some of the following facts: distributed systems do not usually have any central controller providing security to the entire system; the system heterogeneity is usually reflected in heterogeneous security aims; the software life cycle entails evolution and this includes security expectations; the distribution is useful if the entire system is \u201copen\u201d to new (a priori unknown) interactions; the distribution itself poses intrinsically more complex security-related problems, such as communication, cryptography, performance and reliability. We do not expect to solve all of these, but we shall approach the first three. In this dissertation, we take the view of a distributed system from a high-level of abstraction. We then focus on the interactions that can take place between the locations, and aim at providing security to each of these individually. The approach taken is by means of access\u00a0\u2026", "num_citations": "0\n", "authors": ["1602"]}
{"title": "Resilience analysis of key update strategies for resource-constrained networks\n", "abstract": " Severe resource limitations in certain types of networks lead to various open issues in security. Since such networks usually operate in unattended or hostile environments, revoking the cryptographic keys and establishing (also distributing) new keys - which we refer to as key update - is a critical security issue. In this paper, we investigate the behaviour of different key update strategies under deviant network conditions. We consider resource-critical networks that employ symmetric cryptography and rely on (shared) network keys. We provide a methodology for quantitative security and performance analysis, and present a case study covering six different key update strategies.", "num_citations": "0\n", "authors": ["1602"]}
{"title": "CaPiTo: protocol stacks for services\n", "abstract": " CaPiTo allows the modelling of service-oriented applications using process algebras at three levels of abstraction. The abstract level focuses on the key functionality of the services; the plug-in level shows how to obtain security using standardised protocol stacks; finally, the concrete level allows to consider how security is obtained using asymmetric and symmetric cryptographic primitives. The CaPiTo approach therefore caters for a variety of developers that need to cooperate on designing and implementing service-oriented applications. We show how to formally analyse CaPiTo specifications for ensuring the absence of security flaws. The method used is based on static analysis of the corresponding LySa specifications. We illustrate the development on two industrial case studies; one taken from the banking sector and the other a single sign-on protocol.", "num_citations": "0\n", "authors": ["1602"]}
{"title": "The CaPiTo approach to protocol validation\n", "abstract": " We show how to model service-oriented applications using the process algebra CaPiTo so that, on the one hand, we can achieve an abstract specification without being overwhelmed by the underlying implementation details and, on the other hand, we can obtain a concrete specification respecting the industrial standards used for ensuring security. We consider this development important in order to get a good agreement between the protocols analysed by formal tools and the applications developed by practitioners.             We then show how to transform the concrete specification into the LySa analysis framework, used in the SENSORIA EU project and originally developed in the DEGAS EU project, for analysing cryptographic protocols under a Dolev-Yao attacker. This allows us to perform a control flow analysis for ensuring the authenticity (as well as confidentiality) of messages exchanged between\u00a0\u2026", "num_citations": "0\n", "authors": ["1602"]}
{"title": "The CaPiTo Approach to Protocol Validation (Invited Talk)\n", "abstract": " Ingenta is not the publisher of the publication content on this website. The responsibility for the publication content rests with the publishers providing the material. Please refer to our Terms and Conditions.", "num_citations": "0\n", "authors": ["1602"]}
{"title": "High Security at a Low Cost\n", "abstract": " In the future tiny devices with microcontrollers and sensors will be in charge of numerous activities in our lives. Tracking our energy consumption and CO2 emission, controlling our living conditions, enforcing security, and monitoring our health will be some examples of their functions These devices will form wireless networks to communicate with one another, moreover their power consumption will be very low. It is not hard to predict that our modern society will depend on the correct operation of these devices, and the security of the network they are operating. Such sensor-based systems, also known as\" cyber-physical systems\", achieve security by means of cryptographic protocols. In a simplistic setting where the power consumption should be minimum and the processing power is limited, it is more likely that all devices in the network will share the same cryptographic key. In this study, we are working on the trade-off between two challenges:\" the cryptographic key should be changed frequently to preserve security\" and\" the cryptographic key should be changed rarely to save power\". We work on the ZigBee wireless sensor network standard, that offers the advantages of simple and low resource communication. We model the system as a continuous-time Markov chain, and analyze it by posing a number of questions shedding light on its behaviour. The properties we are interested in are expressed in continuous stochastic logic, and probabilistic model checker Prism is used in the analysis.", "num_citations": "0\n", "authors": ["1602"]}
{"title": "Trustworthy Global Computing: 4th International Symposium, TGC 2008, Barcelona, Spain, November 3-4, 2008, Revised Selected Papers\n", "abstract": " This book constitutes the thoroughly refereed post-conference proceedings of the 4th International Symposium on Trustworthy Global Computing, TGC 2008 held in Barcelona, Spain, in November 2008. The 12 revised papers presented together with one invited paper were carefully selected from 26 submissions during two rounds of reviewing and improvement. The TGC 2008 symposium papers focus on providing tools and frameworks for constructing well-behaved applications and for reasoning about their behavior and properties in models of computation that incorporate code and data mobility over distributed networks with highly dynamic topologies and heterogeneous devices.", "num_citations": "0\n", "authors": ["1602"]}
{"title": "Transition systems: Hvordan virker en colaautomatk?\n", "abstract": " Transition systems: Hvordan virker en colaautomatk? \u2014 DTU Research Database Skip to main navigation Skip to search Skip to main content DTU Research Database Logo About DTU Orbit Home Profiles Research Units Research Output Activities Projects Prizes Press / Media Search by expertise, name or affiliation Transition systems: Hvordan virker en colaautomatk? Henrik Pilegaard, Sebastian Nanz, Flemming Nielson, Hanne Riis Nielson Research output: Chapter in Book/Report/Conference proceeding \u203a Book chapter \u203a Education \u203a peer-review Overview Original language English Title of host publication Matematiske Horisonter Publication date 2009 Pages 63-79 ISBN (Print) 9788764304534 Publication status Published - 2009 Cite this APA Author BIBTEX Harvard Standard RIS Vancouver Pilegaard, H., Nanz, S., Nielson, F., & Nielson, HR (2009). Transition systems: Hvordan virker en colaautomatk? In \u2026", "num_citations": "0\n", "authors": ["1602"]}
{"title": "Analyse statique d\u2019un calcul d\u2019acteurs par interpr\u00e9tation abstraite\n", "abstract": " The Actor model, introduced by HEWITT and AGHA in the late 80s, describes a concurrent communicating system as a set of autonomous agents, with non uniform interfaces and communicating by the use of labeled messages. The CAP process calculus, proposed by COLA\u00c7O, is based on this model and allows to describe non trivial realistic systems, without the need of complex encodings. CAP is a higher-order calculus: messages can carry actor behaviors. Multiple works address the analysis of CAP properties, mainly by the use of inferencebased type systems using behavioral types and sub-typing. Otherwise, more recent works, by VENET and later FERET, propose the use of abstract interpretation to analyze process calculi. These approaches allow to compute non-uniform properties. For example, they are able to differentiate recursive instances of the same thread. This thesis is at the crossroad of these two approaches, applying abstract interpretation to the analysis of CAP. Following the framework of FERET, CAP is firstly expressed in a non standard form, easing its analysis. The set of reachable states is then over-approximated via a sound by construction representation within existing abstract domains.New general abstract domains are then introduced in order to improve the accuracy of existing analyses or to represent local properties. CAP specific properties such as the linearity of terms or the absence of orphan messages, are then considered in this framework. Specific abstract domains are defined and used to check these properties. The proposed framework is able to relax any existing restriction of previous analyses such as\u00a0\u2026", "num_citations": "0\n", "authors": ["1602"]}
{"title": "journal homepage: www. elsevier. com/locate/jlap\n", "abstract": " Author Index \u2014 Volume 77 (2008) The Journal of Logic and Algebraic Programming Page 1 Author Index \u2014 Volume 77 (2008) (The issue number is given in front of the page numbers) Aceto, L. and A. Ingolfsdottir, Guest Editors\u2019 Foreword (1\u20132) vii Brekling, A., MR Hansen and J. Madsen, Models and formal verification of multiprocessor systemon-chips (1\u20132) 1 Fecher, H. and H. Schmidt, Comparing disjunctive modal transition systems with an one-selecting variant (1\u20132) 20 Hansen, MR, see Brekling, A. (1\u20132) 1 Ingolfsdottir, A., see Aceto, L. (1\u20132) vii Johnsen, EB and IC Yu, Backwards type analysis of asynchronous method calls (1\u20132) 40 Kramer, S., Cryptographic protocol logic: Satisfaction for (timed) Dolev\u2013Yao cryptography (1\u20132) 60 Madsen, J., see Brekling, A. (1\u20132) 1 Nielson, F., see Pilegaard, H. (1\u20132) 92 Nielson, HR, see Pilegaard, H. (1\u20132) 92 Pilegaard, H., F. Nielson and HR Nielson, Pathway analysis for \u2026", "num_citations": "0\n", "authors": ["1602"]}
{"title": "Denotational Semantics\n", "abstract": " This is also the functionality of Sns and Ssos, and the need for partiality is again demonstrated by the statement while true do skip. The definition is summarized in Table 5.1 and we explain it in detail below; in particular, we shall define the auxiliary functions cond and FIX. For assignment, the clause", "num_citations": "0\n", "authors": ["1602"]}
{"title": "Program Analysis\n", "abstract": " Program analyses give information about the dynamic behaviour of programs. The analyses are performed statically, meaning that the programs are not run on all possible inputs in order to find the result of the analysis. On the other hand, the analyses are safe, meaning that the result of the analysis describes all possible runs of the program. This effect is obtained by letting the analysis compute with abstract properties of the \u201creal\u201d values rather than with the \u201creal\u201d values themselves.", "num_citations": "0\n", "authors": ["1602"]}
{"title": "Axiomatic Program Verification\n", "abstract": " The kinds of semantics we have seen so far specify the meaning of programs, although they may also be used to prove that given programs possess certain properties. We may distinguish among several classes of properties: partial correctness properties are properties expressing that if a given program terminates, then there will be a certain relationship between the initial and the final values of the variables. Thus a partial correctness property of a program need not ensure that it terminates. This is contrary to total correctness properties, which express that the program will terminate and that there will be a certain relationship between the initial and the final values of the variables. Thus we have partial correctness+ termination= total correctnessYet another class of properties is concerned with the resources used when executing the program; an example is the time used to execute the program on a particular\u00a0\u2026", "num_citations": "0\n", "authors": ["1602"]}
{"title": "Operational Semantics\n", "abstract": " In a natural semantics we are concerned with the relationship between the initial and the final state of an execution. Therefore the transition relation will specify the relationship between the initial state and the final state for each statement. We shall write a transition as", "num_citations": "0\n", "authors": ["1602"]}
{"title": "Semantics with {\u0391} pplications:{\u0391} n\n", "abstract": " T\u03bf \u03c4\u03c1\u03af\u03c4\u03bf \u03bc\u03ad\u03c1\u03bf\u03c2 \u03b1\u03c5\u03c4\u03ae\u03c2 \u03c4\u03b7\u03c2 \u03c3\u03b5\u03b9\u03c1\u03ac\u03c2 \u03bf\u03b4\u03b7\u03b3\u03ce\u03bd \u03b3\u03b9\u03b1 Python \u03b8\u03b1 \u03b1\u03bd\u03b1\u03bb\u03c9\u03b8\u03b5\u03af \u03c3\u03c4\u03bf \u03b3\u03b5\u03bd\u03b9\u03ba\u03cc\u03c4\u03b5\u03c1\u03bf \u03c3\u03c7\u03b5\u03b4\u03b9\u03b1\u03c3\u03bc\u03cc \u03b5\u03bd\u03cc\u03c2 \u03bf\u03bb\u03bf\u03ba\u03bb\u03b7\u03c1\u03c9\u03bc\u03ad\u03bd\u03bf\u03c5 \u03c0\u03c1\u03bf\u03b3\u03c1\u03ac\u03bc\u03bc\u03b1\u03c4\u03bf\u03c2, \u03cc\u03c7\u03b9 \u03bc\u03cc\u03bd\u03bf \u03c3\u03b5 \u03c4\u03b5\u03c7\u03bd\u03b9\u03ba\u03ad\u03c2 \u03c0\u03bf\u03c5 \u03b1\u03c0\u03bf\u03b4\u03af\u03b4\u03bf\u03c5\u03bd \u03ba\u03c5\u03c1\u03af\u03c9\u03c2 \u03cc\u03c4\u03b1\u03bd \u03b3\u03c1\u03ac\u03c6\u03bf\u03c5\u03bc\u03b5 \u03bc\u03b9\u03ba\u03c1\u03ac scripts \u03b3\u03b9\u03b1 \u03bd\u03b1 \u03b1\u03c5\u03c4\u03bf\u03bc\u03b1\u03c4\u03bf\u03c0\u03bf\u03b9\u03ae\u03c3\u03bf\u03c5\u03bc\u03b5 \u03bc\u03b9\u03ba\u03c1\u03ad\u03c2 \u03b5\u03c1\u03b3\u03b1\u03c3\u03af\u03b5\u03c2. T\u03bf \u03c0\u03c1\u03cc\u03b2\u03bb\u03b7\u03bc\u03b1, \u03bb\u03bf\u03b9\u03c0\u03cc\u03bd, \u03c0\u03bf\u03c5 \u03ba\u03b1\u03bb\u03bf\u03cd\u03bc\u03b1\u03c3\u03c4\u03b5 \u03bd\u03b1 \u03bb\u03cd\u03c3\u03bf\u03c5\u03bc\u03b5 \u03b1\u03c5\u03c4\u03ae \u03c4\u03b7 \u03c6\u03bf\u03c1\u03ac, \u03b5\u03af\u03bd\u03b1\u03b9 \u03b7 \u03b4\u03b9\u03b1\u03c7\u03b5\u03af\u03c1\u03b9\u03c3\u03b7 \u03b2\u03b9\u03b2\u03bb\u03b9\u03bf\u03b3\u03c1\u03b1\u03c6\u03af\u03b1\u03c2 \u03bc\u03b5 \u03c4\u03b7 \u03c7\u03c1\u03ae\u03c3\u03b7 Python \u03ba\u03b1\u03b9 BibTeX. \u03bf \u03c0\u03b7\u03b3\u03b1\u03af\u03bf\u03c2 \u03ba\u03ce\u03b4\u03b9\u03ba\u03b1\u03c2 \u03c0\u03bf\u03c5 \u03c7\u03c1\u03b7\u03c3\u03b9\u03bc\u03bf\u03c0\u03bf\u03b9\u03bf\u03cd\u03bc\u03b5 \u03c3\u03c4\u03bf tutorial, \u03b5\u03af\u03bd\u03b1\u03b9 \u03b4\u03b9\u03b1\u03b8\u03ad\u03c3\u03b9\u03bc\u03bf\u03c2 \u03c3\u03c4\u03b7\u03bd \u03b7\u03bb\u03b5\u03ba\u03c4\u03c1\u03bf\u03bd\u03b9\u03ba\u03ae \u03b4\u03b9\u03b5\u03cd\u03b8\u03c5\u03bd\u03c3\u03b7 http://www. linu\u03c7format. gr/files/biblio-py. tar. gz.", "num_citations": "0\n", "authors": ["1602"]}
{"title": "More on Program Analysis\n", "abstract": " The detection of signs analysis of Chapter 7 is a first-order analysis. The properties of interest are the signs of values, so rather than computing with numbers, we compute with the sign properties pos, zero, neg, etc. Constant propagation and interval analysis are also first-order analyses. A live variables analysis (see Chapter 7) is a second-order analysis. Here the properties associated with the variables are live and dead, and obviously this does not say much about the \u201creal\u201d value of the variables. However, it expresses a property of the relationship between \u201creal\u201d values: if the property is dead, then the variable could have any value whatsoever\u2014the result of the computation would be the same since the value will never be used. On the other hand, if the property is live, then the \u201creal\u201d value of the variable", "num_citations": "0\n", "authors": ["1602"]}
{"title": "More on Denotational Semantics\n", "abstract": " For both language extensions, the semantic specifications are obtained by suitable modifications of Table 5.1. Although we shall not go into great detail about the foundational properties of the specifications in the present chapter, it is important to note that the fixed point theory of chain complete partially ordered sets and continous functions presented in the previous chapter also applies for the development performed here.", "num_citations": "0\n", "authors": ["1602"]}
{"title": "More on Axiomatic Program Verification\n", "abstract": " Having introduced the axiomatic approach to proving partial correctness properties in the previous chapter, we now turn to the more demanding situation where termination guarantees need to be established as well. In the first part of the chapter, we present an axiomatic system for proving total correctness properties; that is, properties that in addition to partial correctness also guarantee termination of the program of interest. In the second part of the chapter, we study the more demanding scenario where we want to reason about the execution time of programs. To do so, we first extend the natural semantics of Chapter 2 with a notion of time and then we further develop the total correctness axiomatic system to reason about time: the resulting axiomatic system can be used to prove the order of magnitude of the execution time of programs.", "num_citations": "0\n", "authors": ["1602"]}
{"title": "More on Operational Semantics\n", "abstract": " For the While language, the choice between the structural operational semantics and the natural semantics is largely a matter of taste\u2014as expressed by Theorem 2.26, the two semantics are equivalent. For other language constructs, the situation may be more complex: sometimes it is easy to specify the semantics in one style but difficult or even impossible in the other. Also, there are situations where equivalent semantics can be specified in the two styles but where one of the semantics is to be preferred because of a particular application.In the first part of this chapter, we shall study extensions of the language While with non-sequential constructs such as abortion, non-determinism, and parallelism, and in each case we shall consider how to modify the operational semantics of the previous chapter. In the second part, we shall extend While with blocks and local variable and procedure declarations. This leads to the\u00a0\u2026", "num_citations": "0\n", "authors": ["1602"]}
{"title": "Provably Correct Implementation\n", "abstract": " A formal specification of the semantics of a programming language is useful when implementing it. In particular, it becomes possible to argue about the correctness of the implementation. We shall illustrate this by showing how to translate the language While into a structured form of assembler code for an abstract machine, and we shall then prove that the translation is correct. The idea is that we first define the meaning of the abstract machine instructions by an operational semantics. Then we define translation functions that will map expressions and statements in the While language into sequences of such instructions. The correctness result will then state that if we\u2013translate a program into code and\u2013execute the code on the abstract machine, then we get the same result as was specified by the semantic functions Sns and Ssos of Chapter 2.", "num_citations": "0\n", "authors": ["1602"]}
{"title": "Enhancing Creativity by Test Diversity\n", "abstract": " Elements of education fall in four major categories\u2014teaching, learning, evaluation, and experimentation. Each of these elements can have differing impact on the overall result of an education process, partly due to the personal experience provided to learners. Obviously, this connection also holds when parts of the education process are implemented in e-learning tools. However, often electronic modules just mimic the traditional education module they are supposed to replace or support. The typical quiz generator, for example, selects a certain amount of questions from its input to generate a quiz. However, since the initial set of questions is static, the number of possible quizzes is static as well. Students will have to take several quizzes before having seen all questions and this is often experienced as being very unsatisfactory.We suggest using finite automata, a well-understood abstraction technique from computer science, as input data for test generation. This allows describing test data in a concise and compact way, and generating a potentially infinite number of tests as well as a checker to verify solutions.", "num_citations": "0\n", "authors": ["1602"]}
{"title": "Succinct Solver\n", "abstract": " \" The succinct solver is a tool for solving constrains specified by the Alternation-free Least Fixed Point Logic (ALFP) in clausal form, which is an extension of Horn Clause.\"", "num_citations": "0\n", "authors": ["1602"]}
{"title": "Heuristics for enforcing security constraints\n", "abstract": " The flow logic approach to static analysis amounts to axiomatising the admissibility of solutions to analysis problems; when axiomatised using formulae in stratified alternation-free least fixed point logic one may use efficient algorithms for computing the least admissible solutions. We extend this scenario to validate the fulfilment of additional constraints on admissible solutions; the modified development produces a least solution together with a boolean value indicating whether or not the constraints are validated or violated.\u2014Our main contribution is the development of a deterministic heuristics for obtaining a solution that is close to the least solution while enforcing the validation of the security constraints. We illustrate it on the Bell-LaPadula mandatory access control policy where the heuristics is used to suggest modifications to the security annotations of entities in order for the security policy to hold.", "num_citations": "0\n", "authors": ["1602"]}
{"title": "Static Analysis of Processes for No Read-Up and No Write-Down\n", "abstract": " We study a variant of the no read-up/mo write-down security property of Bell and LaPadula for processes in the T-calculus. Once processes are given levels of security clearance, we statically check that a process at a high level never sends names to processes at a lower level. The static check is based on a Control Flow Analysis for the T-calculus that establishes a super-set of the set of names to which a given name may be bound and of the set of names that may be sent and received along a given channel, taking into account its directionality. The static check is shown to imply the natural dynamic condition.", "num_citations": "0\n", "authors": ["1602"]}
{"title": "Static Analysis for Secrecy and Non-interference\n", "abstract": " We introduce the 1/SPI-calculus that strengthens the notion of \u201cperfect symmetric cryptography\u201d of the spi-calculus by taking time into account. This involves defining an operational semantics, defining a control flow analysis (CFA) in the form of a flow logic, and proving semantic correctness. Our first result is that secrecy in the sense of Dolev-Yao can be expressed in terms of the CFA. Our second result is that also non-interference in the sense of Abadi can be expressed in terms of the CFA, unlike Abadi we find the non-interference property to be an extension of the Dolev-Yao property.", "num_citations": "0\n", "authors": ["1602"]}
{"title": "Data Flow Analysis\n", "abstract": " In this chapter we introduce techniques for Data Flow Analysis. Data Flow Analysis is the traditional form of program analysis which is described in many textbooks on compiler writing. We will present analyses for the simple imperative language While that was introduced in Chapter 1. This includes a number of classical Data Flow Analyses: Available Expressions, Reaching Definitions, Very Busy Expressions and Live Variables. We introduce an operational semantics for While and demonstrate the correctness of the Live Variables Analysis. We then present the notion of Monotone Frameworks and show how the examples may be recast as such frameworks. We continue by presenting a worklist algorithm for solving flow equations and we study its termination and correctness properties. The chapter concludes with a presentation of some advanced topics, including Interprocedural Data Flow Analysis and\u00a0\u2026", "num_citations": "0\n", "authors": ["1602"]}
{"title": "Constraint Based Analysis\n", "abstract": " In this chapter we present the technique of Constraint Based Analysis using a simple functional language, FUN. We begin by presenting an abstract specification of a Control Flow Analysis and then study its theoretical properties: it is correct with respect to a Structural Operational Semantics and it can be used to analyse all programs. This specification of the analysis does not immediately lend itself to an efficient algorithm for computing a solution so we proceed by developing first a syntax directed specification and then a constraint based formulation and finally we show how the constraints can be solved. We conclude by illustrating how the precision of the analysis can be improved by combining it with Data Flow Analysis and by incorporating context information thereby linking up with the development of the previous chapter.", "num_citations": "0\n", "authors": ["1602"]}
{"title": "International Workshop on Principles of Program Analysis\n", "abstract": " In this book we shall introduce four of the main approaches to program analysis Data Flow Analysis, Control Flow Analysis, Abstract Interpretation, and Type and Effect Systems. Each of Chapters 2 to 5 deals with one of these approaches to some length and generally treats the more advanced material in later sections. Throughout the book we aim at stressing the many similarities between what may at a first glance appear to be very unrelated approaches. To help getting this idea across, and to serve as a gentle introduction, this chapter treats all of-the approaches at the level of examples. The technical details are worked-out but it may be difficult to apply the techniques to related examples until some of the material of later chapters have been studied.Descriptors:", "num_citations": "0\n", "authors": ["1602"]}
{"title": "Validating Programs in Concurrent ML\n", "abstract": " Interactive and embedded applications often require an ability to deal with concurrent operations. In this chapter we give an overview of one way to extend a functional language with concurrency primitives. Unfortunately, the presence of concurrency may make programs harder to reason about because the flow of control is less perspicuous (as is the case when imperative features are present). This calls for the use of automatic techniques to extract the flow of control in a more readable and succinct form so as to validate the overall structure of communication taking place in the program. In this chapter, we show how type and effect systems can be extended with a notion of causal behaviour (in the manner of process algebras) that makes this possible.", "num_citations": "0\n", "authors": ["1602"]}
{"title": "Interprocedural Control Flow Analysis (Extended version)\n", "abstract": " Control Flow Analysis is a widely used approach for analysing functional and object oriented programs and recently it has also successfully been used to analyse more challenging notions of computation involving concurrency. However, once the applications become more demanding also the analysis needs to be more precise in its ability to deal with mutable state (or side-effects) and to perform polyvariant (or context-sensitive) analysis. Several insights in Data Flow Analysis and Abstract Interpretation show how to do so for imperative programs but the techniques have not had much impact on Control Flow Analysis because of the less abstract way in which the techniques are normally expressed. In this paper we show how to incorporate a number of key insights from Data Flow Analysis involving such advanced interprocedural techniques as call strings and assumption sets using Abstract Interpretation to induce the analyses from a general collecting semantics.", "num_citations": "0\n", "authors": ["1602"]}
{"title": "Chiara Bodei, Pierpaolo Degano, Flemming Nielson, Hanne Riis Nielson 2\n", "abstract": " Control Flow Analysis is a static technique for predicting safe and computable approximations to the set of values that the objects of a program may assume during its execution. We present an analysis for the-calculus that shows how names will be bound to actual channels at run time. The formulation of the analysis requires no extensions to the-calculus, except for assigning channels\" to the occurrences of names within restrictions, and assigning binders\" to the occurrences of names within input prefixes. The result of our analysis establishes a super-set of the set of names to which a given name may be bound and of the set of names that may be sent along a given channel. Applications of our analysis include establishing simple security properties of processes. One example is that P has no leaks, ie P offers communication through public channels only, and confines its secret names within itself.", "num_citations": "0\n", "authors": ["1602"]}
{"title": "Polymorphic Subtyping for Side E ects\n", "abstract": " The integration of polymorphism in the style of the ML let-construct, subtyping, and e ects modelling assignment or communication into one common type system has proved remarkably di cult. This paper presents a type system for a core subset of Concurrent ML that extends the ML type system in a conservative way and that employs all these features; and in addition causality information has been incorporated into the e ects which may therefore be termed behaviours.The semantic soundness of the system is established via a subject reduction result. An inference algorithm is presented; it is proved sound and in a certain sense also complete. A prototype system based on this algorithm has been implemented and can be experienced on the WWW; thanks to a special post-processing phase it produces quite readable and informative output.", "num_citations": "0\n", "authors": ["1602"]}
{"title": "The abstract interpretation based approach (2; 3) is in a sense an intermediary\n", "abstract": " between the flow based and semantics based approaches. It operates equally well on property spaces modelling intensional information as on property spaces modelling extensional information. On the positive side, it allows to give a systematic account of the design of flow based and semantics based program analyses by\" calculating\" the analyses rather than merely specifying them; additionally it offers general tech-niques like\" widening operators\" for the approximation of fixed points. On the negative side, the available technology is not very programming language dependent: good examples of widening operators are hard to find in the literature, and the approach is often based on a rather low-level notion of operational semantics.Programming Languages Program analysis has a number of applications but none as dominating as improv-ing the quality of the code generated by compilers. It is important to consider whether or not the results of the analysis, and any imprecisions in the information obtained, is of relevance to the programmer or not. If it is only of relevance to the compiler internals there is no harm in having the analysis operate on the intermediate language of the compiler. If the information is also of relevance to the programmer, then the use of an intermediate language may make it impossible to present the information to the programmer. Consequently he may be unable to understand why the program cannot be implemented efficiently and how to modify the program. Similarly, there may be small tricks (like don't curry functions need-lessly) that will help a certain analysis technology to produce more precise results or to do so\u00a0\u2026", "num_citations": "0\n", "authors": ["1602"]}
{"title": "Perspectives on program analysis\n", "abstract": " To guide the research efforts in the area of program analysis it is necessary to provide a taxonomy of the various approaches (identifying strengths and weaknesses), and to explore the links to programming languages and theoretical computer science.", "num_citations": "0\n", "authors": ["1602"]}
{"title": "Polymorphic Subtyping for E ect Analysis: the Semantics\n", "abstract": " We study an annotated type and e ect system that integrates let-polymorphism, e ects, and subtyping into an annotated type and e ect system for a fragment of Concurrent ML. First a small step operational semantics is de ned for Concurrent ML and next the annotated type and e ect system is proved semantically sound. This provides insights into the rule for generalisation in the annotated type and e ect system.", "num_citations": "0\n", "authors": ["1602"]}
{"title": "Polymorphic Subtyping for E ect Analysis: the Integration\n", "abstract": " The integration of polymorphism (in the style of the ML let-construct), subtyping, and e ects (modelling assignment or communication) into one common type system has proved remarkably di cult. One line of research has succeeded in integrating polymorphism and subtyping; adding e ects in a straightforward way results in a semantically unsound system. Another line of research has succeeded in integrating polymorphism, e ects, and sube ecting; adding subtyping in a straightforward way invalidates the construction of the inference algorithm. This paper integrates all of polymorphism, e ects, and subtyping into an annotated type and e ect system for Concurrent ML and shows that the resulting system is a conservative extension of the ML type system.", "num_citations": "0\n", "authors": ["1602"]}
{"title": "Polymorphic Subtyping for Effect Analysis: The Integration\n", "abstract": " The integration of polymorphism (in style of the ML let-construct), subtyping, and effects (modelling assignment or communication) into one common type system has proved remarkably difficult. One line of research has succeeded in integrating polymorphism and subtyping; adding effects in a straightforward way results in a semantically unsound system. Another line of research has succeeded in integrating polymorphism, effects, and subeffecting; adding sybtyping in a straightforward way invalidaters the construction of the inference algorithm. This paper integrates all op polymorphism, effects, and sybtyping into an annotated type and effect system for Concurrent ML and shows that the resulting system is a conservative extension of the ML type system.", "num_citations": "0\n", "authors": ["1602"]}
{"title": "Polymorphic Subtyping for Effect Analysis: The Semantics\n", "abstract": " We study an annotated type and effect system that integrates let-polymorphism, effects, and subtyping into an annotated type and effect system for a fragment of Concurrent ML. First a small step operational semantics is defined for concurrent ML and next the annotated type and effect system is proved semantically sound. This provides insights into the rule for generalisation in the annotated type and effect system.", "num_citations": "0\n", "authors": ["1602"]}
{"title": "Organization Committee\n", "abstract": " CiteSeerX \u2014 Organization Committee: Documents Authors Tables Log in Sign up MetaCart DMCA Donate CiteSeerX logo Documents: Advanced Search Include Citations Authors: Advanced Search Include Citations Tables: DMCA Organization Committee: (1995) Cached Download as a PDF Download Links [ojs.statsbiblioteket.dk] Save to List Add to Collection Correct Errors Monitor Changes by Hanne Riis Nielson , Kirsten Lackner Solberg , Fritz Henglein , Daniel Le Me\u0301tayer , Flemming Nielson , David Wright , Hanne Riis , Nielson Kirsten , Lackner Solberg Summary Citations Active Bibliography Co-citation Clustered Documents Version History Share Facebook Twitter Reddit Bibsonomy OpenURL Abstract of the workshop Powered by: Apache Solr About CiteSeerX Submit and Index Documents Privacy Policy Help Data Source Contact Us Developed at and hosted by The College of Information Sciences and \u2026", "num_citations": "0\n", "authors": ["1602"]}
{"title": "Design, Analysis and Reasoning about Tools: Abstracts from the Third Workshop\n", "abstract": " The third DART workshop took place on Thursday August l9th and Friday August 20th at the Department of Computer Science (DIKU) at the University of Copenhagen; it was organized by Mads Rosendahl and others at DIKU, and Torben Amtoft and Susanne Br\u00f8nberg helped producing this report. The first day comprised survey presentations whereas the second contained more research oriented talks. The primary aim of the workshop was to increase the awareness of DART participants for each other\u2019s work, to stimulate collaboration between the different groups, and to inform Danish industry about the skills possessed by the groups.", "num_citations": "0\n", "authors": ["1602"]}
{"title": "Design, Analysis and Reasoning about Tools\n", "abstract": " The third DART workshop took place on Thursday August l9th and Friday August 20th at the Department of Computer Science (DIKU) at the University of Copenhagen; it was organized by Mads Rosendahl and others at DIKU, and Torben Amtoft and Susanne Br\u00f8nberg helped producing this report. The first day comprised survey presentations whereas the second contained more research oriented talks. The primary aim of the workshop was to increase the awareness of DART participants for each other\u2019s work, to stimulate collaboration between the different groups, and to inform Danish industry about the skills possessed by the groups.", "num_citations": "0\n", "authors": ["1602"]}
{"title": "Strictness Analysis\n", "abstract": " We give upper bounds on the number of times the fixed point operator needs to be unfolded for strictness analysis of functional languages with lists. This extends previous work both in the syntax-directed nature of the approach and in the ability to deal with Wadler's method for analysing lists. Limitations of the method are indicated.", "num_citations": "0\n", "authors": ["1602"]}
{"title": "Design, analysis and Reasoning about Tools: Abstracts from the Second Workshop (Aalborg, 1992, 20-21 August)\n", "abstract": " The second DART workshop took place on Thursday August 20\u2019th and Friday August 21\u2019st at Limfjordshotellet in Aalborg. The primary aim of the workshop was to increase the awareness of DART participants for each other\u2019s work, and to stimulate collaboration between the different groups. In addition to this, the Thursday programme was planned so as to be of interest also to computer scientists not participating in DART; hence a number of survey talks about recent research were presented by the contact persons for each area.A brief overview of DART will be given in the remainder of this Introduction; for a more detailed description please consult Section 3 of [95]. The remaining sections list the abstracts of the talks given (Section 2), report on the current state of activities (Sections 3 and 4) and give an overview of all research publications from DART participants (Section 5).", "num_citations": "0\n", "authors": ["1602"]}
{"title": "Fitness Conditions for fixed Point Iteration\n", "abstract": " This paper provides a link between the formulation of static program analyses using the framework of abstract interpretation (popular for functional languages) and using the more classical framework of data flow analysis (popular for imperative languages). In particular we show how the classical notions of fastness, rapidity and k-boundedness carry over to the abstract interpretation framework and how this may be used to bound the number of times a functional should be unfolded in order to yield the fixed point. This is supplemented with a number of results on how to calculate the bounds for iterative forms (as for tail recursion), for linear forms (as for one nested recursive call), and for primitive recursive forms. In some cases this improves the''worst case''results of HR Nielson and F. Nielson: Bounded Fixed Point Iteration, but more importantly it gives much better''average case''results.", "num_citations": "0\n", "authors": ["1602"]}
{"title": "Computer Science Department, Aarhus University\n", "abstract": " This paper provides a link between the formulation of static program analyses using the frame-work of abstract interpretation (popular for func-tional languages) and using the more classical framework of data flow analysis (popular for im-perative languages). In particular we show how the classical notions of fastness, rapidity and k-boundedness carry over to the abstract interpre-tation framework and how this may be used to bound the number of times a functional should be unfolded in order to yield the fixed point. This is supplemented with a number of results on how to calculate the bounds for iterative forms (as for tail recursion), for linear forms (as for one nested recursive call), and for primitive recursive forms. In some cases this improves the \u201cworst case\u201d results of [9], but more importantly it gives much better \u201caverage case\u201d results. where", "num_citations": "0\n", "authors": ["1602"]}
{"title": "Design, Analysis and Reasoning about Tools: Abstracts from the First Workshop (Aarhus, Danmark, 1991, September 16-17\n", "abstract": " The first DART workshop took place on September 16th and September 17th at Aarhus University. It attracted some 26 attendees and 16 halfhour talks were given. This booklet gives\u2022 a brief introduction,\u2022 abstracts of all talks, and\u2022 a detailed description of the goals of the DART project.", "num_citations": "0\n", "authors": ["1602"]}
{"title": "The Mixed-Calculus and Combinatory Logic (an overview)\n", "abstract": " The distinction between binding times is important for the efficiency of a compiler: if parts of the computations of a program can be performed at compile-time then less time will be needed at run-time. As an example consider the program select that returns the n'th element of a list l. In the l-calculus it may be written select= fir (AS. An. l. if eq (1, n) then hd l else S (sub (n, 1))(tl 1))", "num_citations": "0\n", "authors": ["1602"]}
{"title": "The Mixed Lambda-Calculus and Combinatory Logic (an overview)\n", "abstract": " The Mixed Lambda-Calculus and Combinatory Logic (an overview) \u2014 Welcome to DTU Research Database Skip to main navigation Skip to search Skip to main content Welcome to DTU Research Database Home Welcome to DTU Research Database Logo About DTU Orbit Home Profiles Research Units Research output Activities Projects Prizes Press / Media Search by expertise, name or affiliation The Mixed Lambda-Calculus and Combinatory Logic (an overview) Hanne Riis Nielson, Flemming Nielson Research output: Chapter in Book/Report/Conference proceeding \u203a Article in proceedings \u203a Research \u203a peer-review Overview Original language English Title of host publication Computing and Information 1989 Publisher North-Holland Publication date 1989 Pages 39-45 Publication status Published - 1989 Event Computing and Information 1989 - Duration: 1 Jan 1989 \u2192 \u2026 Conference Conference Computing \u2026", "num_citations": "0\n", "authors": ["1602"]}
{"title": "Helmut Seidl\n", "abstract": " The Succinct Solver Suite offers two analysis engines for solving data and control flow problems expressed in clausal form in a large fragment of first order logic. The solvers have proved to be useful for a variety of applications including security properties of Java Card bytecode, access control features of Mobile and Discretionary Ambients, and validation of protocol narrations formalised in a suitable process algebra. Both solvers operate over finite domains although they can cope with regular sets of trees by direct encoding of the tree grammars; they differ in fine details about the demands on the universe and the extent to which universal quantification is allowed. A number of transformation strategies, mainly automatic, have been studied aiming on the one hand to increase the efficiency of the solving process, and on the other hand to increase the ease with which users can develop analyses. The results from benchmarking against state-of-the-art solvers are encouraging. 1", "num_citations": "0\n", "authors": ["1602"]}
{"title": "CSF 2019\n", "abstract": " The following topics are dealt with: security of data; cryptography; computational complexity; data privacy; formal verification; program verification; cryptographic protocols; program diagnostics; graph theory; formal languages.", "num_citations": "0\n", "authors": ["1602"]}
{"title": "NordSecMob Winter School [Programme overview] DTU Week 2, 2014\n", "abstract": " Welcome to the NordSecMob Winter School at DTU main campus in Lyngby 7.-10. January 2014. Most participants will fly in Monday, and will join in an evening walk in Copenhagen before dinner at 6pm at the hotel. Classes start daily at 8am in Building 306 Auditorium 32. Saturday is departure day.", "num_citations": "0\n", "authors": ["1602"]}
{"title": "B\u00fccher und Buch-Herausgaben\n", "abstract": " Publikationseintrag [Zur\u00fcck] B\u00fccher und Buch-Herausgaben: M. Matteo, M. Ryan, P. Ah-Fat, M. Alabbad, M. Alvim, Z. Aslanyan, N. Atzei, K. Babel, M. Bartoletti, L. Bauer, A. Blot, S. Bursuc, P. Ca\u00f1ones, G. Casini, V. Cheval, T. Cimoli, M. Cramer, J. Dreier, C. Dum\u00e9nil, D. Hedin, M. Hicks, M. Huth, L. Jia, C. Johansen, O. Jones, R. Khedri, B. K\u00f6pf, S. Kremer, P. Laud, P. Mardziel, F. Nielson, M. Pettai, F. Piessens, W. Rafnsson, J. Reineke, A. Sabelfeld, R. Sasse, A. Sj\u00f6sten, T. Terauchi, S. Xu, M. Yamamoto (Hrg.): \"Principles of Security and Trust\"; Springer-Verlag, Berlin, Heidelberg, 2017, ISBN: 978-3-662-54454-9; 1 S. \"Offizielle\" elektronische Version der Publikation (entsprechend ihrem Digital Object Identifier - DOI) http://dx.doi.org/10.1007/978-3-662-54455-6 Elektronische Version der Publikation: http://publik.tuwien.ac.at/files/publik_268432.pdf Erstellt aus der Publikationsdatenbank der Technischen Universit\u00e4t Wien. \u2026", "num_citations": "0\n", "authors": ["1602"]}
{"title": "CSF 2017\n", "abstract": " External Reviewers | IEEE Conference Publication | IEEE Xplore External Reviewers Abstract: The conference offers a note of thanks and lists its reviewers. Published in: 2017 IEEE 30th Computer Security Foundations Symposium (CSF) Article #: Date of Conference: 21-25 Aug. 2017 Date Added to IEEE Xplore: 28 September 2017 ISBN Information: Electronic ISBN: 978-1-5386-3217-8 USB ISBN: 978-1-5386-3216-1 Print on Demand(PoD) ISBN: 978-1-5386-3218-5 ISSN Information: Electronic ISSN: 2374-8303 INSPEC Accession Number: Persistent Link: https://xplorestaging.ieee.org/servlet/opac?punumber=8048777 More \u00bb Publisher: IEEE IEEE Account Change Username/Password Update Address Purchase Details Payment Options Order History View Purchased Documents Profile Information Communications Preferences Profession and Education Technical Interests Need Help? US & Canada: +1 800 678 \u2026", "num_citations": "0\n", "authors": ["1602"]}
{"title": "38050 Povo\u2013Trento (Italy), Via Sommarive 14\n", "abstract": " This paper presents a static analysis for investigating properties of biological systems specified in BioAmbients. We exploit the control flow analysis to decode the bindings of variables induced by communications and to build a relation of the ambients that can interact with each other. We eventually apply our analysis to an example of gene regulation by positive feedback taken from the literature.", "num_citations": "0\n", "authors": ["1602"]}
{"title": "Type-checking Availability in Choreographic Programming\n", "abstract": " Choreographic programming is a programming-language design approach that drives a safe protocol development in distributed systems. We study choreographic programming for loosely-coupled infrastructures, where the availability of components may change at runtime. We introduce a choreography language featuring novel operators for multiparty, partial and collective communications; we provide a type discipline that controls how partial communications refer only to available components; and we show that well-typed choreographies enjoy progress.", "num_citations": "0\n", "authors": ["1602"]}
{"title": "Securing statically-verified communications protocols against timing attacks\n", "abstract": " Performance and mobility Mobility and security Mobility and scalability For such a problem it can suffice to undertake two, separate, complementary analyses.", "num_citations": "0\n", "authors": ["1602"]}
{"title": "Information Flow Security for Services\n", "abstract": " Background. Service-Oriented Computing (SOC) is an emerging paradigm where services are understood as autonomous, platform-independent computational entities that can be described, published, discovered, and dynamically assembled for developing massively distributed, interoperable, evolvable systems. However, lacking theoretical and engineering foundations, service-oriented computing and development today is done in a pragmatic, mostly ad-hoc way. Besides functional or quality-of-service requirements, security issues become of utmost importance in the design of services for SOC as well as in the utilisation and composition of services in an SOC-infrastructure. Due to the global availability of services and their reuse in unpredictable environments, non-leakage of information\u2014besides the well-established goals of authorisation, authentication, and integrity\u2014is a major design issue in developing secure services.Topic of the PhD work. This PhD work shall study the systematic integration of non-leakage properties into SOC: From the software engineering perspective, means to model security-level-enriched service descriptions and service composition descriptions have to be worked out and have to be combined with best-practice notations and tools. From the view of security analysis, formal methods for ensuring non-leakage have to be extended to services and service composition. Integrating software engineering with security analysis, formal analysis has to be made available for the software engineer at the service design level and security preserving model transformations from designs to code have to be devised.", "num_citations": "0\n", "authors": ["1602"]}
{"title": "Control Flow Analysis for Security Protocols\n", "abstract": " Control Flow Analysis for Security Protocols Page 1 Control Flow Analysis for Security Protocols Chiara Bodei and Pierpaolo Degano Dipartimento di Informatica, Universit\u00e0 di Pisa, Italy Mikael Buchholtz, Han Gao, Hanne Riis Nielson, and Flemming Nielson Informatics and Mathematical Modelling, Technical University of Denmark Calculi and Models for Security, Pisa, September 2007 \u2013 p.1/26 Page 2 Approach Define a protocol (using a process calculus) Define a Dolev-Yao style attacker Track message flow for protocol and attacker using control flow analysis If messages end up in a wrong place then there may be a problem Attacker can alter message flow arbitrarily Focus on encryption and decryption Calculi and Models for Security, Pisa, September 2007 \u2013 p.2/26 Page 3 Making Narrations Precise Typically, protocols are described by narrations and a textual description but details may be imprecise We make \u2026", "num_citations": "0\n", "authors": ["1602"]}
{"title": "Modelling and Verifying Dependability of Hybrid Systems in HCSP\n", "abstract": " Hybrid systems are dynamic systems with interacting discrete computation and continuous physical processes. They have become ubiquitous in our daily life, eg, automotive, aerospace, medical systems and so on, particular, many of them are safety-critical. For these safety critical systems, it is demanded to guarantee not only the correctness (safety normally), ie, its functions satisfying the given requirements, but also the dependability, ie, the resistance to the unexpected behaviour from its environment, as many of them are deployed in highly uncertain environment, and the unexpected behaviour from the environment may result in a correct system malfunctioning. For example, the interactions between a controller and a physical processes are possibly realised via (wireless) communications. In case that the communications fail, the expected control from the controller may get lost and as a consequence the physical processes cannot behave as expected. In the literature, how to guarantee the correctness of hybrid systems has been extensively investigated, but there is little work on dependability of hybrid systems. To address this issue, this paper proposes a formal framework by extending HCSP, a formal modeling language for hybrid systems, for modelling and verification of hybrid systems in the presence of communication failure. Thus, safety and dependability of hybrid systems can be considered in the unform framework. Furthermore, by leveraging the expressivity and efficiency, we present two inference systems for the extension, and correspondingly implement two theorem provers in Isabelle/HOL. To illustrate our approach, we consider a\u00a0\u2026", "num_citations": "0\n", "authors": ["1602"]}
{"title": "Content-Dependent Security Policies in Avionics\n", "abstract": " We describe a tool (CBIF) for Content-Based Information Flow Control for a subset of the C programming language and show how to use it on applications from the avionics industry. In particular, we consider the secure gateways used in the separation kernels of operating systems designed according to the principles of Multiple Independent Levels of Security (MILS).", "num_citations": "0\n", "authors": ["1602"]}
{"title": "Verification of Stateful Protocols\n", "abstract": " An ideally designed security protocol should not be state-dependent. In practice however real applications require a certain amount of state for different reasons: encryption keys need to be updated periodically to prevent attackers from learning valid ones, messages are signed with timestamps in order to avoid replaying them after they are no longer valid, etc. Specialised protocols that need to run with bandwidth and real-time constraints may rely solely on state mechanisms to provide their claimed security properties, such as MaCAN and CANAuth, two proposed protocols for automotive that we recently analysed [1]. We propose an extension of the applied \u03c0-calculus with support for potentially infinite sets of values. With this extension we are able to analyse protocols with unbounded number of sessions, where security and authenticity properties rely on the use of counters and timestamps, or databases of keys\u00a0\u2026", "num_citations": "0\n", "authors": ["1602"]}
{"title": "Guest Editor\u2019s foreword MR Hansen 355 Three-valued abstraction for probabilistic systems J.-P. Katoen, D. Klink, M. Leucker and V. Wolf 356 Automated debugging based on a\u00a0\u2026\n", "abstract": " Volume 81, issue 4, May 2012 Page 1 CONTENTS Special Issue Guest Editor\u2019s foreword MR Hansen 355 Three-valued abstraction for probabilistic systems J.-P. Katoen, D. Klink, M. Leucker and V. Wolf 356 Automated debugging based on a constraint model of the program and a test case F. Wotawa, M. Nica and I. Moraru 390 Modal transition systems with weight intervals L. Juhl, KG Larsen and J. Srba 408 A formal approach to the specification and transformation of constraints in MDE A. Rutle, A. Rossini, Y. Lamo and U. Wolter 422 A dynamic deontic logic for complex contracts C. Prisacariu and G. Schneider 458 A relational realizability model for higher-order stateful ADTs L. Birkedal, K. St\u00f8vring and J. Thamsborg 491 Static Analysis of IMC N. Skrypnyuk, F. Nielson and H. Pilegaard 522 Termination detection for active objects FS de Boer, I. Grabe and M. Steffen 541 Volume 81, issue 4, May 2012 doi:10.1016/\u2026", "num_citations": "0\n", "authors": ["1602"]}
{"title": "Backwards type analysis of asynchronous method calls EB Johnsen and IC Yu 40 Cryptographic protocol logic: Satisfaction for (timed) Dolev\u2013Yao cryptography S. Kramer 60 Pathway\u00a0\u2026\n", "abstract": " Volume 77, issues 1\u20132, September/October 2008 Page 1 CONTENTS Special issue Guest Editors\u00d5 Foreword L. Aceto and A. Ingolfsdottir vii Models and formal verification of multiprocessor system-on-chips A. Brekling, MR Hansen and J. Madsen 1 Comparing disjunctive modal transition systems with an one-selecting variant H. Fecher and H. Schmidt 20 Backwards type analysis of asynchronous method calls EB Johnsen and IC Yu 40 Cryptographic protocol logic: Satisfaction for (timed) Dolev\u2013Yao cryptography S. Kramer 60 Pathway analysis for BioAmbients H. Pilegaard, F. Nielson and HR Nielson 92 Program and proof optimizations with type systems A. Saabas and T. Uustalu 131 Author Index \u2013 Volume 77 (2008) 155 Keyword Index \u2013 Volume 77 (2008) 156 Volume 77, issues 1\u20132, September/October 2008 doi:10.1016/S1567-8326(08)00068-4 \u2026", "num_citations": "0\n", "authors": ["1602"]}
{"title": "Control Flow Analysis for the Spi-Calculus and possible Applications to Security\n", "abstract": " Control Flow Analysis is a static technique for predicting safe and computable approximations to the set of values that the objects of a program may assume during its execution. Traditionally used for code optimization, as other static techniques, Control Flow Analysis have been recently used to address security issues. We present a preliminary study for concurrent languages oriented to security (see Bod]). To investigate them in a pure form we shall use the spi-calculus AG97, AG99] which is which is an extension of the-calculus MPW92], enriched with primitives for encryption and decryption. The analysis presented for the Spi-calculus extends the Control Flow Analysis given for the-calculus and track the behaviour of names, messages and values. More precisely, it establishes a super-set of the set of: values (eg channels, encrypted values) to which a given variable may be bound; messages that may be sent along\u00a0\u2026", "num_citations": "0\n", "authors": ["1602"]}
{"title": "Sessions for Services\n", "abstract": " Background. The project lies at one of the intersection points between the research conducted at the two institutions involved\u2014Language Based Technology group, Technical University of Denmark, and Laboratory for Global Computing, University of Lisbon\u2014, and aims at understanding how session types can be combined with flow logic in order to address open problems in service oriented computing. Service-oriented computing is an emerging paradigm where services are understood as autonomous, platform-independent computational entities that can be described, published, categorised, discovered, and dynamically assembled for developing massively distributed, interoperable, evolvable systems and applications. These characteristics pushed service-oriented computing towards nowadays widespread success, demonstrated by the fact that many large companies invested a lot of efforts and resources to\u00a0\u2026", "num_citations": "0\n", "authors": ["1602"]}
{"title": "Static Analysis of Services\n", "abstract": " Static Analysis has its origins in improving the efficiency of interpreters and compiled code but is gaining increased importance due to its ability to validate important aspects of systems behaviour. For several years static analysis have been used to analyse process algebras for a variety of communication and mobility paradigms in order to establish communication invariants and correctness of communication protocols.A new challenge arises from the use of process algebras for modelling services-ensuring for example that service invocations do not interfere with each other. In these lectures we provide the foundations for performing static analysis for proces algebras including considerations of correctness, adequacy and complexity and touching upon the distinction between compositionality and global characteristic features.", "num_citations": "0\n", "authors": ["1602"]}
{"title": "Control Flow Analysis and Security\n", "abstract": " \u2022 Choose those values of interest for the language.\u2022 Define the shape of estimates.\u2022 Define a number of clauses.\u2022 Prove that all estimates are semantically correct.\u2022 Prove that least estimate exist.\u2022 Derive a constructive procedure that builds estimates.\u2022 Select a specific dynamic security property and define a static check on estimates.", "num_citations": "0\n", "authors": ["1602"]}
{"title": "\u0426\u0433\u0436\u0431 \u0430 \u043e \u0430 \u0420\u0433\u0436\u0432 \u0430 \u0439\u0437 \u0437\u0418 \u042b\u0438\u0436\u0433\u0432 \u0430\u043d \u042a \u0433 \u0432 \u043e \u0430 \u042a \u0430 \u0438 \u0433\u0432\u0437 \u0432 \u042b\u0434\n", "abstract": " We exhibit a rich class of Horn clauses, which we call \u04201, whose least models, though possibly infinite, can be computed effectively. We show that the least model of an \u04201 clause consists of so-called strongly recognizable relations and present an exponential normalization procedure to compute it. In order to obtain a practical tool for program analysis, we identify a restriction of \u04201 clauses, which we call \u04202, where the least models can be computed in polynomial time. This fragment still allows to express, eg, Cartesian product and transitive closure of relations. Inside \u04202, we exhibit a fragment \u04203 where normalization is even cubic. We demonstrate the usefulness of our approach by deriving a cubic control-flow analysis for the Spi calculus 1\u2104 as presented in 14\u2104.", "num_citations": "0\n", "authors": ["1602"]}
{"title": "D3. a: Advances in Analysis Technology\n", "abstract": " The goal of WP3 is to develop qualitative analyses for verifying properties of service implementations with respect to their formal specifications. This document summarises mainly the research activity carried out in months 13 to 24 within the tasks T3. 1, T3. 2, T3. 3, and T3. 4. Altogether, 34 original contributions have emerged as a result of this research activity. They are briefly described and put in a broader perspective in this document. We refer to the references given in the \u201cRelevant Sensoria Publications and Reports\u201d section for the full details of the contributions.", "num_citations": "0\n", "authors": ["1602"]}
{"title": "DEGAS IST-2001-32072\n", "abstract": " This document constitutes documentation of a prototype tool for static analysis of security protocols given as processes in the process calculus LySa.", "num_citations": "0\n", "authors": ["1602"]}