{"title": "Incremental support vector learning for ordinal regression\n", "abstract": " Support vector ordinal regression (SVOR) is a popular method to tackle ordinal regression problems. However, until now there were no effective algorithms proposed to address incremental SVOR learning due to the complicated formulations of SVOR. Recently, an interesting accurate on-line algorithm was proposed for training \u03bd-support vector classification (\u03bd-SVC), which can handle a quadratic formulation with a pair of equality constraints. In this paper, we first present a modified SVOR formulation based on a sum-of-margins strategy. The formulation has multiple constraints, and each constraint includes a mixture of an equality and an inequality. Then, we extend the accurate on-line \u03bd-SVC algorithm to the modified formulation, and propose an effective incremental SVOR algorithm. The algorithm can handle a quadratic formulation with multiple constraints, where each constraint is constituted of an equality and\u00a0\u2026", "num_citations": "715\n", "authors": ["2098"]}
{"title": "A Robust Regularization Path Algorithm for  -Support Vector Classification\n", "abstract": " The v-support vector classification has the advantage of using a regularization parameter v to control the number of support vectors and margin errors. Recently, a regularization path algorithm for v-support vector classification (v-SvcPath) suffers exceptions and singularities in some special cases. In this brief, we first present a new equivalent dual formulation for v-SVC and, then, propose a robust v-SvcPath, based on lower upper decomposition with partial pivoting. Theoretical analysis and experimental results verify that our proposed robust regularization path algorithm can avoid the exceptions completely, handle the singularities in the key matrix, and fit the entire solution path in a finite number of steps. Experimental results also show that our proposed algorithm fits the entire solution path with fewer steps and less running time than original one does.", "num_citations": "493\n", "authors": ["2098"]}
{"title": "Incremental learning for \u03bd-support vector regression\n", "abstract": " Abstract The \u03bd-Support Vector Regression (\u03bd-SVR) is an effective regression learning algorithm, which has the advantage of using a parameter \u03bd on controlling the number of support vectors and adjusting the width of the tube automatically. However, compared to \u03bd-Support Vector Classification (\u03bd-SVC)(Sch\u00f6lkopf et al., 2000), \u03bd-SVR introduces an additional linear term into its objective function. Thus, directly applying the accurate on-line \u03bd-SVC algorithm (AONSVM) to \u03bd-SVR will not generate an effective initial solution. It is the main challenge to design an incremental \u03bd-SVR learning algorithm. To overcome this challenge, we propose a special procedure called initial adjustments in this paper. This procedure adjusts the weights of \u03bd-SVC based on the Karush\u2013Kuhn\u2013Tucker (KKT) conditions to prepare an initial solution for the incremental learning. Combining the initial adjustments with the two steps of AONSVM\u00a0\u2026", "num_citations": "450\n", "authors": ["2098"]}
{"title": "Cost-sensitive learning and the class imbalance problem\n", "abstract": " Cost-Sensitive Learning is a type of learning in data mining that takes the misclassification costs (and possibly other types of cost) into consideration. The goal of this type of learning is to minimize the total cost. The key difference between cost-sensitive learning and cost-insensitive learning is that cost-sensitive learning treats the different misclassifications differently. Costinsensitive learning does not take the misclassification costs into consideration. The goal of this type of learning is to pursue a high accuracy of classifying examples into a set of known classes.", "num_citations": "389\n", "authors": ["2098"]}
{"title": "Structural minimax probability machine\n", "abstract": " Minimax probability machine (MPM) is an interesting discriminative classifier based on generative prior knowledge. It can directly estimate the probabilistic accuracy bound by minimizing the maximum probability of misclassification. The structural information of data is an effective way to represent prior knowledge, and has been found to be vital for designing classifiers in real-world problems. However, MPM only considers the prior probability distribution of each class with a given mean and covariance matrix, which does not efficiently exploit the structural information of data. In this paper, we use two finite mixture models to capture the structural information of the data from binary classification. For each subdistribution in a finite mixture model, only its mean and covariance matrix are assumed to be known. Based on the finite mixture models, we propose a structural MPM (SMPM). SMPM can be solved effectively by a\u00a0\u2026", "num_citations": "347\n", "authors": ["2098"]}
{"title": "Learning weighted naive Bayes with accurate ranking\n", "abstract": " Naive Bayes is one of most effective classification algorithms. In many applications, however, a ranking of examples are more desirable than just classification. How to extend naive Bayes to improve its ranking performance is an interesting and useful question in practice. Weighted naive Bayes is an extension of naive Bayes, in which attributes have different weights. This paper investigates how to learn a weighted naive Bayes with accurate ranking from data, or more precisely, how to learn the weights of a weighted naive Bayes to produce accurate ranking. We explore various methods: the gain ratio method, the hill climbing method, and the Markov chain Monte Carlo method, the hill climbing method combined with the gain ratio method, and the Markov chain Monte Carlo method combined with the gain ratio method. Our experiments show that a weighted naive Bayes trained to produce accurate ranking\u00a0\u2026", "num_citations": "241\n", "authors": ["2098"]}
{"title": "\" Missing is useful\": Missing values in cost-sensitive decision trees\n", "abstract": " Many real-world data sets for machine learning and data mining contain missing values and much previous research regards it as a problem and attempts to impute missing values before training and testing. In this paper, we study this issue in cost-sensitive learning that considers both test costs and misclassification costs. If some attributes (tests) are too expensive in obtaining their values, it would be more cost-effective to miss out their values, similar to skipping expensive and risky tests (missing values) in patient diagnosis (classification). That is, \"missing is useful\" as missing values actually reduces the total cost of tests and misclassifications and, therefore, it is not meaningful to impute their values. We discuss and compare several strategies that utilize only known values and that \"missing is useful\" for cost reduction in cost-sensitive decision tree learning.", "num_citations": "231\n", "authors": ["2098"]}
{"title": "A Comparative Study of SIFT and its Variants\n", "abstract": " SIFT is an image local feature description algorithm based on scale-space. Due to its strong matching ability, SIFT has many applications in different fields, such as image retrieval, image stitching, and machine vision. After SIFT was proposed, researchers have never stopped tuning it. The improved algorithms that have drawn a lot of attention are PCA-SIFT, GSIFT, CSIFT, SURF and ASIFT. In this paper, we first systematically analyze SIFT and its variants. Then, we evaluate their performance in different situations: scale change, rotation change, blur change, illumination change, and affine change. The experimental results show that each has its own advantages. SIFT and CSIFT perform the best under scale and rotation change. CSIFT improves SIFT under blur change and affine change, but not illumination change. GSIFT performs the best under blur change and illumination change. ASIFT performs the best under affine change. PCA-SIFT is always the second in different situations. SURF performs the worst in different situations, but runs the fastest.", "num_citations": "193\n", "authors": ["2098"]}
{"title": "Thresholding for making classifiers cost-sensitive\n", "abstract": " In this paper we propose a very simple, yet general and effective method to make any cost-insensitive classifiers (that can produce probability estimates) cost-sensitive. The method, called Thresholding, selects a proper threshold from training instances according to the misclassification cost. Similar to other cost-sensitive meta-learning methods, Thresholding can convert any existing (and future) costinsensitive learning algorithms and techniques into costsensitive ones. However, by comparing with the existing cost sensitive meta-learning methods and the direct use of the theoretical threshold, Thresholding almost always produces the lowest misclassification cost. Experiments also show that Thresholding has the least sensitivity on the misclassification cost ratio. Thus, it is recommended to use when the difference on misclassification costs is large.", "num_citations": "172\n", "authors": ["2098"]}
{"title": "Test strategies for cost-sensitive decision trees\n", "abstract": " In medical diagnosis, doctors must often determine what medical tests (e.g., X-ray and blood tests) should be ordered for a patient to minimize the total cost of medical tests and misdiagnosis. In this paper, we design cost-sensitive machine learning algorithms to model this learning and diagnosis process. Medical tests are like attributes in machine learning whose values may be obtained at a cost (attribute cost), and misdiagnoses are like misclassifications which may also incur a cost (misclassification cost). We first propose a lazy decision tree learning algorithm that minimizes the sum of attribute costs and misclassification costs. Then, we design several novel \"test strategies\" that can request to obtain values of unknown attributes at a cost (similar to doctors' ordering of medical tests at a cost) in order to minimize the total cost for test examples (new patients). These test strategies correspond to different situations in\u00a0\u2026", "num_citations": "169\n", "authors": ["2098"]}
{"title": "Graph Contextualized Self-Attention Network for Session-based Recommendation.\n", "abstract": " Session-based recommendation, which aims to predict the user\u2019s immediate next action based on anonymous sessions, is a key task in many online services (eg, e-commerce, media streaming). Recently, Self-Attention Network (SAN) has achieved significant success in various sequence modeling tasks without using either recurrent or convolutional network. However, SAN lacks local dependencies that exist over adjacent items and limits its capacity for learning contextualized representations of items in sequences. In this paper, we propose a graph contextualized self-attention model (GC-SAN), which utilizes both graph neural network and self-attention mechanism, for sessionbased recommendation. In GC-SAN, we dynamically construct a graph structure for session sequences and capture rich local dependencies via graph neural network (GNN). Then each session learns long-range dependencies by applying the self-attention mechanism. Finally, each session is represented as a linear combination of the global preference and the current interest of that session. Extensive experiments on two real-world datasets show that GC-SAN outperforms state-of-the-art methods consistently.", "num_citations": "143\n", "authors": ["2098"]}
{"title": "Where to go next: A spatio-temporal gated network for next poi recommendation\n", "abstract": " Next Point-of-Interest (POI) recommendation which is of great value to both users and POI holders is a challenging task since complex sequential patterns and rich contexts are contained in extremely sparse user check-in data. Recently proposed embedding techniques have shown promising results in alleviating the data sparsity issue by modeling context information, and Recurrent Neural Network (RNN) has been proved effective in the sequential prediction. However, existing next POI recommendation approaches train the embedding and network model separately, which cannot fully leverage rich contexts. In this paper, we propose a novel unified neural network framework, named NeuNext, which leverages POI context prediction to assist next POI recommendation by joint learning. Specifically, the Spatio-Temporal Gated Network (STGN) is proposed to model personalized sequential patterns for users' long\u00a0\u2026", "num_citations": "125\n", "authors": ["2098"]}
{"title": "An abnormal network flow feature sequence prediction approach for DDoS attacks detection in big data environment\n", "abstract": " Distributed denial-of-service (DDoS) is a rapidly growing problem with the fast development of the Internet. There are multitude DDoS detection approaches, however, three major problems about DDoS attack detection appear in the big data environment. Firstly, to shorten the respond time of the DDoS attack detector; secondly, to reduce the required compute resources; lastly, to achieve a high detection rate with low false alarm rate. In the paper, we propose an abnormal network flow feature sequence prediction approach which could fit to be used as a DDoS attack detector in the big data environment and solve aforementioned problems. We define a network flow abnormal index as PDRA with the percentage of old IP addresses, the increment of the new IP addresses, the ratio of new IP addresses to the old IP addresses and average accessing rate of each new IP address. We design an IP address database using sequential storage model which has a constant time complexity. The autoregressive integrated moving average (ARIMA) trending prediction module will be started if and only if the number of continuous PDRA sequence value, which all exceed an PDRA abnormal threshold (PAT), reaches a certain preset threshold. And then calculate the probability that is the percentage of forecasting PDRA sequence value which exceed the PAT. Finally we identify the DDoS attack based on the abnormal probability of the forecasting PDRA sequence. Both theorem and experiment show that the method we proposed can effectively reduce the compute resources consumption, identify DDoS attack at its initial stage with higher detection rate and lower\u00a0\u2026", "num_citations": "113\n", "authors": ["2098"]}
{"title": "Learning from crowdsourced labeled data: a survey\n", "abstract": " With the rapid growing of crowdsourcing systems, quite a few applications based on a supervised learning paradigm can easily obtain massive labeled data at a relatively low cost. However, due to the variable uncertainty of crowdsourced labelers, learning procedures face great challenges. Thus, improving the qualities of labels and learning models plays a key role in learning from the crowdsourced labeled data. In this survey, we first introduce the basic concepts of the qualities of labels and learning models. Then, by reviewing recently proposed models and algorithms on ground truth inference and learning models, we analyze connections and distinctions among these techniques as well as clarify the level of the progress of related researches. In order to facilitate the studies in this field, we also introduce open accessible real-world data sets collected from crowdsourcing systems and open source\u00a0\u2026", "num_citations": "99\n", "authors": ["2098"]}
{"title": "A method for improving CNN-based image recognition using DCGAN\n", "abstract": " Image recognition has always been a hot research topic in the scientific community and industry. The emergence of convolutional neural networks (CNN) has made this technology turned into research focus on the field of computer vision, especially in image recognition. But it makes the recognition result largely dependent on the number and quality of training samples. Recently, DCGAN has become a frontier method for generating images, sounds, and videos. In this paper, DCGAN is used to generate sample that is difficult to collect and proposed an efficient design method of generating model. We combine DCGAN with CNN for the second time. Use DCGAN to generate samples and training in image recognition model, which based by CNN. This method can enhance the classification model and effectively improve the accuracy of image recognition. In the experiment, we used the radar profile as dataset for 4 categories and achieved satisfactory classification performance. This paper applies image recognition technology to the meteorological field.", "num_citations": "82\n", "authors": ["2098"]}
{"title": "Feature value acquisition in testing: a sequential batch test algorithm\n", "abstract": " In medical diagnosis, doctors often have to order sets of medical tests in sequence in order to make an accurate diagnosis of patient diseases. While doing so they have to make a trade-off between the cost of the tests and possible misdiagnosis. In this paper, we use cost-sensitive learning to model this process. We assume that test examples (new patients) may contain missing values, and their actual values can be acquired at cost (similar to doing medical tests) in order to reduce misclassification errors (misdiagnosis). We propose a novel Sequential Batch Test algorithm that can acquire sets of attribute values in sequence, similar to sets of medical tests ordered by doctors in sequence. The goal of our algorithm is to minimize the total cost (ie, the trade-off) of acquiring attribute values and misclassifications. We demonstrate the effectiveness of our algorithm, and show that it outperforms previous methods\u00a0\u2026", "num_citations": "76\n", "authors": ["2098"]}
{"title": "Active learning with imbalanced multiple noisy labeling\n", "abstract": " With crowdsourcing systems, it is easy to collect multiple noisy labels for the same object for supervised learning. This dynamic annotation procedure fits the active learning perspective and accompanies the imbalanced multiple noisy labeling problem. This paper proposes a novel active learning framework with multiple imperfect annotators involved in crowdsourcing systems. The framework contains two core procedures: label integration and instance selection. In the label integration procedure, a positive label threshold (PLAT) algorithm is introduced to induce the class membership from the multiple noisy label set of each instance in a training set. PLAT solves the imbalanced labeling problem by dynamically adjusting the threshold for determining the class membership of an example. Furthermore, three novel instance selection strategies are proposed to adapt PLAT for improving the learning performance. These\u00a0\u2026", "num_citations": "73\n", "authors": ["2098"]}
{"title": "Liver CT sequence segmentation based with improved U-Net and graph cut\n", "abstract": " Liver segmentation has always been the focus of researchers because it plays an important role in medical diagnosis. However, under the condition of low contrast between a liver and surrounding organs and tissues, CT image noise and the large difference between the liver shapes of patients, existing liver image segmentation algorithms are difficult to obtain satisfactory results. To improve this situation, we propose a liver CT sequesnce image segmentation algorithm GIU-Net, which combines an improved U-Net neural network model with graph cutting. Specifically, we initially segment a liver from a liver CT sequence using an improved U-Net and obtain the probability distribution map of the liver regions. Secondly, the sequence segmentation start slice is selected, and then the context information of the liver sequence images and the liver probability distribution map are used to construct a graph cut energy\u00a0\u2026", "num_citations": "70\n", "authors": ["2098"]}
{"title": "Bi-parameter space partition for cost-sensitive SVM\n", "abstract": " Model selection is an important problem of cost-sensitive SVM (CS-SVM). Although using solution path to find global optimal parameters is a powerful method for model selection, it is a challenge to extend the framework to solve two regularization parameters of CS-SVM simultaneously. To overcome this challenge, we make three main steps in this paper.(i) A critical-regions-based bi-parameter space partition algorithm is proposed to present all piecewise linearities of CS-SVM.(ii) An invariant-regions-based bi-parameter space partition algorithm is further proposed to compute empirical errors for all parameter pairs.(iii) The global optimal solutions for K-fold cross validation are computed by superposing K invariant region based bi-parameter space partitions into one. The three steps constitute the model selection of CS-SVM which can find global optimal parameter pairs in K-fold cross validation. Experimental results on seven normal datsets and four imbalanced datasets, show that our proposed method has better generalization ability and than various kinds of grid search methods, however, with less running time.", "num_citations": "63\n", "authors": ["2098"]}
{"title": "Multi-class ground truth inference in crowdsourcing with clustering\n", "abstract": " Due to low quality of crowdsourced labelers, the integrated label of each example is usually inferred from its multiple noisy labels provided by different labelers. This paper proposes a novel algorithm, Ground Truth Inference using Clustering (GTIC), to improve the quality of integrated labels for multi-class labeling. For a K labeling case, GTIC utilizes the multiple noisy label sets of examples to generate features. Then, it uses a K-Means algorithm to cluster all examples into K different groups, each of which is mapped to a specific class. Examples in the same cluster are assigned a corresponding class label. We compare GTIC with four existing multi-class ground truth inference algorithms, majority voting (MV), Dawid & Skene's (DS), ZenCrowd (ZC) and Spectral DS (SDS), on one synthetic and eight real-world datasets. Experimental results show that the performance of GTIC is significantly superior to the others in\u00a0\u2026", "num_citations": "58\n", "authors": ["2098"]}
{"title": "Feature-level Deeper Self-Attention Network for Sequential Recommendation.\n", "abstract": " Sequential recommendation, which aims to recommend next item that the user will likely interact in a near future, has become essential in various Internet applications. Existing methods usually consider the transition patterns between items, but ignore the transition patterns between features of items. We argue that only the item-level sequences cannot reveal the full sequential patterns, while explicit and implicit feature-level sequences can help extract the full sequential patterns. In this paper, we propose a novel method named Feature-level Deeper Self-Attention Network (FDSA) for sequential recommendation. Specifically, FDSA first integrates various heterogeneous features of items into feature sequences with different weights through a vanilla attention mechanism. After that, FDSA applies separated self-attention blocks on item-level sequences and feature-level sequences, respectively, to model item transition patterns and feature transition patterns. Then, we integrate the outputs of these two blocks to a fully-connected layer for next item recommendation. Finally, comprehensive experimental results demonstrate that considering the transition relationships between features can significantly improve the performance of sequential recommendation.", "num_citations": "53\n", "authors": ["2098"]}
{"title": "Feasibility and Finite Convergence Analysis for Accurate On-Line -Support Vector Machine\n", "abstract": " The \u03bd-support vector machine ( \u03bd-SVM) for classification has the advantage of using a parameter \u03bd on controlling the number of support vectors and margin errors. Recently, an interesting accurate on-line algorithm accurate on-line \u03bd-SVM algorithm (AONSVM) is proposed for training \u03bd-SVM. AONSVM can be viewed as a special case of parametric quadratic programming techniques. It is demonstrated that AONSVM avoids the infeasible updating path as far as possible, and successfully converges to the optimal solution based on experimental analysis. However, because of the differences between AONSVM and classical parametric quadratic programming techniques, there is no theoretical justification for these conclusions. In this paper, we prove the feasibility and finite convergence of AONSVM under two assumptions. The main results of feasibility analysis include: 1) the inverses of the two key matrices in\u00a0\u2026", "num_citations": "53\n", "authors": ["2098"]}
{"title": "Improving crowdsourced label quality using noise correction\n", "abstract": " Crowdsourcing systems provide a cost effective and convenient way to collect labels, but they often fail to guarantee the quality of the labels. This paper proposes a novel framework that introduces noise correction techniques to further improve the quality of integrated labels that are inferred from the multiple noisy labels of objects. In the proposed general framework, information about the qualities of labelers estimated by a front-end ground truth inference algorithm is utilized to supervise subsequent label noise filtering and correction. The framework uses a novel algorithm termed adaptive voting noise correction (AVNC) to precisely identify and correct the potential noisy labels. After filtering out the instances with noisy labels, the remaining cleansed data set is used to create multiple weak classifiers, based on which a powerful ensemble classifier is induced to correct these noises. Experimental results on eight\u00a0\u2026", "num_citations": "52\n", "authors": ["2098"]}
{"title": "Imbalanced multiple noisy labeling\n", "abstract": " It can be easy to collect multiple noisy labels for the same object via Internet-based crowdsourcing systems. Labelers may have bias when labeling, due to lacking expertise, dedication, and personal preference. These cause Imbalanced Multiple Noisy Labeling. In most cases, we have no information about the labeling qualities of labelers and the underlying class distributions. It is important to design agnostic solutions to utilize these noisy labels for supervised learning. We first investigate how imbalanced multiple noisy labeling affects the class distributions of training sets and the performance of classification. Then, an agnostic algorithm Positive LAbel frequency Threshold (PLAT) is proposed to deal with the imbalanced labeling issue. Simulations on eight UCI data sets with different underlying class distributions show that PLAT not only effectively deals with the imbalanced multiple noisy labeling problems that off\u00a0\u2026", "num_citations": "48\n", "authors": ["2098"]}
{"title": "Hybrid cost-sensitive decision tree\n", "abstract": " Cost-sensitive decision tree and cost-sensitive na\u00efve Bayes are both new cost-sensitive learning models proposed recently to minimize the total cost of test and misclassifications. Each of them has its advantages and disadvantages. In this paper, we propose a novel cost-sensitive learning model, a hybrid cost-sensitive decision tree, called DTNB, to reduce the minimum total cost, which integrates the advantages of cost-sensitive decision tree and of the cost-sensitive na\u00efve Bayes together. We empirically evaluate it over various test strategies, and our experiments show that our DTNB outperforms cost-sensitive decision and the cost-sensitive na\u00efve Bayes significantly in minimizing the total cost of tests and misclassification based on the same sequential test strategies, and single batch strategies.", "num_citations": "48\n", "authors": ["2098"]}
{"title": "Cross validation through two-dimensional solution surface for cost-sensitive SVM\n", "abstract": " Model selection plays an important role in cost-sensitive SVM (CS-SVM). It has been proven that the global minimum cross validation (CV) error can be efficiently computed based on the solution path for one parameter learning problems. However, it is a challenge to obtain the global minimum CV error for CS-SVM based on one-dimensional solution path and traditional grid search, because CS-SVM is with two regularization parameters. In this paper, we propose a solution and error surfaces based CV approach (CV-SES). More specifically, we first compute a two-dimensional solution surface for CS-SVM based on a bi-parameter space partition algorithm, which can fit solutions of CS-SVM for all values of both regularization parameters. Then, we compute a two-dimensional validation error surface for each CV fold, which can fit validation errors of CS-SVM for all values of both regularization parameters. Finally, we\u00a0\u2026", "num_citations": "47\n", "authors": ["2098"]}
{"title": "Multi-label active learning for image classification\n", "abstract": " Multi-label image data is becoming ubiquitous. Image semantic understanding is typically formulated as a classification problem. This paper focuses on multi-label active learning for image classification. It first extends a traditional example based active learning method for multilabel active learning for image classification. Since the traditional example based active method doesn't work well, we propose a novel example-label based multi-label active learning method. Our experimental results on two image datasets demonstrate that the proposed method significantly reduces the labeling workload and improves the performance of the built classifier. Additionally, we conduct experiments on two other types of multi-label datasets for validating the versatility of our proposed method, and the experimental results show the consistent effect.", "num_citations": "43\n", "authors": ["2098"]}
{"title": "Cost-sensitive test strategies\n", "abstract": " In medical diagnosis doctors must often determine what medical tests (eg, X-ray, blood tests) should be ordered for a patient to minimize the total cost of medical tests and misdiagnosis. In this paper, we design cost-sensitive machine learning algorithms to model this learning and diagnosis process. Medical tests are like attributes in machine learning whose values may be obtained at cost (attribute cost), and misdiagnoses are like misclassifications which may also incur a cost (misclassification cost). We first propose an improved decision tree learning algorithm that minimizes the sum of attribute costs and misclassification costs. Then we design several novel \u201ctest strategies\u201d that may request to obtain values of unknown attributes at cost (similar to doctors\u2019 ordering of medical tests at cost) in order to minimize the total cost for test examples (new patients). We empirically evaluate and compare these test strategies, and show that they are effective and that they outperform previous methods. A case study on heart disease is given.", "num_citations": "43\n", "authors": ["2098"]}
{"title": "Recurrent convolutional neural network for sequential recommendation\n", "abstract": " The sequential recommendation, which models sequential behavioral patterns among users for the recommendation, plays a critical role in recommender systems. However, the state-of-the-art Recurrent Neural Networks (RNN) solutions rarely consider the non-linear feature interactions and non-monotone short-term sequential patterns, which are essential for user behavior modeling in sparse sequence data. In this paper, we propose a novel Recurrent Convolutional Neural Network model (RCNN). It not only utilizes the recurrent architecture of RNN to capture complex long-term dependencies, but also leverages the convolutional operation of Convolutional Neural Network (CNN) model to extract short-term sequential patterns among recurrent hidden states. Specifically, we first generate a hidden state at each time step with the recurrent layer. Then the recent hidden states are regarded as an \u201cimage\u201d, and RCNN\u00a0\u2026", "num_citations": "42\n", "authors": ["2098"]}
{"title": "Noise filtering to improve data and model quality for crowdsourcing\n", "abstract": " Crowdsourcing services provide an easy means of acquiring labeled training data for supervised learning. However, the labels provided by a single crowd worker are often unreliable. Repeated labeling can be used to solve this problem. After multiple labels have been acquired by repeated labeling for each instance, in general consensus methods are used to obtain the integrated labels of instances. Although consensus methods are effective in practice, it cannot be denied that a level of noise still exists in the set of integrated labels. In this study, an attempt was made to employ noise filters to delete the noise in integrated labels, and consequently, enhance the training data and model quality. In fact, noise handling is a relatively mature field in the machine learning community, and many noise filters for deleting label noise have been presented in the past. However, to the best of our knowledge, in very few studies\u00a0\u2026", "num_citations": "37\n", "authors": ["2098"]}
{"title": "A convolutional neural network-based linguistic steganalysis for synonym substitution steganography\n", "abstract": " In this paper, a linguistic steganalysis method based on two-level cascaded convolutional neural networks (CNNs) is proposed to improve the system\u2019s ability to detect stego texts, which are generated via synonym substitutions. The first-level network, sentence-level CNN, consists of one convolutional layer with multiple convolutional kernels in different window sizes, one pooling layer to deal with variable sentence lengths, and one fully connected layer with dropout as well as a softmax output, such that two final steganographic features are obtained for each sentence. The unmodified and modified sentences, along with their words, are represented in the form of pre-trained dense word embeddings, which serve as the input of the network. Sentence-level CNN provides the representation of a sentence, and can thus be utilized to predict whether a sentence is unmodified or has been modified by synonym substitutions. In the second level, a text-level CNN exploits the predicted representations of sentences obtained from the sentence-level CNN to determine whether the detected text is a stego text or cover text. Experimental results indicate that the proposed sentence-level CNN can effectively extract sentence features for sentence-level steganalysis tasks and reaches an average accuracy of 82.245%. Moreover, the proposed steganalysis method achieves greatly improved detection performance when distinguishing stego texts from cover texts.", "num_citations": "36\n", "authors": ["2098"]}
{"title": "Chunk incremental learning for cost-sensitive hinge loss support vector machine\n", "abstract": " Cost-sensitive learning can be found in many real-world applications and represents an important learning paradigm in machine learning. The recently proposed cost-sensitive hinge loss support vector machine (CSHL-SVM) guarantees consistency with the cost-sensitive Bayes risk, and this technique provides better generalization accuracy compared to traditional cost-sensitive support vector machines. In practice, data typically appear in the form of sequential chunks, also called an on-line scenario. However, conventional batch learning algorithms waste a considerable amount of time under the on-line scenario due to re-training of a model from scratch. To make CSHL-SVM more practical for the on-line scenario, we propose a chunk incremental learning algorithm for CSHL-SVM, which can update a trained model without re-training from scratch when incorporating a chunk of new samples. Our method is efficient\u00a0\u2026", "num_citations": "36\n", "authors": ["2098"]}
{"title": "Sensitivity of different machine learning algorithms to noise\n", "abstract": " Noise in data is an effective cause of concern for many machine learning techniques that are used in modeling data. Researchers have studied the impact of noise only on some particular learning algorithm, but only very few attempted to analyze the effect of noise on different ones. In this work, we study the noise sensitivity of four different learning algorithms under different intensities of noise. Particularly, we compare the noise sensitivity of decision tree, na\u00efve bayes, support vector machine, and logistic regression. The algorithms are tested on different datasets that are artificially injected with different degrees of noise. The study helps us understand the impact of different levels of noise on the learning algorithms mentioned above. Furthermore, it also guides of choosing the learning algorithms. In general, na\u00efve bayes is the most resistant to noise. However, it performs also the worst. The other algorithms perform much better than na\u00efve bayes especially after the noisy level is lower than 40%. When we have approaches to improve the data quality (reduce the noise level), decision tree is the most preferred one, followed by support vector machine and log", "num_citations": "34\n", "authors": ["2098"]}
{"title": "Simple test strategies for cost-sensitive decision trees\n", "abstract": " We study cost-sensitive learning of decision trees that incorporate both test costs and misclassification costs. In particular, we first propose a lazy decision tree learning that minimizes the total cost of tests and misclassifications. Then assuming test examples may contain unknown attributes whose values can be obtained at a cost (the test cost), we design several novel test strategies which attempt to minimize the total cost of tests and misclassifications for each test example. We empirically evaluate our tree-building and various test strategies, and show that they are very effective. Our results can be readily applied to real-world diagnosis tasks, such as medical diagnosis where doctors must try to determine what tests (e.g., blood tests) should be ordered for a patient to minimize the total cost of tests and misclassifications (misdiagnosis). A case study on heart disease is given throughout the paper.", "num_citations": "34\n", "authors": ["2098"]}
{"title": "Consensus algorithms for biased labeling in crowdsourcing\n", "abstract": " Although it has become an accepted lay view that when labeling objects through crowdsourcing systems, non-expert annotators often exhibit biases, this argument lacks sufficient evidential observation and systematic empirical study. This paper initially analyzes eight real-world datasets from different domains whose class labels were collected from crowdsourcing systems. Our analyses show that biased labeling is a systematic tendency for binary categorization; in other words, for a large number of annotators, their labeling qualities on the negative class (supposed to be the majority) are significantly greater than are those on the positive class (minority). Therefore, the paper empirically studies the performance of four existing EM-based consensus algorithms, DS, GLAD, RY, and ZenCrowd, on these datasets. Our investigation shows that all of these state-of-the-art algorithms ignore the potential bias characteristics\u00a0\u2026", "num_citations": "32\n", "authors": ["2098"]}
{"title": "Cost-sensitive learning for defect escalation\n", "abstract": " While most software defects (i.e., bugs) are corrected and tested as part of the prolonged software development cycle, enterprise software venders often have to release software products before all reported defects are corrected, due to deadlines and limited resources. A small number of these reported defects will be escalated by customers whose businesses are seriously impacted. Escalated defects must be resolved immediately and individually by the software vendors at a very high cost. The total costs can be even greater, including loss of reputation, satisfaction, loyalty, and repeat revenue. In this paper, we develop a Software defecT Escalation Prediction (STEP) system to mine historical defect report data and predict the escalation risk of current defect reports for maximum net profit. More specifically, we first describe a simple and general framework to convert the maximum net profit problem to cost-sensitive\u00a0\u2026", "num_citations": "32\n", "authors": ["2098"]}
{"title": "Machine learning with crowdsourcing: A brief summary of the past research and future directions\n", "abstract": " With crowdsourcing systems, labels can be obtained with low cost, which facilitates the creation of training sets for prediction model learning. However, the labels obtained from crowdsourcing are often imperfect, which brings great challenges in model learning. Since 2008, the machine learning community has noticed the great opportunities brought by crowdsourcing and has developed a large number of techniques to deal with inaccuracy, randomness, and uncertainty issues when learning with crowdsourcing. This paper summarizes the technical progress in this field during past eleven years. We focus on two fundamental issues: the data (label) quality and the prediction model quality. For data quality, we summarize ground truth inference methods and some machine learning based methods to further improve data quality. For the prediction model quality, we summarize several learning paradigms developed under the crowdsourcing scenario. Finally, we further discuss several promising future research directions to attract researchers to make contributions in crowdsourcing.", "num_citations": "29\n", "authors": ["2098"]}
{"title": "Where to go next: A spatio-temporal LSTM model for next POI recommendation\n", "abstract": " Next Point-of-Interest (POI) recommendation is of great value for both location-based service providers and users. Recently Recurrent Neural Networks (RNNs) have been proved to be effective on sequential recommendation tasks. However, existing RNN solutions rarely consider the spatio-temporal intervals between neighbor check-ins, which are essential for modeling user check-in behaviors in next POI recommendation. In this paper, we propose a new variant of LSTM, named STLSTM, which implements time gates and distance gates into LSTM to capture the spatio-temporal relation between successive check-ins. Specifically, one-time gate and one distance gate are designed to control short-term interest update, and another time gate and distance gate are designed to control long-term interest update. Furthermore, to reduce the number of parameters and improve efficiency, we further integrate coupled input and forget gates with our proposed model. Finally, we evaluate the proposed model using four real-world datasets from various location-based social networks. Our experimental results show that our model significantly outperforms the state-of-the-art approaches for next POI recommendation.", "num_citations": "29\n", "authors": ["2098"]}
{"title": "Label noise correction and application in crowdsourcing\n", "abstract": " The important task of correcting label noise is addressed infrequently in literature. The difficulty of developing a robust label correction algorithm leads to this silence concerning label correction. To break the silence, we propose two algorithms to correct label noise. One utilizes self-training to re-label noise, called Self-Training Correction (STC). Another is a clustering-based method, which groups instances together to infer their ground-truth labels, called Cluster-based Correction (CC). We also adapt an algorithm from previous work, a consensus-based method called Polishing that consults with an ensemble of classifiers to change the values of attributes and labels. We simplify Polishing such that it only alters labels of instances, and call it Polishing Labels (PL). We experimentally compare our novel methods with Polishing Labels by examining their improvements on the label qualities, model qualities, and AUC\u00a0\u2026", "num_citations": "29\n", "authors": ["2098"]}
{"title": "Adaptive DDoS attack detection method based on multiple-kernel learning\n", "abstract": " Distributed denial of service (DDoS) attacks has caused huge economic losses to society. They have become one of the main threats to Internet security. Most of the current detection methods based on a single feature and fixed model parameters cannot effectively detect early DDoS attacks in cloud and big data environment. In this paper, an adaptive DDoS attack detection method (ADADM) based on multiple-kernel learning (MKL) is proposed. Based on the burstiness of DDoS attack flow, the distribution of addresses, and the interactivity of communication, we define five features to describe the network flow characteristic. Based on the ensemble learning framework, the weight of each dimension is adaptively adjusted by increasing the interclass mean with a gradient ascent and reducing the intraclass variance with a gradient descent, and the classifier is established to identify an early DDoS attack by training simple multiple-kernel learning (SMKL) models with two characteristics including interclass mean squared difference growth (M-SMKL) and intraclass variance descent (S-SMKL). The sliding window mechanism is used to coordinate the S-SMKL and M-SMKL to detect the early DDoS attack. The experimental results indicate that this method can detect DDoS attacks early and accurately.", "num_citations": "25\n", "authors": ["2098"]}
{"title": "Majority voting and pairing with multiple noisy labeling\n", "abstract": " With the crowdsourcing of small tasks becoming easier, it is possible to obtain non-expert/imperfect labels at low cost. With low-cost imperfect labeling, it is straightforward to collect multiple labels for the same data items. This paper proposes strategies of utilizing these multiple labels for supervised learning, based on two basic ideas: majority voting and pairing. We show several interesting results based on our experiments. (i) The strategies based on the majority voting idea work well under the situation where the certainty level is high. (ii) On the contrary, the pairing strategies are more preferable under the situation where the certainty level is low. (iii) Among the majority voting strategies, soft majority voting can reduce the bias and roughness, and perform better than majority voting. (iv) Pairing can completely avoid the bias by having both sides (potentially correct and incorrect/noisy information) considered. Beta\u00a0\u2026", "num_citations": "25\n", "authors": ["2098"]}
{"title": "Label noise correction methods\n", "abstract": " The important task of correcting label noise is addressed infrequently in literature. The difficulty of developing a robust label correction algorithm leads to this silence concerning label correction. To break the silence, we propose two algorithms to correct label noise. One utilizes self-training to re-label noise, called Self-Training Correction (STC). Another is a clustering-based method, which groups instances together to infer their ground-truth labels, called Cluster-based Correction (CC). We also adapt an algorithm from previous work, a consensus-based method called Polishing that consults with an ensemble of classifiers to change the values of attributes and labels. We simplify Polishing such that it only alters labels of instances, and call it Polishing Labels (PL). We experimentally compare our novel methods with Polishing Labels by examining their improvements on the label qualities, model qualities, and AUC\u00a0\u2026", "num_citations": "25\n", "authors": ["2098"]}
{"title": "Roulette sampling for cost-sensitive learning\n", "abstract": " In this paper, we propose a new and general preprocessor algorithm, called CSRoulette, which converts any cost-insensitive classification algorithms into cost-sensitive ones. CSRoulette is based on cost proportional roulette sampling technique (called CPRS in short). CSRoulette is closely related to Costing, another cost-sensitive meta-learning algorithm, which is based on rejection sampling. Unlike rejection sampling which produces smaller samples, CPRS can generate different size samples. To further improve its performance, we apply ensemble (bagging) on CPRS; the resulting algorithm is called CSRoulette. Our experiments show that CSRoulette outperforms Costing and other meta-learning methods in most datasets tested. In addition, we investigate the effect of various sample sizes and conclude that reduced sample sizes (as in rejection sampling) cannot be compensated by increasing the\u00a0\u2026", "num_citations": "24\n", "authors": ["2098"]}
{"title": "Comparative study of cost-sensitive classifiers\n", "abstract": " The authors briefly review the theory of cost-sensitive learning, and the existing cost-sensitive learning algorithms. The authors categorize cost-sensitive learning algorithms into direct cost-sensitive learning and cost-sensitive meta-learning, which converts cost-insensitive classifiers into cost-sensitive ones. The authors also propose a simple yet general and effective meta-learning method called Empirical Threshold Adjusting (ETA for short). The authors evaluate the performance of various cost-sensitive meta-learning algorithms including ETA. ETA almost always produces the lowest misclassification cost, and is least sensitive to the misclassification cost ratio. Other useful conclusions on cost-sensitive meta-learning methods are drawn.", "num_citations": "24\n", "authors": ["2098"]}
{"title": "Weak-labeled active learning with conditional label dependence for multilabel image classification\n", "abstract": " Multilabel image classification has been a hot topic in the field of computer vision and image understanding in recent years. To achieve better classification performance with fewer labeled images, multilabel active learning is used for this scenario. Several active learning methods have been proposed for multilabel image classification. However, all of them assume that either all training images have complete labels or label correlations are given at the beginning. These two assumptions are unrealistic. In fact, it is very difficult to obtain complete labels for each example, in particular when the size of labels in a multilabel dataset is very large. Typically, only partial labels are available. This is one type of \u201cweak label\u201d problem. To solve this weak label problem inside multilabel active learning, this paper proposes a novel solution called AE-WLMAL. AE-WLMAL explores conditional label correlations on the weak label\u00a0\u2026", "num_citations": "23\n", "authors": ["2098"]}
{"title": "Multiclass imbalanced learning with one-versus-one decomposition and spectral clustering\n", "abstract": " In many real-world applications, an algorithm needs to learn multiclass classification models from data with imbalanced class distributions. Multiclass imbalanced learning is currently receiving increased attention from researchers. In contrast to traditional imbalanced learning on binary datasets, multiclass imbalanced learning faces great challenges from the variety of changes in the class distributions as well as the inadequate performance of multiclass classification algorithms. In this paper, we propose a novel data preprocessing-based method to solve this problem. The proposed method combines a one-versus-one (OVO) decomposition of class pairs and a spectral clustering technique. This method first decomposes a multiclass dataset into several binary-class datasets. Then, it uses spectral clustering to divide the minority classes of binary-class subsets into subspaces and oversamples them according to the\u00a0\u2026", "num_citations": "22\n", "authors": ["2098"]}
{"title": "Meteorological data analysis using mapreduce\n", "abstract": " In the atmospheric science, the scale of meteorological data is massive and growing rapidly. K-means is a fast and available cluster algorithm which has been used in many fields. However, for the large-scale meteorological data, the traditional K-means algorithm is not capable enough to satisfy the actual application needs efficiently. This paper proposes an improved MK-means algorithm (MK-means) based on MapReduce according to characteristics of large meteorological datasets. The experimental results show that MK-means has more computing ability and scalability.", "num_citations": "21\n", "authors": ["2098"]}
{"title": "Loss functions of generative adversarial networks (GANs): opportunities and challenges\n", "abstract": " Recently, the Generative Adversarial Networks (GANs) are fast becoming a key promising research direction in computational intelligence. To improve the modeling ability of GANs, loss functions are used to measure the differences between samples generated by the model and real samples, and make the model learn towards the goal. In this paper, we perform a survey for the loss functions used in GANs, and analyze the pros and cons of these loss functions. Firstly, the basic theory of GANs, and its training mechanism are introduced. Then, the loss functions used in GANs are summarized, including not only the objective functions of GANs, but also the application-oriented GANs\u2019 loss functions. Thirdly, the experiments and analyses of representative loss functions are discussed. Finally, several suggestions on how to choose appropriate loss functions in a specific task are given.", "num_citations": "20\n", "authors": ["2098"]}
{"title": "Analyzing cross-domain transportation big data of New York City with semi-supervised and active learning\n", "abstract": " The majority of big data analytics applied to transportation datasets suffer from being too domain-specific, that is, they draw conclusions for a dataset based on analytics on the same dataset. This makes models trained from one domain (eg taxi data) applies badly to a different domain (eg Uber data). To achieve accurate analyses on a new domain, substantial amounts of data must be available, which limits practical applications. To remedy this, we propose to use semi-supervised and active learning of big data to accomplish the domain adaptation task: Selectively choosing a small amount of datapoints from a new domain while achieving comparable performances to using all the datapoints. We choose the New York City (NYC) transportation data of taxi and Uber as our dataset, simulating different domains with 90% as the source data domain for training and the remaining 10% as the target data domain for\u00a0\u2026", "num_citations": "19\n", "authors": ["2098"]}
{"title": "A solution path algorithm for general parametric quadratic programming problem\n", "abstract": " Parameter in learning problems (usually arising from the tradeoff between training error minimization and regularization) is often tuned by cross validation (CV). A solution path provides a compact representation of all optimal solutions, which can be used to determine the parameter with the global minimum CV error, without solving original optimization problems multiple times based on grid search. However, existing solution path algorithms do not provide a unified implementation to various learning problems. In this paper, we first introduce a general parametric quadratic programming (PQP) problem that can be instantiated to an extensive number of learning problems. Then, we propose a generalized solution path (GSP) for the general PQP problem. Particularly, we use the QR decomposition to handle singularities in GSP. Finally, we analyze the finite convergence and the time complexity of GSP. Our\u00a0\u2026", "num_citations": "19\n", "authors": ["2098"]}
{"title": "A privacy-preserving algorithm for clinical decision-support systems using random forest\n", "abstract": " Clinical decision-support systems are technology-based tools that help healthcare providers enhance the quality of their services to satisfy their patients and earn their trust. These systems are used to improve physicians\u2019 diagnostic processes in terms of speed and accuracy. Using data-mining techniques, a clinical decision support system builds a classification model from hospital\u2019s dataset for diagnosing new patients using their symptoms. In this work, we propose a privacy-preserving clinical decision-support system that uses a privacy-preserving random forest algorithm to diagnose new symptoms without disclosing patients\u2019 information and exposing them to cyber and network attacks. Solving the same problem with a different methodology, the simulation results show that the proposed algorithm outperforms previous work by removing unnecessary attributes and avoiding cryptography algorithms. Moreover, our model is validated against the privacy requirements of the hospitals\u2019 datasets and votes, and patients\u2019 diagnosed symptoms.", "num_citations": "18\n", "authors": ["2098"]}
{"title": "Empirical comparison of multi-label classification algorithms\n", "abstract": " Multi-label classifications exist in many real world applications. This paper empirically studies the performance of a variety of multi-label classification algorithms. Some of them are developed based on problem transformation. Some of them are developed based on adaption. Our experimental results show that the adaptive Multi-Label K-Nearest Neighbor performs the best, followed by Random k-Label Set, followed by Classifier Chain and Binary Relevance. Adaboost. MH performs the worst, followed by Pruned Problem Transformation. Our experimental results also provide us the confidence of the correlations among multi-labels. These insights shed light for future research directions on multi-label classifications.", "num_citations": "18\n", "authors": ["2098"]}
{"title": "Simple multiple noisy label utilization strategies\n", "abstract": " With the outsourcing of small tasks becoming easier, it is possible to obtain non-expert/imperfect labels at low cost. With low-cost imperfect labeling, it is straightforward to collect multiple labels for the same data items. This paper addresses the strategies of utilizing these multiple labels for improving the performance of supervised learning, based on two basic ideas: majority voting and pair wise solutions. We show several interesting results based on our experiments. The soft majority voting strategies can reduce the bias and roughness, and improve the performance of the directed hard majority voting strategy. Pair wise strategies can completely avoid the bias by having both sides (potential correct and incorrect/noisy information) considered (for binary classification). They have very good performance whenever there are a few or many labels available. However, it could also keep the noise. The improved variation\u00a0\u2026", "num_citations": "18\n", "authors": ["2098"]}
{"title": "Design of building construction safety prediction model based on optimized BP neural network algorithm\n", "abstract": " In order to solve the safety problem of the construction industry, the construction safety prediction model based on the optimized BP neural network algorithm is designed in this study. First, the characteristics of the construction industry were analyzed. As a labor-intensive industry, the construction industry is characterized by numerous factors such as large investment, long construction period and complicated construction environment. Due to the increasingly serious security problem, widespread concern over such problem has been aroused in society. Second, the problem of building construction safety management was summarized, six influencing factors were explored and a building construction safety prediction model based on rough set-genetic-BP neural network was established. Finally, the model was validated by a combination of multiparty consultation, empirical analysis and model comparison. The\u00a0\u2026", "num_citations": "17\n", "authors": ["2098"]}
{"title": "Machine learning for wireless multimedia data security\n", "abstract": " With the rapid development of multimedia technologies, the collection and modification of wireless multimedia data have become greatly convenient and easy. Meanwhile, the wireless multimedia data also made sensitive information available to potential attackers. e credibility of digital wireless multimedia data has thus decreased if the wireless multimedia data cannot be well protected. In addition, the copyright and privacy of wireless multimedia data also are easy to be infringed. Particularly, the data storage and computation have to be delegated to the powerful but always untrusted cloud, which has led to a series of challenging security and privacy threats.Nowadays, artificial intelligence (AI) technology has been widely used in academia and industry. Machine learning can be regarded as one of the most important AI technologies, and it has been successfully used in image processing, pattern recognition, computer vision, natural language processing, and so on. Currently, the traditional steganography and security of encrypted wireless multimedia data face a lot of challenges. us, new types of steganography and encryption of wireless multimedia data, including audio, image, and video, are urgently needed to explore. Moreover, in new environments like cloud computing, the distribution and processing of wireless multimedia data also face more new challenges. For example, how to securely process wireless multimedia data in cloud computing to preserve the privacy", "num_citations": "17\n", "authors": ["2098"]}
{"title": "An ECG signal de-noising approach based on wavelet energy and sub-band smoothing filter\n", "abstract": " Electrocardiographic (ECG) signal is essential to diagnose and analyse cardiac disease. However, ECG signals are susceptible to be contaminated with various noises, which affect the application value of ECG signals. In this paper, we propose an ECG signal de-noising method using wavelet energy and a sub-band smoothing filter. Unlike the traditional wavelet threshold de-noising method, which carries out threshold processing for all wavelet coefficients, the wavelet coefficients that require threshold de-noising are selected according to the wavelet energy and other wavelet coefficients remain unchanged in the proposed method. Moreover, The sub-band smoothing filter is adopted to further de-noise the ECG signal and improve the ECG signal quality. The ECG signals of the standard MIT-BIH database are adopted to verify the proposed method using MATLAB software. The performance of the proposed approach is assessed using Signal-To-Noise ratio (SNR), Mean Square Error (MSE) and percent root mean square difference (PRD). The experimental results illustrate that the proposed method can effectively remove noise from the noisy ECG signals in comparison to the existing methods. View Full-Text", "num_citations": "17\n", "authors": ["2098"]}
{"title": "Active learning with label correlation exploration for multi\u2010label image classification\n", "abstract": " Multi\u2010label image classification has attracted considerable attention in machine learning recently. Active learning is widely used in multi\u2010label learning because it can effectively reduce the human annotation workload required to construct high\u2010performance classifiers. However, annotation by experts is costly, especially when the number of labels in a dataset is large. Inspired by the idea of semi\u2010supervised learning, in this study, the authors propose a novel, semi\u2010supervised multi\u2010label active learning (SSMAL) method that combines automated annotation with human annotation to reduce the annotation workload associated with the active learning process. In SSMAL, they capture three aspects of potentially useful information \u2013 classification prediction information, label correlation information, and example spatial information \u2013 and they use this information to develop an effective strategy for automated annotation of\u00a0\u2026", "num_citations": "17\n", "authors": ["2098"]}
{"title": "Multi-label active learning with label correlation for image classification\n", "abstract": " Label correlation analysis is very important for multi-label classification. And there is no study to measure the label correlation for example-label based active learning. In this paper, from a statistical point of view, we proposed a cosine similarity based multi-label active learning (CosMAL), which uses cosine similarity to accurately evaluate the correlations between all labels. It further uses the average correlation between the potential label and the other unlabeled labels as the label information for each sample-label pair. And then we select the most informativeness example-label pairs. Our empirical results demonstrate that our proposed method CosMAL outperforms the state-of-the-art active learning for multi-label classification. It significantly reduces the labeling workload and improves the performance of a classifier learned.", "num_citations": "17\n", "authors": ["2098"]}
{"title": "Does one-against-all or one-against-one improve the performance of multiclass classifications?\n", "abstract": " One-against-all and one-against-one are two popular methodologies for reducing multiclass classification problems into a set of binary classifications. In this paper, we are interested in the performance of both one-against-all and one-against-one for classification algorithms, such as decision tree, na\u00efve bayes, support vector machine, and logistic regression. Since both one-against-all and one-against-one work like creating a classification committee, they are expected to improve the performance of classification algorithms. However, our experimental results surprisingly show that one-against-all worsens the performance of the algorithms on most datasets. One-against-one helps, but performs worse than the same iterations of bagging these algorithms. Thus, we conclude that both one-against-all and one-against-one should not be used for the algorithms that can perform multiclass classifications directly. Bagging is better approach for improving their performance.", "num_citations": "17\n", "authors": ["2098"]}
{"title": "DOG: A new background removal for object recognition from images\n", "abstract": " For image classification, convolutional neural networks (CNNs) have the advantage of being able to convolve directly with image pixels and extract image features from image pixels. This approach is closer to the treatment of the human brain's visual system. However, up to now, it is impossible to achieve 100% classification accuracy regardless of any kind of convolutional neural network models. At the same time, we also find that sometimes the background of images affects the recognition of neural networks, and removing the background of images can improve their performance of object recognition. Therefore, we design a model named DOG based on CNN to remove the background of images (such as selfies, animals, flowers, etc.) for improving the performance of object recognition. Because of the scarce of samples, we further integrate DOG with DCGAN to further improve the performance of object\u00a0\u2026", "num_citations": "16\n", "authors": ["2098"]}
{"title": "An empirical comparison on multi-target regression learning\n", "abstract": " Multi-target regression is concerned with the simultaneous prediction of multiple continuous target variables based on the same set of input variables. It has received relatively small attention from the Machine Learning community. However, multi-target regression exists in many real-world applications. In this paper we conduct extensive experiments to investigate the performance of three representative multi-target regression learning algorithms (ie Multi-Target Stacking (MTS), Random Linear Target Combination (RLTC), and Multi-Objective Random Forest (MORF)), comparing the baseline single-target learning. Our experimental results show that all three multi-target regression learning algorithms do improve the performance of the single-target learning. Among them, MTS performs the best, followed by RLTC, followed by MORF. However, the single-target learning sometimes still performs very well, even the best. This analysis sheds the light on multi-target regression learning and indicates that the single-target learning is a competitive baseline for multi-target regression learning on multi-target domains.", "num_citations": "16\n", "authors": ["2098"]}
{"title": "A double weighted Naive Bayes with niching cultural algorithm for multi-label classification\n", "abstract": " Multi-label classification is to assign an instance to multiple classes. Naive Bayes (NB) is one of the most popular algorithms for pattern recognition and classification. It has a high performance in single label classification. It is naturally extended for multi-label classification under the assumption of label independence. As we know, NB is based on a simple but unrealistic assumption that attributes are conditionally independent given the class. Therefore, a double weighted NB (DWNB) is proposed to demonstrate the influences of predicting different labels based on different attributes. Our DWNB utilizes the niching cultural algorithm (NLA) to determine the weight configuration automatically. Our experimental results show that our proposed DWNB outperforms NB and its extensions significantly in multi-label classification.", "num_citations": "16\n", "authors": ["2098"]}
{"title": "Multi-label active learning algorithms for image classification: Overview and future promise\n", "abstract": " Image classification is a key task in image understanding, and multi-label image classification has become a popular topic in recent years. However, the success of multi-label image classification is closely related to the way of constructing a training set. As active learning aims to construct an effective training set through iteratively selecting the most informative examples to query labels from annotators, it was introduced into multi-label image classification. Accordingly, multi-label active learning is becoming an important research direction. In this work, we first review existing multi-label active learning algorithms for image classification. These algorithms can be categorized into two top groups from two aspects respectively: sampling and annotation. The most important component of multi-label active learning is to design an effective sampling strategy that actively selects the examples with the highest informativeness\u00a0\u2026", "num_citations": "15\n", "authors": ["2098"]}
{"title": "Crowdsourced label aggregation using bilayer collaborative clustering\n", "abstract": " With online crowdsourcing platforms, labels can be acquired at relatively low costs from massive nonexpert workers. To improve the quality of labels obtained from these imperfect crowdsourced workers, we usually let different workers provide labels for the same instance. Then, the true labels for all instances are estimated from these multiple noisy labels. This traditional general-purpose label aggregation process, solely relying on the collected noisy labels, cannot significantly improve the accuracy of integrated labels under a low labeling quality circumstance. This paper proposes a novel bilayer collaborative clustering (BLCC) method for the label aggregation in crowdsourcing. BLCC first generates the conceptual-level features for the instances from their multiple noisy labels and infers the initially integrated labels by performing clustering on the conceptual-level features. Then, it performs another clustering on\u00a0\u2026", "num_citations": "15\n", "authors": ["2098"]}
{"title": "CEKA: a tool for mining the wisdom of crowds.\n", "abstract": " CEKA is a software package for developers and researchers to mine the wisdom of crowds. It makes the entire knowledge discovery procedure much easier, including analyzing qualities of workers, simulating labeling behaviors, inferring true class labels of instances, filtering and correcting mislabeled instances (noise), building learning models and evaluating them. It integrates a set of state-of-the-art inference algorithms, a set of general noise handling algorithms, and abundant functions for model training and evaluation. CEKA is written in Java with core classes being compatible with the well-known machine learning tool WEKA, which makes the utilization of the functions in WEKA much easier.", "num_citations": "15\n", "authors": ["2098"]}
{"title": "Multi-label active learning with chi-square statistics for image classification\n", "abstract": " Active learning is to select the most informative examples to request their labels. Most previous studies in active learning for multi-label classification didn't pay enough attention on label correlations. This leads to a bad performance for classification. In this paper, we proposed a chi-square statistics multi-label active learning (CSMAL) algorithm, which uses chi-square statistics to accurately evaluate correlations between labels. CSMAL considers not only positive relationships but also negative ones. It uses the average correlation between a potential label and its rest unlabeled labels as the label information for each sample-label pair. CSMAL further integrates uncertainty and label information to select example-label pairs to request labels. Our empirical results demonstrate that our proposed method CSMAL outperforms the state-of-the-art active learning methods for multi-label classification. It significantly reduces\u00a0\u2026", "num_citations": "15\n", "authors": ["2098"]}
{"title": "Partial example acquisition in cost-sensitive learning\n", "abstract": " It is often expensive to acquire data in real-world data mining applications. Most previous data mining and machine learning research, however, assumes that a fixed set of training examples is given. In this paper, we propose an online cost-sensitive framework that allows a learner to dynamically acquire examples as it learns, and to decide the ideal number of examples needed to minimize the total cost. We also propose a new strategy for Partial Example Acquisition (PAS), in which the learner can acquire examples with a subset of attribute values to reduce the data acquisition cost. Experiments on UCI datasets show that the new PAS strategy is an effective method in reducing the total cost for data acquisition.", "num_citations": "15\n", "authors": ["2098"]}
{"title": "A generative model approach for geo-social group recommendation\n", "abstract": " With the development and prevalence of online social networks, there is an obvious tendency that people are willing to attend and share group activities with friends or acquaintances. This motivates the study on group recommendation, which aims to meet the needs of a group of users, instead of only individual users. However, how to aggregate different preferences of different group members is still a challenging problem: 1) the choice of a member in a group is influenced by various factors, e.g., personal preference, group topic, and social relationship; 2) users have different influences when in different groups. In this paper, we propose a generative geo-social group recommendation model (GSGR) to recommend points of interest (POIs) for groups. Specifically, GSGR well models the personal preference impacted by geographical information, group topics, and social influence for recommendation\u00a0\u2026", "num_citations": "14\n", "authors": ["2098"]}
{"title": "Collaborative Self-Attention Network for Session-based Recommendation.\n", "abstract": " Session-based recommendation becomes a research hotspot for its ability to make recommendations for anonymous users. However, existing session-based methods have the following limitations:(1) They either lack the capability to learn complex dependencies or focus mostly on the current session without explicitly considering collaborative information.(2) They assume that the representation of an item is static and fixed for all users at each time step. We argue that even the same item can be represented differently for different users at the same time step. To this end, we propose a novel solution, Collaborative Self-Attention Network (CoSAN) for session-based recommendation, to learn the session representation and predict the intent of the current session by investigating neighborhood sessions. Specially, we first devise a collaborative item representation by aggregating the embedding of neighborhood sessions retrieved according to each item in the current session. Then, we apply self-attention to learn long-range dependencies between collaborative items and generate collaborative session representation. Finally, each session is represented by concatenating the collaborative session representation and the embedding of the current session. Extensive experiments on two real-world datasets show that CoSAN constantly outperforms state-of-the-art methods.", "num_citations": "13\n", "authors": ["2098"]}
{"title": "Ensemble learning from crowds\n", "abstract": " Traditional learning from crowdsourced labeled data consists of two stages: inferring true labels for instances from their multiple noisy labels and building a learning model using these instances with the inferred labels. This straightforward two-stage learning scheme suffers from two weaknesses: (1) the accuracy of inference may be very low; (2) useful information may be lost during inference. In this paper, we proposed a novel ensemble method for learning from crowds. Our proposed method is a meta-learning scheme. It first uses a bootstrapping process to create M sub-datasets from an original crowdsourced labeled dataset. For each sub-dataset, each instance is duplicated with different weights according to the distribution and class memberships of its multiple noisy labels. A base classifier is then trained from this extended sub-dataset. Finally, unlabeled instances are predicted by aggregating the outputs of\u00a0\u2026", "num_citations": "13\n", "authors": ["2098"]}
{"title": "Improving label quality in crowdsourcing using noise correction\n", "abstract": " This paper proposes a novel framework that introduces noise correction techniques to further improve label quality after ground truth inference in crowdsourcing. In the framework, an adaptive voting noise correction algorithm (AVNC) is proposed to identify and correct the most likely noises with the help of estimated qualities of labelers provided by the ground truth inference. The experimental results on two real-world datasets show that (1) the framework can improve label quality regardless of inference algorithms, especially under the circumstance that each example has a few noisy labels; and (2) since the algorithm AVNC considers both the number of and the probability of potential noises, it outperforms a baseline noise correction algorithm.", "num_citations": "13\n", "authors": ["2098"]}
{"title": "Multilevel identification and classification analysis of Tor on mobile and PC platforms\n", "abstract": " In digitalized and automated systems, more and more intelligent devices have become an import part of industrial Internet of Things (IIOT). However, the lack of security in IIOT makes people facing unprecedented threats from the Dark web. Traffic classification is an important means to prevent anonymous attacks. However, the growing usage of smartphones in daily life is deeply changing the nature of network traffic, which makes traffic classification more challenging. In this article, we propose a Tor traffic identification and multilevel classification framework based on network flow features, which realizes the identification of anonymous traffic (L1), traffic types (L2) of anonymous traffic, and applications (L3) on a mobile and a PC platform, respectively. We further analyze differences between the mobile and the PC platform. We conclude that the impact of time-related features is higher than that of the nontime-related\u00a0\u2026", "num_citations": "12\n", "authors": ["2098"]}
{"title": "MRI and PET image fusion using the nonparametric density model and the theory of variable-weight\n", "abstract": " Medical image fusion is important in the field of clinical diagnosis because it can improve the availability of information contained in images. Magnetic Resonance Imaging (MRI) provides excellent anatomical details as well as functional information on regional changes in physiology, hemodynamics, and tissue composition. In contrast, although the spatial resolution of Positron Emission Tomography (PET) provides is lower than that an MRI, PET is capable of depicting the tissue's molecular and pathological activities that are not available from MRI. Fusion of MRI and PET may allow us to combine the advantages of both imaging modalities and achieve more precise localization and characterization of abnormalities. Previous image fusion algorithms, based on the estimation theory, assume that all distortions follow Gaussian distribution and are therefore susceptible to the model mismatch problem. To overcome this\u00a0\u2026", "num_citations": "12\n", "authors": ["2098"]}
{"title": "Adaptive low-rank multi-label active learning for image classification\n", "abstract": " Multi-label active learning for image classification has attracted great attention over recent years and a lot of relevant works are published continuously. However, there still remain some problems that need to be solved, such as existing multi-label active learning algorithms do not reflect on the cleanness of sample data and their ways on label correlation mining are defective. For one thing, sample data is usually contaminated in reality, which disturbs the estimation of data distribution and further hinders the model training. For another, previous approaches for label relationship exploration are purely based on the observed label distribution of an incomplete training set, which cannot provide sufficiently efficient information. To address these issues, we propose a novel adaptive low-rank multi-label active learning algorithm, called LRMAL. Specifically, we first use low-rank matrix recovery to learn an effective low-rank\u00a0\u2026", "num_citations": "12\n", "authors": ["2098"]}
{"title": "Cascade U-ResNets for simultaneous liver and lesion segmentation\n", "abstract": " In recent years, several deep learning networks are proposed to segment 2D or 3D bio-medical images. However, in liver and lesion segmentation, the proportion of interested tissues and lesions are tiny when contrasting to the image background. That is, the objects to be segmented are highly imbalanced in terms of the frequency of occurrences. This makes existing deep learning networks prone to predict pixels of livers and lesions as background. To address this imbalance issue, several loss functions are proposed. Since no researches are having made a comparison among those proposed loss functions, we are curious about that which loss function is the best among them? At the same time, we also want to investigate whether the combination of several different loss functions is effective for liver and lesion segmentation. Firstly, we propose a novel deep learning network (cascade U-ResNets) to produce liver\u00a0\u2026", "num_citations": "11\n", "authors": ["2098"]}
{"title": "Near real-time topic-driven rumor detection in source microblogs\n", "abstract": " Rumors can be propagated across online microblogs at a relatively low cost, but result in a series of major problems in our society. Traditional rumor detection approaches focus on exploring various propagation patterns or data interactions between a source microblog and its subsequent reactions. It is obvious that this causes missing interaction on rumor detection, especially in the absence of retweets or reactions. According to the communication theory of Allport and Postman (1947), Chorus (1953) and Rosnow (1988), the topic of a post can help determine its potential of being a rumor or not. Therefore, we develop a novel topic-driven rumor detection (TDRD) framework to determine whether a post is a rumor only according to its source microblog. Specifically, we first automatically perform topic classification on source microblogs, and then we successfully incorporate the predicted topic vector of the source\u00a0\u2026", "num_citations": "10\n", "authors": ["2098"]}
{"title": "Exploiting aesthetic preference in deep cross networks for cross-domain recommendation\n", "abstract": " Visual aesthetics of products plays an important role in the decision process when purchasing appearance-first products, eg, clothes. Indeed, user\u2019s aesthetic preference, which serves as a personality trait and a basic requirement, is domain independent and could be used as a bridge between domains for knowledge transfer. However, existing work has rarely considered the aesthetic information in product images for cross-domain recommendation. To this end, in this paper, we propose a new deep Aesthetic Cross-Domain Networks (ACDN), in which parameters characterizing personal aesthetic preferences are shared across networks to transfer knowledge between domains. Specifically, we first leverage an aesthetic network to extract aesthetic features. Then, we integrate these features into a cross-domain network to transfer users\u2019 domain independent aesthetic preferences. Moreover, network cross\u00a0\u2026", "num_citations": "10\n", "authors": ["2098"]}
{"title": "Flow correlation degree optimization driven random forest for detecting DDoS attacks in cloud computing\n", "abstract": " Distributed denial-of-service (DDoS) has caused major damage to cloud computing, and the false- and missing-alarm rates of existing DDoS attack-detection methods are relatively high in cloud environment. In this paper, we propose a DDoS attack-detection method with enhanced random forest (RF) optimized by genetic algorithm based on flow correlation degree (FCD) feature. We define the FCD feature according to the asymmetric and semidirectivity interaction characteristics and use the two-tuples FCD feature consisting of packet-statistical degree (PSD) and semidirectivity interaction abnormality (SDIA) to describe the features of attack flow and normal flow. Then we use a genetic algorithm based on the FCD feature sequences to optimize two key parameters of the decision tree in the RF: the maximum number of decision trees and the maximum depth of every single decision tree. We apply the trained RF model with optimized parameters to generate the classifier to be used for DDoS attack-detection. The experiment shows that the proposed method can effectively detect DDoS attacks in cloud environment with a higher accuracy rate and lower false- and missing-alarm rates compared to existing DDoS attack-detection methods.", "num_citations": "10\n", "authors": ["2098"]}
{"title": "An overview of folding techniques in architecture design\n", "abstract": " In recent years, folding techniques are widely used by many architects to make 3D forms from 2D sheets as an inspiration for their design, which enables simpler and more intuitive solutions for architectural realization. This research provides an overview of using folding techniques in architecture design, with an emphasis on their new applications. In this overview, we classify folding techniques as computation geometry folding techniques and manual folding techniques. Finally, we provide recommendations for future development.", "num_citations": "10\n", "authors": ["2098"]}
{"title": "Monochromatic and bichromatic ranked reverse boolean spatial keyword nearest neighbors search\n", "abstract": " Recently, Reverse k Nearest Neighbors (RkNN) queries, returning every answer for which the query is one of its k nearest neighbors, have been extensively studied on the database research community. But the RkNN query cannot retrieve spatio-textual objects which are described by their spatial location and a set of keywords. Therefore, researchers proposed a RSTkNN query to find these objects, taking both spatial and textual similarity into consideration. However, the RSTkNN query cannot control the size of answer set and to be sorted according to the degree of influence on the query. In this paper, we propose a new problem Ranked Reverse Boolean Spatial Keyword Nearest Neighbors query called Ranked-RBSKNN query, which considers both spatial similarity and textual relevance, and returns t answers with most degree of influence. We propose a separate index and a hybrid index to process\u00a0\u2026", "num_citations": "10\n", "authors": ["2098"]}
{"title": "A hybrid intelligent data classification algorithm\n", "abstract": " k-Nearest Neighbour (KNN) is one of the most popular algorithms for pattern recognition and data classification, but the traditional KNN classification method has some disadvantages. In this paper, aim at the KNN classification method\u2019s limitation, we proposed a hybrid intelligent classification algorithm. This novel algorithm combined the particle swarm optimisation algorithm and weighted KNN algorithm to improve classification performance. The experimental results show that our proposed algorithm outperforms the traditional KNN method with greater accuracy.", "num_citations": "10\n", "authors": ["2098"]}
{"title": "Ddos attack detection via multi-scale convolutional neural network\n", "abstract": " Distributed Denial-of-Service (DDoS) has caused great damage to the network in the big data environment. Existing methods are characterized by low computational efficiency, high false alarm rate and high false alarm rate. In this paper, we propose a DDoS attack detection method based on network flow grayscale matrix feature via multiscale convolutional neural network (CNN). According to the different characteristics of the attack flow and the normal flow in the IP protocol, the seven-tuple is defined to describe the network flow characteristics and converted into a grayscale feature by binary. Based on the network flow grayscale matrix feature (GMF), the convolution kernel of different spatial scales is used to improve the accuracy of feature segmentation, global features and local features of the network flow are extracted. A DDoS attack classifier based on multi-scale convolution neural network is constructed. Experiments show that compared with correlation methods, this method can improve the robustness of the classifier, reduce the false alarm rate and the missing alarm rate.", "num_citations": "9\n", "authors": ["2098"]}
{"title": "Location-aware service recommendations with privacy-preservation in the Internet of Things\n", "abstract": " With the ever-increasing maturity and popularization of the Internet of Things (IoT), tremendous business applications developed by distinct enterprises or organizations have been encapsulated into lightweight web services that can easily be accessed or invoked remotely. However, the big volume of candidate web services places a heavy burden on the users\u2019 service selection decision-making process. Under the circumstance, a variety of intelligent recommendation solutions have been developed to reduce the high decision-making cost. Traditional resolutions usually challenge in two aspects. First, the recommendation parameters, i.e., the quality of services (QoS), usually relies on user/service location heavily; therefore, low-quality recommended results may be returned to users if user/service location information is overlooked. Second, historical QoS data often contain partial sensitive information of users\u00a0\u2026", "num_citations": "9\n", "authors": ["2098"]}
{"title": "Keyphrase extraction with sequential pattern mining\n", "abstract": " Existing studies show that extracting a complete keyphrase candidate set is the first and crucial step to extract high quality keyphrases from documents. Based on a common sense that words do not repeatedly appear in an effective keyphrase, we propose a novel algorithm named KCSP for document-specific keyphrase candidate search using sequential pattern mining with gap constraints, which only needs to scan a document once and automatically specifies appropriate gap constraints for words without users\u2019 participation. The experimental results confirm that it helps improve the quality of keyphrase extraction.", "num_citations": "9\n", "authors": ["2098"]}
{"title": "Weak labeled multi-label active learning for image classification\n", "abstract": " In order to achieve better classification performance with even fewer labeled images, active learning is suitable for these situations. Several active learning methods have been proposed for multi-label image classification, but all of them assume that all training images with complete labels. However, as a matter of fact, it is very difficult to get complete labels for each example, especially when the size of labels in a multi-label domain is huge. Usually, only partial labels are available. This is one kind of\" weak label\" problems. This paper proposes an ingeniously solution to this\" weak label\" problem on multi-label active learning for image classification (called WLMAL). It explores label correlation on the weak label problem with the help of input features, and then utilizes label correlation to evaluate the informativeness of each example-label pair in a multi-label dataset for active sampling. Our experimental results on\u00a0\u2026", "num_citations": "9\n", "authors": ["2098"]}
{"title": "Mixed pattern matching-based traffic abnormal behavior recognition\n", "abstract": " A motion trajectory is an intuitive representation form in time-space domain for a micromotion behavior of moving target. Trajectory analysis is an important approach to recognize abnormal behaviors of moving targets. Against the complexity of vehicle trajectories, this paper first proposed a trajectory pattern learning method based on dynamic time warping (DTW) and spectral clustering. It introduced the DTW distance to measure the distances between vehicle trajectories and determined the number of clusters automatically by a spectral clustering algorithm based on the distance matrix. Then, it clusters sample data points into different clusters. After the spatial patterns and direction patterns learned from the clusters, a recognition method for detecting vehicle abnormal behaviors based on mixed pattern matching was proposed. The experimental results show that the proposed technical scheme can recognize main types of traffic abnormal behaviors effectively and has good robustness. The real-world application verified its feasibility and the validity.", "num_citations": "9\n", "authors": ["2098"]}
{"title": "CGCI-SIFT: A More Efficient and Compact Representation of Local Descriptor.\n", "abstract": " This paper proposes a novel invariant local descriptor, a combination of gradient histograms with contrast intensity (CGCI), for image matching and object recognition. Considering the different contributions of sub-regions inside a local interest region to an interest point, we divide the local interest region around the interest point into two main sub-regions: an inner region and a peripheral region. Then we describe the divided regions with gradient histogram information for the inner region and contrast intensity information for the peripheral region respectively. The contrast intensity information is defined as intensity difference between an interest point and other pixels in the local region. Our experimental results demonstrate that the proposed descriptor performs better than SIFT and its variants PCA-SIFT and SURF with various optical and geometric transformations. It also has better matching efficiency than SIFT and its variants PCA-SIFT and SURF, and has the potential to be used in a variety of realtime applications.", "num_citations": "9\n", "authors": ["2098"]}
{"title": "An active learning approach for multi-label image classification with sample noise\n", "abstract": " Multi-label active learning for image classification has been a popular research topic. It faces several challenges, even though related work has made great progress. Existing studies on multi-label active learning do not pay attention to the cleanness of sample data. In reality, data are easily polluted by external influences that are likely to disturb the exploration of data space and have a negative effect on model training. Previous methods of label correlation mining, which are purely based on observed label distribution, are defective. Apart from neglecting noise influence, they also cannot acquire sufficient relevant information. In fact, they neglect inner relation mapping from example space to label space, which is an implicit way of modeling label relationships. To solve these issues, we develop a novel multi-label active learning with low-rank application (ENMAL) algorithm in this paper. A low-rank model is\u00a0\u2026", "num_citations": "8\n", "authors": ["2098"]}
{"title": "Sparse regression with output correlation for cardiac ejection fraction estimation\n", "abstract": " Traditional regression methods minimize the sum of errors of samples with various regularization terms such as the \u21131-norm and \u21132-norm. For the diagnosis of cardiovascular diseases, the cardiac ejection fraction (EF) represents an essential measure. However, existing regularization terms do not consider the output correlation (the correlation between ground truth volumes and estimated volumes w.r.t. each subject), which is beneficial in estimating the cardiac EF. In this paper, we first propose a sparse regression with two regularization terms of the \u21131-norm and output correlation (SROC). Then, we propose a one-dimensional solution path algorithm for quickly finding two good regulation parameters in the formulation of SROC. The solution path algorithm can effectively handle singularities and infinities in the key matrix. Finally, we conduct experiments on a clinical cardiac image dataset with 100 subjects. The\u00a0\u2026", "num_citations": "8\n", "authors": ["2098"]}
{"title": "Social personalized ranking embedding for next poi recommendation\n", "abstract": " As the increasing popularity of the applications of location-based services, points-of-interest (POI) recommendation has become a great value part to help users explore their surrounding living environment and improve the quality of life. Recently, some researchers proposed next POI recommendation, which not only exploiting the users personal interests but also considers the sequential information of users check-ins. There are some next POI recommendation models exploit Metric Embedding method to improve recommendation performance and efficiency. However, these approaches not consider social relations in next POI recommendation, which is challenging due to social relations are noisy and sparse. To this end, in this paper, we proposed a Social Personalized Ranking Embedding (SPRE) model, which integrates user personalization and social relations into consideration, to learn the social relations by\u00a0\u2026", "num_citations": "8\n", "authors": ["2098"]}
{"title": "Label aggregation for crowdsourcing with bi-layer clustering\n", "abstract": " This paper proposes a novel general label aggregation method for both binary and multi-class labeling in crowdsourcing, namely Bi-Layer Clustering (BLC), which clusters two layers of features-the conceptual-level and the physical-level features-to infer true labels of instances. BLC first clusters the instances using the conceptual-level features extracted from their multiple noisy labels and then performs clustering again using the physical-level features. It can facilitate tracking the uncertainty changes of the instances, so that the integrated labels that are likely to be falsely inferred on the conceptual layer can be easily corrected using the estimated labels on the physical layer. Experimental results on two real-world crowdsourcing data sets show that BLC outperforms seven state-of-the-art methods.", "num_citations": "8\n", "authors": ["2098"]}
{"title": "Local density-based similarity matrix construction for spectral clustering\n", "abstract": " According to local and global consistency characteristics of sample data points' distribution, a spectral clustering algorithm using local density-based similarity matrix construction was proposed. Firstly, by analyzing distribution characteristics of sample data points, the definition of local density was given, sorting operation on sample point set from dense to sparse according to sample points' local density was did, and undirected graph in accordance with the designed connection strategy was constructed; then, on the basis of GN algorithm's thinking, a calculation method of weight matrix using edge betweenness was given, and similarity matrix of spectral clustering via data conversion was got; lastly, the class number by appearing position of the first eigengap maximum was determined, and the classification of sample point set in eigenvector space by means of classical clustering method was realized. By means of artificial simulative data set and UCI data set to carry out the experimental tests, results show that the proposed spectral algorithm has better clustering capability.", "num_citations": "8\n", "authors": ["2098"]}
{"title": "Data-driven pollution source location algorithm in water quality monitoring sensor networks\n", "abstract": " Water pollution prevention has been a widely concerned issue for the safety of human lives. To this end, water quality monitoring sensors are introduced in the water distribution systems. Due to the limited budget, it is impossible to deploy sensors everywhere but a small number of sensors are deployed. From the sparse sensor data, it is important, but also challenging, to find out the pollution source location. Traditional methods may suffer from local optimum trapping or low localisation accuracy. To address such problems, we propose a cooperative intelligent optimisation algorithm-based pollution source location algorithm, which is a data-driven approach in simulation-optimisation paradigm. Through open-source EPANET simulator-based experiments, we find out our proposed data-driven algorithm can effectively and efficiently localise the pollution location, as well as the pollution injection starting time, duration\u00a0\u2026", "num_citations": "7\n", "authors": ["2098"]}
{"title": "Security cooperation model based on topology control and time synchronization for wireless sensor networks\n", "abstract": " To address malicious attacks generated from wireless sensor networks (WSNs), in this paper, we study the difficulty of detecting uncoordinated behavior by using a model that is unreliable and has uncontrollable accuracy, trustless control, and an inextensible protocol. A security collaboration model involving coupled state vectors associated with topology control and time synchronization is proposed. The networks achieve synchronization using weights and by controlling the number of goals. The simple calculation of time synchronization values between neighboring nodes serves as the basis for judging the behavior of the node topology control. The coupling state vector calculation is the core of the model. The topology coupling strength rate, signal intensity reduction, clock drift, and clock delay are combined to form a comprehensive model. The network energy consumption is reduced by updating the coupling\u00a0\u2026", "num_citations": "7\n", "authors": ["2098"]}
{"title": "Multi-label active learning with low-rank mapping for image classification\n", "abstract": " In multi-label image classification, each image is always associated with multiple labels and labels are usually correlated with each other. The intrinsic relation among labels can definitely contribute to classifier training. However, most previous studies on active learning for multi-label image classification purely mine label correlation based on observed label distribution. They ignore the mapping relation between examples and their labels. This mapping relation also implicates label relationship. Ignoring the mapping relation leads to an uncomprehensive label correlation estimation and results in a bad performance for classification. In this paper, we propose a novel multi-label active learning with low-rank mapping for image classification, called LMMAL, to solve this issue. More precisely, we train a low-rank mapping matrix to signify the mapping relation between the feature space and the label space of a certain\u00a0\u2026", "num_citations": "7\n", "authors": ["2098"]}
{"title": "A real-time typhoon eye detection method based on deep learning for meteorological information forensics\n", "abstract": " The development of meteorological satellite technology has made it feasible to observe cloud cover over the Earth\u2019s surface, and the number of high-precision meteorological satellite images available has increased dramatically over the years. However, there exists a gap between meteorological satellite cloud images and the true information of the pictured clouds. Therefore, extracting the true atmospheric information from \u201cforged\u201d satellite images in real time is a challenging task. In this paper, we proposed a real-time typhoon eye detection method from meteorological satellite cloud images based on deep learning. This new approach is the first step in detecting hidden information in satellite cloud images and provides important data support to detect true typhoon information. We performed simulation experiments and the results showed that the proposed method performs well in identifying typhoons, where the\u00a0\u2026", "num_citations": "6\n", "authors": ["2098"]}
{"title": "Empirical comparisons of deep learning networks on liver segmentation\n", "abstract": " Accurate segmentation of CT images of liver tumors is an important adjunct for the liver diagnosis and treatment of liver diseases. In recent years, due to the great improvement of hard device, many deep learning based methods have been proposed for automatic liver segmentation. Among them, there are the plain neural network headed by FCN and the residual neural network headed by Resnet, both of which have many variations. They have achieved certain achievements in medical image segmentation. In this paper, we firstly select five representative structures, ie, FCN, U-Net, Segnet, Resnet and Densenet, to investigate their performance on liver segmentation. Since original Resnet and Densenet could not perform image segmentation directly, we make some adjustments for them to perform live segmentation. Our experimental results show that Densenet performs the best on liver segmentation, followed by Resnet. Both perform much better than Segnet, U-Net, and FCN. Among Segnet, U-Net, and FCN, U-Net performs the best, followed by Segnet. FCN performs the worst.", "num_citations": "6\n", "authors": ["2098"]}
{"title": "Forecasting model based on information-granulated GA-SVR and ARIMA for producer price index\n", "abstract": " The accuracy of predicting the Producer Price Index (PPI) plays an indispensable role in government economic work. However, it is difficult to forecast the PPI. In our research, we first propose an unprecedented hybrid model based on fuzzy information granulation that integrates the GA-SVR and ARIMA (Autoregressive Integrated Moving Average Model) models. The fuzzy-information-granulation-based GA-SVR-ARIMA hybrid model is intended to deal with the problem of imprecision in PPI estimation. The proposed model adopts the fuzzy information-granulation algorithm to pre-classification-process monthly training samples of the PPI, and produced three different sequences of fuzzy information granules, whose Support Vector Regression (SVR) machine forecast models were separately established for their Genetic Algorithm (GA) optimization parameters. Finally, the residual errors of the GA-SVR model were rectified through ARIMA modeling, and the PPI estimate was reached. Research shows that the PPI value predicted by this hybrid model is more accurate than that predicted by other models, including ARIMA, GRNN, and GA-SVR, following several comparative experiments. Research also indicates the precision and validation of the PPI prediction of the hybrid model and demonstrates that the model has consistent ability to leverage the forecasting advantage of GA-SVR in non-linear space and of ARIMA in linear space.", "num_citations": "6\n", "authors": ["2098"]}
{"title": "Improve computer visualization of architecture based on the Bayesian network\n", "abstract": " Computer visualization has marvelous effects when it is applied in various fields, especially in architectural design. As an emerging force in the innovation industry, architects and design agencies have already demonstrated the value of architectural visual products in actual application projects. Based on the digital image technology, virtual presentation of future scenes simulates architecture design, architectural renderings and multimedia videos. Therefore, it can help design agencies transform the theoretical design concept into a lively and realistic visual which can provide the audience with a clearer understanding of the engineering and construction projects. However, it is challenging for designers to produce satisfactory renderings due to the frequent fault data during rendering. In this paper, we use the 3Ds MAX as the operating platform and we present an algorithm based on the Bayesian network to construct\u00a0\u2026", "num_citations": "6\n", "authors": ["2098"]}
{"title": "Novel DDoS feature representation model combining deep belief network and canonical correlation analysis\n", "abstract": " Distributed denial of service (DDoS) attacks launch more and more frequently and are more destructive. Feature representation as an important part of DDoS defense technology directly affects the efficiency of defense. Most DDoS feature extraction methods cannot fully utilize the information of the original data, resulting in the extracted features losing useful features. In this paper, a DDoS feature representation method based on deep belief network (DBN) is proposed. We quantify the original data by the size of the network flows, the distribution of IP addresses and ports, and the diversity of packet sizes of different protocols and train the DBN in an unsupervised manner by these quantified values. Two feedforward neural networks (FFNN) are initialized by the trained deep belief network, and one of the feedforward neural networks continues to be trained in a supervised manner. The canonical correlation analysis (CCA) method is used to fuse the features extracted by two feedforward neural networks per layer. Experiments show that compared with other methods, the proposed method can extract better features.", "num_citations": "6\n", "authors": ["2098"]}
{"title": "A DDoS attack situation assessment method via optimized cloud model based on influence function\n", "abstract": " The existing network security situation assessment methods cannot effectively assess the Distributed denial-of-service (DDoS) attack situation. In order to solve these problems, we propose a DDoS attack situation assessment method via optimized cloud model based on influence function. Firstly, according to the state change characteristics of the IP addresses which are accessed by new and old user respectively, this paper defines a fusion feature value. Then, based on this value, we establish a V-Support Vector Machines (V-SVM) classification model to analyze network flow for identifying DDoS attacks. Secondly, according to the change of new and old IP addresses, we propose three evaluation indexes. Furthermore, we propose index weight calculation algorithm to measure the importance of different indexes. According to the fusion index, which is optimized by the weighted algorithm, we define the Risk Degree (RD) and calculate the RD value of each network node. Then we obtain the situation information of the whole network according to the RD values, which are from each network nodes with different weights. Finally, the whole situation information is classified via cloud model to quantitatively assess the DDoS attack situation. The experimental results show that our method can not only improve the detection rate and reduce the missing rate of DDoS attacks, but also access the DDoS attack situation effectively. This method is more accurate and flexible than the existing methods.", "num_citations": "6\n", "authors": ["2098"]}
{"title": "Learning from crowds with active learning and self-healing\n", "abstract": " With the development of crowdsourcing, data acquisition for supervised learning from annotators all over the world becomes simple and economical. To improve accuracy, it is nature to obtain multiple noisy labels (i.e., a multiple label set) for each example from the crowd. Then, consensus algorithms can infer the estimated ground truth from the multiple label set for each example. The estimated ground truth is also called an integrated label, which could be a noise. That is, a dataset constructed via integrating the multiple noisy labels for each example in a crowdsourcing dataset (called an integrated dataset) still contains noises. In order to further improve the data quality of an integrated dataset, so that to improve the performance of a model learned from the integrated dataset, this paper proposes a framework that integrates active learning with the self-healing of a model together. With active learning, a\u00a0\u2026", "num_citations": "6\n", "authors": ["2098"]}
{"title": "Access control model based on time synchronization trust in wireless sensor networks\n", "abstract": " Internal reliability and external safety of Wireless Sensor Networks (WSN) data transmission have become increasingly outstanding issues with the wide applications of WSN. This paper proposes a new method for access control and mitigation of interfering noise in time synchronization environments. First, a formal definition is given regarding the impact interference noise has on the clock skew and clock offset of each node. The degree of node interference behavior is estimated dynamically from the perspective of time-stamp changes caused by the interference noise. Secondly, a general access control model is proposed to resist invasion of noise interference. A prediction model is constructed using the Bayesian method for calculating the reliability of neighbor node behavior in the proposed model. Interference noise, which attacks the time synchronization, is regarded as the key factor for probability estimation of the reliability. The result of the calculations determines whether it is necessary to initiate synchronization filtering. Finally, a division of trust levels with bilinear definition is employed to lower interference noise and improve the quality of interference detection. Experimental results show that this model has advantages in system overhead, energy consumption and testing errors, compared to its counterparts. When the disturbance intensity of a WSN increases, the proposed optimized algorithm converges faster with a lower network communication load. View Full-Text", "num_citations": "6\n", "authors": ["2098"]}
{"title": "A double weighted Naive Bayes for multi-label classification\n", "abstract": " Multi-label classification is to assign an instance to multiple classes. Naive Bayes (NB) is one of the most popular algorithms for pattern recognition and classification. It has a high performance in single label classification. It is naturally extended for multi-label classification under the assumption of label independence. As we know, NB is based on a simple but unrealistic assumption that attributes are conditionally independent given the class. Therefore, a double weighted NB (DWNB) is proposed to demonstrate the influences of predicting different labels based on different attributes. Our DWNB utilizes the niching cultural algorithm to determine the weight configuration automatically. Our experimental results show that our proposed DWNB outperforms NB and its extensions significantly in multi-label classification.", "num_citations": "6\n", "authors": ["2098"]}
{"title": "Scalable Top- Spatial Image Search on Road Networks\n", "abstract": " A top- spatial image search on road networks returns  images based on both their spatial proximity as well as the relevancy of image contents. Existing solutions for the top- text query are not suitable to this problem since they are not sufficiently scalable to cope with hundreds of query keywords and cannot support very large road networks. In this paper, we model the problem as a top- aggregation problem. We first propose a new separate index approach that is based on the visual vocabulary tree image index and the G-tree road network index and then propose a query processing method called an external combined algorithm(CA) method. Our experimental results demonstrate that our approach outperforms the state-of-the-art hybrid method more than one order of magnitude improvement.", "num_citations": "6\n", "authors": ["2098"]}
{"title": "A study on multi-label classification\n", "abstract": " Multi-label classifications exist in many real world applications. This paper empirically studies the performance of a variety of multi-label classification algorithms. Some of them are developed based on problem transformation. Some of them are developed based on adaption. Our experimental results show that the adaptive Multi-Label K-Nearest Neighbor performs the best, followed by Random k-Label Set, followed by Classifier Chain and Binary Relevance. Adaboost.MH performs the worst, followed by Pruned Problem Transformation. Our experimental results also provide us the confidence of existing correlations among multi-labels. These insights shed light for future research directions on multi-label classifications.", "num_citations": "6\n", "authors": ["2098"]}
{"title": "A self-play and sentiment-emphasized comment integration framework based on deep q-learning in a crowdsourcing scenario\n", "abstract": " Crowdsourcing is a hotspot research field which can facilitate machine learning by collecting labels to train models. Consequently, the state-of-the-art research efforts in crowdsourcing focus on truth inference or label integration, to remove inconsistent labels or to alleviate biased labeling. In turn, the integrated labels will be used to fine-tune machine learning models. Particularly, in this paper, we change the target of truth inference in crowdsourcing from discrete labels to multiple comments given by online participants, that is, the integration of the crowdsourced comments. For such a goal, we propose a Self-play and Sentiment-Emphasized Comment Integration Framework (SSECIF), based on deep Q-learning, with three unique features. First, our framework SSECIF can generate the comment integration in a totally self-play way, without relying on the ground truth generated by human effort. Second, the integrated\u00a0\u2026", "num_citations": "5\n", "authors": ["2098"]}
{"title": "Interaction graph neural network for news recommendation\n", "abstract": " Personalized news recommendation has become a highly challenging problem in recent years. Traditional ID-based methods such as collaborative filtering are not suitable for news recommendation due to the extremely rapid update of candidate news. Various content-based methods have been proposed for news recommendation and achieved the state-of-the-art performance. Recently, knowledge-aware news recommendation further improves the performance through discover latent knowledge level connections among the news. However, we argue that the above content-based methods do not fully utilize the collaborative information latent in user-item interactions into user and news representation learning process. In this paper, we propose a new news recommendation model, Interaction Graph Neural Network (IGNN), which integrates a user-item interactions graph and a knowledge graph into the\u00a0\u2026", "num_citations": "5\n", "authors": ["2098"]}
{"title": "A novel DDoS attack detection method using optimized generalized multiple kernel learning\n", "abstract": " Distributed Denial of Service (DDoS) attack has become one of the most destructive network attacks which can pose a mortal threat to Internet security. Existing detection methods can not effectively detect early attacks. In this paper, we propose a detection method of DDoS attacks based on generalized multiple kernel learning (GMKL) combining with the constructed parameter R. The super-fusion feature value (SFV) and comprehensive degree of feature (CDF) are defined to describe the characteristic of attack flow and normal flow. A method for calculating R based on SFV and CDF is proposed to select the combination of kernel function and regularization paradigm. A DDoS attack detection classifier is generated by using the trained GMKL model with R parameter. The experimental results show that kernel function and regularization parameter selection method based on R parameter reduce the randomness of parameter selection and the error of model detection, and the proposed method can effectively detect DDoS attacks in complex environments with higher detection rate and lower error rate.", "num_citations": "5\n", "authors": ["2098"]}
{"title": "Inter-basket and intra-basket adaptive attention network for next basket recommendation\n", "abstract": " Next basket recommendation with consideration of user sequential shopping behaviors plays a significant role in E-commerce to improve the user experience and service quality. Recently, recurrent neural networks (RNNs), especially attention-based RNN, have been widely adopted in the next basket recommendation. However, existing fixed attention mechanisms are not designed to model the dynamic and diverse characteristics of user appetites. In this paper, we propose an inter-basket and intra-basket adaptive attention network (IIAAN) for the next basket recommendation. Specifically, the inter-basket adaptive attention acts on all historical user baskets to model user's diverse long-term preferences, while the intra-basket adaptive attention is designed to act on item-level in the most recent basket to model user's dynamic and different short-term preferences. Then, we further integrate inter-basket and intra\u00a0\u2026", "num_citations": "5\n", "authors": ["2098"]}
{"title": "Coarse to fine: Multi-label image classification with global/local attention\n", "abstract": " In our daily life, the scenes around us are always with multiple labels especially in a smart city, i.e., recognizing the information of city operation to response and control. Great efforts have been made by using Deep Neural Networks to recognize multi-label images. Since multi-label image classification is very complicated, people seek to use the attention mechanism to guide the classification process. However, conventional attention-based methods always analyzed images directly and aggressively. It is difficult for them to well understand complicated scenes. In this paper, we propose a global/local attention method that can recognize an image from coarse to fine by mimicking how human-beings observe images. Specifically, our global/local attention method first concentrates on the whole image, and then focuses on local specific objects in the image. We also propose a joint max-margin objective function, which\u00a0\u2026", "num_citations": "5\n", "authors": ["2098"]}
{"title": "Broaden the minority class space for decision tree induction using antigen-derived detectors\n", "abstract": " To deal with lack of density over imbalanced datasets, a Negative Selection Over-Sampling Technology (NSOTE) is proposed. NSOTE is based on a negative selection mechanism of our human immune system. It generates antigen-derived detectors of majority class examples to enrich the decision regions of the space of minority class. Meanwhile, through learning the density distribution of minority class examples, NSOTE eliminates the noise detectors that deviate from the minority class space. Our experimental results show that our NSOTE can achieve better performance than existing resampling methods.", "num_citations": "5\n", "authors": ["2098"]}
{"title": "An efficient location-aware top-k subscription matching for publish/subscribe with Boolean expressions\n", "abstract": " Location-aware publish/subscribe (pub/sub) has attracted a lot of attentions with the booming of mobile Internet technologies and the rising popularity of smart-phones. Subscribers subscribe their interests with their locations as subscriptions, and publishers publish geo-information as events. Many state-of-art applications with a massive amount of geo-information, such as location-aware targeted advertising systems, face this situation. Existing related work mainly focuses on unstructured geo-textual information. However, many online-to-offline applications have enormous geo-information with different structured descriptions. To handle such structured information, a new type of location-aware pub/sub approach is needed. In this paper, we handle these subscriptions using boolean expressions. Since the number of publishers and subscribers can be enormous, it is extremely important to improve the matching\u00a0\u2026", "num_citations": "5\n", "authors": ["2098"]}
{"title": "Immune centroids oversampling method for binary classification\n", "abstract": " To improve the classification performance of imbalanced learning, a novel oversampling method, immune centroids oversampling technique (ICOTE) based on an immune network, is proposed. ICOTE generates a set of immune centroids to broaden the decision regions of the minority class space. The representative immune centroids are regarded as synthetic examples in order to resolve the imbalance problem. We utilize an artificial immune network to generate synthetic examples on clusters with high data densities, which can address the problem of synthetic minority oversampling technique (SMOTE), which lacks reflection on groups of training examples. Meanwhile, we further improve the performance of ICOTE via integrating ENN with ICOTE, that is, ICOTE + ENN. ENN disposes the majority class examples that invade the minority class space, so ICOTE + ENN favors the separation of both classes. Our\u00a0\u2026", "num_citations": "5\n", "authors": ["2098"]}
{"title": "Maximum classification optimization-based active learning for image classification\n", "abstract": " Traditional multi-class image classification needs a large number of training samples for building a classifier model. However, it is very time-consuming and costly to obtain labels for a large number of training samples from human experts. Active learning is a feasible solution. This paper proposes a maximum classification optimization method (MCO) for actively selecting unlabeled images to acquire labels. It integrated the information of an unlabeled sample from different perspectives with two steps. It first chooses a subset of candidates, and then selects the best from these candidates. Our experimental results show that the maximum classification optimization method outperforms two popular exiting methods (entropy-based uncertainty and BvSB).", "num_citations": "5\n", "authors": ["2098"]}
{"title": "A threshold method for imbalanced multiple noisy labeling\n", "abstract": " Internet-based crowdsourcing systems can be viewed as a kind of loosely coupled social networks. With these systems, it is easy to collect multiple noisy labels for the same object when conducting annotation for supervised learning. Because non-expert labelers lack expertise and dedication, and have strong personal preference, they may have bias when labeling. These cause Imbalanced Multiple Noisy Labeling. In this paper, we propose an agnostic algorithm Positive LAbel frequency Threshold (PLAT) to deal with imbalanced labeling. Because of the dynamics of social networks, in most cases no information about the qualities of labelers and underlying class distributions can be acquired. PLAT does not require prior knowledge of the labeling qualities of labelers, the underlying class distributions, and the level of labeling imbalance. Simulations on eight real-world datasets with different underlying class\u00a0\u2026", "num_citations": "5\n", "authors": ["2098"]}
{"title": "Imbalanced multiple noisy labeling for supervised learning\n", "abstract": " When labeling objects via Internet-based outsourcing systems, the labelers may have bias, because they lack expertise, dedication and personal preference. These reasons cause Imbalanced Multiple Noisy Labeling. To deal with the imbalance labeling issue, we propose an agnostic algorithm PLAT (Positive LAbel frequency Threshold) which does not need any information about quality of labelers and underlying class distribution. Simulations on eight real-world datasets with different underlying class distributions demonstrate that PLAT not only effectively deals with the imbalanced multiple noisy labeling problem that off-the-shelf agnostic methods cannot cope with, but also performs nearly the same as majority voting under the circumstances that labelers have no bias.", "num_citations": "5\n", "authors": ["2098"]}
{"title": "Interval-valued centroids in K-Means algorithms\n", "abstract": " The K-Means algorithms are fundamental in machine learning and data mining. In this study, we investigate interval-valued rather than commonly used point-valued centroids in the K-Means algorithm. Using a proposed interval peak method to select initial interval centroids, we have obtained overall quality improvement of clusters on a set of test problems in the Fundamental Clustering Problem Suite (FCPS).", "num_citations": "5\n", "authors": ["2098"]}
{"title": "Robust Network Alignment via Attack Signal Scaling and Adversarial Perturbation Elimination\n", "abstract": " Recent studies have shown that graph learning models are highly vulnerable to adversarial attacks, and network alignment methods are no exception. How to enhance the robustness of network alignment against adversarial attacks remains an open research problem. In this paper, we propose a robust network alignment solution, RNA, for offering preemptive protection of existing network alignment algorithms, enhanced with the guidance of effective adversarial attacks. First, we analyze how popular iterative gradient-based adversarial attack techniques suffer from gradient vanishing issues and show a fake sense of attack effectiveness. Based on dynamical isometry theory, an attack signal scaling (ASS) method with established upper bound of feasible signal scaling is introduced to alleviate the gradient vanishing issues for effective adversarial attacks while maintaining the decision boundary of network alignment\u00a0\u2026", "num_citations": "4\n", "authors": ["2098"]}
{"title": "A DDoS attack information fusion method based on CNN for multi-element data\n", "abstract": " Traditional distributed denial of service (DDoS) detection methods need a lot of computing resource, and many of them which are based on single element have high missing rate and false alarm rate. In order to solve the problems, this paper proposes a DDoS attack information fusion method based on CNN for multi-element data. Firstly, according to the distribution, concentration and high traffic abruptness of DDoS attacks, this paper defines six features which are respectively obtained from the elements of source IP address, destination IP address, source port, destination port, packet size and the number of IP packets. Then, we propose feature weight calculation algorithm based on principal component analysis to measure the importance of different features in different network environment. The algorithm of weighted multi-element feature fusion proposed in this paper is used to fuse different features, and obtain multi-element fusion feature (MEFF) value. Finally, the DDoS attack information fusion classification model is established by using convolutional neural network and support vector machine respectively based on the MEFF time series. Experimental results show that the information fusion method proposed can effectively fuse multi-element data, reduce the missing rate and total error rate, memory resource consumption, running time, and improve the detection rate.", "num_citations": "4\n", "authors": ["2098"]}
{"title": "Classification on grade, price, and region with multi-label and multi-target methods in wineinformatics\n", "abstract": " Classifying wine according to their grade, price, and region of origin is a multi-label and multi-target problem in wine-informatics. Using wine reviews as the attributes, we compare several different multi-label/multitarget methods to the single-label method where each label is treated independently. We explore both single-label and multi-label approaches for a two-class problem for each of the labels and we explore both single-label and multi-target approaches for a four-class problem on two of the three labels, with the third label remaining a two-class problem. In terms of per-label accuracy, the single-label method has the best performance, although some multi-label methods approach the performance of single-label. However, multi-label/multi-target metrics approaches do exceed the performance of the single-label method.", "num_citations": "4\n", "authors": ["2098"]}
{"title": "Multi-label image classification via coarse-to-fine attention\n", "abstract": " Great efforts have been made by using deep neural networks to recognize multi-label images. Since multi-label image classification is very complicated, many studies seek to use the attention mechanism as a kind of guidance. Conventional attention-based methods always analyzed images directly and aggressively, which is difficult to well understand complicated scenes. We propose a global/local attention method that can recognize a multi-label image from coarse to fine by mimicking how human-beings observe images. Our global/local attention method first concentrates on the whole image, and then focuses on its local specific objects. We also propose a joint max-margin objective function, which enforces that the minimum score of positive labels should be larger than the maximum score of negative labels horizontally and vertically. This function further improve our multi-label image classification method. We\u00a0\u2026", "num_citations": "4\n", "authors": ["2098"]}
{"title": "Genetic risk factors identified in populations of European descent do not improve the prediction of osteoporotic fracture and bone mineral density in Chinese populations\n", "abstract": " Aiming to investigate whether genetic risk factors (GRFs) for fracture and bone mineral density (BMD) identified from people of European descent can help improve the prediction of osteoporotic fracture (OF) risk and BMD in Chinese populations, we built assessment models for femoral neck (FN)-fracture prediction and BMD value prediction using 700 elderly Chinese Han subjects and 1,620 unrelated Chinese Han subjects, respectively. 17 fracture-associated genes and 82 FN-BMD associated genes identified in people of European descent were used to build a logistic regression model with clinical risk factors (CRFs) for FN-fracture prediction in Chinese. Meanwhile 107 BMD-associated genes from people of European descent were used to build a multiple linear regression model with CRFs for BMD prediction in Chinese. A Lasso algorithm was employed for informative SNP selection to construct the genetic risk\u00a0\u2026", "num_citations": "4\n", "authors": ["2098"]}
{"title": "Exploiting visual contents in posters and still frames for movie recommendation\n", "abstract": " Recommender systems, e.g., movie recommendation, play an important role in our life. However, few movie recommendation methods have considered the rich visual content information in posters and still frames, which can be used to alleviate the data sparsity and cold start problems in recommendation. Moreover, no existing paper has taken visual feature learning and recommendation into a unified optimization process. To this end, in this paper, we focus on how to use visual contents to improve the performance of movie recommendation and propose a novel movie recommendation model named unified visual contents matrix factorization (UVMF) that integrates visual feature extraction and recommendation into a unified framework. Specifically, we integrate convolutional neural network into probabilistic matrix factorization, and the model can be trained end-to-end. Moreover, we unfix weights in the last few\u00a0\u2026", "num_citations": "4\n", "authors": ["2098"]}
{"title": "Fog-enabled Event Processing Based on IoT Resource Models\n", "abstract": " Complex Event Processing (CEP) systems extract interest situations from event flows based on event detection patterns. However, local event processing for distributed Internet of Things (IoT) has not been discussed yet. Besides, it is complex or impossible to discover such patterns in some applications of IoT. In this article, we design a complex event service to process event flows based on IoT resource models, which does not depend on existing patterns, and deals with both discrete events and continuous variables. To improve the CEP performance, local IoT resources are used for local event processing, and a lazy exchange method is designed to realize the collaborated event processing between network edges and a data center. Our evaluation shows that our solution is feasible and effective.", "num_citations": "4\n", "authors": ["2098"]}
{"title": "Document-specific keyphrase candidate search and ranking\n", "abstract": " This paper proposes an approach KeyRank to extract proper keyphrases from a document in English. It first searches all keyphrase candidates from the document, and then ranks them for selecting top-N ones as final keyphrases. Existing studies show that extracting a complete keyphrase candidate set that includes semantic relations in context, and evaluating the effectiveness of each candidate are crucial to extract high quality keyphrases from documents. Based on that words do not repeatedly appear in an effective keyphrase in English, a novel keyphrase candidate search algorithm using sequential pattern mining with gap constraints (called KCSP) is proposed to extract keyphrase candidates for KeyRank. And then an effectiveness evaluation measure pattern frequency with entropy (called PF-H) is proposed for KeyRank to rank these keyphrase candidates. Our experimental results show that KeyRank has\u00a0\u2026", "num_citations": "4\n", "authors": ["2098"]}
{"title": "Location-aware publish/subscribe index with complex boolean expressions\n", "abstract": " A location-aware publish/subscribe (pub/sub) system is gaining more and more interest in both industry and academia with the rapid progress of mobile Internet and the rising popularity of smart-phones. Nowadays, with the booming of E-commerce, OTO (online-to-offline) services are gaining more and more popularity, which results in millions of products with different structured descriptions and locations. To meet this requirement, a pub/sub system should handle subscriptions with location-aware boolean expressions to present users\u2019 interests. In this paper, we propose an efficient location-aware pub/sub index for boolean expressions, called RP-trees. RP-trees integrates an R-tree index and a boolean expression index together, can efficiently and simultaneously prune boolean expressions and spatial dimensions. RP-trees is also extensible to support complex environment such as prefix-matching and\u00a0\u2026", "num_citations": "4\n", "authors": ["2098"]}
{"title": "Multi-label active learning for image classification with asymmetrical conditional dependence\n", "abstract": " Image classification is a hot topic of pattern recognition in computer vision. In order to achieve high accuracy of classification, a certain amount of high quality pictures are needed. As a matter of fact, high quality pictures are scarce. Active learning can solve such a problem. Label dependences play an important role in multi-label active learning for image classification. The interdependences between different labels are usually different and asymmetrical. This paper first brings the asymmetrical conditional label dependences into a novel active learning method for multi-label image classification based on the asymmetrical conditional label dependence, called ACDAL. Our extensive experimental results on three image and two non-image datasets show that our new approach ACDAL significantly outperforms existing approaches.", "num_citations": "4\n", "authors": ["2098"]}
{"title": "Integrating active learning with supervision for crowdsourcing generalization\n", "abstract": " With various online crowdsourcing platforms, it is easy to collect multiple labels for the same examples from the crowd. Consensus integration algorithms can infer the estimated ground truths from the multiple label sets of these crowdsourcing datasets. However, it couldn't be avoided that these integrated (estimated) labels still contain noises. In order to further improve the performance of a model learned from data with these integrated labels, we propose an active learning framework to further improve the data quality, such that to improve the model quality, through acquiring limited true labels from experts (the oracle). We further investigate two active learning strategies in terms of two uncertainty measures (i.e., CLUE and MUE) within the active learning framework. From our experimental results on eight simulation crowdsourcing datasets and four real-world crowdsourcing datasets with three popular consensus\u00a0\u2026", "num_citations": "4\n", "authors": ["2098"]}
{"title": "Ranked reverse boolean spatial keyword nearest neighbors search\n", "abstract": " Recently, Reverse k Nearest Neighbors (RkNN) queries, returning every answer for which the query is one of its k nearest neighbors, have been extensively studied on the database research community. But the RkNN query cannot retrieve spatio-textual objects which are described by their spatial location and a set of keywords. Therefore, researchers proposed a RSTkNN query to find these objects, taking both spatial and textual similarity into consideration. However, the RSTkNN query cannot control the size of answer set and to be sorted according to the degree of influence on the query. In this paper, we propose a new problem Ranked Reverse Boolean Spatial Keyword Nearest Neighbors query called Ranked-RBSKNN query, which considers both spatial similarity and textual relevance, and returns t answers with most degree of influence. We propose a separate index and a hybrid index to process\u00a0\u2026", "num_citations": "4\n", "authors": ["2098"]}
{"title": "RPCV: Recommend potential customers to vendors in location-based social network\n", "abstract": " Location-based social network has received much attention recently. It provides rich information of social and spatial context for researchers to study users\u2019 behaviors from different aspects. A number of recent efforts focus on recommending locations, users, activities, and social medias for users. Unlike previous works, we intend to make recommendations for vendors, assisting vendors in finding potential customers in location-based social network. We propose a framework to recommend potential customers to vendors (called RPCV) in location-based social network effectively and efficiently. To find the best set of customers, RPCV takes both spatial relations and user preference into consideration. A reverse spatial-preference kRanks algorithm, which effectively combines spatial relations with user preference, is also proposed. Our experimental results on real datasets from Foursquare and Brightkite show\u00a0\u2026", "num_citations": "4\n", "authors": ["2098"]}
{"title": "Effective spatial keyword query processing on road networks\n", "abstract": " Spatial keyword query plays an important role in many applications with rapid growth of spatio-textual objects collected. In this context, processing boolean spatial keyword query on road networks is one of the most interesting problems. When giving a query which contains a location and a group of keywords, our aim is to return  objects containing all the query keywords which are the nearest to the query location. Though the research on this problem has received extensive studies in Euclidean space, little is done to deal with it on road networks. We first propose novel indexing structures and algorithms that are able to process such query efficiently. Experimental results on multiple real-word datasets show that our methods achieves high performance.", "num_citations": "4\n", "authors": ["2098"]}
{"title": "Studying active learning in the cost-sensitive framework\n", "abstract": " Active learning is a learning paradigm that actively acquires extra information with an \"effort\" for a certain \"gain\" when building learning models. This paper unifies the effort and gain by studying active learning in the cost-sensitive framework. The major advantage of studying active cost-sensitive learning aims at the business goal of minimizing the total cost directly, thus the potential applications of the proposed methods are significant. We first study a simple random active learner \"buying\" additional examples at random in order to reduce the total cost of example acquisition and future misclassifications. Then we propose a novel pool-based cost-sensitive active learner \"buying\" labels of unlabeled examples in a pool. We evaluate our new cost-sensitive active learning algorithms and compare them to previous active cost-sensitive learning methods. Experiment results show that our pool-based cost-sensitive active\u00a0\u2026", "num_citations": "4\n", "authors": ["2098"]}
{"title": "Cost-sensitive learning\n", "abstract": " Classification is the most important task in inductive learning and machine learning. A classifier can be trained from a set of training examples with class labels, and can be used to predict the class labels of new examples. The class label is usually discrete and finite. Many effective classification algorithms have been developed, such as na\u00efve Bayes, decision trees, neural networks, and so on. However, most original classification algorithms pursue to minimize the error rate: the percentage of the incorrect prediction of class labels. They ignore the difference between types of misclassification errors. In particular, they implicitly assume that all misclassification errors cost equally. In many real-world applications, this assumption is not true. The differences between different misclassification errors can be quite large. For example, in medical diagnosis of a certain cancer, if the cancer is regarded as the positive class, and\u00a0\u2026", "num_citations": "4\n", "authors": ["2098"]}
{"title": "A classifier-based approach to user-role assignment for web applications\n", "abstract": " Role-based access control (RBAC) can be used to design a security system for on-line applications. The Role Graph Model is the only RBAC system which has the notion of a group graph. We show how using the group graph to assign users to groups rather than directly to roles helps with this security design. We also show how a machine-learning based classifier can be used to do user-group assignment.", "num_citations": "4\n", "authors": ["2098"]}
{"title": "Multi-label graph node classification with label attentive neighborhood convolution\n", "abstract": " Learning with graph structured data is of great significance for many practical applications. A crucial and fundamental task in graph learning is node classification. In reality, graph nodes are often encoded with various attributes. In addition, the task is usually multi-labeled in nature. In this paper, we tackle the problem of multi-label graph node classification, by leveraging structure, attribute and label information simultaneously. Specifically, to obtain rational node feature representations, we propose an intuitive yet effective graph convolution module to aggregate local attribute information of a given node. Moreover, the homophily hypothesis motivates us to build a label attention module. By exploiting both input and output contextual representations, we utilize the additive attention mechanism and build a label-aware representation learning framework to measure the compatibility between pairs of node embeddings\u00a0\u2026", "num_citations": "3\n", "authors": ["2098"]}
{"title": "Cost-Sensitive Extremely Randomized Trees Algorithm for Online Fault Detection of Wind Turbine Generators\n", "abstract": " The number of normal samples of wind turbine generators is much larger than the number of fault samples. To solve the problem of imbalanced classification in wind turbine generator fault detection, a cost-sensitive extremely randomized trees (CS-ERT) algorithm is proposed in this paper, in which the cost-sensitive learning method is introduced into an extremely randomized trees (ERT) algorithm. Based on the classification misclassification cost and class distribution, the misclassification cost gain (MCG) is proposed as the score measure of the CS-ERT model growth process to improve the classification accuracy of minority classes. The Hilbert-Schmidt independence criterion lasso (HSICLasso) feature selection method is used to select strongly correlated non-redundant features of doubly-fed wind turbine generators. The effectiveness of the method was verified by experiments on 4 different failure datasets of wind turbine generators. The experiment results show that average missing detection rate, average misclassification cost and gMean of the improved algorithm better than those of the ERT algorithm. In addition, compared with the CSForest, AdaCost and MetaCost methods, the proposed method has better real-time fault detection performance.", "num_citations": "3\n", "authors": ["2098"]}
{"title": "Automatic liver segmentation from abdominal CT volumes using improved convolution neural networks\n", "abstract": " Segmentation of the liver from abdominal CT images is an essential step for computer-aided diagnosis and surgery planning. The U-Net architecture is one of the most well-known CNN architectures which achieved remarkable successes in both medical and biological image segmentation domain. However, it does not perform well when the target area is small or partitioned. In this paper, we propose a novel architecture, called dense feature selection U-Net (DFS U-Net), which addresses this challenging problem. Specifically, The Hounsfield unit values were windowed in a range to exclude irrelevant organs, and then use the pre-processed data to train our proposed DFS U-Net model. To further improve the segmentation accuracy of the small region and disconnected regions of interests with limited training datasets, we improve the loss function by adding a parameter to the formula. With respect to the\u00a0\u2026", "num_citations": "3\n", "authors": ["2098"]}
{"title": "Long-and short-term self-attention network for sequential recommendation\n", "abstract": " With great value in real applications, sequential recommendation aims to recommend users the personalized sequential actions. To achieve better performance, it is essential to consider both long-term preferences and sequential patterns (i. e., short-term dynamics). Compared to widely used Recurrent Neural Network (RNN) and Convolutional Neural Network (CNN), Self-Attention Network (SAN) obtains a surge of interest due to fewer parameters, highly parallelizable computation, and flexibility in modeling dependencies. However, existing SAN-based models are inadequate in characterizing and distinguishing users\u2019 long-term preferences and short-term demands since they do not emphasize the importance of the current interest and temporal order information of sequences. In this paper, we propose a novel multi-layer long-and short-term self-attention network (LSSA) for sequential recommendation\u00a0\u2026", "num_citations": "3\n", "authors": ["2098"]}
{"title": "Cross-Domain Recommendation with Adversarial Examples\n", "abstract": " Cross-domain recommendation leverages the knowledge from relevant domains to alleviate the data sparsity issue. However, we find that the state-of-the-art cross-domain models are vulnerable to adversarial examples, leading to possibly large errors in generalization. That\u2019s because most methods rarely consider the robustness of the proposed models. In this paper, we propose a new Adversarial Cross-Domain Network (ACDN), in which adversarial examples are dynamically generated to train the cross-domain recommendation model. Specifically, we first combine two multilayer perceptrons by sharing the user embedding matrix as our base model. Then, we add small but intentionally worst-case perturbations on the model embedding representations to construct adversarial examples, which can result in the model outputting an incorrect answer with a high confidence. By training with these aggressive\u00a0\u2026", "num_citations": "3\n", "authors": ["2098"]}
{"title": "Hierarchical Variational Attention for Sequential Recommendation\n", "abstract": " Attention mechanisms have been successfully applied in many fields, including sequential recommendation. Existing recommendation methods often use the deterministic attention network to consider latent user preferences as fixed points in low-dimensional spaces. However, the fixed-point representation is not sufficient to characterize the uncertainty of user preferences that prevails in recommender systems. In this paper, we propose a new Hierarchical Variational Attention Model (HVAM), which employs variational inference to model the uncertainty in sequential recommendation. Specifically, the attention vector is represented as density by imposing a Gaussian distribution rather than a fixed point in the latent feature space. The variance of the attention vector measures the uncertainty associated with the user\u2019s preference representation. Furthermore, the user\u2019s long-term and short-term preferences are\u00a0\u2026", "num_citations": "3\n", "authors": ["2098"]}
{"title": "Semi-Supervised Multi-Label Learning from Crowds via Deep Sequential Generative Model\n", "abstract": " Multi-label classification (MLC) is pervasive in real-world applications. Conventional MLC algorithms assume that enough ground truth labels are available for training a classifier. While in reality, obtaining ground truth labels is expensive and time-consuming. In the field of data mining, it is more efficient to use crowdsourcing for label collection. In this setting, an MLC algorithm needs to deal with the noisiness of the crowdsourced labels as well as the remaining massive unlabeled data. In this paper, we propose a deep generative model to describe the label generation process for this semi-supervised multi-label learning problem. Although deep generative models are widely used for MLC problems, no previous work could address the noisy crowdsourced multi-labels and unlabeled data simultaneously. To address this challenging problem, our novel generative model incorporates latent variables to describe the\u00a0\u2026", "num_citations": "3\n", "authors": ["2098"]}
{"title": "Automated genomic signal processing for diseased gene identification\n", "abstract": " Genomic signal processing (GSP) is the engineering discipline for the analysis, processing, and use of genomic signals to gain biological knowledge, and the translation of that knowledge into systems-based applications that can be used to diagnose and treat genetic diseases. Statistical Computations on DNA Sequences is one of key areas in which GSP can be applied. In this paper, we apply DSP tools on trinucleotide repeat disorders (too many copies of a certain nucleotide triplet in the DNA) to classify any gene sequence into diseased/non-diseased state. Intially, we collected the Gene sequences responsible for trinucleotide repeat disorders from NCBI. Then, we applied GSP techniques to convert the given gene sequence into an indicator sequence, and furthermore we apply Fast Fourier transforms (FFTs) and Discrete Wavelet Transforms (DWTs), followed by statistical feature extraction and the obtained\u00a0\u2026", "num_citations": "3\n", "authors": ["2098"]}
{"title": "Deep cross networks with aesthetic preference for cross-domain recommendation\n", "abstract": " When purchasing appearance-first products, e.g., clothes, product appearance aesthetics plays an important role in the decision process. Moreover, user's aesthetic preference, which can be regarded as a personality trait and a basic requirement, is domain independent and could be used as a bridge between domains for knowledge transfer. However, existing work has rarely considered the aesthetic information in product photos for cross-domain recommendation. To this end, in this paper, we propose a new deep Aesthetic preference Cross-Domain Network (ACDN), in which parameters characterizing personal aesthetic preferences are shared across networks to transfer knowledge between domains. Specifically, we first leverage an aesthetic network to extract relevant features. Then, we integrate the aesthetic features into a cross-domain network to transfer users' domain independent aesthetic preferences. Moreover, network cross-connections are introduced to enable dual knowledge transfer across domains. Finally, the experimental results on real-world data show that our proposed ACDN outperforms other benchmark methods in terms of recommendation accuracy. The results also show that users' aesthetic preferences are effective in alleviating the data sparsity issue on the cross-domain recommendation.", "num_citations": "3\n", "authors": ["2098"]}
{"title": "Adaptive attention-aware gated recurrent unit for sequential recommendation\n", "abstract": " Due to the dynamic and evolutionary characteristics of user interests, sequential recommendation plays a significant role in recommender systems. A fundamental problem in the sequential recommendation is modeling dynamic user preference. Recurrent Neural Networks (RNNs) are widely adopted in the sequential recommendation, especially attention-based RNN becomes the state-of-the-art solution. However the existing fixed attention mechanism is insufficient to model the dynamic and evolutionary characteristics of user sequential preferences. In this work, we propose a novel solution, Adaptive Attention-Aware Gated Recurrent Unit (3AGRU), to learn adaptive user sequential representations for sequential recommendation. Specifically, we adopt an attention mechanism to adapt the representation of user sequential preference, and learn the interaction between steps and items from data. Moreover, in the\u00a0\u2026", "num_citations": "3\n", "authors": ["2098"]}
{"title": "Detection of tampering by image resizing using local Tchebichef moments\n", "abstract": " There are many image resizing techniques, which include scaling, scale-and-stretch, seam carving, and so on. They have their own advantages and are suitable for different application scenarios. Therefore, a universal detection of tampering by image resizing is more practical. By preliminary experiments, we found that no matter which image resizing technique is adopted, it will destroy local texture and spatial correlations among adjacent pixels to some extent. Due to the excellent performance of local Tchebichef moments (LTM) in texture classification, we are motivated to present a detection method of tampering by image resizing using LTM in this paper. The tampered images are obtained by removing the pixels from original images using image resizing (scaling, scale-and-stretch and seam carving). Firstly, the residual is obtained by image pre-processing. Then, the histogram features of LTM are extracted from the residual. Finally, an error-correcting output code strategy is adopted by ensemble learning, which turns a multi-class classification problem into binary classification sub-problems. Experimental results show that the proposed approach can obtain an acceptable detection accuracies for the three content-aware image re-targeting techniques. View Full-Text", "num_citations": "3\n", "authors": ["2098"]}
{"title": "Optimal building frame column design based on the genetic algorithm\n", "abstract": " Building structure is like the skeleton of the building, it bears the effects of various forces and forms a supporting system, which is the material basis on which the building depends. Hence building structure design is a vital part in architecture design, architects often explore novel applications of their technologies for building structure innovation. However, such searches relied on experiences, expertise or gut feeling. In this paper, a new design method for the optimal building frame column design based on the genetic algorithm is proposed. First of all, in order to construct the optimal model of the building frame column, building units are divided into three categories in general: building bottom, main building and building roof. Secondly, the genetic algorithm is introduced to optimize the building frame column. In the meantime, a PGA-Skeleton based concurrent genetic algorithm design plan is proposed to improve the optimization efficiency of the genetic algorithm. Finally, effectiveness of the mentioned algorithm is verified through the simulation experiment.", "num_citations": "3\n", "authors": ["2098"]}
{"title": "Stratification-based outlier detection over the deep web\n", "abstract": " For many applications, finding rare instances or outliers can be more interesting than finding common patterns. Existing work in outlier detection never considers the context of deep web. In this paper, we argue that, for many scenarios, it is more meaningful to detect outliers over deep web. In the context of deep web, users must submit queries through a query interface to retrieve corresponding data. Therefore, traditional data mining methods cannot be directly applied. The primary contribution of this paper is to develop a new data mining method for outlier detection over deep web. In our approach, the query space of a deep web data source is stratified based on a pilot sample. Neighborhood sampling and uncertainty sampling are developed in this paper with the goal of improving recall and precision based on stratification. Finally, a careful performance evaluation of our algorithm confirms that our approach can effectively detect outliers in deep web.", "num_citations": "3\n", "authors": ["2098"]}
{"title": "Best first over-sampling for multilabel classification\n", "abstract": " Learning from imbalanced multilabel data is a challenging task. It has attracted considerable attention recently. In this paper we propose a MultiLabel Best First Over-sampling (ML-BFO) to improve the performance of multilabel classification algorithms, based on imbalance minimization and Wilson's ENN rule. Our experimental results show that ML-BFO not only duplicates fewer samples but also reduces the imbalance level much more than two state-of-the-art multilabel sampling methods, ie, an over-sampling method LP-ROS and an under-sampling method MLeNN. Besides, ML-BFO significantly improves the performance of multilabel classification algorithms, and performs much better than LP-ROS and MLeNN.", "num_citations": "3\n", "authors": ["2098"]}
{"title": "Immune centroids over-sampling method for multi-class classification\n", "abstract": " To improve the classification performance of imbalanced learning, a novel over-sampling method, Global Immune Centroids Over-Sampling (Global-IC) based on an immune network, is proposed. Global-IC generates a set of representative immune centroids to broaden the decision regions of small class spaces. The representative immune centroids are regarded as synthetic examples in order to resolve the imbalance problem. We utilize an artificial immune network to generate synthetic examples on clusters with high data densities. This approach addresses the problem of synthetic minority oversampling techniques, which lacks of the reflection on groups of training examples. Our comprehensive experimental results show that Global-IC can achieve better performance than renowned multi-class resampling methods.", "num_citations": "3\n", "authors": ["2098"]}
{"title": "An empirical study of reducing multiclass classification methodologies\n", "abstract": " One-against-all and one-against-one are two popular methodologies for reducing multiclass classification problems into a set of binary classifications. In this paper, we are interested in the performance of both one-against-all and one-against-one for basic classification algorithms, such as decision tree, na\u00efve bayes, support vector machine, and logistic regression. Since both one-against-all and one-against-one work like creating a classification committee, they are expected to improve the performance of classification algorithms. However, our experimental results surprisingly show that one-against-all worsens the performance of the algorithms on most datasets. One-against-one helps, but performs worse than the same iterations of bagging these algorithms. Thus, we conclude that both one-against-all and one-against-one should not be used for the algorithms that can perform multiclass classifications\u00a0\u2026", "num_citations": "3\n", "authors": ["2098"]}
{"title": "Boosting inspired process for improving AUC\n", "abstract": " Boosting is a general method of combining a set of classifiers in making final prediction. It is shown to be an effective approach to improve the predictive accuracy of a learning algorithm, but its impact on the ranking performance is unknown. This paper introduces the boosting algorithm AUCBoost, which is a generic algorithm to improve the ranking performance of learning algorithms. Unlike AdaBoost, AUCBoost uses the AUC, not the accuracy, of a classifier to calculate the weight of each training example for building next classifier. To simplify the computation of AUC of weighted instances in AUCBoost, we extend the standard formula for calculating AUC to be a weighted AUC formula (WAUC in short). This extension frees boosting from the resampling process and saves much computation time in the training process. Our experiment results show that the new boosting algorithm AUCBoost does improve\u00a0\u2026", "num_citations": "3\n", "authors": ["2098"]}
{"title": "A novel privacy-preserving speech recognition framework using bidirectional LSTM\n", "abstract": " Utilizing speech as the transmission medium in Internet of things (IoTs) is an effective way to reduce latency while improving the efficiency of human-machine interaction. In the field of speech recognition, Recurrent Neural Network (RNN) has significant advantages to achieve accuracy improvement on speech recognition. However, some of RNN-based intelligence speech recognition applications are insufficient in the privacy-preserving of speech data, and others with privacy-preserving are time-consuming, especially about model training and speech recognition. Therefore, in this paper we propose a novel Privacy-preserving Speech Recognition framework using Bidirectional Long short-term memory neural network, namely PSRBL. On the one hand, PSRBL designs new functions to construct security activation functions by combing with an additive secret sharing protocol, namely a secure piecewise-linear\u00a0\u2026", "num_citations": "2\n", "authors": ["2098"]}
{"title": "Attention and convolution enhanced memory network for sequential recommendation\n", "abstract": " The sequential recommendation, which models sequential behavioral patterns among users for the recommendation, plays a critical role in recommender systems. Conventionally, user general taste and recent demand are combined to promote recommendation performance. However, existing methods usually neglect that user long-term preference keeps evolving over time and only use a static user embedding to model the general taste. Moreover, they often ignore the feature interactions when modeling short-term sequential patterns and integrate user-item or item-item interactions through a linear way, which limits the capability of model. To this end, we propose an ttention and onvolution enhanced memory network for equential ecommendation (ACSR) in this paper. Specifically, an attention layer learns user\u2019s general preference, while the convolutional layer searches for feature interactions and\u00a0\u2026", "num_citations": "2\n", "authors": ["2098"]}
{"title": "Exploring methods of assessing influence relevance of news articles\n", "abstract": " Assessing the influence relevance of a news article is a very important and novel task for news personalized recommendation services. It provides a novel functionality by additionally recommending users news articles that may not match users\u2019 interest points but can help users make good decisions in their daily lives. Since the influence of implicit information delivered by news articles cannot be obtained literally, and meanwhile regions and industries affected by the influence of implicit information are usually not explicitly mentioned in news articles, machine-based methods lost their ability. In this paper we explore methods of assessing influence relevance of news articles by employing crowdsourcing, and the experimental results show that crowdsourcing can assess the influence relevance of news articles very well.", "num_citations": "2\n", "authors": ["2098"]}
{"title": "Keyphrase extraction using sequential pattern mining and entropy\n", "abstract": " This paper proposes an approach KeyRank to extract high quality keyphrases from a document in English. It firstly searches all keyphrase candidates from the document, and then ranks them for selecting top-N keyphrase candidates as final keyphrases. Based on a common sense that words do not repeatedly appear in an effective keyphrase in English, a novel keyphrase candidate search algorithm applying sequential pattern mining with gap constraints (called KCSP) is proposed to search keyphrase candidates for KeyRank. An effectiveness evaluation measure pattern frequency with entropy (called PF-H) is then proposed to rank these keyphrase candidates for KeyRank. Our experimental results show that KeyRank performs better than existing popular approaches do, such as TextRank and KeyEx. Besides, KCSP is much more efficient than a closely related approach SPMW, and PF-H can be applied to\u00a0\u2026", "num_citations": "2\n", "authors": ["2098"]}
{"title": "Learning from the crowd with neural network\n", "abstract": " In general, the first step for supervised learning from crowdsourced data is integration. To obtain training data as traditional machine learning, the ground truth for each example in the crowdsourcing dataset must be integrated with consensus algorithms. However, some information and correlations among labels in the crowdsourcing dataset have discarded after integration. In order to study whether the information and correlations are useful for learning, we proposed three types of neural networks. Experimental results show that i) all the three types of neural networks have abilities to predict labels for future unseen examples, ii) when labelers have lower qualities, the information and correlations in crowdsourcing datasets, which are discarded by integration, does improve the performance of neural networks significantly, iii) when labelers have higher label qualities, the information and correlations have little impact\u00a0\u2026", "num_citations": "2\n", "authors": ["2098"]}
{"title": "TK-SK: Textual-Restricted  Spatial Keyword Query on Road Networks\n", "abstract": " With the rapid development of GPS-enabled devices, spatial keyword query, considering both spatial proximity to a query location and the textual relevance to the query keywords, is applied to many real-world applications. In this context, we study a specific type of spatial keyword query Textual-restricted K Spatial Keyword query (TK-SK query), which returns the nearest  points of interest (POIs) whose textual description is not less than a specified textual relevance threshold and whose location is close to the query location. We further propose a baseline approach and two advanced approaches (a separated index approach and a hybrid index approach) with different indexing strategies to solve this problem. Our comprehensive experiments conducted on real spatial datasets clearly demonstrate the efficiency of our two advanced approaches.", "num_citations": "2\n", "authors": ["2098"]}
{"title": "An Empirical Study of Class Noise Impacts on Supervised Learning Algorithms and Measures\n", "abstract": " Noise in data is an effective cause of concern for many machine learning techniques. Researchers have studied the noise impacts only on some particular learning algorithm. We empirically study the noise impacts on four different representative learning algorithms and the two popular measures (accuracy and AUC) under different intensities of noise, particularly decision tree, na\u00efve bayes, support vector machine, and logistic regression. Our empirical results show that AUC is more tolerant to noise. Among the four algorithms, na\u00efve bayes is the most resistant to noise, but it performs the worst in accuracy. The other algorithms perform much better than na\u00efve bayes especially after the noisy level is lower than 40%. When we develop approaches to improve the data quality (reduce the noise level) and build model with higher accuracy, decision tree is the most preferred one, followed by logistic regression and support vector machine. However, logistic regression performs the best in AUC.", "num_citations": "2\n", "authors": ["2098"]}
{"title": "Survey on the Application of Deep Learning in Extreme Weather Prediction\n", "abstract": " Because of the uncertainty of weather and the complexity of atmospheric movement, extreme weather has always been an important and difficult meteorological problem. Extreme weather events can be called high-impact weather, the \u2018extreme\u2019here means that the probability of occurrence is very small. Deep learning can automatically learn and train from a large number of sample data to obtain excellent feature expression, which effectively improves the performance of various machine learning tasks and is widely used in computer vision, natural language processing, and other fields. Based on the introduction of deep learning, this article makes a preliminary summary of the existing extreme weather prediction methods. These include the ability to use recurrent neural networks to predict weather phenomena and convolutional neural networks to predict the weather. They can automatically extract image features of extreme weather phenomena and predict the possibility of extreme weather somewhere by using a deep learning framework.", "num_citations": "1\n", "authors": ["2098"]}
{"title": "Variational Self-attention Network for Sequential Recommendation\n", "abstract": " Sequential recommendation has become an attractive topic in recommender systems. Existing sequential recommendation methods, including the methods based on the state-of-the-art self-attention mechanism, usually employ deterministic neural networks to represent user preferences as fixed-points in the latent feature spaces. However, the fixed-point vector lacks the ability to capture the uncertainty and dynamics of user preferences that are prevalent in recommender systems. In this paper, we propose a new Variational Self-Attention Network (VSAN), which introduces a variational autoencoder (VAE) into the self-attention network to capture latent user preferences. Specifically, we represent the obtained self-attention vector as density via variational inference, whose variance well characterizes the uncertainty of user preferences. Furthermore, we employ self-attention networks to learn the inference process\u00a0\u2026", "num_citations": "1\n", "authors": ["2098"]}
{"title": "Ct segmentation of liver and tumors fused multi-scale features\n", "abstract": " Liver cancer is one of frequent causes of death from malignancy in the world. Owing to the outstanding advantages of computer-aided diagnosis and deep learning, fully automatic segmentation of computed tomography (CT) images turned into a research hotspot over the years. The liver has quite low contrast with the surrounding tissues, together with its lesion areas are thoroughly complex. To deal with these problems, we proposed effective methods for enhan-cing features and processed public datasets from Liver Tumor Segmentation Chal-lenge (LITS) for the verification. In this experiment, data pre-processing based on the image enhancement and noise reduction. This study redesigned the original UNet with two novel modules and named it DResUNet which was applied deformable convolution. The first module aimed to recalibrate information by the channel and spatial dimension. The other module enriched deep information of these liver CT images through fusing multi-scale features. Besides, we used cross-entropy loss function for adaptive weights to solve the troubles of class imbalance in the dataset samples. These can improve the performance of the network in-depth and breadth feature learning to deal with many complex segmentation scenes in abdominal CT images. More importantly, the effect of predicted images fully proved that our methods are highly competitive among the segmentation of liver and liver tumors.", "num_citations": "1\n", "authors": ["2098"]}
{"title": "A review of Chinese named entity recognition\n", "abstract": " Named Entity Recognition (NER) is used to identify entity nouns in the corpus such as Location, Person and Organization, etc. NER is also an important basic of research in various natural language fields. The processing of Chinese NER has some unique difficulties, for example, there is no obvious segmentation boundary between each Chinese character in a Chinese sentence. The Chinese NER task is often combined with Chinese word segmentation, and so on. In response to these problems, we summarize the recognition methods of Chinese NER. In this review, we first introduce the sequence labeling system and evaluation metrics of NER. Then, we divide Chinese NER methods into rule-based methods, statistics-based machine learning methods and deep learning-based methods. Subsequently, we analyze in detail the model framework based on deep learning and the typical Chinese NER methods. Finally, we put forward the current challenges and future research directions of Chinese NER technology.", "num_citations": "1\n", "authors": ["2098"]}
{"title": "Ensemble learning with attention-integrated convolutional recurrent neural network for imbalanced speech emotion recognition\n", "abstract": " This article addresses observation duplication and lack of whole picture problems for ensemble learning with the attention model integrated convolutional recurrent neural network (ACRNN) in imbalanced speech emotion recognition. Firstly, we introduce Bagging with ACRNN and the observation duplication problem. Then Redagging is devised and proved to address the observation duplication problem by generating bootstrap samples from permutations of observations. Moreover, Augagging is proposed to get oversampling learner to participate in majority voting for addressing the lack of whole picture problem. Finally, Extensive experiments on IEMOCAP and Emo-DB samples demonstrate the superiority of our proposed methods (i.e., Redagging and Augagging).", "num_citations": "1\n", "authors": ["2098"]}
{"title": "An optimal model with a lower bound of recall for imbalanced speech emotion recognition\n", "abstract": " In an early complain warning system, we encounter a common problem - the lack of angry emotions for training classification models. Moreover, the recognition of angry emotion is more important than that of no-anger emotion. Based on this, the main purpose of this paper is to train an optimal model which achieves a high recall above a lower bound and a maximum of F1 score. It is divided into three aspects: 1) A variant of F1 score (TF1 score) takes recall above a lower bound and F1 score into consideration; 2) A Single Emotion Deep Neural Network (SEDNN) and its training process are designed to find an optimal model with a maximum of TF1 score. 3) A performance comparison of different methods is conducted on IEMOCAP and Emo-DB database. Extensive experiments show that when a BCE loss function or a focal loss function is used, the training process can find a model with a recall above a high\u00a0\u2026", "num_citations": "1\n", "authors": ["2098"]}
{"title": "Spatio-Temporal Self-Attention Network for Next POI Recommendation\n", "abstract": " Next Point-of-Interest (POI) recommendation, which aims to recommend next POIs that the user will likely visit in the near future, has become essential in Location-based Social Networks (LBSNs). Various Recurrent Neural Network (RNN) based sequential models have been proposed for next POI recommendation and achieved state-of-the-art performance, however RNN is difficult to parallelize which limits its efficiency. Recently, Self-Attention Network (SAN), which is purely based on the self-attention mechanism instead of recurrent modules, improves both performance and efficiency in various sequential tasks. However, none of the existing self-attention networks consider the spatio-temporal intervals between neighbor check-ins, which are essential for modeling user check-in behaviors in next POI recommendation. To this end, in this paper, we propose a new Spatio-Temporal Self-Attention Network\u00a0\u2026", "num_citations": "1\n", "authors": ["2098"]}
{"title": "Fruited-Forest: A Reachability Querying Method Based on Spanning Tree Modelling of Reduced DAG\n", "abstract": " A reachability query is a fundamental graph operation in real graph applications, which answers whether a node can reach another node through a path in a graph. However, the increasingly large amounts of real graph data make it more challenging for query efficiency and scalability. In this paper, we propose a Fruited-Forest (FF) approach to accelerate reachability queries in large graphs by constructing four kinds of fruited-forests from a reduced DAG in different traversal orders. We build different binary-label schemes for the four kinds of fruited-forests to cover reachability between nodes as much as possible, and create a corresponding index for the deleted edges which are deleted during the construction of fruited-forests. Our experimental results on 18 large real graph datasets show that our FF approach requires less index construct time and a smaller index size, which is more scalable to answer\u00a0\u2026", "num_citations": "1\n", "authors": ["2098"]}
{"title": "Knowledge graph attention network enhanced sequential recommendation\n", "abstract": " Knowledge graph (KG) has recently been proved effective and attracted a lot of attentions in sequential recommender systems. However, the relations between the attributes of different entities in KG, which could be utilized to improve the performance, remain largely unexploited. In this paper, we propose an end-to-end Knowledge Graph attention network enhanced Sequential Recommendation (KGSR) framework to capture the context-dependency of sequence items and the semantic information of items in KG by explicitly exploiting high-order relations between entities. Specifically, our method first combines the user-item bipartite graph and the KG into a unified graph and encodes all nodes of the unified graph into vector representations with TransR. Then, a graph attention network recursively propagates the information of neighbor nodes to refine the embedding of nodes and distinguishes the\u00a0\u2026", "num_citations": "1\n", "authors": ["2098"]}
{"title": "A Roadmap to Domain Knowledge Integration in Machine Learning\n", "abstract": " Many machine learning algorithms have been developed in recent years to enhance the performance of a model in different aspects of artificial intelligence. But the problem persists due to inadequate data and resource. Integrating knowledge in a machine learning model can help to overcome these obstacles up to a certain degree. Incorporating knowledge is a complex task though because of various forms of knowledge representation. In this paper, we will give a brief overview of these different forms of knowledge integration and their performance in certain machine learning tasks.", "num_citations": "1\n", "authors": ["2098"]}
{"title": "Labelling Training Samples Using Crowdsourcing Annotation for Recommendation\n", "abstract": " The supervised learning-based recommendation models, whose infrastructures are sufficient training samples with high quality, have been widely applied in many domains. In the era of big data with the explosive growth of data volume, training samples should be labelled timely and accurately to guarantee the excellent recommendation performance of supervised learning-based models. Machine annotation cannot complete the tasks of labelling training samples with high quality because of limited machine intelligence. Although expert annotation can achieve a high accuracy, it requires a long time as well as more resources. As a new way of human intelligence to participate in machine computing, crowdsourcing annotation makes up for shortages of machine annotation and expert annotation. Therefore, in this paper, we utilize crowdsourcing annotation to label training samples. First, a suitable crowdsourcing mechanism is designed to create crowdsourcing annotation-based tasks for training sample labelling, and then two entropy-based ground truth inference algorithms (i.e., HILED and HILI) are proposed to achieve quality improvement of noise labels provided by the crowd. In addition, the descending and random order manners in crowdsourcing annotation-based tasks are also explored. The experimental results demonstrate that crowdsourcing annotation significantly improves the performance of machine annotation. Among the ground truth inference algorithms, both HILED and HILI improve the performance of baselines; meanwhile, HILED performs better than HILI.", "num_citations": "1\n", "authors": ["2098"]}
{"title": "Interactive Learning with Proactive Cognition Enhancement for Crowd Workers\n", "abstract": " Learning from crowds often performs in an active learning paradigm, aiming to improve learning performance quickly as well as to reduce labeling cost by selecting proper workers to (re) label critical instances. Previous active learning methods for learning from crowds do not have any proactive mechanism to effectively improve the reliability of workers, which prevents to obtain steadily rising learning curves. To help workers improve their reliability while performing tasks, this paper proposes a novel Interactive Learning framework with Proactive Cognitive Enhancement (ILPCE) for crowd workers. The ILPCE framework includes an interactive learning mechanism: When crowd workers perform labeling tasks in active learning, their cognitive ability to the specific domain can be enhanced through learning the exemplars selected by a psychological model-based machine teaching method. A novel probabilistic truth inference model and an interactive labeling scheme are proposed to ensure the effectiveness of the interactive learning mechanism and the performance of learning models can be simultaneously improved through a fast and low-cost way. Experimental results on three real-world learning tasks demonstrate that our ILPCE significantly outperforms five representative state-of-the-art methods.", "num_citations": "1\n", "authors": ["2098"]}
{"title": "Non-homogeneous distributed cloud storage system with minimal redundancy in heterogeneous environment\n", "abstract": " To improve the reasonability of constructing distributed cloud storage system, a method of constructing distributed cloud storage system with minimum redundancy considering heterogeneity in heterogeneous environment is proposed. First, In the analysis of algorithm design, we need to consider the availability of data, which is in heterogeneous environments is developed. Because the computation of data availability is very complicated when the storage node grows, Monte Carlo is an effective method for data availability analysis, its main advantage is that it can reduce the complexity of the analysis framework calculation process. Secondly, since it is difficult to determine the optimal redundancy allocated on each host, a particle swarm optimization (PSO) based allocation method is proposed. Finally, The main feature of this algorithm in the process of data availability analysis is that the redundancy index of the\u00a0\u2026", "num_citations": "1\n", "authors": ["2098"]}
{"title": "AdaCML: Adaptive Collaborative Metric Learning for Recommendation\n", "abstract": " User preferences are dynamic and diverse in real world, while historical preference of a user may not be equally important as current preference when predicting future interests. As a result, learning the evolving user representation effectively becomes a critical problem in personalized recommendation. However, existing recommendation solutions often use a fixed user representation, which is not capable of modeling the complex interests of users. To this end, we propose a novel metric learning approach named Adaptive Collaborative Metric Learning (AdaCML) for recommendation. AdaCML employs a memory component and an attention mechanism to learn an adaptive user representation, which dynamically adapts to locally activated items. In this way, implicit relationships of user-item pairs can be better determined in the metric space and users\u2019 interests can be modeled more accurately. Comprehensive\u00a0\u2026", "num_citations": "1\n", "authors": ["2098"]}
{"title": "Exploiting Aesthetic Features in Visual Contents for Movie Recommendation\n", "abstract": " As one of the most widely used recommender systems, movie recommendation plays an important role in our life. However, the data sparsity problem severely hinders the effectiveness of personalized movie recommendation, which requires more rich content information to be utilized. Posters and still frames, which directly display the visual contents of movies, have significant influences on movie recommendation. They not only reveal rich knowledge for understanding movies but also useful for understanding user preferences. However, existing recommendation methods rarely consider aesthetic features, which tell how the movie looks and feels, extracted from these pictures for the movie recommendation. To this end, in this paper, we propose an aesthetic-aware unified visual content matrix factorization (called UVMF-AES) to integrate visual feature learning and recommendation into a unified framework\u00a0\u2026", "num_citations": "1\n", "authors": ["2098"]}
{"title": "A New Method for Architecture Space Design Based on Substance-Field Analysis\n", "abstract": " Research about novel methods in the architectural design process can enlarge design researches. Structured design methods can make the design process more organized and learnable. Substance-Field (Su-field) Analysis is a TRIZ analytical tool for modeling problems related to existing technological systems. Meanwhile, the space concept is vital in architecture. This paper aims to present Human-Field (Hu-field) Analysis method based on Su-field Analysis and general solutions for more effective architecture space design. A controlled experiment demonstrates the effectiveness of this method by measuring idea quality and quantity.", "num_citations": "1\n", "authors": ["2098"]}
{"title": "Texture Feature Extraction from Thyroid MR Imaging Using High-Order Derived Mean CLBP\n", "abstract": " In the field of medical imaging, the traditional local binary pattern (LBP) and its improved algorithms are often sensitive to noise. Traditional LBPs are solely based on the signal information from local differences, and the binary quantization method oversimplifies the local texture features while disregarding the imaging information from the concaveconvex regions between the high-order pixels and the neighboring sampling points. Therefore, we propose an improved Derived Mean Complete Local Binary Pattern (DM CLBP) algorithm based on high-order derivatives. In the DM CLBP method, the grey value of a single pixel is replaced by the mean grey value of the rectangular area block, and the difference between pixel values in the area is obtained using the second-order differentiation method. Based on the calculation concept of the complete local binary pattern (CLBP) algorithm, the cascade signs and\u00a0\u2026", "num_citations": "1\n", "authors": ["2098"]}
{"title": "Exploiting Implicit Social Relationship for Point-of-Interest Recommendation\n", "abstract": " The emergence of Location-based Social Network (LBSN) services allows users to share their check-ins, providing an excellent opportunity to build personalized Point-of-Interest (POI) recommender systems. Social network data which contains important context information has been demonstrated to have a significant effect on improving recommendation performances. However, explicit social relationships are usually partially available or even unavailable. The gap between the importance of social relationships and their partial availability or unavailability motivates us to study POI recommendation with implicit social relationships, which can well characterize users\u2019 preferences for POIs on both space and content. In this paper, we first extract implicit social relationships and estimate connection strengths by analyzing co-occurrences in both space and time with people\u2019s history check-in data. Then, we\u00a0\u2026", "num_citations": "1\n", "authors": ["2098"]}
{"title": "MeteCloud: Meteorological Cloud Computing Platform for Mobile Weather Forecasts based on Energy-aware Scheduling\n", "abstract": " Nowadays, more and more large-scale data intensive applications such as meteorological big data executed in data centers require a huge amount of electrical energy and energy costs. Therefore, minimizing the energy consumption and reducing the environmental impact is our goal of Green Cloud Computing. In this paper, a new meteorological cloud computing platform (MeteCloud) for Mobile Weather Forecasts based on energy-aware scheduling for improving the energy efficiency is proposed. This approach is different from the existing researches, which wants to emphasize the importance of energy consumption in the study of constructing cloud computing platform for meteorological applications. And, a novel MeteCloud architecture and a hybrid scheduling algorithm are given to testify the availability of", "num_citations": "1\n", "authors": ["2098"]}
{"title": "Effects of unfolding techniques as design stimuli in building design\n", "abstract": " Through paper folding techniques, i.e. origami, people can make fascinating 3D forms from 2D sheets. Many architects utilise folding techniques in their design process as design stimuli. However, the reverse process, unfolding 3D forms, presents computational geometry problems, and there is limited research that clarifies how designers can use theses unfolding techniques. In this study, we begin by introducing a computational geometry method for generating common developments by unfolding 3D plural cuboids. Next, this paper presents the results of an experiment where extended protocol analysis methods were used to examine the effects of using the unfolding techniques as design stimuli during concept generation. The results show that the unfolding techniques promote creativity in building design and enhance participants\u2019 extension of idea space from the microscopic perspective.", "num_citations": "1\n", "authors": ["2098"]}
{"title": "Refining Automatically Extracted Knowledge Bases Using Crowdsourcing\n", "abstract": " Machine-constructed knowledge bases often contain noisy and inaccurate facts. There exists significant work in developing automated algorithms for knowledge base refinement. Automated approaches improve the quality of knowledge bases but are far from perfect. In this paper, we leverage crowdsourcing to improve the quality of automatically extracted knowledge bases. As human labelling is costly, an important research challenge is how we can use limited human resources to maximize the quality improvement for a knowledge base. To address this problem, we first introduce a concept of semantic constraints that can be used to detect potential errors and do inference among candidate facts. Then, based on semantic constraints, we propose rank-based and graph-based algorithms for crowdsourced knowledge refining, which judiciously select the most beneficial candidate facts to conduct crowdsourcing and prune unnecessary questions. Our experiments show that our method improves the quality of knowledge bases significantly and outperforms state-of-the-art automatic methods under a reasonable crowdsourcing cost.", "num_citations": "1\n", "authors": ["2098"]}
{"title": "An efficient location-aware publish/subscribe index with Boolean expressions\n", "abstract": " A location-aware publish/subscribe (pub/sub) system is gaining more and more interest in both industry and academia with the rapid progress of mobile Internet and the rising popularity of smart-phones. Nowadays, with the booming of E-commerce, Object-to-Object (OTO) services are gaining more and more popularity, which results in millions of products with different structured descriptions and locations. To meet this requirement, a pub/sub system should handle subscriptions with location-aware boolean expressions to present users\u2019 interests. In this paper, we propose an efficient location-aware pub/sub index for boolean expressions, called RP-trees. RP-trees integrates an R-tree index and a boolean expression index together, can efficiently and simultaneously prune boolean expressions and spatial dimensions. Our experimental results show that RP-trees achieves better performance on both a\u00a0\u2026", "num_citations": "1\n", "authors": ["2098"]}
{"title": "Improving label accuracy by filtering low-quality workers in crowdsourcing\n", "abstract": " Filtering low-quality workers from data sets labeled via crowdsourcing is often necessary due to the presence of low quality workers, who either lack knowledge on corresponding subjects and thus contribute many incorrect labels to the data set, or intentionally label quickly and imprecisely in order to produce more labels in a short time period. We present two new filtering algorithms to remove low-quality workers, called Cluster Filtering (CF) and Dynamic Classification Filtering (DCF). Both methods can use any number of characteristics of workers as attributes for learning. CF separates workers using k-means clustering with 2 centroids, separating the workers into a high-quality cluster and a low-quality cluster. DCF uses a classifier of any kind to perform learning. It builds a model from a set of workers from other crowdsourced data sets and classifies the workers in the data set to filter. In theory, DCF can be\u00a0\u2026", "num_citations": "1\n", "authors": ["2098"]}
{"title": "Noise correction of image labeling in crowdsourcing\n", "abstract": " We investigate the methods of improving data quality, in terms of label accuracy, in the context of image labeling in crowdsourcing. First, we look at three consensus methods for inferring a ground-truth label from the multiple noisy labels obtained from crowdsourcing, i.e., Majority Voting (MV), Dawid Skene (DS), and KOS. We then apply three noise correction methods to correct labels inferred by these consensus methods, i.e., Polishing Labels (PL), Self-Training Correction (STC), and Cluster Correction (CC). Our experimental results show that the noise correction methods improve the labeling quality significantly.", "num_citations": "1\n", "authors": ["2098"]}
{"title": "Semi-automatic labeling with active learning for multi-label image classification\n", "abstract": " For multi-label image classification, we use active learning to select example-label pairs to acquire labels from experts. The core of active learning is to select the most informative examples to request their labels. Most previous studies in active learning for multi-label classification have two shortcomings. One is that they didn\u2019t pay enough attention on label correlations. The other shortcoming is that existing example-label selection methods predict all the rest labels of the selected example-label pair. This leads to a bad performance for classification when the number of the labels is large. In this paper, we propose a semi-automatic labeling multi-label active learning (SLMAL) algorithm. Firstly, SLMAL integrates uncertainty and label informativeness to select example-label pairs to request labels. Then we choose the most uncertain example-label pair and predict its partial labels using its nearest neighbor\u00a0\u2026", "num_citations": "1\n", "authors": ["2098"]}
{"title": "Feasibility and finite convergence analysis for accurate on-line \u03bd-support vector machine.\n", "abstract": " The \u03bd-support vector machine (\u03bd-SVM) for classification has the advantage of using a parameter \u03bd on controlling the number of support vectors and margin errors. Recently, an interesting accurate on-line algorithm accurate on-line \u03bd-SVM algorithm (AONSVM) is proposed for training \u03bd-SVM. AONSVM can be viewed as a special case of parametric quadratic programming techniques. It is demonstrated that AONSVM avoids the infeasible updating path as far as possible, and successfully converges to the optimal solution based on experimental analysis. However, because of the differences between AONSVM and classical parametric quadratic programming techniques, there is no theoretical justification for these conclusions. In this paper, we prove the feasibility and finite convergence of AONSVM under two assumptions. The main results of feasibility analysis include: 1) the inverses of the two key matrices in\u00a0\u2026", "num_citations": "1\n", "authors": ["2098"]}
{"title": "Fast data acquisition in cost-sensitive learning\n", "abstract": " Data acquisition is the first and one of the most important steps in many data mining applications. It is a time consuming and costly task. Acquiring an insufficient number of examples makes the learned model and future prediction inaccurate, while acquiring more examples than necessary wastes time and money. Thus it is very important to estimate the number examples needed for learning algorithms in machine learning. However, most previous learning algorithms learn from a given and fixed set of examples. To our knowledge, little previous work in machine learning can dynamically acquire examples as it learns, and decide the ideal number of examples needed. In this paper, we propose a simple on-line framework for fast data acquisition                 (FDA). FDA is an extrapolation method that estimates the number of examples needed in each acquisition and acquire them simultaneously. Comparing to\u00a0\u2026", "num_citations": "1\n", "authors": ["2098"]}