{"title": "Ai2: Safety and robustness certification of neural networks with abstract interpretation\n", "abstract": " We present AI 2 , the first sound and scalable analyzer for deep neural networks. Based on overapproximation, AI 2  can automatically prove safety properties (e.g., robustness) of realistic neural networks (e.g., convolutional neural networks). The key insight behind AI 2  is to phrase reasoning about safety and robustness of neural networks in terms of classic abstract interpretation, enabling us to leverage decades of advances in that area. Concretely, we introduce abstract transformers that capture the behavior of fully connected and convolutional neural network layers with rectified linear unit activations (ReLU), as well as max pooling layers. This allows us to handle real-world neural networks, which are often built out of those types of layers. We present a complete implementation of AI 2  together with an extensive evaluation on 20 neural networks. Our results demonstrate that: (i) AI 2  is precise enough to prove\u00a0\u2026", "num_citations": "501\n", "authors": ["1724"]}
{"title": "Securify: Practical security analysis of smart contracts\n", "abstract": " Permissionless blockchains allow the execution of arbitrary programs (called smart contracts), enabling mutually untrusted entities to interact without relying on trusted third parties. Despite their potential, repeated security concerns have shaken the trust in handling billions of USD by smart contracts. To address this problem, we present Securify, a security analyzer for Ethereum smart contracts that is scalable, fully automated, and able to prove contract behaviors as safe/unsafe with respect to a given property. Securify's analysis consists of two steps. First, it symbolically analyzes the contract's dependency graph to extract precise semantic information from the code. Then, it checks compliance and violation patterns that capture sufficient conditions for proving if a property holds or not. To enable extensibility, all patterns are specified in a designated domain-specific language. Securify is publicly released, it has\u00a0\u2026", "num_citations": "434\n", "authors": ["1724"]}
{"title": "Verx: Safety verification of smart contracts\n", "abstract": " We present VerX, the first automated verifier able to prove functional properties of Ethereum smart contracts. VerX addresses an important problem as all real-world contracts must satisfy custom functional specifications.VerX is based on a careful combination of three techniques, enabling it to automatically verify temporal properties of infinite- state smart contracts: (i) reduction of temporal property verification to reachability checking, (ii) a new symbolic execution engine for the Ethereum Virtual Machine that is precise and efficient for a practical fragment of Ethereum contracts, and (iii) delayed predicate abstraction which uses symbolic execution during transactions and abstraction at transaction boundaries.Our extensive experimental evaluation on 83 temporal properties and 12 real-world projects, including popular crowdsales and libraries, demonstrates that VerX is practically effective.", "num_citations": "102\n", "authors": ["1724"]}
{"title": "Dl2: Training and querying neural networks with logic\n", "abstract": " We present DL2, a system for training and querying neural networks with logical constraints. Using DL2, one can declaratively specify domain knowledge constraints to be enforced during training, as well as pose queries on the model to find inputs that satisfy a set of constraints. DL2 works by translating logical constraints into a loss function with desirable mathematical properties. The loss is then minimized with standard gradient-based methods. We evaluate DL2 by training networks with interesting constraints in unsupervised, semi-supervised and supervised settings. Our experimental evaluation demonstrates that DL2 is more expressive than prior approaches combining logic and neural networks, and its loss functions are better suited for optimization. Further, we show that for a number of queries, DL2 can find the desired inputs in seconds (even for large models such as ResNet-50 on ImageNet).", "num_citations": "60\n", "authors": ["1724"]}
{"title": "DP-Finder: Finding Differential Privacy Violations by Sampling and Optimization\n", "abstract": " We present DP-Finder, a novel approach and system that automatically derives lower bounds on the differential privacy enforced by algorithms. Lower bounds are practically useful as they can show tightness of existing upper bounds or even identify incorrect upper bounds. Computing a lower bound involves searching for a counterexample, defined by two neighboring inputs and a set of outputs, that identifies a large privacy violation. This is an inherently hard problem as finding such a counterexample involves inspecting a large (usually infinite) and sparse search space. To address this challenge, DP-Finder relies on two key insights. First, we introduce an effective and precise correlated sampling method to estimate the privacy violation of a counterexample. Second, we show how to obtain a differentiable version of the problem, enabling us to phrase the search task as an optimization objective to be maximized\u00a0\u2026", "num_citations": "35\n", "authors": ["1724"]}
{"title": "ExcUseMe: Asking users to help in item cold-start recommendations\n", "abstract": " The item cold-start problem is of a great importance in collaborative filtering (CF) recommendation systems. It arises when new items are added to the inventory and the system cannot model them properly since it relies solely on historical users' interactions (eg, ratings). Much work has been devoted to mitigate this problem mostly by employing hybrid approaches that combine content-based recommendation techniques or by devoting a portion of the user traffic for exploration to gather interactions from random users. We focus on pure CF recommender systems (ie, without content or context information) in a realistic online setting, where random exploration is inefficient and smart exploration that carefully selects users is crucial due to the huge flux of new items with short lifespan. We further assume that users arrive randomly one after the other and that the system has to immediately decide whether the arriving user\u00a0\u2026", "num_citations": "33\n", "authors": ["1724"]}
{"title": "Config2spec: Mining network specifications from network configurations\n", "abstract": " Network verification and configuration synthesis are promising approaches to make networks more reliable and secure by enforcing a set of policies. However, these approaches require a formal and precise description of the intended network behavior, imposing a major barrier to their adoption: network operators are not only reluctant to write formal specifications, but often do not even know what these specifications are.", "num_citations": "27\n", "authors": ["1724"]}
{"title": "Net2Text: Query-Guided Summarization of Network Forwarding Behaviors\n", "abstract": " Today network operators spend a significant amount of time struggling to understand how their network forwards traffic. Even simple questions such as\" How is my network handling Google traffic?\" often require operators to manually bridge large semantic gaps between lowlevel forwarding rules distributed across many routers and the corresponding high-level insights.", "num_citations": "18\n", "authors": ["1724"]}
{"title": "LCD: Local Combining on Demand\n", "abstract": " Combining methods are highly effective for implementing concurrent queues and stacks. These data structures induce a heavy competition on one or two contention points. However, it was not known whether combining methods could be made effective for parallel scalable data structures that do not have a small number of contention points. In this paper, we introduce local combining on-demand, a new combining method for highly parallel data structures. The main idea is to apply combining locally for resources on which threads contend. We demonstrate the use of local combining on-demand on the common linked-list data structure. Measurements show that the obtained linked-list induces a low overhead when contention is low and outperforms other known implementations by up to 40% when contention is high.", "num_citations": "7\n", "authors": ["1724"]}
{"title": "Smart exploration methods for mitigating item cold-start problem in collaborative filtering recommendation systems\n", "abstract": " Systems and methods for building a latent item vector and item bias for a new item in a collaborative filtering system are disclosed. The method includes dividing incoming users into intervals with each interval having a learning phase and a selection phase. The learning phase scores each incoming user according to a best estimate latent vector and bias and saves the highest score. In the selection each incoming user is scored and a user exceeding the highest score is selected. The best estimate latent vector and bias is then updated based on the user's vector and bias, and the user's interaction with the item. The updated best estimate latent vector is then used in further intervals for learning and selecting users.", "num_citations": "6\n", "authors": ["1724"]}