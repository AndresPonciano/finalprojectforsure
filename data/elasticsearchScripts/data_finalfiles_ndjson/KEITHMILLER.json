{"title": "Random number generators: good ones are hard to find\n", "abstract": " Practical and theoretical issues are presented concerning the design, implementation, and use of a good, minimal standard random number generator that will port to virtually all systems.", "num_citations": "2027\n", "authors": ["323"]}
{"title": "Software testability: The new verification\n", "abstract": " Most verification is concerned with finding incorrect code. Instead, this view looks at the probability that the code will fail if it is faulty. The authors present the benefits of their approach, describe how to design for it, and show how to measure testability through sensitivity analysis.< >", "num_citations": "476\n", "authors": ["323"]}
{"title": "Estimating the probability of failure when testing reveals no failures\n", "abstract": " Formulas are introduced for estimating the probability of failure when testing reveals no errors. These formulas incorporate random testing results, information about the input distribution, and prior assumptions about the probability of failure of the software. The formulas are not restricted to equally-likely input distributions, and the probability of failure estimate can be adjusted when assumptions about the input distribution change. The formulas are based on a discrete sample space statistical model of software and include Bayesian prior assumptions. Reusable software and software in life-critical applications are particularly appropriate candidates for this type of analysis.", "num_citations": "416\n", "authors": ["323"]}
{"title": "Big data: New opportunities and new challenges [guest editors' introduction]\n", "abstract": " We can live with many of the uncertainties of big data for now, with the hope that its benefits will outweigh its harms, but we shouldn't blind ourselves to the possible irreversibility of changes-whether good or bad-to society. The first Web extra at http://youtu.be/24czULRCI9c is an audio recording in which Katina Michael at the University of Wollongong discusses the June 2013 Computer magazine special issue on \"Big Data: New Opportunities and New Challenges,\" introducing the special issue, the guest editors, the authors, the articles, and the IEEE Society on Social Implications of Technology (SSIT). The second Web extra at http://youtu.be/9zpFqEDydDA is an audio recording in which Katina Michael at the University of Wollongong talks about the IEEE Society on the Social Implications of Technology (SSIT), IEEE Technology and Society (T&S) magazine, and the International Symposium on Technology and\u00a0\u2026", "num_citations": "400\n", "authors": ["323"]}
{"title": "BYOD: Security and privacy considerations\n", "abstract": " Clearly, there are several important advantages for employees and employers when employees bring their own devices to work. But there are also significant concerns about security privacy. Companies and individuals involved, or thinking about getting involved with BYOD should think carefully about the risks as well as the rewards.", "num_citations": "365\n", "authors": ["323"]}
{"title": "Predicting where faults can hide from testing\n", "abstract": " Sensitivity analysis, which estimates the probability that a program location can hide a failure-causing fault, is addressed. The concept of sensitivity is discussed, and a fault/failure model that accounts for fault location is presented. Sensitivity analysis requires that every location be analyzed for three properties: the probability of execution occurring, the probability of infection occurring, and the probability of propagation occurring. One type of analysis is required to handle each part of the fault/failure model. Each of these analyses is examined, and the interpretation of the resulting three sets of probability estimates for each location is discussed. The relationship of the approach to testability is considered.< >", "num_citations": "191\n", "authors": ["323"]}
{"title": "Predicting how badly\" good\" software can behave\n", "abstract": " Using fault injection and failure-tolerance measurement with ultrarare inputs, the authors create on automated software environment that can supplement traditional testing methods. Applied to four case studies, their methods promise to make software more robust.", "num_citations": "151\n", "authors": ["323"]}
{"title": "How good is good enough? An ethical analysis of software construction and use\n", "abstract": " We borrow extensively from Rawls's Theory of/ustice [26], especially from his notion that principles of fair practice may be set by negotiations among all parties. In these negotiations, the negotiators' own iden-tities and interests are hidden from themselves behind a veil of ignorance. This veil forces negotiators to worry about the least advantaged, how fairness will be perceived, and so on. We find Rawls's treatment of justice in society at large adaptable to the issue of fairness in the software process.", "num_citations": "142\n", "authors": ["323"]}
{"title": "Software engineering code of ethics\n", "abstract": " The Board of Governors of the IEEE Computer Soci-ety established a steering committee in May 1993 for evaluating, planning, and coordinating actions related to establishing software engineering as a profession. In that same year the ACM Council endorsed the establishment of a Commission on Software Engineering. By January 1994, both societies formed a joint steering committee \u201cto establish the appropriate set (s) of standards for professional practice of software engineering upon which industrial decisions, professional certification, and educational curricula can be based.\u201d To accomplish these tasks they made the following recommendations:", "num_citations": "136\n", "authors": ["323"]}
{"title": "Semantic metrics for software testability\n", "abstract": " Software faults that infrequently affect output cause problems in most software and are dangerous in safety-critical systems. When a software fault causes frequent software failures, testing is likely to reveal the fault before the software is released; when the fault \u201chides\u201d from testing, the hidden fault can cause disaster after the software is installed. During the design of safety-critical software, we can isolate certain subfunctions of the software that tend to hide faults. A simple metric, derivable from semantic information found in software specifications, indicates software subfunctions that tend to hide faults. The metric is the domain/range ratio (DRR): the ratio of the cardinality of the possible inputs to the cardinality of the possible outputs. By isolating modules that implement a high DRR function during design, we can produce programs that are less likely to hide faults during testing. The DRR is available early in the\u00a0\u2026", "num_citations": "123\n", "authors": ["323"]}
{"title": "Software engineering code of ethics is approved\n", "abstract": " The Code includes specific language about the importance of ethical behavior during the maintenance phase of software development. The Code reflects the amount of time a computer professional spends modifying and improving existing software. It also makes clear that we need to treat maintenance with the same professionalism as new development. The quality of maintenance depends upon the professionalism of the software engineer because maintenance is more likely only to be scrutinized locally whereas new development is generally reviewed at a broader corporate level.The purpose of developing a Software Engineering Code of Ethics is to document the ethical and professional responsibilities and obligations of software engineers. This Code is intended to educate and inspire software engineers; it also informs the public about the responsibilities that are important to this profession. The Code\u00a0\u2026", "num_citations": "107\n", "authors": ["323"]}
{"title": "Computer society and ACM approve software engineering code of ethics\n", "abstract": " PURPOSEThe Software Engineering Code of Ethics and Professional Practice, intended as a standard for teaching and practicing software engineering, documents the ethical and professional obligations of software engineers. The code should instruct practitioners about the standards society expects them to meet, about what their peers strive for, and about what to expect of one another. In addition, the code should inform the public about the responsibilities that are important to the profession.Adopted by the Computer Society and the ACM\u2014two leading international computing societies\u2014the code of ethics is intended as a guide for members of the evolving software engineering profession. The code was developed by a multinational task force with additional input from other professionals from industry, government posts, military installations, and educational professions.", "num_citations": "99\n", "authors": ["323"]}
{"title": "Implementing a tenth strand in the CS curriculum\n", "abstract": " 76 December 1996/Vol. 39, No. 12 COMMUNICATIONS OF THE ACM developing an awareness of one\u2019s own strengths and limitations as well as those of the discipline itself.\u201d In Computing Curricula 1991 [1], the basis for defining the curriculum was the \u201cplatform of knowledge that is considered essential for all students who concentrate in the discipline.\u201d Nine subject areas were identified as comprising the subject matter of the discipline. They were chosen because each one had \u201ca significant theoretical base, significant abstractions, and significant design and implementation achievements\u201d[13]. In this article we suggest the extension of the basic platform of knowledge necessary in computer science to include a tenth subject area to cover the social and ethical impact of computing in a comprehensive and meaningful way. Our rationale for doing this is that now we are able to articulate the essential core of\u00a0\u2026", "num_citations": "97\n", "authors": ["323"]}
{"title": "The ethics of designing artificial agents\n", "abstract": " In their important paper \u201cAutonomous Agents\u201d, Floridi and Sanders use \u201clevels of abstraction\u201d to argue that computers are or may soon be moral agents. In this paper we use the same levels of abstraction to illuminate differences between human moral agents and computers. In their paper, Floridi and Sanders contributed definitions of autonomy, moral accountability and responsibility, but they have not explored deeply some essential questions that need to be answered by computer scientists who design artificial agents. One such question is, \u201cCan an artificial agent that changes its own programming become so autonomous that the original designer is no longer responsible for the behavior of the artificial agent?\u201d To explore this question, we distinguish between LoA1 (the user view) and LoA2 (the designer view) by exploring the concepts of unmodifiable, modifiable and fully modifiable tables that control\u00a0\u2026", "num_citations": "85\n", "authors": ["323"]}
{"title": "Why we should have seen that coming: comments on microsoft\u2019s tay \u201cexperiment,\u201d and wider implications\n", "abstract": " In this paper we examine the case of Tay, the Microsoft AI chatbot that was launched in March, 2016. After less than 24 hours, Microsoft shut down the experiment because the chatbot was generating tweets that were judged to be inappropriate since they included racist, sexist, and anti-Semitic language. We contend that the case of Tay illustrates a problem with the very nature of learning software (LS is a term that describes any software that changes its program in response to its interactions) that interacts directly with the public, and the developer\u2019s role and responsibility associated with it. We make the case that when LS interacts directly with people or indirectly via social media, the developer has additional ethical responsibilities beyond those of standard software. There is an additional burden of care.", "num_citations": "81\n", "authors": ["323"]}
{"title": "Un-making artificial moral agents\n", "abstract": " Floridi and Sanders, seminal work, \u201cOn the morality of artificial agents\u201d has catalyzed attention around the moral status of computer systems that perform tasks for humans, effectively acting as \u201cartificial agents.\u201d Floridi and Sanders argue that the class of entities considered moral agents can be expanded to include computers if we adopt the appropriate level of abstraction. In this paper we argue that the move to distinguish levels of abstraction is far from decisive on this issue. We also argue that adopting certain levels of abstraction out of context can be dangerous when the level of abstraction obscures the humans who constitute computer systems. We arrive at this critique of Floridi and Sanders by examining the debate over the moral status of computer systems using the notion of interpretive flexibility. We frame the debate as a struggle over the meaning and significance of computer systems that behave\u00a0\u2026", "num_citations": "80\n", "authors": ["323"]}
{"title": "Improving the software development process using testability research.\n", "abstract": " Software testability is the the tendency of code to reveal existing faults during random testing. This paper proposes to take software testability predictions into account throughout the development process. These predictions can be made from formal specifications, design documents, and the code itself. The insight provided by software testability is valuable during design, coding, testing, and quality assurance. We further believe that software testability analysis can play a crucial role in quantifying the likelihood that faults are not hiding after testing does not result in any failures for the current version.", "num_citations": "74\n", "authors": ["323"]}
{"title": "Paramedic ethics for computer professionals\n", "abstract": " Most computer professionals know that difficult ethical issues may arise in their work. We believe that these professionals want to \u201cdo the right thing.\u201d They accept their responsibilities as moral agents and they recognize that their special technical skills give them power and responsibilities. However, the will to act ethically is not sufficient; computer professionals also need skills to arrive at reasonable, ethical decisions. In this article we suggest a set of guidelines to help computer professionals consider the ethical dimensions of technical decisions and offer practical advice to individuals who need to make timely decisions in an ethical manner. We call our guidelines a paramedic method to suggest a medical analogy. We use our method on two realistic ethical dilemmas facing computer professionals. We gather and analyze the data and reach conclusions much as the principals in our cases might. Our paramedic\u00a0\u2026", "num_citations": "70\n", "authors": ["323"]}
{"title": "Integrating computer ethics into the computer science curriculum\n", "abstract": " The societal and technical aspects of computing are interdependent. Technical issues are best understood (and most effectively taught) in their social context, and the societal aspects of computing are best understood in the context of the underlying technical detail. By including the study of computer ethics in the computer science curriculum, educators can increase students\u2019 motivation and deepen their understanding. Using a case study approach, the value dimensions of technical issues can be naturally incorporated into existing lectures and used with existing textbooks. Specific case studies related to courses from ACM's Curriculum 78 illustrate the utility of this approach.", "num_citations": "69\n", "authors": ["323"]}
{"title": "Putting assertions in their place\n", "abstract": " Assertions that are placed at each statement in a program can automatically monitor the internal computations of a program execution. However, the advantages of universal assertions come at a cost. A program with such extensive internal instrumentation will be slower than the same program without the instrumentation. Some of the assertions may be redundant. The task of instrumenting the code with correct assertions at each location is burdensome, and there is no guarantee that the assertions themselves will be correct. We advocate a middle ground between no assertions at all (the most common practice) and the theoretical ideal of assertions at every location. Our compromise is to place assertions only at locations where traditional testing is unlikely to uncover software faults. One type of testability measurement, sensitivity analysis, identifies locations where testing is unlikely to be effective.< >", "num_citations": "60\n", "authors": ["323"]}
{"title": "Defining an adaptive software security metric from a dynamic software failure tolerance measure\n", "abstract": " This paper describes a software assessment method that is being implemented to quantitatively assess information system security and survivability. Our approach-which we call Adaptive Vulnerability Analysis-exercises software (in source-code form) by simulating incoming malicious and non-malicious attacks that fall under various threat classes. A quantitative metric is computed by determining whether the simulated threats undermine the security of the system as defined by the user according to the application program. This approach stands in contrast to common security assurance methods that rely on black-box techniques for testing completely-installed systems. AVA does not provide an absolute metric, such as mean-time-to-failure, but instead provides a relative metric, allowing a user to compare the security of different versions of the same system, or to compare non-related systems with similar functionality.", "num_citations": "59\n", "authors": ["323"]}
{"title": "Consequences of prairie wetland drainage for crustacean biodiversity and metapopulations\n", "abstract": " Much of Illinois was once wet prairie, dotted with ancient (ca. 10,000\u2010year\u2010old) ephemeral wetlands. Most wetland habitat (85%) was converted to agriculture over a span of about 100 years (ca. 1850\u20131950). The consequences of this severe habitat fragmentation on wetland communities and metapopulations are unknown. We studied crustacean communities (weekly stovepipe samples throughout hydroperiods) for 3 years in a set of extant ephemeral wetlands in Illinois. We generated species\u2010sites curves by rarefaction and extrapolated those curves to conservatively estimate that 83\u201385 crustacean species may have inhabited approximately 4 million ephemeral wetlands that once existed in Illinois; 8\u20139 crustacean species were driven to extinction in Illinois during drainage; and 75\u201376 crustacean species are extant in the few remaining ephemeral wetlands of Illinois. We also conducted cellular automata\u00a0\u2026", "num_citations": "57\n", "authors": ["323"]}
{"title": "Developing artificial agents worthy of trust:\u201cWould you buy a used car from this artificial agent?\u201d\n", "abstract": " There is a growing literature on the concept of e-trust and on the feasibility and advisability of \u201ctrusting\u201d artificial agents. In this paper we present an object-oriented model for thinking about trust in both face-to-face and digitally mediated environments. We review important recent contributions to this literature regarding e-trust in conjunction with presenting our model. We identify three important types of trust interactions and examine trust from the perspective of a software developer. Too often, the primary focus of research in this area has been on the artificial agents and the humans they may encounter after they are deployed. We contend that the humans who design, implement, and deploy the artificial agents are crucial to any discussion of e-trust and to understanding the distinctions among the concepts of trust, e-trust and face-to-face trust.", "num_citations": "54\n", "authors": ["323"]}
{"title": "The revealing power of a test case\n", "abstract": " \u2018Propagation, infection, and execution analysis\u2019 (termed PIE) is used for predicting where faults can more easily hide in software. To make such predictions, programs are dynamically executed with test cases, and information concerning the test cases is collected into a histogram, each bin of which represents a single test case. The score in a bin predicts the likelihood that the test case will reveal a fault through the production of a failure (if a fault exists in the set of program locations that the test case executes). Preliminary experiments using program mutations suggest that the histogram technique presented in this paper can rank test cases according to their fault revealing ability.", "num_citations": "53\n", "authors": ["323"]}
{"title": "Anonymity, pseudonymity, or inescapable identity on the net\n", "abstract": " The first topic of concern is anonymity, specifically the anonymity that is available in communications on the Internet. An earlier paper argues that anonymity in electronic communication is problematic because:", "num_citations": "45\n", "authors": ["323"]}
{"title": "Virtual harms and real responsibility\n", "abstract": " In traditional communities, some actions are widely regarded as bad and unethical. But in online \u201ccommunities,\u201d the virtual analog of those actions may not be regarded with the same clarity. Since \u201cvirtual\u201d behaviors are distinct from ordinary acts, they require further analysis to determine whether they are right or wrong. In this chapter we consider an incident on the Internet that illustrates this confusion. The incident centered on a virtual act of sexual violence. This \u201crape in cyberspace,\u201d reported by Julian Dibbell in 1993, has generated questions about the significance of behaviors in virtual reality environments. We use the case to explore the moral nature of actions in virtual environments, emphasizing the themes of harm and responsibility. We then offer some tentative lessons to be learned and, finally, apply the lessons to virtual sex and to first-person shooter computer games.", "num_citations": "42\n", "authors": ["323"]}
{"title": "Grading essays in computer ethics: rubrics considered helpful\n", "abstract": " Computer ethics courses differ from technical courses in the manner in which they are taught and assessed. A common assignment in a computer ethics course is to write an essay that addresses a technical dilemma. Computer science faculty typically do not have training or experience in grading essays. The purpose of this paper is to present a scoring rubric that has been successfully used to grade and track students' knowledge development as they progress through a computer ethics course. Although this paper focuses upon a specific rubric, general principles will be emphasized to show how scoring rubrics can be used across different courses.", "num_citations": "42\n", "authors": ["323"]}
{"title": "Glueing together software components: How good is your glue\n", "abstract": " We have investigated an assessment technique for studying the failure tolerance of large-scale component-based information systems. Our technique assesses the propagation of information through the interfaces between objects in order to predict how software will behave when corrupt information gets passed. Our approach is applicable to both source code and executable commercial off-the-shelf (COTS) components. The key benefit of our approach is that it can assess the failure tolerance of legacy systems composed entirely of executable software components.", "num_citations": "40\n", "authors": ["323"]}
{"title": "Agile software development: human values and culture\n", "abstract": " Software engineers need to know how to evaluate different methods of developing software. A group of new development methods have emerged under the general label \"agile development.\" These techniques are sometimes called \"light weight\" as opposed to \"heavy weight\" techniques such as those based on the waterfall model. Two classic ethical techniques - utilitarian and deontological analyses - can offer insights into the arguments surrounding, agile methods. These and other applied ethics techniques offer software engineers a more precise language for articulating their ideas about software engineering issues that involve human values.", "num_citations": "39\n", "authors": ["323"]}
{"title": "Self-driving cars and engineering ethics: The need for a system level analysis\n", "abstract": " The literature on self-driving cars and ethics continues to grow. Yet much of it focuses on ethical complexities emerging from an individual vehicle. That is an important but insufficient step towards determining how the technology will impact human lives and society more generally. What must complement ongoing discussions is a broader, system level of analysis that engages with the interactions and effects that these cars will have on one another and on the socio-technical systems in which they are embedded. To bring the conversation of self-driving cars to the system level, we make use of two traffic scenarios which highlight some of the complexities that designers, policymakers, and others should consider related to the technology. We then describe three approaches that could be used to address such complexities and their associated shortcomings. We conclude by bringing attention to the \u201cMoral\u00a0\u2026", "num_citations": "38\n", "authors": ["323"]}
{"title": "Self-driving cars: Ethical responsibilities of design engineers\n", "abstract": " In the wake of the exposure of Volkswagen's diesel engine test-rigging, a Bloomberg Business journalist described the company as \"driven by engineering-crazed executives\" [2] and The New York Times ran a story noting how with today's complex computer systems in automobiles, there are numerous opportunities for misdeeds both by automakers and hackers [3]. With the advent of so-called autonomous or self-driving cars, such issues may become even more pervasive and problematic. From a legal perspective, a key focal point is who would be at fault if and when an accident occurs [4]. Much also has been written about the ethical complexities posed by self-driving cars [5]-[6]. In accordance with Moore's Law, \"[a]s technological revolutions increase their social impact, ethical problems increase\" [7]. Yet relatively little has been said about the ethical responsibilities of the designers of self-driving cars.", "num_citations": "38\n", "authors": ["323"]}
{"title": "Is diversity in computing a moral matter?\n", "abstract": " Women and some minorities are under-represented in academic computer science and in professional computing more generally. Evidence for this assertion appears elsewhere (eg,[2]), and we won't go into the details here. Instead, we focus on the underlying moral issue: Is there anything wrong (immoral, unfair) with so few women and minorities studying or working in computing? First we clear away two distractions. Most of the data about this issue focus on the US, partly because of the special importance of equality and equal opportunity in American democracy. This paper also focuses on the US Nevertheless, the arguments here can apply to many other countries (see [4, 6] in this special issue). Second, our analysis focuses on women in computing, not under-represented minorities. The circumstances of women and minorities are in general quite different. In computing, some minorities appear to be over\u00a0\u2026", "num_citations": "38\n", "authors": ["323"]}
{"title": "Tolerant software interfaces: can COTS-based systems be trusted without them?\n", "abstract": " We have investigated an assessment technique for studying the failure-tolerance of large-scale component-based information systems. Our technique assesses the tolerance of the interfaces between component objects in order to predict how the software will behave if anomalous failures exit certain components and enter others. (Note that we are not talking about graphical user interfaces, but rather the mechanisms that link software components together.) These failures can originate from incorrect code, bad input data from a failed hardware devices. or bad input data from human operators. Our approach is applicable to systems for which source code is available, as well as systems for which no source code is known (e.g., systems composed from executable Commercial Off-The-Shelf (COTS) components), and addresses several of the larger problems associated with software maintenance.", "num_citations": "37\n", "authors": ["323"]}
{"title": "Developing automated deceptions and the impact on trust\n", "abstract": " As software developers design artificial agents (AAs), they often have to wrestle with complex issues, issues that have philosophical and ethical importance. This paper addresses two key questions at the intersection of philosophy and technology: What is deception? And when is it permissible for the developer of a computer artifact to be deceptive in the artifact\u2019s development? While exploring these questions from the perspective of a software developer, we examine the relationship of deception and trust. Are developers using deception to gain our trust? Is trust generated through technological \u201cenchantment\u201d warranted? Next, we investigate more complex questions of how deception that involves AAs differs from deception that only involves humans. Finally, we analyze the role and responsibility of developers in trust situations that involve both humans and AAs.", "num_citations": "36\n", "authors": ["323"]}
{"title": "The Internet of Things: a reality check\n", "abstract": " Today, a new Internet player is rowing more important: things-that is, inanimate objects that can be programmed to communicate, sense, and interact with other things. But will an increasingly fragile ecosystem be able to sustain the amount of power necessary to run all these gadgets? And what other challenges must we overcome to realize a productive and reliable Internet of Things?", "num_citations": "33\n", "authors": ["323"]}
{"title": "Free and open source software\n", "abstract": " In this paper, free and open source software are discussed. Open source is an intellectual property destroyer. Nothing could be worse than this for the software business and the intellectual-property business. Microsoft has an official open source presence on the Web (www.microsoft.com/opensource), and in July 2010, Jean Paoli, the General Manager for Interoperability Strategy at Microsoft, delivered a keynote address at the O'Reilly Open Source Convention.", "num_citations": "32\n", "authors": ["323"]}
{"title": "Ethical issues in open source software\n", "abstract": " In this essay we argue that the current social and ethical structure in the Open Source Software (OSS) Community stem from its roots in academia. The individual developers experience a level of autonomy similar to that of a faculty member. Furthermore, we assert that the Open Source Software Community\u2019s social structure demands benevolent leadership. We argue that it is difficult to pass off low quality open source software as high quality software and that the Open Source development model offers strong accountability. Finally, we argue that Open Source Software introduces ethical challenges for universities and the software development community.", "num_citations": "29\n", "authors": ["323"]}
{"title": "It's not nice to fool humans\n", "abstract": " This paper is about the computer that pool people into thinking they're interacting with human. Because IT professional will be the people who design, develop, and deploy these computers, it seems sensible to explore the ethical ramifications of such machines in IT professional.", "num_citations": "28\n", "authors": ["323"]}
{"title": "The public is the priority: Making decisions using the software engineering code of ethics\n", "abstract": " The Software Engineering Code of Ethics and Professional Practice encourages software engineers to undertake positive actions and to resist pressures to act unethically.", "num_citations": "27\n", "authors": ["323"]}
{"title": "Moral Responsibility for Computing Artifacts:\" The Rules\"\n", "abstract": " At a workshop in March 2010, an interdisciplinary group of philosophers, computer scientists, practitioners, and lawyers started to develop a short statement about the ethics of developing computer systems. The statement has grown into an evolving document about moral responsibility. It's not a Wiki, but 50 people, including academics and IT professionals, have already helped write it. An early working title was \"Principles Governing Moral Responsibility for Computing Artifacts,\" but most of the time, it's just called \"The Rules.\"", "num_citations": "26\n", "authors": ["323"]}
{"title": "Open source software: intellectual challenges to the status quo\n", "abstract": " Open source software is making a large impact on many aspects of society including the business community, the computing industry, the entertainment industry and higher education. The computer science education community has been quiet about issues of open source versus closed source and the role of open source code in the advancement of information technology. A survey of recent issues of SIGCSE Bulletin and SIGCSE conference proceedings shows little attention to the role open source software should play in computer science education. We are here to raise the question: \"What are the social and ethical responsibilities of computer science faculty regarding open source software?\"One set of issues concerns the use of open source software in teaching and the use of open source development models in the teaching of software development. Some basic questions that arise include \"Should analysis of\u00a0\u2026", "num_citations": "26\n", "authors": ["323"]}
{"title": "An ethical analysis of automation, risk, and the financial crises of 2008\n", "abstract": " History demonstrates that hysteria is optional only in a bear market because the market always recovers given enough time. With people's life savings at stake, however, the influence of panic can't be brushed aside. Market conditions in 2008 are unique in that they're far more volatile and seem to inspire the greatest fear factor in the history of the modern market. Moreover, because of extensive global networking and border-transcending fiscal interdependence, initial fluctuations in a single market resonate almost simultaneously world wide.", "num_citations": "25\n", "authors": ["323"]}
{"title": "Confidently assessing a zero probability of software failure\n", "abstract": " Randomly generated software tests are an established method of estimating software reliability [5, 7]. But as software applications require higher and higher reliabilities, practical difficulties with random testing have become increasingly problematic. These practical problems are particularly acute in life-critical applications, where requirements of 10\u22127 failures per hour of system reliability translate into a probability of failure (pof) of perhaps 10\u22129 or less for each individual execution of the software [4]. We refer to software with reliability requirements of this magnitude as ultra-reliable software.             This paper presents a method for assessing the confidence that the software does not contain any faults given that software testing and software testability analysis have been performed. In this method, it is assumed that software testing of the current version has not resulted in any failures, and that software testing\u00a0\u2026", "num_citations": "25\n", "authors": ["323"]}
{"title": "The Boeing 737 MAX: Lessons for engineering ethics\n", "abstract": " The crash of two 737 MAX passenger aircraft in late 2018 and early 2019, and subsequent grounding of the entire fleet of 737 MAX jets, turned a global spotlight on Boeing\u2019s practices and culture. Explanations for the crashes include: design flaws within the MAX\u2019s new flight control software system designed to prevent stalls; internal pressure to keep pace with Boeing\u2019s chief competitor, Airbus; Boeing\u2019s lack of transparency about the new software; and the lack of adequate monitoring of Boeing by the FAA, especially during the certification of the MAX and following the first crash. While these and other factors have been the subject of numerous government reports and investigative journalism articles, little to date has been written on the ethical significance of the accidents, in particular the ethical responsibilities of the engineers at Boeing and the FAA involved in designing and certifying the MAX. Lessons\u00a0\u2026", "num_citations": "24\n", "authors": ["323"]}
{"title": "In trust we trust\n", "abstract": " A variation of a well-known logic problem goes like this: You\u2019re traveling to Happytown when you arrive at a fork in the road at which identical twin brothers man a tollbooth. You have been told that one brother is a complete liar, and the other is completely honest. But because the brothers are identical, you don\u2019t know which one to trust. You also know that you can only pose one question to either of the brothers, and you have no opportunity to test the veracity of a brother\u2019s answer a priori. To take the correct branch of the fork, what question should you ask and to which brother should you pose it? The answer is: You ask either brother \u201cwhich branch would your brother tell me to take to reach Happy-town?\u201d You then take the branch opposite the one given in the answer. The solution to this problem is a relatively simple one logically, but the problem becomes much more difficult to solve if you alter the trust conditions. For example, what if either brother is apt to tell the truth only part of the time? To consider this problem of trust in the context of cloud computing, we must first understand the nature of trust. If we reach back far enough, the word \u201ctrust\u201d is associated with \u201ctrue\u201d(www. merriam-webster. com/netdict/trust). That connection makes sense to us today, but a modern understanding of trust also includes an element of risk. If you know something has happened, then you don\u2019t need to trust someone else\u2019s testimony. For whatever reasons, trust requires us to take a bit of a flier. Trust is less confident than know, but also more confident than hope. Trust is one of a few English words that is both a verb and a noun. We give trust to someone by trusting them\u00a0\u2026", "num_citations": "23\n", "authors": ["323"]}
{"title": "Predicting software's minimum-time-to-hazard and mean-time-to-hazard for rare input events\n", "abstract": " The paper turns the concept of input distributions on its head to exploit inverse input distributions. Although such distributions are not always true mathematical inverses, they do capture an intuitive property: inputs that have high frequencies in the original distribution will have low frequencies in the inverse distribution, and vice versa. We can use the inverse distribution in several different quality checks during development. We provide a fault based (fault injection) method to determine minimum time to failure and mean time to failure for software systems under normal operational and non normal operational conditions (meaning rare but legal events). In our calculations, we consider how various programmer faults, design errors, and incoming hardware failures are expected to impact the observability of the software system.", "num_citations": "22\n", "authors": ["323"]}
{"title": "On the meaning of free software\n", "abstract": " To many who develop and use free software, the GNU General Public License represents an embodiment of the meaning of free software. In this paper we examine the definition and meaning of free software in the context of three events surrounding the GNU General Public License. We use a case involving the GPU software project to establish the importance of Freedom 0 in the meaning of free software. We analyze version 3 of the GNU General Public License and conclude that although a credible case can be made that the added restrictions are consistent with the definition of free software, the case requires subtle arguments. Strong arguments against the added restrictions are less subtle, and may therefore be more convincing to many users and developers. We also analyze the Affero General Public License and conclude that it is inconsistent with the definition of free software.", "num_citations": "21\n", "authors": ["323"]}
{"title": "PISCES: A tool for predicting software testability\n", "abstract": " Before a program can fail, a software fault must be executed, that execution must alter the data state, and the incorrect data state must propagate to a state that results directly in an incorrect output. This paper describes a tool called PISCES (developed by Reliable Software Technologies Corporation) for predicting the probability that faults in a particular program location will accomplish all three of these steps causing program failure. PISCES is a tool that is used during software verification and validation to predict a program's testability.", "num_citations": "21\n", "authors": ["323"]}
{"title": "Acm code of ethics and professional conduct\n", "abstract": " Computing professionals' actions change the world. To act responsibly, they should reflect upon the wider impacts of their work, consistently supporting the public good. The ACM Code of Ethics and Professional Conduct (\"the Code\") expresses the conscience of the profession.  The Code is designed to inspire and guide the ethical conduct of all computing professionals, including current and aspiring practitioners, instructors, students, influencers, and anyone who uses computing technology in an impactful way. Additionally, the Code serves as a basis for remediation when violations occur. The Code includes principles formulated as statements of responsibility, based on the understanding that the public good is always the primary consideration. Each principle is supplemented by guidelines, which provide explanations to assist computing professionals in understanding and applying the principle.", "num_citations": "20\n", "authors": ["323"]}
{"title": "Software engineering code of ethics and professional practice\n", "abstract": " The Software Engineering Code of Ethics and Professional Practice, intended as a standard for teaching and practicing software engineering, documents the ethical and professional obligations of software engineers. The code should instruct practitioners about the standards society expects them to meet, about what their peers strive for, and about what to expect of one another. In addition, the code should also inform the public about the responsibilities that are important to the profession. Adopted in 2000 by the IEEE Computer Society and the ACM-two leading international computing societies-the code of ethics is intended as a guide for members of the evolving software engineering profession. The code was developed by a multinational task force with additional input from other professionals from industry, government posts, military installations, and educational professions.", "num_citations": "20\n", "authors": ["323"]}
{"title": "Using fault injection to assess software engineering standards\n", "abstract": " Standards for quality software are increasingly important, especially for critical systems. Development standards and practices must be subjected to quantitative analyses; it is no longer adequate to encourage practices because they \"make sense\" or \"seem reasonable.\" Process improvement must be demonstrated by a history of improved products. Fault-injection methods can be used to assess the quality of software itself and to demonstrate the effectiveness of software processes. Fault-injection techniques can help developers move beyond the practical limitations of testing. Fault-injection techniques focus on software behavior, not structure; process-oriented techniques cannot measure behavior as precisely. Fault-injection methods are dynamic, empirical, and tractable; as such, they belie the notion that measuring the reliability of critical software is futile. Before focusing too narrowly on the assessment of\u00a0\u2026", "num_citations": "20\n", "authors": ["323"]}
{"title": "This \u201cethical trap\u201d is for roboticists, not robots: on the issue of artificial agent ethical decision-making\n", "abstract": " In this paper we address the question of when a researcher is justified in describing his or her artificial agent as demonstrating ethical decision-making. The paper is motivated by the amount of research being done that attempts to imbue artificial agents with expertise in ethical decision-making. It seems clear that computing systems make decisions, in that they make choices between different options; and there is scholarship in philosophy that addresses the distinction between ethical decision-making and general decision-making. Essentially, the qualitative difference between ethical decisions and general decisions is that ethical decisions must be part of the process of developing ethical expertise within an agent. We use this distinction in examining publicity surrounding a particular experiment in which a simulated robot attempted to safeguard simulated humans from falling into a hole. We conclude that\u00a0\u2026", "num_citations": "18\n", "authors": ["323"]}
{"title": "Ethics and the Cloud\n", "abstract": " Cloud computing is an idea that's rapidly evolving. Still, the amount of money and attention devoted to this topic makes it seems sensible to discuss how ethicists view the kinds of changes in computing that are being called \"the cloud.\" This department is part of a special issue on cloud computing.", "num_citations": "18\n", "authors": ["323"]}
{"title": "Plagiarism and scholarly publications: An ethical analysis\n", "abstract": " All professional organizations that have a publication component should have a strongly articulated position against plagiarism. Such a position has a solid foundation in common understandings of ethical principles including the encouragement of honesty and the discouragement of stealing. Having a strong, ethical position against plagiarism is different from the implementation of a strong, enforceable policy against plagiarism. This paper examines some practical challenges to enforcement policies, including legal liability. These challenges may complicate the development of a broad, enforceable policy against plagiarism that includes sanctions against authors found to be plagiarists. Additionally, such sanctions are needed to deter authors from submitting plagiarized works. One important aspect of discouraging plagiarism is a better use of computer applications that detect copying. Authors can use these\u00a0\u2026", "num_citations": "17\n", "authors": ["323"]}
{"title": "Designing programs that are less likely to hide faults\n", "abstract": " An important motivation for software testing is to increase confidence that the software no longer contains faults. In this paper we explain a technique for using fewer tests to gain an equivalent confidence in software. Our techniques complement random black-box testing. To be able to use fewer tests and gain equivalent confidence, we must either 1.1) isolate and remove software characteristics that discourage software from revealing faults during testing, or2.2) find a method of selecting tests that have a greater ability to reveal the existence of any existing faults. The first of these two alternatives is the subject of this article. We present a conjecture concerning \u201ctestability,\u201d a software characteristic that frequently increases the likelihood that faults are detected during random black-box testing. We propose design measures to increases testability.", "num_citations": "17\n", "authors": ["323"]}
{"title": "A dialogue on responsibility, moral agency, and IT systems\n", "abstract": " The dialogue that follows was written to express some of our ideas and remaining questions about IT systems, moral agency, and responsibility. We seem to have made some progress on some these issues, but we haven't come to anything close to agreement on several important points. While the issues are becoming more clearly drawn, what we have discovered so far is closer to a web of connecting ideas, than to formal claims or final conclusions.", "num_citations": "16\n", "authors": ["323"]}
{"title": "A comparison of a dynamic software testability metric to static cyclomatic complexity\n", "abstract": " A comparison of a dynamic software testability metric to static cyclomatic complexity JM Voas, KW Miller & JE Payne Reliable Software Technologies Corporation, 11150 ABSTRACT This paper compares the dynamic testability prediction technique termed\" sensitivity analysis\" to the static testability technique termed cyclomatic complexity. The appli-cation that we chose in this empirical study is a CASE generated version of a B-737 autoland and yawdamp systems. For the B-737 systems we analyzed, we isolated those functions that we predict are more prone to hide errors during system/reliability test-ing. We also analyzed the code with several other well-known static metrics. This paper compares and contrasts the results of sensitivity analysis to the results of the static metrics. INTRODUCTION The adage that non-exhaustive software testing cannot reveal the absence of errors and only their existence is as true today as it was when Dijkstra wrote it [4, 1]. Unfortunately,", "num_citations": "15\n", "authors": ["323"]}
{"title": "Ethics and professional responsibility in computing\n", "abstract": " Computing professionals have ethical obligations to clients, employers, other professionals, and the public in fulfilling their professional responsibilities. These obligations are expressed in codes of ethics, which can be used to make decisions about ethical problems.", "num_citations": "14\n", "authors": ["323"]}
{"title": "Web standards: Why so many stray from the narrow path\n", "abstract": " 478 Science and Engineering Ethics, Volume 11, Issue 3, 2005 whose standards-compliant technology does not support these new features. The infamous \u201cbrowser wars\u201d 4 are an example of how new proprietary features in Web browsers led to confusion among content developers and those trying to access that content. Web users from a few years ago remember all too well the ubiquitous disclaimers that began with \u201cThis site best viewed with\u2026\u201d Today, most web browsers maintain at least some common functionality, but these battles are not completely over. Whitbeck highlights developers\u2019 responsibility to test sites with a \u201crange of browsers.\u201d 1 Different browsers respond in different ways to certain aspects of Web content, especially when the content diverges (perhaps accidentally) from Web standards. When choosing which browsers and versions to test\u2013and there are too many to test them all\u2013it is sensible to\u00a0\u2026", "num_citations": "14\n", "authors": ["323"]}
{"title": "Making a positive impact: updating the ACM code of ethics\n", "abstract": " 8 COMMUNICATIONS OF THE ACM| DECEMBER 2016| VOL. 59| NO. 12 acm code of ethics and professional conduct the resources needed to execute them. Now computing is ubiquitous\u2014controlling our transportation and communication, and facilitating many human interactions. Computing today is in our bodies\u2014prosthetics, pacemakers, and insulin pumps. Computing is also integral to the ways in which societies wage war. Computers impact all areas of our lives and many lifepreserving functions are relegated to a piece of computer guided machinery. Many of the newest impacts of computing are invisible. Computers make decisions about who is audited, who gets a heart transplant, and who gets targeted by dangerous devices, be they cars or missiles. The changes in technology and the kinds and number of impacted stakeholders are changing society in fundamental ways. Social and technical changes\u00a0\u2026", "num_citations": "13\n", "authors": ["323"]}
{"title": "Characterizing the need for graduate ethics education\n", "abstract": " We report on some initial findings of an investigation into current practices in, and the need for, information/computer ethics curricula at the graduate level. We give some results and analysis from a survey of faculty and graduate students at four diverse US institutions. Faculty and students agree that students will face professional ethical challenges after graduation, but assessment of students' preparedness for these challenges differs widely across the surveyed institutions. A clear majority of faculty and students expressed support for an elective graduate-level ethics course, and roughly half supported a required graduate-level ethics course.", "num_citations": "13\n", "authors": ["323"]}
{"title": "Mobile-app addiction: Threat to security?\n", "abstract": " Giving individuals this kind of information processing power, along with unprecedented connectivity, might be the single most impressive technical achievement of the 21st century. Nobody knows what the full impact of this transformation will be, but it's clear that our embrace of, and reliance on, cheap and easily accessible information presents unprecedented security implications - the enormity of which we have yet to grasp.", "num_citations": "13\n", "authors": ["323"]}
{"title": "Ethical analysis in the cloud\n", "abstract": " People have been studying and practicing applied ethics for thousands of years. It seems sensible to exploit that work, particularly ideas that have gained importance over time. Here, I present three important ideas from applied ethics both to illustrate the use of applied ethics methods and to provoke some thinking among IT professionals about the ethical implications of cloud computing.", "num_citations": "13\n", "authors": ["323"]}
{"title": "Software certification services: Encouraging trust and reasonable expectations\n", "abstract": " This paper proposes a more general acceptance of software certification that comprises two steps: first, it should certify the environment in which the software will execute, second, it should certify the software in the context of that environment. With the proposed certification, more complex single systems can be replaced with multiple simpler systems with increased reliability. A simpler system with a single party responsible for repair is far more likely to be fixed or replaced in a manageable time frame", "num_citations": "13\n", "authors": ["323"]}
{"title": "Computer ethics in the undergraduate curriculum: Case studies and the joint software engineer's code\n", "abstract": " This paper illustrates how to use the Software Engineering Code of Ethics and Professional Practice [1, 2] in three case studies suitable for computer science instruction. This code of ethics was approved by both the Association of Computing Machinery (ACM) and the IEEE Computer Society in 1998. Since then, the code has been translated into seven more languages, and adopted by organizations in many countries.The paper argues that instruction in ethics is vital in computer science education, and that case studies featuring the Software Engineer's Code can be an effective method for that instruction. The three cases all focus on realistic situations in which a software engineer must make choices that involve technical and ethical judgments. For each case, the paper identifies relevant sections of the Code, and analyzes the case study using ideas from those sections.", "num_citations": "13\n", "authors": ["323"]}
{"title": "Test driven development on the cheap: text files and explicit scaffolding\n", "abstract": " Test driven development (also known as test-first development) is a technique associated with Extreme Programming and Agile Programming methods.[1] Most advocates of test driven development use automated testing tools to facilitate bookkeeping and to encourage frequent and thorough regression testing throughout development. These tools (such as JUnit, NUnit, and XUnit) are increasingly popular, and deservedly so. However, in this paper, we suggest a simplified approach that may sometimes be preferable when introducing the idea of test driven programming: using a textfile and a straightforward testing harness. This technique will probably be of limited use to experienced test driven developers, but novices (both students and faculty) may find it a simpler way to understand how test-driven development works without having to install and learn an automated testing system.", "num_citations": "13\n", "authors": ["323"]}
{"title": "Software informed consent: docete emptorem, not caveat emptor\n", "abstract": " Should software be sold \u201cas is\u201d, totally guaranteed, or something else? This paper suggests that \u201cinformed consent\u201d, used extensively in medical ethics, is an appropriate way to envision the buyer/developer relationship when software is sold. We review why the technical difficulties preclude delivering perfect software, but allow statistical predictions about reliability. Then we borrow principles refined by medical ethics and apply them to computer professionals.", "num_citations": "13\n", "authors": ["323"]}
{"title": "Adding data abstraction to Fortran software\n", "abstract": " The Fortran Abstract Data (FAD) system was designed to facilitate the structured reuse of Fortran-callable software. FAD uses data abstraction to implement information hiding. It lets the implementer of a data type explicitly control how instances of that type are used, while itself utilizing Fortran's separate compilation and the vast collection of available Fortran libraries. The principle and methods of information hiding are discussed. The use of FAD, which is designed for situations where the user of an abstract data type is distinct from the implementer of the abstract data type, is described. Some related work is examined.< >", "num_citations": "13\n", "authors": ["323"]}
{"title": "Ethical considerations\n", "abstract": " For the foreseeable future, teachers will increasingly use computers and telecommunications as part of their classes. How can we use these tools wisely? This chapter examines that question from an ethical perspective, touching on pedagogical, legal, and philosophical issues. The best teaching involves us on a personal level; how can we encourage a human touch in electronic teaching? We focus on five specific issues: student privacy, student and teacher authentication, intellectual property concerns, teacher accountability, and the human touch in teaching.", "num_citations": "12\n", "authors": ["323"]}
{"title": "Examining fault-tolerance using unlikely inputs: turning the test distribution up-side down\n", "abstract": " This paper turns the concept of input distributions on its head to exploit \"inverse input distributions\". Although such distributions are not true mathematical inverse functions, they capture the intuitive property of members that have high frequencies in the original distribution have low frequencies in the \"inverse\" distribution, and vice versa. These new distributions have uses in testing for reliability estimates, and more importantly, fault-tolerance analysis.", "num_citations": "12\n", "authors": ["323"]}
{"title": "Vibrational\u2013vibrational coupling in air at low humidities\n", "abstract": " Calculations of sound absorption in air are traditionally based on the assumption that molecular relaxations in nitrogen and oxygen are independent. In binary mixtures of these two gases, however, they are not independent; rather, molecular relaxation is known to be controlled by a very strong vibrational\u2013vibrational (V\u2013V) coupling, which influences both the relaxation frequencies and the relaxation strengths. This article shows that small concentrations of the air constituents carbon dioxide and water vapor, which themselves possess a strong V\u2013V coupling to N2 and O2, serve to decouple the N2 and O2 relaxations. To characterize the N2\u2013O2 coupling a \u2018\u2018coupling strength\u2019\u2019 is derived, which depends upon the constituent concentrations and the related reaction rate constants. It is found that the molecular relaxations associated with N2 and O2 in air experience a gradual transition from strong to weak coupling as the\u00a0\u2026", "num_citations": "12\n", "authors": ["323"]}
{"title": "There\u2019s something in your eye: Ethical implications of augmented visual field devices\n", "abstract": " PurposeThis paper aims to explore the ethical and social impact of augmented visual field devices (AVFDs), identifying issues that AVFDs share with existing devices and suggesting new ethical and social issues that arise with the adoption of AVFDs.", "num_citations": "11\n", "authors": ["323"]}
{"title": "Behind the mask: Machine morality\n", "abstract": " We consider machines that have the ability to masquerade as human in the context of Floridi's information ethics and artificial evil. We analyse a variety of different robots and contexts and the ethical implications for the development of such robots. We demonstrate numerous concerns that arise due to the ambiguity introduced by masquerading machines, suggesting a need for careful consideration regarding the development of masquerading robots.", "num_citations": "11\n", "authors": ["323"]}
{"title": "Artificial agents, cloud computing, and quantum computing: Applying Floridi\u2019s method of levels of abstraction\n", "abstract": " In his paper \u201cOn the Intrinsic Value of Information Objects and the Infosphere,\u201d Luciano Floridi asserts that the goal of Information Ethics (IE) \u201cis to fill an \u2018ethical vacuum\u2019 brought to light by the ICT revolution, to paraphrase Moor\u201d (1985). He claims \u201cIE will prove its value only if its applications bear fruit. This is the work that needs to be done in the near future\u201d (Floridi 2002). Our chapter proposes to do part of that work. Initially we focus on Floridi\u2019s Method of Levels of Abstraction (LoA). We begin by examining his methodology as it was first developed with J. W. Sanders in \u201cThe Method of Abstraction\u201d (Floridi and Sanders 2004) and expanded in \u201cThe Method of Levels of Abstraction\u201d (Floridi 2008a, b). Then we will demonstrate the general applicability and ethical utility of the method of levels of abstraction by considering three different computational paradigms: artificial agents, cloud computing, and quantum\u00a0\u2026", "num_citations": "10\n", "authors": ["323"]}
{"title": "Software engineering code of ethics, version 3.0\n", "abstract": " In May of 1993, the Board of Governors of the IEEE-CS established a steering committee for evaluating, planning, and coordinating actions related to establishing software engineering as a profession. In that same year the ACM Council endorsed the establishment of a Commission on Software Engineering. By January of 1994, both societies formed a joint steering committee\" To establish the appropriate set (s) of standards for professional practice of Software Engineering upon which industrial decisions, professional certification, and educational curricula can be based.\" To accomplish these tasks they made the following recommendations:", "num_citations": "10\n", "authors": ["323"]}
{"title": "Curriculum guidelines for teaching the consequences of computing\n", "abstract": " ImpaetCS, which was initiated to define the core content and pedagogical objectives for integrating social impact and ethics into the computer science curriculum. Over a three year period the project will address three major problems that hamper the implementation of across-the-board curricular change: the lack of a well-specified definition of what the core content and learning objectives should include, the lack of a strategy for adapting and adopting existing materials that address the core topics into the existing CS curriculum, and the lack of awareness and expertise on the part of most CS faculty regarding the need and methodology for presenting such material in their courses. This report provides the conceptual framework and describes the learning objectives, called knowledge units, for defining a new content area in the computer science curriculum. It also discusses strategies and innovative pedagogical\u00a0\u2026", "num_citations": "10\n", "authors": ["323"]}
{"title": "Comparison of algorithms for computing the two-dimensional discrete Hartley transform\n", "abstract": " Three methods have been described for computing the two-dimensional, discrete Hartley transform. Two of these employ a separable transform; the third method, the vector-radix algorithm, does not require separability. In-place computation of the vector-radix method is described. Operation counts and execution times indicate that the vector-radix method is fastest.", "num_citations": "10\n", "authors": ["323"]}
{"title": "Information systems ethics\u2013challenges and opportunities\n", "abstract": " PurposeThe purpose of this paper is to explore the ethical issues surrounding information systems (IS) practice with a view to encouraging greater involvement in this aspect of IS research. Information integrity relies upon the development and operation of computer-based information systems. Those who undertake the planning, development and operation of these information systems have obligations to assure information integrity and overall to contribute to the public good. This ethical dimension of information systems has attracted mixed attention in the IS academic discipline.Design/methodology/approachThe authors are a multidisciplinary team providing a rich, diverse experience which includes professional and information ethics, management information systems, software engineering, data repositories and information systems development. Each author has used this experience to review the IS ethics\u00a0\u2026", "num_citations": "9\n", "authors": ["323"]}
{"title": "Augmented reality all around us: Power and perception at a crossroads\n", "abstract": " In this paper we continue to explore the ethics and social impact of augmented visual field devices (AVFDs). Recently, Microsoft announced the pending release of HoloLens, and Magic Leap filed a patent application for technology that will project light directly onto the wearer's retina. Here we explore the notion of deception in relation to the impact these devices have on developers, users, and non-users as they interact via these devices. These sorts of interactions raise questions regarding autonomy and suggest a strong need for informed consent protocols. We identify issues of ownership that arise due to the blending of physical and virtual space and important ways that these devices impact trust. Finally, we explore how these devices impact individual identity and thus raise the question of ownership of the space between an object and someone's eyes. We conclude that developers ought to take time to design\u00a0\u2026", "num_citations": "9\n", "authors": ["323"]}
{"title": "Information integrity and IT professionals' integrity, intertwined\n", "abstract": " When a consumer accesses information, the consumer wants to trust that information. As computer professionals, our reputation with the public depends in large part on how the public perceives the information we deliver-if the public trusts the information, the public trusts us. This article focus on three threats to information integrity that map directly to three characteristics of information-processing professionals: incompetence, conflicts of interest, and a lack of transparency. In each case, characteristics of both individuals and the profession as a whole interact to undermine information integrity. The article concludes with strategies for improving information integrity by focusing on these three problems.", "num_citations": "9\n", "authors": ["323"]}
{"title": "Angels and artifacts: Moral agents in the age of computers and networks\n", "abstract": " Traditionally, philosophers have ascribed moral agency almost exclusively to humans (Eshleman, 2004). Early writing about moral agency can be traced to Aristotle (Louden, 1989) and Aquinas (1997). In addition to human moral agents, Aristotle discussed the possibility of moral agency of the Greek gods and Aquinas discussed the possibility of moral agency of angels. In the case of angels, a difficulty in ascribing moral agency was that it was suspected that angels did not have enough independence from God to ascribe to the angels genuine moral choices. Recently, new candidateshave been suggested for non\u2010human moral agency. Floridi and Sanders (2004) suggest that artificially intelligence (AI)programs that meet certain criteria may attain the status of moral agents; they suggest a redefinition of moral agency to clarify the relationship between artificial and human agents. Other philosophers, as well as\u00a0\u2026", "num_citations": "9\n", "authors": ["323"]}
{"title": "A modest proposal for software testing\n", "abstract": " Miller suggests a modest improvement to one aspect vital to the maturing of software engineering: better software testing. He believes that a minimal standard should be established for testing commercial software.", "num_citations": "9\n", "authors": ["323"]}
{"title": "Teaching computer ethics using the World Wide Web\n", "abstract": " Teaching computer ethics is challenging in any setting. An online, asynchronous course on computer ethics has unique strengths and weaknesses compared to a face-to-face classroom course. This paper describes several ways to exploit the strengths of asynchronous pedagogy when teaching computer ethics, and suggests ways to deemphasize the weaknesses. Anecdotes are given from the authors experience in teaching computer ethics online to computer science majors.", "num_citations": "9\n", "authors": ["323"]}
{"title": "A framework for implementing and teaching the social and ethical impact of computing\n", "abstract": " This article describes the work of Project ImpactCS, which was initiated to define the core content and pedagogical objectives for integrating social impact and ethics into the computer science (CS) curriculum. Over a three year period the project will address three major problems that hamper the implementation of across-the-board curriculum change: the lack of a well-specified definition of what the core content and learning objectives should include, the lack of a strategy for adapting and adopting existing materials that address the core topics into the existing CS curriculum, and the lack of awareness and expertise on the part of most CS faculties regarding the need and methodology for presenting such material in their courses. This report provides the conceptual frame-work and describes the learning objectives, called knowledge units, for defining a new content area in the computer science curriculum. It\u00a0\u2026", "num_citations": "9\n", "authors": ["323"]}
{"title": "Applying a dynamic testability technique to debugging certain classes of software faults\n", "abstract": " Testability, the tendency for software to reveal its faults during testing, is an important issue for verification and quality assurance. But testability can also be used to good advantage as a debugging technique. Although this concept is more general, we will illustrate it with a specific example: propagation analysis.               Propagation Analysis (PA) is a technique for predicting the probability that a data state error affects program output. PA is a technique that produces information about a piece of software's testability. PA bases its prediction on empirical measurement of the probability that an \u2018artificial\u2019 data state error affects program output. After obtaining propagation analysis information for a program and obtaining a failure probability estimate for the program during execution we build a model that can be used to identify possible sites of missing-assignment faults of the form x \u2254 f(x). Thus we can apply the\u00a0\u2026", "num_citations": "9\n", "authors": ["323"]}
{"title": "Listening to professional voices: draft 2 of the ACM code of ethics and professional conduct\n", "abstract": " 106 COMMUNICATIONS OF THE ACM| MAY 2017| VOL. 60| NO. 5 acm code of ethics and professional conduct ence of computing since 1992. Principle 1.1 has been modified to make this change (that almost all people are now impacted by computing) explicit by adding to the principle \u201cacknowledging that all people are stakeholders in computing and its artifacts.\u201d The phrase \u201ccomputing and its artifacts\u201d is meant to remind practitioners that it is not just the code that they write that matters, but also those things that emerge from that code. In particular, the Task Force is addressing growing concerns about algorithms that emerge from machine learning rather than directly from algorithm designers. Consistent with the importance of computing and the ways it can contribute to society, we added an encouragement to perform pro bono or volunteer work. Like other professions, computing is a service to society. Following\u00a0\u2026", "num_citations": "8\n", "authors": ["323"]}
{"title": "Moral responsibility for computing artifacts: \" the rules\" and issues of trust\n", "abstract": " \"The Rules\" are found in a collaborative document (started in March 2010) that states principles for responsibility when a computer artifact is designed, developed and deployed into a sociotechnical system. At this writing, over 50 people from nine countries have signed onto The Rules (Ad Hoc Committee, 2010). Unlike codes of ethics, The Rules are not tied to any organization, and computer users as well as computing professionals are invited to sign onto The Rules. The emphasis in The Rules is that both users and professionals have responsibilities in the production and use of computing artifacts. In this paper, we use The Rules to examine issues of trust.", "num_citations": "8\n", "authors": ["323"]}
{"title": "Who owns what? The social media quagmire\n", "abstract": " The assumption that participating in social media means abandoning privacy and security is an example of a somewhat false dichotomy \"no security and privacy\" on the one hand and \"no information sharing\" on the other. In reality, social media presents an opportunity to share information in many ways, including being selective about with whom that information is shared. This department is part of a special issue on social computing.", "num_citations": "8\n", "authors": ["323"]}
{"title": "Free, Source-Code-Available, or Proprietary: An ethically charged, context-sensitive choice\n", "abstract": " We demonstrate that different categories of software raise different ethical concerns with respect to whether software ought to be Free Software or Proprietary Software. We outline the ethical tension between Free Software and Proprietary Software that stems from the two kinds of licenses. For some categories of software we develop support for normative statements regarding the software development landscape. We claim that as society's use of software changes, the ethical analysis for that category of software must necessarily be repeated. Finally, we make a utilitarian argument that the software development environment should encourage both Free Software and Proprietary Software to flourish.", "num_citations": "8\n", "authors": ["323"]}
{"title": "Thoughts on higher education and scientific research\n", "abstract": " The notion of a \"tipping point\" isn't new, al though the concept has relevance in differing ways. Academia seems to be at a tipping point, whereby the steady state of disciplinary specialization is about to give way to an interdisciplinary, collaborative approach to knowledge acquisition. To understand this particular tipping point, it must first appreciate the various emergent viewpoints associated with the concept.", "num_citations": "7\n", "authors": ["323"]}
{"title": "The metaphysics of software trust\n", "abstract": " This article focuses on the \"trust\" portion of the trust and dependability duet. Both concepts are important and delicately intertwined, but in this short discussion, the authors say they can only hope to explore one.", "num_citations": "7\n", "authors": ["323"]}
{"title": "Computer security and human values interact\n", "abstract": " Computer security is technically challenging; it is also an area with ethical, legal and sociological implications. When computer security (as well as other technical content) is taught, one should provoke students to think about the human values involved in making technical decisions. This paper develops teaching ideas for two issues in computer security: WWW cookies; and public access to government databases.", "num_citations": "7\n", "authors": ["323"]}
{"title": "Interface robustness for COTS-based systems\n", "abstract": " Interoperability, costs and time-to-market considerations are driving software production toward the use of as much commercial off-the-shelf (COTS) code as possible. Product cycle times of 12-18 months are now moving towards 3-4 months. This does achieve cost savings, but it also creates new problems. COTS code may not work as efficiently or effectively in a new environment. In addition, the COTS code may have hidden, perhaps malicious functionality that is difficult to discern before it causes problems. This paper looks further into these two concerns about using COTS and into what, if anything, can be done to reduce them. (12 pages)", "num_citations": "7\n", "authors": ["323"]}
{"title": "An automated code-based fault-tree mitigation technique\n", "abstract": " This paper presents a framework for an automated safety methodology that: (1) generates fault-trees from code, and (2) then applies a fault-injection based technique to mitigate the potential for non-root nodes to cause hazardous outputs. This methodology reads in source code and user-defined hazards, builds the fault-tree, and then feeds the fault-tree, code, and user-defined operational profile to a mitigator routine that estimates the frequency with which the event in the root node can occur. Preferably this frequency will be zero, but if not, this methodology will allow a user to quickly assign non-zero probabilities to events that could result in hazards.", "num_citations": "7\n", "authors": ["323"]}
{"title": "Using dynamic sensitivity analysis to assess testability\n", "abstract": " This paper discusses sensitivity analysis and its relationship to random black box testing. Sensitivity analysis estimates the impact that a programming fault at a particular location would have on the program's input/output behavior. Locations that are relatively\\insensitive\" to faults can render random black box testing unlikely to uncover programming faults. Therefore, sensitivity analysis gives new insight when interpreting random black box testing results. Although sensitivity analysis is computationally intensive, it requires no oracle and no human intervention.", "num_citations": "7\n", "authors": ["323"]}
{"title": "THINKING PROFESSIONALLY The continual evolution of interest in computing ethics\n", "abstract": " March 2018 marked the first reported pedestrian death from a self-driving car [10]. The possibility of such events caused by significant technological advances has stimulated interest in ethical issues. Many people think of these situations as brand-new problems requiring unique solutions. The truth is we have been here before, many times. Each technological change has created ethical challenges\u2014should we use remote-controlled technology to take lives? Should we allow computers to decide our medical treatment? Do we want unethical people to have access to computer power? The difficulty and complexity of each new technical advance\u2019s ethical problems distract each generation from the fact that these problems are just different species of a common problem, namely the problem of ethically managing the interaction of technology with humanity. The rising interest in ethics is positive, but the belief that these\u00a0\u2026", "num_citations": "6\n", "authors": ["323"]}
{"title": "Why we should have seen that coming\n", "abstract": " In this paper we examine the case of Tay, the Microsoft AI chatbot that was launched in March, 2016. After less than 24 hours, Microsoft shut down the experiment because the chatbot was generating tweets that were judged to be inappropriate since they included racist, sexist, and anti-Semitic language. We contend that the case of Tay illustrates a problem with the very nature of learning software (LS is a term that describes any software that changes its program in response to its interactions) that interacts directly with the public, and the developer\u2019s role and responsibility associated with it. We make the case that when LS interacts directly with people or indirectly via social media, the developer has additional ethical responsibilities beyond those of standard software. There is an additional burden of care.", "num_citations": "6\n", "authors": ["323"]}
{"title": "The code of ethics quiz show\n", "abstract": " This session is intended as a fun and highly interactive way for college and high school teachers to increase their familiarity with the ACM Code of Ethics and Professional Conduct. Using a quiz show format, participants will be asked to provide solutions to knotty (and sometimes humorous) ethical challenges. This will be followed by think-pair-share (so that everyone gets involved), and then a presentation of the relevant sections of the ACM Code of Ethics and Professional Conduct. Members of the ACM's Committee on Professional Ethics will be on hand to collect feedback and questions about the Code, for use by the Code 2018 task force, and for the\" Ask an Ethicist\" feature at http://ethics. acm. org.", "num_citations": "6\n", "authors": ["323"]}
{"title": "Gender and Race in the Timing of Requests for Ethics Consultations: A Single-Center Study.\n", "abstract": " Clinical ethics consultants are expected to\" reduce disparities, discrimination, and inequities when providing consultations,\" but few studies about inequities in ethics consultation exist. 1 The objectives of this study were (1) to determine if there were racial or gender differences in the timing of requests for ethics consultations related to limiting treatment, and (2) if such differences were found, to identify factors associated with that difference and the role, if any, of ethics consultants in mitigating them. The study was a mixed methods retrospective study of consultation summaries and hospital and ethics center data on 56 age-and gender-matched Caucasian and African American Medicare patients who received ethics consultations related to issues around limiting medical treatment in the period 2011 to 2014. The average age of patients was 70.9. Consultation requests for females were made significantly earlier in their stays in the hospital (6.57 days) than were consultation requests made for males (16.07 days). For African American patients, the differences in admission-to-request intervals for female patients (5.93 days) and male patients (18.64 days) were greater than for Caucasian male and female patients. Differences in the timing of a consultation were not significantly correlated with the presence of an advance directive, the specialty of the attending physician, or the reasons for the consult request. Ethics consultants may have mitigated problems that developed during the lag in request times for African American males by spending more time, on average, on those consultations (316 minutes), especially more time, on average, than on\u00a0\u2026", "num_citations": "6\n", "authors": ["323"]}
{"title": "A nonlinear perspective on higher education\n", "abstract": " To their detriment, academic institutions are increasingly stove-piped in highly specialized disciplinary fields, often losing touch with emergent social, cultural, and natural realities.", "num_citations": "6\n", "authors": ["323"]}
{"title": "Toward a model of trust and e-trust processes using object-oriented methodologies\n", "abstract": " This paper builds on the work we have done in two previous papers,\u2015Why Turing Shouldn \u2018t Have to Guess\u2016 33 and\u2015Developing artificial agents worthy of trust: Would you buy a used car from this artificial agent?\u2016 34 In these two works we explore\u2015trust and\u2015e-trust\u2016 and develop principles of trust. In this paper we build on the object-oriented model that we proposed in the previous work that presents trust as a super-class with two sub-classes e-trust and face to face trust (f2-f) trust and assign them attributes.", "num_citations": "6\n", "authors": ["323"]}
{"title": "IT as a profession: is competent creation the primary goal?\n", "abstract": " This article introduces four articles on the general theme of IT professionalism that make up this special issue. The authors also critique the assertion by J. Steib that \"the primary goal of professionalism is competent creation.\" The authors conclude that although competent creation is an important part of IT professionalism, it isn't primary. Instead, the public good is to be primary for IT professionals.", "num_citations": "6\n", "authors": ["323"]}
{"title": "An ethical can of worms for software certifiers\n", "abstract": " Society and the software industry are well served if certifiers do their job ethically. Thus it behooves everyone to, as much as possible, create an environment that encourages ethical behavior while identifying and discouraging unethical behavior during software certification. If enough discerning customers shun low-quality, uncertified software, those products will be replaced by higher quality, certified software. This reasoning implies, however, that options exist; the continuing trend of companies absorbing or merging with other companies could result in a shrinking pool of developers, offering customers fewer and fewer software options. Reduced competition may also reduce the probability that software adhering to quality standards will be available in the marketplace. To avoid this fate, the software development industry must mature professionally. Society needs this maturity as computing and telecommunications\u00a0\u2026", "num_citations": "6\n", "authors": ["323"]}
{"title": "The avalanche paradigm: an experimental software programming technique for improving fault-tolerance\n", "abstract": " Fault propagation is both boon and curse. For programs undergoing V&V, propagation is a boon, since fault detection is the goal. After software deployment, particularly for safety critical applications, propagation can result in hazardous outputs, which are a curse. Methods to decrease fault propagation for deployed systems are warranted, and we have provided just such a technique in this paper. Fault-tolerant mechanisms are more or less effective depending on where they are placed in a program. This paper combines two different techniques in order to find places where fault-tolerant mechanisms are most likely to defend against hazards. The two techniques are: (1) dynamic fault-injection to estimate the likelihood that anomalies will lead to hazards, and (2) a static analysis that predicts (via a heuristic) the likelihood that program state anomalies (\"corruptions\") will propagate to subsequent program states during\u00a0\u2026", "num_citations": "6\n", "authors": ["323"]}
{"title": "Abstract data type development and implementation: An example\n", "abstract": " Data abstraction is an effective tool in the design of complex systems, and the representation independence it provides is a key factor in the maintenance and adaptation of software systems. This paper describes a system development methodology based on the development of hierarchies of abstract data types (ADT's). The methodology preserves a high degree of representation independence throughout both the design and implementation of complex systems. The methodology is illustrated with examples from the design and implementation of a Vision Research Programming System. These examples include ADT specifications, ADT interface specifications, and partial implementation code for the system in two different programming languages, Ada1 and Fortran.", "num_citations": "6\n", "authors": ["323"]}
{"title": "Can We Program Ethics into AI?[Reflections]\n", "abstract": " Note that learning algorithms like neural nets are notoriously difficult for humans to understand once launched. What do you think is the single biggest hurdle to overcome in the road to programming ethics into AI? Would you characterize that hurdle as a technical programming problem, or the need to better understand HUMAN ethical reasoning before trying to program that reasoning into a machine? You have personal thoughts about this question. But separate from your personal opinion about our question, what do you think the general public, in the main, thinks about the question? What do you think AI researchers, on the whole, think about the question? Given your opinions on the probability of success, and the value of the goal in the first place, do you think society should actively pursue the goal of programming ethics into AI? Explores these issues and provides some answers to these questions.", "num_citations": "5\n", "authors": ["323"]}
{"title": "All hands on deck for ACM ethics: Updating the code, revising enforcement, promoting integrity\n", "abstract": " The Association for Computing Machinery's Committee on Professional Ethics (COPE) has been charged to execute three major projects over the next two years: updating ACM's Code of Ethics and Professional Conduct, revising the enforcement procedures for the Code, and developing new media to promote integrity in the profession. We cannot do this alone, and we are asking SIGCAS members to volunteer and get involved. We will briefly describe the rationale and plan behind these projects and describe opportunities to get involved.", "num_citations": "5\n", "authors": ["323"]}
{"title": "Quantum computing and cloud computing: humans trusting humans via machines\n", "abstract": " In this paper we use Levels of Abstraction and an object-oriented model of trust to analyze quantum computing and cloud computing to identify important ethical concerns. The method of Levels of Abstraction aids in identifying broad social concerns of both methods of computation. Both methods of computation have the potential to deeply impact societal trust of computing.", "num_citations": "5\n", "authors": ["323"]}
{"title": "Unmasking your software's ethical risks\n", "abstract": " It's difficult to fully address all our professional obligations as software engineers. Our training focuses on avoiding technical failures, but unfortunately our systems sometimes have unintended consequences. We need to develop products to avoid unintended negative impacts on society, people, and the environment. Professional responsibility requires that we identify the morally salient features of a situation. Some issues are relatively easy to spot; for example, we shouldn't lie to clients, we shouldn't bribe inspectors, and we should respect people's privacy. But some ethical and social risks are harder to recognize. Even developers with the best intentions have walked into ethical traps. When we study technical problems, we apply the project's constraints and priorities to find acceptable possible solutions and choose among them. Here are four suggestions for considering ethical constraints during that process, they\u00a0\u2026", "num_citations": "5\n", "authors": ["323"]}
{"title": "Ethics in the IT Classroom: Why and how?\n", "abstract": " In today's environment, students of MIS or CS must have a thorough understanding of the importance of acknowledging and dealing with ethical issues. Ethical issues are as critical to the success of IT projects as are design and technical issues. Consequently, IT professionals (whom our students hope to become) must know how to view what they are doing or being asked to do from an ethical perspective. The importance of ethics in organizations and management has escalated in the last few years and is now seen as critical. In this paper the authors define IT ethics, discuss the importance of ethics to organizations, thereby justifying the importance of IT ethics to the IT curriculum, discuss how ethics could be incorporated within the curriculum, and finally provide some ethics resources educators can use as they start to deal with ethics in their curricula.", "num_citations": "5\n", "authors": ["323"]}
{"title": "Privacy and/or security: Take your pick\n", "abstract": " The concepts of privacy and security are distinct, but they're often considered synonymously when applied to computational systems. This article explores the conceptual differences between computational privacy and security and suggests four mutually exclusive models that define four different fundamental approaches to privacy and security during design. It's crucial that developers make a conscious and explicit decision how the two concepts should be approached early during system design.", "num_citations": "5\n", "authors": ["323"]}
{"title": "While we weren't paying attention\n", "abstract": " Technology and Society Magazine (T&S), it is clear that technology can change society. But sometimes we lose sight of the idea that society can change technology. As technological changes come at us thick and fast, we can be overwhelmed. Either consciously or unconsciously, we may start to accept some degree of technological determinism or Chandler\u2019s inevitability thesis. The idea that technology is going to happen no matter what we do is both tempting and highly dangerous, as many have pointed out [1]. We have to keep reminding ourselves that we not only can steer technology, but that we should. Engineers especially must remember that part of our professional responsibility is to shape technology for the benefit of the public at large. The topic of technological determinism came to mind for me while editing this issue\u2019s Special Section on Lethal Robots organized by Ronald Arkin, one of the contributors\u00a0\u2026", "num_citations": "5\n", "authors": ["323"]}
{"title": "Computer Scientist, Software Engineer, or IT Professional: Which Do You Think You Are?\n", "abstract": " Job titles and functions shift quickly in the IT world, but some broad classifications can be useful for identifying what people do and how they view themselves. In some ways, the category of \"IT professional\" is the most broadly encompassing, but many people identify more closely with subspecialties such as \"software engineer\" or \"computer scientist.\"", "num_citations": "5\n", "authors": ["323"]}
{"title": "Critiquing a critique\n", "abstract": " I am not a big fan of meta-critiques, but James Stieb\u2019s article \u2018\u2018A Critique of Positive Responsibility in Computing\u2019\u2019[1] includes claims that I judge to be overstated and should be challenged. Stieb\u2019s article also discusses at least three important questions that I think should be further explored.", "num_citations": "5\n", "authors": ["323"]}
{"title": "Silver bullets for little monsters: making software more trustworthy\n", "abstract": " Despite the legions of ideas about how to improve software quality, much commercial software remains untrustworthy. In this article, the authors make the case for at least taking small steps toward improved quality by using silver bullets \"corrective actions or methods\" to at least eliminate some common problems, the \"little monsters\" of the title. Here, they discuss three such problems \"memory leaks, buffer overflows, and files that remain unclosed when a program terminates\" and list several techniques proposed to eliminate them in software.", "num_citations": "5\n", "authors": ["323"]}
{"title": "Substituting Voas's testability measure for Musa's fault exposure ratio\n", "abstract": " This paper analyzes the relationship between Voas's (1991) software testability measure and Musa's (1987) fault exposure ratio, K. It has come to our attention that industrial users of Musa's model employ his published, experimental value for K, 4.2/spl times/10/sup -7/, for their projects, instead of creating their own K estimate for the system whose reliability is being assessed. We provide a theoretical argument for how a slight modification to Voas's formulae for determining a predicted minimal fault size can provide a predicted average fault size. The predicted average fault size can be used as a substitute for 4.2/spl times/10/sup -7/, and in our opinion is a more plausible choice for K.", "num_citations": "5\n", "authors": ["323"]}
{"title": "Investigating Rare-Event Failure Tolerance Reductions in Uncertainty\n", "abstract": " At the 1995 Computer Assurance (COMPASS) conference, Voas and Miller presented atechnique for assessing the failure tolerance ofaprogram when the program was executing in unlikely modes (with respect to the expected operational pro le). In that paper, several preliminary algorithms werepresented for inverting operational pro les to more easily distinguish the unlikely modes of operation from the likely modes. This paper re nes the original algorithms. This paper then demonstrates the new algorithms being used inconjunction with a failure tolerance assessment technique on two small programs. 1", "num_citations": "5\n", "authors": ["323"]}
{"title": "Experimental evidence of sensitivity analysis predicting minimum failure probabilities\n", "abstract": " The authors discuss a theoretical statistical technique complementary to black-box testing, called sensitivity analysis. Black-box testing establishes an upper limit on the likely probability of software failure. Software sensitivity analysis establishes a lower limit on the probability of failures that are likely to occur. Together, these estimates can be used to establish confidence that software does not contain faults. Experimental results show that sensitivity analysis predicts a realistic, lower limit on the probability of failure. This limit is lower than can be generally predicted using testing results only. Sensitivity analysis was applied to three versions of NASA's specification for the sensor management of a redundant strapped down inertial measurement unit (RSDIMU). An RSDIMU is a component of a modern inertial navigation system to provide acceleration data that is integrated to determine velocity and position. The\u00a0\u2026", "num_citations": "5\n", "authors": ["323"]}
{"title": "A software analysis technique for quantifying reliability in high-risk medical devices\n", "abstract": " The authors present a software engineering technique called sensitivity analysis that aims at producing software that is less likely to hide faults. When sensitivity analysis indicates that faults are not likely to hide from testing, they can more comfortably rely on the results of testing. Sensitivity analysis has been automated, and preliminary results from the automated analysis suggest that the technique will have significant advantages for the development, validation, and regulation of medical devices.< >", "num_citations": "5\n", "authors": ["323"]}
{"title": "Fidelity metrics for hexagonally sampled digital imaging systems\n", "abstract": " Sauf mention contraire ci-dessus, le contenu de cette notice bibliographique peut \u00eatre utilis\u00e9 dans le cadre d\u2019une licence CC BY 4.0 Inist-CNRS/Unless otherwise stated above, the content of this bibliographic record may be used under a CC BY 4.0 licence by Inist-CNRS/A menos que se haya se\u00f1alado antes, el contenido de este registro bibliogr\u00e1fico puede ser utilizado al amparo de una licencia CC BY 4.0 Inist-CNRS", "num_citations": "5\n", "authors": ["323"]}
{"title": "Model-based quantification of image quality\n", "abstract": " In 1982, Park and Schowengerdt published an end-to-end analysis of a digital imaging system quantifying three principal degradation components:(1) image blur-blurring caused by the acquisition system,(2) aliasing-caused by insufficient sampling, and (3) reconstruction blur-blurring caused by the imperfect interpolative reconstruction. This analysis, which measures degradation as the square of the radiometric error, includes the sample-scene phase as an explicit random parameter and characterizes the image degradation caused by imperfect acquisition and reconstruction together with the effects of undersampling and random sample-scene phases. In a recent paper Mitchell and Netravelli displayed the visual effects of the above mentioned degradations and presented subjective analysis about their relative importance in determining image quality. The primary aim of the research is to use the analysis of Park\u00a0\u2026", "num_citations": "5\n", "authors": ["323"]}
{"title": "The ethics of information technologies\n", "abstract": " This volume collects key influential papers that have animated the debate about information computer ethics over the past three decades, covering issues such as privacy, online trust, anonymity, values sensitive design, machine ethics, professional conduct and moral responsibility of software developers. These previously published articles have set the tone of the discussion and bringing them together here in one volume provides lecturers and students with a one-stop resource with which to navigate the debate.", "num_citations": "4\n", "authors": ["323"]}
{"title": "Case complexity and quality attestation for clinical ethics consultants\n", "abstract": " A proposal by the American Society for Bioethics and Humanities (ASBH) to identify individuals who are qualified to perform ethics consultations neglects case complexity in candidates\u2019 portfolios. To protect patients and healthcare organizations, and to be fair to candidates, a minimum case complexity level must be clearly and publicly articulated. This proof-of-concept study supports the feasibility of assessing case complexity. Using text analytics, we developed a complexity scoring system, and retrospectively analyzed more than 500 ethics summaries of consults performed at an academic medical center during 2013. We demonstrate its use with seven case summaries that range in complexity from uncomplicated to very complicated. We encourage the ASBH to require a minimum level of case complexity, and recommend that attestation portfolios include several cases of moderate complexity and at least one very\u00a0\u2026", "num_citations": "4\n", "authors": ["323"]}
{"title": "Robots and the internet: Causes for concern\n", "abstract": " Reacting to the turbulent events of the last decade or so, the U.S. government has focused much attention on developing strategies to curtail the misuse of technology, especially biological agents. In principle, any technology can be exploited and used to achieve malicious ends. This is an especially poignant issue now that we have reached the digital age and that an individual person\u00bfs actions can have an impact that spans across the globe. One way in which a malicious actor could cause serious harm is by manipulating how a robot functions.", "num_citations": "4\n", "authors": ["323"]}
{"title": "Is quantum computing inherently evil?\n", "abstract": " Quantum computing is an emerging technology that has significance across several academic disciplines (including physics, computer science, and philosophy). In this paper we apply principles from Floridi and Sanders' work on Information Ethics to explore the ethical implications of quantum computing. In particular, we use three distinct levels of abstraction to examine quantum computing-LoA1: the observables visible to a user of an application that relies on quantum computing, LoA2: the observables visible to computing professionals implementing the application, and LoAS: the observables that make visible the societal consequences of the application. We find evidence that quantum computers are not an instance of evil in the Information Ethics sense and provide evidence that small quantum computers are ethically different than large quantum computers.", "num_citations": "4\n", "authors": ["323"]}
{"title": "Mobile Applications: The Fifth Cycle\n", "abstract": " The world is poised for a fifth cycle of computer capability, this time focused on the burgeoning phenomena of mobile computing. This technology will become an important aspect of how we react as enlightened citizens to increasingly pressing global issues.", "num_citations": "4\n", "authors": ["323"]}
{"title": "The ethical implications of the messenger's haircut: Steganography in the digital age\n", "abstract": " Information hiding has been of interest since the time of the Greeks. Steganography is one technique to hide information. This paper reviews historical uses of steganography and the impact that advances in information and communication technology have had on steganographic techniques. We note that computing has made steganography accessible and convenient. This widespread availability raises ethical challenges. The first part of the paper examines the role of digital steganography in providing privacy and anonymity. The next part looks at security issues and the implications of strict government regulation. The third part examines the role of steganography in digital rights management and the implications for fair use. Finally, we conclude that steganography should not be prohibited for individuals, but should also not be secretly imposed on equipment users without their consent.", "num_citations": "4\n", "authors": ["323"]}
{"title": "Four UNIX programs in four UNIX collections: Seeking consistency in an open source icon\n", "abstract": " An important claim for Open Source Software (OSS) is that it will, over time, improve (Martin, 2003 and Cingely, 2003). Critics of OSS make an opposite claim: that OSS will tend to degrade because its development is unplanned and chaotic (McKendrick, 2003). Although there is much passion in these arguments, there is often little hard data presented to back up either of these claims.In this paper, we present a modest amount of data on a leading Open Source initiative. Using N-version testing techniques (Grissom and Miller, 1999), we explore four UNIX utility programs in four different UNIX implementations in two separate releases. We then compare and contrast this software, examining their agreements and disagreements, the progress between the two versions, the lines of code, and their execution speed.", "num_citations": "4\n", "authors": ["323"]}
{"title": "The ties that bind: connections, comet cursors, and consent\n", "abstract": " Electronic communication and commerce facilitate the collection of information about individual use of the Internet. Focusing on the case of Comet Systems Inc. and its data gathering practices, this paper explores the technical details of gathering personal information in databases in general and the special character of the privacy issue raised by 'anonymous' information about individual behavior on the Internet. The case analysis suggests new insights for our understanding of privacy and frames a discussion of policy alternatives with respect to the privacy of Internet communication.", "num_citations": "4\n", "authors": ["323"]}
{"title": "A statistical and automated code-based fault-tree mitigation framework for C++\n", "abstract": " This paper presents a framework for an automated safety methodology that: (1) generates fault-trees from C++ code, and (2) then applies a fault-injection based technique to mitigate the potential for non-root nodes to cause hazardous outputs. This methodology reads in source C++ code and user-defined hazards, builds the fault-tree, and then feeds the fault-tree, code, and user-defined operational profile to a mitigator routine that estimates the frequency with which the event in the root node can occur. Preferably this frequency will be zero, but if not, this methodology will allow a user to quickly assign non-zero probabilities to events that could result in hazards.", "num_citations": "4\n", "authors": ["323"]}
{"title": "Investigating rare-event failure tolerance: reductions in future uncertainty\n", "abstract": " At the 1995 Computer Assurance (COMPASS) conference, Voas and Miller (1995) presented a technique for assessing the failure tolerance of a program when the program was executing in unlikely modes (with respect to the expected operational profile). In that paper, several preliminary algorithms were presented for inverting operational profiles to more easily distinguish the unlikely modes of operation from the likely modes. This paper refines the original algorithms. It then demonstrates the new algorithms being used in conjunction with a failure tolerance assessment technique on two small programs.", "num_citations": "4\n", "authors": ["323"]}
{"title": "Technical correspondence\n", "abstract": " This correspondence is motivated by two articles in Communications, one of them proposing an\" industry standard\" random number generator [10], the other describing machine language implementations of that generator [2]. In the first article, under the title\" Random number generators: good ones are hard to find,\" Park and Miller confine their discussion to congruential generators and advocate the generator [X. sub. n]= 16807 [x. sub. n]-1 mod [2. sup. 31]-1 as the\" good one,\" citing some 16-bit generators or the notorious 32-bit RANDU for comparison as the\" bad one.\"Such is the impact of Communications, with its wide readership, that numerous people have the impression that [x. sub. n]= 16807 mod [2. sup. 31]-1 is the only good random number generator--the rest are bad.", "num_citations": "4\n", "authors": ["323"]}
{"title": "Automating test case generation for coverages required by FAA standard DO-178B\n", "abstract": " Coverage testing techniques are required by the FAA for various levels of subsystem criticality at the unit testing level. Higher levels of criticality require coverage schemes that frequently require more and more test cases, particularly when the number of conditions in a decision grows. For example, if we have a decision with n conditions of the form: there are 2\" possible combinations of condition outcomes. Given the enormous number of inputs that may be required to satisfy different coverages, and given that there are no automated tools for determining these inputs (to our knowledge), we will show how one alternative testing technique, mutation testing, can be coerced into generating inputs that satisfy a code coverage scheme X, ie, if we modify the rules for mutant generation during mutation testing, this technique will provide test cases that satisfy X.", "num_citations": "4\n", "authors": ["323"]}
{"title": "Local exhaustive testing: a software reliability tool\n", "abstract": " We introduce local exhaustive testing as a simple strategy for creating test cases that uncover faults (a deficiency in the code that is responsible for incorrect behavior) with a higher probability than tests chosen randomly. To use local exhaustive testing, we identify certain inputs points as\" critical,\" and then test all inputs close to that point. We expect that this strategy will be particularly effective in applications that include an emphasis on geometric or other regular organization. We demonstrate the effectiveness of local exhaustive testing on a collection of programs that are all implementations of a single specification, the proportional navigation problem.", "num_citations": "4\n", "authors": ["323"]}
{"title": "Alternate server disciplines for mobile-servers on a congested network\n", "abstract": " This paper examines, by discrete-event simulation, the following question relative to the mobile-server problem: given k servers with fixed home network locations, the shortest travel-time topology of the network, a stochastic model of the request-for-service distribution across the network and a stochastic model of the service time distribution, what is the best server discipline? That is, how should servers be optimally and dynamically assigned to service requests? Four server disciplines are studied: first available, districting, look-ahead and shortest job completion. Of these, the shortest job completion discipline is demonstrated to provide minimum average response, for all levels of congestion, where for each request the response is the elapsed time between the creation of the request for service and the initiation of on-site service.", "num_citations": "4\n", "authors": ["323"]}
{"title": "Defining and implementing Fortran generic abstract data types\n", "abstract": " The Fortran Abstract Data (FAD) project encourages and enforces the encapsulation of generic abstract data types (ADTs) in a Fortran programming environment, using a preprocessor, database, and object library. The FAD database contains information about ADT subroutines and functions; the FAD library contains the compiled bodies of the ADT subprograms. Once ADT implementations have been installed in the FAD database and library, Fortran programmers can declare and use ADT variables. The FAD preprocessor use ADT translates a user's ADT references into traditional Fortran and prohibits illegal use of ADT variables. Thereafter, the standard Fortran compiler and linker-loader are used with the FAD Fortran library and other libraries. The FAD database can be created by experienced Fortran implementors with the FAD tool make ADT. A parser-generator system is employed to generate the parse tables\u00a0\u2026", "num_citations": "4\n", "authors": ["323"]}
{"title": "Dynamic technology challenges static codes of ethics: A case study\n", "abstract": " We describe the process of changing and the changes being suggested for the ACM Code of Ethics and Professional Conduct. In addition to addressing the technical and ethical basis for the proposed changes, we identify suggestions that commenters made in response to the first draft. We invite feedback on the proposed changes and on the suggestions that commenters made.", "num_citations": "3\n", "authors": ["323"]}
{"title": "Action ethics for a software development class\n", "abstract": " The integration of ethics into computer science instruction is not a new idea (for example, see [10]), but it is still useful to illustrate how this integration can be done in specific kinds of courses [14]. In this article, we present a hands-on ethics lesson for students involved in programming. We think this exercise can be used in any undergraduate class that engages students in software development. Although our examples are written using JavaScript, and can run in any modern browser, they could be easily adapted to other programming languages and platforms. Our goal in this exercise is to encourage students to think more carefully about the ethical implications of the kinds of work students are likely to be asked to do in their first software development jobs.In the first part of this lesson, students are encouraged to make modifications to an existing program. That program simulates a system designed to monitor\u00a0\u2026", "num_citations": "3\n", "authors": ["323"]}
{"title": "A secret sociotechnical system\n", "abstract": " In light of the recent furor over the US government's IT surveillance techniques--ignited by Edward Snowden, who gave details of ongoing operations that deal with email and telephone communications--Keith Miller explores ideas relevant to the case. In particular, he reviews issues that are important for IT professionals concerned with the ethical ramifications of their work.", "num_citations": "3\n", "authors": ["323"]}
{"title": "Software testing: What goes around comes around\n", "abstract": " Today's technology gurus understand little about software testing\u2014a fundamental software engineering pillar that presents many challenges. Furthermore, what role will testing play in the new worlds of mobile apps?", "num_citations": "3\n", "authors": ["323"]}
{"title": "Software test cases: is one ever enough?\n", "abstract": " In this paper, software testing theory was examined as it pertains to one test at a time. In doing so, the author hopes to highlight some useful facts about testing theory that are somewhat obvious but often overlooked. Some precise statements about how bad the one-test policy can be were also made", "num_citations": "3\n", "authors": ["323"]}
{"title": "Software in the new millennium: a virtual roundtable\n", "abstract": " What will software look like in the future? To answer this question, we conducted a survey of our editorial and industrial advisory boards, as well as a few outsiders. We constructed a set of 13 questions that we thought reflected the original query. We then circulated these questions to our boards, with a request to respond to the questions, or be extend them with additional are questions as appropriate. The answers were far ranging and sometimes surprising.", "num_citations": "3\n", "authors": ["323"]}
{"title": "Preparing to Teach Computer Ethics: results from the DOLCE project\n", "abstract": " NOTE: The first page of text has been automatically extracted and included below in lieu of an abstract", "num_citations": "3\n", "authors": ["323"]}
{"title": "Rectangularly and hexagonally sampled imaging-system-fidelity analysis\n", "abstract": " This paper provides a common mathematical framework for analyzing image fidelity losses in rectangularly and hexagonally sampled digital imaging systems. The fidelity losses considered are due to blurring during image formation, aliasing due to undersampling, and imperfect reconstruction. The analysis of the individual and combined effects of these losses is based upon an idealized, noiseless, continuous-discrete-continuous end-to-end digital imaging system model consisting of four independent system components: an input scene, an image gathering point spread function, a sampling function, and an image reconstruction function. The generalized sampling function encompasses both rectangular and hexagonal sampling lattices. Quantification of the image fidelity losses is accomplished via the mean-squared-error (MSE) metrics: imaging fidelity loss, sampling and reconstruction fidelity loss, and end-to\u00a0\u2026", "num_citations": "3\n", "authors": ["323"]}
{"title": "Software testability and its application to avionic software\n", "abstract": " Randomly generated black-box testing is an established yet controversial method of estimating software reliability. Unfortunately, as software applications have required higher reliabilities, practical difficulties with black-box testing have become increasingly problematic. These practical problems are particularly acute in life-critical avionics software, where requirements of failures per hour of system reliability can translate into a probability of failure (pof) of perhaps lo-'or less for each individual execution of the software. This paper describes the application of one type of testability analysis called\" sensitivity analysis\" to B-737 avionics software; one application of sensitivity analysis is to quantify whether software testing is capable of detecting faults in a particular program and thus whether we can be confident that a tested program is not hiding faults. We do so by finding the testabilities of the individual statements of\u00a0\u2026", "num_citations": "3\n", "authors": ["323"]}
{"title": "Simulation Analysis of Mobile Servers on a Congested Network\n", "abstract": " SYNOPTIC ABSTRACTWe develop a simulation-based network model to demonstrate the inconsistencies that can arise when a steady-state average response time model is used to determine the home location of mobile servers in a congested network. In addition, we discuss the importance of the transient behavior of a congested network and the need to acctoount for non-homogeneities in the arrival process.", "num_citations": "3\n", "authors": ["323"]}
{"title": "Implementation parallelized queueing network simulations using FORTRAN and data abstraction\n", "abstract": " Researchers experimenting with simulation on novel computers with parallel architectures must contend with numerous disadvantages: limited availability of programming tools, unique synchronization problems when implementing the simulation, and unexpected interactions between elements of the simulation and characteristics of the underlying computer. Since FORTRAN is likely to be available on the computer and familiar to the researcher, it may be the most logical candidate for coding the simulation. However, FORTRAN does not enforce data abstraction, a useful tool in specifying, designing, and implementing a simulation effort. FAD is a FORTRAN preprocessor which allows the encapsulation of user-defined abstract data types. Data abstraction and FAD is illustrated in the simulation of a queueing network. The separation of concerns between a simulation expert (\"the user\") and an expert in exploiting a\u00a0\u2026", "num_citations": "3\n", "authors": ["323"]}
{"title": "Programming in vision research using pixelspaces, a data abstraction (ada)\n", "abstract": " Programmers who manipulate image representations require large and often complex data structures. Data abstraction techniques and programming languages amenable to those techniques facilitate programming with such structures. This thesis presents a programming methodology that combines algebraic specifications of ADTs (abstract data types) with the programming language Ada to produce highly structured programs for vision research. The methodology has three major stages: the identification and specification of image representations, the design of a program that exploits those representations, and the implementation of the representations and the program.", "num_citations": "3\n", "authors": ["323"]}
{"title": "Trust in Artificial Agents\n", "abstract": " This chapter explores properties that bind individuals, knowledge and communities together. Section 23.1 introduces Hardwig\u2019s argument from trust in others\u2019 testimonies as entailing that trust is the glue that binds individuals into communities. Section 23.2 asks \u201cWhat grounds trust?\u201d by exploring assessment of collaborators\u2019 explanatory responsiveness, formal indicators such as affiliation and credibility, appreciation of peers\u2019 tacit knowledge, game-theoretical considerations, and the role moral character of peers, social biases and social values play in grounding trust. Section 23.3 deals with establishing reliability standards for formation and breaching of trust. Different epistemic considerations and their underpinning of inductive risks are examined through various communication routes within a discipline, between disciplines, and to the public. Section 23.4 examines whether a collective entity can be trusted over\u00a0\u2026", "num_citations": "2\n", "authors": ["323"]}
{"title": "Autonomous vehicles and the ethical tension between occupant and non-occupant safety\n", "abstract": " Autonomous vehicle manufacturers, people inside an autonomous vehicle (occupants), and people outside the vehicle (non-occupants) are among the distinct stakeholders when addressing ethical issues inherent in systems that include autonomous vehicles. As responses to recent tragic cases illustrate, advocates for autonomous vehicles tend to focus on occupant safety, sometimes to the exclusion of non-occupant safety. Thus, we aim to examine ethical issues associated with non-occupant safety, including pedestrians, bicyclists, motorcyclists, and riders of motorized scooters. We also explore the ethical implications of technical and policy ideas that some might propose to improve non-occupant safety. In addition, if safety (writ large) is truly the paramount priority for autonomous vehicle advocates, we contend that autonomous public transportation should be considered as a more effective and less expensive way to improve public safety.", "num_citations": "2\n", "authors": ["323"]}
{"title": "Applying a Social-Relational Model to Explore the Curious Case of hitchBOT\n", "abstract": " This paper applies social-relational models of moral standing of robots to cases where the encounters between the robot and humans are relatively brief. Our analysis spans the spectrum of non-social robots to fully-social robots. We consider cases where the encounters are between a stranger and the robot and do not include its owner or operator. We conclude that the developers of robots that might be encountered by other people when the owner is not present cannot wash their hands of responsibility. They must take care with how they develop the robot\u2019s interface with people and take into account how that interface influences the social relationship between it and people, and, thus, the moral standing of the robot with each person it encounters. Furthermore, we claim that developers have responsibility for the impact social robots have on the quality of human social relationships.", "num_citations": "2\n", "authors": ["323"]}
{"title": "Action ethics: testing and data analysis\n", "abstract": " Have you ever wanted to introduce more material on ethics, but backed away because you didn\u2019t feel confident enough about teaching ethics? If so, this article may be of interest. In it, we describe how to combine a software testing exercise with practice in spotting problems, both technical problems and ethical problems. The case central to this paper is adapted from an actual case, sometimes called \u2018diesel-gate\u2019\u2014the intentional \u2018cheat\u2019in the software used in certain engines developed and installed by Volkswagen (VW) and others [26]. The paper includes a link to a website where a testing simulator is available and gives step-by-step directions about how to use that simulation to help student learn about software testing and about ethics analysis.", "num_citations": "2\n", "authors": ["323"]}
{"title": "Medical Records and Software Trust\n", "abstract": " The rapidly growing use of medical software raises many ethical and privacy issues. This column builds on a previous IT Ethics column, which presented a model of trust focused around software. The authors map out different trust relationships that exist between stakeholders in medical record automation to master the trust issues in this complex sociotechnical system.", "num_citations": "2\n", "authors": ["323"]}
{"title": "IEEE Technology and Society Magazine is Going Green [SSIT BOG Message]\n", "abstract": " Magazine from a print publication to an electronic publication. In the last couple of years, financial considerations have been a prime motivator of these discussions. Although a quality electronic publication is by no means expense-free, paper, printing, and postage are all expenses that can be reduced. And SSIT has been looking with increasing intensity to cut costs to the bone.But for all its importance, money was probably not the best argument for going paperless. SSIT has long been concerned with sustainability, and IEEE has also been pushing \u201cgreen\u201d initiatives. Reducing our carbon footprint is consistent with SSIT\u2019s dedication to the environment and to generational justice. Finally, several members of the board expect that many of our subscribers prefer electronic publications to paper; some of us think a new generation of readers will be more likely to read T&S if it is designed and delivered for electronic\u00a0\u2026", "num_citations": "2\n", "authors": ["323"]}
{"title": "Why turing shouldn\u2019t have to guess\n", "abstract": " Soon computers will routinely pass the Turing Test. We discuss a normative question separate from the descriptive question of feasibility: Should human developers program computers to masquerade as humans? We exclude from our discussion scientific experiments and entertainment applications. We contend that in many of the remaining cases, developers should not program machines to masquerade as humans.", "num_citations": "2\n", "authors": ["323"]}
{"title": "Information Flow, Privacy, and Surveillance\n", "abstract": " 5. Nissenbaum\u2019s account of privacy as contextual integrity explains privacy in terms of two norms. Explain, and give two examples of each type of norm. Choose examples that show how the norms vary from context to context.", "num_citations": "2\n", "authors": ["323"]}
{"title": "Influences on and incentives for increasing software reliability\n", "abstract": " We contend that software developers have an ethical responsibility to strive for reliable software. We base that obligation on long standing engineering traditions that place the public good as a central tenant and on the professional relationship between a software developer and the users of the software developed.", "num_citations": "2\n", "authors": ["323"]}
{"title": "Virtual harms and virtual responsibility: A rape in cyberspace\n", "abstract": " Julian Dibbell reported a \"rape in cyberspace\" in 1993. In this paper we use the case to explore the moral nature of actions in virtual environments. We emphasize the themes of harm and responsibility and conclude with some tentative lessons learned, and extend the analysis to virtual sex.", "num_citations": "2\n", "authors": ["323"]}
{"title": "Software Engineering Ethics Training in Industry and Academe: Professionalism and the Software Engineering Code of Ethics\n", "abstract": " Software Engineering Ethics Training in Industry and Academe | Proceedings of the 14th Conference on Software Engineering Education and Training ACM Digital Library home ACM home Google, Inc. (search) Advanced Search Browse About Sign in Register Advanced Search Journals Magazines Proceedings Books SIGs Conferences People More Search ACM Digital Library SearchSearch Advanced Search Browse Browse Digital Library Collections More HomeBrowse by TitleProceedingsCSEET '01Software Engineering Ethics Training in Industry and Academe: Professionalism and the Software Engineering Code of Ethics Article Software Engineering Ethics Training in Industry and Academe: Professionalism and the Software Engineering Code of Ethics Share on Authors: Donald Gotterbarn View Profile , Keith Miller View Profile Authors Info & Affiliations Publication: CSEET '01: Proceedings of the 14th on 10 ! \u2026", "num_citations": "2\n", "authors": ["323"]}
{"title": "Inspecting and ASSERTing Intelligently\n", "abstract": " Software testability is a misunderstood technology by most of the software testing community. Most testing experts believe that software testability is either a measure of complexity or a subjective assessment of how much it will cost to generate test cases, perform coverage testing, write drivers and/or stubs, etc. This perspective is incomplete. In the late 1980s, an alternative perspective on testability was proposed that attempted to answer the following question:\\what is the probability that a program cannot fail even if it is incorrect.\" This suggestion was in sharp contrast to the age old reliability question:\\what is the probability that a program will fail\", and many experts failed to immediately pick up on the subtle difference. The difference represented a paradigm shift for software testing research, and provided new avenues for research that have already yielded unexpected benefits. This paper focuses on one of those benefits: deciding where to ASSERT and inspect code.", "num_citations": "2\n", "authors": ["323"]}
{"title": "Testability: an introduction for COMPASS94\n", "abstract": " Testability is the probability that software will fail during random testing if it contains a fault. Reliability and correctness are distinct from testability, though all three ideas are closely related. It is theoretically possible to have reliable and even correct software that is not very testable, but you would be hard-pressed to give a convincing demonstration that such software has attained that reliability or correctness. Three things have to happen before a fault in software becomes known during testing: the fault must be executed, that execution has to change the data state adversely, and that \"infected\" data state must cause an incorrect output. The three parts of this process are called execution, infection, and propagation. This three-part fault/failure process forms the basis of testability analysis. Testability analysis predicts for a given piece of software how likely it is that a fault in that software (if it exists) will cause a failure\u00a0\u2026", "num_citations": "2\n", "authors": ["323"]}
{"title": "A Model for Assessing the Liability of Seemingly Correct Software\n", "abstract": " Current research on software reliability does not lend itself to quantitatively assessing the risk posed by a piece of life-critical software. Black-box software reliability models are too general and make too many assumptions to be applied confidently to assessing the risk of life-critical software. We present a model for assessing the risk caused by a piece of software; this model combines software testing results and Hamlet's probable correctness model [2]. We show how this model can assess software risk for those who insure against a loss that can occur if life-critical software fails.", "num_citations": "2\n", "authors": ["323"]}
{"title": "Methods of integrating the study of ethics into the computer science curriculum (panel session)\n", "abstract": " METHODS OF INTEGRATING THE STUDY OF ETHICS INTO THE COMPUTER SCIENCE CURRICULUM Panelists: Donald Gotterbarn Department of Compu Page 1 PANEL METHODS OF INTEGRATING THE STUDY OF ETHICS INTO THE COMPUTER SCIENCE CURRICULUM Panelists: Donald Gotterbarn Department of Computer Science The Wichita State University Wichita, Kansas 67208 Deborah Johnson Department of Science and Technology Studies Rensselaer Polytechnic Institute Troy, New York 12180 Keith Miller Department of Computer Science The College of William and Mary Williamsburg, Virginia 23185 Gene Spafford Department of Computer Sciences Purdue University west Lafayette, Indiana 47907 There has been significant interest recently in ethical issues that arises in the context of doing computer science. The two major problems for the computer science professor who is interested in are \u2026", "num_citations": "2\n", "authors": ["323"]}
{"title": "On the Responsibility for Uses of Downstream Software\n", "abstract": " In this paper we explore an issue that is different from whether developers are responsible for the direct impact of the software they write. We examine, instead, in what ways, and to what degree, developers are responsible for the way their software is used \u201cdownstream.\u201d We review some key scholarship analyzing responsibility in computing ethics, including some recent work by Floridi. We use an adaptation of a mechanism developed by Floridi to argue that there are features of software that can be used as guides to better distinguish situations where a software developer might share in responsibility for the software\u2019s downstream use from those in which the software developer likely does not share in that responsibility. We identify five such features and argue how they are useful in the model of responsibility that we develop. The features are: closeness to the hardware, risk, sensitivity of data, degree of control over or knowledge of the future population of users, and the nature of the software (general vs. special purpose).", "num_citations": "1\n", "authors": ["323"]}
{"title": "Yes, but\u2026 our response to:\u201cprofessional ethics in the information age\u201d\n", "abstract": " PurposeThis short viewpoint is a response to a lead paper on professional ethics in the information age. This paper aims to draw upon the authors\u2019 experience of professional bodies such as the ACM over many years. Points of agreement and disagreement are highlighted with the aim of promoting wider debate.Design/methodology/approachAn analysis of the lead paper is undertaken using a binary agree/disagree approach. This highlights the conflicting views which can then be considered in more detail.FindingsFour major agreements and four major disagreements are identified. There is an emphasis on \u201cacultural\u201d professionalism to promote moral behavior rather than amoral behavior.Originality/valueThis is an original viewpoint which draws from the authors\u2019 practical experience and expertise.", "num_citations": "1\n", "authors": ["323"]}
{"title": "The Ethics of Information Systems\u2013challenges and opportunities: a panel discussion\n", "abstract": " Information integrity relies upon the development and operation of computer-based information systems. Those who undertake the planning, development and operation of these information systems have obligations to assure information integrity and overall to contribute to the public good This ethical dimension of information systems has attracted mixed attention in the IS academic discipline. The panel discussion aims to instill greater interest in this important IS perspective through considering the ethical issues surrounding IS practice.", "num_citations": "1\n", "authors": ["323"]}
{"title": "Computing Ethics: A Multicultural Approach\n", "abstract": " This textbook emphasizes a diversity of values from different cultures, religions, and geographical locations. The book is designed to assist students, computing professionals, and faculty members to act in a more professional and ethical manner. Compelling case studies, ethical reasoning, and cultural perspectives will be included throughout the book, and the authors will apply lessons learned over many years of intense involvement in computing ethics. The text is appropriate either as a main text in a stand-alone ethics course or as a supplementary text for other related courses.", "num_citations": "1\n", "authors": ["323"]}
{"title": "Robots, Ethics and Software\u2013FOSS vs. Proprietary Licenses\n", "abstract": " The sociotechnical system of a robot, including its software, matters. Context is central to analyzing the ethical implications of that software for the public and the ethical responsibilities of the developers of that software. Possibly morally neutral concepts such as mass production, information storage, information acquisition, connectivity, ownership and learning can have a collective positive or negative ethical impact for a world with robots. Since robots are a type of artificial agent (AA), we start with a claim by Floridi that the actions of AAs can be sources of moral or immoral actions. Because AAs are in essence multi-agent systems, we apply Floridi\u2019s Distributed Morality (DM). In this paper, we will analyze proprietary and open source licensing schemes as a policy component of DM and show the distinctions between software licensing schemes in terms of how they work to \u201caggregate good actions\u201d and\u00a0\u2026", "num_citations": "1\n", "authors": ["323"]}
{"title": "Ethics and Information Technologies: History and Themes of a Research Field\n", "abstract": " The International Telecommunication Union, the United Nations agency that deals with information and communication technologies (ICTs), estimated the 2014 number of worldwide Internet users was almost 40% of the worldwide population. The 2014 report of the World Economic Forum predicts that the value of the Internet-based economy of the G-20 nations will reach $4.2 trillion (or more than 5% of the countries\u2019 GDP) by 2016.Clearly, we live in data-driven, IT-based societies: societies that depend crucially on information. This may not sound new to the reader. Media, academic articles, and everyday discussions increasingly focus on the informational, technology-driven turn that characterizes this historical moment, in which widely disseminated and radical changes simultaneously affect both individuals and societies. Such changes generate new opportunities, but also new questions and problems ranging from individual well-being and the management of societies, to the regulation of design and deployment of technological artefacts, as well as the definition of \u2018good\u2019and \u2018evil\u2019and our understanding and perception of reality itself. These very same changes make the information revolution, the ubiquitous and capillary dissemination of information technologies, more than just a technological upheaval; for it has helped redefine individuals\u2019 daily practises and changed societies\u2019 social and political priorities.", "num_citations": "1\n", "authors": ["323"]}
{"title": "Workshop-Integrating professional issues into the technical curriculum: Teaching students about the challenge of professionalism and ethics in an increasingly automated world\u00a0\u2026\n", "abstract": " In support of ACM's and the IEEE's commitment to professionalism, the ACM Committee on Professional Ethics, a technical co-sponsor of this conference, is presenting a workshop designed to help faculty provide students with tools to better understand and to better resolve their ethical challenges as professionals. This workshop will have a special focus on issues raised by robots, Google Glass, and other increasingly sophisticated devices. The workshop will use both lecture and small group activities to introduce and enhance participants' teaching skills in computer and engineering ethics. Leaders will present materials to be used in a complete professional ethics course, and that can also be integrated as examples and exercises into specific technical courses. The materials will include case studies, suggested course syllabi, and suggestions for creating and grading assignments. The workshop will feature\u00a0\u2026", "num_citations": "1\n", "authors": ["323"]}
{"title": "Augmented reality in your eye: Google Glass, Space Glasses, and beyond\n", "abstract": " In this paper we consider the impact of augmented visual field devices (AVFDs). We briefly survey current technology and consider potential advances. We argue that Plato\u2019s Allegory of the Cave has influence on the notion of augmented reality. In addition, the ethics of augmented visual field devices are further informed by notions from the digital divide and philosophical notions of transparency. We use ideas from value sensitive design and information ethics to explore concerns about psychological, social and physical well-being of people, while articulating concerns and benefits of both user and developer control of AVFDs. We suggest that there is social benefit in users sharing what is visible on their devices with those who are in close physical proximity. This shows the tension between notions of personal privacy and the establishment and maintenance of social norms.", "num_citations": "1\n", "authors": ["323"]}
{"title": "Technology, Unemployment, and Power\n", "abstract": " Business organizations and people are making predictions and investments based on a recognition that smart machines are starting to make dramatic changes in the world of work and will likely make even more dramatic changes in the near future. Some people see this as an opportunity, while others see it as vulnerability, but many people see it as inevitable.", "num_citations": "1\n", "authors": ["323"]}
{"title": "Is Ethical Behavior Good for Business?\n", "abstract": " Is ethical behavior good for business? In pondering this question, consider what \"good for business\" actually means. Is it just increased profits, or something more? Does being known as an ethical IT professional offer a competitive advantage? Here, Keith Miller critically examines these and related questions.", "num_citations": "1\n", "authors": ["323"]}
{"title": "Introducing professional computing issues into the CS curriculum ACM committee on professional ethics\n", "abstract": " Computing professionals face ethical conflicts. A true professional faces these challenges intelligently and analytically. Professional practice consists of both technical knowledge and the skillful application of that knowledge guided by ethical standards. Computing professionals, like other professionals, must reason through tradeoffs between technical issues, legal issues, economic issues, stakeholder interests, and ethical principles.", "num_citations": "1\n", "authors": ["323"]}
{"title": "Joining the conversation about IT ethics\n", "abstract": " IT Professional is a publication for practitioners, and proudly so. In this department, we often talk about the practical side of ethics issues, including advice on how professionals can recognize, analyze, and make judgments on challenging questions about right, wrong, and computing. But in this issue's installment, the author takes a somewhat broader view, starting with an examination of ethical issues in computing as discussed at a recent conference on computer ethics.", "num_citations": "1\n", "authors": ["323"]}
{"title": "The Future Looks Dim: Building the Information Society with Shoddy Materials\n", "abstract": " The ETHICOMP 99 Conference encourages us to\" look to the future of the information society.\" The information society of the future is being built on the software and data of today. The quality of software and data today does not reassure us about the future. This paper explores issues that complicate the improvement of software quality.(We leave the discussion of data integrity to others.) The paper suggests practical steps that may improve computer software, an important\" material\" that we will use to build the information society.", "num_citations": "1\n", "authors": ["323"]}
{"title": "Integrating the ethical and social context of computing into the computer science curriculum\n", "abstract": " This paper describes the major components of ImpactCS, a program to develop strategies and curriculum materials for integrating social and ethical considerations into the computer science curriculum. It presents, in particular, the content recommendations of a subcommittee of ImpactCS; and it illustrates the interdisciplinary nature of the field, drawing upon concepts from computer science, sociology, philosophy, psychology, history and economics.", "num_citations": "1\n", "authors": ["323"]}
{"title": "Programming and the public trust\n", "abstract": " PW Robert Collins and Keith Miller rrogramming and the Public Trust People do not like to trust computers, but increasing-ly they must. As computers become ubiquitous, so do complaints about the mistakes they make. Up to now, computer programmers have largely escaped widespread public animosity. The public's generosity toward programmers and animosity toward machines are both misplaced: computers do exactly what they are told to do with great reliability. Computers\" misbehave\" only when they are told to do the wrong thing. It is only a matter of time until the public's perception catches up to the reality. Programmers have benefited from general ignorance about machines. If the public thinks that computers have a will of their own, then programmers are to be congratu-lated for controlling these obstinate machines as well as they do. However, computers do not have any will and, in fact, loyally do what\u00a0\u2026", "num_citations": "1\n", "authors": ["323"]}
{"title": "Maintaining FORTRAN software by enforcing abstract data types\n", "abstract": " The principles of data abstraction facilitate maintenance and enhance software reliability. However, FORTRAN includes features that undermine data abstraction. A FORTRAN preprocessor called FAD enforces data abstraction when reusing FORTRAN-callable subprograms. Using FAD, reusable software is organized as the implementation of abstract data types (ADTs). FAD users access the reusable software by declarations and subprogram invocations based on the ADTs. The FAD preprocessor translates ADT references into FORTRAN code and prohibits inappropriate manipulation of ADT instances. With the FAD system, ADT implementations can be changed without changing FORTRAN code that uses the ADTs. A maintenance strategy using FAD facilitates detailed control of reusable software.<>", "num_citations": "1\n", "authors": ["323"]}
{"title": "De ning an Adaptive Software Security Metric from a Dynamic Software Failure Tolerance Measure\n", "abstract": " This paper describes a software assessment method that is being implemented to quantitatively assess information system security and survivability. Our approach| which we call Adaptive Vulnerability Analysis| exercises software (in source-code form) by simulating incoming malicious and non-malicious attacks that fall under various threat classes. A quantitative metric is computed by determining whether the simulated threats undermine the security of the system as defined by the user according to the application program. This approach stands in contrast to common security assurance methods that rely on black-box techniques for testing completely-installed systems. AVA does not provide an absolute metric, such as mean-time-to-failure, but instead provides a relative metric, allowing a user to compare the security of different versions of the same system, or to compare non-related systems with similar functionality.", "num_citations": "1\n", "authors": ["323"]}