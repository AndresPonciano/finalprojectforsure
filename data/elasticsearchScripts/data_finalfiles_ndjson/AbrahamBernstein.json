{"title": "Tools for inventing organizations: Toward a handbook of organizational processes\n", "abstract": " The paper describes a new project intended to provide a firmer theoretical and empirical foundation for such tasks as enterprise modeling, enterprise integration, and process re-engineering. The project includes: (1) collecting examples of how different organizations perform similar processes, and (2) representing these examples in an on-line 'process handbook' which includes the relative advantages of the alternatives. The handbook is intended to help: (a) redesign existing organizational processes, (b) invent new organizational processes that take advantage of information technology, and perhaps (c) automatically generate software to support organizational processes. A key element of the work is a novel approach to representing processes at various levels of abstraction. This approach uses ideas from computer science about inheritance and from coordination theory about managing dependencies. Its\u00a0\u2026", "num_citations": "1374\n", "authors": ["2081"]}
{"title": "Hexastore: sextuple indexing for semantic web data management\n", "abstract": " Despite the intense interest towards realizing the Semantic Web vision, most existing RDF data management schemes are constrained in terms of efficiency and scalability. Still, the growing popularity of the RDF format arguably calls for an effort to offset these drawbacks. Viewed from a relational-database perspective, these constraints are derived from the very nature of the RDF data model, which is based on a triple format. Recent research has attempted to address these constraints using a vertical-partitioning approach, in which separate two-column tables are constructed for each property. However, as we show, this approach suffers from similar scalability drawbacks on queries that are not bound by RDF property value. In this paper, we propose an RDF storage scheme that uses the triple nature of RDF as an asset. This scheme enhances the vertical partitioning idea and takes it to its logical conclusion. RDF\u00a0\u2026", "num_citations": "811\n", "authors": ["2081"]}
{"title": "SPARQL basic graph pattern optimization using selectivity estimation\n", "abstract": " In this paper, we formalize the problem of Basic Graph Pattern (BGP) optimization for SPARQL queries and main memory graph implementations of RDF data. We define and analyze the characteristics of heuristics for selectivity-based static BGP optimization. The heuristics range from simple triple pattern variable counting to more sophisticated selectivity estimation techniques. Customized summary statistics for RDF data enable the selectivity estimation of joined triple patterns and the development of efficient heuristics. Using the Lehigh University Benchmark (LUBM), we evaluate the performance of the heuristics for the queries provided by the LUBM and discuss some of them in more details.", "num_citations": "457\n", "authors": ["2081"]}
{"title": "Fair and balanced? bias in bug-fix datasets\n", "abstract": " Software engineering researchers have long been interested in where and why bugs occur in code, and in predicting where they might turn up next. Historical bug-occurence data has been key to this research. Bug tracking systems, and code version histories, record when, how and by whom bugs were fixed; from these sources, datasets that relate file changes to bug fixes can be extracted. These historical datasets can be used to test hypotheses concerning processes of bug introduction, and also to build statistical bug prediction models. Unfortunately, processes and humans are imperfect, and only a fraction of bug fixes are actually labelled in source code version histories, and thus become available for study in the extracted datasets. The question naturally arises, are the bug fixes recorded in these historical datasets a fair representation of the full population of bug fixes? In this paper, we investigate historical\u00a0\u2026", "num_citations": "439\n", "authors": ["2081"]}
{"title": "Toward intelligent assistance for a data mining process: An ontology-based approach for cost-sensitive classification\n", "abstract": " A data mining (DM) process involves multiple stages. A simple, but typical, process might include preprocessing data, applying a data mining algorithm, and postprocessing the mining results. There are many possible choices for each stage, and only some combinations are valid. Because of the large space and nontrivial interactions, both novices and data mining specialists need assistance in composing and selecting DM processes. Extending notions developed for statistical expert systems we present a prototype intelligent discovery assistant (IDA), which provides users with 1) systematic enumerations of valid DM processes, in order that important, potentially fruitful options are not overlooked, and 2) effective rankings of these valid processes by different criteria, to facilitate the choice of DM processes to execute. We use the prototype to show that an IDA can indeed provide useful enumerations and effective\u00a0\u2026", "num_citations": "296\n", "authors": ["2081"]}
{"title": "GINO\u2013a guided input natural language ontology editor\n", "abstract": " The casual user is typically overwhelmed by the formal logic of the Semantic Web. The gap between the end user and the logic-based scaffolding has to be bridged if the Semantic Web\u2019s capabilities are to be utilized by the general public. This paper proposes that controlled natural languages offer one way to bridge the gap. We introduce GINO, a guided input natural language ontology editor that allows users to edit and query ontologies in a language akin to English. It uses a small static grammar, which it dynamically extends with elements from the loaded ontologies. The usability evaluation shows that GINO is well-suited for novice users when editing ontologies. We believe that the use of guided entry overcomes thehabitability problem, which adversely affects most natural language systems. Additionally, the approach\u2019s dynamic grammar generation allows for easy adaptation to new ontologies.", "num_citations": "286\n", "authors": ["2081"]}
{"title": "Software infrastructure and design challenges for ubiquitous computing applications\n", "abstract": " Striving to integrate computing into everyday activities in a seamless manner.", "num_citations": "279\n", "authors": ["2081"]}
{"title": "Improving performance, perceived usability, and aesthetics with culturally adaptive user interfaces\n", "abstract": " When we investigate the usability and aesthetics of user interfaces, we rarely take into account that what users perceive as beautiful and usable strongly depends on their cultural background. In this paper, we argue that it is not feasible to design one interface that appeals to all users of an increasingly global audience. Instead, we propose to design culturally adaptive systems, which automatically generate personalized interfaces that correspond to cultural preferences. In an evaluation of one such system, we demonstrate that a majority of international participants preferred their personalized versions over a nonadapted interface of the same Website. Results show that users were 22% faster using the culturally adapted interface, needed fewer clicks, and made fewer errors, in line with subjective results demonstrating that they found the adapted version significantly easier to use. Our findings show that interfaces\u00a0\u2026", "num_citations": "263\n", "authors": ["2081"]}
{"title": "How useful are natural language interfaces to the semantic web for casual end-users?\n", "abstract": " Natural language interfaces offer end-users a familiar and convenient option for querying ontology-based knowledge bases. Several studies have shown that they can achieve high retrieval performance as well as domain independence. This paper focuses on usability and investigates if NLIs are useful from an end-user\u2019s point of view. To that end, we introduce four interfaces each allowing a different query language and present a usability study benchmarking these interfaces. The results of the study reveal a clear preference for full sentences as query language and confirm that NLIs are useful for querying Semantic Web data.", "num_citations": "257\n", "authors": ["2081"]}
{"title": "Knowing what a user likes: A design science approach to interfaces that automatically adapt to culture\n", "abstract": " Adapting user interfaces to a user's cultural background can increase satisfaction, revenue, and market share. Conventional approaches to cateringfor culture are restricted to adaptations for specific countries and modify only a limited number of interface components, such as the language or date and time formats. We argue that a more comprehensive personalization of interfaces to cultural background is needed to appeal to users in expanding markets. This paper introduces a low-cost, yet efficient method to achieve this goal: cultural adaptivity. Culturally adaptive interfaces are able to adapt their look and feel to suit visual preferences. In a design science approach, we have developed a number of artifacts that support cultural adaptivity, including a prototype web application. We evaluate the efficacy of the prototype's automatically generated interfaces by comparing them with the preferred interfaces of 105\u00a0\u2026", "num_citations": "239\n", "authors": ["2081"]}
{"title": "Querix: A natural language interface to query ontologies based on clarification dialogs\n", "abstract": " The logic-based machine-understandable framework of the Semantic Web typically challenges casual users when they try to query ontologies. An often proposed solution to help casual users is the use of natural language interfaces. Such tools, however, suffer from one of the biggest problems of natural language: ambiguities. Furthermore, the systems are hardly adaptable to new domains. This paper addresses these issues by presenting Querix, a domain-independent natural language interface for the Semantic Web. The approach allows queries in natural language, thereby asking the user for clarification in case of ambiguities. The preliminary evaluation showed good retrieval performance.", "num_citations": "233\n", "authors": ["2081"]}
{"title": "Serching for services on the semantic web using process ontologies.\n", "abstract": " The ability to rapidly locate useful on-line services (eg software applications, software components, process models, or service organizations), as opposed to simply useful documents, is becoming increasingly critical in many domains. As the sheer number of such services increases it will become increasingly more important to provide tools that allow people (and software) to quickly find the services they need, while minimizing the burden for those who wish to list their services with these search engines. This can be viewed as a critical enabler of the \u2018friction-free\u2019markets of the \u2018new economy\u2019. Current service retrieval technology is, however, seriously deficient in this regard. The information retrieval community has focused on the retrieval of documents, not services per se, and has as a result emphasized keyword-based approaches. Those approaches achieve fairly high recall but low precision. The software agents and distributed computing communities have developed simple \u2018frame-based\u2019approaches for \u2018matchmaking\u2019between tasks and on-line services increasing precision at the substantial cost of requiring all services to be modeled as frames and only supporting perfect matches. This paper proposes a novel, ontology-based approach that employs the characteristics of a processtaxonomy to increase recall without sacrificing precision and computational complexity of the service retrieval process.", "num_citations": "232\n", "authors": ["2081"]}
{"title": "Applied temporal RDF: Efficient temporal querying of RDF data with SPARQL\n", "abstract": " Many applications operate on time-\u201csensitive\u201d data. Some of these data are only valid for certain intervals (e.g., job-assignments, versions of software code), others describe temporal events that happened at certain points in time (e.g., a person\u2019s birthday). Until recently, the only way to incorporate time into Semantic Web models was as a data type property. Temporal RDF, however, considers time as an additional dimension in data preserving the semantics of time.                 In this paper we present a syntax and storage format based on named graphs to express temporal RDF. Given the restriction to preexisting RDF-syntax, our approach can perform any temporal query using standard SPARQL syntax only. For convenience, we introduce a shorthand format called \u03c4-SPARQL for temporal queries and show how \u03c4-SPARQL queries can be translated to standard SPARQL. Additionally, we show that\u00a0\u2026", "num_citations": "214\n", "authors": ["2081"]}
{"title": "Toward high-precision service retrieval\n", "abstract": " Online repositories are increasingly called on to provide access to services that describe or provide useful behaviors. Existing techniques for finding services offer low retrieval precision, returning many irrelevant matches. We introduce a novel service retrieval approach that captures service semantics using process models, and applies a pattern-matching algorithm to find the services with the behavior the user wants. Evaluations suggest that process-based queries offer substantially greater retrieval precision than existing approaches and scale well with the number of services being accessed.", "num_citations": "214\n", "authors": ["2081"]}
{"title": "Evaluating the usability of natural language query languages and interfaces to Semantic Web knowledge bases\n", "abstract": " The need to make the contents of the Semantic Web accessible to end-users becomes increasingly pressing as the amount of information stored in ontology-based knowledge bases steadily increases. Natural language interfaces (NLIs) provide a familiar and convenient means of query access to Semantic Web data for casual end-users. While several studies have shown that NLIs can achieve high retrieval performance as well as domain independence, this paper focuses on usability and investigates if NLIs and natural language query languages are useful from an end-user's point of view. To that end, we introduce four interfaces each allowing a different query language and present a usability study benchmarking these interfaces. The results of the study reveal a clear preference for full natural language query sentences with a limited set of sentence beginnings over keywords or formal query languages. NLIs to\u00a0\u2026", "num_citations": "202\n", "authors": ["2081"]}
{"title": "How can cooperative work tools support dynamic group process? bridging the specificity frontier\n", "abstract": " In the past, most collaboration support systems have focused on either automating fixed work processes or simply supporting communication in ad-hoc processes. This results in systems that are usually inflexible and difficult to change or that provide no specific support to help users decide what to do next.", "num_citations": "186\n", "authors": ["2081"]}
{"title": "Towards high-precision service retrieval\n", "abstract": " The ability to rapidly locate useful on-line services (e.g. software applications, software components, process models, or service organizations), as opposed to simply useful documents, is becoming increasingly critical in many domains. Current service retrieval technology is, however, notoriously prone to low precision. This paper describes a novel service retrieval approached based on the sophisticated use of process ontologies. Our preliminary evaluations suggest that this approach offers qualitatively higher retrieval precision than existing (keyword and table-based) approaches without sacrificing recall and computational tractability/scalability.", "num_citations": "169\n", "authors": ["2081"]}
{"title": "NLP-Reduce: A naive but domainindependent natural language interface for querying ontologies\n", "abstract": " Casual users are typically overwhelmed by the formal logic of the Semantic Web. The question is how to help casual users to query a web based on logic that they do not seem to understand. An often proposed solution is the use of natural language interfaces. Such tools, however, suffer from the problem that entries have to be grammatical. Furthermore, the systems are hardly adaptable to new domains. We address these issues by presenting NLP-Reduce, a \u201cna\u0131ve,\u201d domain-independent natural language interface for the Semantic Web. The simple approach deliberately avoids any complex linguistic and semantic technology while still achieving good retrieval performance as shown by the preliminary evaluation.", "num_citations": "154\n", "authors": ["2081"]}