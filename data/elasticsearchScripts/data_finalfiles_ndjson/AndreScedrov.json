{"title": "Categories, allegories\n", "abstract": " General concepts and methods that occur throughout mathematics\u2013and now also in theoretical computer science\u2013are the subject of this book. It is a thorough introduction to Categories, emphasizing the geometric nature of the subject and explaining its connections to mathematical logic. The book should appeal to the inquisitive reader who has seen some basic topology and algebra and would like to learn and explore further. The first part contains a detailed treatment of the fundamentals of Geometric Logic, which combines four central ideas: natural transformations, sheaves, adjoint functors, and topoi. A special feature of the work is a general calculus of relations presented in the second part. This calculus offers another, often more amenable framework for concepts and methods discussed in part one. Some aspects of this approach find their origin in the relational calculi of Peirce and Schroeder from the last century, and in the 1940's in the work of Tarski and others on relational algebras. The representation theorems discussed are an original feature of this approach.", "num_citations": "940\n", "authors": ["1611"]}
{"title": "Uniform proofs as a foundation for logic programming\n", "abstract": " Miller, D., G. Nadathur, F. Pfenning and A. Scedrov, Uniform proofs as a foundation for logic programming, Annals of Pure and Applied Logic 51 (1991) 125\u2013157. A proof-theoretic characterization of logical languages that form suitable bases for Prolog-like programming languages is provided. This characterization is based on the principle that the declarative meaning of a logic program, provided by provability in a logical system, should coincide with its operational meaning, provided by interpreting logical connectives as simple and fixed search instructions. The operational semantics is formalized by the identification of a class of cut-free sequent proofs called uniform proofs. A uniform proof is one that can be found by a goal-directed search that respects the interpretation of the logical connectives as search instructions. The concept of a uniform proof is used to define the notion of an abstract logic programming\u00a0\u2026", "num_citations": "866\n", "authors": ["1611"]}
{"title": "Bounded linear logic: a modular approach to polynomial-time computability\n", "abstract": " Usual typed lambda-calculi yield input/output specifications; in this paper the authors show how to extend this paradigm to complexity specifications. This is achieved by means of a restricted version of linear logic in which the use of exponential connectives is bounded in advance. This bounded linear logic naturally involves polynomials in its syntax and dynamics. It is then proved that any functional term of appropriate type actually encodes a polynomial-time algorithm and that conversely any polynomial-time function can be obtained in this way.", "num_citations": "340\n", "authors": ["1611"]}
{"title": "Functorial polymorphism\n", "abstract": " In the past s Li. e-ai years types have become an important component of programming iat; guagc dcsigg. TZi< y pmvde a logical framework to ensure that programs meet given specifications, support a partial correctness or verification mechanism, enhance software maintenance, and encourage the systematic building of complex modules from si nphzr ones. These features are crucial in large-scale programming projects requiring coordination among many teams of programmers. Man) recently developed programming languages have more sophisticated typing mechanisms than the familiar Algal/Pascal family. For example L-like languages [2?, 40, 62, 15], as well as such languages as Ada [3] and CPU [35], feature aspects of polymorphic or generic data types which allow the programmer great flexibility and abstraction.", "num_citations": "226\n", "authors": ["1611"]}
{"title": "An extension of system F with subtyping\n", "abstract": " System F is a well-known typed \u03bb-calculus with polymorphic types, which provides a basis for polymorphic programming languages. We study an extension of F, called F<: (pronounced ef-sub), that combines parametric polymorphism with subtyping. The main focus of the paper is the equational theory of F<:, which is related to PER models and the notion of parametricity. We study some categorical properties of the theory when restricted to closed terms, including interesting categorical isomorphisms. We also investigate proof-theoretical properties, such as the conservativity of typing judgments with respect to F. We demonstrate by a set of examples how a range of constructs may be encoded in F<:. These include record operations and subtyping hierarchies that are related to features of object-oriented languages.", "num_citations": "165\n", "authors": ["1611"]}
{"title": "An extension of system F with subtyping\n", "abstract": " System F is a well-known typed \u03bb-calculus with polymorphic types, which provides a basis for polymorphic programming languages. We study an extension of F, called F <:, that combines parametric polymorphism with subtyping.             The main focus of the paper is the equational theory of F <:, which is related to PER models and the notion of parametricity. We study some categorical properties of the theory when restricted to closed terms, including interesting categorical isomorphisms. We also investigate proof-theoretical properties, such as the conservativity of typing judgments with respect to F.             We demonstrate by a set of examples how a range of constructs may be encoded in F <:. These include record operations and subtyping hierarchies that are related to features of object-oriented languages.", "num_citations": "131\n", "authors": ["1611"]}
{"title": "A probabilistic polynomial-time process calculus for the analysis of cryptographic protocols\n", "abstract": " We prove properties of a process calculus that is designed for analysing security protocols. Our long-term goal is to develop a form of protocol analysis, consistent with standard cryptographic assumptions, that provides a language for expressing probabilistic polynomial-time protocol steps, a specification method based on a compositional form of equivalence, and a logical basis for reasoning about equivalence.The process calculus is a variant of CCS, with bounded replication and probabilistic polynomial-time expressions allowed in messages and boolean tests. To avoid inconsistency between security and nondeterminism, messages are scheduled probabilistically instead of nondeterministically. We prove that evaluation of any process expression halts in probabilistic polynomial time and define a form of asymptotic protocol equivalence that allows security properties to be expressed using observational\u00a0\u2026", "num_citations": "119\n", "authors": ["1611"]}
{"title": "Breaking and fixing public-key Kerberos\n", "abstract": " We report on a man-in-the-middle attack on PKINIT, the public key extension of the widely deployed Kerberos 5 authentication protocol. This flaw allows an attacker to impersonate Kerberos administrative principals (KDC) and end-servers to a client, hence breaching the authentication guarantees of Kerberos. It also gives the attacker the keys that the KDC would normally generate to encrypt the service requests of this client, hence defeating confidentiality as well. The discovery of this attack caused the IETF to change the specification of PKINIT and Microsoft to release a security update for some Windows operating systems. We discovered this attack as part of an ongoing formal analysis of the Kerberos protocol suite, and we have formally verified several possible fixes to PKINIT\u2014including the one adopted by the IETF\u2014that prevent our attack as well as other authentication and secrecy properties of Kerberos with\u00a0\u2026", "num_citations": "117\n", "authors": ["1611"]}
{"title": "Inductive methods and contract-signing protocols\n", "abstract": " Garay, Jakobsson and MacKenzie introduced the notion of abuse-free distributed contract-signing: at any stage of the protocol, no participant Ahas the ability to prove to an outside party, that A has the power to choose between completing the contract and aborting it. We study a version of this property, which is naturally formulated in terms of game strategies, and which we formally state and prove for a two-party, optimistic contract-signing protocol. We extend to this setting the formal inductive proof methods previously used in the formal analysis of simpler, trace-based properties of authentication protocols.", "num_citations": "98\n", "authors": ["1611"]}
{"title": "A categorical approach to realizability and polymorphic types\n", "abstract": " A categorical calculus of relations is used to derive a unified setting for higher order logic and polymorphic lambda calculus.", "num_citations": "97\n", "authors": ["1611"]}
{"title": "Key-dependent message security under active attacks\u2013BRSIM/UC-soundness of Dolev\u2013Yao-style encryption with key cycles\n", "abstract": " Key-dependent message (KDM) security was introduced by Black, Rogaway and Shrimpton to address the case where key cycles occur among encryptions, eg, a key is encrypted with itself. It was mainly motivated by key cycles in Dolev\u2013Yao models, ie, symbolic abstractions of cryptography by term algebras, and a corresponding computational soundness result was later shown by Ad\u00e3o et al. However, both the KDM definition and this soundness result do not allow the general active attacks typical for Dolev\u2013Yao models or for security protocols in general.", "num_citations": "94\n", "authors": ["1611"]}
{"title": "Formal analysis of multiparty contract signing\n", "abstract": " We analyze the multiparty contract-signing protocols of Garay and MacKenzie (GM) and of Baum and Waidner (BW). We use a finite-state tool, Mocha, which allows specification of protocol properties in a branching-time temporal logic with game semantics. While our analysis does not reveal any errors in the BW protocol, in the GM protocol we discover serious problems with fairness for four signers and an oversight regarding abuse-freeness for three signers. We propose a complete revision of the GM subprotocols in order to restore fairness.", "num_citations": "92\n", "authors": ["1611"]}
{"title": "A Brief Guide to Linear Logic.\n", "abstract": " An overview of linear logic is given, including an extensive bibliography and a simple example of the close relationship between linear logic and computation.", "num_citations": "88\n", "authors": ["1611"]}
{"title": "A formal analysis of some properties of Kerberos 5 using MSR\n", "abstract": " We give three formalizations of the Kerberos 5 authentication protocol in the Multi-Set Rewriting (MSR) formalism. One is a high-level formalization containing just enough detail to prove authentication and confidentiality properties of the protocol. A second formalization refines this by adding a variety of protocol options; we similarly refine proofs of properties in the first formalization to prove properties of the second formalization. Our third formalization adds timestamps to the first formalization but has not been analyzed extensively. The various proofs make use of rank and corank functions, inspired by work of Schneider in CSP, and provide examples of reasoning about real-world protocols in MSR. We also note some potentially curious protocol behavior; given our positive results, this does not compromise the security of the protocol.", "num_citations": "87\n", "authors": ["1611"]}
{"title": "Soundness of formal encryption in the presence of key-cycles\n", "abstract": " Both the formal and the computational models of cryptography contain the notion of message equivalence or indistinguishability. An encryption scheme provides soundness for indistinguishability if, when mapping formal messages into the computational model, equivalent formal messages are mapped to indistinguishable computational distributions. Previous soundness results are limited in that they do not apply when key-cycles are present. We demonstrate that an encryption scheme provides soundness in the presence of key-cycles if it satisfies the recently-introduced notion of key-dependent message (KDM) security. We also show that soundness in the presence of key-cycles (and KDM security) neither implies nor is implied by security against chosen ciphertext attack (CCA-2). Therefore, soundness for key-cycles is possible using a new notion of computational security, not possible using previous such\u00a0\u2026", "num_citations": "85\n", "authors": ["1611"]}
{"title": "Formal analysis of Kerberos 5\n", "abstract": " We report on the detailed verification of a substantial portion of the Kerberos 5 protocol specification. Because it targeted a deployed protocol rather than an academic abstraction, this multiyear effort led to the development of new analysis methods in order to manage the inherent complexity. This enabled proving that Kerberos supports the expected authentication and confidentiality properties, and that it is structurally sound; these results rely on a pair of intertwined inductions. Our work also detected a number of innocuous but nonetheless unexpected behaviors, and it clearly described how vulnerable the cross-realm authentication support of Kerberos is to the compromise of remote administrative domains.", "num_citations": "84\n", "authors": ["1611"]}
{"title": "Cryptographically sound security proofs for basic and public-key kerberos\n", "abstract": " We present a computational analysis of basic Kerberos and Kerberos with public-key authentication (PKINIT) in which we consider authentication and key secrecy properties. Our proofs rely on the Dolev-Yao style model of Backes, Pfitzmann and Waidner, which allows for mapping results obtained symbolically within this model to cryptographically sound proofs if certain assumptions are met. This is the most complex fragment of an industrial protocol that has yet been verified at the computational level. Considering a recently fixed version of PKINIT, we extend symbolic correctness results we previously attained in the Dolev-Yao model to cryptographically sound results in the computational model.", "num_citations": "83\n", "authors": ["1611"]}
{"title": "Relating state-based and process-based concurrency through linear logic (full-version)\n", "abstract": " This paper has the purpose of reviewing some of the established relationships between logic and concurrency, and of exploring new ones. Concurrent and distributed systems are notoriously hard to get right. Therefore, following an approach that has proved highly beneficial for sequential programs, much effort has been invested in tracing the foundations of concurrency in logic. The starting points of such investigations have been various idealized languages of concurrent and distributed programming, in particular the well established state-transformation model inspired by Petri nets and multiset rewriting, and the prolific process-based models such as the \u03c0-calculus and other process algebras. In nearly all cases, the target of these investigations has been linear logic, a formal language that supports a view of formulas as consumable resources. In the first part of this paper, we review some of these interpretations\u00a0\u2026", "num_citations": "81\n", "authors": ["1611"]}
{"title": "HEREDITARY HARROP FORMULAS AND UNIFORM PROOF SYSTEMS.\n", "abstract": " The authors are concerned with strengthening the logical foundations of the logic programming paradigm. In particular, they are interested in those logical systems whose provability predicate preserves a simple and natural search-related interpretation of the logical connectives. Proof systems which are sound and complete for this interpretation are called uniform proof systems. For the purposes of this paper, a logic programming language is identified with any logical system whose proof predicate is uniform. They present three logic programming languages which extend the positive Hern clause logic programming language. The most expressive language is based on hereditary Harrop formulas and uses higher-order intuitionistic logic as its proof system. Several metatheoretic properties of hereditary Harrop formulas are presented.", "num_citations": "79\n", "authors": ["1611"]}
{"title": "A linguistic characterization of bounded oracle computation and probabilistic polynomial time\n", "abstract": " We present a higher-order functional notation for polynomial-time computation with an arbitrary 0, 1-valued oracle. This formulation provides a linguistic characterization for classes such as NP and BPP, as well as a notation for probabilistic polynomial-time functions. The language is derived from Hofmann's adaptation of Bellantoni-Cook safe recursion, extended to oracle computation via work derived from that of Kapron and Cook. Like Hofmann's language, ours is an applied typed lambda calculus with complexity bounds enforced by a type system. The type system uses a modal operator to distinguish between two sorts of numerical expressions. Recursion can take place on only one of these sorts. The proof that the language captures precisely oracle polynomial time is model-theoretic, using adaptations of various techniques from category theory.", "num_citations": "76\n", "authors": ["1611"]}
{"title": "Notes on sconing and relators\n", "abstract": " This paper describes a semantics of typed lambda calculi based on relations. The main mathematical tool is a category-theoretic method of sconing, also called glueing or Freyd covers. Its correspondence to logical relations is also examined.", "num_citations": "74\n", "authors": ["1611"]}
{"title": "A probabilistic polynomial-time calculus for analysis of cryptographic protocols:(preliminary report)\n", "abstract": " We describe properties of a process calculus that has been developed for the purpose of analyzing security protocols. The process calculus is a restricted form of \u03c0-calculus, with bounded replication and probabilistic polynomial-time expressions allowed in messages and boolean tests. In order to avoid problems expressing security in the presence of nondeterminism, messages are scheduled probabilistically instead of nondeterministically. We prove that evaluation may be completed in probabilistic polynomial time and develop properties of a form of asymptotic protocol equivalence that allows security to be specified using observational equivalence, a standard relation from programming language theory that involves quantifying over possible environments that might interact with the protocol. We also relate process equivalence to cryptographic concepts such as pseudo-random number generators and\u00a0\u2026", "num_citations": "66\n", "authors": ["1611"]}
{"title": "Composition of cryptographic protocols in a probabilistic polynomial-time process calculus\n", "abstract": " We describe a probabilistic polynomial-time process calculus for analyzing cryptographic protocols and use it to derive compositionality properties of protocols in the presence of computationally bounded adversaries. We illustrate these concepts on oblivious transfer, an example from cryptography. We also compare our approach with a framework based on interactive Turing machines.", "num_citations": "64\n", "authors": ["1611"]}
{"title": "Probabilistic bisimulation and equivalence for security analysis of network protocols\n", "abstract": " Using a probabilistic polynomial-time process calculus designed for specifying security properties as observational equivalences, we develop a form of bisimulation that justifies an equational proof system. This proof system is sufficiently powerful to derive the semantic security of El Gamal encryption from the Decision Diffie-Hellman (DDH) assumption. The proof system can also derive the converse: if El Gamal is secure, then DDH holds. While these are not new cryptographic results, these example proofs show the power of probabilistic bisimulation and equational reasoning for protocol security.", "num_citations": "60\n", "authors": ["1611"]}
{"title": "Computational and information-theoretic soundness and completeness of formal encryption\n", "abstract": " We consider expansions of the Abadi-Rogaway logic of indistinguishability of formal cryptographic expressions. We expand the logic in order to cover cases when partial information of the encrypted plaintext is revealed. We consider not only computational, but also purely probabilistic, information-theoretic interpretations. We present a general, systematic treatment of the expansions of the logic for symmetric encryption. We establish general soundness and completeness theorems for the interpretations. We also present applications to specific settings not covered in earlier works: a purely probabilistic one based on one-time pad, and computational settings of the so-called type-2 (which-key revealing) and type-3 (which-key and length revealing) encryption schemes based on computational complexity.", "num_citations": "55\n", "authors": ["1611"]}
{"title": "Normal forms and cut-free proofs as natural transformations\n", "abstract": " What equations can we guarantee that simple functional programs must satisfy, irrespective of their obvious defining equations? Equivalently, what non-trivial identifications must hold between lambda terms, thought-of as encoding appropriate natural deduction proofs ? We show that the usual syntax guarantees that certain naturality equations from category theory are necessarily provable. At the same time, our categorical approach addresses an equational meaning of cut-elimination and asymmetrical interpretations of cut-free proofs. This viewpoint is connected to Reynolds\u2019 relational interpretation of parametricity ([27], [2]), and to the Kelly-Lambek-Mac Lane-Mints approach to coherence problems in category theory.", "num_citations": "50\n", "authors": ["1611"]}
{"title": "Maintaining distributed logic programs incrementally\n", "abstract": " Distributed logic programming languages, which allow both facts and programs to be distributed among different nodes in a network, have been recently proposed and used to declaratively program a wide-range of distributed systems, such as network protocols and multi-agent systems. However, the distributed nature of the underlying systems poses serious challenges to developing efficient and correct algorithms for evaluating these programs. This paper proposes an efficient asynchronous algorithm to compute incrementally the changes to the states in response to insertions and deletions of base facts. Our algorithm is formally proven to be correct in the presence of message reordering in the system. To our knowledge, this is the first formal proof of correctness for such an algorithm.", "num_citations": "47\n", "authors": ["1611"]}
{"title": "Specifying kerberos 5 cross-realm authentication\n", "abstract": " Cross-realm authentication is a useful and interesting component of Kerberos aimed at enabling secure access to services astride organizational boundaries. We present a formalization of Kerberos 5 cross-realm authentication in MSR, a specification language based on multiset rewriting. We also adapt the Dolev-Yao intruder model to the cross-realm setting and prove an important property for a critical field in a cross-realm ticket. Finally, we document several failures of authentication and confidentiality in the presence of compromised intermediate realms. Although the current Kerberos specifications disclaim responsibility for these vulnerabilities, the associated security implications must be highlighted for system administrators to decide whether to adopt this technology and to aid designers with future development.", "num_citations": "47\n", "authors": ["1611"]}
{"title": "Contract signing, optimism, and advantage\n", "abstract": " A contract signing protocol lets two parties exchange digital signatures on a pre-agreed text. Optimistic contract signing protocols enable the signers to do so without invoking a trusted third party. However, an adjudicating third party remains available should one or both signers seek timely resolution. We analyze optimistic contract signing protocols using a game-theoretic approach and prove a fundamental impossibility result: in any fair, optimistic, timely protocol, an optimistic player yields an advantage to the opponent. The proof relies on a careful characterization of optimistic play that postpones communication to the third party. Since advantage cannot be completely eliminated from optimistic protocols, we argue that the strongest property attainable is the absence of provable advantage, i.e., abuse-freeness in the sense of Garay-Jakobsson-MacKenzie.", "num_citations": "46\n", "authors": ["1611"]}
{"title": "Freyd's models for the independence of the axiom of choice\n", "abstract": " We relate Freyd's topos-theoretic models for the independence of the axiom of choice to the more familiar symmetric Boolean-valued models.", "num_citations": "46\n", "authors": ["1611"]}
{"title": "Computing with coercions\n", "abstract": " This paper relates two views of the operational semantics of a language with multiple inheritance. It is shown that the introduction of explicit coercions as an interpretation for the implicit coercion of inheritance does not affect the evaluation of a program in an essential way. The result is proved by semantic means using a denotational model and a computational adequacy result to relate the operational and denotational semantics.", "num_citations": "44\n", "authors": ["1611"]}
{"title": "Games and the impossibility of realizable ideal functionality\n", "abstract": " A cryptographic primitive or a security mechanism can be specified in a variety of ways, such as a condition involving a game against an attacker, construction of an ideal functionality, or a list of properties that must hold in the face of attack. While game conditions are widely used, an ideal functionality is appealing because a mechanism that is indistinguishable from an ideal functionality is therefore guaranteed secure in any larger system that uses it. We relate ideal functionalities to games by defining the set of ideal functionalities associated with a game condition and show that under this definition, which reflects accepted use and known examples, bit commitment, a form of group signatures, and some other cryptographic concepts do not have any realizable ideal functionality.", "num_citations": "41\n", "authors": ["1611"]}
{"title": "Interpreting strands in linear logic\n", "abstract": " The adoption of the Dolev-Yao model, an abstraction of security protocols that supports symbolic reasoning, is responsible for many successes in protocol analysis. In particular, it has enabled using logic effectively to reason about protocols. One recent framework for expressing the basic assumptions of the Dolev-Yao model is given by strand spaces, certain directed graphs whose structure reflects causal inter-actions among protocol participants. We represent strand constructions as relatively simple formulas in first-order linear logic, a refinement of traditional logic known for an intrinsic and natural accounting of process states, events, and resources. The proposed encoding is shown to be sound and complete. Interestingly, this encoding differs from the multiset rewriting definition of the Dolev-Yao model, which is also based on linear logic. This raises the possibility that the multiset rewriting framework may differ from strand spaces in some subtle way, although the two settings are known to agree on the basic secrecy property.Descriptors:", "num_citations": "41\n", "authors": ["1611"]}
{"title": "The undecidability of second order multiplicative linear logic\n", "abstract": " Decision problems for propositional (quantifier-free) linear logic were first studied by Lincoln et al.[LMSS]. In referring to linear logic fragments let M stand for multiplicative, A for additives, E for exponentials (or modalities), 1 for first order quantifiers, 2 for second order propositional quantifiers, and I for the``intuitionistic''version. In [LMSS] it was shown that full propositional linear logic is undecidable and that MALL is PSPACE-complete. The main problems left open in [LMSS] were the NP-completeness of MLL, the decidability of MELL, and the decidability of various fragments of propositional linear logic without exponentials but extended with second order propositional quantifiers. The decision problem for MELL is still open, but almost all the other problems have been solved: v The NP-completeness of MLL has been obtained by Kanovich [K1]. Moreover, Lincoln and Winkler [LW] have established that MLL without\u00a0\u2026", "num_citations": "41\n", "authors": ["1611"]}
{"title": "FSR: Formal analysis and implementation toolkit for safe interdomain routing\n", "abstract": " Interdomain routing stitches the disparate parts of the Internet together, making protocol stability a critical issue to both researchers and practitioners. Yet, researchers create safety proofs and counterexamples by hand and build simulators and prototypes to explore protocol dynamics. Similarly, network operators analyze their router configurations manually or using homegrown tools. In this paper, we present a comprehensive toolkit for analyzing and implementing routing policies, ranging from high-level guidelines to specific router configurations. Our Formally Safe Routing (FSR) toolkit performs all of these functions from the same algebraic representation of routing policy. We show that routing algebra has a natural translation to both integer constraints (to perform safety analysis with SMT solvers) and declarative programs (to generate distributed implementations). Our extensive experiments with realistic\u00a0\u2026", "num_citations": "37\n", "authors": ["1611"]}
{"title": "Intuitionistic set theory\n", "abstract": " Publisher SummaryThis chapter describes Friedman's contributions to intuitionistic set theory. These contributions include Friedman's extension of Gael's negative interpretation and Friedman's extension of Kleene's recursive realizability. One of the first significant results about intuitionistic systems was obtained in 1932 by Godel who gave a syntactical translation of classical predicate calculus into Heyting's predicate calculus. Thus the consistency of a system with classical logic is reduced to the consistency of a system with intuitionistic logic, and furthermore the classical system can be viewed as a subsystem (or a special case) of an intuitionistic one. Finally, the chapter discusses the partially intuitionistic fragments of ZFC for which Excluded Middle holds for an important class of formulas.", "num_citations": "36\n", "authors": ["1611"]}
{"title": "Soundness and completeness of formal encryption: The cases of key cycles and partial information leakage\n", "abstract": " In their seminal work, Abadi and Rogaway show that the formal (Dolev\u2013Yao) notion of indistinguishability is sound with respect to the computational model: messages that are indistinguishable in the formal model become indistinguishable messages in the computational model. However, this result leaves two problems unsolved. First, it cannot tolerate key cycles. Second, it makes the too-strong assumption that the underlying cryptography hides all aspects of the plaintext, including its length. In this paper we extend their work in order to address these problems.", "num_citations": "31\n", "authors": ["1611"]}
{"title": "Specifying real-time finite-state systems in linear logic\n", "abstract": " Real-time finite-state systems may be specified in linear logic by means of linear implications between conjunctions of fixed finite length. In this setting, where time is treated as a dense linear ordering, safety properties may be expressed as certain provability problems. These provability problems are shown to be in pspace. They are solvable, with some guidance, by finite proof search in concurrent logic programming environments based on linear logic and acting as sort of model-checkers. One advantage of our approach is that either it provides unsafe runs or it actually establishes safety.", "num_citations": "31\n", "authors": ["1611"]}
{"title": "Linear logic and computation: A survey\n", "abstract": " This is a survey of computational aspects of linear logic related to proof search.", "num_citations": "31\n", "authors": ["1611"]}
{"title": "Logic and Computer Science\n", "abstract": " Piergiorgio Odifreddi & Felice Cardone, Logic and Computer Science - PhilPapers Sign in | Create an account PhilPapers PhilPeople PhilArchive PhilEvents PhilJobs PhilPapers home Syntax Advanced Search Syntax Advanced Search Syntax Advanced Search Logic and Computer Science Piergiorgio Odifreddi & Felice Cardone (1990) Authors Piergiorgio Odifreddi Abstract This article has no associated abstract. (fix it) Keywords Logic programming Computer science Categories Areas of Mathematics in Philosophy of Mathematics (categorize this paper) Buy this book Find it on Amazon.com ISBN(s) 0125242204 Options Edit this record Mark as duplicate Export citation Find it on Scholar Request removal from index Revision history Download options PhilArchive copy Upload a copy of this paper Check publisher's policy Papers currently archived: 59,338 External links This entry has no external links. Add one. \u2026", "num_citations": "30\n", "authors": ["1611"]}
{"title": "A probabilistic polynomial-time calculus for analysis of cryptographic protocols\n", "abstract": " We prove properties of a process calculus that is designed for analyzing security protocols. Our long-term goal is to develop a form of protocol analysis, consistent with standard cryptographic assumptions, that provides a language for expressing probabilistic polynomial-time protocol steps, a specification method based on a compositional form of equivalence, and a logical basis for reasoning about equivalence.The process calculus is a restricted form of \u03c0-calculus, with bounded replication and probabilistic polynomial-time expressions allowed in messages and boolean tests. To avoid inconsistency between security and nondeterminism, messages are scheduled probabilistically instead of nondeterministically. We prove that evaluation of any process expression halts in probabilistic polynomial time and define a form of asymptotic protocol equivalence that allows security properties to be expressed using observational equivalence, a standard relation from programming language theory that involves quantifying over possible environments that might interact with the protocol. A technique based on a form of bisimulation is proved sufficient to establish basic instances of observational equivalences. The method is illustrated by showing that a standard cryptographic definition, the cryptographically strong pseudo-random number generator, is characterized by observational equivalence.", "num_citations": "29\n", "authors": ["1611"]}
{"title": "Cryptographically sound security proofs for basic and public-key Kerberos\n", "abstract": " We present a computational analysis of basic Kerberos with and without its public-key extension PKINIT in which we consider authentication and key secrecy properties. Our proofs rely on the Dolev\u2013Yao style model of Backes, Pfitzmann, and Waidner, which allows for mapping results obtained symbolically within this model to cryptographically sound proofs if certain assumptions are met. This work was the first verification at the computational level of such a complex fragment of an industrial protocol. By considering a recently fixed version of PKINIT, we extend symbolic correctness results we previously attained in the Dolev\u2013Yao model to cryptographically sound results in the computational model.", "num_citations": "28\n", "authors": ["1611"]}
{"title": "Classifying topoi and finite forcing\n", "abstract": " We show that Robinson's finite forcing, for a theory T, is a universal construction in the sense of categorical algebra: it is the satisfaction relation for the universal model in the classifying topos E of a certain universal Horn theory defined from T. Assuming, without loss of generality, that T is axiomatized by universal sentences, we construct, as sheaf subtopoi of E, the classifying topoi for (ie, universal examples of) finitely generic models, existentially closed models, and arbitrary models of T (with complemented primitive predicates).", "num_citations": "28\n", "authors": ["1611"]}
{"title": "Collaborative planning with confidentiality\n", "abstract": " Collaboration among organizations or individuals is common.While these participants are often unwilling to share all their information with each other, some information sharing is unavoidable when achieving a common goal. The need to share information and the desire to keep it confidential are two competing notions which affect the outcome of a collaboration. This paper proposes a formal model of collaboration which addresses confidentiality concerns. We draw on the notion of a plan which originates in the AI literature. We use data confidentiality policies to assess confidentiality in transition systems whose actions have an equal number of predicates in their pre- and post-conditions. Under two natural notions of policy compliance, we show that it is PSPACE-complete to schedule a plan leading from a given initial state to a desired goal state while simultaneously deciding compliance with respect to the\u00a0\u2026", "num_citations": "27\n", "authors": ["1611"]}
{"title": "Subexponentials in non-commutative linear logic\n", "abstract": " Linear logical frameworks with subexponentials have been used for the specification of, among other systems, proof systems, concurrent programming languages and linear authorisation logics. In these frameworks, subexponentials can be configured to allow or not for the application of the contraction and weakening rules while the exchange rule can always be applied. This means that formulae in such frameworks can only be organised as sets and multisets of formulae not being possible to organise formulae as lists of formulae. This paper investigates the proof theory of linear logic proof systems in the non-commutative variant. These systems can disallow the application of exchange rule on some subexponentials. We investigate conditions for when cut elimination is admissible in the presence of non-commutative subexponentials, investigating the interaction of the exchange rule with the local and non-local\u00a0\u2026", "num_citations": "26\n", "authors": ["1611"]}
{"title": "Phase semantics for light linear logic\n", "abstract": " Light linear logic [1] is a refinement of the propositions-as-types paradigm to polynomial-time computation. A semantic setting for the underlying logical system is introduced here in terms of fibred phase spaces. Strong completeness is established, with a purely semantic proof of cut elimination as a consequence. A number of mathematical examples of fibred phase spaces are presented that illustrate subtleties of light linear logic.", "num_citations": "24\n", "authors": ["1611"]}
{"title": "Bounded memory Dolev\u2013Yao adversaries in collaborative systems\n", "abstract": " In a collaborative system, the agents collaborate to achieve a common goal, but they are not willing to share some sensitive private information.The question is how much damage can be done by a malicious participant sitting inside the system.We assume that all the participants (including internal adversaries) have bounded memory \u2013 at any moment, they can store only a fixed number of messages of a fixed size. The Dolev\u2013Yao adversaries can compose, decompose, eavesdrop, and intercept messages, and create fresh values (nonces), but within their bounded memory.We prove that the secrecy problem is PSPACE-complete in the bounded memory model where all actions are balanced and a potentially infinite number of the nonce updates is allowed.We also show that the well-known security protocol anomalies (starting from the Lowe attack to the Needham\u2013Schroeder protocol) can be rephrased within the\u00a0\u2026", "num_citations": "22\n", "authors": ["1611"]}
{"title": "Phase semantics for light linear logic\n", "abstract": " Light linear logic (Girard, Inform. Comput. 14 (1998) 175\u2013204) is a refinement of the propositions-as-types paradigm to polynomial-time computation. A semantic setting for the underlying logical system is introduced here in terms of fibred phase spaces. Strong completeness is established, with a purely semantic proof of cut elimination as a consequence. A number of mathematical examples of fibred phase spaces are presented that illustrate subtleties of light linear logic.", "num_citations": "22\n", "authors": ["1611"]}
{"title": "A rewriting framework for activities subject to regulations\n", "abstract": " Activities such as clinical investigations or financial processes are subject to regulations to ensure quality of results and avoid negative consequences. Regulations may be imposed by multiple governmental agencies as well as by institutional policies and protocols. Due to the complexity of both regulations and activities there is great potential for violation due to human error, misunderstanding, or even intent. Executable formal models of regulations, protocols, and activities can form the foundation for automated assistants to aid planning, monitoring, and compliance checking. We propose a model based on multiset rewriting where time is discrete and is specified by timestamps attached to facts. Actions, as well as initial, goal and critical states may be constrained by means of relative time constraints. Moreover, actions may have non-deterministic effects, that is, they may have different outcomes whenever applied. We demonstrate how specifications in our model can be straightforwardly mapped to the rewriting logic language Maude, and how one can use existing techniques to improve performance. Finally, we also determine the complexity of the plan compliance problem, that is, finding a plan that leads from an initial state to a desired goal state without reaching any undesired critical state. We consider all actions to be balanced, that is, their pre and post-conditions have the same number of facts. Under this assumption on actions, we show that the plan compliance problem is PSPACE-complete when all actions have only deterministic effects and is EXPTIME-complete when actions may have non-deterministic effects.", "num_citations": "21\n", "authors": ["1611"]}
{"title": "Undecidability of the Lambek calculus with a relevant modality\n", "abstract": " Morrill and Valent\u00edn in the paper \u201cComputational coverage of TLG: Nonlinearity\u201d considered an extension of the Lambek calculus enriched by a so-called \u201cexponential\u201d modality. This modality behaves in the \u201crelevant\u201d style, that is, it allows contraction and permutation, but not weakening. Morrill and Valent\u00edn stated an open problem whether this system is decidable. Here we show its undecidability. Our result remains valid if we consider the fragment where all division operations have one direction. We also show that the derivability problem in a restricted case, where the modality can be applied only to variables (primitive types), is decidable and belongs to the NP class.", "num_citations": "20\n", "authors": ["1611"]}
{"title": "Relating state-based and process-based concurrency through linear logic\n", "abstract": " This paper has the purpose of reviewing some of the established relationships between logic and concurrency, and of exploring new ones.Concurrent and distributed systems are notoriously hard to get right. Therefore, following an approach that has proved highly beneficial for sequential programs, much effort has been invested in tracing the foundations of concurrency in logic. The starting points of such investigations have been various idealized languages of concurrent and distributed programming, in particular the well-established state-transformation model inspired to Petri nets and multiset rewriting, and the prolific process-based models such as the \u03c0-calculus and other process algebras. In nearly all cases, the target of these investigations has been linear logic, a formal language that supports a view of formulas as consumable resources. In the first part of this paper, we review some of these interpretations of\u00a0\u2026", "num_citations": "20\n", "authors": ["1611"]}
{"title": "Verifying confidentiality and authentication in kerberos 5\n", "abstract": " We present results from a recent project analyzing Kerberos 5. The main expected properties of this protocol, namely confidentiality and authentication, hold throughout the protocol. Our analysis also highlights a number of behaviors that do not follow the script of the protocol, although they do not appear harmful for the principals involved. We obtained these results by formalizing Kerberos 5 at two levels of detail in the multiset rewriting formalism MSR and by adapting an inductive proof methodology pioneered by Schneider. Our more detailed specification takes into account encryption types, flags and options, error messages, and a few timestamps.", "num_citations": "20\n", "authors": ["1611"]}
{"title": "A guide to polymorphic types\n", "abstract": " Types have now become an important ingredient of programming language design as a powerful, flexible syntax of a logic of program specifications that can be incorporated into a programming language itself. Types provide both a context for an organized, logical development of programs according to given specifications and a framework for a partial verification mechanism (see eg Breazu-Tannen et a i.[88]). These features are crucial in largescale programming efforts that require coordination among many teams of programmers.One of the most important aspects of recently developed programming languages such as 11L-like languages (Gordon et a i.[79], Milner [81, 1.], MacQueen [85], Cousineau [87]), Ada (Barnes (81]), Miranda (Turner (85]), and Clu (Liskov (81]) is the way in which they extend the conventional type systems in the Algol/Pascal family of programming languages: they feature polymorphic or\u00a0\u2026", "num_citations": "20\n", "authors": ["1611"]}
{"title": "Time, computational complexity, and probability in the analysis of distance-bounding protocols\n", "abstract": " Many security protocols rely on the assumptions on the physical properties in which its protocol sessions will be carried out. For instance, Distance Bounding Protocols take into account the round trip time of messages and the transmission velocity to infer an upper bound of the distance between two agents. We classify such security protocols as Cyber-Physical. Time plays a key role in design and analysis of many of these protocols. This paper investigates the foundational differences and the impacts on the analysis when using models with discrete time and models with dense time. We show that there are attacks that can be found by models using dense time, but not when using discrete time. We illustrate this with an attack that can be carried out on most Distance Bounding Protocols. In this attack, one exploits the execution delay of instructions during one clock cycle to convince a verifier that he is in a location\u00a0\u2026", "num_citations": "19\n", "authors": ["1611"]}
{"title": "Discrete vs. dense times in the analysis of cyber-physical security protocols\n", "abstract": " Many security protocols rely on the assumptions on the physical properties in which its protocol sessions will be carried out. For instance, Distance Bounding Protocols take into account the round trip time of messages and the transmission velocity to infer an upper bound of the distance between two agents. We classify such security protocols as Cyber-Physical. Time plays a key role in design and analysis of many of these protocols. This paper investigates the foundational differences and the impacts on the analysis when using models with discrete time and models with dense time. We show that there are attacks that can be found by models using dense time, but not when using discrete time. We illustrate this with a novel attack that can be carried out on most distance bounding protocols. In this attack, one exploits the execution delay of instructions during one clock cycle to convince a verifier that he is in\u00a0\u2026", "num_citations": "19\n", "authors": ["1611"]}
{"title": "Analyzing bgp instances in maude\n", "abstract": " Analyzing Border Gateway Protocol (BGP) instances is a crucial step in the design and implementation of safe BGP systems. Today, the analysis is a manual and tedious process. Researchers study the instances by manually constructing execution sequences, hoping to either identify an oscillation or show that the instance is safe by exhaustively examining all possible sequences. We propose to automate the analysis by using Maude, a tool based on rewriting logic. We have developed a library specifying a generalized path vector protocol, and methods to instantiate the library with customized routing policies. Protocols can be analyzed automatically by Maude, once users provide specifications of the network topology and routing policies. Using our Maude library, protocols or policies can be easily specified and checked for problems. To validate our approach, we performed safety analysis of well-known\u00a0\u2026", "num_citations": "19\n", "authors": ["1611"]}
{"title": "Policy compliance in collaborative systems\n", "abstract": " When collaborating agents share sensitive information to achieve a common goal it would be helpful to them to decide whether doing so will lead to an unwanted release of confidential data. These decisions are based on which other agents are involved, what those agents can do in the given context, and the individual confidentiality preferences of each agent. In this paper we consider a model of collaboration in which each agent has an explicit confidentiality policy. We offer three ways to interpret policy compliance (system compliance, plan compliance and weak plan compliance) corresponding to different levels of trust among the agents. We show it is EXPSPACE-complete to determine whether a given system is compliant and whether the agents can collaboratively reach a given common goal. On the other hand, we show it is undecidable to determine whether a given system has either a compliant plan or a\u00a0\u2026", "num_citations": "19\n", "authors": ["1611"]}
{"title": "\u03bbProlog: An extended logic programming language\n", "abstract": " The logic programming language AProlog is an extension of conventional Prolog in several different directions. These extensions provide higher-order functions, A-terms, a polymorphic typing discipline, modules, and a mechanism for providing secure abstract datatypes. Our original goal in developing AProlog was to understand the essential logical and proof theoretic nature of these extensions. This work has led us to describe a class of formulas called higher-order hereditary ttarrop formulas which play a role in AProlog that is similar to the role of positive Horn clauses in Prolog. This extended class of formulas permits stronger forms of logical reasoning than can be found in Prolog. For example, it allows universal quantification and implications into the bodies of program clauses as well as some forms of higher-order quantification. Higher-order hereditary Harrop formulas, therefore, significantly extend positive\u00a0\u2026", "num_citations": "19\n", "authors": ["1611"]}
{"title": "When not all bits are equal: Worth-based information flow\n", "abstract": " Only recently have approaches to quantitative information flow started to challenge the presumption that all leaks involving a given number of bits are equally harmful. This paper proposes a framework to capture the semantics of information, making quantification of leakage independent of the syntactic representation of secrets. Secrets are defined in terms of fields, which are combined to form structures; and a worth assignment is introduced to associate each structure with a worth (perhaps in proportion to the harm that would result from disclosure). We show how worth assignments can capture inter-dependence among structures within a secret, modeling: (i) secret sharing, (ii) information-theoretic predictors, and (iii) computational (as opposed to information-theoretic) guarantees for security. Using non-trivial worth assignments, we generalize Shannon entropy, guessing entropy, and probability of\u00a0\u2026", "num_citations": "18\n", "authors": ["1611"]}
{"title": "Analysis of EAP-GPSK authentication protocol\n", "abstract": " The EAP-GPSK protocol is a lightweight, flexible authentication protocol relying on symmetric key cryptography. It is part of an ongoing IETF process to develop authentication methods for the EAP framework. We analyze the protocol and find three weaknesses: a repairable Denial-of-Service attack, an anomaly with the key derivation function used to create a short-term master session key, and a ciphersuite downgrading attack. We propose fixes to these anomalies, and use a finite-state verification tool to search for remaining problems after making these repairs. We then prove the fixed version correct using a protocol verification logic. We discussed the attacks and our suggested fixes with the authors of the specification document which has subsequently been modified to include our proposed changes.", "num_citations": "18\n", "authors": ["1611"]}
{"title": "Contract signing, optimism, and advantage\n", "abstract": " A contract signing protocol lets two parties exchange digital signatures on a pre-agreed text. Optimistic contract signing protocols enable the signers to do so without invoking a trusted third party. However, an adjudicating third party remains available should one or both signers seek timely resolution. We analyze optimistic contract signing protocols using a game-theoretic approach and prove a fundamental impossibility result: in any fair, optimistic, timely protocol, an optimistic player yields an advantage to the opponent. The proof relies on a careful characterization of optimistic play that postpones communication to the third party.", "num_citations": "18\n", "authors": ["1611"]}
{"title": "Some semantic aspects of polymorphic lambda calculus\n", "abstract": " A simple relational framework is used in obtaining new characterizations of partial recursive functions and higher-order partial recursive functionals from the point of view of models for polymorphic lambda calculus. This framework also enables us to establish the higher-order expressive power of polymorphic terms. the parameter-binding mechanisms and data type abstraction in functional programming languages. Such features are present to a certain extent in languages CLU, Ada, ML and HOPE (see", "num_citations": "18\n", "authors": ["1611"]}
{"title": "Reduction-based formal analysis of bgp instances\n", "abstract": " Today\u2019s Internet interdomain routing protocol, the Border Gateway Protocol (BGP), is increasingly complicated and fragile due to policy misconfigurations by individual autonomous systems (ASes). These misconfigurations are often difficult to manually diagnose beyond a small number of nodes due to the state explosion problem. To aid the diagnosis of potential anomalies, researchers have developed various formal models and analysis tools. However, these techniques do not scale well or do not cover the full set of anomalies. Current techniques use oversimplified BGP models that capture either anomalies within or across ASes, but not the interactions between the two. To address these limitations, we propose a novel approach that reduces network size prior to analysis, while preserving crucial BGP correctness properties. Using Maude, we have developed a toolkit that takes as input a network instance\u00a0\u2026", "num_citations": "16\n", "authors": ["1611"]}
{"title": "Computer Security is not a Science (but it should be)\n", "abstract": " Introduction Security research is sometimes referred to as the\" Humanities of Computer Science\" because, too frequently,\" secure\" systems are built using equal measures of folklore and black arts. Despite the humorous intention, there is a kernel of truth in this jest---computer security, at least\" security in the large\", is not currently a science. This claim may seem unfair, given the progress made in security over the past decades. However, our present tools and methodologies are at most adequate for understanding systems security on a small scale. Cryptography, for example, is perhaps the most thoroughly studied and most rigorously modeled aspect of security. Despite its tremendous importance, cryptography alone is not sufficient for building secure systems. Indeed, the vast majority of all security flaws arise because of faulty software (eg, the ubiquitous buffer overflow problem). Such security holes cannot be avoided by cryptographic techniques, and despite widely known and", "num_citations": "16\n", "authors": ["1611"]}
{"title": "Semantic parametricity in polymorphic lambda calculus\n", "abstract": " A semantic condition necessary for the parametricity of polymorphic functions is considered. One of its instances is the stability condition for elements of variable type in the coherent domains semantics. A larger setting is presented that does not use retract pairs and keeps intact a basic feature of a certain function-type constructor. Polymorphic lambda terms are semantically parametric because of normalization.<>", "num_citations": "16\n", "authors": ["1611"]}
{"title": "A logical framework with commutative and non-commutative subexponentials\n", "abstract": " Logical frameworks allow the specification of deductive systems using the same logical machinery. Linear logical frameworks have been successfully used for the specification of a number of computational, logics and proof systems. Its success relies on the fact that formulas can be distinguished as linear, which behave intuitively as resources, and unbounded, which behave intuitionistically. Commutative subexponentials enhance the expressiveness of linear logic frameworks by allowing the distinction of multiple contexts. These contexts may behave as multisets of formulas or sets of formulas. Motivated by applications in distributed systems and in type-logical grammar, we propose a linear logical framework containing both commutative and non-commutative subexponentials. Non-commutative subexponentials can be used to specify contexts which behave as lists, not multisets, of formulas. In addition\u00a0\u2026", "num_citations": "15\n", "authors": ["1611"]}
{"title": "Declarative privacy policy: finite models and attribute-based encryption\n", "abstract": " Regulations and policies regarding Electronic Health Information (EHI) are increasingly complex. Federal and State policy makers have called for both education to increase stakeholder understanding of complex policies and improved systems that impose policy restrictions on access and transmission of EHI. Building on prior work formalizing privacy laws as logic programs, we prove that for any privacy policy that conforms to patterns evident in HIPAA, there exists a finite representative hospital database that illustrates how the law applies in all possible hospitals. This representative illustrative example can support new education, new policy development, and new policy debugging tools. Addressing the need for secure transmission of usable EHI, we show how policy formalized as a logic program can also be used to automatically generate a form of access control policy used in Attribute-Based Encryption (ABE\u00a0\u2026", "num_citations": "15\n", "authors": ["1611"]}
{"title": "Normal i Zat i on Rev is it ed\n", "abstract": " We give a semantic proof of normal ization for second-order polymorphic lambda calculus, that every polymorphic lambda term may be reduced to an irreducible one in finitely many steps.", "num_citations": "15\n", "authors": ["1611"]}
{"title": "Polynomially graded logic I. A graded version of system T\n", "abstract": " An investigation is made of a logical framework for programming languages which treats requirements on computation resources as part of the formal program specification. Resource bounds are explicit in the syntax of all programs. In a programming language based on this approach, compliance of a program with imposed resource bounds would be assured by verifying the syntactic correctness using a compiler with a static type checking feature. The principal innovation is the introduction of systems of logical inference, called polynomially graded logics. These logics make resource bounds part of every proposition and every deduction. The sample calculus presented is a restriction of Godel's system T to polynomial time resources. It is proved that the numerical functions representable in this calculus are exactly the PTIME functions.<>", "num_citations": "15\n", "authors": ["1611"]}
{"title": "A rewriting framework and logic for activities subject to regulations\n", "abstract": " Activities such as clinical investigations (CIs) or financial processes are subject to regulations to ensure quality of results and avoid negative consequences. Regulations may be imposed by multiple governmental agencies as well as by institutional policies and protocols. Due to the complexity of both regulations and activities, there is great potential for violation due to human error, misunderstanding, or even intent. Executable formal models of regulations, protocols and activities can form the foundation for automated assistants to aid planning, monitoring and compliance checking. We propose a model based on multiset rewriting where time is discrete and is specified by timestamps attached to facts. Actions, as well as initial, goal and critical states may be constrained by means of relative time constraints. Moreover, actions may have non-deterministic effects, i.e. they may have different outcomes whenever applied\u00a0\u2026", "num_citations": "14\n", "authors": ["1611"]}
{"title": "Games and the impossibility of realizable ideal functionality\n", "abstract": " A cryptographic primitive or a security mechanism can be specified in a variety of ways, such as a condition involving a game against an attacker, construction of an ideal functionality, or a list of properties that must hold in the face of attack. While game conditions are widely used, an ideal functionality is appealing because a mechanism that is indistinguishable from an ideal functionality is therefore guaranteed secure in any larger system that uses it. We relate ideal functionalities to games by defining the set of ideal functionalities associated with a game condition and show that under this definition, which reflects accepted use and known examples, a number of cryptographic concepts do not have any realizable ideal functionality in the plain model. Some interesting examples are multiparty coin-tossing, bit-commitment and shared random sequences. One interpretation of this negative result is that equational approaches based on computational observational equivalence might be better applied to reasoning about game conditions than equivalence with ideal functionalities. Alternatively, generality might be obtained by allowing for various setup assumptions, or by other means.", "num_citations": "14\n", "authors": ["1611"]}
{"title": "Complete topoi representing models of set theory\n", "abstract": " By a model of set theory we mean a Boolean-valued model of Zermelo-Fraenkel set theory allowing atoms (ZFA), which contains a copy of the ordinary universe of (two-valued, pure) sets as a transitive subclass; examples include Scott-Solovay Boolean-valued models and their symmetric submodels, as well as Fraenkel-Mostowski permutation models. Any such model M can be regarded as a topos. A logical subtopos E of M is said to represent M if it is complete and its cumulative hierarchy, as defined by Fourman and Hayashi, coincides with the usual cumulative hierarchy of M. We show that, although M need not be a complete topos, it has a smallest complete representing subtopos, and we describe this subtopos in terms of definability in M. We characterize, again in terms of definability, those models M whose smallest representing topos is a Grothendieck topos. Finally, we discuss the extent to which a model\u00a0\u2026", "num_citations": "14\n", "authors": ["1611"]}
{"title": "Bounded memory protocols and progressing collaborative systems\n", "abstract": " It is well-known that the Dolev-Yao adversary is a powerful adversary. Besides acting as the network, intercepting, sending, and composing messages, he can remember as much information as he needs. That is, his memory is unbounded. We recently proposed a weaker Dolev-Yao like adversary, which also acts as the network, but whose memory is bounded. We showed that this Bounded Memory Dolev-Yao adversary, when given enough memory, can carry out many existing protocol anomalies. In particular, the known anomalies arise for bounded memory protocols, where there is only a bounded number of concurrent sessions and the honest participants of the protocol cannot remember an unbounded number of facts nor an unbounded number of nonces at a time. This led us to the question of whether it is possible to infer an upper-bound on the memory required by the Dolev-Yao adversary to carry\u00a0\u2026", "num_citations": "13\n", "authors": ["1611"]}
{"title": "Extending G\u00f6del's modal interpretation to type theory and set theory\n", "abstract": " Publisher SummaryHeyting's propositional calculus can be embedded in Lewis's modal propositional calculus S4, as exhibited by Godel. Thus, S4 conservatively contains both classical and intuitionistic propositional calculi. It is also observed that using topological Boolean algebras, a similar interpretation can be extended to the predicate calculus without equality. When attempting to build type theory or set theory based on S4, one has to be careful with comprehension. The chapter describes an extensional type theory based on S4. This theory exhibits existence and disjunction properties and the intiutionistic type theory can be interpreted in it. The chapter considers the topological interpretation of S4 logic without restricting to the first-order case. The intuitionistic Zermelo-Fraenkel set theory (ZF) can be interpreted in set theory based on S4. The chapter also formulates a higher-order S4 calculus containing all\u00a0\u2026", "num_citations": "13\n", "authors": ["1611"]}
{"title": "Resource-bounded intruders in denial of service attacks\n", "abstract": " Denial of Service (DoS) attacks have been a serious security concern, as no service is, in principle, protected against them. Although a Dolev-Yao intruder with unlimited resources can trivially render any service unavailable, DoS attacks do not necessarily have to be carried out by such (extremely) powerful intruders. It is useful in practice and more challenging for formal protocol verification to determine whether a service is vulnerable even to resource-bounded intruders that cannot generate or intercept arbitrary large volumes of traffic. This paper proposes a novel, more refined intruder model where the intruder can only consume at most some specified amount of resources in any given time window. Additionally, we propose protocol theories that may contain timeouts and specify service resource usage during protocol execution. In contrast to the existing resource-conscious protocol verification models, our model\u00a0\u2026", "num_citations": "12\n", "authors": ["1611"]}
{"title": "Undecidability of the Lambek calculus with subexponential and bracket modalities\n", "abstract": " The Lambek calculus is a well-known logical formalism for modelling natural language syntax. The original calculus covered a substantial number of intricate natural language phenomena, but only those restricted to the context-free setting. In order to address more subtle linguistic issues, the Lambek calculus has been extended in various ways. In particular, Morrill and Valent\u00edn (2015) introduce an extension with so-called exponential and bracket modalities. Their extension is based on a non-standard contraction rule for the exponential that interacts with the bracket structure in an intricate way. The standard contraction rule is not admissible in this calculus. In this paper we prove undecidability of the derivability problem in their calculus. We also investigate restricted decidable fragments considered by Morrill and Valent\u00edn and we show that these fragments belong to the NP class.", "num_citations": "12\n", "authors": ["1611"]}
{"title": "Diagonalization of continuous matrices as a representation of intuitionistic reals\n", "abstract": " We use topological models of intuitionistic analysis to answer some of the recent questions of Kadison [7] concerning diagonalization of matrices of continuous functions. Let X be a compact Hausdorff space, and let%(X) be the ring of continuous real functions on X. In the topological interpretation of intuitionistic analysis over X [3],%(X) represents the internal set of (Dedekind) reals. Thus we can address the questions from [7] simply by intuitionistic examination of elementary linear algebra. We show that for O-dimensional spaces X, diagonalization of y1 x rz symmetric matrices over q (X) is characterized by requiring that any two disjoint open F, sets have disjoint closures, ie X is an F-space [4, 5]. In fact, we obtain this result as a consequence of a stronger, internal intuitionistic result. Internally, the condition states that the ordering 6 on Dedekind reals is a linear ordering.", "num_citations": "12\n", "authors": ["1611"]}
{"title": "A note on the Friedman slash and Freyd covers\n", "abstract": " Publisher SummaryThis chapter describes the Friedman slash and Freyd covers and provides a proof that F* can be described in purely categorical terms from the Freyd cover from which Friedman's method can be reconstructed. Kleene's method [K] for proving the disjunction and existence properties (DP, EP) for HA was further developed and extended to intuitionistic type theory. Freyd independently gave an elegant proof of DP and EP for higher-order intuitionistic arithmetic (HAH), avoiding explicit syntactic constructions of but relying instead on general topos-theoretic facts on glueing of toposes. Both methods are essentially the same, by defining an elementary topos that embodies Friedman's notion of realizability and then showing that this topos is a subtopos of the topos (SetsCr) obtained by glueing the free topos and the topos of Sets along the global section functor F\u2192Sets. Thus, Freyd's use of retracts and\u00a0\u2026", "num_citations": "12\n", "authors": ["1611"]}
{"title": "Timed multiset rewriting and the verification of time-sensitive distributed systems\n", "abstract": " Time-Sensitive Distributed Systems (TSDS), such as applications using autonomous drones, achieve goals under possible environment interference (e.g., winds). Moreover, goals are often specified using explicit time constraints which must be satisfied by the system perpetually. For example, drones carrying out the surveillance of some area must always have recent pictures, i.e., at most M time units old, of some strategic locations. This paper proposes a Multiset Rewriting language with explicit time for specifying and analysing TSDSes. We introduce two properties, realizability (some trace is good) and survivability (where, in addition, all admissible traces are good). A good trace is an infinite trace in which goals are perpetually satisfied. We propose a class of systems called progressive timed systems (PTS), where intuitively only a finite number of actions can be carried out in a bounded time period. We\u00a0\u2026", "num_citations": "11\n", "authors": ["1611"]}
{"title": "Automated synthesis of reactive controllers for software-defined networks\n", "abstract": " With the tremendous growth of the Internet and the emerging software-defined networks, there is an increasing need for rigorous and scalable network management methods and tool support. This paper proposes a synthesis approach for managing software-defined networks. We formulate the construction of network control logic as a reactive synthesis problem which is solvable with existing synthesis tools. The key idea is to synthesize a strategy that manages control logic in response to network changes while satisfying some network-wide specification. Finally, we investigate network abstractions for scalability. For large networks, instead of synthesizing control logic directly, we use its abstraction-a smaller network that simulates its behavior-for synthesis, and then implement the synthesized control on the original network while preserving the correctness. By using the so-called simulation relations, we also prove\u00a0\u2026", "num_citations": "11\n", "authors": ["1611"]}
{"title": "Bounded memory Dolev-Yao adversaries in collaborative systems\n", "abstract": " This paper extends existing models for collaborative systems. We investigate how much damage can be done by insiders alone, without collusion with an outside adversary. In contrast to traditional intruder models, such as in protocol security, all the players inside our system, including potential adversaries, have similar capabilities. They have bounded storage capacity, that is, they can only remember at any moment a bounded number of facts. This is technically imposed by only allowing balanced actions, that is, actions that have the same number of facts in their pre and post conditions. On the other hand, the adversaries inside our system have many capabilities of the standard Dolev-Yao intruder, namely, they are able, within their bounded storage capacity, to compose, decompose, overhear, and intercept messages as well as update values with fresh ones. We investigate the complexity of the decision\u00a0\u2026", "num_citations": "11\n", "authors": ["1611"]}
{"title": "Collaborative planning with privacy\n", "abstract": " Collaboration among organizations or individuals is common. While these participants are often unwilling to share all their information with each other, some information sharing is unavoidable when achieving a common goal. The need to share information and the desire to keep it private/ secret are two competing notions which affect the outcome of a collaboration. This paper proposes a formal model of collaboration which addresses privacy/secrecy concerns. We draw on the notion of a plan which originates in the AI literature. We consider transition systems in which actions have pre- and post-conditions of the same size. We show it is PSPACE-complete to decide whether a given such system protects the privacy/secrecy of its participants and whether it contains a plan leading from a given initial state to a desired goal state.", "num_citations": "11\n", "authors": ["1611"]}
{"title": "Boolean classifying topoi\n", "abstract": " Let \u03bb be a finitary geometric theory and \u03b4 its classifying topos. We prove that \u03b4 is Boolean if and only if (1) every first-order formula in the language of \u03bb is \u29f8-provably equivalent to a geometric formula and (2) for any finite list of varibles, x, there are, up to \u29f8-provable equivalence, only finitely many formulas, in the language of \u03bb with free variables among x. We use this characterization to show that, when \u03b4 is Boolean, it is an atomic topos and can be viewed as a finite coproduct of topoi of continuous G-sets for topological groups G satisfying a certain finiteness condition.", "num_citations": "11\n", "authors": ["1611"]}
{"title": "Towards timed models for cyber-physical security protocols\n", "abstract": " Many security protocols rely on the assumptions on the physical properties in which its protocol sessions will be carried out. For instance, Distance Bounding Protocols take into account the round trip time of messages and the transmission velocity to infer an upper bound of the distance between two agents. We classify such security protocols as cyber-physical. The key elements of such protocols are the use of cryptographic keys, nonces and time. This paper investigates timed models for the verification of such protocols. Firstly, we introduce a multiset rewriting framework with continuous time and fresh values. We demonstrate that in this framework one can specify distance bounding protocols and intruder models for cyberphysical security protocols that take into account the physical properties of the environment. We then investigate how the models with continuous time relate to models with discrete time in protocol verification and show that there is a difference between these models in exposing security flaws. This is done by proposing a protocol and demonstrating that there is no attack to this protocol when using the model with discrete time, but there is an attack when using the model with continuous time. For the important class of Bounded Memory Cyber-Physical Security Protocols with a Memory Bounded Intruder the reachability problem is PSPACE-complete if the size of terms is bounded.", "num_citations": "10\n", "authors": ["1611"]}
{"title": "Towards an automated assistant for clinical investigations\n", "abstract": " Before a drug can be made available to the general public, its effectiveness has to be experimentally evaluated. Experiments that involve human subjects are called Clinical Investigations (CIs). Since human subjects are involved, procedures for CIs are elaborated so that data required for validating the drug can be collected while ensuring the safety of subjects. Moreover, CIs are heavily regulated by public agencies, such as the Food and Drug Administration (FDA). Violations of regulations or deviations from procedures should be avoided as they may incur heavy penalties and more importantly may compromise the health of subjects. However, CIs are prone to human error, since CIs are carried out by the study team, which might be overloaded with other tasks, such as hospital and/or pharmacy duties, other trials, etc. In order to avoid discrepancies, we propose developing an automated assistant for helping all the\u00a0\u2026", "num_citations": "9\n", "authors": ["1611"]}
{"title": "Progressing collaborative systems\n", "abstract": " This paper builds on existing models for collaborative systems with confidentiality policies. The actions in these models are balanced, namely, they have an equal number of facts in their pre-and postconditions. Here we consider a further restriction that each instance of an action is used at most once in a process. Administrative processes usually involve such progressing behavior, that is, whenever a transaction is performed, it does not need to be repeated. We investigate the complexity of the decision problem whether there exists a sequence of transitions from an initial state to a final state that avoids any critical states, eg, states which conflict with the given confidentiality policies. We show that this problem is NP-complete when balanced actions do not involve fresh values and when the system is progressing. The same problem is shown to be PSPACE-complete when the system is not progressing, and PSPACE-hard when the system is progressing, but when actions may update values with fresh ones. The bounds hold even when balanced actions change only one fact in a configuration. We implement some examples in logic-based verification tools and model-check that they comply with certain policies.", "num_citations": "9\n", "authors": ["1611"]}
{"title": "The complexity of multiplicative-additive Lambek calculus: 25 years later\n", "abstract": " The Lambek calculus was introduced as a mathematical description of natural languages. The original Lambek calculus is NP-complete (Pentus), while its product-free fragment with only one implication is polynomially decidable (Savateev). We consider Lambek calculus with the additional connectives: conjunction and disjunction. It is known that this system is PSPACE-complete (Kanovich, Kanazawa). We prove, in contrast with the polynomial-time result for the product-free Lambek calculus with one implication, that the derivability problem is still PSPACE-complete even for a very small fragment , including one implication and conjunction only. PSPACE-completeness is also provided for the  fragment, which includes only one implication and disjunction. Categorial grammars based on the original Lambek calculus generate exactly the class of context-free languages (Gaifman, Pentus). The class of languages\u00a0\u2026", "num_citations": "8\n", "authors": ["1611"]}
{"title": "A multiset rewriting model for specifying and verifying timing aspects of security protocols\n", "abstract": " Catherine Meadows has played an important role in the advancement of formal methods for protocol security verification. Her insights on the use of, for example, narrowing and rewriting logic has made possible the automated discovery of new attacks and the shaping of new protocols. Meadows has also investigated other security aspects, such as, distance-bounding protocols and denial of service attacks. We have been greatly inspired by her work. This paper describes the use of Multiset Rewriting for the specification and verification of timing aspects of protocols, such as network delays, timeouts, timed intruder models and distance-bounding properties. We detail these timed features with a number of examples and describe decidable fragments of related verification problems.", "num_citations": "8\n", "authors": ["1611"]}
{"title": "Statistical model checking of distance fraud attacks on the Hancke-Kuhn family of protocols\n", "abstract": " Distance-bounding (DB) protocols protect against relay attacks on proximity-based access control systems. In a DB protocol, the verifier computes an upper bound on the distance to the prover by measuring the time-of-flight of exchanged messages. DB protocols are, however, vulnerable to distance fraud, in which a dishonest prover is able to manipulate the distance bound computed by an honest verifier. Despite their conceptual simplicity, devising a formal characterization of DB protocols and distance fraud attacks that is amenable to automated formal analysis is non-trivial, primarily because of their real-time and probabilistic nature. In this work, we introduce a generic, computational model, based on Rewriting Logic, for formally analyzing various forms of distance fraud, including recently identified timing attacks, on the Hancke-Kuhn family of DB protocols through statistical model checking. While providing an\u00a0\u2026", "num_citations": "8\n", "authors": ["1611"]}
{"title": "Lindenbaum algebras of intuitionistic theories and free categories\n", "abstract": " We consider formal theories synonymous with various free categories (logoi and topoi). Their Lindenbaum algebras may be described as the lattices of subobjects of a terminator. These theories have intuitionistic logic. We show that the Lindenbaum algebras of second order and higher order arithmetic (topoi), and set theory are not isomorphic to the Lindenbaum algebras of first order theories such as arithmetic (logoi). We also show that there are only five kernels of representations of the free Heyting algebra on one generator in these Lindenbaum algebras.", "num_citations": "8\n", "authors": ["1611"]}
{"title": "Independence of the fan theorem in the presence of continuity principles\n", "abstract": " Publisher SummaryCompactness of 2N plays an important role in the development of intuitionistic analysis and is known as \u201cthe Fan theorem (FT),\u201d which implies local compactness of the reals and is itself a consequence of the principle of bar induction (BI). This chapter describes the independence of the FT in the presence of continuity principles. It has been shown by Fourman and Hyland (FH) that both BI and FT can fail in sheaves over Heyting algebras (cHa), thus showing independence from higher-order intuitionistic arithmetic (HAH) and from intuitionistic set theory (ZFI). FT is independent of ZFI, and the construction preserves additional assumptions on functions as well. Thus, one gets independence of FT from ZFI with Brouwer theorem. Arithmetic + power sets (HAH) suffices for the construction presented in the chapter, giving independence results with respect to HAH, and working on the level of ZFI gives\u00a0\u2026", "num_citations": "8\n", "authors": ["1611"]}
{"title": "A polynomial time algorithm for the Lambek calculus with brackets of bounded order\n", "abstract": " Lambek calculus is a logical foundation of categorial grammar, a linguistic paradigm of grammar as logic and parsing as deduction. Pentus (2010) gave a polynomial-time algorithm for determ- ining provability of bounded depth formulas in the Lambek calculus with empty antecedents allowed. Pentus' algorithm is based on tabularisation of proof nets. Lambek calculus with brackets is a conservative extension of Lambek calculus with bracket modalities, suitable for the modeling of syntactical domains. In this paper we give an algorithm for provability the Lambek calculus with brackets allowing empty antecedents. Our algorithm runs in polynomial time when both the formula depth and the bracket nesting depth are bounded. It combines a Pentus-style tabularisation of proof nets with an automata-theoretic treatment of bracketing.", "num_citations": "7\n", "authors": ["1611"]}
{"title": "On Lambek\u2019s restriction in the presence of exponential modalities\n", "abstract": " The Lambek calculus can be considered as a version of non-commutative intuitionistic linear logic. One of the interesting features of the Lambek calculus is the so-called \u201cLambek\u2019s restriction,\u201d that is, the antecedent of any provable sequent should be non-empty. In this paper we discuss ways of extending the Lambek calculus with the linear logic exponential modality while keeping Lambek\u2019s restriction. We present several versions of the Lambek calculus extended with exponential modalities and prove that those extensions are undecidable, even if we take only one of the two divisions provided by the Lambek calculus.", "num_citations": "7\n", "authors": ["1611"]}
{"title": "Denotational semantics for subtyping between recursive types\n", "abstract": " Inheritance in the form of subtyping is considered in the framework of a polymorphic type discipline with records, variants, and recursive types. We give a denotational semantics based on the paradigm that interprets subtyping as explicit coercion. The main technical result gives a coherent interpretation for a strong rule for deriving inheritances between recursive types.", "num_citations": "7\n", "authors": ["1611"]}
{"title": "Intuitionistically provable recursive well-orderings\n", "abstract": " We consider intuitionistic number theory with recursive infinitary rules (HA*). Any primitive recursive binary relation for which transfinite induction schema is provable is in fact well founded. Its ordinal is less than \u03b50 if the transfinite induction schema is intuitionistically provable in elementary number theory. These results are provable intuitionistically. In fact, it suffices to consider transfinite induction with respect to one particular number-theoretic property.", "num_citations": "7\n", "authors": ["1611"]}
{"title": "Compliance in real time multiset rewriting models\n", "abstract": " The notion of compliance in Multiset Rewriting Models (MSR) has been introduced for untimed models and for models with discrete time. In this paper we revisit the notion of compliance and adapt it to fit with additional nondeterminism specific for dense time domains. Existing MSR with dense time are extended with critical configurations and non-critical traces, that is, traces involving no critical configurations. Complexity of related {\\em non-critical reachability problem} is investigated. Although this problem is undecidable in general, we prove that for balanced MSR with dense time the non-critical reachability problem is PSPACE-complete.", "num_citations": "6\n", "authors": ["1611"]}
{"title": "Bounded memory protocols\n", "abstract": " It is well-known that the Dolev\u2013Yao adversary is a powerful adversary. Besides acting as the network, intercepting, decomposing, composing and sending messages, he can remember as much information as he needs. That is, his memory is unbounded. We recently proposed a weaker Dolev\u2013Yao like adversary, which also acts as the network, but whose memory is bounded. We showed that this Bounded Memory Dolev\u2013Yao adversary, when given enough memory, can carry out many existing protocol anomalies. In particular, the known anomalies arise for bounded memory protocols, where although the total number of sessions is unbounded, there are only a bounded number of concurrent sessions and the honest participants of the protocol cannot remember an unbounded number of facts or an unbounded number of nonces at a time. This led us to the question of whether it is possible to infer an upper-bound\u00a0\u2026", "num_citations": "6\n", "authors": ["1611"]}
{"title": "An operational semantics for network datalog\n", "abstract": " Network Datalog (NDlog) is a recursive query language that extends Datalog by allowing programs to be distributed in a network. In our initial efforts to formally specify NDlog\u2019s operational semantics, we have found several problems with the current evaluation algorithm being used, including unsound results, unintended multiple derivations of the same table entry, and divergence. In this paper, we make a first step towards correcting these problems by formally specifying a new operational semantics for NDlog and proving its correctness for the fragment of non-recursive programs. We also argue that if termination is guaranteed, then the results also extend to recursive programs. Finally, we identify a number of potential implementation improvements to NDlog.", "num_citations": "6\n", "authors": ["1611"]}
{"title": "Small decidable sheaves\n", "abstract": " Fred Richman conjectured that the following principle is not constructive:(*) If A is a decidable subset of the set N of natural numbers and if, for every decidable subset B of N, either A \u2286 B or A \u2286 N \u2212 B, then, for some n \u2208 N, A \u2286 {n}.A set A of natural numbers is called decidable if \u2200n(n \u2208 A \u2228 \u2309 (n \u2208 A)) holds. In recursive models, this agrees with the recursion-theoretic meaning of decidability. In other contexts, \u201ccomplemented\u201d and \u201cdetachable\u201d are often used.Richman's conjecture was motivated by the problem of uniqueness of divisible hulls of abelian groups in constructive algebra. Richman showed that a countable discrete abelian p-group G has a unique (up to isomorphism over G) divisible hull if the subgroup pG is decidable. He also showed that the converse implies.We confirm the nonconstructive nature of by showing (in \u00a71) that it is not provable in intuitionistic set theory, IZF. Thus, in the models we\u00a0\u2026", "num_citations": "6\n", "authors": ["1611"]}
{"title": "Reconciling Lambek\u2019s restriction, cut-elimination and substitution in the presence of exponential modalities\n", "abstract": " The Lambek calculus can be considered as a version of non-commutative intuitionistic linear logic. One of the interesting features of the Lambek calculus is the so-called \u2018Lambek\u2019s restriction\u2019, i.e. the antecedent of any provable sequent should be non-empty. In this paper, we discuss ways of extending the Lambek calculus with the linear logic exponential modality while keeping Lambek\u2019s restriction. Interestingly enough, we show that for any system equipped with a reasonable exponential modality the following holds: if the system enjoys cut elimination and substitution to the full extent, then the system necessarily violates Lambek\u2019s restriction. Nevertheless, we show that two of the three conditions can be implemented. Namely, we design a system with Lambek\u2019s restriction and cut elimination and another system with Lambek\u2019s restriction and substitution. For both calculi, we prove that they are undecidable\u00a0\u2026", "num_citations": "5\n", "authors": ["1611"]}
{"title": "Can we mitigate the attacks on Distance-Bounding Protocols by using challenge-response rounds repeatedly?\n", "abstract": " Distance Bounding Protocols are used to infer an upper-bound on the distance between two participants by measuring the round trip time of a challenge response round launched by the Verifier, who owns the desired resource, to a Prover, who wants access to the resource. A Verifier, who owns the desired resource, sends a challenge to the Prover, who wants the resource, remembering when the challenge was sent. The Prover then responds to the challenge (as quick as possible). From the roundtrip time, Verifier can infer an upper-bound on the distance to Prover. Only if Prover is within some pre-established distance, Verifier grants him access to the resource, eg, open a door.In our previous work [2], we discovered a new attack on Distance Bounding Protocols, called Attack In-Between-Ticks, showing that an Intruder can gain access to a resource although he is not within the pre-established distance to Verifier. The attack exploits the differences between discrete measurements used by Verifier and the actual distance. We then speculated that the Attack in Between Ticks could be mitigated by using a large number of challenge response rounds.", "num_citations": "5\n", "authors": ["1611"]}
{"title": "Formal analysis of Kerberos 5\n", "abstract": " \u2022 Discussed possible fixes we were considering\u2022 Attack announced on WG list in July 2005\u2022 We verified a fix the WG suggested\u2013This was incorporated into PKINIT-27 and into RFC 4556\u2022 Presented this work at IETF-63\u2013Discussed possible fixes and our analysis of these\u2013Useful discussions with WG participants on other areas for work\u2022 Participating in WG subsequent meetings", "num_citations": "5\n", "authors": ["1611"]}
{"title": "Recursive realizability semantics for calculus of constructions\n", "abstract": " Recursive realizability semantics for calculus of constructions | Logical foundations of functional programming ACM Digital Library home ACM home Google, Inc. (search) Advanced Search Browse About Sign in Register Advanced Search Journals Magazines Proceedings Books SIGs Conferences People More Search ACM Digital Library SearchSearch Advanced Search Browse Browse Digital Library Collections More HomeBrowse by TitleBooksLogical foundations of functional programmingRecursive realizability semantics for calculus of constructions chapter Recursive realizability semantics for calculus of constructions Share on Author: Andre Scedrov profile image Andre Scedrov View Profile Authors Info & Affiliations Publication: Logical foundations of functional programmingJune 1990 Pages 419\u2013430 0citation", "num_citations": "5\n", "authors": ["1611"]}
{"title": "Soft subexponentials and multiplexing\n", "abstract": " Linear logic and its refinements have been used as a specification language for a number of deductive systems. This has been accomplished by carefully studying the structural restrictions of linear logic modalities. Examples of such refinements are subexponentials, light linear logic, and soft linear logic. We bring together these refinements of linear logic in a non-commutative setting. We introduce a non-commutative substructural system with subexponential modalities controlled by a minimalistic set of rules. Namely, we disallow the contraction and weakening rules for the exponential modality and introduce two primitive subexponentials. One of the subexponentials allows the multiplexing rule in the style of soft linear logic and light linear logic. The second subexponential provides the exchange rule. For this system, we construct a sequent calculus, establish cut elimination, and also provide a complete\u00a0\u2026", "num_citations": "4\n", "authors": ["1611"]}
{"title": "L-models and R-models for Lambek calculus enriched with additives and the multiplicative unit\n", "abstract": " Language and relational models, or L-models and R-models, are two natural classes of models for the Lambek calculus. Completeness w.r.t. L-models was proved by Pentus and completeness w.r.t. R-models by Andr\u00e9ka and Mikul\u00e1s. It is well known that adding both additive conjunction and disjunction together yields incompleteness, because of the distributive law. The product-free Lambek calculus enriched with conjunction only, however, is complete w.r.t. L-models (Buszkowski) as well as R-models (Andr\u00e9ka and Mikul\u00e1s). The situation with disjunction turns out to be the opposite: we prove that the product-free Lambek calculus enriched with disjunction only is incomplete w.r.t. L-models as well as R-models. If the empty premises are allowed, the product-free Lambek calculus enriched with conjunction only is still complete w.r.t. L-models but in which the empty word is allowed. Both versions are decidable\u00a0\u2026", "num_citations": "4\n", "authors": ["1611"]}
{"title": "Bracket induction for Lambek calculus with bracket modalities\n", "abstract": " Relativisation involves dependencies which, although unbounded, are constrained with respect to certain island domains. The Lambek calculus L can provide a very rudimentary account of relativisation limited to unbounded peripheral extraction; the Lambek calculus with bracket modalities Lb can further condition this account according to island domains. However in na\u00efve parsing/theorem-proving by backward chaining sequent proof search for Lb the bracketed island domains, which can be indefinitely nested, have to be specified in the linguistic input. In realistic parsing word order is given but such hierarchical bracketing structure cannot be assumed to be given. In this paper we show how parsing can be realised which induces the bracketing structure in backward chaining sequent proof search with Lb.", "num_citations": "4\n", "authors": ["1611"]}
{"title": "A reduction-based approach towards scaling up formal analysis of internet configurations\n", "abstract": " The Border Gateway Protocol (BGP) is the single inter-domain routing protocol that enables network operators within each autonomous system (AS) to influence routing decisions by independently setting local policies on route filtering and selection. This independence leads to fragile networking and makes analysis of policy configurations very complex. To aid the systematic and efficient study of the policy configuration space, this paper presents network reduction, a scalability technique for policy-based routing systems. In network reduction, we provide two types of reduction rules that transform policy configurations by merging duplicate and complementary router configurations to simplify analysis. We show that the reductions are sound, dual of each other and are locally complete. The reductions are also computationally attractive, requiring only local configuration information and modification. We have developed\u00a0\u2026", "num_citations": "4\n", "authors": ["1611"]}
{"title": "Maintaining distributed recursive views incrementally\n", "abstract": " Distributed logic programming languages, that allow both facts and programs to be distributed among different nodes in a network, have been recently proposed and used to declaratively program a wide-range of distributed systems, such as network protocols and multi-agent systems. However, the distributed nature of the underlying systems poses serious challenges to developing efficient and correct algorithms for evaluating these programs. This paper proposes an efficient asynchronous algorithm to compute incrementally the changes to the states in response to insertions and deletions of base facts. Our algorithm is formally proven to be correct in the presence of message reordering in the system. To our knowledge, this is the first formal proof of correctness for such an algorithm.", "num_citations": "4\n", "authors": ["1611"]}
{"title": "The impossibility of realizable ideal functionality\n", "abstract": " A cryptographic primitive or a security mechanism can be specified in a variety of ways, such as a condition involving a game against an attacker, construction of an ideal functionality, or a list of properties that must hold in the face of attack. One reason that an ideal functionality is appealing is that if an implementation cannot be distinguished from an ideal functionality, by any feasible attack in any environment, then the mechanism is therefore secure in any larger system that uses it. We make accepted aspects of ideal functionality precise by relating ideal functionality to game specifications, and show that bit commitment, group signatures, and other cryptographic concepts do not have any realizable ideal functionality. This suggests that in order to develop composable security conditions, either alternative notions of ideal functionality must be developed, or another specification method must be used.", "num_citations": "4\n", "authors": ["1611"]}
{"title": "Resource and timing aspects of security protocols\n", "abstract": " Protocol security verification is one of the best success stories of formal methods. However, some aspects important to protocol security, such as time and resources, are not covered by many formal models. While timing issues involve eg, network delays and timeouts, resources such as memory, processing power, or network bandwidth are at the root of Denial of Service (DoS) attacks which have been a serious security concern. It is useful in practice and more challenging for formal protocol verification to determine whether a service is vulnerable not only to powerful intruders, but also to resource-bounded intruders that cannot generate or intercept arbitrarily large volumes of traffic. A refined Dolev\u2013Yao intruder model is proposed, that can only consume at most some specified amount of resources in any given time window. Timed protocol theories that specify service resource usage during protocol execution are\u00a0\u2026", "num_citations": "3\n", "authors": ["1611"]}
{"title": "Undecidability of a newly proposed calculus for CatLog3\n", "abstract": " In his recent papers \u201cParsing/theorem-proving for logical grammar CatLog3\u201d and \u201cA note on movement in logical grammar\u201d, Glyn Morrill proposes a new substructural calculus to be used as the basis for the categorial grammar parser CatLog3. In this paper we prove that the derivability problem for a fragment of this calculus is algorithmically undecidable.", "num_citations": "3\n", "authors": ["1611"]}
{"title": "Reconciling Lambek's restriction, cut-elimination, and substitution in the presence of exponential modalities\n", "abstract": " The Lambek calculus can be considered as a version of non-commutative intuitionistic linear logic. One of the interesting features of the Lambek calculus is the so-called \"Lambek's restriction,\" that is, the antecedent of any provable sequent should be non-empty. In this paper we discuss ways of extending the Lambek calculus with the linear logic exponential modality while keeping Lambek's restriction. Interestingly enough, we show that for any system equipped with a reasonable exponential modality the following holds: if the system enjoys cut elimination and substitution to the full extent, then the system necessarily violates Lambek's restriction. Nevertheless, we show that two of the three conditions can be implemented. Namely, we design a system with Lambek's restriction and cut elimination and another system with Lambek's restriction and substitution. For both calculi we prove that they are undecidable, even if we take only one of the two divisions provided by the Lambek calculus. The system with cut elimination and substitution and without Lambek's restriction is folklore and known to be undecidable.", "num_citations": "3\n", "authors": ["1611"]}
{"title": "Brief announcement: A calculus of policy-based routing systems\n", "abstract": " The BGP (Border Gateway Protocol) is the single inter-domain routing protocol that enables network operators within each autonomous system (AS) to influence routing decisions by independently setting local policies on route filtering and selection. This independence leads to fragile networking and makes analysis of policy configurations very complex. To aid the systematic and efficient study of the policy configuration space, this paper presents a reduction calculus on policy-based routing systems. In the calculus, we provide two types of reduction rules that transform policy configurations by merging duplicate and complementary router configurations to simplify analysis. We show that the reductions are sound, dual of each other and are locally complete. The reductions are also computationally attractive, requiring only local configuration information and modification. These properties establish our reduction\u00a0\u2026", "num_citations": "3\n", "authors": ["1611"]}
{"title": "Computational sound mechanized proof of PKINIT for Kerberos\n", "abstract": " Here we report initial results on the formalization and analysis, using the CryptoVerif tool [4, 5, 6], of the public-key extension to the Kerberos protocol, PKINIT [10]. This protocol provides a good test case for analysis techniques because it incorporates many different protocol design elements: symmetric and asymmetric encryption, digital signatures, and keyed hash functions. We are able to prove, using CryptoVerif\u2019s interactive mode, secrecy and authentication properties for PKINIT at the computational level. Because Kerberos appears to be more complex than the protocols previously analyzed using CryptoVerif, our work provides evidence of the suitability of CryptoVerif for the analysis of real-world industrial protocols. This work is part of an ongoing project to formalize and analyze the Kerberos protocol suite; earlier work has included symbolic proofs (by hand) of security properties of the basic protocol [7], the discovery of a flaw in a draft version of PKINIT (which led to a Windows Security Bulletin [12]) and the symbolic proof of its fixes [8], and by-hand computational proofs of the security of Kerberos with the fixed version of PKINIT using the BPW model [2]. The current work extends this project to include the use of a mechanized tool, Blanchet\u2019s CryptoVerif (v. 1.06).Kerberos and PKINIT. Kerberos [14] is designed to allow a user to repeatedly authenticate herself to multiple servers based upon a single login. The client\u2019s interactions with the servers partition the basic Kerberos protocol into three different rounds. Our focus here is on the first round, called the Authentication Service (AS) Exchange in the protocol specification [14]. The PKINIT\u00a0\u2026", "num_citations": "3\n", "authors": ["1611"]}
{"title": "Software Security--Theories and Systems: Mext-NSF-JSPS International Symposium, ISSS 2002, Tokyo, Japan, November 8-10, 2002, Revised Papers\n", "abstract": " For more than the last three decades, the security of software systems has been an important area of computer science, yet it is a rather recent general recognition that technologies for software security are highly needed. This book assesses the state of the art in software and systems security by presenting a carefully arranged selection of revised invited and reviewed papers. It covers basic aspects and recently developed topics such as security of pervasive computing, peer-to-peer systems and autonomous distributed agents, secure software circulation, compilers for fail-safe C language, construction of secure mail systems, type systems and multiset rewriting systems for security protocols, and privacy issues as well.", "num_citations": "3\n", "authors": ["1611"]}
{"title": "Kleene computable functionals and the higher order existence property\n", "abstract": " Let F be the free topos with the natural number object (nno). Let C be the full Cartesian closed subcategory of F generated by nno We show that the morphisms of C are given by the Kleene computable functionals that are provably total in intuitionistic type theory. We thus establish the existence property for functionals of finite type.", "num_citations": "3\n", "authors": ["1611"]}
{"title": "Sheaves and Forcing and Their Metamathematical Applications.\n", "abstract": " Degree: Ph. D.DegreeYear: 1981Institute: State University of New York at BuffaloWe consider forcing over categories as a way of constructing objects by geometric approximation, including a construction of a generic model of a geometric theory (Cf. M. Makkai, G. Reyes: Springer LNM 611), as its special case. When determining decisive properties of a required object, one fi", "num_citations": "3\n", "authors": ["1611"]}
{"title": "Reduction-based analysis of BGP systems with BGPVerif\n", "abstract": " Today's inter-domain routing protocol, the Border Gateway Protocol (BGP), is increasingly complicated and fragile due to policy misconfiguration by individual autonomous systems (ASes). Existing configuration analysis techniques are either manual and tedious, or do not scale beyond a small number of nodes due to the state explosion problem. To aid the diagnosis of misconfigurations in real-world large BGP systems, this paper presents BGPVerif , a reduction based analysis toolkit. The key idea is to reduce BGP system size prior to analysis while preserving crucial correctness properties. BGPVerif consists of two components, NetReducer that simplifies BGP configurations, and NetAnalyzer that automatically detects routing oscillation. BGPVerif accepts a wide range of BGP configuration inputs ranging from real-world traces (Rocketfuel network topologies), randomly generated BGP networks (GT-ITM), Cisco\u00a0\u2026", "num_citations": "2\n", "authors": ["1611"]}
{"title": "Timed collaborative systems\n", "abstract": " Time is often a key component used in specifying the rules and the requirements of a collaboration. For a correct collaboration and to achieve a common goal, participants usually should follow strict deadlines and should have quick reactions to some (unexpected) event.Consider, for example, the scenario where a sponsor, typically a pharmaceutical company, colaborates with health institutions, typically hospitals, to test a new drug on human subjects. An institution provides subjects with samples of the new drugs that can be taken in the institution or at the subjects\u2019 homes. However, in order for the correct testing of the drug, the samples have to be taken in well-defined periods of time and the institution must periodically monitor the subjects in order to determine the drug\u2019s effectiveness as well as the subjects\u2019 health. If any problem with any subject is reported during the testing phase, the competent authority must be promptly informed. In the USA, the responsible authority is the Food and Drug Administration (FDA). Moreover, the correct procedure for such collaboration is regulated by the US Department of Health and Human Services related to drugs for human use, namely, by the Federal Regulations CFR21, Part 312 related to so called Investigational New Drug Application (IND)[23]. For instance, the paragraph 312.32 on IND safety includes explicit time constraints that must be followed in case of any unexpected, serious or life-threatening adverse drug experience:", "num_citations": "2\n", "authors": ["1611"]}
{"title": "Confidentiality and authentication in Kerberos 5\n", "abstract": " We give three formalizations of the Kerberos 5 authentication protocol in the Multi-Set Rewriting (MSR) formalism. One is a high-level formalization containing just enough detail to prove authentication and confidentiality properties of the protocol. A second formalization refines this by adding a variety of protocol options; we similarly refine proofs of properties in the first formalization to prove properties of the second formalization. Our third formalization adds timestamps to the first formalization but has not been analyzed extensively. The various proofs make use of rank and corank functions, inspired by work of Schneider in CSP, and provide examples of reasoning about real-world protocols in MSR. We also note some potentially curious protocol behavior; given our positive results, this does not compromise the security of the protocol.\u2217 Corresponding author: AD Jaggard.\u2020 Partially supported by ONR Grant N00014\u00a0\u2026", "num_citations": "2\n", "authors": ["1611"]}
{"title": "Some properties of epistemic set theory with collection\n", "abstract": " Myhill [12] extended the ideas of Shapiro [15], and proposed a system of epistemic set theory IST (based on modal S4 logic) in which the meaning of the necessity operator is taken to be the intuitive provability, as formalized in the system itself. In this setting one works in classical logic, and yet it is possible to make distinctions usually associated with intuitionism, e.g. a constructive existential quantifier can be expressed as (\u2203x) \u25a1 \u2026. This was first confirmed when Goodman [7] proved that Shapiro's epistemic first order arithmetic is conservative over intuitionistic first order arithmetic via an extension of G\u00f6del's modal interpretation [6] of intuitionistic logic.Myhill showed that whenever a sentence \u25a1A \u2228 \u25a1B is provable in IST, then A is provable in IST or B is provable in IST (the disjunction property), and that whenever a sentence \u2203x.\u25a1A(x) is provable in IST, then so is A(t) for some closed term t (the existence property\u00a0\u2026", "num_citations": "2\n", "authors": ["1611"]}
{"title": "Embedding sheaf models for set theory into boolean-valued permutation models with an interior operator\n", "abstract": " Myhill [14] proposed a system of set theory based on $4 modal logic, which crystallized into its present form in [9, 10, 16, 17, 3]. In this setting, one works in classical logic, but at the same time one can make distinctions usually associated with intuitionism. A constructive existential quantifier, for example, can be expressed as (: Ix) El.... Epistemic ZF set theory is a conservative extension of both classical ZF set theory [9, 17] and intuitionistic ZF set theory [3](the latter via an extension of a G6del-type modal interpretation of intuitionistic logic [15] to set theory [16]). Furthermore, epistemic ZF (like intuitionistic ZF, but unlike classical ZF) has the numerical existence property: if it proves a sentence: Ix\u2022 to ElA (x), then there is a (definable) standard numeral n such that A (n) is provable [9, 17].Considering the slash interpretations [14, 9, 17] of epistemic ZF only as tools of technical nature, one wants to know whether this theory\u00a0\u2026", "num_citations": "2\n", "authors": ["1611"]}
{"title": "On the impossibility of explicit upper bounds on lengths of some provably finite algorithms in computable analysis\n", "abstract": " One of the most interesting features of computable analysis [1, 8] is the continuity of all computable real functions [3, 7, 9]. One usually specifies computable reals as programs for computing Cauchy sequences of rationals on a generic computing device (say, a Turing machine). A computable real function is defined as a program for an extensional algorithm on codes of computable reals. The Continuity Theorem states that given a computable real function, one can construct an algorithm for a modulus of continuity of that function. A bound on the new algorithm may be obtained from some additional information about the computable function, eg, from a formal proof that it terminates on all inputs. In all proofs of the Continuity Theorem, the modulus of continuity algorithm involves a search-and-verify procedure which cannot go on indefinitely, but the argument does not provide an explicit bound on the length of\u00a0\u2026", "num_citations": "2\n", "authors": ["1611"]}
{"title": "On the Complexity of Verification of Time-Sensitive Distributed Systems: Technical Report\n", "abstract": " Time-Sensitive Distributed Systems (TSDS), such as applications using autonomous drones, achieve goals under possible environment interference (e.g., winds). Goals are often specified using explicit time constraints, and, moreover, goals must be satisfied by the system perpetually. For example, drones carrying out the surveillance of some area must always have recent pictures, i.e., at most M time units old, of some strategic locations. This paper proposes a Multiset Rewriting language with explicit time for specifying and analyzing TSDSes. We introduce new properties, such as realizability (there exists a good trace), survivability (where, in addition, all admissible traces are good), recoverability (all compliant traces do not reach points-of-no-return), and reliability (system can always continue functioning using a good trace). A good trace is an infinite trace in which goals are perpetually satisfied. We propose a class of systems called Progressing Timed Systems (PTS), where intuitively only a finite number of actions can be carried out in a bounded time period. We prove that for this class of systems the problems of realizability, recoverability, reliability, and survivability are PSPACE-complete. Furthermore, if we impose a bound on time (as in bounded model-checking), we show that for PTS, realizability becomes NP-complete, while survivability and reliability problems are in the  class of the polynomial hierarchy.", "num_citations": "1\n", "authors": ["1611"]}
{"title": "Language models for some extensions of the Lambek calculus\n", "abstract": " We investigate language interpretations of two extensions of the Lambek calculus: with additive conjunction and disjunction and with additive conjunction and the unit constant. For extensions with additive connectives, we show that conjunction and disjunction behave differently. Adding both of them leads to incompleteness due to the distributivity law. We show that with conjunction only no issues with distributivity arise. In contrast, there exists a corollary of the distributivity law in the language with disjunction only which is not derivable in the non-distributive system. Moreover, this difference keeps valid for systems with permutation and/or weakening structural rules, that is, intuitionistic linear and affine logics and affine multiplicative-additive Lambek calculus. For the extension of the Lambek calculus with the unit constant, we present a calculus which reflects natural algebraic properties of the empty word. We do not\u00a0\u2026", "num_citations": "1\n", "authors": ["1611"]}
{"title": "The multiplicative-additive Lambek calculus with subexponential and bracket modalities\n", "abstract": " We give a proof-theoretic and algorithmic complexity analysis for systems introduced by Morrill to serve as the core of the CatLog categorial grammar parser. We consider two recent versions of Morrill\u2019s calculi, and focus on their fragments including multiplicative (Lambek) connectives, additive conjunction and disjunction, brackets and bracket modalities, and the ! subexponential modality. For both systems, we resolve issues connected with the cut rule and provide necessary modifications, after which we prove admissibility of cut (cut elimination theorem). We also prove algorithmic undecidability for both calculi, and show that categorial grammars based on them can generate arbitrary recursively enumerable languages.", "num_citations": "1\n", "authors": ["1611"]}
{"title": "On security analysis of periodic systems: expressiveness and complexity\n", "abstract": " Development of automated technological systems has seen the increase in interconnectivity among its components. This includes Internet of Things (IoT) and Industry 4.0 (I4.0) and the underlying communication between sensors and controllers. This paper is a step toward a formal framework for specifying such systems and analyzing underlying properties including safety and security. We introduce automata systems (AS) motivated by I4.0 applications. We identify various subclasses of AS that reflect different types of requirements on I4.0. We investigate the complexity of the problem of functional correctness of these systems as well as their vulnerability to attacks. We model the presence of various levels of threats to the system by proposing a range of intruder models, based on the number of actions intruders can use.", "num_citations": "1\n", "authors": ["1611"]}
{"title": "Statistical Model Checking of Guessing and Timing Attacks on Distance-bounding Protocols\n", "abstract": " Distance-bounding (DB) protocols were proposed to thwart relay attacks on proximity-based access control systems. In a DB protocol, the verifier computes an upper bound on the distance to the prover by measuring the time needed for a signal to travel to the prover and back. DB protocols are, however, vulnerable to distance fraud, in which a dishonest prover is able to manipulate the distance bound computed by an honest verifier. Despite their conceptual simplicity, devising a formal characterization of DB protocols and distance fraud attacks that is amenable to automated formal analysis is non-trivial, primarily because of their real-time and probabilistic nature. In this work, we present a framework, based on rewriting logic, for formally analyzing different forms of distance-fraud, including recently identified timing attacks. We introduce a generic, real-time and probabilistic model of DB protocols and use it to (mechanically) verify false-acceptance and false-rejection probabilities under various settings and attacker models through statistical model checking with MAUDE and PVESTA. Using this framework, we first accurately confirm known results and then define and quantitatively evaluate new guessing-ahead attack strategies that would otherwise be difficult to analyze manually.", "num_citations": "1\n", "authors": ["1611"]}
{"title": "FSR: A Formal Analysis and Development Toolkit for Safe Inter-domain Routing\n", "abstract": " The design and evaluation of inter-domain routing protocols is complicated because even the most basic goal\u2014guaranteed convergence\u2014depends on the local routing policies. Our Formally Safe Routing (FSR) toolkit assists in each stage of the design process:(i) demonstrating that specific configurations (\u201cgadgets\u201d) diverge,(ii) verifying that proposed constraints on routing policy ensure convergence, and (iii) generating a provably-correct protocol implementation to use in experiments. FSR uses routing algebra to analyze convergence and declarative networking to generate implementations from algebraic specifications. Our implementation of FSR uses the RapidNet declarative networking system, Yices SMT solver, and Maude logic-based model checker. We run FSR to show that well-known BGP gadgets diverge and recently-proposed policy guidelines ensure convergence. Experiments on the protocol implementations validate the results obtained in the analysis phase.", "num_citations": "1\n", "authors": ["1611"]}
{"title": "When not all bits are equal: Incorporating \u201cworth\u201d into information-flow measures\n", "abstract": " Approaches to quantitative information flow (QIF) traditionally have presumed that all leaks involving a given number of bits are equally harmful. The presumption is unrealistic, so a new approach to QIF is described. Here, secrets are defined in terms of fields, where derived secrets obtained by combining these fields can be assigned a different \u201cworth\u201d(perhaps in proportion to the harm that would result from disclosure). New measures that incorporate worth into QIF are then defined; they generalize probability of guessing, guessing entropy, and Shannon entropy. A lattice of information is derived to provide an underlying algebraic structure for an adversary\u2019s state of knowledge in this more-general setting. Keywords: information-flow, quantitative methods, information theory, lattice of information, entropy.", "num_citations": "1\n", "authors": ["1611"]}
{"title": "Relating cryptography and cryptographic protocols\n", "abstract": " In recent years, there has been significant attention paid to the application of Lean thinking to software-centric organizations. However, there is noticeable challenges accompanying the use of it. Even when applied properly, sustaining the realized benefits becomes challenging. There is a need to have a sustainable and continuous improvement method that is embedded into the daily operations of the development process. We provide a summary of our experience on how Kaizen has helped in improving a software development team's productivity by more than 20%, enhanced the responsiveness of the team by more than 62%, increased the overall customer satisfaction by more than 17%, and is still improving!", "num_citations": "1\n", "authors": ["1611"]}
{"title": "Inheritance as implicit coercion\n", "abstract": " We present a method for providing semantic interpretations for languages with a type system featuring inheritance polymorphism. Our approach is illustrated on an extension of the language Fun of Cardelli and Wegner, which we interpret via a translation into an extended polymorphic lambda calculus. Our goal is to interpret inheritances in Fun via coercion functions which are definable in the target of the translation. Existing techniques in the theory of semantic domains can be then used to interpret the extended polymorphic lambda calculus, thus providing many models for the original language. This technique makes it possible to model a rich type discipline which includes parametric polymorphism and recursive types as well as inheritance.", "num_citations": "1\n", "authors": ["1611"]}
{"title": "Decompositions of finitely generated modules over C(X): sheaf semantics and a decision procedure\n", "abstract": " In the theory of operator algebras the rings of finite matrices over such algebras play a very important role (see [10]). For commutative operator algebras, the Gelfand-Naimark representation allows one to concentrate on matrices over rings of continuous complex functions on compact Hausdorif spaces.", "num_citations": "1\n", "authors": ["1611"]}