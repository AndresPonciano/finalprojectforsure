{"title": "Pad: Performance anomaly detection in multi-server distributed systems\n", "abstract": " Multi-server distributed systems are becoming increasingly popular with the emergence of cloud computing. These systems need to provide high throughput with low latency, which is a difficult task to achieve. Manual performance tuning and diagnosis of such systems, however, is hard as the amount of relevant performance diagnosis data is large. To help system developers with performance diagnosis, we have developed a tool called Performance Anomaly Detector (PAD). PAD combines user-driven navigation analysis with automatic correlation and comparative analysis techniques. The combination results in a powerful tool that can help find a number of performance anomalies. Based on our experience in applying PAD to the Orleans system, we discovered that PAD was able to reduce developer time and effort detecting anomalous performance cases and improve a developer's ability to perform deeper\u00a0\u2026", "num_citations": "45\n", "authors": ["730"]}
{"title": "Towards modeling the behavior of static code analysis tools\n", "abstract": " This paper presents preliminary results of an independent study to assess the performance of a static code analysis (SCA) tool's ability to detect and identify weaknesses and vulnerabilities in source code. The goal of the study is to model the behavior of static code analysis tools, and predict what SCA tool, or set of SCA tools, should be applied against a given source code to identify weaknesses and vulnerabilities.", "num_citations": "16\n", "authors": ["730"]}
{"title": "Towards detecting software performance anti-patterns using classification techniques\n", "abstract": " This paper presents a non-intrusive machine learning approach called Non-intrusive Performance Anti-pattern Detecter (NiPAD) for identifying and classifying software performance anti-patterns. NiPAD uses only system performance metrics-as opposed to analyzing application level performance metrics or source code and the design of a software application to identify and classify software performance anti-patterns within an application. The results of applying NiPAD to an example application show that NiPAD is able to predict the One Lane Bridge software performance anti-pattern within a software application with 0.94 accuracy.", "num_citations": "13\n", "authors": ["730"]}
{"title": "Automatically detecting\" excessive dynamic memory allocations\" software performance anti-pattern\n", "abstract": " This paper presents a methodology for automatically detecting the excessive dynamic memory allocation software performance anti-pattern, which is implemented in a tool named Excessive Memory Allocation Detector (EMAD). To the best of author's knowledge, EMAD is the first attempt to detect excessive dynamic memory allocation anti-pattern without human intervention. EMAD uses dynamic binary instrumentation and exploratory data analysis to determine if an application (or middleware) exhibits excessive dynamic memory allocations. Unlike traditional approaches, EMAD's technique does not rely on source code analysis. Results of applying EMAD to several open-source projects show that EMAD can detect the excessive dynamic memory allocations anti-pattern correctly. The results also show that application performance improves when the detected excessive dynamic memory allocations are resolved.", "num_citations": "12\n", "authors": ["730"]}
{"title": "Adapting system execution traces for validation of distributed system QoS properties\n", "abstract": " System execution traces are useful artifacts for validating distributed system quality-of-service (QoS) properties, such as end-to-end response time, throughput, and service time. With proper planning during development phase of the software lifecycle, it is possible to ensure such traces contain required properties to facilitate analysis for QoS validation. In some case, however, it is not possible to ensure system execution traces contain the necessary properties for QoS analysis. This paper presents the System Execution Trace Adaptation Framework (SETAF) for adapting system execution traces to support analysis of QoS properties. It also presents results from applying SETAF to externally developed applications. The results show that it is possible to validate QoS properties by automatically adapting system execution traces at analysis time instead of modifying the application's existing source code.", "num_citations": "5\n", "authors": ["730"]}
{"title": "Adapting system execution traces to support analysis of software system performance properties\n", "abstract": " UNITE is a method and tool that analyzes software system performance properties, e.g., end-to-end response time, throughput, and service time, via system execution traces. UNITE, however, assumes that a system execution trace contains properties (e.g., identifiable keywords, unique message instances, and enough variation among the same event types) to support performance analysis. With proper planning, it is possible to ensure that properties required to support such analysis are incorporated in the generated system execution trace. It, however, is not safe to assume this to be the case with many existing software systems.This article therefore presents a method and a tool called the System Execution Trace Adaptation Framework (SETAF), which is built atop of UNITE and adapts system execution traces to support performance analysis of software systems. It also presents examples and results of applying\u00a0\u2026", "num_citations": "2\n", "authors": ["730"]}
{"title": "Auto-constructing dataflow models from system execution traces\n", "abstract": " This paper presents a method and tool named the Dataflow Model Auto-Constructor (DMAC). DMAC uses frequent-sequence mining and Dempster-Shafer theory to mine a system execution trace and reconstruct its corresponding dataflow model. Distributed system testers then use the resultant dataflow model to analyze performance properties (e.g., end-to-end response time, throughput, and service time) captured in the system execution trace. Results from applying DMAC to different case studies show that DMAC can reconstruct dataflow models that cover at most 94% of the events in the original system execution trace. Likewise, more than 2 sources of evidence are needed to reconstruct dataflow models for systems with multiple execution contexts.", "num_citations": "2\n", "authors": ["730"]}