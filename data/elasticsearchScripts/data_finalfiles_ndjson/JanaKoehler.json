{"title": "Web service composition-current solutions and open problems\n", "abstract": " Composition of Web services has received much interest to support business-to-business or enterprise application integration. On the one side, the business world has developed a number of XML-based standards to formalize the specification of Web services, their flow composition and execution. This approach is primarily syntactical: Web service interfaces are like remote procedure call and the interaction protocols are manually written. On the other side, the Semantic Web community focuses on reasoning about web resources by explicitly declaring their preconditions and effects with terms precisely defined in ontologies. For the composition of Web services, they draw on the goal-oriented inferencing from planning. So far, both approaches have been developed rather independently from each other. We compare these approaches and discuss their solutions to the problems of modeling, composing, executing, and verifying Web services. We discuss what makes the Web service composition so special and derive challenges for the AI planning community.", "num_citations": "839\n", "authors": ["643"]}
{"title": "Extending planning graphs to an ADL subset\n", "abstract": " We describe an extension of GRAPHPLAN to a subset of ADL that allows conditional and universally quantified effects in operators in such a way that almost all interesting properties of the original GRAPHPLAN algorithm are preserved.", "num_citations": "411\n", "authors": ["643"]}
{"title": "The refined process structure tree\n", "abstract": " We consider a workflow graph as a model for the control flow of a business process and study the problem of workflow graph parsing, i.e., finding the structure of a workflow graph. More precisely, we want to find a decomposition of a workflow graph into a hierarchy of sub-workflows that are subgraphs with a single entry and a single exit of control. Such a decomposition is the crucial step, for example, to translate a process modeled in a graph-based language such as BPMN into a process modeled in a block-based language such as BPEL. For this and other applications, it is desirable that the decomposition be unique, modular and as fine as possible, where modular means that a local change of the workflow graph can only cause a local change of the decomposition. In this paper, we provide a decomposition that is unique, modular and finer than in previous work. We call it the refined process structure tree. It is\u00a0\u2026", "num_citations": "284\n", "authors": ["643"]}
{"title": "Encoding planning problems in nonmonotonic logic programs\n", "abstract": " We present a framework for encoding planning problems in logic programs with negation as failure, having computational efficiency as our major consideration. In order to accomplish our goal, we bring together ideas from logic programming and the planning systems GRAPHPLAN and SATPLAN. We discuss different representations of planning problems in logic programs, point out issues related to their performance, and show ways to exploit the structure of the domains in these representations. For our experimentation we use an existing implementation of the stable models semantics called SMODELS. It turns out that for careful and compact encodings, the performance of the method across a number of different domains, is comparable to that of planners like GRAPHPLAN and SATPLAN.", "num_citations": "250\n", "authors": ["643"]}
{"title": "Plan reuse versus plan generation: A theoretical and empirical analysis\n", "abstract": " The ability of a planner to reuse parts of old plans is hypothesized to be a valuable tool for improving efficiency of planning by avoiding the repetition of the same planning effort. We test this hypothesis from an analytical and empirical point of view. A comparative worst-case complexity analysis of generation and reuse under different assumptions reveals that it is not possible to achieve a provable efficiency gain of reuse over generation. Further, assuming \u201cconservative\u201d plan modification, plan reuse can actually be strictly more difficult than plan generation. While these results do not imply that there won't be an efficiency gain in some situations, retrieval of a good plan may present a serious bottleneck for plan reuse systems, as we will show. Finally, we present the results of an empirical study of two different plan reuse systems, pointing out possible pitfalls one should be aware of when attempting to employ reuse\u00a0\u2026", "num_citations": "245\n", "authors": ["643"]}
{"title": "A review of OMG MOF 2.0 Query/Views/Transformations Submissions and Recommendations towards the final Standard\n", "abstract": " Model-to-model transformation is a key technology for the OMG\u2019s Model Driven ArchitectureTM. The need for standardization in this area lead to the MOF 2.0 Query/Views/Transformations Request for Proposals (RFP) from the OMG. The RFP elicited eight separate submissions. This paper makes the following contributions: Terminology for queries, views, and transformations is introduced that is based on the terminology used in the submissions, but which is edited for consistency. A set of common transformation scenarios is described, which is motivated by the authors\u2019 practical experiences with transformations. The submissions are reviewed, compared to each other, and their highlights discussed. Based on the review and the experience of the authors in developing model-driven transformations, recommendations for the final standard are presented.", "num_citations": "220\n", "authors": ["643"]}
{"title": "AIPS 2000 planning competition: The fifth international conference on artificial intelligence planning and scheduling systems\n", "abstract": " The planning competition has become a regular part of the biennial Artificial Intelligence Planning and Scheduling (AIPS) conferences. AIPS'98 featured the very first competition, and for AIPS'00, we built on this foundation to run the second competition. The 2000 competition featured a much larger group of participants and a wide variety of different approaches to planning. Some of these approaches were refinements of known techniques, and others were quite different from anything that had been tried before. Besides the dramatic increase in participation, the 2000 competition demonstrated that planning technology has taken a giant leap forward in performance since 1998. The 2000 competition featured planning systems that were orders of magnitude faster than the planners of just two years prior. This article presents an overview of the competition and reviews the main results.", "num_citations": "203\n", "authors": ["643"]}
{"title": "The refined process structure tree\n", "abstract": " We consider workflow graphs as a model for the control flow of a business process model and study the problem of workflow graph parsing, i.e., finding the structure of a workflow graph. More precisely, we want to find a decomposition of a workflow graph into a hierarchy of sub-workflows that are subgraphs with a single entry and a single exit of control. Such a decomposition is the crucial step, for example, to translate a process modeled in a graph-based language such as BPMN into a process modeled in a block-based language such as BPEL. For this and other applications, it is desirable that the decomposition be unique, modular and as fine as possible, where modular means that a local change of the workflow graph can only cause a local change of the decomposition. In this paper, we provide a decomposition that is unique, modular and finer than in previous work. It is based on and extends similar\u00a0\u2026", "num_citations": "191\n", "authors": ["643"]}
{"title": "Managing architectural decision models with dependency relations, integrity constraints, and production rules\n", "abstract": " Software architects consider capturing and sharing architectural decisions increasingly important; many tacit dependencies exist in this architectural knowledge. Architectural decision modeling makes these dependencies explicit and serves as a foundation for knowledge management tools. In practice, however, text templates and informal rich pictures rather than models are used to capture the knowledge; a formal definition of model entities and their relations is missing in the current state of the art. In this paper, we propose such a formal definition of architectural decision models as directed acyclic graphs with several types of nodes and edges. In our models, architectural decision topic groups, issues, alternatives, and outcomes form trees of nodes connected by edges expressing containment and refinement, decomposition, and triggers dependencies, as well as logical relations such as (in)compatibility of\u00a0\u2026", "num_citations": "172\n", "authors": ["643"]}
{"title": "Planning under Resource Constraints.\n", "abstract": " This paper outlines the basic principles underlying reasoning about resources in IPP, which is a classical planner based on planning graphs originally introduced with the graphplan system. The main idea is to deal with resources in a strictly action-centered way, ie, one speci es how each action consumes or produces resources, but no explicit temporal model is used. This avoids the computational problems of solving general constraint satisfaction problems by using instead interval arithmetics and propagation of resource requirements over time steps in the planning graph.", "num_citations": "172\n", "authors": ["643"]}
{"title": "On reasonable and forced goal orderings and their use in an agenda-driven planning algorithm\n", "abstract": " The paper addresses the problem of computing goal orderings, which is one of the longstanding issues in AI planning. It makes two new contributions. First, it formally defines and discusses two different goal orderings, which are called the reasonable and the forced ordering. Both orderings are defined for simple STRIPS operators as well as for more complex ADL operators supporting negation and conditional effects. The complexity of these orderings is investigated and their practical relevance is discussed. Secondly, two different methods to compute reasonable goal orderings are developed. One of them is based on planning graphs, while the other investigates the set of actions directly. Finally, it is shown how the ordering relations, which have been derived for a given set of goals G, can be used to compute a so-called goal agenda that divides G into an ordered set of subgoals. Any planner can then, in principle, use the goal agenda to plan for increasing sets of subgoals. This can lead to an exponential complexity reduction, as the solution to a complex planning problem is found by solving easier subproblems. Since only a polynomial overhead is caused by the goal agenda computation, a potential exists to dramatically speed up planning algorithms as we demonstrate in the empirical evaluation, where we use this method in the IPP planner.", "num_citations": "166\n", "authors": ["643"]}
{"title": "End-to-end business process solution creation\n", "abstract": " A system and method for creating and managing a business process integration solution comprises modeling a business strategy including elements representing business measurements and initiatives according to defined business goals and objectives of an entity; modeling business operations of the entity in terms of business process elements including process tasks, artifact flows and artifact repositories, and business commitment elements including incorporating key performance indicators; mapping elements of the strategy model with artifact and process elements of the operations model; and, measuring business performance and comparing performance measurements against the key performance indicators. The business strategy and operation model process elements may be continuously refined over a solution development lifecycle as a result of process measurements and comparing. A business level\u00a0\u2026", "num_citations": "163\n", "authors": ["643"]}
{"title": "Ignoring irrelevant facts and operators in plan generation\n", "abstract": " It is traditional wisdom that one should start from the goals when generating a plan in order to focus the plan generation process on potentially relevant actions. The GRAPHPLAN system, however, which is the most efficient planning system nowadays, builds a \u201cplanning graph\u201d in a forward-chaining manner. Although this strategy seems to work well, it may possibly lead to problems if the planning task description contains irrelevant information. Although some irrelevant information can be filtered out by GRAPHPLAN, most cases of irrelevance are not noticed.             In this paper, we analyze the effects arising from \u201cirrelevant\u201d information to planning task descriptions for different types of planners. Based on that, we propose a family of heuristics that select relevant information by minimizing the number of initial facts that are used when approximating a plan by backchaining from the goals ignoring any conflicts\u00a0\u2026", "num_citations": "149\n", "authors": ["643"]}
{"title": "Applying patterns during business process modeling\n", "abstract": " Although the business process community has put a major emphasis on patterns, notably the famous workflow patterns, only limited support for using patterns in today\u2019s business process modeling tools can be found. While the basic workflow patterns for control flow are available in almost every business process modeling tool, there is no support for the user in correctly applying these simple patterns leading to many incorrectly modeled business processes. Only limited support for pattern compounds can be found in some tools, there is no active support for selecting patterns that are applicable in some user-determined context, tools do not give feedback to the user if applying a pattern can lead to a modeling error, nor do they trace the sequence of applied patterns during the editing process.               In this paper, we describe an extension of a business process modeling tool with patterns to provide these\u00a0\u2026", "num_citations": "138\n", "authors": ["643"]}
{"title": "From business process model to consistent implementation: A case for formal verification methods\n", "abstract": " Today's business applications and their underlying process models are becoming more and more complicated, making the implementation of these processes an increasingly challenging task. On the one hand, tools and methods exist to describe the business processes. On the other hand, different tools and method exist to describe the IT artifacts implementing them. But a significant gap exists between the two. To overcome this gap, new methodologies are sought. In this paper we discuss a pattern-based modeling and mapping process. Starting from a business process model, which emphasizes the underlying structural process pattern and its associated requirements, we map this model into a corresponding IT model based on nondeterministic automata with state variables. Model checking techniques are used to automatically verify elementary requirements on a process such as the termination and\u00a0\u2026", "num_citations": "135\n", "authors": ["643"]}
{"title": "Process anti-patterns: How to avoid the common traps of business process modeling\n", "abstract": " Business process modeling is gaining increasing importance with more and more people getting involved with business process modeling projects. The output of these projects are process models, which become a direct input into the software development process. Consequently, the impact of the process models on the IT systems and the operational efficiency of an enterprise is increasing. With that, the associated economic risk of using badly designed process models is growing as well. In this report, we address the problem of quality assurance for business process models. Based on hundreds of real world business process models that we reviewed over the past two years, we extracted typical modeling errors that we generalized into anti-patterns. These anti-patterns cover six common process modeling scenarios ranging from the modeling of branching and iterative behavior, over the modeling of data flow, to the reuse of process models in composite processes. For each scenario, an example illustrating typical errors is introduced and then generalized into an anti-pattern, which highlights the modeling error. Then, one or several patterns are presented that show a correct solution to the modeling scenario, followed by a summarizing recommendation. 1", "num_citations": "102\n", "authors": ["643"]}
{"title": "A model-driven transformation method\n", "abstract": " Model-driven architectures (MDA) separate the business or application logic from the underlying platform technology and represent this logic with precise semantic models. These models are supposed to span the entire life cycle of a software system and ease the software production and maintenance tasks. Consequently, tools will be needed that support these tasks. In this paper, we present a method that implements model-driven transformations between particular platform-independent (business view) and platform-specific (IT architectural) models. On the business level, we focus on business view models expressed in ADF or UML2, whereas on the IT architecture side we focus on service-oriented architectures with Web service interfaces and processes specified in business process protocol languages such as BPEL4WS.", "num_citations": "89\n", "authors": ["643"]}
{"title": "Method and apparatus for generating it level executable solution artifacts from the operational specification of a business\n", "abstract": " A system and method that implements top-down and bottom-up model-driven transformations between platform-independent (business view) modeling approaches and platform-specific (IT architectural) models. On the business level, business view models may be expressed in, but not limited to ADF or UML2, whereas on the IT architecture side, service-oriented architectures with Web service interfaces and processes are specified in business process protocol languages including, but not limited to, BPEL4WS, or workflow definitions. An architecture and a transformation method based on typed information flows automatically transforms platform-independent business models into executable information technology (IT) architecture specifications constrained by a specific IT platform, and vice versa. The models generated span the entire life cycle of a software system and ease the software production, deployment\u00a0\u2026", "num_citations": "88\n", "authors": ["643"]}
{"title": "Improving business process models with reference models in business-driven development\n", "abstract": " Reference models capture best-practice solutions for a specific industry such as retail, banking, or insurance. The models usually cover the whole range of solution components such as product models, business rules, data models, and service models. Over the past years, business process reference models have gained increasing attention. Process merging is a technique that brings together several process models to create a new process model. In this paper, we introduce process merging for a scenario which focuses on the improvement of an existing AS-IS business process by using a reference process model. We describe an approach that enables a business architect to establish correspondences between two process models in a systematic way and show how these correspondences define concrete refactoring operations that serve to improve the AS-IS model.                                        Category\u00a0\u2026", "num_citations": "80\n", "authors": ["643"]}
{"title": "Planning from second principles\n", "abstract": " Planning from second principles by reusing and modifying plans is one way of improving the efficiency of planning systems. In this paper, we study it in the general framework of deductive planning and develop a logical formalization of planning from second principles, which relies on a systematic decomposition of the planning process.Deductive inference processes with clearly defined semantics formalize each of the subtasks a second principles planner has to address. Plan modification, which comprises matching and adaptation tasks, is based on a deductive approach yielding provably correct modified plans. Description logics are introduced as query languages to plan libraries, which leads to a novel and efficient solution to the indexing problem in case-based reasoning.Apart from sequential plans, this approach enables a planner to reuse and modify complex plans containing control structures like\u00a0\u2026", "num_citations": "79\n", "authors": ["643"]}
{"title": "An AI-based approach to destination control in elevators\n", "abstract": " Not widely known by the AI community, elevator control has become a major field of application for AI technologies. Techniques such as neural networks, genetic algorithms, fuzzy rules and, recently, multiagent systems and AI planning have been adopted by leading elevator companies not only to improve the transportation capacity of conventional elevator systems but also to revolutionize the way in which elevators interact with and serve passengers. In this article, we begin with an overview of AI techniques adopted by this industry and explain the motivations behind the continuous interest in AI. We review and summarize publications that are not easily accessible from the common AI sources. In the second part, we present in more detail a recent development project to apply AI planning and multiagent systems to elevator control problems.", "num_citations": "78\n", "authors": ["643"]}
{"title": "The AIPS-98 planning competition\n", "abstract": " In 1998, the international planning community was invited to take part in the first planning competition, hosted by the Artificial Intelligence Planning Systems Conference, to provide a new impetus for empirical evaluation and direct comparison of automatic domain-independent planning systems. This article describes the systems that competed in the event, examines the results, and considers some of the implications for the future of the field.", "num_citations": "78\n", "authors": ["643"]}
{"title": "Compiling process graphs into executable code\n", "abstract": " Model-driven architecture envisions a paradigm shift as dramatic as the one from low-level assembler languages to high-level programming languages. In order for this vision to become reality, algorithms are needed that compile models of software systems into deployable and executable implementations. This paper discusses two algorithms that provide such transformations for process graph models in a business process or workflow environment and produce executable programs based on Web services and orchestration languages. The reverse transformations back from executable programs to process graphs are also described.", "num_citations": "69\n", "authors": ["643"]}
{"title": "Modal logics, description logics and arithmetic reasoning\n", "abstract": " We introduce mathematical programming and atomic decomposition as the basic modal (T-Box) inference techniques for a large class of modal and description logics. The class of description logics suitable for the proposed methods is strong on the arithmetical side. In particular there may be complex arithmetical conditions on sets of accessible worlds (role fillers).The atomic decomposition technique can deal with set constructors for modal parameters (role terms) and parameter (role) hierarchies specified in full propositional logic. Besides the standard modal operators, a number of other constructors can be added in a relatively straightforward way. Examples are graded modalities (qualified number restrictions) and also generalized quantifiers like \u201cmost\u201d, \u201cn%\u201d, \u201cmore\u201d and \u201cmany\u201d.", "num_citations": "69\n", "authors": ["643"]}
{"title": "Elevator Control as a Planning Problem.\n", "abstract": " The synthesis of elevator control commands ia difficult problem when new service requirements such as VIP service, acccsu restrictions, nonstop travel etc. have to bc individually tailored to each passenger. AI plamling technology offers a very elegant and flexible solution because the possible actions of a control system can be made explicit and their preconditions and effects can bc specified using expressive representation formalisms. Based on the specification, a planner can flexibly synthesize the required control and dmnges in the specification do not require any reimplementation of the control software. In this pap~, we describe the application and investigate how currently available domain-independent plamting formalksms can cope with it.", "num_citations": "65\n", "authors": ["643"]}
{"title": "Untangling unstructured cyclic flows\u2013a solution based on continuations\n", "abstract": " We present a novel transformation method that allows us to map unstructured cyclic business process models to functionally equivalent workflow specifications that support structured cycles only. Our solution is based on a continuation semantics, which we developed for the graphical representation of a process model. By using a rule-based transformation method originally developed in compiler theory, we can untangle the unstructured flow while solving a set of abstract continuation equations. The generated workflow code can be optimized by controlling the order in which the transformation rules are applied.               We then present an implementation of the transformation method that directly manipulates an object-oriented model of the Business Process Execution Language for Web Services BPEL4WS. The implementation maps abstract continuation equations to the BPEL4WS control-flow graph. The\u00a0\u2026", "num_citations": "64\n", "authors": ["643"]}
{"title": "An application of terminological logics to case-based reasoning\n", "abstract": " A key problem in case-based reasoning is the representation, organization and maintenance of case libraries. While current approaches rely on heuristic and psychologically inspired formalisms, terminological logics have emerged as a powerful representation formalism with clearly defined formal semantics. This paper demonstrates how the indexing of case libraries can be grounded on terminological logics by using them as a kind of query language to the case library. Indices of cases are represented as concepts in a terminological logic. They are automatically constructed from the symbolic representation of cases with the help of a well-defined abstraction process. The retrieval of cases from the library is grounded on concept classification. The theoretical approach provides the formal foundation for the fully implemented case-based planning system MRL. The use of terminological logics allows formal proof of\u00a0\u2026", "num_citations": "62\n", "authors": ["643"]}
{"title": "PHI: a logic-based tool for intelligent help systems\n", "abstract": " We introduce a system which improves the performance of intelligent help systems by supplying them with plan generation and plan recognition components. Both components work in close mutual cooperation. We demonstrate two modes of cross-talk between them, one where plan recognition is done on the basis of abstract plans provided by the planner and the other where optimal plans are generated based on recognition results. The examples which are presented are taken from an operating system domain, namely from the UNIX mail domain. Our system is completely logic-based. Relying on a common logical framework--the interval-based modal temporal logic LLP which we have developed--both components are implemented as special purpose inference procedures. Plan generation from first and second principles is provided and carried out deductively, whereas plan recognition follows a new abductive approach for modal logics. The plan recognizer is additionally supplied with a probabilistic reasoner as a means to adjust the help provided for user-specific characteristics.", "num_citations": "49\n", "authors": ["643"]}
{"title": "Plan modifications versus plan generation: A complexity-theoretic perspective\n", "abstract": " The ability of a planner to modify a plan is considered as a valuable tool for improving efficiency of planning by avoiding the repetition of the same planning effort. From a computational complexity point of view, however, it is by no means obvious that modifying a plan is computationally as easy as planning from scratch if the modification has to follow the principle of \"conservatism\", i.e., to reuse as much of the old plan as possible. Indeed, considering propositional STRIPS planning, it turns out that conservative plan modification is as hard as planning and can sometimes be harder than plan generation. Furthermore, this holds even if we consider modification problems where the old and the new goal specification are similar. We put these results into perspective and discuss the relationship to existing plan modification systems. Although sometimes claimed otherwise, these systems do not address the modification problem, but use a non-conservative form of plan modification as a heuristic technique.", "num_citations": "49\n", "authors": ["643"]}
{"title": "On autonomic computing architectures\n", "abstract": " We discuss the key features of autonomic computing and their relationship to AI systems. We present a generic architecture for autonomic computing systems and propose a computational model based on communicating automata networks to implement such architectures. We illustrate this approach with an intelligent device discovery tool that analyzes the inventory and topology of large computer networks.", "num_citations": "47\n", "authors": ["643"]}
{"title": "Deductive planning and plan reuse in a command language environment\n", "abstract": " In this paper we introduce a deductive planning system currently being developed as the kernel of an intelligent help system. It consists of a deductive planner and a plan reuse component and with that provides planning from first as well as planning from second principles. Both components rely upon an interval-based temporal logic. The deductive formalisms realizing plan formation from formal specifications and the reuse of already existing plans respectively are presented and demonstrated by examples taken from an operating system's domain.", "num_citations": "44\n", "authors": ["643"]}
{"title": "A new method to index and query sets\n", "abstract": " Let us consider the following problem: Given a (probably huge) set of sets S and a query set g, is there some set s S such that This problem occurs in at least four application areas: the match ing of a large number (usually several 100,000 s) of production rules, the pro cessing of queries in data bases support ing set-valued attributes, the identifica tion of inconsistent subgoals during ar tificial intelligence planning and the de tection of potential periodic chains in la beled tableau systems for modal logics. In this paper, we introduce a data struc ture and algorithm that allow a com pact representation of such a huge set of sets and an efficient answering of subset and superset queries. The algorithm has been used successfully in the IPP system and enabled this planner to win the ADL track of the first planning competition.", "num_citations": "42\n", "authors": ["643"]}
{"title": "Solving Complex Planning Tasks Through Extraction of Subproblems.\n", "abstract": " The paper introduces an approach to derive a total ordering between increasing sets of subgoals by defining a relation over atomic goals. The ordering is represented in a so-called goal agenda that is used by the planner to incrementally plan for the increasing sets of subgoals. This can lead to an exponential complexity reduction because the solution to a complex planning problem is found by solving easier subproblems. Since only a polynomial overhead is caused by the goal agenda computation, a potential exists to dramatically speed up planning algorithms as we demonstrate in the empirical evaluation.", "num_citations": "42\n", "authors": ["643"]}
{"title": "Flexible plan reuse in a formal framework\n", "abstract": " The reuse of plans is widely considered as a valuable tool for the improvement of e ciency in planning systems because it avoids the repetition of planning e ort. Several approaches which investigate the modi cation and reuse of sequential plans in the framework of strips-based planning have been developed.In this paper we present a domain-independent approach to exible plan reuse based on a deductive framework. A formalization of the whole reuse process is proposed including the modi cation, representation and retrieval of plans. Plan modi cation is based on a semantic approach which yields provably correct modi ed plans. The plan library is represented in a hybrid knowledge representation formalism linking the planning logic with a terminological logic and is dynamically created and maintained by the system requiring no user interaction.", "num_citations": "41\n", "authors": ["643"]}
{"title": "Repository for business processes and arbitrary associated metadata\n", "abstract": " We have published a repository for storing business processes and associated metadata. The BPEL Repository is an Eclipse plug-in originally built for BPEL business processes and other related XML data. It provides a framework for storing, finding and using these documents. Other research prototypes can reuse these features and build on top of it. The repository can easily be extended with new types of XML documents. It provides a Java API for manipulating the XML files as Java objects hiding the serialization and de-serialization from a user. This has the advantage that the user can manipulate the data as more convenient Java objects, although the data is stored as XML files compliant with the standard XML schemas. The data can be queried as Java objects using an object-oriented query language, namely the Object Constraint Language (OCL). Moreover, the flexible design allows the OCL query engine to be replaced with another engine based on other query language.", "num_citations": "40\n", "authors": ["643"]}
{"title": "Planning with workflows-an emerging paradigm for web service composition\n", "abstract": " In a previous work, we had analyzed the gaps in the prevalent approaches (ie, Semantic Web Services and WSDL-described Web Services) for the problems of modeling, composing, executing, and verifying Web services, and derived challenges for the AI planning community. The challenges were in representation of complex actions, handling of richly typed messages, dynamic object creation and specification of multi-partner interactions. An important question that constantly arose was how the goals for automatic composition would be derived. In this paper, we revisit this issue in the light of new trends in software engineering towards Model Driven Architecture and early deployment of Web service composition solutions. We argue that Web services composition can not be seen as a one-shot plan synthesis problem defined with explicit goals but rather as a continual process of manipulating complex workflows, which requires to solve synthesis, execution, optimization, and maintenance problems as goals get incrementally refined. We then identify additional issues that become important in applying planning techniques.", "num_citations": "38\n", "authors": ["643"]}
{"title": "System and method for creating and expressing risk-extended business process models\n", "abstract": " A method and computer program product for integrating risk management concepts into a standard business process metamodel by defining a set of metamodel extensions to standard process modeling languages that incorporate risk information directly in the process model. The method includes collecting risk-relevant information for addition to a business process model, and enabling visualizing of a risk-extended business process model. using a notation to express notions as failure modes of resources, root cause events, and sources of execution failure and low job output quality directly in the context of process models. Additionally, the method enables the computation of risk-related impacts on the distribution of process performance measures using a Bayesian network model or a discrete-event simulation model.", "num_citations": "31\n", "authors": ["643"]}
{"title": "Handling of conditional effects and negative goals in IPP\n", "abstract": " This report describes an extension of planning graphs to handle conditional effects and true negation in the system IPP. Starting from the planning formalism ADL, a formal semantics for parallel plans containing actions with conditional effects is defined. We review the formalism of planning graphs, which was developed in the Graphplan system and show how the approach can be extended to deal with the full expressivity of ADL. In contrast to Graphplan, IPP does not generate the planning graph explicitely, but builds only one fact and action layer. Furthermore, actions and states are represetended using a bitvector representation, which allows for the time-and memory-efficient implementation of the sound and complete search algorithm.", "num_citations": "30\n", "authors": ["643"]}
{"title": "Method for generating an executable workflow code from an unstructured cyclic process model and method for executing a workflow code of an arbitrary process model\n", "abstract": " A method for generating an executable workflow code from an unstructured cyclic process model comprises the following steps. First, the unstructured cyclic process model is transformed into a preliminary workflow code. Then, from the preliminary workflow code the executable workflow code is generated by eliminating unstructured cycles.", "num_citations": "29\n", "authors": ["643"]}
{"title": "Architectural decision models as micro-methodology for service-oriented analysis and design\n", "abstract": " During the construction of service-oriented architectures, service modelers concern themselves with the characteristics of good services and how such services can be designed. For instance, they look for advice regarding interface granularity and criteria to assess whether existing software assets are fit for reuse in service-oriented environments. There are no straightforward answers to such questions\u2013service identification, specification and realization techniques are required. Service identification and specification are well covered by existing methodologies; for service realization, architectural decision models can be leveraged. At present, the construction of architectural decision models is an education-and labor-intensive undertaking; if such models exist at all, they often are isolated from other artifacts. In this paper, we propose a new engineering approach to service modeling that leverages reusable architectural decision models as its central service realization concept. We outline a multi-level decision tree and position it as a prescriptive service realization methodology for three engagement types observed in practice. The benefits of service engineering with reusable architectural decision models are semiautomatic decision identification in analysis models, improved decision making quality, and better decision enforcement and risk mitigation capabilities.", "num_citations": "29\n", "authors": ["643"]}
{"title": "An impact-oriented maturity model for IT-based case management\n", "abstract": " Case management comprises various complex activities. Consequently, case managers have to balance very diverging requirements and needs, while at the same time facing increasingly complex decisions. Case management software systems (CMS) provide capabilities such as information assessment and handling, decision and collaboration management as well as flexible process guidance to support case managers. When introducing a CMS into an organization, a maturity model of IT-based case management helps in mastering different levels of technology adoption by exploiting technological benefits and carefully addressing associated risks. In this paper, we propose the C3M maturity model for IT-based case management that links maturity levels with sets of capabilities that are typical for case management in social work, health care, and the handling of complex claims in insurance. The model focuses\u00a0\u2026", "num_citations": "27\n", "authors": ["643"]}
{"title": "Business Process Model and Notation\n", "abstract": " The Business Process Model and Notation (BPMN) has seen a huge uptake in both academia and industry over the past years. It is seen by many as the de facto standard for business process modeling and has become very popular with business analysts, tool vendors and end users. As of version 2.0, the BPMN contains a comprehensive set of concepts and notational elements, as well as an execution semantics, an interchange format and a mapping to the Business Process Execution Language (BPEL). This enables it to be used for many different purposes, such as business process modeling and the development of tools for workflow enactment or simulation.The BPMN 2011 workshop was the third workshop in the BPMN workshop series and was held in Lucerne, Switzerland, at the University of Applied Sciences and Arts. The workshop lasted two days and consisted of both a scientific and a practitioner event\u00a0\u2026", "num_citations": "26\n", "authors": ["643"]}
{"title": "Method for generating a business process execution language for web services executable workflow code from an unstructured cyclic business process model\n", "abstract": " A method for generating a BPEL4WS executable workflow code from an unstructured cyclic business process model. The method inputs a graphical representation of the business process model using a graphical modeling language. The graphical representation comprises activities, decisions and an unstructured cycle including more than one entry or more than one exit to an activity or a decision. The method assigns continuation semantics to the graphical representation which comprises partitioning the activities and the decisions of the graphical representation into the past, present, and future. The method assigns a continuation variable to a start and an end of the graphical representation and assigns a continuation variable to each activity and each decision that has more than one incoming link or more than one outgoing link.", "num_citations": "24\n", "authors": ["643"]}
{"title": "On the Instantiation of ADL Operators Involving Arbitrary First-Order Formulas.\n", "abstract": " The generation of the set of all ground actions for a given set of ADL operators, which are allowed to have conditional e ects and preconditions that can be represented using arbitrary rst-order formulas is a complex process which heavily in uences the performance of any planner or pre-planning analysis method. The paper describes a sophisticated instantiation procedure that determines so-called inertia in a given problem representation and uses them to perform simpli cations of formulas during the instantiation process. As a result, many inapplicable actions are detected and ruled out from the domain representation yielding a much smaller search space for the planner.", "num_citations": "24\n", "authors": ["643"]}
{"title": "Business process innovation with artificial intelligence: Levering Benefits and controlling operational risks\n", "abstract": " Artificial Intelligence (AI) is gaining a strong momentum in business leading to novel business models and triggering business process innovation. This article reviews key AI technologies such as machine learning, decision theory, and intelligent search and discusses their role in business process innovation. Besides discussing potential benefits, it also identifies sources of potential risks and discusses a blueprint for the quantification and control of AI-related operational risk.", "num_citations": "21\n", "authors": ["643"]}
{"title": "Capabilities and levels of maturity in it-based case management\n", "abstract": " We present the results of a case study where we compared the needs of case managers with the capabilities of case management software systems (CMS) in social work, health care, and the handling of complex claims in insurance. Building on existing maturity models, we relate capabilities with maturity levels and present the C3M maturity model for IT-based case management.               Whereas vendors of business process management suites (BPMS) argue that case management requires flexible process guidance and improved context-sensitive information handling, we identify case assessment and case similarity as key capabilities of future CMS. We show how these and other capabilities are implemented in CMS today and discuss future trends of how CMS capabilities will evolve further. Furthermore, we discuss the impact of CMS technology on the practice of case management in an organization\u00a0\u2026", "num_citations": "20\n", "authors": ["643"]}
{"title": "Method and system for combining quality assurance and model transformations in a business-driven development environment\n", "abstract": " A system for combining quality assurance and model transformations in a business-driven development environment includes a host system executing a business modeling application, a transformation framework including a transformation programming interface (TPI) and a quality assurance framework executing on top of the business modeling application, and a plurality of transformation plug-in tools in communication with the TPI. The TPI includes options for model access and traversal, model element creation/removal, model element property editing and analysis. The options are applied to the transformations, via the selected transformation plug-in tools, to a business model resulting in a modified business model that conforms to an information technology (IT)-based executable code. The quality assurance framework performs single-entry-single-exit (SESE) fragment decomposition of the modified business\u00a0\u2026", "num_citations": "20\n", "authors": ["643"]}
{"title": "Handling of inertia in a planning system\n", "abstract": " The generation of the set of all ground actions for a given set of ADL operators, which are allowed to have conditional effects and preconditions that can be represented using arbitrary first-order formulas is a complex process which heavily influences the performance of any planner or preplanning analysis method. The paper describes a sophisticated instantiation procedure that determines so-called inertia in a given problem representation and uses them to perform simplifications of formulas during the instantiation process. As a result, many inapplicable actions are detected and ruled out from the domain representation yielding a much smaller search space for the planner. May 1 Introduction A planning system that handles a more expressive language than STRIPS requires sophisticated algorithmic solutions to quite a number of problems, which have nothing to do with the actual search process for a plan. One of these problems concerns the computation of the set of actions as all ground...", "num_citations": "20\n", "authors": ["643"]}
{"title": "Method for generating an executable workflow code from an unstructured cyclic process model\n", "abstract": " A method for generating an executable workflow code from an unstructured cyclic process model. The method comprises the following steps. First a continuation equation system is generated from the unstructured cyclic process model. Then, the executable workflow code is generated from the continuation equation system, wherein therefore, the continuation equation system is solved by means of transformation rules.", "num_citations": "18\n", "authors": ["643"]}
{"title": "The Process-Rule Continuum-Can BPMN & SBVR Cope with the Challenge?\n", "abstract": " With increasing needs for business agility and cost pressures on IT, Business Process Management (BPM) is asked to move towards \"Dynamic BPM\" and \"Intelligent Case Management\" instead of freezing process flows in hard to change IT solutions. Although business rules are considered an important ingredient of dynamic BPM solutions, only little is understood about the interplay of business processes and business rules. We report on the results of a case study in the area of electronic billing where we explored the interplay between business processes and business rules based on a set of scenarios for the so-called process-rule continuum proposed by Gartner. We critically review these scenarios and argue that they can be reduced to 4 key patterns of rule usage. We review the BPMN and SBVR standards to which extent they support these 4 key patterns and identify critical gaps that should be addressed by\u00a0\u2026", "num_citations": "16\n", "authors": ["643"]}
{"title": "A collaboration and productiveness analysis of the BPM community\n", "abstract": " The main scientific event for academics working in the field of Business Process Management is the International BPM Conference. In this paper, social network analysis techniques are used to unveil the co-authorship networks that can be derived from the papers presented at this conference. Links between two researchers are established by their co-authorship of a paper at one of the conference editions throughout the years 2003-2008. Beyond the relations between individual authors, aggregated analyses are presented of the interactions between the institutes that the authors are affiliated with as well as their country of residence. Additionally, the output of individual authors is measured. All analyses are carried out for the individual conference years and at cumulative levels. In this way, this paper identifies the hotbeds of BPM research and maps the progressive collaboration patterns within the BPM\u00a0\u2026", "num_citations": "16\n", "authors": ["643"]}
{"title": "The role of architectural decisions in model-driven SOA construction\n", "abstract": " On Service-Oriented Architecture (SOA) delivery projects, practitioners concern themselves with the characteristics of good services and how such services can be designed. For instance, they look for advice regarding interface granularity and criteria to assess whether existing software assets are fit for reuse in SOA environments. In this paper, we position architectural decision modeling as a prescriptive service realization technique. We propose a multidimensional SOA decision catalog, separating platform-independent from platform-specific concerns and supporting dependency management. The catalog is positioned in a three-stage model transformation chain for SOA.", "num_citations": "16\n", "authors": ["643"]}
{"title": "Avoiding Pitfalls in Case-based Planning.\n", "abstract": " Case-based planning is considered as a valuable tool for improving efficiency in planning by reuse and modification of existing plans. In this paper, the results of an empirical study are discussed in which several factors influencing case-based planning are investigated. The results demonstrate relative efficiency gains or losses caused by different refitting strategies, different types of plans or typical properties of the application domain and identify possible pitfalls for case-based planning.", "num_citations": "16\n", "authors": ["643"]}
{"title": "Integrated Plan Generation and Recognition\u2014A Logic-Based Approach\u2014\n", "abstract": " The work we present in this paper is settled within the field of intelligent help systems. Intelligent help systems aim at supporting users of application systems by the achievements of qualified experts. In order to provide such qualified support our approach is based on the integration of plan generation and plan recognition components. Plan recognition in this context serves to identify the users goals and so forms the basis for an active user support. The planning component dynamically generates plans which are proposed for the user to reach her goal. We introduce a logic-based approach where plan generation and plan recognition is done on a common logical basis and both components work in some kind of cross-talk.", "num_citations": "15\n", "authors": ["643"]}
{"title": "Metric planning using planning graphs-a first investigation\n", "abstract": " After the extension of the graphplan formalism to ADL, another important aspect of planning problems forms the focus for the development of IPP: resourceconstrained planning problems. IPP's basic resource representation language BRL is motivated, and its syntax and semantics are de ned. A sound and complete search algorithm is de ned, which can be easily extended to handle conditional resource e ects. Examples illustrate the use of the BRL formalism.", "num_citations": "14\n", "authors": ["643"]}
{"title": "How to Augment a Formal System with a Boolean Algebra Component\n", "abstract": " Reasoning with Boolean Algebras is just propositional reasoning. This is well investigated and a lot of good algorithms have been developed. Other formal systems, for example mathematical programming for reasoning about arithmetical equation systems, are equally well developed. Combining such a system with a Boolean component where the Boolean expressions are interpreted as sets, would allow one to use arithmetical algorithms to reason about numerical features of sets.", "num_citations": "14\n", "authors": ["643"]}
{"title": "Role Hierarchies and Number Restrictions.\n", "abstract": " We present the atomic decomposition technique as a general method for reducing reasoning about cardinalities of sets, in the DL case the cardinalities of role llers, to equation solving problems. Then we apply the technique to a particular description logic with complex role terms and role hierarchies and a strong arithmetic component.", "num_citations": "14\n", "authors": ["643"]}
{"title": "Managing the life cycle of plans\n", "abstract": " The scalability of recent planning algorithms allows developers to automate planning tasks, which so far have been reserved to humans. However in real-world applications, synthesizing a plan is just the beginning of a complex life-cycle management process. Plans must be organized in large collections, where they can be grouped along different purposes and are amenable to the search, inspection, evaluation, and modification by human experts or automated reasoning systems. Eventually, plans will outlast their utility and be replaced.We present our solution to plan life cycle management for an autonomic computing application. We focus in particular on the automatic synthesis of plan metadata for plans containing conditional and parallel actions, well-structured loops, and non-deterministic choices. The plans are of unknown origin, ie, their underlying action model, which could provide us with pre-and postconditions, is not available. New analysis techniques are presented that uniformly generate metadata for plans, thus allowing a system to embed plans into context and organize them in meaningfully structured plan repositories.", "num_citations": "13\n", "authors": ["643"]}
{"title": "Travel sequence planning for elevators\n", "abstract": " A method and an apparatus for determining the optimal travel sequence for an elevator installation includes smart terminals sending destination specific travel requests and other planning information to a job manager for each elevator car. The job managers perform a situation-based search process to determine the optimal travel sequence plan for the associated elevator and submit an offer to the terminal sending the travel request. The terminal compares offers and books a selected one. The job managers are responsive to relevant changes in the situation upon which the plan is based for determining a changed actual travel sequence and associated changed offer.", "num_citations": "13\n", "authors": ["643"]}
{"title": "Constraint deduction in an interval-based temporal logic\n", "abstract": " We describe reasoning methods for the interval-based modal temporal logic LLP which employs the modal operators sometimes, always, next, and chop. We propose a constraint deduction approach and compare it with a sequent calculus, developed as the basic machinery for the deductive planning system PHI which uses LLP as underlying formalism.", "num_citations": "13\n", "authors": ["643"]}
{"title": "Mobilizing agencies for incidence surveys on child maltreatment: successful participation in Switzerland and lessons learned\n", "abstract": " Many countries around the world lack data on the epidemiology of agency response to child maltreatment. They therefore lack information on how many children in need get help and protection or if children stand equal chances across regions to get services. However, it has proven difficult to commit child protection agencies to participation in incidence studies. The Optimus Study invested in a continuous collaborative effort between research and practice to develop a data collection for the first national study on the incidence of agency responses to all forms of child maltreatment in Switzerland. An innovative approach of utilizing individual agencies\u2019 standardized data reduced work burden for participation respectably: any arbitrary excerpt of data on new cases between September 1 and November 30, 2016, could be uploaded to a secured web-based data integration platform. It was then mapped automatically to fit the study\u2019s definitions and operationalizations. This strategy has led to a largely successful participation rate of 76% of agencies in the nationwide sample. 253 agencies from the social and health sector, public child protection, and the penal sector have provided data. Valuing agencies context-specific knowledge and expertise instead of viewing them as mere providers of data is a precondition for representativeness of incidence data on agency responses to child maltreatment. Potential investigators of future similar studies might benefit from the lessons learned of the presented project.", "num_citations": "12\n", "authors": ["643"]}
{"title": "The role of BPMN in a modeling methodology for dynamic process solutions\n", "abstract": " This paper introduces a design method for dynamic business process management solutions in which the well-known modeling elements of business object life cycles, business rules, and business activities are integrated in a distributed system as equal communicating components. Using the EURENT car rental domain originally developed by the business rules community, it is demonstrated how this method can be used to enable adhoc and rule-driven activities integrated with the life cycle management of business objects. A modeling methodology based on BPMN collaboration diagrams is proposed to describe component interactions and behavior. Agile principles are applicable to incrementally build the solution in which scenarios play a major role to validate and further evolve the solution\u2019s behavior. A clear separation between components, their interaction, and details of the internal component\u00a0\u2026", "num_citations": "11\n", "authors": ["643"]}
{"title": "Online Synthese von Aufzugssteuerungen als Planungsproblem.\n", "abstract": " Bei MICONIC-10, einem neuartigen Aufzugssystem der Firma Schindler Aufz uge AG, geben die Passagiere schon vor Fahrtantritt das Zielstockwerk an. Dies erm oglicht es, Passagiere einzeln zu erfassen und somit auf ihre speziellen Bed urfnisse einzugehen. Gleichzeitig soll m oglichst der Aufzugsbetrieb optimiert werden. Eine komplexit atstheoretische Analyse des Problems zeigt jedoch sofort, da das Minimierungsproblem bez uglich der L osungsl ange NP-vollst andig ist. Eine direkte Berechnung eines minimalen Fahrtwegs des Aufzugs ist somit e zient nicht m oglich. Da das Problem Planungscharakter hat {es soll der Fahrtweg des Aufzugs geplant werden {bietet sich eine entsprechende Modellierung an. Nachfolgend diskutieren wir zwei alternative Realisierungen des Planungsverfahrens. Die erste Realisierung basiert auf einem Constraint-Satisfaction Algorithmus, die zweite auf einer heuristisch angesteuerten Vorw artssuche.", "num_citations": "10\n", "authors": ["643"]}
{"title": "Method for creating and expressing risk-extended business process models\n", "abstract": " A method and computer program product for extending a business process model. The method includes specifying first elements representing performance measures and objectives of a business process which may be compromised by risk events; specifying second elements representing contextual information describing circumstances which may be relevant to a failure mode of the process, said contextual information comprising a type and state of: resources to support the process, of jobs and artifacts that undergo the process; and, a type and state of environmental factors; specifying third elements representing errors which may occur during process execution; specifying fourth elements representing causal relationships among risk events related to the resources, activities, and said environmental factors that may influence process execution; and providing a set of metamodel extensions to a standard process\u00a0\u2026", "num_citations": "9\n", "authors": ["643"]}
{"title": "System and method for hierarchically decomposing process model\n", "abstract": " A system and associated method for hierarchically decomposing a workflow graph G into a process structure tree PST. The workflow graph G is a two-terminal graph parsed into a tree T having triconnected components. Boundary pairs of all triconnected components in T are computed and fragments are discovered with boundary pairs. T is restructured into PST pursuant to categories of triconnected components in T. PST is deterministic and modular. PST represents a block-based process model that has fine blocks of execution units. PST is computed in time linear to the number of edges in G.", "num_citations": "9\n", "authors": ["643"]}
{"title": "Service-oriented computing\u2014introduction to the special theme\n", "abstract": " Service-oriented computing is an emerging cross-disciplinary paradigm for distributed computing, which is changing the way software applications are designed, delivered and consumed. At the heart of service-oriented computing are services that provide autonomous, platform-independent, computational elements that can be described, published, discovered, orchestrated and programmed using standard protocols to build networks of collaborating applications distributed within and across organizational boundaries.Grid services and Web services are currently the most common forms of service for implementing service-oriented computing. Grid services provide the foundation for the distributed execution of long-running scientific computations over very large data sets using a standardized and stateful service interface. Web services provide the basis for the development and execution of business processes that are distributed over the network and available via standard interfaces and protocols. Technically, these two types of service have converged to a large extent in recent years, but the difference in application focus leads to a variety of complementing research questions.", "num_citations": "8\n", "authors": ["643"]}
{"title": "Planning with goal agendas\n", "abstract": " The paper introduces an approach to derive a total ordering between increasing sets of subgoals by defining a relation over atomic goals. The ordering is represented in a so-called goal agenda that is used by the planner to incrementally plan for the increasing sets of subgoals. This can lead to an exponential complexity reduction because the solution to a complex planning problem is found by solving easier subproblems. Since only a polynomial overhead is caused by the goal agenda computation, a potential exists to dramatically speed up planning algorithms as we demonstrate in the empirical evaluation. This technical report is an extended and updated version of the paper Solving Complex Planning Tasks Through Extraction of Subproblems that has been published at AIPS-98. Contents 1 Introduction 1 2 Defining a Relation between Atomic Goals 2 2.1 Exploiting Knowledge about the State s A................... 3 2.2 Restricting the action set O................", "num_citations": "8\n", "authors": ["643"]}
{"title": "Reasoning about sets via atomic decomposition\n", "abstract": " We introduce a new technique that translates cardinality information about finite sets into simple arithmetic terms and thereby enables a system to reason about such set cardinalities by solving arithmetic equation problems. The atomic decomposition technique separates a collection of sets into mutually disjoint smallest components (\" atoms\") such that the cardinality of the sets are just the sum of the cardinalities of their atoms. With this idea it is possible to have languages combining arithmetic formulae with set terms, and to translate the formulae of this combined logic into pure arithmetical formulae. As a particular application we show how this technique yields new inference procedures for concept languages with so called number restriction operators.", "num_citations": "8\n", "authors": ["643"]}
{"title": "Correct modification of complex plans\n", "abstract": " We present a general approach to exible plan modi cation based on a deductive framework that enables a planner to correctly modify complex plans containing control structures like conditionals and iterations.", "num_citations": "8\n", "authors": ["643"]}
{"title": "Towards a logical treatment of plan reuse\n", "abstract": " We discuss a deductive approach to plan reuse that integrates planning from second principles into a deductive planner. The logical formalism is reflected in a theorem proving approach in which the reuse component tries to prove a new plan specification using one of the generalized plan specifications stored in a plan library. If the proof succeeds the old plan can be used to satisfy even the new specification. If it fails the information for successfully modifying the old plan can be extracted from the failed proof.", "num_citations": "8\n", "authors": ["643"]}
{"title": "The Process-Rule Continuum\u2014How can the BPMN and SBVR Standards interplay?\n", "abstract": " With increasing needs for business agility and cost pressures on IT, Business Process Management (BPM) is asked to move towards \u201cDynamic BPM\u201d and \u201cIntelligent Case Management\u201d instead of freezing process flows in hard-tochange IT solutions. Although business rules are considered an important ingredient of dynamic BPM, only little is understood about the interplay of business processes and business rules. Today\u2019s business process and business rule management systems only support one scenario of using business rules in business processes and show difficulty to evolve to more agile scenarios. Gartner has recently published a report about the so-called process-rule continuum that sketches seven scenarios of how rules and processes can be combined. In this paper, we refine these scenarios, draw precise borderlines between them, and describe concrete patterns of rule usage for each scenario. We show how the BPMN and SBVR standards interplay across the scenarios to support these patterns and identify gaps in the standards.", "num_citations": "7\n", "authors": ["643"]}
{"title": "RIFO within IPP\n", "abstract": " The paper describes the implementation of the RIFO family of heuristics to detect irrelevant operators and initial facts within the IPP planning system. It discusses the main differences to the original RIFO method that was developed by Bernhard Nebel for STRIPS operators. For IPP, this method was extended to handle conditional effects and negation. Furthermore, a metastrategy was added, which allows the planner to decide when to activate RIFO depending on the number of objects and ground operators in a planning problem. A summary of results from the 1998 planning competition shows the effectiveness of this strategy.", "num_citations": "7\n", "authors": ["643"]}
{"title": "Computer-implemented method and systems for assisting a user in applying a business process pattern\n", "abstract": " A computer-implemented method for assisting a user in applying a business process pattern. In some embodiments, the computer-implemented method includes providing a graphical user interface (GUI) adapted for displaying a first representation of a business process and for allowing user editing of the business process. The computer-implemented method also includes receiving a user selection of a fragment of the business process as displayed in the first representation. In some embodiments, the computer-implemented method includes calling a second representation of the business process, the second representation including a hierarchy of fragments of business process, and checking whether the fragment selected by the user corresponds to one of the fragments of the second representation. The computer-implemented method may also include instantiating a business process pattern using the selected\u00a0\u2026", "num_citations": "6\n", "authors": ["643"]}
{"title": "Automatic insertion point identification in model merging operations\n", "abstract": " Methods and systems are provided for automatic identification of an insertion point. Comparison defining the correspondence between elements of models is done. The sequence order of elements in the second model is analyzed to identify predecessor and successor elements of the element t. The comparison is used to identify a set of transferred predecessors (P trans), comprising elements of the first model which correspond to predecessor elements (P S) in the second model, and a set of transferred successors (S trans) comprising elements of the first model which correspond to successor elements (S S) in the second model. Then, positions of the elements x, y in the sequence order of the first model are compared with the positions of elements in the sets of transferred predecessors and successors (P trans, S trans). An edge between the elements x and y is identified as an insertion point.", "num_citations": "6\n", "authors": ["643"]}
{"title": "AI in Switzerland\n", "abstract": " Although Switzerland is a small country, it is home to many internationally renowned universities and scientific institutions. The research landscape in Switzerland is rich, and AI-related themes are investigated by many teams under diverse umbrellas. This column sheds some light on selected developments and trends on AI in Switzerland as perceived by members of the Special Interest group on Artificial Intelligence and Cognitive Science (SGAICO) organizational team, which has brought together researchers from Switzerland interested in AI and cognitive science for over 30 years.", "num_citations": "5\n", "authors": ["643"]}
{"title": "Faster and Better Business Process Modeling with the IBM Pattern-based Process Model Accelerators.\n", "abstract": " The IBM Pattern-based Process Model Accelerators add a set of patterns, transformations, refactoring operations, and a control-flow analysis feature to IBM WebSphere Business Modeler that make it easy for users to apply common best practices when modeling business processes. As a result, users create and edit higher-quality process models and they benefit from the automation of tedious editing tasks resulting in productivity gains and a more enjoyable user experience. This demo targets participants with interest on faster process modeling approaches leading to higher-quality process models.", "num_citations": "5\n", "authors": ["643"]}
{"title": "Towards a Compiler for Business-IT Systems\n", "abstract": " Business information systems and enterprise applications have continuously evolved into Business-IT systems over the last decades, directly linking and integrating Business Process Management with recent technology evolutions such as Web services and Service-Oriented Architectures. Many of these technological evolutions include areas of past academic research: Business rules closely relate to expert systems, Semantic Web technology uses results from description logics, attempts have been made to compose Web services using intelligent planning techniques, and the analysis of business processes and Web service choreographies often relies on model checking. As such, many of the problems that arise with these new technologies have been solved at least in principle.               However, if we try to apply these \u201cin principle\u201d solutions, we are confronted with the failure of these solutions in practice\u00a0\u2026", "num_citations": "5\n", "authors": ["643"]}
{"title": "A classification of UML2 activity diagrams\n", "abstract": " We present the results of a case study where we investigated a semantic mapping of UML2 activity diagrams to the-calculus. Our study was initiated by recent discussions on the role of the-calculus for future business-process management systems as well as our interest in developing formal analysis techniques for activity diagrams.The study revealed interesting insights into the semantic expressivity of activity diagrams and the semantic nature of the different modeling elements, in particular of object nodes and activity final nodes. We show that for certain types of diagrams, a semantic mapping of object nodes, in particular of pins, to message reading and receiving operations is insufficient and propose an encoding of pins as-processes. Our results motivated us to present a novel classification of activity diagrams based on their semantic expressivity.", "num_citations": "5\n", "authors": ["643"]}
{"title": "From theory to practice: AI planning for high performance elevator control\n", "abstract": " Offering an individually tailored service to passengers while maintaining a high transportation capacity of an elevator group is an upcoming challenge in the elevator business, which cannot be met by software methods traditionally used in this industry. AI planning offers a novel solution to these control problems: (1) by synthesizing the optimal control for any situation occurring in a building based on fast search algorithms, (2) by implementing a domain model, which allows to easily add new features to the control software. By embedding the planner into a multi-agent system, real-time interleaved planning and execution is implemented and results in a highperforming, self-adaptive, and modular control software.", "num_citations": "5\n", "authors": ["643"]}
{"title": "IPP--A Planning System for ADL and Resource-Constrained Planning Problems\n", "abstract": " CiteSeerX \u2014 IPP -- A Planning System for ADL and Resource-Constrained Planning Problems Documents Authors Tables Log in Sign up MetaCart DMCA Donate CiteSeerX logo Documents: Advanced Search Include Citations Authors: Advanced Search Include Citations Tables: DMCA IPP -- A Planning System for ADL and Resource-Constrained Planning Problems (1999) Cached Download as a PDF Download Links [user.enterpriselab.ch] [user.enterpriselab.ch] Save to List Add to Collection Correct Errors Monitor Changes by Jana K\u00f6hler Summary Citations Active Bibliography Co-citation Clustered Documents Version History Share Facebook Twitter Reddit Bibsonomy OpenURL Abstract Keyphrases ipp planning system resource-constrained planning problem Powered by: Apache Solr About CiteSeerX Submit and Index Documents Privacy Policy Help Data Source Contact Us Developed at and hosted by The \u2026", "num_citations": "5\n", "authors": ["643"]}
{"title": "Approaches to the reuse of plan schemata in planning formalisms\n", "abstract": " Planning in complex domains is normally a resource and time consuming process when it is purely based on first principles. Once a plan is generated it represents problem solving knowledge. It implicitly describes knowledge used by the planning system to achieve a given goal state from a particular initial state. In classical planning systems, this knowledge is often lost after the plan has been successfully executed. If such a planner has to solve the same problem again, it will spend the same planning effort to solve it and is not capable of \"learning'; from its \"experience';. Therefore it seems to be useful to save generated plans for a later reuse and thus, extending the problem solving knowledge possessed by the planner. The planning knowledge can now be applied to find out whether a problem can be solved by adapting an already existing plan. The aim of this paper is to analyze the problem of plan reuse and to describe the state of the art based on a variety of approaches which might contribute to a solution of the problem. It describes the main problems and results that could be of some relevance for the integration of plan reuse into a deductive planning formalism. As a result, this description of the state of the art leads to a deeper insight into the complex problem of plan reuse, but also shows that the problem itself is still far from being solved.", "num_citations": "5\n", "authors": ["643"]}
{"title": "Towards intelligent process support for customer service desks: Extracting problem descriptions from noisy and multi-lingual texts\n", "abstract": " Customer service is a differentiating capability for companies, but it faces significant challenges due to the growing individualization and connectivity of products, the increasing complexity of knowledge that service employees need to deal with, and steady cost pressure. Artificial intelligence (AI) can support service processes in a variety of ways, however, many projects simply propose replacing employees with chat bots. In contrast to pure automation focusing on customer self-service, we introduce three intelligent assistants that support service employees in their complex tasks: the scribe, the skill manager, and the background knowledge worker.               In this paper, we discuss the technology and architecture underlying the skill manager in more detail. We present the results from an evaluation of commercial cognitive services from IBM and Microsoft on comprehensive real-world data that comprises over\u00a0\u2026", "num_citations": "4\n", "authors": ["643"]}
{"title": "System and method to create process reference maps from links described in a business process model\n", "abstract": " A method of constructing a process reference map. The method includes iterating over each of a plurality of process models. An intermediary reference graph is created. A directed link for each reference in the process models is added to the intermediary reference graph, the link pointing from a node in the reference graph representing a process model within which a reference occurred to a node representing a process model that the reference is pointing towards. The method determines, between two process models of the plurality of process models, whether an inconsistency including one of an outbound process reference missing inconsistency, an inbound process reference missing inconsistency, and an unavailable information inconsistency exists. A new process model map is created from the intermediary reference graph with one element each representing a process models and the elements being linked\u00a0\u2026", "num_citations": "4\n", "authors": ["643"]}
{"title": "Business process management: 7th international conference, BPM 2009, Ulm, Germany, September 8-10, 2009, proceedings\n", "abstract": " The BPM (Business Process Management) Conference series has the ambition to be the premier forum for researchersin the area of process-awareinformation systems. It has a recordfor attracting contributions in innovative researchofthe highest quality related to all aspects of business process management including theory, frameworks, methods, techniques, architectures, and empirical? ndings. BPM 2009 was the 7th instantiation of this series. It took place in Ulm, G-many, September 8\u201310, 2009, organized by the Institute of Databases and Inf-mation Systems of the University of Ulm. This volume contains 17 contributed research papers and two contributed industrial papers selected from 116 s-missions from 31 countries. The thorough reviewing process\u2014each paper was reviewed by three to? ve Program Committee members\u2014was extremely c-petitive as the acceptance rate of 16% indicates. In addition to the contributed papers, these proceedings contain two papers and an outline documenting the invited keynote talks. Furthermore, a report is included on the collaboration structure in BPM research derived from an analysis of papers accepted for all past BPM conferences. In conjunction with the main conference, nine international workshops took place the day before the conference. These workshops fostered the exchange of fresh ideas and experiences between active BPM researchers, and stimulated discussions on new and emerging issues in line with the conference topics. The proceedings with the papers of all workshops will be published in a separate volume of Springer\u2019s Lecture Notes in Business Information Processing series.", "num_citations": "4\n", "authors": ["643"]}
{"title": "Ibm pattern-based process model accelerators for websphere business modeler\n", "abstract": " IBM R Pattern-based process Model Accelerators for WebSphere R Business Modeler are a set of features designed specifically for users who create and edit process models using WebSphere Business Modeler. The accelerators provide users with a set of plug-ins for IBM WebSphere Business Modeler V6. 2 that add patterns, transformations and refactorings to the business process modeling environment. In addition, a feature to automatically detect control-flow errors is now available. By using the accelerators users can move away from a traditional business process modeling approach where process models are drawn by dragging and dropping elements on the drawing canvas that are then manually connected. The accelerators make it possible to create business process models of higher quality by composing them from larger building blocks or by applying semantically correct change operations to a model with a single click. Models will contain significantly less modeling errors, modeling becomes a much more fun exercise and users will experience productivity gains of about 70% compared to the traditional approach. This technical report contains a series of 4 articles that provide users with detailed documentation of the accelerators. Part 1 of this article series contains a tutorial that gives an overview of how to work with the accelerators while modeling a business process. Part 2 presents the business process patterns that are available in this release, while Parts 3 and 4 explain process model transformations and refactorings in detail.", "num_citations": "4\n", "authors": ["643"]}
{"title": "Using Patterns in the Design of Inter-organizational Systems\u2013An Experience Report\n", "abstract": " The modeling, design, and implementation of inter-organizational systems (IOS) is a challenging new problem. In contrast to previous systems, where components have clearly defined interfaces and serve a well-defined purpose, components of IOS exist in a distributed environment, where each component of the system may exist at a separate corporation and must conform to the interface of partner components. This creates a complicated problem for designers. In this paper, we investigate to which extent control flow, communication, and data manipulation patterns can help to ease the manual design process of IOS implemented in the Business Process Execution Language for Web services (BPEL4WS). By applying patterns of all three types in an iterative fashion we go from an abstract representation of the example process to a graphical solution with a one-to-one mapping to executable BPEL4WS code.", "num_citations": "4\n", "authors": ["643"]}
{"title": "Collecting data on the incidence of child endangerment in Switzerland: Lessons learned\n", "abstract": " There is widespread agreement that in order to make progress in the prevention and reduction of child maltreatment it is important for policy\u2010makers to have information on the scope and characteristics of reported incidents, on gaps and regional disparities in reporting. Globally, studies to nationally collect data on agency responses to child maltreatment are, however, rare (Jud, Fegert, & Finkelhor, 2016; Jud, Fluke, et al., 2013; Kr\u00fcger & Jud, 2015). The first national survey on agency responses to child maltreatment in Switzerland bridges this gap and was highly successful in mobilizing agencies to participate: 81% of the sampled agencies have provided data on their caseload of newly reported incidents between September 1, 2016 and November 30, 2016. Based on these data we have been able to identify regional disparities in reported incidents, biased decision\u2010making, gaps in service provision, etc. These major findings are made available to child protection professionals and the public in a booklet translated into German, French, Italian and English (free download at http://www. optimusstudy. org/index. php? id= 260). Secondary analyses will follow and be published in peer\u2010reviewed academic journals. The present report accompanies the booklet and scrutinizes the survey\u2019s procedure to identify beneficial strategies, hurdles and barriers for future researchers. The lessons learned will cover the contacts with agencies, measures, data collection and cleaning, analyses and dissemination. They both address the expertise and knowledge of social scientists and IT\u2010specialists as both groups have contributed to a successful survey.This first\u00a0\u2026", "num_citations": "3\n", "authors": ["643"]}
{"title": "Kooperative Hilfesysteme f\u00fcr Anwendungssoftware Entwicklungsstand und Forschungstrends\n", "abstract": " Bei der Entwicklung intelligenter Hilfesysteme geht man davon aus, da\u00df ein Benutzer zur Erreichung seines Arbeitsziels einen bestimmten Plan verfolgt, der sich in einer Folge von Bedienaktionen konkretisiert. Ein solcher Plan kann fehlerhaft, suboptimal, oder unvollst\u00e4ndig sein, weil der Bediener die Funktionali\u00e4t des Softwaresystems nur zum Teil beherrscht. Der Begriff planbasierte Hilfesysteme weist auf die zentrale Rolle von Bedienpl\u00e4nen f\u00fcr die Unterst\u00fctzung des Benutzers hin: einerseits mu\u00df das System zun\u00e4chst den intendierten Plan des Benutzers m\u00f6glichst fr\u00fchzeitig erkennen, um rechtzeitige und effiziente Hilfestellungen anzubieten. Andrerseits mu\u00df das Hilfesystem auch in der Lage sein, selbst Pl\u00e4ne zu generieren, die das angenommene Benutzerziel effizient erreichen, zB wenn der Benutzer selbst nicht weiterkommt oder einen offensichtlich fehlerhaften oder im gegebenen Kontext suboptimalen Plan verfolgt. Das bedeutet, da\u00df planbasierte Hilfesysteme \u00fcber Module zur Erkennung und zur Generierung von Pl\u00e4nen verf\u00fcgen m\u00fcssen. Der Umgang mit Pl\u00e4nen ist ein wissensintensiver Prozess, der zB auf die Semantik der elementaren Bedienaktionen Bezug nehmen mu\u00df. Unsere Arbeitshypothese ist, da\u00df solches Planungswissen am besten so repr\u00e4sentiert wird, da\u00df es sowohl f\u00fcr die Plangenerierung als auch f\u00fcr die Planerkennung nutzbar ist.", "num_citations": "3\n", "authors": ["643"]}
{"title": "Planning with communicating automata\n", "abstract": " Until today, planning operators are mostly considered as atomic transitions that change the value of boolean or numeric state variables. This remains also true if nondeterministic effects are added to operator descriptions. Solely, the compound tasks used in HTN planners encapsulate more complex behavior, but it is difficult to model nondeterminism and iterations using HTN representations. In many real-world applications however, in particular in technical environments such as hardware and software systems (for example networks, server farms, or embedded controllers), more expressive planning operators that encapsulate nondeterministic and iterative behavior are needed. In this paper, we propose to use nondeterministic communicating automata as the operators for a planning system. We show how to model such operators, define the planning problem with communicating automata and present a first, preliminary planner involving model checking techniques.", "num_citations": "2\n", "authors": ["643"]}
{"title": "AI for Service Composition\n", "abstract": " In the last years, there has been increasing interest in service composition. The key idea is that existing distributed services can be selected and combined into suitable workflows of tasks, in order to provide new functionalities or applications. Service composition has the potentiality to revolutionize the classical approaches to data integration and business process integration, reducing development time and effort. Standards and platforms based on service models and supporting service composition have been developed in different frameworks, including web services, grid services, and agent services. AI techniques have been used to support different key aspects of the management of service compositions, including tasks such as their generation, allocation of resources, execution, monitoring and repair. For instance, knowledge representation techniques have been exploited to provide suitable semantic annotations of services; planning has been applied to an automatic generation of the workflows composing the services; scheduling has been applied to resource allocation and workflow optimization; and agent techniques have been applied to support a dynamic adaptation of the workflows. However, many issues remain to be resolved. These include (1) forming precise, clean and general characterizations of service compositions, and identifying the most appropriate ways to formalize the critical steps in their life cycle;(2) determining suitable languages to represent service compositions in all their relevant aspects and finding ways of bridging the gap between service composition languages used in the industry and languages exploited in AI\u00a0\u2026", "num_citations": "2\n", "authors": ["643"]}
{"title": "Multi-sectoral response to child maltreatment in Switzerland for different age groups: Varying rates of reported incidents and gaps in identification\n", "abstract": " BackgroundAs many countries lack (multi-sectoral) data on the epidemiology of agency responses to child maltreatment, they do not know if children in different regions of the country have equal chances to receive help and protection. The Optimus Study, the first nationally representative Swiss study on multi-sectoral responses to child maltreatment, examines gaps in identifying children in need and reveals opportunities for improved support and protection.MethodsA stratified sample of 351 agencies (participation rate 81 %) in the social and health sector, public child protection, and the penal sector provided data on new cases between September 1 and November 30, 2016. The resulting study data on 7651 cases included information on the maltreatment incident, specifics of the report/referral, and child characteristics. The weighting procedure to produce national estimates was based on inverse sampling\u00a0\u2026", "num_citations": "1\n", "authors": ["643"]}
{"title": "Automatic insertion point identification in model merging operations\n", "abstract": " Automatic identification of an insertion point is done by comparisons defining the correspondence between elements of models. The sequence order of elements in the second model is analyzed to identify predecessor and successor elements of the element t. The comparison is used to identify a set of transferred predecessors (P trans), comprising elements of the first model which correspond to predecessor elements (P S) in the second model, and a set of transferred successors (S trans) comprising elements of the first model which correspond to successor elements (S S) in the second model. Then, positions of the elements x, y in the sequence order of the first model are compared with the positions of elements in the sets of transferred predecessors and successors (P trans, S trans). An edge between the elements x and y is identified as an insertion point.", "num_citations": "1\n", "authors": ["643"]}
{"title": "On Reasonable and Forced Goal Orderings and their Use in an Agenda-Driven Planning Algorithm\n", "abstract": " The paper addresses the problem of computing goal orderings, which is one of the longstanding issues in AI planning. It makes two new contributions. First, it formally defines and discusses two different goal orderings, which are called the reasonable and the forced ordering. Both orderings are defined for simple STRIPS operators as well as for more complex ADL operators supporting negation and conditional effects. The complexity of these orderings is investigated and their practical relevance is discussed. Secondly, two different methods to compute reasonable goal orderings are developed. One of them is based on planning graphs, while the other investigates the set of actions directly. Finally, it is shown how the ordering relations, which have been derived for a given set of goals G, can be used to compute a so-called goal agenda that divides G into an ordered set of subgoals. Any planner can then, in\u00a0\u2026", "num_citations": "1\n", "authors": ["643"]}
{"title": "The Fourteenth International Conference on Automated Planning and Scheduling (ICAPS-04)\n", "abstract": " The Fourteenth International Conference on Automated Planning and Scheduling (ICAPS-04) was held in Canada in June of 2004. It covered the latest theoretical and empirical advances in planning and scheduling. The conference program consisted of tutorials, workshops, a doctoral consortium, and three days of technical paper presentations in a single plenary track, one day of which was jointly organized with the Ninth International Conference on Principles of Knowledge Representation and Reasoning. ICAPS-04 also hosted the International Planning Competition, including a classical track and a newly formed probabilistic track. This report describes the conference in more detail.", "num_citations": "1\n", "authors": ["643"]}
{"title": "KI 2002: Advances in Artificial Intelligence: 25th Annual German Conference on AI, KI 2002, Aachen, Germany, September 16-20, 2002. Proceedings\n", "abstract": " This book constitutes the refereed proceedings of the 25th Annual German conference on Artificial Intelligence, KI 2002, held in Aachen, Germany in September 2002. The 20 revised full papers presented were carefully reviewed and selected from 58 submissions. The book offers topical sections on natural language processing; machine learning; knowledge representation, semantic web, and AI; neural networks; logic programming, theorem proving, and model checking; and vision and spatial reasoning.", "num_citations": "1\n", "authors": ["643"]}
{"title": "On reasonable and forced goal orderings and their use in an incremental planning algorithm\n", "abstract": " The paper addresses the problem of computing goal orderings, which is one of the longstanding issues in AI planning. It makes two new contributions. First, it formally defines and discusses two different goal orderings, which are called the reasonable and the forced ordering. Both orderings are defined for simple STRIPS operators as well as for more complex ADL operators supporting negation and conditional effects. The complexity of these orderings is investigated and their practical relevance is discussed. Secondly, two different methods to compute reasonable goal orderings are developed. One of them is based on planning graphs, while the other investigates the set of actions directly. Finally, it is shown how the ordering relations, which have been derived for a given set of goals G, can be used to compute a so-called goal agenda that divides G into an ordered set of subgoals. Any planner can then, in principle, use the goal agenda to incrementally plan for increasing sets of subgoals. This can lead to an exponential complexity reduction, as the solution to a complex planning problem is found by solving easier subproblems. Since only", "num_citations": "1\n", "authors": ["643"]}
{"title": "Reasoning about sets via atomic decomposition\n", "abstract": " We introduce a new technique that translates cardinality information about nite sets into simple arithmetic terms and thereby enables a system to reason about such set cardinalities by solving arithmetic equation problems. The atomic decomposition technique separates a collection of sets into mutually disjoint smallest components (\\atoms\") such that the cardinality of the sets are just the sum of the cardinalities of their atoms. With this idea it is possible to have languages combining arithmetic formul with set terms, and to translate the formul of this combined logic into pure arithmetical formul.", "num_citations": "1\n", "authors": ["643"]}
{"title": "Efficient Retrieval with Guaranteed Success\n", "abstract": " The retrieval of appropriate cases is a central problem in case-based reasoning, comprising the indexing and matching of cases. This paper introduces a novel solution to the indexing and matching problem based on description logics. Cases can be represented as usual in any arbitrary case representation formalism, while their indices are represented in the description logic. We obtain a hybrid representation for which ecient retrieval procedures are available that will nd existing solutions to a given case in the case library.", "num_citations": "1\n", "authors": ["643"]}
{"title": "Planning from second principles: a logic-based approach\n", "abstract": " In this paper, a logical formalization of planning from second principles is proposed, which relies on a systematic decomposition of the planning process. Deductive inference processes with clearly defined semantics formalize planning from second principles. Plan modification is based on a deductive approach which yields provably correct modified plans. Reusable plans are retrieved from a dynamically created plan library using terminological logic as a query language to the library. Apart from sequential plans, this approach enables a planner to efficiently reuse and modify plans containing control structures like conditionals and iterations.", "num_citations": "1\n", "authors": ["643"]}