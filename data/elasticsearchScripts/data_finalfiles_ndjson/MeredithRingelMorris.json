{"title": "User-defined gestures for surface computing\n", "abstract": " Many surface computing prototypes have employed gestures created by system designers. Although such gestures are appropriate for early investigations, they are not necessarily reflective of user behavior. We present an approach to designing tabletop gestures that relies on eliciting gestures from non-technical users by first portraying the effect of a gesture, and then asking users to perform its cause. In all, 1080 gestures from 20 participants were logged, analyzed, and paired with think-aloud data for 27 commands performed with 1 and 2 hands. Our findings indicate that users rarely care about the number of fingers they employ, that one hand is preferred to two, that desktop idioms strongly influence users' mental models, and that some commands elicit little gestural agreement, suggesting the need for on-screen widgets. We also present a complete user-defined gesture set, quantitative agreement scores\u00a0\u2026", "num_citations": "1341\n", "authors": ["1183"]}
{"title": "Method and system for usage analyzer that determines user accessed sources, indexes data subsets, and associated metadata, processing implicit queries based on potential\u00a0\u2026\n", "abstract": " The present invention relates to systems and methods providing content-access-based information retrieval. Information items from a plurality of disparate information sources that have been previously accessed or considered are automatically indexed in a data store, whereby a multifaceted user interface is provided to efficiently retrieve the items in a cognitively relevant manner. Various display output arrangements are possible for the retrieved information items including timeline visualizations and multidimensional grid visualizations. Input options include explicit, implicit, and standing queries for retrieving data along with explicit and implicit tagging of items for ease of recall and retrieval. In one aspect, an automated system is provided that facilitates concurrent searching across a plurality of information sources. A usage analyzer determines user accessed items and a content analyzer stores subsets of data\u00a0\u2026", "num_citations": "591\n", "authors": ["1183"]}
{"title": "SearchTogether: an interface for collaborative web search\n", "abstract": " Studies of search habits reveal that people engage in many search tasks involving collaboration with others, such as travel planning, organizing social events, or working on a homework assignment. However, current Web search tools are designed for a single user, working alone. We introduce SearchTogether, a prototype that enables groups of remote users to synchronously or asynchronously collaborate when searching the Web. We describe an example usage scenario, and discuss the ways SearchTogether facilitates collaboration by supporting awareness, division of labor, and persistence. We then discuss the findings of our evaluation of SearchTogether, analyzing which aspects of its design enabled successful collaboration among study participants.", "num_citations": "577\n", "authors": ["1183"]}
{"title": "Tweeting is believing? Understanding microblog credibility perceptions\n", "abstract": " Twitter is now used to distribute substantive content such as breaking news, increasing the importance of assessing the credibility of tweets. As users increasingly access tweets through search, they have less information on which to base credibility judgments as compared to consuming content from direct social network connections. We present survey results regarding users' perceptions of tweet credibility. We find a disparity between features users consider relevant to credibility assessment and those currently revealed by search engines. We then conducted two experiments in which we systematically manipulated several features of tweets to assess their impact on credibility ratings. We show that users are poor judges of truthfulness based on content alone, and instead are influenced by heuristics such as user name when making credibility assessments. Based on these findings, we discuss strategies tweet\u00a0\u2026", "num_citations": "536\n", "authors": ["1183"]}
{"title": "DiamondSpin: an extensible toolkit for around-the-table interaction\n", "abstract": " DiamondSpin is a toolkit for the efficient prototyping of and experimentation with multi-person, concurrent interfaces for interactive shared displays. In this paper, we identify the fundamental functionality that tabletop user interfaces should embody, then present the toolkit's architecture and API. DiamondSpin provides a novel real-time polar to Cartesian transformation engine that has enabled new, around-the-table interaction metaphors to be implemented. DiamondSpin allows arbitrary document positioning and orientation on a tabletop surface. Polygonal tabletop layouts such as rectangular, octagonal, and circular tabletops can easily be constructed. DiamondSpin also supports multiple work areas within the same digital tabletop. Multi-user operations are offered through multi-threaded input event streams, multiple active objects, and multiple concurrent menus. We also discuss insights on tabletop interaction\u00a0\u2026", "num_citations": "483\n", "authors": ["1183"]}
{"title": "SIDES: a cooperative tabletop computer game for social skills development\n", "abstract": " This paper presents a design case study of SIDES: Shared Interfaces to Develop Effective Social Skills. SIDES is a tool designed to help adolescents with Asperger's Syndrome practice effective group work skills using a four-player cooperative computer game that runs on tabletop technology. We present the design process and evaluation of SIDES conducted over six months with a middle school social group therapy class. Our findings indicate that cooperative tabletop computer games are a motivating and supportive tool for facilitating effective group work among our target population and reveal several design lessons to inform the development of similar systems.", "num_citations": "451\n", "authors": ["1183"]}
{"title": "What do you see when you're surfing? Using eye tracking to predict salient regions of web pages\n", "abstract": " An understanding of how people allocate their visual attention when viewing Web pages is very important for Web authors, interface designers, advertisers and others. Such knowledge opens the door to a variety of innovations, ranging from improved Web page design to the creation of compact, yet recognizable, visual representations of long pages. We present an eye-tracking study in which 20 users viewed 361 Web pages while engaged in information foraging and page recognition tasks. From this data, we describe general location-based characteristics of visual attention for Web pages dependent on different tasks and demographics, and generate a model for predicting the visual attention that individual page elements may receive. Finally, we introduce the concept of fixation impact, a new method for mapping gaze data to visual scenes that is motivated by findings in vision research.", "num_citations": "346\n", "authors": ["1183"]}
{"title": "Cooperative gestures: multi-user gestural interactions for co-located groupware\n", "abstract": " Multi-user, touch-sensing input devices create opportunities for the use of cooperative gestures--multi-user gestural interactions for single display groupware. Cooperative gestures are interactions where the system interprets the gestures of more than one user as contributing to a single, combined command. Cooperative gestures can be used to enhance users' sense of teamwork, increase awareness of important system events, facilitate reachability and access control on large, shared displays, or add a unique touch to an entertainment-oriented activity. This paper discusses motivating scenarios for the use of cooperative gesturing and describes some initial experiences with CollabDraw, a system for collaborative art and photo manipulation. We identify design issues relevant to cooperative gesturing interfaces, and present a preliminary design framework. We conclude by identifying directions for future research\u00a0\u2026", "num_citations": "341\n", "authors": ["1183"]}
{"title": "A survey of collaborative web search practices\n", "abstract": " Today's Web browsers provide limited support for rich information-seeking and information-sharing scenarios. A survey we conducted of 204 knowledge workers at a large technology company has revealed that a large proportion of users engage in searches that include collaborative activities. We present the results of the survey, and then review the implications of these findings for designing new Web search interfaces that provide tools for sharing.", "num_citations": "336\n", "authors": ["1183"]}
{"title": "Understanding users' preferences for surface gestures\n", "abstract": " We compare two gesture sets for interactive surfaces\u2014a set of gestures created by an end-user elicitation method and a set of gestures authored by three HCI researchers. Twenty-two participants who were blind to the gestures\u2019 authorship evaluated 81 gestures presented and performed on a Microsoft Surface. Our findings indicate that participants preferred gestures authored by larger groups of people, such as those created by end-user elicitation methodologies or those proposed by more than one researcher. This preference pattern seems to arise in part because the HCI researchers proposed more physically and conceptually complex gestures than end-users. We discuss our findings in detail, including the implications for surface gesture design.", "num_citations": "301\n", "authors": ["1183"]}
{"title": "CoSearch: a system for co-located collaborative web search\n", "abstract": " Web search is often viewed as a solitary task; however, there are many situations in which groups of people gather around a single computer to jointly search for information online. We present the findings of interviews with teachers, librarians, and developing world researchers that provide details about users' collaborative search habits in shared-computer settings, revealing several limitations of this practice. We then introduce CoSearch, a system we developed to improve the experience of co-located collaborative Web search by leveraging readily available devices such as mobile phones and extra mice. Finally, we present an evaluation comparing CoSearch to status quo collaboration approaches, and show that CoSearch enabled distributed control and division of labor, thus reducing the frustrations associated with shared-computer searches, while still preserving the positive aspects of communication and\u00a0\u2026", "num_citations": "299\n", "authors": ["1183"]}
{"title": "iStuff: a physical user interface toolkit for ubiquitous computing environments\n", "abstract": " The iStuff toolkit of physical devices, and the flexible software infrastructure to support it, were designed to simplify the exploration of novel interaction techniques in the post-desktop era of multiple users, devices, systems and applications collaborating in an interactive environment. The toolkit leverages an existing interactive workspace in-frastructure, making it lightweight and platform independent. The supporting software framework includes a dynamically configurable intermediary to simplify the mapping of devices to applications. We describe the iStuff architecture and provide several examples of iStuff, organized into a design space of ubiquitous computing interaction components. The main contribution is a physical toolkit for distributed, heterogeneous environments with run-time retargetable device data flow. We conclude with some insights and experiences derived from using this toolkit and framework to\u00a0\u2026", "num_citations": "279\n", "authors": ["1183"]}
{"title": "Exploring the effects of group size and table size on interactions with tabletop shared-display groupware\n", "abstract": " Interactive tabletops have been previously proposed and studied in the domain of co-located group applications. However, little fundamental research has been done to explore the issue of size. In this paper we identify a number of size considerations for tabletop design, and present an experiment to explore some of these issues, in particular the effects of group size and table size on the speed at which the task was performed, the distribution of work among group members, issues of shared resources, and user preference for table size. Our findings shed light on (1) how work strategies are affected by group size,(2) how social interaction varies with respect to table size, and (3) how the speed of task performance is influenced by group size but not by table size. In addition, our experiments revealed that for larger groups, designers might need to add additional vertical displays for shared information. This finding\u00a0\u2026", "num_citations": "251\n", "authors": ["1183"]}
{"title": "Beyond\" social protocols\" multi-user coordination policies for co-located groupware\n", "abstract": " The status quo for co-located groupware is to assume that\" social protocols\"(standards of polite behavior) are sufficient to coordinate the actions of a group of users; however, prior studies of groupware use as well as our own observations of groups using a shared tabletop display suggest potential for improving groupware interfaces by incorporatingcoordination policies-direct manipulation mechanisms for avoiding and resolving conflicts. We discuss our observations of group tabletop usage and present our coordination framework. We conclude with example usage scenarios and discuss future research suggested by this framework.", "num_citations": "235\n", "authors": ["1183"]}
{"title": "Milestones in time: The value of landmarks in retrieving information from personal stores\n", "abstract": " We describe the design and analysis of timeline visualizations for displaying the results of queries on an index of personal content. The visualization was built on top of a personal search engine that provides a unified index of all the information a user has seen, including web pages, email, and documents. Results of searches are presented with an overview-plus-detail timeline visualization. A summary view shows the distribution of search hits over time, and a detailed view allows for inspection of individual search results. In a user study, we explore the value of extending a basic time view by adding public landmarks (holidays and important news events) and personal landmarks (photos and important calendar events).", "num_citations": "201\n", "authors": ["1183"]}
{"title": "From internet access to internet skills: digital inequality among older adults\n", "abstract": " Although much research examines the factors that affect technology adoption and use, less is known about how older adults as a group differ in their ability to use the Internet. The theory of digital inequality suggests that even once people have gone online, differences among them will persist in important ways such as their online skills. We analyze survey data about older American adults\u2019 Internet skills to examine whether skills differ in this group and if they do, what explains differential online abilities. We find that there is considerable variation in Internet know-how and this relates to both socioeconomic status and autonomy of use. The results suggest that attempts to achieve a knowledgeable older adult population regarding Internet use must take into account these users\u2019 socioeconomic background and available access points.", "num_citations": "194\n", "authors": ["1183"]}
{"title": "Augmenting web pages and search results to support credibility assessment\n", "abstract": " The presence (and, sometimes, prominence) of incorrect and misleading content on the Web can have serious consequences for people who increasingly rely on the internet as their information source for topics such as health, politics, and financial advice. In this paper, we identify and collect several page features (such as popularity among specialized user groups) that are currently difficult or impossible for end users to assess, yet provide valuable signals regarding credibility. We then present visualizations designed to augment search results and Web pages with the most promising of these features. Our lab evaluation finds that our augmented search results are particularly effective at increasing the accuracy of users'\" credibility assessments, highlighting the potential of data aggregation and simple interventions to help people make more informed decisions as they search for information online.", "num_citations": "192\n", "authors": ["1183"]}
{"title": "CoSense: enhancing sensemaking for collaborative web search\n", "abstract": " Making sense of the information found during an investigational Web search task can be daunting. With the recent emergence of tools to support collaborative Web search, the associated sensemaking task has become even more complex, requiring sense to be made not only of the products of a search (ie, results found) but of the process, as well (ie, group division of labor and decision-making).", "num_citations": "189\n", "authors": ["1183"]}
{"title": "Social networking site use by mothers of young children\n", "abstract": " In this paper, we present the first formal study of how mothers of young children (aged three and under) use social networking sites, particularly Facebook and Twitter, including mothers' perceptions of which SNSes are appropriate for sharing information about their children, changes in post style and frequency after birth, and the volume and nature of child-related content shared in these venues. Our findings have implications for improving the utility and usability of SNS tools for mothers of young children, as well as for creating and improving sociotechnical systems related to maternal and child health.", "num_citations": "188\n", "authors": ["1183"]}
{"title": "Visual challenges in the everyday lives of blind people\n", "abstract": " The challenges faced by blind people in their everyday lives are not well understood. In this paper, we report on the findings of a large-scale study of the visual questions that blind people would like to have answered. As part of this year-long study, 5,329 blind users asked 40,748 questions about photographs that they took from their iPhones using an application called VizWiz Social. We present a taxonomy of the types of questions asked, report on a number of features of the questions and accompanying photographs, and discuss how individuals changed how they used VizWiz Social over time. These results improve our understanding of the problems blind people face, and may help motivate new projects more accurately targeted to help blind people live more independently in their everyday lives.", "num_citations": "188\n", "authors": ["1183"]}
{"title": "Experiences with and observations of direct-touch tabletops\n", "abstract": " The design of multitouch multiuser tabletop user interfaces is still in its infancy and is not yet well understood. To date, published experimental results have primarily focused on controlled user studies. In this paper, we present observations of user experience \"in the wild\" on interactive tables in four different real world contexts - all noncontrolled settings. We reflect upon our collective experience, report our observations, and summarize lessons learned by identifying design considerations relating to several aspects of interactive tables, such as simultaneous touching, ambiguous input, one-fingered touch, finger resolution, alternate touch input, crowding and clutter, text input, orientation, multiuser coordination, occlusion, ergonomic issues, and mental models.", "num_citations": "184\n", "authors": ["1183"]}
{"title": "SearchBar: a search-centric web history for task resumption and information re-finding\n", "abstract": " Current user interfaces for Web search, including browsers and search engine sites, typically treat search as a transient activity. However, people often conduct complex, multi-query investigations that may span long durations and may be interrupted by other tasks. In this paper, we first present the results of a survey of users' search habits, which show that many search tasks span long periods of time. We then introduce SearchBar, a system for proactively and persistently storing query histories, browsing histories, and users' notes and ratings in an interrelated fashion. SearchBar supports multi-session investigations by assisting with task context resumption and information re-finding. We describe a user study comparing use of SearchBar to status-quo tools such as browser histories, and discuss our findings, which show that users find SearchBar valuable for task reacquisition. Our study also reveals the strategies\u00a0\u2026", "num_citations": "179\n", "authors": ["1183"]}
{"title": "WeSearch: supporting collaborative search and sensemaking on a tabletop display\n", "abstract": " Groups of users often have shared information needs--for example, business colleagues need to conduct research relating to joint projects and students must work together on group homework assignments. In this paper, we introduce WeSearch, a collaborative Web search system designed to leverage the benefits of tabletop displays for face-to-face collaboration and organization tasks. We describe the design of WeSearch and explain the interactions it affords. We then describe an evaluation in which eleven groups used WeSearch to conduct real collaborative search tasks. Based on our study's findings, we analyze the effectiveness of the features introduced by WeSearch.", "num_citations": "177\n", "authors": ["1183"]}
{"title": "ShadowGuides: visualizations for in-situ learning of multi-touch and whole-hand gestures\n", "abstract": " We present ShadowGuides, a system for in-situ learning of multi-touch and whole-hand gestures on interactive surfaces. ShadowGuides provides on-demand assistance to the user by combining visualizations of the user's current hand posture as interpreted by the system (feedback) and available postures and completion paths necessary to finish the gesture (feedforward). Our experiment compared participants learning gestures with ShadowGuides to those learning with video-based instruction. We found that participants learning with ShadowGuides remembered more gestures and expressed significantly higher preference for the help system.", "num_citations": "172\n", "authors": ["1183"]}
{"title": "Discovering and using groups to improve personalized search\n", "abstract": " Personalized Web search takes advantage of information about an individual to identify the most relevant results for that person. A challenge for personalization lies in collecting user profiles that are rich enough to do this successfully. One way an individual's profile can be augmented is by using data from other people. To better understand whether groups of people can be used to benefit personalized search, we explore the similarity of query selection, desktop information, and explicit relevance judgments across people grouped in different ways. The groupings we explore fall along two dimensions: the longevity of the group members' relationship, and how explicitly the group is formed. We find that some groupings provide valuable insight into what members consider relevant to queries related to the group focus, but that it can be difficult to identify valuable groups implicitly. Building on these findings, we explore\u00a0\u2026", "num_citations": "152\n", "authors": ["1183"]}
{"title": "Informing the design of direct-touch tabletops\n", "abstract": " Tables provide a large and natural interface for supporting direct manipulation of visual content for human-to-human interactions. Such surfaces also support collaboration, coordination, and parallel problem solving. However, the direct-touch table metaphor also presents considerable challenges, including the need for input methods that transcend traditional mouse- and keyboard-based designs. In this paper, we've designed, implemented, and studied a variety of tabletop user interfaces, interaction techniques, and usage scenarios", "num_citations": "152\n", "authors": ["1183"]}
{"title": "Collaborative search revisited\n", "abstract": " Despite recent innovations in technologies supporting collaborative web search [11, 13, 25, 34, 35, 37], the features of the primary tools for digital information seeking (web browsers and search engines) continue to reflect a presumption that search is a single-user activity. In this paper, we present the findings of a survey of 167 diverse users' collaborative web search practices, including the prevalence and frequency of such activities, the information needs motivating collaboration, the methods and tools employed in such tasks, and users' satisfaction with the status quo. We find an increased prevalence and frequency of collaborative search, particularly by younger users, and an appropriation of\" old\" technologies like e-mail as well as\" new\" technologies like smartphones and social networking sites, rather than the use of dedicated collaborative search tools. We reflect on how and why collaborative search practices\u00a0\u2026", "num_citations": "151\n", "authors": ["1183"]}
{"title": "Conflict resolution for graphic multi-user interface\n", "abstract": " A graphic multi-user interface resolves multi-user conflicts. The interface includes a touch sensitive surface on which items, such as documents and images, can be displayed. The items have an associated state and policy. Touch samples are generated when users touch the touch sensitive surface. Each samples is identified with a particular user generating the of sample. The samples are associated with particular items. Touching items generates events. A decision with respect to a conflict affecting a next state of a particular item is made according to the events, the state and the policy.", "num_citations": "151\n", "authors": ["1183"]}
{"title": "User-defined gesture set for surface computing\n", "abstract": " The claimed subject matter provides a system and/or a method that facilitates generating an intuitive set of gestures for employment with surface computing. A gesture set creator can prompt two or more users with a potential effect for a portion of displayed data. An interface component can receive at least one surface input from the user in response to the prompted potential effect. A surface detection component can track the surface input utilizing a computer vision-based sensing technique. The gesture set creator collects the surface input from the two or more users in order to identify a user-defined gesture based upon a correlation between the respective surface inputs, wherein the user-defined gesture is defined as an input that initiates the potential effect for the portion of displayed data.", "num_citations": "143\n", "authors": ["1183"]}
{"title": "Co-located collaborative visual analytics around a tabletop display\n", "abstract": " Co-located collaboration can be extremely valuable during complex visual analytics tasks. We present an exploratory study of a system designed to support collaborative visual analysis tasks on a digital tabletop display. Fifteen participant pairs employed Cambiera, a visual analytics system, to solve a problem involving 240 digital documents. Our analysis, supported by observations, system logs, questionnaires, and interview data, explores how pairs approached the problem around the table. We contribute a unique, rich understanding of how users worked together around the table and identify eight types of collaboration styles that can be used to identify how closely people work together while problem solving. We show how the closeness of teams' collaboration and communication influenced how they performed on the task overall. We further discuss the role of the tabletop for visual analytics tasks and derive\u00a0\u2026", "num_citations": "141\n", "authors": ["1183"]}
{"title": "Investigating the appropriateness of social network question asking as a resource for blind users\n", "abstract": " Recent work has shown the potential of having remote humans answer visual questions that blind users have. On the surface social networking sites (SNSs) offer an attractive free source of human-powered answers that can be personalized to the user. In this paper, we explore the potential of blind users asking visual questions to their social networks. We present the first formal study of how blind people use social networking sites via a survey of 191 blind adults. We also explore whether blind users find SNSs an appropriate venue for Q&A through a log analysis of questions asked using VizWiz Social, an iPhone app with over 5,000 users, which lets blind users ask questions to either the crowd or friends. We then report findings of a field experiment with 23 blind VizWiz Social users, which explored question asking on VizWiz Social in the presence of monetary costs for non-social sources. We find that blind people\u00a0\u2026", "num_citations": "139\n", "authors": ["1183"]}
{"title": "Access overlays: improving non-visual access to large touch screens for blind users\n", "abstract": " Many touch screens remain inaccessible to blind users, and those approaches to providing access that do exist offer minimal support for interacting with large touch screens or spatial data. In this paper, we introduce a set of three software-based access overlays intended to improve the accessibility of large touch screen interfaces, specifically interactive tabletops. Our access overlays are called edge projection, neighborhood browsing, and touch-and-speak. In a user study, 14 blind users compared access overlays to an implementation of Apple's VoiceOver screen reader. Our results show that two of our techniques were faster than VoiceOver, that participants correctly answered more questions about the screen's layout using our techniques, and that participants overwhelmingly preferred our techniques. We developed several applications demonstrating the use of access overlays, including an accessible map\u00a0\u2026", "num_citations": "134\n", "authors": ["1183"]}
{"title": "Toward everyday gaze input: Accuracy and precision of eye tracking and implications for design\n", "abstract": " For eye tracking to become a ubiquitous part of our everyday interaction with computers, we first need to understand its limitations outside rigorously controlled labs, and develop robust applications that can be used by a broad range of users and in various environments. Toward this end, we collected eye tracking data from 80 people in a calibration-style task, using two different trackers in two lighting conditions. We found that accuracy and precision can vary between users and targets more than six-fold, and report on differences between lighting, trackers, and screen regions. We show how such data can be used to determine appropriate target sizes and to optimize the parameters of commonly used filters. We conclude with design recommendations and examples how our findings and methodology can inform the design of error-aware adaptive applications.", "num_citations": "131\n", "authors": ["1183"]}
{"title": "Reading revisited: Evaluating the usability of digital display surfaces for active reading tasks\n", "abstract": " A number of studies have shown that paper holds several advantages over computers for reading tasks. However, these studies were carried out several years ago, and since that time computerized reading technology has advanced in many areas. We revisit the issue of reading in the workplace, comparing paper use to state-of-the-art hardware and software. In particular, we studied how knowledge workers perform reading tasks in four conditions: (1) using paper, (2) using a dual-monitor desktop system, (3) using a pen- enabled horizontal display surface, and (4) using multiple tablet computers. We discuss our findings, noting the strengths and shortcomings of each configuration. Based on these findings, we propose design guidelines for hybrid horizontal + vertical systems that support active reading tasks.", "num_citations": "130\n", "authors": ["1183"]}
{"title": "Web on the wall: insights from a multimodal interaction elicitation study\n", "abstract": " New sensing technologies like Microsoft's Kinect provide a low-cost way to add interactivity to large display surfaces, such as TVs. In this paper, we interview 25 participants to learn about scenarios in which they would like to use a web browser on their living room TV. We then conduct an interaction-elicitation study in which users suggested speech and gesture interactions for fifteen common web browser functions. We present the most popular suggested interactions, and supplement these findings with observational analyses of common gesture and speech conventions adopted by our participants. We also reflect on the design of multimodal, multi-user interaction-elicitation studies, and introduce new metrics for interpreting user-elicitation study findings.", "num_citations": "127\n", "authors": ["1183"]}
{"title": "Teamsearch: Comparing techniques for co-present collaborative search of digital media\n", "abstract": " Interactive tables can enhance small group colocated collaborative work in many domains. One application enabled by this new technology is copresent, collaborative search for digital content. For example, a group of students could sit around an interactive table and search for digital images to use in a report. We have developed TeamSearch, an application that enables this type of activity by supporting group specification of Boolean style queries. We explore whether TeamSearch should consider all group members' activities as contributing to a single query or should interpret them as separate, parallel search requests. The results reveal that both strategies are similarly efficient, but that collective query formation has advantages in terms of enhancing group collaboration and awareness, allowing users to bootstrap query specification skills, and personal preference. This suggests that team centric ills may offer\u00a0\u2026", "num_citations": "126\n", "authors": ["1183"]}
{"title": "Release, relocate, reorient, resize: fluid techniques for document sharing on multi-user interactive tables\n", "abstract": " Group work frequently involves transitions between periods of active collaboration and periods of individual activity. We aim to support this typical work practice by introducing four tabletop direct-manipulation interaction techniques that can be used to transition the status of an electronic document from private to group-accessible. After presenting our four techniques-release, relocate, reorient, and resize-we discuss the results of an empirical study that compares and evaluates these mechanisms for sharing documents in a co-located tabletop environment.", "num_citations": "123\n", "authors": ["1183"]}
{"title": "An exploratory study of co-located collaborative visual analytics around a tabletop display\n", "abstract": " Co-located collaboration can be extremely valuable during complex visual analytics tasks. This paper presents an exploratory study of a system designed to support collaborative visual analysis tasks on a digital tabletop display. Fifteen participant pairs employed Cam-biera, a visual analytics system, to solve a problem involving 240 digital documents. Our analysis, supported by observations, system logs, questionnaires, and interview data, explores how pairs approached the problem around the table. We contribute a unique, rich understanding of how users worked together around the table and identify eight types of collaboration styles that can be used to identify how closely people work together while problem solving. We show how the closeness of teams' collaboration influenced how well they performed on the task overall. We further discuss the role of the tabletop for visual analytics tasks and derive novel\u00a0\u2026", "num_citations": "122\n", "authors": ["1183"]}
{"title": "Reducing legacy bias in gesture elicitation studies\n", "abstract": " UI elements from traditional PC interfaces, most participants suggested mouse-like single-point or simple-path gestures [1]. The participants, too, acknowledged these biases: One said,\u201cI\u2019ma child of the mouse\u201d; another said,\u201cI\u2019m falling back on the old things that I\u2019ve learned.\u201d In a multimodal gesture and speech elicitation study, Morris [3] noted similar examples, including a participant who referred to his hand as the mouse, a participant who avoided bimanual gestures because they might require that a system have two cursors, and several participants who suggested speech commands based on keyboard shortcuts (eg, saying \u201cF5\u201d aloud to reload a Web page). Legacy bias does have some benefits. Because they draw upon culturally shared metaphors, participants tend to propose similar legacyinspired interactions, resulting in high agreement scores in elicitation studies [1]. This agreement indicates that legacy\u00a0\u2026", "num_citations": "117\n", "authors": ["1183"]}
{"title": "Sign language recognition, generation, and translation: An interdisciplinary perspective\n", "abstract": " Developing successful sign language recognition, generation, and translation systems requires expertise in a wide range of fields, including computer vision, computer graphics, natural language processing, human-computer interaction, linguistics, and Deaf culture. Despite the need for deep interdisciplinary knowledge, existing research occurs in separate disciplinary silos, and tackles separate portions of the sign language processing pipeline. This leads to three key questions: 1) What does an interdisciplinary view of the current landscape reveal? 2) What are the biggest challenges facing the field? and 3) What are the calls to action for people working in the field? To help answer these questions, we brought together a diverse group of experts for a two-day workshop. This paper presents the results of that interdisciplinary workshop, providing key background that is often overlooked by computer scientists, a\u00a0\u2026", "num_citations": "116\n", "authors": ["1183"]}
{"title": "Code space: touch+ air gesture hybrid interactions for supporting developer meetings\n", "abstract": " We present Code Space, a system that contributes touch+ air gesture hybrid interactions to support co-located, small group developer meetings by democratizing access, control, and sharing of information across multiple personal devices and public displays. Our system uses a combination of a shared multi-touch screen, mobile touch devices, and Microsoft Kinect sensors. We describe cross-device interactions, which use a combination of in-air pointing for social disclosure of commands, targeting and mode setting, combined with touch for command execution and precise gestures. In a formative study, professional developers were positive about the interaction design, and most felt that pointing with hands or devices and forming hand postures are socially acceptable. Users also felt that the techniques adequately disclosed who was interacting and that existing social protocols would help to dictate most\u00a0\u2026", "num_citations": "116\n", "authors": ["1183"]}
{"title": "Systems and methods for constructing and using models of memorability in computing and communications applications\n", "abstract": " One or more models of memorability are provided that facilitate various computer-based applications including those centering on the storage, retrieval, and processing of information, applications that remind people about items they risk not recalling or overlooking, and facilitating communications of reminders. In one application, the models are used to help compose and navigate large personal stores of information about a user's activities, communications, images, and other content. In another application, views of files in directories are extended with the addition of memory landmarks, and a means for controlling the number of landmarks provided via changing a threshold on inferred memorability. Another application centers on the use of models of memorability to select subsets of images from larger sets representing events, for display in a slide show or ambient photo display. In another application, a system is\u00a0\u2026", "num_citations": "116\n", "authors": ["1183"]}
{"title": "TeamTag: exploring centralized versus replicated controls for co-located tabletop groupware\n", "abstract": " We explore how the placement of control widgets (such as menus) affects collaboration and usability for co-located tabletop groupware applications. We evaluated two design alternatives: a centralized set of controls shared by all users, and separate per-user controls replicated around the borders of the shared tabletop. We conducted this evaluation in the context of TeamTag, a system for collective annotation of digital photos. Our comparison of the two design alternatives found that users preferred replicated over shared controls. We discuss the cause of this preference, and also present data on the impact of these interface design variants on collaboration, as well as the role that orientation, co-touching, and the use of different regions of the table played in shaping users' behavior and preferences.", "num_citations": "112\n", "authors": ["1183"]}
{"title": "Stanford interactive workspaces: a framework for physical and graphical user interface prototyping\n", "abstract": " Most smart homes are created evolutionarily by adding more and more technologies to an existing home, rather than being developed on a single occasion by building a new home from scratch. This incremental addition of technology requires a highly flexible infrastructure to accommodate both future extensions and legacy systems without requiring extensive rewiring of hardware or extensive reconfiguration on the software level. Stanford's iStuff (Interactive Stuff) provides an example of a hardware interface abstraction technique that enables quick customization and reconfiguration of Smart Home solutions. iStuff gains its power from its combination with the Stanford Interactive Room Operating System (iROS), which creates a flexible and robust software framework that allows custom and legacy applications to communicate with each other and with user interface devices in a dynamically configurable way. The\u00a0\u2026", "num_citations": "111\n", "authors": ["1183"]}
{"title": "Enabling people with visual impairments to navigate virtual reality with a haptic and auditory cane simulation\n", "abstract": " Traditional virtual reality (VR) mainly focuses on visual feedback, which is not accessible for people with visual impairments. We created Canetroller, a haptic cane controller that simulates white cane interactions, enabling people with visual impairments to navigate a virtual environment by transferring their cane skills into the virtual world. Canetroller provides three types of feedback:(1) physical resistance generated by a wearable programmable brake mechanism that physically impedes the controller when the virtual cane comes in contact with a virtual object;(2) vibrotactile feedback that simulates the vibrations when a cane hits an object or touches and drags across various surfaces; and (3) spatial 3D auditory feedback simulating the sound of real-world cane interactions. We designed indoor and outdoor VR scenes to evaluate the effectiveness of our controller. Our study showed that Canetroller was a promising\u00a0\u2026", "num_citations": "106\n", "authors": ["1183"]}
{"title": "Accessible crowdwork? Understanding the value in and challenge of microtask employment for people with disabilities\n", "abstract": " We present the first formal study of crowdworkers who have disabilities via in-depth open-ended interviews of 17 people (disabled crowdworkers and job coaches for people with disabilities) and a survey of 631 adults with disabilities. Our findings establish that people with a variety of disabilities currently participate in the crowd labor marketplace, despite challenges such as crowdsourcing workflow designs that inadvertently prohibit participation by, and may negatively affect the worker reputations of, people with disabilities. Despite such challenges, we find that crowdwork potentially offers different opportunities for people with disabilities relative to the normative office environment, such as job flexibility and lack of a need to rely on public transit. We close by identifying several ways in which crowd labor platform operators and/or individual task requestors could improve the accessibility of this increasingly important\u00a0\u2026", "num_citations": "106\n", "authors": ["1183"]}
{"title": "iStuff: A Scalable Architecture for Lightweight, Wireless Devices for Ubicomp User Interfaces\n", "abstract": " INTRODUCTION iStuff is a toolbox of wireless, platform-independent, physical user interface components designed to leverage the tuple-space-based software infrastructure of Stanford\u2019s iRoom, a technology-augmented room used as a testbed for ubiquitous computing and user interface research [4]. Application users can easily and dynamically configure iStuff physical interface components to flexibly set up sensors and actuators in a ubicomp environment without having to solder components, run wires, or write device drivers. As a prototyping toolkit, iStuff aims to facilitate research at the crossroads of ubiquitous computing and HCI.In the past, Ishii\u2019s Tangible Bits project [3] introduced the notion of bridging the world between \u201cbits and atoms\u201d in user interfaces. More recently, Greenberg\u2019s Phidgets [2] provide physical widgets, designed for rapid development of physical interfaces that expand Desktop GUIs. In contrast, our approach assumes an entire interactive room as its environment. Consequently, our devices must be dynamically retargetable to different applications and platforms. Additionally, devices are lightweight because they can leverage the existing interactive room infrastructure.", "num_citations": "106\n", "authors": ["1183"]}
{"title": "Touchplates: low-cost tactile overlays for visually impaired touch screen users\n", "abstract": " Adding tactile feedback to touch screens can improve their accessibility to blind users, but prior approaches to integrating tactile feedback with touch screens have either offered limited functionality or required extensive (and typically expensive) customization of the hardware. We introduce touchplates, carefully designed tactile guides that provide tactile feedback for touch screens in the form of physical guides that are overlaid on the screen and recognized by the underlying application. Unlike prior approaches to integrating tactile feedback with touch screens, touchplates are implemented with simple plastics and use standard touch screen software, making them versatile and inexpensive. Touchplates may be customized to suit individual users and applications, and may be produced on a laser cutter, 3D printer, or made by hand. We describe the design and implementation of touchplates, a\" starter kit\" of\u00a0\u2026", "num_citations": "105\n", "authors": ["1183"]}
{"title": "Mediating group dynamics through tabletop interface design\n", "abstract": " A Stanford University research group explores how design alternatives for tabletop interfaces can impact group dynamics to promote effective teamwork. They built and evaluated a series of novel prototypes that explore multi-user coordination policies and cooperative gesturing, encouraging equitable participation in educational tasks and supporting social skills development for special-needs populations", "num_citations": "104\n", "authors": ["1183"]}
{"title": "Understanding blind people's experiences with computer-generated captions of social media images\n", "abstract": " Research advancements allow computational systems to automatically caption social media images. Often, these captions are evaluated with sighted humans using the image as a reference. Here, we explore how blind and visually impaired people experience these captions in two studies about social media images. Using a contextual inquiry approach (n= 6 blind/visually impaired), we found that blind people place a lot of trust in automatically generated captions, filling in details to resolve differences between an image's context and an incongruent caption. We built on this in-person study with a second, larger online experiment (n= 100 blind/visually impaired) to investigate the role of phrasing in encouraging trust or skepticism in captions. We found that captions emphasizing the probability of error, rather than correctness, encouraged people to attribute incongruence to an incorrect caption, rather than missing\u00a0\u2026", "num_citations": "102\n", "authors": ["1183"]}
{"title": "Factors affecting response quantity, quality, and speed for questions asked via social network status messages\n", "abstract": " Social networking tools enable people to easily ask questions of large groups of personal acquaintances, but the effectiveness of doing so depends in part on how the question is phrased. In this paper we present a study in which 282 participants posted variants of the same question as their status message on Facebook. We analyze the quantity, quality, and speed of the responses each variant received. We find that by ending an information need with a question mark, explicitly scoping the audience, and being succinct, a person can increase the likelihood of quickly receiving many high-quality answers.", "num_citations": "102\n", "authors": ["1183"]}
{"title": "Pictionaire: supporting collaborative design work by integrating physical and digital artifacts\n", "abstract": " This paper introduces an interactive tabletop system that enhances creative collaboration across physical and digital artifacts. Pictionaire offers capture, retrieval, annotation, and collection of visual material. It enables multiple designers to fluidly move imagery from the physical to the digital realm; work with found, drawn and captured imagery; organize items into functional collections; and record meeting histories. These benefits are made possible by a large interactive table augmented with high-resolution overhead image capture. Summative evaluations with 16 professionals and four student pairs validated discoverability and utility of interactions, uncovered emergent functionality, and suggested opportunities for transitioning content to and from the table.", "num_citations": "98\n", "authors": ["1183"]}
{"title": "Enhancing collaborative web search with personalization: groupization, smart splitting, and group hit-highlighting\n", "abstract": " Collaboration on Web search is common in many domains, such as education and knowledge work; recently, HCI researchers have begun to introduce prototype collaborative search tools to support such scenarios. We analyze data from a collaborative search experiment, and based on these data we propose three techniques that can enhance the value of collaborative search tools using personalization: groupization, smart splitting, and group hit-highlighting.", "num_citations": "95\n", "authors": ["1183"]}
{"title": "\" With most of it being pictures now, I rarely use it\" Understanding Twitter's Evolving Accessibility to Blind Users\n", "abstract": " Social media is an increasingly important part of modern life. We investigate the use of and usability of Twitter by blind users, via a combination of surveys of blind Twitter users, large-scale analysis of tweets from and Twitter profiles of blind and sighted users, and analysis of tweets containing embedded imagery. While Twitter has traditionally been thought of as the most accessible social media platform for blind users, Twitter's increasing integration of image content and users' diverse uses for images have presented emergent accessibility challenges. Our findings illuminate the importance of the ability to use social media for people who are blind, while also highlighting the many challenges such media currently present this user base, including difficulty in creating profiles, in awareness of available features and settings, in controlling revelations of one's disability status, and in dealing with the increasing\u00a0\u2026", "num_citations": "94\n", "authors": ["1183"]}
{"title": "Searchbuddies: Bringing search engines into the conversation\n", "abstract": " Although people receive trusted, personalized recommendations and auxiliary social benefits when they ask questions of their friends, using a search engine is often a more effective way to find an answer. Attempts to integrate social and algorithmic search have thus far focused on bringing social content into algorithmic search results. However, more of the benefits of social search can be preserved by reversing this approach and bringing algorithmic content into natural question-based conversations. To do this successfully, it is necessary to adapt search engine interaction to a social context. In this paper, we present SearchBuddies, a system that responds to Facebook status message questions with algorithmic search results. Via a three-month deployment of the system to 122 social network users, we explore how people responded to search content in a highly social environment. Our experience deploying SearchBuddies shows that a socially embedded search engine can successfully provide users with unique and highly relevant information in a social context and can be integrated into conversations around an information need. The deployment also illuminates specific challenges of embedding a search engine in a social environment and provides guidance toward solutions.", "num_citations": "94\n", "authors": ["1183"]}
{"title": "Individual audio channels with single display groupware: effects on communication and task strategy\n", "abstract": " We introduce a system that allows four users to each receive sound from a private audio channel while using a shared tabletop display. In order to explore how private audio channels affect a collaborative work environment, we conducted a user study with this system. The results reveal differences in work strategies when groups are presented with individual versus public audio, and suggest that the use of private audio does not impede group communication and may positively impact group dynamics. We discuss the findings, as well as their implications for the design of future audio-based\" single display privacyware\" systems.", "num_citations": "91\n", "authors": ["1183"]}
{"title": "Augmenting interactive tables with mice & keyboards\n", "abstract": " This note examines the role traditional input devices can play in surface computing. Mice and keyboards can enhance tabletop technologies since they support high fidelity input, facilitate interaction with distant objects, and serve as a proxy for user identity and position. Interactive tabletops, in turn, can enhance the functionality of traditional input devices: they provide spatial sensing, augment devices with co-located visual content, and support connections among a plurality of devices. We introduce eight interaction techniques for a table with mice and keyboards, and we discuss the design space of such interactions.", "num_citations": "89\n", "authors": ["1183"]}
{"title": "Accessing social support and overcoming judgment on social media among parents of children with special needs\n", "abstract": " Over 10 million children are diagnosed with a special need in the United States each year. For their parents, the economic and emotional costs can be overwhelming. Using a mixed methods approach, we show that parents of children with special needs rely primarily on Facebook pages, Facebook groups, and Yahoo! groups for accessing information and social support. Specifically, these groups offer geographic communities for local needs (eg school services) and case-based communities for specific conditions (eg autism). Promisingly, parents perceive less judgment online than offline when talking about their children\u2019s special needs; however, these perceptions are nuanced. In particular, posts containing humor, achievement, or treatment suggestions are perceived to be more socially appropriate than posts containing judgment, violence, or social comparisons. However, results show that social media generally fails at connecting special needs families over time and across the life span. We discuss implications for social media site design and for supporting special needs families.", "num_citations": "87\n", "authors": ["1183"]}
{"title": "Barehands: implement-free interaction with a wall-mounted display\n", "abstract": " We describe Barehands, a free-handed interaction technique, in which the user can control the invocation of system commands and tools on a touch screen by touching it with distinct hand postures. Using behind-screen infrared (IR) illumination and a video camera with an IR filter, we enable a back-projected SMARTBoard (a commercially available, 61 3/8\" x 47\" touch-sensing display) to identify and respond to several distinct hand postures. Barehands provides a natural, quick, implement-free method of interacting with large, wall-mounted interactive surfaces.", "num_citations": "85\n", "authors": ["1183"]}
{"title": "Collaborative Web Search: Who, What, Where, When, and Why\n", "abstract": " Today, Web search is treated as a solitary experience. Web browsers and search engines are typically designed to support a single user, working alone. However, collaboration on information-seeking tasks is actually commonplace. Students work together to complete homework assignments, friends seek information about joint entertainment  opportunities, family members jointly plan vacation travel, and colleagues jointly  conduct research for their projects. As improved networking technologies and the  rise of social media simplify the process of remote collaboration, and large, novel  display form-factors simplify the process of co-located group work, researchers have  begun to explore ways to facilitate collaboration on search tasks.  This lecture investigates the who, what, where, when and why of  collaborative search, and gives insight in how emerging solutions can address  collaborators' needs.   Table of\u00a0\u2026", "num_citations": "81\n", "authors": ["1183"]}
{"title": "\" Why would anybody do this?\" Understanding Older Adults' Motivations and Challenges in Crowd Work\n", "abstract": " Diversifying participation in crowd work can benefit the worker and requester. Increasing numbers of older adults are online, but little is known about their awareness of or how they engage in mainstream crowd work. Through an online survey with 505 seniors, we found that most have never heard of crowd work but would be motivated to complete tasks by earning money or working on interesting or stimulating tasks. We follow up results from the survey with interviews and observations of 14 older adults completing crowd work tasks. While our survey data suggests that financial incentives are encouraging, in-depth interviews reveal that a combination of personal and social incentives may be stronger drivers of participation, but only if older adults can overcome accessibility issues and understand the purpose of crowd work. This paper contributes insights into how crowdsourcing sites could better engage seniors\u00a0\u2026", "num_citations": "80\n", "authors": ["1183"]}
{"title": "Seeingvr: A set of tools to make virtual reality more accessible to people with low vision\n", "abstract": " Current virtual reality applications do not support people who have low vision, ie, vision loss that falls short of complete blindness but is not correctable by glasses. We present SeeingVR, a set of 14 tools that enhance a VR application for people with low vision by providing visual and audio augmentations. A user can select, adjust, and combine different tools based on their preferences. Nine of our tools modify an existing VR application post hoc via a plugin without developer effort. The rest require simple inputs from developers using a Unity toolkit we created that allows integrating all 14 of our low vision support tools during development. Our evaluation with 11 participants with low vision showed that SeeingVR enabled users to better enjoy VR and complete tasks more quickly and accurately. Developers also found our Unity toolkit easy and convenient to use.", "num_citations": "76\n", "authors": ["1183"]}
{"title": "To search or to ask: The routing of information needs between traditional search engines and social networks\n", "abstract": " In status message question asking (SMQA), members of social networking sites make use of status messages to express information needs to friends and contacts. We present findings from a laboratory study that examined 82 participants' SMQA behaviors in the broader context of online information seeking. When given the option of using a search engine and/or a social network, participants leveraged SMQA for 20% of their information needs, most often posing a question to their network in addition to issuing a query. We show the important roles played by the specificity of the information need and the perceived audience of a given network on routing decisions. We then demonstrate that routing decisions have varied effects on participants' satisfaction, information value, and trust of outcomes. In addition to highlighting the complementary advantages and disadvantages of search and SMQA, our findings suggest\u00a0\u2026", "num_citations": "71\n", "authors": ["1183"]}
{"title": "Smartphone-based gaze gesture communication for people with motor disabilities\n", "abstract": " Current eye-tracking input systems for people with ALS or other motor impairments are expensive, not robust under sunlight, and require frequent re-calibration and substantial, relatively immobile setups. Eye-gaze transfer (e-tran) boards, a low-tech alternative, are challenging to master and offer slow communication rates. To mitigate the drawbacks of these two status quo approaches, we created GazeSpeak, an eye gesture communication system that runs on a smartphone, and is designed to be low-cost, robust, portable, and easy-to-learn, with a higher communication bandwidth than an e-tran board. GazeSpeak can interpret eye gestures in real time, decode these gestures into predicted utterances, and facilitate communication, with different user interfaces for speakers and interpreters. Our evaluations demonstrate that GazeSpeak is robust, has good user satisfaction, and provides a speed improvement with\u00a0\u2026", "num_citations": "70\n", "authors": ["1183"]}
{"title": "Gauging receptiveness to social microvolunteering\n", "abstract": " Crowd-powered systems that help people are difficult to scale and sustain because human labor is expensive and worker pools are difficult to grow. To address this problem we introduce the idea of social microvolunteering, a type of intermediated friendsourcing in which a person can provide access to their friends as potential workers for microtasks supporting causes that they care about. We explore this idea by creating Visual Answers, an exemplar social microvolunteering application for Facebook that posts visual questions from people who are blind. We present results of a survey of 350 participants on the concept of social microvolunteering, and a deployment of the Visual Answers application with 91 participants, which collected 618 high-quality answers to questions asked over 12 days, illustrating the feasibility of the approach.", "num_citations": "70\n", "authors": ["1183"]}
{"title": "Microblog credibility perceptions: comparing the USA and China\n", "abstract": " Microblogs have become an increasingly important source of information, both in the US (Twitter) and in China (Weibo). However, the brevity of microblog updates, combined with increasing access of microblog content through search rather than through direct network connections, makes it challenging to assess the credibility of news relayed in this manner [34]. This paper reports on experimental and survey data that compare the impact of several features of microblog updates (author's gender, name style, profile image, location, and degree of network overlap with the reader) on credibility perceptions among US and Chinese audiences. We reveal the complex mechanism of credibility perceptions, identify several key differences in how users from each country critically consume microblog content, and discuss how to incorporate these findings into the design of improved user interfaces for accessing microblogs in\u00a0\u2026", "num_citations": "70\n", "authors": ["1183"]}
{"title": "S3: Storable, Shareable Search\n", "abstract": " We present S3, a system that implicitly captures the process and products of Web investigations (exploratory searches involving multiple queries). This automatically-created, persistent representation of an investigation enables future review and continuation of suspended search activities. This persistent representation can reduce unnecessary re-execution of queries and enable users to quickly regain the context of a resumed activity. Stored investigations can also be shared with, and augmented by, collaborators. Furthermore, a stored investigation can act as a standing query, proactively updating itself when a user revisits it.", "num_citations": "69\n", "authors": ["1183"]}
{"title": "Improving dwell-based gaze typing with dynamic, cascading dwell times\n", "abstract": " We present cascading dwell gaze typing, a novel approach to dwell-based eye typing that dynamically adjusts the dwell time of keys in an on-screen keyboard based on the likelihood that a key will be selected next, and the location of the key on the keyboard. Our approach makes unlikely keys more difficult to select and likely keys easier to select by increasing and decreasing their required dwell times, respectively. To maintain a smooth typing rhythm for the user, we cascade the dwell time of likely keys, slowly decreasing the minimum allowable dwell time as a user enters text. Cascading the dwell time affords users the benefits of faster dwell times while causing little disruption to users' typing cadence. Results from a longitudinal study with 17 non-disabled participants show that our dynamic cascading dwell technique was significantly faster than a static dwell approach. Participants were able to achieve typing\u00a0\u2026", "num_citations": "66\n", "authors": ["1183"]}
{"title": "Supporting effective interaction with tabletop groupware\n", "abstract": " This workshop position paper describes our prior and ongoing research on horizontal computing systems, which is focused on understanding how interactive tables can effectively support co-located computer-supported collaborative work. We describe our recent contributions in the areas of multi-user coordination policies for interactive tables, using audio as a means of supplementing a tabletop display with private information, and exploring appropriate graphical layouts for horizontal interfaces. We also discuss our ongoing work in developing cooperative tabletop gestures and evaluating the potential of tabletop computing for educational activities.", "num_citations": "59\n", "authors": ["1183"]}
{"title": "A crowd-powered socially embedded search engine\n", "abstract": " People have always asked questions of their friends, but now, with social media, they can broadcast their questions to their entire social network. In this paper we study the replies received via Twitter question asking, and use what we learn to create a system that augments naturally occurring \u201cfriendsourced\u201d answers with crowdsourced answers. By analyzing of thousands of public Twitter questions and answers, we build a picture of which questions receive answers and the content of their answers. Because many questions seek subjective responses but go unanswered, we use crowdsourcing to augment the Twitter question asking experience. We deploy a system that uses the crowd to identify question tweets, create candidate replies, and vote on the best reply from among different crowd-and friend-generated answers. We find that crowdsourced answers are similar in nature and quality to friendsourced answers, and that almost a third of all question askers provided unsolicited positive feedback upon receiving answers from this novel information agent.", "num_citations": "58\n", "authors": ["1183"]}
{"title": "Search on surfaces: Exploring the potential of interactive tabletops for collaborative search tasks\n", "abstract": " Collaborative information seeking often takes place in co-located settings; such opportunities may be planned (business colleagues meeting in a conference room or students working together in a library) or spontaneous (family members gathered in their living room or friends meeting at a caf\u00e9). Surface computing technologies (i.e., interactive tabletops) hold great potential for enhancing collaborative information seeking activities. Such devices provide engaging direct manipulation interactions, facilitate awareness of collaborators\u2019 activities, and afford spatial organization of content. However, current tabletop technologies also present several challenges that creators of collaborative information seeking system must account for in their designs. In this article, we explore the design space for collaborative search systems on interactive tabletops, discussing the benefits and challenges of creating search applications\u00a0\u2026", "num_citations": "56\n", "authors": ["1183"]}
{"title": "Understanding the challenges faced by neurodiverse software engineering employees: Towards a more inclusive and productive technical workforce\n", "abstract": " Technology workers are often stereotyped as being socially awkward or having difficulty communicating, often with humorous intent; however, for many technology workers with atypical cognitive profiles, such issues are no laughing matter. In this paper, we explore the hidden lives of neurodiverse technology workers, eg, those with autism spectrum disorder (ASD), attention deficit hyperactivity disorder (ADHD), and/or other learning disabilities, such as dyslexia. We present findings from interviews with 10 neurodiverse technology workers, identifying the challenges that impede these employees from fully realizing their potential in the workplace. Based on the interview findings, we developed a survey that was taken by 846 engineers at a large software company. In this paper, we reflect on the differences between the neurotypical (N= 781) and neurodiverse (N= 59) respondents. Technology companies struggle to\u00a0\u2026", "num_citations": "55\n", "authors": ["1183"]}
{"title": "Caption crawler: Enabling reusable alternative text descriptions using reverse image search\n", "abstract": " Accessing images online is often difficult for users with vision impairments. This population relies on text descriptions of images that vary based on website authors' accessibility practices. Where one author might provide a descriptive caption for an image, another might provide no caption for the same image, leading to inconsistent experiences. In this work, we present the Caption Crawler system, which uses reverse image search to find existing captions on the web and make them accessible to a user's screen reader. We report our system's performance on a set of 481 websites from alexa. com's list of most popular sites to estimate caption coverage and latency, and also report blind and sighted users' ratings of our system's output quality. Finally, we conducted a user study with fourteen screen reader users to examine how the system might be used for personal browsing.", "num_citations": "54\n", "authors": ["1183"]}
{"title": "When one isn't enough: an analysis of virtual desktop usage strategies and their implications for design\n", "abstract": " Screen space is a limited resource for computer users-multiple monitors are one means of workspace expansion, and\" virtual desktops\" are yet another way to increase screen real-estate. We present a taxonomy of organization strategies based on our observations during a series of interviews with virtual desktop users. Additionally, we explore causes of varying user preferences for physical versus virtual means of screen-space expansion. Finally, we discuss the design implications of our findings.", "num_citations": "54\n", "authors": ["1183"]}
{"title": "RIMES: Embedding interactive multimedia exercises in lecture videos\n", "abstract": " Teachers in conventional classrooms often ask learners to express themselves and show their thought processes by speaking out loud, drawing on a whiteboard, or even using physical objects. Despite the pedagogical value of such activities, interactive exercises available in most online learning platforms are constrained to multiple-choice and short answer questions. We introduce RIMES, a system for easily authoring, recording, and reviewing interactive multimedia exercises embedded in lecture videos. With RIMES, teachers can prompt learners to record their responses to an activity using video, audio, and inking while watching lecture videos. Teachers can then review and interact with all the learners' responses in an aggregated gallery. We evaluated RIMES with 19 teachers and 25 students. Teachers created a diverse set of activities across multiple subjects that tested deep conceptual and procedural\u00a0\u2026", "num_citations": "53\n", "authors": ["1183"]}
{"title": "Sensemaking in collaborative web search\n", "abstract": " Sensemaking is an important aspect of information-seeking tasks but has mostly been studied at the individual level. We conducted a study of sensemaking in collaborative Web search using SearchTogether and found that collaborators face several challenges in making sense of information during collaborative search tasks. We built and evaluated a new tool, CoSense, which enhanced sensemaking in SearchTogether. The evaluation of CoSense provided insights into how collaborative sensemaking differed from individual sensemaking in terms of the different kinds of information that collaborators needed to make sense of. In this article we discuss findings about how sensemaking occurs in synchronous and asynchronous collaboration and the challenges participants face in handling handoffs. We found that participants had two different strategies of handling handoffs\u2014search-lead and sensemaking-lead\u2014and\u00a0\u2026", "num_citations": "51\n", "authors": ["1183"]}
{"title": "Swarm: an actuated wearable for mediating affect\n", "abstract": " We present SWARM, a wearable affective technology designed to help a user to reflect on their own emotional state, modify their affect, and interpret the emotional states of others. SWARM aims for a universal design (inclusive of people with various disabilities), with a focus on modular actuation components to accommodate users' sensory capabilities and preferences, and a scarf form-factor meant to reduce the stigma of accessible technologies through a fashionable embodiment. Using an iterative, user-centered approach, we present SWARM's design. Additionally, we contribute findings for communicating emotions through technology actuations, wearable design techniques (including a modular soft circuit design technique that fuses conductive fabric with actuation components), and universal design considerations for wearable technology.", "num_citations": "50\n", "authors": ["1183"]}
{"title": "Rich representations of visual content for screen reader users\n", "abstract": " Alt text (short for\" alternative text\") is descriptive text associated with an image in HTML and other document formats. Screen reader technologies speak the alt text aloud to people who are visually impaired. Introduced with HTML 2.0 in 1995, the alt attribute has not evolved despite significant changes in technology over the past two decades. In light of the expanding volume, purpose, and importance of digital imagery, we reflect on how alt text could be supplemented to offer a richer experience of visual content to screen reader users. Our contributions include articulating the design space of representations of visual content for screen reader users, prototypes illustrating several points within this design space, and evaluations of several of these new image representations with people who are blind. We close by discussing the implications of our taxonomy, prototypes, and user study findings.", "num_citations": "48\n", "authors": ["1183"]}
{"title": "Dynamic mapping of physical controls for tabletop groupware\n", "abstract": " Multi-touch interactions are a promising means of control for interactive tabletops. However, a lack of precision and tactile feedback makes multi-touch controls a poor fit for tasks where precision and feedback are crucial. We present an approach that offers precise control and tactile feedback for tabletop systems through the integration of dynamically re-mappable physical controllers with the multi-touch environment, and we demonstrate this approach in our collaborative tabletop audio editing environment. An observational user study demonstrates that our approach can provide needed precision and feedback, while preserving the collaborative benefits of a shared direct-manipulation surface. Our observations also suggest that direct touch and physical controllers can offer complementary benefits, and that providing both allows users to adjust their control strategy based on considerations including precision\u00a0\u2026", "num_citations": "48\n", "authors": ["1183"]}
{"title": "Mudslide: A spatially anchored census of student confusion for online lecture videos\n", "abstract": " Educators have developed an effective technique to get feedback after in-person lectures, called\" muddy cards.\" Students are given time to reflect and write the\" muddiest\"(least clear) point on an index card, to hand in as they leave class. This practice of assigning end-of-lecture reflection tasks to generate explicit student feedback is well suited for adaptation to the challenge of supporting feedback in online video lectures. We describe the design and evaluation of Mudslide, a prototype system that translates the practice of muddy cards into the realm of online lecture videos. Based on an in-lab study of students and teachers, we find that spatially contextualizing students' muddy point feedback with respect to particular lecture slides is advantageous to both students and teachers. We also reflect on further opportunities for enhancing this feedback method based on teachers' and students' experiences with our prototype.", "num_citations": "47\n", "authors": ["1183"]}
{"title": "Towards supporting search over trending events with social media\n", "abstract": " Many search engines identify bursts of activity around particular topics and reflect these back to users as Popular Now or Hot Searches. Activity around these topics typically evolves quickly in real-time during the course of a trending event. Users\u2019 informational needs when searching for such topics will vary depending on the stage at which they engage with an event. Through a survey and log study, we observe that interaction with content about trending events varies significantly with prior awareness of the event. Building on this observation, we conduct a larger-scale analysis of query logs and social media data associated with hundreds of trending events. We find that search and social media activity tend to follow similar temporal patterns, but that social media activity leads by a few hours. While user interest in trending event content predictably diverges during peak activity periods, the overlap between content searched and shared increases. We discuss how these findings relate to the design of interfaces to better support sensemaking around trending events by integrating real-time social media content with traditional search results.", "num_citations": "47\n", "authors": ["1183"]}
{"title": "Search-centric hierarchichal browser history\n", "abstract": " A search-centric hierarchical browser history technique that provides for the creation of a Web search history hierarchy organized according to the search queries that a user has conducted. In one embodiment, search queries occupy the highest level of the search history hierarchy and all Web sites/search results relating to a particular search query that the user accessed are hierarchically organized below that query. In another embodiment, queries may also be optionally grouped into a higher-level hierarchy that reflects search topics.", "num_citations": "47\n", "authors": ["1183"]}
{"title": "Insights on interactive tabletops: A survey of researchers and developers\n", "abstract": " Recently, interest in tabletop computing has surged, both within the research community and within the commercial sector. However, given the early stage of interactive tabletop adoption and current low availability, it is difficult to find end users with extended experience in using such devices. We conducted a survey of 58 tabletop researchers and developers, the only available population with longer-term tabletop use experience, to find out how they use their devices, what they use them for, and what features they consider important for novice, single-user, and collaborative scenarios. While not without inherent biases, their answers suggest important directions for further research in designing and evaluating interactive tabletop systems, including identification of obstacles to mainstream adoption, and input and ergonomic challenges.", "num_citations": "47\n", "authors": ["1183"]}
{"title": "Interfaces for collaborative exploratory web search: Motivations and directions for multi-user design\n", "abstract": " In this position paper, we examine exploratory Web search as a collaborative activity and propose that such collaborations are commonplace. We present survey results that support this claim, and argue that current search interfaces provide limited support for common collaboration needs. We identify four features of the exploratory search experience (coverage, confidence, exposure, and productivity) that could be enhanced by providing explicit support for collaboration during the search and subsequent sensemaking processes.", "num_citations": "46\n", "authors": ["1183"]}
{"title": "Toward fairness in AI for people with disabilities SBG@ a research roadmap\n", "abstract": " AI technologies have the potential to dramatically impact the lives of people with disabilities (PWD). Indeed, improving the lives of PWD is a motivator for many state-of-the-art AI systems, such as automated speech recognition tools that can caption videos for people who are deaf and hard of hearing, or language prediction algorithms that can augment communication for people with speech or cognitive disabilities. However, widely deployed AI systems may not work properly for PWD, or worse, may actively discriminate against them. These considerations regarding fairness in AI for PWD have thus far received little attention. In this position paper, we identify potential areas of concern regarding how several AI technology categories may impact particular disability constituencies if care is not taken in their design, development, and testing. We intend for this risk assessment of how various classes of AI might interact\u00a0\u2026", "num_citations": "45\n", "authors": ["1183"]}
{"title": "ClassSearch: Facilitating the development of web search skills through social learning\n", "abstract": " We explore the use of social learning-improving knowledge skills by observing peer behavior-in the domain of Web search skill acquisition, focusing specifically on co-located classroom scenarios. Through a series of interviews, pilot studies, and classroom deployments, we conclude that a peripheral display of Web search activity within a classroom facilitates both social learning and teacher-led discourse. We present the ClassSearch system for shared awareness of Web search activity, which embodies principles gleaned from our iterative design process, and show results from a ClassSearch deployment in twelve middle-school classroom sessions. Finally, we highlight design suggestions and opportunities for future work while taxonomizing the space of co-located search pedagogies.", "num_citations": "45\n", "authors": ["1183"]}
{"title": "Remote shopping advice: enhancing in-store shopping with social technologies\n", "abstract": " Consumers shopping in\" brick-and-mortar\"(non-virtual) stores often use their mobile phones to consult with others about potential purchases. Via a survey (n= 200), we detail current practices in seeking remote shopping advice. We then consider how emerging social platforms, such as social networking sites and crowd labor markets, could offer rich next-generation remote shopping advice experiences. We conducted a field experiment in which shoppers shared photographs of potential purchases via MMS, Facebook, and Mechanical Turk. Paid crowdsourcing, in particular, proved surprisingly useful and influential as a means of augmenting in-store shopping. Based on our findings, we offer design suggestions for next-generation remote shopping advice systems.", "num_citations": "44\n", "authors": ["1183"]}
{"title": "Collaborating alone and together: Investigating persistent and multi-user web search activities\n", "abstract": " Today\u201f s web browsers provide limited support for rich information seeking and sharing scenarios. A survey we conducted of 204 knowledge workers at a large technology company has revealed that a large proportion of users engage in searches spanning multiple sessions and machines, and that such searches may include collaborative activities. We present the results of the survey, and then review the implications of these findings for designing new web search interfaces that provide tools for resumption of state and for sharing. Guided by the survey results, we propose a set of key collaboration features, including the importance of providing support for persistence, awareness, and division of labor.", "num_citations": "44\n", "authors": ["1183"]}
{"title": "How teens with visual impairments take, edit, and share photos on social media\n", "abstract": " We contribute a qualitative investigation of how teens with visual impairments (VIP) access smartphone photography, from the time they take photos through editing and sharing them on social media. We observed that they largely want to engage with photos visually, similarly to their sighted peers, and have developed strategies around photo capture, editing, sharing, and consumption that attempt to mitigate usability limitations of current photography and social media apps. We demonstrate the need for more work examining how young people with low vision engage with smartphone photography and social media, as they are heavy users of such technologies and have challenges distinct from their totally blind counterparts. We conclude with design considerations to alleviate the usability barriers we uncovered and for making smartphone photography and social media more accessible and relevant for VIPs.", "num_citations": "43\n", "authors": ["1183"]}
{"title": "\u201cIt's almost like they're trying to hide it\u201d: How User-Provided Image Descriptions Have Failed to Make Twitter Accessible\n", "abstract": " To make images on Twitter and other social media platforms accessible to screen reader users, image descriptions (alternative text) need to be added that describe the information contained within the image. The lack of alternative text has been an enduring accessibility problem since the \u201calt\u201d attribute was added in HTML 2.0 over 20 years ago, and the rise of user-generated content has only increased the number of images shared. As of 2016, Twitter provides users the ability to turn on a feature that allows descriptions to be added to images in their tweets, presumably in an effort to combat this accessibility problem. What has remained unknown is whether simply enabling users to provide alternative text has an impact on experienced accessibility. In this paper, we present a study of 1.09 million tweets with images, finding that only 0.1% of those tweets included descriptions. In a separate analysis of the timelines of\u00a0\u2026", "num_citations": "41\n", "authors": ["1183"]}
{"title": "Toward scalable social alt text: Conversational crowdsourcing as a tool for refining vision-to-language technology for the blind\n", "abstract": " The access of visually impaired users to imagery in social media is constrained by the availability of suitable alt text. It is unknown how imperfections in emerging tools for automatic caption generation may help or hinder blind users' understanding of social media posts with embedded imagery. In this paper, we study how crowdsourcing can be used both for evaluating the value provided by existing automated approaches and for enabling workflows that provide scalable and useful alt text to blind users. Using real-time crowdsourcing, we designed experiences that varied the depth of interaction of the crowd in assisting visually impaired users at caption interpretation, and measured trade-offs in effectiveness, scalability, and reusability. We show that the shortcomings of existing AI image captioning systems frequently hinder a user's understanding of an image they cannot see to a degree that even clarifying conversations with sighted assistants cannot correct. Our detailed analysis of the set of clarifying conversations collected from our studies led to the design of experiences that can effectively assist users in a scalable way without the need for real-time interaction. They also provide lessons and guidelines that human captioners and the designers of future iterations of AI captioning systems can use to improve labeling of social media imagery for blind users.", "num_citations": "41\n", "authors": ["1183"]}
{"title": "Estimating the social costs of friendsourcing\n", "abstract": " Every day users of social networking services ask their followers and friends millions of questions. These friendsourced questions not only provide informational benefits, but also may reinforce social bonds. However, there is a limit to how much a person may want to friendsource. They may be uncomfortable asking questions that are too private, might not want to expend others' time or effort, or may feel as though they have already accrued too many social debts. These perceived social costs limit the potential benefits of friendsourcing. In this paper we explore the perceived social costs of friendsourcing on Twitter via a monetary choice. We develop a model of how users value the attention and effort of their social network while friendsourcing, compare and contrast it with paid question answering in a crowdsourced labor market, and provide future design considerations for better supporting friendsourcing.", "num_citations": "41\n", "authors": ["1183"]}
{"title": "Surface-based collaborative search\n", "abstract": " BACKGROUND0002 Today, most computing devices, whether stationary or mobile device, utilize some form of display screen or surface as a user-interface (UI) component. Often these dis plays are merely output only devices, while a growing num ber utilize touch-sensitive screens for interactivity and/or input functionality. Recent technological advances both in terms of user-interfaces as well as display Surfaces have sparked a growing evolution toward Surface computing. In the domain of Surface computing, the associated displays are generally touch-sensitive screens of Substantially any form factor that often forego many traditional I/O devices such as a keyboard or mouse in favor of tactile-based manipulation. In order to compensate for this transition, computing Surfaces can be implemented as multi-touch surfaces. 0003. Due to the growing interest in surface computing, new techniques or technologies can be\u00a0\u2026", "num_citations": "41\n", "authors": ["1183"]}
{"title": "A field study of knowledge workers\u2019 use of interactive horizontal displays\n", "abstract": " To better understand the potential for horizontal surfaces in day-to-day work, we conducted a field study. We collected and analyzed over a month of use data from eight participants who used horizontal displays in conjunction with their existing office computer setups. Our analysis of the system logs, observations, and interview data from the study reveals clear differences in preference and use patterns for horizontal and vertical display configurations. Based on these findings, we formulate hardware and software design guidelines that would increase the utility of interactive horizontal displays for office scenarios.", "num_citations": "39\n", "authors": ["1183"]}
{"title": "Docudesk: An interactive surface for creating and rehydrating many-to-many linkages among paper and digital documents\n", "abstract": " Knowledge workers often undertake tasks that involve a variety of information artifacts, including both paper and digital documents. In this paper, we first summarize findings from a study that illustrate some of the challenges of managing tasks that include both paper and digital content. We then introduce DocuDesk, a prototype interactive desk that demonstrates interaction techniques for establishing many-to-many linkages among paper and digital documents which can be used to quickly ldquorehydraterdquo task state.", "num_citations": "38\n", "authors": ["1183"]}
{"title": "Disability, bias, and AI\n", "abstract": " On March 28, 2019, the AI Now Institute at New York University (NYU), the NYU Center for Disability Studies, and Microsoft convened disability scholars, AI developers, and computer science and human-computer interaction researchers to discuss the intersection of disability, bias, and AI, and to identify areas where more research and intervention are needed. 1This report captures and expands on some of the themes that emerged during discussion and debate. In particular, it identifies key questions that a focus on disability raises for the project of understanding the social implications of AI, and for ensuring that AI technologies don\u2019t reproduce and extend histories of marginalization.", "num_citations": "34\n", "authors": ["1183"]}
{"title": "Managing uncertainty in time expressions for virtual assistants\n", "abstract": " \" Remind me to get milk later this afternoon.\" In communications and planning, people often express uncertainty about time using imprecise temporal expressions (ITEs). Unfortunately, modern virtual assistants often lack system support to capture the intents behind these expressions. This can result in unnatural interactions and undesirable interruptions (eg, having a work reminder delivered at 12pm when out at lunch, because the user said\" this afternoon\"). In this paper we explore existing practices, expectations, and preferences surrounding the use of ITEs. Our mixed methods approach employs surveys, interviews, and an analysis of a large corpus of written communications. We find that people frequently use a diverse set of ITEs in both communication and planning. These uses reflect a variety of motivations, such as conveying uncertainty or task priority. In addition, we find that people have a variety of\u00a0\u2026", "num_citations": "34\n", "authors": ["1183"]}
{"title": "\" Person, Shoes, Tree. Is the Person Naked?\" What People with Vision Impairments Want in Image Descriptions\n", "abstract": " Access to digital images is important to people who are blind or have low vision (BLV). Many contemporary image description efforts do not take into account this population's nuanced image description preferences. In this paper, we present a qualitative study that provides insight into 28 BLV people's experiences with descriptions of digital images from news websites, social networking sites/platforms, eCommerce websites, employment websites, online dating websites/platforms, productivity applications, and e-publications. Our findings reveal how image description preferences vary based on the source where digital images are encountered and the surrounding context. We provide recommendations for the development of next-generation image description technologies inspired by our empirical analysis.", "num_citations": "32\n", "authors": ["1183"]}
{"title": "Eyes-free art: Exploring proxemic audio interfaces for blind and low vision art engagement\n", "abstract": " Engagement in the arts1 is an important component of participation in cultural activities, but remains a largely unaddressed challenge for people with sensory disabilities. Visual arts are generally inaccessible to people with visual impairments due to their inherently visual nature. To address this, we present Eyes-Free Art, a design probe to explore the use of proxemic audio for interactive sonic experiences with 2D art work. The proxemic audio interface allows a user to move closer and further away from a painting to experience background music, a novel sonification, sound effects, and a detailed verbal description. We conducted a lab study by creating interpretations of five paintings with 13 people with visual impairments and found that participants enjoyed interacting with the artwork. We then created a live installation with a visually impaired artist to iterate on this concept to account for multiple users and\u00a0\u2026", "num_citations": "32\n", "authors": ["1183"]}
{"title": "Co-located collaborative web search: understanding status quo practices\n", "abstract": " Co-located collaborative Web search is a surprisingly common activity, despite the fact that Web browsers and search engines are not designed to support collaboration. We report the findings of two studies (a diary study and an observational study) that provide insights regarding the frequency of co-located collaborative searching, the strategies participants use, and the pros and cons of these strategies. We then articulate design implications for next-generation tools that could enhance the experience of co-located collaborative search.", "num_citations": "31\n", "authors": ["1183"]}
{"title": "Supporting cooperative language learning: Issues in interface design for an interactive table\n", "abstract": " The recent introduction of computationally-enhanced tables that support simultaneous, multi-user input has important implications for co-located, face-to-face activity. Educational applications particularly stand to benefit from this new technology, which can combine the benefits of small group work with the enhancements offered by digital media. In this paper, we explore how the unique affordances of interactive tables provide a match for the needs of foreign language education, and how the design of tabletop software can be subtly altered to encourage desired educational outcomes. We present three prototype applications, and explore four design variations (feedback modality, feedback privacy, spatial configuration, and interaction visualizations) to assess their impact on student participation and self-assessment. We present observations of the use of our prototypes in two settings:(1) a controlled laboratory study and (2) authentic use by students as part of a language course at our university, and discuss our preliminary findings and avenues for future exploration.", "num_citations": "31\n", "authors": ["1183"]}
{"title": "Understanding the needs of searchers with dyslexia\n", "abstract": " As many as 20% of English speakers have dyslexia, a language disability that impacts reading and spelling. Web search is an important modern literacy skill, yet the accessibility of this language-centric endeavor to people with dyslexia is largely unexplored. We interviewed ten adults with dyslexia and conducted an online survey with 81 dyslexic and 80 non-dyslexic adults, in which participants described challenges they face in various stages of web search (query formulation, search result triage, and information extraction). We also report the findings of an online study in which 174 adults with dyslexia and 172 without dyslexia rated the readability and relevance of sets of search query results. Our findings demonstrate differences in behaviors and preferences between dyslexic and non-dyslexic searchers, and indicate that factoring readability into search engine rankings and/or interfaces may benefit both dyslexic\u00a0\u2026", "num_citations": "28\n", "authors": ["1183"]}
{"title": "AACrobat: Using mobile devices to lower communication barriers and provide autonomy with gaze-based AAC\n", "abstract": " Gaze-based alternative and augmentative communication (AAC) devices provide users with neuromuscular diseases the ability to communicate with other people through only the movement of their eyes. These devices suffer from slow input, causing a host of communication breakdowns to occur during face-to-face conversations. These breakdowns lead to decreased user autonomy, conversation quality, and communication partner engagement. Attempts to improve communication through these devices has mainly focused on throughput and rate enhancement, though this has only attained meager results to date. In this work, we address this issue from the top down by considering AAC devices as a form of groupware and designing interactions around this groupware that facilitate better conversations for all involved communicators. We first present qualitative findings on issues with gaze-based AAC and end\u00a0\u2026", "num_citations": "28\n", "authors": ["1183"]}
{"title": "iDwidgets: parameterizing widgets by user identity\n", "abstract": " We introduce the concept of identity-differentiating widgets (iDwidgets), widgets parameterized by the identity of their user. Although multi-user applications have become more common, most support only traditional \u201csingle-user\u201d widgets. By adding user-identity information we allow interactions with today\u2019s widgets to be dynamically customized on a per-user basis in a group usage setting. The concept has inspired the design of new widgets as well. In this paper we describe example iDwidgets and define a conceptual framework based on what is being customized in the widget. iDwidgets can support novel interaction techniques in collaborative settings.", "num_citations": "28\n", "authors": ["1183"]}
{"title": "Subcontracting microwork\n", "abstract": " Mainstream crowdwork platforms treat microtasks as indivisible units; however, in this article, we propose that there is value in re-examining this assumption. We argue that crowdwork platforms can improve their value proposition for all stakeholders by supporting subcontracting within microtasks. After describing the value proposition of subcontracting, we then define three models for microtask subcontracting: real-time assistance, task management, and task improvement, and reflect on potential use cases and implementation considerations associated with each. Finally, we describe the outcome of two tasks on Mechanical Turk meant to simulate aspects of subcontracting. We reflect on the implications of these findings for the design of future crowd work platforms that effectively harness the potential of subcontracting workflows.", "num_citations": "26\n", "authors": ["1183"]}
{"title": "\" At times avuncular and cantankerous, with the reflexes of a mongoose\" Understanding Self-Expression through Augmentative and Alternative Communication Devices\n", "abstract": " Amyotrophic Lateral Sclerosis (ALS) is a disease that causes individuals to lose their ability to control their muscles, eventually leaving them unable to speak or write. People with ALS often transition to using an augmentative and alternative communication device (AAC), which requires both the AAC user and their conversation partners to adjust to new and different communication patterns. We conducted interviews with seven individuals with ALS and their partners, focusing on how AAC use has impacted their communication and personal expression. Our participants experienced a range of communication difficulties, including conversational pacing, personality expression, and interacting with unfamiliar conversational partners. Participants worked to adapt their communication behaviors to the AAC device, but still experienced challenges in expressing themselves, and sometimes felt compelled to withdraw from\u00a0\u2026", "num_citations": "26\n", "authors": ["1183"]}
{"title": "Multiple mouse text entry for single-display groupware\n", "abstract": " A recent trend in interface design for classrooms in developing regions has many students interacting on the same display using mice. Text entry has emerged as an important problem preventing such mouse-based singledisplay groupware systems from offering compelling interactive activities. We explore the design space of mouse-based text entry and develop 13 techniques with novel characteristics suited to the multiple mouse scenario. We evaluated these in a 3-phase study over 14 days with 40 students in 2 developing region schools. The results show that one technique effectively balanced all of our design dimensions, another was most preferred by students, and both could benefit from augmentation to support collaborative interaction. Our results also provide insights into the factors that create an optimal text entry technique for single-display groupware systems.", "num_citations": "26\n", "authors": ["1183"]}
{"title": "AI and Accessibility\n", "abstract": " A discussion of ethical considerations.", "num_citations": "25\n", "authors": ["1183"]}
{"title": "Automated message prioritization: Making voicemail retrieval more efficient\n", "abstract": " Navigating through new voicemall messages to find messages of interest is a time-consuming task, particularly for high-volume users. When checking messages under a time contraint (eg, during a brief meeting break), users need to identify those messages requiring urgent action since not all messages can be processed in limited time. For these users, it would be useful if messages of greater urgency can be played first. For other users, distinguishing personal from business voicemail is a pressing need, to separate their home and business lives. We have successfully applied machine-learning techniques to lexical, acoustic, and contextual features of voicemail in order to sort messages based on urgency and on business-relevance.", "num_citations": "25\n", "authors": ["1183"]}
{"title": "Bridging screen readers and voice assistants for enhanced eyes-free web search\n", "abstract": " People with visual impairments often rely on screen readers when interacting with computer systems. Increasingly, these individuals also make extensive use of voice-based virtual assistants (VAs). We conducted a survey of 53 people who are legally blind to identify the strengths and weaknesses of both technologies, as well as the unmet opportunities at their intersection. We learned that virtual assistants are convenient and accessible, but lack the ability to deeply engage with content (eg, read beyond the first few sentences of Wikipedia), and the ability to get a quick overview of the landscape (list alternative search results & suggestions). In contrast, screen readers allow for deep engagement with content (when content is accessible), and provide fine-grained navigation & control, but at the cost of increased complexity, and reduced walk-up-and-use convenience. In this demonstration, we showcase VERSE, a\u00a0\u2026", "num_citations": "24\n", "authors": ["1183"]}
{"title": "How to remember what to remember: exploring possibilities for digital reminder systems\n", "abstract": " Digital reminder systems typically use time and place as triggers to remind people to perform activities. In this paper, we investigate how digital reminder systems could better support the process of remembering in a wider range of situations. We report findings from a survey and one-week diary study, which reveal that people want to remember to perform a broad spectrum of activities in the future, many of which cannot be supported by simple time- and location-based reminders. In addition to these examples of prospective memory, or \u2018remembering intentions\u2019 [53], we also find that people want support in \u2018retrieving\u2019 [53] information and details, especially those encountered through social interactions or intended for use in conversations with others. Drawing on our analysis of what people want to remember and how they try to support this, we draw implications for the design of intelligent reminder systems such as\u00a0\u2026", "num_citations": "24\n", "authors": ["1183"]}
{"title": "Crowdsourcing similarity judgments for agreement analysis in end-user elicitation studies\n", "abstract": " End-user elicitation studies are a popular design method, but their data require substantial time and effort to analyze. In this paper, we present Crowdsensus, a crowd-powered tool that enables researchers to efficiently analyze the results of elicitation studies using subjective human judgment and automatic clustering algorithms. In addition to our own analysis, we asked six expert researchers with experience running and analyzing elicitation studies to analyze an end-user elicitation dataset of 10 functions for operating a web-browser, each with 43 voice commands elicited from end-users for a total of 430 voice commands. We used Crowdsensus to gather similarity judgments of these same 430 commands from 410 online crowd workers. The crowd outperformed the experts by arriving at the same results for seven of eight functions and resolving a function where the experts failed to agree. Also, using Crowdsensus\u00a0\u2026", "num_citations": "23\n", "authors": ["1183"]}
{"title": "Managing stress: the needs of autistic adults in video calling\n", "abstract": " Video calling (VC) aims to create multi-modal, collaborative environments that are \"just like being there.\" However, we found that autistic individuals, who exhibit atypical social and cognitive processing, may not share this goal. We interviewed autistic adults about their perceptions of VC compared to other computer- mediated communications (CMC) and face-to-face interactions. We developed a neurodiversity-sensitive model of CMC that describes how stressors such as sensory sensitivities, cognitive load, and anxiety, contribute to their preferences for CMC channels. We learned that they apply significant effort to construct coping strategies to support their sensory, cognitive, and social needs. These strategies include moderating their sensory inputs, creating mental models of conversation partners, and attempting to mask their autism by adopting neurotypical behaviors. Without effective strategies, interviewees\u00a0\u2026", "num_citations": "22\n", "authors": ["1183"]}
{"title": "Enhancing technical Q&A forums with CiteHistory\n", "abstract": " Software engineers often use Q&A forums like Stack Overflow and MSDN to ask and answer technical questions. Through a survey study and web browser log analysis, we find that both askers and answerers of technical forum questions typically conduct extensive online research before composing their posts. The inclusion of links to these research materials is beneficial to the forum participants, though post authors do not always include such citations. Based on these findings, we developed CiteHistory, a browser plugin that simplifies the process of including relevant search queries and URLs as bibliographic supplements to forum posts, and supports information re-finding for post authors. We discuss the results of a two-week deployment of CiteHistory with professional software engineers, which demonstrated that CiteHistory increased reference inclusion in posts, and offered auxiliary benefits as a personal research tracker.", "num_citations": "21\n", "authors": ["1183"]}
{"title": "Identity-differentiating widgets for multiuser interactive surfaces\n", "abstract": " Widgets - standard reusable GUI elements - are a staple of user-interface development. The use of widget toolkits, such as Java's Swing, X Window System's Motif, or Microsoft's MFC, allows programmers to quickly incorporate a number of standard interactions (such as clicking buttons, selecting check boxes, or scrolling through lists) into their software. To date, most widgets have been designed for use by one person at a time. Within a single session, a widget behaves the same regardless of who uses it. By applying the iDwidgets concept, the authors supplement traditional widgets with identity differentiation that supports widget reuse, dynamic widget customization, clutter reduction, and novel multiuser widget type creation. This article introduces a conceptual framework for iDwidgets, describing four axes that application can customize by exploiting identity differentiation: function, content, appearance, and group\u00a0\u2026", "num_citations": "21\n", "authors": ["1183"]}
{"title": "Reducing clutter on tabletop groupware systems with tangible drawers\n", "abstract": " Simultaneously presenting multiple users\u2019 data on a single, shared display, such as an interactive tabletop, often results in visual clutter. One strategy to reduce clutter on horizontal surfaces in the physical world is to store objects in drawers. Items in drawers are hidden from view but are accessible when needed. Inspired by analogies with traditional desks and tables, we have developed tangible drawer mechanisms to augment a projected multi-user tabletop display. The drawers serve as dedicated input mechanisms to access, scroll through, and hide personal data. We describe our implementation and interaction techniques, and then report results from an informal pilot study.", "num_citations": "21\n", "authors": ["1183"]}
{"title": "Closing the gap: Designing for the last-few-meters wayfinding problem for people with visual impairments\n", "abstract": " Despite the major role of Global Positioning Systems (GPS) as a navigation tool for people with visual impairments (VI), a crucial missing aspect of point-to-point navigation with these systems is the last-few-meters wayfinding problem. Due to GPS inaccuracy and inadequate map data, systems often bring a user to the vicinity of a destination but not to the exact location, causing challenges such as difficulty locating building entrances or a specific storefront from a series of stores. In this paper, we study this problem space in two parts:(1) A formative study (N= 22) to understand challenges, current resolution techniques, and user needs; and (2) A design probe study (N= 13) using a novel, vision-based system called Landmark AI to understand how technology can better address aspects of this problem. Based on these investigations, we articulate a design space for systems addressing this challenge, along with\u00a0\u2026", "num_citations": "20\n", "authors": ["1183"]}
{"title": "VERSE: Bridging screen readers and voice assistants for enhanced eyes-free web search\n", "abstract": " People with visual impairments often rely on screen readers when interacting with computer systems. Increasingly, these individuals also make extensive use of voice-based virtual assistants (VAs). We conducted a survey of 53 people who are legally blind to identify the strengths and weaknesses of both technologies, and the unmet opportunities at their intersection. We learned that virtual assistants are convenient and accessible, but lack the ability to deeply engage with content (eg, read beyond the first few sentences of an article), and the ability to get a quick overview of the landscape (eg, list alternative search results and suggestions). In contrast, screen readers allow for deep engagement with content (when content is accessible), and provide fine-grained navigation and control, but at the cost of reduced walk-up-and-use convenience. Based on these findings, we implemented VERSE (Voice Exploration\u00a0\u2026", "num_citations": "20\n", "authors": ["1183"]}
{"title": "Accessible by design: An opportunity for virtual reality\n", "abstract": " Too often, the accessibility of technology to people with disabilities is an afterthought (if it is considered at all); post-hoc or third-party patches to accessibility, while better than no solution, are less optimal than interface designs that consider ability-based concerns from the start [31]. Virtual Reality (VR) technologies are at a crucial point of near-maturity, with emerging, but not yet widespread, commercialization; as such, VR technologies have an opportunity to integrate accessibility as a fundamental, developing cross-industry standards and guidelines to ensure high-quality, inclusive experiences that could revolutionize the power and reach of this medium. In this position paper, we discuss the needs, opportunities, and challenges of creating accessible VR.", "num_citations": "20\n", "authors": ["1183"]}
{"title": "Exploring the complementary roles of social networks and search engines\n", "abstract": " The Web has become an important information repository; often it is the first source a person turns to with an information need. One common way to search the Web is with a search engine. However, it is not always easy for people to find what they are looking for with keyword search, and at times the desired information may not be readily available online. An alternative, facilitated by the rise of social media, is to pose a question to one's online social network. We present a series of studies that have explored the differences in the types of questions that people choose to explore via asking their networks versus using search engines, and compare the speed, quality, and quantity of answers discovered using these two methods. We then discuss the implications of these findings for nextgeneration information-seeking technologies that integrate the benefits of using both search engines and social networks. We believe there is an opportunity for tools to help people\u2019s friends collaborate with algorithmic information retrieval tools to produce better answers than either approach might identify alone.", "num_citations": "19\n", "authors": ["1183"]}
{"title": "Understanding groups' properties as a means of improving collaborative search systems\n", "abstract": " Understanding the similar properties of people involved in group search sessions has the potential to significantly improve collaborative search systems; such systems could be enhanced by information retrieval algorithms and user interface modifications that take advantage of important properties, for example by re-ordering search results using information from group members' combined user profiles. Understanding what makes group members similar can also assist with the identification of groups, which can be valuable for connecting users with others with whom they might undertake a collaborative search. In this workshop paper, we describe our current research efforts towards studying the properties of a variety of group types. We discuss properties of groups that may be relevant to designers of collaborative search systems, and propose ways in which understanding such properties could influence the design of interfaces and algorithms for collaborative Web search.", "num_citations": "19\n", "authors": ["1183"]}
{"title": "FootNotes: Geo-referenced audio annotations for nonvisual exploration\n", "abstract": " The majority of information in the physical environment is conveyed visually, meaning that people with vision impairments often lack access to the shared cultural, historical, and practical features that define a city. How can someone who is blind find out about the sleek skyscrapers that dot a modern city's skyline, historic cannons that have been remade into traffic pillars, or ancient trees that uproot a neighborhood's sidewalks? We present FootNotes, a system that embeds rich textual descriptions of objects and locations in OpenStreetMap, a popular geowiki. Both sighted and blind users can annotate the physical environment with functional, visual, historical, and social descriptions. We report on the experience of ten participants with vision impairments who used a spatialized audio application to interact with these annotations while exploring a city. By sharing rich annotations of physical objects and areas\u00a0\u2026", "num_citations": "18\n", "authors": ["1183"]}
{"title": "Exploring the Design Space of AAC Awareness Displays\n", "abstract": " Augmentative and alternative communication (AAC) devices are a critical technology for people with disabilities that affect their speech. One challenge with AAC systems is their inability to portray aspects of nonverbal communication that typically accent, complement, regulate, or substitute for verbal speech. In this paper, we explore the design space of awareness displays that can supplement AAC devices, considering their output features and their effects on the perceptions of interlocutors. Through designing prototypes and getting feedback on our designs from people with ALS, their primary caregivers, and other communication partners, we consider (1) the consistent tensions that arose between abstractness and clarity in meaning for these designs and (2) the ways in which these designs can further mark users as\" other.\" Overall, we contribute a generative understanding of designing AAC awareness displays to\u00a0\u2026", "num_citations": "18\n", "authors": ["1183"]}
{"title": "\u201cWhy would anybody do this?\u201d: Older Adults\u2019 Understanding of and Experiences with Crowd Work\n", "abstract": " Diversifying participation in crowd work can benefit the worker and requester. Increasing numbers of older adults are online, but little is known about their awareness of or how they engage in mainstream crowd work. Through an online survey with 505 seniors, we found that most have never heard of crowd work but would be motivated to complete tasks by earning money or working on interesting or stimulating tasks. We follow up results from the survey with interviews and observations of 14 older adults completing crowd work tasks. While our survey data suggests that financial incentives are encouraging, in-depth interviews reveal that a combination of personal and social incentives may be stronger drivers of participation, but only if older adults can overcome accessibility issues and understand the purpose of crowd work. This paper contributes insights into how crowdsourcing sites could better engage seniors and other users.", "num_citations": "18\n", "authors": ["1183"]}
{"title": "Credibility perceptions of content contributors and consumers in social media\n", "abstract": " This panel addresses information credibility issues in the context of social media. During this panel, participants will discuss people's credibility perceptions of online content in social media from the perspectives of both content contributors and consumers. Each panelist will bring her own perspective on credibility issues in various social media, including Twitter (Morris), Wikipedia (Metzger; Francke), blogs (Rieh), and social Q&A (Jeon). This panel aims to flesh out multi\u2010disciplinary approaches to the investigation of credibility and discuss integrated conceptual frameworks and future research directions focusing on assessing and establishing credibility in social media.", "num_citations": "18\n", "authors": ["1183"]}
{"title": "Mapping of physical controls for surface computing\n", "abstract": " Physical controls on a physical controller device (PCD) are dynamically mapped to application controls for an application being executed on a computer having a touch-sensitive display surface. The computer identifies a PCD which has been placed by a user on the display surface and displays a mapping aura for the PCD. When the user touches an activate direct-touch button displayed within the mapping aura, the computer activates a mapping procedure for the PCD and displays a highlighted direct-touch button over each application control which is available to be mapped to the physical controls on the PCD. When the user selects a particular application control which is available to be mapped by touching the highlighted button residing over the control, the computer creates a dynamic mapping between the selected application control and a user-selected physical control on the PCD.", "num_citations": "18\n", "authors": ["1183"]}
{"title": "Crowdlicit: A system for conducting distributed end-user elicitation and identification studies\n", "abstract": " End-user elicitation studies are a popular design method. Currently, such studies are usually confined to a lab, limiting the number and diversity of participants, and therefore the representativeness of their results. Furthermore, the quality of the results from such studies generally lacks any formal means of evaluation. In this paper, we address some of the limitations of elicitation studies through the creation of the Crowdlicit system along with the introduction of end-user identification studies, which are the reverse of elicitation studies. Crowdlicit is a new web-based system that enables researchers to conduct online and in-lab elicitation and identification studies. We used Crowdlicit to run a crowd-powered elicitation study based on Morris's\" Web on the Wall\" study (2012) with 78 participants, arriving at a set of symbols that included six new symbols different from Morris's. We evaluated the effectiveness of 49 symbols\u00a0\u2026", "num_citations": "17\n", "authors": ["1183"]}
{"title": "Assessing the readability of web search results for searchers with dyslexia\n", "abstract": " Standards organizations,(eg, the World Wide Web Consortium), are placing increased importance on the cognitive accessibility of online systems, including web search. Previous work has shown an association between query-document relevance judgments, and query-independent assessments of document readability. In this paper we study the lexical and aesthetic features of web documents that may underlie this relationship. Leveraging a data set consisting of relevance and readability judgments for 200 web pages as assessed by 174 adults with dyslexia and 172 adults without dyslexia, we answer the following research questions:(1) Which web page features are most associated with readability?(2) To what extent are these features also associated with relevance? And,(3) are any features associated with the differences in readability/relevance judgments observed between dyslexic and non-dyslexic\u00a0\u2026", "num_citations": "16\n", "authors": ["1183"]}
{"title": "Understanding the accessibility of smartphone photography for people with motor impairments\n", "abstract": " We present the results of an exploration to understand the accessibility of smartphone photography for people with motor impairments. We surveyed forty-six people and interviewed twelve people about capturing, editing, and sharing photographs on smartphones. We found that people with motor impairments encounter many challenges with smartphone photography, resulting in users capturing fewer photographs than they would like. Participants described various strategies they used to overcome challenges in order to capture a quality photograph. We also found that photograph quality plays a large role in deciding which photographs users share and how often they share, with most participants rating their photographs as average or poor quality compared to photos shared on their social networks. Additionally, we created design probes of two novel photography interfaces and received feedback from our\u00a0\u2026", "num_citations": "16\n", "authors": ["1183"]}
{"title": "TeleTourist: Immersive telepresence tourism for mobility-restricted participants\n", "abstract": " People can have experiences through video calls that are otherwise inaccessible. For example, someone who cannot leave the home may wish to experience visiting the zoo. We present TeleTourist, a system that uses video calls with strangers to share experiences for people with mobility restrictions. We designed TeleTourist to enhance immersion and personalization, as well as help balance the relationship between participants of the video calls. We discuss features we have implemented or envisioned for TeleTourist, as well as attributes we wish to evaluate in future work.", "num_citations": "16\n", "authors": ["1183"]}
{"title": "Is anyone out there? Unpacking Q&A hashtags on Twitter\n", "abstract": " In addition to posting news and status updates, many Twitter users post questions that seek various types of subjective and objective information. These questions are often labeled with'Q&A'hashtags, such as# lazyweb or# twoogle. We surveyed Twitter users and found they employ these Q&A hashtags both as a topical signifier (this tweet needs an answer!) and to reach out to those beyond their immediate followers (a community of helpful tweeters who monitor the hashtag). However, our log analysis of thousands of hashtagged Q&A exchanges reveals that nearly all replies to hashtagged questions come from a user's immediate follower network, contradicting users' beliefs that they are tapping into a larger community by tagging their question tweets. This finding has implications for designing next-generation social search systems that reach and engage a wide audience of answerers.", "num_citations": "16\n", "authors": ["1183"]}
{"title": "Kinected browser: depth camera interaction for the web\n", "abstract": " Interest in and development of gesture interfaces has recently exploded, fueled in part by the release of Microsoft Corporation's Kinect, a low-cost, consumer-packaged depth camera with integrated skeleton tracking. Depth-camera-based gestures can facilitate interaction with the Web on keyboard-and-mouse-free and/or multi-user technologies, such as large display walls or TV sets. We present a toolkit for bringing such gesture affordances into modern Web browsers using existing Web programming methods. Our framework is designed to enable Web programmers to incrementally add this capability with minimum effort by leveraging Web standard DOM structures and event models. We describe our framework's design and architecture, and illustrate its usability and versatility.", "num_citations": "15\n", "authors": ["1183"]}
{"title": "Collaborative tabletop research and evaluation\n", "abstract": " Tables provide a large and natural interface for supporting direct manipulation of visual content, for human-to-human interactions and for collaboration, coordination, and parallel problem solving. However, the direct-touch table metaphor also presents considerable challenges, including the need for input methods that transcend traditional mouse- and keyboard-based designs.", "num_citations": "15\n", "authors": ["1183"]}
{"title": "Quantifying collaboration on computationally-enhanced tables\n", "abstract": " Recent research in our group has focused on tabletop interface design, with an emphasis on identifying design guidelines that facilitate group work. We have developed several collaborative tabletop applications, and have evaluated them through formal usability studies and informal walkthroughs. However, while we have had success in evaluating the usability of specific aspects of the tabletop interfaces (aspects of what Pinelle et al.[5] refer to as \u201ctaskwork\u201d), the impact of the interface on the \u201cteamwork\u201d dynamics is far more difficult to judge. We hope that this workshop will provide a stepping-stone for developing a standard for quantitatively and qualititatively describing the impact of groupware technology on collaboration.", "num_citations": "15\n", "authors": ["1183"]}
{"title": "Modular wearable device for conveying affective state\n", "abstract": " A wearable device conveys information to a user. The device includes a master soft circuit cell and a plurality of actuation soft circuit cells. These cells are physically interconnected to form a garment that is worn by a user and each of these cells includes an electrically non-conductive fabric covering. Each of the actuation cells is electrically connected to and operates under the control of the master cell. The master cell is configured to wirelessly receive actuation instructions and activate a combination of the actuation cells based on the received actuation instructions. Each of the actuation cells is configured to generate a particular actuation that is perceived by one or more senses of the user whenever the actuation cell is activated by the master cell. A system also conveys affective state information to a user.", "num_citations": "14\n", "authors": ["1183"]}
{"title": "Obtaining remote shopping advice\n", "abstract": " Various methods and systems for obtaining remote shopping advice are described herein. In one example, a method includes taking two or more media representations of items to be discussed. A parameter is selected within a social shopping app for obtaining feedback on the items to be discussed. The two or more media representations are assembled into a query within the social shopping app based, at least in part, on the parameter. The query is sent to a reviewer from within the social shopping app. Feedback on the items to be discussed is received from the reviewer within the social shopping app.", "num_citations": "13\n", "authors": ["1183"]}
{"title": "Using physical signaling to support collaborative mobile search\n", "abstract": " Often when people search the web from their phones, they do so collaboratively. We present a mobile application that supports in-person collaborative search by allowing users to physically signal a willingness to share. While the core application provides standard mobile search functionality, users rotate their devices to landscape orientation to indicate (to the device and others) they are entering a collaborative mode. We study two uses of collaborative mode, one where users rate results to create a group list, and another where screens and actions are shared across devices.", "num_citations": "13\n", "authors": ["1183"]}
{"title": "Linking digital and paper documents\n", "abstract": " Various embodiments facilitate linking physical documents to digital documents. Links link physical documents to digital documents. Using a sensor, the physical documents are automatically detected and identified on a digital workspace. A computer is capable of displaying graphics, and user interaction with displayed graphics can be detected. The digital workspace displays a GUI component having one or more controls, and the GUI component is displayed at a location relative to a physical document on the digital workspace. User interaction with the control is detected and either a link between the physical document and one of the digital documents is edited, or an existing link between the physical document and a digital document is used to perform an operation on the digital document. Alternatively or additionally, links may be automatically generated digital documents determined to be implicitly related to the\u00a0\u2026", "num_citations": "13\n", "authors": ["1183"]}
{"title": "System and interface for co-located collaborative web search\n", "abstract": " Systems and methods are provided to perform collaborative retrieval, communication, and navigation of electronic content in a co-located environment. In an illustrative implementation, a collaborative content environment comprises a collaborative content interface engine, and an instruction set comprising at least one instruction providing instructions to the collaborative content interface engine to process data representative of inputs from two or more cooperating interface devices to allow for the retrieval, communication, search, and navigation of electronic content. In the illustrative implementation, the collaborative content interface engine can present retrieved, communicated, searched, and/or navigated data according to a selected display paradigm. The display paradigm can include one or more display portions of a display pane comprising data responsive to the inputs received from the two or more\u00a0\u2026", "num_citations": "12\n", "authors": ["1183"]}
{"title": "Voicesetting: voice authoring UIs for improved expressivity in augmentative communication\n", "abstract": " Alternative and augmentative communication (AAC) systems used by people with speech disabilities rely on text-to-speech (TTS) engines for synthesizing speech. Advances in TTS systems allowing for the rendering of speech with a range of emotions have yet to be incorporated into AAC systems, leaving AAC users with speech that is mostly devoid of emotion and expressivity. In this work, we describe voicesetting as the process of authoring the speech properties of text. We present the design and evaluation of two voicesetting user interfaces: the Expressive Keyboard, designed for rapid addition of expressivity to speech, and the Voicesetting Editor, designed for more careful crafting of the way text should be spoken. We evaluated the perceived output quality, requisite effort, and usability of both interfaces; the concept of voicesetting and our interfaces were highly valued by end-users as an enhancement to\u00a0\u2026", "num_citations": "10\n", "authors": ["1183"]}
{"title": "Supporting interpersonal interaction during collaborative mobile search\n", "abstract": " O-SNAP is a mobile application that explicitly supports in-person collaborative search by enabling users to physically signal their willingness to share and by facilitating face-to-face search-related communication. The Web extra at http://youtu.be/AKoITuxB9BY is a video in which author Meredith Ringel Morris discusses scenarios that can prompt collaborative information seeking.", "num_citations": "10\n", "authors": ["1183"]}
{"title": "Strategies for auditory display of Social Media\n", "abstract": " Social media is an overwhelmingly visual medium, and we ask the simple question: How can the data and images of social media posts be transformed into something as meaningful and vivid in the auditory sense? Such a design would be useful for eyes-free browsing and could enhance the existing visual media. Our strategy first uses artificial intelligence systems to transform low-level input data into high-level sociocultural features. These features are then conveyed using a multifactored temporal design that uses speech, sonification, auditory scenes, and music.", "num_citations": "9\n", "authors": ["1183"]}
{"title": "Web search as a linguistic tool\n", "abstract": " Many people rely on web search engines to check the spelling or grammatical correctness of input phrases. For example, one might search [recurring or reoccurring] to decide between these similar words. While language-related queries are common, they have low click-through rates, lack a strong intent signal, and are generally challenging to study. Perhaps for these reasons, they have yet to be characterized in the literature. In this paper we report the results of two surveys that investigate how, when, and why people use web search to support low-level, language-related tasks. The first survey was distributed by email, and asked participants to reflect on a recent search task. The second survey was embedded directly in search result pages, and captured information about searchers' intents in-situ. Our analysis confirms that language-related search tasks are indeed common, accounting for at least 2.7% of all\u00a0\u2026", "num_citations": "9\n", "authors": ["1183"]}
{"title": "Using physical objects in conjunction with an interactive surface\n", "abstract": " An interaction management module (IMM) is described for allowing users to engage an interactive Surface in a collabo rative environment using various input devices, such as key board-type devices and mouse-type devices. The IMM dis plays digital objects on the interactive Surface that are associated with the devices in various ways. The digital objects can include input display interfaces, cursors, soft-key input mechanisms, and so on. Further, the IMM provides a mechanism for establishing a frame of reference for govern ing the placement of each cursor on the interactive surface. Further, the IMM provides a mechanism for allowing users to make a digital copy of a physical article placed on the inter active surface. The IMM also provides a mechanism which duplicates actions taken on the digital copy with respect to the physical article, and vice versa.", "num_citations": "9\n", "authors": ["1183"]}
{"title": "Understanding the potential for collaborative search technologies in clinical settings\n", "abstract": " In this position paper, we report the findings of interviews with four medical doctors regarding the use of internet search by doctors and patients in support of the treatment process; we particularly focus on opportunities for collaboration between doctors and patients in clinical information retrieval scenarios.", "num_citations": "9\n", "authors": ["1183"]}
{"title": "\u201cI just went into it assuming that I wouldn't be able to have the full experience\u201d Understanding the Accessibility of Virtual Reality for People with Limited Mobility\n", "abstract": " Virtual reality (VR) has the potential to transform many aspects of our daily lives, including work, entertainment, communication, and education. However, there has been little research into understanding the usability of VR for people with mobility limitations. In this paper, we present the results of an exploration to understand the accessibility of VR for people with limited mobility. We conducted semi-structured interviews with 16 people with limited mobility about their thoughts on, and experiences with, VR systems. We identified 7 barriers related to the physical accessibility of VR devices that people with limited mobility might encounter, ranging from the initial setup of a VR system to keeping VR controllers in view of cameras embedded in VR headsets. We also elicited potential improvements to VR systems that would address some accessibility concerns. Based on our findings, we discuss the importance of\u00a0\u2026", "num_citations": "8\n", "authors": ["1183"]}
{"title": "The impact of web browser reader views on reading speed and user experience\n", "abstract": " As reading increasingly shifts from paper to online media, many web browsers now provide a\" Reader View,''which modifies web page layout and design for better readability. However, research has yet to establish whether Reader Views are effective in improving readability and how they might change the user experience. We characterize how Mozilla Firefox's Reader View significantly reduces the visual complexity of websites by excluding menus, images, and content. We then conducted an online study with 391 participants (including 42 who self-reported having been diagnosed with dyslexia), showing that compared to standard websites the Reader View increased reading speed by 5% for readers on average, and significantly improved perceived readability and visual appeal. We suggest guidelines for the design of websites and browsers that better support people with varying reading skills.", "num_citations": "8\n", "authors": ["1183"]}
{"title": "Demonstration of enabling people with visual impairments to navigate virtual reality with a haptic and auditory cane simulation\n", "abstract": " Traditional virtual reality (VR) mainly focuses on visual feedback, which is not accessible for people with visual impairments. We created Canetroller [6], a haptic cane controller that simulates white cane interactions, enabling people with visual impairments to navigate a virtual environment by transferring their cane skills into the virtual world. Canetroller provides three types of feedback:(1) physical resistance generated by a wearable programmable brake mechanism that physically impedes the controller when the virtual cane comes in contact with a virtual object;(2) vibrotactile feedback that simulates the vibrations when a cane hits an object or touches and drags across various surfaces; and (3) spatial 3D auditory feedback simulating the sound of real-world cane interactions. We demonstrate the design of Canetroller in this paper.", "num_citations": "8\n", "authors": ["1183"]}
{"title": "Let's Talk about X: Combining image recognition and eye gaze to support conversation for people with ALS\n", "abstract": " Communicating at a natural speed is a significant challenge for users of augmentative and alternative communication (AAC) devices, especially when input is provided by eye gaze, as is common for people with ALS and similar conditions. One way to improve AAC throughput is by drawing on contextual information from the outside world. Toward this goal, we present SceneTalk, a prototype gaze-based AAC system that uses computer vision to identify objects in the user's field of view and suggests words and phrases related to the current scene. We conducted a formative evaluation of SceneTalk with six people with ALS, in which we evaluated their preference for user interface modes and output preferences. Participants agreed that integrating contextual awareness into their AAC device could be helpful across a diverse range of situations.", "num_citations": "8\n", "authors": ["1183"]}
{"title": "Edufeed: A social feed to engage preliterate children in educational activities\n", "abstract": " In this work, we present EduFeed, a system that enables preliterate children to explore an algorithmically-mediated social feed of learning exercises, select activities to engage in, and share them with their peers. We deployed EduFeed as a technology probe to three classrooms of ESL students in the first year of elementary school in India who had limited English literacy and limited experience with touchscreen technology. We found that children were able to self-direct their engagement with the system and were initially motivated by digital sharing, while social context surrounding the system in physical space was also important. Based on our design and probe deployment, we reflect on issues relevant to adapting the social feed paradigm to this context, such as ranking algorithms, physicality, immediacy, and bridging physical and digital collaborative experiences.", "num_citations": "8\n", "authors": ["1183"]}
{"title": "Collaborative search tools\n", "abstract": " Described herein are technologies pertaining to search in general, and collaborative searching in particular. Graphical items are generated that are representative of searches. The graphical items include graphical indicia that indicate which search results were included in other, related searches.", "num_citations": "8\n", "authors": ["1183"]}
{"title": "Benefits and Challenges of Tabletop Peripheral Displays\n", "abstract": " People tend to gather around tables both for work and for recreation, making them a tempting space to present awareness information. We motivate the use of tables as ambient displays in ubiquitous computing spaces, and reflect on lessons learned from our experiences with the AmbienTable, a prototype tabletop peripheral display deployed in the iRoom.", "num_citations": "8\n", "authors": ["1183"]}
{"title": "Evaluating and Complementing Vision-to-Language Technology for People who are Blind with Conversational Crowdsourcing.\n", "abstract": " We study how real-time crowdsourcing can be used both for evaluating the value provided by existing automated approaches and for enabling workflows that provide scalable and useful alt text to blind users. We show that the shortcomings of existing AI image captioning systems frequently hinder a user\u2019s understanding of an image they cannot see to a degree that even clarifying conversations with sighted assistants cannot correct. Based on analysis of clarifying conversations collected from our studies, we design experiences that can effectively assist users in a scalable way without the need for real-time interaction. Our results provide lessons and guidelines that the designers of future AI captioning systems can use to improve labeling of social media imagery for blind users.", "num_citations": "7\n", "authors": ["1183"]}
{"title": "Designing tabletop groupware\n", "abstract": " Interactive tables are an emerging class of devices that are subject to different design constraints than other types of single display groupware. Through prototype-building and evaluation, we have identified three key design challenges for tabletop groupware: integrating access to public and private information, managing display elements, and mediating group dynamics. We discuss each of these issues and present approaches we have developed to address the challenges they present.", "num_citations": "7\n", "authors": ["1183"]}
{"title": "Visualization for Casual Debugging and System Awareness in a Ubiquitous Computing Environment\n", "abstract": " We describe a visualization of the status of information flow in a ubiquitous computing setting. We explain the semantics of the visualization, and discuss how this display has assisted novice users of our ubicomp environment with debugging and system understanding.", "num_citations": "7\n", "authors": ["1183"]}
{"title": "Designing an Online Infrastructure for Collecting AI Data From People With Disabilities\n", "abstract": " AI technology offers opportunities to expand virtual and physical access for people with disabilities. However, an important part of bringing these opportunities to fruition is ensuring that upcoming AI technology works well for people with a wide range of abilities. In this paper, we identify the lack of data from disabled populations as one of the challenges to training and benchmarking fair and inclusive AI systems. As a potential solution, we envision an online infrastructure that can enable large-scale, remote data contributions from disability communities. We investigate the motivations, concerns, and challenges that people with disabilities might experience when asked to collect and upload various forms of AI-relevant data through a semi-structured interview and an online survey that simulated a data contribution process by collecting example data files through an online portal. Based on our findings, we outline\u00a0\u2026", "num_citations": "6\n", "authors": ["1183"]}
{"title": "User interface for generating expressive content\n", "abstract": " Generation of expressive content is provided. An expressive synthesized speech system provides improved voice authoring user interfaces by which a user is enabled to efficiently author content for generating expressive output. An expressive synthesized speech system provides an expressive keyboard for enabling input of textual content and for selecting expressive operators, such as emoji objects or punctuation objects for applying predetermined prosody attributes or visual effects to the textual content. A voicesetting editor mode enables the user to author and adjust particular prosody attributes associated with the content for composing carefully-crafted synthetic speech. An active listening mode (ALM) is provided, which when selected, a set of ALM effect options are displayed, wherein each option is associated with a particular sound effect and/or visual effect. The user is enabled to rapidly respond with\u00a0\u2026", "num_citations": "6\n", "authors": ["1183"]}
{"title": "Conflict resolution in paper and digital worlds: Two surveys of user expectations\n", "abstract": " We discuss the findings of two surveys, which presented respondents with a hypothetical situation regarding a conflict over either a paper or a digital document and solicited their free-form responses regarding possible outcomes of the situation. The results suggest conditions under which mechanisms to coordinate the outcome of such conflicts might be useful to include in groupware, as well as offering possibilities for what these mechanisms might be.", "num_citations": "6\n", "authors": ["1183"]}
{"title": "Centering disability perspectives in algorithmic fairness, accountability, & transparency\n", "abstract": " It is vital to consider the unique risks and impacts of algorithmic decision-making for people with disabilities. The diverse nature of potential disabilities poses unique challenges for approaches to fairness, accountability, and transparency. Many disabled people choose not to disclose their disabilities, making auditing and accountability tools particularly hard to design and operate. Further, the variety inherent in disability poses challenges for collecting representative training data in any quantity sufficient to better train more inclusive and accountable algorithms.", "num_citations": "5\n", "authors": ["1183"]}
{"title": "Leveraging environmental context for enhanced communication throughput\n", "abstract": " An environmental context of a user may be taken into account to enhance the user's communication throughput. An \u201cenvironmental context\u201d can include spatial surroundings of a user, device, and/or sensor of the device and more broadly to denote the context of the user in a multiplicity of environments such as, for example, the surroundings of a user, a digital environment such as the user or other individuals' interactions with or made near a device, etc. The techniques can include obtaining contextual data to provide context-predicted suggestions of words and/or phrases that a user can select to be output on the user's behalf. In some examples, the techniques can also use contextual data to weight, sort, rank, and/or filter word and/or phrase suggestions.", "num_citations": "5\n", "authors": ["1183"]}
{"title": "Social microvolunteering: Donating access to your friends for charitable microwork\n", "abstract": " We propose social microvolunteering, in which people can do charitable microwork themselves for free, but also grant access to their Facebook friends as additional volunteers to magnify their effort. Social microvolunteering lets people volunteer despite temporal, financial, or physical limitations.", "num_citations": "5\n", "authors": ["1183"]}
{"title": "Shared sensemaking: Enhancing the value of collaborative web search tools\n", "abstract": " Current Web search tools, such as browsers and search engine sites, are designed for a single user, working alone. However, users frequently need to collaborate on information-finding tasks; for example, students often work together in groups on homework assignments. To address this need, we have prototyped and evaluated several collaborative web search tools (S3, SearchTogether, and CoSearch) that enable synchronous, asynchronous, colocated, and remote collaboration on Web search tasks. Such tools could be further enhanced by enabling collaborators to transition from shared Web searching to joint sensemaking activities; the products of this sensemaking could in turn be offered to others in response to their queries, enabling a community-level search/sensemaking cycle.", "num_citations": "5\n", "authors": ["1183"]}
{"title": "Virtual information piles for small screen devices\n", "abstract": " We describe an implementation that has users' flick'notes, images, audio, and video files onto virtual piles beyond the display of small-screen devices. This scheme allows PDA users to keep information close at hand without sacrificing valuable screen real estate. Our approach takes advantage of human spatial memory capabilities. It also obviates the need to browse complex folder trees during a working session. The system also allows co-located individuals with PDAs to share and organize information items (eg, photos, text, sound clips, etc.) by placing them in shared, imaginary off-screen piles. We also introduce an extension that allows PDA owners to transfer information piles to and from a shared tabletop display.", "num_citations": "5\n", "authors": ["1183"]}
{"title": "Designing Disaggregated Evaluations of AI Systems: Choices, Considerations, and Tradeoffs\n", "abstract": " Several pieces of work have uncovered performance disparities by conducting \"disaggregated evaluations\" of AI systems. We build on these efforts by focusing on the choices that must be made when designing a disaggregated evaluation, as well as some of the key considerations that underlie these design choices and the tradeoffs between these considerations. We argue that a deeper understanding of the choices, considerations, and tradeoffs involved in designing disaggregated evaluations will better enable researchers, practitioners, and the public to understand the ways in which AI systems may be underperforming for particular groups of people.", "num_citations": "4\n", "authors": ["1183"]}
{"title": "Addressing the Accessibility of Social Media\n", "abstract": " Social media platforms are deeply ingrained in society, and they offer many different spaces for people to engage with others. Unfortunately, accessibility barriers prevent people with disabilities from fully participating in these spaces. Social media users commonly post inaccessible media, including videos without captions (which are important for people who are deaf or hard of hearing) and images without alternative text (descriptions read aloud by screen readers for people who are blind). Users with motor impairments must find workarounds to deal with the complex user interfaces of these platforms, and users with cognitive disabilities may face barriers to composing and sharing information. Accessibility researchers, industry practitioners, and end-users with disabilities will come together to outline challenges and solutions for improving social media accessibility. The workshop starts with a panel of end-users\u00a0\u2026", "num_citations": "4\n", "authors": ["1183"]}
{"title": "Friendsourcing for the greater good: perceptions of social microvolunteering\n", "abstract": " People with disabilities can be reluctant to friendsource help from their own friends for fear of appearing dependent or annoying. Our social microvolunteering approach has volunteers post friendsourcing tasks on behalf of people with disabilities. We demonstrate this approach via a Facebook application that answers visual questions on behalf of blind users.", "num_citations": "4\n", "authors": ["1183"]}
{"title": "Code space: Combining touch, devices, and skeletal tracking to support developer meetings\n", "abstract": " We present Code Space, a system that contributes touch+ air gesture hybrid interactions to support co-located, small group developer meetings by democratizing access, control, and sharing of information across multiple personal devices and public displays. Our system uses a combination of a shared multi-touch screen, mobile touch devices, and Microsoft Kinect sensors. We describe cross-device interactions, which use a combination of in-air pointing for social disclosure of com-mands, targeting and mode setting, combined with touch for command execution and precise gestures. In a formative study, professional developers were positive about the interaction design, and most felt that pointing with hands or devices and forming hand postures are socially acceptable. Users also felt that the techniques adequately disclosed who was interacting and that existing social protocols would help to dictate most\u00a0\u2026", "num_citations": "4\n", "authors": ["1183"]}
{"title": "Collaborative information retrieval\n", "abstract": " The goal of the workshop is to bring together researchers interested in various aspects of small-team collaborative search to share ideas, to stimulate research in the area, and to increase the visibility of this emerging area. We expect to identify promising directions for further exploration and to establish collaborative links among research groups.", "num_citations": "4\n", "authors": ["1183"]}
{"title": "\u201cI Am Iron Man\u201d Priming Improves the Learnability and Memorability of User-Elicited Gestures\n", "abstract": " Priming is used as a way of increasing the diversity of proposals in end-user elicitation studies, but priming has not been investigated thoroughly in this context. We conduct a distributed end-user elicitation study with 167 participants, which had three priming groups: a no-priming control group, sci-fi priming, and a creative mindset group. We evaluated the gestures proposed by these groups in a distributed learnability and memorability study with 18 participants. We found that the user-elicited gestures from the sci-fi group were significantly faster to learn, requiring an average of 1.22 viewings to learn compared to 1.60 viewings required to learn the control gestures, and 1.56 viewings to learn the gestures elicited from the creative mindset group. In addition, both primed gesture groups had higher memorability with 80% of the sci-fi-primed gestures and 73% of the creative mindset group gestures were recalled\u00a0\u2026", "num_citations": "3\n", "authors": ["1183"]}
{"title": "Mobile support for face-to-face social interaction\n", "abstract": " Mobile devices allow people to connect with the rest of the world from anywhere. People can now be reached regardless of where they are. If a child gets injured at a school, for example, their teacher can connect with a parent immediately, even if the parent is not at home or work. People can also access information from anywhere. Before ordering dinner at a new restaurant, a diner can look up the most popular dishes on Yelp right from the table.Ironically, however, while mobile devices connect users with the greater world, they often disengage them from their immediate environment. Individuals are isolated by their mobile devices even when they are surrounded by other people, creating situations in which people are \u201calone together\u201d[14]. In a study of hundreds of enterprise workers, we found that people believe phone use interferes with meeting productivity and collaboration [1]. Mobile devices are so disruptive that we create rules to regulate their use (eg,\u201cNo phones allowed at this meeting!\u201d).", "num_citations": "3\n", "authors": ["1183"]}
{"title": "A Taxonomy of Sounds in Virtual Reality\n", "abstract": " Virtual reality (VR) leverages human sight, hearing and touch senses to convey virtual experiences. For d/Deaf and hard of hearing (DHH) people, information conveyed through sound may not be accessible. To help with future design of accessible VR sound representations for DHH users, this paper contributes a consistent language and structure for representing sounds in VR. Using two studies, we report on the design and evaluation of a novel taxonomy for VR sounds. Study 1 included interviews with 10 VR sound designers to develop our taxonomy along two dimensions: sound source and intent. To evaluate this taxonomy, we conducted another study (Study 2) where eight HCI researchers used our taxonomy to document sounds in 33 VR apps. We found that our taxonomy was able to successfully categorize nearly all sounds (265/267) in these apps. We also uncovered additional insights for designing\u00a0\u2026", "num_citations": "2\n", "authors": ["1183"]}
{"title": "Understanding In-Situ Use of Commonly Available Navigation Technologies by People with Visual Impairments\n", "abstract": " Despite the large body of work in accessibility concerning the design of novel navigation technologies, little is known about commonly available technologies that people with visual impairments currently use for navigation. We address this gap with a qualitative study consisting of interviews with 23 people with visual impairments, ten of whom also participated in a follow-up diary study. We develop the idea of complementarity first introduced by Williams et al.[53] and find that in addition to using apps to complement mobility aids, technologies and apps complemented each other and filled in for the gaps inherent in one another. Furthermore, the complementarity between apps and other apps/aids was primarily the result of the differences in information and modalities in which this information is communicated by apps, technology and mobility aids. We propose design recommendations to enhance this\u00a0\u2026", "num_citations": "2\n", "authors": ["1183"]}
{"title": "Sense and accessibility: Understanding people with physical disabilities\u2019 experiences with sensing systems\n", "abstract": " Sensing technologies that implicitly and explicitly mediate digital experiences are an increasingly pervasive part of daily living; it is vital to ensure that these technologies work appropriately for people with physical disabilities. We conducted on online survey with 40 adults with physical disabilities, gathering open-ended descriptions about respondents\u2019 experiences with a variety of sensing systems, including motion sensors, biometric sensors, speech input, as well as touch and gesture systems. We present findings regarding the many challenges status quo sensing systems present for people with physical disabilities, as well as the ways in which our participants responded to these challenges. We conclude by reflecting on the significance of these findings for defining a future research agenda for creating more inclusive sensing systems.", "num_citations": "2\n", "authors": ["1183"]}
{"title": "Future research directions for accessible social media\n", "abstract": " Social media platforms are deeply ingrained in society, and they offer many different spaces for people to engage with others. Unfortunately, accessibility barriers prevent people with disabilities from fully participating in these spaces. Social media users commonly post inaccessible media, including videos without captions (which are important for people who are Deaf or Hard of Hearing) and images without alternative text (descriptions read aloud by screen readers for people who are blind). Users with motor impairments must find workarounds to deal with the complex user interfaces of these platforms, and users with cognitive disabilities may face barriers to composing and sharing information. We invited accessibility researchers, industry practitioners, and end-users with disabilities to come together at the Computer-Supported Cooperative Work conference (CSCW 2019) to discuss challenges and solutions for\u00a0\u2026", "num_citations": "2\n", "authors": ["1183"]}
{"title": "Facilitating awareness and conversation throughput in an augmentative and alternative communication system\n", "abstract": " Speech generating devices, communication systems, and methods for communicating using the devices and systems are disclosed herein. In certain examples, a communication system is configured to receive a generated communication, establish a connection between a speech generating device and a computing device subsequent to receipt of the generated communication, and transmit the generated communication to the computing device. In other examples, a computing device is configured to establish a connection with a speech generating device, and receive a transmission generated by the speech generating device following the connection, the transmission including previously generated communications or real-time communication segments or proxies. In other examples, a speech generating device is configured to establish a connection with one or more computing devices, receive one or more\u00a0\u2026", "num_citations": "2\n", "authors": ["1183"]}
{"title": "\u201cDoes Anyone Know How to Get Good Answers?\u201d How Social Network Questions Shape Replies\n", "abstract": " Social networking tools make it easy for people to ask questions of large groups of their personal acquaintances. In this article, we explore how the questions people ask of their social networks via status message updates shape the replies they receive. We present the results of a survey of 624 people, in which participants were asked to share the questions they have asked and answered of their online social networks. We observe interesting variations in how people ask natural, real-world questions that suggest that the effectiveness of a question posed to one\u2019s social network could depend on who asks the question, when the question is asked, and how the question is phrased. To understand whether these factors actually do shape question replies, we conducted a controlled study in which 282 participants posted variants of the same question as their status message on Facebook. By analyzing the quantity, quality, and speed of the responses, we find that by controlling the time of day a question is posed and how the question is phrased, and by maintaining a strong network, a person can increase the likelihood of quickly receiving many high-quality answers. ________________________________________________________________________", "num_citations": "2\n", "authors": ["1183"]}
{"title": "Multi-user piles across space\n", "abstract": " We introduce Multi-User Piles Across Space, a technique that allows co-located individuals with PDAs to share and organize information items (e.g., photos, text, sound clips, etc.) by placing these items in shared, imaginary off-screen piles. This technique relies on human capacities to remember spatial layouts, and allows small co-located groups with limited screen real estate to collaboratively manage information. Each participant can use their PDA's stylus to flick information to shared off-screen piles and view their contents.  Connections are implemented through ad hoc WiFi. Optimistic concurrency control provides long term data consistency. We also describe an extension that allows PDA owners to transfer information items and piles to and from a tabletop display.", "num_citations": "2\n", "authors": ["1183"]}
{"title": "Use Cases and Impact of Audio-Based Virtual Exploration\n", "abstract": " Audio-based virtual navigation experiences present an opportunity for people who are blind or have low vision to increase their familiarity with an area before traveling. Such experiences could also increase people\u2019s excitement and confidence in exploring places. As a preliminary investigation, we developed the Audio-based Virtual Exploration (AVE) app. In a user study with 14 people who were blind or had low vision, we explored use cases of virtual navigation, how app features could support those uses, and how the experience could impact mental maps and interest", "num_citations": "2\n", "authors": ["1183"]}
{"title": "Designing Tools for High-Quality Alt Text Authoring\n", "abstract": " Alternative (alt) text provides access to descriptions of digital images for people who use screen readers. While prior work studied screen reader users\u2019(SRUs\u2019) preferences about alt text and automatic alt text (ie, alt text generated by artificial intelligence), little work examined the alt text author\u2019s experience composing or editing these descriptions. We built two types of prototype interfaces for two tasks: authoring alt text and providing feedback on automatic alt text. Through combined interview-usability testing sessions with alt text authors and interviews with SRUs, we tested the effectiveness of our prototypes in the context of Microsoft PowerPoint. Our results suggest that authoring interfaces that support authors in choosing what to include in their descriptions result in higher quality alt text. The feedback interfaces highlighted considerable differences in the perceptions of authors and SRUs regarding \u201chigh-quality\u201d alt\u00a0\u2026", "num_citations": "1\n", "authors": ["1183"]}
{"title": "Understanding the Representation and Representativeness of Age in AI Data Sets\n", "abstract": " A diverse representation of different demographic groups in AI training data sets is important in ensuring that the models will work for a large range of users. To this end, recent efforts in AI fairness and inclusion have advocated for creating AI data sets that are well-balanced across race, gender, socioeconomic status, and disability status. In this paper, we contribute to this line of work by focusing on the representation of age by asking whether older adults are represented proportionally to the population at large in AI data sets. We examine publicly-available information about 92 face data sets to understand how they codify age as a case study to investigate how the subjects' ages are recorded and whether older generations are represented. We find that older adults are very under-represented; five data sets in the study that explicitly documented the closed age intervals of their subjects included older adults (defined as older than 65 years), while only one included oldest-old adults (defined as older than 85 years). Additionally, we find that only 24 of the data sets include any age-related information in their documentation or metadata, and that there is no consistent method followed across these data sets to collect and record the subjects' ages. We recognize the unique difficulties in creating representative data sets in terms of age, but raise it as an important dimension that researchers and engineers interested in inclusive AI should consider.", "num_citations": "1\n", "authors": ["1183"]}
{"title": "Dueto: accessible, gaze-operated musical expression\n", "abstract": " Gaze-tracking technologies can enable computer access for users who are unable to use standard input devices. However, using gaze as input poses challenges for interactions that require visual planning, like playing a digital instrument. We explore how multimodality can support eye-controlled musical expression by designing different multi-modal gaze interactions around a digital instrument we call Dueto. We tackle three design goals: creating an instrument that is explorable, easy to learn, and allows feature controllability. We showcase three different multimodal interactions for music playing such as eye gaze only, gaze+ switch, and gaze+ partner mode.", "num_citations": "1\n", "authors": ["1183"]}
{"title": "Demonstration of SeeingVR: a set of tools to make virtual reality more accessible to people with low vision\n", "abstract": " Current virtual reality applications do not support people who have low vision. We present SeeingVR, a set of 14 tools that enhance a VR app for people with low vision by providing visual and audio augmentations. A user can select, adjust, and combine different tools based on their preferences. We demonstrate the design of SeeingVR in this paper.", "num_citations": "1\n", "authors": ["1183"]}
{"title": "Presenting ranked search results based on accessibility scores\n", "abstract": " An example system for presenting search results includes a computer memory and a processor. The processor is to receive a set of search results in response to a query. The processor is to extract a feature and text from each of the search results. The processor is to also calculate an accessibility score for each of the search results based on the extracted feature and the text. The processor is to further rank the set of search results based on the accessibility score. The processor is to also further present the ranked search results based on an accessibility score of a user.", "num_citations": "1\n", "authors": ["1183"]}
{"title": "Immersive telepresence\n", "abstract": " In general, the immersive telepresence implementations described herein allow desired telepresence experiences of users or telepresence travel participants to be automatically matched with travel volunteers that can provide these telepresence experiences. The mobile computing devices of the travel volunteers provide audio, video and other data to the travel participant so that the travel participant can experience the sights and sounds of a desired telepresence experience (which can include location and time, as well as a desired activity) without the travel participant physically being present. The immersive telepresence implementations described herein automatically find matches between telepresence experiences on a list (eg, bucket list) of a travel participant and one or more travel volunteers and provide for various features to provide an immersive and personalized telepresence experience for the travel\u00a0\u2026", "num_citations": "1\n", "authors": ["1183"]}
{"title": "Understanding and Supporting Sensemaking in Collaborative Web Search\n", "abstract": " While there has been some research on sensemaking in individual information seeking, there is little understanding of sensemaking in collaborative information seeking tasks, such as collaborative Web search. We conducted a study of users\u2019 sensemaking in collaborative Web search tasks performed using SearchTogether. Based on findings of this study, we designed, implemented, and evaluated a tool, CoSense, to enhance sensemaking for collaborative search tasks. The results of our evaluation of CoSense provide insight into how people collaboratively make sense of information and what design features can help them.", "num_citations": "1\n", "authors": ["1183"]}
{"title": "Collaborative Information Seeking\n", "abstract": " Pascal 001 Exact sciences and technology/001A Sciences and techniques of general use/001A01 Information science. Documentation/001A01A Library and information science. General aspects/001A01A05 Use and user studies. Information needsPascal 001 Exact sciences and technology/001A Sciences and techniques of general use/001A01 Information science. Documentation/001A01E Information processing and retrieval/001A01E03 Information retrieval. Man machine relationship/001A01E03C Research process. Evaluation", "num_citations": "1\n", "authors": ["1183"]}
{"title": "Web\n", "abstract": " Abstract not available.", "num_citations": "1\n", "authors": ["1183"]}