{"title": "Relational concept analysis: mining concept lattices from multi-relational data\n", "abstract": " The processing of complex data is admittedly among the major concerns of knowledge discovery from data (kdd). Indeed, a major part of the data worth analyzing is stored in relational databases and, since recently, on the Web of Data. This clearly underscores the need for Entity-Relationship and rdf compliant data mining (dm) tools. We are studying an approach to the underlying multi-relational data mining (mrdm) problem, which relies on formal concept analysis (fca) as a framework for clustering and classification. Our relational concept analysis (rca) extends fca to the processing of multi-relational datasets, i.e., with multiple sorts of individuals, each provided with its own set of attributes, and relationships among those. Given such a dataset, rca constructs a set of concept lattices, one per object sort, through an iterative analysis process that is bound towards a fixed-point. In doing that, it abstracts the links\u00a0\u2026", "num_citations": "164\n", "authors": ["791"]}
{"title": "Metamodel matching for automatic model transformation generation\n", "abstract": " Applying Model-Driven Engineering (MDE) leads to the creation of a large number of metamodels, since MDE recommends an intensive use of models defined by metamodels. Metamodels with similar objectives are then inescapably created. A recurrent issue is thus to turn compatible models conforming to similar metamodels, for example to use them in the same tool. The issue is classically solved developing ad hoc model transformations. In this paper, we propose an approach that automatically detects mappings between two metamodels and uses them to generate an alignment between those metamodels. This alignment needs to be manually checked and can then be used to generate a model transformation. Our approach is built on the Similarity Flooding algorithm used in the fields of schema matching and ontology alignment. Experimental results comparing the effectiveness of the application of\u00a0\u2026", "num_citations": "134\n", "authors": ["791"]}
{"title": "Relational concept discovery in structured datasets\n", "abstract": " Relational datasets, i.e., datasets in which individuals are described both by their own features and by their relations to other individuals, arise from various sources such as databases, both relational and object-oriented, knowledge bases, or software models, e.g., UML class diagrams. When processing such complex datasets, it is of prime importance for an analysis tool to hold as much as possible to the initial format so that the semantics is preserved and the interpretation of the final results eased. Therefore, several attempts have been made to introduce relations into the formal concept analysis field which otherwise generated a large number of knowledge discovery methods and tools. However, the proposed approaches invariably look at relations as an intra-concept construct, typically relating two parts of the concept description, and therefore can only lead to the discovery of coarse-grained patterns. As\u00a0\u2026", "num_citations": "128\n", "authors": ["791"]}
{"title": "Towards a traceability framework for model transformations in kermeta\n", "abstract": " Implementing a model transformation is a very complex task and in an MDA process, chains of model transformations are usually built. When writing such a transformation chain, developers often need to have information on the previously applied transformations. Thus, disposing of a traceability framework enabling to gather information on the transformation behavior is an important feature for a transformation language. In this paper, we propose to implement a traceability framework in the Kermeta language based on a language independent trace metamodel.", "num_citations": "110\n", "authors": ["791"]}
{"title": "A proposal for combining formal concept analysis and description logics for mining relational data\n", "abstract": " Recent advances in data and knowledge engineering have emphasized the need for formal concept analysis (fca) tools taking into account structured data. There are a few adaptations of the classical fca methodology for handling contexts holding on complex data formats, e.g. graph-based or relational data. In this paper, relational concept analysis (rca) is proposed, as an adaptation of fca for analyzing objects described both by binary and relational attributes. The rca process takes as input a collection of contexts and of inter-context relations, and yields a set of lattices, one per context, whose concepts are linked by relations. Moreover, a way of representing the concepts and relations extracted with rca is proposed in the framework of a description logic. The rca process has been implemented within the Galicia platform, offering new and efficient tools for knowledge and software engineering.", "num_citations": "101\n", "authors": ["791"]}
{"title": "On automatic class insertion with overloading\n", "abstract": " Several algorithms [Cas92, MS89, Run92, DDHL94a, DDHL95, GMM95] have been proposed to automatically insert a class into an inheritance hierarchy. But actual hierarchies all include overriden and overloaded properties that these algorithms handle either very partially or not at all. Partially handled means handled provided there is a separate given function f able to compare overloaded properties [DDHL95, GMM95].In this paper, we describe a new version of our algorithm (named Ares) which handles automatic class insertion more efficiently using such a function f. Although impossible to fully define, this function can be computed for a number of well defined cases of overloading and overriding. We give a classification of such cases and describe the computation process for a well-defined set of nontrivial cases.The algorithm preserves these important properties:- preservation of the maximal factorization of\u00a0\u2026", "num_citations": "89\n", "authors": ["791"]}
{"title": "Automatic extraction of a wordnet-like identifier network from software\n", "abstract": " A large part of the time allocated to software maintenance is dedicated to the program comprehension. Many approaches that uses the program structure or the external documentation have been created to assist program comprehension. However, the identifiers of the program are an important source of information that is still not widely used for this purpose. In this article, we propose an approach, based upon Natural Language Processing techniques, that automatically extracts and organizes concepts from software identifiers in a WordNet-like structure that we call lexical views. These lexical views give useful insight on an overall software architecture and can be used to improve results of many software engineering tasks. The proposal is evaluated against a corpus of 24 open source programs.", "num_citations": "70\n", "authors": ["791"]}
{"title": "Monotonic conflict resolution mechanisms for inheritance\n", "abstract": " The main topic of this paper is multiple inheritance and conflict resolution methods in Object Oriented Programming. Our aim is to develop sound mechanisms easily understandable to any user. For this purpose, coherent behaviors of conflict resolution methods for multiple inheritance (such as supporting incrementality-monotonicity and stability under link subdivision) are introduced. We present interesting examples in which multiple inheritance known linearization algorithms (such as in CLOS [2] and LOOPS [19]) behave badly. Then we carefully study the conditions (on the inheritance graph) which assure good linearizations. We end with some suggestions for an incremental inheritance algorithm.", "num_citations": "68\n", "authors": ["791"]}
{"title": "Galois lattice as a framework to specify building class hierarchies algorithms\n", "abstract": " In the context of object-oriented systems, algorithms for building class       hierarchies are currently receiving much attention. We present here a characterization of several global       algorithms.       A global algorithm is one which starts with only the set of classes (provided with all their properties) and directly builds       the hierarchy.       The algorithms scrutinized were developped each in a different framework.       In this survey, they are explained in a single framework, which takes       advantage of a substructure of the Galois lattice associated with the binary relation       mapping the classes to their properties.       Their characterization allows to figure the results of the algorithms without running       them in simple cases.       This study once again highlights the Galois lattice as a main and intuitive model for       class hierarchies.", "num_citations": "63\n", "authors": ["791"]}
{"title": "Proposal for a monotonic multiple inheritance linearization\n", "abstract": " Previous studies concerning multiple inheritance convinced us that a better analysis of conflict resolution mechanisms was necessary. In [DHHM92], we stated properties that a sound mechanism has to respect. Among them, a monotonicity principle plays a critical role, ensuring that the inheritance mechanism behaves \u201cnaturally\u201d relative to the incremental design of the inheritance hierarchy. We focus here on linearizations and present an intrinsically monotonic linearization, whereas currently used linearizations are not. This paper describes the algorithm in detail, explains the design choices, and compares it to other linearizations, with LOOPS and CLOS taken as references. In particular, this new linearization extends CLOS and LOOPS linearizations, producing the same results when these linearizations are sound.", "num_citations": "61\n", "authors": ["791"]}
{"title": "Improving Generalization Level in UML Models Iterative Cross Generalization in Practice\n", "abstract": " FCA has been successfully applied to software engineering tasks such as source code analysis and class hierarchy re-organization. Most notably, FCA puts mathematics behind the mechanism of abstracting from a set of concrete software artifacts. A key limitation of current FCA-based methods is the lack of support for relational information (e.g., associations between classes of a hierarchy): the focus is exclusively on artifact properties whereas inter-artifact relationships may encode crucial information. Consequently, feeding-in relations into the abstraction process may substantially improve its precision and thus open the access to qualitatively new generalizations. In this paper, we elaborate on ICG, an FCA-based methodology for extracting generic parts out of software models that are described as UML class diagrams. The components of ICG are located within the wider map of an FCA framework for\u00a0\u2026", "num_citations": "52\n", "authors": ["791"]}
{"title": "Le point sur l'h\u00e9ritage multiple\n", "abstract": " Sauf mention contraire ci-dessus, le contenu de cette notice bibliographique peut \u00eatre utilis\u00e9 dans le cadre d\u2019une licence CC BY 4.0 Inist-CNRS/Unless otherwise stated above, the content of this bibliographic record may be used under a CC BY 4.0 licence by Inist-CNRS/A menos que se haya se\u00f1alado antes, el contenido de este registro bibliogr\u00e1fico puede ser utilizado al amparo de una licencia CC BY 4.0 Inist-CNRS", "num_citations": "52\n", "authors": ["791"]}
{"title": "Foundations of a simple and unified component-oriented language\n", "abstract": " Component-oriented programming (COP) is actually a key research track in software engineering. A variety of component-oriented languages (COLs) have been proposed with new or adapted abstractions and mechanisms to support this new paradigm. However, the proposed features vary quite widely from one proposal to another. There is a need for a closer analysis and synthesis of these features to really discover the new possibilities of COP. In this article we present SCL, our proposition of simple language dedicated to COP. Through the presentation of SCL, we discuss and compare the main features of COLs such as component class, component, interface, port, service or connector. But these features are not enough to build a COL. Indeed, unanticipated connection of independently developed components is one of the key issues of COP. Most approaches use language primitives or connectors and shared\u00a0\u2026", "num_citations": "46\n", "authors": ["791"]}
{"title": "Performances of galois sub-hierarchy-building algorithms\n", "abstract": " Abstract The Galois Sub-hierarchy (GSH) is a polynomial-size representation of a concept lattice which has been applied to several fields, such as software engineering and linguistics. In this paper, we analyze the performances, in terms of computation time, of three GSH-building algorithms with very different algorithmic strategies: Ares, Ceres and Pluton. We use Java and C++ as implementation languages and Galicia as our development platform. Our results show that implementations in C++ are significantly faster, and that in most cases Pluton is the best algorithm.", "num_citations": "42\n", "authors": ["791"]}
{"title": "Computing interfaces in java\n", "abstract": " Investigates the separation between types and classes by putting to use a special feature of Java regarding classes, interfaces and inheritance. We propose an original method which, from a single inheritance class hierarchy, extracts a multiple inheritance interface hierarchy, which contains all the types of the original hierarchy, each class being linked to the interface representing its type. In the resulting structure, interfaces are well-organized and follow a natural multiple specialization, which would not have been possible using only the single inheritance which comes with Java. Our method is based on the use of a Galois lattice, which is a reference for the elaboration of hierarchies. We introduce and justify the need for a new algorithm that efficiently builds an essential part of the Galois lattice.", "num_citations": "40\n", "authors": ["791"]}