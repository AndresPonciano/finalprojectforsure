{"title": "Software unit test coverage and adequacy\n", "abstract": " Objective measurement of test quality is one of the key issues in software testing. It has been a major research focus for the last two decades. Many test criteria have been proposed and studied for this purpose. Various kinds of rationales have been presented in support of one criterion or another. We survey the research work in this area. The notion of adequacy criteria is examined together with its role in software dynamic testing. A review of criteria classification is followed by a summary of the methods for comparison and assessment of criteria.", "num_citations": "1696\n", "authors": ["473"]}
{"title": "Estimating bounds on the reliability of diverse systems\n", "abstract": " We address the difficult problem of estimating the reliability of multiple-version software. The central issue is the degree of statistical dependence between failures of diverse versions. Previously published models of failure dependence described what behavior could be expected \"on average\" from a pair of \"independently generated\" versions. We focus instead on predictions using specific information about a given pair of versions. The concept of \"variation of difficulty\" between situations to which software may be subject is central to the previous models cited, and it turns out to be central for our question as well. We provide new understanding of various alternative imprecise estimates of system reliability and some results of practical use, especially with diverse systems assembled from pre-existing (e.g., \"off-the-shelf\") subsystems. System designers, users, and regulators need useful bounds on the probability of\u00a0\u2026", "num_citations": "59\n", "authors": ["473"]}
{"title": "Reliability estimation from appropriate testing of plant protection software\n", "abstract": " Plant protection software may be realistically tested using inputs from a plant model before its initial use, or when it is not feasible to take the plant into certain fault conditions. If statistical estimation of software reliability is to be performed using the test results, it is not sufficient for the plant model to produce inputs which are simply correct in the sense that the plant could have produced them. In addition, the operational distribution of the input space must be simulated. The paper illustrates how to perform such a simulation, by developing an example in which an existing non-random plant model is randomised to simulate the operational distribution of the software. In addition, two methods of estimating the probability of failure on demand (pfd) for a program are reported. Both methods estimate a pfd given results from dynamic testing, during which the program is exercised according to its operational distribution. The\u00a0\u2026", "num_citations": "59\n", "authors": ["473"]}
{"title": "Building a system failure rate estimator by identifying component failure rates\n", "abstract": " Following the current trend towards the increased use of commercial off-the-shelf (COTS) components in safety-critical systems, the need arises to address safety issues related to COTS-based systems. In this paper, we introduce a hierarchical model to estimate the probability of failure, on demand, of a software system consisting of components. Thereby, available evidence on the components' failure behaviour is combined using a Bayesian approach. An additive error term is proposed to model the changes in a component's prior reliability once the component is transferred from the operational environment assumed by the software developer into the actual operating environment. Statistical system test data are incorporated to calculate the estimator of the system failure rate. This approach involves prior knowledge at the level where it is most likely to be available: the component level.", "num_citations": "41\n", "authors": ["473"]}
{"title": "Incident analysis & digital forensics in SCADA and industrial control systems\n", "abstract": " SCADA and industrial control systems have been traditionally isolated in physically protected environments. However, developments such as standardisation of data exchange protocols and increased use of IP, emerging wireless sensor networks and machine-to-machine communication mean that in the near future related threat vectors will require consideration too outside the scope of traditional SCADA security and incident response. In the light of the significance of SCADA for the resilience of critical infrastructures and the related targeted incidents against them (e.g. the development of stuxnet), cyber security and digital forensics emerge as priority areas. In this paper we focus on the latter, exploring the current capability of SCADA operators to analyse security incidents and develop situational awareness based on a robust digital evidence perspective. We look at the logging capabilities of a typical SCADA\u00a0\u2026", "num_citations": "36\n", "authors": ["473"]}
{"title": "Inductive inference and software testing\n", "abstract": " The term \u2018inductive inference\u2019 denotes the process of hypothesizing a general rule from examples. It can be considered as the inverse process of program testing, which is a process of sampling the behaviour of a program and gathering confidence in the quality of the software from the samples. As one of the fundamental and ubiquitous components of intelligent behaviour, much effort has been spent on both the theory and practice of inductive inference as a branch of artificial intelligence. In this paper, software testing and inductive inference are reviewed to illustrate how the rich and solid theory of inductive inference can be used to study the foundations of software testing.", "num_citations": "26\n", "authors": ["473"]}
{"title": "A study of the precursors leading to \u2018organisational\u2019accidents in complex industrial settings\n", "abstract": " This study aggregates the narrative findings from the investigation of 12 accidents or \u2018near hits\u2019 across a wide range of industrial settings to build a catalogue of organisational and cultural precursors to accidents. It was found that many were important factors in multiple events. It is argued that by addressing these potential vulnerabilities using the findings and proposed tools based upon them, organisations undertaking safety related activities will not only develop greater awareness of these deeper-lying issues but should be able to better control the risks associated with them.The precursors have been classified under eight headings and examples of key findings from three of these are presented. Statements providing potential defences against the identified vulnerabilities have been developed which should enable organisations to scrutinise the adequacy of existing expectations or requirements within their\u00a0\u2026", "num_citations": "20\n", "authors": ["473"]}
{"title": "Component-Based software reliability analysis\n", "abstract": " New reliability models are derived to describe how test-based software reliability estimates depend on the component structure of code. The models can analyze dependent component failures. Models of this type are important for two main reasons. Firstly, they provide a quality model for software development based on component reuse. For simple software architectures, it is shown that it is feasible to re-use evidence of a component\u2019s reliability from previous testing/usage in a different system. This technique has potential to provide extremely efficient software verification.Secondly, the new models provide a meaning for \u2018reliable software design,\u2019making it possible to identify software designs whose reliability can be demonstrated. Traditionally, the complexity of a computation is measured in terms of the number of elemental computations used. In contrast, a statistical complexity measure is proposed to describe complexity in terms of statistical software testability. A highly complex program requires intense testing in order to justify a claim that the program achieves a given level of reliability. A low complexity program requires less testing to achieve the same claim.", "num_citations": "18\n", "authors": ["473"]}
{"title": "A model of code sharing for estimating software failure on demand probabilities\n", "abstract": " A statistical software testing model is proposed in which white box factors have a role. The model combines test adequacy notions with statistical analysis, and in so doing provides a rudimentary treatment of dependencies between test results caused by the execution of common code during the tests. The model is used to estimate the probability of failure on demand for software performing safety shutdown functions on large plants and concerns the case where extensive test results are available on the latest version of the software, none of which have resulted in software failure. According to the model, there are circumstances in which some current statistical models for dynamic software testing are too conservative, and others are not conservative, depending on the software architecture.< >", "num_citations": "17\n", "authors": ["473"]}
{"title": "A discussion of statistical testing on a safety-related application\n", "abstract": " Safety-critical and safety-related systems are increasingly based, at least partially, on the use of software or logic components. High integrity claims are usually placed on these systems, which means that their probability of failure during operation should be below a specified level in order to ensure that risk of operation is sufficiently low. All this implies that some knowledge needs to be gained on the dependability of these systems or components in actual field use. Dependability assessment methods for software are not as well established as for hardware. Currently, formal proofs and statistical testing methods provide the only methods that have the potential to assess software dependability quantitatively. The present paper explores the applicability of statistical (software) testing (ST) to the example of a real safety-related software application. It discusses the key points arising in this task and highlights the unique\u00a0\u2026", "num_citations": "15\n", "authors": ["473"]}
{"title": "The effectiveness of statistical testing when applied to logic systems\n", "abstract": " In this paper we demonstrate the effectiveness of statistical testing for error detection on the example of a Programmable Logic System (PLS). Statistical testing was introduced into this project as a complementary testing technique with the potential to quantify system reliability, after a variety of acceptance tests had been performed. An appropriate statistical testing algorithm was devised and implemented, which is described in detail in this paper. We compare the results of statistical testing with those of a variety of other testing methods employed on the PLS. In terms of differences detected per number of tests, statistical testing showed an outstanding effectiveness. Furthermore, it detected a problem, which was missed by all other testing techniques. This together with its potential for reliability quantification illustrates its importance for system validation as part of a risk-based safety-case.", "num_citations": "15\n", "authors": ["473"]}
{"title": "Test-adequacy and statistical testing: combining different properties of a test-set\n", "abstract": " Dependability assessment of safety-critical or safety-related software components is an important issue for example within the nuclear industry, the avionics sector or the military. Statistical testing is one way of quantifying the dependability of a given software product. The use of sector-specific standards with their suggested test-criteria is another (nonquantitative) way of aiming at employing only components that are \"dependable enough\". Ideally, both, the acknowledged test criteria and statistical test methods should come into play when assessing software dependability. We want to - in the long-term - move towards this aim. Thus we investigate in this paper a model to combine the fault-detection power of a given test-set (a test-adequacy criterion) with the statistical power of the test-set, i.e. the number of statistical tests within the test-set. With this model we aim at drawing out of any given test-set - whether devised\u00a0\u2026", "num_citations": "14\n", "authors": ["473"]}
{"title": "Structural software reliability estimation\n", "abstract": " Structure is introduced to the process of software reliability estimation. An estimator for the overall software failure rate is constructed using estimators of subtask\u2014failure rates. This is done for the case when testing reveals no failure. The obtained estimator depends on the number of subtasks present in the code and on the code structure. The model proposed covers sequential and simple branching structures.", "num_citations": "12\n", "authors": ["473"]}
{"title": "New statistics for demand-based software testing\n", "abstract": " Current statistical failure probability estimators for software are based on failure probability models which are too simple to be generally applicable. New failure probability models are required which account for the complexities of software structure, or at least allow the significance of such complexities to be understood since it may be the case that current models are sufficient in some circumstances \u2014 this question is open. An example of such a new failure probability model is developed for a simple program structure, and shows how current models can lead to inadequate failure probability estimation.", "num_citations": "12\n", "authors": ["473"]}
{"title": "Integrity prediction during software development\n", "abstract": " A new approach to software development integrity prediction is proposed. The approach is intended to form the basis for a software tool to help project managers assess the quality of completed software development work. Integrities for intermediate products in the development lifecycle are predicted from measurements of integrity-related attributes of the development process and products. The software development lifecycle is modelled as sequences of atomic processes. The analysis only considers development stages after requirements capture and prior to code testing. Atomic processes are considered to comprise of design problems followed by design reviews. The same set of integrity-related attributes are associated with each atomic process. Differences between the atomic processes are modelled by the measured values for the attributes.Integrity for a product of a development stage S is determined from\u00a0\u2026", "num_citations": "12\n", "authors": ["473"]}
{"title": "Using influence diagrams to aid the management of software change\n", "abstract": " In a large software management programme, the number of software changes and enhancements requested for inclusion in the next software release often far exceeds the implementation resources available. Thus, during the preceding months before the final decision is made on which changes to include, there needs to be a way of incorporating all the different factors that influence these possible changes into a coherent set of information to enable good decisions to be made. This paper describes the use of influence diagrams to implement a risk model to formalise the combining of these different factors to aid the decision process. This model not only reflects the likelihood of all the necessary criteria for a requested change to be viable being met, but also considers the financial or other benefits to the organisation that would result from the change being included in the next software release.", "num_citations": "10\n", "authors": ["473"]}
{"title": "Test statistics for system design failure\n", "abstract": " A structural model for the estimation of software failure rates is proposed which is based on a partition of the code into components. Systematic failure is assumed to be induced by the interaction of these components. A Bayesian inference scheme is used to perform failure rate estimation on the basis of N failure free test runs. The approach splits the problem of constructing a system prior up into the smaller, conceivably simpler problems of constructing subtask priors. Thereby a wider range of prior information is used in the process of assessing system safety. The work in this paper constitutes a first step towards a formal statistical understanding of the relationship between system complexity and system testing for reliability. Long-term implications are the achievement of more informative reliability estimates and guidelines on cost-effective testing.", "num_citations": "10\n", "authors": ["473"]}
{"title": "Understanding software test adequacy-an axiomatic and measurement theory approach\n", "abstract": " Understanding software test adequacy- an axiomatic and measurement theory approach \u2014 University of Bristol Skip to main navigation Skip to search Skip to main content University of Bristol Logo Help & Terms of Use Home Profiles Research Units Research Outputs Projects Student theses Datasets Activities Prizes Facilities/Equipment Search by expertise, name or affiliation Understanding software test adequacy- an axiomatic and measurement theory approach H Zhu, P Hall, JHR May Department of Civil Engineering Systems Centre Research output: Chapter in Book/Report/Conference proceeding \u203a Conference Contribution (Conference Proceeding) Overview Translated title of the contribution Understanding software test adequacy- an axiomatic and measurement theory approach Original language English Title of host publication Mathematics of Dependable Systems Conference, Royal Holloway, University of \u2026", "num_citations": "10\n", "authors": ["473"]}
{"title": "Coping after a big nuclear accident\n", "abstract": " This is the author accepted manuscript (AAM). The final published version (version of record) is available online via Elsevier at https://www. sciencedirect. com/science/article/pii/S0957582017303166. Please refer to any applicable terms of use of the publisher.", "num_citations": "8\n", "authors": ["473"]}
{"title": "Cultural and organizational factors leading to major events\n", "abstract": " Cultural and Organizational Factors Leading to Major Events \u2014 University of Bristol Skip to main navigation Skip to search Skip to main content University of Bristol Logo Help & Terms of Use Home Profiles Research Units Research Outputs Projects Student theses Datasets Activities Prizes Facilities/Equipment Search by expertise, name or affiliation Cultural and Organizational Factors Leading to Major Events L van Wijk, RH Taylor, JHR May Department of Civil Engineering Systems Centre Research output: Chapter in Book/Report/Conference proceeding \u203a Conference Contribution (Conference Proceeding) Overview Translated title of the contribution Cultural and Organizational Factors Leading to Major Events Original language English Title of host publication Proceedings International Topical Meeting on Safety of Nuclear Installations(TOPSAFE) Publication status Published - Oct 2008 Bibliographical note Name : \u2026", "num_citations": "8\n", "authors": ["473"]}
{"title": "Fault analysis of the software generation process-The FASGEP project\n", "abstract": " Fault analysis of the software generation process-The FASGEP project \u2014 University of Bristol Skip to main navigation Skip to search Skip to main content University of Bristol Logo Help & Terms of Use Home Profiles Research Units Research Outputs Projects Student theses Datasets Activities Prizes Facilities/Equipment Search by expertise, name or affiliation Fault analysis of the software generation process-The FASGEP project M Cottam, JHR May, al et Department of Civil Engineering Systems Centre Research output: Chapter in Book/Report/Conference proceeding \u203a Conference Contribution (Conference Proceeding) Overview Translated title of the contribution Fault analysis of the software generation process-The FASGEP project Original language English Title of host publication Safety and Reliability Society Symposium: Risk Management and Critical Protective Systems Publication status Published - Oct 1994 .\u2026", "num_citations": "8\n", "authors": ["473"]}
{"title": "Human Error in the Software Generation Process\n", "abstract": " In this paper we discuss how faults are introduced into the software generation process. The Fault Analysis of the Software Generation Process (FASGEP) project has classified faults into Random and Symptomatic. Symptomatic faults are those faults where the input to the process was correct; but the output from the process was incorrect due to an error in the process. Random faults are those faults for which no specific cause for the fault can be identified, This paper discusses the nature of random faults and to what extent they can be attributed to human error.           Software process decomposition shows that the human engineering process can be described as a combination of intellectual (novel) processes and more mechanistic processes. The mechanistic processes, e.g. the use of tools, can be considered to be a specific form of humancomputer interaction via a particular human-machine interface\u00a0\u2026", "num_citations": "8\n", "authors": ["473"]}
{"title": "Efficient modeling of correlated shadow fading in dense wireless multi-hop networks\n", "abstract": " Correlated shadow fading has a detrimental effect on the performance of wireless systems. Neglecting shadowing correlations could lead to inaccurate simulation results and unreliable wireless system design. In this paper, we propose and analyze a correlated shadow fading model based on Gaussian random fields. The model enables the generation of spatially correlated shadow fading for all meshed links in wireless multi-hop networks. Both analytical and numerical results show that the proposed model is in good agreement with the literature in terms of the statistical properties and correlation coefficients. Furthermore, the Circulant Embedding method of the proposed simulation model significantly reduces the computational cost.", "num_citations": "7\n", "authors": ["473"]}
{"title": "Gaining confidence in the software development process using expert systems\n", "abstract": " Software safety standards recommend techniques to use throughout the software development lifecycle. These recommendations are a result of consensus building amongst software safety experts. Thus the reasoning underpinning compliance to these standards tends to be quite subjective. In addition, there are factors such as the size of the project, the effect of a review process on earlier phases of the development lifecycle, the complexity of the design and the quality of the staff, that arguably influence the assessment process but are not formally addressed by software safety standards. In this paper we present an expert system based on Bayesian Belief networks that take into account these and other factors when assessing the integrity at which the software was developed. This system has been reviewed by engineers working with software safety standard IEC61508. In this paper we illustrate some\u00a0\u2026", "num_citations": "7\n", "authors": ["473"]}
{"title": "Assessment of the benefit of redundant systems\n", "abstract": " The evaluation of the gain in reliability of mult-iversion software is one of the key issues in the safety assessment of high integrity systems. Fault simulation has been proposed as a practical method to estimate diversity of multi-version software. This paper applies data-flow perturbation as an implementation of the fault injection technique to evaluate redundant systems under various conditions. A protection system is used as an example to illustrate the evaluation of software structural diversity, optimal selection of channel- pairs and the assessment of different designs.", "num_citations": "7\n", "authors": ["473"]}
{"title": "A face centered cubic key agreement mechanism for mobile ad hoc networks\n", "abstract": " Mobile ad hoc networking is an operating mode for rapid mobile node networking. Each node relies on adjacent nodes in order to achieve and maintain connectivity and functionality. Security is considered among the main issues for the successful deployment of mobile ad hoc networks (MANETs). In this paper we introduce a weak to strong authentication mechanism associated with a multiparty contributory key establishment method. The latter is designed for MANETs with dynamic changing topologies, due to continuous flow of incoming and departing nodes. We introduce a new cube algorithm based on the face-centered cubic (FCC) structure. The proposed architecture employs elliptic curve cryptography, which is considered more efficient for thin clients where processing power and energy consumption are significant constraints.", "num_citations": "6\n", "authors": ["473"]}
{"title": "Safety critical software process improvement by multi-objective optimization algorithms\n", "abstract": " One of the main concerns in safety critical software development is to identify a path through the software development lifecycle that will allow the software artefact to meet the target safety integrity level (SIL) at an acceptable cost. In our previous work we modelled aspects of the software development process recommended by IEC61508-3 software safety standard. In general, there are a number of paths that one can follow in order to comply with a target SIL. The path that one chooses to follow will undoubtedly effect the costs of the software development. In this paper we study a series of optimization algorithms that can be used to improve the software development process by optimization of two objectives, development costs and confidence in claimable integrity. Our analyses show that the non-dominated sorting genetic algorithm (NSGA) is the best performing algorithm in the search for these optimal\u00a0\u2026", "num_citations": "6\n", "authors": ["473"]}
{"title": "Testing the reliability of component-based safety critical software\n", "abstract": " Testing the Reliability of Component-Based Safety Critical Software \u2014 University of Bristol Skip to main navigation Skip to search Skip to main content University of Bristol Logo Help & Terms of Use Home Profiles Research Units Research Outputs Projects Student theses Datasets Activities Prizes Facilities/Equipment Search by expertise, name or affiliation Testing the Reliability of Component-Based Safety Critical Software JHR May Department of Civil Engineering Department of Computer Science Systems Centre Research output: Chapter in Book/Report/Conference proceeding \u203a Conference Contribution (Conference Proceeding) Overview Translated title of the contribution Testing the Reliability of Component-Based Safety Critical Software Original language English Title of host publication Proceeding 20th International System Safety Conference, Denver, August Publisher System Safety Society, PO Box 70, , , - (, \u2026", "num_citations": "6\n", "authors": ["473"]}
{"title": "Fault Simulating to validate fault-tolerance in Ada\n", "abstract": " Software engineering has concentrated on provision of programming language features to support error trapping. Whilst useful, this represents only a small part of the problem of building effective diagnostics for fault tolerance. Effectiveness depends on many things such as the various possible distributions of error traps throughout the hierarchical code structure, certain properties of the language, and the frequency of different fault classes in practice. To choose between schemes it is necessary to estimate their effectiveness. Fault injection is one possible measurement technique. The issues are discussed in the context of the Ada language.", "num_citations": "6\n", "authors": ["473"]}
{"title": "A diversity model based on failure distribution and its application in safety cases\n", "abstract": " This work develops a new basis for evaluating the reliability benefits of diverse software, based on fault injection testing. In particular, the work investigates new forms of argumentation that could in principle be used to justify diversity as a basis for the construction of safety claims. Failure distributions of two versions of diverse software under various fault conditions are revealed separately by fault injection methods, and then the common failure probability of the version-pair can be estimated. The approach is justified theoretically, and cross validated with other work. This method is also used to explain the fundamental influence of failure distributions on diversity. Furthermore, the unique capabilities of the method are demonstrated by implementation of the fault injection test on a program pair.", "num_citations": "5\n", "authors": ["473"]}
{"title": "Empirical assessment of software on-line diagnostics using fault injection\n", "abstract": " This paper is part of an on-going empirical research programme to develop an improved understanding of the implementation and evaluation of on-line diagnostics in software. In this study we have concentrated on the hypothesis that residual design errors exist because their coupling to the input space is very small, making them difficult to detect in normal testing. The objective of the reported experiment was basically to add a simple group of diagnostic checks to a reasonably complex program and use arbitrary fault injection to assess the error detection in relation to the coupling of the fault to the input space. The results were promising in that they demonstrated no significant deterioration in the effectiveness of the diagnostics as the fault coupling to the input space decreased. On this basis the use of diagnostics can be seen as supplementary to validation testing.", "num_citations": "5\n", "authors": ["473"]}
{"title": "Using influence diagrams in software change management\n", "abstract": " This paper describes the use of in uence diagrams and a risk-based model to formalise the combining of these di erent factors to aid the decision process. This model not only re ects the likelihood of all the necessary requirements for a change being met but also allows for the nancial or other bene ts to the organisation that would result from the change being included in the next software release.", "num_citations": "5\n", "authors": ["473"]}
{"title": "Testing the diversity of multi-version software using fault injection\n", "abstract": " Testing the diversity of multi-version software using fault injection \u2014 University of Bristol Skip to main navigation Skip to search Skip to main content University of Bristol Logo Help & Terms of Use Home Profiles Research Units Research Outputs Projects Student theses Datasets Activities Prizes Facilities/Equipment Search by expertise, name or affiliation Testing the diversity of multi-version software using fault injection L Chen, J Napier, J May, G Hughes Department of Civil Engineering Department of Computer Science Systems Centre Research output: Chapter in Book/Report/Conference proceeding \u203a Conference Contribution (Conference Proceeding) Overview Translated title of the contribution Testing the diversity of multi-version software using fault injection Original language English Title of host publication Unknown Publisher SARS Ltd Pages 13 - 1 Number of pages 12 Publication status Published - 1999 note \u2026", "num_citations": "5\n", "authors": ["473"]}
{"title": "A family of key agreement mechanisms for mission critical communications for secure mobile ad hoc and wireless mesh internetworking\n", "abstract": " Future wireless networks like mobile ad hoc networks and wireless mesh networks are expected to play important role in demanding communications such as mission critical communications. MANETs are ideal for emergency cases where the communication infrastructure has been completely destroyed and there is a need for quick set up of communications among the rescue/emergency workers. In such emergency scenarios wireless mesh networks may be employed in a later phase for providing advanced communications and services acting as a backbone network in the affected area. Internetworking of both types of future networks will provide a broad range of mission critical applications. While offering many advantages, such as flexibility, easy of deployment and low cost, MANETs and mesh networks face important security and resilience threats, especially for such demanding applications. We\u00a0\u2026", "num_citations": "4\n", "authors": ["473"]}
{"title": "Estimation of software diversity by fault simulation and failure searching\n", "abstract": " An important problem for computer-based systems is providing fault tolerance for unknown (at the time of commencement of service) systematic design errors. Such design errors can have a long latency in normal operation and only become apparent under specific conditions associated with particular combinations of input and internal system states. The use of 'diverse' software versions remains a possible approach to prevent coincidental failure, but its potential value has never been quantified. This paper presents the application of data-flow and constant perturbation to simulate the introduction of faults or errors into programs and explores methods to establish the magnitudes and locations of the associated input space failure regions. Used together, these two techniques enable failure behaviour to be described in a quantitative way and provide a method to estimate the diversity of multi-version software. A\u00a0\u2026", "num_citations": "4\n", "authors": ["473"]}
{"title": "A constant perturbation method for evaluation of structural diversity in multiversion software\n", "abstract": " In this paper, fault simulation is discussed as a test method for diversity assessment of multiversion software and data flow perturbation is used as a main technique for implementation. More specifically, constant perturbation is introduced as a specific example of data-flow perturbation. Some quantitative metrics are proposed for the description of software diversity, and the parameters needed to calculate the metrics estimated by fault injection experiments. A case study is presented to illustrate that the diversity metrics are appropriate, and that constant perturbation is a practical fault injecting technique to estimate parameters necessary for assessing diversity.", "num_citations": "4\n", "authors": ["473"]}
{"title": "Implementing Software On-Line Diagnostics in Safety Critical Systems\n", "abstract": " Current design and assessment methods cannot ensure that software is error free and consequently fault tolerant techniques play an important role in safety critical systems to ensure reliable software behaviour. Unfortunately general guidelines for the implementation of software diagnostics are lacking. The aim of this work is to build on the previous research in software error detection and the principles for hardware error detection, to gain an overall systems appreciation of, and develop a general methodology for, implementing fault diagnosis in computer based systems. A boiler control software case study is presented and is used to demonstrate the potential of our approach and to highlight the implications of different diagnostic strategies. This paper also discusses the potential of using empirical techniques such as fault simulation to study the coverage of different diagnostic options.", "num_citations": "4\n", "authors": ["473"]}
{"title": "Fault prediction for software development processes\n", "abstract": " Fault prediction for software development processes \u2014 University of Bristol Skip to main navigation Skip to search Skip to main content University of Bristol Logo Help & Terms of Use Home Profiles Research Units Research Outputs Projects Student theses Datasets Activities Prizes Facilities/Equipment Search by expertise, name or affiliation Fault prediction for software development processes JHR May, al et Department of Civil Engineering Systems Centre Research output: Chapter in Book/Report/Conference proceeding \u203a Conference Contribution (Conference Proceeding) Overview Translated title of the contribution Fault prediction for software development processes Original language English Title of host publication Mathematics of Dependable Systems Conference Publication status Published - Sep 1993 Bibliographical note Name and Venue of Event: Royal Holloway, university of London, Egham, Surrey : of , ./\u2026", "num_citations": "4\n", "authors": ["473"]}
{"title": "Investigation of an expert systems approach to bacterial identification\n", "abstract": " An investigation was carried out to assess the feasibility of using an expert systems approach to assist in the identification of unknown isolates of bacteria. A system was developed using Lisp which utilized the knowledge stored in standard bacteriological texts. A comparison of the expert systems approach and the probabilistic approach based on Bayes Theorem was made together with the advantages and disadvantages of each approach.", "num_citations": "4\n", "authors": ["473"]}
{"title": "Partial hydatidiform mole following intracytoplasmic sperm injection and transfer of a cryopreserved-thawed blastocyst\n", "abstract": " DiscussionSeveral cases of complete hydatidiform mole have been reported following assisted reproductive techniques, however reports of partial moles following ICSI are rare (Wood et al. 2002; Ulug et al. 2004). We believe this to be the first report of a partial molar pregnancy following the combination of ICSI and freeze-thawed blastocyst transfer.", "num_citations": "3\n", "authors": ["473"]}
{"title": "Soft systems methodology in net-centric cyber defence system development\n", "abstract": " Complexity is ever increasing within our information environment and organisations, as interdependent dynamic relationships within sociotechnical systems result in high variety and uncertainty from a lack of information or control. A net-centric approach is a strategy to improve information value, to enable stakeholders to extend their reach to additional data sources, share Situational Awareness (SA), synchronise effort and optimise resource use to deliver maximum (or proportionate) effect in support of goals. This paper takes a systems perspective to understand the dynamics within a net-centric information system. This paper presents the first stages of the Soft Systems Methodology (SSM), to develop a conceptual model of the human activity system and develop a system dynamics model to represent system behaviour, that will inform future research into a net-centric approach with information security. Our model\u00a0\u2026", "num_citations": "3\n", "authors": ["473"]}
{"title": "A case for new statistical software testing models\n", "abstract": " There is growing interest in statistical software testing (SST) as a software assurance technique. While the approach has major attractions, there is a need for new statistical models to infer failure probabilities from SST. The paper constructs a simple but realistic case in which the traditional binomial model does not work. The paper shows that if possible test failure dependencies are neglected, could the failure probability would be underestimated. The paper compares the results of our new probability model based on pairwise failures with results achieved when applying the traditional single-urn model, i.e., assuming no dependencies in the failure process", "num_citations": "3\n", "authors": ["473"]}
{"title": "Safety assessment of systems embedded with COTS components by PIP technique\n", "abstract": " The difficulties to assess reliability of systems that use COTS components are sometimes compounded by the inaccessibility of some COTS codes. This paper develops an approach of Perturbation of Interface Parameters (PIP) to simulate failures of COTS components. It is to validate the use of PIP as a fault-injection technique to test COTS components and surrounding systems. Tests of a nuclear protection system will be presented to demonstrate that PIP can be used to assess and aid safety designs in COTS based software.", "num_citations": "3\n", "authors": ["473"]}
{"title": "Statistical Software Testing\n", "abstract": " This chapter discusses the statistical testing of software. Statistical Software Testing (SST) is gaining more acceptance as a method of assessing software integrity and provides a quantifiable measure of reliability. The tasks necessary to carry out SST are described. SST for risk estimation is compared against SST for failure probability estimation. Software environment simulation for SST is particularly demanding; the various issues are described. SST is related to test adequacy measurement as commonly understood.", "num_citations": "3\n", "authors": ["473"]}
{"title": "Understanding organisational and cultural precursors to events\n", "abstract": " Reviewing the collective findings from investigations into a range of major events in high-hazard industries has led to the conclusion that there is a need to develop greater resilience to the organisational and cultural causes of these events. This requires more rigorous methods for identifying disaster precursors and for supporting intervention design. A study of the organisational and cultural precursors relating to 12 major events across several industries revealed shared precursors in areas such as leadership, operational attitudes and behaviours, communication, risk analysis, learning and oversight and scrutiny. This has enabled statements of good practice to be developed, together with question sets that can be used by regulators and the industry to profile organisational risk management resilience and thereby drive organisational learning. The research shows that the processes of incubation and evolution of\u00a0\u2026", "num_citations": "2\n", "authors": ["473"]}
{"title": "Effects of correlated shadowing modeling on performance evaluation of wireless sensor networks\n", "abstract": " Wireless links are typically modeled in isolation as independent and parallel links. However, in reality, there is often a correlation in defects and impairments between collocated links. The spatial correlation of shadowing among proximate wireless links has been frequently observed. Although different types of correlated shadowing models have been proposed for wireless channels, these models are not present in popular network simulators. Ignoring such correlations results in the diversity of adjacent links being over- estimated. Our hypothesis is that this could lead to incorrect results when evaluating the performance of wireless systems and network protocols. In this paper, the ns-3 simulation environment has been enhanced with a prototype correlated shadowing model developed in our previously published work. We study the end-to-end packet delivery ratio and delay in wireless sensor networks using both\u00a0\u2026", "num_citations": "2\n", "authors": ["473"]}
{"title": "A viable systems approach towards cyber situational awareness\n", "abstract": " There is a gap in the ability to gain sufficient Situational Awareness (SA) of the cyber domain at the strategic level, leading nations and organisations to rapidly develop this capability. Through various cyber strategies, nations are seeking to encourage multi-organisation collaboration and information infrastructures between government, military, critical national infrastructure and engaging with the public and private sectors to secure cyberspace and its dependencies. This paper discusses the benefits of a systems approach to the complex sociotechnical problem of collaboration towards a cyber defence capability, and how challenges can be managed through the perspective of a viable system. The Viable Systems Model (VSM) provides a perspective for understanding system behaviour and anticipating, planning, and implementing large scale organisational change. The output from focus group sessions with\u00a0\u2026", "num_citations": "2\n", "authors": ["473"]}
{"title": "Reliability modeling and prediction of wireless multi-hop networks with correlated shadowing\n", "abstract": " Shadowing losses on proximate wireless links have been experimentally proven to be highly correlated in various scenarios. However, most of the existing works on the reliability modeling of Wireless Multi-Hop Networks (WMHNs) assume independent link shadowing. Neglecting shadowing correlations could lead to inaccurate network simulation results and unreliable wireless system design. In this paper, we present a more realistic reliability model of WMHN that incorporates correlated link shadowing. In particular, we use the correlated shadowing model that was developed in our previous work. This model enables the efficient generation of spatially correlated shadowing. It has been proved to agree well with the literature in terms of statistical properties. The proposed network model allows us to predict the reliability metrics of WMHNs and study network designs that can lessen the effect of correlated shadowing\u00a0\u2026", "num_citations": "2\n", "authors": ["473"]}
{"title": "A dynamic key agreement mechanism for mission critical mobile ad hoc networking\n", "abstract": " Mobile ad hoc networks are expected to play an important role in demanding communications such as military and emergency response. In Mobile ad hoc networking each node relies on adjacent nodes in order to achieve and maintain connectivity and functionality. While offering many advantages, such as flexibility, easy of deployment and low cost, mobile ad hoc networking faces important security threats that could be proven vital in future telecommunication applications. This paper introduces a key dynamic agreement method based on a weak to strong authentication mechanism associated with a multiparty contributory key establishment method. It is designed for dynamic changing topologies, it employs elliptic curve cryptography to best serve thin clients with energy constrains, and reduces significantly key re-establishment due to network formation changes.", "num_citations": "2\n", "authors": ["473"]}
{"title": "Application of statistical testing to smart device code\n", "abstract": " Statistical testing can produce dependability information by estimating the probability of failure on demand for a system. In this paper we explore issues related to the construction of statistical test-cases for the firmware of a smart device. Our aim is to share our own experience with the technique and we expect to derive some general insights into what needs to be taken into account when designing such test-cases for smart devices. This provides useful information for situations where one would like to perform statistical testing but where no access to the device code is available. This paper describes the status quo of this project, further results are expected to emerge from this work", "num_citations": "2\n", "authors": ["473"]}
{"title": "Managing the organizational and cultural precursors to major events\u2013recognising and addressing complexity\n", "abstract": " \uf0e6 There have been many organisational accidents and nearmisses across industries such as petrochemical, nuclear, transport, major civil engineering projects, etc;\uf0e6 Some have been during \u2018normal\u2019operation, some during outages and some during one-off projects;\uf0e6 Looking at these collectively/holistically allows us to identify event precursors. There are strong similarities between them and clear patterns of failure emerge;\uf0e6 We will summarise some key findings and then discuss techniques that are being developed to address them more effectively;", "num_citations": "1\n", "authors": ["473"]}
{"title": "Optimisation of safety critical software development processes\n", "abstract": " Optimisation of safety critical software development processes \u2014 University of Bristol Skip to main navigation Skip to search Skip to main content University of Bristol Logo Help & Terms of Use Home Profiles Research Units Research Outputs Projects Student theses Datasets Activities Prizes Facilities/Equipment Search by expertise, name or affiliation Optimisation of safety critical software development processes MP Brito, JHR May Department of Civil Engineering Systems Centre Research output: Chapter in Book/Report/Conference proceeding \u203a Conference Contribution (Conference Proceeding) Overview Translated title of the contribution Optimisation of safety critical software development processes Original language English Title of host publication ESREL 2007 Stavanger, Norway 25-27 June 2007 Editors Aven , Vinnem Publisher Taylor & Francis Group Pages 621 - 628 Publication status Published - Jun 2007 \u2026", "num_citations": "1\n", "authors": ["473"]}
{"title": "Use of Graphical Probabilistic Models to build SIL claims based on software safety standards such as IEC61508-3\n", "abstract": " Software reliability assessment is \u2018different\u2019 from traditional reliability techniques and requires a different process. The use of development standards is common in current good practice. Software safety standards recommend processes to design and assure the integrity of safety-related software. However the reasoning on the validity of these processes is complex and opaque. In this paper an attempt is made to use Graphical Probability Models (GPMs) to formalise the reasoning that underpins the construction of a Safety Integrity Level (SIL) claim based upon a safety standard such as IEC61508 Part 3. There are three major benefits: the reasoning becomes compact and easy to comprehend, facilitating its scrutiny, and making it easier for experts to develop a consensus using a common formal framework; the task of the regulator is supported because to some degree the subjective reasoning which\u00a0\u2026", "num_citations": "1\n", "authors": ["473"]}
{"title": "Reliability Specification for Component-Based Software\n", "abstract": " Reliability Specification for Component-Based Software \u2014 University of Bristol Skip to main navigation Skip to search Skip to main content University of Bristol Logo Help & Terms of Use Home Profiles Research Units Research Outputs Projects Student theses Datasets Activities Prizes Facilities/Equipment Search by expertise, name or affiliation Reliability Specification for Component-Based Software X Mao, JHR May Department of Civil Engineering Systems Centre Research output: Chapter in Book/Report/Conference proceeding \u203a Conference Contribution (Conference Proceeding) Overview Translated title of the contribution Reliability Specification for Component-Based Software Original language English Title of host publication 8th IASTED International Conference on Software Engineering and Applications (SEA 2004) MIT Massachusetts US 9-11 Nov 2004 Publication status Published - Nov 2004 Cite this APA .\u2026", "num_citations": "1\n", "authors": ["473"]}
{"title": "The effectiveness of statistical testing when applied to logic systems\n", "abstract": " In this paper we demonstrate the effectiveness of statistical testing for error detection on the example of a Programmable Logic System (PLS). The introduction of statistical testing arose from the wish to quantify the PLS\u2019s reliability. An appropriate statistical testing algorithm was devised and implemented, which is described in detail in this paper.We compare the results of statistical testing with those of a variety of other testing methods employed on the PLS. In terms of differences detected per number of tests, statistical testing showed an outstanding effectiveness. Furthermore, it detected a problem, which was missed by all other testing techniques. This together with its potential for reliability quantification illustrates its importance for system validation as part of a risk\u2014based safety\u2014case.", "num_citations": "1\n", "authors": ["473"]}
{"title": "Formal coupling of software components\n", "abstract": " Previous work on structural software reliability modelling should be extended to account for data flow in software. A way forward is explained by contrasting two extremely simple examples of software structure. In addition to improving software reliability estimates, development of such an approach is important because it has the potential to provide guidelines for testable software and it would provide a formal meaning for the notion of coupling between software components.", "num_citations": "1\n", "authors": ["473"]}
{"title": "Fault prediction for software\n", "abstract": " Fault prediction for software \u2014 University of Bristol Skip to main navigation Skip to search Skip to main content University of Bristol Logo Help & Terms of Use Home Profiles Research Units Research Outputs Projects Student theses Datasets Activities Prizes Facilities/Equipment Search by expertise, name or affiliation Fault prediction for software J May, P Hall, H Zhu, T Cockram, N Bird, L Winsborrow Department of Civil Engineering Systems Centre Research output: Chapter in Book/Report/Conference proceeding \u203a Chapter in a book 53 Citations (Scopus) Overview Translated title of the contribution Fault prediction for software Original language English Title of host publication Mathematics of Dependable Systems Editors C. Mitchell, V. Stavridou Publisher Oxford University Press Pages 165 - 181 Number of pages 16 ISBN (Print) 0198534914 Publication status Published - 1995 Access to Document http://www.cs.bris.\u2026", "num_citations": "1\n", "authors": ["473"]}
{"title": "Nuclear Electric\u2019s Contributions to the CONTESSE Testing Framework and its Early Application\n", "abstract": " The various areas of study undertaken by Nuclear Electric for their contributions to the CONTESSE project are briefly listed. One of these areas, methods for statistical software testing, is then reported more fully, after its role in the UK\u2019s safety principles for nuclear power plants has been identified. Appropriate techniques for statistical testing of plant protection systems are detailed.", "num_citations": "1\n", "authors": ["473"]}
{"title": "Injecting faults into environment simulators for testing safety critical software\n", "abstract": " Software testing via environment simulation is an approach to testing safety critical software. By this approach, to test software in adverse conditions we need to simulate the failure processes of the environment system. Such testing is essential for safety critical software, especially for protection software. However, due to the complexity of failure processes, the development of simulators of failure processes is complicated, expensive and difficult. This paper presents a method to derive such simulators systematically and efficiently. The basic idea is to inject faults into the simulator of the healthy environment system to obtain the simulators of faulty environments.", "num_citations": "1\n", "authors": ["473"]}
{"title": "Estimating faults introduced by software maintenance\n", "abstract": " Estimating faults introduced by software maintenance \u2014 University of Bristol Skip to main navigation Skip to search Skip to main content University of Bristol Logo Help & Terms of Use Home Profiles Research Units Research Outputs Projects Student theses Datasets Activities Prizes Facilities/Equipment Search by expertise, name or affiliation Estimating faults introduced by software maintenance T Cockram, JHR May Department of Civil Engineering Systems Centre Research output: Chapter in Book/Report/Conference proceeding \u203a Conference Contribution (Conference Proceeding) Overview Translated title of the contribution Estimating faults introduced by software maintenance Original language English Title of host publication Centre for Software Reliability Conference, Dublin Ireland Publication status Published - Sep 1994 Cite this APA Author BIBTEX Harvard Standard RIS Vancouver Cockram, T., & May, JHR. /\u2026", "num_citations": "1\n", "authors": ["473"]}
{"title": "Knowledge engineering helps testing protection software\n", "abstract": " Knowledge engineering helps testing protection software \u2014 University of Bristol Skip to main navigation Skip to search Skip to main content University of Bristol Logo Help & Terms of Use Home Profiles Research Units Research Outputs Projects Student theses Datasets Activities Prizes Facilities/Equipment Search by expertise, name or affiliation Knowledge engineering helps testing protection software H Zhu, P Hall, JHR May, T Cockram Department of Civil Engineering Systems Centre Research output: Chapter in Book/Report/Conference proceeding \u203a Conference Contribution (Conference Proceeding) Overview Translated title of the contribution Knowledge engineering helps testing protection software Original language English Title of host publication International Conference on Software Engineering and Knowledge Engineering Publication status Published - 1994 Cite this APA Author BIBTEX Harvard RIS Zhu.\u2026", "num_citations": "1\n", "authors": ["473"]}
{"title": "Software Reliability Assessment for Branching Structures: A Hierarchical Approach\n", "abstract": " An increased use of software systems in safety\u2013critical applications has made the estimation of the software probability of failure on demand (pfd) an issue of great importance. In this paper, estimation of the system pfd is based on the decomposition of the system into a set of sub\u2013systems with independent failure behaviour. Structures which fork and then join again can pose a problem when it comes to defining independently failing sub-systems. A Bayesian approach performed on two levels of granularity is suggested to perform system pfd estimation on such structures.", "num_citations": "1\n", "authors": ["473"]}