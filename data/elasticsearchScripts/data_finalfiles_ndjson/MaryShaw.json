{"title": "Abstractions for software architecture and tools to support them\n", "abstract": " Architectures for software use rich abstractions and idioms to describe system components, the nature of interactions among the components, and the patterns that guide the composition of components into systems. These abstractions are higher level than the elements usually supported by programming languages and tools. They capture packaging and interaction issues as well as computational functionality. Well-established (if informal) patterns guide the architectural design of systems. We sketch a model for defining architectures and present an implementation of the basic level of that model. Our purpose is to support the abstractions used in practice by software designers. The implementation provides a testbed for experiments with a variety of system construction mechanisms. It distinguishes among different types of components and different ways these components can interact. It supports abstract\u00a0\u2026", "num_citations": "1318\n", "authors": ["623"]}
{"title": "Prospects for an engineering discipline of software\n", "abstract": " Although software engineering is not yet a true engineering discipline, it has the potential to become one. Older engineering fields are examined to ascertain the character that software engineering might have. The current state of software technology is discussed, covering information processing as an economic force, the growing role of software in critical applications, the maturity of development techniques, and the scientific basis for software engineering practice. Five basic steps that the software engineering profession must take to become a true engineering discipline are described. They are: understanding the nature of expertise, recognizing different ways to get information, encouraging routine practice, expecting professional specializations, and improving the coupling between science and commercial practice.< >", "num_citations": "557\n", "authors": ["623"]}
{"title": "Estimating the numbers of end users and end user programmers\n", "abstract": " In 1995, Boehm predicted that by 2005, there would be \"55 million performers\" of \"end user programming\" in the United States. The original context and method which generated this number had two weaknesses, both of which we address. First, it relies on undocumented, judgment-based factors to estimate the number of end user programmers based on the total number of end users; we address this weakness by identifying specific end user sub-populations and then estimating their sizes. Second, Boehm's estimate relies on additional undocumented, judgment-based factors to adjust for rising computer usage rates; we address this weakness by integrating fresh Bureau of Labor Statistics (BLS) data and projections as well as a richer estimation method. With these improvements to Boehm's method, we estimate that in 2012 there will be 90 million end users in American workplaces. Of these, we anticipate that over\u00a0\u2026", "num_citations": "458\n", "authors": ["623"]}
{"title": "The golden age of software architecture\n", "abstract": " Since the late 1980s, software architecture has emerged as the principled understanding of the large-scale structures of software systems. From its roots in qualitative descriptions of empirically observed useful system organizations, software architecture has matured to encompass a broad set of notations, tools, and analysis techniques. Whereas initially the research area interpreted software practice, it now offers concrete guidance for complex software design and development. It has made the transition from basic research to an essential element of software system design and construction. This retrospective examines software architecture's growth in the context of a technology maturation model, matching its significant accomplishments to the model's stages to gain perspective on where the field stands today. This trajectory has taken architecture to its golden age.", "num_citations": "409\n", "authors": ["623"]}
{"title": "An introduction to the construction and verification of Alphard programs\n", "abstract": " The programming language Alphard is designed to provide support for both the methodologies of \"well-structured\" programming and the techniques of formal program verification. Language constructs allow a programmer to isolate an abstraction, specifying its behavior publicly while localizing knowledge about its implementation. The verification of such an abstraction consists of showing that its implementation behaves in accordance with its public specifications; the abstraction can then be used with confidence in constructing other programs, and the verification of that use employs only the public specifications.", "num_citations": "407\n", "authors": ["623"]}
{"title": "A field guide to boxology: Preliminary classification of architectural styles for software systems\n", "abstract": " Software architects use a number of commonly-recognized \"styles\" to guide their design of system structures. Each of these is appropriate for some classes of problems, but none is suitable for all problems. How, then, does a software designer choose an architecture suitable for the problem at hand? Two kinds of information are required: (1) careful discrimination among the candidate architectures and (2) design guidance on how to make appropriate choices. In this paper, we support careful discrimination with a preliminary classification of styles. We use a 2D classification strategy with control and data issues as the dominant organizing axes. We position the major styles within this space and use finer-grained discriminations to elaborate variations on the styles. This provides a framework for organizing design guidance, which we partially flesh out with rules of thumb.", "num_citations": "373\n", "authors": ["623"]}
{"title": "Writing good software engineering research papers\n", "abstract": " Software engineering researchers solve problems of several different kinds. To do so, they produce several different kinds of results, and they should develop appropriate evidence to validate these results. They often report their research in conference papers. I analyzed the abstracts of research papers submitted to XSE 2002 in order to identify the types of research reported in the submitted and accepted papers, and I observed the program committee discussions about which papers to accept. This report presents the research paradigms of the papers, common concerns of the program committee, and statistics on success rates. This information should help researchers design better research projects and write papers that present their results to best advantage.", "num_citations": "360\n", "authors": ["623"]}
{"title": "What makes good research in software engineering?\n", "abstract": " Physics, biology, and medicine have well-refined public explanations of their research processes. Even in simplified form, these provide guidance about what counts as \u201cgood research\u201d both inside and outside the field. Software engineering has not yet explicitly identified and explained either our research processes or the ways we recognize excellent work. Science and engineering research fields can be characterized in terms of the kinds of questions they find worth investigating, the research methods they adopt, and the criteria by which they evaluate their results. I will present such a characterization for software engineering, showing the diversity of research strategies and the way they shift as ideas mature. Understanding these strategies should help software engineers design research plans and report the results clearly; it should also help explain the character of software engineering research to\u00a0\u2026", "num_citations": "325\n", "authors": ["623"]}
{"title": "Software engineering education: A roadmap\n", "abstract": " Software's increasingly critical role in systems of widespread significance presents new challenges for the education of software engineers. Not only is our dependence on software increasing, but the character of software production is itself changing-and with it the demands on the software developers. Four challenges for educators of software developers help identify aspirations for software engineering education.", "num_citations": "301\n", "authors": ["623"]}
{"title": "The coming-of-age of software architecture research\n", "abstract": " Over the past decade, software architecture research has emerged as the principled study of the overall structure of software systems, especially the relations among subsystems and components. From its roots in qualitative descriptions of useful system organizations, software architecture has matured to encompass broad explorations of notations, tools, and analysis techniques. Whereas initially the research area interpreted software practice, it now offers concrete guidance for complex software design and development. We can understand the evolution and prospects of software architecture research by examining the research paradigms used to establish its results. These are, for the most part, the paradigms of software engineering. We advance our fundamental understanding by posing research questions of several kinds and applying appropriate research techniques, which differ from one type of problem to another, yield correspondingly different kinds of results, and require different methods of validation. Unfortunately, these paradigms are not recognized explicitly and are often not carried out correctly; indeed not all are consistently accepted as valid. This retrospective on a decade-plus of software architecture research examines the maturation of the software architecture research area by tracing the types of research questions and techniques used at various stages. We will see how early qualitative results set the stage for later precision, formality, and automation and how results build up over time. This generates advice to the field and projections about future impact.", "num_citations": "283\n", "authors": ["623"]}
{"title": "Procedure calls are the assembly language of software interconnection: Connectors deserve first-class status\n", "abstract": " Software designers compose systems from components written in some programming language. They regularly describe systems using abstract patterns and sophisticated relations among components. However, the configuration tools at their disposal restrict them to composition mechanisms directly supported by the programming language. To remedy this lack of expressiveness, we must elevate the relations among components to first-class entities of the system, entitled to their own specifications and abstractions.", "num_citations": "282\n", "authors": ["623"]}
{"title": "Global variable considered harmful\n", "abstract": " N0te that the var1a61e5 wh05e 5tate5 are de5cr16ed 6y the 1081ca1 pr0p051t10n5 P and P\u2022 a550c1ated w1th any 91ven 5e9ment 0f text 5 w111 n0t 1n 9enera1 6e the 5ame var1a61e5 de5cr16ed 6y the pr0p05t10n5 a550c1ated w1th adjacent 5e9ment5 0f text. 1n 0rder t0 check the c0rrectne55, 0r even the p1au516111ty, 0f a Pr09ram, 1t 15 nece55ary t0 en5ure that the pr0p051t10n P 15 va11d-that the var1a61e5 1n P actua11y have the va1u05 c1a1med f0r them. 1n a 5tra19ht-11ne Pr09ram th15 w0u1d pre5ent n0 pr061em: 1t w0u1d 6e 5uff1c1ent t0 5can 6ackward thr0u9h the Pr09ram unt11 a pr0p051t10n 1nv01v1n9 each 0f the var1a61e5 1n 4ue5t10n wa5 f0und. H0wever, 5tra19ht-11ne Pr09ram5 are rare (exCept 1n 1an9ua9e5 5uCh a5 APL where much 0f the c0ntr01 151mp11\u00a2 1t), 50 1t 15 nece55ary t0 check 6ackward a10n9 a11 p055161e c0ntr01 path5 unt11 an a55ert10n a60ut each\u00a0\u2026", "num_citations": "268\n", "authors": ["623"]}
{"title": "Abstraction techniques in modern programming languages\n", "abstract": " Modern Programming languages depend on abstraction: they manage complexity by emphazing what is significant to the user and suppressing what is not.", "num_citations": "217\n", "authors": ["623"]}
{"title": "Architectural issues in software reuse: It's not just the functionality, it's the packaging\n", "abstract": " Effective reuse depends not only on finding and reusing components, but also on the ways those components are combined. The informal folklore of software engineering provides a number of diverse styles for organizing software systems. These styles, or architectures, show how to compose systems from components; different styles expect different kinds of component packaging and different kinds of interactions between the components. Unfortunately, these styles and packaging distinctions are often implicit; as a consequence, components with appropriate functionality may fail to work together. This talk surveys common architectural styles, including important packaging and interaction distinctions, and proposes an approach to the problem of reconciling architectural mismatches.", "num_citations": "206\n", "authors": ["623"]}
{"title": "Larger scale systems require higher-level abstractions\n", "abstract": " Over the past thirty years, abstraction techniques such as high level programming languages and abstract data types have improved our ability to specify and develop software. However, the increasing size and complexity of software systems have introduced new problems that are not solved by the current techniques. These new problems involve the system-level design of software, in which the important decisions are concerned with the kinds of modules and subsystems to use and the way these modules and subsystems are organized. This level of organization, the software archirecrure level, requires new kinds of abstractions that capture essential properties of major subsystems and the ways they interact.", "num_citations": "187\n", "authors": ["623"]}
{"title": "Abstraction and verification in Alphard: Defining and specifying iteration and generators\n", "abstract": " The Alphard \u201cform\u201d provides the programmer with a great deal of control over the implementation of abstract data types. In this paper the abstraction techniques are extended from simple data representation and function definition to the iteration statement, the most important point of interaction between data and the control structure of the language itself. A means of specializing Alphard's loops to operate on abstract entities without explicit dependence on the representation of those entities is introduced. Specification and verification techniques that allow the properties of the generators for such iterations to be expressed in the form of proof rules are developed. Results are obtained that for common special cases of these loops are essentially identical to the corresponding constructs in other languages. A means of showing that a generator will terminate is also provided.", "num_citations": "181\n", "authors": ["623"]}
{"title": "ALPHARD: Form and content\n", "abstract": " Alphard is a design for a programming system that supports the abstraction and verification techniques required by modern program'ming methodology. During the language design process, we were concerned simultaneously with problems of methodology, correctness, and efficiency. Methodological concerns are addressed through facilities for defining new, task\u00b7 specific abstractions that capture complex notions in terms of their intended properties, without explicating them in terms of specific low\u00b7 level implementations. Techniques for verifying certain properties of these programs address the correctness concerns. Finally, the language has been designed to permit compilation to efficient object code. Although a compiler was not implemented, the research shed light on specification issues and on programming methodology.Alphard language constructs allow a programmer to isolate an abstraction, specifying its\u00a0\u2026", "num_citations": "171\n", "authors": ["623"]}
{"title": "Beyond objects: A software design paradigm based on process control\n", "abstract": " A standard demonstration problem in object-oriented programming is the design of an automobile cruise control. This design exercise demonstrates object-oriented techniques well, but it does not ask whether the object-oriented paradigm is the best one for the task. Here we examine the alternative view that cruise control is essentially a control problem. We present a new software organization paradigm motivated by process control loops. The control view leads us to an architecture that is dominated by analysis of a classical feedback loop rather than by the identification of discrete stateful components to treat as objects. The change in architectural model calls attention to important questions about the cruise control task that aren't addressed in an object-oriented design.", "num_citations": "166\n", "authors": ["623"]}
{"title": "Abstractions and implementations for architectural connections\n", "abstract": " The architecture of a software system shows how the system is realized by a collection of components together with the interactions among these components. Conventional design focuses the components, but the properties of the system depend critically on the character of the interactions. Although software designers have good informal abstractions for these interactions, these abstractions are poorly supported by the available languages and tools. As a result, the choice of interaction is often defaulted or made implicitly rather than deliberately chosen. Further, interactions are usually programmed in terms of underlying mechanisms rather than the designers natural abstractions. UniCon supports a rich selection of abstractions for the connectors that mediate interactions among components. Connector implementation presents special challenges. The \"compiler\" must produce and integrate not only the object code\u00a0\u2026", "num_citations": "164\n", "authors": ["623"]}
{"title": "Some patterns for software architectures\n", "abstract": " Design patterns for software architectures interactions. The architectural diagrams are often highly specific to the systems they describe, especially in the labeling of components.", "num_citations": "155\n", "authors": ["623"]}
{"title": "Comparing architectural design styles\n", "abstract": " Different architectural styles lead not simply to different designs, but to designs with significantly different properties. This look at 11 designs of a cruise-control system shows that solutions varied, even within a design style, because of how the architectural choice leads the designer to view the system's environment.< >", "num_citations": "148\n", "authors": ["623"]}
{"title": "Empirical evaluation of defect projection models for widely-deployed production software systems\n", "abstract": " Defect-occurrence projection is necessary for the development of methods to mitigate the risks of software defect occurrences. In this paper, we examine user-reported software defect-occurrence patterns across twenty-two releases of four widely-deployed, business-critical, production, software systems: a commercial operating system, a commercial middleware system, an open source operating system (OpenBSD), and an open source middleware system (Tomcat). We evaluate the suitability of common defect-occurrence models by first assessing the match between characteristics of widely-deployed production software systems and model structures. We then evaluate how well the models fit real world data. We find that the Weibull model is flexible enough to capture defect-occurrence behavior across a wide range of systems. It provides the best model fit in 16 out of the 22 releases. We then evaluate the ability of\u00a0\u2026", "num_citations": "135\n", "authors": ["623"]}
{"title": "Fundamental structures of computer science\n", "abstract": " From the Publisher: This textbook is designed to support an intermediate-level course in computer science. It is intended for students who have at least one or two semesters of programming and problem-solving experience and wish to prepare for more advanced topics in computing. Ideally, the students will also have a semester's background in discrete mathematics. This textbook is also an introduction to the science that underlies good programming.", "num_citations": "114\n", "authors": ["623"]}
{"title": "Truth vs. knowledge: The difference between what a component does and what we know it does\n", "abstract": " Conventional doctrine holds that specifications are sufficient, complete, static, and homogeneous. For system level specifications, especially for software architectures, conventional doctrine often fails to hold. This can happen when properties other than functionality are critical, when not all properties of interest can be identified in advance, or when the specifications are expensive to create. That is, the conventional doctrine often fails for practical software components. Specifications for real software must be incremental, extensible, and heterogeneous. To support such specifications, our notations and tools must be able to extend and manipulate structured specifications. In the UniCon architecture description language, we introduce credentials, a property list form of specification that supports evolving heterogeneous specifications and their use with system building and analysis tools.", "num_citations": "110\n", "authors": ["623"]}
{"title": "Models for undergraduate project courses in software engineering\n", "abstract": " The software engineering course provides undergraduates with an opportunity to learn something about real-world software development. Since software engineering is far from being a mature engineering discipline, it is not possible to define a completely satisfactory syllabus. Content with a sound basis is in short supply, and the material most often taught is at high risk of becoming obsolete within a few years.             Undergraduate software engineering courses are now offered in more than 100 universities. Although three textbooks dominate the market, there is not yet consensus on the scope and form of the course. The two major decisions an instructor faces are the balance between technical and management topics and the relation between the lecture and project components. We discuss these two decisions, with support from sample syllabi and survey data on course offerings in the US and Canada\u00a0\u2026", "num_citations": "110\n", "authors": ["623"]}
{"title": "Experiences and results from initiating field defect prediction and product test prioritization efforts at ABB Inc.\n", "abstract": " Quantitatively-based risk management can reduce the risks associated with field defects for both software producers and software consumers. In this paper, we report experiences and results from initiating risk-management activities at a large systems development organization. The initiated activities aim to improve product testing (system/integration testing), to improve maintenance resource allocation, and to plan for future process improvements. The experiences we report address practical issues not commonly addressed in research studies: how to select an appropriate modeling method for product testing prioritization and process improvement planning, how to evaluate accuracy of predictions across multiple releases in time, and how to conduct analysis with incomplete information. In addition, we report initial empirical results for two systems with 13 and 15 releases. We present prioritization of configurations\u00a0\u2026", "num_citations": "108\n", "authors": ["623"]}
{"title": "\" Self-healing\": softening precision to avoid brittleness: position paper for WOSS'02: workshop on self-healing systems\n", "abstract": " Modern practical computing systems are much more complex than the simple programs on which we developed our models of dependability. These dependability models depend on precise specifications, but it is often impractical to obtain precise specifications of practical software-intensive systems. Furthermore, the criteria for acceptable behavior vary from time to time and from one user to another. When development methods are based on the classic models that assume precise specifications, the resulting systems are often brittle---they are vulnerable to unexpected conditions and hard to tune to changing expectations. Practical systems would be better served by development models that recognize the variability and unpredictability of the environment in which the systems are used. Such development methods should pursue not the absolute criterion of correctness, but rather the goal of fitness for the intended\u00a0\u2026", "num_citations": "103\n", "authors": ["623"]}
{"title": "Curriculum'78\u2014is computer science really that unmathematical?\n", "abstract": " If computer science had not developed--significantly-as a science in the ten years between Curriculum'68 [2] and Curriculum'78 [3], then perhaps all those people who wondered if computer science was really a discipline would have been correct. In 1968 computer science was searching for but had not yet found much in the way of the principles and theoretical underpinnings which characterize a (mature) science. Ten years later, there is nothing laughable about calling computer science a science. This decade has seen major advances in the theory of computation and in the utility of theoretical results in practical settings. The rapid growth of the field of computational complexity has greatly increased our ability to analyze algorithms. And perhaps most significantly, we have finally started to make real progress in developing principles and theories for the design and verification of algorithms and programs. Are these\u00a0\u2026", "num_citations": "102\n", "authors": ["623"]}
{"title": "Toward higher-level abstractions for software systems\n", "abstract": " Software now accounts for most of the cost of computer-based systems. Over the past thirty years, abstraction techniques such as high level programming languages and abstract data types have improved our ability to develop software. However, the increasing size and complexity of software systems have introduced new problems that are not solved by the current techniques. These new problems involve the system-level design of software, in which the important decisions are concerned with the kinds of modules and subsystems to use and the way these modules and subsystems are organized. This level of organization, the software architecture level, requires new kinds of abstractions. These new abstractions will capture essential properties of major subsystems and the ways they interact.", "num_citations": "101\n", "authors": ["623"]}
{"title": "Abstraction and verification in Alphard: Introduction to language and methodology\n", "abstract": " Alphard is a programming language whose goals include supporting both the development of well-structured programs and the formal verification of these programs. This paper attempts to capture the symbiotic influence of these two goals on the design of the language. To that end the language description is interleaved with the presentation of a proof technique and discussion of programming methodology. Examples to illustrate both the language and the verification technique are included.", "num_citations": "95\n", "authors": ["623"]}
{"title": "Computer analysis of chronological seriation\n", "abstract": " Any reconstruction of the history of a culture requires that the events be $ aced in a chronological order. In view of this fundamental importance of dating, archeologists have tested and pioneered in the development of many techniques. At the present, the dating of archeological remains can be accomplished by a number of independent methods which yield chronologies of varying degrees of precision. Unfortunately, most of these techniques are limited in their application and the deposits in a typical archeological site may, therefore, need to be dated by several methods. It is toward a refinement of dating by one such method-the seriation of artifacts-that we direct our attention in this study.Techniques to deduce chronological order by analyzing systematic changes in assemblages of artifacts are important tools that can be used independently or in conjunction with other dating methods. Intuition had long suggested, and specific studies had demonstrated, that changes in artifacts may be lineally related to time. Again, intuition suggested, but it had not been systematically tested, that some archeological data are more amenable to seriation than others. In fact, a number of seriations and other chronological orderings of archeological material had been performed by archeologists over the years with little concern as to the suitability of the techniques or the validity of the theories on which they were based. It was with these issues in mind that we undertook the present project. Without the use of computers, any large-scale testing program would have been impossible. It was therefore natural that the evaluation and development of methods of seriation\u00a0\u2026", "num_citations": "95\n", "authors": ["623"]}
{"title": "Patterns for software architectures\n", "abstract": " Software designers rely on informal patterns, or idioms, to describe the architectures of their software systems\u2014the configurations of components that make up the systems. My purpose here is to reflect on the role these patterns play in software design. I am particularly interested in the ways that informal patterns shape the configurations. These patterns, or idioms, determine how separate parts are combined, or \u201cwoven together\u201d. The resulting organization is often called the architecture of the system. Current programming languages do not support these patterns; indeed, the patterns address problems that lie outside the scope of conventional programming languages. This paper describes the character of these architectural patterns and the status of work on models and tools to support them.", "num_citations": "92\n", "authors": ["623"]}
{"title": "Heterogeneous design idioms for software architecture\n", "abstract": " Software designers use a variety of structural patterns to specify system architectures. These patterns, or idioms, are currently used informally and imprecisely. Nevertheless, they provide a useful, broadly shared vocabulary. In practice, a given design often relies on several patterns. This paper reviews some common architectural idioms, shows several ways in which they are used heterogeneously, and discusses the benefits of making these idioms and their combinations more explicit and precise.", "num_citations": "83\n", "authors": ["623"]}
{"title": "Software metrics: an analysis and evaluation\n", "abstract": " Software metrics is a new area of computer science designed to enable programmers and other practitioners to assign quantitative indexes of merit to software. In this volume,\" software\" is defined broadly as a generic for all the stages of tailoring a computer system to solve a problem. Software Metrics is the first book to survey this new area, measuring its present extent, describing its characteristic features, and indicating directions of potential expansion. The aim of the articles included in the book is to provide precise, quantified answers to such questions as: What are the memory requirements of the software? The speed requirements? What is the cost of production? The likely time schedule of production? When will it have to be replaced? What manpower loading should be used? how close to its limits is the system expected to run? What levels of satisfactory testing are sufficient? How well does the testing environment approximate the execution environment? What is the enhancement cost? To what extent has the problem\u2014of the technology\u2014moved beyond the program? Would it cost less to rebuild the system than to maintain and enhance it?\" In software, evolutionary complexity is probably more important than the classical time and space measures with which computer science has been concerned so far,\" the editors note in their introductory overview. This overview gauges the range of the book's fifteen contributions by the major developers of software metrics.", "num_citations": "70\n", "authors": ["623"]}
{"title": "The impact of abstraction concerns on modern programming languages\n", "abstract": " The major issues of modern software are its size and complexity, and its major problems involve finding effective techniques and tools for organization and maintenance. This paper traces the important ideas of modern programming languages to their roots in the problems and languages of the past decade and shows how these modern languages respond to contemporary problems in software development. Modern programming's key concept for controlling complexity is abstraction-that is, selective emphasis on detail; new developments in programming languages provide ways to support and exploit abstraction techniques.", "num_citations": "66\n", "authors": ["623"]}
{"title": "Topes\n", "abstract": " Programmers often omit input validation when inputs can appear in many different formats or when validation criteria cannot be precisely specified. To enable validation in these situations, we present a new technique that puts valid inputs into a consistent format and that identifies \"questionable\" inputs which might be valid or invalid, so that these values can be double-checked by a person or a program. Our technique relies on the concept of a \"tope\", which is an application-independent abstraction describing how to recognize and transform values in a category of data. We present our definition of topes and describe a development environment that supports the implementation and use of topes. Experiments with web application and spreadsheet data indicate that using our technique improves the accuracy and reusability of validation code and also improves the effectiveness of subsequent data cleaning such as\u00a0\u2026", "num_citations": "65\n", "authors": ["623"]}
{"title": "The golden age of software architecture revisited\n", "abstract": " In \"The Golden Age of Software Architecture\" Paul Clements and Mary Shaw reviewed the emergence of software architecture as the principled understanding of the large-scale structures of software systems. Here they reflect on progress since that article, updating the state of practice and reassessing some of the opportunities.", "num_citations": "62\n", "authors": ["623"]}
{"title": "Finding predictors of field defects for open source software systems in commonly available data sources: A case study of openbsd\n", "abstract": " Open source software systems are important components of many business software applications. Field defect predictions for open source software systems may allow organizations to make informed decisions regarding open source software components. In this paper, we remotely measure and analyze predictors (metrics available before release) mined from established data sources (the code repository and the request tracking system) as well as a novel source of data (mailing list archives) for nine releases of OpenBSD. First, we attempt to predict field defects by extending a software reliability model fitted to development defects. We find this approach to be infeasible, which motivates examining metrics-based field defect prediction. Then, we evaluate 139 predictors using established statistical methods: Kendall's rank correlation, Pearson's rank correlation, and forward AIC model selection. The metrics we\u00a0\u2026", "num_citations": "57\n", "authors": ["623"]}
{"title": "On the number of multiplications for the evaluation of a polynomial and some of its derivatives\n", "abstract": " A family of new algorithms is given for evaluating the first m derivatives of a polynomial. In particular, it is shown that all derivatives may be evaluated in 3n - 2 multiplications. The best previous result required 1/2n(n + 1) multiplications. Some optimality results are presented.", "num_citations": "55\n", "authors": ["623"]}
{"title": "The role of design spaces\n", "abstract": " A central task in design is deciding what artifact will best satisfy the client's needs, whether that requires creating an artifact or choosing from existing alternatives. A design space identifies and organizes the decisions that must be made, together with the alternatives for those decisions, thereby providing guidance for creating artifacts or a framework for comparing them. The Studying Professional Software Design workshop studied three pairs of professional software designers sketching designs for a traffic signal simulator. A discussion of the design space for the simulation task shows how this design space enables comparison of the designs. It also illustrates the benefits of explicitly considering the design space during design and the risks of failing to do so.", "num_citations": "52\n", "authors": ["623"]}
{"title": "Deciding what to design: Closing a gap in software engineering education\n", "abstract": " Software has jumped \u201cout of the box\u201d \u2013 it controls critical systems, pervades business and commerce, and infuses entertainment, communication, and other everyday activities. These applications are constrained not only by traditional capability and performance considerations but also by economic, business, market and policy issues and the context of intended use. The diver sity of applications requires adaptability in responding to client needs, and the diversity of clients and contexts requires the ability to discriminate among crite ria for success. As a result, software designers must also get out of their boxes: in addition to mastering classical software development skills, they must master the contextual issues that discriminate good solutions from merely competent ones. Current software engineering education, however, remains largely \u201cin the box\u201d: it neglects the rich fabric of issues that lie between the\u00a0\u2026", "num_citations": "52\n", "authors": ["623"]}
{"title": "Forecasting field defect rates using a combined time-based and metrics-based approach: a case study of OpenBSD\n", "abstract": " Open source software systems are critical infrastructure for many applications; however, little has been precisely measured about their quality. Forecasting the field defect-occurrence rate over the entire lifespan of a release before deployment for open source software systems may enable informed decision-making. In this paper, we present an empirical case study often releases of OpenBSD. We use the novel approach of predicting model parameters of software reliability growth models (SRGMs) using metrics-based modeling methods. We consider three SRGMs, seven metrics-based prediction methods, and two different sets of predictors. Our results show that accurate field defect-occurrence rate forecasts are possible for OpenBSD, as measured by the Theil forecasting statistic. We identify the SRGM that produces the most accurate forecasts and subjectively determine the preferred metrics-based prediction\u00a0\u2026", "num_citations": "51\n", "authors": ["623"]}
{"title": "an introduction to sofware architecture\n", "abstract": " An Introduction to Software Architecture By David Garlan & Mary Shaw \u2013 94 Page 1 WATERLOO CHERITON SCHOOL OF COMPUTER SCIENCE An Introduction to Software Architecture By David Garlan & Mary Shaw \u2013 94 CS 446/646 ECE452 May 16th, 2011 IMPORTANT NOTICE TO STUDENTS These slides are NOT to be used as a replacement for student notes. These slides are sometimes vague and incomplete on purpose to spark a class discussion Page 2 2011-05-04 CS446/646 ECE452 2 WATERLOO CHERITON SCHOOL OF COMPUTER SCIENCE Motivation Software Systems \u25cf are more complex & bigger \u25cf are not just about \u201calgorithms\u201d anymore Challenges \u2013 structural issues \u2013 communication (type, protocol) \u2013 synchronization \u2013 data access & manipulation \u2013 deployment \u2013 performance \u2013 testing Which ones of these issues are more important than the others? Page 3 2011-05-04 CS446/646 ECE452 \u2026", "num_citations": "51\n", "authors": ["623"]}
{"title": "Toward boxology: Preliminary classification of architectural styles\n", "abstract": " Software archifecfs use a number of commonlyrecognized \u201cstyles\u201d fo guide fheir design of system sfrucfures. We are beginning fo classify these sfyles. We use a fwo-dimensional classification sfrafegy wifh confrol and data issuesas fhedominanf organizingaxes. Weposition the major sfyles within this space and use finer-grained discriminations fo elaborate variafions on the sfyles. This provides a fiameworkfor organizing design guidance.", "num_citations": "50\n", "authors": ["623"]}
{"title": "Software Engineering for the 21st Century: A basis for rethinking the curriculum\n", "abstract": " Progress in both software and hardware technology over the past decade make it timely to re-examine our curriculum in software engineering and related topics. This manifesto describes the Carnegie Mellon approach to software engineering, the essential capabilities of a software engineer, and the pedagogical principles that guide our curriculum design.Our objective here is to articulate Carnegie Mellon's core academic values for the discipline of software engineering. This characterization of software engineering covers undergraduate, professional, and research curricula. It is informed by other software engineering curriculum designs, but it is independent of them. Curriculum design must reconcile the objectives of numerous stakeholders; this document states the case of the academic-values stakeholder.", "num_citations": "49\n", "authors": ["623"]}
{"title": "Continuing prospects for an engineering discipline of software\n", "abstract": " In her 1990 IEEE Software article \"Prospects for an Engineering Discipline of Software\" (Nov./Dec, pp. 15-24), Mary Shaw identified the key areas that the software development profession must address to become a true engineering discipline. That classic article made the magazine's 25th anniversary top picks list (Jan./Feb. 2009, pp. 9-11). Here, Mary reflects on the evolution of her thinking since the publication of \"Prospects\". The paper dealt with the topics of: programming progress; beyond programming; management of the software production; and progress toward an engineering discipline.", "num_citations": "40\n", "authors": ["623"]}
{"title": "The Software Engineering Institute: Bridging Practice and Potential\n", "abstract": " As a leading consumer of software systems, the US Department of De-fense is among those groups most con-cerned with developingmeans through which the software industry can increase its ability to produce systems in keeping with productivity and quality requirements. Such concerns are not limited to the software product; they are germane to every phase of the software development and support process. Over the past several years, the Department of Defense has taken on a key role in improving the state of the practice through its software initiative,'creases in the size andcomplexity of both development and maintenance which supports the Software Technol-software systems have made those arelargelylabor-related, yetthe supply ogy for Adaptable Reliable Systems problems more apparent. Today, soft-of computer professionals in the counprogram, the Ada Joint Program Of-ware is perceived as a\u00a0\u2026", "num_citations": "40\n", "authors": ["623"]}
{"title": "The impact of modelling and abstraction concerns on modern programming languages\n", "abstract": " The major issues of modern software are its size and complexity, and its major problems involve finding effective techniques and tools for organization and maintenance. This chapter traces the important ideas of modern programming languages to their roots in the problems and languages of the past decade and shows how these modern languages respond to contemporary problems in software development. Modern programming\u2019s key concept for controlling complexity is abstraction \u2014 that is, selective emphasis on detail. New developments in programming languages provide ways to support and exploit abstraction techniques.", "num_citations": "40\n", "authors": ["623"]}
{"title": "A formal system for specifying and verifying program performance\n", "abstract": " Formal techniques for specifying performance properties of programs (eg, execution time) and for verifying the correctness of these specifications are developed. These techniques are extensions of well-known predicate transformer techniques for specifying and verifying purely functional properties of programs.", "num_citations": "38\n", "authors": ["623"]}
{"title": "Making choices: A comparison of styles for software architecture\n", "abstract": " Good engineering practice solves problems not only by applying scientific techniques but also by making design choices that reconcile conflicting requirements. We are interested here in design of the overall organizations and system-level properties of software systems\u2014that is, their architectures. Early decisions about design strategies can have far-reaching consequences, because they shape the analysis of the problem and the expression of the design. This paper explores the consequences of one of the earliest decisions, the choice of architectural style and its associated notations. The paper shows how different architectural styles lead not simply to different designs, but to designs with distinctly\u2014and significantly\u2014different properties. I examine eleven different published designs for\" the same\" problem (automobile cruise control), classify and compare the approaches, and discuss major differences among the\u00a0\u2026", "num_citations": "37\n", "authors": ["623"]}
{"title": "Descartes: a programming-language approach to interactive display interfaces\n", "abstract": " This paper shows how the principles of programming methodology and language design can help solve the problem of specifying and creating interactive display interfaces for software systems. Abstraction techniques, such as abstract data types, can support both the specification of display interfaces and the implementation of those interfaces in a variety of styles. These abstraction techniques also guide the organization of software systems that will use display interfaces. We are developing a system that includes specifications, interface description tools, prototype organizations, and runtime support. The emphasis is on flexibility and on the separation of policy from particular instances. Preliminary results from implementations in a prototype domain indicate the feasibility of the approach.", "num_citations": "37\n", "authors": ["623"]}
{"title": "We can teach software better\n", "abstract": " In recent issues of CRN, Bill Wulf and Dave Patterson ask some questions about undergraduate computer science programs: Are we teaching the best content in the best way? Can we do so without fragmenting the discipline or creating administrative obstacles?[Wulf 91, Patterson 92] As they observe, the last two decades have seen radical changes in hardware technology, networking, system interconnection, and sophisticated applications, but our curricula generally ignore these changes. Further, software production problems lead the list of problems in developing computer applications. Wulf and Patterson ask why our current programs don't teach these improved technologies to the students who will need to apply them.I would like to look specifically at education in software development: programming, programmed systems, and the engineering of software. This is not the whole of computer science, but it includes a large share. The typical software curriculum features dinosaur courses, classroom presentations that don't use new technology, naive approaches to software development, innocence of engineering design considerations, a severe shortage of examples relevant to anyone but a systems programmer, and ignorance of the system context of most useful software.", "num_citations": "35\n", "authors": ["623"]}
{"title": "Everyday dependability for everyday needs\n", "abstract": " Everyday software must be sufficiently dependable for the needs of everyday people. Everyday people can usually intervene when software misbehaves, and problems with their software are usually irritating but not catastrophic. Everyday software must thus provide cost-effective service with reasonable amounts of human attention. Dependability for these everyday needs arises from matching dependability levels to actual needs, achieving reasonably low failure rates at reasonable cost, providing understandable mechanisms to recognize and deal with failure, and enabling creation of individually-tailored systems and configurations from available resources. This leads to different challenges from mission-critical systems that operate autonomously and risk catastrophic failure. Much everyday software depends on inexpensive or free information resources available dynamically over the Internet or through retail channels. Much of this software runs on mobile devices with limited power. Increasingly, it is composed by its users rather than by professionals, and the resulting software uses information resources in ways that the resources' creators could not anticipate. In the near future user-managed configurations will have to interact acceptably with configurations managed by other users. Software development in this setting requires methods that tolerate incomplete knowledge, pursue value rather than simply capability, and base reasoning on aggregate rather than fullydetailed information. We will identify research challenges that arise from the need for everyday dependability and give examples of current Carnegie Mellon research that addresses\u00a0\u2026", "num_citations": "34\n", "authors": ["623"]}
{"title": "Component-based software engineering and the issue of trust\n", "abstract": " Software component consumers are entitled to trusted components. This panel addresses the criteria for trusted components and presents generally accepted definitions for all terms used to describe both software components and the methods and processes required to verify trusted software components.", "num_citations": "33\n", "authors": ["623"]}
{"title": "Advancing software engineering professional education\n", "abstract": " JULY/AUGUST 2011| IEEE SOFTWARE 59 what US-centric focus, but many of the activities it depicts were international in scope. We also recognize that significant contributions to the advancement of SE education occurred throughout the world, particularly in the development and accreditation of software educational programs in Canada, Mexico, Europe, Australia, Asia, and South America.\u201cGraduate Software Engineering 2009 (GSwE2009): Curriculum Guidelines for Graduate Degree Programs in Software Engineering\u201d is a recently developed set of curriculum guidelines for master\u2019s programs. 9 A group of SE educators and practitioners developed GSwE2009 as part of the Integrated Software & Systems Engineering (ISSEC) curriculum project at Stevens Institute of Technology. An underlying focus of GSwE2009 is how to advance the state of SE practice and support a better understanding and agreement about the nature of professional software engineers.", "num_citations": "30\n", "authors": ["623"]}
{"title": "An approach for categorizing end user programmers to guide software engineering research\n", "abstract": " Over 64 million Americans used computers at work in 1997, and we estimate this number will grow to 90 million in 2012, including over 55 million spreadsheet and database users and 13 million self-reported programmers. Existing characterizations of this end user population based on software usage provide minimal guidance on how to help end user programmers practice better software engineering. We describe an enhanced method of characterizing the end user population, based on categorizing end users according to the ways they represent abstractions. Since the use of abstraction can facilitate or impede achieving key software engineering goals (such as improving reusability and maintainability), this categorization promises an improved ability to highlight niches of end users with special software engineering capabilities or struggles. We have incorporated this approach into an in-progress survey of end\u00a0\u2026", "num_citations": "30\n", "authors": ["623"]}
{"title": "Intelligently creating and recommending reusable reformatting rules\n", "abstract": " When users combine data from multiple sources into a spreadsheet or dataset, the result is often a mishmash of different formats, since phone numbers, dates, course numbers and other string-like kinds of data can each be written in many different formats. Although spreadsheets provide features for reformatting numbers and a few specific kinds of string data, they do not provide any support for the wide range of other kinds of string data encountered by users. We describe a user interface where a user can describe the formats of each kind of data. We provide an algorithm that uses these formats to automatically generate reformatting rules that transform strings from one format to another. In effect, our system enables users to create a small expert system called a\" tope\" that can recognize and reformat instances of one kind of data. Later, as the user is working with a spreadsheet, our system recommends appropriate\u00a0\u2026", "num_citations": "29\n", "authors": ["623"]}
{"title": "A comparison of programming languages for software engineering\n", "abstract": " Four programming languages (Fortran, Cobol, Jovial and the proposed DoD standard) are compared in the light of modern ideas of good software engineering practice. The comparison begins by identifying a core for each language that captures the essential properties of the language and the intent of the language designers. These core languages then serve as a basis for the discussion of the language philosophies and the impact of the language on gross program organization and on the use of individual statements.", "num_citations": "29\n", "authors": ["623"]}
{"title": "Architectural requirements for computing with coalitions of resources\n", "abstract": " Widespread use of the Internet is enabling a fundamentally new approach to software development: computing through dynamically formed, task-specific, coalitions of distributed autonomous resources. The resources may be information, calculation, communication, control, or services. Unlike traditional software systems, the coalitions lack direct control over the incorporated resources, which are independently created and managed. Moreover, the resources may be transient, either because of the resource manager\u2019s actions or because of service interruptions. Development tools for resource coalitions will require new degrees of autonomy and automation in order to identify, compose, and track the resources. An economically viable reward structure will be required to establish a rich population of available resources. Evaluation will require new models of adequacy rather than classical full correctness. Computing through resource coalitions will thus create novel architectural challenges and opportunities.", "num_citations": "28\n", "authors": ["623"]}
{"title": "An approach to preserving sufficient correctness in open resource coalitions\n", "abstract": " Most software that most people use most of the time needs only moderate assurance of fitness for its intended purpose. Unlike high-assurance software, where the severe consequences of failure justify substantial investment in validation, everyday software is used in settings in which occasional degraded service or even failure is tolerable. Unlike high-assurance software, which has been the subject of extensive scrutiny, everyday software has received only meager attention concerning how good it must be, how to decide whether a system is sufficiently correct, or how to detect and remedy abnormalities. The need for such techniques is particularly strong for software that takes the form of open resource coalitions - loosely-coupled aggregations of independent distributed resources. We discuss the problem of determining fitness for purpose, introduce a model for detecting abnormal behavior, and describe some of\u00a0\u2026", "num_citations": "27\n", "authors": ["623"]}
{"title": "An input-output model of interactive systems\n", "abstract": " Interactive user interfaces depend critically on underlying computing system facilities for input and output. However, most computing systems still have input-output facilities designed for batch processing. These facilities are not adequate for interfaces that rely on graphical output, interactive input, or software constructed with modern methodologies. This paper details the deficiencies of batch-style input-output for modern interactive systems, presents a new model for input-output that overcomes these deficiencies, and suggests software organizations to take advantage of the new model.", "num_citations": "25\n", "authors": ["623"]}
{"title": "Time is Not Money\n", "abstract": " \" Time is money\", or so goes the old saying. Perhaps influenced by this aphorism, some strategies for incorporating costs in the analysis of software design express all costs in currency units for reasons of simplicity and tractability. Indeed, in theoretical economics all costs can, in principle, be expressed in dollars. Software engineering problems, however, often present situations in which converting all costs to a common currency is problematical. In this paper we pinpoint some of these situations and the underlying causes of the problems, and we argue that it is often better to treat costs as a multidimensional value, with dimensions corresponding to distinct types of resources. We go on to highlight the differences among cost dimensions that need to be considered when developing cost-benefit analyses, and we suggest mechanisms for mediating among heterogeneous cost dimensions.", "num_citations": "23\n", "authors": ["623"]}
{"title": "Beyond programming-in-the-large: The next challenges for software engineering\n", "abstract": " As society's dependence on computing broadens, software engineering is being called upon to address new problems that raise new technical and nontechnical concerns. Aspirations and expectations for the application of computers appear to be unbounded, but present software development and support techniques will not be adequate to build computational systems that satisfy our expectations, even at very high cost. Each order-of-magnitude increase in the scale of the problems being solved leads to a new set of critical problems that require essentially new solutions. The next challenges for software engineering will deal with software as one of many elements in complex systems, which we call program-as-component, and with the role of software as an active participant in the software development process, which we call program-as-deputy.", "num_citations": "23\n", "authors": ["623"]}
{"title": "Informatics for a new century: computing education for the 1990s and beyond\n", "abstract": " Information Technology and computer science have not only reshaped computation, communication and commerce; they have expanded the basic models and paradigms of many disciplines. Informatics education has obligations to all the communities that rely on information technology, not just the computing professionals. Serving this extended audience well requires changes in the content and presentation of computing curricula. This paper sketches the coming needs for information processing and analyzes the populations that will require informatics education. It considers curriculum requirements through two examples, one outside the traditional boundary of computer science and one inside.", "num_citations": "22\n", "authors": ["623"]}
{"title": "Software architectures for shared information systems\n", "abstract": " Software system design takes place at many levels, each with its own Cancern*. We learn from computer hardware design that each of these \u0426\u044f\u0429:;; has its own elements and composition operator\u00bb and its own notations, analysis toob, and design rules. From the 1960s through the 1980s! developers concentrated on the programming level. At this level, t higher level programming languages provide for die definitions of algorithms and data structures using the familiar programming language control statements, types, and procedures. Now we are turnin \u0430\u0438\u0435\u0446| \u043a\u0437& to the architectural level, in which patterns for organizing module-scafe componenu guide software system design.", "num_citations": "21\n", "authors": ["623"]}
{"title": "Sufficient correctness and homeostasis in open resource coalitions\n", "abstract": " Proving system correctness is tough. It can fail, or succeed, or just bluff. When the parts come and go You may never quite know\u2026 Can you tell when just \u201cgood\u201d is enough?", "num_citations": "20\n", "authors": ["623"]}
{"title": "Tyrannical Languages *Still* Preempt System Design\n", "abstract": " It is a prime tenet of most programming language design that \u201chigher-level\u201d languages are a good thing--indeed the higher the level, the better. The assumption is that the higher the level of the language--the more abstract the abstractions--the greater the leverage provided to the programmer. The language designer usually ensures that the higher-level constructs capture his intention by completely specifying the associated semantics.A decade ago, we challenged the \u201chigher-level is better\u201d assumption. The paper in which we did this has largely been ignored. Perhaps it should have been, but we don\u2019t think so. In fact we see this apparently benign assumption as aggressively interfering with good application design. Unfortunately, the consequences of blind adherence to this tenet are spreading in both current language proposals and larger system designs.", "num_citations": "20\n", "authors": ["623"]}
{"title": "The \u201855m end-user programmers\u2019 estimate revisited\n", "abstract": " In 1995, Boehm predicted that by 2005, there would be \u201c55 million performers\u201d of \u201cend-user programming\u201d in the United States. Examining the original context and method which generated this number reveals that it actually estimates the number of computer users in businesses\u2014not programmers, per se\u2014and it assumes constant computer usage rates. This paper extends Boehm\u2019s estimate using fresh Bureau of Labor Statistics (BLS) data, including the latest BLS occupational projections (which are for 2012), and a richer estimation method.We estimate that in 2012, there will be 90 million end-users in American workplaces. Of these, we anticipate that over 55 million will use spreadsheets or databases (and therefore will be potential end-user programmers), while over 13 million will describe themselves as programmers. Thus, the potential pool of end-user programmers will probably substantially exceed the population who view themselves as programmers. Each of these estimates, in turn, substantially exceeds the latest BLS projections of fewer than 3 million professional programmers in 2012.", "num_citations": "19\n", "authors": ["623"]}
{"title": "Cheating policy in a computer science department\n", "abstract": " 1. Backgroun dThe primary objective of any course should be to teac h information and skills to the students. However, the nature of th e University imposes an additional obligation to evaluate th e performance of each student and to report his mastery of th e material via a grade. A variety of pressures divert students' attention from the knowledge to the grades; occasionally thi s leads to attempts to obtain grades by cheating instead of learning.", "num_citations": "19\n", "authors": ["623"]}
{"title": "The potential for synergy between certification and insurance\n", "abstract": " Because of their affordability and availability, reusable software components have long been a tantalizing IT investment. However, the risks associated with uncertainties about technical attributes and lack of protection against undesirable behaviors often deters their adoption. Certification and insurance are potential approaches to managing these risks. Probabilistic certification and insurance base their predictions and products on similar kinds of data this offers the prospect of consistency 1by using the same data for both and cost-effectiveness by reusing the data. The combined benefits of the two methods in the form of risk reduction and lowering of variance may make software reuse investments more attractive to risk-averse companies.Descriptors:", "num_citations": "18\n", "authors": ["623"]}
{"title": "Toward a scientific basis for software evaluation\n", "abstract": " An examination of the general practice of science, and in particular the interaction of experiment and analysis to generate structurally based system models, suggests a paradigm for the development of a science of software evaluation. We present a view of the development of structured models that is appropriate to software evaluation. We suggest research problems and research techniques which can lead to improvement in software measurement and evaluation methods.", "num_citations": "18\n", "authors": ["623"]}
{"title": "Trial by water: creating Hurricane Katrina \u201cperson locator\u201d web sites\n", "abstract": " We interviewed six people who led teams that created web sites enabling Hurricane Katrina survivors to report their status. We learned that interviewees did not discover and communicate with other teams when they started their projects, which resulted in redundant sites. The absence of a shared task impeded trust between teams, ultimately inhibiting data collection and aggregation. Moreover, communication within teams was problematic; developers who had adequate technical skills to work alone were more positive about their sites\u2019 success compared to developers who had to shore up skill weaknesses through collaboration. These problems did not simply result from team leaders\u2019 oversized egos because site creators were generally motivated by concern for other people instead of self-interest. Rather, these problems highlight the need for improved development methods and systems to help developers\u00a0\u2026", "num_citations": "17\n", "authors": ["623"]}
{"title": "Three Patterns that help explain the development of Software Engineering\n", "abstract": " The term \u201csoftware engineering\u201d came to prominence when it was used as the name of a NATO workshop in 1968 [NaRan69]. It was used then to draw attention to software development problems. It was then, as to a large extent it remains now, a phrase of aspiration, not of description. In the intervening years, the focus of the academic community (though not so much the industrial software development community) has shifted from simply writing programs to analyzing and reasoning about large distributed systems of software and data the come from diverse sources. Figure 1 lays out the highlights of these shifts.", "num_citations": "16\n", "authors": ["623"]}
{"title": "Computer Analysis of Chronological Seriation. Frank Hole and Mary Shaw. Rice University Studies Vol. 53, No. 3, Houston, 1967. 166 pp., 33 figs., 25 tables, 5 appendixes. $2.25.\n", "abstract": " //static.cambridge.org/content/id/urn%3Acambridge.org%3Aid%3Aarticle%3AS0002731600094221/resource/name/firstPage-S0002731600094221a.jpg", "num_citations": "16\n", "authors": ["623"]}
{"title": "Using topes to validate and reformat data in end-user programming tools\n", "abstract": " End-user programming tools offer no data types except\" string\" for many categories of data, such as person names and street addresses. Consequently, these tools cannot automatically validate or reformat these data. To address this problem, we have developed a user-extensible model for string-like data. Each\" tope\" in this model is a user-defined abstraction that guides the interpretation of strings as a particular kind of data. Specifically, each tope implementation contains software functions for recognizing and reformatting instances of that tope's kind of data. This makes it possible at runtime to distinguish between invalid data, valid data, and questionable data that could be valid or invalid. Once identified, questionable and/or invalid data can be double-checked and possibly corrected, thereby increasing the overall reliability of the data. Valid data can be automatically reformatted to any of the formats appropriate\u00a0\u2026", "num_citations": "15\n", "authors": ["623"]}
{"title": "Software risk management and insurance\n", "abstract": " How can we promote reuse of code, data and services? How can we make it easier to combine on-line resources to perform specific tasks? One serious impediment is the risk of relying on software that you do not control, especially the difficulty of determining whether the software is dependable enough for the specific task at hand. We concentrate on one form of economic risk mitigation, insurance, and explore its suitability for the software domain we are interested in. After reviewing the basic principles of insurance we present some feasible directions for dealing with software related issues and raise some software engineering research challenges.", "num_citations": "15\n", "authors": ["623"]}
{"title": "Research toward an engineering discipline for software\n", "abstract": " Software engineering should aspire to be a true engineering discipline. We have made good progress in some areas, but a number of aspects of practical engineering are under-represented in our research portfolio. We have been slow to move beyond well-delimited systems developed by professional programmers to systems integrated from multiple public sources that evolve in the hands of their users. We have focused on formal reasoning and systematic testing to the detriment of qualitative and incremental reasoning supporting cost-effective, rather than perfect solutions. We have been slow to codify our results into unified theories and practical reference material. To establish a true engineering discipline for software, we need to broaden our view of what constitutes a\" software system\" and we need to develop techniques that help to provide cost-effective quality despite associated uncertainties.", "num_citations": "14\n", "authors": ["623"]}
{"title": "Software mythbusters explore formal methods\n", "abstract": " In 1990, Anthony Hall identified and challenged seven common myths about formal methods in the IEEE Software article \"Seven Myths of Formal Methods.\" This update re-examines those myths, reflecting both on the authors' experience with formal methods in practice and on their persistent mythic status", "num_citations": "14\n", "authors": ["623"]}
{"title": "Toward a calculus of confidence\n", "abstract": " Programmers, and end-user programmers in particular, often have difficulty evaluating software, data, and communication components for reuse in new software systems, which effectively reduces the value programmers derive from those components. End-user programmers are especially ill equipped to exercise the customary high-ceremony means of evaluating software quality. We seek effective ways to use low-ceremony sources of evidence, such as online reviews and reputation data, to make components' quality attributes easier to establish, thereby facilitating more effective selection of components for reuse. Achieving this will require identifying sources of low-ceremony evidence, designing the meta-information required to track the differing sources and levels of credibility of various sources of evidence, and developing a method for combining pieces of disparate information into overall estimates of\u00a0\u2026", "num_citations": "13\n", "authors": ["623"]}
{"title": "Incorporating nontechnical attributes in multi-attribute analysis for security\n", "abstract": " The most obvious considerations that affect an organization's choice of security technologies are the threats the organization considers significant and the costeffectiveness of various security technologies against those threats. In practice, however, the choice is also strongly driven by less tangible, more nontechnical, considerations such as ease of implementation and maintenance, fit with organizational culture, or intuitive appeal to security personnel. We originally designed the Security Attribute Evaluation Method (SAEM) to respond to the former considerations. As SAEM has evolved, its multi-attribute risk elicitation and sensitivity analysis also address the latter considerations by helping security engineers make consistent judgements, focus on the highest points of leverage, and understand the implications of potential changes. As a result, the benefit of the method lies not only in its recommendations, but also in its ability to sharpen the security engineers' understanding of their needs and options.", "num_citations": "13\n", "authors": ["623"]}
{"title": "Chapter\n", "abstract": " Software designers rely on informal patterns, or idioms, to describe the architectures of their software systems\u2014the configurations of components that make up the systems. At the first PLoP, I identified seven patterns that guide high-level system design and discussed the way they guide the composition of systems from particular types of components [Shaw 95]. This paper extends the descriptions of those patterns (plus one) in response to the discussion at the conference. Most significantly, it adds information on the kinds of problems each pattern handles best. Software designers describe overall system architectures using a rich vocabulary of abstractions. Although the descriptions and the underlying vocabulary are imprecise and informal, designers nevertheless communicate with some success. They depict the architectural abstractions both in pictures and words.\u201cBox-and-line\u201d diagrams often illustrate system structure. These diagrams use different shapes to suggest structural differences among the components, but they make little discrimination among the lines\u2014that is, among different kinds of interactions. The architectural diagrams are often highly specific to the systems they describe, especially in the labeling of components.", "num_citations": "13\n", "authors": ["623"]}
{"title": "An Assessment of Software Engineering Body of Knowledge Efforts\n", "abstract": " In May 1999 the ACM Council adopted a resolution both reaffirming ACM\u2019s commitment to solving the software quality problem and also stating its opposition to licensing software engineers, on the grounds that licensing is premature and would be ineffective in addressing the software quality problem. ACM Council also affirmed its interest in developing a core body of knowledge for software engineering, which is often viewed as an appealing step toward improving software quality. Our committee was formed to study the existing software engineering body of knowledge efforts\u2014including SWEBOK, with which ACM is involved through the joint IEEE CS/ACM Software Engineering Coordinating Committee (SWECC). Our charge was to determine the status, progress, and likely outcome of these efforts. This report documents our findings, our reasoning, and our conclusions.", "num_citations": "13\n", "authors": ["623"]}
{"title": "Lessons on converting batch systems to support interaction: experience report\n", "abstract": " Software often evolves from batch to interactive use. Because these two usage styles are so different, batch systems usually require substantial changes to support interactive use. Specific issues that arise during conversion include assumptions about duration of system execution, incremental and partial processing, scope of processing, unordered and repeated processing, and error handling. Addressing these issues affects the implementation in the areas of memory management, assumptions and invariants, computational organization, and error handling. We use as a working example our conversion of the batch processor. for the UniCon architecture description tool into an interactive architecture development tool. To capture the lessons for practitioners undertaking this type of conversion, we summarize with a checklist of design and implementation considerations.", "num_citations": "13\n", "authors": ["623"]}
{"title": "How Should Patterns Influence Architecture Description Languages?\n", "abstract": " The software architecture and the design pattern communities have overlapping interests. The software architecture community is chiefly concerned with structure and organization of large software systems; the patterns community with exposition of design information. These intersect in the exposition of design information at the system level. This essay lays out a framework for the software architecture community to consider (a) what new ADL capability is suggested by design patterns and (b) to what extent ADLs are appropriately carriers of pattern information, and how they should do so.", "num_citations": "13\n", "authors": ["623"]}
{"title": "When Is' Good'Enough?: Evaluating and Selecting Software Metrics\n", "abstract": " Abstract ln assessing the use of metrics for software, it is important to consider the quality of the metrics themselves. This has two components. First, we can determine some of the statistical properties of the metric itself. Second, we can assess the way a metric will be used and select one that provides appropriate information without excess expense. This note discusses some issues about the validation and efficiency of measurement techniques. lntroductionThis note addresses two questions related to the judicious use of software metrics. The first is how proposed metrics should be described and evaluated. The second is how to select metrics that are costeffective, in the sense that they strike a reasonable balance between the amount and precision of the information delivered and the cost of collecting and processing raw data. The first question is of concern to people who develop metrics. lt pertains to the criteria that should be used for evaluating metrics and the guidance that should be provided to prospective users. lt covers not only ways to state properties of individual metrics, but also ways to validate the models that underlie the metrics and ways to decide when it is appropriate to introduce new metrics. The second question is of concern to people who use metrics. lt pertains to criteria for deciding when imprecise measures offer good enough results\u2014that is, to ways to determine the cost-effectiveness of a metric. Many people succumb to the temptation to demand as much detail as technologically possible, neglecting the costs which arise from", "num_citations": "13\n", "authors": ["623"]}
{"title": "Language design for the Ironman requirement: reference manual\n", "abstract": " Tartan is an experiment in language design. The goal was to determine whether a \"simple\" language could meet substantially all of the Ironman requirement for a common high-order programming language.We undertook this experiment because we believed that all the designs done in the first phase of the DOD effort were too large and too complex. We saw that complexity as a serious failure of the designs: excess complexity in a programming language can interiere with its use, even to the extent that any beneficial properties are of little consequence. We wanted to find out whether the requirements inherently lead to such complexity or whether a substantially simpler language would suffice.Three ground rules drove the experiment. First, no more than two months -- April 1 to May 31 -- would be devoted to the project. Second, the language would meet all the Ironman requirements except for a few points at which it\u00a0\u2026", "num_citations": "12\n", "authors": ["623"]}
{"title": "Modularity for the modern world: summary of invited keynote\n", "abstract": " Aspect-oriented software development is motivated by the desire to localize definitions of independent concerns in the software. Localized definitions are a form of modularity that achieve separation of concerns in the design, but the non-hierarchical character of the concerns creates structure clashes with the hierarchical modular constructs in conventional programming languages. Aspect-oriented modularity achieves the benefits of localized definitions, but at the costs of complexity both in the tools that weave the aspects into code and in the task of understanding the interactions among definitions.", "num_citations": "11\n", "authors": ["623"]}
{"title": "In search of a unified theory for early predictive design evaluation for software\n", "abstract": " Traditional engineering design discipline calls for designs to be evaluated long before they are implemented. Early design evaluations predict properties of the artifact that will result from a proper implementation of the design and the value of those properties to the client or end user. The predicted properties can include costs as well as functionality, performance, and quality measures. Software engineering has some such evaluation techniques but the discipline lacks a systematic way to explain, compare, develop, and apply them. We discuss the role of early predictive design evaluation in software design, show how a variety of specific predictors serve this role, and propose a unifying framework, Predictive Analysis for Design (PAD) for design evaluation techniques. We are especially interested in techniques that predict the value of the finished software system to its client or end user and that make the predictions before the expense of software development or integration is incurred. We show that our PAD framework, even in its preliminary state, is sufficiently expressive to be useful in explaining and characterizing design evaluation techniques. We argue that the PAD framework shows sufficient promise to justify further development toward a unified theory of early predictive design evaluation.", "num_citations": "11\n", "authors": ["623"]}
{"title": "A twenty year retrospective of the NATO software engineering conferences (panel session) remembrances of a graduate student\n", "abstract": " Different method calls may have different contributions to the precision of the final application when abstracted into the call strings. The existing call string based pointer analysis algorithms do not consider such contribution difference and hence often can not achieve best cost-effectiveness. To solve the problem, this paper firstly proposes a contribution-based call stack abstraction method which abstracts the call stacks to the call strings with the contribution information under consideration. Then, we apply the new call stack abstraction method to the pointer analysis of AspectJ programs and propose a concern-sensitive points-to analysis method. The concern-sensitive points-to analysis is more cost-effective than the ordinary call string based approaches for an application that detects harmful advices. It more concretely and more clearly shows that the contribution-based call stack abstraction can lead to better cost\u00a0\u2026", "num_citations": "11\n", "authors": ["623"]}
{"title": "\" What Can We Specify? Questions in the Domains of Software Specifications\n", "abstract": " Formal specifications customarily deal exclusively with the domain of functional properties of software.  However, other domians are of interest to software desginers and developers.  Two particular areas of concern for practical software development are not yet well-served by formal specifications.  This note raises issues about how those areas might be better served.", "num_citations": "11\n", "authors": ["623"]}
{"title": "Progress toward an engineering discipline of software\n", "abstract": " Is \"software engineering\" really engineering? The term was coined in 1968 to call attention to problems with software production. Both theory and practice for software have evolved since then, but do we yet have a true engineering discipline? This keynote sketches the evolution of software engineering, drawing on civil engineering and software architecture for examples that show the progressive codification of informal knowledge toward rigorous models and tools. This provides the basis for assessing the maturity of the field and identifying our next challenges.", "num_citations": "10\n", "authors": ["623"]}
{"title": "What's the value proposition of distance education?\n", "abstract": " BackgrOuNdConsiderable attention has been given recently to the online offerings such as edX and Coursera by prestigious universities such as MIT, Stanford, and Harvard. Those offerings are typically wrapped in words such as \u2018expert\u2019and \u2018world class\u2019. But here\u2019s the rub: if a job candidate came to you and said he or she had watched an assortment of TED lectures and passed some automated tests, would you trust that the candidate was educated? Marian ran a straw poll on that question at ICSE, at a recent social gathering, and at the local pub, and the reply was resoundingly \u2018no\u2019\u2013except in the few cases when it was \u2018well, that depends on what else the student does\u2019, and further criteria were suggested.We discussed this at ICSE, and Mary suggested considering the \u2018value proposition\u2019, a business notion that identifies the value the organization promises to deliver\u2013and why the customers believe they\u2019ll receive\u00a0\u2026", "num_citations": "10\n", "authors": ["623"]}
{"title": "Fast, accurate creation of data validation formats by end-user developers\n", "abstract": " Inputs to web forms often contain typos or other errors. However, existing web form design tools require end-user developers to write regular expressions (\u201cregexps\u201d) or even scripts to validate inputs, which is slow and error-prone because of the poor match between common data types and the regexp notation. We present a new technique enabling end-user developers to describe data as a series of constrained parts, and we have incorporated our technique into a prototype tool. Using this tool, end-user developers can create validation code more quickly and accurately than with existing techniques, finding 90% of invalid inputs in a lab study. This study and our evaluation of the technique\u2019s generality have motivated several tool improvements, which we have implemented and now evaluate using the Cognitive Dimensions framework.", "num_citations": "10\n", "authors": ["623"]}
{"title": "Beyond Objects: A Software Design Paradigm Based on Process Control.\n", "abstract": " A standard demonstration problem in object-oriented programming is the design of an automobile cruise control. This design exercise demonstrates object-oriented techniques well, but it does not ask whether the object-oriented paradigm is the best one for the task Here we examine the alternative view that cruise control is essentially a control problem. We present a new software organization paradigm motivated by process control loops. The control view leads us to an architecture that is dominated by analysis of a classical feedback loop rather than by the identification of discrete stateful components to treat as objects. The change in architectural model calls attention to important questions about the cruise control task that arent addressed in an object-oriented design.Descriptors:", "num_citations": "10\n", "authors": ["623"]}
{"title": "Scaling up: a research agenda for software engineering\n", "abstract": " Large and growing opportunity costs are resulting from the inability to produce sophisticated, reliable software in a timely manner. Software engineering presents stubborn problems, but in this book, a group of experts suggest several constructive directions for research. Together, they support the need for greater interaction between researchers and practitioners and more aggressive efforts to share and reuse software engineering knowledge.", "num_citations": "10\n", "authors": ["623"]}
{"title": "Studies in Ada Style\n", "abstract": " Since the initial publication of Studies, some parts of the Ada 1 language have been changed in response to the ANSI standardization process. The second edition of Studies has been updated to conform to the latest available Ada manual [Department of Defense 82]. 2 All of our references to the Ada manual come from this document (see page 36).", "num_citations": "10\n", "authors": ["623"]}
{"title": "An Alphard Specification of a Correct and Efficient Transformation on Data Structures.\n", "abstract": " In this paper we study standard program components applicable to a wide variety of design tasks we choose for this study the specific problem domain of data structures for general search problems. Within this domain transformations for converting solutions of simple searching problems to solutions of more complex problems have been developed. We discuss one of those transformations, specify precisely the transformation and its conditions of applicability, and prove its correctness we accomplish this by casting it in terms of abstract data types--specifically by using the Alphard form mechanism. We also demonstrate that the costs of the structures derived by this transformation are only slightly greater than the costs of the original solutions. The transformation we describe has already been used to develop a number of new algorithms, and it represents a new level of generality in software engineering tools.Descriptors:", "num_citations": "10\n", "authors": ["623"]}
{"title": "Research directions in abstract data structures\n", "abstract": " A number of interesting research problems arise from current attempts to incorporate abstraction mechanisms in programming languages. Some of them are central issues in current research projects and others are direct extensions of current work. Several problems in each of these areas are outlined below. A third section presents a series of speculations about how this work might evolve in the future. Since this is supposed to be a session to spark research ideas, I have written brief descriptions of a number of topics and not delved very deeply into any one. Most of these problems can probably be solved in more than one way. Hence the fact that a problem is being worked on should not deter anyone from looking at it from another viewpoint.", "num_citations": "10\n", "authors": ["623"]}
{"title": "Elements of a design language for software architecture\n", "abstract": " Hardware design is carried out at several different levels, with different issues, models, and design strategies at each level. Thus circuits, registers, instruction sets, and architectures are designed in terms of different components combined with different operators; the analysis techniques (indeed, what is analyzed), notations, and appropriate tools are correspondingly different.", "num_citations": "9\n", "authors": ["623"]}
{"title": "Maybe your next programming language shouldn't be a programming language\n", "abstract": " Software needs now strain the design limits of traditional programming languages. Modern application needs are not satisfied by traditional programming languages, which evolved in response to systems programming needs. Current programming language research focuses on incremental improvements, not on major changes to the nature of software development. But major breakthroughs are needed in two areas: Non-programmers dominate modern computer use. Low computing costs have enabled a wide spectrum of application, and end users who are not programmers need to control their own computations. Order-of-magnitude increases in service require substantial shifts of technology. Computer users are interested in results, not in programming; software must reflect this. Requirements for large complex software systems exceed our production ability. Growth of demand is greater than growth in capacity\u00a0\u2026", "num_citations": "9\n", "authors": ["623"]}
{"title": "The Topes Format Editor and Parser\n", "abstract": " It is currently difficult and time-consuming to validate and manipulate data in web applications, so we have developed an editor and a parser to simplify these tasks. Our editor enables end-user programmers to create and debug reusable, flexible data formats without learning a complex new language. Our parser uses these formats to turn strings into structured objects and to report its level of confidence that each string is a valid instance of the format. End-user programmers can use our system to create validation code that takes a graduated response to slightly invalid data. We evaluate our system\u2019s expressiveness by defining formats for commonly-occurring web data.", "num_citations": "8\n", "authors": ["623"]}
{"title": "A software engineering project course with a real client\n", "abstract": " At Carnegie Mellon University, we taught an introductory software engineering course that was organized around a project with a real deliverable for a real client. This case study describes the background and organization of the course and presents the lecture and project materials produced by the faculty and students of the course. Carnegie Mellon University has offered a course in software engineering since the early 1970s. Although its organization and position in the curriculum have changed over the years, the course has always had the primary objective of teaching undergraduate students something about the practical problems of building real-world software--groups of people must cooperate to understand just what problem is being solved and then create and integrate a collection of software modules that solve the problem. This traditionally has been a group-project course with a lecture component. In recent years it has been a senior-level elective its prerequisites are intended to ensure that students have already studied medium-sized systems such as compilers and operating systems. Often students who select this course are considering entering the job market as software developers.Descriptors:", "num_citations": "8\n", "authors": ["623"]}
{"title": "Immigration course in computer science\n", "abstract": " The IC (Immigration Course) is a process for initializing new students into the enviromnent of the Computer Science depart_Rent at C~ J. It is an intensive six-week program intended to provide a cowmon foundation for students with diverse backgrounds. The goals of the IC are to provide each new student with:", "num_citations": "8\n", "authors": ["623"]}
{"title": "Specifying Reliability as a Software Attribute.\n", "abstract": " This paper examines come issues in specifying reliability as a software attribute. A scheme for characterizing software reliability, known as a failure profile, is introduced. Failure profiles are derived for particular implementations of an abstraction by identifying analytically the behavior of the module when software or hardware faults occur. A failure profile is developed for a sorting program to demonstrate an informal technique for identifying the consequences of faults. The derived failure profile is compared with observations of the programs behavior in the presence of artificially induced faults to demonstrate the effectiveness of the failure profile characterization of software reliability. The issues raised in the application of the informal technique are discussed with respect to developing a formal and more mechanical technique for producing and using failure profiles. AuthorDescriptors:", "num_citations": "6\n", "authors": ["623"]}
{"title": "A fundamental computer science course that unifies theory and practice\n", "abstract": " If computer programming is to become an\" engineering discipline,\" computer science students must acquire the tools for rigorous analysis and evaluation of programs. An early course in the undergraduate curriculum must introduce the fundamental principles of the discipline, just as freshman calculus teaches the basic analysis skills for most engineering disciplines. The course described in this paper teaches mathematical principles and practical programming applications in a unified form. It has been successfully taught to sophomores for four years.", "num_citations": "6\n", "authors": ["623"]}
{"title": "Reduction of Compilation Costs Through Language Contraction\n", "abstract": " Programming languages tailored to particular groups of users can often be constructed by removing unwanted features from a general purpose language. This paper describes the use of simulation techniques to predict the savings in compilation cost achievable by such an approach. The results suggest a function which describes the effect of changes in the power of a language on the compilation cost of an algorithm expressed in that language: when features not actually used by the algorithm are removed from the language, the cost of compiling the algorithm decreases moderately, but when features that are needed are removed, the compilation cost increases sharply.", "num_citations": "6\n", "authors": ["623"]}
{"title": "Software architecture education session report\n", "abstract": " In the software architecture education session, we discussed four main issues: how to make a software architecture course sufficiently realistic, how to teach non-technical competencies of software architects, the place of such a course in a university curriculum, and how to grow software architects beyond the university. The session resulted in a first sketch of software architecture knowledge areas, and the extent to which these are deemed required for certain classes of software professionals.", "num_citations": "5\n", "authors": ["623"]}
{"title": "A value-based approach to predicting system properties from design\n", "abstract": " Traditional engineering requires evaluating designs before implementing them. Evaluating a design predicts the properties of a reasonable implementation and the value of these properties to a stakeholder. Software engineering has some (though not enough) relevant evaluation techniques but lacks frameworks to compare, develop, and apply those techniques in a manner that respects h value varies by stakeholder. We present an adaptation of economists' value models that, given a design and a development method, predicts value to a client. We give examples supporting our approach. Even in its preliminary state, our approach helps to explain and characterize design evaluation techniques and shows sufficient promise to justify further development.", "num_citations": "5\n", "authors": ["623"]}
{"title": "Anticipatory configuration of resource-aware applications\n", "abstract": " We propose an improved approach to dynamic configuration of resource-aware applications. The new anticipatory model of configuration maximizes utility based on three inputs: user preferences, application capability profiles, and resource availability. In this respect, the proposed model is similar to a model of configuration described in [2]. However, the latter addresses the dynamic nature of the problem by reacting to changes (such as decrease in resource availability), and maximizes the utility in a point-wise manner. The newly proposed anticipatory approach explicitly models the duration of the task and leverages possible information about the future (such as stochastic resource availability over the expected duration of the task).We expect that the anticipatory model will improve user's utility, conserve scarce resources, and reduce the amount of disruption to the user resulting from changes when compared to\u00a0\u2026", "num_citations": "5\n", "authors": ["623"]}
{"title": "Computer Science: Reflections on the Field, Reflections from the Field\n", "abstract": " Computer Science: Reflections on the Field, Reflections from the Field https://s3-eu-west-1.amazonaws.com/876az-branding-figshare/cmu/logo_header.png Browse Cite Download Share Embed Computer Science: Reflections on the Field, Reflections from the Field 2004-01-01T00:00:00Z (GMT) by Mary Shaw Institute for Software Research Categories Computer Software not elsewhere classified Keyword(s) Software Research License In Copyright Export RefWorks BibTeX Endnote DataCite NLM DC Hide footer About How to Deposit Preparing Data DMP Tool Deposit Support Contact Deposit Agreement Terms Privacy Tools FAQs Disclaimer Sitemap figshare. credit for all your research. About How to Deposit Preparing Data DMP Tool Deposit Support Contact Deposit Agreement Terms Privacy Tools FAQs Disclaimer Sitemap figshare. credit for all your research. \u2026", "num_citations": "5\n", "authors": ["623"]}
{"title": "Software engineering body of knowledge (SWEBOK)(panel session)\n", "abstract": " The goals of the SWEBOK project has been to develop a topical guide to the body of knowledge (BoK) supporting the discipline of software engineering. The project, sponsored by IEEE Computer Society, is over three years old and is nearing completion of its third and final stage. However, there has been some disagreement as to whether there is currently a common core software engineering body of knowledge at its current stage of evolution, and if so, what is size and contents of that BoK. This panel will present the current status of the SWEBOK and discuss its strengths and weakness, as well as address the more general question of the possible existence and nature of a software engineering body of knowledge. Issues related to internationalization, certification, and accreditation will be examined. The need for various computing societies to be invited to and contribute to the improvement of the SWEBOK project\u00a0\u2026", "num_citations": "5\n", "authors": ["623"]}
{"title": "Innovation and obstacles: the future of computing\n", "abstract": " In this multidisciplinary glimpse forward, some of this decade's key players offer opinions on a range of topics-from what has driven progress, to where innovation will come from and to obstacles we have yet to overcome. In this excerpt from\" Visions for the Future of the Fields,\" a panel discussion held at the 10th anniversary of the US Computer Science and Telecommunications Board, experts identify critical issues for various aspects of computing. In the accompanying sidebars, some of the same experts elaborate on points in the panel discussion in mini-essays: David Clark, CSTB chairman, looks at the changes needed, as computing science research comes of age. The current context of computer science, Clark states, is shaped by past successes and chronic trouble spots. Mary Shaw, Carnegie Mellon University, examines challenges for software system designers. Shaw states that disintermediation-the direct\u00a0\u2026", "num_citations": "5\n", "authors": ["623"]}
{"title": "The Carnegie Mellon University Master of Software Engineering Specialization Tracks\n", "abstract": " There is an increasing demand for domain specific software. For example, the software to control a machine on a factory floor is different in significant ways from the software to manipulate large databases. The software engineer building real time systems software to control a motor that powers a piece of machinery needs some understanding of the motor's servo system; whereas a software engineer who designs the software to manage large databases for the NASA Space Station needs specific knowledge about database models as well as the types of data handled on a long term space vehicle. Specialization tracks within the Master of Software Engineering (MSE) Program at Carnegie Mellon University enable students to gain application domain knowledge while developing fundamental software engineering skills. The MSE Program currently offers specialization tracks in real time computing, human computer\u00a0\u2026", "num_citations": "5\n", "authors": ["623"]}
{"title": "Software architecture: the next step for object technology (panel)\n", "abstract": " Architectures are the structuring paradigms, styles and patterns that make up our software systems. They are important in many ways: they allow us to talk usefully about systems without talking about their detail; a knowledge of them gives us design choices; attention to this level can make systems and families of systems have the non-functional properties we want, especially changeability.", "num_citations": "5\n", "authors": ["623"]}
{"title": "Software and Some Lessons from Engineering (Videorecording).\n", "abstract": " Physical description 1 VHS video 12 in. col. mono. playing time 82 mins. standard playback sp. Traditional engineering disciplines have centuries of history--enough time to gain a perspective on how they emerge and mature. Software engineering has no such history. Drawing on the history of traditional engineering disciplines for examples and analogies, Mary Shaw offers insights into the path the software engineering profession must take if it is to become a legitimate engineering discipline. These insights can be used as guidance for improving the practice of software engineering.Descriptors:", "num_citations": "5\n", "authors": ["623"]}
{"title": "Education for the future of software engineering\n", "abstract": " The discipline of software engineering is developing rapidly. Its practitioners must deal with an evolving collection of problems and with new technologies for dealing with those problems. Software engineering education must anticipate new problems and technologies, providing education in the enduring principles of the field in the context of the best current practice. Since changes in the discipline cannot be completely anticipated, software engineers must be able to assume responsibility for their own continuing professional development. This paper describes significant changes now taking place in the field of software engineering and proposes some goals and objectives for the professional education of software engineers.", "num_citations": "5\n", "authors": ["623"]}
{"title": "Accommodating data heterogeneity in ULS systems\n", "abstract": " Ultra-Large Scale (ULS) systems comprise numerous software elements designed and implemented by independent stakeholders whose requirements may vary widely. Consequently, elements in a ULS system may use different data formats, which complicates integration of elements. Writing code to robustly convert data from one format to another requires time and skills that some programmers may lack. Worse, the stakeholders who control a software element may change the element's data format at any point in the future without warning, causing format incompatibility not foreseen during the ULS system's construction.", "num_citations": "4\n", "authors": ["623"]}
{"title": "Tool support for data validation by end-user programmers\n", "abstract": " End-user programming tools for creating spreadsheets and webforms offer no data types except \"string\" for storing many kinds of data, such as person names and street addresses. Consequently, these tools cannot automatically validate these data. To address this problem, we have developed a new userextensible model for string-like data. Each \"tope\" in this model is a user-defined abstraction that guides the interpretation of strings as a particular kind of data, such as a mailing address. Specifically, each tope implementation contains software functions for recognizing and reformatting that tope's kind of data. With our tools, end-user programmers define new topes and associate them with fields in spreadsheets, webforms, and other programs. This makes it possible at runtime to distinguish between invalid data, valid data, and questionable data that could be valid or invalid. Once identified, questionable and/or\u00a0\u2026", "num_citations": "4\n", "authors": ["623"]}
{"title": "Challenges, Motivations, and Success Factors in the Creation of Hurricane Katrina\" Person Locator\" Web Sites.\n", "abstract": " We interviewed six people who led teams that created web sites enabling Hurricane Katrina survivors to report their status. We learned that interviewees did not discover and communicate with other teams when they started their projects, which resulted in redundant sites. The absence of a shared task impeded trust between teams, ultimately inhibiting data collection and aggregation. Moreover, communication within teams was problematic; developers who had adequate technical skills to work alone were more positive about their sites\u2019 success compared to developers who had to shore up skill weaknesses through collaboration. These problems did not simply result from team leaders\u2019 over-sized egos, since site creators were generally motivated by concern for other people instead of self-interested motivations. Rather, these problems highlight the need for improved development methods and systems to help developers discover and communicate with other teams\u2019 leaders in order to collaborate on widely distributed, time-critical projects.", "num_citations": "4\n", "authors": ["623"]}
{"title": "Identifying categories of end users based on the abstractions that they create\n", "abstract": " Software created by end users often lacks key quality attributes that professional programmers try to ensure through the use of abstraction. Yet to date, large-scale studies of end users have not examined end user software usage at a level which is sufficiently fine-grained to determine the extent to which they create abstractions.To address this, we deployed an online survey to Information Week subscribers to ask about not only software usage but also feature usage related to abstraction creation. Most respondents did create abstractions. Moreover, through factor analysis, we found that features fell into three clusters\u2013when users had a propensity to use one feature, then they also had a propensity to use other features in the same cluster. These clusters corresponded to macro features, linked data structure features, and imperative features.", "num_citations": "4\n", "authors": ["623"]}
{"title": "A Profession of Software Engineering, Is There a Need? YES. Are We Ready? NO.\n", "abstract": " Software is increasingly critical to the successful operation of real systems, including not only life-critical control systems but also ordinary communication and commerce. There is little question that unreliable poorly-designed, or undelivered software can cause these systems to fail. Since software is a technological product, it is fair to conclude the society needs a professional level of engineering for the design and development of software products. The question \"should there be a profession of software engineering\" is often asked in the form \"isn\"t it time we started licensing software engineers through the usual mechanisms of professional engineering registration?\" The purpose of professional engineering registration is to protect the public by providing some external assurance that a particular engineer will produce safe systems; by signing off on a project, the engineer assumes personal responsibility. The level\u00a0\u2026", "num_citations": "4\n", "authors": ["623"]}
{"title": "Validating the utility of abstraction techniques\n", "abstract": " A number of recent research efforts have been based on the hypothesis that encapsulation techniques, formal specification, and verification lead to significant improvements in program quality. As we gain experience with the language facilities produced by this research, we should attempt to validate that hypothesis. This paper poses this validation as the next major task in this area and outlines some ways to address it.", "num_citations": "4\n", "authors": ["623"]}
{"title": "Introducing\" theory\" in the second programming course\n", "abstract": " Traditionally, the first two programming courses have emphasized basic techniques and skills\u2014the details of a programming language, basic problem solving and program development,\u201cstructured programming\u201d, the manipulation of simple data structures and files, basic sorting and searching algorithms, etc.", "num_citations": "4\n", "authors": ["623"]}
{"title": "On the number of multiplications for the evaluation of a polynomial and all its derivatives\n", "abstract": " Some of the recent work in computational complexity has dealt with the number of arithmetics needed to evaluate a polynomial or a polynomial and its first derivative [Bo72],[Mun72]# Here we address the problem of evaluating a polynomial and all its derivatives. Prior to the new results presented here, the best known algorithm for computing a polynomial P (x) of degree n and all its derivatives n2+ n was the repeated application of synthetic division, which requires\u2014multiplications and the same number of additions. We present a new algorithm which reduces the number of multiplications required to compute the values of a polynomial and all its deriva-2 tives from 0 (n) to 0 (n). This algorithm and several known results can be explained as special cases of a general algorithm based on polynomial splitting.In this discussion we concentrate on reducing the number of multiplications required without allowing the number of additions to grow. Division is permitted, all multiplications and divisions are counted, and preconditioning is not allowed. We calculate the normalized derivative P^(x)/j! rather than P^(x) itself. The normalized derivative is what is normally needed in practice.\\", "num_citations": "4\n", "authors": ["623"]}
{"title": "Developing confidence in software through credentials and low-ceremony evidence\n", "abstract": " Conventional software specifications and reasoning based on such specifications do not accommodate uncertainty in the specifications, nor do they support the informal, subjective sorts of reasoning that many people use when making decisions about complex systems. We propose a notation for representing specifications in which attributes have different levels of confidence and we discuss ways that uncertain information can contribute usefully to software decisions.", "num_citations": "3\n", "authors": ["623"]}
{"title": "An Inventory of Techniques that Predict Value from Design\n", "abstract": " In prior work, we provided a framework for early design evaluation of software. This framework predicts the cost and benefits that customers are likely to receive from implementations of software designs. Prior to incurring the significant expense associated with implementing a design, software engineers can apply techniques within this framework to candidate designs, thus identifying designs that will yield high net value. We treat value as benefit net of costs and consider value from the customer\u2019s perspective.The meaning of software cost and benefit is highly context-dependent. It depends on characteristics of the customer and the producer, as well as the type of software under consideration. Thus, to be effective, our framework must be populated with diverse techniques that apply to a variety of circumstances.", "num_citations": "3\n", "authors": ["623"]}
{"title": "Outlook on software system design\n", "abstract": " CiNii \u8ad6\u6587 - Outlook on Software System Design CiNii \u56fd\u7acb\u60c5\u5831\u5b66\u7814\u7a76\u6240 \u5b66\u8853\u60c5\u5831\u30ca\u30d3\u30b2\u30fc\u30bf[\u30b5\u30a4\u30cb\u30a3 ] \u65e5\u672c\u306e\u8ad6\u6587\u3092\u3055\u304c\u3059 \u5927\u5b66\u56f3\u66f8\u9928\u306e\u672c\u3092\u3055\u304c\u3059 \u65e5\u672c\u306e\u535a\u58eb\u8ad6\u6587\u3092\u3055\u304c\u3059 \u65b0\u898f\u767b\u9332 \u30ed\u30b0\u30a4\u30f3 English \u691c\u7d22 \u3059\u3079\u3066 \u672c\u6587\u3042\u308a \u3059\u3079\u3066 \u672c\u6587\u3042\u308a \u9589\u3058\u308b \u30bf\u30a4\u30c8\u30eb \u8457\u8005\u540d \u8457\u8005ID \u8457\u8005\u6240\u5c5e \u520a\u884c\u7269\u540d ISSN \u5dfb\u53f7 \u30da\u30fc\u30b8 \u51fa\u7248\u8005 \u53c2\u8003\u6587\u732e \u51fa\u7248\u5e74 \u5e74\u304b\u3089 \u5e74\u307e\u3067 \u691c\u7d22 \u691c\u7d22 \u691c\u7d22 Outlook on Software System Design SHAW M. \u88ab\u5f15\u7528\u6587\u732e: 1\u4ef6 \u8457\u8005 SHAW M. \u53ce\u9332\u520a\u884c\u7269 IEEE Computer IEEE Computer January, 32, 1998 \u88ab\u5f15\u7528\u6587\u732e: 1\u4ef6\u4e2d 1-1\u4ef6\u3092 \u8868\u793a 1 21\u4e16\u7d00\u306e\u30bd\u30d5\u30c8\u30a6\u30a7\u30a2\u6280\u8853\u306e\u7814\u7a76\u52d5\u5411 \u5c71\u672c \u4fee\u4e00\u90ce \u96fb\u5b50\u60c5\u5831\u901a\u4fe1\u5b66\u4f1a\u6280\u8853\u7814\u7a76\u5831\u544a. AI, \u4eba\u5de5\u77e5\u80fd\u3068\u77e5\u8b58\u51e6\u7406 100(709), 81-88, 2001-03-12 \u53c2\u8003\u6587\u732e45\u4ef6 Tweet \u5404\u7a2e\u30b3\u30fc\u30c9 NII\u8ad6\u6587ID(NAID) 10022162292 \u8cc7\u6599\u7a2e\u5225 \u96d1\u8a8c\u8ad6\u6587 \u30c7\u30fc\u30bf\u63d0\u4f9b\u5143 CJP\u5f15\u7528 \u66f8\u304d\u51fa\u3057 RefWorks\u306b\u66f8\u304d\u51fa\u3057 EndNote\u306b\u66f8\u304d\u51fa\u3057 Mendeley\u306b\u66f8\u304d\u51fa\u3057 Refer/BiblX\u3067 \u8868\u793a RIS\u3067\u8868\u793a BibTeX\u3067\u8868\u793a TSV\u3067\u8868\u793a \u554f\u984c\u306e\u6307\u6458 \u30da\u30fc\u30b8\u30c8\u30c3\u30d7\u3078 \u30b9\u30de\u30fc\u30c8\u30d5\u30a9\u30f3\u7248 | \u2026", "num_citations": "3\n", "authors": ["623"]}
{"title": "Goals for computer science education in the 1980s\n", "abstract": " The nature of computing, and hence of computer science, is changing rapidly. Many topics that now seem interesting will be obsolete or irrelevant within ten years, and our perspective on other topics will change. If a curriculum designed now is to remain effective through 1990 or beyond, we must try to understand the forces that are shaping the field and to anticipate the roles that computing and computer science will play in the future. At Carnegie-Mellon, a group of eight faculty and graduate students is designing a new undergraduate computer science curriculum. We began by examining the trends that will affect the field over the next decade and the new phenomena and issues that may arise. From this basis we are developing a new curriculum without prior assumptions drawn from existing curricula. In this talk I will discuss our view of current trends in computer science and the roles that colleges and universities\u00a0\u2026", "num_citations": "3\n", "authors": ["623"]}
{"title": "Mathematics curriculum and the needs of computer science\n", "abstract": " Computer science is concerned with the phenomena surrounding computers and computation; it embraces the study of algorithms, the representation and organization of information, the management of complexity, and the relationship between computers and their users. Computer science is like engineering in that it is largely a problem-solving discipline, concerned with the design and construction of systems. But the computer scientist, like the mathematician, must be able to make deliberate use of the intellectual tools of abstraction and of analysis and synthesis. The relationship between computer science and mathematics is very close and has been discussed at length in the literature. Two very interesting examinations of this relationship are [3] and [5].", "num_citations": "3\n", "authors": ["623"]}
{"title": "Making software engineering issues real to undergraduates\n", "abstract": " Good software engineering education should not merely present techniques for dealing with large programs\u2014it must also convince the students that there are real problems for which these techniques are very much more effective than the casual methods they probably learned as beginners. It is often difficult to motivate the need for these techniques, and we consequently end up slighting important issues. I would like to list some of the issues we tend to avoid and some of the reasons we seem to do so. I will try to organize them so that this list will provoke more examples and provide some structure for discussion. I would like to hear from University people about techniques for making these ideas easier for students to appreciate; I would like to hear from practitioners about deficiencies they find in college-trained programmers.", "num_citations": "3\n", "authors": ["623"]}
{"title": "A system for structured programming\n", "abstract": " U 0 0: ULC)-\"'U U U 0 7 E. 0 3 C CLO)> 0 Ci JC a\u2022. _ L-- 0 3 0 C> 0 0_ 3 U 0+'L 0 a) U'UO r U.\"'1r G) 0 U a. U a U 3 l 3 U.. _0---00000 0", "num_citations": "3\n", "authors": ["623"]}
{"title": "Immigration course in computer science: teaching materials and 1972 schedule\n", "abstract": " BackgroundIn order to collect a group of worthwhile problems that can be solved with a reasonable amount of effort, the Computer Science department-sponsored an IC problem competition in the Spring of 1970. All the graduate students in the department were asked to submit problems touching on major aspects of Compute r Science together with complete solutions of the problems. To stimulate interest, ten prizes of $100. 00 were announced. A second contest was held in the spring of 1972. Five prizes of $100.00 were awarded in the second contest.", "num_citations": "3\n", "authors": ["623"]}
{"title": "Language Structures for Contractible Compilers.\n", "abstract": " The work explores the decomposition of a language into a hierarchy of sub-languages of gradually decreasing power. Features of a language are isolated the language is contracted by removing those features not used by some class of problems and the effectiveness of the resulting language for many classes of problems is evaluated. Performing such contractions on a language and its subsets yields a set of languages partially ordered by inclusion. The hypothesis of the thesis is that there exist languages such that for some implementation of the compiler for a language, parallel subsets of the language and the compiler may be selected with the properties that the subsets are useful in some appropriate sense, and diminishing size and power in the language correspond to diminishing size and cost in the compiler. AuthorDescriptors:", "num_citations": "3\n", "authors": ["623"]}
{"title": "The Role of Design Spaces in Guiding a Software Design\n", "abstract": " 3.1 DESIGN SPACES The design space in which a designer seeks to solve a problem is the set of decisions to be made about the designed artifact together with the alternative choices for these decisions.", "num_citations": "2\n", "authors": ["623"]}
{"title": "Panel on the role of graduate software and systems engineering bodies of knowledge in formulating graduate software engineering curricula\n", "abstract": " The Software Engineering Body of Knowledge (SWEBOK), published in 2004, and now under revision, has influenced many software engineering graduate programs worldwide. In 2009, guidelines were published for graduate programs in software engineering (GSWE2009). GSWE2009, now sponsored by both the IEEE Computer Society and the Association for Computing Machinery, strongly rely on the SWEBOK but also recommends specific systems engineering knowledge for students to master. Today, an international team is creating a rigorous Systems Engineering Body of Knowledge (SEBoK) with the help of the IEEE Computer Society and the International Council on Systems Engineering and other professional societies. As it matures, the SEBoK should influence future versions of GSWE2009 and graduate program curricula worldwide. This panel will examine the influence of bodies of knowledge on both\u00a0\u2026", "num_citations": "2\n", "authors": ["623"]}
{"title": "The challenge of pervasive software to the conventional wisdom of software engineering.\n", "abstract": " The Challenge of Pervasive Software to the Conventional Wisdom of Software Engineering Page 1 1 Institute for Software Research The Challenge of Pervasive Software to the Conventional Wisdom of Software Engineering Mary Shaw Carnegie Mellon University http://www.cs.cmu.edu/~shaw/ Page 2 2 Institute for Software Research Most software creators are not software professionals. Ultra-Large-Scale systems are a qualitative shift. How does current research match these challenges? What new types of research does this suggest? Page 3 3 Institute for Software Research Most software creators are not software professionals. y End users are participants and developers, not passive consumers y They do not reason about software like professionals Ultra-Large-Scale systems are a qualitative shift. How does current research match these challenges? What new types of research does this suggest? Page 4 4 \u2026", "num_citations": "2\n", "authors": ["623"]}
{"title": "Inferring reusability of end-user programmers\u2019 code from low-ceremony evidence\n", "abstract": " While end-user programmers sometimes combine, learn from, or otherwise reuse existing code to quickly create new programs, not all code is equally reusable. Some code is reused by its creator or by others, but other code simply languishes on servers and never provides any help in the creation of subsequent programs. In this paper, we draw on numerous empirical studies of end-user and professional programmers to show that the reusability of code can be inferred on the basis of \u201clow-ceremony\u201d evidence. This evidence is information that is often informal, possibly unreliable, but that can be quickly gathered, interpreted and synthesized without the investment of substantial effort or skill by code producers or consumers. In the studies considered here, it includes information about code\u2019s mass appeal, flexibility, understandability, functional size, authorship, and prior reuses. We summarize a simple machine learning model that has successfully predicted reuse of web macros based on this low-ceremony evidence.", "num_citations": "2\n", "authors": ["623"]}
{"title": "Collaboration and communication: growing and sustaining ultra large scale (ULS) systems\n", "abstract": " Mission-and life-critical Ultra-Large-Scale (ULS) systems are increasingly prevalent and networked in many domains, including business, aviation, communication, defense, finance, health, and public utilities. Such systems are often too complex for generally centralized methods to work well for such tasks as requirements discovery, development, system integration, test, deployment, configuration, operation protection, and evolution. Yet today we lack sound methods and technologies for distributing these tasks across large ecosystems of system production. What technical, legal, contractual, and cultural frameworks are needed to enable global partners with independent, sometimes conflicting agendas, to function effectively in the execution of such tasks? Can a competitive and collaborative distributed design ecosystem deliver value and robustness over time consistent with demands for quality, intellectual property\u00a0\u2026", "num_citations": "2\n", "authors": ["623"]}
{"title": "2.5\u2013Strategies for Achieving Robustness in Coalitions of Systems\n", "abstract": " This case is the focus of much of formal language theory and static program analysis, which attempt to make guarantees about programs based on the code of a system. In recent years this has focused on specific properties rather than complete specifications. The objective here is absolute guarantees.", "num_citations": "2\n", "authors": ["623"]}
{"title": "Sparking research ideas from the friction between doctrine and reality\n", "abstract": " Good research ideas often arise from critical observation of inconsistencies between researchers\u2019 assumptions about software development and practical reality. This dissonance creates a kind of friction that can spark research ideas. This is the text for the Stevens Award Lecture on November 8, 2005. The Stevens Award was created to recognize outstanding contributions to the literature or practice of methods for software and systems development.", "num_citations": "2\n", "authors": ["623"]}
{"title": "The Tyranny of Transistors: What Counts about Software?\n", "abstract": " Our intuitions tell us that computer software is vastly better than it was 20 years ago--more diverse, more reliable, more powerful. However, the aggregate measures we use for software show only slow progress. Meanwhile, computer hardware basks in the glow of Moore's Law, and software seems to pale in comparison. While it is possible that software power does grows sluggishly in comparison to hardware, it seems more likely that hardware reaps the benefits of a better decision about what to count in describing progress over time. As we pursue value propositions in software, we should consider carefully the values that we pursue. A good start would be to switch from counting measures of our input effort to counting measures of the results of this effort", "num_citations": "2\n", "authors": ["623"]}
{"title": "Proposal for an undergraduate computer science curriculum for the 1980s: part II, detailed course descriptions\n", "abstract": " The authors propose to the Carnegie-Mellon Computer Science Department a curriculum for undergraduate computer science. This Part contains the detailed course descriptions that support the curriculum proposal described in Part I.", "num_citations": "2\n", "authors": ["623"]}
{"title": "An Alphard specification of a correct and efficient transformation on data structures\n", "abstract": " In this paper we study the problem of designing and specifying standard program components applicable to a wide variety of tasks; we choose for this study the specific problem domain of data structures for general searching problems. Within this domain Bentley and Saxe [1] have developed transformations for converting solutions of simple searching problems to solutions of more complex problems. We discuss one of those transformations, specify precisely the transformation and its conditions of applicability, and prove its correctness; we accomplish this by casting it in terms of abstract data types\u2013specifically by using the Alphard form mechanism. The costs of the structures derived by this transformation are only slightly greater than the costs of the original structures, and the correctness of the transformation definition together with the correctness of the original structure assure the correctness of the derived\u00a0\u2026", "num_citations": "2\n", "authors": ["623"]}
{"title": "Abstraction, data types, and models for software\n", "abstract": " In the area of software development and maintenance, a major issue is managing the complexity of the systems. Programming methodologies and languages to support them have grown in response to new ideas about how to cope with this complexity. A dominant theme in the growth of methodologies and languages is the development of tools dealing with abstractions. An abstraction is a simplified description, or specification, of a system that emphasizes some of its details or properties while suppressing others. A good abstraction is one in which information that is significant to the reader (ie, the user) is emphasized while details that are immaterial, at least for the moment, are suppressed.", "num_citations": "2\n", "authors": ["623"]}
{"title": "Abstraction and verification in Alphard: A symbol table example\n", "abstract": " The design of the Alphard programming language has been strongly influenced by ideas from the areas of programming methodology and formal program verification. In this paper we design, implement, and verify a general symbol table mechanism. This example is rich enough to allow us to illustrate the use as well as the definition of programmer-defined abstractions. The verification illustrates the power of the form to simplify proofs by providing strong specifications of such abstractions.", "num_citations": "2\n", "authors": ["623"]}
{"title": "Software Professionalism-Is it'Good Enough?'\n", "abstract": " In the 21st Century, software is the enabling innovation pillar for all of civilization\u2019s needs\u2013including: food supply, living space (water, waste, power, and climate) management, services (health, financial, transportation, communication) and human relations (social networking). While the professionalism inherent in implement-ing, deploying, and configuring software systems may not appear as advanced as that found in other more regulated professions such as medicine, aviation, and engineering\u2013is it \u201cgood enough\u201d? This panel will discuss whether we are learning effectively from our experiences with failure and human hazards. Panelists will also discuss how software professionalism can be accelerated and debate the effectiveness of proficiency certifications in fostering increased professionalism.", "num_citations": "1\n", "authors": ["623"]}
{"title": "Empirical challenges in ultra large scale systems\n", "abstract": " Ultra Large Scale (ULS) systems are complex software-intensive systems that are deeply embedded in a business and social context with many and diverse stakeholders. They are qualitatively more complex and challenging than software-intensive systems or even \u201csystems of systems\u201d. ULSs, like other complex systems, are large along many dimensions, but the special character of \u201cultra-large scale\u201d systems arises from their decentralized operation and control, their conflicting and even unknowable requirements, their continuous evolution requiring integration of heterogeneous and inconsistent elements, the indistinct boundary between the system and its users, and their consequent need for new forms of governance. The capability of a ULS arises not solely from the software and hardware of the system, but from the things that stakeholders with different objectives do with and to the system.", "num_citations": "1\n", "authors": ["623"]}
{"title": "Helping everday users establish confidence for everyday applications\n", "abstract": " End users obtain their desired results by combining elements of information and computation from different applications. Software engineering provides little support for identifying, selecting, or combining these elements \u00c3\u00a2 \u00e2 \u201a\u00ac \u00e2\u20ac \u0153 that is, for helping end users to design computational support for their own tasks. Software engineering provides even less support to help end users to decide whether the resulting system is sufficiently dependable \u00c3\u00a2 \u00e2 \u201a\u00ac \u00e2\u20ac \u0153whether it will meet their expectations. Many users, especially end users, base judgments about software on informal and undependable information, and they draw conclusions with informal rather than rational decision methods. We have been developing support for everyday dependability, with an emphasis on expressing expectations in abstractions familiar to the user and on obtaining software behavior that reasonably satisfies those expectations. In this Dagstuhl I would like to explore the differences between everyday informal reasoning and the rational processes of computer science in order to develop means for establishing credible indications of confidence for end users.", "num_citations": "1\n", "authors": ["623"]}
{"title": "Research Opportunities in the Virtual Agora: Market Aspects of Open Resource Coalitions\n", "abstract": " For at least a decade, we have looked forward to an open market for software components and services. Recent advances in networking have created in the Internet a fertile environment for the creation and distribution of components, and we see a rich potential for value-added as well as primary goods. However, the economic infrastructure for an open market in software resources is still lacking, and support for automation of the marketplace is scant indeed. The prospect of automatically identifying, procuring, and integrating network-based resources intensifies the need to provide a robust economic infrastructure. We sketch the requirements for an electronic marketplace in software goods and services, explores some of the remaining shortfalls, and identify research opportunities.", "num_citations": "1\n", "authors": ["623"]}
{"title": "Constructing Systems from Parts: What Students Should Learn about Software Architecture\" and\" Architectural Mismatch, Interoperability, and the Prospects for Electronic\u00a0\u2026\n", "abstract": " Constructing Systems from Parts: What Students Should Learn about Software Architecture\" and \"Architectural Mismatch, Interoperability, and the Prospects for Electronic Commerce in Software Parts and Services https://s3-eu-west-1.amazonaws.com/876az-branding-figshare/cmu/logo_header.png Browse Cite Download Share Embed Constructing Systems from Parts: What Students Should Learn about Software Architecture\" and \"Architectural Mismatch, Interoperability, and the Prospects for Electronic Commerce in Software Parts and Services 1998-01-01T00:00:00Z (GMT) by Mary Shaw Institute for Software Research Categories Computer Software not elsewhere classified Keyword(s) Software Research License In Copyright Export RefWorks BibTeX Endnote DataCite NLM DC Hide footer About How to Deposit Preparing Data DMP Tool Deposit Support Contact Deposit Agreement Terms Privacy Tools FAQs \u2026", "num_citations": "1\n", "authors": ["623"]}
{"title": "Putting \u201cengineering\u201d into software engineering\n", "abstract": " Publication: CSC'94: Proceedings of the 22nd annual ACM computer science conference on Scaling up: meeting the challenge of complexity in real-world computing applications: meeting the challenge of complexity in real-world computing applications March 1994 https://doi. org/10.1145/197530.197679", "num_citations": "1\n", "authors": ["623"]}
{"title": "The role of mathematics in computer science education\n", "abstract": " Computer science relies heavily on mathematics for its foundations and methods. However, the traditional mathematics curriculum for students of the physical sciences is increasingly perceived as inappropriate for computer science undergraduates. On the other hand, it has been hard to translate this perception into curriculum recommendations; perhaps because so many of our programs and faculty originated in departments of mathematics or electrical engineering. For example, mathematics requirements are featured prominently in suggested curricula of the ACM and IEEE, but these curricula do not give much detail about suggested content of the required mathematics classes nor do they address the integration of the mathematics and computer science classes.These issues have received increasing public attention in the last five years, and it seems that we are on the brink of major changes in the mathematical\u00a0\u2026", "num_citations": "1\n", "authors": ["623"]}
{"title": "Software: Practice and Experience\n", "abstract": " Four programming languages (Fortran, Cobol, Jovial and the proposed DoD standard) are compared in the light of modern ideas of good software engineering practice. The comparison begins by identifying a core for each language that captures the essential properties of the language and the intent of the language designers. These core languages then serve as a basis for the discussion of the language philosophies and the impact of the language on gross program organization and on the use of individual statements", "num_citations": "1\n", "authors": ["623"]}
{"title": "Language design for the Ironman requirement: notes and examples\n", "abstract": " The Tartan language was designed as an experiment to see whether the Ironman requirement for a common high-order programming language could be satisfied by an extremely simple language. The result, Tartan substantially meets the Ironman requirement. We believe it is substantially simpler than the four designs that were done in the first phase of the DOD-1 effort. The language definition appears in a companion report; this report provides a more expository discussion of some of the language's features, some examples of its use, and a discussion of some facilities that could enhance the basic design at relatively little cost.", "num_citations": "1\n", "authors": ["623"]}
{"title": "Selection of good algorithms from a family of algorithms for polynomial derivative evaluation\n", "abstract": " 1. INTRODUCTION We have previously presented a one-parameter family of algorithms for evaluating the first m derivatives of a polynomial of degree n [1]. We also gave a program (called Dl) for computing the m derivatives under the assumption that the parameter q divides n+ 1.\" The value selected for the parameter affects the number of multiplications and divisions used to compute the derivatives. In this paper we show how the parameter q can be chosen to achieve an optimal or close-to-optimal algorithm in our family. We shall also present a generalization of program Dl (program D2) which can be used to evaluate the first m derivatives of a polynomial if q does not necessarily divide n+ 1. We show how q must be computed to achieve a nearly optimal performance in this more general case. The results should be of help in implementing the algorithms of [1]. When all derivatives are desired, the classical algorithm of Horner [2] uses n (n+ l)/2 additions and n (n+ l)/2 multiplications. As a special case of the work in [1] we presented an algorithm for computing all derivatives which requires the same number of additions but only a linear number of multiplications and divisions (M/D)[3]. This result and concurrent research on applications of fast algorithms related to the discrete Fourier Transform led to an improving sequence of asymptotic results for the total arithmetics 3 needed to compute all derivatives. Borodin first showed that 0 (n log n) total 2 arithmetic operations were sufficient [4]. It was reduced to 0 (n log n) by Kung [5], Strassen [6], and Borodin [7], and the new results by Aho, Steiglitz, and Ullman [8] and by Vari [9] are 0 (n log n). The\u00a0\u2026", "num_citations": "1\n", "authors": ["623"]}