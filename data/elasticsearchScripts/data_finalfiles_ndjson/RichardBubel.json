{"title": "Verifying OpenJDK\u2019s sort method for generic collections\n", "abstract": " TimSort is the main sorting algorithm provided by the Java standard library and many other programming frameworks. Our original goal was functional verification of TimSort with mechanical proofs. However, during our verification attempt we discovered a bug which causes the implementation to crash by an uncaught exception. In this paper, we identify conditions under which the bug occurs, and from this we derive a bug-free version that does not compromise performance. We formally specify the new version and verify termination and the absence of exceptions including the bug. This verification is carried out mechanically with KeY, a state-of-the-art interactive verification tool for Java. We provide a detailed description and analysis of the proofs. The complexity of the proofs required extensions and new capabilities in KeY, including symbolic state merging.", "num_citations": "21\n", "authors": ["702"]}
{"title": "Ensuring the correctness of lightweight tactics for JavaCard dynamic logic\n", "abstract": " The interactive theorem prover developed in the KeY project, which implements a sequent calculus for JavaCard Dynamic Logic (JavaCardDL) is based on taclets. Taclets are lightweight tactics with easy to master syntax and semantics. Adding new taclets to the calculus is quite simple, but poses correctness problems. We present an approach how derived (non-axiomatic) taclets for JavaCardDL can be proven sound in JavaCardDL itself. Together with proof management facilities, our concept allows the safe introduction of new derived taclets while preserving the soundness of the calculus.", "num_citations": "16\n", "authors": ["702"]}
{"title": "PE-KeY: A partial evaluator for Java programs\n", "abstract": " We present a prototypical implementation of a partial evaluator for Java programs based on the verification system KeY. We argue that using a program verifier as technological basis provides potential benefits leading to a higher degree of specialization. We discuss in particular how loop invariants and preconditions can be exploited to specialize programs. In addition, we provide the first results which we achieved with the presented tool.", "num_citations": "13\n", "authors": ["702"]}
{"title": "The Schorr-Waite-Algorithm\n", "abstract": " Abstract The Schorr-Waite graph marking algorithm named after its inventors Schorr and Waite [1967] has become an unofficial benchmark for the verification of programs dealing with linked data structures. It has been originally designed with a LISP garbage collector as application field in mind and thus, its main characteristic is low additional memory consumption. The original design claimed only two markers per data object and, more important, only three auxiliary pointers at all during the algorithm\u2019s runtime. It is the latter point, where most other graph marking algorithms lose against Schorr-Waite and need to allocate (often implicitly as part of the method stack) additional memory linear in the number of nodes in the worst case. These resources are used to log the taken path for later backtracking when a circle is detected or a sink reached. Schorr and Waite\u2019s trick is to keep track of the path by reversing traversed\u00a0\u2026", "num_citations": "13\n", "authors": ["702"]}
{"title": "Runtime assertion checking and theorem proving for concurrent and distributed systems\n", "abstract": " We investigate the usage of a history-based specification approach for concurrent and distributed systems. In particular, we compare two approaches on checking that those systems behave according to their specification. Concretely, we apply runtime assertion checking and static deductive verification on two small case studies to detect specification violations, respectively to ensure that the system follows its specifications. We evaluate and compare both approaches with respect to their scope and ease of application. We give recommendations on which approach is suitable for which purpose as well as the implied costs and benefits of each approach.", "num_citations": "7\n", "authors": ["702"]}
{"title": "Formal verification of recursive predicates.\n", "abstract": " The KeY-approach aims at the integration of deductive verification within the development process. Therefore a tight integration into standard development environments as CASE (computer aided design environment) tools and IDE (integrated development environments) is indispensable. KeY adds specification and verification support to these tools. A semiautomatic prover builds up the system\u2019s core component that allows to prove that the implementation meets its specification, visualise possible thrown and uncaught exceptions or generate test cases. The taken approach allows to draw benefit even from incomplete specifications or not completed proofs. As target programming language JAVA CARD has been chosen, which is mainly a subset of JAVA. At the moment of writing 1 this means no multi-threading, floating point operations or graphical user interface classes are supported including some other minor simplifications. But in addition to standard JAVA it comes with built-in support for transactions. KeY supports the complete JAVA CARD language and also most of the features previously summarised under minor simplifications like full object and class initialisation. The supported high-level specification languages are\u2022 the Unified Modelling Language (UML) in combination with the Object Constraint Language which is part of the UML specification [Obj01].\u2022 the Java Modelling Language [LPC+ 02, LBR00] a specification language designed for the specification of JAVA programs. these specifications become then translated into a variant of dynamic logic called JAVA CARD DL, which can also be seen as a low-level specification language\u00a0\u2026", "num_citations": "6\n", "authors": ["702"]}
{"title": "KeY quicktour for JML\n", "abstract": " When we started writing this document, we aimed at providing a short tutorial accompanying the reader at her/his first steps with the KeY system. The KeY-Tool is designed as an integrated environment for creating, analysing, and verifying software models and their implementation. The reader shall learn how to install and use the basic functionality of the KeY-Tool. Besides practical advises how to install and get KeY started, we show along a small project how to use the KeY-Tool to verify programs. Verification means to prove that a program complies its specification in mathematical rigorous way. In order to fulfil this task, the specification needs to be given in a formal language with a precise defined meaning. In the current version of the document we focus on the popular Java Modeling Language (JML)[LPC+ 08, LBR04] as specification language. In the next sections we show how to verify a JML annotated (specified) JavaCard program. Therefore features KeY a calculus for the complete Java-Card language including advanced features like transactions. Besides JML, the KeY-Tool supports UML/OCL and JavaCardDL as specification languages. Later versions of this quicktour will cover them\u2013for the moment we can refer only to an outdated quicktour for OCL [BHS] from which this document evolved.", "num_citations": "6\n", "authors": ["702"]}
{"title": "Verification of Variable Software: An Experience Report\u22c6\n", "abstract": " We report on our experiences with formal specification and verification of variable and customizable software realized in a software product family architecture using the Java Modeling Language (JML) and the KeY verification system. Software product families can be adapted to different deployment scenarios and provide instantiable feature sets as requested by the customer. Along a small case study we explore how to generate JML specifications for/from a given feature configuration and report on verification attempts of selected methods of the derived product. We identify challenges that need to be solved to allow scalable specification and verification of variable software.", "num_citations": "4\n", "authors": ["702"]}
{"title": "Dependency-based information flow analysis with declassification in a program logic\n", "abstract": " We present a deductive approach for the analysis of secure information flows with support for fine-grained policies that include declassifications in the form of delimited information release. By explicitly tracking the dependencies of program locations as a computation history, we maintain high precision, while avoiding the need for comparing independent program runs. By considering an explicit heap model, we argue that the proposed analysis can straightforwardly be applied on object-oriented programs.", "num_citations": "3\n", "authors": ["702"]}
{"title": "A theorem prover backed approach to array abstraction\n", "abstract": " We present an extension to an on-demand abstraction framework, which integrates deductive verification and abstract interpretation. Our extension allows for a significantly higher precision when reasoning about programs containing arrays. We demonstrate the usefulness of our approach in the context of reasoning about secure information flow. In addition to abstracting arrays that may have been modified, our approach can also keep full precision while adding additional information about array elements which have been only read but not modified.", "num_citations": "3\n", "authors": ["702"]}
{"title": "Theories\n", "abstract": " For a program verification tool to be useful it needs to be able to reason about at least the most important data types, both abstract data types, as well as those built into the programming language.  This chapter presents how the theories of some data structures are realized in KeY's logic: finite sequences, Java strings, and Java integer data types.", "num_citations": "2\n", "authors": ["702"]}
{"title": "Modular specification and verification\n", "abstract": " In this chapter, concepts already addressed in previous chapters are reconsidered and extended to cater for modularity. In particular, it is shown how method contracts can be used in proofs (as opposed to being verified themselves). Another central topic is nonfunctional framing information, i.e., information on what locations a method may write to or read from. But, there are also items that are discussed here in depth for the first time: model methods, an abstraction of Java methods that are only used in specification, verification of recursive methods, and object invariants.  For any of the arising proof obligations the calculus rules needed to dispatch them are shown.", "num_citations": "2\n", "authors": ["702"]}
{"title": "Inferring secrets by guided experiments\n", "abstract": " A program has secure information flow if it does not leak any secret information to publicly observable output. A large number of static and dynamic analyses have been devised to check programs for secure information flow. In this paper, we present an algorithm that can carry out a systematic and efficient attack to automatically extract secrets from an insecure program. The algorithm combines static analysis and dynamic execution. The attacker strategy learns from past experiments and chooses as its next attack one that promises maximal knowledge gain about the secret. The idea is to provide the software developer with concrete information about the severity of an information leakage.", "num_citations": "1\n", "authors": ["702"]}
{"title": "Program transformation and compilation\n", "abstract": " This chapter consists of two parts: The first describes how to  interleave symbolic execution with partial evaluation to render the  representation of proof trees more compact. Besides saving proof effort, it  helps a human user to navigate and comprehend a given proof situation  better.  The second part is about verifiably correct compilation.  Instead  of verifying a compiler, we use the verification engine of KeY to prove for  a given program on the fly that it is correctly compiled through a sound  program transformation.  Program behavior of the source code is provably  preserved at the level of the target language: source and compiled  program terminate in states in which the values of a user-specified region  of the heap are equivalent.  We give a proof-of-concept of the approach in  realizing a partial evaluator, i.e., a source-to-source compiler.", "num_citations": "1\n", "authors": ["702"]}
{"title": "A comparison of runtime assertion checking and theorem proving for concurrent and distributed systems\n", "abstract": " We investigate the usage of a history-based specification approach for concurrent and distributed systems. In particular, we compare two approaches on checking that those systems behave according to their specification. Concretely, we apply runtime assertion checking and static deductive verification on two small case studies to detect specification violations, respectively to ensure that the system follows its specifications. We evaluate and compare both approaches with respect to their scope and ease of application. We give recommendations on which approach is suitable for which purpose as well as the implied costs and benefits of each approach.", "num_citations": "1\n", "authors": ["702"]}