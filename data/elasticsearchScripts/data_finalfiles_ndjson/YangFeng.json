{"title": "Using semi-supervised clustering to improve regression test selection techniques\n", "abstract": " Cluster test selection is proposed as an efficient regression testing approach. It uses some distance measures and clustering algorithms to group tests into some clusters. Tests in a same cluster are considered to have similar behaviors. A certain sampling strategy for the clustering result is used to build up a small subset of tests, which is expected to approximate the fault detection capability of the original test set. All existing cluster test selection methods employ unsupervised clustering. The previous test results are not used in the process of clustering. It may lead to unsatisfactory clustering results in some cases. In this paper, a semi-supervised clustering method, namely semi-supervised K-means (SSKM), is introduced to improve cluster test selection. SSKM uses limited supervision in the form of pair wise constraints: Must-link and Cannot-link. These pair wise constraints are derived from previous test results to\u00a0\u2026", "num_citations": "59\n", "authors": ["2158"]}
{"title": "Measuring the Diversity of a Test Set With Distance Entropy\n", "abstract": " Most existing metrics that we call white-box metrics, such as coverage metrics, require white-box information, like program structure information, and historical runtime information, to evaluate the fault detection capability of a test set. In practice, such white-box information is usually unavailable or difficult to obtain, which means they often cannot be used. In this paper, we propose a black-box metric, distance entropy, based on the diversification idea behind many published diversity-based techniques. Distance entropy provides a possible solution for test set evaluation when white-box information is not available. The empirical study illustrates that distance entropy can effectively evaluate test sets if the distance metric between tests is well defined. Meanwhile, distance entropy outperforms simple diversity metrics without increasing time complexity.", "num_citations": "31\n", "authors": ["2158"]}
{"title": "Deepgini: prioritizing massive tests to enhance the robustness of deep neural networks\n", "abstract": " Deep neural networks (DNN) have been deployed in many software systems to assist in various classification tasks. In company with the fantastic effectiveness in classification, DNNs could also exhibit incorrect behaviors and result in accidents and losses. Therefore, testing techniques that can detect incorrect DNN behaviors and improve DNN quality are extremely necessary and critical. However, the testing oracle, which defines the correct output for a given input, is often not available in the automated testing. To obtain the oracle information, the testing tasks of DNN-based systems usually require expensive human efforts to label the testing data, which significantly slows down the process of quality assurance.", "num_citations": "23\n", "authors": ["2158"]}
{"title": "Successes, challenges, and rethinking\u2013an industrial investigation on crowdsourced mobile application testing\n", "abstract": " The term crowdsourcing \u2013 a compound contraction of crowd and outsourcing \u2013 is a new paradigm for utilizing the power of crowds of people to facilitate large-scale tasks that are costly or time consuming with traditional methods. This paradigm offers mobile application companies the possibility to outsource their testing activities to crowdsourced testers (crowdtesters) who have various testing facilities and environments, as well as different levels of skills and expertise. With this so-called Crowdsourced Mobile Application Testing (CMAT), some of the well-recognized issues in testing mobile applications, such as multitude of mobile devices, fragmentation of device models, variety of OS versions, and omnifariousness of testing scenarios, could be mitigated. However, how effective is CMAT in practice? What are the challenges and issues presented by the process of applying CMAT? How can these issues and\u00a0\u2026", "num_citations": "21\n", "authors": ["2158"]}
{"title": "Multi-label software behavior learning\n", "abstract": " Software behavior learning is an important task in software engineering. Software behavior is usually represented as a program execution. It is expected that similar executions have similar behavior, i.e. revealing the same faults. Single-label learning has been used to assign a single label (fault) to a failing execution in the existing efforts. However, a failing execution may be caused by several faults simultaneously. Hence, it needs to assign multiple labels to support software engineering tasks in practice. In this paper, we present multi-label software behavior learning. A well-known multi-label learning algorithm ML-KNN is introduced to achieve comprehensive learning of software behavior. We conducted a preliminary experiment on two industrial programs: flex and grep. The experimental results show that multi-label learning can produce more precise and complete results than single-label learning.", "num_citations": "16\n", "authors": ["2158"]}
{"title": "An empirical study on clustering for isolating bugs in fault localization\n", "abstract": " Spectrum-based Fault Localization (SBFL) techniques use risk evaluation formulas to calculate each statement's likelihood of having a bug based on test results. SBFL can not only be used in statement level, but also can be used with other program entities such as branches, functions and so on. Most previous studies have been conducted under the assumption of a single bug. However, software always contains multi-bugs in practice. A natural idea of debugging is to isolate bugs and then use SBFL techniques to locate one bug for each group. In this paper, we conduct an empirical study on clustering for isolating bugs in fault localization. We analyze the effects of six fault localization techniques and two cluster algorithms. The main observations are: (1) ER5 (Wong1) achieves the best results of fault localization with clustering; (2) K-means outperforms hierarchical clustering for isolating bugs in fault localization.", "num_citations": "15\n", "authors": ["2158"]}
{"title": "Multi-Winner Contests for Strategic Diffusion in Social Networks\n", "abstract": " Strategic diffusion encourages participants to take active roles in promoting stakeholders\u2019 agendas by rewarding successful referrals. As social media continues to transform the way people communicate, strategic diffusion has become a powerful tool for stakeholders to influence people\u2019s decisions or behaviors for desired objectives. Existing reward mechanisms for strategic diffusion are usually either vulnerable to falsename attacks or not individually rational for participants that have made successful referrals. Here, we introduce a novel multi-winner contests (MWC) mechanism for strategic diffusion in social networks. The MWC mechanism satisfies several desirable properties, including false-name-proofness, individual rationality, budget constraint, monotonicity, and subgraph constraint. Numerical experiments on four real-world social network datasets demonstrate that stakeholders can significantly boost participants\u2019 aggregated efforts with proper design of competitions. Our work sheds light on how to design manipulation-resistant mechanisms with appropriate contests.", "num_citations": "10\n", "authors": ["2158"]}
{"title": "Bug Inducing Analysis to Prevent Fault Prone Bug Fixes\n", "abstract": " Bug fix is an important and challenging task in software development and maintenance. Bug fix is also a dangerous change, because it might induce new bugs. It is difficult to decide whether a bug fix is safe in practice. In this paper, we conducted an empirical study on bug inducing analysis to discover the types and features of fault prone bug fixes. We use a classical algorithm to track the location of the code changes introducing the bugs. The change types of the codes will be checked by an automatic tool and whether this change is a bug fix change is recorded. We analyze the statistics to find out what types of change are most prone to induce new bugs when they are intended to fix a bug. Finally, some guidelines are provided to help developers prevent such fault prone bug fixes.", "num_citations": "10\n", "authors": ["2158"]}
{"title": "Lirat: Layout and image recognition driving automated mobile testing of cross-platform\n", "abstract": " The fragmentation issue spreads over multiple mobile platforms such as Android, iOS, mobile web, and WeChat, which hinders test scripts from running across platforms. To reduce the cost of adapting scripts for various platforms, some existing tools apply conventional computer vision techniques to replay the same script on multiple platforms. However, because these solutions can hardly identify dynamic or similar widgets. It becomes difficult for engineers to apply them in practice. In this paper, we present an image-driven tool, namely LIRAT, to record and replay test scripts cross platforms, solving the problem of test script cross-platform replay for the first time. LIRAT records screenshots and layouts of the widgets, and leverages image understanding techniques to locate them in the replay process. Based on accurate widget localization, LIRAT supports replaying test scripts across devices and platforms. We\u00a0\u2026", "num_citations": "9\n", "authors": ["2158"]}
{"title": "NeuralVis: visualizing and interpreting deep learning models\n", "abstract": " Deep Neural Network (DNN) techniques have been prevalent in software engineering. They are employed to facilitate various software engineering tasks and embedded into many software applications. However, because DNNs are built upon a rich data-driven programming paradigm that employs plenty of labeled data to train a set of neurons to construct the internal system logic, analyzing and understanding their behaviors becomes a difficult task for software engineers. In this paper, we present an instance-based visualization tool for DNN, namely NeuralVis, to support software engineers in visualizing and interpreting deep learning models. NeuralVis is designed for: 1). visualizing the structure of DNN models, i.e., neurons, layers, as well as connections; 2). visualizing the data transformation process; 3). integrating existing adversarial attack algorithms for test input generation; 4). comparing intermediate layers'\u00a0\u2026", "num_citations": "7\n", "authors": ["2158"]}
{"title": "Software engineering practice in the development of deep learning applications\n", "abstract": " Deep-Learning(DL) applications have been widely employed to assist in various tasks. They are constructed based on a data-driven programming paradigm that is different from conventional software applications. Given the increasing popularity and importance of DL applications, software engineering practitioners have some techniques specifically for them. However, little research is conducted to identify the challenges and lacks in practice. To fill this gap, in this paper, we surveyed 195 practitioners to understand their insight and experience in the software engineering practice of DL applications. Specifically, we asked the respondents to identify lacks and challenges in the practice of the development life cycle of DL applications. The results present 13 findings that provide us with a better understanding of software engineering practice of DL applications. Further, we distil these findings into 7 actionable recommendations for software engineering researchers and practitioners to improve the development of DL applications.", "num_citations": "7\n", "authors": ["2158"]}
{"title": "Using weighted attributes to improve cluster test selection\n", "abstract": " Cluster Test Selection (CTS) is widely-used in observation-based testing and regression testing. CTS selects a small subset of tests to fulfill the original testing task by clustering execution profiles. In observation-based testing, CTS saves human efforts for result inspection by reducing the number of tests and finding failures as many as possible. This paper proposes a novel strategy, namely WAS (Weighted Attribute based Strategy), to improve CTS. WAS is inspired by the idea of fault localization, which ranks the program entities to find possible faulty entities. The ranking of entity is considered as a weight of attribute in WAS. And then it helps build up a more suitable distance space for CTS. As a result, a more accurate clustering is obtained to improve CTS. We conducted an experiment on three open-source programs: flex, grep and gzip. The experimental results show that WAS can outperform all existing CTS\u00a0\u2026", "num_citations": "6\n", "authors": ["2158"]}
{"title": "Mubug: a mobile service for rapid bug tracking\n", "abstract": " With the increasing popularity of mobile applications, a light-weighted bug                 tracking systems has been widely needed. While the high release frequency of the                 mobile applications requires a rapid bug tracking system for the software                 maintenance, the needs for users\u2019 feedback can be easily accessed and manipulated                 for both common users and developers, which motivates us to develop a mobile service                 for bug tracking, namely Mubug, by combining the natural language processing                 technique and machine learning technique. Project managers can easily configure and                 setup bug tracking service without any installation on Mubug. Reporters can submit                 bug reports with texts, voices or images using their mobile devices. Bug reports can                 thus be processed and assigned to developers automatically. In this paper, we\u00a0\u2026", "num_citations": "4\n", "authors": ["2158"]}
{"title": "Improving Fault-Localization Accuracy by Referencing Debugging History to Alleviate Structure Bias in Code Suspiciousness\n", "abstract": " Spectrum-based fault localization (SBFL) techniques can automatically localize software faults. They employ the program spectrum, such as code coverage profile with test verdicts, to rank the program entities based on their code suspiciousness. In the past decades, researchers have proposed many approaches to optimize these techniques; however, the program structure, which can influence their performance, is not taken into consideration in developing and improving these techniques. In this article, we identify and analyze the effect of the program structure on the application of SBFL techniques. We observe that some specific program structures may introduce structure bias to code suspiciousness and negatively influence the output of SBFL techniques. To mitigate these effects and improve the performance of fault localization, we propose Delta4Ts, a structure-aware technique. Delta4Ts references debugging\u00a0\u2026", "num_citations": "3\n", "authors": ["2158"]}
{"title": "Quality assessment of crowdsourced test cases\n", "abstract": " Various software-engineering problems have been solved by crowdsourcing. In many projects, the software outsourcing process is streamlined on cloud-based platforms. Among software engineering tasks, test-case development is particularly suitable for crowdsourcing, because a large number of test cases can be generated at little monetary cost. However, the numerous test cases harvested from crowdsourcing can be high- or low-quality. Owing to the large volume, distinguishing the high-quality tests by traditional techniques is computationally expensive. Therefore, crowdsourced testing would benefit from an efficient mechanism distinguishes the qualities of the test cases. This paper introduces an automated approach \u2014 TCQA \u2014 to evaluate the quality of test cases based on the onsite coding history. Quality assessment by TCQA proceeds through three steps: (1) modeling the code history as a time series, (2\u00a0\u2026", "num_citations": "2\n", "authors": ["2158"]}
{"title": "An Empirical Study of the Impact of Code Smell on File Changes\n", "abstract": " Code smells are considered to have negative impacts on software evolution and maintenance. Many researchers have conducted studies to investigate these effects and correlations. However, because code smells constantly change in the evolution, understanding these changes and the correlation between them and the operations of source code files is helpful for developers in maintenance. In this paper, on four popular Java projects with 58 release versions, we conduct an extensive empirical study to investigate the correlation between code smells and basic operations of source code files. We find that, the density of code smells decreases with the software evolution. The files containing smells have a higher likelihood to be modified while smells are not strongly correlated with adding or removing files. Furthermore, some certain smells have significant impact on file changes. These findings are helpful for\u00a0\u2026", "num_citations": "2\n", "authors": ["2158"]}
{"title": "Fault Interference and Coupling Effect\n", "abstract": " Any program may contain more than one fault, and these faults may interfere with each other in a variety of ways. Software behavior may be affected by the interference, resulting in some uncertain results. Such results have negative impact on many software engineering tasks, including regression testing, fault localization, debugging, fault clustering etc. Therefore, understanding the interference becomes an important topic. This paper investigates the fault interference from the perspective of software construction. We introduce the coupling of software construction in order to explain the reasons for fault interference. We observed that different types of coupling may cause three kinds of fault interference and have different probabilities to make the software strike the fault interference traps. We conducted a preliminary experiment on four industrial programs. The results show that our approach gives a good explanation on fault interference.", "num_citations": "2\n", "authors": ["2158"]}
{"title": "Mining sequential patterns of predicates for fault localization and understanding\n", "abstract": " Fault localization has been widely recognized as one of the most costly activities in software engineering. Most of existing techniques target a single faulty entity as the root cause of a failure. However these techniques often fail to reveal the context of a failure which can be valuable for the developers and testers to understand and correct faults. Thus some tentative solutions have been proposed to localize faults as sequences of software entities. However, as far as we know, none of these pioneering works consistently handles execution data in a sequence-oriented way, i.e., they analyze suspiciousness of software entities separately before or after the construction of a faulty sequence. In this paper, we establish a systematic framework based on sequential-pattern mining to assist fault localization. We model the executions of test cases as sequences of predicates. Our framework outputs sequential patterns which\u00a0\u2026", "num_citations": "2\n", "authors": ["2158"]}
{"title": "PyART: Python API Recommendation in Real-Time\n", "abstract": " API recommendation in real-time is challenging for dynamic languages like Python. Many existing API recommendation techniques are highly effective, but they mainly support static languages. A few Python IDEs provide API recommendation functionalities based on type inference and training on a large corpus of Python libraries and third-party libraries. As such, they may fail to recommend or make poor recommendations when type information is missing or target APIs are project-specific. In this paper, we propose a novel approach, PyART, to recommending APIs for Python programs in real-time. It features a light-weight analysis to derive so-called optimistic data-flow, which is neither sound nor complete, but simulates the local data-flow information humans can derive. It extracts three kinds of features: data-flow, token similarity, and token co-occurrence, in the context of the program point where a\u00a0\u2026", "num_citations": "1\n", "authors": ["2158"]}
{"title": "An approach for developing a highly trustworthy crowd-sourced workforce\n", "abstract": " In applying crowd-sourcing techniques, one of the most critical challenges is building a crowd workforce that is both capable and trustworthy. Previous studies proposed numerous strategies, methods, and mechanism to motivate individuals; however, although the results improved the effectiveness and efficiency of finishing crowd-sourcing tasks, few studies focused on improving the honesty of crowd-sourced workers and assisting requesters in obtaining the correct quality report. To address this, based on the principal-agent model and signaling game theory, we design a novel mechanism for building a capable and trustworthy crowd-sourced workforce. This mechanism enables information exchange between crowd-sourced workers and requesters, and leverages a random inspection strategy to assign financial incentives/punishments to honest/dishonest behaviors accordingly. To validate our mechanism, we conduct an extensive simulation. The results show this mechanism is effective and efficient to motivate workers to behave in a trustworthily manner and capable of changing the behavior of dishonest workers with minimal extra cost.", "num_citations": "1\n", "authors": ["2158"]}
{"title": "Leveraging the Power of Crowds: Automated Test Report Processing for The Maintenance of Mobile Applications\n", "abstract": " Crowdsourcing is an emerging distributed problem-solving model combining human and machine computation. It collects intelligence and knowledge from a large and diverse workforce to complete complex tasks. In the software engineering domain, crowdsourced techniques have been adopted to facilitate various tasks, such as design, testing, debugging, development, and so on. Specifically, in crowdsourced testing, crowdsourced workers are given testing tasks to perform and submit their feedback in the form of test reports. One of the key advantages of crowdsourced testing is that it is capable of providing engineers software engineers with domain knowledge and feedback from a large number of real users. Based on diverse software and hardware settings of these users, engineers can bugs that are not caught by traditional quality assurance techniques. Such benefits are particularly ideal for mobile application testing, which needs rapid development-and-deployment iterations and support diverse execution environments. However, crowdsourced testing naturally generates an overwhelming number of crowdsourced test reports, and inspecting such a large number of reports becomes a time-consuming yet inevitable task. This dissertation presents a series of techniques, tools and experiments to assist in crowdsourced report processing. These techniques are designed for improving this task in multiple aspects: 1. prioritizing crowdsourced report to assist engineers in finding as many unique bugs as possible, and as quickly as possible; 2. grouping crowdsourced report to assist engineers in identifying the representative ones in a short time\u00a0\u2026", "num_citations": "1\n", "authors": ["2158"]}