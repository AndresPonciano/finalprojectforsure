{"title": "A hybrid approach to solve the agile team allocation problem\n", "abstract": " The success of the team allocation in a agile software development project is essential. The agile team allocation is a NP-hard problem, since it comprises the allocation of self-organizing and cross-functional teams. Many researchers have driven efforts to apply Computational Intelligence techniques to solve this problem. This work presents a hybrid approach based on NSGA-II multi-objective metaheuristic and Mamdani Fuzzy Inference Systems to solve the agile team allocation problem, together with an initial evaluation of its use in a real environment.", "num_citations": "31\n", "authors": ["1379"]}
{"title": "Toward a hybrid approach to generate software product line portfolios\n", "abstract": " Software Product Line (SPL) development is a new approach to software engineering that aims at the development of a whole range of products. One of the problems which hinders the adoption of that approach is related with the management of the products of the line. Additionally, the scope of a software product line is determined by the bounds of the capabilities provided by the collection of products in the product line. This introduces new challenges related to the scope problem. One of the main three different forms of scoping is the Product Portfolio Scoping (PPS). PPS aims at defining the products that should be developed as well as their key features. While this has an impact on the actual reuse opportunities, it is usually driven from marketing aspects. Defining a product portfolio by considering costumers satisfaction and cost aspects is a NP-hard problem. This work presents a hybrid approach, which\u00a0\u2026", "num_citations": "22\n", "authors": ["1379"]}
{"title": "Localization of a mobile robot based on odometry and natural landmarks using extended kalman filter\n", "abstract": " This work proposes a localization system for mobile robots using the Extended Kalman Filter. The robot navigates in an known environment where the lines of the floor are used as natural landmarks and identifiqued by using the Hough transform.The prediction phase of the Kalman Filter is implemented using the odometry model of the robot. The update phase directly uses the parameters of the lines detected by the Hough algorithm to correct the robot\u2019s pose", "num_citations": "19\n", "authors": ["1379"]}
{"title": "A hybrid approach to suggest software product line portfolios\n", "abstract": " Software product line (SPL) development is a new approach to software engineering which aims at the development of a whole range of products. However, as long as SPL can be useful, there are many challenges regarding the use of that approach. One of the main problems which hinders the adoption of software product line (SPL) is the complexity regarding product management. In that context, we can remark the scoping problem. One of the existent ways to deal with scoping is the product portfolio scoping (PPS). PPS aims to define the products that should be developed as well as their key features. In general, that approach is driven by marketing aspects, like cost of the product and customer satisfaction. Defining a product portfolio by using the many different available aspects is a NP-hard problem. This work presents an improved hybrid approach to solve the feature model selection problem, aiming at\u00a0\u2026", "num_citations": "15\n", "authors": ["1379"]}
{"title": "A hybrid approach for test case prioritization and selection\n", "abstract": " Software testing consists in the dynamic verification of the behavior of a program on a set of test cases. When a program is modified, it must be tested to verify if the changes did not imply undesirable effects on its functionality. The rerunning of all test cases can be impossible, due to cost, time and resource constraints. So, it is required the creation of a test cases subset before the test execution. This is a hard problem and the use of standard Software Engineering techniques could not be suitable. This work presents an approach for test case prioritization and selection, based in relevant inputs obtained from a software development environment. The approach uses Software Quality Function Deployment (SQFD) to deploy the features relevance among the system components, Mamdani fuzzy inference systems to infer the criticality of each class and Ant Colony Optimization to select test cases. An evaluation of the\u00a0\u2026", "num_citations": "14\n", "authors": ["1379"]}
{"title": "On using cell broadband engine for object detection in ITS\n", "abstract": " Trade-off between accuracy and computational cost is usually hard to achieve in order to build a real-time and accurate object recognition system. Many theoretically conceived, efficient computer vision applications are avoided to run on-the-fly for hardware limitations. For recognizing objects in images and extracting object information, a system usually owns object searching, object classification and object tracking modules. Nevertheless, each one of these modules may be high time demanding, requiring to be implemented in different computers in order to achieve efficient runtime. On the other hand, more multi-core processor computers come to provide powerful processing towards full parallel implementations inside cost effective systems. In this way, the main contribution of this paper is not only a survey of works under the main architecture pipeline of object recognition systems in the point of view of computational cost but also pointing some directions to implement those systems in the Cell broadband engine, coming with Playstation 3TM game console. The main purpose is the implementation of a complete object detection system for Intelligent Transportation Systems.", "num_citations": "8\n", "authors": ["1379"]}
{"title": "Representation of Odometry Errors on Occupancy Grids.\n", "abstract": " In this work we propose an enhanced model for mapping from sonar sensors and odometry that allows a robot to represent an environment map in a more suitable way to both the sonar sensory data and odometry system of the robot. We use a stochastic modelling of the errors that brings up reliable information. As a contribution, we obtain a final map that is more coherent with the reality of the original data provided by the robotic system. Practical experiments show the results obtained with the proposed modification to be trustable in such a way that this map can be used to provide previous knowledge to the mobile robot in order to perform its tasks in an easier and accurate way. Moreover, the map can help the robot to support unexpected situations inside of the environment.", "num_citations": "8\n", "authors": ["1379"]}
{"title": "Knowledge Classification for Supporting Effort Estimation in Global Software Engineering Projects\n", "abstract": " Background: Global Software Engineering (GSE) has become a widely applied operational model for the development of software systems; it can increase profits and decrease time-to-market. However, there are many challenges associated with development of software in a globally distributed fashion. There is evidence that these challenges affect many process related to software development, such as effort estimation. To the best of our knowledge, there are no empirical studies to gather evidence on effort estimation in the GSE context. In addition, there is no common terminology for classifying GSE scenarios focusing on effort estimation.Objective: The main objective of this thesis is to support effort estimation in the GSE context by providing a taxonomy to classify the existing knowledge in this field.Method: Systematic literature review (to identify and analyze the state of the art), survey (to identify and analyze the state of the practice), systematic mapping (to identify practices to design software engineering taxonomies), and literature survey (to complement the states of the art and practice) were the methods employed in this thesis.Results: The results on the states of the art and practice show that the effort estimation techniques employed in the GSE context are the same techniques used in the collocated context. It was also identified that global aspects, eg time, geographical and social-cultural distances, are accounted for as cost drivers, although it is not clear how they are measured. As a result of the conducted mapping study, we reported a method that can be used to design new SE taxonomies. The aforementioned results were combined to\u00a0\u2026", "num_citations": "5\n", "authors": ["1379"]}
{"title": "Athena: A visual tool to support the development of computational intelligence systems\n", "abstract": " Computational Intelligence (CI) embraces techniques designed to address complex real-world problems in which traditional approaches are ineffective or infeasible. Some of these techniques are being used to solve several complex problems, such as the team allocation, building products portfolios in a software product line and test case selection/prioritization. However, despite the usefulness of these applications, the development of solutions based in CI techniques is not a trivial activity, since it involves the implementation/adaptation of algorithms to specific context and problems. This work presents Athena, a visual tool developed aiming at offering a simple approach to develop CI-based software systems. In order to do this, we proposed a drag-and-drop approach, which we called CI as a Service (CIaaS). Based on a preliminary study, we can state that Athena can help researchers to save time during the\u00a0\u2026", "num_citations": "5\n", "authors": ["1379"]}
{"title": "A Test Case Prioritization Approach Based on Software Component Metrics\n", "abstract": " The most common way of performing regression testing is by executing all test cases associated with a software system. However, this approach is not scalable since time and cost to execute the test cases increase together with the system's size. A way to address this consists of prioritizing the existing test cases, aiming to maximize a test suite's fault detection rate. To address the limitations of existing approaches, in this paper we propose a new approach to maximize the rate of fault detection of test suites. Our proposal has three steps: i) infer code components' criticality values using a fuzzy inference system; ii) calculate test cases' criticality; iii) prioritize the test cases using ant colony optimization. The test cases are prioritized considering criticality, execution time and history of faults, and the resulting test suites are evaluated according to their fault detection rate. The evaluation was performed in eight programs\u00a0\u2026", "num_citations": "4\n", "authors": ["1379"]}
{"title": "UseSkill: uma ferramenta de apoio \u00e0 avalia\u00e7\u00e3o de usabilidade de sistemas Web\n", "abstract": " A avalia\u00e7\u00e3o de usabilidade de sistemas Web \u00e9 crucial para aumentar sua aceita\u00e7\u00e3o perante seus usu\u00e1rios finais. Entretanto, a complexidade e os custos associados a avalia\u00e7\u00e3o de usabilidade desencorajam a execu\u00e7\u00e3o dessa atividade. Neste trabalho, apresenta-se a ferramenta UseSkill, que visa facilitar a execu\u00e7\u00e3o desse tipo de avalia\u00e7\u00e3o. A ferramenta compara as a\u00e7oes realizadas por usu\u00e1rios \u201cexperientes\u201d e usu\u00e1rios sem conhecimentos no sistema, denominados \u201cnovatos\u201d. Um experimento foi realizado para avaliar a ferramenta proposta. Os resultados mostram que \u00e9 poss\u00edvel identificar problemas de usabilidade com base nas diferen\u00e7as entre o comportamento de usuarios, de forma distribu\u00edda, facilitando assim a aplica\u00e7\u00e3o desse tipo de teste.", "num_citations": "4\n", "authors": ["1379"]}
{"title": "Ferramentas para desenvolvimento de sistemas baseados em intelig\u00eancia computacional: Um mapeamento sistem\u00e1tico\n", "abstract": " Computational Intelligence techniques represent an emerging computational paradigm because they have been successful in solving complex problems in the most diverse areas, however, despite their usefulness, there are few tools that facilitate handling CI techniques to solve a specific problem and, to the best of our knowledge, there is no a paper that includes such tools offering a complete map of this line of research. Thus, this work presents a Systematic Mapping (SM) aiming at identifying tools that provide support to the development of intelligent systems, summarizing the results obtained, identifying gaps in this research area and indicating points to be explored in future works.", "num_citations": "4\n", "authors": ["1379"]}
{"title": "CIaaS-computational intelligence as a service with Athena\n", "abstract": " Computational Intelligence (CI) is a sub-branch of Artificial Intelligence (AI) that focus on studying adaptive mechanisms to enable intelligent behavior in complex environments. CI techniques have been successful in solving complex problems in many different knowledge areas. However, despite their usefulness, developing solutions based on CI techniques is not a trivial activity, since it involves the codification/adaptation of algorithms to specific context and problems. In this paper, we present and validate through a quasi-experiment a new paradigm to develop CI-based solutions using a more mature version of Athena (2.0): Computational Intelligence as a Service (CIaaS). Using this tool, both researchers and practitioners can design and evaluate CI-based solutions by dragging and dropping components in a visual environment, in a cloud-based platform. The results of the quasi-experiment suggest that our\u00a0\u2026", "num_citations": "3\n", "authors": ["1379"]}
{"title": "Strategizing and Evaluating the Onboarding of Software Developers in Large-Scale Globally Distributed Legacy Projects\n", "abstract": " Background: Recruitment and onboarding of software developers are essential steps in software development undertakings. The need for adding new people is often associated with large-scale long-living projects and globally distributed projects. The formers are challenging because they may contain large amounts of legacy (and often complex) code (legacy projects). The latters are challenging, because the inability to find sufficient resources in-house may lead to onboarding people at a distance, and often in many distinct sites. While onboarding is of great importance for companies, there is little research about the challenges and implications associated with onboarding software developers and teams in large-scale globally distributed projects with large amounts of legacy code. Furthermore, no study has proposed any systematic approaches to support the design of onboarding strategies and evaluation of onboarding results in the aforementioned context.Objective: The aim of this thesis is two-fold: i) identify the challenges and implications associated with onboarding software developers and teams in large-scale globally distributed legacy projects; and ii) propose solutions to support the design of onboarding strategies and evaluation of onboarding results in large-scale globally distributed legacy projects.Method: In this thesis, we employed literature review, case study, and business process modeling. The main case investigated in this thesis is the development of a legacy telecommunication software product in Ericsson.Results: The results show that the performance (productivity, autonomy, and lead time) of new developers/teams\u00a0\u2026", "num_citations": "3\n", "authors": ["1379"]}
{"title": "BULNER: BUg Localization with word embeddings and NEtwork Regularization\n", "abstract": " Bug localization (BL) from the bug report is the strategic activity of the software maintaining process. Because BL is a costly and tedious activity, BL techniques information retrieval-based and machine learning-based could aid software engineers. We propose a method for BUg Localization with word embeddings and Network Regularization (BULNER). The preliminary results suggest that BULNER has better performance than two state-of-the-art methods.", "num_citations": "2\n", "authors": ["1379"]}
{"title": "Uma arquitetura distribu\u00edda de hardware e software para controle de um rob\u00f4 m\u00f3vel aut\u00f4nomo\n", "abstract": " Neste trabalho \u00e9 apresentada uma arquitetura de hardware e software para controle do rob\u00f4 m\u00f3vel aut\u00f4nomo Kapeck. O hardware do rob\u00f4 Kapeck \u00e9 composto por um conjunto de sensores e atuadores organizados em um barramento de comunica\u00e7\u00e3o CAN. Dois computadores embarcados e oito placas microcontroladas foram utilizadas no sistema. Um dos computadores foi utilizado para o sistema de vis\u00e3o, devido \u00e0 grande necessidade de processamento deste tipo de sistema. O outro computador foi utilizado para coordenar e acessar o barramento CAN e realizar as outras atividades do rob\u00f4. Placas microcontroladas foram utilizadas nos sensores e atuadores. O rob\u00f4 possui esta configura\u00e7\u00e3o distribu\u00edda para um bom desempenho em tempo-real, onde os tempos de resposta e a previsibilidade temporal do sistema s\u00e3o importantes. Foi seguido o paradigma h\u00edbrido deliberativo-reativo para desenvolver a arquitetura proposta, devido \u00e0 necessidade de aliar o comportamento reativo da rede de sensores-atuadores com as atividades deliberativas necess\u00e1rias para realizar tarefas mais complexas.", "num_citations": "2\n", "authors": ["1379"]}
{"title": "Using Machine Intelligence to Prioritise Code Review Requests\n", "abstract": " Modern Code Review (MCR) is the process of reviewing new code changes that need to be merged with an existing codebase. As a developer, one may receive many code review requests every day, i.e., the review requests need to be prioritised. Manually prioritising review requests is a challenging and time-consuming process. To address the above problem, we conducted an industrial case study at Ericsson aiming at developing a tool called Pineapple, which uses a Bayesian Network to prioritise code review requests. To validate our approach/tool, we deployed it in a live software development project at Ericsson, wherein more than 150 developers develop a telecommunication product. We focused on evaluating the predictive performance, feasibility, and usefulness of our approach. The results indicate that Pineapple has competent predictive performance (RMSE =0.21 and MAE =0.15). Furthermore, around\u00a0\u2026", "num_citations": "1\n", "authors": ["1379"]}
{"title": "Athena: Uma Ferramenta Visual para Auxiliar o Ensino da Intelig\u00eancia Computacional\n", "abstract": " Computational Intelligence (CI) techniques have been used in many different knowledge areas in order to rationalize costs and potentially increase profits. Nevertheless, using this kind of technique is not straight forward, especially in the case of sectors whose practitioners do not have enough programming knowledge. In order to facilitate the teaching, learning, research and usage of CI techniques, we have developed a tool called Athena. In this paper, we report the results of an experiment that we conducted to identify to which extent Athena improves the performance of students during the learning of IC techniques. The results indicate that our tool can be very useful for educators involved in teaching IC.", "num_citations": "1\n", "authors": ["1379"]}