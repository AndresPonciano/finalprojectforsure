{"title": "More dynamic object reclassification: Fickle_II\n", "abstract": " Reclassification changes the class membership of an object at run-time while retaining its identity. We suggest language features for object reclassification, which extend an imperative, typed, class-based, object-oriented language.We present our proposal through the language Fickle\u22c4\u22c4. The imperative features, combined with the requirement for a static and safe type system, provided the main challenges. We develop a type and effect system for Fickle\u22c4\u22c4 and prove its soundness with respect to the operational semantics. In particular, even though objects may be reclassified across classes with different members, there will never be an attempt to access nonexisting members.", "num_citations": "117\n", "authors": ["1514"]}
{"title": "Engineering resilient collective adaptive systems by self-stabilisation\n", "abstract": " Collective adaptive systems are an emerging class of networked computational systems particularly suited for application domains such as smart cities, complex sensor networks, and the Internet of Things. These systems tend to feature large-scale, heterogeneity of communication model (including opportunistic peer-to-peer wireless interaction) and require inherent self-adaptiveness properties to address unforeseen changes in operating conditions. In this context, it is extremely difficult (if not seemingly intractable) to engineer reusable pieces of distributed behaviour to make them provably correct and smoothly composable. Building on the field calculus, a computational model (and associated toolchain) capturing the notion of aggregate network-level computation, we address this problem with an engineering methodology coupling formal theory and computer simulation. On the one hand, functional properties are\u00a0\u2026", "num_citations": "70\n", "authors": ["1514"]}
{"title": "A calculus of computational fields\n", "abstract": " A number of recent works have investigated the notion of \u201ccomputational fields\u201d as a means of coordinating systems in distributed, dense and mobile environments such as pervasive computing, sensor networks, and robot swarms. We introduce a minimal core calculus meant to capture the key ingredients of languages that make use of computational fields: functional composition of fields, functions over fields, evolution of fields over time, construction of fields of values from neighbours, and restriction of a field computation to a sub-region of the network. This calculus can act as a core for actual implementation of coordination languages and models, as well as pave the way towards formal analysis of properties concerning expressiveness, self-stabilisation, topology independence, and relationships with the continuous space-time semantics of spatial computations.", "num_citations": "58\n", "authors": ["1514"]}
{"title": "Code mobility meets self-organisation: A higher-order calculus of computational fields\n", "abstract": " Self-organisation mechanisms, in which simple local interactions result in robust collective behaviors, are a useful approach to managing the coordination of large-scale adaptive systems. Emerging pervasive application scenarios, however, pose an openness challenge for this approach, as they often require flexible and dynamic deployment of new code to the pertinent devices in the network, and safe and predictable integration of that new code into the existing system of distributed self-organisation mechanisms. We approach this problem of combining self-organisation and code mobility by extending \u201ccomputational field calculus\u201d, a universal calculus for specification of self-organising systems, with a semantics for distributed first-class functions. Practically, this allows self-organisation code to be naturally handled like any other data, e.g., dynamically constructed, compared, spread across devices, and\u00a0\u2026", "num_citations": "57\n", "authors": ["1514"]}
{"title": "Efficient engineering of complex self-organising systems by self-stabilising fields\n", "abstract": " Self-organising systems are notoriously difficult to engineer, particularly due to the interactions between complex specifications and the simultaneous need for efficiency and for resilience to faults and changes in execution conditions. We address this problem with an engineering methodology that separates these three aspects, allowing each to be engineered independently. Beginning with field calculus, we identify the largest known sub-language of self-stabilising programs, guaranteed to eventually attain correct behaviour despite any perturbation in state or topology. Construction of complex systems is then facilitated by identifying \"building block\" operators expressed in this language, into which many complex specifications can be readily factored, thereby attaining resilience but possibly with improvable efficiency. Efficient implementation may then be achieved by substituting high-performance coordination\u00a0\u2026", "num_citations": "52\n", "authors": ["1514"]}
{"title": "A calculus of self-stabilising computational fields\n", "abstract": " Computational fields are spatially distributed data structures created by diffusion/aggregation processes, designed to adapt their shape to the topology of the underlying (mobile) network and to the events occurring in it: they have been proposed in a thread of recent works addressing self-organisation mechanisms for system coordination in scenarios including pervasive computing, sensor networks, and mobile robots. A key challenge for these systems is to assure behavioural correctness, namely, correspondence of micro-level specification (computational field specification) with macro-level behaviour (resulting global spatial pattern). Accordingly, in this paper we investigate the propagation process of computational fields, especially when composed one another to achieve complex spatial structures. We present a tiny, expressive, and type-sound calculus of computational fields, enjoying self-stabilisation, i\u00a0\u2026", "num_citations": "49\n", "authors": ["1514"]}
{"title": "A higher-order calculus of computational fields\n", "abstract": " The complexity of large-scale distributed systems, particularly when deployed in physical space, calls for new mechanisms to address composability and reusability of collective adaptive behaviour. Computational fields have been proposed as an effective abstraction to fill the gap between the macro-level of such systems (specifying a system\u2019s collective behaviour) and the micro-level (individual devices\u2019 actions of computation and interaction to implement that collective specification), thereby providing a basis to better facilitate the engineering of collective APIs and complex systems at higher levels of abstraction. This article proposes a full formal foundation for field computations, in terms of a core (higher-order) calculus of computational fields containing a few key syntactic constructs, and equipped with typing, denotational and operational semantics. Critically, this allows formal establishment of a link between the\u00a0\u2026", "num_citations": "47\n", "authors": ["1514"]}
{"title": "Compositional blocks for optimal self-healing gradients\n", "abstract": " With the constant increase in the number of interconnected devices in today networks, and the high demand of adaptiveness, more and more computations can be designed according to self-organisation principles. In this context, a key building block for large-scale system coordination, called gradient, is used to estimate distances in a fully-distributed way: it is the basis for a vast variety of higher level patterns including information broadcast, events forecasting, distributed sensing, and so on. However, computing gradients is very problematic in mobile environments: the fastest self-healing gradient conceived so far (called BIS) achieves a reaction speed proportional to the single-path speed of information in the network. In this paper we introduce a new gradient algorithm, SVD (Stale Values Detection) gradient, which uses broadcasts to reach a reaction speed that is equal to the multi-path speed of information\u00a0\u2026", "num_citations": "40\n", "authors": ["1514"]}
{"title": "On traits and types in a Java-like setting\n", "abstract": " Both single and multiple class-based inheritance are often inappropriate as a reuse mechanism, because classes play two competing roles. Namely, a class is both a generator of instances and a unit of reuse. Traits are composable pure units of behavior reuse, consisting only of methods, that have been proposed as an add-on to single class-based inheritance in order to improve reuse. However, adopting traits as an add-on to traditional class-based inheritance is not enough: classes, besides their primary role of generators of instances, still play the competing role of units of reuse. Therefore, a style of programming oriented to reuse is not enforced by the language, but left to the programmer\u2019s skills. Traits have been originally proposed in the setting of dynamically typed language. When static typing is also taken into account, the role of unit of reuse and the role of type are competing, too.                 We\u00a0\u2026", "num_citations": "39\n", "authors": ["1514"]}
{"title": "Self-adaptation to device distribution in the Internet of Things\n", "abstract": " A key problem when coordinating the behaviour of spatially situated networks, like those typically found in the Internet of Things (IoT), is adaptation to changes impacting network topology, density, and heterogeneity. Computational goals for such systems, however, are often dependent on geometric properties of the continuous environment in which the devices are situated rather than the particulars of how devices happen to be distributed through it. In this article, we identify a new property of distributed algorithms, eventual consistency, which guarantees that computation converges to a final state that approximates a predictable limit, based on the continuous environment, as the density and speed of devices increases. We then identify a large class of programs that are eventually consistent, building on prior results on the field calculus computational model (Beal et al. 2015; Viroli et al. 2015a) that identify a class of\u00a0\u2026", "num_citations": "37\n", "authors": ["1514"]}
{"title": "A type-sound calculus of computational fields\n", "abstract": " A number of recent works have investigated the notion of \u201ccomputational fields\u201d as a means of coordinating systems in distributed, dense and dynamic environments such as pervasive computing, sensor networks, and robot swarms. We introduce a minimal core calculus meant to capture the key ingredients of languages that make use of computational fields: functional composition of fields, functions over fields, evolution of fields over time, construction of fields of values from neighbours, and restriction of a field computation to a sub-region of the network. We formalise a notion of type soundness for the calculus that encompasses the concept of domain alignment, and present a sound static type inference system. This calculus and its type inference system can act as a core for actual implementation of coordination languages and models, as well as to pave the way towards formal analysis of properties concerning\u00a0\u2026", "num_citations": "36\n", "authors": ["1514"]}
{"title": "From field-based coordination to aggregate computing\n", "abstract": " Aggregate computing is an emerging approach to the engineering of complex coordination for distributed systems, based on viewing system interactions in terms of information propagating through collectives of devices, rather than in terms of individual devices and their interaction with their peers and environment. The foundation of this approach is the distillation of a number of prior approaches, both formal and pragmatic, proposed under the umbrella of field-based coordination, and culminating into the field calculus, a functional programming model for the specification and composition of collective behaviours with equivalent local and aggregate semantics. This foundation has been elaborated into a layered approach to engineering coordination of complex distributed systems, building up\u00a0to pragmatic applications through intermediate layers encompassing reusable libraries of provably resilient program\u00a0\u2026", "num_citations": "33\n", "authors": ["1514"]}
{"title": "Separating type, behavior, and state to achieve very fine-grained reuse\n", "abstract": " Recently, Sch{\\\"a}rli et al. pointed out that both single and multiple class-based inheritance are often inappropriate as a reuse mechanism, because classes play two competing roles, namely, a class is both a generator of instances and a unit of reuse. To overcome this problem, Sch{\\\"a}rli et al. proposed traits, which are composable pure units of behavior reuse consisting only of methods. However, both in the original proposal and (to the best of our knowledge) in all the trait-based approaches that can be found in the literature, traits live together with the traditional class-based inheritance. Therefore, besides their primary role of generators of instances, classes can still play a secondary role of units of (state and behavior) reuse, and a style of programming oriented to reuse is not enforced by the language, but left to the programmer's skills. When static typing is also taken into account, the role of unit of reuse and the role of type are competing, too.  We argue that, in order to support the development of reusable program components, class-based statically typed programming languages should be designed according to the principle that each programming construct must have exactly one role. We present language constructs that separate completely the declarations of object type, behavior, state, and generator.", "num_citations": "30\n", "authors": ["1514"]}
{"title": "From distributed coordination to field calculus and aggregate computing\n", "abstract": " Aggregate computing is an emerging approach to the engineering of complex coordination for distributed systems, based on viewing system interactions in terms of information propagating through collectives of devices, rather than in terms of individual devices and their interaction with their peers and environment. The foundation of this approach is the distillation of a number of prior approaches, both formal and pragmatic, proposed under the umbrella of field-based coordination, and culminating into the field calculus, a universal functional programming model for the specification and composition of collective behaviours with equivalent local and aggregate semantics. This foundation has been elaborated into a layered approach to engineering coordination of complex distributed systems, building up to pragmatic applications through intermediate layers encompassing reusable libraries of program components\u00a0\u2026", "num_citations": "28\n", "authors": ["1514"]}
{"title": "Towards a unified model of spatial computing\n", "abstract": " In spatial computing, there is a fundamental tension between discrete and continuous models of computation: computational devices are generally discrete, yet it is often useful to program them in terms of the continuous environment through which they are embedded. Aggregate programming models for spatial computers have attempted to resolve this tension in a variety of different ways, generating a profusion of approaches that are difficult to compare or combine. Recently, however, two minimal models have been proposed: continuous space-time universality and a discrete field calculus. This paper unifies these two models by proving that field calculus is space-time universal, and thus provides the first formal connection between continuous and discrete approaches to spatial computing.", "num_citations": "28\n", "authors": ["1514"]}
{"title": "Stochastic calculus of wrapped compartments\n", "abstract": " The Calculus of Wrapped Compartments (CWC) is a variant of the Calculus of Looping Sequences (CLS). While keeping the same expressiveness, CWC strongly simplifies the development of automatic tools for the analysis of biological systems. The main simplification consists in the removal of the sequencing operator, thus lightening the formal treatment of the patterns to be matched in a term (whose complexity in CLS is strongly affected by the variables matching in the sequences). We define a stochastic semantics for this new calculus. As an application we model the interaction between macrophages and apoptotic neutrophils and a mechanism of gene regulation in E.Coli.", "num_citations": "28\n", "authors": ["1514"]}
{"title": "A decidable intersection type system based on relevance\n", "abstract": " In this paper we introduce a notion of \u201crelevance\u201d for type assignment systems including intersection types. We define a relevant system which is an extension of a particular rank 2 intersection system and of the polymorphic type discipline limited to rank 2. We study some of its properties and finally state the decidability of type inference providing an algorithm which is sound and complete.", "num_citations": "28\n", "authors": ["1514"]}
{"title": "Detecting and removing dead-code using rank 2 intersection\n", "abstract": " In this paper we extend, by allowing the use of rank 2 intersection, the non-standard type assignment system for the detection and elimination of dead-code in typed functional programs presented by Coppo et al in the Static Analysis Symposium '96. The main application of this method is the optimization of programs extracted from proofs in logical frameworks, but it could be used as well in the elimination of dead-code determined by program specialization. The use of nonstandard types (also called annotated types) allows to exploit the type structure of the language for investigating program properties. Dead-code is detected via annotated type inference, which can be performed in a complete way, by reducing it to the solution of a system of inequalities between annotation variables. Even though the language considered in the paper is the simply typed \u03bb-calculus with cartesian product, if-then-else, fixpoint\u00a0\u2026", "num_citations": "27\n", "authors": ["1514"]}
{"title": "Space-time universality of field calculus\n", "abstract": " Recent work in the area of coordination models and collective adaptive systems promotes a view of distributed computations as functional blocks manipulating data structures spread over space and evolving over time. In this paper, we address expressiveness issues of such computations, and specifically focus on the field calculus, a prominent emerging language in this context. Based on the classical notion of event structure, we introduce the cone Turing machine as a ground for studying computability issues, and first use it to prove that field calculus is space-time universal. We then observe that, in the most general case, field calculus computations can be rather inefficient in the size of messages exchanged, but this can be remedied by an encoding to nearly similar computations with slower information speed. We capture this concept by a notion of delayed space-time universality, which we prove to hold\u00a0\u2026", "num_citations": "26\n", "authors": ["1514"]}
{"title": "Refinement types for program analysis\n", "abstract": " In this paper we introduce a system for the detection and elimination of dead code in typed functional programs. The main application of this method is the optimization of programs extracted from proofs in logical frameworks but it could be used as well in the elimination of dead code determined by program specialization. Our algorithm is based on a type inference system suitable for reasoning about dead code information. This system relays on refinement types which allow to exploit the type structure of the language for the investigation of program properties. The detection of dead code is obtained via type inference, which can be performed in an efficient and complete way, by reducing it to the solution of a system of inequalities between type variables. A key feature of our method is that program analysis can be performed in a strictly incremental way. Even though the language considered in the paper is a\u00a0\u2026", "num_citations": "26\n", "authors": ["1514"]}
{"title": "Self-adaptation to device distribution changes\n", "abstract": " A key problem when coordinating the behaviour of devices in situated networks (e.g., pervasive computing, smart cities, Internet of Things, wireless sensor networks) is adaptation to changes impacting network topology, density, and heterogeneity. Computational goals for such systems are often expressed in terms of geometric properties of the continuous environment in which the devices are situated, and the results of resilient computations should depend primarily on that continuous environment, rather than the particulars of how devices happen to be distributed through it. In this paper, we identify a new property of distributed algorithms, eventual consistency, which guarantees that computation self-stabilizes to a final state that approximates a predictable limit as the density and speed of devices increases. We then identify a large class of programs that are eventually consistent, building on prior results on the\u00a0\u2026", "num_citations": "25\n", "authors": ["1514"]}
{"title": "Refined Effects for Unanticipated Object Re-classification: Fickle_3\n", "abstract": " In previous work on the language Fickle and its extension FickleII Dezani and us introduced language features for object re-classification for imperative, typed, class-based, object-oriented languages. In this paper we present the language Fickle3, which on one side refines FickleII with more expressive effect annotations, and on the other eliminates the need to declare explicitly which are the classes of the objects that may be re-classified. Therefore, Fickle3 allows to correctly type meaningful programs which FickleII rejects. Moreover, re-classification may be decided by the client of a class, allowing unanticipated object reclassification. As for FickleII, also the type and effect system for Fickle3 guarantees that, even though objects may be re-classified across classes with different members, they will never attempt to access non existing members.The type and effect system of Fickle3 has some significant differences from the one of FickleII. In particular, besides the fact that intra-class type checking has to track the more refined effects, when a class is combined with other classes some additional inter-class checking is introduced.", "num_citations": "25\n", "authors": ["1514"]}
{"title": "Optimal single-path information propagation in gradient-based algorithms\n", "abstract": " Scenarios like wireless network networks, Internet of Things, and pervasive computing, promote full distribution of computation as well as opportunistic, peer-to-peer interactions between devices spread in the environment. In this context, computing estimated distances between devices in the network is a key component, commonly referred to as the gradient self-organisation pattern: it is frequently used to broadcast information, forecast pointwise events, as carrier for distributed sensing, and as combinator for higher-level spatial structures. However, computing gradients is very problematic in an environment affected by mutability in the position and working frequency of devices: existing algorithms fail in reaching adequate trade-offs between accuracy and reaction speed to environment changes.We propose BIS (Bounded Information Speed) gradient, a fully-distributed algorithm that uses time information to achieve\u00a0\u2026", "num_citations": "22\n", "authors": ["1514"]}
{"title": "Type-based self-stabilisation for computational fields\n", "abstract": " Emerging network scenarios require the development of solid large-scale situated systems. Unfortunately, the diffusion/aggregation computational processes therein often introduce a source of complexity that hampers predictability of the overall system behaviour. Computational fields have been introduced to help engineering such systems: they are spatially distributed data structures designed to adapt their shape to the topology of the underlying (mobile) network and to the events occurring in it, with notable applications to pervasive computing, sensor networks, and mobile robots. To assure behavioural correctness, namely, correspondence of micro-level specification (single device behaviour) with macro-level behaviour (resulting global spatial pattern), we investigate the issue of self-stabilisation for computational fields. We present a tiny, expressive, and type-sound calculus of computational fields, and define sufficient conditions for self-stabilisation, defined as the ability to react to changes in the environment finding a new stable state in finite time. A type-based approach is used to provide a correct checking procedure for self-stabilisation.", "num_citations": "22\n", "authors": ["1514"]}
{"title": "Type-based useless-code elimination for functional programs position paper\n", "abstract": " In this paper we present a survey of the work on type-based useless-code elimination for higher-order functional programs. After some historical remarks on the motivations and early approaches we give an informal but complete account of the techniques and results developed at the Computer Science Department of the University of Torino. In particular, we focus on the fact that, for each of the type-based techniques developed, there is an optimal program simplification.", "num_citations": "22\n", "authors": ["1514"]}
{"title": "Strictness, totality, and non-standard-type inference\n", "abstract": " In this paper we present two non-standard-type inference systems for conjunctive strictness and totality analyses of higher-order-typed functional programs and prove completeness results for both the strictness and the totality-type entailment relations. We also study the interactions between strictness and totality analyses, showing that the information obtainable by a system that combines the two analyses, even though more refined than the information given by the two separate systems, cannot be effectively used. A main feature of our approach is that all the results are proved by relying directly on the operational semantics of the programming language considered. This leads to a rather direct presentation which involves relatively little mathematical overhead.", "num_citations": "21\n", "authors": ["1514"]}
{"title": "Run-time management of computation domains in field calculus\n", "abstract": " The field calculus is proposed as a foundational model for collective adaptive systems, capturing in a tiny language essential aspects of distributed interaction, restriction and evolution, as well as providing ground for engineering resiliency properties. In this paper, we investigate the interplay between interaction and restriction: known as \"domain alignment\" in field calculus, it is extremely powerful but can cause subtle bugs when not handled properly. We propose a disciplined programming approach based on the interplay between a weak and a strong version of alignment, mixing static and dynamic checks. This is exemplified to design a new reusable component dynamically updating the strategy by which a device can extract information from neighbours, which find applications, for instance, in the on-the-fly evolution of metrics in smart mobility applications.", "num_citations": "20\n", "authors": ["1514"]}
{"title": "On type checking delta-oriented product lines\n", "abstract": " A Software Product Line (SPL) is a set of similar programs generated from a common code base. Delta Oriented Programming (DOP) is a flexible approach to implement SPLs. Efficiently type checking an SPL (i.e., checking that all its programs are well-typed) is challenging. This paper proposes a novel type checking approach for DOP. Intrinsic complexity of SPL type checking is addressed by providing early detection of type errors and by reducing type checking to satisfiability of a propositional formula. The approach is tunable to exploit automatically checkable DOP guidelines for making an SPL more comprehensible and type checking more efficient. The approach and guidelines are formalized by means of a core calculus for DOP of product lines of Java programs.", "num_citations": "20\n", "authors": ["1514"]}
{"title": "On designing multicore-aware simulators for biological systems\n", "abstract": " The stochastic simulation of biological systems is an increasingly popular technique in bioinformatics. It often is an enlightening technique, which may however result in being computational expensive. We discuss the main opportunities to speed it up on multi-core platforms, which pose new challenges for parallelisation techniques. These opportunities are developed in two general families of solutions involving both the single simulation and a bulk of independent simulations (either replicas of derived from parameter sweep). Proposed solutions are tested on the parallelisation of the CWC simulator (Calculus of Wrapped Compartments) that is carried out according to proposed solutions by way of the Fast Flow programming framework making possible fast development and efficient execution on multi-cores.", "num_citations": "20\n", "authors": ["1514"]}
{"title": "Rank 2 intersection types for local definitions and conditional expressions\n", "abstract": " We propose a rank 2 intersection type system with new typing rules for local definitions (let-expressions and letrec-expressions) and conditional expressions (if-expressions and match-expressions). This is a further step towards the use of intersection types in \"real\" programming languages.The technique for typing local definitions relies entirely on the principal typing property (i.e. it does not depend on particulars of rank 2 intersection), so it can be applied to any system with principal typings. The technique for typing conditional expressions, which is based on the idea of introducing metrics on types to \"limit the use\" of the intersection type constructor in the types assigned to the branches of the conditionals, is instead tailored to rank 2 intersection. However, the underlying idea might also be useful for other type systems.", "num_citations": "20\n", "authors": ["1514"]}
{"title": "Optimally-self-healing distributed gradient structures through bounded information speed\n", "abstract": " With the constant increase in the number of interconnected devices in\u00a0today networks, more and more computations can be described by spatial computing abstractions. In this context, distances can be estimated in a fully-distributed way by the so-called gradient self-organisation pattern: it is a basic building block also for large-scale system coordination, frequently used to broadcast information, forecast pointwise events, as carrier for distributed sensing, and as combinator for higher-level spatial structures. However, computing gradients is very problematic in a mutable environment: existing algorithms fail in reaching adequate trade offs between accuracy and reaction speed to environment changes.                 In this paper we introduce a new gradient algorithm, BIS (Bounded Information Speed) gradient, which uses time information to achieve a smooth and predictable reaction speed, which is proved\u00a0\u2026", "num_citations": "19\n", "authors": ["1514"]}
{"title": "Abstract compilation of object-oriented languages into coinductive CLP (X): can type inference meet verification?\n", "abstract": " This paper further investigates the potential and practical applicability of abstract compilation in two different directions. First, we formally define an abstract compilation scheme for precise prediction of uncaught exceptions for a simple Java-like language; besides the usual user declared checked exceptions, the analysis covers the runtime ClassCastException. Second, we present a general implementation schema for abstract compilation based on coinductive CLP with variance annotation of user-defined predicates, and propose an implementation based on a Prolog prototype meta-interpreter, parametric in the solver for the subtyping constraints.", "num_citations": "19\n", "authors": ["1514"]}
{"title": "On flexible dynamic trait replacement for java-like languages\n", "abstract": " Dynamic trait replacement is a programming language feature for changing the objects\u2019 behavior at runtime by replacing some of the objects\u2019 methods. In previous work on dynamic trait replacement for Java-like languages, the objects\u2019 methods that may be replaced must correspond exactly to a named trait used in the object\u2019s class definition. In this paper we propose the notion of replaceable: a programming language feature that decouples the trait replacement operation code and the class declaration code, thus making it possible to refactor classes and to perform unanticipated trait replacement operations without invalidating existing code. We give a formal account of our proposal through a core calculus, FDTJ (Featherweight Dynamic Trait Java), equipped with a static type system guaranteeing that in a well-typed program no runtime type error will take place.", "num_citations": "18\n", "authors": ["1514"]}
{"title": "A filter model for mobile processes\n", "abstract": " This paper presents a filter model for \u03c0-calculus and shows its full abstraction with respect to a \u2018may\u2019 operational semantics. The model is introduced in the form of a type assignment system. Types are related by a preorder that mimics the operational behaviour of terms. A subject expansion theorem holds. Terms are interpreted as filters of types: this interpretation is compositional. The proof of full abstraction relies on a notion of realizability of types and on the construction of terms, which test when an arbitrary term has a fixed type.", "num_citations": "18\n", "authors": ["1514"]}
{"title": "Engineering collective intelligence at the edge with aggregate processes\n", "abstract": " Edge computing promotes the execution of complex computational processes without the cloud, i.e., on top of the heterogeneous, articulated, and possibly mobile systems composed of IoT and edge devices. Such a pervasive smart fabric augments our environment with computing and networking capabilities. This leads to a complex and dynamic ecosystem of devices that should not only exhibit individual intelligence but also collective intelligence\u2014the ability to take group decisions or process knowledge among autonomous units of a distributed environment. Self-adaptation and self-organisation mechanisms are also typically required to ensure continuous and inherent toleration of changes of various kinds, to distribution of devices, energy available, computational load, as well as faults. To achieve this behaviour in a massively distributed setting like edge computing demands, we seek for identifying proper\u00a0\u2026", "num_citations": "17\n", "authors": ["1514"]}
{"title": "Hybrid calculus of wrapped compartments\n", "abstract": " The modelling and analysis of biological systems has deep roots in Mathematics, specifically in the field of ordinary differential equations (ODEs). Alternative approaches based on formal calculi, often derived from process algebras or term rewriting systems, provide a quite complementary way to analyze the behaviour of biological systems. These calculi allow to cope in a natural way with notions like compartments and membranes, which are not easy (sometimes impossible) to handle with purely numerical approaches, and are often based on stochastic simulation methods. Recently, it has also become evident that stochastic effects in regulatory networks play a crucial role in the analysis of such systems. Actually, in many situations it is necessary to use stochastic models. For example when the system to be described is based on the interaction of few molecules, when we are at the presence of a chemical instability, or when we want to simulate the functioning of a pool of entities whose compartmentalised structure evolves dynamically. In contrast, stable metabolic networks, involving a large number of reagents, for which the computational cost of a stochastic simulation becomes an insurmountable obstacle, are efficiently modelled with ODEs. In this paper we define a hybrid simulation method, combining the stochastic approach with ODEs, for systems described in CWC, a calculus on which we can express the compartmentalisation of a biological system whose evolution is defined by a set of rewrite rules.", "num_citations": "17\n", "authors": ["1514"]}
{"title": "Automatic useless-code elimination for HOT functional programs\n", "abstract": " In this paper we present two type inference systems for detecting useless-code in higher-order typed functional programs. Type inference can be performed in an efficient and complete way, by reducing it to the solution of a system of constraints. We also give a useless-code elimination algorithm which is based on a combined use of these type inference systems. The main application of the technique is the optimization of programs extracted from proofs in logical frameworks, but it could be used as well in the elimination of useless-code determined by program transformations.", "num_citations": "17\n", "authors": ["1514"]}
{"title": "Non-standard type inference for functional programs\n", "abstract": " We propose a general framework for \u201cnon-standard type inference based\u201d static analyses of typed functional programs and study inference systems (with and without conjunction) for strictness, totality, and dead-code analyses. A key feature of our framework is that it provides a foundation of the program analyses which is based directly on the operational semantics of the programming language considered. This results in a rather direct presentation which involves relatively little mathematical overhead. We develop a semantical investigation of the systems and discuss in some detail possible implementations of the presented analyses. In particular we give sound and complete inference algorithms for strictness and dead-code analyses without conjunction.", "num_citations": "17\n", "authors": ["1514"]}
{"title": "Effective collective summarisation of distributed data in mobile multi-agent systems\n", "abstract": " One of the key applications of physically-deployed multi-agent systems, such as mobile robots, drones, or personal agents in human mobility scenarios, is to promote a pervasive notion of distributed sensing achieved by strict agent cooperation. A quintessential operation of distributed sensing is data summarisation over a region of space, which finds many applications in variations of counting problems: counting items, measuring space, averaging environmental values, and so on. A typical strategy to perform peer-to-peer data summarisation with local interactions is to progressively accumulate information towards one or more collector agents, though this typically exhibits several sources of fragility, especially in scenarios featuring high mobility.In this paper, we introduce a new multi-agent algorithm for dynamic summarisation of distributed data, called parametric weighted multi-path, based on a local strategy to break, send, and then recombine sensed data across neighbours based on their estimated distance, ultimately resulting in the formation of multiple, dynamic and emergent paths of information flow towards collectors. By empirical evaluation via simulation in synthetic and realistic case studies, accounting for various sources of volatility, using different state-of-the-art distance estimations, and comparing to other existing implementations of aggregation algorithms, we show that parametric weighted multi-path is able to retain adequate accuracy even in high-variability scenarios where all other algorithms are significantly diverging from correct estimations.", "num_citations": "14\n", "authors": ["1514"]}
{"title": "A formal model for multi SPLs\n", "abstract": " A Software Product Line (SPL) is a family of similar programs generated from a common artifact base. A Multi SPL (MPL) is a set of interdependent SPLs that are typically managed and developed in a decentralized fashion. Delta-Oriented Programming (DOP) is a flexible and modular approach to implement SPLs. This paper presents new concepts that extend DOP to support the implementation of MPLs. These extensions aim to accommodate compositional analyses. They are presented by means of a core calculus for delta-oriented MPLs of Java programs. Suitability for MPL compositional analyses is demonstrated by compositional reuse of existing SPL analysis techniques.", "num_citations": "14\n", "authors": ["1514"]}
{"title": "A toolchain for delta-oriented modeling of software product lines\n", "abstract": " Software is increasingly individualized to the needs of customers and may have to be adapted to changing contexts and environments after deployment. Therefore, individualized software adaptations may have to be performed. As a large number of variants for affected systems and domains may exist, the creation and deployment of the individualized software should be performed automatically based on the software\u2019s configuration and context. In this paper, we present a toolchain\u00a0to develop and deploy individualized software adaptations based on Software Product Line (SPL) engineering. In particular, we contribute a description and technical realization of a toolchain ranging from variability modeling over variability realization to variant derivation for the automated deployment of individualized software adaptations. To capture the variability within realization artifacts, we employ delta modeling, a\u00a0\u2026", "num_citations": "14\n", "authors": ["1514"]}
{"title": "Alias types for \u201cenvironment-aware\u201d computations\n", "abstract": " In previous work with Bono we introduced a calculus for modelling \u201cenvironment-aware\u201d computations, that is computations that adapt their behavior according to the capabilities of the environment. The calculus is an imperative, object-based language (with extensible objects and primitives for discriminating the presence or absence of attributes of objects) equipped with a small-step operational semantics.In this paper we define a type and effect system for the calculus. The typing judgements specify, via constraints, the shape of environments which guarantees the correct execution of expressions and the typing rules track the effect of expression evaluation on the environment. The type and effect system is sound w.r.t. the operational semantics of the language.", "num_citations": "14\n", "authors": ["1514"]}
{"title": "Simulation techniques for the calculus of wrapped compartments\n", "abstract": " The modelling and analysis of biological systems has deep roots in Mathematics, specifically in the field of Ordinary Differential Equations (ODEs). Alternative approaches based on formal calculi, often derived from process algebras or term rewriting systems, provide a quite complementary way to analyse the behaviour of biological systems. These calculi allow to cope in a natural way with notions like compartments and membranes, which are not easy (sometimes impossible) to handle with purely numerical approaches, and are often based on stochastic simulation methods. Recently, it has also become evident that stochastic effects in regulatory networks play a crucial role in the analysis of such systems. Actually, in many situations it is necessary to use stochastic models. For example when the system to be described is based on the interaction of few molecules, when we are at the presence of a chemical\u00a0\u2026", "num_citations": "13\n", "authors": ["1514"]}
{"title": "Modelling ammonium transporters in arbuscular mycorrhiza symbiosis\n", "abstract": " The Stochastic Calculus of Wrapped Compartments (SCWC) is a recently proposed variant of the Stochastic Calculus of Looping Sequences (SCLS), a language for the representation and simulation of biological systems. In this work we apply SCWC to model a newly discovered ammonium transporter. This transporter is believed to play a fundamental role for plant mineral acquisition, which takes place in the arbuscular mycorrhiza, the most wide-spread plant-fungus symbiosis on earth. Investigating this kind of symbiosis is considered one of the most promising ways to develop methods to nurture plants in more natural manners, avoiding the complex chemical productions used nowadays to produce artificial fertilizers. In our experiments the passage of NH               3 / NH               4               \u2009+\u2009 from the fungus to the plant has been dissected in known and hypothetical mechanisms; with the model so far we\u00a0\u2026", "num_citations": "13\n", "authors": ["1514"]}
{"title": "On re-classification and multithreading\n", "abstract": " In this paper we consider re-classification in the presence of multi-threading. To this aim we define a multi-threaded extension of the language Fickle, that we call FickleMT. We define an operational semantics and a type and effect system for the language. Each method signature carries the information on the possible effects of the method execution. The type and effect system statically checks this information. The operational semantics uses this information in order to delay the execution of some threads when this could cause access to non-existing members of objects. We show that in the execution of a well-typed expression such delays do not produce deadlock. Lastly we discuss a translation from FickleMT into Java, showing how the operational semantics can be implemented with the standard Java multi-threading constructs.", "num_citations": "13\n", "authors": ["1514"]}
{"title": "Aggregate processes in field calculus\n", "abstract": " Engineering distributed applications and services in emerging and open computing scenarios like the Internet of Things, cyber-physical systems and pervasive computing, calls for identifying proper abstractions to smoothly capture collective behaviour, adaptivity, and dynamic injection and execution of concurrent distributed activities. Accordingly, we introduce a notion of \u201caggregate process\u201d as a concurrent field computation whose execution and interactions are sustained by a dynamic team of devices, and whose spatial region can opportunistically vary over time. We formalise this notion by extending the Field Calculus with a new primitive construct, spawn, used to instantiate a set of field computations and regulate key aspects of their life-cycle. By virtue of an open-source implementation in the ScaFi framework, we show basic programming examples and benefits via two case studies of mobile ad-hoc\u00a0\u2026", "num_citations": "12\n", "authors": ["1514"]}
{"title": "Useless-code detection and elimination for pcf with algebraic data types\n", "abstract": " We present a non-standard type assignment system and simplifications mappings for detecting and removing useless-code in simply typed functional programs with algebraic datatypes and recursive functions. We characterize two classes of useless-code: the dead-code, that is code that is never executed under the lazy-call-by-name evaluation, and the minimum-information-code, that is code that contributes to the computation only with a minimum amount of constant information.", "num_citations": "12\n", "authors": ["1514"]}
{"title": "A provenly correct translation of Fickle into Java\n", "abstract": " We present a translation from Fickle, a small object-oriented language allowing objects to change their class at run-time, into Java. The translation is provenly correct, in the sense that we have shown it to preserve the static and dynamic semantics. Moreover, it is compatible with separate compilation, since the translation of a Fickle class does not depend on the implementation of used classes. Based on the formal system, we have developed an implementation. The translation turned out to be a more subtle problem than we expected, and the proofs helped us uncover several subtle errors. In this paper, we discuss four different possible approaches we considered for the design of the translation and justify our choice, we present formally the translation and the proof of preservation of the static and dynamic semantics, and we discuss the prototype implementation. The language Fickle has undergone, and is still undergoing several phases of development. In this paper we are discussing the translation of FickleII.", "num_citations": "12\n", "authors": ["1514"]}
{"title": "Adaptive distributed monitors of spatial properties for cyber\u2013physical systems\n", "abstract": " Cyber\u2013physical systems increasingly feature highly-distributed and mobile deployments of devices spread over large physical environments: in these contexts, it is generally very difficult to engineer trustworthy critical services, mostly because formal methods generally hardly scale with the number of involved devices, especially when faults, continuous changes, and dynamic topologies are the norm. To start addressing this problem, in this paper we devise a formally correct and self-adaptive implementation of distributed monitors for spatial properties. We start from the Spatial Logic of Closure Spaces, and provide a compositional translation that takes a formula and yields a distributed program that provides runtime verification of its validity. Such programs are expressed in terms of the field calculus, a recently emerged computational model that focusses on global-level outcomes instead of single-device behaviour\u00a0\u2026", "num_citations": "11\n", "authors": ["1514"]}
{"title": "On checking delta-oriented product lines of statecharts\n", "abstract": " A Software Product Line (SPL) is a set of programs, called variants, which are generated from a common artifact base. Delta-Oriented Programming (DOP) is a flexible approach to implement SPLs. In this article, we provide a foundation for rigorous development of delta-oriented product lines of statecharts. We introduce a core language for statecharts, we define DOP on top of it, we present an analysis ensuring that a product line is well-formed (i.e., all variants can be generated and are well-formed statecharts), and we illustrate how an implementation of the analysis has been applied to an industrial case study.", "num_citations": "11\n", "authors": ["1514"]}
{"title": "A spatial calculus of wrapped compartments\n", "abstract": " The Calculus of Wrapped Compartments (CWC) is a recently proposed modelling language for the representation and simulation of biological systems behaviour. Although CWC has no explicit structure modelling a spatial geometry, its compartment labelling feature can be exploited to model various examples of spatial interactions in a natural way. However, specifying large networks of compartments may require a long modelling phase. In this work we present a surface language for CWC that provides basic constructs for modelling spatial interactions. These constructs can be compiled away to obtain a standard CWC model, thus exploiting the existing CWC simulation tool. A case study concerning the modelling of Arbuscular Mychorrizal fungi growth is discussed.", "num_citations": "11\n", "authors": ["1514"]}
{"title": "Re-classification and multi-threading: FickleMT\n", "abstract": " In this paper we consider re-classification in the presence of multi-threading. To this aim we define a multi-threaded extension of the language Fickle, that we call Fickle MT. We define an operational semantics and a type and effect system for the language. Each method signature carries the information on the possible effects of the method execution. The type and effect system statically checks this information. The operational semantics uses this information in order to delay the execution of some threads when this could cause messageNotUnderstood errors. We prove that in the execution of a well-typed expression such delays do not produce deadlock.", "num_citations": "11\n", "authors": ["1514"]}
{"title": "FScaFi : A Core Calculus for Collective Adaptive Systems Programming\n", "abstract": " A recently proposed approach to the rigorous engineering of collective adaptive systems is the aggregate computing paradigm, which operationalises the idea of expressing collective adaptive behaviour by a global perspective as a functional composition of dynamic computational fields (i.e., structures mapping a collection of individual devices of a collective to computational values over time). In this paper, we present FScaFi, a core language that captures the essence of exploiting field computations in mainstream functional languages, and which is based on a semantic model for field computations leveraging the novel notion of \u201ccomputation against a neighbour\u201d. Such a construct models expressions whose evaluation depends on the same evaluation that occurred on a neighbour, thus abstracting communication actions and, crucially, enabling deep and straightforward integration in the Scala programming\u00a0\u2026", "num_citations": "10\n", "authors": ["1514"]}
{"title": "A calculus for \u201cenvironment-aware\u201d computation\n", "abstract": " We present a calculus for modelling \u201cenvironment-aware\u201d computations, that is computations that adapt their behaviour according to the capabilities of the environment. The calculus is an imperative, object-based language with extensible objects, equipped with a labelled transition semantics. A notion of bisimulation, lifting to computations a correspondence between the capabilities of different environments, is provided. Bisimulation can be used to prove that a program is \u201ccross-environment\u201d, i.e., it has the same behaviour when run in different environments.", "num_citations": "10\n", "authors": ["1514"]}
{"title": "A formal model for multi software product lines\n", "abstract": " A Software Product Line (SPL) is a family of similar programs generated from a common artifact base. A Multi SPL (MPL) is a set of interdependent SPLs that are typically managed and developed in a decentralized fashion. Delta-Oriented Programming (DOP) is a flexible and modular approach to implement SPLs. This paper presents new concepts that extend DOP to support the implementation of MPLs. These extensions aim to accommodate compositional analyses. They are presented by means of a core calculus for delta-oriented MPLs of Java programs. Suitability for MPL compositional analyses is demonstrated by compositional reuse of existing SPL analysis techniques.", "num_citations": "9\n", "authors": ["1514"]}
{"title": "Distributed real-time shortest-paths computations with the field calculus\n", "abstract": " As the density of sensing/computation/actuation nodes is increasing, it becomes more and more feasible and useful to think at an entire network of physical devices as a single, continuous space-time computing machine. The emergent behaviour of the whole software system is then induced by local computations deployed within each node and by the dynamics of the information diffusion. A relevant example of this distribution model is given by aggregate computing and its companion language field calculus, a minimal set of purely functional constructs used to manipulate distributed data structures evolving over space and time, and resulting in robustness to changes. In this paper, we study the convergence time of an archetypal and widely used component of distributed computations expressed in field calculus, called gradient: a fully-distributed estimation of distances over a metric space by a spanning tree. We\u00a0\u2026", "num_citations": "9\n", "authors": ["1514"]}
{"title": "A novel model-based testing approach for software product lines\n", "abstract": " Model-based testing relies on a model of the system under test. FineFit is a framework for model-based testing of Java programs. In the FineFit approach, the model is expressed by a set of tables based on Parnas tables. A software product line is a family of programs (the products) with well-defined commonalities and variabilities that are developed by (re)using common artifacts. In this paper, we address the issue of using the FineFit approach to support the development of correct software product lines. We specify a software product line as a specification product line where each product is a FineFit specification of the corresponding software product. The main challenge is to concisely specify the software product line while retaining the readability of the specification of a single system. To address this, we used delta-oriented programming, a recently proposed flexible approach for implementing software\u00a0\u2026", "num_citations": "9\n", "authors": ["1514"]}
{"title": "XTRAITJ: Traits for the Java platform\n", "abstract": " Traits were proposed as a mechanism for fine-grained code reuse to overcome many limitations of class-based inheritance. A trait is a set of methods that is independent from any class hierarchy and can be flexibly used to build other traits or classes by means of a suite of composition operations. In this paper we present the new version of Xtraitj, a trait-based programming language that features complete compatibility and interoperability with the Java platform. Xtraitj is implemented in Xtext and Xbase, and it provides a full Eclipse IDE that supports an incremental adoption of traits in existing Java projects. The new version of Xtraitj allows traits to be accessed from any Java project or library, even if the original Xtraitj source code is not available, since traits can be accessed in their byte-code format. This allows developers to create Xtraitj libraries that can be provided in their binary only format. We detail the\u00a0\u2026", "num_citations": "9\n", "authors": ["1514"]}
{"title": "Modelling spatial interactions in the arbuscular mycorrhizal symbiosis using the calculus of wrapped compartments\n", "abstract": " Arbuscular mycorrhiza (AM) is the most wide-spread plant-fungus symbiosis on earth. Investigating this kind of symbiosis is considered one of the most promising ways to develop methods to nurture plants in more natural manners, avoiding the complex chemical productions used nowadays to produce artificial fertilizers. In previous work we used the Calculus of Wrapped Compartments (CWC) to investigate different phases of the AM symbiosis. In this paper, we continue this line of research by modelling the colonisation of the plant root cells by the fungal hyphae spreading in the soil. This study requires the description of some spatial interaction. Although CWC has no explicit feature modelling a spatial geometry, the compartment labelling feature can be effectively exploited to define a discrete surface topology outlining the relevant sectors which determine the spatial properties of the system under consideration. Different situations and interesting spatial properties can be modelled and analysed in such a lightweight framework (which has not an explicit notion of geometry with coordinates and spatial metrics), thus exploiting the existing CWC simulation tool.", "num_citations": "9\n", "authors": ["1514"]}
{"title": "An inference algorithm for strictness\n", "abstract": " In this paper we introduce an algorithm for detecting strictness information in typed functional programs. Our algorithm is based on a type inference system which allows to exploit the type structure of the language for the investigation of program properties. The detection of strictness information can be performed in a complete way, by reducing it to the solution of a set of constraints involving type variables. A key feature of our method is that it is compositional and there is a notion of principal type scheme. Even though the language considered in the paper is the simply typed lambda-calculus with a fixpoint constructor and arithmetic constants we can generalize our approach to polymorphic languages like Lazy ML. Although focused on strictness our method can also be applied to the investigation of other program properties, like dead code and binding time.", "num_citations": "9\n", "authors": ["1514"]}
{"title": "An effective translation of Fickle into Java\n", "abstract": " We present a translation from Fickle (a Java-like language allowing dynamic object re-classification, that is, objects that can change their class at run-time) into plain Java. The translation is proved to preserve static and dynamic semantics; moreover, it is shown to be effective, in the sense that the translation of a Fickle class does not depend on the implementation of used classes, hence can be done in a separate way, that is, without having their sources, exactly as it happens for Java compilation. The aim is to demonstrate that an extension of Java supporting dynamic object re-classification could be fully compatible with the existing Java environment.", "num_citations": "9\n", "authors": ["1514"]}
{"title": "Multi software product lines in the wild\n", "abstract": " Modern software systems are often built from customizable and inter-dependent components. Such customizations usually define which features are offered by the components, and may depend on backend components being configured in a specific way. As such system become very large, with a huge number of possible configurations and complex dependencies between components, maintenance and ensuring the consistency of such systems is a challenge.", "num_citations": "8\n", "authors": ["1514"]}
{"title": "A higher-order calculus of computational fields\n", "abstract": " The complexity of large-scale distributed systems, particularly when deployed in physical space, calls for new mechanisms to address composability and reusability of collective adaptive behaviour. Computational fields have been proposed as an effective abstraction to fill the gap between the macro-level of such systems (specifying a system's collective behaviour) and the micro-level (individual devices' actions of computation and interaction to implement that collective specification), thereby providing a basis to better facilitate the engineering of collective APIs and complex systems at higher levels of abstraction. This paper proposes a full formal foundation for field computations, in terms of a core (higher-order) calculus of computational fields containing a few key syntactic constructs, and equipped with typing, denotational and operational semantics. Critically, this allows formal establishment of a link between the micro- and macro-levels of collective adaptive systems, by a result of full abstraction and adequacy for the (aggregate) denotational semantics with respect to the (per-device) operational semantics.", "num_citations": "8\n", "authors": ["1514"]}
{"title": "Refactoring delta-oriented product lines to achieve monotonicity\n", "abstract": " Delta-oriented programming (DOP) is a flexible transformational approach to implement software product lines. In delta-oriented product lines, variants are generated by applying operations contained in delta modules to a (possibly empty) base program. These operations can add, remove or modify named elements in a program (e.g., classes, methods and fields in a Java program). This paper presents algorithms for refactoring a delta-oriented product line into monotonic form, i.e., either to contain add and modify operations only (monotonic increasing) or to contain remove and modify operations only (monotonic decreasing). Because of their simpler structure, monotonic delta-oriented product lines are easier to analyze. The algorithms are formalized by means of a core calculus for DOP of product lines of Java programs and their correctness and complexity are given.", "num_citations": "8\n", "authors": ["1514"]}
{"title": "Refactoring delta-oriented product lines to enforce guidelines for efficient type-checking\n", "abstract": " A Software Product Line (SPL) is a family of similar programs generated from a common code base. Delta-Oriented Programming (DOP) is a flexible and modular approach to construct SPLs. Ensuring type safety in an SPL (i.e., ensuring that all its programs are well-typed) is a computationally expensive task. Recently, five guidelines to address the complexity of type checking delta-oriented SPLs have been proposed. This paper presents algorithms to refactor delta-oriented SPLs in order to follow the five guidelines. Complexity and correctness of the refactoring algorithms are stated.", "num_citations": "7\n", "authors": ["1514"]}
{"title": "Pure trait-based programming on the Java platform\n", "abstract": " Traits provide a mechanism for fine-grained code reuse to overcome the limitations of class-based inheritance. A trait is a set of methods which is completely independent from any class hierarchy and can be flexibly used to build other traits or classes by means of a suite of composition operations. We present:(i) a formulation of traits which aims to achieve complete compatibility and interoperability with the Java platform without reducing the flexibility of traits, and (ii) an integration with Eclipse which aims to support an incremental adoption of traits in existing Java projects. Indeed, the proposed trait language can coexist with Java code. Single parts of a project can be refactored to use traits, without requiring a complete rewrite of the whole existing code-base.", "num_citations": "7\n", "authors": ["1514"]}
{"title": "Combining traits with boxes and ownership types in a Java-like setting\n", "abstract": " The box model is a lightweight component model for the object-oriented paradigm, which structures the flat object-heap into hierarchical runtime components called boxes. Boxes have clear runtime boundaries that divide the objects of a box into objects that can be used to interact with the box (the boundary objects) and objects that are encapsulated and represent the state of the box (the local objects). The distinction into local and boundary objects is statically achieved by an ownership type system for boxes that uses domain annotations to classify objects into local and boundary objects and that guarantees that local objects can never be directly accessed by the context of a box. A trait is a set of methods divorced from any class hierarchy. Traits are units of fine-grained reuse that can be composed together to form classes or other traits. This paper integrates traits into an ownership type system for boxes. This\u00a0\u2026", "num_citations": "7\n", "authors": ["1514"]}
{"title": "On parallelizing on-line statistics for stochastic biological simulations\n", "abstract": " This work concerns a general technique to enrich parallel version of stochastic simulators for biological systems with tools for on-line statistical analysis of the results. In particular, within the FastFlow parallel programming framework, we describe the methodology and the implementation of a parallel Monte Carlo simulation infrastructure extended with user-defined on-line data filtering and mining functions. The simulator and the on-line analysis were validated on large multi-core platforms and representative proof-of-concept biological systems.", "num_citations": "7\n", "authors": ["1514"]}
{"title": "A calculus of agents and artifacts\n", "abstract": " A library-based extension of Java, the simpA framework, introduced a new abstraction based on agent-oriented concepts. Agents are autonomous entities that cooperate by exploiting artifacts, representing resources that are dynamically created and shared by agents. In this paper we present a core calculus integrating techniques coming from the area of concurrency and from OO programming. The syntax of the calculus with its static and dynamic semantics are introduced through an example. The calculus aims to foster the formalization (and proof) of type soundness of simpA programs and the development of techniques for analyzing the computational behaviour of agents and artifacts.", "num_citations": "7\n", "authors": ["1514"]}
{"title": "A mechanism for flexible dynamic trait replacement\n", "abstract": " Dynamic trait replacement is a programming language feature for changing the objects' behavior at runtime by replacing some of the objects' methods. In previous work on dynamic trait replacement for JAVA-like languages, the object's methods that may be replaced must correspond exactly to a named trait used in the object's class definition. In this paper we propose the notion of replaceable: a programming language feature that decouples trait replacement operation code and class declaration code, thus making it possible refactoring classes and/or performing unanticipated trait replacement operations without invalidating existing code.", "num_citations": "7\n", "authors": ["1514"]}
{"title": "Types for Proofs and Programs\n", "abstract": " Types for Proofs and Programs - NASA/ADS Now on home page ads icon ads Enable full ADS view NASA/ADS Types for Proofs and Programs Berardi, Stefano ; Damiani, Ferruccio ; de'Liguoro, Ugo Abstract Publication: Lecture Notes in Computer Science Pub Date: 2009 DOI: 10.1007/978-3-642-02444-3 Bibcode: 2009LNCS......B Keywords: Computer Science; Logics and Meanings of Programs; Mathematical Logic and Formal Languages; Programming Languages; Compilers; Interpreters; Symbolic and Algebraic Manipulation; Artificial Intelligence (incl. Robotics) full text sources Publisher | \u00a9 The SAO/NASA Astrophysics Data System adshelp[at]cfa.harvard.edu The ADS is operated by the Smithsonian Astrophysical Observatory under NASA Cooperative Agreement NNX16AC86A NASA logo Smithsonian logo Resources About ADS ADS Help What's New Careers@ADS Social @adsabs ADS Blog Project Switch \u2026", "num_citations": "7\n", "authors": ["1514"]}
{"title": "A conjunctive type system for useless-code elimination\n", "abstract": " We investigate the use of conjunctive non-standard type inference for the elimination of useless code in higher-order typed functional programs. In particular, we present a non-standard type assignment system for detecting useless code together with a mapping that simplifies a program by removing the useless code detected using the system.", "num_citations": "7\n", "authors": ["1514"]}
{"title": "On strictness and totality\n", "abstract": " In this paper we present a revised and extended version of the strictness and totality type assignment system introduced by Solberg, Nielson and Nielson in the Static Analysis Symposium '94. Our main result is that (w.r.t. the possibility of replacing safely a lazy application by a strict one) the strictness and totality information given by this system is equivalent to the information given by two separate systems: one for strictness, and one for totality. This result is interesting from both a theoretical (understanding of the relations between strictness and totality) and a practical (more efficient checking and inference algorithms) point of view. Moreover we prove that both the system for strictness and the system for totality have a sound and complete inclusion relation between types w.r.t. the semantics induced by the term model of a language including a convergence to weak head normal form test at higher types.", "num_citations": "7\n", "authors": ["1514"]}
{"title": "The share Operator for Field-Based Coordination\n", "abstract": " Recent work in the area of coordination models and collective adaptive systems promotes a view of distributed computations as functions manipulating computational fields (data structures spread over space and evolving over time), and introduces the field calculus as a formal foundation for field computations. With the field calculus, evolution (time) and neighbor interaction (space) are handled by separate functional operators: however, this intrinsically limits the speed of information propagation that can be achieved by their combined use. In this paper, we propose a new field-based coordination operator called share, which captures the space-time nature of field computations in a single operator that declaratively achieves: (i) observation of neighbors\u2019 values; (ii) reduction to a single local value; and (iii) update and converse sharing to neighbors of a local variable. In addition to conceptual economy, use\u00a0\u2026", "num_citations": "6\n", "authors": ["1514"]}
{"title": "Generic traits for the Java platform\n", "abstract": " A trait is a set of methods that is independent from any class hierarchy and can be flexibly used to build other traits or classes by means of a suite of composition operations. Traits were proposed as a mechanism for fine-grained code reuse to overcome many limitations of class-based inheritance. In this paper we present the extended version of Xtraitj, a trait-based programming language that features complete compatibility and interoperability with the Java platform. Xtraitj provides a full Eclipse IDE that aims to support an incremental adoption of traits in existing Java projects. This new version fully supports Java generics: traits can have type parameters just like in Java, so that they can completely interoperate with any existing Java library. Furthermore, Xtraitj now supports Java annotations, so that it can integrate with frameworks like JUnit 4.", "num_citations": "6\n", "authors": ["1514"]}
{"title": "Refinement-based testing of delta-oriented product lines\n", "abstract": " We present an approach for specifying and testing delta-oriented software product lines (SPLs) of Java programs. To this end we extend FineFit---a tool and an approach for refinement-based testing of single products. The input to FineFit consists of an abstract model (ie, the specification of the program) given as a set of tables, and a retrieve function which maps concrete states (of the program under test) to abstract states (of the model). To leverage FineFit for testing of SPLs we propose the concept of delta tables for specifying SPLs, and we use DeltaJ, a delta-oriented programming language, for implementing the retrieve functions of the various software products. Our preliminary investigations suggest that the new ideas can significantly reduce the amount of input, repetition, and mistakes done by the user.", "num_citations": "6\n", "authors": ["1514"]}
{"title": "A type system for checking specialization of packages in object-oriented programming\n", "abstract": " Large object-oriented software systems are usually structured using modules or packages to enable large-scale development using clean interfaces that promote encapsulation and information hiding. However, in most OO languages, package interfaces (or signatures) are only implicitly defined.", "num_citations": "6\n", "authors": ["1514"]}
{"title": "Standard type soundness for agents and artifacts\n", "abstract": " Formal models, core calculi, and type systems, are important tools for rigorously stating the more subtle details of a language, to characterise and study its features and the correctness properties of its programs. In this paper we present FAAL (Featherweight Agent and Artifact Language), a formal calculus modelling the agent and artifact program abstractions provided by the simpA agent framework. The formalisation is largely inspired by Featherweight Java. It is based on reduction rules applied at certain evaluation contexts, properly adapted to the concurrency nature of simpA. On top of this calculus we introduce a standard type system and prove its soundness, so as to guarantee that the execution of a well-typed program does not get stuck. Namely, all primitive mechanisms of agents (activity execution), artifacts (eld/property access and step execution), and their interaction (observation and invocation) are guaranteed to be used in a way that is structurally compliant with the corresponding denitions: hence, there will not be run-time errors due to FAAL distinctive primitives.", "num_citations": "6\n", "authors": ["1514"]}
{"title": "On state classes and their dynamic semantics\n", "abstract": " We introduce state classes, a construct to program objects that can be safely concurrently accessed. State classes model the notion of object\u2019s state (intended as some abstraction over the value of fields) that plays a key role in concurrent object-oriented programming (as the state of an object changes, so does its coordination behavior). We show how state classes can be added to Java-like languages by presenting StateJ, an extension of Java with state classes. The operational semantics of the state class construct is illustrated both at an abstract level, by means of a core calculus for StateJ, and at a concrete level, by defining a translation from StateJ into Java.", "num_citations": "6\n", "authors": ["1514"]}
{"title": "Aggregate graph statistics\n", "abstract": " Collecting statistic from graph-based data is an increasingly studied topic in the data mining community. We argue that these statistics have great value as well in dynamic IoT contexts: they can support complex computational activities involving distributed coordination and provision of situation recognition. We show that the HyperANF algorithm for calculating the neighbourhood function of vertices of a graph naturally allows for a fully distributed and asynchronous implementation, thanks to a mapping to the field calculus, a distribution model proposed for collective adaptive systems. This mapping gives evidence that the field calculus framework is well-suited to accommodate massively parallel computations over graphs. Furthermore, it provides a new \"self-stabilising\" building block which can be used in aggregate computing in several contexts, there including improved leader election or network vulnerabilities detection.", "num_citations": "5\n", "authors": ["1514"]}
{"title": "A calculus for boxes and traits in a Java-like setting\n", "abstract": " The box model is a component model for the object-oriented paradigm, that defines components (the boxes) with clear encapsulation boundaries. Having well-defined boundaries is crucial in component-based software development, because it enables to argue about the interference and interaction between a component and its context. In general, boxes contain several objects and inner boxes, of which some are local to the box and cannot be accessed from other boxes and some can be accessible by other boxes. A trait is a set of methods divorced from any class hierarchy. Traits can be composed together to form classes or other traits. We present a calculus for boxes and traits. Traits are units of fine-grained reuse, whereas boxes can be seen as units of coarse-grained reuse. The calculus is equipped with an ownership type system and allows us to combine coarse- and fine-grained reuse of code by\u00a0\u2026", "num_citations": "5\n", "authors": ["1514"]}
{"title": "Dipartimento di Informatica\n", "abstract": " Bibliography of \"Formal Methods in Computing\" Chronological Overview Type-Hierarchical Overview Formal Methods in Computing (Most of the papers antecedent to 1995 are not included in the list) FRAMES NO FRAME DIPARTIMENTO DI INFORMATICA Universit\u00e0 degli Studi di Torino Formal Methods in Computing 2018 Paolini, Piccolo and Zorzi \"QPCF: higher order languages and quantum circuits\" Technical report. 2017 Paolini, Piccolo and Luca \"A class of Recursive Permutations which is Primitive Recursive complete\" Technical report. 2015 Paolini, Piccolo and Roversi \"Big and Small-step Operational Semantics of the Reversible Programming Language Janus\" Technical report. 2012 Aldinucci, Danelutto and Torquati \"FastFlow tutorial\" Technical report. 2011 Aldinucci, Drocco, Giordano, Spampinato and Torquati \"A Parallel Edge Preserving Algorithm for Salt and Pepper Image Denoising\" Technical report. \u2026", "num_citations": "5\n", "authors": ["1514"]}
{"title": "Solving the Santa Claus problem using state classes\n", "abstract": " In this paper we present a solution to the Santa Claus problem by using the state class construct. The Santa Claus problem is a programming exercise that has been used to illustrate the concurrency primitives of Ada, Java, and Polyphonic C\u266f.", "num_citations": "5\n", "authors": ["1514"]}
{"title": "Rank 2 intersection types for modules\n", "abstract": " We propose a rank 2 intersection type system for a language of modules built on a core ML-like language. The principal typing property of the rank 2 intersection type system for the core language plays a crucial role in the design of the type system for the module language. We first consider a\" plain\" notion of module, where a module is just a set of mutually recursive top-level definitions, and illustrate the notions of: module intrachecking (each module is typechecked in isolation and its interface, which is the set of typings of the defined identifiers, is inferred); interface interchecking (when linking modules, typechecking is done just by looking at the interfaces); interface specialization (interface intrachecking may require to specialize the typing listed in the interfaces); principal interfaces (the principal typing property for the type system of modules); and separate typechecking (looking at the code of the modules does not\u00a0\u2026", "num_citations": "5\n", "authors": ["1514"]}
{"title": "Typing local definitions and conditional expressions with rank 2 intersection\n", "abstract": " We introduce a variant of the system of rank 2 intersection types with new typing rules for local definitions (let-expressions and letrec-expressions) and conditional expressions (if-expressions and case-expressions). These extensions are a further step towards the use of intersection types in \u201creal\u201d programming languages.", "num_citations": "5\n", "authors": ["1514"]}
{"title": "Inference based analyses of functional programs: dead-code and strictness\n", "abstract": " We present a simple framework for \"non-standard type inference based\"                    analyses of functional programs and show how to apply it to dead-code and                    strictness analyses. A key feature of this framework is that is based directly                    on operational semantics.", "num_citations": "5\n", "authors": ["1514"]}
{"title": "On designing multicore-aware simulators for systems biology endowed with online statistics\n", "abstract": " The paper arguments are on enabling methodologies for the design of a fully parallel, online, interactive tool aiming to support the bioinformatics scientists .In particular, the features of these methodologies, supported by the FastFlow parallel programming framework, are shown on a simulation tool to perform the modeling, the tuning, and the sensitivity analysis of stochastic biological models. A stochastic simulation needs thousands of independent simulation trajectories turning into big data that should be analysed by statistic and data mining tools. In the considered approach the two stages are pipelined in such a way that the simulation stage streams out the partial results of all simulation trajectories to the analysis stage that immediately produces a partial result. The simulation-analysis workflow is validated for performance and effectiveness of the online analysis in capturing biological systems behavior on a multicore platform and representative proof-of-concept biological systems. The exploited methodologies include pattern-based parallel programming and data streaming that provide key features to the software designers such as performance portability and efficient in-memory (big) data management and movement. Two paradigmatic classes of biological systems exhibiting multistable and oscillatory behavior are used as a testbed.", "num_citations": "4\n", "authors": ["1514"]}
{"title": "Parameter identification and assessment of nutrient transporters in AM symbiosis through stochastic simulations\n", "abstract": " This paper presents a methodology for identifying the kinetic parameters of a biological system and their relationships with the concentration variations of the species by means of in silico experiments. A nonlinear goal programming technique is employed to identify the kinetic parameters that best satisfy the biological hypothesis of the system behaviour. The simulations are performed on a stochastic simulator for the Calculus of Wrapped Compartments. The extraction of parameters with optimization techniques is usually applied to systems modeled by means of differential equations. Its application in a stochastic framework is rather new. The methodology may open a new path for the investigation of a broader class of biochemical systems (including those that cannot be easily modeled by differential equations) when in vitro experimental measurements are unavailable. The methodology is applied to model the\u00a0\u2026", "num_citations": "4\n", "authors": ["1514"]}
{"title": "Formal Verification of Object-Oriented Software\n", "abstract": " This volume contains the invited papers, research papers, case studies, and position papers presented at the International Conference on Formal Verification of Object-Oriented Software (FoVeOOS 2011), that was held October 5-7, 2011 in Torino, Italy. Post-conference proceedings with revised versions of selected papers will be published within Springer\u2019s Lecture Notes in Computer Science series after the conference.Formal software verification has outgrown the area of academic case studies, and industry is showing serious interest. The logical next goal is the verification of industrial software products. Most programming languages used in industrial practice are object-oriented, eg Java, C++, or C\u266f. FoVeOOS 2011 aimed to foster collaboration and interactions among researchers in this area.", "num_citations": "4\n", "authors": ["1514"]}
{"title": "Featherweight agent language: a core calculus for agents and artifacts\n", "abstract": " The widespread diffusion and availability of multicore architectures is going to make more and more aspects of concurrency and distribution to be part of mainstream programming and software engineering. The SIMPA framework is a recently proposed library-based extension of JAVA that introduces on top of the OO layer a new abstraction layer based on agent-oriented concepts. Asimpa program is organized in terms of dynamic set of autonomous pro-active task-oriented entities\u2013the agents\u2013that cooperate by exploiting some artifacts, that represents resources and tools that are dynamically constructed, shared and co-used by agents. In this paper we promote the applicability of the agent and artifact metamodel in OO programming a step further. Namely, we propose a core calculus that integrates techniques coming from concurrency theory and from OO programming languages to provide a first basic formal framework for designing agent-oriented languages and studying properties of agent-oriented programs.", "num_citations": "4\n", "authors": ["1514"]}
{"title": "On polymorphic recursion, type systems, and abstract interpretation\n", "abstract": " The problem of typing polymorphic recursion (i.e. recursive function definitions rec {x=e} where different occurrences of x in e are used with different types) has been investigated both by people working on type systems and by people working on abstract interpretation.               Recently, Gori and Levi have developed a family of abstract interpreters that are able to type all the ML typable recursive definitions and interesting examples of polymorphic recursion. The problem of finding type systems corresponding to their abstract interpreters was open (such systems would lie between the let-free-free fragments of the ML and of the Milner-Mycroft systems).               In this paper we exploit the notion of principal typing to: (i) provide a complete stratification of (let-free) Milner-Mycroft typability, and (ii) solve the problem of finding type systems corresponding to the type abstract interpreters proposed by Gori and Levi.", "num_citations": "4\n", "authors": ["1514"]}
{"title": "Rank 2 intersection for recursive definitions\n", "abstract": " Let\u22a2 be an intersection type system. We say that a term is\u22a2-simple (or just simple when the system\u22a2 is clear from the context) if system\u22a2 can prove that it has a simple type. In this paper we propose new typing rules and algorithms that are able to type (with rank 2 intersection types) recursive definitions that are not simple. Typing rules for assigning intersection types to (nonsimple) recursive definitions have been already proposed in the literature. However, at the best of our knowledge, previous algorithms for typing recursive definitions in the presence of intersection types allow only simple recursive definitions to be typed. The rules and algorithms proposed in this paper are also able to type interesting examples of polymorphic recursion (ie, recursive definitions rec {x= e} where different occurrences of x in e are used with different types). Moreover, the underlying techniques do not depend on particulars of rank 2\u00a0\u2026", "num_citations": "4\n", "authors": ["1514"]}
{"title": "Refined effects for re-classification: FickleIII\n", "abstract": " In this paper we present the language FickleIII, which refines FickleII with a more expressive type and effect system. FickleIII allows to correctly type meaningful programs which FickleII reject. This is done by taking into account the initial and the final class of each reclassification. The syntax of FickleIII and the syntax of FickleII differ only in the effect annotations occurring in methods\u2019 signatures (every FickleII-style effect annotation can be coded into a FickleIII-style effect annotation, but not vice versa). The operational semantics (which ignores effect annotations) is unchanged.", "num_citations": "4\n", "authors": ["1514"]}
{"title": "Conjunctive Types and Useless-code Elimination.\n", "abstract": " We investigate the use of conjunctive non-standard type inference for the elimination of useless-code in higher-order typed functional programs. In particular, we present a non-standard type assignment system for detecting useless-code and a mapping that simplifies a program by removing all the useless-code that can be detected by using the system.", "num_citations": "4\n", "authors": ["1514"]}
{"title": "Aggregate centrality measures for IoT-based coordination\n", "abstract": " Collecting statistics from graph-based data is an increasingly studied topic in the data mining community. We argue that they can have great value in the coordination of dynamic IoT systems as well, especially to support complex coordination strategies related to distributed situation recognition.Thanks to a mapping to the field calculus, a distribution coordination model proposed for collective adaptive systems, we show that many existing \u201ccentrality measures\u201d for graphs can be naturally turned into field computations that compute the centrality of nodes in a network. Not only this mapping gives evidence that the field coordination is well-suited to accommodate massively parallel computations over graphs, but also it provides a new basic \u201cbrick\u201d of coordination which can be used in several contexts, there including improved leader election or network vulnerabilities detection. We validate our findings by simulation, first\u00a0\u2026", "num_citations": "3\n", "authors": ["1514"]}
{"title": "A formal model of the kubernetes container framework\n", "abstract": " Loosely-coupled distributed systems organized as collections of so-called cloud-native microservices are able to adapt to traffic in very fine-grained and flexible ways. For this purpose, the cloud-native microservices exploit containerization and container management systems such as Kubernetes. This paper presents a formal model of resource consumption and scaling for containerized microservices deployed and managed by Kubernetes. Our aim is that the model, developed in Real-Time ABS, can be used as a framework to explore the behavior of deployed systems under various configurations at design time\u2014before the systems are actually deployed. We further present initial results comparing the observed behavior of instances of our modeling framework to corresponding observations of real systems. These preliminary results suggest that the modeling framework can provide a satisfactory accuracy with\u00a0\u2026", "num_citations": "3\n", "authors": ["1514"]}
{"title": "Resilient distributed collection through information speed thresholds\n", "abstract": " One of the key coordination problems in physically-deployed distributed systems, such as mobile robots, wireless sensor networks, and IoT systems in general, is to provide notions of \u201cdistributed sensing\u201d achieved by the strict, continuous cooperation and interaction among individual devices. An archetypal operation of distributed sensing is data summarisation over a region of space, by which several higher-level problems can be addressed: counting items, measuring space, averaging environmental values, and so on. A typical coordination strategy to perform data summarisation in a peer-to-peer scenario, where devices can communicate only with a neighbourhood, is to progressively accumulate information towards one or more collector devices, though this typically exhibits problems of reactivity and fragility, especially in scenarios featuring high mobility. In this paper, we propose coordination\u00a0\u2026", "num_citations": "3\n", "authors": ["1514"]}
{"title": "Field-based coordination with the share operator\n", "abstract": " Field-based coordination has been proposed as a model for coordinating collective adaptive systems, promoting a view of distributed computations as functions manipulating data structures spread over space and evolving over time, called computational fields. The field calculus is a formal foundation for field computations, providing specific constructs for evolution (time) and neighbor interaction (space), which are handled by separate operators (called rep and nbr, respectively). This approach, however, intrinsically limits the speed of information propagation that can be achieved by their combined use. In this paper, we propose a new field-based coordination operator called share, which captures the space-time nature of field computations in a single operator that declaratively achieves: (i) observation of neighbors' values; (ii) reduction to a single local value; and (iii) update and converse sharing to neighbors of a local variable. We show that for an important class of self-stabilising computations, share can replace all occurrences of rep and nbr constructs. In addition to conceptual economy, use of the share operator also allows many prior field calculus algorithms to be greatly accelerated, which we validate empirically with simulations of frequently used network propagation and collection algorithms.", "num_citations": "3\n", "authors": ["1514"]}
{"title": "On distributed runtime verification by aggregate computing\n", "abstract": " Runtime verification is a computing analysis paradigm based on observing a system at runtime (to check its expected behaviour) by means of monitors generated from formal specifications. Distributed runtime verification is runtime verification in connection with distributed systems: it comprises both monitoring of distributed systems and using distributed systems for monitoring. Aggregate computing is a programming paradigm based on a reference computing machine that is the aggregate collection of devices that cooperatively carry out a computational process: the details of behaviour, position and number of devices are largely abstracted away, to be replaced with a space-filling computational environment. In this position paper we argue, by means of simple examples, that aggregate computing is particularly well suited for implementing distributed monitors. Our aim is to foster further research on how to generate aggregate computing monitors from suitable formal specifications.", "num_citations": "3\n", "authors": ["1514"]}
{"title": "CWC simulator (Calculus of Wrapped Compartments)\n", "abstract": " The CWC simulator is a simulation tool for the Calculus of Wrapped Compartments (CWC) that is based on Gillespie\u2019s direct method supporting the simulation and the analysis simulating biological phenomena. The CWC simulator is parallel application able to exploit the full power of multicore platforms by way of the fastflow lock-free C++ library.", "num_citations": "3\n", "authors": ["1514"]}
{"title": "Rank-2 intersection and polymorphic recursion\n", "abstract": " Let \u22a2 be a rank-2 intersection type system. We say that a term is \u22a2 -simple (or just simple when the system \u22a2 is clear from the context) if system \u22a2 can prove that it has a simple type. In this paper we propose new typing rules and algorithms that are able to type recursive definitions that are not simple. At the best of our knowledge, previous algorithms for typing recursive definitions in the presence of rank-2 intersection types allow only simple recursive definitions to be typed. The proposed rules are also able to type interesting examples of polymorphic recursion (i.e., recursive definitions rec {x = e} where different occurrences of x in e are used with different types). Moreover, the underlying techniques do not depend on particulars of rank-2 intersection, so they can be applied to other type systems.", "num_citations": "3\n", "authors": ["1514"]}
{"title": "Automatic refactoring of delta-oriented SPLs to remove-free form and replace-free form\n", "abstract": " Delta-oriented programming (DOP) is a flexible transformational approach to implement software product lines (SPLs). In delta-oriented SPLs, variants are generated by applying operations contained in delta modules to a base program. These operations can add, remove or modify named elements in a program (eg classes, methods and fields in a Java program). This paper presents two notions of normal form for delta-oriented SPLs. Both normal forms do not contain the remove operation. Additionally, the second normal form enforces a limitation on the use of the method-modify operation. For each of the proposed normal forms an algorithm for refactoring a delta-oriented SPL into one that satisfies that normal form is described. The algorithms are formalized for a core calculus for delta-oriented SPLs of Java programs.", "num_citations": "2\n", "authors": ["1514"]}
{"title": "Certifying delta-oriented programs\n", "abstract": " A major design concern in modern software development frameworks is to ensure that mechanisms for updating code running on remote devices comply with given safety specifications. This paper presents a delta-oriented approach for implementing product lines where software reuse is achieved at the three levels of state-diagram modeling, C/source code and binary code. A safety specification is expressed on the properties of reusable software libraries that can be dynamically loaded at run time after an over-the-air update. The compilation of delta-engineered code is certified using the framework of proof-carrying code in order to guarantee safety of software updates on remote devices. An empirical evaluation of the computational cost associated with formal safety checks is done by means of experimentation.", "num_citations": "2\n", "authors": ["1514"]}
{"title": "Abstract compilation of object-oriented languages into coinductive CLP (X): when type inference meets verification\n", "abstract": " We propose a novel general approach for defining expressive type systems for object-oriented languages, based on abstract compilation of programs into coinductive constraint logic programs defined on a specific constraint domain X called type domain. In this way, type checking and type inference amount to resolving a certain goal w.r.t. the coinductive (that is, the greatest) Herbrand model of a logic program (that is, a Horn formula) with constraints over a fixed type domain X.  In particular, we show an interesting instantiation where the constraint predicates of X are syntactic equality and subtyping over coinductive object and union types. The corresponding type system is so expressive to allow verification of simple properties like data structure invariants.  Finally, we show a prototype implementation, written in Prolog, of the inference engine for coinductive CLP(X), which is parametric in the solver for the type domain X.", "num_citations": "2\n", "authors": ["1514"]}
{"title": "Types for Proofs and Programs: International Conference, TYPES 2008 Torino, Italy, March 26-29, 2008 Revised Selected Papers\n", "abstract": " These proceedings contain a selection of refereed papers presented at or-lated to the Annual Workshop of the TYPES project (EU coordination action 510996), which was held during March 26\u201329, 2008 in Turin, Italy. The topic of this workshop, and of all previous workshops of the same project, was f-mal reasoning and computer programming based on type theory: languages and computerized tools for reasoning, and applications in several domains such as analysis of programming languages, certi? ed software, mobile code, formali-tion of mathematics, mathematics education. The workshop was attended by more than 100 researchers and included more than 40 presentations. We also had three invited lectures, from A. Asperti (University of Bologna), G. Dowek (LIX, Ecole polytechnique, France) and JW Klop (Vrije Universiteit, A-terdam, The Netherlands). From 27 submitted papers, 19 were selected after a reviewing process. Each submitted paper was reviewed by three referees; the? nal decisions were made by the editors. This workshop is the last of a series of meetings of the TYPES working group funded by the European Union (IST project 29001, ESPRIT Working Group 21900, ESPRIT BRA 6435).", "num_citations": "2\n", "authors": ["1514"]}
{"title": "Alias Types and Effects for\" Environment-aware\" Computations\n", "abstract": " We adapt the alias type technology to dealwith primitives supporting environment-awareness (that is, the ability to adapt the behavior of an object according to the capabilities of the environment). In particular, we propose a type and effect system for an imperative object-based calculus with a primitive for discriminating the presence or absence of the object's attributes. Both the shape of the environment which guarantees the correct execution of expressions and the effect of expression evaluation on the environment are specified via suitable aliasing constraints.", "num_citations": "2\n", "authors": ["1514"]}
{"title": "On slicing software product line signatures\n", "abstract": " A Software Product Line (SPL) is a family of similar programs (called variants) generated from a common artifact base. Variability in an SPL can be documented in terms of abstract description of functionalities (called features): a feature model (FM) identifies each variant by a set of features (called a product). Delta-orientation is a flexible approach to implement SPLs. An SPL Signature (SPLS) is a variability-aware Application Programming Interface (API), i.e., an SPL where each variant is the API of a program. In this paper we introduce and formalize, by abstracting from SPL implementation approaches, the notion of slice of an SPLS K for a set of features F (i.e., an SPLS obtained from by K by hiding the features that are not in F). Moreover, we formulate the challenge of defining an efficient algorithm that, given a delta-oriented SPLS K and a set of features F, sreturns a delta-oriented SPLS that is an slice of K for F\u00a0\u2026", "num_citations": "1\n", "authors": ["1514"]}
{"title": "Formal Methods for Components and Objects: 10th International Symposium, FMCO 2011, Turin, Italy, October 3-5, 2011, Revised Selected Papers\n", "abstract": " Formal methods have been applied successfully to the verification of medium-sized programs in protocol and hardware design for some time. However, their application to the development of large systems requires more emphasis on specification, modeling, and validation techniques supporting the concepts of reusability and modifiability, and their implementation in new extensions of existing programming languages like Java. This book contains 20 revised papers submitted after the 10th Symposium on Formal Methods for Components and Objects, FMCO 2011, which was held in Turin, Italy, in October 2011. Topics covered include autonomic service-component ensembles; trustworthy eternal systems via evolving software, data, and knowledge; parallel patterns for adaptive heterogeneous multicore systems; programming for future 3D architectures with many cores; formal verification of object oriented software; and an infrastructure for reliable computer systems.", "num_citations": "1\n", "authors": ["1514"]}
{"title": "Formal Verification of Object-Oriented Software: International Conference, FoVeOO 2011, Turin, Italy, October 5-7, 2011, Revised Selected Papers\n", "abstract": " This book presents the thoroughly refereed post-conference proceedings of the International Conference on Formal Verification of Object-Oriented Software, FoVeOOS 2011, held in Turin, Italy, in October 2011\u2013organised by COST Action IC0701. The 10 revised full papers presented together with 5 invited talks were carefully reviewed and selected from 19 submissions. Formal software verification has outgrown the area of academic case studies, and industry is showing serious interest. The logical next goal is the verification of industrial software products. Most programming languages used in industrial practice are object-oriented, eg Java, C++, or C#. FoVeOOS 2011 aimed to foster collaboration and interactions among researchers in this area.", "num_citations": "1\n", "authors": ["1514"]}
{"title": "Tests as Documentation: a First Attempt at Quality Evaluation\n", "abstract": " We present a novel method, and its associated supporting tool, for automatically singling out sloppy tests; that is, tests that run successfully on (some) incorrect implementations, that violate the property they are expected to verify. Our freely available tool is written in C#, but the technique is language agnostic and can be easily applied to other languages.", "num_citations": "1\n", "authors": ["1514"]}
{"title": "Modelling an ammonium transporter with SCLS\n", "abstract": " The Stochastic Calculus of Looping Sequences (SCLS) is a recently proposed modelling language for the representation and simulation of biological systems behaviour. It has been designed with the aim of combining the simplicity of notation of rewrite systems with the advantage of compositionality. It also allows a rather simple and accurate description of biological membranes and their interactions with the environment. In this work we apply SCLS to model a newly discovered ammonium transporter. This transporter is believed to play a fundamental role for plant mineral acquisition, which takes place in the arbuscular mycorrhiza, the most wide-spread plant-fungus symbiosis on earth. Due to its potential application in agriculture this kind of symbiosis is one of the main focuses of the BioBITs project. In our experiments the passage of NH3 / NH4+ from the fungus to the plant has been dissected in known and hypothetical mechanisms; with the model so far we have been able to simulate the behaviour of the system under different conditions. Our simulations confirmed some of the latest experimental results about the LjAMT2;2 transporter. The initial simulation results of the modelling of the symbiosis process are promising and indicate new directions for biological investigations.", "num_citations": "1\n", "authors": ["1514"]}
{"title": "Fickle: Dynamic Object Reclassification\n", "abstract": " IRIS incontri per adulti lecco nascondi/visualizza icone a destra le donne senza amore muoiono da vive social networking sites for singles nascondi/visualizza menu in alto incontri trieste bakeca", "num_citations": "1\n", "authors": ["1514"]}
{"title": "Fickle: Dynamic object re-classification\n", "abstract": " Fickle: Dynamic object re-classification/SOPHIA DROSSOPOULOU; FERRUCCIO DAMIANI; M. DEZANI; PAOLA GIANNINI.-(2001), pp. 1-14.((Intervento presentato al convegno FOOL'01 tenutosi a London nel 20/1/2001.", "num_citations": "1\n", "authors": ["1514"]}
{"title": "Evaluation of CSF neuropeptides and peptidase activities in primary headaches\n", "abstract": " Various neuropeptides seem to paticipate in the pain transmission mechanism, among which, substance P (SP) is the major candidate as transmitter of a certain sub-population of primary sensory neurons (1). Somatostatin (SST) is also contained within small diaixeter sensory fibres, although its possible role is less clear. SST is capable of inhibiting SP release and effects at both central and peripheral endings of sensory neurons (2).(Met5 1-enkephalin (ME is unevenly distributed in the brain, and that contained in some interneurons of the spinal cord and medulla oblongata seems to inhibit the activity of sensory afferents (3). Until now it has not been clarified how the peptide signal is turned off at the synaptic level. Since no re-uptake mechanism has been described, diffusion and degradation of peptide transmitters are considered the main form of inactivation. Enkephalinase has shown to inactivate enkephalins\u00a0\u2026", "num_citations": "1\n", "authors": ["1514"]}