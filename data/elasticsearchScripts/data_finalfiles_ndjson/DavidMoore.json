{"title": "Inferring internet denial-of-service activity\n", "abstract": " In this article, we seek to address a simple question: \u201cHow prevalent are denial-of-service attacks in the Internet?\u201d Our motivation is to quantitatively understand the nature of the current threat as well as to enable longer-term analyses of trends and recurring patterns of attacks. We present a new technique, called \u201cbackscatter analysis,\u201d that provides a conservative estimate of worldwide denial-of-service activity. We use this approach on 22 traces (each covering a week or more) gathered over three years from 2001 through 2004. Across this corpus we quantitatively assess the number, duration, and focus of attacks, and qualitatively characterize their behavior. In total, we observed over 68,000 attacks directed at over 34,000 distinct victim IP addresses---ranging from well-known e-commerce companies such as Amazon and Hotmail to small foreign ISPs and dial-up connections. We believe our technique is the first to\u00a0\u2026", "num_citations": "2093\n", "authors": ["707"]}
{"title": "Inside the slammer worm\n", "abstract": " The Slammer worm spread so quickly that human response was ineffective. In January 2003, it packed a benign payload, but its disruptive capacity was surprising. Why was it so effective and what new challenges do this new breed of worm pose?.", "num_citations": "1403\n", "authors": ["707"]}
{"title": "Code-Red: a case study on the spread and victims of an Internet worm\n", "abstract": " On July 19, 2001, more than 359,000 computers connected to the Internet were infected with the Code-Red (CRv2) worm in less than 14 hours. The cost of this epidemic, including subsequent strains of Code-Red, is estimated to be in excess of $2.6 billion. Despite the global damage caused by this attack, there have been few serious attempts to characterize the spread of the worm, partly due to the challenge of collecting global information about worms. Using a technique that enables global detection of worm spread, we collected and analyzed data over a period of 45 days beginning July 2nd, 2001 to determine the characteristics of the spread of Code-Red throughout the Internet. In this paper, we describe the methodology we use to trace the spread of Code-Red, and then describe the results of our trace analyses. We first detail the spread of the Code-Red and CodeRedII worms in terms of infection and\u00a0\u2026", "num_citations": "1197\n", "authors": ["707"]}
{"title": "Internet quarantine: Requirements for containing self-propagating code\n", "abstract": " It has been clear since 1988 that self-propagating code can quickly spread across a network by exploiting homogeneous security vulnerabilities. However, the last few years have seen a dramatic increase in the frequency and virulence of such \"worm\" outbreaks. For example, the Code-Red worm epidemics of 2001 infected hundreds of thousands of Internet hosts in a very short period - incurring enormous operational expense to track down, contain, and repair each infected machine. In response to this threat, there is considerable effort focused on developing technical means for detecting and containing worm infections before they can cause such damage. This paper does not propose a particular technology to address this problem, but instead focuses on a more basic question: How well will any such approach contain a worm epidemic on the Internet? We describe the design space of worm containment systems\u00a0\u2026", "num_citations": "1011\n", "authors": ["707"]}
{"title": "What do packet dispersion techniques measure?\n", "abstract": " The packet pair technique estimates the capacity of a path (bottleneck bandwidth) from the dispersion (spacing) experienced by two back-to-back packets. We demonstrate that the dispersion of packet pairs in loaded paths follows a multimodal distribution, and discuss the queueing effects that cause the multiple modes. We show that the path capacity is often not the global mode, and so it cannot be estimated using standard statistical procedures. The effect of the size of the probing packets is also investigated, showing that the conventional wisdom of using maximum sized packet pairs is not optimal. We then study the dispersion of long packet trains. Increasing the length of the packet train reduces the measurement variance, but the estimates converge to a value, referred to as the asymptotic dispersion rate (ADR), that is lower than the capacity. We derive the effect of the cross traffic in the dispersion of long packet\u00a0\u2026", "num_citations": "882\n", "authors": ["707"]}
{"title": "Packet-dispersion techniques and a capacity-estimation methodology\n", "abstract": " The packet-pair technique aims to estimate the capacity of a path (bottleneck bandwidth) from the dispersion of two equal-sized probing packets sent back to back. It has been also argued that the dispersion of longer packet bursts (packet trains) can estimate the available bandwidth of a path. This paper examines such packet-pair and packet-train dispersion techniques in depth. We first demonstrate that, in general, packet-pair bandwidth measurements follow a multimodal distribution and explain the causes of multiple local modes. The path capacity is a local mode, often different than the global mode of this distribution. We illustrate the effects of network load, cross-traffic packet-size variability, and probing packet size on the bandwidth distribution of packet pairs. We then switch to the dispersion of long packet trains. The mean of the packet-train dispersion distribution corresponds to a bandwidth metric that we\u00a0\u2026", "num_citations": "552\n", "authors": ["707"]}
{"title": "Building a better NetFlow\n", "abstract": " Network operators need to determine the composition of the traffic mix on links when looking for dominant applications, users, or estimating traffic matrices. Cisco's NetFlow has evolved into a solution that satisfies this need by reporting flow records that summarize a sample of the traffic traversing the link. But sampled NetFlow has shortcomings that hinder the collection and analysis of traffic data. First, during flooding attacks router memory and network bandwidth consumed by flow records can increase beyond what is available; second, selecting the right static sampling rate is difficult because no single rate gives the right tradeoff of memory use versus accuracy for all traffic mixes; third, the heuristics routers use to decide when a flow is reported are a poor match to most applications that work with time bins; finally, it is impossible to estimate without bias the number of active flows for aggregates with non-TCP traffic\u00a0\u2026", "num_citations": "550\n", "authors": ["707"]}
{"title": "Scalability, fidelity, and containment in the potemkin virtual honeyfarm\n", "abstract": " The rapid evolution of large-scale worms, viruses and bot-nets have made Internet malware a pressing concern. Such infections are at the root of modern scourges including DDoS extortion, on-line identity theft, SPAM, phishing, and piracy. However, the most widely used tools for gathering intelligence on new malware--network honeypots--have forced investigators to choose between monitoring activity at a large scale or capturing behavior with high fidelity. In this paper, we describe an approach to minimize this tension and improve honeypot scalability by up to six orders of magnitude while still closely emulating the execution behavior of individual Internet hosts. We have built a prototype honeyfarm system, called Potemkin, that exploits virtual machines, aggressive memory sharing, and late binding of resources to achieve this goal. While still an immature implementation, Potemkin has emulated over 64,000\u00a0\u2026", "num_citations": "493\n", "authors": ["707"]}
{"title": "The spread of the witty worm\n", "abstract": " On Friday, 19 March 2004, at approximately 8:45 p.m. Pacific Standard Time (PST), an Internet worm began to spread, targeting a buffer overflow vulnerability in several Internet Security Systems (ISS) products, including its RealSecure Network, RealSecure Server Sensor, RealSecure Desktop, and BlackICE. The worm took advantage of a security flaw in these firewall applications that eEye Digital Security discovered earlier in March. Once the Witty worm - so called because its payload contained the phrase, \"(^,^)insert witty message here (^,^)\" - infects a computer, it deletes a randomly chosen section of the hard drive, which, over time, renders the machine unusable. We share a global view of the worm's spread, with particular attention to its features.", "num_citations": "454\n", "authors": ["707"]}
{"title": "Topology discovery by active probing\n", "abstract": " As the Internet has grown, so has the challenge of accurate measurement and modeling of its topology. Commonly used but coarse methods of measuring topology, e.g., BGP tables, suffer from several limitations. To pursue more accurate empirically-based topology modeling, in 1998 CAIDA began its Macroscopic Topology Project, which focuses on actively measuring topology and round trip time (RTT) information across a large cross-section of the commodity Internet. We describe CAIDA's topology measurement architecture and our analysis and visualization tools. We describe differences between IP and AS (BGP-based) granularities of topology modeling, including advantages and limitations of both, as well as how correlation between both types of data can yield more relevant insights. We introduce four new visualization metaphors for handling macroscopic topology data, as well as a tool for aggregating\u00a0\u2026", "num_citations": "340\n", "authors": ["707"]}
{"title": "The spread of the sapphire/slammer worm\n", "abstract": " CiNii \u8ad6\u6587 - The Spread of the Sapphire/Slammer Worm CiNii \u56fd\u7acb\u60c5\u5831\u5b66\u7814\u7a76\u6240 \u5b66\u8853\u60c5\u5831 \u30ca\u30d3\u30b2\u30fc\u30bf[\u30b5\u30a4\u30cb\u30a3] \u65e5\u672c\u306e\u8ad6\u6587\u3092\u3055\u304c\u3059 \u5927\u5b66\u56f3\u66f8\u9928\u306e\u672c\u3092\u3055\u304c\u3059 \u65e5\u672c\u306e\u535a\u58eb\u8ad6\u6587\u3092\u3055\u304c\u3059 \u65b0\u898f \u767b\u9332 \u30ed\u30b0\u30a4\u30f3 English \u691c\u7d22 \u3059\u3079\u3066 \u672c\u6587\u3042\u308a \u3059\u3079\u3066 \u672c\u6587\u3042\u308a \u9589\u3058\u308b \u30bf\u30a4\u30c8\u30eb \u8457\u8005\u540d \u8457\u8005ID \u8457\u8005 \u6240\u5c5e \u520a\u884c\u7269\u540d ISSN \u5dfb\u53f7\u30da\u30fc\u30b8 \u51fa\u7248\u8005 \u53c2\u8003\u6587\u732e \u51fa\u7248\u5e74 \u5e74\u304b\u3089 \u5e74\u307e\u3067 \u691c\u7d22 \u691c\u7d22 \u691c\u7d22 CiNii\u306e \u30b5\u30fc\u30d3\u30b9\u306b\u95a2\u3059\u308b\u30a2\u30f3\u30b1\u30fc\u30c8\u3092\u5b9f\u65bd\u4e2d\u3067\u3059\uff0811/11(\u6c34)-12/23(\u6c34)\uff09 The Spread of the Sapphire/Slammer Worm MOORE D. \u88ab\u5f15\u7528\u6587\u732e: 1\u4ef6 \u8457\u8005 MOORE D. \u53ce\u9332\u520a\u884c\u7269 http://www.cs.berkeley.edu/\u301cnweaver/sapphire http://www.cs.berkeley.edu/\u301cnweaver/sapphire \u88ab\u5f15\u7528\u6587\u732e: 1\u4ef6\u4e2d 1-1\u4ef6\u3092 \u8868\u793a 1 \u9001\u53d7\u4fe1 \u30c7\u30fc\u30bf\u9593\u306e\u76f8\u95a2\u306b\u57fa\u3065\u304f\u672a\u77e5\u30ef\u30fc\u30e0\u691c\u77e5\u3092\u5229\u7528\u3057\u305f\u8513\u5ef6\u9632\u6b62\u624b\u6cd5\u306e\u63d0\u6848 \u677e\u672c \u9686\u660e , \u6749\u6751 \u53cb\u5e78 , \u9234\u6728 \u529f\u4e00 , \u524d\u7530 \u79c0\u4ecb , \u99ac\u5834 \u9054\u4e5f , \u6c34\u91ce \u5fe0\u5247 , \u897f\u57a3 \u6b63\u52dd \u60c5\u5831\u51e6\u7406\u5b66\u4f1a\u8ad6\u6587\u8a8c 47(6), 1941-1953, 2006-06-15 \u53c2\u8003\u6587\u732e23\u4ef6 \u88ab\u5f15\u7528\u6587\u732e2\u4ef6 CiNii\u5229\u7528\u8005\u30a2\u30f3\u30b1\u30fc\u30c8 Tweet \u5404\u7a2e\u30b3\u30fc\u30c9 \u2026", "num_citations": "324\n", "authors": ["707"]}
{"title": "The top speed of flash worms\n", "abstract": " Flash worms follow a precomputed spread tree using prior knowledge of all systems vulnerable to the worm's exploit. In previous work we suggested that a flash worm could saturate one million vulnerable hosts on the Internet in under 30 seconds [18]. We grossly over-estimated.", "num_citations": "286\n", "authors": ["707"]}
{"title": "Longitudinal study of Internet traffic in 1998-2003\n", "abstract": " There is growing interest in capturing and analyzing Internet traffic characteristics in pursuit of insights into its evolution. We present a study of one of the few sources of publicly available long-term Internet traffic workload data, namely the NLANR PMA archive of packet header traces. Trace samples were collected at a number of academic, research, and commercial sites during years 1998--2003. We consider four metrics of traffic: bytes, packets, flows, and number of source-destination pairs. We also analyze the composition of traffic by protocol.", "num_citations": "234\n", "authors": ["707"]}
{"title": "Distance metrics in the Internet\n", "abstract": " Distance metrics in the Internet Page 1 Distance metrics in the Internet Bradley Huffaker, Marina Fomenkov, Daniel J. Plummer, David Moore and k claffy CAIDA, SDSC, UC San Diego {bradley,marina,djp,dmoore,kc}@caida.org IEEE International, Telecommunications Symposium, (ITS2002) Page 2 overview \u2022 server selection problem \u2022 data used in this study \u2022 distance metrics \u2022 metric success rates \u2022 conclusions Page 3 server selection \u2022 Many Internet services are provided by multiple servers. \u2022 Clients want to select a server that optimizes their access to a given service. \u2022 Possible optimizations: server load, available bandwidth, loss rate, transit time. \u2022 We will look at the problem of optimizing minimum transit time or Round Trip Time (RTT). Page 4 Approach for selecting minimum RTT \u2022 A common solution to this problem is a selection system which is local to a client and can do the selection for it. \u2022 This system requires \u2026", "num_citations": "217\n", "authors": ["707"]}
{"title": "Network telescopes: Technical report\n", "abstract": " A network telescope is a portion of routed IP address space in which little or no legitimate traffic exists. Monitoring unexpected traffic arriving at a network telescope provides the opportunity to view remote network security events such as various forms of flooding denial-of-service attacks, infection of hosts by Internet worms, and network scanning. In this paper, we examine the effects of the scope and locality of network telescopes on accurate measurement of both pandemic incidents (the spread of an Internet worm) and endemic incidents (denial-of-service attacks) on the Internet. In particular, we study the relationship between the size of the network telescope and its ability to detect network events, characterize its precision in determining event duration and rate, and discuss practical considerations in the deployment of network telescopes.", "num_citations": "203\n", "authors": ["707"]}
{"title": "Replication strategies for highly available peer-to-peer storage\n", "abstract": " In the past few years, peer-to-peer networks have become an extremely popular mechanism for large-scale content sharing. Unlike traditional client-server applications, which centralize the management of data in a few highly reliable servers, peer-to-peer systems distribute the burden of data storage, computation, communications and administration among thousands of individual client workstations. While the popularity of this approach, exemplified by systems such as Gnutella [28.3], was driven by the popularity of unrestricted music distribution, newer work has expanded the potential application base to generalized distributed file systems [28.1], [28.4], persistent anonymous publishing [28.5], as well as support for high-quality video distribution [28.2]. The wide-spread attraction of the peer-to-peer model arises primarily from its potential for both low-cost scalability and enhanced availability. Ideally a peer-to\u00a0\u2026", "num_citations": "183\n", "authors": ["707"]}
{"title": "The architecture of CoralReef: an Internet traffic monitoring software suite\n", "abstract": " The volume and complexity of traffic on the Internet is increasing rapidly, making it both more difficult and more important to understand. To this end we have created the CoralReef passive traffic monitoring suite, which can be", "num_citations": "179\n", "authors": ["707"]}
{"title": "The coralreef software suite as a tool for system and network administrators\n", "abstract": " Until now, system administrators have lacked a flexible real-time network traffic flow monitoring package. Such a package must provide a wide range of services but remain flexible enough for rapid in-house customization. Existing passive data collection tools are typically narrow in scope, designed for specific tasks from packet capture (tcpdump [9]) to accounting (NeTraMet [4]). In response, CAIDA has created the CoralReef suite designed to provide network administrators and researchers with a consistent interface for a wide range of network analysis applications, from raw capture to flows analysis to real-time report generation. CoralReef provides a convenient set of passive data tools for a diverse audience.", "num_citations": "173\n", "authors": ["707"]}
{"title": "Network telescopes: Observing small or distant security events\n", "abstract": " A network telescope is a portion of routed IP address space on which little or no legitimate traffic exists. Monitoring unexpected traffic arriving at a network telescope yields a view of certain remote network events. Among the visible events are various forms of flooding DoS attacks, infection of hosts by Internet worms, and network scanning. In this presentation, we'll examine questions such as: How large should my network telescope be? How well can one go backwards from a local view to an estimate of the global phenomenon? How big (in packets sent) or long (in duration) must an event be to be seen? What can I see from my own backyard telescope?", "num_citations": "151\n", "authors": ["707"]}
{"title": "Beyond folklore: observations on fragmented traffic\n", "abstract": " Fragmented IP traffic is a poorly understood component of the overall mix of traffic on the Internet. Many assertions about the nature and extent of fragmented traffic are anecdotal rather than empirical. In this paper we examine the causes and attributes of measured fragment traffic, in particular, the effects of NFS, streaming media, networked video games, tunneled traffic, and the prevalence of packet fragmentation due to improperly configured machines. To understand the prevalence, causes, and effects of fragmented IP traffic, we have collected and analyzed seven multiday traces from four sources. These sources include a university commodity access link, two highly aggregated commercial exchange points, and a local NAP. Although there is no practical method of ascertaining whether any data provide a representative sample of all Internet traffic, we include data sources that cover several different types of WAN\u00a0\u2026", "num_citations": "123\n", "authors": ["707"]}
{"title": "Network telescopes\n", "abstract": " Network Telescopes Page 1 UCSD CSE David Moore October 29th, 2003 - USENIX LISA dmoore@caida.org www.caida.org Network Telescopes Page 2 University California, San Diego \u2013 Department of Computer Science COOPERATIVE ASSOCIATION FOR INTERNET DATA ANALYSIS UCSD CSE What is a \"Network Telescope\"? \u2022 A way of seeing remote security events, without being there. \u2022 Can see: \u2013 victims of certain kinds of denial-of-service attacks \u2013 hosts infected by random-spread worms \u2013 port and host scanning \u2013 misconfiguration Page 3 University California, San Diego \u2013 Department of Computer Science COOPERATIVE ASSOCIATION FOR INTERNET DATA ANALYSIS UCSD CSE If a computer sends packets to IP addresses randomly, we should see some of the packets if we monitor enough address space. Network Telescope: Basic Idea Page 4 University California, San Diego \u2013 Department of \u2026", "num_citations": "102\n", "authors": ["707"]}
{"title": "A robust system for accurate real-time summaries of internet traffic\n", "abstract": " Good performance under extreme workloads and isolation between the resource consumption of concurrent jobs are perennial design goals of computer systems ranging from multitasking servers to network routers. In this paper we present a specialized system that computes multiple summaries of IP traffic in real time and achieves robustness and isolation between tasks in a novel way: by automatically adapting the parameters of the summarization algorithms. In traditional systems, anomalous network behavior such as denial of service attacks or worms can overwhelm the memory or CPU, making the system produce meaningless results exactly when measurement is needed most. In contrast, our measurement system reacts by gracefully degrading the accuracy of the affected summaries.The types of summaries we compute are widely used by network administrators monitoring the workloads of their networks\u00a0\u2026", "num_citations": "101\n", "authors": ["707"]}
{"title": "The spread of the code red worm (crv2)\n", "abstract": " CiNii \u8ad6\u6587 - The Spread of the Code Red Worm (CRv2) CiNii \u56fd\u7acb\u60c5\u5831\u5b66\u7814\u7a76\u6240 \u5b66\u8853\u60c5\u5831 \u30ca\u30d3\u30b2\u30fc\u30bf[\u30b5\u30a4\u30cb\u30a3] \u65e5\u672c\u306e\u8ad6\u6587\u3092\u3055\u304c\u3059 \u5927\u5b66\u56f3\u66f8\u9928\u306e\u672c\u3092\u3055\u304c\u3059 \u65e5\u672c\u306e\u535a\u58eb\u8ad6\u6587\u3092\u3055\u304c\u3059 \u65b0\u898f \u767b\u9332 \u30ed\u30b0\u30a4\u30f3 English \u691c\u7d22 \u3059\u3079\u3066 \u672c\u6587\u3042\u308a \u3059\u3079\u3066 \u672c\u6587\u3042\u308a \u9589\u3058\u308b \u30bf\u30a4\u30c8\u30eb \u8457\u8005\u540d \u8457\u8005ID \u8457\u8005 \u6240\u5c5e \u520a\u884c\u7269\u540d ISSN \u5dfb\u53f7\u30da\u30fc\u30b8 \u51fa\u7248\u8005 \u53c2\u8003\u6587\u732e \u51fa\u7248\u5e74 \u5e74\u304b\u3089 \u5e74\u307e\u3067 \u691c\u7d22 \u691c\u7d22 \u691c\u7d22 [\u6a5f\u95a2 \u8a8d\u8a3c] \u5229\u7528\u7d99\u7d9a\u624b\u7d9a\u304d\u306e\u3054\u6848\u5185 \u5b66\u8a8d\u8a8d\u8a3c\u306e\u4e0d\u5177\u5408\u306b\u3064\u3044\u3066 The Spread of the Code Red Worm (CRv2) MOORE D. \u88ab\u5f15\u7528\u6587\u732e: 1\u4ef6 \u8457\u8005 MOORE D. \u53ce\u9332\u520a\u884c\u7269 http://www.caida.org/publications/papers/2002/codered/codered.pdf http://www.caida.org/publications/papers/2002/codered/codered.pdf, 2001 \u88ab\u5f15\u7528\u6587\u732e: 1\u4ef6\u4e2d 1-1\u4ef6\u3092 \u8868\u793a 1 \u7aef\u672b\u9593\u901a\u4fe1\u306b\u3088\u3063\u3066\u611f\u67d3\u3059\u308b Malware \u306e\u691c\u51fa\u624b\u6cd5\u306b\u95a2\u3059\u308b\u8003\u5bdf \u5c71\u4e0b \u4ec1 , \u4e2d\u91ce \u656c\u4ecb , \u4ed9\u77f3 \u6b63\u548c \u96fb\u5b50\u60c5\u5831\u901a\u4fe1\u5b66\u4f1a\u6280\u8853\u7814\u7a76\u5831\u544a. NS, \u30cd\u30c3\u30c8\u30ef\u30fc\u30af\u30b7\u30b9\u30c6\u30e0 109(326), 115-118, 2009-12-03 \u53c2\u8003\u6587\u732e14\u4ef6 Tweet \u5404\u7a2e\u30b3\u30fc\u30c9 NII\u8ad6\u6587ID(NAID) \u2026", "num_citations": "96\n", "authors": ["707"]}
{"title": "Characteristics of fragmented IP traffic on Internet links\n", "abstract": " Fragmented IP traffic is a unique component of the overall mix of traffic on the Internet. Many assertions about the nature and extent of fragmented traffic are anecdotal rather than empirical. In this paper we examine the causes and attributes of measured fragment traffic and contrast those results with commonly cited beliefs. In particular, the effects of NFS, streaming media, networked video games, and tunneled traffic are quantified, and we estimate the prevalence of packet fragmentation due to improperly configured machines. To understand the prevalence, causes, and effects of fragmented IP traffic, we have collected and analyzed seven multi-day traces from three sources. These sources include a university commodity access link, a highly aggregated commercial exchange point, and a local NAP. Although there is no practical method of ascertaining whether any data provide a representative sample of all\u00a0\u2026", "num_citations": "74\n", "authors": ["707"]}
{"title": "Macroscopic analyses of the infrastructure: Measurement and visualization of Internet connectivity and performance\n", "abstract": " | The robustness and reliability of the Internet is highly dependent on ecient, stable connectivity and routing among networks comprising the global infrastructure. To provide macroscopic insights into Internet topology and performance, the Cooperative Association for Internet Data Analysis (CAIDA) has developed and deployed the skitter tool to dynamically discover and depict global Internet topology and measure performance across speci c paths. We are developing a systematic approach to visualizing the multi-dimensional parameter space covered by", "num_citations": "71\n", "authors": ["707"]}
{"title": "The internet measurement data catalog\n", "abstract": " Internet data remains one of the basic components of computer science network research. Despite its necessity, available data is limited by legal, social, and technical constraints on its collection and distribution. Thus, optimal distribution of knowledge about available data is a valuable service to the research community. To this end, CAIDA has developed the Internet Measurement Data Catalog to:provide a searchable index of available dataenhance documentation of datasets via a public annotation systemadvance network science by promoting reproducible researchThis paper describes the impetus, design, and planned deployment of the Internet Measurement Data Catalog.", "num_citations": "56\n", "authors": ["707"]}
{"title": "A platform for cooperative and coordinated control of multiple vehicles: The Caltech Multi-Vehicle Wireless Testbed\n", "abstract": " Abstract The Caltech Multi-Vehicle Wireless Testbed (MVWT) is an experimental platform for investigating the increasingly important intersecting frontiers of reliable distributed computation, communication and control. The testbed consists of eight autonomous vehicles equipped with onboard sensing, communication and computation. The vehicles are underactuated and exhibit nonlinear second-order dynamics, key properties that capture the essence of similar real-world applications at the forefront of cooperative control.The relative simplicity of the testbed facilitates the investigation and application of novel ideas in reliable computing, real-time optimal control, stability of interconnected systems, control of and over networks, and formation flight. In this paper, we describe in detail the MVWT and its components so that readers may envision how it can be used to provide proof-of-concept for new techniques in multi-vehicle control.", "num_citations": "33\n", "authors": ["707"]}
{"title": "The spread of the Witty worm\n", "abstract": " Malware Recon www. computer. org/security/\u25a0 IEEE SECURITY & PRIVACY 47 sized packets and complicate simple blocking measures that limit or prevent the worm\u2019s spread. If they had been a fixed size, it would have been easier to quickly block Witty traffic to limit or prevent the worm\u2019s spread. The worm payload of 637 bytes is padded with data from system memory to fill the random size, and a packet is sent out from source port 4000. After Witty sends the 20,000 packets, it seeks out a random point on the hard disk and writes 65kbytes of data from the beginning of iss-pam1. dll to the disk. After closing the disk, Witty repeats this process until the machine is rebooted or until it permanently crashes.", "num_citations": "31\n", "authors": ["707"]}
{"title": "Measurements of the Internet topology in the Asia-Pacific region\n", "abstract": " CAIDA, the Cooperative Association for Internet Data Analysis, has done a study of network connectivity in the Asia-Pacific region. The focus is on network latency and performance, autonomous system (AS) and country peering, and third party transit. Using ICMP packets from nine geographically diverse monitors we collect data that includes the forward IP path and the round-trip delay to about 2000 destinations (mostly web servers) in the Asia-Pacific region. From these IP paths and delay values we gather statistics about transit providers, peering, and the appropriateness of our metrics to measure the Internet.", "num_citations": "30\n", "authors": ["707"]}
{"title": "Network telescopes: Tracking denial-of-service attacks and Internet worms around the globe\n", "abstract": " Network telescopes provide the unique ability to see large-scale globally dispersed network security events, such as denial-of-service attacks and the spread of Internet worms. A network telescope is a portion of routed IP address space with little or no legitimate traffic. By monitoring unexpected traffic arriving at a telescope, we can determine remote victims of DoS or hosts infected by a worm. This talk covers trends in DoS attacks and victims over the past 2 years, as well as the Code-Red, CodeRed II, and SQL Slammer/Sapphire worms.", "num_citations": "27\n", "authors": ["707"]}
{"title": "What do packet dispersion techniques measure?\n", "abstract": " The packet pair technique estimates the capacity of a path (bottleneck bandwidth) from the dispersion (spacing) experienced by two back-to-back packets [1][2][3]. We demonstrate that the dispersion of packet pairs in loaded paths follows a multimodal distribution, and discuss the queueing effects that cause the multiple modes. We show that the path capacity is often not the global mode, and so it cannot be estimated using standard statistical procedures. The effect of the size of the probing packets is also investigated, showing that the conventional wisdom of using maximum sized packet pairs is not optimal. We then study the dispersion of long packet trains. Increasing the length of the packet train reduces the measurement variance, but the estimates converge to a value, referred to as Asymptotic Dispersion Rate (ADR), that is lower than the capacity. We derive the effect of the cross traffic in the dispersion of long packet trains, showing that the ADR is not the available bandwidth in the path, as was assumed in previous work. Putting all the pieces together, we present a capacity estimation methodology that has been implemented in a tool called pathrate.", "num_citations": "15\n", "authors": ["707"]}
{"title": "Selection of materials\n", "abstract": " What are the best procedures for textbook selection in the content areas? Textbooks are a central feature of secondary school instruction. De-scriptive research into US secondary school instruction indicates the prevalent use of textbooks (Fancett & Hawke, 1982; Goodlad, 1984; Jarolimek, 1977; Stake & Easley, 1978). Furthermore, his-torical research indicates that this prevalence has persisted for at least the past 100 years (Cuban, 1984). In most schools, each student receives a copy of the text adopted for each class. The texts then constitute the core of the curriculum; teachers rely on them as the primary sources of the information to be imparted to students. However, as noted in the first chapter of this volume, the actual reliance students place on texts is suspect. Students seem to rely to varying degrees on teachers' restatements or explanations of textual materials.", "num_citations": "13\n", "authors": ["707"]}
{"title": "Passive sonar target recognition using a back-propagating neural network\n", "abstract": " The prompt and accurate processing of sonar data is essential in undersea warfare. The ability to quickly detect and classify sonar targets is crucial to the performance and survivability of all navy surface ships and submarines. With the advent of neural network technology, new opportunities have arisen which could greatly enhance current sonar target recognition capabilities. The main objective of this research is to demonstrate the practical usage of neural networks in recognizing the acoustic signatures of passive sonar targets using simulated-at-sea conditions. We will review the theory behind neural networks, the problems associated with recognizing acoustic signals in an underwater environment, and we will make a detailed case study of a neural networks performance using test data generated from simulated sonar targets.Descriptors:", "num_citations": "11\n", "authors": ["707"]}
{"title": "Quantitative network security analysis\n", "abstract": " As part of the CAIDA grant, Moore lead several tool development efforts. CoralReef [9, 10], a suite of tools for passive network measurement, has been used in numerous university courses and was the basis of an educational CDROM developed by the NSF-funded Internet Engineering Curriculum grant. NetGeo [11], a publically available service for mapping IP addresses to geographic locations, typically serves over 500,000 requests from over 4,000 clients per day. Both CoralReef and NetGeo have been licensed from the University of California; NetGeo is an integral component of a commercial geographic location service. Additionally CoralReef has been used under DARPA contract by SPAWAR in San Diego as part of the Navy\u2019s Reconfigurable Land Based Test Site (RLBTS) to measure one-way communication delays.", "num_citations": "7\n", "authors": ["707"]}
{"title": "A delayed and rather unusual presentation of a bladder injury after pelvic trauma: 5 years after a road traffic accident\n", "abstract": " Associated injuries frequently occur in patients who sustain fractures of the pelvis. Specifically, high-energy trauma resulting in pelvic fractures places the bladder and urethra at risk for injury, often resulting in significant complications. Timely identification and management of genitourinary injuries minimize associated morbidity. Prompt injury identification depends upon a systematic evaluation with careful consideration of the mechanism of injury. Physical examination is pertinent as well as analysis of the urine and appropriate diagnostic imaging. Despite such increased vigilance genitourinary injuries get missed and delayed presentations in the order of a few weeks have been well documented. To our knowledge, this is the first report of its kind in the literature showing such a particularly delayed (5 years) and rather unusual presentation of a bladder injury after pelvic trauma.", "num_citations": "5\n", "authors": ["707"]}
{"title": "How to Steal an Election: The Inside Story of How George Bush's Brother and FOX Network Miscalled the 2000 Election and Changed the Cour\n", "abstract": " This is the inside story of how Jeb Bush persuaded the Fox network to call the presidential election for his brother George W. Bush on Election Night 2000. It was one phone call to Fox\u2014the details of which are revealed in this book for the first time\u2014that propelled George W. Bush into leading position for 43rd president of the United States. Even though the erroneous statement had to be retracted within two hours, the damage done by this false call to Al Gore's chances of winning the election were incalculable. David Moore, at the time senior editor for the Gallup Poll, makes the plausible and alarming case that, had Fox not made this miscall, the resulting political environment would have been less biased in favor of Bush, and that Al Gore could have won. On Election Night in 2000, Moore was with the exit poll\" decision team\" of CBS and CNN, taking notes on how election races were called, and miscalled, around the country\u2014including the two miscalls and two rescissions in Florida. Prior to joining Gallup in 1993, Moore was founder and director of the Survey Center at the University of New Hampshire.", "num_citations": "5\n", "authors": ["707"]}
{"title": "A robust system for accurate real-time summaries of Internet traffic: Technical report\n", "abstract": " Good performance under extreme workloads and isolation between the resource consumption of concurrent jobs and perennial design goals of computer systems ranging from multitasking servers to network routers. In this paper we present a specialized system that computes multiple summaries of IP traffic in real time and achieves robustness and isolation between tasks in a novel way: by automatically adapting the parameters of the summarization algorithms. In traditional systems, anomalous network behavior such as denial of service attacks or worms can overwhelm the memory or CPU, making the system produce meaningless results exactly when measurement is needed most. In contrast, our measurement system reacts by gracefully degrading the accuracy of the affected summaries. https://www. caida. org/publications/presentations/2005/summaries_internet_traffic/The types of summaries we compute are\u00a0\u2026", "num_citations": "1\n", "authors": ["707"]}
{"title": "Pitfalls and Problems with Internet Data\n", "abstract": " Tools Lie\u2022 passive taps can drop, reorder and duplicate packets\u2022 so can kernels/NICs for active measurements\u2022 tools may not be robust to unexpected data\u2022 Internet checksums are weak\u2022 unknown network gear: L2 switches, passive caches\u2022 tools pretend to be atomic when they aren\u2019t\u2022 tools can\u2019t tell corrupt data (garbage in, garbage out)", "num_citations": "1\n", "authors": ["707"]}