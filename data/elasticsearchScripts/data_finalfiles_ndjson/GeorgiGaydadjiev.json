{"title": "The MOLEN polymorphic processor\n", "abstract": " In this paper, we present a polymorphic processor paradigm incorporating both general-purpose and custom computing processing. The proposal incorporates an arbitrary number of programmable units, exposes the hardware to the programmers/designers, and allows them to modify and extend the processor functionality at will. To achieve the previously stated attributes, we present a new programming paradigm, a new instruction set architecture, a microcode-based microarchitecture, and a compiler methodology. The programming paradigm, in contrast with the conventional programming paradigms, allows general-purpose conventional code and hardware descriptions to coexist in a program: In our proposal, for a given instruction set architecture, a onetime instruction set extension of eight instructions, is sufficient to implement the reconfigurable functionality of the processor. We propose a microarchitecture\u00a0\u2026", "num_citations": "514\n", "authors": ["1049"]}
{"title": "64-bit floating-point FPGA matrix multiplication\n", "abstract": " We introduce a 64-bit ANSI/IEEE Std 754-1985 floating point design of a hardware matrix multiplier optimized for FPGA implementations. A general block matrix multiplication algorithm, applicable for an arbitrary matrix size is proposed. The algorithm potentially enables optimum performance by exploiting the data locality and reusability incurred by the general matrix multiplication scheme and considering the limitations of the I/O bandwidth and the local storage volume. We implement a scalable linear array of processing elements (PE) supporting the proposed algorithm in the Xilinx Virtex II Pro technology. Synthesis results confirm a superior performance-area ratio compared to related recent works. Assuming the same FPGA chip, the same amount of local memory, and the same I/O bandwidth, our design outperforms related proposals by at least 1.7 X and up to 18X consuming the least reconfigurable resources. A\u00a0\u2026", "num_citations": "288\n", "authors": ["1049"]}
{"title": "March LR: A test for realistic linked faults\n", "abstract": " Many march tests have already been designed to cover faults of different fault models. The complexity of these tests arises when linked faults are taken into consideration. This paper gives an overview of the most important and commonly used fault models, including the industry's popular disturb fault model. The fault coverage of march tests is analysed in a novel way, i.e., in terms of their detection capabilities for: simple faults, and linked faults; whereby the infinite class of linked faults has been reduced to a set of realistic linked faults. Thereafter the paper presents a methodology to design tests for realistic linked faults, resulting in the new tests March LR, March LRD and March LRDD. These new tests will be shown to be more efficient and to offer a higher fault coverage than comparable existing tests.", "num_citations": "151\n", "authors": ["1049"]}
{"title": "DWARV: Delftworkbench automated reconfigurable VHDL generator\n", "abstract": " In this paper, we present the DWARV C-to-VHDL generation toolset. The toolset provides support for broad range of application domains. It exploits the operation parallelism, available in the algorithms. Our designs are generated with a view of actual hardware/software co-execution on a real hardware platform. The carried experiments on the MOLEN polymorphic processor prototype suggest overall application speedups between 1.4x and 6.8x, corresponding to 13% to 94% of the theoretically achievable maximums, constituted by Amdahl's law.", "num_citations": "149\n", "authors": ["1049"]}
{"title": "Architectural exploration of the ADRES coarse-grained reconfigurable array\n", "abstract": " Reconfigurable computational architectures are envisioned to deliver power efficient, high performance, flexible platforms for embedded systems design. The coarse-grained reconfigurable architecture ADRES (Architecture for Dynamically Reconfigurable Embedded Systems) and its compiler offer a tool flow to design sparsely interconnected 2D array processors with an arbitrary number of functional units, register files and interconnection topologies. This article presents an architectural exploration methodology and its results for the first implementation of the ADRES architecture on a 90nm standard-cell technology. We analyze performance, energy and power trade-offs for two typical kernels from the multimedia and wireless domains: IDCT and FFT. Architecture instances of different sizes and interconnect structures are evaluated with respect to their power versus performance trade-offs. An optimized\u00a0\u2026", "num_citations": "132\n", "authors": ["1049"]}
{"title": "Transparent reconfigurable acceleration for heterogeneous embedded applications\n", "abstract": " Embedded systems are becoming increasingly complex. Besides the additional processing capabilities, they are characterized by high diversity of computational models coexisting in a single device. Although reconfigurable architectures have already shown to be a potential solution for such systems, they just present significant speedups of very specific dataflow oriented kernels. Furthermore, reconfigurable fabric is still withheld by the need of special tools and compilers, clearly not sustaining backward software compatibility. In this paper, we propose a new technique to optimize both dataflow and control-flow oriented code in a totally transparent process, without the need of any modification in the source or binary codes. For that, we have developed a Binary Translation algorithm implemented in hardware, which works in parallel to a MIPS processor. The proposed mechanism is responsible for transforming\u00a0\u2026", "num_citations": "124\n", "authors": ["1049"]}
{"title": "The state-of-art and future trends in testing embedded memories\n", "abstract": " According to the International Technology Roadmap for Semiconductors (ITRS 2001), embedded memories will continue to dominate the increasing system on chips (SoCs) content in the next years, approaching 94% in about 10 years. Therefore the memory yield will have a dramatical impact on the overall defect-per-million (DPM) level, hence on the overall SoC yield. Meeting a high memory yield requires understanding memory designs, modelling their faulty behaviors in the presence of defects, designing adequate tests and diagnosis strategies as well as efficient repair schemes. This paper presents the state of art in memory testing including fault modeling, test design, built-in-self-test (BIST) and built-in-self-repair (BISR). Further research challenges and opportunities are discussed in enabling testing (embedded) memories, which use deep submicron technologies.", "num_citations": "124\n", "authors": ["1049"]}
{"title": "A platform for RFID security and privacy administration\n", "abstract": " This paper presents the design, implementation, and evaluation of the RFID Guardian, the first-ever unified platform for RFID security and privacy administration. The RFID Guardian resembles an \u2018\u2018RFID firewall,\u2019\u2019that monitors and controls access to RFID tags by combining a standard-issue RFID reader with unique RFID tag emulation capabilities. Our system provides a platform for both automated and coordinated usage of RFID security mechanisms, offering finegrained control over RFID-based auditing, key management, access control, and authentication capabilities. We have prototyped the RFID Guardian using off-the-shelf components, and our experience has shown that active mobile devices are a valuable tool for managing the security of RFID tags in a variety of applications, including protecting low-cost tags that are unable to regulate their own usage.More philosophically, RFID technology vividly illustrates the difficulties of security administration in a world of increasingly pervasive, decentralized, low-cost, and low-power computing. Our paper thus also offers a glimpse of what system administration may be like in the future, when laymen face the responsibility to manage systems of tiny computers that they are barely aware of.", "num_citations": "106\n", "authors": ["1049"]}
{"title": "Reverse engineering java card applets using power analysis\n", "abstract": " Power analysis on smart cards is widely used to obtain information about implemented cryptographic algorithms. We propose similar methodology for Java Card applets reverse engineering. Because power analysis alone does not provide enough information, we refine our methodology by involving additional information sources. Issues like distinguishing between bytecodes performing similar tasks and reverse engineering of conditional branches and nested loops are also addressed. The proposed methodology is applied to a commercially available Java Card smart card and the results are reported. We conclude that our augmented power analysis can be successfully used to acquire information about the bytecodes executed on a Java Card smart card.", "num_citations": "88\n", "authors": ["1049"]}
{"title": "Architecture enhancements for the ADRES coarse-grained reconfigurable array\n", "abstract": " Reconfigurable architectures provide power efficiency, flexibility and high performance for next generation embedded multimedia devices. ADRES, the IMEC Coarse-Grained Reconfigurable Array architecture and its compiler DRESC enable the design of reconfigurable 2D array processors with arbitrary functional units, register file organizations and interconnection topologies. This creates an enormous design space making it difficult to find optimized architectures. Therefore, architectural explorations aiming at energy and performance trade-offs become a major effort. In this paper we investigate the influence of register file partitions, register file sizes and the interconnection topology of ADRES. We analyze power, performance and energy delay trade-offs using IDCT and FFT as benchmarks while targeting 90nm technology. We also explore quantitatively the influences of several hierarchical optimizations\u00a0\u2026", "num_citations": "83\n", "authors": ["1049"]}
{"title": "The molen programming paradigm\n", "abstract": " In this paper we present the Molen programming paradigm, which is a sequential consistency paradigm for programming Custom Computing Machines (CCM). The programming paradigm allows for modularity and provides mechanisms for explicit parallel execution. Furthermore it requires only few instructions to be added in an architectural instruction set while allowing an almost arbitrary number of op-codes per user to be used in a CCM. A number of programming examples and discussion is provided in order to clarify the operation, sequence control and parallelism of the proposed programming paradigm.", "num_citations": "78\n", "authors": ["1049"]}
{"title": "The SARC architecture\n", "abstract": " The SARC architecture is composed of multiple processor types and a set of user-managed direct memory access (DMA) engines that let the runtime scheduler overlap data transfer and computation. The runtime system automatically allocates tasks on the heterogeneous cores and schedules the data transfers through the DMA engines. SARC's programming model supports various highly parallel applications, with matching support from specialized accelerator processors.", "num_citations": "73\n", "authors": ["1049"]}
{"title": "Assessing fat-tree topologies for regular network-on-chip design under nanoscale technology constraints\n", "abstract": " Most of past evaluations of fat-trees for on-chip interconnection networks rely on oversimplifying or even irrealistic architecture and traffic pattern assumptions, and very few layout analyses are available to relieve practical feasibility concerns in nanoscale technologies. This work aims at providing an in-depth assessment of physical synthesis efficiency of fat-trees and at extrapolating silicon-aware performance figures to back-annotate in the system-level performance analysis. A 2D mesh is used as a reference architecture for comparison, and a 65 nm technology is targeted by our study. Finally, in an attempt to mitigate the implementation cost of k-ary n-tree topologies, we also review an alternative unidirectional multi-stage interconnection network which is able to simplify the fat-tree architecture and to minimally impact performance.", "num_citations": "71\n", "authors": ["1049"]}
{"title": "Euroserver: Energy efficient node for european micro-servers\n", "abstract": " EUROSERVER is a collaborative project that aims to dramatically improve data centre energy-efficiency, cost, and software efficiency. It is addressing these important challenges through the coordinated application of several key recent innovations: 64-bit ARM cores, 3D heterogeneous silicon-on-silicon integration, and fully-depleted silicon-on-insulator (FD SOI) process technology, together with new software techniques for efficient resource management, including resource sharing and workload isolation. We are pioneering a system architecture approach that allows specialized silicon devices to be built even for low-volume markets where NRE costs are currently prohibitive. The EUROSERVER device will embed multiple silicon \"chiplets\" on an active silicon interposer. Its system architecture is being driven by requirements from three use cases: data centres and cloud computing, telecom infrastructures, and\u00a0\u2026", "num_citations": "69\n", "authors": ["1049"]}
{"title": "The hipeac vision\n", "abstract": " European Information & Communication Technology (ICT) research and development helped to solve many societal challenges by providing ever more computing power together with new applications that exploited these increasing processing capabilities. Numerous examples of the profound impact the computing industry had can be seen in medical imaging, chemical modeling for the development of new drugs, the Internet, business process automation, mobile communication, computer-aided design, computer-aided manufacturing, climate simulation and weather prediction, automotive safety, and many more.Advances in these areas were only possible because of the exponential growth in computing performance and power efficiency over the last decades. By comparison, if the aviation industry had made the same progress between 1982 and 2008, we would now fly from Brussels to New York in less than a second. Unfortunately, several evolutions are now threatening to bring an end to the exponential growth path of the computer industry.", "num_citations": "58\n", "authors": ["1049"]}
{"title": "OpenMP extensions for FPGA accelerators\n", "abstract": " Reconfigurable computing is one of the paths to explore towards low-power supercomputing. However, programming these reconfigurable devices is not an easy task and still requires significant research and development efforts to make it really productive. In addition, the use of these devices as accelerators in multicore, SMPs and ccNUMA architectures adds an additional level of programming complexity in order to specify the offloading of tasks to reconfigurable devices and the interoperability with current shared-memory programming paradigms such as openMP. This paper presents extensions to openMP 3.0 that try to address this second challenge and an implementation in a prototype runtime system. With these extensions the programmer can easily express the offloading of an already existing reconfigurable binary code (bitstream) hiding all the complexities related with device configuration, bitstream\u00a0\u2026", "num_citations": "55\n", "authors": ["1049"]}
{"title": "The MOLEN processor prototype\n", "abstract": " We present a prototype design of the MOLEN polymorphic processor, a CCM based on the co-processor architectural paradigm. The Xilinx Virtex II Pro technology is used as a prototyping platform. Experimental results prove the viability of the MOLEN concept. More precisely, the MPEG-2 application is accelerated very closely to its theoretical limits by implementing SAD, DCT and IDCT in reconfigurable hardware. The MPEG-2 encoder overall speedup is in the range between 2.80 and 2.96. The speedup of the MPEG-2 decoder varies between 1.56 and 1.63.", "num_citations": "53\n", "authors": ["1049"]}
{"title": "Sparse matrix storage format\n", "abstract": " Operations on Sparse Matrices are the key computational kernels in many scientific and engineering applications. They are characterized with poor substantiated performance. It is not uncommon for microprocessors to gain only 10-20% of their peak floating-point performance when doing sparse matrix computations even when special vector processors have been added as coprocessor facilities. In this paper we present new data format for sparse matrix storage. This format facilitates the continuous reuse of elements in the processing array. In comparison to other formats we achieve lower storage efficiency (only an extra bit per non-zero elements). A conjuncture of the proposed approach is that the hardware execution efficiency on sparse matrices can be improved.", "num_citations": "52\n", "authors": ["1049"]}
{"title": "Multimedia rectangularly addressable memory\n", "abstract": " We propose a scalable data alignment scheme incorporating module assignment functions and a generic addressing function for parallel access of randomly aligned rectangular blocks of data. The addressing function implicitly embeds the module assignment functions and it is separable, which potentially enables short critical paths and saves hardware resources. We also discuss the interface between the proposed memory organization and a linearly addressable memory. An implementation, suitable for MPEG-4 is presented and mapped onto an FPGA technology as a case study. Synthesis results indicate reasonably small hardware costs in the order of up to a few thousand FPGA slices for an exemplary 512/spl times/1024 two-dimensional (2-D) addressable space and a range of access pattern dimensions. Experiments suggest that speedups close to 8/spl times/ can be expected when compared to linear\u00a0\u2026", "num_citations": "47\n", "authors": ["1049"]}
{"title": "Routing protocols for mobile ad-hoc networks: current development and evaluation\n", "abstract": " Current research on routing protocols for Mobile Ad-hoc NETwork (MANET) has converged to several dominating routing protocols, including Optimized Link State Routing (OLSR), Ad-hoc On-demand Distance Vector (AODV) and Dynamic Source Routing (DSR). At the same time, classic routing protocols such as Open Shortest Path First (OSPF) and Destination Sequenced Distance Vector (DSDV) are improved for the MANET context. Research efforts also focus on issues such as Quality of Service (QoS), energy efficiency, and security, which already exist in the wired networks and are worsened in MANET. This paper examines the routing protocols and their newest improvements. We discuss the metrics used to evaluate these protocols and highlight the essential problems in the evaluation process itself.", "num_citations": "47\n", "authors": ["1049"]}
{"title": "March U: a test for unlinked memory faults\n", "abstract": " Short and efficient memory tests is the goal of every test designer. To reduce the cost of production tests, often a simple test which covers most of the faults, e.g. all simple (unlinked) faults, is desirable to eliminate most defective parts; a more costly test can be used thereafter to eliminate the remainder of the bad parts. Such a test-cost efficient approach is used by most manufacturers. In addition, system power-on tests are not allowed a long test time while a high fault coverage is desirable. The authors propose a new realistic fault model (the disturb fault model), and a set of tests for unlinked faults. These tests have the property of covering all simple (unlinked) faults at a very reasonable test time compared with existing tests.", "num_citations": "44\n", "authors": ["1049"]}
{"title": "March LA: a test for linked memory faults.\n", "abstract": " If a particular march testMguarantees the detection of each of the faults< y; x> jai and< y; x> ik1 (ja and k1 are the coupling cells with the closest address to the coupled cell) of S within a single march element, then that march test can detect linked faults consisting of any number of faults of S. Exceptions consist of some faults which are not detectable by linear tests [1]", "num_citations": "42\n", "authors": ["1049"]}
{"title": "Online task scheduling for the FPGA-based partially reconfigurable systems\n", "abstract": " Given the FPGA-based partially reconfigurable systems, hardware tasks can be configured into (or removed from) the FPGA fabric without interfering with other tasks running on the same device. In such systems, the efficiency of task scheduling algorithms directly impacts the overall system performance. By using previously proposed 2D scheduling model, existing algorithms could not provide an efficient way to find all suitable allocations. In addition, most of them ignored the single reconfiguration port constraint and inter-task dependencies. Further more, to our best knowledge there is no previous work investigating in the impact on the scheduling result by reusing already placed tasks. In this paper, we focus on online task scheduling and propose task scheduling solution that takes the ignored constraints into account. In addition, a novel \u201creuse and partial reuse\u201d approach is proposed. The simulation\u00a0\u2026", "num_citations": "39\n", "authors": ["1049"]}
{"title": "Online hardware task scheduling and placement algorithm on partially reconfigurable devices\n", "abstract": " In this paper, we propose an online hardware task scheduling and placement algorithm and evaluate it performance. Experimental results on large random task set show that our algorithm outperforms the existing algorithms in terms of reduced total wasted area up to 89.7%, has 1.5 % shorter schedule time and 31.3% faster response time.", "num_citations": "39\n", "authors": ["1049"]}
{"title": "A quantitative prediction model for hardware/software partitioning\n", "abstract": " An important step in Heterogeneous System Development is Hardware/Software Partitioning. This process involves exploring a huge design space. By using profiling to select hot-spots and estimate area and delay we can prune the design space considerably. We present a Quantitative Model that makes early predictions to prune the design space and support the partitioning process. The model is based on Software Complexity Metrics, which capture important aspects of functions as control intensity, data intensity, and code size. To remedy interdependence among software metrics, we performed a Principal Component Analysis. The hardware characteristics were determined by automatically generating VHDL from C using the DWARV C-to-VHDL compiler. Linear regression on these data generated our model. The model error differs per hardware characteristic. We show that for flip-flops the mean error is 69\u00a0\u2026", "num_citations": "38\n", "authors": ["1049"]}
{"title": "Intelligent merging online task placement algorithm for partial reconfigurable systems\n", "abstract": " Speed and placement quality are two very important attributes of a good online placement algorithm, because the time taken by the algorithm is considered as an overhead to the application overall execution time. To solve this problem, we propose three techniques: Merging Only if Needed (MON), Partial Merging (PM), and Direct Combine (DC). Our IM (intelligent merging) algorithm uses dynamically these three techniques to exploit their specific advantages. IM outperforms Bazargan's algorithm as it has placement quality within 0.89% but is 1.72 times faster.", "num_citations": "34\n", "authors": ["1049"]}
{"title": "Multi-core platforms for beamforming and wave field synthesis\n", "abstract": " Immersive-Audio technologies are widely used to build experimental and commercial audio systems. However, most of them are based on standard PCs, which introduce performance limitations and excessive power consumption. To address these drawbacks, we explore the implementation prospectives of two Immersive-Audio technologies: the beamforming (BF) and the wave field synthesis (WFS). We target two popular multi-core platforms, namely graphic processor units (GPUs) and field programmable gate arrays (FPGAs). We identify the most computationally intensive parts of both applications and employ the CUDA environment to map them onto a Quadro FX1700, a GeForce 8600GT, a GTX275, and a GTX460 GPU. Furthermore, we design our custom multi-core hardware accelerators for both algorithms and map them onto Virtex6 FPGAs. Both GPU and FPGA implementations are compared against\u00a0\u2026", "num_citations": "32\n", "authors": ["1049"]}
{"title": "A communication aware online task scheduling algorithm for FPGA-based partially reconfigurable systems\n", "abstract": " In this paper, we propose an efficient online task scheduling algorithm which targets 2D FPGA area partitioning model and takes into account the data dependency and the data communications 1) among hardware tasks and 2) between hardware tasks and external devices which have not been explicitly investigated in previous work. In the experiment with 10000 workloads, the evaluation result shows that our proposed scheduling algorithm is about 20 \u00d7 faster than the comparable approach.", "num_citations": "32\n", "authors": ["1049"]}
{"title": "Memory testing with a RISC microcontroller\n", "abstract": " Many systems are based on embedded microcontrollers. Applications demand for production and Power-On testing, including memory testing. Because low-end microcontrollers may not have memory BIST, the CPU will be the only resource to perform at least the Power-On tests. This paper shows the problems, solutions and limitations of CPU-based at-speed memory testing, illustrated with examples from the ATMEL RISC microcontroller.", "num_citations": "32\n", "authors": ["1049"]}
{"title": "CLOUDLIGHTNING: A framework for a self-organising and self-managing heterogeneous cloud\n", "abstract": " As clouds increase in size and as machines of different types are added to the infrastructure in order to maximize performance and power efficiency, heterogeneous clouds are being created. However, exploiting different architectures poses significant challenges. To efficiently access heterogeneous resources and, at the same time, to exploit these resources to reduce application development effort, to make optimisations easier and to simplify service deployment, requires a re-evaluation of our approach to service delivery. We propose a novel cloud management and delivery architecture based on the principles of self-organisation and self-management that shifts the deployment and optimisation effort from the consumer to the software stack running on the cloud infrastructure. Our goal is to address inefficient use of resources and consequently to deliver savings to the cloud provider and consumer in terms of reduced power consumption and improved service delivery, with hyperscale systems particularly in mind. The framework is general but also endeavours to enable cloud services for high performance computing. Infrastructure-as-a-Service provision is the primary use case, however, we posit that genomics, oil and gas exploration, and ray tracing are three downstream use cases that will benefit from the proposed architecture.", "num_citations": "31\n", "authors": ["1049"]}
{"title": "An efficient algorithm for free resources management on the FPGA\n", "abstract": " Finding the available empty space for arrival tasks on FPGAs with runtime partially reconfigurable abilities is the most time consuming phase in on-line placement algorithms. Naturally, this phase has the highest impact on the overall system performance. In this paper, we present a new algorithm which is used to find the complete set of maximum free rectangles on the FPGA at runtime. During scanning, our algorithm relies on dynamic information about the edges of all already placed tasks. Simulation results show that our algorithm has 1.5times to 5times speedup compared to state of the art algorithms aiming at maximum free rectangles. In addition, our proposal requires at least 4.4times less scanning load.", "num_citations": "31\n", "authors": ["1049"]}
{"title": "SAMS multi-layout memory: providing multiple views of data to boost SIMD performance\n", "abstract": " We propose to bridge the discrepancy between data representations in memory and those favored by the SIMD processor by customizing the low-level address mapping. To achieve this, we employ the extended Single-Affiliation Multiple-Stride (SAMS) parallel memory scheme at an appropriate level in the memory hierarchy. This level of memory provides both Array of Structures (AoS) and Structure of Arrays (SoA) views for the structured data to the processor, appearing to have maintained multiple layouts for the same data. With such multi-layout memory, optimal SIMDization can be achieved. Our synthesis results using TSMC 90nm CMOS technology indicate that the SAMS Multi-Layout Memory system has efficient hardware implementation, with a critical path delay of less than 1ns and moderate hardware overhead. Experimental evaluation based on a modified IBM Cell processor model suggests that our\u00a0\u2026", "num_citations": "30\n", "authors": ["1049"]}
{"title": "3D compaction: a novel blocking-aware algorithm for online hardware task scheduling and placement on 2D partially reconfigurable devices\n", "abstract": " Few of the benefits of exploiting partially reconfigurable devices are power consumption reduction, cost reduction, and customized performance improvement. To obtain these benefits, one main problem needs to be solved is the task scheduling and placement. Existing algorithms tend to allocate tasks at positions where can block future tasks to be scheduled earlier denoted as \u201dblocking-effect\u201d. To tackle this effect, a novel 3D total contiguous surface (3DTCS) heuristic is proposed for equipping our scheduling and placement algorithm with blocking-awareness. The proposed algorithm is evaluated with both synthetic and real workloads (e.g. MDTC, matrix multiplication, hamming code, sorting, FIR, ADPCM, etc). The proposed algorithm not only has better scheduling and placement quality but also has shorter algorithm execution time compared to existing algorithms.", "num_citations": "27\n", "authors": ["1049"]}
{"title": "Comparing tightly and loosely coupled mesochronous synchronizers in a NoC switch architecture\n", "abstract": " With the advent of networks-on-chip (NoCs), the interest for mesochronous synchronizers is again on the rise due to the intricacies of skew-controlled chip-wide clock tree distribution. Recently proposed schemes agree on a source synchronous design style with some form of ping-pong buffering to counter timing and metastability concerns. However, the integration issues of such synchronizers in a NoC setting are still largely uncovered. Most schemes are in fact placed between communicating switches, thus neglecting the abrupt increase of buffering resources needed at switch input stages. This paper goes a step forward and aims at deep integration of the synchronizer in the switch architecture, thus merging key tasks such as synchronization, buffering and flow control into a unique architecture block. This paper compares the integrated and the loosely coupled solutions from a performance and area viewpoint\u00a0\u2026", "num_citations": "26\n", "authors": ["1049"]}
{"title": "New algorithms for address decoder delay faults and bit line imbalance faults\n", "abstract": " Due to the rapid decrease of technology feature size speed related faults, such as Address Decoder Delay Faults (ADDFs), are becoming very important. In addition, increased leakage currents demand for improved tests for Bit Line Imbalance Faults (BLIFs)(caused by memory cell pass transistor leakage). This paper contributes to new and improved algorithms for detecting these faults. First it provides an improved version of existing GalPat algorithm and introduces two new algorithms to detect ADDFs; the paper also shines a new light on the use of the different stress combinations (counting methods, data-backgrounds) and their importance for the detection of ADDFs. Second, it provides an improved algorithm for detecting BLIFs; it increases the defect coverage by being able to detect lower leakage currents.", "num_citations": "25\n", "authors": ["1049"]}
{"title": "Test set development for cache memory in modern microprocessors\n", "abstract": " Up to 53% of the time spent on testing current Intel microprocessors is needed to test on-chip caches, due to the high complexity of memory tests and to the large amount of transistors dedicated to such memories. This paper discusses the methodology used to develop effective and efficient cache tests, and the way it is implemented to optimize the test set used at Intel to test their 512-kB caches manufactured in a 0.13- mum technology. An example is shown where a maximal test set of 15 tests with a corresponding maximum test time of 160.942 ms/chip is optimized to only six tests that require a test time of only 30.498 ms/chip.", "num_citations": "24\n", "authors": ["1049"]}
{"title": "The molen media processor: Design and evaluation\n", "abstract": " We present a fully operational prototype of the Molen reconfigurable processor based on the tightly coupled co-processor architectural paradigm. Within the Molen concept, a general purpose core processor controls the execution and reconfiguration of a reconfigurable co-processor, tuning the latter to various application specific algorithms. An ISA extension of only 4 instructions supports an arbitrary number of application specific functionalities running on the reconfigurable processor. The design is implemented on the Xilinx Virtex II ProTM technology and is modular. For the experiments, we consider three media applications: MJPEG, MPEG-2, and MPEG-4. Experimental data suggest two orders of magnitude kernel speedups, approaching 98% of the theoretical maximum speedups at the application level. The Molen infrastructure consumes trivial hardware resources. Its hardware-efficient FPGA implementation leaves 98% of the considered xc2vp20 chip area available for reconfigurable implementations of user designs.", "num_citations": "24\n", "authors": ["1049"]}
{"title": "Mesochronous NoC technology for power-efficient GALS MPSoCs\n", "abstract": " MPSoCs are today frequently designed as the composition of multiple voltage/frequency islands, thus calling for a GALS clocking style. In this context, the on-chip interconnection network can be either inferred as a single and independent clock domain or it can be distributed among core's domains. This paper targets the former scenario, since it results in the homogeneous speed of the NoC switching elements. From a physical design viewpoint, the main issues lie however in the chip-wide extension of the network domain and in the growing uncertainties affecting nanoscale silicon technologies. This paper proves that partitioning the network into mesochronous domains and merging synchronizers with NoC building blocks, two main advantages can be achieved. First, it is possible to evolve synchronous networks to mesochronous ones with marginal performance and area overhead. Second, the mesochronous\u00a0\u2026", "num_citations": "23\n", "authors": ["1049"]}
{"title": "Designing regular network-on-chip topologies under technology, architecture and software constraints\n", "abstract": " Regular multi-core processors are appearing in the embedded system market as high performance software programmable solutions. The use of regular interconnect fabrics for them allows fast design time, ease of routing, predictability of electrical parameters and good scalability. k-ary n-mesh topologies are candidate solutions for these systems, borrowed from the domain of off-chip interconnection networks. However, the on-chip integration has to deal with unique challenges at different levels of abstraction. From a technology viewpoint, interconnect reverse scaling causes critical paths to go across global links. Poor interconnect performance might also impact IP core speed depending on the synchronization mechanism at the interface. Finally, this might also conflict with the requirements that communication libraries employed in the MPSoC domain pose on the underlying interconnect fabric. This paper\u00a0\u2026", "num_citations": "23\n", "authors": ["1049"]}
{"title": "Construction and evaluation of an ultra low latency frameless renderer for VR\n", "abstract": " Latency-the delay between a user\u2019s action and the response to this action-is known to be detrimental to virtual reality. Latency is typically considered to be a discrete value characterising a delay, constant in time and space-but this characterisation is incomplete. Latency changes across the display during scan-out, and how it does so is dependent on the rendering approach used. In this study, we present an ultra-low latency real-time ray-casting renderer for virtual reality, implemented on an FPGA. Our renderer has a latency of\u223c 1 ms from \u2018tracker to pixel\u2019. Its frameless nature means that the region of the display with the lowest latency immediately follows the scan-beam. This is in contrast to frame-based systems such as those using typical GPUs, for which the latency increases as scan-out proceeds. Using a series of high and low speed videos of our system in use, we confirm its latency of\u223c 1 ms. We examine how the renderer performs when driving a traditional sequential scan-out display on a readily available HMD, the Oculus Rift DK2. We contrast this with an equivalent apparatus built using a GPU. Using captured human head motion and a set of image quality measures, we assess the ability of these systems to faithfully recreate the stimuli of an ideal virtual reality system-one with a zero latency tracker, renderer and display running at 1 kHz. Finally, we examine the results of these quality measures, and how each rendering approach is affected by velocity of movement and display persistence. We find that our system, with a lower average latency, can more faithfully draw what the ideal virtual reality system would. Further, we find that with\u00a0\u2026", "num_citations": "22\n", "authors": ["1049"]}
{"title": "Profiling of symmetric-encryption algorithms for a novel biomedical-implant architecture\n", "abstract": " Starting with the implantable pacemaker, microelectronic implants have been around for more than 50 years. A plethora of commercial and research-oriented devices have been developed so far for a wide range of biomedical applications. In view of an envisioned expanding implant market in the years to come, our ongoing research work is focusing on the specification and design of a novel biomedical microprocessor core, carefully tailored to a large subset of existing and future biomedical applications. Towards this end, we have taken steps in identifying various tasks commonly required by such applications and profiling their behavior and requirements. One such task is decryption of incoming commands to an implant and encryption of outgoing (telemetered) biological data. Secure bidirectional information relaying in implants has been largely overlooked so far although protection of personal (biological) data is\u00a0\u2026", "num_citations": "22\n", "authors": ["1049"]}
{"title": "A self-adaptive on-line task placement algorithm for partially reconfigurable systems\n", "abstract": " With the arrival of partial reconfiguration technology, modern FPGAs support swapping tasks in or out individually at run-time without interrupting other tasks running on the same FPGA. Although, implementing this feature achieves much better flexibility and device utilization, the challenge remains to quickly and efficiently place tasks arriving at run-time on such partially reconfigurable systems. In this paper, we propose an algorithm to handle this on-line, run-time task placement problem. By adding logical constraints on the FPGA and introducing our resources management solution, the simulation results show our algorithm has better overall performances compared with previous reported methods in terms of task rejection number, placement quality and execution time.", "num_citations": "22\n", "authors": ["1049"]}
{"title": "A fault primitive based analysis of dynamic memory faults\n", "abstract": " The new memory technologies and processes are introducing defects that cause faults that were unknown previously. One of the new observed faults in real designs are called dynamic faults. The paper gives a mathematical analysis of such a fault class based on the fault primitive concept. The dynamic fault space will be then established; within this space dynamic functional fault models can be studied and analyzed.", "num_citations": "22\n", "authors": ["1049"]}
{"title": "An AppGallery for dataflow computing\n", "abstract": " This paper describes the vision behind and the mission of the Maxeler Application Gallery (AppGallery.Maxeler.com) project. First, it concentrates on the essence and performance advantages of the Maxeler dataflow approach. Second, it reviews the support technologies that enable the dataflow approach to achieve its maximum. Third, selected examples of the Maxeler Application Gallery are presented; these examples are treated as the final achievement made possible when all the support technologies are put to work together (internal infrastructure of the AppGallery.Maxeler.com is given in a follow-up paper). As last, the possible impact of the Application Gallery is presented and the major conclusions are drawn.", "num_citations": "21\n", "authors": ["1049"]}
{"title": "Spatial programming with OpenSPL\n", "abstract": " In this                                                                  chapter we present OpenSPL, a novel programming language that enables designers to describe their computational structures in space and benefit from parallelism at multiple levels. We start with our motivation why spatial programming is currently among the most promising approaches for building future computing systems in Sect.\u20095.1. In Sect.\u20095.2 we introduce the basic principles behind OpenSPL and exemplify them with few simple examples targeting the first commercial offering of a Spatial Computer system by Maxeler Technologies. We validate the potential of Spatial Computers in Sect.\u20095.3 and conclude in Sect.\u20095.4.", "num_citations": "21\n", "authors": ["1049"]}
{"title": "General purpose computing with reconfigurable acceleration\n", "abstract": " In this paper we describe a new generic approach for accelerating software functions using a reconfigurable device connected through a high-speed link to a general purpose system. As opposed to related ISA extension approaches, we insert system calls to the original program at hand to control the reconfigurable accelerator. The reconfigurable device is controlled by the host through a device driver, and initiates communication by raising interrupts; it further has direct accesses to the main memory (DMA) operating in the virtual address space. To do so, the reconfigurable device supports address translation, memory protection and paging, while the driver serves the device interrupts, and ensures that shared data in the host-cache remain coherent. The system is implemented in a machine which provides a Hyper Transport bus connecting a Xilinx Virtex4-100 FPGA.", "num_citations": "21\n", "authors": ["1049"]}
{"title": "A novel fast online placement algorithm on 2D partially reconfigurable devices\n", "abstract": " In this paper, we propose a new strategy for online placement algorithm on 2D partially reconfigurable devices, termed the quad-corner (QC). The main differences between our algorithm and related art are quad-corner spreading capability and dynamical searching sequences. Moreover, existing algorithms do not evaluate their algorithms with real hardware tasks; we do experimentations with real hardware tasks on a real FPGA. Our proposal achieves better placement quality and fast online placement compared to existing approaches. Experiments with real workloads (e.g. MDCT, matrix multiplication, Hamming code, sorting, FIR, ADPCM, etc) on Virtex-4 show that the QC not only has 78% less penalty and 93% less wasted area than the existing algorithms on average but also has lower runtime overhead.", "num_citations": "21\n", "authors": ["1049"]}
{"title": "Reconfigurable universal adder\n", "abstract": " In this paper we present a novel adder/subtracter arithmetic unit that combines binary and binary code decimal (BCD) operations. The proposed unit uses effective addition/subtraction operations on unsigned, sign-magnitude, and various complement representations. Our design overcomes the limitations of previously reported approaches that produce some of the results in complement representation when operating on sign-magnitude numbers. The proposal can be implemented in ASIC as a run time configurable unit as well as in reconfigurable technology in form of a run-time reconfigurable engine. When reconfigurable technology is considered, a preliminary estimation indicates that 40 % of the hardware resources are shared by the different operations. This makes the proposed unit highly suitable for reconfigurable platforms with partial reconfiguration support. The proposed design together with some\u00a0\u2026", "num_citations": "21\n", "authors": ["1049"]}
{"title": "Elastic pipeline: addressing GPU on-chip shared memory bank conflicts\n", "abstract": " One of the major problems with the GPU on-chip shared memory is bank conflicts. We observed that the throughput of the GPU processor core is often constrained neither by the shared memory bandwidth, nor by the shared memory latency (as long as it stays constant), but is rather due to the varied latencies caused by memory bank conflicts. This results in conflicts at the writeback stage of the in-order pipeline and pipeline stalls, thus degrading system throughput. Based on this observation, we investigate and propose a novel elastic pipeline design that minimizes the negative impact of on-chip memory bank conflicts on system throughput, by decoupling bank conflicts from pipeline stalls. Simulation results show that our proposed elastic pipeline together with the co-designed bank-conflict aware warp scheduling reduces the pipeline stalls by up to 64.0%(with 42.3% on average) and improves the overall\u00a0\u2026", "num_citations": "20\n", "authors": ["1049"]}
{"title": "Addressing GPU on-chip shared memory bank conflicts using elastic pipeline\n", "abstract": " One of the major problems with the GPU on-chip shared memory is bank conflicts. We analyze that the throughput of the GPU processor core is often constrained neither by the shared memory bandwidth, nor by the shared memory latency (as long as it stays constant), but is rather due to the varied latencies caused by memory bank conflicts. This results in conflicts at the writeback stage of the in-order pipeline and causes pipeline stalls, thus degrading system throughput. Based on this observation, we investigate and propose a novel Elastic Pipeline design that minimizes the negative impact of on-chip memory bank conflicts on system throughput, by decoupling bank conflicts from pipeline stalls. Simulation results show that our proposed Elastic Pipeline together with the co-designed bank-conflict aware warp scheduling reduces the pipeline stalls by up to 64.0 % (with 42.3 % on average) and improves the\u00a0\u2026", "num_citations": "19\n", "authors": ["1049"]}
{"title": "Design space exploration of a mesochronous link for cost-effective and flexible GALS NOCs\n", "abstract": " There is today little doubt on the fact that a high-performance and cost-effective Network-on-Chip can only be designed in 45nm and beyond under a relaxed synchronization assumption. In this direction, this paper focuses on a GALS system where the NoC and its end-nodes have independent clocks (unrelated in frequency and phase) and are synchronized via dual-clock FIFOs at network interfaces. Within the network, we assume mesochronous synchronization implemented with hierarchical clock tree distribution. This paper contributes two essential components of any practical design automation support for network instantiation in the target system. On one hand, it introduces a switch design which greatly reduces the overhead for mesochronous synchronization and can be adapted to meet different layout constraints. On the other hand, the paper illustrates a design space exploration framework of\u00a0\u2026", "num_citations": "19\n", "authors": ["1049"]}
{"title": "Run-time adaptable architectures for heterogeneous behavior embedded systems\n", "abstract": " As embedded applications are getting more complex, they are also demanding highly diverse computational capabilities. The majority of all previously proposed reconfigurable architectures targets static data stream oriented applications, optimizing very specific computational kernels, corresponding to the typical embedded systems characteristics in the past. Modern embedded devices, however, impose totally new requirements. They are expected to support a wide variety of programs on a single platform. Besides getting more heterogeneous, these applications have very distinct behaviors. In this paper we explore this trend in more detail. First, we present a study about the behavioral difference of embedded applications based on the Mibench benchmark suite. Thereafter, we analyze the potential optimizations and constraints for two different run-time dynamic reconfigurable architectures with distinct\u00a0\u2026", "num_citations": "19\n", "authors": ["1049"]}
{"title": "Range tries for scalable address lookup\n", "abstract": " In this paper we introduce the Range Trie, a new multiway tree data structure for address lookup. Each Range Trie node maps to an address range [N a, N b) and performs multiple comparisons to determine the subrange an incoming address belongs to. Range Trie improves on the existing Range Trees allowing shorter comparisons than the address width. The maximum comparison length in a Range Trie node is [log 2 (N b--N a)] bits. Address parts can be shared among multiple concurrent comparisons or even omitted. Addresses can be properly aligned to further reduce the required address bits per comparison. In so doing, Range Tries can store in a single tree node more address bounds to be compared. Given a memory bandwidth, more comparisons are performed in a single step reducing lookup latency, memory accesses per lookup, and overall memory requirements. Latency and memory size scale\u00a0\u2026", "num_citations": "18\n", "authors": ["1049"]}
{"title": "A reconfigurable beamformer for audio applications\n", "abstract": " Beamforming is a signal processing technique that improves the signal strength received from a specific location. It is already used for many decades in telecommunications, while over the last years, it has been adopted by the audio research society, mostly to enhance speech recognition. In this paper, we propose a scalable organization for a hardware time-invariant beamformer that can be used in small handheld devices and complete 3D-audio systems. Our design can be configured according to the number of input channels. Furthermore, all critical internal modules, such as decimators, FIR filters and interpolators can be adjusted to support various input sampling rates. We developed a hardware prototype in VHDL targeting the Xilinx ML410 board incorporating Virtex4 FX60 FPGA. Following a constrained approach regarding FPGA resource utilization, our hardware prototype occupies 21% of the\u00a0\u2026", "num_citations": "18\n", "authors": ["1049"]}
{"title": "Reconfigurable multithreading architectures: A survey\n", "abstract": " This paper provides a survey on the existing proposals in the field of reconfigurable multithreading (\u03c1MT) architectures. Until now, the reconfigurable architectures have been classified according to implementation or architectural criteria, but never based on their \u03c1MT capabilities. More specifically, we identify reconfigurable architectures that provide implicit, explicit or no architectural support for \u03c1MT. For each of the proposals, we discuss the conceptual model, the limitations and the typical application domains. We also summarize the main design problems and identify some key research questions related to highly efficient \u03c1MT support. In addition, we discuss the application prospectives and propose possible research directions for future investigations.", "num_citations": "18\n", "authors": ["1049"]}
{"title": "Memory organization with multi-pattern parallel accesses\n", "abstract": " We propose an interleaved memory organization supporting multi-pattern parallel accesses in two-dimensional (2D) addressing space. Our proposal targets computing systems with high memory bandwidth demands such as vector processors, multimedia accelerators, etc. We substantially extend prior research on interleaved memory organizations introducing 2D-strided accesses along with additional parameters, which define a large variety of 2D data patterns. The proposed scheme guarantees minimum memory latency and efficient bandwidth utilization for arbitrary configuration parameters of the data pattern. We provide mathematical descriptions and proofs of correctness for the proposed addressing schemes. The design complexity and the critical paths are evaluated using technology independent resource counts and confirm the scalability of the proposal. Hardware synthesis results for 90 nm CMOS\u00a0\u2026", "num_citations": "18\n", "authors": ["1049"]}
{"title": "Infrastructure for cross-layer designs interaction\n", "abstract": " The current system design of mobile ad hoc networks (MANET), derived from their traditional fixed counterparts, cannot fully meet the requirements inherent to the dynamic nature of such networks. Cross-layer (CL) designs, a modification of the classic protocol stack, are envisioned as a solution for this problem. Many CL design approaches are proposed, each for a different optimization purpose. Mobile terminals require a variety of optimizations that can be provided only by using different CL designs. Consequently, the coexistence and interaction of such designs needs attention. The lack of common interface and infrastructure among different CL designs, however, makes their interaction a significant problem. The proposed common interaction infrastructure is able to compensate for the negative effects introduced by particular CL design by using runtime information from all CL implementations involved in the\u00a0\u2026", "num_citations": "18\n", "authors": ["1049"]}
{"title": "Profiling of lossless-compression algorithms for a novel biomedical-implant architecture\n", "abstract": " In view of a booming market for microelectronic implants, our ongoing research work is focusing on the specification and design of a novel biomedical microprocessor core targeting a large subset of existing and future biomedical applications. Towards this end, we have taken steps in identifying various tasks commonly required by such applications and profiling their behavior and requirements. A prominent family of such tasks is lossless data compression. In this work we profile a large collection of compression algorithms on suitably selected biomedical workloads. Compression ratio, average and peak power consumption, total energy budget, compression rate and program-code size metrics have been evaluated. Findings indicate the best-performing algorithms across most metrics to be mlzo (scores high in 5 out of 6 imposed metrics) and fin (present in 4 out of 6 metrics). Further mlzo profiling reveals the\u00a0\u2026", "num_citations": "17\n", "authors": ["1049"]}
{"title": "SAMS: single-affiliation multiple-stride parallel memory scheme\n", "abstract": " In this paper, we analyze the problem of supporting conflict-free access for multiple stride families in parallel memory schemes targeted for SIMD processing systems. We propose a Single-Affiliation Multiple-Stride (SAMS) scheme to support both unit-stride and strided conflict-free vector memory accesses. We compare our scheme against other previously proposed techniques using buffers and inter-vector out-of-order access. The main advantage of our proposal is that the atomic parallel access is supported without limiting the vector lengths. This provides better support when short vectors are considered. Our scheme also has the merit of better memory module resources utilization compared to the solutions with additional modules. Synthesis results for reconfigurable platform Virtex2-Pro FPGA indicate that the address translation of the SAMS scheme has efficient hardware implementation, which has a logic delay\u00a0\u2026", "num_citations": "17\n", "authors": ["1049"]}
{"title": "The challenges of intra-spacecraft wireless data interfacing\n", "abstract": " The onboard computer, various subsystems and the data handling system of a spacecraft can be viewed as the nodes of a sensor/actuator network. Wireless sensor networks for monitoring and control have been in existence for several years, however, their adoption to space applications is still under discussion. Despite the fact that many communication protocols with adequate power and reliability characteristics are commercially available, the selection of a suitable standard for spacecraft onboard communication remains an open question. This paper enlists the challenges related to wireless interfacing onboard spacecraft in general. Thereafter, characteristics of major intra-spacecraft data traffic types in a typical microsatellite are discussed. Based on this information we evaluate Bluetooth, WiFi and ZigBee as three potential candidates and suggest Bluetooth and ZigBee as two good options for onboard data communication of a microsatellite.", "num_citations": "17\n", "authors": ["1049"]}
{"title": "Reconfigurable implementation for the AES algorithm\n", "abstract": " The choice of a platform, software, ASIC or FPGA, is driven by several aspects, such as algorithm performance, cost and flexibility. Although ASIC has the highest performance and the lowest unit cost, it has no flexibility at all. While software has the most flexibility of all, the performance is very low. The MOLEN architecture, developed at the Techinical University of Delft, open up new perspective for this problem. The architecture is based on a cooperation between a general purpose core processor and reconfigurable hardware, for example a FPGA. Since cryptographic algorithms are relative frequently upgraded, this high flexibility is desperately needed. There are several reasons for upgrading such as when the algorithm is broken or there is a better algorithm or even in case where an algorithm independent protocol is needed. To put it briefly the\u00a2\u00a4\u00a3-coded processor put a new perspective on great performance and high flexibility. In this paper we investigate several Rijndael (AES) implementations based on the Molen\u00a2\u00a4\u00a3-coded processor. Two types of FPGAs, Xilinx and Altera, are evaluated in order to produce realistic results. In addition, a modified simulator based on the SimpleScalar Toolset (v3. 0) is used to estimate the performance potential. The profiling of the AES code is done based on different methodologies. In this paper an analogy is drawn between. The VHDL descriptions produced, are enhanced with standard interface making them reusable for other research projects based on the same architecture and dealing with similar data processing problems. The AES running on the top of Molen performs equaly good as other FPGA\u00a0\u2026", "num_citations": "17\n", "authors": ["1049"]}
{"title": "Improving soft error correction capability of 4-d parity codes\n", "abstract": " In order to reduce overall system costs, the aerospace industry has been increasingly using commercial off the shelf components in their products. The sensitivity of these products to radiation induced soft errors becomes a major concern. In this paper, we propose a method to increase the reliability of a given off the shelf component by manipulating the software-based error correction algorithm of its already existing 4-D parity codes. The paper shows that using this approach, it is possible to correct triple bit adjacent errors, without adversely affecting the performance or memory usage. Furthermore, we discuss the results of implementing and validating the proposed approach in practice on PIC microcontrollers.", "num_citations": "16\n", "authors": ["1049"]}
{"title": "Faster: facilitating analysis and synthesis technologies for effective reconfiguration\n", "abstract": " The FASTER (Facilitating Analysis and Synthesis Technologies for Effective Reconfiguration) EU FP7 project, aims to ease the design and implementation of dynamically changing hardware systems. Our motivation stems from the promise reconfigurable systems hold for achieving high performance and extending product functionality and lifetime via the addition of new features that operate at hardware speed. However, designing a changing hardware system is both challenging and time-consuming.FASTER facilitates the use of reconfigurable technology by providing a complete methodology enabling designers to easily specify, analyze, implement and verify applications on platforms with general-purpose processors and acceleration modules implemented in the latest reconfigurable technology. Our tool-chain supports both coarse- and fine-grain FPGA reconfiguration, while during execution a flexible run-time\u00a0\u2026", "num_citations": "15\n", "authors": ["1049"]}
{"title": "A Polymorphic Register File for matrix operations\n", "abstract": " Previous vector architectures divided the available register file space in a fixed number of registers of equal sizes and shapes. We propose a register file organization which allows dynamic creation of a variable number of multidimensional registers of arbitrary sizes referred to as a Polymorphic Register File. Our objective is to evaluate the performance benefits of the proposed organization. Simulation results using real applications (Floyd and CG) suggest speedups of up to 3 times compared to the Cell SPU for Floyd and 2 times compared to a one dimensional vectorized version of the sparse matrix vector multiplication. Moreover, in the same experimental context, a large reduction in the number of executed instructions of up to 3000 times for Floyd and 2000 times for sparse matrix vector multiplication is achieved.", "num_citations": "15\n", "authors": ["1049"]}
{"title": "ImpBench: A novel benchmark suite for biomedical, microelectronic implants\n", "abstract": " So far, design and deployment of microelectronic, implantable devices has largely had a strongly ldquoad-hocrdquo character. The majority of existing devices has been custom-tailored to the specific application in mind, in an effort to abide by strict design constraints on safety as well as power and size. However, an enabling technology and the fact that implants are gradually becoming mainstream market products calls for a more structured design approach. Towards that end, in this paper we present ImpBench, a novel benchmark suite meant for designing and evaluating new digital processors for microelectronic implants. In an application field as wide as the various pathoses of the human body, we have conceptualized this suite based on common-sense and market-driven indicators, and we have established its usefulness and uniqueness based on extensive experimental measurement. The suite consists of\u00a0\u2026", "num_citations": "15\n", "authors": ["1049"]}
{"title": "External memory controller for Virtex II Pro\n", "abstract": " An implementation of an on chip memory (OCM) based dual data rate external memory controller (OCM2DDR) for Virtex II Pro is described. The proposed OCM2DDR controller comprises data side OCM (DSOCM) bus interface module, read and write control logic, halt read module and Xilinx DDR controller IP core. The presented design supports 16MB of external DDR memory and 32 to 64 bits data conversion for single read and write operations. Our implementation uses 1063 slices of Virtex2Pro FPGA and runs at 100 MHz. The major benefits of the proposed design are high bandwidth to external memory with reduced and more predictable access times compared to the Xilinx PLB DDR controller implementation. More specially, our read and write accesses are 2,44 and 4,25 times faster, than the PLB based solution respectively", "num_citations": "15\n", "authors": ["1049"]}
{"title": "The vineyard approach: Versatile, integrated, accelerator-based, heterogeneous data centres\n", "abstract": " Emerging web applications like cloud computing, Big Data and social networks have created the need for powerful centres hosting hundreds of thousands of servers. Currently, the data centres are based on general purpose processors that provide high flexibility buts lack the energy efficiency of customized accelerators. VINEYARD aims to develop an integrated platform for energy-efficient data centres based on new servers with novel, coarse-grain and fine-grain, programmable hardware accelerators. It will, also, build a high-level programming framework for allowing end-users to seamlessly utilize these accelerators in heterogeneous computing systems by employing typical data-centre programming frameworks (e.g. MapReduce, Storm, Spark, etc.). This programming framework will, further, allow the hardware accelerators to be swapped in and out of the heterogeneous infrastructure so as to offer high\u00a0\u2026", "num_citations": "14\n", "authors": ["1049"]}
{"title": "Efficient datapath merging for the overhead reduction of run-time reconfigurable systems\n", "abstract": " High latencies in FPGA reconfiguration are known as a major overhead in run-time reconfigurable systems. This overhead can be reduced by merging multiple data flow graphs representing different kernels of the original program into a single (merged) datapath that will be configured less often compared to the separate datapaths scenario. However, the additional hardware introduced by this technique increases the kernels execution time. In this paper, we present a novel datapath merging technique that reduces both the configuration and execution times of kernels mapped on the reconfigurable fabric. Experimental results show up to 13% reduction in the configuration and execution times of kernels from media-bench workloads, compared to previous art on datapath merging. When compared to conventional high-level synthesis algorithms, our proposal reduces kernels configuration and execution times\u00a0\u2026", "num_citations": "14\n", "authors": ["1049"]}
{"title": "Bandwidth analysis for reusing functional interconnect as Test Access Mechanism\n", "abstract": " Test data travels through a System-on-Chip (SOC) from the chip pins to the module-under-test and vice versa via a Test Access Mechanism (TAM). Conventionally, a TAM is implemented with dedicated wires. However, also existing functional interconnect, such as a bus or Network-on-Chip (NOC), can be reused as TAM. This will reduce the overall design effort and the silicon area. For a given module, its test set, and maximal bandwidth that the functional interconnect can offer between ATE and module-under-test, our approach designs a test wrapper for the module-under-test such that the test length is minimized. Unfortunately, it is unavoidable that with the test data also unused (idle) bits are transported. This paper presents a TAM bandwidth utilization analysis and techniques for idle bits reduction, to minimize the test length. We classify the idle bits into four types which explain the reason for bandwidth under\u00a0\u2026", "num_citations": "14\n", "authors": ["1049"]}
{"title": "The Virtex II ProTM MOLEN Processor\n", "abstract": " We use the Xilinx Virtex II ProTM technology as prototyping platform to design a MOLEN polymorphic processor, a custom computing machine based on the co-processor architectural paradigm. The PowerPC embedded in the FPGA is operating as a general purpose (core) processor and the reconfigurable fabric is used as a reconfigurable co-processor. The paper focuses on hardware synthesis results and experimental performance evaluation, proving the viability of the MOLEN concept. More precisely, the MPEG-2 application is accelerated very closely to its theoretical limits by implementing SAD, DCT and IDCT as reconfigurable co-processors. For a set of popular test video sequences the MPEG-2 encoder overall speedup is in the range between 2.64 and 3.18. The speedup of the MPEG-2 decoder varies between 1.65 and 1.94.", "num_citations": "14\n", "authors": ["1049"]}
{"title": "Rapid development of Gzip with MaxJ\n", "abstract": " Design productivity is essential for high-performance application development involving accelerators. Low level hardware description languages such as Verilog and VHDL are widely used to design FPGA accelerators, however, they require significant expertise and considerable design efforts. Recent advances in high-level synthesis have brought forward tools that relieve the burden of FPGA application development but the achieved performance results can not approximate designs made using low-level languages. In this paper we compare different FPGA implementations of gzip. All of them implement the same system architecture using different languages. This allows us to compare Verilog, OpenCL and MaxJ design productivity. First, we illustrate several conceptional advantages of the MaxJ language and its platform over OpenCL. Next we show on the example of our gzip implementation how an\u00a0\u2026", "num_citations": "13\n", "authors": ["1049"]}
{"title": "Online evolving fuzzy rule-based prediction model for high frequency trading financial data stream\n", "abstract": " Analyzing and predicting the high frequency trading (HFT) financial data stream is very challenging due to the fast arrival times and large amount of the data samples. Aiming at solving this problem, an online evolving fuzzy rule-based prediction model is proposed in this paper. Because this prediction model is based on evolving fuzzy rule-based systems and a novel, simpler form of data density, it can autonomously learn from the live data stream, automatically build/remove its rules and recursively update the parameters. This model responds quickly to all unpredictable sudden changes of financial data and re-adjusts itself to follow the new data pattern. Experimental results show the excellent prediction performance of the proposed approach with real financial data stream regardless of quick shifts of data patterns and frequent appearances of abnormal data samples.", "num_citations": "13\n", "authors": ["1049"]}
{"title": "FPGA accelerator for real-time skin segmentation\n", "abstract": " Many real-time image processing applications are confronted with performance limitations when implemented in software. The skin segmentation algorithm utilized in hand gesture recognition as developed by the ICT department of Delft University of Technology presents an example of such an application. This paper presents the design of an FPGA based accelerator which alleviates the host PC's computational effort required for real-time skin segmentation. We show that our design utilizes no more than 88% of the resources available within the targeted XC2VP30 device. In addition, the proposed approach is highly portable and not limited to the considered real-time image processing algorithm only", "num_citations": "13\n", "authors": ["1049"]}
{"title": "An analysis of (linked) address decoder faults\n", "abstract": " The complexity of memory tests arises when linked faults are taken into consideration. Usually only the class of linked faults in the memory cell array have been taken into consideration, while the class of linked faults involving address decoder faults has been ignored. This paper gives an overview of the most important and commonly used fault models including the disturb fault model. It derives a set of conditions march tests have to satisfy in order to detect address decoder faults (AFs) when they are not linked; these conditions are shown to be dependent on the memory technology (SRAM and DRAM). Next, a set of conditions for march tests are derived to detect linked AFs (linked with other AFs or linked with faults in the memory cell array). The paper concludes with the analysis of a set of well-known march tests for the fault coverage of unlinked and linked AFs. Many of the widely used tests are shown not to be\u00a0\u2026", "num_citations": "13\n", "authors": ["1049"]}
{"title": "Scalability evaluation of a Polymorphic Register File: a CG case study\n", "abstract": " We evaluate the scalability of a Polymorphic Register File using the Conjugate Gradient method as a case study. We focus on a heterogeneous multi-processor architecture, taking into consideration critical parameters such as cache bandwidth and memory latency. We compare the performance of 256 Polymorphic Register File-augmented workers against a single Cell PowerPC Processor Unit (PPU). In such a scenario, simulation results suggest that for the Sparse Matrix Vector Multiplication kernel, absolute speedups of up to 200 times can be obtained. Moreover, when equal number of workers in the range 1-256 is employed, our design is between 1.7 and 4.2 times faster than a Cell PPU-based system. Furthermore, we study the memory latency and cache bandwidth impact on the sustainable speedups of the system considered. Our tests suggest that a 128 worker configuration requires the caches to\u00a0\u2026", "num_citations": "12\n", "authors": ["1049"]}
{"title": "Model-based fault detection for the DELFI-N3XT attitude determination system\n", "abstract": " The Delfi-n3Xt nanosatellite is the second Dutch university satellite currently being developed at the Delft University of Technology. In its design, the Attitude Determination System (ADS) will be pivotal for optimal power point tracking to adequately provide the energy needed for normal operation and charging of the batteries. In this paper we explore a fault detection mechanism for the ADS based on the Unscented Kalman Filter (UKF) state estimator which has been successfully integrated into the simulation and modelling environment. The UKF provides a more computationally efficient estimator than traditional Kalman filter variants. Faults introduced in the system include changes in the noise model and stuck-at-0 faults, resulting in disturbances in the output of the filter. Parameters of the filter are varied and the behaviour of the outcoming residuals is analyzed to evaluate its effectiveness in the detection of these\u00a0\u2026", "num_citations": "12\n", "authors": ["1049"]}
{"title": "High speed merged-datapath design for run-time reconfigurable systems\n", "abstract": " Datapath merging is an efficient high level synthesis method to merge data flow graphs (DFGs), corresponding to two or more computational intensive loops. This process creates a general purpose datapaths (merged datapaths) instead of multiple datapaths that results in shorter bit-stream length and therefore reduces the configuration time in reconfigurable systems. The merged datapath, however has worse loop execution time. This paper represents two datapath merging algorithms to address this problem. These algorithms consider the impact of adding multiplexer's latency to the critical path delay of the merged datapath. The former algorithm merges DFGs from the biggest DFG to the smallest one to make high speed merged datapath. The latter merges DFGs in steps, and in the final step, it combines the resources inside the merged datapath to achieve additional reduction in configuration time. The proposed\u00a0\u2026", "num_citations": "12\n", "authors": ["1049"]}
{"title": "FPGA implementation of modified Gram-Schmidt qr-decomposition\n", "abstract": " Computer Engineering Publications Database - View Publication CE logo Computer Engineering Publications Database (2000-2018) Publications Authors Home \u00bb Publications \u00bb FPGA Implementation of Modified Gram-Schmidt QR-Decomposition FPGA Implementation of Modified Gram-Schmidt QR-Decomposition 417_fpga_implementation_of_modified_gramschmidt_qrdecompositio.PDF Publication Type Conference Paper Title FPGA Implementation of Modified Gram-Schmidt QR-Decomposition Author(s) PN Ganchosov GK Kuzmanov H. Kabakchiev V. Behar RP Romansky GN Gaydadjiev Publication Date January 2009 Conference Name 3rd HiPEAC Workshop on Reconfigurable Computing Period 25 January 2009 Location Paphos, Cyprus ISBN t Page Numbers 41-51 published Published Selected Publication No Note Topic(s) None Theme(s) None Project(s) None Group(s) Computer Engineering IEEE \u2026", "num_citations": "12\n", "authors": ["1049"]}
{"title": "Hartes toolchain early evaluation: Profiling, Compilation and HDL generation\n", "abstract": " The aim of the hartes project is to facilitate and automate the rapid design and development of heterogeneous embedded systems, targeting a combination of a general purpose embedded processor, digital signal processing and reconfigurable hardware. In this paper, we evaluate three tools from the hartes toolchain supporting profiling, compilation, and HDL generation. These tools facilitate the HW/SW partitioning, co-design, co-verification, and co-execution of demanding embedded applications. The described tools are provided by the Delft Work Bench framework 1 . Experimental results on MJPEG and G721 encoder application case studies suggest overall performance improvement of 228% and 36% respectively.", "num_citations": "12\n", "authors": ["1049"]}
{"title": "LEGaTO: towards energy-efficient, secure, fault-tolerant toolset for heterogeneous computing\n", "abstract": " LEGaTO is a three-year EU H2020 project which started in December 2017. The LEGaTO project will leverage task-based programming models to provide a software ecosystem for Made-in-Europe heterogeneous hardware composed of CPUs, GPUs, FPGAs and dataflow engines. The aim is to attain one order of magnitude energy savings from the edge to the converged cloud/HPC.", "num_citations": "11\n", "authors": ["1049"]}
{"title": "Architecture-level fault-tolerance for biomedical implants\n", "abstract": " In this paper, we describe the design and implementation of a new fault-tolerant RISC-processor architecture suitable for a design framework targeting biomedical implants. The design targets both soft and hard faults and is original in efficiently combining as well as enhancing classic fault-tolerance techniques. The proposed architecture allows run-time tradeoffs between performance and fault tolerance by means of instruction-level configurability. The system design is synthesized for UMC 90nm CMOS standard-process and is evaluated in terms of fault coverage, area, average power consumption, total energy consumption and performance for various duplication policies and test-sequence schedules. It is shown that area and power overheads of approximately 25% and 32%, respectively, are required to implement our techniques on the baseline processor. The major overheads of the proposed architecture are\u00a0\u2026", "num_citations": "11\n", "authors": ["1049"]}
{"title": "Using a CISC microcontroller to test embedded memories\n", "abstract": " Small microcontroller-based systems are omnipresent. Often, they do not have Memory BIST (MBIST), or the MBIST is not available to the user. In such cases the CPU will be the only resource to perform at least the Power-On testing of the embedded memories. This paper highlights the capabilities and limitations of CISC architectures to apply at-speed memory tests.", "num_citations": "11\n", "authors": ["1049"]}
{"title": "Low-cost, customized and flexible SRAM MBIST engine\n", "abstract": " This paper contributes to the field of test engineering: it shows the tradeoffs and engineering aspects of a low-cost, flexible SRAM MBIST engine, applied to the 768 and 256 byte SRAMs of an 8051 microcontroller. The simplicity and orthogonality of the architecture allowed for a full-custom implementation by Micronas in 120 hours of design time, while the area is reduced by 75% of an earlier commercial version.", "num_citations": "11\n", "authors": ["1049"]}
{"title": "Capturing topology-level implications of link synthesis techniques for nanoscale networks-on-chip\n", "abstract": " In the context of nanoscale networks-on-chip (NoCs), each link implementation solution is not just a specific synthesis optimization technique with local performance and power implications, but gives rise to a well-differentiated point in the architecture design space. This in an effect of the tight interaction existing between architecture and physical design layers in nanoscale technologies.", "num_citations": "11\n", "authors": ["1049"]}
{"title": "Preliminary analysis of the cell be processor limitations for sequence alignment applications\n", "abstract": " The fast growth of bioinformatics field has attracted the attention of computer scientists in the last few years. At the same time the increasing database sizes require greater efforts to improve the computational performance. From a computer architecture point of view, we intend to investigate how bioinformatics applications can benefit from future multi-core processors. In this paper we present a preliminary study of the Cell BE processor limitations when executing two representative sequence alignment applications (Ssearch and ClustalW). The inherent large parallelism of the targeted algorithms makes them ideal for architectures supporting multiple dimensions of parallelism (TLP and DLP). However, in the case of Cell BE we identified several architectural limitations that need a careful study and quantification.", "num_citations": "11\n", "authors": ["1049"]}
{"title": "DRAM-specific space of memory tests\n", "abstract": " DRAM testing has always been theoretically considered as a subset of general memory testing, despite the disagreement of this assumption with the DRAM test practice. This paper presents a recently developed space of DRAM faults that describes the unique aspects of DRAM behavior, it validates this fault space using extensive Spice simulation, and it identifies the memory tests necessary to detect these faults. Six different tests are derived and shown to correspond to highly effective DRAM tests in practice", "num_citations": "11\n", "authors": ["1049"]}
{"title": "Loading \u03c1\u03bc-Code: Design Considerations\n", "abstract": " This article investigates microcode generation, finalization and loading in MOLEN \u03c1\u03bc processors. In addition, general solutions for these issues are presented and implementation for Xilinx Virtex-II Pro platform FPGA is introduced.", "num_citations": "11\n", "authors": ["1049"]}
{"title": "Convolutional neural networks on dataflow engines\n", "abstract": " In this paper we discuss a high performance implementation for Convolutional Neural Networks (CNNs) inference on the latest generation of Dataflow Engines (DFEs). We discuss the architectural choices made during the design phase taking into account the DFE chip properties. We then perform design space exploration, considering the memory bandwidth and resources utilisation constraints derived from the used DFE and the chosen architecture. Finally, we discuss the high performance implementation and compare the obtained performance against other implementations, showing that our proposed design reaches 2,450 GOPS when running VGG16 as a test case.", "num_citations": "10\n", "authors": ["1049"]}
{"title": "EXTRA: Towards the exploitation of eXascale technology for reconfigurable architectures\n", "abstract": " To handle the stringent performance requirements of future exascale-class applications, High Performance Computing (HPC) systems need ultra-efficient heterogeneous compute nodes. To reduce power and increase performance, such compute nodes will require hardware accelerators with a high degree of specialization. Ideally, dynamic reconfiguration will be an intrinsic feature, so that specific HPC application features can be optimally accelerated, even if they regularly change over time. In the EXTRA project, we create a new and flexible exploration platform for developing reconfigurable architectures, design tools and HPC applications with run-time reconfiguration built-in as a core fundamental feature instead of an add-on. EXTRA covers the entire stack from architecture up to the application, focusing on the fundamental building blocks for run-time reconfigurable exascale HPC systems: new chip\u00a0\u2026", "num_citations": "10\n", "authors": ["1049"]}
{"title": "An improved system approach towards future cochlear implants\n", "abstract": " Cochlear implants (CIs) have been used for many years to restore hearing for deaf patients. Unfortunately, today's CIs are still bulky devices and uncomfortable to wear. In this paper we present three innovations that ultimately should pave the way to a fully implantable bionic ear. First a microfabrication process used to fabricate the polymer metal microelectrode array for auditory nerve stimulation is discussed. Subsequently, a compact biphasic programmable stimulator chip to be used along with this electrode array is presented. By using a double loop feedback circuit topology, the circuit provides a precise stimulation current while requiring only little voltage headroom. The resulting low power consumption and reduced chip area allow for integration of the electronic circuitry onto the electrode array. Finally, as reliability and data transmission rate are two of the most critical issues in CI devices, we propose a\u00a0\u2026", "num_citations": "10\n", "authors": ["1049"]}
{"title": "Evaluating various branch-prediction schemes for biomedical-implant processors\n", "abstract": " This paper evaluates various branch-prediction schemes under different cache configurations in terms of performance, power, energy and area on suitably selected biomedical workloads. The benchmark suite used consists of compression, encryption and data-integrity algorithms as well as real implant applications, all executed on realistic biomedical input datasets. Results are used to drive the (micro)architectural design of a novel microprocessor targeting microelectronic implants. Our profiling study has revealed that, under strict or relaxed area constraints and regardless of cache size, the ALWAYS TAKEN and ALWAYS NOT-TAKEN static prediction schemes are, in almost all cases, the most suitable choices for the envisioned implant processor. It is further shown that bimodal predictors with small Branch-Target-Buffer (BTB) tables are suboptimal yet also attractive solutions when processor I/D-cache sizes are\u00a0\u2026", "num_citations": "10\n", "authors": ["1049"]}
{"title": "Butterfly vs. unidirectional fat-trees for networks-on-chip: Not a mere permutation of outputs\n", "abstract": " Bidirectional topologies are usually preferred over unidirectional ones. However, recent works have demonstrated that RUFT, a traffic-balancing routing algorithm on a Unidirectional Multistage Network (UMIN), can perform as well as a Bidirectional Multistage Network, but significantly reducing both implementation and operating costs. RUFT is a simplification of the k-ary n-tree topology, the most widely-used implementation of the Fat-Tree topology. RUFT resembles the classical unidirectional Butterfly topology, but with a different connection pattern between switches from the last stage and cores. This work provides a comparison in terms of performance and implementation costs between both topologies, RUFT and unidirectional Butterfly for on-chip interconnects. Our high level and post-layout analysis shows that RUFT is a much more convenient alternative than traditional Butterfly when laying out on silicon.", "num_citations": "10\n", "authors": ["1049"]}
{"title": "Efficient Multicast Support in High-Speed Packet Switches.\n", "abstract": " The tremendous growth of the Internet coupled with newly emerging applications has created a vital need for multicast traffic support by backbone routers and ATM switches. Considerable research work has been done on Input Queued (IQ) switches to handle multicast traffic flows. Unfortunately, all previously proposed solutions were of no practical value because they either lack performance or were simply too complex to implement. Internally Buffered Crossbar (IBC) switches, where a limited small amount of memory is added in each crosspoint of the crossbar fabric, on the other hand, have been considered as a robust alternative to buffer-less crossbar switches to improve the switching performance. However, very little has been done on multicasting in IBC switches. In this paper, we fill this gap and study the multicasting problem in IBC switches. In particular, we propose a novel IBC based multicast architecture along with a simple scheduling scheme named Multicast cross-point Round Robin (MXRR). Our scheme was shown to handle multicast traffic more efficiently and far better than all previous schemes for both the multicast FIFO architecture as well as the multicast k FIFO queues architecture. Yet, MXRR is both practical and achieves high performance.", "num_citations": "10\n", "authors": ["1049"]}
{"title": "Quantum chemistry in dataflow: Density-fitting MP2\n", "abstract": " We demonstrate the use of dataflow technology in the computation of the correlation energy in molecules at the M\u00f8ller\u2013Plesset perturbation theory (MP2) level. Specifically, we benchmark density fitting (DF)-MP2 for as many as 168 atoms (in valinomycin) and show that speed-ups between 3 and 3.8 times can be achieved when compared to the MOLPRO package run on a single CPU. Acceleration is achieved by offloading the matrix multiplications steps in DF-MP2 to Dataflow Engines (DFEs). We project that the acceleration factor could be as much as 24 with the next generation of DFEs.", "num_citations": "9\n", "authors": ["1049"]}
{"title": "Maxeler data-flow in computational finance\n", "abstract": " Computational finance is an area that includes many algorithms in trading and analytics that are both computationally very complex and performance critical. As financial institutions intend to perform a steadily increasing number of computations and obtain the results as quickly as possible, computer systems are expected to satisfy these growing performance demands. However, recent years have brought the end of \u201cfree\u201d processors speed-ups, and single-thread performance is no longer the driving force behind automatic performance gains enjoyed by the\u00a0industry for many decades. Nowadays, high-performance computing systems have to increasingly rely on parallel programming models where the original application has to be modified to exploit many parallel cores. This requires considerable redesign efforts and yet, the desired performance improvements are not guaranteed. Some financial applications\u00a0\u2026", "num_citations": "9\n", "authors": ["1049"]}
{"title": "Smart technologies for effective reconfiguration: The faster approach\n", "abstract": " Current and future computing systems increasingly require that their functionality stays flexible after the system is operational, in order to cope with changing user requirements and improvements in system features, i.e. changing protocols and data-coding standards, evolving demands for support of different user applications, and newly emerging applications in communication, computing and consumer electronics. Therefore, extending the functionality and the lifetime of products requires the addition of new functionality to track and satisfy the customers needs and market and technology trends. Many contemporary products along with the software part incorporate hardware accelerators for reasons of performance and power efficiency. While adaptivity of software is straightforward, adaptation of the hardware to changing requirements constitutes a challenging problem requiring delicate solutions. The FASTER\u00a0\u2026", "num_citations": "9\n", "authors": ["1049"]}
{"title": "Data path Configuration Time Reduction for Run-time Reconfigurable Systems.\n", "abstract": " The FPGA (re) configuration is a time-consuming process and a bottleneck in FPGA-based Run-Time Reconfigurable (RTR) systems. In this paper, we present a High Level Synthesis (HLS) method, based on the data path merging technique to amortize the hardware configuration time in RTR systems. It merges the Data Flow Graphs (DFGs) of two or more computational intensive parts of the application and makes one general purpose data path (merged data path) which results in shorter bit-stream length and therefore reduces the configuration time. Our experimental results using the proposed method on mediabench applications, show up to 40% reduction in the configuration time compared to conventional synthesis method.", "num_citations": "9\n", "authors": ["1049"]}
{"title": "Implementation of a reliable date bus for the Delfi nanosatellite programme\n", "abstract": " The Delfi-n3Xt nano-satellite is the second Dutch university satellite currently being developed at the Delft University of Technology (TUD) as successor of the Delfi-C3 that has been successfully launched in April 2008. Compared to Delfi-C3, the Delfi-n3Xt platform provides significant advancements to the platform: a high-speed downlink, three-axis attitude control and a single-point of failure free battery. In total five payloads will be flown that generate a considerable larger amount of data compared to Delfi-C3 that implies, as well, a robust and adequate design for the data handling system that interlinks the various embedded systems on board.", "num_citations": "9\n", "authors": ["1049"]}
{"title": "Trends in tests and failure mechanisms in deep sub-micron technologies\n", "abstract": " The increasing integration density of semiconductor devices and the usage of new materials and innovative manufacturing techniques result in introducing new and gradually changing the types of failure mechanisms and defects that take place in manufactured silicon. This is particularly true for current deep submicron manufacturing technologies. As we approach the nanoscale domain, new types of fault models and test methods are needed to cope with the increasing complexity of the observed faulty behavior. This paper discusses the latest trends in testing and failure mechanisms in all stages of IC production", "num_citations": "9\n", "authors": ["1049"]}
{"title": "Dataflow acceleration of smith-waterman with traceback for high throughput next generation sequencing\n", "abstract": " Smith-Waterman algorithm is widely adopted by most popular DNA sequence aligners. The inherent algorithm computational intensity and the vast amount of NGS input data it operates on, create a bottleneck in genomic analysis flows for short-read alignment. FPGA architectures have been extensively leveraged to alleviate the problem, each one adopting a different approach. In existing solutions, effective co-design of the NGS short-read alignment still remains an open issue, mainly due to narrow view on real integration aspects, such as system wide communication and accelerator call overheads. In this paper, we propose a dataflow architecture for Smith-Waterman Matrix-fill and Traceback alignment stages, to perform short-read alignment on NGS data. The architectural decision of moving both stages on chip extinguishes the communication overhead, and coupled with radical software restructuring, allows for\u00a0\u2026", "num_citations": "8\n", "authors": ["1049"]}
{"title": "LEGaTO: first steps towards energy-efficient toolset for heterogeneous computing\n", "abstract": " LEGaTO is a three-year EU H2020 project which started in December 2017. The LEGaTO project will leverage task-based programming models to provide a software ecosystem for Made-in-Europe heterogeneous hardware composed of CPUs, GPUs, FPGAs and dataflow engines. The aim is to attain one order of magnitude energy savings from the edge to the converged cloud/HPC.", "num_citations": "8\n", "authors": ["1049"]}
{"title": "From exaflop to exaflow\n", "abstract": " Exascale computing is facing a gap between the ever increasing demand for application performance and the underlying chip technology that does no longer deliver the expected exponential increases in CPU performance. The industry is now progressively moving towards dedicated accelerators to deliver high performance and better energy efficiency. However, the question of programmability still remains. To address this challenge we propose a dedicated high-level accelerator programming and execution model where performance and efficiency are primary targets. Our model splits the computation into a conventional CPU-oriented part and a highly efficient fully programmable data flow part. We present a number of systematic transformations and optimisations targeting Maxeler dataflow systems that typically yield one to two orders of magnitude improvements in terms of both performance and energy\u00a0\u2026", "num_citations": "8\n", "authors": ["1049"]}
{"title": "Automated dataflow graph merging\n", "abstract": " In this paper we present several algorithms used to construct a tool that automatically optimizes static dataflow graphs for the purpose of high level hardware synthesis. Our target is to automatically merge multiple dataflow graphs in order to create a single structure implementing all distinct operations with minimal area overhead by time-slicing hardware resources. We show that a combination of dedicated optimizations and a simple greedy approach for graph merging reduces the overall area by up to 4x compared to a naive hardware implementation.", "num_citations": "8\n", "authors": ["1049"]}
{"title": "Crystal: A design-time resource partitioning method for hybrid main memory\n", "abstract": " Non-Volatile Memory (NVM) technologies can be used to reduce system-level execution time, energy, or cost but they add a new design dimension. Finding the best amounts of DRAM and NVM in hybrid main memory systems is a nontrivial design-time issue, the best solution to which depends on many factors. Such resource partitioning between DRAM and NVM can be framed as an optimization problem where the minimum of a target metric is sought, trends matter more than absolute values, and thus the precision of detailed modeling is overkill. Here we present Crystal, an analytic approach to early and rapid design-time resource partitioning of hybrid main memories. Crystal provides first-order estimates of system-level execution time and energy, sufficient to enable exhaustive search of the best amount and type of NVM for given workloads and partitioning goals. Crystal thus helps system designers to quickly\u00a0\u2026", "num_citations": "8\n", "authors": ["1049"]}
{"title": "A novel configuration circuit architecture to speedup reconfiguration and relocation for partially reconfigurable devices\n", "abstract": " Long reconfiguration times form a major bottleneck in dynamic reconfigurable systems. Many approaches have been proposed to address this problem. However, improvements in the configuration circuit that introduces this overhead are usually not considered. The high reconfiguration times are due to the large amount of configuration bits sent through a constrained data path. In order to alleviate this, we propose a novel FPGA configuration circuit architecture to speedup bitstream (re)configuration and relocation. Experimental results using the MCNC benchmark set indicate that our proposal reconfigures 4 times faster and relocates 19.8 times more efficient compared to the state of the art approaches. This is achieved by transporting only the data required for the configuration in flight and by avoiding external communication while relocating. Moreover, the configuration bitstream sizes of the evaluated benchmarks\u00a0\u2026", "num_citations": "8\n", "authors": ["1049"]}
{"title": "High-bandwidth address generation unit\n", "abstract": " In this paper we present an efficient data fetch circuitry to retrieve several operands from a n-way parallel memory system in a single machine cycle. The proposed address generation unit operates with an improved version of the low-order parallel memory access approach. Our design supports data structures of arbitrary lengths and different odd strides. The experimental results show that our address generation unit is capable of generating eight 32\u2009\u2212\u2009bit addresses every 6\u00a0ns for different strides when implemented on a VIRTEX-II PRO xc2vp30-7ff1696 FPGA device using only trivial hardware resources.", "num_citations": "8\n", "authors": ["1049"]}
{"title": "Low power microarchitecture with instruction reuse\n", "abstract": " Power consumption has become a very important metric and challenging research topic in the design of microprocessors in the recent years. The goal of this work is to improve power efficiency of superscalar processors through instruction reuse at the execution stage. This paper proposes a new method for reusing instructions when they compose small loops: the loop's instructions are first buffered in the Reorder Buffer and reused afterwards without the need for dynamically unrolling the loop, as commonly implemented by the traditional instruction reusing techniques. The proposed method is implemented with the introduction of two new auxiliary hardware structures in a typical superscalar microarchitecture: a Finite State Machine (FSM), used to detect the reusable loops; and a Log used to store the renaming data for each instruction when the loop is\" unrolled\". In order to evaluate the proposed method we\u00a0\u2026", "num_citations": "8\n", "authors": ["1049"]}
{"title": "An investigation on capacitive coupling in ram address decoders\n", "abstract": " In this paper, a complete analysis of address decoder delay faults due to capacitive coupling between address lines is presented. Detection conditions are used to explore the space of possible tests in order to detect these faults, resulting in new tests. The best test is proposed to be combined with other tests (while using the freedom of march tests) to target other faults.", "num_citations": "8\n", "authors": ["1049"]}
{"title": "Visual data rectangular memory\n", "abstract": " We focus on the parallel access of randomly aligned rectangular blocks of visual data. As an alternative of traditional linearly addressable memories, we suggest a memory organization based on an array of memory modules. A highly scalable data alignment scheme incorporating module assignment functions and a new generic addressing function are proposed. To enable short critical paths and to save hardware resources, the addressing function implicitly embeds the module assignment functions and it is separable. A corresponding design is evaluated and compared to existing schemes and is found to be cost-effective.", "num_citations": "8\n", "authors": ["1049"]}
{"title": "The HiPEAC vision. High performance and embedded architecture and compilation\n", "abstract": " author=\" M. Duranton and S. Yehia and B. de Sutter and K. de Bosschere and A. Cohen and B. Falsafi and GN Gaydadjiev and MGH Katevenis and A. Ramirez and O. Temam and M. Valero\",", "num_citations": "7\n", "authors": ["1049"]}
{"title": "High-speed Binary Signed-Digit RNS adder with posibit and negabit encoding\n", "abstract": " Binary Signed-Digit Residue Number System (BSD-RNS) has been proposed in the literatures as an appropriate number system to perform the arithmetic operations in parallel. BSD-RNS addition is the basic operation and improving its performance results in efficient VLSI arithmetic circuits. Here, we present a new architecture for carry-free BSD-RNS addition utilizing a recently proposed posibit and negabit BSD representation. Compared to 2's complement BSD-RNS adder, the proposed architecture has 21% less delay. Besides, for a same delay (0.6ns), we obtain 48% less area and 28% less power than the most efficient existing BSD-RNS adder.", "num_citations": "7\n", "authors": ["1049"]}
{"title": "Data structure, method and system for address lookup\n", "abstract": " Method and computer system for constructing a decision tree for use in address lookup of a requested address in an address space. The address space is arranged as a set of basic address ranges. Each basic address range is defined by a lower and an upper bound address, and an address in the address space is represented by a predetermined number of bits.", "num_citations": "7\n", "authors": ["1049"]}
{"title": "HiPEAC: Upcoming challenges in reconfigurable computing\n", "abstract": " The new developments in semiconductor technology cause significant problems in chips\u2019 performance, power consumption and reliability, indicating that the \u201cgolden\u201d CMOS era is long gone. Technology scaling does not deliver anymore significant performance speedup, the increasing power density poses severe limitations in chips, while, transistors become less reliable. The above introduce great challenges for reconfigurable computing; that is to provide the answer to the performance, power-efficiency and reliability quest posed by current technology trends. Reconfigurable Computing has the potential to achieve such a goal; however, several improvements are required to be performed first. In this chapter, we discuss a number of issues which need to be addressed in order to make Reconfigurable Computing a widely used solution for future systems.", "num_citations": "7\n", "authors": ["1049"]}
{"title": "A modified merging approach for datapath configuration time reduction\n", "abstract": " This paper represents a modified datapath merging technique to amortize the configuration latency of mapping datapaths on reconfigurable fabric in Run-Time Reconfigurable Systems (RTR). This method embeds together the different Data Flow Graphs (DFGs), corresponding to the loop kernels to create a single datapath (merged datapath) instead of multiple datapaths. The DFGs are merged in steps where each step corresponds to combining a DFG onto the merged datapath. Afterwards, the method combines the resources inside the merged datapath to minimize the configuration time by employing the maximum weighted clique technique. The proposed merging technique is evaluated using the Media-bench suit workloads. The results indicate that our technique outperforms previous HLS approaches aimed at RTR systems and reduces the datapath configuration time up to 10%.", "num_citations": "7\n", "authors": ["1049"]}
{"title": "A 3D-audio reconfigurable processor\n", "abstract": " Various multimedia communication systems based on 3D-Audio algorithms have been proposed by researchers from the acoustic data processing domain. However, all systems reported in the literature follow a PC-based approach that introduces processing bottlenecks and excessive power consumption. In order to alleviate these problems, we propose a reconfigurable 3D-Audio processor that can record and render sound sources concurrently. Audio recording and rendering are performed by two hardware accelerators exploiting the beamforming and the Wave Field Synthesis algorithms. The theoretical scalability of the proposed processor is explored with respect to systems consisting of different microphone and loudspeaker arrays configurations. A working FPGA prototype is compared against a software implementation on a Core2 Duo system. Results suggest that the proposed reconfigurable hardware\u00a0\u2026", "num_citations": "7\n", "authors": ["1049"]}
{"title": "Parallel FPGA design of CA CFAR algorithm\n", "abstract": " Virtex II Pro technology. Synthesis and post place and route results from the Xilinx ISE toolset suggest a linear speedup and resource utilization. More specifically, a single CFAR implementation utilizes 1.4% of the VIRTEX II Pro XC2VP30 chip, providing a throughput of 974 Mbps. Regarding the parallel design, a structure of 32 CA-CFARs provides 37.5% utilization and 31Gbps for the same FPGA chip. Furthermore, the power consumption of the design is evaluated in terms of power vs. technology cost trade-offs.", "num_citations": "7\n", "authors": ["1049"]}
{"title": "The case for a generic implant processor\n", "abstract": " A more structured and streamlined design of implants is nowadays possible. In this paper we focus on implant processors located in the heart of implantable systems. We present a real and representative biomedical-application scenario where such a new processor can be employed. Based on a suitably selected processor simulator, various operational aspects of the application are being monitored. Findings on performance, cache behavior, branch prediction, power consumption, energy expenditure and instruction mixes are presented and analyzed. The suitability of such an implant processor and directions for future work are given.", "num_citations": "7\n", "authors": ["1049"]}
{"title": "Cross-layer designs architecture for LEO satellite ad hoc network\n", "abstract": " Future Low Earth Orbit (LEO) satellite networks are envisioned as distributed architectures of autonomous data processing nodes. Such ad hoc networks should deliver reliable communication channels for control commands and data among ground stations and satellites minimizing delay and power. The LEO satellite networks are different from the generic ad hoc scenario. In this paper, we first analyze the specifics of ad hoc LEO satellite networks. Next, we propose a cross-layer protocol architecture that includes three cross-layer optimizations: simple integrated MAC/PHY layer, novel Balanced Predictable Routing (BPR) and a dedicated QoS aware TCP sliding window control mechanism. They all contribute to the end-to-end delays improvement and successful delivery increase. It also fulfills the QoS requirements. According to our simulations, the coverage of ground stations is improved. The throughput\u00a0\u2026", "num_citations": "7\n", "authors": ["1049"]}
{"title": "Optimizing test length for soft faults in DRAM devices\n", "abstract": " Soft faults in DRAMs are faults that do not get sensitized directly after an operation is performed, but require a time to pass before the fault can be detected. Tests developed to detect these faults are rather complex and take an exceptionally long time to apply on the memory. This paper discusses a number of methods to optimize the test length for soft faults, based on the electrical design of the memory and the topology of the layout. These methods make it possible to reduce the delay time needed in the test such that it does not scale with the number of cells in the memory", "num_citations": "7\n", "authors": ["1049"]}
{"title": "Memory mapping for multi-die fpgas\n", "abstract": " This paper proposes an algorithm for mapping logical to physical memory resources on FPGAs. Our greedy strategy based algorithm is specifically designed to facilitate timing closure on modern multi-die FPGAs for static-dataflow accelerators utilising most of the on-chip resources. The main objective of the proposed algorithm is to ensure that specific sub-parts of the design under consideration can fully reside within a single die to limit inter-die communication. The above is achieved by performing the memory mapping for each sub-part of the design separately while keeping allocation of the available physical resources balanced. As a result the number of inter-die connections is reduced on average by 50% compared to an algorithm targeting minimal area usage for real, complex applications using most of the on-chip's resources. Additionally, our algorithm is the only one out of the four evaluated approaches\u00a0\u2026", "num_citations": "6\n", "authors": ["1049"]}
{"title": "AEGLE's Cloud Infrastructure for Resource Monitoring and Containerized Accelerated Analytics\n", "abstract": " This paper presents the cloud infrastructure of the AEGLE project, that targets to integrate cloud technologies together with heterogeneous reconfigurable computing in large scale healthcare systems for Big Bio-Data analytics. AEGLEs engineering concept brings together the hot big-data engines with emerging acceleration technologies, putting the basis for personalized and integrated health-care services, while also promoting related research activities. We introduce the design of AEGLE's accelerated infrastructure along with the corresponding software and hardware acceleration stacks to support various big data analytics workloads showing that through effective resource containerization AEGLE's cloud infrastructure is able to support high heterogeneity regarding to storage types, execution engines, utilized tools and execution platforms. Special care is given to the integration of high performance accelerators\u00a0\u2026", "num_citations": "6\n", "authors": ["1049"]}
{"title": "Extra: Towards an efficient open platform for reconfigurable high performance computing\n", "abstract": " To handle the stringent performance requirements of future exascale-class applications, High Performance Computing (HPC) systems need ultra-efficient heterogeneous compute nodes. To reduce power and increase performance, such compute nodes will require hardware accelerators with a high degree of specialization. Ideally, dynamic reconfiguration will be an intrinsic feature, so that specific HPC application features can be optimally accelerated, even if they regularly change over time. In the EXTRA project, we create a new and flexible exploration platform for developing reconfigurable architectures, design tools and HPC applications with run-time reconfiguration built-in as a core fundamental feature instead of an add-on. EXTRA covers the entire stack from architecture up to the application, focusing on the fundamental building blocks for run-time reconfigurable exascale HPC systems: new chip\u00a0\u2026", "num_citations": "6\n", "authors": ["1049"]}
{"title": "Generic march element based memory built-in self test\n", "abstract": " Method for testing a memory under test (1) including a plurality of memory cells and a Memory Built-In Self-Test Engine (2) connectable to a memory under test. The MBIST engine (2) is arranged to generate appropriate addressing and read and/or write operations to the memory under test (1). The MBIST engine (2) is connected to a March Element Stress register (MESR)(3), a generic march element register (GMER)(4), and a Command Memory (5). The GMER (4) specifies one of a set of Generic March Elements (GME), and the MESR (3) specifies the stress conditions to be applied. Only a few GMEs are required in order to specify most industrial algorithms. The architecture is orthogonal and modular, and all speed related information is contained in the GME. In addition, only little memory is required for the specification of the test, providing a low implementation cost, yet with a high flexibility.", "num_citations": "6\n", "authors": ["1049"]}
{"title": "Implementation study of FFT on multi-lane vector processors\n", "abstract": " In this paper we extend a custom FFT vector architecture by adding multiple lane capabilities and study its hardware implementation. We use the six step algorithm to segment a long transform of size N = Z \u00d7 L into L smaller transforms of size Z. We split the data into pairs of vector registers (for the real and imaginary part), containing Z elements. A vector register pair with its corresponding functional unit form a single lane replicated L times. While smaller transforms proceed iteratively all of them are computed in parallel. The shorter FFT transforms along the X dimension are computed using previously proposed vector permutations while the transforms along the Y dimension are performed using a simple butterfly network that handles inter-lane communication. All data patterns required by the FFT computation are generated implicitly in hardware by a simple control unit. No data transposition is required and the\u00a0\u2026", "num_citations": "6\n", "authors": ["1049"]}
{"title": "A novel HDL coding style to reduce power consumption for reconfigurable devices\n", "abstract": " Power consumption has become the major factor that has to be considered while designing systems using reconfigurable devices, especially for battery-operated applications. Minimizing transitions is one of the ways to reduce power consumption. Overwriting a register with the same value occurs frequently in real digital systems. Such unneeded transitions increase the power consumption. To avoid this, a new HDL coding style to reduce power consumption for reconfigurable devices is proposed. The idea is to \u201cforce\u201d the CAD tool to configure the CLB flip-flop as a T flip-flop with its T input held constantly at logic one and drive its clock through the lookup table(LUT). Based on an extensive evaluation using MCNC benchmark circuits on a real FPGA and a real CAD tool, our proposal reduces total power consumption by 13-90 % and runs 2-20 % faster with 0-45 % area overhead compared to conventional coding\u00a0\u2026", "num_citations": "6\n", "authors": ["1049"]}
{"title": "Fine-grain fault diagnosis for fpga logic blocks\n", "abstract": " In this paper we introduce a fine-grain fault diagnosis approach for reconfigurable logic blocks. As opposed to previous works, we propose to reuse rather than to discard defective blocks. We describe methods to analyze deeper a defective Xilinx Virtex2Pro slice and diagnose the fault, out of a set of 150, that causes the malfunction. The outcome of the fault diagnosis is subsequently used to characterize the defective slice functionality and then match it with a suitable design configuration. The proposed methods are implemented and prototyped in a Virtex2Pro-30. A single-phase fault diagnosis covers 95% of the faults and takes 170-390 nsec to test a single slice and 27-62 \u03bcsec for a frame of 160 slices. A two-phase approach uses reconfiguration and covers the entire set of faults requiring up to 8.5 \u03bcsec and 80 \u03bcsec for a single slice and an entire frame, respectively.", "num_citations": "6\n", "authors": ["1049"]}
{"title": "Contrasting topologies for regular interconnection networks under the constraints of nanoscale silicon technology\n", "abstract": " Nowadays, system designers have adopted Networks-on-Chip as communication infrastructure of general-purpose tile-based Multi-Processor System-on-Chip (MPSoC). Such decision implies that a certain topology has to be selected to efficiently interconnect many cores on the chip. To ease such a choice, the networking literature offers a plethora of works about topology analysis and characterization for the off-chip domain. However, theoretical parameters and many intuitive assumptions of such off-chip networks do not necessarily hold when a topology is laid out on a 2D silicon surface. This is due to the distinctive features of silicon technology design pitfalls. This work is a first milestone to bridge this gap, in fact, we propose a comprehensive analysis framework to assess k-ary n-mesh and C-mesh topologies at different level of abstractions, from system to layout level, while capturing implications of system and\u00a0\u2026", "num_citations": "6\n", "authors": ["1049"]}
{"title": "Scalability analysis of progressive alignment on a multicore\n", "abstract": " Sequence alignment is a fundamental instrument in bioinformatics. In recent years, numerous proposals have been addressing the problem of accelerating this class of applications. This, due to the rapid growth of sequence databases in combination with the high computational demands imposed by the algorithms. In this paper we focus on the analysis of the progressive alignment in ClustalW, a widely used program for performing multiple sequence alignment. We have parallelized ClustalW for the Cell processor architecture and have carefully analyzed the scalability of its different phases with both the number of cores used and the input size. Experimental results show that computing profile scores scales well up to 16 SPE cores. With the increase of the input size, profiles initialization in the PPE core becomes the predominant bottleneck.", "num_citations": "6\n", "authors": ["1049"]}
{"title": "A hybrid cross layer architecture for wireless protocol stacks\n", "abstract": " Many architectures to support multiple cross-layer optimizations have been proposed. Most of them can be categorized as either signaling-based or function-call based. The signaling approaches use messages to propagate the information in the protocol stack, while the function-call uses application programming interface (API) for direct access to variables. The signaling approach complies with the layered protocol stack architecture but introduces latency in the information propagation and additionally increases the packet size. The function- call approaches are more efficient but highly operating system dependent. Even a slight protocol modification requires the function-call middleware to be updated. We previously proposed an infrastructure for cross-layer designs interaction (ICDI) based only on the signaling approach. In this paper, we first provide in-depth analysis of the two main schemes. Thereafter we\u00a0\u2026", "num_citations": "6\n", "authors": ["1049"]}
{"title": "Real-time FPGA-implementation for blue-sky Detection\n", "abstract": " Currently, television sets with flat plasma and LCD screens with improved resolutions and better color quality are emerging. To fully utilize their capabilities, lower resolution standard definition video material is enhanced. During such process, existing noise can become clearly visible, or additional artifacts may be introduced. These impairments are usually better visible in smooth image areas such as sky regions, motivating the development of special techniques for their removal. In this paper, we introduce a hardware accelerator for an existing pixel-accurate and spatially-consistent sky-detection algorithm. We describe the algorithmic and architectural design considerations of a resource-efficient real-time system, targeting an FPGA platform. Our results show that it is feasible to implement a simplified algorithm version by using only 5,756 logic-and 23,687 memory elements of the targeted device. A demonstrator\u00a0\u2026", "num_citations": "6\n", "authors": ["1049"]}
{"title": "PISC: Polymorphic instruction set computers\n", "abstract": " We introduce a new paradigm in the computer architecture referred to as Polymorphic Instruction Set Computers (PISC). This new paradigm, in difference to RISC/CISC, introduces hardware extended functionality on demand without the need of ISA extensions. We motivate the necessity of PISCs through an example, which arises several research problems unsolvable by traditional architectures and fixed hardware designs. More specifically, we address a new framework for tools, supporting reconfigurability; new architectural and microarchitectural concepts; new programming paradigm allowing hardware and software to coexist in a program; and new spacial compilation techniques. The paper illustrates the theoretical performance boundaries and efficiency of the proposed paradigm utilizing established evaluation metrics such as potential zero execution (PZE) and the Amdahl\u2019s law. Overall, the PISC\u00a0\u2026", "num_citations": "6\n", "authors": ["1049"]}
{"title": "Legato: low-energy, secure, and resilient toolset for heterogeneous computing\n", "abstract": " The LEGaTO project leverages task-based programming models to provide a software ecosystem for Made in-Europe heterogeneous hardware composed of CPUs, GPUs, FPGAs and dataflow engines. The aim is to attain one order of magnitude energy savings from the edge to the converged cloud/HPC, balanced with the security and resilience challenges. LEGaTO is an ongoing three-year EU H2020 project started in December 2017.", "num_citations": "5\n", "authors": ["1049"]}
{"title": "Bit-flip aware control-flow error detection\n", "abstract": " Recent increase of transient fault rates has made processor reliability a major concern. Moreover performance improvements are required for many of today's embedded systems. At the same time software implemented fault detection remains the only option for off-the-shelf processors. Software methods, however, introduce significant performance overheads due to the additional instructions required for the detection. A good observation is that often code segments not susceptible to faults are protected. In this paper we propose a technique for systematic analysis of the bit-flip effects on the program control-flow in order to identify only those locations susceptible to control-flow errors and hence minimize the number of fault detection assertions. We instrument the code with minimal overhead, while maintaining high fault coverage level. Our experiments show that using the result of our bit-flip analysis and limiting the\u00a0\u2026", "num_citations": "5\n", "authors": ["1049"]}
{"title": "Scalability study of polymorphic register files\n", "abstract": " We study the scalability of multi-lane 2D Polymorphic Register Files (PRFs) in terms of clock cycle time, chip area and power consumption. We assume an implementation which stores data in a 2D array of linearly addressable memory banks, and consider one single-view and four suitable multi-view parallel access schemes which cover all basic access patterns commonly used in scientific and multimedia applications. The PRF design features 2 read and 1 write ports, targeting the TSMC 90nm ASIC technology. We consider three PRF sizes - 32KB, 128KB and 512KB and four multi-lane configurations - 8 / 16 / 32 and 64 lanes. Synthesis results suggest that the clock frequency varies between 500MHz for a 512KB PRF with 64 vector lanes and 970Mhz for a 32KB / 8-lanes case. Estimated power consumption ranges from less than 300mW (dynamic) and 10mW (leakage) for our 8-lane, 32KB PRF up to 8.7W\u00a0\u2026", "num_citations": "5\n", "authors": ["1049"]}
{"title": "Compatibility study of compile-time optimizations for power and reliability\n", "abstract": " Historically compiler optimizations have been used mainly for improving embedded systems performance. However, for a wide range of today's power restricted, battery operated embedded devices, power consumption becomes a crucial problem that is addressed by modern compilers. Biomedical implants are one good example of such embedded systems. In addition to power, such devices need to also satisfy high reliability levels. Therefore, performance, power and reliability optimizations should all be considered while designing and programming implantable systems. Various software optimizations, e.g., during compilation, can provide the necessary means to achieve this goal. Additionally the system can be configured to trade-off between the above three factors based on the specific application requirements. In this paper we categorize previous works on compiler optimizations for low power and fault\u00a0\u2026", "num_citations": "5\n", "authors": ["1049"]}
{"title": "Profiling, compilation, and hdl generation within the hartes project\n", "abstract": " The hArtes project addresses optimal and rapid design of embedded systems from high-level descriptions, targeting a combination of embedded processors, digital signal processing, and reconfigurable hardware. In this paper, we present three tools from the hArtes toolchain, namely profiling, compilation, and HDL generation tools, that facilitate the HW/SW partitioning, co-design, co-verification, and co-execution of demanding embedded applications. The described tools are provided by the DelftWorkBench framework.", "num_citations": "5\n", "authors": ["1049"]}
{"title": "Comparison of Static and Dynamic Faults in 65nm Memory Technology\n", "abstract": " This paper presents single-cell dynamic fault models for deep-submicron semiconductor memories together with their associated tests (test primitives). The test primitives are evaluated industrially, together with the traditional tests, using 65nm technology 131 Kbytes embedded SRAMs. A comparison between static faults and dynamic faults is presented and the results are reported; they show the increasing importance of dynamic faults, and the exceptional effectiveness of using back-to-back operations (with complementary data values) along bit lines during memory testing. The paper also presents a systematic approach to distinguish between the different detected faults and therefore evaluate the importance and the occurrence frequency of such faults.", "num_citations": "5\n", "authors": ["1049"]}
{"title": "Cloud deployment and management of dataflow engines\n", "abstract": " Maxeler Technologies successfully commercialises high-performance computing systems based on dataflow technology. Maxeler dataflow computers have been deployed in a wide range of application domains including financial data analytics, geoscience and low-latency transaction processing. In the context of cloud computing steadily growing acceptance in new domains, we illustrate how Maxeler dataflow systems can be integrated and employed in a self-organising self-managing heterogeneous cloud environment.", "num_citations": "4\n", "authors": ["1049"]}
{"title": "The VINEYARD project: Versatile integrated accelerator-based heterogeneous data centres\n", "abstract": " Emerging applications like cloud computing and big data analytics have created the need for powerful centers hosting hundreds of thousands of servers. Currently, the data centers are based on general purpose processors that provide high flexibility but lacks the energy efficiency of customized accelerators. VINEYARD1 aims to develop novel servers based on programmable hardware accelerators. Furthermore, VINEYARD will develop an integrated framework for allowing end-users to seamlessly utilize these accelerators in heterogeneous computing systems by using typical data-center programming frameworks (i.e. Spark). VINEYARD will foster the expansion of the soft-IP cores industry, currently limited in the embedded systems, to the data center market. VINEYARD plans to demonstrate the advantages of its approach in three real use-cases a) a bio-informatics application for high-accuracy brain modeling, b\u00a0\u2026", "num_citations": "4\n", "authors": ["1049"]}
{"title": "Separable 2D convolution with polymorphic register files\n", "abstract": " This paper studies the performance of separable 2D convolution on multi-lane Polymorphic Register Files (PRFs). We present a matrix transposition algorithm optimized for PRFs, and a 2D vectorized convolution algorithm which avoids strided memory accesses. We compare the throughput of our PRF to the nVidia Tesla C2050 GPU. The results show that even in bandwidth constrained systems, multi-lane PRFs can outperform the GPU for 9 \u00d79 or larger mask sizes.", "num_citations": "4\n", "authors": ["1049"]}
{"title": "On implementability of polymorphic register files\n", "abstract": " This paper studies the implementability of performance efficient multi-lane Polymorphic Register Files (PRFs). Our PRF implementation uses a 2D array of p \u00d7 q linearly addressable memory banks, with customized addressing functions to avoid address routing circuits. We target one single-view and a set of four non redundant multi-view parallel memory schemes that cover all widely used access patterns in scientific and multimedia applications: 1) p \u00d7 q rectangle, p \u00b7 q row, p \u00b7 q main and secondary diagonals; 2) p \u00d7 q rectangle, p \u00b7 q column, p \u00b7 q main and secondary diagonals; 3) p \u00b7 q row, p \u00b7 q column, aligned p \u00d7 q rectangle; 4) p \u00d7 q, q \u00d7 p rectangles (transposition). Reconfigurable hardware was chosen for the implementation due to its potential in enhancing the PRF runtime adaptability. For a proof of concept, we prototyped a 2 read, 1 write ports PRF on a Virtex-7 XC7VX1140T-2 FPGA. We consider four sizes\u00a0\u2026", "num_citations": "4\n", "authors": ["1049"]}
{"title": "Reconfigurable acceleration and dynamic partial self-reconfiguration in general purpose computing\n", "abstract": " In this paper, we describe a generic approach for integrating a dynamically reconfigurable device into a general purpose system interconnected with a high-speed link. The system can dynamically install and execute hardware instances of functions to accelerate parts of a given software code. The hardware descriptions of the functions (bitstreams) are inserted into the executable binary running on the system. Our compiler further inserts system-calls to the software code to control the reconfigurable device. Thereby, the general purpose host-processor of the system manages the hardware reconfiguration and execution through a Linux device driver. The device has direct access to the main memory (DMA) operating in the virtual address space; it further supports memory mapped IO for data and control, and is able to raise and handle interrupts for synchronization. The above system is implemented on a general\u00a0\u2026", "num_citations": "4\n", "authors": ["1049"]}
{"title": "Vector processor customization for fft\n", "abstract": " Processors and memory systems suffer from a growing performance gap between them. Each technology generation increases the on-chip performance capabilities however, memory bandwidth increases at a much slower pace. Therefore, overall performance improvements are constrained by the available memory bandwidth. In this paper, we address the memory bandwidth problem of vector processors by introducing hardware customizations which drastically reduce the memory transfers required by the FFT computation. We show that an FFT transform of length equal to the machine size Z can be performed using only O(Z) memory accesses, hence we reduce the memory bandwidth requirement by an order of O(log(Z)) compared to a conventional vector machine. We achieve bandwidth reduction by extending a classic IBM S/370 vector architecture for better register re-use. Our hardware extension completely\u00a0\u2026", "num_citations": "4\n", "authors": ["1049"]}
{"title": "A minimalistic architecture for reconfigurable WFS-based immersive-audio\n", "abstract": " We propose a minimalistic processor architecture tailoring Wave Field Synthesis (WFS)-based audio applications to configurable hardware. Eleven high-level instructions provide the required flexibility for embedded WFS customization. We describe the implementation of the proposed instructions and apply them to a multi-core reconfigurable WFS architecture. Our approach combines software programming flexibility with improved hardware performance and low power consumption. Experimental results suggest that our Virtex4FX60-based FPGA prototype, running at 100 MHz, can provide a kernel speedup of up to 4.5 times compared to an OpenMP-annotated software solution implemented on a Core2 Duo at 3.0 GHz. Furthermore, when larger FPGAs are utilized, we estimate that our system can render in real-time up to 32 acoustic sources when driving 64 loudspeakers. Ultimately, we estimated that the\u00a0\u2026", "num_citations": "4\n", "authors": ["1049"]}
{"title": "ImpBench revisited: An extended characterization of implant-processor benchmarks\n", "abstract": " Implants are nowadays transforming rapidly from rigid, custom-based devices with very narrow applications to highly constrained albeit multifunctional embedded systems. These systems contain cores able to execute software programs so as to allow for increased application versatility. In response to this trend, a new collection of benchmark programs for guiding the design of implant processors, ImpBench, has already been proposed and characterized. The current paper expands on this characterization study by employing a genetic-algorithm-based, design-space exploration framework. Through this framework, ImpBench components are evaluated in terms of their implications on implant-processor design. The benchmark suite is also expanded by introducing one new benchmark and two new stressmarks based on existing ImpBench benchmarks. The stressmarks are proposed for achieving further speedups in\u00a0\u2026", "num_citations": "4\n", "authors": ["1049"]}
{"title": "Data structure, method and system for address lookup\n", "abstract": " Data structure, method and system for address lookup \u2014 TU Delft Research Portal Skip to main navigation Skip to search Skip to main content TU Delft Research Portal Logo Help & FAQ Home Researchers Research Units Research output Activities Datasets Press / Media Prizes Projects Search by expertise, name or affiliation Data structure, method and system for address lookup I Sourdis (Inventor), R Smet de (Inventor), G Stefanakis (Inventor), GN Gaydadjiev (Inventor) Computer Engineering Research output: Patent Overview Original language English Patent number NL 2002799 Priority date 26/10/10 Publication status Published - 2010 Keywords Octrooi Cite this APA Author BIBTEX Harvard Standard RIS Vancouver Sourdis, I., Smet de, R., Stefanakis, G., & Gaydadjiev, GN. (2010). Data structure, method and system for address lookup. (Patent No. NL 2002799). Sourdis, I (Inventor) ; Smet de, R (Inventor) ; \u2026", "num_citations": "4\n", "authors": ["1049"]}
{"title": "Exploring suitable adder designs for biomedical implants\n", "abstract": " Modern applications demand extremely low power budgets in computer architectures for battery-operated devices. In the particular case of implantable devices\u2014the main focus of this thesis\u2014the system must have a long life span and batteries may not be possible or easy to recharge. In addition to power, chip area is also of major concern in this specific scenario. Since implantable devices are sometimes placed at locations inside the body where limited space is available, the implant must be as small as possible. The vast amount of volume of an implant is typically occupied by the battery and its electrodes, so the affordable chip area is very limited. Another reason why we want very small processor cores, is because this approach leaves more space for cache memory and it statistically reduces the chance of hardware failures. In this thesis we focus on the arithmetic unit (AU) of such a core, which is typically the adder/subtracter. The goal is to explore existing fault-tolerant and low-power AUs which are suitable for implementation in biomedical implants. A second objective is to study our own idea for a resource-constrained AU, based on graceful degradation: the so-called scalable arithmetic unit (ScAU). When an error occurs, the ScAU is able to proceed with the computational work, but no longer at the normal throughput: instead of single-cycle we downgrade to double-cycle operations. The design of our ScAU as well as several reference designs are all implemented in VHDL, synthesized and analyzed using Synopsys Design Compiler/PrimeTime and ModelSim. A major part of this thesis is dedicated to fault-tolerant design. An extensive study\u00a0\u2026", "num_citations": "4\n", "authors": ["1049"]}
{"title": "A Novel Logic Element for Power Reduction in FPDs\n", "abstract": " Although many techniques have been proposed for power reduction in fieldprogrammable devices (FPDs), they are all based on conventional logic elements (LEs). In the conventional LE, the output of the combinational logic (eg the lookup table (LUT) in many FPGAs) is connected to the input of the storage element; while the D flip-flop (DFF) is always clocked even when it is not necessary. Such unnecessary transitions waste power. To address this problem, we propose a novel low power LE. The differences between our LE and the conventional LE are in the type of flip-flops used and the internal organization. Instead of using DFFs, we use T flip-flops with the input T permanently connected to logic value one. Instead of connecting the output of the combinational logic to the input of the FF, we connect it to the clock input of the FF. Transistor-level circuit simulations on MCNC benchmark circuits indicate that the FPD using the proposed LEs not only consumes up to 42% less total power by avoiding the unnecessary activities of the clock, logic, and interconnect, but performs up to 33% faster than the FPD using conventional LEs.", "num_citations": "4\n", "authors": ["1049"]}
{"title": "Smart power management for an onboard wireless sensors and actuators network\n", "abstract": " INIATURIZATION of spacecraft modules driven by applying novel technologies and advanced electronic design enabled more efficient and autonomous onboard sensors and actuators. For example, application of onboard wireless communication between spacecraft subsystems allows overall mass reduction and increased power efficiency while improving the flexibility of the spacecraft design, integration and testing. Statistics show that 6 to 10 percent of the mass of a spacecraft is due to wires and electrical interfaces1. Furthermore, enabling wireless communication can address other issues of wired communication such as: failures of wires and connectors, high cost of late design changes, time overhead for allocating routes and shields, undesired ground loops, and etc. The employment of wireless communication technology onboard spacecraft is still in early demonstration phase due to its technical challenges\u00a0\u2026", "num_citations": "4\n", "authors": ["1049"]}
{"title": "Parameter optimization of the adaptive MVDR QR-based beamformer for jamming and multipath supression in GPS/GLONASS receivers\n", "abstract": " This paper analyzes the influence of the space-time signal processing technique on the performance of GPS signal acquisition in conditions of strong broadband interference (jamming) and multipath. The space-time processing method used for effective mitigation of GPS interference before processing by a conventional acquisition algorithm is the Minimum Variance Distortionless Response beamforming method with QR factorization (MVDR QR). The numerical results obtained by simulations demonstrate that many factors such as array configuration, number of array elements, and sampling rate of the incoming data have a considerable effect on the effectiveness of both beamforming and acquisition algorithms.", "num_citations": "4\n", "authors": ["1049"]}
{"title": "Vectorized AES core for high-throughput secure environments\n", "abstract": " Parallelism has long been used to increase the throughput of applications that process independent data. With the advent of multicore technology designers and programmers are increasingly forced to think in parallel. In this paper we present the evaluation of an encryption core capable of handling multiple data streams. The design is oriented towards future scenarios for internet, where throughput capacity requirements together with privacy and integrity will be critical for both personal and corporate users. To power such scenarios we present a technique that increases the efficiency of memory bandwidth utilization of cryptographic cores. We propose to feed cryptographic engines with multiple streams to better exploit the available bandwidth. To validate our claims, we have developed an AES core capable of encrypting two streams in parallel using either ECB or CBC modes. Our AES core\u00a0\u2026", "num_citations": "4\n", "authors": ["1049"]}
{"title": "A new model of placement quality measurement for online task placement\n", "abstract": " With the arrival of partial reconfiguration technology, modern FPGAs support tasks that can be loaded in (removed from) the FPGA individually without interrupting other tasks already running on the same FPGA. Many online task placement algorithms designed for such partially reconfigurable systems have been proposed to provide efficient and fast task placement. In these algorithms, the resource wastage and task rejection rate are usually used to measure placement quality. However, these algorithms only calculate them individually. These considerations can not reflect the overall situation of placement quality during the application execution. In this paper, we propose a novel model for placement quality measurement, which consists of resource wastage from both placed task side and rejected task side as well as the information of task rejection rate and task life time.", "num_citations": "4\n", "authors": ["1049"]}
{"title": "Manifestation of precharge faults in high speed DRAM devices\n", "abstract": " High speed DRAMs today suffer from an increased sensitivity to interference and noise problems. Signal integrity issues, caused by bit line and word line coupling, result in their own set of faults, and increase the complexity of already known faults. This paper describes the influence of bit line coupling on precharge faults, where the memory is rendered unable to set the proper precharge voltages at the end of each operation, which causes the memory to fail in subsequent read operations. This kind of bit line coupling effect on precharge behavior has been observed in high speed DRAMs at Qimonda. This paper gives a detailed analysis of the problem, and suggests effective tests to detect it. The paper also describes the results of an industrial test evaluation on actual DRAMs chips, performed to validate the effectiveness of the proposed tests.", "num_citations": "4\n", "authors": ["1049"]}
{"title": "A new digital architecture for reliable, ultra-low-power systems\n", "abstract": " We are working towards the speci cation and design of a new system-level architecture serving as the digital control/processing core of ultra-low-power (< 100 \u00b5W) and reliable systems along with a suitable, new compiler. Our primary area of focus is implantable microelectronic devices. While respecting the traditional design constraints of biomedical-implant design for low power consumption and miniature device size, the architecture shall be generic in nature, ie allowing for different peripheral blocks (sensors, actuators etc.) to be ported for building various applicationspeci c implantable systems. Also importantly, the proposed architecture shall employ various fault-tolerance techniques for building highly reliable devices. Our approach is bottomup one, starting from the architectural level and being complemented by a suitable, new compiler. The compiler shall provide the means to exploiting this architecture for different application setups and, by design, shall further underpin the reliability and low-power issues.", "num_citations": "4\n", "authors": ["1049"]}
{"title": "Investigation of Single-Cell Dynamic Faults in Deep-Submicron Memory Technologies\n", "abstract": " This paper presents single-cell dynamic fault models for deep-submicron semiconductor memories together with their associated tests (test primitives). The test primitives are evaluated industrially, together with the traditional tests, using 65nm technology 131 Kbytes embedded SRAMs. The test results are reported, and their analysis shows the increasing importance of dynamic faults and tests, and the exceptional effectiveness of using back-to-back operations (with complementary data values) along bit lines during memory testing.", "num_citations": "4\n", "authors": ["1049"]}
{"title": "Flux caches: What are they and are they useful?\n", "abstract": " In this paper, we introduce the concept of flux caches envisioned to improve processor performance by dynamically changing the cache organization and implementation. Contrary to the traditional approaches, processors designed with flux caches instead of assuming a hardwired cache organization change their cache \u201ddesign\u201d on program demand. Consequently program (data and instruction) dynamic behavior determines the cache hardware design. Experimental results to confirm the flux caches potential are also presented.", "num_citations": "4\n", "authors": ["1049"]}
{"title": "Damp-delft altera-based multimedia platform\n", "abstract": " This paper describes the DAMP (Delft Alterabased Multimedia Platform) architecture. DAMP\u2019s main goal is to provide a low cost platform for the embedded systems specification and hardware-software co design, with the main focus on (mobile) multimedia applications. This platform is based on the Altera Excalibur device incorporating a 400k gates FPGA and a state of the art ARM922T processor. In addition, 32MB flash and up to 512MB SDRAM memories are supported to provide sufficient application design space. Wide range of peripheral interfaces, such as ethernet, PS/2, IDE, 24-bit audio in/out and video out are also supported by DAMP. Additionally DAMP provides a methodology for application mapping.", "num_citations": "4\n", "authors": ["1049"]}
{"title": "The case for polymorphic registers in dataflow computing\n", "abstract": " Heterogeneous systems are becoming increasingly popular, delivering high performance through hardware specialization. However, sequential data accesses may have a negative impact on performance. Data parallel solutions such as Polymorphic Register Files (PRFs) can potentially accelerate applications by facilitating high-speed, parallel access to performance-critical data. This article shows how PRFs can be integrated into dataflow computational platforms. Our semi-automatic, compiler-based methodology generates customized PRFs and modifies the computational kernels to efficiently exploit them. We use a separable 2D convolution case study to evaluate the impact of memory latency and bandwidth on performance compared to a state-of-the-art NVIDIA Tesla C2050\u00a0GPU. We improve the throughput up\u00a0to 56.17X and show that the PRF-augmented system outperforms the GPU for  or\u00a0\u2026", "num_citations": "3\n", "authors": ["1049"]}
{"title": "EXA2PRO programming environment: Architecture and Applications\n", "abstract": " The EXA2PRO programming environment will integrate a set of tools and methodologies that will allow to systematically address many exascale computing challenges, including performance, performance portability, programmability, abstraction and reusability, fault tolerance and technical debt. The EXA2PRO tool-chain will enable the efficient deployment of applications in exascale computing systems, by integrating high-level software abstractions that offer performance portability and efficient exploitation of exascale systems' heterogeneity, tools for efficient memory management, optimizations based on trade-offs between various metrics and fault-tolerance support. Hence, by addressing various aspects of productivity challenges, EXA2PRO is expected to have significant impact in the transition to exascale computing, as well as impact from the perspective of applications. The evaluation will be based on 4\u00a0\u2026", "num_citations": "3\n", "authors": ["1049"]}
{"title": "Low-cost software control-flow error recovery\n", "abstract": " In modern safety-critical embedded systems reliability and performance are two important criteria. In many systems based on off-the-shelf processors software implemented error recovery is the only option to improve the reliability of the system. However, software methods typically introduce large performance overheads. Another important factor in error recovery schemes is the recovery time, especially in systems with real-time requirements. A key observation that helps improve software recovery methods is that only a defined number of locations in the program are susceptible to errors. In this paper we propose a fast software recovery scheme that instruments the program only at locations vulnerable to control-flow errors. We use a systematic bit-flip analysis to identify the exact locations susceptible to control-flow errors in a given program. This helps us to instrument the code with minimal overheads, while\u00a0\u2026", "num_citations": "3\n", "authors": ["1049"]}
{"title": "Compiler-aided methodology for low overhead on-line testing\n", "abstract": " Reliability is emerging as an important design criterion in modern systems due to increasing transient fault rates. Hardware fault-tolerance techniques, commonly used to address this, introduce high design costs. As alternative, software Signature-Monitoring (SM) schemes based on compiler assertions are an efficient method for control-flow-error detection. Existing SM techniques do not consider application-specific-information causing unnecessary overheads. In this paper, compile-time Control-Flow-Graph (CFG) topology analysis is used to place best-suited assertions at optimal locations of the assembly code to reduce overheads. Our evaluation with representative workloads shows fault-coverage increase with overheads close to Assertion-based Control-Flow Correction (ACFC), the method with lowest overhead. Compared to ACFC, our technique improves (on average) fault coverage by 17%, performance\u00a0\u2026", "num_citations": "3\n", "authors": ["1049"]}
{"title": "Generic march element based memory built-in-self-test\n", "abstract": " Computer Engineering Publications Database - View Publication CE logo Computer Engineering Publications Database (2000-2018) Publications Authors Home \u00bb Publications \u00bb GENERIC MARCH ELEMENT BASED MEMORY BUILT-IN SELF TEST GENERIC MARCH ELEMENT BASED MEMORY BUILT-IN SELF TEST Publication Type Patent Title GENERIC MARCH ELEMENT BASED MEMORY BUILT-IN SELF TEST Author(s) S. Hamdioui Z. Al-Ars GN Gaydadjiev AJ van de Goor Publication Date April 2013 Patent Number US 20130086440 Patent Asignee Patent filed in USA Selected Publication Yes Note Topic(s) None Theme(s) Dependable Nano Computing Project(s) None Group(s) Computer Engineering IEEE BibTex entry: @patent{, author = \"S. Hamdioui and Z. Al-Ars and GN Gaydadjiev and AJ van de Goor\", assignee = \"\", title = \"GENERIC MARCH ELEMENT BASED MEMORY BUILT-IN SELF TEST\", \u2026", "num_citations": "3\n", "authors": ["1049"]}
{"title": "Parametrizing multicore architectures for multiple sequence alignment\n", "abstract": " Sequence alignment is one of the fundamental tasks in bioinformatics. Due to the exponential growth of biological data and the computational complexity of the algorithms used, high performance computing systems are required. Although multicore architectures have the potential of exploiting the task-level parallelism found in these workloads, efficiently harnessing systems with hundreds of cores requires deep understanding of the applications and the architecture. When incorporating large numbers of cores, performance scalability will likely saturate shared hardware resources like buses and memories. In this paper we evaluate the performance impact of various configurations of an accelerator-based multicore architecture with the aim of revealing and quantifying the bottlenecks. Then, we compare against a multicore using general-purpose processors and discuss the performance gap. Our target application is\u00a0\u2026", "num_citations": "3\n", "authors": ["1049"]}
{"title": "Exploiting spmd horizontal locality\n", "abstract": " In this paper, we analyze a particular spatial locality case (called horizontal locality) inherent to manycore accelerator architectures employing barrel execution of SPMD kernels, such as GPUs. We then propose an adaptive memory access granularity framework to exploit and enforce the horizontal locality in order to reduce the interferences among accelerator cores memory accesses and hence improve DRAM efficiency. With the proposed technique, DRAM efficiency grows by 1.42X on average, resulting in 12.3% overall performance gain, for a set of representative memory intensive GPGPU applications.", "num_citations": "3\n", "authors": ["1049"]}
{"title": "Minimalistic architecture for reconfigurable audio Beamforming\n", "abstract": " In this paper, we propose a minimal programming model that is tailored to audio Beamforming applications. The model consists of nine instructions that provide high flexibility to customize multi-core reconfigurable beamformers. We describe all instructions and demonstrate their functionality through pseudocode examples. We apply the proposed programming paradigm to a multi-core reconfigurable Beamforming architecture. Our approach combines software programming flexibility with improved hardware performance. Experimental results suggest that our Virtex4FX60-based solution at 100 MHz, can extract in real-time up to 12 acoustic sources 2.6x faster than a 3.0 GHz Core2 Duo OpenMP-based implementation.", "num_citations": "3\n", "authors": ["1049"]}
{"title": "ImpEDE: A multidimensional design-space exploration framework for biomedical-implant processors\n", "abstract": " The demand for biomedical implants keeps increasing. However, most of the current implant design methodologies involve custom-ASIC design. The SiMS project aims to change this process and make implant design more modular, flexible, faster and extensible. The most recent work within the SiMS context provides ImpEDE, a framework based on a multiobjective genetic algorithm, for automatic exploration of the design space of implant processors. The framework provides the processor designer with a Pareto front through which informed decisions can be made about specific implant families after analyzing their particular tradeoffs and requirements. A highly efficient, parallelized version of the genetic algorithm is also used to evolve the front and has as its objectives the optimization of power, performance and area. In addition, we illustrate the extensibility of our framework by modifying it to include a case study\u00a0\u2026", "num_citations": "3\n", "authors": ["1049"]}
{"title": "Range trees with variable length comparisons\n", "abstract": " In this paper we introduce a new data structure for address lookup, a new tree structure which improves on the existing range trees allowing shorter comparisons than the address width. The proposed scheme shares among multiple concurrent comparisons common address prefixes and suffixes and also omits address parts not required for computing a next node branch. In so doing, for a given memory bandwidth, we achieve a larger number of concurrent comparisons than the original range tree. This results in less memory accesses and lower latency per lookup. Performance scales better as the address width and the number of address ranges increase. We describe the rules employed to construct the proposed structure and offer two heuristics which generate the ldquoconfigurationrdquo of the decision tree given a set of address ranges. The proposed range tree with variable-length comparisons (RT-VLC) has\u00a0\u2026", "num_citations": "3\n", "authors": ["1049"]}
{"title": "Integration of power saving techniques in the unisim simulation framework through the shadow module design paradigm\n", "abstract": " Performance is no longer the only metric dominating modern system-level design. Power is emerging as major constraint to consider during system development. Consequently, several CAD tools with power estimation capabilities in addition to performance figures have been developed. Among these tools, UNISIM is a simulation framework that enables the architects to rapidly design a new system at different levels of granularity in systemC. It allows quick design space exploration and offers cycle accurate performance evaluation. We propose the shadow module, a new design paradigm for UNISIM that enables the framework to account for energy estimation. In this respect, we discuss the implementation of various cache power saving techniques. Experimental results utilizing realistic benchmarks show that power and performance figures can be easily identified with our enhanced analysis framework.", "num_citations": "3\n", "authors": ["1049"]}
{"title": "High-bandwidth address generation unit\n", "abstract": " In this paper we describe an efficient data fetch circuitry for retrieving several operands from a n-bank interleaved memory system in a single machine cycle. The proposed address generation (AGEN) unit operates with a modified version of the low-order-interleaved memory access approach. Our design supports data structures with arbitrary lengths and different (odd) strides. A detailed discussion of the 32-bit AGEN design aimed at multiple-operand functional units is presented. The experimental results indicate that our AGEN is capable of producing 8 x 32-bit addresses every 6 ns for different stride cases when implemented on VIRTEX-II PRO xc2vp30-7ff1696 FPGA device using trivial hardware resources.", "num_citations": "3\n", "authors": ["1049"]}
{"title": "SAD prefetching for MPEG4 using flux caches\n", "abstract": " In this paper, we consider flux caches prefetching and a media application. We analyze the MPEG4 encoder workload with realistic data set in a scenario representative for the embedded systems domain. Our study shows that different well known data prefetch mechanisms can gain little reduction in the cache miss ratios when applied on the complete MPEG4 application. Furthermore, we investigate the potential improvement when dedicated prefetching strategies are applied to the sum of absolute differences (SAD) kernels in MPEG4. We propose a flux cache mechanism that dynamically invokes cache designs with dedicated prefetching engines that can fully utilize the available memory bandwidth. We show that our proposal improves the cache miss ratios by a factor close to 3x.", "num_citations": "3\n", "authors": ["1049"]}
{"title": "The midlifekicker microarchitecture evaluation metric\n", "abstract": " We introduce the midlfekicker metric for evaluating microarchitectures mostly during the design process. We assume a microarchitecture designed at a time T-1 and estimate if a new microarchitecture projected for time T has advantages over the microarchitecture designed at T-1 and remapped on the same technology at time T. We consider that microarchitects minimize the product cycles per instruction (CPI) x cycle time and estimate performance based on CPI with a soft-threshold to include cycle time product effects. Some measurements are also reported.", "num_citations": "3\n", "authors": ["1049"]}
{"title": "Polymorphic processors: How to expose arbitrary hardware functionality to programmers\n", "abstract": " In this paper, we describe a way to extend the flexibility of hardware and provide the programmer with an arbitrary number of processing units to use. To achieve our goals, we present a new programming paradigm, a new instruction set architecture, a microcode-based microarchitecture, and a compiler methodology. The programming paradigm, in contrast with the conventional programming paradigm, mixes general-purpose conventional code with hardware descriptions and allows ultra complex instructions. The instruction set is designed such that it requires only a one-time extension for every family of computers. It requires only 8 instructions that are capable of invoking emulation. Emulation is combined with the microarchitecture to allow high-speed reconfiguration and execution. Finally, it is indicated that a compiler can be built to automatically transform a program to conform with the described polymorphic\u00a0\u2026", "num_citations": "3\n", "authors": ["1049"]}
{"title": "SCISM IA-32 binary translator\n", "abstract": " With today\u2019s IC technology approaching the edge of the Moore\u2019s law, it is emerging to obtain execution speed-ups by applying different methods rather than future clock speed increases. The execution time can be improved by exploiting the parallelism inherent in the binary code, ie Instruction Level Parallelism (ILP)[3]. In such a way, designing a new architecture from scratch and recompilation of the existing code (written and tested for years) can be avoided. The Scalable Compound Instruction Set Machine (SCISM)[6] organization addresses this problem by analyzing the instruction dependencies at execution time and by compounding them together for parallel execution according to a pre-defined categorization based on hardware utilization rather than opcode description. The main SCISM advantage is that it provides a design that remains binary compatible with the original instruction set architecture. This paper introduces SCISM software simulator able to read, translate and simulate parallel execution of IA-32 legacy code. The main goal is to provide a tool for easy exploration of the parallelism present in the native IA-32 binary code. The SCISM simulator is (open source) software project written in C++ under Linux. The compounding rules and all additional information, eg ISA description, hardware implementation 1 details etc., are provided through a set of plain text configuration files that can be easily modified. Preliminary results suggest that performance gains of about 30% are feasible.", "num_citations": "3\n", "authors": ["1049"]}
{"title": "March LA: A Test for All Linked Memory Faults\n", "abstract": " Many march tests have already been designed to cover faults of different fault models. The complexity of these tests arises when linked faults are taken into consideration. This paper presents a methodology to design tests for linked faults, resulting in the march tests: March LA, LA-, LAD and LADD-. They allow for the detection of any number of simple and linked faults. Different tests are proposed for SRAMs and DRAMs; ie, the tests are shown to be memory technology dependent. These new tests are more efficient and offer a higher fault coverage than comparable existing tests.", "num_citations": "3\n", "authors": ["1049"]}
{"title": "March u: A test for unlinked memory faults\n", "abstract": " Short and efficient memory tests is the goal of cvcry tcst dcsigncr. To reduce the cost of production tests, often a simple test which covers most of the faults, eg all simple (unlinked) faults, is desirable to eliminatc most defective parts; a more costly test can be used thereafter to eliminate the remainder of the bad parts. Such a test-cost efficient approach is used by most manufacturers. In addition, system power-on tests are not allowed a long test time while a high fault coverage is desirable. The authors propose a new realistic fault model (the disturb fault model), and a sct of tcsts for unlinked faults. These tests have the property of covering all simple (unlinked) faults at a very reasonable test time compared with cxisting tcsts.", "num_citations": "3\n", "authors": ["1049"]}
{"title": "MC-DeF: Creating Customized CGRAs for Dataflow Applications\n", "abstract": " Executing complex scientific applications on Coarse-Grain Reconfigurable Arrays (CGRAs) promises improvements in execution time and/or energy consumption compared to optimized software implementations or even fully customized hardware solutions. Typical CGRA architectures contain of multiple instances of the same compute module that consist of simple and general hardware units such as ALUs, simple processors. However, generality in the cell contents, while convenient for serving a wide variety of applications, penalizes performance and energy efficiency. To that end, a few proposed CGRAs use custom logic tailored to a particular application\u2019s specific characteristics in the compute module. This approach, while much more efficient, restricts the versatility of the array. To date, versatility at hardware speeds is only supported with Field programmable gate arrays (FPGAs), that are reconfigurable at a\u00a0\u2026", "num_citations": "2\n", "authors": ["1049"]}
{"title": "Performance portable fpga design\n", "abstract": " FPGA platforms are widely used for application acceleration. Although a number of high-level design frameworks exist, application and performance portability across different platforms remain challenging. To address the above problem, we propose an API design for high-level development tools to separate platform-dependent code from the remaining application design. Additionally, we propose design guidelines to assist with performance portability. To demonstrate our techniques, a large-scale application, originally developed for an Intel Stratix-V FPGA is ported to several new Xilinx Virtex UltraScale+ systems. The accelerated application, developed in a high-level framework, is rapidly moved onto the new platforms with minimal changes. The original, unmodified kernel code delivers a 1.74 x speedup due to increased clock frequency on the new platform. Subsequently, the application is further optimised to\u00a0\u2026", "num_citations": "2\n", "authors": ["1049"]}
{"title": "Low area overhead custom buffering for FFT\n", "abstract": " In this paper we propose a technique to minimise the area overhead of a double buffered implementation of Radix-4 Fast Fourier Transformation (FFT). Our proposal circumvents the need for double buffering by exploiting opportunities in the specific data reordering of the buffers that are needed when implementing a fully pipelined FFT. By using the same read and write pattern, a single buffer is sufficient to perform data reordering while maintaining data integrity without degrading performance. We demonstrate this approach in an FPGA implementation. As a result of our optimisation, the memory depth can be reduced by a factor of two with very small overhead in control logic complexity.", "num_citations": "2\n", "authors": ["1049"]}
{"title": "A Parallel and Improved Quadrivalent Quantum-Inspired Gravitational Search Algorithm in Optimal Design of WSNs\n", "abstract": " Wireless Sensor Networks (WSNs) are recently used in monitoring applications. One of the most important challenges in WSNs is determining the operational mode of sensors, decreasing the energy consumption while the connectivity requirements and the special properties are satisfied. This problem is an NP-hard one and is a time\u2013consuming progress. In this study, an improved version of quadrivalent quantum-inspired gravitational search algorithm as a new metaheuristic, well suitable for quadrivalent problems is proposed using Not Q-Gate to optimize the performance of the WSN. Beside, to enhance the speed and the accuracy of the algorithm more, we used a parallelizing technique using Open-MP. Parallelizing this algorithm on mentioned problem is useful from four aspects; 1 - accelerate the speed of the algorithm, 2 - improving the quality of solutions by letting the increasing the population size, 3\u00a0\u2026", "num_citations": "2\n", "authors": ["1049"]}
{"title": "A non-conservative software-based approach for detecting illegal CFEs caused by transient faults\n", "abstract": " Software-based methods for the detection of control-flow errors caused by transient fault usually consist in the introduction of protecting instructions both at the beginning and at the end of basic blocks. These methods are conservative in nature, in the sense that they assume that all blocks have the same probability of being the target of control flow errors. Because of that assumption they can lead to a considerable increase both in memory and performance overhead during execution time. In this paper, we propose a static analysis that provide a more refined information about which basic blocks can be the target of control-flow-errors caused by single-bit flips. This information can then be used to guide a program transformation in which only susceptible blocks have to be protected. We implemented the static analysis and program transformation in the context of the LLVM framework and performed an extensive fault\u00a0\u2026", "num_citations": "2\n", "authors": ["1049"]}
{"title": "Ultra low latency dataflow renderer\n", "abstract": " Reconfigurable hardware has been used before for low latency image synthesis. These are typically low level implementations with tight vertical integration. For example the apparatus of both Regan et al and Ng et al had the tracker driven by the same device performing the rendering. Reconfigurable hardware combined with the dataflow programming model can make application specific rendering hardware cost effective. Our sprite renderer has comparable scope to both prior examples, but our dataflow graph can be adapted to other use cases with an effort comparable to GPU shader programming.", "num_citations": "2\n", "authors": ["1049"]}
{"title": "Custom architecture for multicore audio beamforming systems\n", "abstract": " The audio Beamforming (BF) technique utilizes microphone arrays to extract acoustic sources recorded in a noisy environment. In this article, we propose a new approach for rapid development of multicore BF systems. Research on literature reveals that the majority of such experimental and commercial audio systems are based on desktop PCs, due to their high-level programming support and potential of rapid system development. However, these approaches introduce performance bottlenecks, excessive power consumption, and increased overall cost. Systems based on DSPs require very low power, but their performance is still limited. Custom hardware solutions alleviate the aforementioned drawbacks, however, designers primarily focus on performance optimization without providing a high-level interface for system control and test. In order to address the aforementioned problems, we propose a custom\u00a0\u2026", "num_citations": "2\n", "authors": ["1049"]}
{"title": "Novel design methods and a tool flow for unleashing dynamic reconfiguration\n", "abstract": " During the last few years, there is an increasing interest in mixing software and hardware to serve efficiently different applications. This is due to the heterogeneity characterizing the tasks of an application which require the presence of resources from both worlds, software and hardware. Controlling effectively these resources through an integrated tool flow is a challenging problem and towards this direction only a few efforts exist. In fact, a framework that seamlessly exploits both resources of a platform for executing efficiently an application has not yet come into existence. Moreover, reconfigurable computing often incorporated in such platforms due to its high flexibility and customization, has not yet taken off due to the lack of exploiting its full capabilities. Thus, the capability of reconfigurable devices such as Field Programmable Gate Arrays (FPGAs) to be dynamically reconfigured, i.e. reprogramming part of the chip\u00a0\u2026", "num_citations": "2\n", "authors": ["1049"]}
{"title": "On improved MANET network utilization\n", "abstract": " Mobile ad hoc network (MANET) is a new opportunity for mobile networking using intelligent mobile terminals. However, the widely used shortest path first based routing algorithm leads to various network utilization problems. Mobile terminals have limited power, hence, power saving should be considered when terminals serve as intermediate nodes in MANET. Furthermore, ad hoc routing table calculation is distributed among all network terminals. Therefore, we also need to construct stable paths with longer lifetime in order to reduce the communication overhead introduced by route reconstruction. A less evenly distributed traffic exhausts power on the nodes in the center of the network and leads to shorter path lifetime. Such a network deployment is not fair for the internal nodes. The above problems exist for all routing protocols especially proactive routing protocols based on shortest path first algorithm OLSR. In\u00a0\u2026", "num_citations": "2\n", "authors": ["1049"]}
{"title": "4-D parity codes for soft error correction in aerospace applications\n", "abstract": " In order to reduce the overall system cost, the aerospace industry has been increasingly using commercial off the shelf components in their products. The sensitivity of these products to radiation induced soft errors becomes a major concern. In this paper, we propose a method to increase the reliability of a given off the shelf component by manipulating the software-based error correction algorithm of its already existing 4-D parity codes. The paper shows that using this approach, it is possible to correct triple bit adjacent errors, without adversely affecting the performance or memory usage.", "num_citations": "2\n", "authors": ["1049"]}
{"title": "Scaling HMMER Performance on Multicore Architectures\n", "abstract": " In bioinformatics, protein sequence alignment is one of the fundamental tasks that scientists perform. Since the growth of biological data is exponential, there is an ever-increasing demand for computational power. While current processor technology is shifting towards the use of multicores, the mapping and parallelization of applications has become a critical issue. In order to keep up with the processing demands, applications' bottlenecks to performance need to be found and properly addressed. In this paper we study the parallelism and performance scalability of HMMER, a bioinformatics application to perform sequence alignment. After our study of the bottlenecks in a HMMER version ported to the Cell processor, we present two optimized versions to improve scalability in a larger multicore architecture. We use a simulator that allows us to model a system with up to 512 processors and study the performance of\u00a0\u2026", "num_citations": "2\n", "authors": ["1049"]}
{"title": "A novel HDL coding style for power reduction in FPGAs\n", "abstract": " Power consumption has become the major factor that has to be considered while designing systems using reconfigurable devices, especially for battery-operated applications. Minimizing transitions is one of the ways to reduce power consumption. Overwriting a register with the same value occurs frequently in real digital systems. Such unneeded transitions increase the power consumption. To avoid this, a new HDL coding style to reduce power consumption for reconfigurable devices is proposed. The idea is to\u201d force\u201d the CAD tool to configure the CLB flip-flop as a T flip-flop with its T input held constantly at logic one and drive its clock through the lookup table (LUT). Based on an extensive evaluation using MCNC benchmark circuits on a real FPGA and a real CAD tool, our proposal reduces total power consumption by 13-90% and runs 2-20% faster with 0-45% area overhead compared to conventional coding style solutions. As a parallel activity we proposed a new logic element (LE) that implements the proposed design style directly.", "num_citations": "2\n", "authors": ["1049"]}
{"title": "High Quality Simulation Tool for Memory Redundancy Algorithms\n", "abstract": " This paper presents a high quality simulation tool that evaluates the efficiency of redundancy algorithms (RAs) for repairable memory devices. The tool can generate various faulty memory models to be analyzed by a given RA. Furthermore it can provide useful information for the feedback to RA under evaluation when the RA fails to repair any theoretically repairable model. The approach and the external specifications are described according to the properties required for the tool.", "num_citations": "2\n", "authors": ["1049"]}
{"title": "Matched sams scheme: Supporting multiple stride unaligned vector accesses with multiple memory modules\n", "abstract": " In this paper, we analyze the problem of supporting conflict-free access for multiple stride families in parallel memory schemes targeted for high performance vector processing systems. We propose the Matched SAMS Scheme, which is based on the basic SAMS scheme, to support conflict-free vector memory accesses for strides from multiple stride families. We compare our scheme against previously proposed techniques, eg using buffers and inter-vector out-of-order access. The main advantage of our proposal is that the atomic parallel access is supported without limiting the vector lengths. This provides better support for short vectors. Our scheme also has the merit of better memory module utilization compared to the solutions with additional modules. Synthesis results for TSMC 90 nm Low-K CMOS technology indicate that the Matched SAMS Scheme has efficient hardware implementations, with a critical path delay of less than 1 ns and moderate hardware resource utilization. To validate the performance of proposed Matched SAMS Scheme in real applications, we applied it to IBM Cell processor by integrating it to the Cell SPE local store, and did experiments with applications from PARSEC benchmarks and micro-kernels from IBM Cell SDK. Simulation results show that with the direct support of unaligned and strided memory access patterns by our parallel memory scheme, the dynamic instruction counts drops by up to 49%, which turns into a reduction of around 46% in execution time.", "num_citations": "2\n", "authors": ["1049"]}
{"title": "Performance Evaluation of Multi-threading Operating Systems in MP-SoCs Generated by ESPAM\n", "abstract": " Computer Engineering Publications Database - View Publication CE logo Computer Engineering Publications Database (2000-2018) Publications Authors Home \u00bb Publications \u00bb Performance Evaluation of Multi-threading Operating Systems in MPSoCs generated by ESPAM Performance Evaluation of Multi-threading Operating Systems in MPSoCs generated by ESPAM 474_performance_evaluation_of_multithreading_operating_systems.pdf Publication Type Technical Report Title Performance Evaluation of Multi-threading Operating Systems in MPSoCs generated by ESPAM Author(s) E. Cannella TP Stefanov GN Gaydadjiev Publication Date June 2008 Report Number CE-TR-2008-02 Report Name CE technical report Selected Publication No Note Topic(s) None Theme(s) None Project(s) None Group(s) Computer Engineering IEEE BibTex entry: @techreport{, author = \"E. Cannella and TP Stefanov and GN \u2026", "num_citations": "2\n", "authors": ["1049"]}
{"title": "SARC Power Estimation Methodology\n", "abstract": " In modern CMOS technologies, power consumption is becoming a significant challenge for the integrated circuits industry. Accurate estimation of power dissipation is very important during micro-architectural design of every computational structure. This work presents the methodology we intent to use in future investigations regarding power consumption of the SARC architecture. SARC project is targeting next generation scalable computer architectures where multiple cores will be responsible for the performance gains. Proposing new approaches to reduce power consumption and scale for power and performance in the architectural development is one of the main challenges of this project. Therefore, adequate methodology to estimate it is needed. In this paper, we introduce the tools (ie, Unisim simulator and Cacti 4.0) and the proposed methodology to investigate the problem of power consumption in such architecture.", "num_citations": "2\n", "authors": ["1049"]}
{"title": "Two-dimensional memory implementation with multiple data patterns\n", "abstract": " In this paper, we propose an implementation of a two-dimensional interleaved memory organization with dynamically reconfigurable access patterns. Our solution targets computing devices with high demands on memory bandwidth, such as multimedia-specific DSPs, scientific vector processors, and SIMD machines. The approach extends prior art by introducing advanced two-dimensional strided accesses augmented with additional parameters for arbitrary rectangular data patterns support. Our scheme provides runtime dynamical reconfiguration and guarantees minimum memory latency and efficient bandwidth utilization for arbitrary chosen pattern parameter combinations. We have implemented in VHDL an architecture independent memory organization and synthesized a set of configurations with 2x2 up to 8x8 memory modules for 90 nm CMOS technology. Synthesis results support our claim on high performance of the memory organization together with high system scalability. More specifically, our estimations suggest that a throughput of up to 1182 Gbit/s can be obtained at the cost of only 212 Kgates.", "num_citations": "2\n", "authors": ["1049"]}
{"title": "FPGA based implementation of Reconfigurable Universal Adders\n", "abstract": " Computer Engineering Publications Database - View Publication CE logo Computer Engineering Publications Database (2000-2018) Publications Authors Home \u00bb Publications \u00bb FPGA based \ufeffimplementation of Reconfigurable Universal Adders FPGA based \ufeffimplementation of Reconfigurable Universal Adders Publication Type Technical Report Title FPGA based \ufeffimplementation of Reconfigurable Universal Adders Author(s) DRH Calder\u00f3n GN Gaydadjiev S. Vassiliadis Publication Date January 2007 Report Number CE-TR-2007-01 Report Name CE technical report Selected Publication No Note Topic(s) None Theme(s) None Project(s) None Group(s) Computer Engineering IEEE BibTex entry: @techreport{, author = \"DRH Calder\u00f3n and GN Gaydadjiev and S. Vassiliadis\", title = \"FPGA based \ufeffimplementation of Reconfigurable Universal Adders\", institution = \"Delft University of Technology\", address = \"Delft, \u2026", "num_citations": "2\n", "authors": ["1049"]}
{"title": "Testing of modern semiconductor memory structures\n", "abstract": " Introduction he systems on chip (SoC) as known in 2007 are turning into memory hungry devices in order to cope with the continuously increasing application requirements. Another important driver behind this trend is in the significant increase in number of transistors with each technology node and the forthcoming impatience among SoC designers to utilize those resources as on-chip memory. Figure 1.1 shows how embedded memory is expected to dominate the chip area (growing from about 48% in 2004 to more than 60% expected after 2009) according to the 2005 ITRS [1]. In addition, future SoCs are expected to embed memories of increasing sizes, eg 256Mbits and more. As a result, the overall SoC yield will be dominated by the memory yield. Due to the fact that memory yield decreases with the increasing memory sizes, the overall yield may become unacceptable, unless special measures are taken. The bottom curve in Figure 1.2 shows the impact increasing memory sizes can have on the yield. For instance, the yield of 24Mbits embedded memory is about 20%; the example assumes a 0.13 micron 12x12mm chip, with a memory defect", "num_citations": "2\n", "authors": ["1049"]}
{"title": "OCM-to-DDR memory controller for VirtexII-Pro FPGA\n", "abstract": " We consider the memory subsystem of the Power PC 405 Processor embedded in a Xilinx Virtex-II Pro FPGA chip. There are three processor bus interfaces that can be used for memory access, namely: the On-Chip Peripheral Bus (OPB), the Processor Local Bus (PLB) and the On-Chip Memory Controller (OCM) bus. We are interested in fast memory transfers, therefore we consider the fastest of the above interfaces, the OCM interface. In this paper, we propose a design of a Dual Data Rate (DDR) Memory controller that can be connected to the OCM bus. The controller comprises an OCM bus interface module and a modified Xilinx DDR controller core. To implement time-efficient data transfers between the PPC interface and the external DDR chips, we finely synchronize the OCM interface and the DDR. Our FPGA modules are developed using Xilinx Project Navigator 6.3 i and Xilinx Platform Studio 6.3 i and are described using VHDL. ModelTech Modelsim is used to simulate and fine-tune the designs. The design has been simulated and synthesized. The results suggest that the hardware costs of the proposed solution are trivial (1%-2% of the available reconfigurable resources). Furthermore, the timing analisys report that the solution can run on a maximum frequency fmax of 100 MHz. The controller can be employed as part of a reconfigurable caching structure. The proposed OCM DDR controller solves the size limitation problem of the on-chip memory on Virtex II-Pro. It provides high bandwidth to external memory which typically has a larger volume compared to the on-chip memory. Our proposal makes it possible to build fast and cost efficient\u00a0\u2026", "num_citations": "2\n", "authors": ["1049"]}
{"title": "Efficient filtering with the co-vector processor\n", "abstract": " This paper describes the mapping of Finite Impulse Response (FIR) and Decimation filters on a new DSP architecture: the Co-Vector Processor (CVP) developed by Philips. This architecture is targeting the baseband signal processing algorithms for the third generation mobile communication (3G). CVP is a Very Long Instruction Word (VLIW) architecture with functional units supporting vector parallelism. To exploit efficiently the architecture, a large portion of the targeted DSP algorithms must be properly vectorized. In this paper, different vectorization strategies for FIR and Decimation filters for the CVP architecture are investigated. The approach used is to restructure the original sequential 1 algorithms into block forms 2 that are suitable for parallel processing. In addition, the vectorization should fully utilize the Multiply-Accumulate (MAC) structure. It is shown that for the targeted filters, several good vectorization strategies can be applied. The benchmark results obtained using the proposed strategies outperform results of other architectures previously reported.", "num_citations": "2\n", "authors": ["1049"]}
{"title": "Realistic linked memory cell array faults\n", "abstract": " The problem of designing memory tests is to establish a relevant set of fault models only consisting of those faults which are shown to be possible to occur in practice. Thereafter, it is a challenge to the test designer to design an optimum test covering the faults of the established fault models. A new fault model, the disturb fault model, is introduced. The notation of linked faults is established and it is shown that march tests can only detect a subset of all linked faults. Thereafter, the universe of linked faults is reduced to the set of realistic linked faults. Last, the effectiveness of the realistic linked fault model is shown via new tests with a higher fault coverage and a shorter test length.", "num_citations": "2\n", "authors": ["1049"]}
{"title": "On Predictable Reconfigurable System Design\n", "abstract": " We propose a design methodology to facilitate rigorous development of complex applications targeting reconfigurable hardware. Our methodology relies on analytical estimation of system performance and area utilisation for a given specific application and a particular system instance consisting of a controlflow machine working in conjunction with one or more reconfigurable dataflow accelerators. The targeted application is carefully analyzed, and the parts identified for hardware acceleration are reimplemented as a set of representative software models. Next, with the results of the application analysis, a suitable system architecture is devised and its performance is evaluated to determine bottlenecks, allowing predictable design. The architecture is iteratively refined, until the final version satisfying the specification requirements in terms of performance and required hardware area is obtained. We validate the\u00a0\u2026", "num_citations": "1\n", "authors": ["1049"]}
{"title": "Towards real time radiotherapy simulation\n", "abstract": " We propose a novel reconfigurable hardware architecture to implement Monte Carlo based simulation of physical dose accumulation for intensity-modulated adaptive radiotherapy. The long term goal of our effort is to provide accurate dose calculation in real-time during patient treatment. This will allow wider adoption of personalised patient therapies which has the potential to significantly reduce dose exposure to the patient as well as shorten treatment and greatly reduce costs. The proposed architecture exploits the inherent parallelism of Monte Carlo simulations to perform domain decomposition and provide high resolution simulation without being limited by on-chip memory capacity. We present our architecture in detail and provide a performance model to estimate execution time, hardware area and bandwidth utilisation. Finally, we evaluate our architecture on a Xilinx VU9P platform as well as the Xilinx Alveo\u00a0\u2026", "num_citations": "1\n", "authors": ["1049"]}
{"title": "Feedbackward Decoding for Semantic Segmentation\n", "abstract": " We propose a novel approach for semantic segmentation that uses an encoder in the reverse direction to decode. Many semantic segmentation networks adopt a feedforward encoder-decoder architecture. Typically, an input is first downsampled by the encoder to extract high-level semantic features and continues to be fed forward through the decoder module to recover low-level spatial clues. Our method works in an alternative direction that lets information flow backward from the last layer of the encoder towards the first. The encoder performs encoding in the forward pass and the same network performs decoding in the backward pass. Therefore, the encoder itself is also the decoder. Compared to conventional encoder-decoder architectures, ours doesn't require additional layers for decoding and further reuses the encoder weights thereby reducing the total number of parameters required for processing. We show by using only the 13 convolutional layers from VGG-16 plus one tiny classification layer, our model significantly outperforms other frequently cited models that are also adapted from VGG-16. On the Cityscapes semantic segmentation benchmark, our model uses 50.0% less parameters than SegNet and achieves an 18.1% higher \"IoU class\" score; it uses 28.3% less parameters than DeepLab LargeFOV and the achieved \"IoU class\" score is 3.9% higher; it uses 89.1% fewer parameters than FCN-8s and the achieved \"IoU class\" score is 3.1% higher. Our code will be publicly available on Github later.", "num_citations": "1\n", "authors": ["1049"]}
{"title": "Towards domain-specific instruction-set generation\n", "abstract": " Over the past years, a considerable amount of effort has been devoted to the definition and implementation of techniques for the optimization and acceleration of applications on various (reconfigurable) computing platforms. Among these techniques, the extension of a given instruction-set architecture with custom instructions has become a common approach. Custom instructions effectively reduce the dynamic instruction count, which, in turn, leads to an increase in performance. Traditionally, existing techniques address Instruction-Set Extension (ISE) on a per-application basis. Anyhow, when many applications have to be considered at the same time, ISE on a per-application basis is, clearly, less effective, as the custom instructions have, often, limited re-utilization across applications. To overcome this problem, we propose a new framework for the automatic generation of domain-specific ISEs. Experimental results\u00a0\u2026", "num_citations": "1\n", "authors": ["1049"]}
{"title": "FPGA-based design using the FASTER toolchain: the case of STM Spear development board\n", "abstract": " Even though FPGAs are becoming more and more popular as they are used in many different scenarios like communications and HPC, the steep learning curve needed to work with this technology is still the major limiting factor to their full success. Many works proposed to mitigate this problem by creating a companion of tools to support the designer during the development phase for this technology. The EU FASTER Project aims at realizing an integrated toolchain that assists the designer in the steps of the design flow that are necessary to port a given application onto an FPGA device. The novelty of the framework relies in the fact that the partial dynamic reconfiguration, which FPGA devices can exploit, is seen as a first class citizen throughout the whole design flow. This work reports a case study in which the FASTER toolchain has been used to port a raytracer application onto the STM Spear prototyping\u00a0\u2026", "num_citations": "1\n", "authors": ["1049"]}
{"title": "Towards scalable arithmetic units with graceful degradation\n", "abstract": " This article presents a new family of scalable arithmetic units (ScAUs) targeting resource-constrained, embedded devices. We, first, study the performance, power, area and scalability properties of general adders. Next, suitable error-detection schemes for low-power embedded systems are discussed. As a result, our ScAUs are enhanced with a suitable error-detection scheme, resulting in a Parity-Checked ScAU (PCScAU) design. The PCScAU strikes a flexible trade-off between space and time redundancy, offering dependability similar to high-end techniques for the area and power cost of low-end approaches. An alternative design, the Precision-Scalable Arithmetic Unit (PScAU) maintains throughput with degraded precision in case of hardware failures. The PScAU is targeting dependable applications where latency rather than numerical accuracy is more important. The PScAU's downscaled mode is also\u00a0\u2026", "num_citations": "1\n", "authors": ["1049"]}
{"title": "Towards code safety with high performance\n", "abstract": " Reliability is a major issue for safety-critical embedded systems such as biomedical implants. In such systems, hardware fault tolerance techniques are usually not available in off-the-shelf processors, because of the intrinsic energy costs of hardware duplication or triplication. As an alternative, software schemes based on compiler transformations are used for error detection and recovery. A common software error class caused by hardware transient faults is Control-Flow Errors (CFEs). In this paper we demonstrate how a new technique based on software instrumentation can benefit from loop-unrolling, with huge impact on control-flow reliability. We show the impact of loop-unrolling on fault-coverage and performance of these schemes. Thanks to the proposed approach, significant fault-coverage concerning CFE can be obtained with no extra costs, and even faster than other available techniques with the\u00a0\u2026", "num_citations": "1\n", "authors": ["1049"]}
{"title": "FASTER run-time reconfiguration management\n", "abstract": " The FASTER project Run-Time System Manager offloads programmers from low-level operations by performing task placement, scheduling, and dynamic FPGA reconfiguration. It also manages device fragmentation, configuration caching, pre-fetching and reuse, bitstream compression, and optimizes the system thermal and power footprints. We propose a micro-reconfiguration aware, configuration content agnostic ISA interface and a technology independent Task Configuration Microcode format targeting Maxeler Data Flow computers and Xilinx XUPV5 platforms. We achieve improved resource utilization with negligible performance overhead. Up to 4Gbps for DMA transfers, and up to 3Gbps for FPGA reconfiguration on Xilinx Virtex-5/6 devices is achieved.", "num_citations": "1\n", "authors": ["1049"]}
{"title": "Improving DRAM performance and energy efficiency\n", "abstract": " In many core systems with shared DRAM memory a clear performance dissbalance exists between the requirements of the processors and the bandwidth that the memory system can provide. Very often the utilization of the memory interface is poor even for well understood and regular workloads. In this paper we propose a method to reorder the in-flight requests by the multiple processing elements at the level of the memory controller and significantly reduce the number of row changes in a fashion transparent to the workload, the CPU ISA or the bus protocol. Several reordering policies have been considered and after a thorough analysis one was selected for implementation. We have obtained application speedups of 1.58 x for 3D FFT and 1.4 x for Conjugate Gradient workloads. In addition, our reordering proposal reduces the activation power of the memory by up to 40% while the total energy reduction per application is 26.6% for 3D FFT and 13.2% for CG.", "num_citations": "1\n", "authors": ["1049"]}
{"title": "HMMER Performance Model for Multicore Architectures\n", "abstract": " Exponential growth in biological sequence data combined with the computationally intensive nature of bioinformatics applications results in a continuously rising demand for processing power. In this paper, we propose a performance model that captures the behavior and performance scalability of HMMER, a bioinformatics application that identifies similarities between protein sequences and a protein family model. With our analytical model, the optimal master-worker ratio for a user scenario can be estimated. The model is evaluated and is found accurate with less than 2% error. We applied our model to a widely used heterogeneous multicore, the Cell BE, using the PPE and SPEs as master and workers respectively. Experimental results show that for the current parallelization strategy, the I/O speed at which the database is read from disk and the inputs pre-processing are the two most limiting factors in the Cell BE\u00a0\u2026", "num_citations": "1\n", "authors": ["1049"]}
{"title": "Efficient hardware task reuse and interrupt handling mechanisms for FPGA-based partially reconfigurable systems\n", "abstract": " The partial reconfigurability of FPGAs allows real-time systems to adapt to changing application requirements. However, the additional time and power needed for partial reconfiguration as well as the sequential reconfiguration process degrade the overall system performance. This is considered as one of the main reasons for restricted use of partial reconfiguration technology. In addition, hardware interrupts have not been well supported in existing systems, which makes the task preemption hard to realize in real-time systems. In this paper, we will propose a novel mechanism for reusing already configured hardware and a generic interrupt handling mechanism. Experimental results show that when our reuse mechanism could be applied, a reduction of approximately 1400x in terms of loaded configuration data can be achieved compared to the traditional reconfiguration. Our interrupt mechanism brings additional\u00a0\u2026", "num_citations": "1\n", "authors": ["1049"]}
{"title": "Mirror Routing for Satellite Networks with Cross-Layer Optimization\n", "abstract": " Several strategies have been proposed for routing in the Low Earth Orbit (LEO) satellite networks. The multi-layered routing approaches are envisioned as promising because they use Middle Earth Orbit (MEO) satellite to extend the LEO satellite network\u2019s communication capabilities. The previously proposed multi-layered routing approaches, however, still assume that the satellites in the same layer share similar characteristics. This assumption is not true in the future satellite networks. This is because the satellites in the future will be heterogeneous with various computation, communication and power capacities that lead to more complicated route construction challenges. In order to solve this problem, we propose the usage of cross-layer designs that can collect information from the neighboring satellites and evaluate their capacity during route construction and maintenance phases. This paper first\u00a0\u2026", "num_citations": "1\n", "authors": ["1049"]}
{"title": "A polymorphic register file architecture\n", "abstract": " Previous vector architectures divided the available register file space in a fixed number of registers of equal sizes. We propose a novel register file organization which allows dynamic creation of a variable number of multidimensional registers of arbitrary sizes-the Polymorphic Register File. We have selected Floyd 64x64 as our benchmark. Simulation results suggest a speedup of up to 8X compared to an idealized Cell PPU scalar processor and a large reduction in the number of executed instructions. Preliminary results indicate that the proposed architecture outperforms the Cell SPU by around 50% without exceeding the 256KB storage size of the Local Store.", "num_citations": "1\n", "authors": ["1049"]}
{"title": "State-of-the-art reconfigurable multithreading architectures\n", "abstract": " This report provides a survey on the existing proposals in the field of reconfigurable multithreading architectures (\u03c1MT). Until now, the reconfigurable architectures have been classified according to implementation or architectural criteria, but never based on their \u03c1MT capabilities. More specifically, we identify reconfigurable architectures that provide implicit, explicit or no architectural support for \u03c1MT. Further subdivision of these three classes is also provided by the proposed taxonomy. For each of the proposals, we discuss the conceptual model, the limitations and the typical application domains. We also summarize the main design problems and identify some key research questions related to highly efficient \u03c1MT support. In addition, we discuss the application prospectives and propose possible research directions for future investigations.", "num_citations": "1\n", "authors": ["1049"]}
{"title": "Preliminary work on a mechanism for testing a customized architecture\n", "abstract": " Hardware customization for scientific applications has shown a big potential for reducing power consumption and increasing performance. In particular, the automatic generation of ISA extensions for General-Purpose Processors (GPPs) to accelerate domain-specific applications is an active field of research. Those domain-specific customized processors are mostly evaluated in simulation environments due to technical and programmability issues while using real hardware. There is no automatic mechanism to test ISA extensions in a real hardware environment. In this paper we present a toolchain that can automatically identify candidate parts of the code suitable for acceleration to test them in a reconfigurable hardware. We validate our toolchain using a bioinformatic application, ClustalW, obtaining an overall speed-up over 2x.", "num_citations": "1\n", "authors": ["1049"]}
{"title": "Metodolog\u00eda para la generaci\u00f3n y evaluaci\u00f3n autom\u00e1tica de hardware espec\u00edfico\n", "abstract": " En el \u00e1rea de la bioinform\u00e1tica podemos encontrar aplicaciones que suponen un reto para el dise\u00f1o de nuevas arquitecturas de procesadores en t\u00e9rminos de rendimiento, ya que sus caracter\u00edsticas difieren de las de las aplicaciones de prop\u00f3sito general. Por ello proponemos una nueva arquitectura con unidades funcionales reconfigurables para un dominio espec\u00edfico de aplicaciones. As\u00ed, el primer paso para definir la nueva arquitectura ser\u00e1 la creaci\u00f3n de la nueva ISA del procesador, que se compondr\u00e1 de extensiones de la ISA original. Para conseguir dicho objetivo, presentamos una metodolog\u00eda para identificar autom\u00e1ticamente patrones de instrucciones y generar prototipos de las unidades funcionales que las ejecutan. Hemos implementado la metodolog\u00eda de manera experimental con el soporte de la infraestructura Trimaran para la identificaci\u00f3n de extensiones de la ISA, la herramienta DWARV para la generaci\u00f3n de c\u00f3digo VHDL, y la plataforma MOLEN para la evaluaci\u00f3n de los prototipos hardware espec\u00edficos generados autom\u00e1ticamente. En las evaluaciones iniciales de los prototipos generados para una aplicaci\u00f3n de estudio, ClustalW, se ha obtenido hasta un 8.54x de speed-up para un \u00fanico acelerador, mientras que el speed-up de toda la aplicaci\u00f3n est\u00e1 por encima de 2x.", "num_citations": "1\n", "authors": ["1049"]}
{"title": "On the feasibility of fat-tree topologies for netowrks-on-chip\n", "abstract": " Most of past evaluations of fat-trees for on-chip interconnection networks rely on oversimplifying or even irrealistic architecture and traffic pattern assumptions, and very few layout analyses are available to relieve practical feasibility concerns in nanoscale technologies. This work aims at providing an in-depth assessment of physical synthesis efficiency of fat-trees and at extrapolating silicon-aware performance figures to back-annotate in the system-level performance analysis. A 2D mesh is used as a reference architecture for comparison, and a 65 nm technology is targeted by our study. Finally, in an attempt to mitigate the implementation cost of k-ary n-tree topologies, we also review an alternative unidirectional multi-stage interconnection network which is able to simplify the fat-tree architecture and to minimally impact performance.", "num_citations": "1\n", "authors": ["1049"]}
{"title": "\u0421\u0442\u0440\u0443\u043a\u0442\u0443\u0440\u043d\u043e\u0435 \u0434\u0432\u043e\u0438\u0447\u043d\u043e\u0435 \u043a\u043e\u0434\u0438\u0440\u043e\u0432\u0430\u043d\u0438\u0435 \u0432 \u043d\u0435\u043f\u043e\u0437\u0438\u0446\u0438\u043e\u043d\u043d\u043e\u043c \u043f\u0440\u043e\u0441\u0442\u0440\u0430\u043d\u0441\u0442\u0432\u0435 \u0438\u0437\u043e\u0442\u043e\u043f\u043d\u044b\u0445 \u0443\u0440\u043e\u0432\u043d\u0435\u0439 \u0430\u0440\u0445\u0438\u0442\u0435\u043a\u0442\u0443\u0440\u044b \u0440\u0435\u043b\u044c\u0435\u0444\u0430 \u0438\u0437\u043e\u0431\u0440\u0430\u0436\u0435\u043d\u0438\u044f\n", "abstract": " \u0418\u0437\u043b\u0430\u0433\u0430\u044e\u0442\u0441\u044f \u043e\u0441\u043d\u043e\u0432\u043d\u044b\u0435 \u043e\u0441\u043e\u0431\u0435\u043d\u043d\u043e\u0441\u0442\u0438 \u043f\u043e\u0441\u0442\u0440\u043e\u0435\u043d\u0438\u044f \u043c\u0435\u0442\u043e\u0434\u0430 \u0441\u0436\u0430\u0442\u0438\u044f \u0432\u0438\u0434\u0435\u043e\u0434\u0430\u043d\u043d\u044b\u0445 \u043d\u0430 \u043e\u0441\u043d\u043e\u0432\u0435 \u0441\u0442\u0440\u0443\u043a\u0442\u0443\u0440\u043d\u043e\u0433\u043e \u043a\u043e\u0434\u0438\u0440\u043e\u0432\u0430\u043d\u0438\u044f \u0432 \u043d\u0435\u043f\u043e\u0437\u0438\u0446\u0438\u043e\u043d\u043d\u043e\u043c \u0430\u0440\u0445\u0438\u0442\u0435\u043a\u0442\u0443\u0440\u043d\u043e\u043c \u043f\u0440\u043e\u0441\u0442\u0440\u0430\u043d\u0441\u0442\u0432\u0435 \u043c\u0443\u043b\u044c\u0442\u0438\u0438\u0437\u043e\u0442\u043e\u043f\u043d\u043e\u0433\u043e \u0440\u0435\u043b\u044c\u0435\u0444\u0430 \u0438\u0437\u043e\u0431\u0440\u0430\u0436\u0435\u043d\u0438\u044f. \u041f\u043e\u043a\u0430\u0437\u044b\u0432\u0430\u0435\u0442\u0441\u044f, \u0447\u0442\u043e \u043a\u043e\u0434\u0438\u0440\u043e\u0432\u0430\u043d\u0438\u0435 \u0431\u0430\u0437\u0438\u0440\u0443\u0435\u0442\u0441\u044f \u043d\u0430: \u043f\u0435\u0440\u0435\u0444\u043e\u0440\u043c\u0430\u0442\u0438\u0440\u043e\u0432\u0430\u043d\u0438\u0438 \u0430\u0440\u0445\u0438\u0442\u0435\u043a\u0442\u0443\u0440\u044b \u0440\u0435\u043b\u044c\u0435\u0444\u0430 \u0438\u0437\u043e\u0431\u0440\u0430\u0436\u0435\u043d\u0438\u044f, \u043e\u0441\u043d\u043e\u0432\u0430\u043d\u043d\u043e\u0433\u043e \u043d\u0430 \u0441\u0432\u043e\u0439\u0441\u0442\u0432\u0430\u0445 \u043d\u0435\u043f\u043e\u0437\u0438\u0446\u0438\u043e\u043d\u043d\u043e\u0441\u0442\u0438 \u0438 \u0432\u0437\u0430\u0438\u043c\u043e\u0438\u0441\u043a\u043b\u044e\u0447\u0430\u0435\u043c\u043e\u0441\u0442\u0438 \u0438\u0437\u043e\u0442\u043e\u043f\u043d\u044b\u0445 \u0443\u0440\u043e\u0432\u043d\u0435\u0439; \u0441\u0442\u0440\u0443\u043a\u0442\u0443\u0440\u043d\u043e\u0439 \u043d\u0443\u043c\u0435\u0440\u0430\u0446\u0438\u0438 \u043f\u0435\u0440\u0435\u0444\u043e\u0440\u043c\u0430\u0442\u0438\u0440\u043e\u0432\u0430\u043d\u043d\u043e\u0439 \u0430\u0440\u0445\u0438\u0442\u0435\u043a\u0442\u0443\u0440\u044b \u0440\u0435\u043b\u044c\u0435\u0444\u0430 \u0438\u0437\u043e\u0431\u0440\u0430\u0436\u0435\u043d\u0438\u044f \u0432 \u043d\u0435\u043f\u043e\u0437\u0438\u0446\u0438\u043e\u043d\u043d\u043e\u043c \u043c\u0443\u043b\u044c\u0442\u0438\u0438\u0437\u043e\u0442\u043e\u043f\u043d\u043e\u043c \u043f\u0440\u043e\u0441\u0442\u0440\u0430\u043d\u0441\u0442\u0432\u0435. \u041e\u0431\u043e\u0441\u043d\u043e\u0432\u044b\u0432\u0430\u0435\u0442\u0441\u044f, \u0447\u0442\u043e \u0441\u0436\u0430\u0442\u0438\u0435 \u0438\u0437\u043e\u0431\u0440\u0430\u0436\u0435\u043d\u0438\u0439 \u0434\u043e\u0441\u0442\u0438\u0433\u0430\u0435\u0442\u0441\u044f \u0437\u0430 \u0441\u0447\u0435\u0442 \u0441\u043e\u043a\u0440\u0430\u0449\u0435\u043d\u0438\u044f \u0438\u0437\u0431\u044b\u0442\u043e\u0447\u043d\u043e\u0441\u0442\u0438, \u043e\u0431\u0443\u0441\u043b\u043e\u0432\u043b\u0435\u043d\u043d\u043e\u0439: \u043e\u0434\u043d\u043e\u0432\u0440\u0435\u043c\u0435\u043d\u043d\u044b\u043c \u0443\u0447\u0435\u0442\u043e\u043c \u043f\u043e\u0437\u0438\u0446\u0438\u0439 \u0441 \u0437\u0430\u043f\u0440\u0435\u0442\u043e\u043c \u043f\u043e\u044f\u0432\u043b\u0435\u043d\u0438\u044f \u0435\u0434\u0438\u043d\u0438\u0447\u043d\u044b\u0445 \u044d\u043b\u0435\u043c\u0435\u043d\u0442\u043e\u0432 \u0438 \u043e\u0433\u0440\u0430\u043d\u0438\u0447\u0435\u043d\u0438\u0439 \u043d\u0430 \u0434\u0438\u043d\u0430\u043c\u0438\u0447\u0435\u0441\u043a\u0438\u0435 \u0434\u0438\u0430\u043f\u0430\u0437\u043e\u043d\u044b \u044d\u043b\u0435\u043c\u0435\u043d\u0442\u043e\u0432 \u0432 \u043f\u043e\u0437\u0438\u0446\u0438\u043e\u043d\u0438\u0440\u0443\u044e\u0449\u0438\u0445 \u043c\u0430\u0441\u0441\u0438\u0432\u0430\u0445; \u0432\u044b\u044f\u0432\u043b\u0435\u043d\u0438\u0435\u043c \u0438\u0437\u043e\u0442\u043e\u043f\u043d\u044b\u0445 \u0443\u0440\u043e\u0432\u043d\u0435\u0439 \u0434\u043b\u044f \u0444\u0440\u0430\u0433\u043c\u0435\u043d\u0442\u043e\u0432 \u0438\u0437\u043e\u0431\u0440\u0430\u0436\u0435\u043d\u0438\u0439; \u0438\u0441\u043a\u043b\u044e\u0447\u0435\u043d\u0438\u0435\u043c \u0438\u0437 \u043e\u0431\u0440\u0430\u0431\u043e\u0442\u043a\u0438 \u0438\u0437\u043e\u0442\u043e\u043f\u043d\u043e\u0433\u043e \u0443\u0440\u043e\u0432\u043d\u044f, \u0441\u043e\u0434\u0435\u0440\u0436\u0430\u0449\u0435\u0433\u043e \u043d\u0430\u0438\u0431\u043e\u043b\u044c\u0448\u0435\u0435 \u043a\u043e\u043b\u0438\u0447\u0435\u0441\u0442\u0432\u043e \u0435\u0434\u0438\u043d\u0438\u0447\u043d\u044b\u0445 \u044d\u043b\u0435\u043c\u0435\u043d\u0442\u043e\u0432.", "num_citations": "1\n", "authors": ["1049"]}
{"title": "Architecture and implementation of the 2D memory with multi-pattern parallel accesses\n", "abstract": " This report presents a novel multi-pattern parallel addressing scheme in two-dimensional (2D) addressing space and the corresponding 2D interleaved memory organization with run-time reconfiguration features. The proposed architecture targets mainly multimedia and scientific applications with block cyclic data organization running on computing systems with high memory bandwidth demands, such as vector processors, multimedia accelerators, etc. The prior research on 2D addressing schemes is substantially extended introducing additional parameters, which define a large variety of 2D data patterns. The proposed scheme guarantees minimum memory latency and efficient bandwidth utilization for arbitrary configuration parameters of the data pattern. The presented mathematical descriptions prove the correctness of the proposed addressing schemes. The design and wire complexities, as well as the critical paths are evaluated using technology independent methodology and confirm the scalability of the memory organization. These theoretical results are confirmed by the synthesis for both ASIC and FPGA technologies. Comparison with the related works shows the advantages of reported addressing scheme. The RTL implementation of the memory organization represents the complete platformindependent IP and can be integrated in any architecture.", "num_citations": "1\n", "authors": ["1049"]}
{"title": "Using Linear Tests for Transient Faults in DRAMs\n", "abstract": " Recent developments in the theory of DRAM fault modeling have identified the space of tests needed to detect all DRAM faults. Tests developed to target transient DRAM faults are very time consuming, as they have a quadratic dependence on the number of tested memory cells. This paper presents techniques to reduce the complexity of these tests. The paper also introduces a reduced test, with linear dependency on the number of cells, that detect all realistic transient faults in DRAMs.", "num_citations": "1\n", "authors": ["1049"]}
{"title": "An extensive survey of microelectronic implants\n", "abstract": " In recent years, biomedical engineering has seen phenomenal technological achievements. A particular sub eld-biomedical, microelectronic implants-has emerged and, in time, gained much momentum. Starting with the implantable pacemaker some 50 years ago, such devices have been increasingly investigated over the last two decades, resulting in a plethora of actual systems of diverse capabilities and for various biomedical applications. However, the special nature of the implant application environment, ie the inside of the human body, poses many stringent design constraints, the two most important being low power consumption and small implant size. These have traditionally limited the design space of implant researchers and developers. Nonetheless, over the last few years, phenomenal advances in microelectronic technology, featuring ultra-lowpower transistors of miniature size, have somewhat relaxed\u00a0\u2026", "num_citations": "1\n", "authors": ["1049"]}
{"title": "A generic digital architecture & compiler for implantable devices\n", "abstract": " A new system-level architecture serving as the digital control/processing core of biomedical, microelectronic implants along with a suitable, new compiler is being proposed. While respecting the traditional design constraints of biomedical-implant design for low power consumption and miniature device size, the architecture shall be generic in nature, ie allowing for different peripheral blocks (sensors, actuators etc.) to be ported for building various application-specific implantable systems. Also importantly, the proposed architecture shall employ various faulttolerance techniques for building highly dependable devices. The edge over the extra cost (in power and size) paid for designing a generic-as opposed to a dedicated-architecture will be given by the recent, rapid advances in CMOS semiconductor technology (small transistor size and low power consumption)-a fact now making specific design choices viable. The new compiler shall provide the means to exploiting this architecture for different application setups and, by design, shall further underpin the dependability and low-power issues.", "num_citations": "1\n", "authors": ["1049"]}
{"title": "SMOKE-speeding up MPEG-4 operational kernels on excalibur\n", "abstract": " This paper presents SMOKE hardware/software software co-design targeting computation intensive appli-(HW/SW) co design exploration of an MPEG-4 decoder on Excalibur. SMOKE\u2019s main goal is to provide a full-featured hardware accelerated MPEG-4 decoder on the Altera Excalibur device providing adequate speed performance. The software part of SMOKE is based upon modi\ufb01ed versions of an open source operating system and codec-Linux and XviD respectively. The SMOKE hardware accelerators are designed using VHDL. The complete HW/SW system is built using the Quartus design environment of Altera and a single make\ufb01le. It is shown that a speedup of 1.29 for the MPEG-4 decoder will be realizable.", "num_citations": "1\n", "authors": ["1049"]}
{"title": "SCISM vs IA-64 tagging: differences/code density effects\n", "abstract": " In this paper we first present two tagging mechanisms; the SCISM and IA-64; thereafter we describe the mapping of IA-64 ISA to a SCISM configuration without changing or reassigning the IA-64 instructions to preserve the original architectural properties. Under this limiting SCISM scenario, opcode re-assignment will improve even more the SCISM performance, it is shown that SCISM tagging will significantly improve (between 21 and 29%) static code density. The results are based on analysis of various SPECINT2000 executables.", "num_citations": "1\n", "authors": ["1049"]}