{"title": "Methods for Generating Auxiliary Data Operations for a Role Based Personalized Business User Workplace\n", "abstract": " Methods for generating auxiliary data operations for a role-based personalized business user workplace based on business processes includes analyzing a work-low of a business process to specify business items as an input or output of a task in the business process; identifying data operations for each one of the business items by examining associated attributes and usage of the business item; categorizing the data operations by associating common data operations to the business items, and attaching specific data operations based on the context of the workflow and use by particular business item instances of the business item; and assigning a user role for access to the business items.", "num_citations": "201\n", "authors": ["1017"]}
{"title": "Dynamically configuring a role-based collaborative space\n", "abstract": " A method for role-based personalization of a collaborative space can include generating a collaborative space utilizing role information for an interacting user that has been defined by an underlying business process model in a workflow. For example, the step of generating a collaborative space can include parsing the workflow to extract a role model, generating a collaborative space domain model from the role model, selecting a plurality of user interface components based upon the role model, organizing the selected user interface components in the collaborative space, and rendering the collaborative space.", "num_citations": "134\n", "authors": ["1017"]}
{"title": "An approach for context-aware service discovery and recommendation\n", "abstract": " Given the large amount of existing services and the diversified needs nowadays, it is time-consuming for end-users to find appropriate services. To help end-users obtain their desired services, context-aware systems provide a promising way to automatically search and recommend services using a user's context. However, existing context-aware techniques have limited support for dynamic adaption to newly added context types (e.g., location, time and activity). Due to the diversity of user's environment, the available context types may change over time. It is challenging to anticipate a complete set of context types while we design a context aware system. In this paper, we propose a context modeling approach which can dynamically handle various context types and values. More specifically, we use ontologies to enhance the meaning of a user's context values and automatically identify the relations among different\u00a0\u2026", "num_citations": "99\n", "authors": ["1017"]}
{"title": "Migration of SOAP-based services to RESTful services\n", "abstract": " Web services are designed to provide rich functionality for organizations and support interoperable interactions over a network. Web services are mainly realized in two ways: 1) SOAP-based services and 2) RESTful services. For the service providers, RESTful services can improve system flexibility, scalability, and performance as compared to the SOAP-based Web services. It is equally attractive to end users as it is consume less resources (i.e., battery, processor speed, and memory). Additionally, REST-based services do not include complex standards and heterogeneous operations; and hence are easier to consume and compose as compared to SOAP-based Web services. We provide an approach to migrate SOAP-based services to RESTful services. We identify resources from a SOAP-based Web service by analyzing its service description and mapping the contained operations to resources and HTTP\u00a0\u2026", "num_citations": "86\n", "authors": ["1017"]}
{"title": "Towards cloud-based analytics-as-a-service (claaas) for big data analytics in the cloud\n", "abstract": " Data Analytics has proven its importance in knowledge discovery and decision support in different data and application domains. Big data analytics poses a serious challenge in terms of the necessary hardware and software resources. The cloud technology today offers a promising solution to this challenge by enabling ubiquitous and scalable provisioning of the computing resources. However, there are further challenges that remain to be addressed such as the availability of the required analytic software for various application domains, estimation and subscription of necessary resources for the analytic job or workflow, management of data in the cloud, and design, verification and execution of analytic workflows. We present a taxonomy for analytic workflow systems to highlight the important features in existing systems. Based on the taxonomy and a study of the existing analytic software and systems, we propose\u00a0\u2026", "num_citations": "70\n", "authors": ["1017"]}
{"title": "Supporting change impact analysis for service oriented business applications\n", "abstract": " Business applications encode various business processes within an organization. Business process specification languages such as BPEL (Business Process Execution Language) are commonly used to integrate various services in order to automate business processes within an organization. To remain competitive edge, managers frequently modify their processes. Determining the cost of modifying a business process is not trivial since the changes to the business process have to account for source code changes in various services. In this paper, we propose an approach to estimating the cost of a business process change in a service oriented business application. The approach applies change impact analysis techniques to business process specifications, and source code. The approach generates an initial change impact set from business process components. These components are then mapped to the\u00a0\u2026", "num_citations": "61\n", "authors": ["1017"]}
{"title": "An approach for extracting workflows from e-commerce applications\n", "abstract": " For many enterprises, reacting to fast changes to their business process is key to maintaining their competitive edge in the market. However, developers often must manually locate and modify business logics in source code, in order to meet new requirements. This situation has caused system maintenance costs to escalate while budgets and corporate spending shrink. In this paper, we propose an automatic approach that recovers business processes from source code and refines them using control structure information in as-specified workflows (a workflow is a computerized representation of a business process). By using the as-specified workflows to guide our recovery, we can limit the search scope for business logics in the source code and we can locate explicit associations between artifacts in the as-specified and as-implemented workflows. Our case studies illustrate the effectiveness of this structural based\u00a0\u2026", "num_citations": "61\n", "authors": ["1017"]}
{"title": "Detecting android malware using clone detection\n", "abstract": " Android is currently one of the most popular smartphone operating systems. However, Android has the largest share of global mobile malware and significant public attention has been brought to the security issues of Android. In this paper, we investigate the use of a clone detector to identify known Android malware. We collect a set of Android applications known to contain malware and a set of benign applications. We extract the Java source code from the binary code of the applications and use NiCad, a near-miss clone detector, to find the classes of clones in a small subset of the malicious applications. We then use these clone classes as a signature to find similar source files in the rest of the malicious applications. The benign collection is used as a control group. In our evaluation, we successfully decompile more than 1 000 malicious apps in 19 malware families. Our results show that using a small\u00a0\u2026", "num_citations": "59\n", "authors": ["1017"]}
{"title": "Enhancing source-based clone detection using intermediate representation\n", "abstract": " Detecting software clones in large scale projects helps improve the maintainability of large code bases. The source code representation (e.g., Java or C files) of a software system has traditionally been used for clone detection. In this paper, we propose a technique that transforms the source code to an intermediate representation, and then reuses established source-based clone detection techniques to detect clones in the intermediate representation. The clones are mapped back to the source code and are used to augment the results reported by source-based clone detection. We demonstrate the performance of our new technique using systems from the Bellon clone evaluation benchmark. The result shows that our technique can detect Type 3 clones. Our technique has higher recall with minimal drop in precision using Bellon corpus. By examining the complete clone groups, our technique has higher precision\u00a0\u2026", "num_citations": "53\n", "authors": ["1017"]}
{"title": "An approach for mining web service composition patterns from execution logs\n", "abstract": " A service-oriented application is composed of multiple web services to fulfill complex functionality that cannot be provided by individual web service. The combination of services is not random. In many cases, a set of services are repetitively used together in various applications. We treat such a set of services as a service composition pattern. The quality of the patterns is desirable due to the extensive uses and testing in the large number of applications. Therefore, the service composition patterns record the best practices in designing and developing reliable service-oriented applications. The execution log tracks the execution of services in a service-oriented application. To document the service composition patterns, we propose an approach that automatically identifies service composition patterns from various applications using execution logs. We locate a set of associated services using Apriori algorithm and\u00a0\u2026", "num_citations": "48\n", "authors": ["1017"]}
{"title": "Improving the usability of e-commerce applications using business processes\n", "abstract": " E-commerce applications automate many daily business activities. Users interact with e-commerce applications through menu-driven User Interface (Ul) components such as toolbars, dialogs, and windows. However, the tremendous number of functionalities may overwhelm the users. Users struggle to locate the appropriate Ul components to accomplish the tasks required by business processes. In this paper, we enhance e-commerce applications by improving their usability using the knowledge embedded in business process definitions. Our improved application provides contextual information to fulfill each business task. The improved application guides users through the various tasks in a step-by-step fashion. Through a controlled experiment, we demonstrate that our improved application offers a better usability experience for novice users by giving them more guidance and reducing the time needed to locate\u00a0\u2026", "num_citations": "45\n", "authors": ["1017"]}
{"title": "A compound control method based on the adaptive neural network and sliding mode control for inertial stable platform\n", "abstract": " To improve the control performance of the inertial stable platform (ISP), a compound control method based on the adaptive neural network and sliding mode control method is proposed to deal with the system model uncertainties and the disturbances. A sliding mode control is designed for the ISP system to achieve the initial stability. Moreover, an adaptive neural network is proposed to approximate the system uncertainties and unknown disturbances to argument the control performance. Based on the current state error information, the weight matrix of adaptive neural network can be updated on line. Therefore, the adaptive neural network can be constructed directly without priori training. The applicability of the proposed method is validated by a series of simulations and flight tests. The control method can improve the attitude stabilization accuracy of payloads effectively during the flight process.", "num_citations": "40\n", "authors": ["1017"]}
{"title": "A framework for verifying sla compliance in composed services\n", "abstract": " Service level agreements (SLAs) impose many non-functional requirements on services. Business analysts specify and check these requirements in business process models using tools such as IBM WebSphere Business Modeler. System integrators on the other hand use service composition tools such as IBM WebSphere Integration Developer to create service composition models, which specify the integration of services. However, system integrators rarely verify SLA compliance in their proposed composition designs. Instead, SLA compliance is verified after the composed services are deployed in the field. To improve the quality of the composed services, we propose a framework to verify SLA compliance in composed services at design time. The framework re-uses information in business process models to simulate services and verify the non-functional requirements before the service deployment. To\u00a0\u2026", "num_citations": "31\n", "authors": ["1017"]}
{"title": "An automatic approach for ontology-driven service composition\n", "abstract": " Current service composition techniques and tools are mainly designed for use by service oriented architecture (SOA) professionals to solve business problems. This focus on SOA professionals creates challenges for the non-expert users, with limited SOA knowledge, who try to integrate SOA solutions into their online experience. To shelter non-expert users from the complexity of service composition, we propose an approach which automatically composes a service on the fly to meet the situational needs of a user. We present a tag-based service description schema which allows non-expert users to easily understand the description of services and add their own descriptions using descriptive tags. Instead of specifying the detailed steps for composing a service, a non-expert user would specify the goal of their desired activities using a set of keywords then our approach can automatically identify the relevant\u00a0\u2026", "num_citations": "30\n", "authors": ["1017"]}
{"title": "Too many user-reviews, what should app developers look at first?\n", "abstract": " Due to the rapid growth in the number of mobile applications (apps) in the past few years, succeeding in mobile app markets has become ruthless. Online app markets, such as Google Play Store, let users rate apps on a five-star scale and leave feedback. Given the importance of high star-ratings to the success of an app, it is crucial to help developers find the key topics of user-reviews that are significantly related to star-ratings of a given category. Having considered the key topics of user-reviews, app developers can narrow down their effort to the user-reviews that matter to be addressed for receiving higher star-ratings. We study 4,193,549 user-reviews of 623 Android apps that were collected from Google Play Store in ten different categories. The results show that few key topics commonly exist across categories, and each category has a specific set of key topics. We also evaluated the identified key topics with\u00a0\u2026", "num_citations": "28\n", "authors": ["1017"]}
{"title": "An approach for mining service composition patterns from execution logs\n", "abstract": " A service\u2010oriented application is composed of multiple Web services to fulfill complex functionality that cannot be provided by individual Web service. The combination of services is not random. In many cases, a set of services are repetitively used together in various applications. We treat such a set of services as a service composition pattern. The quality of the patterns is desirable because of the extensive uses and testing in the large number of applications. Therefore, the service composition patterns record the best practices in designing and developing reliable service\u2010oriented applications. The execution log tracks the execution of services in a service\u2010oriented application. To document the service composition patterns, we propose an approach that automatically identifies service composition patterns from various applications using execution logs. We locate a set of associated services using Apriori algorithm\u00a0\u2026", "num_citations": "25\n", "authors": ["1017"]}
{"title": "Detecting clones in business applications\n", "abstract": " A business application automates a collection of business processes. A business process describes how a set of logically related tasks are executed, ordered and managed by following business rules to achieve business objectives. An online bookstore business application contains several tasks such as buying a book, ordering a book, and sending out promotions. Business analysts specify business tasks and software developers implement these tasks. Throughout the lifetime of a business application, business analysts may clone (e.g., copy and slightly modify) business processes to handle special circumstances or promotions. Identifying these clones and removing them helps improve the efficiency of an organization. However most clone detection techniques are source code based not business process based. In this paper, we propose an approach that makes use of traditional source code detection\u00a0\u2026", "num_citations": "25\n", "authors": ["1017"]}
{"title": "Ontology-driven service composition for end-users\n", "abstract": " Current service composition techniques and tools are mainly designed for use by Service-Oriented Architecture (SOA) professionals to solve business problems. Little attention has been paid to allowing end-users without sufficient service composition skills to compose services and integrate SOA solutions into their online experience to fulfill their daily activities. To shelter end-users from the complexity of service composition, we propose an approach which can compose services on the fly to meet the situational needs of end-users. We present a tag-based service description schema which allows non-IT professional users to easily understand the description of services and add their own descriptions using descriptive tags. Instead of requiring end-users to specify detailed steps for composition, the end-users only need to describe their goals using a few keywords. Our approach expands the meaning of a\u00a0\u2026", "num_citations": "24\n", "authors": ["1017"]}
{"title": "Recovering business processes from business applications\n", "abstract": " A business process, such as the process followed when ordering a book, describes the order of executing tasks (e.g., check inventory, verify credit card, and ship book). Business applications implement the business processes for the daily operations of an organization. Organizations must continuously modify their business applications to accommodate changes to business processes. However, business applications are often designed and developed without referring to the documented definitions of business processes. Modifying business applications is a time\u2010consuming and error\u2010prone task. To correctly perform this task, developers require an in\u2010depth understanding of multi\u2010tiered applications and the definitions of the business processes that they implement. In this paper, we present an approach that automatically recovers business process definitions from multi\u2010tiered business applications. Given the\u00a0\u2026", "num_citations": "24\n", "authors": ["1017"]}
{"title": "Recovering workflows from multi tiered e-commerce systems\n", "abstract": " A workflow is a computerized specification of a business process. A workflow describes how tasks are executed and ordered following business policies. E-commerce systems implement the workflows of the daily operations of an organization. Organizations must continuously modify their e-commerce systems in order to accommodate workflow changes. However, e-commerce systems are often designed and developed without referring to the workflows. Modifying e-commerce systems is a time consuming and error prone task. In order to correctly perform this task, developers require an in-depth understanding of multi tiered e-commerce systems and the workflows that they implement. In this paper, we present an approach which automatically recovers workflows from three tier e-commerce systems. Given the starting UI page of a particular workflow, the approach traces the flow of control throughout the different\u00a0\u2026", "num_citations": "24\n", "authors": ["1017"]}
{"title": "Latest advances in soft X-ray spectromicroscopy at SSRF\n", "abstract": " The BL08U1 A beamline is established as a sophisticated platform at Shanghai Synchrotron Radiation Facility (SSRF), taking advantage of its high spatial resolution (30 nm) and high energy resolving power (10 000), for studying properties of solid, liquid, gas, film and other forms of materials at sub-micron scale. In this paper, we present a review on newly implemented techniques, such as total electron yield (TEY), dual energy contrast imaging, nano-CT, soft X-ray excited optical luminance (SXEOL), and coherent diffraction imaging (CDI) under development. Several research cases in nanomaterials, environmental science and biology are presented to demonstrate capabilities of the beamline.", "num_citations": "23\n", "authors": ["1017"]}
{"title": "A business-process-driven approach for generating e-commerce user interfaces\n", "abstract": " A business process contains a set of interdependent activities that describe operations provided by an organization. E-commerce applications are designed to automate business processes. A business process specification (i.e., a workflow) is defined by a business analyst from the viewpoint of the end-users. The process encapsulates the knowledge related to the natural work rhythms that a business user would follow when using an e-commerce application. In this paper, we analyze the information embedded in business process specifications, and infer the functional and usability requirements. We use the inferred information in a model-driven approach to automatically generate user interfaces (UIs) from a business process specification through a set of transformations. To improve the usability of UIs for the e-commerce applications, each transformation is guided by usability principles.", "num_citations": "23\n", "authors": ["1017"]}
{"title": "Are tweets useful in the bug fixing process? An empirical study on Firefox and Chrome\n", "abstract": " When encountering an issue, technical users (e.g., developers) usually file the issue report to the issue tracking systems. But non-technical end-users are more likely to express their opinions on social network platforms, such as Twitter. For software systems (e.g., Firefox and Chrome) that have a high exposure to millions of non-technical end-users, it is important to monitor and solve issues observed by a large user base. The widely used micro-blogging site (i.e., Twitter) has millions of active users. Therefore, it can provide instant feedback on products to the developers. In this paper, we investigate whether social networks (i.e., Twitter) can improve the bug fixing process by analyzing the short messages posted by end-users on Twitter (i.e., tweets). We propose an approach to remove noisy tweets, and map the remaining tweets to bug reports. We conduct an empirical study to investigate the usefulness of\u00a0\u2026", "num_citations": "19\n", "authors": ["1017"]}
{"title": "A business process explorer: recovering and visualizing e-commerce business processes\n", "abstract": " A business process is composed of a set of interrelated tasks which are joined together by control flow elements. E-commerce systems implement business processes to automate the daily operations of an organization. Organizations must continuously modify their e-commerce systems to accommodate changes to business processes. However, modifying e-commerce systems is a time consuming and error prone task. To correctly perform this task, developers require an in-depth understanding of multi-tiered e-commerce systems and the business processes that they implement. In this paper, we present a business process explorer tool which automatically recovers business processes from three tier e-commerce systems. Developers can explore the recovered business processes and browse the corresponding source code. We integrate our tool with IBM WebSphere Business Modeler (WBM), a leading\u00a0\u2026", "num_citations": "19\n", "authors": ["1017"]}
{"title": "Incremental transformation of procedural systems to object oriented platforms\n", "abstract": " Over the past years, the reengineering of legacy software systems to object oriented platforms has received significant attention. In this paper, we present a generic re-engineering source code transformation framework to support the incremental migration of such procedural legacy systems to object oriented platforms. First, a source code representation framework that uses a generic domain model for procedural languages allows for the representation of abstract syntax trees as XML documents. Second, a set of transformations allow for the identification of object models in specific parts of the legacy source code. In this way, the migration process is applied incrementally on different parts of the system. A clustering technique is used to decompose a program into a set of smaller components that are suitable for the incremental migration process. Finally, the migration process gradually composes the object models\u00a0\u2026", "num_citations": "19\n", "authors": ["1017"]}
{"title": "Research on image steganography analysis based on deep learning\n", "abstract": " Although steganalysis has developed rapidly in recent years, it still faces many difficulties and challenges. Based on the theory of in-depth learning method and image-based general steganalysis, this paper makes a deep study of the hot and difficult problem of steganalysis feature expression, and tries to establish a new steganalysis paradigm from the idea of feature learning. The main contributions of this paper are as follows: 1. An innovative steganalysis paradigm based on in-depth learning is proposed. Based on the representative deep learning method CNN, the model is designed and adjusted according to the characteristics of steganalysis, which makes the proposed model more effective in capturing the statistical characteristics such as neighborhood correlation. 2. A steganalysis feature learning method based on global information constraints is proposed. Based on the previous research of steganalysis\u00a0\u2026", "num_citations": "17\n", "authors": ["1017"]}
{"title": "Towards prioritizing user-related issue reports of mobile applications\n", "abstract": " The competitive market of mobile applications (apps) has driven app developers to pay more attention to addressing the issues of mobile apps. Prior studies have shown that addressing the issues that are reported in user-reviews shares a statistically significant relationship with star-ratings. However, despite the prevalence and importance of user-reviews and issue reports prioritization, no prior research has analyzed the relationship between issue reports prioritization and star-ratings. In this paper, we integrate user-reviews into the process of issue reports prioritization. We propose an approach to map issue reports that are recorded in issue tracking systems to user-reviews. Through an empirical study of 326 open-source Android apps, our approach achieves a precision of 79% in matching user-reviews with issue reports. Moreover, we observe that prioritizing the issue reports that are related to user\u00a0\u2026", "num_citations": "15\n", "authors": ["1017"]}
{"title": "Automatically composing services by mining process knowledge from the web\n", "abstract": " Current approaches in Service-Oriented Architecture (SOA) are challenging for users to get involved in the service composition due to the in-depth knowledge required for SOA standards and techniques. To shield users from the complexity of SOA standards, we automatically generate composed services for end-users using process knowledge available in the Web. Our approach uses natural language processing techniques to extract tasks. Our approach automatically identifies services required to accomplish the tasks. We represent the extracted tasks in a task model to find the services and then generate a user interface (UI) for a user to perform the tasks. Our case study shows that our approach can extract the tasks from how-to instructions Web pages with high precision (i.e., 90%). The generated task model helps to discover services and compose the found services to perform a task. Our case study\u00a0\u2026", "num_citations": "15\n", "authors": ["1017"]}
{"title": "Quality driven software migration of procedural code to object-oriented design\n", "abstract": " In the context of software maintenance, legacy software systems are continuously re-engineered in order to correct errors, provide new functionality, or port them into modern platforms. However, software re-engineering activities should not occur in a vacuum, and it is important to incorporate non-functional requirements as part of the re-engineering process. We present an incremental reengineering framework that allows for quality requirements to be modeled as soft-goals, and transformations to be applied selectively towards achieving specific quality requirements for the target system. To deal with large software systems, we decompose the system into a collection of smaller clusters. The reengineering framework can be applied incrementally to each of these clusters and results are assembled to produce the final system.", "num_citations": "15\n", "authors": ["1017"]}
{"title": "A technique for just-in-time clone detection in large scale systems\n", "abstract": " Existing clone tracking tools have limited support for sharing clone information between developers in a large scale system. Developers are not notified when new clones are introduced by other developers or when existing clones are modified. We propose a client-server architecture that centrally detects and maintains clone information for an entire software system stored in a version control system. Clients retrieve a list of clones relevant to the code they are working on from the server. Whenever an update is committed to the version control system, the server detects and incrementally updates clone information. We propose techniques to improve the speed of the incremental clone detection. In order to reduce the number of comparisons required for clone detection, we select representative clones from the existing clone list. We build a string-based technique to compare the newly committed code with the\u00a0\u2026", "num_citations": "14\n", "authors": ["1017"]}
{"title": "reengineering user interfaces of E-Commerce applications using business processes\n", "abstract": " E-commerce applications are designed to streamline the business processes for an organization. Graphical user interfaces allow business users to perform daily business activities by interacting with e-commerce applications through menu-driven user interface components, such as toolbars and dialog windows. However, business users are often overwhelmed by the enormous functionality available. Users struggle in deciding where to start and where to go next in order to accomplish tasks required by business processes. In this paper, we utilize the knowledge embedded in business processes to reengineer the user interfaces of existing e-commerce applications that implement business processes. We aim to improve the usability of user interfaces by providing contextual information and guiding users to fulfil business processes step by step. We evaluate our proposed approach by reengineering the user\u00a0\u2026", "num_citations": "14\n", "authors": ["1017"]}
{"title": "Automatically learning user preferences for personalized service composition\n", "abstract": " With the rapid growth of the web services technologies, users often leverage various web services to perform their daily activities, such as on-line shopping. Due to the massive amount of web services available, a user faces numerous choices to meet their personal preferences when selecting the desired services from the web services with the similar functionality. Therefore, it becomes tedious and cumbersome tasks for users to discover and compose services. To reduce user's cognitive burden, it is critical to support automated service composition and make efficient recommendation of personalized services to achieve user's overall goals. However, existing approaches only offer users with limited options designed for the interest of a group of users without considering individual users' interests. To allow users to compose personalized services without much manual specification, we propose a machine learning\u00a0\u2026", "num_citations": "13\n", "authors": ["1017"]}
{"title": "An intelligent framework for auto-filling web forms from different web applications\n", "abstract": " Nowadays, people use on-line services to conduct various tasks such as on-line shopping and holiday trip planning using web applications. Generally users are required to enter information into web forms to interact with the web applications. However they often have to type in the same information to different web applications repetitively. It could be a tedious job for a user to fill in a large amount of web forms with the same information. To save users from typing redundant information, it is critical to propagate and pre-fill the user's previous inputs across different web applications. However, existing software and approaches cannot meet this urgent need. In this position paper, we propose an intelligent framework to propagate user's inputs across different web applications. Our framework collects user's inputs and analyzes the patterns of user's usage. Furthermore it detects the changes of user's contexts by extracting\u00a0\u2026", "num_citations": "13\n", "authors": ["1017"]}
{"title": "A business process\u2010driven approach for generating software modules\n", "abstract": " Business processes describe the business operations of an organization and capture the business requirements. Business applications provide automated support for an organization to achieve their business objectives. A software modular structure represents the structure of a business application and shows the distribution of functionality to software components. However, mainstream design approaches rely on software architects' craftsmanship to derive software modular structures from business requirements. Such a manual approach is inefficient and often leads to inconsistency between business requirements and business applications. To address this problem, we propose an approach to derive software modular structures from business processes. We use clustering algorithms to analyze dependencies among data and tasks captured in business processes and group the strongly dependent tasks and\u00a0\u2026", "num_citations": "13\n", "authors": ["1017"]}
{"title": "Verifying business processes extracted from E-commerce systems using dynamic analysis\n", "abstract": " E-commerce systems must react in real-time to user inputs and business rules. For the purpose of redocumentation, static analysis is often adopted to recover business processes implemented in ecommerce systems. However, static analysis fails to recover the complete tasks in business processes due to the dynamic nature of e-commerce systems. To improve the accuracy of recovered business processes, we devise dynamic analysis techniques which trace the execution of processes. We recover usage scenarios from the execution logs and use them to verify the business processes recovered using static analysis. We verify the effectiveness of our proposed approach through a case study on OFBiz e-commerce applications.", "num_citations": "13\n", "authors": ["1017"]}
{"title": "Extracting business processes from three-tier architecture systems\n", "abstract": " To minimize the overall expense and to reduce time to market, organizations either modify existing source code to meet the new requirements, or reuse existing components in new systems. Unfortunately, many software systems never have up-to-date documentation. Absence of good documentation increases the challenges for maintenance because the developers must read through the source code to understand the behaviors of the systems and to locate business logics manually. In this paper, we proposed an automatic method to generate the business processes for the three-tier architecture systems by identifying the business data and business policies in the source code.", "num_citations": "13\n", "authors": ["1017"]}
{"title": "An empirical study on the teams structures in social coding using GitHub projects\n", "abstract": " Social coding enables collaborative software development in virtual and distributed communities. Social coding platforms (e.g., GitHub) provide the pull request feature that allows developers to clone a project, make code changes, and request the project owners to review and integrate the code changes to the main stream of a project. The pull request feature has been widely adopted by a large number of GitHub projects, as it minimizes the risk of exposing the projects to the open communities. The efficiency of the pull requests review process depends both on technical (e.g., the code quality) and social (e.g., the connection of a contributor to the project maintainer) factors. However, it is still unclear which social factors have the most impact on the efficiency of the review process. To identify the social factors, we study the team structures formed by the developers within the projects that adopt the pull-based\u00a0\u2026", "num_citations": "12\n", "authors": ["1017"]}
{"title": "Design of an ultrahigh-energy-resolution and wide-energy-range soft X-ray beamline\n", "abstract": " A new ultrahigh-energy-resolution and wide-energy-range soft X-ray beamline has been designed and is under construction at the Shanghai Synchrotron Radiation Facility. The beamline has two branches: one dedicated to angle-resolved photoemission spectroscopy (ARPES) and the other to photoelectron emission microscopy (PEEM). The two branches share the same plane-grating monochromator, which is equipped with four variable-line-spacing gratings and covers the 20\u20132000\u2005eV energy range. Two elliptically polarized undulators are employed to provide photons with variable polarization, linear in every inclination and circular. The expected energy resolution is approximately 10\u2005meV at 1000\u2005eV with a flux of more than 3 \u00d7 1010\u2005photons\u2005s\u22121 at the ARPES sample positions. The refocusing of both branches is based on Kirkpatrick\u2013Baez pairs. The expected spot sizes when using a 10\u2005\u00b5m exit slit are\u00a0\u2026", "num_citations": "12\n", "authors": ["1017"]}
{"title": "A framework for exacting workflows from e-commerce systems\n", "abstract": " For many organizations, reacting to fast changes in customers\u2019 requirements becomes keys to maintain the competitive edge in the market. However, developers must locate business logics manually in source code in order to add new requirements. This problem has caused maintenance costs to escalate while budgets and the corporate spending are shrinking. In this paper, we propose an automatic approach that extracts workflows from sources code and utilizes control structure information in as-specified workflows to refine the recovered as-implemented workflows from source code. By using the as-specified workflows to guide our extraction, we can limit the searching scope for business logics and locate explicit associations between artifacts in the as-specified and as-implemented workflows.", "num_citations": "12\n", "authors": ["1017"]}
{"title": "Mining user intents to compose services for end-users\n", "abstract": " End-users repetitively perform various on-line tasks and invoke multiple web services for their re-occurring activities, such as planning a trip. Usually, end-users have to complete different tasks in order to achieve a goal, and look through large volumes of services to find the best ones that satisfy their constraints, such as a budget limit. Current approaches on service composition require programming skills and domain knowledge to accomplish goals. Moreover, existing approaches lack an automatic way to analyze end-users' goals and extract relevant tasks for achieving goals. In this paper, we provide a lightweight service composition framework for end-users with limited technical background. Our framework analyzes endusers' goals expressed in natural languages to mine tasks (e.g., plan a trip) and non-functional constraints (e.g., budget <; 500). Our framework extracts task models from textual descriptions of\u00a0\u2026", "num_citations": "11\n", "authors": ["1017"]}
{"title": "Techniques and Methodologies for the Migration of Legacy Systems to Object Oriented Platforms\n", "abstract": " Over the past years it has become evident that the benefits of object orientation warrant the design and development of reengineering methods that aim to migrate legacy procedural systems to modern object oriented platforms. However, most of the research in this direction focuses on the extraction of an object model from the legacy procedural code without taking into account quality requirements for the target migrant system.This thesis presents a reengineering framework that allows for quality requirements of the target system to be modelled as soft-goals, and transformations to be applied selectively towards achieving specific quality requirements for the target system. In this context, the migration process is denoted by a sequence of transformations each one of which alters the state of the system being migrated. A state transition system and the Viterbi algorithm are used to identify the optimal sequence of transformations that can be applied at any given state of the migration process. The reengineering framework can be applied incrementally after a large system has been decomposed into a collection of work areas. Furthermore, a technique that allows for the integration of the migrant systems with other third party applications in a Web enabled environment is presented. A reengineering toolkit to automatically migrate a set of open source procedural systems, such as Apache, Bash and Clips to an object oriented platform has been developed using the theory presented in this thesis. The obtained results demonstrate the effectiveness and usefulness of the proposed incremental quality driven migration technique.", "num_citations": "10\n", "authors": ["1017"]}
{"title": "Developing an adaptive user interface in eclipse\n", "abstract": " The usability of user interfaces is often neglected in the design and development of software applications. The Eclipse Integrated Development Environment (IDE) is especially prone to poor usability problems due to the rich functionality introduced by the additions of external plug-ins and Eclipse\u2019s board target user base (from novice to expert developers). To improve the usability of Eclipse\u2019s user interface, we propose an Adaptive User Interface (AUI) architecture which modifies the existing Eclipse menu system based on statistical user interaction patterns with the user interface. Specifically, the AUI hides infrequently used menu elements, and predicts the next menu elements that a user is likely to click. Moreover, we develop adaptive algorithms that perform a cost-benefit analysis for making modifications to the menus system, and determine the optimal changes to make. A prototype AUI is developed as an Eclipse plug-in. Through an initial case study, we demonstrate the enhancement to the current Eclipse menu system using our Adaptive User Interface.", "num_citations": "9\n", "authors": ["1017"]}
{"title": "Proceedings\n", "abstract": " Biblioteca Conmemorativa Orton (IICA / CATIE) Cat\u00e1logo ORTON B\u00fasqueda general: Formato: Cantidad a desplegar: Orden ascendente: Texto completo: B\u00fasqueda por diccionario: Cantidad a desplegar: Alianza SIDALC 1 / 1 Seleccione referencia / Select reference Signatura: 634.95620631 I61 1980 Corporativo: Canadian Forestry Service, Ontario (Canad\u00e1) Autor: Wang, BSP; Pitel, JA Conferencia: International Symposium on Forest Tree Seed Storage. Chalk River, Ontario (Canad\u00e1). 23-27 Set 1980. T\u00edtulo: Proceedings. ISBN: 0662120620 Idioma: EN P.imprenta: Ontario (Canad\u00e1). CFS. 1982. 243 p. Notas: Ilus. Tab. Bib. A la cabeza de t\u00edtulo: IUFRO Working Party on Seed Problems Descriptores_Es: ARBOLES FORESTALES; SEMILLAS; ALMACENAMIENTO DE SEMILLAS; CONTENIDO DE HUMEDAD DE SEMILLAS; ESTRATIFICACION; TRATAMIENTO DE SEMILLAS; GERMINACION; SECADO \u2026", "num_citations": "9\n", "authors": ["1017"]}
{"title": "Towards quality of experience driven service composition\n", "abstract": " Web service composition enables seamless and dynamic integration of applications on the web. Generally a user has to find services, select proper services and form a flow to create a service composition. The performance of the composed application is determined by the performance of the involved Web services. Current work in web service selection and discovery are based on non-functional, quality of service (QoS) aspects (such as, response time and availability). However, QoS information does not reflect an end user's perspective on the quality of services. An end user's perspective of a service is a credible source of information, covers diverse platforms and geographical locations. In this position paper, we provide an approach to extract a user's perception of the quality of services from user reviews on services and use such information to compose services. We provide a mechanism to select a particular\u00a0\u2026", "num_citations": "8\n", "authors": ["1017"]}
{"title": "Study on logistics operation cost control based on the DEA model\n", "abstract": " To solve the problem that the logistics operation cost can't be controlled well by traditional methods, a DEA (data envelopment analysis) model is presented. The mechanism of the model is to make the logistics activities as a decision making unit to evaluate the efficiency of input and output. Base on the DEA result, the efficient logistics activities are reserved, and the inefficient ones are improved by explicit methods and goals. The key procedures of DEA model include establishing a standard logistics activity database, decomposing logistics activities and determining that the logistics is the efficient decision unit. The paper is of great significance to improve operation efficiency of logistics network.", "num_citations": "8\n", "authors": ["1017"]}
{"title": "A framework for automatically supporting end-users in service composition\n", "abstract": " In Service Oriented Architecture (SOA), service composition integrates existing services to fulfill specific tasks using a set of standards and tools. However, current service composition techniques and tools are mainly designed for SOA professionals. It becomes challenging for end-users without sufficient service composition skills to compose services. In this paper, we propose a framework that supports end-users to dynamically compose and personalize services to meet their own context. Instead of requiring end-users to specify detailed steps in the composition, our framework only requires end-users to specify\u00a0the goals of their desired activities using a few keywords to generate a task list.\u00a0\u00a0To organize the task list, we analyze the historical usage data and recover the control flows among the tasks in the task list. We also mine the task usage pattern from the historical usage data to recommend new services\u00a0\u2026", "num_citations": "8\n", "authors": ["1017"]}
{"title": "A business process explorer: Recovering business processes from business applications\n", "abstract": " A business process contains a set of logically related tasks executed to fulfill business goals. Business applications enable organizations to automatically perform their daily operations. Business processes and business applications keep on changing independently due to dynamic business environments. Therefore, business process definitions are rarely up-to-dated to reflect the processes deployed in business applications. This inconsistency creates difficulties for the communications between business analysts and software developers. We present a business process explorer tool which automatically recovers business processes from business applications and refines the process definitions by detecting business task clones which have similar functionality across processes.", "num_citations": "8\n", "authors": ["1017"]}
{"title": "Learning to reuse user inputs in service composition\n", "abstract": " Users visit web services and compose them to accomplish on-line tasks. Normally, users enter the same information into various web services to finish such tasks. However, repetitively typing the same information into services is unnecessary and decreases the service composition efficiency. In this paper, we propose a context-aware ranking approach to recommend previous user inputs into input parameters and save users from repetitive typing. We develop five different ranking features constructed from various types of information, such as user contexts. We adopt a learning-to-rank approach, a machine learning technology automatically constructing the ranking model, and integrate our ranking features into a state-of-the-art learning-to-rank framework. Our approach learns the information of interactions between input parameters and user inputs to reuse user inputs under different contexts. Through an empirical\u00a0\u2026", "num_citations": "7\n", "authors": ["1017"]}
{"title": "A Framework for Incorporating Usability into Model Transformations.\n", "abstract": " The usability of user interfaces is crucial for the success of an application. Model driven user interface (UI) development speeds up the production of UIs and improves the maintainability of UIs. However, the usability evaluation of UIs is usually conducted by end-users or experts after UIs are generated. Such a user centric evaluation is usually time consuming and expensive, especially when the usability problems are detected in the last phase of the software development. In this paper, we propose a framework that incorporates the usability evaluation as an integral part of automatic processes for UI generation. To link the usability goal into the UI generation process, we model the usability using a goal graph for each intermediate UI model and associate the usability goals to the attributes of the models. Our proposed framework detects and addresses usability problems in the early phase of the software development.", "num_citations": "7\n", "authors": ["1017"]}
{"title": "Automated workplace design and reconfiguration for evolving business processes.\n", "abstract": " In this ever-changing business environment, business processes are constantly being customized to reflect the up-to-date organizational structure and business objectives. Furthermore, technological updates and innovation also affect the way business is carried out. A workplace application provides an interactive electronic working environment that integrates software applications to assist users in performing their daily work more efficiently. It is challenging to maintain workplace applications as it often involves laborintensive manual reconfiguration to adapt workplace applications to the changes to business processes. In this paper, we propose a workplace design framework that automatically analyzes business processes and generates workplace applications. Furthermore, it permits workplace reconfiguration at run time, which minimizes the interruption to users\u2019 work and simplifies deployment of business process changes to workplace applications. A prototype workplace application is designed and developed to demonstrate the effectiveness of the proposed framework.", "num_citations": "7\n", "authors": ["1017"]}
{"title": "A new extra-focus monochromator designed for high-performance VUV beamlines\n", "abstract": " A new monochromator called an extra-focus constant-included-angle varied-line-spacing (VLS) cylindrical-grating monochromator (extra-focus CIA-VCGM) is described. This monochromator is based on the Hettrick\u2013Underwood scheme where the plane VLS grating is replaced by a cylindrical one in order to zero the defocus at three reference photon energies in the vacuum-ultraviolet range. It has a simple mechanical structure and a fixed focus spot with high performance over a wide energy range. Furthermore, its mechanical compatibility with a standard VLS plane-grating monochromator allows convenient extension into the soft-X-ray range.", "num_citations": "6\n", "authors": ["1017"]}
{"title": "A framework for automatic generation of evolvable e-commerce workplaces using business processes\n", "abstract": " Business processes encapsulate the knowledge of operations and services provided by organizations. Due to the changing nature of business processes, the design and implementation of e-commerce applications, such as workplace applications, could not be evolved consistently to support changing business requirements. E-commerce workplaces suffer from design and usability problems and may not conform to updated and constantly changing business processes. In this research demonstration, we present a framework that automatically generates business workplaces using workflow specifications. The generated workplaces can easily adapt to the changing business needs and reflect better the interaction within complex business processes in organizations.", "num_citations": "6\n", "authors": ["1017"]}
{"title": "Local versus global models for effort-aware defect prediction\n", "abstract": " Software entities (eg, files or classes) do not have the same density of defects and therefore do not require the same amount of effort for inspection. With limited resources, it is critical to reveal as many defects as possible. To satisfy such need, effort-aware defect prediction models have been proposed. However, the performance of prediction models is commonly affected by a large amount of possible variability in the training data. Prior studies have inspected whether using a subset of the original training data (ie, local models) could improve the performance of prediction models in the context of defect prediction and effort estimation in comparison with global models (ie, trained on the whole dataset). However, no consensus has been reached and the comparison has not been performed in the context of effort-aware defect prediction. In this study, we compare local and global effort-aware defect prediction models using 15 projects from the widely used AEEEM and PROMISE datasets. We observe that although there is at least one local model that can outperform the global model, there always exists another local model that performs very poorly in all the projects. We further find that the poor performing local model is built on the subset of the training set with a low ratio of defective entities. By excluding such subset of the training set and building a local effort-aware model with the remaining training set, the local model usually underperforms the global model in 11 out of the 15 studied projects. A close inspection on the failure of local effortaware models reveals that the major challenge comes from defective entities with small size (ie, few lines of\u00a0\u2026", "num_citations": "5\n", "authors": ["1017"]}
{"title": "System and method for dynamically configuring user interface components of a collaborative space based on mapping rules and user roles\n", "abstract": " A method for role-based personalization of a collaborative space can include generating a collaborative space utilizing role information for an interacting user that has been defined by an underlying business process model in a workflow. For example, the step of generating a collaborative space can include parsing the workflow to extract a role model, generating a collaborative space domain model from the role model, selecting a plurality of user interface components based upon the role model, organizing the selected user interface components in the collaborative space, and rendering the collaborative space.", "num_citations": "5\n", "authors": ["1017"]}
{"title": "A Business Process Driven Approach for Generating Software Architecture\n", "abstract": " Business processes describe business operations of an organization and capture business requirements. Business applications provide automated support for an organization to achieve business objectives. Software architecture represents the gross structure of a business application and shows the distribution of business requirements among software components. However, mainstream design approaches rely on software architects' craftsmanship to derive software architectures from business requirements. Such a manual approach is inefficient and often leads to inconsistency between business requirements and business applications. To address this problem, we propose an approach to derive software architecture from business processes. We use clustering analysis to analyze dependencies among data and tasks captured in business processes and distribute functionalities to software components. A case\u00a0\u2026", "num_citations": "5\n", "authors": ["1017"]}
{"title": "Adapting the User Interface of Integrated Development Environments (IDEs) for Novice Users.\n", "abstract": " The usability of a user interface is often neglected in the design and development of software applications. An Integrated Development Environment (IDE) is prone to poor usability problems due to the rich functionality offered through its User Interface (UI). Since an IDE targets a wide range of users (from novice to expert users), the usability requirement for an IDE vary considerably. Novice users, such as first year undergraduate students, often have difficulty in understanding many of the features provided in an IDE and have a hard time locating the appropriate menu elements. We propose an Adaptive User Interface (AUI) architecture which provides a simplified UI for the Eclipse IDE. The AUI assists novice users in using complex IDEs. We develop adaptive algorithms that modify the existing menu system for the Eclipse IDE based on statistical user interaction patterns. Our adaptive algorithms perform a cost-benefit analysis when modifying the menu system. The algorithms determine the optimal changes which reduce the time needed by novice users when searching for menu elements. A prototype AUI is developed as an Eclipse plug-in for novice users of the Eclipse IDE. Through an initial case study, we demonstrate the benefits of our AUI in improving the usability of the Eclipse IDE.", "num_citations": "5\n", "authors": ["1017"]}
{"title": "Application of Particle Swarm Optimization based BP neural networks to atmosphere environment assessment of thermal power plants\n", "abstract": " The Particle Swarm Optimization (PSO) algorithm was used to improve the traditional BP neural network, and the assessment model based on the improved BP neural network was established and later applied to atmosphere environment assessment of thermal power plants. The global optimization of PSO and the local accurate searching performance of BP are combined, which effectively prevents the network from falling into local minimum and ensures assessment accuracy. Example calculation shows that the assessment model is both convenient and accurate.", "num_citations": "5\n", "authors": ["1017"]}
{"title": "An empirical study of developer discussions in the gitter platform\n", "abstract": " Developer chatrooms (e.g., the Gitter platform) are gaining popularity as a communication channel among developers. In developer chatrooms, a developer (asker) posts questions and other developers (respondents) respond to the posted questions. The interaction between askers and respondents results in a discussion thread. Recent studies show that developers use chatrooms to inquire about issues, discuss development ideas, and help each other. However, prior work focuses mainly on analyzing individual messages of a chatroom without analyzing the discussion thread in a chatroom. Developer chatroom discussions are context-sensitive, entangled, and include multiple participants that make it hard to accurately identify threads. Therefore, prior work has limited capability to show the interactions among developers within a chatroom by analyzing only individual messages. In this article, we perform an in\u00a0\u2026", "num_citations": "4\n", "authors": ["1017"]}
{"title": "Soft x-ray spectroscopic endstation at beamline 08U1A of Shanghai Synchrotron Radiation Facility\n", "abstract": " A spectroscopic endstation with magnetic field, voltage, and low temperature control has been installed and commissioned at the soft X-ray beamline 08U1A of Shanghai Synchrotron Radiation Facility, which can obtain a magnetic field up to \u00b10.53 T, applied current and bias voltage, and cryogenic temperatures down to 14 K with a Gifford-McMahon cycle cryocooler. The endstation can perform soft X-ray absorption spectroscopy methods including total electron yield, fluorescence yield, and X-ray excited optical luminance. Combined with an elliptically polarized undulator and the in situ conditions, the endstation can effectively perform X-ray magnetic circular and linear dichroism experiments in the soft X-ray range between photon energies of 250 and 2000 eV.", "num_citations": "4\n", "authors": ["1017"]}
{"title": "Design of wide-range energy material beamline at the Shanghai Synchrotron Radiation Facility\n", "abstract": " We report the design of a wide-range energy material beamline (E-line) with multiple experimental techniques at the Shanghai Synchrotron Radiation Facility. The undulators consisted of an elliptically polarizing undulator and in-vacuum undulator that generate the soft and hard X-rays, respectively. The beamline covered a wide energy range from 130 to 18\u00a0keV with both a high photon flux (>\u00a01012\u00a0phs/s with exit silt 30\u00a0\u03bcm in soft X-ray and >\u00a05\u00a0\u00d7\u00a01012\u00a0phs/s in hard X-ray within 0.1%BW bandwidth) and promising resolving power (maximum E/\u2206E\u00a0>\u00a015,000 in soft X-ray with exit silt 30\u00a0\u03bcm and >\u00a06000 in hard X-ray). Moreover, the beam spots from the soft and hard X-rays were focused to the same sample position with a high overlap ratio, so that the surfaces, interfaces, and bulk properties were characterized in situ by changing the probing depth.", "num_citations": "4\n", "authors": ["1017"]}
{"title": "Integrating heterogeneous web services from an end user perspective\n", "abstract": " Service composition combines a set of available Web services using control flows to create a more complex service. The service composition is a complex process which is challenging even for experienced users to discover and select appropriate service among a set of similar services. The available tools and techniques for service composition either are too complicated or require technical knowledge (such as script language). Moreover the heterogeneity in service description language and communication protocols make service composition more difficult. In our research, we propose an approach that allows non-technical users (ie, end users) to easily compose heterogeneous Web resources with different communication protocol. The goal of this research is fulfilled on two stages: 1) identifying integrable Web resources from different Web applications and SOAP-based Web services; and 2) providing\u00a0\u2026", "num_citations": "4\n", "authors": ["1017"]}
{"title": "Comparison of clone detection techniques\n", "abstract": " Many techniques for detecting duplicated source code (software clones) have been proposed in the software reengineering literature. However, comparison of these techniques in terms of performance is not widely studied. There are four general categories for clone detection techniques; textual, lexical, syntactic, and semantic. This report presents an experiment that evaluates different clone detectors based on four Java programs of small to medium size scales. These subject systems have been used in the recent literature, and can be considered as standard systems for this purpose. At least one clone detection tool has been tested for each category. The comparison of different techniques is done based on performance metrics for clone detection tools. The most widely used metrics, precision and recall, have been used to calculate quantitative values for the performance of different techniques so that they can be compared with each other. The reference clones used in the comparison are those in the Bellon corpus. Our goal was to only evaluate systems that were not previously evaluated using Bellon benchmark, and not to replicate the previous works in our main experiment.", "num_citations": "4\n", "authors": ["1017"]}
{"title": "An approach for estimating the time needed to perform code changes in business applications\n", "abstract": " Business applications automate various business processes within an organization. Business analysts frequently modify business processes to maintain a competitive edge. Estimating the time needed to modify a business process is not a trivial task, since changes to the business process result in changes to the source code of which the business analyst has limited knowledge. We propose a change impact metric which estimates the code to be modified as a result of a business process change. We demonstrate the effectiveness of our proposed change impact metric through a case study, using seven large business applications from the OFBiz open source project.", "num_citations": "4\n", "authors": ["1017"]}
{"title": "Weaving business requirements into model transformations\n", "abstract": " Model driven development (MDD) is regarded as a promising software development technique which can reduce the complexity and cost of developing large software systems. In recent years research in MDD has focused on the technical domain where techniques and tools are developed to assist in automatically transforming design models to implementation models. However, little attention has been paid on automatically transforming knowledge embedded in business requirement models (eg, business processes) into generic design models and implementation models. In this paper, we use aspect-oriented modeling (AOM) techniques to help us customize the primary model (eg, design model and implementation model) by weaving different business requirements into it. As a result, we can verify the primary models against the business requirements. Our case study demonstrates the feasibility of our proposed approach.", "num_citations": "4\n", "authors": ["1017"]}
{"title": "Incorporating quality requirements in software migration process\n", "abstract": " The reengineering of legacy software systems to modern object oriented platforms has received significant attention over the past few years. However, most often the reengineering process ignores to take into account specific non-functional requirements, such as maintainability, for the target system. In this paper, we propose a quality driven software migration framework that aims to identify and extract an object model from a procedural system and to generate quality migrant object oriented code which satisfies non-functional requirements. Such a reengineering framework is composed of quality models to denote desired quality characteristics for the target migrant systems, transformation rules and, an incremental and iterative quality-driven transformation process that is based on a state transition system. The process aims to identify a sequence of software transformations that generate a target system with desired\u00a0\u2026", "num_citations": "4\n", "authors": ["1017"]}
{"title": "Research on Human Movement Target Recognition Algorithm in Complex Traffic Environment\n", "abstract": " With the increase in the total population of the society and the continuous increase in the number of trips, the traffic pressures faced by people are increasing. With the development and advancement of computer technology, the emergence of intelligent transportation provides a better way to solve the problem of effectively alleviating traffic pressure and reducing the incidence of traffic accidents. In recent years, intelligent traffic monitoring system, as one of the important branches in the field of intelligent transportation, has also received more and more attention. Among them, video-based moving target recognition technology involves theoretical knowledge in various fields such as artificial intelligence, image processing, pattern recognition and computer vision. It is an important means to realize \u201csafe city\u201d and \u201csmart city\u201d and a key technology for intelligent monitoring. Therefore, the research on human motion target\u00a0\u2026", "num_citations": "3\n", "authors": ["1017"]}
{"title": "Incremental quality driven software migration to object oriented systems\n", "abstract": " In the context of software maintenance, legacy software systems are continuously re-engineered in order to correct errors, provide new functionality, or port them into modern platforms. However, software re-engineering activities should not occur in a vacuum, and it is important to incorporate non-functional requirements as part of the re-engineering process. This work presents an incremental reengineering framework that allows for quality requirements to be modeled as soft-goals, and transformations to be applied selectively towards achieving specific quality requirements for the target system. Moreover, to deal with large software systems, a system can be decomposed into a collection of smaller clusters. The reengineering framework can be applied incrementally to each of these clusters and results are assembled to produce the final system. Using the theory presented We developed a reengineering toolkit to\u00a0\u2026", "num_citations": "3\n", "authors": ["1017"]}
{"title": "1116: Improved Stone Comminution and Simultaneously Reduced Tissue Injury with an Upgraded Electrohydraulic Lithotripter: in Vivo Studies\n", "abstract": " CONCLUSIONS: I) Pretreatment of the renal pole with 500 low-energy SWs greatly reduces the hemorrhagic injury to that pole normally caused by 2000 high-energy SWs, 2) The threshold for the protective effect seems to be less than 100 SWs, and 3) SW-induced renal vasoconstriction may mediate the protection since SWL-induced injury occurred during forced renal vasodilation induced by dopamine.", "num_citations": "3\n", "authors": ["1017"]}
{"title": "Predicting Performance Anomalies in Software Systems at Run-time\n", "abstract": " High performance is a critical factor to achieve and maintain the success of a software system. Performance anomalies represent the performance degradation issues (e.g., slowing down in system response times) of software systems at run-time. Performance anomalies can cause a dramatically negative impact on users\u2019 satisfaction. Prior studies propose different approaches to detect anomalies by analyzing execution logs and resource utilization metrics after the anomalies have happened. However, the prior detection approaches cannot predict the anomalies ahead of time; such limitation causes an inevitable delay in taking corrective actions to prevent performance anomalies from happening. We propose an approach that can predict performance anomalies in software systems and raise anomaly warnings in advance. Our approach uses a Long-Short Term Memory neural network to capture the normal\u00a0\u2026", "num_citations": "2\n", "authors": ["1017"]}
{"title": "Context-aware service input ranking by learning from historical information\n", "abstract": " Users visit on-line services and compose them to accomplish on-line tasks, such as shopping on-line. Quite often, users enter the same information into various on-line services to finish on-line tasks. However, repetitively typing the same information into web forms is a tedious job for users. In this paper, we propose a context-aware ranking framework to rank values for input parameters. We propose 6 categories of ranking features constructed from various types of information, such as user contexts and patterns of user inputs. Our framework adopts learning-to-rank (LtR) algorithms that consist of a set of machine learned models to automatically construct ranking models by integrating the ranking features. When a user enters a value to an input parameter, an interaction between the user input and the input parameter is established. Our framework learns information relevant to such interactions and ranks user inputs\u00a0\u2026", "num_citations": "2\n", "authors": ["1017"]}
{"title": "A personalized assistant framework for service recommendation\n", "abstract": " The popularity of service-oriented computing makes more and more services available on the Web. Users make use of these services to achieve their personal goals, such as purchasing movie tickets on-line and booking flights. Existing research has proposed various techniques to assist users to select services for achieving user goals. Typically, user choice of services change under different contexts. However, these approaches cannot recommend the desired services based on the changes of user contexts, and are not able to learn from user service selection history. In this paper, we provide an intellectually cognitive personalized assistant framework to achieve user goals. In particular, considering user contexts and historical service selection, our framework interacts with users by asking relevant and necessary questions, and help users navigate through sets of services to identify the desired services. We have\u00a0\u2026", "num_citations": "2\n", "authors": ["1017"]}
{"title": "Personalized Service Discovery and Composition\n", "abstract": " With the prevalence of Service-Oriented Architecture (SOA), end-users, who are not familiar with SOA standards and tools, want to customize services to fulfill their daily activities. However, it is challenging for end-users to get involved in the service composition, due to the in-depth knowledge needed for SOA standards and techniques. To help end-users compose services for their daily activities, we propose an approach that shields end-users from the complexity of SOA standards and automatically generates composed services by specifying a goal using keywords. We expand the meaning of a user\u2019s goal using ontologies and derive a group of keywords for discovering services in order to achieve a user\u2019s goal. We also detect contextual environment of a user and personalize the service composition to meet a user\u2019s situational needs. A prototype is developed as a proof of concept to show that our approach enables nonexpert end-users to discover and compose services easily.", "num_citations": "2\n", "authors": ["1017"]}
{"title": "An approach for estimating code changes in e-commerce applications\n", "abstract": " E-commerce applications automate various business processes within an organization. To maintain a competitive edge, business analysts frequently modify business processes. Determining the effort for modifying a business process is not a trivial task, since the changes to the business process will result in changes to the source code for which the business analyst has limited knowledge. In this paper, we propose an approach for tracing the propagation of a change from the business process level to the code. We derive a change impact metric which estimates the code to be modified as a result of a business process change. A case study, using a large e-commerce application from the OFBiz open source project, demonstrates the effectiveness of our proposed change impact metric.", "num_citations": "2\n", "authors": ["1017"]}
{"title": "Using self-reconfigurable workplaces to automate the maintenance of evolving business applications\n", "abstract": " In this ever changing business environment, business processes are constantly being customized to reflect the up-to-date organizational structure and business objectives. Technology updates and innovation also affect the way business is carried out. A workplace application provides an interactive electronic working environment that integrates software applications to assist users in performing their daily work more efficiently. Managing and maintaining workplace applications within an organization is a challenging job, since it often involves labor intensive manual reconfiguration to adapt the workplace to the changes in business processes. In this paper, we propose a dynamic reconfigurable workplace framework that supports the changing nature of the business domain. This framework updates the workplace at run time, minimizes the interruption to users' work, and simplifies the evolution of a business\u00a0\u2026", "num_citations": "2\n", "authors": ["1017"]}
{"title": "FeatCompare: Feature comparison for competing mobile apps leveraging user reviews\n", "abstract": " Given the competitive mobile app market, developers must be fully aware of users\u2019 needs, satisfy users\u2019 requirements, combat apps of similar functionalities (i.e., competing apps), and thus stay ahead of the competition. While it is easy to track the overall user ratings of competing apps, such information fails to provide actionable insights for developers to improve their apps over the competing apps (AlSubaihin et al., IEEE Trans Softw Eng, 1\u20131, 2019). Thus, developers still need to read reviews from all their interested competing apps and summarize the advantages and disadvantages of each app. Such a manual process can be tedious and even infeasible with thousands of reviews posted daily. To help developers compare users\u2019 opinions among competing apps on high-level features, such as the main functionalities and the main characteristics of an app, we propose a review analysis approach named\u00a0\u2026", "num_citations": "1\n", "authors": ["1017"]}
{"title": "Pred-cache: a predictive caching method in database systems\n", "abstract": " The performance of large-scale systems (LSS) depends heavily on the time consumed in retrieving users\u2019 data from the databases. The database management system (DBMS) is essential to handle the storage and retrieval of users\u2019 data. Recent studies show that performance degradation in retrieving users\u2019 data can cause a severe revenue loss. Hence, improving the performance of the DBMS is essential for maintaining and enhancing user experience. Query caching is a technique employed by the DBMS that presents immense improvements to the overall performance of the system. Prior work improves query caching techniques by maximizing the reuse of the cached queries (eg, deciding on the beneficial queries to cache and deciding on the cache eviction and replacement policies). However, the existing work is tailored to specific server query languages and lacks in the adaptation to the different changing factors in the system, such as the occurrences of queries, the time of their occurrence, and query coupling. In this work, we propose a predictive database caching framework, which can be deployed as a middleware layer independently from the database system. Our framework uses deep learning models to predict expensiveness (in terms of execution time) and the occurrences of queries to guide the caching process. We evaluate our framework using the TPC Benchmark DS (TPC-DS) database where we generate a 50GB database with 100,000 queries. Remarkably, our framework improves the cache hit ratio by 6% to 29% over the existing query caching mechanisms in the different benchmark scenarios that simulate the different\u00a0\u2026", "num_citations": "1\n", "authors": ["1017"]}
{"title": "Exploration and Practice on Training Mode of Innovative Network Engineering Talents\n", "abstract": " This paper analyzes the current situation of innovative talent cultivation and summarizes the main factors that restrict the cultivation of innovative network engineering talents. Combined with the actual situation of our university, the \u201csix-in-one\u201d innovative network engineering talent training system is proposed. The practical results show that the training system is effective.", "num_citations": "1\n", "authors": ["1017"]}
{"title": "Applications of VUV extra-focus mechanism: high-performance dual-mode monochromator from VUV to soft X-ray\n", "abstract": " A new monochromator scheme is presented in which an extra-focus constant-included-angle varied-line-spacing cylindrical-grating monochromator (extra-focus CIA-VCGM) is conveniently combined with a variable-included-angle varied-line-spacing plane-grating monochromator (VIA-VPGM). This dual-mode solution delivers high performance in the energy range from vacuum ultraviolet (VUV) to soft X-ray. The resolving power and the efficiency of this dual-mode grating monochromator are analyzed in detail based on realistic parameters. Comparisons with the commonly used variable-included-angle plane-grating monochromator and normal-incidence monochromator (VIA-PGM/NIM) hybrid monochromator are made.", "num_citations": "1\n", "authors": ["1017"]}
{"title": "Automatic Filling Values to Services: A Road Map\n", "abstract": " It is common for users to explicitly or implicitly compose on-line services to accomplish daily tasks, such as shopping for a pair of shoes on-line. However, unnecessary and repetitive data typing into the services would negatively impact the user experience and decrease the efficiency of service composition. Recent studies have proposed several approaches to help users fill in values to services automatically. However, existing approaches suffer the following two drawbacks: 1) poor accuracy of filling values to services, 2) not designed for service composition. In this position paper, we first present the recent approaches improving the process of filling values to services. We then present our recent achievements and results of using our proposed approaches to help users fill values to services. Lastly, we discuss the various opportunities and challenges in the research field of filling values to services.", "num_citations": "1\n", "authors": ["1017"]}
{"title": "An approach for service discovery and recommendation using contexts\n", "abstract": " Given the large amount of existing Web services nowadays, it is time-consuming for users to find appropriate Web services to satisfy their diversity requirements. Context-aware techniques provide a promising way to help users obtain their desired services by automatically analyzing a user\u2019s context and recommending services for the user. Most existing context-aware techniques require system designers to manually define reactions to contexts based on context types (e.g., location) and context values (e.g., Toronto). Those context-aware techniques have limited support for dynamic adaptation to new context types and values. Due to the diversity of user\u2019s environments, the available context types and potential context values are changing overtime. It is challenging to anticipate a complete set of context types with various potential context values to provide corresponding reactions. In this chapter, we present\u00a0\u2026", "num_citations": "1\n", "authors": ["1017"]}
{"title": "A framework for composing personalized web resources\n", "abstract": " There are a large number of Web resources available on the Internet. However, only small subsets of Web resources are used to fulfill a user\u2019s needs. Due to the heterogeneity and decentralization of Web resources, it is a time-consuming and tedious process for users to identify Web resources to fulfill their needs. For repeated activities, a user has to perform the same process over and over. To support users\u2019 recurring online activities, we propose a framework for creating a personalized Web space to manage and orchestrate Web resources. Our framework provides helps to: 1) discover Web resources distributed in different websites despite their format; 2) provide mechanisms to allow users to share their information and resources; and 3) compose Web resources distributed in different websites. As a proof of concept, we designed and developed a prototype to demonstrate the use of our proposed\u00a0\u2026", "num_citations": "1\n", "authors": ["1017"]}
{"title": "Guest editors' introduction to the special section from the international symposium on web systems evolution\n", "abstract": " With the growth of the Internet, there is an urgent need to develop Web-based applications. Initially, the Web was presented as a giant URL-based le server for publishing static information in a hypertext electronic form. With the incorporation of multi-tier architectures and internet programming techniques, such as CGI scripts, Java servlets and Ajax, the Web is evolved into an interactive medium that provides dynamic information services. Nowadays, Web services are developed as self-contained, self-describing, and modular applications that can be published, located, and invoked across the Web. The service-oriented architecturent (SOA) uses loosely coupled Web services as basic constructs to build more complex systems in a exible and rapid way.", "num_citations": "1\n", "authors": ["1017"]}
{"title": "An approach for describing heterogeneous web resources in a unified schema\n", "abstract": " Web resources can be located and accessed through the Internet to provide information and functionalities to users. However, different types of web resources (e.g., Web Services, RESTful services and information based web pages) are represented in heterogeneous ways. It prevents the ability to discover and locate web resources with similar functionality in the service composition. In this paper, we present an approach to represent various web resources in a unified schema. Such a schema can improve the opportunity to find web resources with similar functionality, but not limiting to the same type of web resources. We develop techniques to automatically extract information from web resources. The results of the case study show that our approach can effectively describe web resources to facilitate the discovery of similar web resources among different types.", "num_citations": "1\n", "authors": ["1017"]}
{"title": "Practice of Teaching Reform of Network Security Technology Course under the Background of Internet\n", "abstract": " Network security technology is an important professional course for computers and related majors. It has the characteristics of wide content, pre-requisite knowledge, fast curriculum knowledge update and strong practical practice. In this paper, the teaching content, teaching methods and assessment methods of the course have been reformed for the problems existing in the teaching of network security technology courses. Practice has shown that reforms have stimulated students\u2019 interest in learning and improved their ability to apply knowledge.", "num_citations": "1\n", "authors": ["1017"]}
{"title": "A Framework for Composing Web Resources\n", "abstract": " Large amount of heterogeneous Web resources, such as SOAP-based Web Service and RESTful service exist on the Internet. It is labor-intensive and inefficient for an end-user to search and compose different Web resources in order to fulfill his/her requirement. To support the end-user\u2019s various activities, we propose a Web resources composition framework. This framework can help end-user: 1) discover available Web resources to fulfill the end-user\u2019s goal, despite of their types; 2) represent the relation between different resources to allow them to be used collaboratively; 3) automatically compose required Web resources to fulfill the goal specified by the enduser.", "num_citations": "1\n", "authors": ["1017"]}