{"title": "JPF\u2013SE: A symbolic execution extension to java pathfinder\n", "abstract": " We present JPF\u2013SE, an extension to the Java PathFinder Model Checking framework (JPF) that enables the symbolic execution of Java programs. JPF\u2013SE uses JPF to generate and explore symbolic execution paths and it uses off-the-shelf decision procedures to manipulate numeric constraints.", "num_citations": "339\n", "authors": ["1030"]}
{"title": "A survey of new trends in symbolic execution for software testing and analysis\n", "abstract": " Symbolic execution is a well-known program analysis technique which represents program inputs with symbolic values instead of concrete, initialized, data and executes the program by manipulating program expressions involving the symbolic values. Symbolic execution has been proposed over three decades ago but recently it has found renewed interest in the research community, due in part to the progress in decision procedures, availability of powerful computers and new algorithmic developments. We provide here a survey of some of the new research trends in symbolic execution, with particular emphasis on applications to test generation and program analysis. We first describe an approach that handles complex programming constructs such as input recursive data structures, arrays, as well as multithreading. Furthermore, we describe recent hybrid techniques that combine concrete and symbolic\u00a0\u2026", "num_citations": "296\n", "authors": ["1030"]}
{"title": "What went wrong: Explaining counterexamples\n", "abstract": " One of the chief advantages of model checking is the production of counterexamples demonstrating that a system does not satisfy a specification. However, it may require a great deal of human effort to extract the essence of an error from even a detailed source-level trace of a failing run. We use an automated method for finding multiple versions of an error (and similar executions that do not produce an error), and analyze these executions to produce a more succinct description of the key elements of the error. The description produced includes identification of portions of the source code crucial to distinguishing failing and succeeding runs, differences in invariants between failing and non-failing runs, and information on the necessary changes in scheduling and environmental actions needed to cause successful runs to fail.", "num_citations": "272\n", "authors": ["1030"]}
{"title": "Test input generation for Java containers using state matching\n", "abstract": " The popularity of object-oriented programming has led to the wide use of container libraries. It is important for the reliability of these containers that they are tested adequately. We describe techniques for automated test input generation of Java container classes. Test inputs are sequences of method calls from the container interface. The techniques rely on state matching to avoid generation of redundant tests. Exhaustive techniques use model checking with explicit or symbolic execution to explore all the possible test sequences up to predefined input sizes. Lossy techniques rely on abstraction mappings to compute and store abstract versions of the concrete states; they explore underapproximations of all the possible test sequences. We have implemented the techniques on top of the Java PathFinder model checker and we evaluate them using four Java container classes. We compare state matching based\u00a0\u2026", "num_citations": "197\n", "authors": ["1030"]}
{"title": "Verification of Java programs using symbolic execution and invariant generation\n", "abstract": " Software verification is recognized as an important and difficult problem. We present a novel framework, based on symbolic execution, for the automated verification of software. The framework uses annotations in the form of method specifications and loop invariants. We present a novel iterative technique that uses invariant strengthening and approximation for discovering these loop invariants automatically. The technique handles different types of data (e.g. boolean and numeric constraints, dynamically allocated structures and arrays) and it allows for checking universally quantified formulas. Our framework is built on top of the Java PathFinder model checking toolset and it was used for the verification of several non-trivial Java programs.", "num_citations": "169\n", "authors": ["1030"]}
{"title": "Addressing dynamic issues of program model checking\n", "abstract": " Model checking real programs has recently become an active research area. Programs however exhibit two characteristics that make model checking dificult: the complexity of their state and the dynamic nature of many programs. Here we address both these issues within the context of the Java PathFinder (JPF) model checker. Firstly, we will show how the state of a Java program can be encoded efficiently and how this encoding can be exploited to improve model checking. Next we show how to use symmetry reductions to alleviate some of the problems introduced by the dynamic nature of Java programs. Lastly, we show how distributed model checking of a dynamic program can be achieved, and furthermore, how dynamic partitions of the state space can improve model checking. We support all our findings with results from applying these techniques within the JPF model checker.", "num_citations": "152\n", "authors": ["1030"]}
{"title": "Green: reducing, reusing and recycling constraints in program analysis\n", "abstract": " The analysis of constraints plays an important role in many aspects of software engineering, for example constraint satisfiability checking is central to symbolic execution. However, the norm is to recompute results in each analysis. We propose a different approach where every call to the solver is wrapped in a check to see if the result is not already available. While many tools use some form of results caching, the novelty of our approach is the persistence of results across runs, across programs being analyzed, across different analyses and even across physical location. Achieving such reuse requires that constraints be distilled into their essential parts and represented in a canonical form.", "num_citations": "151\n", "authors": ["1030"]}
{"title": "Probabilistic symbolic execution\n", "abstract": " The continued development of efficient automated decision procedures has spurred the resurgence of research on symbolic execution over the past decade. Researchers have applied symbolic execution to a wide range of software analysis problems including: checking programs against contract specifications, inferring bounds on worst-case execution performance, and generating path-adequate test suites for widely used library code.", "num_citations": "138\n", "authors": ["1030"]}
{"title": "Reliability analysis in symbolic pathfinder\n", "abstract": " Software reliability analysis tackles the problem of predicting the failure probability of software. Most of the current approaches base reliability analysis on architectural abstractions useful at early stages of design, but not directly applicable to source code. In this paper we propose a general methodology that exploit symbolic execution of source code for extracting failure and success paths to be used for probabilistic reliability assessment against relevant usage scenarios. Under the assumption of finite and countable input domains, we provide an efficient implementation based on Symbolic PathFinder that supports the analysis of sequential and parallel programs, even with structured data types, at the desired level of confidence. The tool has been validated on both NASA prototypes and other test cases showing a promising applicability scope.", "num_citations": "136\n", "authors": ["1030"]}
{"title": "Model checking Java programs using structural heuristics\n", "abstract": " We describe work in troducing heuristic search into the Java PathFinder model checker, which targets Java bytecode. Rather than focusing on heuristics aimed at a particular kind of error (such as deadlocks) we describe heuristics based on a modification of traditional branch coverage metrics and other structure measures, such as thread inter-dependency. We present experimental results showing the utility of these heuristics, and argue for the usefulness of structural heuristics as a class.", "num_citations": "132\n", "authors": ["1030"]}
{"title": "Heuristics for model checking Java programs\n", "abstract": " Model checking of software programs has two goals \u2013 the verification of correct software and the discovery of errors in faulty software. Some techniques for dealing with the most crucial problem in model checking, the state space explosion problem, concentrate on the first of these goals. In this paper we present an array of heuristic model checking techniques for combating the state space explosion when searching for errors. Previous work on this topic has mostly focused on property-specific heuristics closely related to particular kinds of errors. We present structural heuristics that attempt to explore the structure (branching structure, thread interdependency structure, abstraction structure) of a program in a manner intended to expose errors efficiently. Experimental results show the utility of this class of heuristics. In contrast to these very general heuristics, we also present very lightweight techniques for\u00a0\u2026", "num_citations": "127\n", "authors": ["1030"]}
{"title": "Experimental evaluation of verification and validation tools on martian rover software\n", "abstract": " We report on a study to determine the maturity of different verification and validation technologies (V&V) applied to a representative example of NASA flight software. The study consisted of a controlled experiment where three technologies (static analysis, runtime analysis and model checking) were compared to traditional testing with respect to their ability to find seeded errors in a prototype Mars Rover controller. What makes this study unique is that it is the first (to the best of our knowledge) controlled experiment to compare formal methods based tools to testing on a realistic industrial-size example, where the emphasis was on collecting as much data on the performance of the tools and the participants as possible. The paper includes a description of the Rover code that was analyzed, the tools used, as well as a detailed description of the experimental setup and the results. Due to the complexity of setting\u00a0\u2026", "num_citations": "123\n", "authors": ["1030"]}
{"title": "Finding feasible counter-examples when model checking abstracted Java programs\n", "abstract": " Despite recent advances in model checking and in adapting model checking techniques to software, the state explosion problem remains a major hurdle in applying model checking to software. Recent work in automated program abstraction has shown promise as a means of scaling model checking to larger systems. Most common abstraction techniques compute an upper approximation of the original program. Thus, when a specification is found true for the abstracted program, it is known to be true for the original program. Finding a specification to be false, however, is inconclusive since the specification may be violated on a behavior in the abstracted program which is not present in the original program. We have extended an explicit-state model checker, Java PathFinder (JPF), to analyze counter-examples in the presence of abstractions. We enhanced JPF to search for \u201cfeasible\u201d (i.e. nondeterminismfree\u00a0\u2026", "num_citations": "99\n", "authors": ["1030"]}
{"title": "Verification of time partitioning in the DEOS scheduler kernel\n", "abstract": " This paper describes an experiment to use the Spin model checking system to support automated verification of time partitioning in the Honeywell DEOS real-time scheduling kernel. The goal of the experiment was to investigate whether model checking could be used to find a subtle implementation error that was originally discovered and fixed during the standard formal review process. To conduct the experiment, a core slice of the DEOS scheduling kernel was first translated without abstraction from C++ into Promela (the input language for Spin). We constructed an abstract \u201ctest-driver\u201d environment and carefully introduced several abstractions into the system to support verification. Several experiments were run to attempt to verify that the system implementation adhered to the critical time partitioning requirements. During these experiments, the known error was rediscovered in the time partitioning implementation\u00a0\u2026", "num_citations": "94\n", "authors": ["1030"]}
{"title": "Verifying android applications using Java PathFinder\n", "abstract": " Mobile application testing is a specialised and complex field. Due to mobile applications' event driven design and mobile runtime environment, there currently exist only a small number of tools to verify these applications. This paper describes the development of JPF-ANDROID, an Android application verification tool. JPF-ANDROID is built on Java Pathfinder, a Java model checking engine. JPF-ANDROID provides a simplified model of the Android framework on which an Android application can run. It then allows the user to script input events to drive the application flow. JPF-ANDROID provides a way to detect common property violations such as deadlocks and runtime exceptions in Android applications.", "num_citations": "86\n", "authors": ["1030"]}
{"title": "SE 2014: Curriculum guidelines for undergraduate degree programs in software engineering\n", "abstract": " The SE 2004 guidelines were assembled by an ACM/IEEE Computer Society task force led by Rich LeBlanc and Ann Sobel. However, because software engineering knowledge continues to grow and evolve, the societies created a new task force in 2010 (see \u201cSoftware Engineering 2014 Curriculum Guidelines Task Forces\u201d sidebar), asking members to consider whether revisions were needed and, if so, how extensive they should be. The group duly sought feedback by running events at major conferences; consulting with individuals; and organizing an online survey, which received 477 completed returns from 42 countries. In addition to these efforts, the task force looked at activities related to the Guide to the Software Engineering Body of Knowledge (SWEBOK; www. computer. org/web/swebok), such as the Software En gineering Competency Model (SWECOM; www. computer. org/web/peb/swecom), and related\u00a0\u2026", "num_citations": "83\n", "authors": ["1030"]}
{"title": "Variably interprocedural program analysis for runtime error detection\n", "abstract": " This paper describes an analysis approach based on a of static and dynamic techniques to? nd run-time errors in Java code. It uses symbolic execution to? nd constraints under which an error (eg a null pointer dereference, array out of bounds access, or assertion violation) may occur and then solves these constraints to? nd test inputs that may expose the error. It only alerts the user to the possibility of a real error when it detects the expected exception during a program run.", "num_citations": "74\n", "authors": ["1030"]}
{"title": "Combining static analysis and model checking for software analysis\n", "abstract": " We present an iterative technique in which model checking and static analysis are combined to verify large software systems. The role of the static analysis is to compute partial order information which the model checker uses to reduce the state space. During exploration, the model checker also computes aliasing information that it gives to the static analyzer which can then refine its analysis. The result of this refined analysis is then fed back to the model checker which updates its partial order reduction. At each step of this iterative process, the static analysis computes optimistic information which results in an unsafe reduction of the state space. However, we show that the process converges to a fixed point at which time the partial order information is safe and the whole state space is explored.", "num_citations": "69\n", "authors": ["1030"]}
{"title": "Symbolic execution with abstraction\n", "abstract": " We address the problem of error detection for programs that take recursive data structures and arrays as input. Previously we proposed a combination of symbolic execution and model checking for the analysis of such programs: we put a bound on the size of the program inputs and/or the search depth of the model checker to limit the search state space. Here we look beyond bounded model checking and consider state matching techniques to limit the state space. We describe a method for examining whether a symbolic state that arises during symbolic execution is subsumed by another symbolic state. Since the number of symbolic states may be infinite, subsumption is not enough to ensure termination. Therefore, we also consider abstraction techniques for computing and storing abstract states during symbolic execution. Subsumption checking determines whether an abstract state is being revisited, in\u00a0\u2026", "num_citations": "67\n", "authors": ["1030"]}
{"title": "Symbolic execution with abstract subsumption checking\n", "abstract": " We address the problem of error detection for programs that take recursive data structures and arrays as input. Previously we proposed a combination of symbolic execution and model checking for the analysis of such programs: we put a bound on the size of the program inputs and/or the search depth of the model checker to limit the search state space. Here we look beyond bounded model checking and consider state matching techniques to limit the state space. We describe a method for examining whether a symbolic state that arises during symbolic execution is subsumed by another symbolic state. Since subsumption is in general not enough to ensure termination, as the number of symbolic states may be infinite, we also consider abstraction techniques for computing and storing abstract states during symbolic execution. Subsumption checking determines whether an abstract state is being revisited, in\u00a0\u2026", "num_citations": "66\n", "authors": ["1030"]}
{"title": "Compositional solution space quantification for probabilistic software analysis\n", "abstract": " Probabilistic software analysis aims at quantifying how likely a target event is to occur during program execution. Current approaches rely on symbolic execution to identify the conditions to reach the target event and try to quantify the fraction of the input domain satisfying these conditions. Precise quantification is usually limited to linear constraints, while only approximate solutions can be provided in general through statistical approaches. However, statistical approaches may fail to converge to an acceptable accuracy within a reasonable time.", "num_citations": "60\n", "authors": ["1030"]}
{"title": "Model checking programs with Java PathFinder\n", "abstract": " Model Checking Programs with Java PathFinder ~ Part 2: Design Page 1 Model Checking Programs with Java PathFinder ~ Part 2: Design 1 Willem Visser <wvisser@email.arc.nasa.gov> Peter Mehlitz <pcmehlitz@email.arc.nasa.gov> NASA Ames Research Center Page 2 Roadmap \u2726 What is JPF? \u2726 Motivating Examples \u2726 How To Run It \u2022 invocation, configuration, distribution components \u2726 Basic JPF Design \u2022 Search, VM \u2726 Extending JPF \u2022 Listeners \u2022 Properties \u2022 MJI \u2726 Underlying Mechanisms \u2022 Partial Order Reduction \u2726 Future Infrastructure \u2022 ChoiceGenerator (yet another extension mechanism) 2 Page 3 What is Java PathFinder (1) \u2726 explicit state model checker for Java bytecode \u2726 focus is on finding bugs in Java programs \u2022 concurrency related: deadlocks, (races), missed signals etc. \u2022 Java runtime related: unhandled exceptions, heap usage, (cycle budgets) \u2022 but also: complex application specific assertions 3 *.\u2026", "num_citations": "58\n", "authors": ["1030"]}
{"title": "Concrete model checking with abstract matching and refinement\n", "abstract": " We propose an abstraction-based model checking method which relies on refinement of an under-approximation of the feasible behaviors of the system under analysis. The method preserves errors to safety properties, since all analyzed behaviors are feasible by definition. The method does not require an abstract transition relation to be generated, but instead executes the concrete transitions while storing abstract versions of the concrete states, as specified by a set of abstraction predicates. For each explored transition the method checks, with the help of a theorem prover, whether there is any loss of precision introduced by abstraction. The results of these checks are used to decide termination or to refine the abstraction by generating new abstraction predicates. If the (possibly infinite) concrete system under analysis has a finite bisimulation quotient, then the method is guaranteed to eventually explore an\u00a0\u2026", "num_citations": "58\n", "authors": ["1030"]}
{"title": "Exact and approximate probabilistic symbolic execution for nondeterministic programs\n", "abstract": " Probabilistic software analysis seeks to quantify the likelihood of reaching a target event under uncertain environments. Recent approaches compute probabilities of execution paths using symbolic execution, but do not support nondeterminism. Nondeterminism arises naturally when no suitable probabilistic model can capture a program behavior, eg, for multithreading or distributed systems.", "num_citations": "53\n", "authors": ["1030"]}
{"title": "Execution and property specifications for jpf-android\n", "abstract": " JPF-Android is a model checking tool for Android applications allowing them to be verified outside of an emulator on Java PathFinder (JPF). The Android applications are executed on a model of the Android software stack and their execution driven by simulating user and system input events. This paper follows from our previous work describing the design decisions and implementation of JPF-Android. Here we discuss the syntax and implementation of the scripting environment which is used to drive the execution of the An- droid application under analysis. It also focuses on a further extension to the tool used to automatically monitor the run- time behavior of Android applications.", "num_citations": "49\n", "authors": ["1030"]}
{"title": "Verifying time partitioning in the DEOS scheduling kernel\n", "abstract": " This paper describes an experiment to use the Spin model checking system to support automated verification of time partitioning in the Honeywell DEOS real-time scheduling kernel. The goal of the experiment was to investigate whether model checking with minimal abstraction could be used to find a subtle implementation error that was originally discovered and fixed during the standard formal review process. The experiment involved translating a core slice of the DEOS scheduling kernel from C++ into Promela, constructing an abstract \u201ctest-driver\u201d environment and carefully introducing several abstractions into the system to support verification. Attempted verification of several properties related to time-partitioning led to the rediscovery of the known error in the implementation. The case study indicated several limitations in existing tools to support model checking of software. The most difficult task in the\u00a0\u2026", "num_citations": "47\n", "authors": ["1030"]}
{"title": "Heuristic model checking for java programs\n", "abstract": " Two recent areas of interest in software model checking are checking programs written in standard programming languages [1],[5] and using heuristics to guide the exploration of an explicit-state model checker [3]. Model checking real programs has the drawback that programs often contain a larger degree of detail than designs and hence are more dificult to check (due to the more acute stateexplosion problem); however the large amount of detail in a program allows more precise heuristics for narrowing down the search space when using a model checker for error-detection. This paper describes the addition of support for heuristic (or directed) search strategies to Java PathFinder (JPF), an explicit state model checker for Java bytecode that uses a custom-made Java Virtual Machine (JVM) [5].               The primary benefits of heuristic search are: discovery of errors that a depth- first search fails to find, and\u00a0\u2026", "num_citations": "44\n", "authors": ["1030"]}
{"title": "Memory efficient state storage in Spin.\n", "abstract": " The use of an Ordered Binary Decision Diagram (OBDD) to store all visited states during on-thefly model checking (or reachability analysis) is investigated. To improve the time and space efficiency a state compression technique is introduced. This compression technique is safe, in the sense that no two unique states will have the same compressed representation. A number of examples are used to evaluate an experimental implementation of the OBDD state store within the SPIN validation tool. In all the examples a reduction in space is achieved when using the OBDD state store as opposed to the more traditional hash table state store. The memory and time usage when combining partial orders with the OBDD state store is also considered.", "num_citations": "44\n", "authors": ["1030"]}
{"title": "Evaluating paper and author ranking algorithms using impact and contribution awards\n", "abstract": " In the work presented in this paper, we analyse ranking algorithms that can be applied to bibliographic citation networks and rank academic entities such as papers and authors. We evaluate how well these algorithms identify important and high-impact entities.The ranking algorithms are computed on the Microsoft Academic Search (MAS) and the ACM digital library citation databases. The MAS database contains 40 million papers and over 260 million citations that span across multiple academic disciplines, while the ACM database contains 1.8 million papers from the computing literature and over 7 million citations.We evaluate the ranking algorithms by using a test data set of papers and authors that won renowned prizes at numerous computer science conferences. The results show that using citation counts is, in general, the best ranking metric to measure high-impact. However, for certain tasks, such as ranking\u00a0\u2026", "num_citations": "41\n", "authors": ["1030"]}
{"title": "Symbolic execution of programs with strings\n", "abstract": " Symbolic execution has long been a popular technique for automated test generation and for error detection in complex code. Most of the focus has however been on programs manipulating integers, booleans, and references in object oriented programs. Recently researchers have started looking at programs that do lots of string processing; this is motivated by the popularity of the web and the risk that errors in such programs may lead to security violations. Attempts to extend symbolic execution to the domain of strings have mainly been divided into one of two camps: automata-based approaches and approaches based on efficient bitvector analysis. Here we investigate these two approaches in one setting: the symbolic execution framework of Java PathFinder. First we describe the implementations of both approaches and then do an extensive evaluation to show under what circumstances each approach performs\u00a0\u2026", "num_citations": "41\n", "authors": ["1030"]}
{"title": "Model checking real time Java using Java PathFinder\n", "abstract": " The Real Time Specification for Java (RTSJ) is an augmentation of Java for real time applications of various degrees of hardness. The central features of RTSJ are real time threads; user defined schedulers; asynchronous events, handlers, and control transfers; a priority inheritance based default scheduler; non-heap memory areas such as immortal and scoped, and non-heap real time threads whose execution is not impeded by garbage collection. The Robust Software Systems group at NASA Ames Research Center has Java PathFinder (JPF) under development, a Java model checker. JPF at its core is a state exploring JVM which can examine alternative paths in a Java program (e.g., via backtracking) by trying all nondeterministic choices, including thread scheduling order. This paper describes our implementation of an RTSJ profile (subset) in JPF, including requirements, design decisions, and current\u00a0\u2026", "num_citations": "40\n", "authors": ["1030"]}
{"title": "Finding feasible abstract counter-examples\n", "abstract": " A strength of model checking is its ability to automate the detection of subtle system errors and produce traces that exhibit those errors. Given the high-computational cost of model checking most researchers advocate the use of aggressive property-preserving abstractions. Unfortunately, the more aggressively a system is abstracted the more infeasible behavior it will have. Thus, while abstraction enables efficient model checking it also threatens the usefulness of model checking as a defect detection tool, since it may be difficult to determine whether a counter-example is feasible and hence worth developer time to analyze.               We have explored several strategies for addressing this problem by extending an explicit-state model checker, Java PathFinder (JPF), to search for and analyze counter-examples in the presence of abstractions. We demonstrate that these techniques effectively preserve the defect\u00a0\u2026", "num_citations": "38\n", "authors": ["1030"]}
{"title": "Statistical symbolic execution with informed sampling\n", "abstract": " Symbolic execution techniques have been proposed recently for the probabilistic analysis of programs. These techniques seek to quantify the likelihood of reaching program events of interest, eg, assert violations. They have many promising applications but have scalability issues due to high computational demand. To address this challenge, we propose a statistical symbolic execution technique that performs Monte Carlo sampling of the symbolic program paths and uses the obtained information for Bayesian estimation and hypothesis testing with respect to the probability of reaching the target events. To speed up the convergence of the statistical analysis, we propose Informed Sampling, an iterative symbolic execution that first explores the paths that have high statistical significance, prunes them from the state space and guides the execution towards less likely paths. The technique combines Bayesian estimation\u00a0\u2026", "num_citations": "35\n", "authors": ["1030"]}
{"title": "BLISS: improved symbolic execution by bounded lazy initialization with SAT support\n", "abstract": " Lazy Initialization (LI) allows symbolic execution to effectively deal with heap-allocated data structures, thanks to a significant reduction in spurious and redundant symbolic structures. Bounded lazy initialization (BLI) improves on LI by taking advantage of precomputed relational bounds on the interpretation of class fields in order to reduce the number of spurious structures even further. In this paper we present bounded lazy initialization with SAT support (BLISS), a novel technique that refines the search for valid structures during the symbolic execution process. BLISS builds upon BLI, extending it with field bound refinement and satisfiability checks. Field bounds are refined while a symbolic structure is concretized, avoiding cases that, due to the concrete part of the heap and the field bounds, can be deemed redundant. Satisfiability checks on refined symbolic heaps allow us to prune these heaps as soon as they are\u00a0\u2026", "num_citations": "33\n", "authors": ["1030"]}
{"title": "Program model checking as a new trend\n", "abstract": " This paper introduces a special section of the STTT journal containing a selection of papers that were presented at the 7th international SPIN workshop, Stanford, 30 August \u2013 1 September 2000. The workshop was named SPIN Model Checking and Software Verification, with an emphasis on model checking of programs. The paper outlines the motivation for stressing software verification, rather than only design and model verification, by presenting the work done in the Automated Software Engineering group at NASA Ames Research Center within the last 5 years. This includes work in software model checking, testing like technologies and static analysis.", "num_citations": "33\n", "authors": ["1030"]}
{"title": "Practical CTL* model checking: Should SPIN be extended?\n", "abstract": " We describe an efficient CTL* model checking algorithm based on alternating automata and games. A CTL* formula, expressing a correctness property, is first translated to a hesitant alternating automaton and then composed with a Kripke structure representing the model to be checked, after which this resulting automaton is then checked for nonemptiness. We introduce the nonemptiness game that checks the nonemptiness of a hesitant alternating automaton (HAA). In the same way that alternating automata generalise nondeterministic automata, we show that this game for checking the nonemptiness of HAA, generalises the nested depth-first algorithm used to check the nonemptiness of nondeterministic B\u00fcchi automata (used in Spin).", "num_citations": "33\n", "authors": ["1030"]}
{"title": "Test input generation for red-black trees using abstraction\n", "abstract": " We consider the problem of test input generation for code that manipulates complex data structures. Test inputs are sequences of method calls from the data structure interface. We describe test input generation techniques that rely on state matching to avoid generation of redundant tests. Exhaustive techniques use explicit state model checking to explore all the possible test sequences up to predefined input sizes. Lossy techniques rely on abstraction mappings to compute and store abstract versions of the concrete states; they explore under-approximations of all the possible test sequences. We have implemented the techniques on top of the Java PathFinder model checker and we evaluate them using a Java implementation of red-black trees.", "num_citations": "29\n", "authors": ["1030"]}
{"title": "The hidden models of model checking\n", "abstract": " In the past, applying formal analysis, such as model checking, to industrial problems required a team of formal methods experts and a great deal of effort. Model checking has become popular, because model checkers have evolved to allow domain-experts, who lack model checking expertise, to analyze their systems. What made this shift possible and what roles did models play in this? That is the main question we consider here. We survey approaches that transform domain-specific input models into alternative forms that are invisible to the user and which are amenable to model checking using existing techniques\u2014we refer to these as hidden models. We observe that keeping these models hidden from the user is in fact paramount to the success of the domain-specific model checker. We illustrate the value of hidden models by surveying successful examples of their use in different areas of model\u00a0\u2026", "num_citations": "28\n", "authors": ["1030"]}
{"title": "Autonomy software: V& V challenges and characteristics\n", "abstract": " The successful operation of unmanned air vehicles requires software with a high degree of autonomy. Only if high level functions can be carried out without human control and intervention can complex missions, in a changing and potentially unknown environment, be carried out successfully. Autonomy software is highly mission and safety critical: failures, caused by flaws in the software cannot only jeopardize the mission, but could also endanger human life (e.g., a crash of an UAV in a densely populated area). Due to its large size, complex architecture, and use of specialized algorithms (planners, constraint-solvers, etc.), autonomy software poses specific challenges for its verification, validation, and certification. We have carried out a survey among researchers and scientists at NASA to study these issues. In this paper, we will present major results of this study, discussing the broad spectrum of notions and\u00a0\u2026", "num_citations": "28\n", "authors": ["1030"]}
{"title": "What makes killing a mutant hard\n", "abstract": " Mutation operators have been studied at length to determine which ones are the``best\" at some metric (for example creates the least equivalent mutants, creates hard-to-kill mutants, etc.). These studies though have focused on specific test suites, where the test inputs and oracles are fixed, which leads to results that are strongly influenced by the test suites and thus makes the conclusions potentially less general. In this paper we consider all test inputs and we assume we have no prior knowledge about the likelihood of any specific inputs. We will also show how varying the strength of the oracle have a big impact on the results. We only consider a few mutation operators (mostly relational), only a handful of programs to mutate (amenable to probabilistic symbolic execution), and only consider how likely it is that a mutant is killed. A core finding is that the likelihood of reaching the source line where the mutation is\u00a0\u2026", "num_citations": "26\n", "authors": ["1030"]}
{"title": "Predicate abstraction with under-approximation refinement\n", "abstract": " We propose an abstraction-based model checking method which relies on refinement of an under-approximation of the feasible behaviors of the system under analysis. The method preserves errors to safety properties, since all analyzed behaviors are feasible by definition. The method does not require an abstract transition relation to be generated, but instead executes the concrete transitions while storing abstract versions of the concrete states, as specified by a set of abstraction predicates. For each explored transition the method checks, with the help of a theorem prover, whether there is any loss of precision introduced by abstraction. The results of these checks are used to decide termination or to refine the abstraction by generating new abstraction predicates. If the (possibly infinite) concrete system under analysis has a finite bisimulation quotient, then the method is guaranteed to eventually explore an equivalent finite bisimilar structure. We illustrate the application of the approach for checking concurrent programs.", "num_citations": "26\n", "authors": ["1030"]}
{"title": "Model counting for complex data structures\n", "abstract": " We extend recent approaches for calculating the probability of program behaviors, to allow model counting for complex data structures with numeric fields. We use symbolic execution with lazy initialization to compute the input structures leading to the occurrence of a target event, while keeping a symbolic representation of the constraints on the numeric data. Off-the-shelf model counting tools are used to count the solutions for numerical constraints and field bounds encoding data structure invariants are used to reduce the search space. The technique is implemented in the Symbolic PathFinder tool and evaluated on several complex data structures. Results show that the technique is much faster than an enumeration-based method that uses the Korat tool and also highlight the benefits of using the field bounds to speed up the analysis.", "num_citations": "25\n", "authors": ["1030"]}
{"title": "ESML-a validation language for concurrent systems\n", "abstract": " Designing a concurrent reactive system which can be proven correct is a challenging task. A promising technique involves building a validation model which can be shown to have important correctness properties. This paper describes a language to specify such models. A model consists of one or more interconnected state machines. The global state of a model is the combined state of all state machines. Channels which enable state machines to communicate form part of the global state. Temporal logic is used to specify correctness requirements of a model and a validation system (based on model checking) can be used to check these requirements. Design errors such as deadlock can thus be detected.", "num_citations": "22\n", "authors": ["1030"]}
{"title": "Generation of library models for verification of android applications\n", "abstract": " Android applications are difficult to verify and test since they have many external dependencies. To overcome this problem, environment generation can be used to create a model of the environment to simulate the behavior of these external dependencies. Creating this environment model manually is a tedious process and although there are many techniques available to generate models, the key lies in identifying how these techniques can be applied to a specific domain. In this paper we discuss two static analysis tools OCSEGen [3] and Modgen [1] and how they can be applied to the Android domain to generate models for specific parts of the environment.", "num_citations": "21\n", "authors": ["1030"]}
{"title": "Comparing paper ranking algorithms\n", "abstract": " The research presented in this paper focuses on comparing and evaluating various ranking algorithms that can be used on citation graphs in order to rank individual papers according to their importance and relevance. The graph analysis algorithms investigated in this paper are PageRank, CiteRank and an algorithm proposed by Hwang et al. and compared to the method of simply counting the number of citations of a publication. In addition, a new algorithm, NewRank, is proposed which is a combination of the PageRank and CiteRank algorithms with the focus on identifying influential papers that were published recently. A customizable crawler framework was developed to collect publication datasets from various sources. The development of this framework is discussed in detail. Finally, the ranking algorithms are evaluated against the list of the most influential papers compiled by the ICSE selection committee.", "num_citations": "21\n", "authors": ["1030"]}
{"title": "Bounded lazy initialization\n", "abstract": " Tight field bounds have been successfully used in the context of bounded-exhaustive bug finding. They allow one to check the correctness of, or find bugs in, code manipulating data structures whose size made this kind of analyses previously infeasible. In this article we address the question of whether tight field bounds can also contribute to a significant speed-up for symbolic execution when using a system such as Symbolic Pathfinder. Specifically, we propose to change Symbolic Pathfinder\u2019s lazy initialization mechanism to take advantage of tight field bounds. While a straightforward approach that takes into account tight field bounds works well for small scopes, the lack of symmetry-breaking significantly affects its performance. We then introduce a new technique that generates only non-isomorphic structures and consequently is able to consider fewer structures and to execute faster than lazy initialization.", "num_citations": "19\n", "authors": ["1030"]}
{"title": "Field-exhaustive testing\n", "abstract": " We present a testing approach for object oriented programs, which encompasses a testing criterion and an automated test generation technique. The criterion, that we call field-exhaustive testing, requires a user-provided limit n on the size of data domains, and is based on the idea of considering enough inputs so as to exhaustively cover the extension of class fields, within the limit n. Intuitively, the extension of a field f is the binary relation established between objects and their corresponding values for field f, in valid instances. Thus, a suite S is field-exhaustive if whenever a field f relates an object o with a value v (ie, o. f= v) within a valid instance I of size bounded by n, then S contains at least one input I'covering such relationship, ie, o must also be part of I', and o. f= v must hold in I'. Our test generation technique uses incremental SAT solving to produce small field-exhaustive suites: field-exhaustiveness can be\u00a0\u2026", "num_citations": "18\n", "authors": ["1030"]}
{"title": "CTL* model checking for SPIN\n", "abstract": " We describe an efficient CTL* model checking algorithm based on alternating automata and games. A CTL* formula, expressing a correctness property, is first translated to a hesitant alternating automaton and then composed with a Kripke structure representing the model to be checked, this resulting automaton is then checked for nonemptiness. We introduce the nonemptiness game that checks the nonemptiness of a hesitant alternating automata (HAA). In the same way that alternating automata generalises nondeterministic automata, we show that this game for checking the nonemptiness of HAA, generalises the nested depth-first algorithm used to check the nonemptiness of nondeterministic B uchi automata (used in SPIN).", "num_citations": "18\n", "authors": ["1030"]}
{"title": "Efficient CTL* model checking using games and automata\n", "abstract": " Formal verification, where a system is verified with respect to a desired behaviour, has now become popular in industry, especially in mission and safety critical applications. Specifically model checking methods, which can be fully automated, are being used extensively to verify that a finite state system meets a desired behaviour. The desired behaviour is often specified by a temporal logic formula. In this thesis we are interested in efficient algorithms for CTL* model checking, where the system to be verified is specified as a Kripke structure and the formula to be checked is given in the branching time temporal logic CTL*.", "num_citations": "18\n", "authors": ["1030"]}
{"title": "Program model checking: a practitioner\u2019s guide\n", "abstract": " Program model checking is a verification technology that uses state-space exploration to evaluate large numbers of potential program executions. It can be effective at detecting critical software errors that are difficult to find through traditional testing. Program model checking provides improved coverage over testing by systematically evaluating all possible test inputs and all possible interleavings of threads in a multithreaded system.In the real world,\u201call possible\u201d can be a very big number. To address this challenge, model-checking algorithms use several classes of optimizations to reduce the time and memory requirements for analysis, as well as heuristics for meaningful analysis of partial areas of the state space. This is still not always sufficient to enable exhaustive coverage. However, even with only partial coverage of a system, the ability to control thread scheduling and environment responses while monitoring the system state offers benefits over testing for finding requirements violations.", "num_citations": "17\n", "authors": ["1030"]}
{"title": "Symlnfer: Inferring program invariants using symbolic states\n", "abstract": " We introduce a new technique for inferring program invariants that uses symbolic states generated by symbolic execution. Symbolic states, which consist of path conditions and constraints on local variables, are a compact description of sets of concrete program states and they can be used for both invariant inference and invariant verification. Our technique uses a counterexample-based algorithm that creates concrete states from symbolic states, infers candidate invariants from concrete states, and then verifies or refutes candidate invariants using symbolic states. The refutation case produces concrete counterexamples that prevent spurious results and allow the technique to obtain more precise invariants. This process stops when the algorithm reaches a stable set of invariants. We present Symlnfer, a tool that implements these ideas to automatically generate invariants at arbitrary locations in a Java program. The\u00a0\u2026", "num_citations": "16\n", "authors": ["1030"]}
{"title": "Author ranking evaluation at scale\n", "abstract": " We evaluate author impact indicators and ranking algorithms on two publication databases using large test data sets of well-established researchers. The test data consists of (1) ACM fellowship and (2) various life-time achievement awards. We also evaluate different approaches of dividing credit of papers among co-authors and analyse the impact of self-citations. Furthermore, we evaluate different graph normalisation approaches for when PageRank is computed on author citation graphs.We find that PageRank outperforms citation counts in identifying well-established researchers. This holds true when PageRank is computed on author citation graphs but also when PageRank is computed on paper graphs and paper scores are divided among co-authors. In general, the best results are obtained when co-authors receive an equal share of a paper's score, independent of which impact indicator is used to compute\u00a0\u2026", "num_citations": "15\n", "authors": ["1030"]}
{"title": "Adding active objects to SPIN\n", "abstract": " We adapt the SPIN system to allow more e cient program veri cation. Speci cally, we add a feature to the language that makes it possible to model check PROMELA systems containing active objects, ie objects that are capable of executing autonomously, and the contents of which can be accessed via object references.", "num_citations": "13\n", "authors": ["1030"]}
{"title": "SPIN Model Checking and Software Verification: 7th International SPIN Workshop Stanford, CA, USA, August 30-September 1, 2000 Proceedings\n", "abstract": " The SPIN workshop is a forum for researchers interested in the subject of automata-based, explicit-state model checking technologies for the analysis and veri? cation of asynchronous concurrent and distributed systems. The SPIN-del checker (http://netlib. bell-labs. com/netlib/spin/whatispin. html), developed by Gerard Holzmann, is one of the best known systems of this kind, and has attracted a large user community. This can likely be attributed to its e? cient state exploration algorithms. The fact that SPIN\u2019s modeling language, Promela, resembles a programming language has probably also contributed to its success. Traditionally, the SPIN workshops present papers on extensions and uses of SPIN. As an experiment, this year\u2019s workshop was broadened to have a slightly wider focus than previous workshops in that papers on software veri? cation were encouraged. Consequently, a small collection of papers describe attempts to analyze and verify programs written in conventional programming languages. Solutions include translations from source code to Promela, as well as specially designed model checkers that accept source code. We believe that this is an-teresting research direction for the formal methods community, and that it will result in a new set of challenges and solutions. Of course, abstraction becomes the key solution to deal with very large state spaces. However, we also see-tential for integrating model checking with techniques such as static program analysis and testing. Papers on these issues have therefore been included in the proceedings.", "num_citations": "12\n", "authors": ["1030"]}
{"title": "Java Ranger at SV-COMP 2020 (competition contribution)\n", "abstract": " Path-merging is a known technique for accelerating symbolic execution. One technique, named \u201cveritesting\u201d by Avgerinos et al. uses summaries of bounded control-flow regions and has been shown to accelerate symbolic execution of binary code. But, when applied to symbolic execution of Java code, veritesting needs to be extended to summarize dynamically dispatched methods and exceptional control-flow. Such an extension of veritesting has been implemented in Java Ranger by implementing as an extension of Symbolic PathFinder, a symbolic executor for Java bytecode. In this paper, we briefly describe the architecture of Java Ranger and describe its setup for SV-COMP 2020.", "num_citations": "11\n", "authors": ["1030"]}
{"title": "Symbolic execution and model checking for testing\n", "abstract": " Techniques for checking complex software range from model checking and static analysis to testing. We aim to use the power of exhaustive techniques, such as model checking and symbolic execution, to enable thorough testing of complex software. In particular, we have extended the Java PathFinder model checking tool (JPF) [3] with a symbolic execution capability [4,2] to enable test case generation for Java programs. Our techniques handle complex data structures, arrays, as well as multithreading, and generate optimized test suites that satisfy user-specified testing coverage criteria.", "num_citations": "11\n", "authors": ["1030"]}
{"title": "Efficient CTL* Model Checking for Analysis of Rainbow Designs\n", "abstract": " We describe an efficient implementation of a CTL* model-checking algorithm based on alternating automata. We use this to check properties of an asynchronous micropipeline design described in the Rainbow framework, which operates at the micropipeline level and leads to compact models of the hardware. We also use alternating automata to characterise the expressive power and model-checking complexity for sub-logics of CTL*.", "num_citations": "11\n", "authors": ["1030"]}
{"title": "Coastal: Combining concolic and fuzzing for Java (competition contribution)\n", "abstract": " COASTAL is a program analysis tool for Java programs. It combines concolic execution and fuzz testing in a framework with built-in concurrency, allowing the two approaches to cooperate naturally.", "num_citations": "9\n", "authors": ["1030"]}
{"title": "How to evaluate rankings of academic entities using test data\n", "abstract": " In the field of scientometrics, impact indicators and ranking algorithms are frequently evaluated using unlabelled test data comprising relevant entities (e.g., papers, authors, or institutions) that are considered important. The rationale is that the higher some algorithm ranks these entities, the better its performance. To compute a performance score for an algorithm, an evaluation measure is required to translate the rank distribution of the relevant entities into a single-value performance score. Until recently, it was simply assumed that taking the average rank (of the relevant entities) is an appropriate evaluation measure when comparing ranking algorithms or fine-tuning algorithm parameters.With this paper we propose a framework for evaluating the evaluation measures themselves. Using this framework the following questions can now be answered: (1) which evaluation measure should be chosen for an experiment\u00a0\u2026", "num_citations": "9\n", "authors": ["1030"]}
{"title": "Environment modeling using runtime values for JPF-Android\n", "abstract": " Software applications are developed to be executed in a specific environment. This environment includes external/ native libraries to add functionality to the application and drivers to fire the application execution. For testing and verification, the environment of an application is simplified/abstracted using models or stubs. Empty stubs, returning default values, are simple to generate automatically, but they do not perform well when the application expects specific return values. Symbolic execution is used to find input parameters for drivers and return values for library stubs, but it struggles to detect the values of complex objects. In this work-in-progress paper, we explore an approach to generate drivers and stubs based on values collected during runtime instead of using default values. Entry-points and methods that need to be modeled are instrumented to log their parameters and return values. The instrumented\u00a0\u2026", "num_citations": "7\n", "authors": ["1030"]}
{"title": "Who Really Cares If the Program Crashes?.\n", "abstract": " X4 (1)>= X8 (1) && X10 (2)> X8 (1) && X10 (2)<= X11 (2) && X11 (2)> 0 && X10 (2)> 0 && X8 (1)<= X9 (1) && X9 (1)> 0 && X8 (1)> 0 && X4 (1)<= X2 (1) && X6 (2)> X4 (1) && X6 (2)<= X7 (2) && X7 (2)> 0 && X6 (2)> 0 && X4 (1)<= X5 (1) && X5 (1)> 0 && X4 (1)> 0 && X2 (1)<= X0 (1) && X2 (1)<= X3 (1) && X3 (1)> 0 && X2 (1)> 0 && X0 (1)<= X1 (1) && X1 (1)> 0 && X0 (1)> 0 insert (X0); insert (X1); insert (X2); insert (X3); insert (X4); insert (X5); insert (X6); insert (X7); insert (X8); insert (X9); insert (X10); insert (X11); extractMin (); private void merge (BinomialHeapNode binHeap){BinomialHeapNode temp1= Nodes, temp2= binHeap; while ((temp1!= null) && (temp2!= null)){if (temp1. degree== temp2. degree){BinomialHeapNode tmp= temp2; temp2= temp2. sibling; tmp. sibling= temp1. sibling; temp1. sibling= tmp; temp1= tmp. sibling;} else {if (temp1. degree< temp2. degree){if ((temp1. sibling== null)||(temp1. sibling. degree> temp2. degree)){", "num_citations": "7\n", "authors": ["1030"]}
{"title": "A Run-time Environment for a Validation\n", "abstract": " Our Department is currently engaged in a project to validate the correctness of reactive systems, speci cally operating system kernels. Model checking is used as a validation technique. A model checker was implemented using transition systems as a modelling formalism and computation tree logic (CTL) to specify correctness requirements. Although transition systems are powerful enough to specify the behaviour of reactive systems, it is inconvenient to use because it is too low level. Therefore a high-level validation language is required. Since the behaviour of an operating system kernel is often dependent on the manipulation of complex data the validation language must support complex data structures.This thesis describes the design and implementation of a compiler and run-time environment for a high-level validation language. The validation language ESML supporting records and lists is used for the e cient modelling of reactive systems. The compiler translates an ESML model into an equivalent transition system which is used as input by the model checker. During model checking the transitions are executed in an e cient run-time environment. A compaction technique is implemented during run-time that allows memory e cient model checking of ESML models with complex data. The design and implementation of the ESML compiler and run-time environment are described and compared to existing systems.", "num_citations": "7\n", "authors": ["1030"]}
{"title": "On the interplay between normalisation, bias, and performance of paper impact metrics\n", "abstract": " We evaluate article-level metrics along two dimensions. Firstly, we analyse metrics\u2019 ranking bias in terms of fields and time. Secondly, we evaluate their performance based on test data that consists of (1) papers that have won high-impact awards and (2) papers that have won prizes for outstanding quality. We consider different citation impact indicators and indirect ranking algorithms in combination with various normalisation approaches (mean-based, percentile-based, co-citation-based, and post hoc rescaling). We execute all experiments on two publication databases which use different field categorisation schemes (author-chosen concept categories and categories based on papers\u2019 semantic information).In terms of bias, we find that citation counts are always less time biased but always more field biased compared to PageRank. Furthermore, rescaling paper scores by a constant number of similarly aged papers\u00a0\u2026", "num_citations": "6\n", "authors": ["1030"]}
{"title": "Automated coverage calculation and test case generation\n", "abstract": " This article describes the use of symbolic execution, a formal method of static analysis, to calculate code coverage of a program's existing JUnit test suites. Code coverage is measured with respect to a number of test adequacy criteria, including statement coverage, branch coverage, condition coverage, method coverage, class coverage, and loop coverage. The results of the code coverage calculation is then used to automatically generate JUnit test cases to reach areas of a program that are not sufficiently covered. The level of redundancy of each test case is also calculated during coverage calculation, thereby identifying fully redundant, and partially redundant, test cases.", "num_citations": "6\n", "authors": ["1030"]}
{"title": "Using code level model checking to discover automation surprises\n", "abstract": " Presented a framework for automatic discovery of mode confusions in software used for simulations of aircraft and shuttle automation. We demonstrated our approach on the example of a Web-based autopilot tutorial used at NASA for pilot training. The main approach is to identify the four models of the system: the machine, the interface, the user, and the user task. The user task is described as a collection of sequences of actions performed on the display using regular expressions notation. The code for the user task is generated automatically. The user task plays the role of a driver that synchronously executes the remaining models in the system. JPF is used to go through all of the executions of the task and to check the consistency of the states across the models. If one of the models goes into a state that belongs to a different \"specification class\" than the others, JPF records the faulty execution. We implemented a\u00a0\u2026", "num_citations": "6\n", "authors": ["1030"]}
{"title": "Globalised vs averaged: Bias and ranking performance on the author level\n", "abstract": " We analyse the difference between the averaged (average of ratios) and globalised (ratio of averages) author-level aggregation approaches based on various paper-level metrics. We evaluate the aggregation variants in terms of (1) their field bias on the author-level and (2) their ranking performance based on test data that comprises researchers that have received fellowship status or won prestigious awards for their long-lasting and high-impact research contributions to their fields. We consider various direct and indirect paper-level metrics with different normalisation approaches (mean-based, percentile-based, co-citation-based) and focus on the bias and performance differences between the two aggregation variants of each metric. We execute all experiments on two publication databases which use different field categorisation schemes. The first uses author-chosen concept categories and covers the computer\u00a0\u2026", "num_citations": "5\n", "authors": ["1030"]}
{"title": "Veritesting challenges in symbolic execution of Java\n", "abstract": " Scaling symbolic execution to industrial-sized programs is an important open research problem. Veritesting is a promising technique that improves scalability by combining the advantages of static symbolic execution with those of dynamic symbolic execution. The goal of veritesting is to reduce the number of paths to explore in symbolic execution by creating formulas describing regions of code using disjunctive formulas. In previous work, veritesting was applied to binary-level symbolic execution. Integrating veritesting with Java bytecode presents unique challenges: notably, incorporating non-local control jumps caused by runtime polymorphism, exceptions, native calls, and dynamic class loading. If these language features are not accounted for, we hypothesize that the static code regions described by veritesting are often small and may not lead to substantial reduction in paths. We examine this hypothesis by\u00a0\u2026", "num_citations": "5\n", "authors": ["1030"]}
{"title": "Probabilistic program analysis\n", "abstract": " This paper provides a survey of recent work on adapting techniques for program analysis to compute probabilistic characterizations of program behavior. We survey how the frameworks of data flow analysis and symbolic execution have incorporated information about input probability distributions to quantify the likelihood of properties of program states. We identify themes that relate and distinguish a variety of techniques that have been developed over the past 15 years in this area. In doing so, we point out opportunities for future research that builds on the strengths of different techniques.", "num_citations": "5\n", "authors": ["1030"]}
{"title": "Reliability analysis in symbolic pathfinder: A brief summary\n", "abstract": " Designing a software for critical applications requires a precise assessment of reliability. Most of the reliability analysis techniques perform at the architecture level, driving the design since its early stages, but are not directly applicable to source code. We propose a general methodology based on symbolic execution of source code for extracting failure and success paths to be used for probabilistic reliability assessment against relevant usage scenarios. Under the assumption of finite and countable input domains, we provide an efficient implementation based on Symbolic PathFinder that supports the analysis of sequential and parallel Java programs, even with structured data types, at the desired level of confidence. We validated our approach on both NASA prototypes and other test cases showing a promising applicability scope.Design and implementation of software systems for critical applications is stressing the the need for methodologies and tools to assess and certify its reliability. Different definitions of reliability are introduced within different domains. In this paper we generically refer to reliability as the probability of the software to successfully accomplish its assigned task when requested (Che80). In reality most of the software we use daily is defective in some way, though it can most of the time do its job. Indeed, the presence of a defect in the code may never be realized if the input does not activate the fault (ALRL04). For this reason, the reliability of a software heavily depends on the actual usage profile the software is required to deal with.", "num_citations": "5\n", "authors": ["1030"]}
{"title": "Towards the Verification of Human-Robot Teams\n", "abstract": " Human-Agent collaboration is increasingly important. Not only do high-profile activities such as NASA missions to Mars intend to employ such teams, but our everyday activities involving interaction with computational devices falls into this category. In many of these scenarios, we are expected to trust that the agents will do what we expect and that the agents and humans will work together as expected. But how can we be sure? In this paper, we bring together previous work on the verification of multi-agent systems with work on the modelling of human-agent teamwork. Specifically, we target human-robot teamwork. This paper provides an outline of the way we are using formal verification techniques in order to analyse such collaborative activities. A particular application is the analysis of human-robot teams intended for use in future space exploration.", "num_citations": "5\n", "authors": ["1030"]}
{"title": "Monte Carlo tree search for finding costly paths in programs\n", "abstract": " We describe a heuristic analysis technique for finding costly paths in programs, where the cost refers to the execution time or memory consumed by the program. The analysis can support various software engineering tasks, such as finding vulnerabilities related to denial-of-service attacks, guiding compiler optimizations or finding performance bottlenecks in software. The analysis performs sampling over symbolic program paths, which are computed with a symbolic execution over the program, and uses Monte Carlo Tree Search (MCTS) to guide the search for costly paths. We implemented the proposed method in Symbolic PathFinder and we evaluated it on Java programs. Our experiments show the promise of the technique for finding performance bottlenecks in software.", "num_citations": "4\n", "authors": ["1030"]}
{"title": "Probabilistic programming for Java using symbolic execution and model counting\n", "abstract": " In this paper we describe a probabilistic programming environment for Java that is based on symbolic execution and model counting. The novelty of the framework is that the probability distributions in the program can themselves be symbolic, which allows parametric probabilistic programming. The framework handles typical probabilistic programming features, such as observe statements, and can be used for the encoding and analysis of Discrete Time Markov Chains (DTMC), Bayesian Networks, etc. We show two examples of using the system:(1) analysis of bubble sort when using an unreliable comparison operation, and,(2) analysis of a simulation model of autonomous aircraft towing vehicles, to show whether plans generated for these vehicles are robust when probability distributions are changed from the ones used to generate the plans.", "num_citations": "4\n", "authors": ["1030"]}
{"title": "Investigating termination of affine loops with jpf\n", "abstract": " We present some preliminary work on how to discover infinite paths through while loop programs in which the variables in the loop condition are only transformed with affine functions. The infinite paths gathered in this manner are repetitive, that is, after a fixed number of iterations the loop condition is no nearer to being violated than it was initially. A proof is given that shows that this period of repetition is 2 for the one variable case, while for the two variable case simulations suggest that the maximum period is at least 6, but a fixed period is not yet known. The algorithm is implemented as a listener in Symbolic Java PathFinder, and this implementation formed part of the Google Summer of Code 2011.", "num_citations": "4\n", "authors": ["1030"]}
{"title": "Detecting data races with java pathfinder\n", "abstract": " Roughly speaking, a (data) race on a shared variable arises in a concurrent program if two threads access that variable simultaneously and the accesses are conflicting, that is, at least one of them writes to the variable. Although some races are benign, races often are an indication of bugs. Hence, tools that detect them are invaluable to those writing concurrent programs. Many tools have been developed to detect races. These tools are based on two types of race detection techniques: dynamic and static. In dynamic race detection, a single execution of a concurrent program is checked for races. One of the key approaches to detect races dynamically is based on locksets and has been popularized by the Eraser tool [1]. In this paper, we focus on static race detection. All potential executions are considered in static race detection. Although this approach gives rise to tools that are usually sound (that is, the races that are reported by the tool are real races), the tools are generally not complete (that is, not all races are always reported). Several different approaches exist to statically detect races. Here, we concentrate on model checking. In [2] model checking is exploited to detect races in programs written in an extension of C. Here, we focus on Java PathFinder (JPF) 3 [3]. This is a model checker for Java bytecode. It has been developed in such a way that it can easily be extended. Extensions to detect races is the topic of this paper.The lockset algorithm and its numerous variations are usually exploited for dynamic race detection. However, this algorithm has also been used for static race detection. A variation on the lockset algorithm has been\u00a0\u2026", "num_citations": "4\n", "authors": ["1030"]}
{"title": "Java Ranger: Statically summarizing regions for efficient symbolic execution of Java\n", "abstract": " Merging execution paths is a powerful technique for reducing path explosion in symbolic execution. One approach, introduced and dubbed \u201cveritesting\u201d by Avgerinos et al., works by translating abounded control flow region into a single constraint. This approach is a convenient way to achieve path merging as a modification to a pre-existing single-path symbolic execution engine. Previous work evaluated this approach for symbolic execution of binary code, but different design considerations apply when building tools for other languages. In this paper, we extend the previous approach for symbolic execution of Java.", "num_citations": "3\n", "authors": ["1030"]}
{"title": "Test-case generation and bug-finding through symbolic execution\n", "abstract": " In this paper we present Artemis, a tool to analyse Java bytecode and discover run-time errors. Artemis uses the method of symbolic execution to perform path-sensitive analysis on compiled Java classes, in the process building up constraints under which errors like null pointer dereferences and division-by-zero errors can occur. During the analysis, many warnings for possible errors may occur, but not all paths leading to these warnings are feasible. Artemis uses an external decision procedure---a constraint solver---to decide the feasibility of paths, and only if a path is feasible does it generate a JUnit test case for that path. It signals the possibility of a real error only if a test case manages to detect an expected exception during an actual run by the JUnit core.", "num_citations": "3\n", "authors": ["1030"]}
{"title": "Program model checking: A practitioner's guide\n", "abstract": " Program model checking is a verification technology that uses state-space exploration to evaluate large numbers of potential program executions. Program model checking provides improved coverage over testing by systematically evaluating all possible test inputs and all possible interleavings of threads in a multithreaded system. Model-checking algorithms use several classes of optimizations to reduce the time and memory requirements for analysis, as well as heuristics for meaningful analysis of partial areas of the state space Our goal in this guidebook is to assemble, distill, and demonstrate emerging best practices for applying program model checking. We offer it as a starting point and introduction for those who want to apply model checking to software verification and validation. The guidebook will not discuss any specific tool in great detail, but we provide references for specific tools.", "num_citations": "3\n", "authors": ["1030"]}
{"title": "Testing ethereum smart contracts: A comparison of symbolic analysis and fuzz testing tools\n", "abstract": " Ethereum smart contract exploits have inflicted enormous monetary damage due to vulnerabilities introduced accidentally by the contract authors. Many of these errors can now be detected automatically by a growing number of security analysis tools that specifically target the most common vulnerabilities present in the Ethereum smart contract ecosystem. The aim of this work is to identify state-of-the-art security analysis tools that assist auditors in automatically testing and verifying real-world contracts. We compare two such symbolic executioners, Manticore (which we also extend) and Mythril, and one fuzz tester, Echidna, to evaluate their effectiveness when analysing a set of challenge contracts hosted online, as well as twenty of the most popular ERC-20 tokens found on the main Ethereum network. Our results showed that the tools were able to solve 24 of the 39 challenge contracts and both symbolic tools\u00a0\u2026", "num_citations": "2\n", "authors": ["1030"]}
{"title": "Addressing challenges in obtaining high coverage when model checking android applications\n", "abstract": " Current dynamic analysis tools for Android applications do not get good code coverage since they can only explore a subset of the behaviors of the applications and do not have full control over the environment in which they execute. In this work we use model checking to systematically explore application paths while reducing the analysis size using state matching and backtracking. In particular, we extend the Java PathFinder (JPF) model checking environment for Android. We describe the difficulties one needs to overcome to make this a reality as well as our current approaches to handling these issues. We obtain significantly higher coverage using shorter event sequences on a representative sample of Android apps, when compared to Dynodroid and Sapienz, the current state-of-the-art dynamic analysis tools for Android applications.", "num_citations": "2\n", "authors": ["1030"]}
{"title": "Impendulo: debugging the programmer\n", "abstract": " We describe the Impendulo tool for fine-grained analyses of programmer behavior. The initial design goal was to create a system to answer the following simple question:\" What kind of mistakes do programmers make and how often do they make these mistakes?\" However it quickly became apparent that the tool can be used to also analyze other fundamental software engineering questions, such as, how good are static analysis tools at finding real errors?, what is the fault finding capability of automated test generation tools?, what is the influence of a bad specification?, etc. We briefly describe the tool and some of the insights gained from using it.", "num_citations": "2\n", "authors": ["1030"]}
{"title": "What went wrong: Explaining counterexamples\n", "abstract": " Model checking, initially successful in the field of hardware design, has recently been applied to software. One of the chief advantages of model checking is the production of counterexamples demonstrating that a system does not satisfy a specification. However, it may require a great deal of human effort to extract the essence of an error from even a detailed source-level trace of a failing run. We use an automated method for finding multiple versions of an error (and similar executions that do not produce an error), and analyze these executions to produce a more succinct description of the key elements of the error. The description produced includes identification of portions of the source code crucial to distinguishing failing and succeeding runs, differences in invariants between failing and non-failing runs, and information on the necessary changes in scheduling and environmental actions needed to cause successful runs to fail. In addition, this analysis allows a classification of errors by features such as whether they are purely concurrent (ie can be induced by changing only thread scheduling).", "num_citations": "2\n", "authors": ["1030"]}
{"title": "Proceedings of the 7th International SPIN Workshop on SPIN Model Checking and Software Verification\n", "abstract": " Proceedings of the 7th International SPIN Workshop on SPIN Model Checking and Software Verification | Guide Proceedings ACM Digital Library home ACM home Google, Inc. (search) Advanced Search Browse About Sign in Register Advanced Search Journals Magazines Proceedings Books SIGs Conferences People More Search ACM Digital Library SearchSearch Advanced Search Browse Browse Digital Library Collections More HomeBrowse by TitleProceedingsProceedings of the 7th International SPIN Workshop on SPIN Model Checking and Software Verification ABSTRACT No abstract available. Index Terms (auto-classified) 1.Proceedings of the 7th International SPIN Workshop on SPIN Model Checking and Software Verification 1.Software and its engineering 1.Software creation and management 1.Software development process management 2.Software verification and validation 1.Formal software \u2026", "num_citations": "2\n", "authors": ["1030"]}
{"title": "Improving Symbolic Automata Learning with Concolic Execution.\n", "abstract": " Inferring the input grammar accepted by a program is central for a variety of software engineering problems, including parsers verification, grammar-based fuzzing, communication protocol inference, and documentation. Sound and complete active learning techniques have been developed for several classes of languages and the corresponding automaton representation, however there are outstanding challenges that are limiting their effective application to the inference of input grammars. We focus on active learning techniques based on L* and propose two extensions of the Minimally Adequate Teacher framework that allow the efficient learning of the input language of a program in the form of symbolic automata, leveraging the additional information that can extracted from concolic execution. Upon these extensions we develop two learning algorithms that reduce significantly the number of queries required to converge to the correct hypothesis.", "num_citations": "1\n", "authors": ["1030"]}
{"title": "StateComparator: Detecting Unbounded Variables Using JPF\n", "abstract": " Model checking software applications can result in exploring large or infinite state spaces. It is thus essential to identify and abstract variables that could potentially take on a large number of values, in order to increase state matching. In this paper we describe a tool we created as an extension to Java PathFinder, called State-Comparator, which compares states in the state space to identify variables that should be abstracted.", "num_citations": "1\n", "authors": ["1030"]}
{"title": "Verification of Java Programs using Symbolic Execution and Invariant Generation\n", "abstract": " Software verification is recognized as an important and difficult problem. We present a novel framework, based on symbolic execution, for the automated verification of software. The framework uses annotations in the form of method specifications and loop invariants. We present a novel iterative technique that uses invariant strengthening and approximation for discovering these loop invariants automatically. The technique handles different types of data (eg boolean and numeric constraints, dynamically allocated structures and arrays) and it allows for checking universally quantified formulas. Our framework is built on top of the Java PathFinder model checking toolset and it was used for the verification of several non-trivial Java programs.", "num_citations": "1\n", "authors": ["1030"]}
{"title": "The first international workshop on automated program analysis, testing and verification\n", "abstract": " Drug-Drug Interactions (DDIs) and associated Adverse Drug Reactions (ADRs) represent a significant public health problem in the United States. The research presented in this paper tackles the problems of representing, discovering, quantifying and visualizing patterns from high-order DDIs in a purely data-driven fashion. We formulate the problems based on a notion of directional DDI relations and correspondingly developed weighted hyper-graphlets for their representation. We also develop a convolutional scheme and its stochastic algorithm SD3ID2S to learn the directional DDI based drug-drug similarities. Our experimental results demonstrate that such approaches can well capture the patterns from high-order DDIs.", "num_citations": "1\n", "authors": ["1030"]}
{"title": "A Simulation Based Model Checker for Real Time Java\n", "abstract": " The Real Time Specification for Java (RTSJ) is an augmentation of Java for real time applications. The possibility of applying a model checker to RTSJ has great appeal given the complexity and safety requirements of its intended applications. The Robust Software Systems group at NASA Ames Research Center has Java PathFinder (JPF) under development, a Java model checker. JPF at its core is a state exploring JVM which can examine alternative paths in a Java program (eg, via backtracking) by trying all nondeterministic choices, including thread scheduling order. This paper describes our implementation of an RTSJ profile (subset) in JPF, including requirements, design decisions, and potential future extensions. The implementation relies on a discrete event simulation library, which enables modeling and verification of an RTSJ application under a programmed test environment. The primary advantage of this approach is the possibility of direct execution of the combined model on ordinary Java systems (without the benefit of state backtracking or cost accounting); the primary drawback is the difficulty of implementing important RTSJ features such as non-heap memory areas and asynchronous control transfers. The utility of a general model checker such as JPF in finding RTSJ logic and timing errors is discussed, as well as opportunities presented by JPF for more advanced forms of program analysis such as symbolic execution and test input generation.", "num_citations": "1\n", "authors": ["1030"]}