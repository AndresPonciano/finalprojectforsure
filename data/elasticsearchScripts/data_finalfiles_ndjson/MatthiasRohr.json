{"title": "Research issues in software fault categorization\n", "abstract": " Software faults are a major threat for the dependability of software systems. When we intend to study the impact of software faults on software behavior, examine the quality of fault tolerance mechanisms, or evaluate diagnostic techniques, the issue of distinguishing fault categories and their frequency distribution arises immediately. This article surveys the literature that provides quantitative data on categories of software faults and discusses the applicability of these software fault category distributions to fault injection case studies.", "num_citations": "49\n", "authors": ["715"]}
{"title": "Model-driven development of self-managing software systems\n", "abstract": " The promise of self-management is to increase the dependability of complex software systems and its quality-of-service. However, self-management is a very complex task if implemented manually at code level. It introduces high risks to the system\u2019s maintainability and dependability. Model-driven development of self-management at the architectural level is a promising alternative to manual low-level approaches. This paper outlines a model-driven approach for the model-driven realisation of self-management. The core of the approach are meta-models to specify constraints (based on architectural views), monitoring, and reconfiguration operations. These models can be used to generate selfmanagement consisting of (1.) the monitoring instrumentation,(2.) the runtime model that reflects the current state of the system in causal connection to architectural entities,(3.) the automatic checking of the conformance of the current runtime model to the given constraints, and (4.) the mapping to the reconfiguration operations that are provided by the employed middleware platforms.", "num_citations": "27\n", "authors": ["715"]}
{"title": "A classification scheme for self-adaptation research\n", "abstract": " The research on self-adaptation is distributed across many sub-disciplines of computer science. This leads to the reinvention of concepts and impairs the ability to establish a structured research program on self-adaptation. This paper contributes a classification scheme that allows to structure selfadaptation research and to compare approaches from different domains. The classification scheme is based on basic concepts that are shared across the research disciplines presented in this paper.", "num_citations": "26\n", "authors": ["715"]}
{"title": "Software reliability\n", "abstract": " Many concepts of software reliability engineering can be adapted from the older and successful techniques of hardware reliability. However, this must be done with care, since there are some fundamental differences in the nature of hardware and software and its failure processes. This chapter gives an introduction into software reliability metrics.", "num_citations": "22\n", "authors": ["715"]}
{"title": "A style-based architecture modelling approach for uml 2 component diagrams\n", "abstract": " There has been a variety of work arguing that the UML 1.x was not adequate as an Architectural Description Language (ADL). UML 2.x has made a large step towards supporting modelling software architectures, e.g. through the introduction of modelling constructs for composite structures. But many modelling constructs from ADLs can still not be mapped to the UML in a straightforward way. Important examples are typed connectors and architectural styles. We propose a mapping of of the MidArch modelling approach, which is similar to the well-known ADL Acme, to the UML 2.x and the OCL. The mapping is based on mapping the style/family construct to UML Profiles and the system/configuration construct to UML Component Diagrams. Architectural constraints are directly mapped to OCL constraints. In addition, OCL constraints are used to specialize the architecture modelling constructs of UML 2.x, and thus adapt the UML 2.x to the MidArch modelling approach. We describe a case study applying our approach and discuss our experiences.", "num_citations": "16\n", "authors": ["715"]}
{"title": "Workload-sensitive Timing Behavior Analysis for Fault Localization in Software Systems\n", "abstract": " Software timing behavior measurements, such as response times, often show high statistical variance. This variance can make the analysis difficult or even threaten the applicability of statistical techniques. This thesis introduces a method for improving the analysis of software response time measurements that show high variance. Our approach can find relations between timing behavior variance and both trace shape information and workload intensity information. This relation is used to provide timing behavior measurements with virtually less variance. This can make timing behavior analysis more robust (eg, improved confidence and precision) and faster (eg, less simulation runs and shorter monitoring period). The thesis contributes TracSTA (Trace-Context-Sensitive Timing Behavior Analysis) and WiSTA (Workload-Intensity-Sensitive Timing Behavior Analysis). TracSTA uses trace shape information (ie, the shape of the control flow corresponding to a software operation execution) and WiSTA uses workload intensity metrics (eg, the number of concurrent software executions) to create context-specific timing behavior profiles. Both the applicability and effectiveness are evaluated in several case studies and field studies. The evaluation shows a strong relation between timing behavior and the metrics considered by TracSTA and WiSTA. Additionally, a fault localization approach for enterprise software systems is presented as application scenario. It uses the timing behavior data provided by TracSTA and WiSTA for anomaly detection.", "num_citations": "13\n", "authors": ["715"]}
{"title": "Performability\n", "abstract": " Performability combines performance and reliability analysis in order to estimate the quality of service characteristics of a system in the presence of faults. This chapter provides an introduction to performability, discusses its relation to reliability and performance metrics, and presents common models used in performability analysis, such as Markov reward models or Stochastic Petri Nets.", "num_citations": "10\n", "authors": ["715"]}
{"title": "Timing Behavior Anomaly Detection in Enterprise Information Systems\n", "abstract": " Business-critical enterprise information systems (EIS) have to satisfy high availability requirements. In order to achieve the required availability, automatic failure detection and diagnosis techniques must be used. A major cause of failures in EIS are software faults in the application layer. In this paper, we propose to use anomaly detection to diagnose failures in the application layer of EIS. Anomaly detection aims to identify unusual system behavior in monitoring data. These anomalies can be valuable indicators for availability or security problems, and support failure diagnosis. In this paper we outline the basic principles of anomaly detection, present the state of the art, and typical application challenges. We outline a new approach for anomaly detection in Enterprise Information Systems that addresses some of these challenges.", "num_citations": "9\n", "authors": ["715"]}
{"title": "Architecture and Quality Standards for the Joint Development of Modular Open Source Software for Power Grid Distribution Management Systems\n", "abstract": " Regulatory effects, business pressure and the transformation to smart grids foster the need for up-todate software systems for managing and operating the grid operators\u2019 electric power grids. The complexity of these systems has grown over decades. This makes enhancements and development of new functionalities in existing systems cost intensive, vendor/system specific and often prevents meeting time to market and quality requirements. Public interfaces and open data formats allow development of enhancements and new functionality as re-usable modules by 3rd parties, thus allowing the integration of best-of-breed systems in the system landscape at grid operators. A significant reduction of system complexity is a precondition to develop such reusable modules while meeting time to market and quality requirements in critical infrastructure. This is accomplished by defining a common architecture framework, common processes and quality standards.", "num_citations": "8\n", "authors": ["715"]}
{"title": "The 5% Approach as Building Block of an Energy System Dominated by Renewables\n", "abstract": " We describe an approach for doubling distribution grid capacity for connecting renewable generators based on curtailing a maximum of 5 % of the yearly energy fed into the grid on a per-generator basis. The paper contains information about the control unit needed for automatic minimum curtailment and the field test that has been set up to validate the approach. Furthermore, topics concerning the operationalization of the 5 % approach using both operational technology and information technology are discussed.", "num_citations": "8\n", "authors": ["715"]}
{"title": "Software-Betriebs-Leitst\u00e4nde f\u00fcr Unternehmensanwendungslandschaften\n", "abstract": " In Kontrollzentren f\u00fcr Telefon-, Verkehrs- oder Energieversorgungsnetzen werden Leitst\u00e4nde verwendet, um dem Betriebspersonal einen schnellen \u00dcberblick \u00fcber die Netzarchitektur und deren gegenw\u00e4rtige Eigenschaften (z.B. Auslastung) zu bieten. Leitst\u00e4nde sind ein grundlegender Bestandteil von Kontrollzentren z.B. f\u00fcr Energieversorgungsnetze. F\u00fcr Softwaresysteme sind solche \u00dcberwachungs- und Steuerungssysteme bislang wenig verbreitet. Leitst\u00e4nde k\u00f6nnen bei der System\u00fcberwachung und dem Erkennen und Beheben von St\u00f6rungen helfen, da Betriebsdaten im Zusammenhang \u00fcberblickt werden k\u00f6nnen. Wir charakterisieren Software-Betriebs-Leitst\u00e4nde mit Hilfe einer Taxonomie von Software-Leitst\u00e4nden und beschreiben Anforderungen an solche Leitst\u00e4nde, beispielhaft f\u00fcr JavaEE-basierte Systeme.", "num_citations": "8\n", "authors": ["715"]}
{"title": "Reference architecture for open, maintainable and secure software for the operation of energy networks\n", "abstract": " Regulatory effects, business pressure, and the transformation to smart grids foster the need for up-to-date software systems to manage and operate the grid operators' electric power grids. The complexity of these systems has grown over decades. This makes enhancements and development of new functionalities in existing systems cost intensive, vendor/system specific and often prevents meeting time to market and quality requirements. Public interfaces and open data formats allow the development of enhancements and new functionality as reusable modules by third parties, thus enabling the integration of best-of-breed systems in the system landscape at grid operators. A reduction of system complexity is a precondition to develop such reusable modules while meeting time to market and quality requirements in critical infrastructure. This is accomplished by defining reference architecture with a common\u00a0\u2026", "num_citations": "6\n", "authors": ["715"]}
{"title": "Instrumentierung zum Monitoring mittels Aspekt-orientierter Programmierung\n", "abstract": " Das Monitoring gro\u00dfer, kontinuierlich laufender Softwaresysteme liefert wichtige Daten zu deren \u00dcberwachung und Fehlerdiagnose. Wenn die Wartbarkeit der zum Monitoring n\u00f6tigen Instrumentierung und der Softwareapplikation selbst kritisch ist, verbietet sich ein manuelles Einbringen des Messcodes. Aspekt-orientierte Programmierung (AOP) erm\u00f6glicht die isolierte Programmierung von Querschnittsbelangen und das automatisierte Integrieren in den Applikationscode per Annotationen. Unser Beitrag berichtet \u00fcber Erfahrungen mit AOP zur Instrumentierung f\u00fcr Performance-Monitoring in einem verteilten Kundenportalsystem eines Telekommunikationsanbieters. Insbesondere bedarf der durch AOP erhoffte Wartbarkeitsvorteil einer kritischen Untersuchung.", "num_citations": "6\n", "authors": ["715"]}
{"title": "Using CIM for Smart Grid ICT integration\n", "abstract": " The eTelligence project explores and demonstrates various smart energy grid ideas by using modern ICT (information and communications technology). For this purpose, many new and heterogeneous types of smart grid systems have to be developed and integrated, such as a regional energy market, distributed energy management systems, and an advanced metering infrastructure. The future interaction scenarios of such new systems are still topics of research, which calls for an architecture easily supporting future changes. The integration capabilities of the eTelligence ICT architecture are based on standardized communication, especially using IEC 61970/61968 (Common Information Model, CIM) and an easily extensible market product description language also realized with CIM. Additionally, we present a process model for using CIM, and report our experiences from using CIM for integration.", "num_citations": "5\n", "authors": ["715"]}
{"title": "Ein Vorgehensmodell f\u00fcr Performance-Monitoring von Informationssystemlandschaften\n", "abstract": " Der Betrieb von softwareintensiven, gesch\u00e4ftskritischen Informationssystemlandschaften ben\u00f6tigt ein Performance-Monitoring um die \u00dcberwachung und Analyse von Laufzeitverhaltens zu erm\u00f6glichen. W\u00e4hrend die rein technische Implementierung von Performance-Monitoring eher unproblematisch ist, bietet sich bisher kein Vorgehensmodell f\u00fcr den systematischen, zielgerichteten Einsatz in komplexen Systemen an. Somit haben die in der Praxis anzutreffenden \u201ead-hoc\u201d-Realisierungen oftmals eine mangelhafte Effektivit\u00e4t und Wartbarkeit zur Folge. Aus diesem Grund wird in diesem Artikel ein Monitoring-Ansatz vorgestellt, dessen Kern aus einem Vorgehensmodell f\u00fcr die Planung und Integration eines Performance-Monitoring besteht. Damit zusammenh\u00e4ngend wurde eine wiederverwendbare Infrastruktur entwickelt, die die Monitoringdatenintegration f\u00fcr verteilte Systeme leistet. Der vorgestellte Ansatz wurde in einem Telekommunikationsunternehmen evaluiert und die dementsprechend umgesetzte Monitoring-L\u00f6sung befindet sich seit Mai 2006 im operativen Betrieb.", "num_citations": "5\n", "authors": ["715"]}
{"title": "Towards a modular and scalable architecture for high-level smart grid applications\n", "abstract": " Sensor and actor population within future smart distribution grids is much denser than within transmission grids. Thereby, future grid management systems have to cope with larger amounts of data than today's grid management systems. Also, future high-level applications for network management must be suited for use within automatic control loops. This results in new challenges for designing high-level application components for power grid management. This paper addresses related software engineering challenges and presents solutions for designing software within the context of grid management.", "num_citations": "3\n", "authors": ["715"]}
{"title": "Realisierung einer Smart Grid-Architektur\n", "abstract": " In eTelligence erfolgte die technische Umsetzung einiger Anwendungsfelder aus dem Bereich \u201eSmart Energy\u201c. Im Projekt wurde lediglich der Energietr\u00e4ger Strom betrachtet, ausgespart wurden jedoch die Aspekte Stromspeicherung, Elektromobilit\u00e4t und Z\u00e4hlerwechselprozesse. Hinsichtlich der konkreten Umsetzung werden in diesem Kapitel die vorl\u00e4ufigen Erfahrungen mit der Architektur und dem dazugeh\u00f6rigen System betrachtet. Im Folgenden werden die Architekturkonzeption (Abschnitt 9.1), die verwendeten Architekturstile (Abschnitt 9.2), die verwendeten Kommunikationsstandards mit einem Detailbeispiel (Abschnitt 9.3) und die dazugeh\u00f6rigen IT-Architektur (Abschnitt 9.4) vorgestellt.", "num_citations": "2\n", "authors": ["715"]}
{"title": "Die eTelligence-Referenzarchitektur\u2013Eine standardbasierte Architektur f\u00fcr regionale Stromm\u00e4rkte\n", "abstract": " Aus dem aktuellen Wandel in der Energiewirtschaft hin zu einer dezentralen Energieversorgung ergeben sich sowohl technische und konzeptuelle Herausforderungen als auch \u00f6konomische und \u00f6kologische Potenziale. Im E-Energy-Projekt eTelligence wird derzeit eine Referenzarchitektur entwickelt, welche die grunds\u00e4tzlichen Anforderungen an einen regionalen Strommarkt erfasst und auf eine abstrakte Systemarchitektur abbildet. Prozesse der Gesch\u00e4fts-und Automatisierungsebene werden dabei vorrangig auf Basis internationaler Standards (IEC 61850, IEC 61968/61970) umgesetzt. Dieser Beitrag gibt erste Einblicke in die Struktur und Schwerpunkte der entwickelten Architektur.", "num_citations": "2\n", "authors": ["715"]}
{"title": "Liability risks in reusing third-party software\n", "abstract": " Liability risks in reusing third-party software Page 1 144 December 2006/Vol. 49, No. 12 COMMUNICATIONS OF THE ACM Reuse of well-tried components promises cost- effective construction of high-quality software systems. With this approach, third-party soft- ware components are usually integrated into complex software systems. The risks of using such components of different suppliers are both technical and judicial. Some technical problems were discussed by Peter G. Neumann in the July 2006 \u201cInside Risks\u201d column. Here, we discuss emergent judicial concerns as they apply in Europe. From the judicial point of view, a risk exists for system vendors to be held liable for malfunctions that are not self-induced, without being able to take recourse to the supplier delivering the faulty component. The resulting problems are evident in the context of German legislation. These problems apply throughout the European \u2026", "num_citations": "2\n", "authors": ["715"]}
{"title": "Example of empirical research: N-version programming\n", "abstract": " Software engineering aims to improve the process of software development and its resulting product. The human factor introduces complex behavior into the process. This is difficult to describe with analytical mod els. Therefore, empirical research methods often are a more effective way to validate research results. In this paper empirical research methods are studied. We focus the analysis on examples from N-version programming research. N-version programming is a software development strategy to increase reliability throug h redundancy. This area is chosen because its nature suggests and supports the empirical examination very well, with still providing typical complexity and a large number of empirical studies available.", "num_citations": "2\n", "authors": ["715"]}
{"title": "Timing Behavior Anomaly Detection for Fault Localization\n", "abstract": " Mission-critical enterprise information systems have to satisfy high availability requirements. The availability of a system is determined by the reliability of its components and the mean time to repair when a failure occurs. The automatic localization of a fault (which is the cause of a failure) can significantly reduce repair times and therefore, lead to better availability. Today\u2019s enterprise systems are increasingly software-intensive, so that in particular software faults threaten the system dependability.For some failures of software, fault localization is simple as the failure symptoms directly point to the location of the responsible fault. However, many faults are very difficult to localize, and are a major threat to dependability because of long repair times. The major difficulty in the localization of these software faults originates from the high complexity of the underlying error propagation processes. As software systems have become very complex itself, it is often hard to understand how a system performs service delivery. The backward reconstruction of the system operation to identify possible causes of failures is usually an even greater challenge. Additionally, the transient system state is often lost after a failure occurrence and with it many hints for fault localization. Therefore, many systems have integrated detailed monitoring to record persistent information about the system behavior that helps to explain failures and find their faults. However, it is difficult and time-consuming to manually analyze this large amounts of information.", "num_citations": "1\n", "authors": ["715"]}
{"title": "Kiek-Eine Modellierungsumgebung f\u00fcr Hierarchische Asymmetrische Zellulare Automaten\n", "abstract": " Zellulare Automaten (ZA) bieten eine einfache M\u00f6glichkeit, r\u00e4umliche Prozesse zu modellieren. Mit ihrer Hilfe wird deutlich, wie durch einfache Regeln komplexes Verhalten entstehen kann, wie es in der Natur zu finden ist. Allerdings lassen sich viele reale \u00f6kologische Systeme nur mit M\u00fche in dieses Modell \u00fcberf\u00fchren, da durch eine Rasterung des Gebietes wichtige r\u00e4umliche Informationen verloren gehen. Hierarchische Asymmetrische Zellulare Automaten (HAZA) sind eine auf ZA basierende, an der Universit\u00e4t Oldenburg entwickelte Modellierungsmethode mit dem Ziel, den erweiterten Anforderungen von (landschafts-) \u00f6kologischen oder sozio-\u00f6konomischen Systemen gerecht zu werden. Im vorliegenden Aufsatz soll zum einem das Konzept, welches HAZA zugrunde liegt, erl\u00e4utert und zum anderen unsere auf HAZA basierende Modellierungs-und Simulationsumgebung\" Kiek\" vorgestellt werden.", "num_citations": "1\n", "authors": ["715"]}