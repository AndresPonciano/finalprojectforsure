{"title": "A model for spectra-based software diagnosis\n", "abstract": " This article presents an improved approach to assist diagnosis of failures in software (fault localisation) by ranking program statements or blocks in accordance with to how likely they are to be buggy. We present a very simple single-bug program to model the problem. By examining different possible execution paths through this model program over a number of test cases, the effectiveness of different proposed spectral ranking methods can be evaluated in idealised conditions. The results are remarkably consistent to those arrived at empirically using the Siemens test suite and Space benchmarks. The model also helps identify groups of metrics that are equivalent for ranking. Due to the simplicity of the model, an optimal ranking method can be devised. This new method out-performs previously proposed methods for the model program, the Siemens test suite and Space. It also helps provide insight into other ranking\u00a0\u2026", "num_citations": "465\n", "authors": ["1819"]}
{"title": "Negation and control in Prolog\n", "abstract": " The contributions to this volume cover all aspects of the assessment and management of hepatobiliary disease. The focal points of the book consist of three state-of-the-art summaries. The first of these deals with the highly topical problem of liver transplants from the point of view of patient selection. The second considers drug-induced liver injury in view of the fact that the liver is the main metabolic site for a number of drugs. The final summary deals with liver and aging: it asks whether the liver follows the aging process of the host organisms and whether the liver of aged liver transplant candidate donors could be suitable for grafting. Aside from these topics, the volume presents basic research on hepatic transport mechanisms, intrahepatic cholestasis and gall-stone disease, which serves as a background for the topics more specifically concerning the assessment of liver function. Much of the book is then devoted to the management of the commonest forms of liver diseases and their complications, such as chronic active hepatitis, liver cirrhosis, portal hypertension, hepatic encephalopathy, hepatorenal syndrome, and ascites.", "num_citations": "340\n", "authors": ["1819"]}
{"title": "Hybrid probabilistic programs\n", "abstract": " The precise probability of a compound event (eg e 1\u2228 e 2, e 1\u2227 e 2) depends upon the known relationships (eg independence, mutual exclusion, ignorance of any relationship, etc.) between the primitive events that constitute the compound event. To date, most research on probabilistic logic programming has assumed that we are ignorant of the relationship between primitive events. Likewise, most research in AI (eg Bayesian approaches) has assumed that primitive events are independent. In this paper, we propose a hybrid probabilistic logic programming language in which the user can explicitly associate, with any given probabilistic strategy, a conjunction and disjunction operator, and then write programs using these operators. We describe the syntax of hybrid probabilistic programs, and develop a model theory and fixpoint theory for such programs. Last, but not least, we develop three alternative procedures\u00a0\u2026", "num_citations": "160\n", "authors": ["1819"]}
{"title": "A declarative debugging scheme\n", "abstract": " We present a very simple but exible declarative debugging scheme. A declarative debugger can be de ned in Prolog with a single clause and relies on the de nition of just two additional predicates. With suitable de nitions of these predicates the debugger can diagnose several classes of bugs in many languages. We give examples of diagnosis of wrong answers in functional, relational and object oriented languages as well as missing answers in relational languages and calls which are not well-de ned in functional languages. By using declarative semantics of programs, the debugger is able to hide complex execution mechanisms such as uni cation, backtracking, coroutining, parallelism, higher order functions, lazy evaluation, message passing and inheritance.", "num_citations": "155\n", "authors": ["1819"]}
{"title": "Automating control for logic programs\n", "abstract": " A model for the coroutined execution of PROLOG programs is presented, and two control primitives are described. Heuristics for the control of data-base and recursive procedures are given, which lead to algorithms for generating control information. These algorithms can be incorporated into a preprocessor for logic programs. It is argued that automatic generation should be an important consideration when designing control primitives and is a significant step towards simplifying the task of programming.", "num_citations": "110\n", "authors": ["1819"]}
{"title": "Negation and quantifiers in NU-Prolog\n", "abstract": " We briefly discuss the shortcomings of negation in conventional Prolog systems. The design and implementation of the negation constructs in NU-Prolog are then presented. The major difference is the presence of explicit quantifiers. However, several other innovations are used to extract the maximum flexibility from current implementation techniques. These result in improved treatment of \u201cif\u201d, existential quantifiers, inequality and non-logical primitives. We also discuss how the negation primitives of NU-Prolog can be added to conventional systems, and how they can improve the implementation of higher level constructs.", "num_citations": "98\n", "authors": ["1819"]}
{"title": "Parallelizing nu-prolog\n", "abstract": " CiNii \u8ad6\u6587 - Parallelizing NU-Prolog CiNii \u56fd\u7acb\u60c5\u5831\u5b66\u7814\u7a76\u6240 \u5b66\u8853\u60c5\u5831\u30ca\u30d3\u30b2\u30fc\u30bf[\u30b5\u30a4\u30cb\u30a3] \u65e5\u672c\u306e \u8ad6\u6587\u3092\u3055\u304c\u3059 \u5927\u5b66\u56f3\u66f8\u9928\u306e\u672c\u3092\u3055\u304c\u3059 \u65e5\u672c\u306e\u535a\u58eb\u8ad6\u6587\u3092\u3055\u304c\u3059 \u65b0\u898f\u767b\u9332 \u30ed\u30b0\u30a4\u30f3 English \u691c\u7d22 \u3059\u3079\u3066 \u672c\u6587\u3042\u308a \u3059\u3079\u3066 \u672c\u6587\u3042\u308a \u9589\u3058\u308b \u30bf\u30a4\u30c8\u30eb \u8457\u8005\u540d \u8457\u8005ID \u8457\u8005\u6240\u5c5e \u520a\u884c\u7269\u540d ISSN \u5dfb\u53f7\u30da\u30fc\u30b8 \u51fa\u7248\u8005 \u53c2\u8003\u6587\u732e \u51fa\u7248\u5e74 \u5e74\u304b\u3089 \u5e74\u307e\u3067 \u691c\u7d22 \u691c\u7d22 \u691c\u7d22 CiNii\u7a93\u53e3\u696d\u52d9\u306e\u518d\u958b\u306b\u3064\u3044\u3066 Parallelizing NU-Prolog NAISH L. \u88ab\u5f15\u7528\u6587\u732e: 1\u4ef6 \u8457\u8005 NAISH L. \u53ce\u9332\u520a\u884c\u7269 Logic Programming, Proceedings of the Fifth International Conference and Symposium Logic Programming, Proceedings of the Fifth International Conference and Symposium, 1546-1564, 1988 The MIT Press \u88ab\u5f15\u7528\u6587\u732e: 1\u4ef6\u4e2d 1-1\u4ef6\u3092 \u8868\u793a 1 AND OR\u4e26\u5217\u8ad6\u7406\u578b\u8a00\u8a9eANDOR - II\u306e\u4e26\u5217\u8ad6\u7406\u578b \u8a00\u8a9e\u3078\u306e\u5909\u63db \u7af9\u5185 \u5f70\u4e00 , \u9ad8\u6a4b \u548c\u5b50 , \u5742\u672c \u5fe0\u662d \u60c5\u5831\u51e6\u7406\u5b66\u4f1a\u8ad6\u6587\u8a8c 33(1), 54-63, 1992-01-15 \u53c2\u8003 \u6587\u732e19\u4ef6 Tweet \u5404\u7a2e\u30b3\u30fc\u30c9 NII\u8ad6\u6587ID(NAID) 10007985948 \u8cc7\u6599\u7a2e\u5225 \u56f3\u66f8\u306e\u4e00\u90e8 \u30c7\u30fc\u30bf\u63d0\u4f9b\u5143 CJP\u2026", "num_citations": "93\n", "authors": ["1819"]}
{"title": "A higher order rewriting logic for functional logic programming\n", "abstract": " According to a well known conception, programs in a declarative programming language can be viewed as theories in some suitable logic, while computations can be viewed as deductions. In our opinion, there is yet no general assent on the logic to be viewed as the foundation of higher order, lazy functional logic languages. In this paper, we argue that a specific rewriting logic can play this role, and we justify the adequacy of our proposal by means of proof-theoretical and model-theoretical results. Moreover, we present a sound and complete lazy narrowing calculus for goal solving, and we discuss a circuit synthesis problem that illustrates the expressiveness of our approach. This example has been tested in an implemented system.", "num_citations": "91\n", "authors": ["1819"]}
{"title": "Adding equations to NU-Prolog\n", "abstract": " This paper describes an extension to NU-Prolog which allows evaluable functions to be defined using equations. We consider it to be the most pragmatic way of combining functional and relational programming. The implementation consists of several hundred lines of Prolog code and the underlying Prolog implementation was not modified at all. However, the system is reasonably efficient and supports coroutining, optional lazy evaluation, higher order functions and parallel execution. Efficiency is gained in several ways. First, we use some new implementation techniques. Second, we exploit some of the unique features of NU-Prolog, though these features are not essential to the implementation. Third, the language is designed so that we can take advantage of implicit mode and determinism information. Although we have not concentrated on the semantics of the language, we believe that our language\u00a0\u2026", "num_citations": "76\n", "authors": ["1819"]}
{"title": "Most specific logic programs\n", "abstract": " More specific versions of definite logic programs are introduced. These are versions of a program in which each clause is further instantiated or removed and which have an equivalent set of successful derivations to those of the original program, but a possibly increased set of finitely failed goals. They are better than the original program because failure in a non-successful derivation may be detected more quickly. Furthermore, information about allowed variable bindings which is hidden in the original program may be made explicit in a more specific version of it. This allows better static analysis of the program's properties and may reveal errors in the original program. A program may have several more specific versions but there is always a most specific version which is unique up to variable renaming. Methods to calculate more specific versions are given and it is characterized when they give the most\u00a0\u2026", "num_citations": "71\n", "authors": ["1819"]}
{"title": "Declarative diagnosis of missing answers\n", "abstract": " This paper investigates algorithms for declarative diagnosis of missing answers in Prolog programs, especially programs which use coroutines. The logic of the problem is first presented, in the form of the simplest possible debugger. Next, we compare several previously published declarative debuggers based on Shapiro\u2019s work. Examples showing incompleteness, incorrectness and equivalence of debuggers are given. Several enhancements to these debuggers are presented which can reduce the number and complexity of questions asked of the oracle, while still supporting coroutines. Although no debugger considered is best in all cases, the new algorithms are a practical contribution. Finally, we discuss diagnosis algorithms based more on Pereira\u2019s work. These algorithms ask easier questions than Shapiro\u2019s algorithms but rely on the standard left to right computation rule. We discuss possible ways to\u00a0\u2026", "num_citations": "68\n", "authors": ["1819"]}
{"title": "Assumption Grammars for Processing Natural Language.\n", "abstract": " In this paper we examine three natural language uses of a recently developed logic grammar formalism-Assumption Grammars-particularly suitable for hypothetical reasoning. They are based on intuitionistic and linear implications scoped over the current continuation, which allows us to follow given branches of the computation under hypotheses that disappear when and if backtracking takes place. We also show two results which were surprising to us, namely: a) Assumption grammars allow a direct and efficient implementation of link grammars\u2014a context-free like formalism developed independently from logic grammars; and b) they offer the flexibility of switching between data-driven or goal-driven reasoning, at no overhead in. terms of either syntax or implementation.", "num_citations": "67\n", "authors": ["1819"]}
{"title": "An introduction to MU-Prolog\n", "abstract": " As a logic programming language, PROLOG is deficient in two areas: negation and control facilities. Unsoundly implemented negation affects the correctness of programs and poor control facilities affect the termination and efficiency. These problems are illustrated by examples.", "num_citations": "63\n", "authors": ["1819"]}
{"title": "Higher-order logic programming in Prolog\n", "abstract": " This is yet another paper which tells logic programmers what functional programmers have known and practiced for a long time:\\higher order\" programming is the way to go. How is this paper different from some of the others? First, we point out that call/N is not the way to go, despite its recent popularity as the primitive to use for higher order logic programming. Second, we use standard Prolog rather than a new language. Third, we compare higher order programming with the skeletons and techniques approach. Fourth, we present solutions to some (slightly) more challenging programming tasks. The interaction between higher order programming and some of the unique features of logic programming is illustrated and some important programming techniques are discussed. Finally, we examine the efficiency issue.", "num_citations": "61\n", "authors": ["1819"]}
{"title": "Types and the intended meaning of logic programs\n", "abstract": " CiNii \u8ad6\u6587 - Types and the intended meaning of logic programs CiNii \u56fd\u7acb\u60c5\u5831\u5b66\u7814\u7a76\u6240 \u5b66\u8853 \u60c5\u5831\u30ca\u30d3\u30b2\u30fc\u30bf[\u30b5\u30a4\u30cb\u30a3] \u65e5\u672c\u306e\u8ad6\u6587\u3092\u3055\u304c\u3059 \u5927\u5b66\u56f3\u66f8\u9928\u306e\u672c\u3092\u3055\u304c\u3059 \u65e5\u672c\u306e\u535a\u58eb\u8ad6\u6587\u3092\u3055\u304c\u3059 \u65b0\u898f \u767b\u9332 \u30ed\u30b0\u30a4\u30f3 English \u691c\u7d22 \u3059\u3079\u3066 \u672c\u6587\u3042\u308a \u3059\u3079\u3066 \u672c\u6587\u3042\u308a \u9589\u3058\u308b \u30bf\u30a4\u30c8\u30eb \u8457\u8005\u540d \u8457\u8005ID \u8457\u8005\u6240\u5c5e \u520a\u884c\u7269\u540d ISSN \u5dfb\u53f7\u30da\u30fc\u30b8 \u51fa\u7248\u8005 \u53c2\u8003\u6587\u732e \u51fa\u7248\u5e74 \u5e74\u304b\u3089 \u5e74\u307e\u3067 \u691c\u7d22 \u691c\u7d22 \u691c\u7d22 CiNii\u306e\u30b5\u30fc\u30d3\u30b9 \u306b\u95a2\u3059\u308b\u30a2\u30f3\u30b1\u30fc\u30c8\u3092\u5b9f\u65bd\u4e2d\u3067\u3059\uff0811/11(\u6c34)-12/23(\u6c34)\uff09 Types and the intended meaning of logic programs NAISH L. \u88ab\u5f15\u7528\u6587\u732e: 1\u4ef6 \u8457\u8005 NAISH L. \u53ce\u9332\u520a\u884c\u7269 Typed in Logic Programming Typed in Logic Programming, 189-216, 1992 The MIT Press \u88ab\u5f15\u7528\u6587\u732e: 1\u4ef6\u4e2d 1-1\u4ef6\u3092 \u8868\u793a 1 Applying Program Transformation to Type Inference for a Logic Language KAWAGUCHI Yuuichi , AKAMA Kiyoshi , MIYAMOTO Eiichi IEICE transactions on information and systems 81(11), 1141-1147, 1998-11-25 \u53c2\u8003\u6587\u732e10\u4ef6 CiNii\u5229\u7528\u8005\u30a2\u30f3\u30b1\u30fc\u30c8 Tweet \u5404\u7a2e\u30b3\u30fc\u30c9 \u2026", "num_citations": "59\n", "authors": ["1819"]}
{"title": "The NU-Prolog Debugging Environment.\n", "abstract": " One of the advantages of logic programming is that it is easy to reason about what is computed by a program (the declarative semantics) independently of how it is computed (the procedural semantics). As well as being useful for writing, transforming and understanding programs, these two alternative viewpoints are useful for testing and debugging programs. By taking full advantage of declarative and procedural semantics, we anticipate that very powerful programming environments can be constructed. In this paper we describe the NU-Prolog Debugging Environment (NUDE) which is currently under development. NUDE has three main components. First, several static program analysis tools are used for detecting program errors such as simple typing mistakes,\u2018type\u2019errors, infinite loops and floundering. Second, dynamic tools are provided for diagnosing incorrect behaviour of a query at run time. There are tools for diagnosing wrong answers, missing answers, infinite loops and floundering. Third, there is a mechanism for automatically testing programs to detect queries with wrong or missing answers. The three components are integrated into the NU-Prolog system, supporting a rapid test-debug-recompile cycle.", "num_citations": "52\n", "authors": ["1819"]}
{"title": "Practical aspects of declarative debugging in Haskell 98\n", "abstract": " Non-strict purely functional languages pose many challenges to the designers of debugging tools. Declarative debugging has long been considered a suitable candidate for the task due to its abstraction over the evaluation order of the program, although the provision of practical implementations has been lagging. In this paper we discuss the solutions used in our declarative debugger for Haskell to tackle the problems of printing values, memory usage and I/O. The debugger is based on program transformation, although much leverage is gained by interfacing with the runtime environment of the language implementation through a foreign function interface.", "num_citations": "51\n", "authors": ["1819"]}
{"title": "Coroutining and the construction of terminating logic programs\n", "abstract": " This paper investigates the role of coroutining in the termination of logic programs. We de ne a variant of SLD resolution, in which the execution of atoms may be suspended inde nitely, and give some basic results concerning success, nite failure and oundering. Next we discuss how correct procedures can be combined to form new procedures using disjunction, conjunction and recursion. We argue that modes are crucial to reasoning about termination and show that cyclic modes are the basic reason for conjunctions looping. When recursion is used we identify another cause of loops: speculative binding of output variables. That is, binding output variables before it is known that a solution to a subcomputation exists.", "num_citations": "51\n", "authors": ["1819"]}
{"title": "Declarative debugging of lazy functional programs\n", "abstract": " Declarative debugging (also called algorithmic, rational and deductive debugging) Sha83, Per86, SS86, DL87, Llo87] is a debugging methodology which was originally developed for logic programming. Bugs can be located using only declarative knowledge of the program (what results returned by procedures are correct) rather than procedural knowledge (the sequence of operations performed during execution). This approach is particularly advantageous when the evaluation mechanism is complicated. Prolog, for example, uses uni cation, backtracking and (in some systems) coroutining, so nding errors from a trace of the execution can be very di cult. In contrast, the declarative semantics of pure Prolog programs is straightforward. A program can be seen as a set of formulas in rst order logic. A declarative debugger for Prolog asks the user (or some other oracle) if results returned by procedures are true in the intended interpretation of the program. In this way the bug can isolated to a particular procedure or clause.Many functional programming languages have well de ned declarative semantics or, like Prolog, have\\pure\" subsets with this property. Referential transparency allows us to determine the correctness of the result of a function call without knowing the actual steps in the execution. This is exactly what is required for declarative debugging. It is rather surprising how little work there has been on adapting declarative debugging techniques to these languages. The debugging support for many functional languages is poor, and many languages use lazy evaluation. Lazy evaluation, like the complex evaluation mechanism of Prolog, makes\u00a0\u2026", "num_citations": "47\n", "authors": ["1819"]}
{"title": "Shuffle-sum: coercion-resistant verifiable tallying for STV voting\n", "abstract": " There are many advantages to voting schemes in which voters rank all candidates in order, rather than just choosing their favorite. However, these schemes inherently suffer from a coercion problem when there are many candidates, because a coercer can demand a certain permutation from a voter and then check whether that permutation appears during tallying. Recently developed cryptographic voting protocols allow anyone to audit an election (universal verifiability), but existing systems are either not applicable to ranked voting at all, or reveal enough information about the ballots to make voter coercion possible. We solve this problem for the popular single transferable vote (STV) ranked voting system, by constructing an algorithm for the verifiable tallying of encrypted votes. Our construction improves upon existing work because it extends to multiple-seat STV and reveals less information than other schemes\u00a0\u2026", "num_citations": "46\n", "authors": ["1819"]}
{"title": "Towards a portable lazy functional declarative debugger\n", "abstract": " Declarative (or algorithmic) debugging is a promising technique for debugging lazy functional programs. This paper addresses two important reasons why it is not more widespread: the di culty of writing a declarative debugger for a lazy functional language in the language itself and the e ciency of the debugger. Using the source language to implement the debugger is desirable for portability and we discuss the reasons why this is very di cult to do. We propose a system in which nearly all the code is in the source language but there is one function which must be written at lower level. We also show how this function can be the key to signi cantly improving the e ciency of declarative debuggers for such languages.", "num_citations": "46\n", "authors": ["1819"]}
{"title": "A three-valued declarative debugging scheme\n", "abstract": " Declarative debugging has many advantages over conventional approaches to debugging for logic and functional programs. This paper extends a previously defined scheme for declarative debugging in which computations were considered either correct or erroneous. We argue that a third value, \"inadmissible\", should be supported and show how this can be done. Two classes of bugs are defined: one equivalent to the bugs defined by the two valued scheme, the other associated with inadmissibility: it is shown how different instances of the scheme can be used to diagnose type errors, mode errors, violated assertions and abnormal termination as well as the more familiar classes of bugs detected by declarative debuggers.", "num_citations": "43\n", "authors": ["1819"]}
{"title": "A Strong Correspondence between Description Logics and Open Logic Programming.\n", "abstract": " This paper formally investigates the relationship between Open Logic Programming (OLP) and Description Logics (DL). A description logic is designed to represent two different forms of knowledge. A T-Box represents definitional knowledge, ie definitions for a set of concepts. An A-Box represents assertional knowledge about specific domain objects. OLP is a declarative, terminological interpretation of the formalism of Abductive Logic Programming. In this interpretation, an abductive logic program is considered to consist of a T-Box providing definitions for non-abducible predicates and an A-Box providing assertional knowledge in the form of first order logic axioms. We define a provably correct mapping of DL theories to open logic programs, and identify sublanguages of OLP corresponding to several description logics. We also show strong correspondences between derivations produced by a typical DL algorithm and an abductive resolution procedure. The correspondences clarify long-questioned relationships between Logic Programming and Description Logics. To the LP community they may offer the possibility to import efficient reasoning techniques used in description logics. More importantly, the correspondences indicate the value of OLP as a suitable and highly expressive knowledge representation language, as opposed to both standard LP and first order logic. As current description logics are all subsets of OLP, the latter may also indicate directions for enhancing the expressivity of the former.", "num_citations": "41\n", "authors": ["1819"]}
{"title": "A superjoin algorithm for deductive databases\n", "abstract": " This paper describes a join algorithm suitable for deductive as well as relational databases that are accessed by computers with large main memories. Using multi-key hashing and appropriate buffering, joins can be performed on very large relations more efficiently than with existing methods. This algorithm fits naturally into PROLOG top-down computations and can be made very flexible by incorporating additional PROLOG features. It can also be used with bottom-up query evaluation strategies.", "num_citations": "39\n", "authors": ["1819"]}
{"title": "All Solutions Predicates in Prolog.\n", "abstract": " It is generally agreed that an\" all solutions\u201d predicate is a useful extension to PROLOG. There are a great number of implementations of such predicates but all those we know of lack a well defined declarative semantics. All can be used to implement non-logical\" predicates\", such One specification of the semantics of an all solutions predicate appears in the literature but we show this leads to inefficiency, if implemented correctly.", "num_citations": "38\n", "authors": ["1819"]}
{"title": "NUA-Prolog: An Extension to the WAM for Parallel Andorra.\n", "abstract": " NUA-Prolog is an experimental parallel Prolog system which uses the Andorra model to exploit and-parallelism. Built on the Parallel NU-Prolog system, NUA-Prolog combines a compile-time analysis of possible determinism with a small number of new Warren abstract machine instructions. A variant of decision trees, called clause sets, has been developed to allow the detection of determinism. The generation of decision trees is an NP-hard problem, leading to unacceptable increases in code size for more complex predicates. Clause sets provide a simple way of avoiding NP-hardness, while maintaining flexibility. Performance data shows that NUA-Prolog has comparable performance to sequential NU-Prolog, when run on a single processor, and sometimes considerable parallel speed-ups.", "num_citations": "37\n", "authors": ["1819"]}
{"title": "Visual representations for recursive algorithms\n", "abstract": " We have developed a framework for pedagogically-oriented animations, designed to help students learn new algorithms. Recursive sorting and searching algorithms pose a particular challenge, as it can be difficult to find visual representations that help students develop a mental model of how the recursion proceeds. Relatively complex representations, such as thumbnail sketches or explicitly showing the function stack along with the data structure are appropriate for some algorithms, while simpler representations suffice for others. We have found it useful to classify recursive algorithms according to the way they navigate through a data structure and manipulate data items within it, sometimes with further subdivision according to the kind of recursion. Within each category there are common strategies for visual representation. While there may be no single, general way to represent recursive algorithms, classification\u00a0\u2026", "num_citations": "36\n", "authors": ["1819"]}
{"title": "Coercion-Resistant Tallying for STV Voting.\n", "abstract": " There are many advantages to voting schemes in which voters rank all candidates in order, rather than just choosing their favourite. However, these schemes inherently suffer from a coercion problem when there are many candidates, because a coercer can demand a certain permutation from a voter and then check whether that permutation appears during tallying. In this paper, we solve this problem for the popular STV system, by constructing an algorithm for the verifiable tallying of encrypted votes. Our construction improves upon existing work because it extends to multiple-seat STV and reveals less information than other schemes.", "num_citations": "35\n", "authors": ["1819"]}
{"title": "Study of the relationship of bug consistency with respect to performance of spectra metrics\n", "abstract": " In practice, manual debugging to locate bugs is a daunting and time-consuming task. By using software fault localization, we can reduce this time substantially. The technique of software fault localization can be performed using execution profiles of the software under several test inputs. Such profiles, known as program spectra, consist of the coverage of correct and incorrect executions statement from a given test suite. We have performed a systematic evaluation of several metrics that make use of measurement obtained from program spectra on Siemens test suite. In this paper, we discuss how the effectiveness of various metrics degrade in determining buggy statements as the bug consistency (error detection accuracy, q e ) of a statement approaches zero. Bug consistency of a statement refers to the ratio of the number of failed tests executing the statement over the total number of tests executing the statement\u00a0\u2026", "num_citations": "32\n", "authors": ["1819"]}
{"title": "Prolog control rules\n", "abstract": " We present an overview of the many control constructs and heuristics used by PROLOG systems with extra control facilities. Two features of computations rules are used to evaluate and classify them. They are detecting failure quickly (where it is unavoidable) and avoiding failures. By examining current systems in this light, we reach conclusions concerning deficiencies in performance, and how they may be overcome. We propose an idealized computation rule which uses a hierarchy of goals and a breadth first component.", "num_citations": "32\n", "authors": ["1819"]}
{"title": "Concurrent Database Updates in PROLOG.\n", "abstract": " The standard primitives available in Prolog for updating databases are not adequate for practical database systems. There are significant problems with: semantics; implementation when using efficient indexing schemes and multi-user access; integrity constraint checking; maintaining database consistency in am ulti-user environment; and backup and recovery.", "num_citations": "31\n", "authors": ["1819"]}
{"title": "Automatic Compile-time Parallelization of Prolog Programs for Dependent And-Parallelism.\n", "abstract": " We discuss the issues involved in using static analysis to detect dependent andparallelism in Prolog programs. We present a static analysis technique based on abstract interpretation that detects (fruitful) dependent and-parallelism. Our method makes use of several types of information about the program\u2014sharing and freeness, granularity of subgoals, and binding-times of program variables\u2014computed using abstract interpretation. The information collected from different sources is used to produce a suitable annotation of the original program. This annotation identifies:(i) the most fruitful sources of parallelism; and,(ii) the dependencies that must be respected during execution. A prototype compiler that incorporates these ideas has been implemented and tested on the ACE and-or parallel Prolog system. The encouraging results obtained are reported here.", "num_citations": "28\n", "authors": ["1819"]}
{"title": "Spectral debugging with weights and incremental ranking\n", "abstract": " Software faults can be diagnosed using program spectra. The program spectra considered here provide information about which statements are executed in each one of a set of test cases. This information is used to compute a value for each statement which indicates how likely it is to be buggy, and the statements are ranked according to these values. We present two improvements to this method. First, we associate varying weights with failed test cases --- test cases which execute fewer statements are given more weight and have more influence on the ranking. This generally improves diagnosis accuracy, with little additional cost. Second, the ranking is computed incrementally. After the top-ranked statement is identified, the weights are adjusted in order to compute the rest of the ranking. This further improves accuracy. The cost is more significant, but not prohibitive.", "num_citations": "27\n", "authors": ["1819"]}
{"title": "A Declarative View of Modes.\n", "abstract": " Mode information in logic programming is concerned with such things as inputs and outputs of procedures, producers and consumers of variable bindings, instantiation states of calls during execution and the order of execution. Modes seem inextricably tied to the procedural rather than the declarative view of logic programs. Despite this, we argue that purely declarative information can actually express the essence of modes remarkable well. The declarative view allows a high level notion of correctness which is independent of how the information is used.We start from a framework which includes types and show how a set of ground atoms related to the success set can be used to express mode information. We introduce constrained regular trees to define such sets and show how they can be used as the basis for a polymorphic mode system. The mode system can express directional types, back communication and linearity and can be used to infer lower level mode information for languages such as Mercury.", "num_citations": "27\n", "authors": ["1819"]}
{"title": "Implementation Mechanisms for Dependent And-Parallelism.\n", "abstract": " We consider the problem of exploiting non-deterministic dependent and-parallelism (DAP) from Prolog programs. The main issues that arise in designing a parallel Prolog system for exploiting DAP are discussed. Three criteria that an ideal implementation scheme for DAP should satisfy are developed. We argue that an ideal system that satisfies all three criteria cannot be constructed. These criteria are then used to evaluate and classify existing implementation schemes proposed for exploiting DAP, and to inspire new schemes that are arguably better than the existing ones. One such scheme, termed the Filtered Binding Scheme is presented. The Filtered Binding scheme has been incorporated in the ACE And-Or parallel Prolog system, running on a Sequent Symmetry and Sun Spare Multiprocessors. Performance results from this implementation are presented and shown to be better than the results achieved by other systems.", "num_citations": "25\n", "authors": ["1819"]}
{"title": "The NU-Prolog deductive database system\n", "abstract": " The NU-Prolog deductive database system | Prolog and databases: implementations and new directions ACM Digital Library home ACM home Google, Inc. (search) Advanced Search Browse About Sign in Register Advanced Search Journals Magazines Proceedings Books SIGs Conferences People More Search ACM Digital Library SearchSearch Advanced Search Browse Browse Digital Library Collections More HomeBrowse by TitleBooksProlog and databases: implementations and new directionsThe NU-Prolog deductive database system chapter The NU-Prolog deductive database system Share on Authors: Kotagiri Ramamohanarao profile image K. Ramamohanarao View Profile , John Shepherd profile image J. Shepherd View Profile , I Balbin profile image I. Balbin View Profile , GS Port profile image G. Port View Profile , Lee Naish profile image L. Naish View Profile , James A. Thom profile image J. Thom \u2026", "num_citations": "24\n", "authors": ["1819"]}
{"title": "Specification= program+ types\n", "abstract": " It has been claimed that logic programs are equivalent to or consequences of specifications. We argue this is generally not correct. Programs often make implicit assumptions about types, leading to the possibility of incorrect answers. If the assumptions are made explicit, so that the program is equivalent to the specification, the program is less efficient. We define when programs with type declarations are type correct and show all well typed answers returned by such programs are correct.             As well as making to relationship between programs and specifications clear, this type scheme can be used to detect certain programming errors. The semantics we define for type declarations can also be applied to other type schemes. This leads to a simple characterization of what errors are detected by these schemes, and a way to generalize these schemes to allow arbitrary type definitions. One such\u00a0\u2026", "num_citations": "23\n", "authors": ["1819"]}
{"title": "A declarative debugger for a logical-functional language\n", "abstract": " Logic and functional programming languages have many advantages and there is a growing trend to develop languages which incorporate both these paradigms. One of the disadvantages of such languages is that the execution mechanisms are so complex that traditional debugging methods are di cult to use. Declarative debugging techniques have been successful applied to Prolog and more recently functional languages. They allow programs to be debugged using only knowledge of the declarative semantics, hiding the details of the execution from the programmer. In this paper we describe a declarative debugger for a combined logic and functional programming language, NUE-Prolog. The debugger combines both existing and new algorithms. The main new algorithm is for declarative debugging of functions which for some inputs are not well-de ned (typically resulting in a runtime error). The algorithms can easily be adapted to other logic and functional languages.", "num_citations": "22\n", "authors": ["1819"]}
{"title": "Translating Logic Programs into Conditional Rewriting Systems.\n", "abstract": " In this paper a translation from a subclass of logic programs consisting of the simply moded logic programs into rewriting systems is defined. In these rewriting systems conditions and explicit substitutions may be present. We argue that our translation is more natural than previously studied ones and establish a result showing its correctness.", "num_citations": "21\n", "authors": ["1819"]}
{"title": "Effective software bug localization using spectral frequency weighting function\n", "abstract": " This paper presents an approach of bug localization using a frequency weighting function. In an existing approach, only binary information of execution count from test executions is used. Information of each program statement being executed and not executed by a particular test is used; indicated by 1 and 0 respectively. In our proposed approach, frequency execution count of each program statement executed by a respective test is used. We evaluate several well-known spectra metrics using our proposed approach and the existing approach (using binary information of execution count) on two test suites; Siemens Test Suite and Unix datasets. We show that the bug localization performance is improved by using our proposed approach. We conduct statistical test and show that the improved bug localization performance using our approach (using frequency execution count) is statistically significant than using the\u00a0\u2026", "num_citations": "20\n", "authors": ["1819"]}
{"title": "Pruning in logic programming\n", "abstract": " The logic programming community has a love--hate relationship with operators for pruning the search space of logic programs such as cut, commit, once, conditionals and variations on these. Pruning operators typically are not declarative, result in incompleteness and/or unsoundness, decrease readability and flexibility of code and make program analysis and transformation more difficult. Despite this, nearly all non-trivial Prolog programs contain cuts, nearly all more recent logic programming languages have similar pruning operators and many languages insist on pruning operators in every clause. In practice, logic programming is less logical than functional programming. Why it this so? Do we really need pruning operators? Can we have sufficiently powerful pruning operators which do not destroy the declarative semantics of programs? How are pruning operators related to logic, modes, functions and lazy evaluation? This paper attempts to answer some of these questions. Keywords: cut, soft...", "num_citations": "20\n", "authors": ["1819"]}
{"title": "Verification of logic programs and imperative programs\n", "abstract": " This paper explores the relationship between veri cation of logic programs and imperative programs with the aim of uncovering the kinds of reasoning used to construct logic programs. We discuss forward reasoning, such as that used for verifying imperative programs using the inductive assertion method, and backward reasoning, such as that used for verifying imperative programs using subgoal induction and logic programs using consequence veri cation. We argue that consequence veri cation is often inadequate for Prolog programs because programmers make implicit assumptions about how procedures are called. These assumptions can be made explicit using general type declarations. Veri cation of logic programs with type declarations can be done in two steps. We show that one corresponds to subgoal induction and the other corresponds to the inductive assertion method. Thus two existing veri cation methods are combined. The forward and backward reasoning inherent in this method of veri cation can be used for constructing Prolog programs. Type declarations can be used to document the equivalent of loop invariants in the inductive assertion method. We discuss how Prolog programs can be constructed using di erent combinations of forward and backward reasoning. Backward reasoning", "num_citations": "19\n", "authors": ["1819"]}
{"title": "Capturing Database Dynamics by Deferred Updates.\n", "abstract": " In this paper we address the explicit construction of (complex) update programs from basic update operations like\" insert tuple\" and\" delete tuple\". The main contribution is the definition of a semantics that is based on sets of deferred update requests. We propose a logic in which besides the concurrent and sequential composition of update operations also set-oriented updates can be expressed.", "num_citations": "18\n", "authors": ["1819"]}
{"title": "Duals in spectral fault localization\n", "abstract": " Numerous set similarity metrics have been used for ranking \"suspiciousness\" of code in spectral fault localization, which uses execution profiles of passed and failed test cases to help locate bugs. Research in data mining has identified several forms of possibly desirable symmetry in similarity metrics. Here we define several forms of \"duals\" of metrics, based on these forms of symmetries. Use of these duals, plus some other slight modifications, leads to several new similarity metrics. We show that versions of several previously proposed metrics are optimal, or nearly optimal, for locating single bugs. We also show that a form of duality exists between locating single bugs and locating \"deterministic\" bugs (execution of which always results in test case failure). Duals of the various single bug optimal metrics are optimal for locating such bugs. This more theoretical work leads to a conjecture about how different metrics\u00a0\u2026", "num_citations": "17\n", "authors": ["1819"]}
{"title": "Improving spectral\u2010based fault localization using static analysis\n", "abstract": " Debugging is crucial for producing reliable software. One of the effective bug localization techniques is spectral\u2010based fault localization (SBFL). It helps to locate a buggy statement by applying an evaluation metric to program spectra and ranking program components on the basis of the score it computes. SBFL is an example of a dynamic analysis \u2013 an analysis of computer program that is performed by executing it with sufficient number of test cases. Static analysis, on the other hand, is performed in a non\u2010runtime environment. We introduce a weighting technique by combining these two kinds of program analysis. Static analysis is performed to categorize program statements into different classes and giving them weights based on the likelihood of being buggy statement. Statements are finally ranked on the basis of the weights computed by statements' categorization (static analysis) and scores computed by SBFL\u00a0\u2026", "num_citations": "16\n", "authors": ["1819"]}
{"title": "The effectiveness of using non redundant test cases with program spectra for bug localization\n", "abstract": " In this paper, we present our approach of using non redundant test cases with program spectra (one of the automated bug localization techniques) to locate software bugs in a program. We evaluate several spectra metrics (functions mapped from program spectra) using the non redundant test cases. Extensive evaluation on Siemens Test Suite and subset of Unix datasets shows the effectiveness of locating bug using non redundant test cases with program spectra. In this paper, we also show that by adding duplicates of non redundant test cases, the stability and performance of spectra metrics are affected.", "num_citations": "15\n", "authors": ["1819"]}
{"title": "Multiple bug spectral fault localization using genetic programming\n", "abstract": " Debugging is crucial for producing reliable software. One of the effective bug localization techniques is Spectral-Based Fault Localization (SBFL). It locates a buggy statement by applying an evaluation metric to program spectra and ranking program components on the basis of the score it computes. Recently, genetic programming has been proposed as a way to find good metrics. We have found that the huge search space for metrics can cause this approach to be slow and unreliable, even for relatively simple data sets. Here we propose a restricted class of \"hyperbolic\" metrics, with a small number of numeric parameters. This class of functions is based on past theoretical and empirical results. We show that genetic programming can reliably discover effective metrics over a wide range of data sets of program spectra. We evaluate the performance for both real programs and model programs with single bugs\u00a0\u2026", "num_citations": "14\n", "authors": ["1819"]}
{"title": "Visualization of and/or-parallel execution of logic programs\n", "abstract": " In this paper we consider the problem of designing a graphical tool for visualizing and-or parallel execution. We first present a paradigm for visualizing and-or parallel execution. This paradigm is based on an abstract representation of and-or parallel execution called the recomputation tree. We present a general purpose, interactive, both static and animated, tool called VACE that realizes this paradigm. Interesting features of VACE and their implementation are discussed.", "num_citations": "14\n", "authors": ["1819"]}
{"title": "Spectral\u2010based fault localization using hyperbolic function\n", "abstract": " Debugging is crucial for producing reliable software. One of the effective bug localization techniques is spectral\u2010based fault localization. It tries to locate a buggy statement by applying an evaluation metric to program spectra and ranking program components on the basis of the score it computes. Here, we propose a restricted class of \u201chyperbolic\u201d metrics, with a small number of numeric parameters. This class of functions is based on past theoretical and empirical results. We show that optimization methods such as genetic programming and simulated annealing can reliably discover effective metrics over a wide range of data sets of program spectra. We evaluate the performance for both real programs and model programs with single bugs, multiple bugs, \u201cdeterministic\u201d bugs, and nondeterministic bugs and find that the proposed class of metrics performs as well as or better than the previous best\u2010performing metrics\u00a0\u2026", "num_citations": "13\n", "authors": ["1819"]}
{"title": "Spectral debugging: How much better can we do?\n", "abstract": " This paper investigates software fault localization methods which are based on program spectra\u2013data on execution profiles from passed and failed tests. We examine a standard method of spectral fault localization: for each statement we determine the number of passed and failed tests in which the statement was/wasn\u2019t executed and a function, or metric, of these four values is used to rank statements according to how likely they are to be buggy. Many different metrics have been used. Here our main focus is to determine how much improvement in performance could be achieved by finding better metrics. We define the cost of fault localization using a given metric and the unavoidable cost, which is independent of the choice of metric. We define a class of strictly rational metrics and argue that is reasonable to restrict attention to these metrics. We show that every single bug optimal metric performs as well as any strictly rational metric for single bug programs, and the resulting cost is the unavoidable cost. We also show how any metric can be adapted so it is single bug optimal, and give results of empirical experiments using single-and two-bug programs.", "num_citations": "13\n", "authors": ["1819"]}
{"title": "A three-valued semantics for logic programmers\n", "abstract": " This paper describes a simpler way for programmers to reason about the correctness of their code. The study of semantics of logic programs has shown strong links between the model theoretic semantics (truth and falsity of atoms in the programmer's interpretation of a program), procedural semantics (for example, SLD resolution) and fixpoint semantics (which is useful for program analysis and alternative execution mechanisms). Most of this work assumes that intended interpretations are two-valued: a ground atom is true (and should succeed according to the procedural semantics) or false (and should not succeed). In reality, intended interpretations are less precise. Programmers consider that some atoms \u201cshould not occur\u201d or are \u201cill-typed\u201d or \u201cinadmissible\u201d. Programmers don't know and don't care whether such atoms succeed. In this paper we propose a three-valued semantics for (essentially) pure Prolog\u00a0\u2026", "num_citations": "13\n", "authors": ["1819"]}
{"title": "Stepwise enhancement and higher-order programming in prolog\n", "abstract": " This paper presents two views of stepwise enhancement, one a pragmatic syntax-based approach and the other a semantic approach based on higher-order functions and relating to shape and polytypism. The approaches are outlined, and the perhaps surprisingly close relationship between the two described. By combining the advantages of both approaches, it is shown how more code in both functional and logic programming languages can be constructed in a systematic way. We describe a prototype system that allows higher-order predicate definitions to be produced automatically from type definitions or Horn clause skeletons and relate some experiences in using higherorder programming in Prolog.", "num_citations": "13\n", "authors": ["1819"]}
{"title": "Heterogeneous SLD resolution\n", "abstract": " Due to a significant oversight in the definition of computation rules, the current theory of SLD resolution is not general enough to model the behavior of some PROLOG implementations with advanced control facilities. In this paper, Heterogeneous SLD resolution is defined. It is an extension of SLD resolution which increases the \u201cdon't care\u201d nondeterminism of computation rules and can decrease the size of the search space. Soundness and completeness, for success and finite failure, are proved using similar results from SLD resolution. Though Heterogeneous SLD resolution was originally devised to model current systems, it can be exploited more fully than it is now. As an example, an interesting new computation rule is described. It can be seen as a simple form of intelligent backtracking with few overheads.", "num_citations": "13\n", "authors": ["1819"]}
{"title": "Statements versus predicates in spectral bug localization\n", "abstract": " This paper investigates the relationship between the use of predicate-based and statement-based program spectra for bug localization. Branch and path spectra are also considered. Although statement and predicate spectra can be based on the same raw data, the way the data is aggregated results in different information being lost. We propose a simple and cheap modification to the statement-based approach which retains strictly more information. This allows us to compare statement and predicate ''metrics'' (functions used to rank the statements, predicates or paths). We show that improved bug localization performance is possible using single-bug models and benchmarks.", "num_citations": "12\n", "authors": ["1819"]}
{"title": "Animating recursive algorithms\n", "abstract": " Designing visual representations for recursive algorithms has been addressed within a pedagogically-oriented framework for animating algorithms. We present a classification for choosing the kind of visual representation that is most helpful to students. The classification is based on the way the algorithm navigates through a data structure and manipulates data items within a data structure, and suggest strategies for visual representation that work within the categories of this classification. Further opportunities for tailoring representation derive from the shape of the data structure and particular forms of recursion, such as tail recursion. While there may be no single, general way to represent recursive algorithms, our classification is a useful guide to picking an appropriate strategy for use when animating recursive algorithms for teaching purposes.", "num_citations": "12\n", "authors": ["1819"]}
{"title": "A three-valued semantic for Horn clause programs\n", "abstract": " The study of semantics of logic programs has shown strong links between the model theoretic semantics (truth and falsity of atoms in the programmer's interpretation of a program), procedural semantics (for example, SLD resolution) and fixpoint semantics (which is useful for program analysis and alternative execution mechanisms). Nearly all of this work assumes that intended interpretations are two-valued: a ground atom is true (and should succeed according to the procedural semantics) or false (and should not succeed). In reality, intended interpretations are less precise. Programmers consider that some atoms \"should not occur\" or are \"ill-typed\" or \"inadmissible\". Programmers don't know and don't care whether such atoms succeed. In this paper we propose a three-valued semantics for (essentially) Horn clause programs which reflects this. It is simpler and more flexible than previously proposed type schemes\u00a0\u2026", "num_citations": "11\n", "authors": ["1819"]}
{"title": "A program transformation for debugging Haskell 98\n", "abstract": " 4 Revudp\u00c3 l \u00e5 svu mudu\u00f0 u7x mu p ud W \u00c3\u00d7 v P ymly xvxvtl l dy\u00c2 ml Pp7v pm W ml vk& msvu \u00a7 y (u\u00d8 \u00db b u7xv udpmu7 \u00aay\u00c2 ml e\u00df\u00c7 (msvu\u00d7 vy W \u00c1v pr y mkW v u7 p& y (e udpm vt\u00d5 \u00d6\u00f0 rts uj wdr lp& svuf\u00d7 v Pevy\u00c2\u00d2 W 6 (\u00a5 ry (Rqf evud% txy (\u00aay\u00c2 oWu e u7u vk kW vk R txp7ve h \u00fc e lp% Ppmp y& R v \u00a7 ueu7 svudpmu\u00da 6 pmud% ml R\u00d6 \u00e6d v\u00a5 mu \u00aasv v x\u00d4 vut\u00d7 xme 7 ky (jTw# r lpT u q& p W v \u00aa% u% \u00d2 (\u00d2\u00a9 p W v 7u\u00da m \u00aay (p\u00d7 ry\u00c2 W \u00c1\u00d6 rtsvu \u00a7 W m lk ly (tU xv m Wk \u00aay (mu% \u00e9R xpA y pi\u00d7 W mu e\u00c3 m \u00ba y\u00e4 vudh xm Wk \u00aay (hsl \u00aasg 7 xv udp svu\u00e4 o\u00c2y (tl vu\u00e4# svu\u00bd W m lk lyt xv m Wk \u00aay (\u00f1 y e\u00d1 xv e% u p\u00d8 y j wdr e udp% u vk\u00f0 s y\u00c2 \u00bd 7 xv \u00aay\u00c2 ml U\u00d6 \u00dc\u00d3u\u00e3 ueu7k l msv xp xy xPud h ms\u00d9 y6 e u7\u00ed vml \u00e3 (t svu\u00d8 jTw# r\u00da\u00d6\u00c1 \u00dc\u00d3u v mtl vu msvu y pi\u00d7 W m ry (ml E y (Pe\u00eb% W pm le ud \u00d8 svu\u00c3 e \u00d5\u00e8 7 vt\u00d5 6 ry\u00c2 m mud \u00d0 sv lk s u7 m\u00d2p W e ud \u00da xv m Wk \u00aay (k \u00d6 \u00dc\u00d3ur ms u7 \u00d9 p y\u00c2 u msvu\u00d0% &\u00d2 xvtlu% uy pi\u00d7 W m ry (ml \u00e4 yp# y\u00d8 pmu7 ludpd (ud\u00d4 y (ml pd \u00c2o ud dy yu pi yW y 4 pmqR W \u00aay\u00c2\u00e9f (msv\u00fc tly vk Py (k uW\u00d6 \u00dc\u00d3u u7txy\u00c2 uA vdh W m\u00e7 A msvu4 mu pi T msvu4 \u00ed u7txer y (e& svu7 \u00d0% P% tl eu \u00d6x y tl ly m iq h ms6\u00f7 4yWp \u00e7Wu7tlt lpb yWpmpm v ude\u00c1\u00d60 \u00ce d\u00cf\u00a5 \u00cc\u00cbd e 9f \u00cb\u00cd \u00cb g D rtsvu j wdr\u00f5 u7xv udpmu7 pypy% u \u00a7 (msvu udo\u00c2y (tl y\u00c2 W \u00d0 y& xv kW y f\u00d6\u00a1 4 e udp l ms u\u00da m u7u% W m udpmxe e\u00d8 m\u00d7 v P yml y xvxvtl l dy\u00c2 ml Pp s y\u00c2 r h\u00c7u7 u\u00d8 ry e u6 eml vk\u00d3 xv m Wk \u00aay (2 u7o\u00c2y (tl \u00d2 y (ml \u00c1v4 7 y vkg\u00d7 v% mly (udpf y (PeE u%\u00d7 u7 u7 P% udp\u00d8 m svu7 l \u00e4 y (kv ud W \u00aap y (e\u00f5 mu p t\u00d5 \u00d6 rts u\u00c3 py (mx \u00e3 7y t tA kW y xvs \u00c1 msvu# xv kW ye u7 mud ml vudp ms u# e udxPud e ud% ludp\u00c7 ueu% ih\u00c7u7u7 veu p7\u00d6T W p xe ud t msvu\u00da \u00c2q xv k \u00aay (Y ueu7tl \u00c2hA~", "num_citations": "9\n", "authors": ["1819"]}
{"title": "An analysis of New South Wales electronic vote counting\n", "abstract": " We re-examine the 2012 local government elections in New South Wales, Australia. The count was conducted electronically using a randomised form of the Single Transferable Vote (STV). It was already well known that randomness does make a difference to outcomes in some seats. We describe how the process could be amended to include a demonstration that the randomness was chosen fairly.", "num_citations": "8\n", "authors": ["1819"]}
{"title": "Disjunctive Logic Programming as Constrained Inferences.\n", "abstract": " Previously we have proposed a logic, called priority logic 18, 20], where a theory consists of a collection of logic programming-like inference rules (without default negation) and a priority constraint among them. We showed that nonmonotonic reasoning in general can be viewed as selecting monotonic inferences that satisfy the speci ed priority constraints. The goal of this paper is to investigate how semantics of disjunctive programs can be understood as selecting monotonic inferences. We focus on credulous semantics. We show that the stable semantics of a disjunctive program can be represented by priority logic. The highlight of this paper is an interesting new semantics for disjunctive programs, discoved during this study, which has an abductive interpretation in the sense of Eshghi and Kowalski, whose abductive procedure can be adopted to serve as a credulous proof procedure for the new semantics.", "num_citations": "8\n", "authors": ["1819"]}
{"title": "A higher order reconstruction of stepwise enhancement\n", "abstract": " This paper presents two views of stepwise enhancement, one a pragmatic syntax-based approach and the other a semantic approach based on higher order functions and relating to shape and polytypism. The approaches are outlined, and the perhaps surprisingly close relation-ship between the two described. By combining the advantages of both approaches, it is shown how more code in both functional and logic programming languages can be constructed in a systematic and partially automated way.", "num_citations": "7\n", "authors": ["1819"]}
{"title": "Specialisation of higher-order functions for debugging\n", "abstract": " Because functions are abstract values without convenient print representations, implementing debuggers which support higher-order code is a challenge. We present an algorithm for statically specialising higher-order functions and encoding higher-order values to allow printing. We define our algorithm for a small functional language and discuss how it may be extended to support sophisticated features of modern functional programming languages. This research forms part of a project3      to build a declarative debugger for Haskell, based primarily on source-to-source transformation.", "num_citations": "6\n", "authors": ["1819"]}
{"title": "A guide to the NU-Prolog Debugging Environment\n", "abstract": " The NU-Prolog Debugging Environment (Nude) is a collection of integrated tools for locating bugs in both pure and non-logical NU-Prolog programs. It has static analyses and user-driven dynamic analyses including a four-port debugger and a declarative debugger. This document is a guide to using the environment.", "num_citations": "6\n", "authors": ["1819"]}
{"title": "Resource-oriented deadlock analysis\n", "abstract": " We present a method of detecting if deadlocks may occur in concurrent logic programs. Typical deadlock analysis is \u201cprocess-oriented\u201d, being based on possible interleaving of processes. Our method is oriented towards the shared resources (communication channels, locks et cetera) and is based on orders in which individual resources are used by different processes. In cases where there are resources used by only a subset of all processes the search space can be dramatically reduced. The method arises very naturally out of the concurrent logic programming paradigm. Analysis of concurrent programs has previously used \u201ccoarsification\u201d and \u201cpartial order\u201d methods to reduce the search space. Our approach rediscovers and also extends these techniques. Our presentation is based around a logic programming pearl which finds deadlocked computations in a program which solves the dining\u00a0\u2026", "num_citations": "5\n", "authors": ["1819"]}
{"title": "Declarative debugging of a logical-functional language\n", "abstract": " We present a declarative debugger capable of diagnosing wrong and missing answers in NUE-Prolog, a logical {functional language with lazy evaluation and higher-order functions. Debugging mixed logical and functional code is straightforward. However lazy evaluation allows a new kind of bug which occurs when a function over-evaluates its argument. We describe a second missing answer diagnosis algorithm which can diagnose this class of bug. The new type of bug appears to be a generalised form of uncovered atom, containing both universal and existential quanti ers.", "num_citations": "5\n", "authors": ["1819"]}
{"title": "Incorporating a Pruning Strategy into the Computation of Stable Models based on MGTP\n", "abstract": " The stable model semantics is now one of the standard semantics for general logic programs. A simple procedure for computing stable models has been proposed by Inoue et al. [5]. In this paper, we propose search strategies based on dynamic analysis, which is incorporated into the computation of stable models based on MGTP (Model Generation Theorem Prover) [3]. We also show some experimental results which show remarkable speedup compared with the original procedure.", "num_citations": "4\n", "authors": ["1819"]}
{"title": "Proving properties of committed choice logic programs\n", "abstract": " PROLOG and its variants are based on SLD resolution, which uses \u201cdon't know\u201d nondeterminism to explore the search space. Don't care (or committed choice) nondeterminism can be introduced by operations such as commit in Concurrent PROLOG and cut in sequential PROLOG. This prevents the whole SLD tree from being examined. The effect on completeness of programs is of major importance. This paper presents a theoretical model of guarded clauses, which exhibits don't know nondeterminism and also has a guard construct like many parallel PROLOGs. Next, we investigate proving properties concerning success and finite failure of guarded clause programs with restricted input-output modes. We present methodologies for proving completeness and weaker properties, which we call semicompleteness and failure soundness.", "num_citations": "4\n", "authors": ["1819"]}
{"title": "Transforming floundering into success\n", "abstract": " We show how logic programs with \u201cdelays\u201d can be transformed to programs without delays in a way that preserves information concerning floundering (also known as deadlock). This allows a declarative (model-theoretic), bottom-up or goal-independent approach to be used for analysis and debugging of properties related to floundering. We rely on some previously introduced restrictions on delay primitives and a key observation which allows properties such as groundness to be analysed by approximating the (ground) success set.", "num_citations": "3\n", "authors": ["1819"]}
{"title": "Partial disclosure of votes in STV elections\n", "abstract": " Full disclosure of votes in STV elections can allow coercion of voters by the use of \u201csignature attacks\u201d, but limiting disclosure can make independent verification of results impossible. We propose disclosure of a subset of the preferences in each vote, namely those that are actually used in the count. This scheme is easy to implement, permits verification of the tally, and combats signature attacks to a large degree.", "num_citations": "3\n", "authors": ["1819"]}
{"title": "Probabilistic declarative debugging\n", "abstract": " Probabilistic Declarative Debugging Page 1 Probabilistic Declarative Debugging Lee Naish Computer Science and Software Engineering University of Melbourne 1 Page 2 Outline Declarative Debugging Search strategy Estimating probabilities Examples Conclusion 2 Page 3 But first . . . \u201cGod does not play dice\u201d \u2014 Einstein \u201cGod not only plays dice but also sometimes throws them where they cannot be seen\u201d \u2014 Hawking 3 Page 4 A puzzle for the rational Suppose N dice of various designs have been created Each die i, 1 \u2264 i \u2264 N is thrown Si times, Si > 0 and on at least one throw of some die the side of the die which comes up is blank \u2014 at least one of the dice is defective! Each die i is thrown Ki more times, Ki \u2265 0 and no blanks come up 1. What are the odds that die i is defective and 2. assuming it is, what are the odds its next throw comes up blank? You may want to introduce some simplifying assumptions such as \u2026", "num_citations": "3\n", "authors": ["1819"]}
{"title": "Mode checking using constrained regular trees\n", "abstract": " In a previous paper we presented a high level polymorphic mode system for logic programs. In this paper we present an algorithm which checks if a program is well moded, given that is it well-typed in the sense of Mycroft and O'Keefe. A program is well-moded if the set of ground atoms de ned by mode declarations is a superset of the success set. The novelty of the algorithm is the expressiveness of the mode declarations. Constrained regular trees are used to de ne sets of terms and atoms. These are based on polymorphic types but allow set and multiset constraints over type variables. The expressiveness of this domain makes it very promising for many program analysis applications. Complexity is also (exponentially) better than other proposed domains for certain analysis tasks.", "num_citations": "3\n", "authors": ["1819"]}
{"title": "Grants are not research outputs\n", "abstract": " In his paper in Australian Universities' Review 53(1), Martin (2011) presents several criticisms of the Australian Research Council's Excellence in Research for Australia (ERA) scheme and, like many other commentators, encourages the development of new ideas which may overcome some of these defects. Here the focus is on one particular criticism of the ERA: inputs to research (namely, grants) are counted as outputs of research (in the same class as journal publications). Some of the negative consequences of this are examined in more detail and a solution is proposed: use direct peer assessment of research excellence. This solution has a relatively low marginal cost, provides a more accurate assessment, avoids the negative consequences of treating inputs as outputs and could potentially help avoid other contentious issues such as those surrounding journal rankings.", "num_citations": "2\n", "authors": ["1819"]}
{"title": "Completeness of an improved declarative debugger\n", "abstract": " We prove a completeness theorem for an improved practical declarative debugger for arbitrary logic programs which checks the satisfiability rather than the validity of solved goals wrt their intended interpretations in the process of identifying errors.", "num_citations": "2\n", "authors": ["1819"]}
{"title": "Sharing analysis in the Pawns compiler\n", "abstract": " Pawns is a programming language under development that supports algebraic data types, polymorphism, higher order functions and \u201cpure\u201d declarative programming. It also supports impure imperative features including destructive update of shared data structures via pointers, allowing significantly increased efficiency for some operations. A novelty of Pawns is that all impure \u201ceffects\u201d must be made obvious in the source code and they can be safely encapsulated in pure functions in a way that is checked by the compiler. Execution of a pure function can perform destructive updates on data structures that are local to or eventually returned from the function without risking modification of the data structures passed to the function. This paper describes the sharing analysis which allows impurity to be encapsulated. Aspects of the analysis are similar to other published work, but in addition it handles explicit pointers and destructive update, higher order functions including closures and pre- and post-conditions concerning sharing for functions.", "num_citations": "1\n", "authors": ["1819"]}
{"title": "An informal introduction to Pawns: a declarative/imperative language\n", "abstract": " Pawns is yet another programming language under development which attempts to combine the elegance of declarative programming with the algorithmic expressive power of imperative programming. Algebraic data types can be defined and viewed as decriptions of high level values which can be manipulated in declarative ways. The same type definitions can also be viewed at a much lower level, involving pointers to possibly shared data structures which can be destructively updated. Pawns programs contain annotations and declarations which indicate whether the high or low level view should be used in different program components and what variables may be updated at each point. This makes all effects obvious and allows efficient imperative code to be encapsulated within a declarative interface, with \u201cpurity\u201d of functions and consistency of annotations and declarations being guaranteed by the compiler.", "num_citations": "1\n", "authors": ["1819"]}
{"title": "Declarative diagnosis of floundering\n", "abstract": " Many logic programming languages have delay primitives which allow coroutining. This introduces a class of bug symptoms -- computations can flounder when they are intended to succeed or finitely fail. For concurrent logic programs this is normally called deadlock. Similarly, constraint logic programs can fail to invoke certain constraint solvers because variables are insufficiently instantiated or constrained. Diagnosing such faults has received relatively little attention to date. Since delay primitives affect the procedural but not the declarative view of programs, it may be expected that debugging would have to consider the often complex details of interleaved execution. However, recent work on semantics has suggested an alternative approach. In this paper we show how the declarative debugging paradigm can be used to diagnose unexpected floundering, insulating the user from the complexities of the execution. Keywords: logic programming, coroutining, delay, debugging, floundering, deadlock, constraints", "num_citations": "1\n", "authors": ["1819"]}
{"title": "Effective maintenance of recursive views: Improvements to the dred algorithm\n", "abstract": " In this paper, one of the most recent promising algorithms that compute changes to recursive structures in response to changes to the extensional database (EDB) relations (i.e. DRed algorithm) has been studied and it has been improved. In the improved algorithm, the computation hits been further \u201cincrementalized\u201d in comparison to DRed algorithm using extra intra-iteration computations in each phase. Also, both of the algorithms have been implemented in a testbed to study their performance through simulations.", "num_citations": "1\n", "authors": ["1819"]}