{"title": "\u00b5CRL: A Toolset for Analysing Algebraic Specifications\n", "abstract": " \u00b5CRL [13] is a language for specifying and verifying distributed systems in an algebraic fashion. It targets the specification of system behaviour in a process-algebraic style and of data elements in the form of abstract data types. The \u00b5CRL toolset [21] (see http://www.cwi.nl/~mcrl) supports the analysis and manipulation of \u00b5CRL specifications. A \u00b5CRL specification can be automatically transformed into a linear process operator (LPO). All other tools in the \u00b5CRL toolset use LPOs as their starting point. The simulator allows the interactive simulation of an LPO. There are a number of tools that allow optimisations on the level of LPOs. The instantiator generates a labelled transition system (LTS) from an LPO (under the condition that it is finite-state), and the resulting LTS can be visualised, analysed and minimised.", "num_citations": "224\n", "authors": ["1398"]}
{"title": "LTSmin: high-performance language-independent model checking\n", "abstract": " In recent years, the LTSmin model checker has been extended with support for several new modelling languages, including probabilistic (Mapa) and timed systems (Uppaal). Also, connecting additional language front-ends or ad-hoc state-space generators to LTSmin was simplified using custom C-code. From symbolic and distributed reachability analysis and minimisation, LTSmin\u2019s functionality has developed into a model checker with multi-core algorithms for on-the-fly LTL checking with partial-order reduction, and multi-core symbolic checking for the modal \u03bc calculus, based on the multi-core decision diagram package Sylvan. In LTSmin, the modelling languages and the model checking algorithms are connected through a Partitioned Next-State Interface (Pins), that allows to abstract away from language details in the implementation of the analysis algorithms and on-the-fly optimisations. In the current paper, we\u00a0\u2026", "num_citations": "146\n", "authors": ["1398"]}
{"title": "LTSmin: Distributed and symbolic reachability\n", "abstract": " In model checking, analysis algorithms are applied to large graphs (state spaces), which model the behavior of (computer) systems. These models are typically generated from specifications in high-level languages. The LTSmin toolset provides means to generate state spaces from high-level specifications, to check safety properties on-the-fly, to store the resulting labelled transition systems (LTSs) in compressed format, and to minimize them with respect to (branching) bisimulation.", "num_citations": "140\n", "authors": ["1398"]}
{"title": "A bounded retransmission protocol for large data packets\n", "abstract": " A protocol is described for the transmission of large data packets over unreliable channels. The protocol splits each data packet and broadcasts it in parts. In case of failure of transmission, only a limited number of retries is allowed (bounded retransmission), hence the protocol may give up the delivery of a part of the packet. Both the sending and the receiving client are informed adequately. This protocol is used in one of Philips' products.             We used \u03bcCRL as formal framework, a combination of process algebra and abstract data types. The protocol and its external behaviour are specified in \u03bcCRL. The correspondence between these is shown using the proof theory of \u03bcCRL. The whole proof of this correspondence has been computer checked using the proof checker Coq. This provides an example showing that proof checking of realistic protocols is feasible within the setting of process algebras.", "num_citations": "125\n", "authors": ["1398"]}
{"title": "Boosting multi-core reachability performance with shared hash tables\n", "abstract": " This paper focuses on data structures for multi-core reachability, which is a key component in model checking algorithms and other verification methods. A cornerstone of an efficient solution is the storage of visited states. In related work, static partitioning of the state space was combined with thread-local storage. This solution leaves room for improvements. This paper presents a solution with a shared state storage. It is based on a lockless hash table implementation and scales better. The solution is specifically designed for the cache architecture of modern CPUs. Because model checking algorithms impose loose requirements on the hash table operations, their design can be streamlined substantially compared to related work on lockless hash tables. The resulting speedups are analyzed and compared with related tools. Our implementation outperforms two state-of-the-art multi-core model checkers, SPIN\u00a0\u2026", "num_citations": "104\n", "authors": ["1398"]}
{"title": "State space reduction by proving confluence\n", "abstract": " We present a modular method for on-the-fly state space reduction. The theoretical foundation of the method is a new confluence notion for labeled transition systems. The method works by adding confluence information to the symbolic representation of the state space. We present algorithms for on-the-fly exploration of the reduced state space, for detection of confluence properties and for a symbolic reduction, called prioritization. The latter two algorithms rely on an automated theorem prover to derive the necessary information. We also present some case studies in which tools that implement these algorithms were used.", "num_citations": "95\n", "authors": ["1398"]}
{"title": "Termination of higher-order rewrite systems\n", "abstract": " This thesis has not been written in isolation; it could not have been. I needed nice people to be friends with, to chat to, to listen to, to learn from and to become inspired by.I am indebted to my supervisors Jan Friso Groote, who initiated my research, and Marc Bezem, who read my papers and directed me during writing this thesis with many valuable remarks and wise lessons. He also is my co-promotor. I am very grateful to my promotor, Jan Bergstra. His in uence is not measurable, but large. He was always willing to give advice, asked and unasked. He stimulated and enabled various escapades outside my specialistic research and forced me to think about\\what next\".", "num_citations": "80\n", "authors": ["1398"]}
{"title": "Termination proofs for higher-order rewrite systems\n", "abstract": " This paper deals with termination proofs for Higher-Order Rewrite Systems (HRSs), introduced in [12]. This formalism combines the computational aspects of term rewriting and simply typed lambda calculus. The result is a proof technique for the termination of a HRS, similar to the proof technique \u201cTermination by interpretation in a well-founded monotone algebra\u201d, described in [8, 19]. The resulting technique is as follows: Choose a higher-order algebra with operations for each function symbol in the HRS, equipped with some well-founded partial ordering. The operations must be strictly monotonic in this ordering. This choice generates a model for the HRS. If the choice can be made in such a way that for each rule the interpretation of the left hand side is greater than the interpretation of the right hand side, then the HRS is terminating. At the end of the paper some applications of this technique are given, which\u00a0\u2026", "num_citations": "78\n", "authors": ["1398"]}
{"title": "Strict functionals for termination proofs\n", "abstract": " A semantical method to prove termination of higher order rewrite systems (HRS) is presented. Its main tool is the notion of a strict functional, which is a variant of Gandy's notion of a hereditarily monotonic functional [1]. The main advantage of the method is that it makes it possible to transfer ones intuitions about why an HRS should be terminating into a proof: one has to find a'\" strict\" interpretation of the constants involved in such a way that the left hand side of any rewrite rule gets a bigger value than the right hand side. The applicability of the method is demonstrated in three examples.", "num_citations": "67\n", "authors": ["1398"]}
{"title": "State space reduction using partial \u03c4-confluence\n", "abstract": " We present an efficient algorithm to determine the maximal class of confluent \u03c4-transitions in a labelled transition system. Confluent \u03c4-transitions are inert with respect to branching bisimulation. This allows to use \u03c4-priorisation, which means that in a state with a confluent outgoing \u03c4-transition all other transitions can be removed, maintaining branching bisimulation. In combination with the removal of \u03c4-loops, and the compression of \u03c4-sequences this yields an efficient algorithm to reduce the size of large state spaces.", "num_citations": "66\n", "authors": ["1398"]}
{"title": "Improved multi-core nested depth-first search\n", "abstract": " This paper presents C ndfs, a tight integration of two earlier multi-core nested depth-first search (N dfs) algorithms for LTL model checking. C ndfs combines the different strengths and avoids some weaknesses of its predecessors. We compare C ndfs to an earlier ad-hoc combination of those two algorithms and show several benefits: It has shorter and simpler code and a simpler correctness proof. It exhibits more robust performance with similar scalability, while at the same time reducing memory requirements. The algorithm has been implemented in the multi-core backend of the LTS min model checker, which is now benchmarked for the first time on a 48 core machine (previously 16). The experiments demonstrate better scalability than other parallel LTL model checking algorithms, but we also investigate apparent bottlenecks. Finally, we noticed that the multi-core N dfs algorithms produce shorter counterexamples\u00a0\u2026", "num_citations": "62\n", "authors": ["1398"]}
{"title": "Distributed algorithms for SCC decomposition\n", "abstract": " We study existing parallel algorithms for the decomposition of a partitioned graph into its strongly connected components (SCCs). In particular, we identify several individual procedures that the algorithms are assembled from and show how to assemble a new and more efficient algorithm, called Recursive OBF (OBFR), to solve the decomposition problem. We also report on a thorough experimental study to evaluate the new algorithm. It shows that it is possible to perform SCC decomposition in parallel efficiently and that OBFR, if properly implemented, is the best choice in most cases.", "num_citations": "59\n", "authors": ["1398"]}
{"title": "Multi-Core LTSmin: Marrying Modularity and Scalability\n", "abstract": " The LTSmin toolset provides multiple generation and on-the-fly analysis algorithms for large graphs (state spaces), typically generated from concise behavioral specifications (models) of systems. LTSmin supports a variety of input languages, but its key feature is modularity: language frontends, optimization layers, and algorithmic backends are completely decoupled, without sacrificing performance. To complement our existing symbolic and distributed model checking algorithms, we added a multi-core backend for checking safety properties, with several new features to improve efficiency and memory usage: low-overhead load balancing, incremental hashing and scalable state compression.", "num_citations": "59\n", "authors": ["1398"]}
{"title": "Equational binary decision diagrams\n", "abstract": " We allow equations in binary decision diagrams (BDD). The resulting objects are called EQ-BDDs. A straightforward notion of reduced ordered EQ-BDDs (EQ-OBDD) is defined, and it is proved that each EQ-BDD is logically equivalent to an EQ-OBDD. Moreover, on EQOBDDs satisfiability and tautology checking can be done in constant time. Several procedures to eliminate equality from BDDs have been reported in the literature. Typical for our approach is that we keep equalities, and as a consequence do not employ the finite domain property. Furthermore, our setting does not strictly require Ackermann's elimination of function symbols. This makes our setting much more amenable to combinations with other techniques in the realm of automatic theorem proving, such as term rewriting. We introduce an algorithm, which for any propositional formula with equations finds an EQ-OBDD that is equivalent to it\u00a0\u2026", "num_citations": "59\n", "authors": ["1398"]}
{"title": "Multi-core nested depth-first search\n", "abstract": " Abstract The LTL Model Checking problem is reducible to finding accepting cycles in a graph. The Nested Depth-First Search (Ndfs) algorithm detects accepting cycles efficiently: on-the-fly, with linear-time complexity and negligible memory overhead. The only downside of the algorithm is that it relies on an inherently-sequential, depth-first search. It has not been parallelized beyond running the independent nested search in a separate thread (dual core). In this paper, we introduce, for the first time, a multi-core Ndfs algorithm that can scale beyond two threads, while maintaining exactly the same worst-case time complexity. We prove this algorithm correct, and present experimental results obtained with an implementation in the LTSmin tool set on the entire Beem benchmark database. We measured considerable speedups compared to the current state of the art in parallel cycle detection algorithms.", "num_citations": "56\n", "authors": ["1398"]}
{"title": "Sylvan: Multi-core decision diagrams\n", "abstract": " Decision diagrams such as binary decision diagrams and multi-valued decision diagrams play an important role in various fields, including symbolic model checking. An ongoing challenge is to develop datastructures and algorithms for modern multi-core architectures. The BDD package Sylvan provides one contribution by implementing parallelized BDD operations and thus allowing sequential algorithms to exploit the power of multi-core machines.                 We present several extensions to Sylvan. We implement parallel operations on list decision diagrams, a variant of multi-valued decision diagrams that is useful for symbolic model checking. We also substitute several core components of Sylvan by new designs, such as the work-stealing framework, the unique table and the operation cache. Furthermore, we combine parallel operations with parallelization on a higher level, by partitioning the transition\u00a0\u2026", "num_citations": "52\n", "authors": ["1398"]}
{"title": "Verification of a sliding window protocol in \u03bc CRL and PVS\n", "abstract": " We prove the correctness of a sliding window protocol with an arbitrary finite window size n and sequence numbers modulo 2n. The correctness consists of showing that the sliding window protocol is branching bisimilar to a queue of capacity 2n. The proof is given entirely on the basis of an axiomatic theory, and has been checked in the theorem prover PVS.", "num_citations": "52\n", "authors": ["1398"]}
{"title": "A database approach to distributed state space generation\n", "abstract": " We study distributed state space generation on a cluster of workstations. It is explained why state space partitioning by a global hash function is problematic when states contain variables from unbounded domains, such as lists or other recursive datatypes. Our solution is to introduce a database which maintains a global numbering of state values. We also describe tree-compression, a technique of recursive state folding, and show that it is superior to manipulating plain state vectors.This solution is implemented and linked to the \u03bcCRL toolset, where state values are implemented as maximally shared terms (ATerms). However, it is applicable to other models as well, e.g., PROMELA models via the NIPS virtual machine. Our experiments show the trade-offs between keeping the database global, replicated, or local, depending on the available network bandwidth and latency.", "num_citations": "51\n", "authors": ["1398"]}
{"title": "Verifying a Sliding Window Protocol in \u03bcCRL\n", "abstract": " We prove the correctness of a sliding window protocol with an arbitrary finite window size n and sequence numbers modulo 2n. We show that the sliding window protocol is branching bisimilar to a queue of capacity 2n. The proof is given entirely on the basis of an axiomatic theory, and was checked with the help of PVS.", "num_citations": "50\n", "authors": ["1398"]}
{"title": "Equivalence checking for infinite systems using parameterized boolean equation systems\n", "abstract": " In this paper, we provide a transformation from the branching bisimulation problem for infinite, concurrent, data-intensive systems in linear process format, into solving Parameterized Boolean Equation Systems. We prove correctness, and illustrate the approach with an unbounded queue example. We also provide some adaptations to obtain similar transformations for weak bisimulation and simulation equivalence.", "num_citations": "49\n", "authors": ["1398"]}
{"title": "Symbolic reachability for process algebras with recursive data types\n", "abstract": " In this paper, we present a symbolic reachability algorithm for process algebras with recursive data types. Like the various saturation based algorithms of Ciardo et al, the algorithm is based on partitioning of the transition relation into events whose influence is local. As new features, our algorithm supports recursive data types and allows unbounded non-determinism, which is needed to support open systems with data. The algorithm does not use any specific features of process algebras. That is, it will work for any system that consists of a fixed number of communicating processes, where in each atomic step only a subset of the processes participate. As proof of concept we have implemented the algorithm in the context of the \u03bcCRL toolset. We also compared the performance of this prototype with the performance of the existing explicit tools on a set of typical case studies.", "num_citations": "48\n", "authors": ["1398"]}
{"title": "Multi-core emptiness checking of timed B\u00fcchi automata using inclusion abstraction\n", "abstract": " This paper contributes to the multi-core model checking of timed automata (TA) with respect to liveness properties, by investigating checking of TA B\u00fcchi emptiness under the very coarse inclusion abstraction or zone subsumption, an open problem in this field. We show that in general B\u00fcchi emptiness is not preserved under this abstraction, but some other structural properties are preserved. Based on those, we propose a variation of the classical nested depth-first search (ndfs) algorithm that exploits subsumption. In addition, we extend the multi-core cndfs algorithm with subsumption, providing the first parallel LTL model checking algorithm for timed automata. The algorithms are implemented in LTSmin, and experimental evaluations show the effectiveness and scalability of both contributions: subsumption halves the number of states in the real-world FDDI case study, and the multi-core algorithm yields speedups of\u00a0\u2026", "num_citations": "40\n", "authors": ["1398"]}
{"title": "Parallel recursive state compression for free\n", "abstract": " This paper focuses on reducing memory usage in enumerative model checking, while maintaining the multi-core scalability obtained in earlier work. We present a multi-core tree-based compression method, which works by leveraging sharing among sub-vectors of state vectors. An algorithmic analysis of both worst-case and optimal compression ratios shows the potential to compress even large states to a small constant on average (8 bytes). Our experiments demonstrate that this holds up in practice: the median compression ratio of 279 measured experiments is within 17% of the optimum for tree compression, and five times better than the median compression ratio of Spin\u2019s Collapse compression. Our algorithms are implemented in the LTSmin tool, and our experiments show that for model checking, multi-core tree compression pays its own way: it comes virtually without overhead compared to the fastest hash\u00a0\u2026", "num_citations": "40\n", "authors": ["1398"]}
{"title": "Improved distributed algorithms for SCC decomposition\n", "abstract": " We study and improve the OBF technique [Barnat, J. and P.Moravec, Parallel algorithms for finding SCCs in implicitly given graphs, in: Proceedings of the 5th International Workshop on Parallel and Distributed Methods in Verification (PDMC 2006), LNCS (2007)], which was used in distributed algorithms for the decomposition of a partitioned graph into its strongly connected components. In particular, we introduce a recursive variant of OBF and experimentally evaluate several different implementations of it that vary in the degree of parallelism. For the evaluation we used synthetic graphs with a few large components and graphs with many small components. We also experimented with graphs that arise as state spaces in real model checking applications. The experimental results are compared with that of other successful SCC decomposition techniques [Orzan, S., \u201cOn Distributed Verification and Verified\u00a0\u2026", "num_citations": "40\n", "authors": ["1398"]}
{"title": "Multi-core on-the-fly SCC decomposition\n", "abstract": " The main advantages of Tarjan's strongly connected component (SCC) algorithm are its linear time complexity and ability to return SCCs on-the-fly, while traversing or even generating the graph. Until now, most parallel SCC algorithms sacrifice both: they run in quadratic worst-case time and/or require the full graph in advance.", "num_citations": "39\n", "authors": ["1398"]}
{"title": "A State Space Distribution Policy Based on Abstract Interpretation\n", "abstract": " We aim at improving the performance of distributed algorithms for model checking and state space reduction. To this end, we introduce a new distribution policy of states over workers. This policy reduces the number of transitions between states located at different workers. This in turn is expected to reduce the communication costs of the distributed algorithms.The main idea is to use Abstract Interpretation techniques to compute a small approximation of the state space, starting from some high level description of the system. Based on this approximation, the connectivity of concrete states is predicted. This information is used to distribute states with expected connectivity to the same worker. Experiments show a considerable reduction of cross transitions, at the expense of a modest unbalance of nodes per worker.", "num_citations": "38\n", "authors": ["1398"]}
{"title": "Modeling biological pathway dynamics with timed automata\n", "abstract": " Living cells are constantly subjected to a plethora of environmental stimuli that require integration into an appropriate cellular response. This integration takes place through signal transduction events that form tightly interconnected networks. The understanding of these networks requires capturing their dynamics through computational support and models. ANIMO (analysis of Networks with Interactive Modeling) is a tool that enables the construction and exploration of executable models of biological networks, helping to derive hypotheses and to plan wet-lab experiments. The tool is based on the formalism of Timed Automata, which can be analyzed via the UPPAAL model checker. Thanks to Timed Automata, we can provide a formal semantics for the domain-specific language used to represent signaling networks. This enforces precision and uniformity in the definition of signaling pathways, contributing to the\u00a0\u2026", "num_citations": "37\n", "authors": ["1398"]}
{"title": "Guard-based Partial-Order Reduction\n", "abstract": " This paper aims at making partial-order reduction independent of the modeling language. To this end, we present a guard-based method which is a general-purpose implementation of the stubborn set method. We approach the implementation through so-called necessary enabling sets and do-not-accord sets, and give an algorithm suitable for an abstract model checking interface. We also introduce necessary disabling sets and heuristics to produce smaller stubborn sets and thus better reduction at low costs. We explore the effect of these methods using an implementation in the model checker LTSmin. We experiment with partial-order reduction on a number of Promela models, on benchmarks from the BEEM database in the DVE language, and with several with LTL properties. The efficiency of the heuristic algorithm is established by a comparison to the subset-minimal Deletion algorithm and the simple\u00a0\u2026", "num_citations": "37\n", "authors": ["1398"]}
{"title": "A prover for the  CRL toolset with applications : version 0.1\n", "abstract": " This document describes an automated theorem prover, based on an extension of binary decision diagrams. The prover transforms quantifier-free formulae into equivalent BDD-forms, w.r.t.~to some algebraic data specification. The prover is used by four tools for the symbolic analysis of distributed systems specified in CRL (i.e.~process algebra plus algebraic data types). The main techniques are invariants and confluence.  Two case studies are reported: the DKR leader election protocol [13], and SPLICE [15], a coordination architecture of industrial origin. In both cases using confluence information leads to a reduced state space.", "num_citations": "36\n", "authors": ["1398"]}
{"title": "Sylvan: multi-core framework for decision diagrams\n", "abstract": " Decision diagrams, such as binary decision diagrams, multi-terminal binary decision diagrams and multi-valued decision diagrams, play an important role in various fields. They are especially useful to represent the characteristic function of sets of states and transitions in symbolic model checking. Most implementations of decision diagrams do not parallelize the decision diagram operations. As performance gains in the current era now mostly come from parallel processing, an ongoing challenge is to develop datastructures and algorithms for modern multi-core architectures. The decision diagram package Sylvan provides a contribution by implementing parallelized decision diagram operations and thus allowing sequential algorithms that use decision diagrams to exploit the power of multi-core machines. This paper discusses the design and implementation of Sylvan, especially an improvement to the lock\u00a0\u2026", "num_citations": "35\n", "authors": ["1398"]}
{"title": "Confluence reduction for probabilistic systems\n", "abstract": " This paper presents a novel technique for state space reduction of probabilistic specifications, based on a newly developed notion of confluence for probabilistic automata. We prove that this reduction preserves branching probabilistic bisimulation and can be applied on-the-fly. To support the technique, we introduce a method for detecting confluent transitions in the context of a probabilistic process algebra with data, facilitated by an earlier defined linear format. A case study demonstrates that significant reductions can be obtained.", "num_citations": "34\n", "authors": ["1398"]}
{"title": "Checking verifications of protocols and distributed systems by computer\n", "abstract": " We provide a treatise about checking proofs of distributed systems by computer using general purpose proof checkers. In particular, we present two approaches to verifying and checking the verification of the Sequential Line Interface Protocol (SLIP), one using rewriting techniques and one using the so-called cones and foci theorem. Finally, we present an overview of literature containing checked proofs.", "num_citations": "34\n", "authors": ["1398"]}
{"title": "A multi-core solver for parity games\n", "abstract": " We describe a parallel algorithm for solving parity games, with applications in, e.g., modal \u03bc-calculus model checking with arbitrary alternations, and (branching) bisimulation checking. The algorithm is based on Jurdzinski's Small Progress Measures. Actually, this is a class of algorithms, depending on a selection heuristics. Our algorithm operates lock-free, and mostly wait-free (except for infrequent termination detection), and thus allows maximum parallelism. Additionally, we conserve memory by avoiding storage of predecessor edges for the parity graph through strictly forward-looking heuristics. We evaluate our multi-core implementation's behaviour on parity games obtained from \u03bc-calculus model checking problems for a set of communication protocols, randomly generated problem instances, and parametric problem instances from the literature.", "num_citations": "33\n", "authors": ["1398"]}
{"title": "Distributed Analysis with \u03bcCRL: A Compendium of Case Studies\n", "abstract": " Models in process algebra with abstract data types can be analysed by state space generation and reduction tools. The \u03bcCRL toolset implements a suite of distributed verification tools for clusters of workstations. We illustrate their application to large case studies from a wide range of application areas, such as functional analysis, scheduling, security analysis, test case generation and game solving.", "num_citations": "33\n", "authors": ["1398"]}
{"title": "Lace: non-blocking split deque for work-stealing\n", "abstract": " Work-stealing is an efficient method to implement load balancing in fine-grained task parallelism. Typically, concurrent deques are used for this purpose. A disadvantage of many concurrent deques is that they require expensive memory fences for local deque operations.               In this paper, we propose a new non-blocking work-stealing deque based on the split task queue. Our design uses a dynamic split point between the shared and the private portions of the deque, and only requires memory fences when shrinking the shared portion.               We present Lace, an implementation of work-stealing based on this deque, with an interface similar to the work-stealing library Wool, and an evaluation of Lace based on several common benchmarks. We also implement a recent approach using private deques in Lace. We show that the split deque and the private deque in Lace have similar low overhead and\u00a0\u2026", "num_citations": "32\n", "authors": ["1398"]}
{"title": "State space reduction of linear processes using control flow reconstruction\n", "abstract": " We present a new method for fighting the state space explosion of process algebraic specifications, by performing static analysis on an intermediate format: linear process equations (LPEs). Our method consists of two steps: (1) we reconstruct the LPE\u2019s control flow, detecting control flow parameters that were introduced by linearisation as well as those already encoded in the original specification; (2) we reset parameters found to be irrelevant based on data flow analysis techniques similar to traditional liveness analysis, modified to take into account the parallel nature of the specifications. Our transformation is correct with respect to strong bisimilarity, and never increases the state space. Case studies show that impressive reductions occur in practice, which could not be obtained automatically without reconstructing the control flow.", "num_citations": "32\n", "authors": ["1398"]}
{"title": "Cones and foci: A mechanical framework for protocol verification\n", "abstract": " We define a cones and foci proof method, which rephrases the question whether two system specifications are branching bisimilar in terms of proof obligations on relations between data objects. Compared to the original cones and foci method from Groote and Springintveld, our method is more generally applicable, because it does not require a preprocessing step to eliminate \u03c4-loops. We prove soundness of our approach and present a set of rules to prove the reachability of focus points. Our method has been formalized and proved correct using PVS. Thus we have established a framework for mechanical protocol verification. We apply this framework to the Concurrent Alternating Bit Protocol.", "num_citations": "32\n", "authors": ["1398"]}
{"title": "Multi-core BDD operations for symbolic reachability\n", "abstract": " This paper presents scalable parallel BDD operations for modern multi-core hardware. We aim at increasing the performance of reachability analysis in the context of model checking. Existing approaches focus on performing multiple independent BDD operations rather than parallelizing the BDD operations themselves. In the past, attempts at parallelizing BDD operations have been unsuccessful due to communication costs in shared memory.We solved this problem by extending an existing lockless hashtable to support BDDs and garbage collection and by implementing a lockless memoization table. Using these lockless hashtables and the work-stealing framework Wool, we implemented a multi-core BDD package called Sylvan.We provide the experimental results of using this multi-core BDD package in the framework of the model checker LTSmin. We measured the runtime of the reachability algorithm on\u00a0\u2026", "num_citations": "31\n", "authors": ["1398"]}
{"title": "Modeling and verification of the bitcoin protocol\n", "abstract": " Bitcoin is a popular digital currency for online payments, realized as a decentralized peer-to-peer electronic cash system. Bitcoin keeps a ledger of all transactions; the majority of the participants decides on the correct ledger. Since there is no trusted third party to guard against double spending, and inspired by its popularity, we would like to investigate the correctness of the Bitcoin protocol. Double spending is an important threat to electronic payment systems. Double spending would happen if one user could force a majority to believe that a ledger without his previous payment is the correct one. We are interested in the probability of success of such a double spending attack, which is linked to the computational power of the attacker. This paper examines the Bitcoin protocol and provides its formalization as an UPPAAL model. The model will be used to show how double spending can be done if the parties in the Bitcoin protocol behave maliciously, and with what probability double spending occurs.", "num_citations": "30\n", "authors": ["1398"]}
{"title": "Formal verification of replication on a distributed data space architecture\n", "abstract": " We investigate the formal verification of safety-critical systems on top of the distributed data space architecture Splice. In Splice each component has its own local data space which can be kept small using keys, time stamps and selective over-writing. We use two complementary formal tools: first the \u00b5CRL tool set for a rapid investigation of alternatives by a limited verification with state space exploration techniques; next the most promising solutions are verified in general by means of the interactive theorem prover of PVS. These formal techniques are used to investigate transparent replication of certain components on top of Splice. We prove that a convenient solution can be obtained by means of a slight extension of the write primitive of Splice.", "num_citations": "29\n", "authors": ["1398"]}
{"title": "Multi-core reachability for timed automata\n", "abstract": " Abstract Model checking of timed automata is a widely used technique. But in order to take advantage of modern hardware, the algorithms need to be parallelized. We present a multi-core reachability algorithm for the more general class of well-structured transition systems, and an implementation for timed automata. Our implementation extends the opaal tool to generate a timed automaton successor generator in c++, that is efficient enough to compete with the uppaal model checker, and can be used by the discrete model checker LTSmin, whose parallel reachability algorithms are now extended to handle subsumption of semi-symbolic states. The reuse of efficient lockless data structures guarantees high scalability and efficient memory use. With experiments we show that opaal+ LTSmin can outperform the current state-of-the-art, uppaal. The added parallelism is shown to reduce verification times from minutes to\u00a0\u2026", "num_citations": "28\n", "authors": ["1398"]}
{"title": "Bridging the gap between enumerative and symbolic model checkers\n", "abstract": " We present a method to perform symbolic state space generation for languages with existing enumerative state generators. The method is largely independent from the chosen modelling language. We validated this on three different types of languages and tools: state-based languages (PROMELA), action-based process algebras (\u00b5CRL, mCRL2), and discrete abstractions of ODEs (Maple). Only little information about the combinatorial structure of the underlying model checking problem needs to be provided. The key enabling data structure is the \u201cPINS\u201d dependency matrix. Moreover, it can be provided gradually (more precise information yields better results). Second, in addition to symbolic reachability, the same PINS matrix contains enough information to enable new optimizations in state space generation (local transition caching), again independent from the chosen modelling language. We have also based existing optimizations, like (recursive) state collapsing, on top of PINS and hint at how to support partial order reduction techniques. Third, PINS allows interfacing of existing state generators to, eg, distributed reachability tools. Thus, besides the stated novelties, the method we propose also significantly reduces the complexity of building modular yet still efficient model checking tools. Our experiments show that we can match or even outperform existing tools by reusing their own state generators, which we have linked into an implementation of our ideas.", "num_citations": "28\n", "authors": ["1398"]}
{"title": "Resource-constrained optimal scheduling of synchronous dataflow graphs via timed automata\n", "abstract": " Synchronous dataflow (SDF) graphs are a widely used formalism for modelling, analysing and realising streaming applications, both on a single processor and in a multiprocessing context. Efficient schedules are essential to obtain maximal throughput under the constraint of available resources. This paper presents an approach to schedule SDF graphs using a proven formalism of timed automata (TA). TA maintain a good balance between expressiveness and tractability, and are supported by powerful verification tools, e.g. UPPAAL. We describe a compositional translation of SDF graphs to TA, and perform analysis and verification in the UPPAAL state-of-the-art tool. This approach does not require the (exponential) transformation of SDF graphs to homogeneous SDF graphs and helps to find schedules with a trade-off between the number of processors required and the throughput. It also allows quantitative model\u00a0\u2026", "num_citations": "27\n", "authors": ["1398"]}
{"title": "Biological networks 101: Computational modeling for molecular biologists\n", "abstract": " Computational modeling of biological networks permits the comprehensive analysis of cells and tissues to define molecular phenotypes and novel hypotheses. Although a large number of software tools have been developed, the versatility of these tools is limited by mathematical complexities that prevent their broad adoption and effective use by molecular biologists. This study clarifies the basic aspects of molecular modeling, how to convert data into useful input, as well as the number of time points and molecular parameters that should be considered for molecular regulatory models with both explanatory and predictive potential. We illustrate the necessary experimental preconditions for converting data into a computational model of network dynamics. This model requires neither a thorough background in mathematics nor precise data on intracellular concentrations, binding affinities or reaction kinetics. Finally, we\u00a0\u2026", "num_citations": "27\n", "authors": ["1398"]}
{"title": "Leader election in anonymous rings: Franklin goes probabilistic\n", "abstract": " We present a probabilistic leader election algorithm for anonymous, bidirectional, asynchronous rings. It is based on an algorithm from Franklin 22, augmented with random identity selection, hop counters to detect identity clashes, and round numbers modulo 2. As a result, the algorithm is finite-state, so that various model checking techniques can be employed to verify its correctness, that is, eventually a unique leader is elected with probability one. We also sketch a formal correctness proof of the algorithm for rings with arbitrary size.", "num_citations": "26\n", "authors": ["1398"]}
{"title": "Formal Specification of JavaSpaces\u2122 Architecture Using \u03bcCRL\n", "abstract": " We study a formal specification of the shared data space architecture, JavaSpaces. This Java technology provides a virtual space for entities, like clients and servers, to communicate by sharing objects. We use \u03bcCRL, a language that combines abstract data types with process algebra, to model an abstraction of this coordination architecture. Besides the basic primitives write, read and take, our model captures transactions and leasing. The main purpose of the proposed formalism is to allow the verification of distributed applications built under the JavaSpaces model. A simple case study is analyzed and automatically model checked using the \u03bcCRL and CADP tool sets.", "num_citations": "26\n", "authors": ["1398"]}
{"title": "Bandwidth and wavefront reduction for static variable ordering in symbolic reachability analysis\n", "abstract": " We investigate the use of bandwidth and wavefront reduction algorithms to determine a static BDD variable ordering. The aim is to reduce the size of BDDs arising in symbolic reachability. Previous work showed that minimizing the (weighted) event span of the variable dependency graph yields small BDDs. The bandwidth and wavefront of symmetric matrices are well studied metrics, used in sparse matrix solvers, and many bandwidth and wavefront reduction algorithms are readily available in libraries like Boost and ViennaCL.                 In this paper, we transform the dependency matrix to a symmetric matrix and apply various bandwidth and wavefront reduction algorithms, measuring their influence on the (weighted) event span. We show that Sloan\u2019s algorithm, executed on the total graph of the dependency matrix, yields a variable order with minimal event span. We demonstrate this on a large benchmark\u00a0\u2026", "num_citations": "25\n", "authors": ["1398"]}
{"title": "Just-in-time: On strategy annotations\n", "abstract": " A simple kind of strategy annotations is investigated, giving rise to a class of strategies, including leftmost-innermost. It is shown that under certain restrictions on annotations, an interpreter can be written which computes a normal form of a term in a bottom-up traversal. The main contribution is a correctness proof of this interpreter. Furthermore, a default strategy annotation is provided, called just-in-time, which satisfies the criteria for the interpreter. The just-in-time strategy has a better termination behaviour than innermost rewriting for many interesting examples.", "num_citations": "24\n", "authors": ["1398"]}
{"title": "Modelling with ANIMO: between fuzzy logic and differential equations\n", "abstract": " Computational support is essential in order to reason on the dynamics of biological systems. We have developed the software tool ANIMO (Analysis of Networks with Interactive MOdeling) to provide such computational support and allow insight into the complex networks of signaling events occurring in living cells. ANIMO makes use of timed automata as an underlying model, thereby enabling analysis techniques from computer science like model checking. Biology experts are able to use ANIMO via a user interface specifically tailored for biological applications. In this paper we compare the use of ANIMO with some established formalisms on two case studies. ANIMO is a powerful and user-friendly tool that can compete with existing continuous and discrete paradigms. We show this by presenting ANIMO models for two case studies: Drosophila melanogaster circadian clock, and signal transduction events\u00a0\u2026", "num_citations": "23\n", "authors": ["1398"]}
{"title": "A linear process-algebraic format with data for probabilistic automata\n", "abstract": " This paper presents a novel linear process-algebraic format for probabilistic automata. The key ingredient is a symbolic transformation of probabilistic process algebra terms that incorporate data into this linear format while preserving strong probabilistic bisimulation. This generalises similar techniques for traditional process algebras with data, and \u2014 more importantly \u2014 treats data and data-dependent probabilistic choice in a fully symbolic manner, leading to the symbolic analysis of parameterised probabilistic systems. We discuss several reduction techniques that can easily be applied to our models. A validation of our approach on two benchmark leader election protocols shows reductions of more than an order of magnitude.", "num_citations": "23\n", "authors": ["1398"]}
{"title": "Solving scheduling problems by untimed model checking: the clinical chemical analyser case study\n", "abstract": " In this paper, we show how scheduling problems can be modelled in untimed process algebra, by using special tick-actions. As a result, we can use efficient, distributed state space generators to solve scheduling problems. Also, we can use more flexible data specifications than timed model checkers usually provide. We propose a variant on breadth-first search, which visits the states per time slice between ticks. We applied our approach to find optimal schedules for test batches of a realistic clinical chemical analyser, which performs several kinds of tests on patient samples.", "num_citations": "23\n", "authors": ["1398"]}
{"title": "Read, write and copy dependencies for symbolic model checking\n", "abstract": " This paper aims at improving symbolic model checking for explicit state modeling languages, eg, Promela, Dve and mCRL 2. The modular Pins architecture of LTSmin supports a notion of event locality, by merely indicating for each event on which variables it depends. However, one could distinguish four separate dependencies: read, may-write, must-write and copy. In this paper, we introduce these notions in a language-independent manner. In particular, models with arrays need to distinguish overwriting and copying of values. We also adapt the symbolic model checking algorithms to exploit the refined dependency information. We have implemented refined dependency matrices for Promela, Dve and mCRL 2, in order to compare our new algorithms to the original version of LTSmin. The results show that the amount of successor computations and memory footprint are greatly reduced. Finally, the optimal\u00a0\u2026", "num_citations": "22\n", "authors": ["1398"]}
{"title": "Variations on multi-core nested depth-first search\n", "abstract": " Recently, two new parallel algorithms for on-the-fly model checking of LTL properties were presented at the same conference: Automated Technology for Verification and Analysis, 2011. Both approaches extend Swarmed NDFS, which runs several sequential NDFS instances in parallel. While parallel random search already speeds up detection of bugs, the workers must share some global information in order to speed up full verification of correct models. The two algorithms differ considerably in the global information shared between workers, and in the way they synchronize. Here, we provide a thorough experimental comparison between the two algorithms, by measuring the runtime of their implementations on a multi-core machine. Both algorithms were implemented in the same framework of the model checker LTSmin, using similar optimizations, and have been subjected to the full BEEM model database. Because both algorithms have complementary advantages, we constructed an algorithm that combines both ideas. This combination clearly has an improved speedup. We also compare the results with the alternative parallel algorithm for accepting cycle detection OWCTY-MAP. Finally, we study a simple statistical model for input models that do contain accepting cycles. The goal is to distinguish the speedup due to parallel random search from the speedup that can be attributed to clever work sharing schemes.", "num_citations": "22\n", "authors": ["1398"]}
{"title": "Automatic model-based generation of parameterized test cases using data abstraction\n", "abstract": " Developing test suites is a costly and error-prone process. Model-based test generation tools facilitate this process by automatically generating test cases from system models. The applicability of these tools, however, depends on the size of the target systems. Here, we propose an approach to generate test cases by combining data abstraction, enumerative test generation and constraint-solving. Given the concrete specification of a possibly infinite system, data abstraction allows to derive an abstract system, which is finite and thus suitable for the automatic generation of abstract test cases with enumerative tools. To execute abstract test cases, we have to instantiate them with concrete data. For data selection we make use of constraint-solving techniques.", "num_citations": "22\n", "authors": ["1398"]}
{"title": "Integrated Formal Methods: 5th International Conference, IFM 2005, Eindhoven, The Netherlands, November 29-December 2, 2005. Proceedings\n", "abstract": " This is the 5th edition of the International Conference on Integrated Formal Methods (IFM). Previous IFM conferences were held in York (June 1999), D-stuhl (November 2000), Turku (May 2002) and Canterbury (April 2004). This year's IFM was held in December 2005 on the campus of the Technische Univ-siteit Eindhoven in The Netherlands. This year IFM received 40 submissions, from which 19 high-quality papers wereselectedbytheProgramCommittee. Besidesthese, theproceedingscontain invited contributions by Patrice Godefroid, David Parnas and Doron Peled. It was 10 years ago that Jonathan P. Bowen and Michael G. Hinchey p-lished their famous Ten Commandments of Formal Methods in IEEE Computer 28 (4). Their very? rst commandment\u2014Thou shalt choose an appropriate-tation\u2014touches the heart of the IFM theme: Complex systems have di? erent aspects, and each aspect requires its own appropriate notation. Classical examples of models for various aspects are: state based notations andalgebraicdatatypesfordata, processalgebrasandtemporallogicsforbeh-ior, duration calculus and timed automata for timing aspects, etc. The central question is how the models of di? erent notations relate. Recently, Bowen and Hinchey presented their Ten Commandments Revisited (in: ACM proceedings of the 10th InternationalWorkshop on Formal Methods for Industrial Critical S-tems). Theydistinghuishvariationsin combiningnotations, rangingfromloosely coupled viewpoints to integrated methods. Thelooselycoupledviewpointsarequitepopular (cf. thesuccessofUML) and are easy to adopt in a leightweight process. They could be useful for\u00a0\u2026", "num_citations": "21\n", "authors": ["1398"]}
{"title": "Refinement and Verification Applied to an In-Flight Data Acquisition Unit\n", "abstract": " In order to optimise maintenance and increase safety, the Royal Netherlands Navy initiated the development of a multi-channel on-board data acquisition system for its Lynx helicopters. This AIDA (Automatic In-flight Data Acquisition) system records usage and loads data on main rotor, engines and airframe. We used refinement in combination with model checking to arrive at a formally verified prototype implementation of the AIDA system, starting from the functional requirements.", "num_citations": "20\n", "authors": ["1398"]}
{"title": "Green computing: Power optimisation of VFI-based real-time multiprocessor dataflow applications\n", "abstract": " Execution time is no longer the only performance metric for computer systems. In fact, a trend is emerging to trade raw performance for energy savings. Techniques like Dynamic Power Management (DPM, switching to low power state) and Dynamic Voltage and Frequency Scaling (DVFS, throttling processor frequency) help modern systems to reduce their power consumption while adhering to performance requirements. To balance flexibility and design complexity, the concept of Voltage and Frequency Islands (VFIs) was recently introduced for power optimisation. It achieves fine-grained system-level power management, by operating all processors in the same VFI at a common frequency/voltage. This paper presents a novel approach to compute a power management strategy combining DPM and DVFS. In our approach, applications (modelled in full synchronous dataflow, SDF) are mapped on heterogeneous\u00a0\u2026", "num_citations": "19\n", "authors": ["1398"]}
{"title": "Data abstraction and constraint solving for conformance testing\n", "abstract": " Conformance testing is one of the most rigorous and well-developed testing techniques. Model-based test generation is an essential phase of the conformance testing approach. The main problem in this phase is the explosion of the number of test cases, often caused by large or infinite data domains for input and output data. In this paper we propose a test generation framework based on the use of data abstraction and constraint solving to suppress the number of test cases. The approach is evaluated on the CEPS (common electronic purse specifications) case study.", "num_citations": "19\n", "authors": ["1398"]}
{"title": "Multi-core SCC-based LTL model checking\n", "abstract": " We investigate and improve the scalability of multi-core LTL model checking. Our algorithm, based on parallel DFS-like SCC decomposition, is able to efficiently decompose large SCCs on-the-fly, which is a difficult problem to solve in parallel.               To validate the algorithm we performed experiments on a 64-core machine. We used an extensive set of well-known benchmark collections obtained from the BEEM database and the Model Checking Contest. We show that the algorithm is competitive with the current state-of-the-art model checking algorithms. For larger models we observe that our algorithm outperforms the competitors. We investigate how graph characteristics relate to and pose limitations on the achieved speedups.", "num_citations": "18\n", "authors": ["1398"]}
{"title": "A rewriting approach to binary decision diagrams\n", "abstract": " Binary decision diagrams (BDDs) provide an established technique for propositional formula manipulation. In this paper, we present the basic BDD theory by means of standard rewriting techniques. Since a BDD is a DAG instead of a tree we need a notion of shared rewriting and develop appropriate theory. A rewriting system is presented by which canonical reduced ordered BDDs (ROBDDs) can be obtained and for which uniqueness of ROBDD representation is proved. Next, an alternative rewriting system is presented, suitable for actually computing ROBDDs from formulas. For this rewriting system a layerwise strategy is defined, and it is proved that when replacing the classical apply-algorithm by layerwise rewriting, roughly the same complexity bound is reached as in the classical algorithm. Moreover, a layerwise innermost strategy is defined and it is proved that the full classical algorithm for computing\u00a0\u2026", "num_citations": "18\n", "authors": ["1398"]}
{"title": "Parallel model checking algorithms for linear-time temporal logic\n", "abstract": " Model checking is a fully automated, formal method for demonstrating absence of bugs in reactive systems. Here, bugs are violations of properties in Linear-time Temporal Logic (LTL). A fundamental challenge to its application is the exponential explosion in the number of system states. The current chapter discusses the use of parallelism in order to overcome this challenge. We reiterate the textbook automata-theoretic approach, which reduces the model checking problem to the graph problem of finding cycles. We discuss several parallel algorithms that attack this problem in various ways, each with different characteristics: Depth-first search (DFS) based algorithms rely on heuristics for good parallelization, but exhibit a low complexity and good on-the-fly behavior. Breadth-first search (BFS) based approaches, on the other hand, offer good parallel scalability and support distributed parallelism. In addition\u00a0\u2026", "num_citations": "17\n", "authors": ["1398"]}
{"title": "Generating and solving symbolic parity games\n", "abstract": " We present a new tool for verification of modal mu-calculus formulae for process specifications, based on symbolic parity games. It enhances an existing method, that first encodes the problem to a Parameterised Boolean Equation System (PBES) and then instantiates the PBES to a parity game. We improved the translation from specification to PBES to preserve the structure of the specification in the PBES, we extended LTSmin to instantiate PBESs to symbolic parity games, and implemented the recursive parity game solving algorithm by Zielonka for symbolic parity games. We use Multi-valued Decision Diagrams (MDDs) to represent sets and relations, thus enabling the tools to deal with very large systems. The transition relation is partitioned based on the structure of the specification, which allows for efficient manipulation of the MDDs. We performed two case studies on modular specifications, that demonstrate that the new method has better time and memory performance than existing PBES based tools and can be faster (but slightly less memory efficient) than the symbolic model checker NuSMV.", "num_citations": "17\n", "authors": ["1398"]}
{"title": "A linear process-algebraic format for probabilistic systems with data\n", "abstract": " This paper presents a novel linear process-algebraic format for probabilistic automata. The key ingredient is a symbolic transformation of probabilistic process algebra terms that incorporate data into this linear format while preserving strong probabilistic bisimulation. This generalises similar techniques for traditional process algebras with data, and - more importantly - treats data and data-dependent probabilistic choice in a fully symbolic manner, paving the way to the symbolic analysis of parameterised probabilistic systems.", "num_citations": "17\n", "authors": ["1398"]}
{"title": "Distributed branching bisimulation minimization by inductive signatures\n", "abstract": " We present a new distributed algorithm for state space minimization modulo branching bisimulation. Like its predecessor it uses signatures for refinement, but the refinement process and the signatures have been optimized to exploit the fact that the input graph contains no tau-loops. The optimization in the refinement process is meant to reduce both the number of iterations needed and the memory requirements. In the former case we cannot prove that there is an improvement, but our experiments show that in many cases the number of iterations is smaller. In the latter case, we can prove that the worst case memory use of the new algorithm is linear in the size of the state space, whereas the old algorithm has a quadratic upper bound. The paper includes a proof of correctness of the new algorithm and the results of a number of experiments that compare the performance of the old and the new algorithms.", "num_citations": "17\n", "authors": ["1398"]}
{"title": "JITty: a rewriter with strategy annotations\n", "abstract": " We demonstrate JITty, a simple rewrite implementation with strategy annotations, along the lines of the Just-In-Time rewrite strategy, explained and justified in [4]. Our tool has the following distinguishing features:                                         It provides the flexibility of user defined strategy annotations, which specify the order of normalizing arguments and applying rewrite rules.                                                           Strategy annotations are checked for correctness, and it is guaranteed that all produced results are normal forms w.r.t. the underlying TRS.                                                           The tool is \u201clight-weight\u201d with compact but fast code.                                                           A TRS is interpreted, rather than compiled, so the tool has a short start-up time and is portable to many platforms.", "num_citations": "17\n", "authors": ["1398"]}
{"title": "Simulation as a correct transformation of rewrite systems\n", "abstract": " Kamperman and Walters proposed the notion of a simulation of one rewrite system by another one, whereby each term of the simulating rewrite system is related to a term in the original rewrite system. In this paper it is shown that if such a simulation is sound and complete and preserves termination, then the transformation of the original into the simulating rewrite system constitutes a correct step in the compilation of the original rewrite system. That is, the normal forms of a term in the original rewrite system can then be obtained by computing the normal forms of a related term in the simulating rewrite system.", "num_citations": "17\n", "authors": ["1398"]}
{"title": "Compositional control synthesis for partially observable systems\n", "abstract": " We present a compositional method for deriving control constraints on a network of interconnected, partially observable and partially controllable plant components. The constraint derivation method works in conjunction with an antichain\u2013based, symbolic algorithm for computing weakest strategies in safety games of imperfect information. We demonstrate how the technique allows a reactive controller to be synthesized in an incremental manner, exploiting locality and independence in the problem specification.", "num_citations": "16\n", "authors": ["1398"]}
{"title": "Generalizing DPLL and satisfiability for equalities\n", "abstract": " We present GDPLL, a generalization of the DPLL procedure. It solves the satisfiability problem for decidable fragments of quantifier-free first-order logic. Sufficient conditions are identified for proving soundness, termination and completeness of GDPLL. We show how the original DPLL procedure is an instance. Subsequently the GDPLL instances for equality logic, and the logic of equality over infinite ground term algebras are presented. Based on this, we implemented a decision procedure for inductive datatypes. We provide some new benchmarks, in order to compare variants.", "num_citations": "16\n", "authors": ["1398"]}
{"title": "Verification of JavaSpaces/spl trade/parallel programs\n", "abstract": " We illustrate a formal verification method for distributed JavaSpaces applications by analyzing a nontrivial fault tolerant algorithm that solves a typical coordination problem. The problem consists of the computation of an extensive task, performed in parallel by splitting it into smaller and more manageable parts. The proposed solution, based on JavaSpaces coordination primitives, transactions and timeouts, is verified by translating it to the formal language /spl mu/CRL, together with the previously developed /spl mu/CRL-model of the JavaSpaces architecture, and by using model checking techniques.", "num_citations": "16\n", "authors": ["1398"]}
{"title": "Operational semantics of rewriting with priorities\n", "abstract": " We study the semantics of term rewriting systems with rule priorities (PRS), as introduced in Baeten et al. (1989). Three open problems posed in that paper are solved, by giving counter examples. Moreover, a class of executable PRSs is identified. A translation of PRSs into transition system specifications (TSS) is given. This translation introduces negative premises. We prove that the translation preserves the operational semantics.", "num_citations": "16\n", "authors": ["1398"]}
{"title": "Modularity in many-sorted term rewriting systems\n", "abstract": " Many-sorted term rewriting systems (MTRS) are an extension of the formalism of term rewriting systems (TRS). The direct sum of TRS's is generalized to the direct sum of MTRS's. Some equivalence between\\taking the direct sum\" and\\eliminating the sorts\" is established: Component closed reduction properties which are resistant against disjoint union (modularity), are also resistant against sort elimination (persistence). The reverse has been proved earlier.", "num_citations": "16\n", "authors": ["1398"]}
{"title": "TTCN-3 testing of hoorn-kersenboogerd railway interlocking\n", "abstract": " Railway control systems are safety-critical, so we have to ensure that they are designed and implemented correctly. Testing these systems is a key issue. Prior to system testing, the software of a railway control system is tested separately from the hardware. The interlocking is a layer of railway control systems that guarantees safety. It allows to execute commands given by a user only if they are safe; unsafe commands are rejected. Railway interlockings are central to efficient and safe traffic management for railway infrastructure managers and operators. European integration requires new standards for specification and testing interlockings. Here we propose an approach to testing interlockings with TTCN-3 and give an example for its application. The code of interlockings is simulated during test execution. For assessing the quality of the tests, we propose an approach inspired by the classification tree method", "num_citations": "15\n", "authors": ["1398"]}
{"title": "New developments around the \u00b5CRL tool set\n", "abstract": " Some recent developments in the \u03bcCRL tool set are presented. New analysis techniques are a symbolic model checker, and a visualizer for huge state spaces. Also various transformations are presented. At symbolic level, theorem proving, data flow analysis, and confluence checking are used to obtain considerable state space reductions. At the concrete level, distributed implementations of state space generation and minimization are recent. We mention the successful application of the tools to the verification of large data-intensive distributed systems.", "num_citations": "14\n", "authors": ["1398"]}
{"title": "Multi-core symbolic bisimulation minimisation\n", "abstract": " We introduce parallel symbolic algorithms for bisimulation minimisation, to combat the combinatorial state space explosion along three different paths. Bisimulation minimisation reduces a transition system to the smallest system with equivalent behaviour. We consider strong and branching bisimilarity for interactive Markov chains, which combine labelled transition systems and continuous-time Markov chains. Large state spaces can be represented concisely by symbolic techniques, based on binary decision diagrams. We present specialised BDD operations to compute the maximal bisimulation using signature-based partition refinement. We also study the symbolic representation of the quotient system and suggest an encoding based on representative states, rather than block numbers. Our implementation extends the parallel, shared memory, BDD library Sylvan, to obtain a significant speedup on multi-core\u00a0\u2026", "num_citations": "13\n", "authors": ["1398"]}
{"title": "Partial-order reduction for GPU model checking\n", "abstract": " Model checking using GPUs has seen increased popularity over the last years. Because GPUs have a limited amount of memory, only small to medium-sized systems can be verified. For on-the-fly explicit-state model checking, we improve memory efficiency by applying partial-order reduction. We propose novel parallel algorithms for three practical approaches to partial-order reduction. Correctness of the algorithms is proved using a new, weaker version of the cycle proviso. Benchmarks show that our implementation achieves a reduction similar to or better than the state-of-the-art techniques for CPUs, while the amount of runtime overhead is acceptable.", "num_citations": "13\n", "authors": ["1398"]}
{"title": "Thoughtful brute-force attack of the RERS 2012 and 2013 Challenges\n", "abstract": " The Rigorous Examination of Reactive Systems\u2019 (rers) Challenges provide a forum for experimental evaluation based on specifically synthesized benchmark suites. In this paper, we report on our \u2018brute-force attack\u2019 of the rers 2012 and 2013 Challenges. We connected the rers problems to two state-of-the-art explicit state model checkers: LTSmin and Spin. Apart from an effective compression of the state vector, we did not analyze the source code of the problems. Our brute-force approach was successful: it won both editions of the rers Challenge.", "num_citations": "13\n", "authors": ["1398"]}
{"title": "Efficient instantiation of parameterised boolean equation systems to parity games\n", "abstract": " Parameterised Boolean Equation Systems (PBESs) are sequences of Boolean fixed point equations with data variables, used for, e.g., verification of modal mu-calculus formulae for process algebraic specifications with data. Solving a PBES is usually done by instantiation to a Parity Game and then solving the game. Practical game solvers exist, but the instantiation step is the bottleneck. We enhance the instantiation in two steps. First, we transform the PBES to a Parameterised Parity Game (PPG), a PBES with each equation either conjunctive or disjunctive. Then we use LTSmin, that offers transition caching, efficient storage of states and both distributed and symbolic state space generation, for generating the game graph. To that end we define a language module for LTSmin, consisting of an encoding of variables with parameters into state vectors, a grouped transition relation and a dependency matrix to indicate the dependencies between parts of the state vector and transition groups. Benchmarks on some large case studies, show that the method speeds up the instantiation significantly and decreases memory usage drastically.", "num_citations": "13\n", "authors": ["1398"]}
{"title": "Distributed Markovian bisimulation reduction aimed at CSL model checking\n", "abstract": " The verification of quantitative aspects like performance and dependability by means of model checking has become an important and vivid area of research over the past decade.An important result of that research is the logic CSL (continuous stochastic logic) and its corresponding model checking algorithms. The evaluation of properties expressed in CSL makes it necessary to solve large systems of linear (differential) equations, usually by means of numerical analysis. Both the inherent time and space complexity of the numerical algorithms make it practically infeasible to model check systems with more than 100 million states, whereas realistic system models may have billions of states.To overcome this severe restriction, it is important to be able to replace the original state space with a probabilistically equivalent, but smaller one. The most prominent equivalence relation is bisimulation, for which also a stochastic\u00a0\u2026", "num_citations": "13\n", "authors": ["1398"]}
{"title": "Formal requirements specification for command and control systems\n", "abstract": " This paper presents an approach to formal requirements specification of embedded systems. The specific demands of a specification for command and control systems are addressed. The proposed method allows various views of a system, like conventional methods. The added value lies in the fact that the relationship between the views is specified formally, and consistency between views can be analyzed formally. As a case study, we develop and analyze a formal requirements specification for a subsystem of a realistic command and control system. Specification and verification are carried out using the language and proof checker of PVS.", "num_citations": "13\n", "authors": ["1398"]}
{"title": "Maximizing synchronization for aligning observed and modelled behaviour\n", "abstract": " Conformance checking is a branch of process mining that aims to assess to what degree event data originating from the execution of a (business) process and a corresponding reference model conform to each other. Alignments have been recently introduced as a solution for conformance checking and have since rapidly developed into becoming the de facto standard.                 The state-of-the-art method to compute alignments is based on solving a shortest path problem derived from the reference model and the event data. Within such a shortest path problem, a cost function is used to guide the search to an optimal solution. The standard cost-function treats mismatches in the model and log as equal. In this paper, we consider a variant of this standard cost function which maximizes the number of correct matches instead. We study the effects of using this cost-function compared to the standard cost\u00a0\u2026", "num_citations": "12\n", "authors": ["1398"]}
{"title": "Abstraction of parallel uniform processes with data\n", "abstract": " In practice, distributed systems are quite often composed by an arbitrarily large but finite number of processes that execute a similar program. Abstract interpretation is an effective technique to fight state explosion problems. In this paper, we propose a general framework for abstracting parallel composition of uniform processes with data, in the setting of a process algebraic language /spl mu/CRL We illustrate the feasibility of this technique by proposing two instances of the general framework and applying them to the verification of two systems.", "num_citations": "12\n", "authors": ["1398"]}
{"title": "Refinement in requirements specification and analysis: A case study\n", "abstract": " This paper presents a formal method for requirements specification and analysis. Using this method some techniques for step-wise refinement are studied. During the early phases of system development, where the exact requirements are yet unclear these techniques allow to write incomplete and global specifications, which during successive steps can be refined and completed. At each step the method supports formal analysis of the specification. In particular two abstraction techniques are studied: nondeterminism and uninterpreted symbols. These techniques are explored using a realistic case study, that was inspired by the specification of an existing naval command and control system. Specifications are written and analysed using the language and proof checker of PVS.", "num_citations": "12\n", "authors": ["1398"]}
{"title": "Layered and collecting NDFS with subsumption for parametric timed automata\n", "abstract": " This paper studies the analysis and parameter synthesis problems for Parametric Timed Automata (PTA) with properties in Linear-time Temporal Logic (LTL). It introduces a series of variations of Nested Depth-First Search (NDFS). We first study the LTL model checking problem for PTA. Based on a careful analysis of parametric zones, we introduce a new layered NDFS approach to LTL model checking. We integrate this with several techniques to prune the search space. In particular, we apply subsumption abstraction to PTA for the first time. We also propose heuristics on the search order to improve the performance. Next, we study parameter synthesis. To this end, this new layered approach and subsumption are added to a Collecting NDFS scheme. We implemented all algorithms in the Imitator tool and analyse their efficiency in a number of experiments.", "num_citations": "11\n", "authors": ["1398"]}
{"title": "Synthesizing Energy-Optimal Controllers for Multiprocessor Dataflow Applications with Uppaal Stratego\n", "abstract": " Streaming applications for mobile platforms impose high demands on a system\u2019s throughput and energy consumption. Dynamic system-level techniques have been introduced, to reduce power consumption at the expense of performance. We consider DPM (Dynamic Power Management) and DVFS (Dynamic Voltage and Frequency Scaling). The complex programming task now includes mapping and scheduling every task onto a heterogeneous multi-processor hardware platform. Moreover, DPM and DVFS parameters must be controlled, to meet all throughput constraints while minimizing the energy consumption. Previous work proposed to automate this process, by modeling streaming applications in SDF (Synchronous Data Flow), modeling the processor platform, translating both models to PTA (Priced Timed Automata, where prices model energy), and using Uppaal Cora to compute energy-optimal schedules\u00a0\u2026", "num_citations": "11\n", "authors": ["1398"]}
{"title": "Setting parameters for biological models with ANIMO\n", "abstract": " ANIMO (Analysis of Networks with Interactive MOdeling) is a software for modeling biological networks, such as e.g. signaling, metabolic or gene networks. An ANIMO model is essentially the sum of a network topology and a number of interaction parameters. The topology describes the interactions between biological entities in form of a graph, while the parameters determine the speed of occurrence of such interactions. When a mismatch is observed between the behavior of an ANIMO model and experimental data, we want to update the model so that it explains the new data. In general, the topology of a model can be expanded with new (known or hypothetical) nodes, and enables it to match experimental data. However, the unrestrained addition of new parts to a model causes two problems: models can become too complex too fast, to the point of being intractable, and too many parts marked as \"hypothetical\" or \"not known\" make a model unrealistic. Even if changing the topology is normally the easier task, these problems push us to try a better parameter fit as a first step, and resort to modifying the model topology only as a last resource. In this paper we show the support added in ANIMO to ease the task of expanding the knowledge on biological networks, concentrating in particular on the parameter settings.", "num_citations": "11\n", "authors": ["1398"]}
{"title": "Computing weakest strategies for safety games of imperfect information\n", "abstract": " cedar (Counter Example Driven Antichain Refinement) is a new symbolic algorithm for computing weakest strategies for safety games of imperfect information. The algorithm computes a fixed point over the lattice of contravariant antichains. Here contravariant antichains are antichains over pairs consisting of an information set and an allow set representing the associated move. We demonstrate how the richer structure of contravariant antichains for representing antitone functions, as opposed to standard antichains for representing sets of downward closed sets, allows cedar to apply a significantly less complex controllable predecessor step than previous algorithms.", "num_citations": "11\n", "authors": ["1398"]}
{"title": "Simulated time for testing railway interlockings with TTCN-3\n", "abstract": " Railway control systems are timed and safety-critical. Testing these systems is a key issue. Prior to system testing, the software of a railway control system is tested separately from the hardware. Here we show that real time and scaled time semantics are inefficient for testing this software. We provide a time semantics with simulated time and show that this semantics is more suitable for testing of software of railway control systems.               TTCN-3 is a standardized language for specifying and executing test suites. It supports real time and scaled time but not simulated time. We provide a solution that allows simulated time testing with TTCN-3. Our solution is based on Dijkstra\u2019s distributed termination detection algorithm. The solution is implemented and can be reused for simulated time testing of other systems with similar characteristics.", "num_citations": "11\n", "authors": ["1398"]}
{"title": "Adaptive learning for learn-based regression testing\n", "abstract": " Regression testing is an important activity to prevent the introduction of regressions into software updates. Learn-based testing can be used to automatically check new versions of a system for regressions on a system level. This is done by learning a model of the system and model checking this model for system property violations.                 Learning the model of a large system can take an unpractical amount of time however. In this work we investigate if the concept of adaptive learning can improve the learning speed of a model in a regression testing scenario.                 We have performed several experiments with this technique on two systems: ToDoMVC and SSH. We find that there can be a large benefit to using adaptive learning. In addition we find three main factors that influence the benefit of adaptive learning. There are however also some shortcomings to adaptive learning that should be\u00a0\u2026", "num_citations": "10\n", "authors": ["1398"]}
{"title": "Symbolically aligning observed and modelled behaviour\n", "abstract": " Conformance checking is a branch of process mining that aims to assess to what degree a given set of log traces and a corresponding reference model conform to each other. The state-of-the-art approach in conformance checking is based on the concept of alignments. Alignments express the observed behaviour in terms of the reference model while minimizing the number of mismatches between the event data and the model. The currently known best algorithm for constructing alignments applies the A* shortest path algorithm for each trace of event data. In this work, we apply insights from the field of model checking to aid conformance checking. We investigate whether alignments can be computed efficiently via symbolic reachability with decision diagrams. We designed a symbolic algorithm for computing shortest-paths on graphs restricted to 0- and 1-cost edges (which is typical for alignments). We have\u00a0\u2026", "num_citations": "10\n", "authors": ["1398"]}
{"title": "Symbolic Reachability Analysis of B Through ProB and LTSmin\n", "abstract": " We present a symbolic reachability analysis approach for B that can provide a significant speedup over traditional explicit state model checking. The symbolic analysis is implemented by linking ProB to LTSmin, a high-performance language independent model checker. The link is achieved via LTSmin \u2019s Pins interface, allowing ProB to benefit from LTSmin \u2019s analysis algorithms, while only writing a few hundred lines of glue-code, along with a bridge between ProB and C using \u00d8MQ. ProB supports model checking of several formal specification languages such as B, Event-B, Z and . Our experiments are based on a wide variety of B-Method and Event-B models to demonstrate the efficiency of the new link. Among the tested categories are state space generation and deadlock detection; but action detection and invariant checking are also feasible in principle. In many cases we observe speedups of\u00a0\u2026", "num_citations": "10\n", "authors": ["1398"]}
{"title": "Mechanical verification of a two-way sliding window protocol (full version including proofs)\n", "abstract": " We prove the correctness of a two-way sliding window protocol with piggybacking, where the acknowledgments of the latest received data are attached to the next data transmitted back into the channel. The window size of both parties are considered to be finite, though they can be of different sizes. We show that this protocol is equivalent (branching bisimilar) to a pair of FIFO queues of finite capacities. The protocol is first modeled and manually proved for its correctness in the process algebraic language of \u00b5CRL. We use the theorem prover PVS to formalize and to mechanically prove the correctness. This implies both safety and liveness (under the assumption of fairness).", "num_citations": "10\n", "authors": ["1398"]}
{"title": "TTCN-3 for distributed testing embedded software\n", "abstract": " TTCN-3 is a standardized language for specifying and executing test suites that is particularly popular for testing embedded systems. Prior to testing embedded software in a target environment, the software is usually tested in the host environment. Executing in the host environment often affects the real-time behavior of the software and, consequently, the results of real-time testing.               Here we provide a semantics for host-based testing with simulated time and a a simulated-time solution for distributed testing with TTCN-3.", "num_citations": "10\n", "authors": ["1398"]}
{"title": "Zero, successor and equality in BDDs\n", "abstract": " We extend BDDs (binary decision diagrams) for plain propositional logic to the fragment of first order logic, consisting of quantifier free logic with zero, successor and equality. We allow equations with zero and successor in the nodes of a BDD, and call such objects (0, S,=)-BDDs. We extend the notion of Ordered BDDs in the presence of zero, successor and equality.(0, S,=)-BDDs can be transformed to equivalent Ordered (0, S,=)-BDDs by applying a number of rewrite rules until a normal form is reached. All paths in these ordered (0, S,=)-BDDs represent satisfiable conjunctions. The major advantage of transforming a formula to an equivalent Ordered (0, S,=)-BDD is that on the latter it can be observed in constant time whether the formula is a tautology, a contradiction, or just satisfiable.", "num_citations": "10\n", "authors": ["1398"]}
{"title": "Generalized innermost rewriting\n", "abstract": " We propose two generalizations of innermost rewriting for which we prove that termination of innermost rewriting is equivalent to termination of generalized innermost rewriting. As a consequence, by rewriting in an arbitrary TRS certain non-innermost steps may be allowed by which the termination behavior and efficiency is often much better, but never worse than by only doing innermost rewriting.", "num_citations": "10\n", "authors": ["1398"]}
{"title": "Model checking and evaluating QoS of batteries in MPSoC dataflow applications via hybrid automata\n", "abstract": " System lifetime is a major design constraint for battery-powered mobile embedded systems. The increasing gap between the energy demand of portable devices and their battery capacities is further limiting durability of mobile devices. Thus, the guarantees over Quality of Service (QoS) of battery-constrained devices under strict battery capacities are of primary interest for mobile embedded systems' manufacturers and stakeholders. This paper presents a novel approach for deriving QoS of applications modelled as synchronous dataflow (SDF) graphs. We map these applications on heterogeneous multiprocessor platforms that are partitioned into Voltage and Frequency Islands, together with multiple kinetic battery models (KiBaMs). By modelling the whole system as hybrid automata, and applying model-checking, we evaluate, (1) system lifetime, and (2) minimum required initial battery capacities to achieve the\u00a0\u2026", "num_citations": "9\n", "authors": ["1398"]}
{"title": "Accelerated modal abstractions of labelled transition systems\n", "abstract": " Modal Labelled Transition Systems (Modal-LTSs) can be used to specify system behaviour. They distinguish between required behaviour and allowed behaviour. This makes Modal-LTSs a suitable formalism to specify abstractions of a system by over- and under-approximations. This paper studies an extension to Modal-LTSs by allowing accelerated-transitions, i.e.\u00a0transitions labelled with regular expressions. This permits to represent that a process can reach a state by executing some sequence of actions, abstracting away the intermediate states. We show how accelerated transitions improve the expressiveness of abstractions. Consequently, more liveness properties can be checked.", "num_citations": "9\n", "authors": ["1398"]}
{"title": "Minimal-time synthesis for parametric timed automata\n", "abstract": " Parametric timed automata (PTA) extend timed automata by allowing parameters in clock constraints. Such a formalism is for instance useful when reasoning about unknown delays in a timed system. Using existing techniques, a user can synthesize the parameter constraints that allow the system to reach a specified goal location, regardless of how much time has passed for the internal clocks. We focus on synthesizing parameters such that not only the goal location is reached, but we also address the following questions: what is the minimal time to reach the goal location? and for which parameter values can we achieve this? We analyse the problem and present an algorithm that solves it. We also discuss and provide solutions for minimizing a specific parameter value to still reach the goal. We empirically study the performance of these algorithms on a benchmark set for PTAs and show that minimal-time reachability synthesis is more efficient to compute than the standard synthesis algorithm for reachability.", "num_citations": "8\n", "authors": ["1398"]}
{"title": "Distributed binary decision diagrams for symbolic reachability\n", "abstract": " Decision diagrams are used in symbolic verification to concisely represent state spaces. A crucial symbolic verification algorithm is reachability: systematically exploring all reachable system states. Although both parallel and distributed reachability algorithms exist, a combined solution is relatively unexplored. This paper contributes BDD-based reachability algorithms targeting compute clusters: high-performance networks of multi-core machines. The proposed algorithms may use the entire memory of every machine, allowing larger models to be processed while increasing performance by using all available computational power. To do this effectively, a distributed hash table, cluster-based work stealing algorithms, and several caching structures have been designed that all utilise the newest networking technology. The approach is evaluated extensively on a large collection of models, thereby demonstrating\u00a0\u2026", "num_citations": "8\n", "authors": ["1398"]}
{"title": "Multi-core and/or symbolic model checking\n", "abstract": " We review our progress in high-performance model checking. Our multi-core model checker is based on a scalable hash-table design and parallel random-walk traversal. Our symbolic model checker is based on Multiway Decision Diagrams and the saturation strategy. The LTSmin tool is based on the PINS architecture, decoupling model checking algorithms from the input specification language. Consequently, users can stay in their own specification language and postpone the choice between parallel or symbolic model checking. We support widely different specification languages including those of SPIN (Promela), mCRL2 and UPPAAL (timed automata). So far, multi-core and symbolic algorithms had very little in common, forcing the user in the end to make a wise trade-off between memory or speed. Recently, however, we designed a novel multi-core BDD package called Sylvan. This forms an excellent basis for scalable parallel symbolic model checking.", "num_citations": "8\n", "authors": ["1398"]}
{"title": "Towards Automatic Generation of Parameterized Test Cases from Abstractions\n", "abstract": " CWI is a founding member of ERCIM, the European Research Consortium for Informatics and Mathematics. CWI's research has a theme-oriented structure and is grouped into four clusters. Listed below are the names of the clusters and in parentheses their acronyms.", "num_citations": "8\n", "authors": ["1398"]}
{"title": "Binary decision diagrams by shared rewriting\n", "abstract": " In this paper we propose a uniform description of basic BDD theory and algorithms by means of term rewriting. Since a BDD is a DAG instead of a tree we need a notion of shared rewriting and develop appropriate theory. A rewriting system is presented by which canonical forms can be obtained. Various reduction strategies give rise to different algorithms. A layerwise strategy is proposed having the same time complexity as the traditional apply- algorithm, and the lazy strategy is studied, which resembles the existing up-one-algorithm. We show that these algorithms have incomparable performance.", "num_citations": "8\n", "authors": ["1398"]}
{"title": "Sound black-box checking in the LearnLib\n", "abstract": " In Black-Box Checking (BBC) incremental hypotheses of a system are learned in the form of finite automata. On these automata LTL formulae are verified, or their counterexamples validated on the actual system. We extend the LearnLib\u2019s system-under-learning API for sound BBC, by means of state equivalence, that contrasts the original proposal where an upper-bound on the number of states in the system is assumed. We will show how LearnLib\u2019s new BBC algorithms can be used in practice, as well as how one could experiment with different model checkers and BBC algorithms. Using the RERS 2017 challenge we provide experimental results on the performance of all LearnLib\u2019s active learning algorithms when applied in a BBC setting. The performance of learning algorithms was unknown for this setting. We will show that the novel incremental algorithms TTT, and ADT perform the best.", "num_citations": "7\n", "authors": ["1398"]}
{"title": "Detecting strongly connected components in large distributed state spaces\n", "abstract": " Detecting cycles in a state space is a key task in verification algortihms like LTL/CTL model checking and, less well known, reduction modulo branching bisimulation. This paper focuses on the problem of finding cycles (strongly connected components) in very large distributed state spaces. We present a collection of state space transformations meant as building blocks for custom algorithms. We also describe two example algorithms and show that they perform well on practical case studies", "num_citations": "7\n", "authors": ["1398"]}
{"title": "Equivalent semantic models for a distributed dataspace architecture\n", "abstract": " The general aim of our work is to support formal reasoning about components on top of the distributed dataspace architecture Splice. To investigate the basic properties of Splice and to support compositional verification, we have defined a denotational semantics for a basic Splice-like language. To increase the confidence in this semantics, also an operational semantics has been defined which is shown to be equivalent to the denotational one using the theorem prover PVS. A verification framework based on the denotational semantics is applied to an example of top-down development and transparent replication.", "num_citations": "7\n", "authors": ["1398"]}
{"title": "ECHO, the executable CHOndrocyte: A computational model to study articular chondrocytes in health and disease\n", "abstract": " Computational modeling can be used to investigate complex signaling networks in biology. However, most modeling tools are not suitable for molecular cell biologists with little background in mathematics. We have built a visual-based modeling tool for the investigation of dynamic networks. Here, we describe the development of computational models of cartilage development and osteoarthritis, in which a panel of relevant signaling pathways are integrated. In silico experiments give insight in the role of each of the pathway components and reveal which perturbations may deregulate the basal healthy state of cells and tissues.We used a previously developed computational modeling tool Analysis of Networks with Interactive Modeling (ANIMO) to generate an activity network integrating 7 signal transduction pathways resulting in a network containing over 50 nodes and 200 interactions. We performed in silico\u00a0\u2026", "num_citations": "6\n", "authors": ["1398"]}
{"title": "Sound black-box checking in the LearnLib\n", "abstract": " In black-box checking (BBC) incremental hypotheses on the behavior of a system are learned in the form of finite automata, using information from a given set of requirements, specified in Linear-time Temporal Logic (LTL). The LTL formulae are checked on intermediate automata and potential counterexamples are validated on the actual system. Spurious counterexamples are used by the learner to refine these automata. We improve BBC in two directions. First, we improve checking lasso-like counterexamples by assuming a check for state equivalence. This provides a sound method without knowing an upper-bound on the number of states in the system. Second, we propose to check the safety portion of an LTL property first, by deriving simple counterexamples using monitors. We extended LearnLib\u2019s system under learning API to make our methods accessible, using LTSmin as model checker under the\u00a0\u2026", "num_citations": "6\n", "authors": ["1398"]}
{"title": "Software architecture of modern model checkers\n", "abstract": " Automated formal verification using model checking is a mature field with many tools available. We summarize the recent trends in the design and architecture of model checking tools. An important design goal of modern model checkers is to support many input languages (front-end) and many verification strategies (back-end), and to allow arbitrary combinations of them. This widens the applicability of new verification algorithms, avoids duplicate implementation of the analysis techniques, improves quality of the tools, and eases use of verification for a newly introduced high-level specification, such as a domain specific language.", "num_citations": "6\n", "authors": ["1398"]}
{"title": "Automated verification of nested dfs\n", "abstract": " In this paper we demonstrate the automated verification of the Nested Depth-First Search (NDFS) algorithm for detecting accepting cycles. The starting point is a recursive formulation of the NDFS algorithm. We use Dafny to annotate the algorithm with invariants and a global specification. The global specification requires that NDFS indeed solves the accepting cycle problem. The invariants are proved automatically by the SMT solver Z3 underlying Dafny. The global specifications, however, need some inductive reasoning on paths in a graph. To prove these properties, some auxiliary lemmas had to be provided. The full specification is contained in this paper. It fits on 4 pages, is verified by Dafny in about 2 minutes, and was developed in a couple of weeks.", "num_citations": "6\n", "authors": ["1398"]}
{"title": "PDL over accelerated labeled transition systems\n", "abstract": " We present a thorough study of propositional dynamic logic over a variation of labeled transition systems, called accelerated labelled transition systems, which are transition systems labeled with regular expressions over action labels. We study the model checking and satisfiability decision problems. Through a notion of regular expression rewriting, we reduce these two problems to the corresponding ones of PDL in the traditional semantics (w.r.t. LTS). As for the complexity, both of problems are proved to be ExPSPACE-complete. Moreover, the program complexity of model checking problem turns out to be NLOGSPACE-complete. Furthermore, we provide an axiomatization for PDL which involves Kleene Algebra as an Oracle. The soundness and completeness are shown.", "num_citations": "6\n", "authors": ["1398"]}
{"title": "A BDD-representation for the logic of equality and uninterpreted functions\n", "abstract": " The logic of equality and uninterpreted functions (EUF) has been proposed for processor verification. This paper presents a new data structure called Binary Decision Diagrams for representing EUF formulas (EUF-BDDs). We define EUF-BDDs similar to BDDs, but we allow equalities between terms as labels instead of Boolean variables. We provide an approach to build a reduced ordered EUF-BDD (EUF-ROBDD) and prove that every path to a leaf is satisfiable by construction. Moreover, EUF-ROBDDs are logically equivalent representations of EUF-formulae, so they can also be used to represent state spaces in symbolic model checking with data.", "num_citations": "6\n", "authors": ["1398"]}
{"title": "Distribution of a simple shared dataspace architecture\n", "abstract": " We study a simple software architecture, in which components are coordinated by writing into and reading from a global set. This simple architecture is inspired by the industrial software architecture Splice. We present two results. First, a distributed implementation of the architecture is given and proved correct formally. In the implementation, local sets are maintained and data items are exchanged between these local sets. Next we show that the architecture is sufficiently expressive in principle. In particular, every global specification of a system's behaviour can be divided into components, which coordinate by read and write primitives on a global set only. We heavily rely on recent concepts and proof methods from process algebra.", "num_citations": "6\n", "authors": ["1398"]}
{"title": "Iterative bounded synthesis for efficient cycle detection in parametric timed automata\n", "abstract": " We study semi-algorithms to synthesise the constraints under which a Parametric Timed Automaton satisfies some liveness requirement. The algorithms traverse a possibly infinite parametric zone graph, searching for accepting cycles. We provide new search and pruning algorithms, leading to successful termination for many examples. We demonstrate the success and efficiency of these algorithms on a benchmark. We also illustrate parameter synthesis for the classical Bounded Retransmission Protocol. Finally, we introduce a new notion of completeness in the limit, to investigate if an algorithm enumerates all solutions.", "num_citations": "5\n", "authors": ["1398"]}
{"title": "Parameter synthesis algorithms for parametric interval Markov chains\n", "abstract": " This paper considers the consistency problem for Parametric Interval Markov Chains. In particular, we introduce a co-inductive definition of consistency, which improves and simplifies previous inductive definitions considerably. The equivalence of the inductive and co-inductive definitions has been formally proved in the interactive theorem prover PVS.               These definitions lead to forward and backward algorithms, respectively, for synthesizing an expression for all parameters for which a given PIMC is consistent. We give new complexity results when tackling the consistency problem for IMCs (i.e. without parameters). We provide a sharper upper bound, based on the longest simple path in the IMC. The algorithms are also optimized, using different techniques (dynamic programming cache, polyhedra representation, etc.). They are evaluated on a prototype implementation. For parameter synthesis, we\u00a0\u2026", "num_citations": "5\n", "authors": ["1398"]}
{"title": "A calculus for four-valued sequential logic\n", "abstract": " We present a complete axiomatisation for four-valued sequential logic. It consists of nine axioms, from which all valid laws can be derived by equational reasoning. These nine axioms are independent of each other.", "num_citations": "5\n", "authors": ["1398"]}
{"title": "Expressiveness of basic SPLICE\n", "abstract": " We study a simple software architecture, in which application processes are coordinated by writing into and reading from a global set. This architecture underlies Splice, which is developed and used at the company Hollandse Signaalapparaten. Our approach is distinguished by viewing the architecture as a component itself, described formally by means of process algebra.Two results are proved. First a distributed implementation of the architecture is given, in which each component maintains a local set and data items are exchanged between these local sets. The implementation is proved to be behaviourally equivalent to the conceptual view of having one global set. Next we show that every requirements speci cation expressible as a nite process has a distributed implementation on this architecture.", "num_citations": "5\n", "authors": ["1398"]}
{"title": "Modular formal specification of data and behaviour\n", "abstract": " We propose a modular approach to the formal specification of the requirements on embedded systems. In this approach, requirements on data axe specified as invariants on states. Requirements on behaviour are specified assertionally by temporal logic formulae, restricting the runs of the system. The proposed method is modular, because components can be specified and analysed in isolation, and the views of several components can be combined in an easy way. Requirements can be combined by simply putting them in conjunction. A mathematical framework supporting this approach is developed and implemented in the theorem prover PVS. The method is illustrated by formalising the requirements of a miniature embedded system. This specification is then analysed using the theorem prover, revealing some errors in the original specification.", "num_citations": "5\n", "authors": ["1398"]}
{"title": "A calculus for sequential logic with 4 values\n", "abstract": " This note presents a complete axiomatisation for four-valued sequential logic.Sequential'means that arguments are evaluated from left to right, until an answer can be obtained. Three-valued sequential logic is due to McCarthy 6]. In 1] four truth-values are introduced: true, false, mistake and divergent. Several four-valued logics arise by restricting the set of connectives. In the nomenclature of 1], four-valued sequential logic is characterized as 4 (:^ \u043e _\u043e). An axiomatisation of this system has not been given before. In 2] it is examined whether four-valued sequential logic can serve as a basis for data type specifications. That application motivates and justifies the metamathematical study of four-valued logics. Our complete axiomatisation can also be viewed as an!-complete data type specification (see 4]). We refer to 1] for an introduction to three-and four-valued logic and also for further references. In 3] a complete axiomatisation is given for McCarthy's system. Completeness is obtained by characterizing all algebras satisfying the axioms. The completeness proof for the axiomatisation of the four-valued system that we give is quite different. Our proof yields a systematic method to prove each valid formula from the axioms.", "num_citations": "5\n", "authors": ["1398"]}
{"title": "A Bounded Retransmission Protocol for Large Data Packets: A Case Study in Computer Checked Algebraic Verification\n", "abstract": " This note describes a protocol for the transmission of data packets that are too large to be transferred in their entirety. Therefore, the protocol splits the data packets and broadcasts it in parts. It is assumed that in case of failure of transmission through data channels, only a limited number of retries are allowed (bounded retransmission). If repeated failure occurs, the protocol stops trying and the sending and receiving protocol users are informed accordingly. The protocol and its external behaviour are specified in \u03bcCRL. The correspondence between these is shown using the axioms of \u03bcCRL. The whole proof of this correspondence has been computer checked using the proof checker Coq. This provides an example showing that proof checking of realistic protocols is feasible within the setting of process algebras.", "num_citations": "5\n", "authors": ["1398"]}
{"title": "Synchronous or Alternating?\n", "abstract": " Mealy machines transduce inputs to outputs, based on finite memory. They are often used to model reactive systems. The requirements on their behaviour can be specified by formulas in Linear-time Temporal Logic. We will study two interpretations of LTL for Mealy machines: the synchronous semantics, where inputs and outputs occur simultaneously; and the alternating semantics, where inputs and outputs strictly alternate. We define and study Mealy-robust LTL properties, which are insensitive to which of these interpretations is chosen.                 The motivating application is in the context of black-box checking: Given the interface to some reactive system, one would like to test that a particular LTL property holds. To this end, we combine active automata learning with model checking into sound black-box checking. Here the LTL properties are already checked on intermediate hypotheses, in order to\u00a0\u2026", "num_citations": "4\n", "authors": ["1398"]}
{"title": "Multi-core On-The-Fly Saturation.\n", "abstract": " Saturation is an efficient exploration order for computing the set of reachable states symbolically. Attempts to parallelize saturation have so far resulted in limited speedup. We demonstrate for the first time that on-the-fly symbolic saturation can be successfully parallelized at a large scale. To this end, we implemented saturation in Sylvan\u2019s multicore decision diagrams used by the LTSmin model checker. We report extensive experiments, measuring the speedup of parallel symbolic saturation on a 48-core machine, and compare it with the speedup of parallel symbolic BFS and chaining. We find that the parallel scalability varies from quite modest to excellent. We also compared the speedup of on-the-fly saturation and saturation for pre-learned transition relations. Finally, we compared our implementation of saturation with the existing sequential implementation based on Meddly. The empirical evaluation uses Petri nets from the model checking contest, but thanks to the architecture of LTSmin, parallel on-the-fly saturation is now available to multiple specification languages. Data or code related to this paper is available at:[34].", "num_citations": "4\n", "authors": ["1398"]}
{"title": "Model checking and evaluating QoS of batteries in MPSoC dataflow applications via hybrid automata (extended version)\n", "abstract": " System lifetime is always a major design impediment for battery-powered mobile embedded systems such as, cell phones and satellites. The increasing gap between energy demand of portable devices and their battery capacities is further limiting durability of mobile devices. For example, energy-hungry applications like video streaming pose serious limitations on the system lifetime. Thus, guarantees over Quality of Service (QoS) of battery constrained devices under strict battery capacities is a primary interest for mobile embedded systems\u2019 manufacturers and other stakeholders.This paper presents a novel approach for deriving QoS, for applications modelled as synchronous dataflow (SDF) graphs. These applications are mapped on heterogeneous multiprocessor platforms that are partitioned into Voltage and Frequency Islands, together with multiple kinetic battery models (KiBaMs). By modelling whole system as hybrid automata, and applying model-checking, we evaluate QoS in terms of,(1) achievable application performance within the given batteries\u2019 capacities; and (2) minimum required batteries\u2019 capacities to achieve desired application performance. We demonstrate that our approach shows a significant improvement in terms of scalability, as compared to priced timed automata based KiBaM model [15]. This approach also allows early detection of design errors via model checking.", "num_citations": "4\n", "authors": ["1398"]}
{"title": "Mathematical modeling of signaling pathways in osteoarthritis\n", "abstract": " Purpose: Cartilage homeostasis relies on an intricate balance between anabolic and catabolic processes. In osteoarthritis this balance is shifted towards catabolism, leading to hypertrophy and a gradual degradation of cartilage tissue. So far, drug-based intervention in this process has shown limited progress. We propose to construct a mathematical model of the molecular network that governs key processes in articular cartilage homeostasis. This model can be used as a platform for model expansion by introduction of new experimental findings and hypotheses.Methods: We recently developed ANIMO (Analysis of Networks with Interactive Modeling), an intuitive software tool for modeling molecular networks. Here, we demonstrate a mathematical model of growth plate cartilage using a combination of literature and experimental data. We show how ANIMO allows for intuitive exploration of the model, despite the size and complexity of the model. Results: We constructed a network model of regulatory processes in growth plate chondrocytes. In this model the effects downstream of extracellular growth factors FGF, WNT, IGF-1, PTHrP, Ihh, BMP, and TGF-b are integrated into a cellular response (Figure 1). In silico experiments predict the phenotypic outcome for different inputs and starting states of the model.", "num_citations": "4\n", "authors": ["1398"]}
{"title": "Applying model-based testing to html rendering engines\u2013a case study\n", "abstract": " Conformance testing is a widely used approach to validate a system correct w.r.t. its specification. This approach is mainly used for behavior-oriented systems. BAiT (Behavior Adaptation in Testing) is a conformance testing approach for data-intensive reactive systems. In this paper, we validate the applicability of BAiT to systems, which are not behavior-oriented (reactive) but document-centered.               In particular, we apply BAiT to the test of the HTML rendering engine Gecko, which is used by Mozilla Firefox. In order to do so, we formally specify a part of the CSS box model in the specification language \u03bcCRL and implement a wrapper for the Gecko renderer. Then, we automatically generate test cases and run tests with BAiT in a controlled experiment in order to demonstrate our approach on the relevant part of Gecko.", "num_citations": "4\n", "authors": ["1398"]}
{"title": "An algorithm to verify formulas by means of (0, s,=)-BDDs\n", "abstract": " In this article we provide an algorithm to verify formulas of the fragment of first order logic, consisting of quantifier free logic with zero, successor and equality. We first develop a rewrite system to extract an equivalent Ordered (0, S,=)-BDD from any given (0, S,=)-BDD. Then we show completeness of the rewrite system. Finally we make an algorithm with the same result as the rewrite system. Given an Ordered (0, S,=)-BDDs we are able to see in constant time whether the formula is a tautology, a contradiction, or only satisfiable.", "num_citations": "4\n", "authors": ["1398"]}
{"title": "Two different strong normalization proofs?\n", "abstract": " A proof of \u2200t\u2203nSN(t, n) (term t performs at most n reduction steps) is given, based on strong computability predicates. Using modified realizability, a bound on reduction lengths is extracted from it. This upper bound is compared with the one Gandy defines, using strictly monotonic functionals. This reveals a remarkable connection between his proof and Tait's. We show the details for simply typed \u03bb-calculus and G\u00f6del's T. For the latter system, program extraction yields considerably sharper upper bounds.", "num_citations": "4\n", "authors": ["1398"]}
{"title": "Automated verification of parallel nested DFS\n", "abstract": " Model checking algorithms are typically complex graph algorithms, whose correctness is crucial for the usability of a model checker. However, establishing the correctness of such algorithms can be challenging and is often done manually. Mechanising the verification process is crucially important, because model checking algorithms are often parallelised for efficiency reasons, which makes them even more error-prone. This paper shows how the VerCors concurrency verifier is used to mechanically verify the parallel nested depth-first search (NDFS) graph algorithm of Laarman et al.[25]. We also demonstrate how having a mechanised proof supports the easy verification of various optimisations of parallel NDFS. As far as we are aware, this is the first automated deductive verification of a multi-core model checking algorithm.", "num_citations": "3\n", "authors": ["1398"]}
{"title": "Model checking with generalized Rabin and Fin-less automata\n", "abstract": " In the automata theoretic approach to explicit state LTL model checking, the synchronized product of the model and an automaton that represents the negated formula is checked for emptiness. In practice, a (transition-based generalized) B\u00fcchi automaton (TGBA) is used for this procedure. This paper investigates whether using a more general form of acceptance, namely a transition-based generalized Rabin automaton (TGRA), improves the model checking procedure. TGRAs can have significantly fewer states than TGBAs; however, the corresponding emptiness checking procedure is more involved. With recent advances in probabilistic model checking and LTL to TGRA translators, it is only natural to ask whether checking a TGRA directly is more advantageous in practice. We designed a multi-core TGRA checking algorithm and performed experiments on a subset of the models and formulas from the 2015\u00a0\u2026", "num_citations": "3\n", "authors": ["1398"]}
{"title": "Bandwidth and Wavefront Reduction for Static Variable Ordering in Symbolic Model Checking\n", "abstract": " We demonstrate the applicability of bandwidth and wavefront reduction algorithms to static variable ordering. In symbolic model checking event locality plays a major role in time and memory usage. For example, in Petri nets event locality can be captured by dependency matrices, where nonzero entries indicate whether a transition modifies a place. The quality of event locality has been expressed as a metric called (weighted) event span. The bandwidth of a matrix is a metric indicating the distance of nonzero elements to the diagonal. Wavefront is a metric indicating the degree of nonzeros on one end of the diagonal of the matrix. Bandwidth and wavefront are well studied metrics used in sparse matrix solvers. In this work we prove that span is limited by twice the bandwidth of a matrix. This observation makes bandwidth reduction algorithms useful for obtaining good variable orders. One major issue we address is that the reduction algorithms can only be applied on symmetric matrices, while the dependency matrices are asymmetric. We show that the Sloan algorithm executed on the total graph of the adjacency graph gives the best variable orders. Practically, we demonstrate that our work allows to call standard sparse matrix operations in Boost and ViennaCL, computing very good static variable orders in milliseconds. Future work is promising, because a whole new spectrum of more off-the-shelf algorithms, including metaheuristic ones, become available for variable ordering.", "num_citations": "3\n", "authors": ["1398"]}
{"title": "An echo in biology: Validating the executable chondrocyte\n", "abstract": " Purpose: Computational modeling of biological networks permits comprehensive analysis of cells and tissues to define molecular phenotypes and novel hypotheses. We recently presented ANIMO (Analysis of Networks with Interactive Modeling), an intuitive software tool for modeling molecular networks for use by biologists. We used ANIMO to generate a computational model of articular cartilage, ECHO.", "num_citations": "3\n", "authors": ["1398"]}
{"title": "Verification of distributed dataspace architectures\n", "abstract": " The space calculus is introduced as a language to model distributed dataspace systems, i.e. distributed applications that use a shared (but possibly distributed) dataspace to coordinate. The publish-subscribe and the global dataspace are particular instances of our model. We give the syntax and operational semantics of this language and provide tool support for functional and performance analysis of its expressions. Functional behaviour can be checked by an automatic translation to \u03bcCRL and the use of a model checker. Performance analysis can be done using an automatically generated distributed C prototype.", "num_citations": "3\n", "authors": ["1398"]}
{"title": "Two solutions to incorporate zero, successor and equality in binary decision diagrams\n", "abstract": " In this article we extend BDDs (binary decision diagrams) for plain propositional logic to the fragment of first order logic, consisting of quantifier free logic with equality, zero and successor. We insert equations with zero and successor in BDDs, and call these objects (0, S,=)-BDDs. We extend the notion of Ordered BDDs in the presence of equality, zero and successor.(0, S,=)-BDDs can be transformed to equivalent Ordered (0, S,=)-BDDs by applying a number of rewrite rules. All paths in these extended OBDDs are satisfiable. The major advantage of transforming a formula to an equivalent Ordered (0, S,=)-BDD is that on the latter it can be observed in constant time whether the formula is a tautology, a contradiction, or just satisfiable.", "num_citations": "3\n", "authors": ["1398"]}
{"title": "Two Different Strong Normalization Proofs?-computability versus functionals of finite type\n", "abstract": " A proof of 8t9nSN (t; n)(term t performs at most n reduction steps) is given, based on strong computability predicates. Using modified realizability, a bound on reduction lengths is extracted from it. This upper bound is compared with the one Gandy defines, using strictly monotonic functionals. This reveals a remarkable connection between his proof and Tait's. We show the details for simply typed-calculus and Godel's T. For the latter system, program extraction yields considerably sharper upper bounds. 1 Introduction The purpose of this paper is to compare two different methods to prove strong normalization. The first method uses the notion of strong computability predicates. This method is attributed to Tait [Tai67], who used convertibility predicates to prove a normal form theorem for various systems. Prawitz [Pra71] and Girard [Gir72] introduced stronger variants, to deal with permutative conversions (arising from natural deduction for first order predicate logic) and the impredic...", "num_citations": "3\n", "authors": ["1398"]}
{"title": "Concurrent chaining hash maps for software model checking\n", "abstract": " Stateful model checking creates numerous states which need to be stored and checked if already visited. One option for such storage is a hash map and this has been used in many model checkers. In particular, we are interested in the performance of concurrent hash maps for use in multi-core model checkers with a variable state vector size. Previous research claimed that open addressing was the best performing method for the parallel speedup of concurrent hash maps. However, here we demonstrate that chaining lends itself perfectly for use in a concurrent setting. We implemented 12 hash map variants, all aiming at multicore efficiency. 8 of our implementations support variable-length key-value pairs. We compare our implementations and 22 other hash maps by means of an extensive test suite. Of these 34 hash maps, we show the representative performance of 11 hash maps. Our implementations not only\u00a0\u2026", "num_citations": "2\n", "authors": ["1398"]}
{"title": "Explicit state model checking with generalized B\u00fcchi and Rabin automata\n", "abstract": " In the automata theoretic approach to explicit state LTL model checking, the synchronized product of the model and an automaton that represents the negated formula is checked for emptiness. In practice, a (transition-based generalized) B\u00fcchi automaton (TGBA) is used for this procedure.", "num_citations": "2\n", "authors": ["1398"]}
{"title": "A distributed hash table for shared memory\n", "abstract": " Distributed algorithms for graph searching require a high-performance CPU-efficient hash table that supports find-or-put. This operation either inserts data or indicates that it has already been added before. This paper focuses on the design and evaluation of such a hash table, targeting supercomputers. The latency of find-or-put is minimized by using one-sided RDMA operations. These operations are overlapped as much as possible to reduce waiting times for roundtrips. In contrast to existing work, we use linear probing and argue that this requires less roundtrips. The hash table is implemented in UPC. A peak-throughput of 114.9 million op/s is reached on an Infiniband cluster. With a load-factor of 0.9, find-or-put can be performed in $$4.5\\,\\upmu \\mathrm{s}$$ on average. The hash table performance remains very high, even under high loads.", "num_citations": "2\n", "authors": ["1398"]}
{"title": "Simulated time for host\u2010based testing with TTCN\u20103\n", "abstract": " Prior to testing embedded software in a target environment, it is usually tested in a host environment used for developing the software. When a system is tested in a host environment, its real\u2010time behaviour is affected by the use of simulators, emulation and monitoring. In this paper, the authors provide a semantics for host\u2010based testing with simulated time and propose a simulated\u2010time solution for distributed testing with TTCN\u20103, which is a standardized language for specifying and executing test suites. The paper also presents the application of testing with simulated time to two real\u2010life systems. Copyright \u00a9 2007 John Wiley & Sons, Ltd.", "num_citations": "2\n", "authors": ["1398"]}
{"title": "Semantic models of a timed distributed dataspace architecture\n", "abstract": " We investigate various formal aspects of a distributed dataspace architecture in which data storage is based on time stamps. An operational and a denotational semantics have been defined and the equivalence of these two formulations has been proved. Moreover, the denotational semantics is fully abstract with respect to the observation of produced data items. It is used as a basis for compositional reasoning about components, supported by the interactive theorem prover PVS. We use this framework for a small example where components make mutual assumptions about each other's output.", "num_citations": "2\n", "authors": ["1398"]}
{"title": "Solving satisfiability of ground term algebras using DPLL and unification\n", "abstract": " Abstract datatypes can be viewed as sorted ground term algebras. Unification can be used to solve conjunctions of equations. We give a new algorithm to extend this to the full quantifier free fragment, ie including formulas with disjunction and negation. The algorithm is based on unification (to deal with equality) and DPLL (to deal with propositional logic). In this paper we present our algorithm as an instance of a generalized DPLL algorithm. We prove soundness and completeness of the class of generalized DPLL algorithms, in particular for the algorithm for ground term algebras.", "num_citations": "2\n", "authors": ["1398"]}
{"title": "Verifying replication on a distributed shared data space with time stamps\n", "abstract": " We investigate transparent replication of components on top of the distributed data space architecture Splice. In Splice each component has its own local data space which can be kept small using keys, time stamps and selective overwriting. Since Splice applications are often safety-critical, we use two complementary formal tools to ensure correctness: the CRL tool set is used for a rapid investigation of alternatives by a limited verification with state space exploration techniques; next the most promising solutions are verified in general by means of the interactive theorem prover of PVS. With these formal techniques we showed that replication of transformation components can be achieved using sequence numbers. We also prove the correctness of a nicer, more transparent solution which requires a slight extension of the write primitive of Splice.", "num_citations": "2\n", "authors": ["1398"]}
{"title": "Requirements specification and analysis of command and control systems\n", "abstract": " This report presents a method for formally specifying and analyzing requirements speci cations of command and control systems. In this method, a speci cation consists of a number of speci cation blocks, each specifying a particular aspect of the system. The main blocks are:", "num_citations": "2\n", "authors": ["1398"]}
{"title": "Correct transformation of rewrite systems for implementation purposes\n", "abstract": " We propose the notion of a correct transformation of one rewrite system into another. If such a transformation is correct, then the normal forms of a term in the original rewrite system can be obtained by computing the normal forms of the interpretation of this term in the transformed rewrite system. We show for several transformations from the literature that they are correct, most notably for the notion of simulation from Kamperman and Walters.", "num_citations": "2\n", "authors": ["1398"]}
{"title": "Operational semantics of term rewriting with priorities\n", "abstract": " We study the semantics of term rewriting systems with rule priorities (PRS), as introduced in [1]. Three open problems posed in that paper are solved, by giving counter examples. Moreover, a class of executable PRSs is identified. A translation of PRSs into transition system specifications (TSS) is given. This translation introduces negative premises. We prove that the translation preserves the operational semantics.", "num_citations": "2\n", "authors": ["1398"]}
{"title": "Aligning observed and modelled behaviour by maximizing synchronous moves and using milestones\n", "abstract": " Given a process model and an event log, conformance checking aims to relate the two together, eg to detect discrepancies between them. For the synchronous product net of the process and a log trace, we can assign different costs to a synchronous move, and a move in the log or model. By computing a path through this (synchronous) product net, whilst minimizing the total cost, we create a so-called optimal alignment\u2014which is considered to be the primary target result for conformance checking. Traditional alignment-based approaches (1) have performance problems for larger logs and models, and (2) do not provide reliable diagnostics for non-conforming behaviour (eg bottleneck analysis is based on events that did not happen). This is the reason to explore an alternative approach that maximizes the use of observed events. We also introduce the notion of milestone activities, ie unskippable activities, and show\u00a0\u2026", "num_citations": "1\n", "authors": ["1398"]}
{"title": "Polymorphic types and effects with Boolean unification\n", "abstract": " We present a simple, practical, and expressive type and effect system based on Boolean constraints. The effect system extends the Hindley-Milner type system, supports parametric polymorphism, and preserves principal types modulo Boolean equivalence. We show how to support type inference by extending Algorithm W with Boolean unification based on the successive variable elimination algorithm.   We implement the type and effect system in the Flix programming language. We perform an in-depth evaluation on the impact of Boolean unification on type inference time and end-to-end compilation time. While the computational complexity of Boolean unification is NP-hard, the experimental results demonstrate that it works well in practice. We find that the impact on type inference time is on average a 1.4x slowdown and the overall impact on end-to-end compilation time is a 1.1x slowdown.", "num_citations": "1\n", "authors": ["1398"]}
{"title": "Certifying Emptiness of Timed B\u00fcchi Automata\n", "abstract": " Model checkers for timed automata are widely used to verify safety-critical, real-time systems. State-of-the-art tools achieve scalability by intricate abstractions. We aim at further increasing the trust in their verification results, in particular for checking liveness properties. To this end, we develop an approach for extracting certificates for the emptiness of timed B\u00fcchi automata from model checking runs. These certificates can be double checked by a certifier that we formally verify in Isabelle/HOL. We study liveness certificates in an abstract setting and show that our approach is sound and complete. To also demonstrate its feasibility, we extract certificates for several models checked by TChecker and Imitator, and validate them with our verified certifier.", "num_citations": "1\n", "authors": ["1398"]}
{"title": "On completeness of liveness synthesis for parametric timed automata\n", "abstract": " We discuss what kind of completeness guarantees can be provided by semi-algorithms for the synthesis of the set of parameters under which a parametric timed automata meets some liveness property.", "num_citations": "1\n", "authors": ["1398"]}
{"title": "Multi-core Decision Diagrams.\n", "abstract": " Decision diagrams are fundamental data structures that revolutionized fields such as model checking, automated reasoning and decision processes. As performance gains in the current era mostly come from parallel processing, an ongoing challenge is to develop data structures and algorithms for modern multi-core architectures. This chapter describes the parallelization of decision diagram operations as implemented in the parallel decision diagram package Sylvan, which allows sequential algorithms that use decision diagrams to exploit the power of multi-core machines.", "num_citations": "1\n", "authors": ["1398"]}
{"title": "Parallel algorithms for model checking\n", "abstract": " Model checking is an automated verification procedure, which checks that a model of a system satisfies certain properties. These properties are typically expressed in some temporal logic, like LTL and CTL. Algorithms for LTL model checking (linear time logic) are based on automata theory and graph algorithms, while algorithms for CTL (computation tree logic) are based on fixed-point computations and set operations.", "num_citations": "1\n", "authors": ["1398"]}
{"title": "Improving the Timed Automata approach to biological pathway dynamics\n", "abstract": " Biological systems such as regulatory or gene networks can be seen as a particular type of distributed systems, and for this reason they can be modeled within the Timed Automata paradigm, which was developed in the computer science context. However, tools designed to model distributed systems often require a computer science background, making their use less attractive for biologists. ANIMO (Analysis of Networks with Interactive MOdeling) was built with the aim to provide biologists with access to the powerful modeling formalism of Timed Automata in a user friendly way. Continuous dynamics is handled by discrete approximations.                 In this paper we introduce an improved modeling approach that allows us to considerably increase ANIMO\u2019s performances, opening the way for the analysis of bigger models. Moreover, this improvement makes the introduction of model checking in ANIMO a\u00a0\u2026", "num_citations": "1\n", "authors": ["1398"]}
{"title": "An ECHO in biology II: Insights in chondrocyte cell fate\n", "abstract": " Purpose: An intricate network of regulatory processes determines the chondrocyte cell fate during development and maintains tissue homeostasis. In the event of a disease such as OA, the regulatory network is critically compromised. To cure the disease, we need to restore the regulatory processes to their original state. However, because of the inherent complexity of regulatory networks, they cannot be efficiently analyzed and understood without computational assistance. To obtain insight into the function of such complex networks we developed a dynamic computational model of chondrocytes, the Executable CHOndrocyte or ECHO. In ECHO cell fates corresponding to osteoarthritis as well as healthy chondrocytes can be investigated. We used ECHO to predict potential targets for switching from an OA-like chondrocyte to a healthy articular chondrocyte.", "num_citations": "1\n", "authors": ["1398"]}
{"title": "ANIMO: a tool for modeling biological pathway dynamics\n", "abstract": " Introduction Computational methods are applied with increasing success to the analysis of complex biological systems. However, their adoption is sometimes made difficult by requiring prior knowledge about the foundations of such methods, which often come from a different branch of science. The software ANIMO (Analysis of Networks with Interactive MOdel ing,[1]) allows the tissue engineer to add dynamic behavior to tradi tional static models of signaling events. We use ANIMO to optimize cartilage tissue engineering. Materials and methods Starting from a signaling network as tradition ally represented in books, ANIMO allows biologists to take advantage of their expertise, enriching the symbolic description with quantitative parameters. The underlying computational model is based on the for malism of Timed Automata [2] and is automatically generated and analyzed by ANIMO. Implementation as a Cytoscape [3] plugin makes the interface intuitively usable: for example, an existing network topol ogy can be extended with few mouse clicks, adding new nodes and edges. The use of ANIMO does not require detailed knowledge of the underlying formalism of the model. Results Figure 1 shows the user interface of Cytoscape enriched by ANIMO: simulation runs are shown in form of graphs (on the right). The course of a simulation is mirrored in the network (left) thanks to a usermovable slider under the corresponding graph: different colors indicate different activity levels as shown in the Legend. The Timed Automata model is automatically produced by ANIMO from the net work defined in the Cytoscape interface, completely transparently to the user\u00a0\u2026", "num_citations": "1\n", "authors": ["1398"]}
{"title": "Model Checking Software: 17th International SPIN Workshop, Enschede, the Netherlands, September 27-29, 2010, Proceedings\n", "abstract": " Annotation. This book constitutes the refereed proceedings of the 17th InternationalSPIN workshop on Model Checking Software, SPIN 2010, held at theUniversity of Twente, in Enschede, The Netherlands, in September 2010. The 13 revised full papers presented together with 2 tool papers and 3invited talks were carefully reviewed and selected from 33 submissions. The papers are organized in topical sections on satisfiability modulotheories for model checking, model checking in context (simulation, testing, UML), implementation and performance of model checking, LTL and B chi automata, extensions to infinite-state systems, and concurrentsoftware.", "num_citations": "1\n", "authors": ["1398"]}
{"title": "Bug hunting with false negatives\n", "abstract": " Safe data abstractions are widely used for verification purposes. Positive verification results can be transferred from the abstract to the concrete system. When a property is violated in the abstract system, one still has to check whether a concrete violation scenario exists. However, even when the violation scenario is not reproducible in the concrete system (a false negative), it may still contain information on possible sources of bugs.             Here, we propose a bug hunting framework based on abstract violation scenarios. We first extract a violation pattern from one abstract violation scenario. The violation pattern represents multiple abstract violation scenarios, increasing the chance that a corresponding concrete violation exists. Then, we look for a concrete violation that corresponds to the violation pattern by using constraint solving techniques. Finally, we define the class of counterexamples that we can handle\u00a0\u2026", "num_citations": "1\n", "authors": ["1398"]}
{"title": "Formal Methods: Applications and Technology: 11th International Workshop on Formal Methods for Industrial Critical Systems, FMICS 2006, and 5th International Workshop on\u00a0\u2026\n", "abstract": " These are the joint? nal proceedings of the 11th International Workshop on Formal Methods for Industrial Critical Systems (FMICS 2006) and the? fth International Workshop on Parallel and Distributed Methods in Veri? cation (PDMC 2006). Both workshops were organized as satellite events of CONCUR 2006, the 17th International Conference on Concurrency Theory that was or-nized in Bonn, August 2006. The FMICS workshop continued successfully the aim of the FMICS working group\u2013to promote the use of formal methods for industrial applications, by supporting research in this area and its application in industry. The emphasis in these workshops is on the exchange of ideas between researchers and prac-tioners, in both industry and academia. This year the Program Committee received a record number of submissions. The 16 accepted regular contributions and 2 accepted tool papers, selected out of a total of 47 submissions, cover formal methodologies for handling large state spaces, model-based testing, formal description and analysis techniques as well as a range of applications and case studies. The workshop program included two invited talks, by Anna Slobodova from Intel on \u201cChallenges for Formal Veri? cation in an Industrial Setting\u201d and by Edward A. Lee from the University of California at Berkeley on \u201cMaking C-currency Mainstream.\u201d The former full paper can be found in this volume.", "num_citations": "1\n", "authors": ["1398"]}
{"title": "Automatisierte erzeugung von ttcn-3 testf\u00e4llen aus uml-modellen\n", "abstract": " Der Test von Software ist ein notwendiges, jedoch ressourcenintensives Unterfangen. Aus diesem Grund wurden verschiedene Ans\u00e4tze entwickelt, die einzelnen Aspekte des Softwaretests zu automatisieren. In diesem Paper stellen wir einen Ansatz zur automatischen Testfallerzeugung f\u00fcr den modellbasierten Test vor. Dabei werden aus UML-Modellen eines Softwaresystems und der Beschreibung von Testszenarien parametrisierbare Testf\u00e4lle in TTCN-3 erzeugt. Die Parametrisierung erh\u00f6ht dabei die Wiederverwendbarkeit der Testf\u00e4lle, unterst\u00fctzt die gezielte Auswahl geeigneter Testdaten und wirkt so dem Ph\u00e4nomen der Testfallexplosion entgegen.", "num_citations": "1\n", "authors": ["1398"]}
{"title": "Verifying a sliding window protocol in iCRL\n", "abstract": " We prove the correctness of a sliding window protocol with an arbitrary finite window size n and sequence numbers modulo In. We show that the sliding window protocol is branching bisimilar to a queue of capacity In. The proof is given entirely on the basis of an axiomatic theory, and was checked with the help of PVS.", "num_citations": "1\n", "authors": ["1398"]}
{"title": "CWI and INRIA join forces on safety-critical systems\n", "abstract": " CWI and INRIA join forces on safety-critical systems (2004) | www.narcis.nl KNAW KNAW Narcis Back to search results Eindhoven University of Technology Publication CWI and INRIA join forces on safety-critical systems (2004) Pagina-navigatie: Main Save publication Save as MODS Export to Mendeley Save as EndNote Export to RefWorks Title CWI and INRIA join forces on safety-critical systems Published in ERCIM News. ERCIM. ISSN 0926-4981. Author Fokkink, WJ; Garavel, H.; Pol, van de JC Publisher Design and Analysis of Systems; Research on miscellaneous topics in computing science, not included in one of the research schools Date issued 2004 Access Closed Access Language English Type Article Publisher ERCIM Publication https://research.tue.nl/nl/publications/cwi-and-inria-join-f... OpenURL Search this publication in (your) library Persistent Identifier urn:nbn:nl:ui:25-507d650e-b2d8-4dd5-94ab-\u2026", "num_citations": "1\n", "authors": ["1398"]}
{"title": "muCRL specification of Event Notification in JavaSpaces\n", "abstract": " muCRL specification of Event Notification in JavaSpaces (2002) | www.narcis.nl KNAW KNAW Narcis Back to search results CWI Publication muCRL specification of Event Notification in JavaSpaces (2002) Open access . Pagina-navigatie: Main Save publication Save as MODS Export to Mendeley Save as EndNote Export to RefWorks Title muCRL specification of Event Notification in JavaSpaces Author JC van de Pol (Jaco); MA Valero Espada (Miguel) Supporting host Specification and Analysis of Embedded Systems Date issued 2002-01-01 Access Open Access Language English Type Conference Paper Publisher Universidad de Zaragoza Publication https://ir.cwi.nl/pub/10638 Persistent Identifier urn:NBN:nl:ui:18-10638 Metadata XML Source CWI Go to Website Navigation: Home about narcis login Nederlands contact Anna van Saksenlaan 51 2593 HW Den Haag narcis@dans.knaw.nl More >>> Youtube \u2026", "num_citations": "1\n", "authors": ["1398"]}