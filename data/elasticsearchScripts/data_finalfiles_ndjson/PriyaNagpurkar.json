{"title": "Transactional memory system supporting unbroken suspended execution\n", "abstract": " Mechanisms are provided, in a data processing system having a processor and a transactional memory, for executing a transaction in the data processing system. These mechanisms execute a transaction comprising one or more instructions that modify at least a portion of the transactional memory. The transaction is suspended in response to a transaction suspend instruction being executed by the processor. A suspended block of code is executed in a non-transactional manner while the transaction is suspended. A determination is made as to whether an interrupt occurs while the transaction is suspended. In response to an interrupt occurring while the transaction is suspended, a transaction abort operation is delayed until after the transaction suspension is discontinued.", "num_citations": "122\n", "authors": ["1948"]}
{"title": "Slow and stale gradients can win the race: Error-runtime trade-offs in distributed SGD\n", "abstract": " Distributed Stochastic Gradient Descent (SGD) when run in a synchronous manner, suffers from delays in waiting for the slowest learners (stragglers). Asynchronous methods can alleviate stragglers, but cause gradient staleness that can adversely affect convergence. In this work we present the first theoretical characterization of the speed-up offered by asynchronous methods by analyzing the trade-off between the error in the trained model and the actual training runtime (wallclock time). The novelty in our work is that our runtime analysis considers random straggler delays, which helps us design and compare distributed SGD algorithms that strike a balance between stragglers and staleness. We also present a new convergence analysis of asynchronous SGD variants without bounded or exponential delay assumptions, and a novel learning rate schedule to compensate for gradient staleness.", "num_citations": "104\n", "authors": ["1948"]}
{"title": "Energy consumption and conservation in mobile peer-to-peer systems\n", "abstract": " Today's mobile devices are growing in number and computational resources. Devices capable of storing gigabytes of digital content are becoming ubiquitous, making them an ideal platform for peer-to-peer content delivery and sharing. However, the always on communication patterns of P2P networks is not a natural fit for energy-constrained mobile devices. In this paper, we perform a detailed study of energy consumption of a structured P2P overlay on a PDA device. Using actual energy measurements, we present energy consumption results for different type of operations in P2P overlays. Based on these observations, we implement an approach to improve energy conservation on P2P protocols and show some promising preliminary results.", "num_citations": "73\n", "authors": ["1948"]}
{"title": "On the benefits and pitfalls of extending a statically typed language JIT compiler for dynamic scripting languages\n", "abstract": " Whenever the need to compile a new dynamically typed language arises, an appealing option is to repurpose an existing statically typed language Just-In-Time (JIT) compiler (repurposed JIT compiler). Existing repurposed JIT compilers (RJIT compilers), however, have not yet delivered the hoped-for performance boosts. The performance of JVM languages, for instance, often lags behind standard interpreter implementations. Even more customized solutions that extend the internals of a JIT compiler for the target language compete poorly with those designed specifically for dynamically typed languages. Our own Fiorano JIT compiler is an example of this problem. As a state-of-the-art, RJIT compiler for Python, the Fiorano JIT compiler outperforms two other RJIT compilers (Unladen Swallow and Jython), but still shows a noticeable performance gap compared to PyPy, today's best performing Python JIT compiler. In\u00a0\u2026", "num_citations": "39\n", "authors": ["1948"]}
{"title": "Phase-aware remote profiling\n", "abstract": " Recent advances in networking and embedded device technology have made the vision of ubiquitous computing a reality; users can access the Internet's vast offerings anytime and anywhere. Moreover, battery-powered devices such as personal digital assistants and Web-enabled mobile phones have successfully emerged as new access points to the world's digital, infrastructure. This ubiquity offers a new opportunity for software developers: users can now participate in the software development, optimization, and evolution process while they use their software. Such participation requires effective techniques for gathering profile information from remote, resource-constrained devices. Further, these techniques must be unobtrusive and transparent to the user; profiles must be gathered using minimal computation, communication, and power. Toward this end, we present a flexible hardware-software scheme for\u00a0\u2026", "num_citations": "39\n", "authors": ["1948"]}
{"title": "Workload characterization of selected jee-based web 2.0 applications\n", "abstract": " Web 2.0 represents the evolution of the web from a source of information to a platform. Network advances have permitted users to migrate from desktop applications to so-called Rich Internet Applications (RIAs) characterized by thin clients, which are browser-based and store their state on managed servers. Other Web 2.0 technologies have enabled users to more easily participate, collaborate, and share in web-based communities. With the emergence of wikis, blogs, and social networking, users are no longer only consumers, they become contributors to the collective knowledge accessible on the web. In another Web 2.0 development, content aggregation is moving from portal-based technologies to more sophisticated so-called mashups where aggregation capabilities are greatly expanded. While Web 2.0 has generated a great deal of interest and discussion, there has not been much work on analyzing these\u00a0\u2026", "num_citations": "36\n", "authors": ["1948"]}
{"title": "Supporting exception handling for futures in java\n", "abstract": " A future is a simple and elegant construct that programmers can use to identify potentially asynchronous computation and to introduce parallelism into serial programs. In its recent 5.0 release, Java provides an interface-based implementation of futures that enables users to encapsulate potentially asynchronous computation and to define their own execution engines for futures. In prior work, we have proposed an alternative model, called directive-based lazy futures (DBLFutures), to support futures in Java, that simplifies Java programmer effort and improves performance and scalability of future-based applications. In the DBLFuture model, programmers use a new directive,\"@ future\", to specify potentially concurrent computations within a serial program. DBLFutures enable programmers to focus on the logic and correctness of a program in the serial version first, and then to introduce parallelism gradually and\u00a0\u2026", "num_citations": "33\n", "authors": ["1948"]}
{"title": "Efficient remote profiling for resource-constrained devices\n", "abstract": " The widespread use of ubiquitous, mobile, and continuously connected computing agents has inspired software developers to change the way they test, debug, and optimize software. Users now play an active role in the software evolution cycle by dynamically providing valuable feedback about the execution of a program to developers. Software developers can use this information to isolate bugs in, maintain, and improve the performance of a wide-range of diverse and complex embedded device applications. The collection of such feedback poses a major challenge to systems researchers since it must be performed without degrading a user's experience with, or consuming the severely restricted resources of the mobile device. At the same time, the resource constraints of embedded devices prohibit the use of extant software profiling solutions. To achieve efficient remote profiling of embedded devices, we couple\u00a0\u2026", "num_citations": "33\n", "authors": ["1948"]}
{"title": "Adding dynamically-typed language support to a statically-typed language compiler: performance evaluation, analysis, and tradeoffs\n", "abstract": " Applications written in dynamically typed scripting languages are increasingly popular for Web software development. Even on the server side, programmers are using dynamically typed scripting languages such as Ruby and Python to build complex applications quickly. As the number and complexity of dynamically typed scripting language applications grows, optimizing their performance is becoming important. Some of the best performing compilers and optimizers for dynamically typed scripting languages are developed entirely from scratch and target a specific language. This approach is not scalable, given the variety of dynamically typed scripting languages, and the effort involved in developing and maintaining separate infrastructures for each. In this paper, we evaluate the feasibility of adapting and extending an existing production-quality method-based Just-In-Time (JIT) compiler for a language with\u00a0\u2026", "num_citations": "27\n", "authors": ["1948"]}
{"title": "Accelerating business analytics applications\n", "abstract": " Business text analytics applications have seen rapid growth, driven by the mining of data for various decision making processes. Regular expression processing is an important component of these applications, consuming as much as 50% of their total execution time. While prior work on accelerating regular expression processing has focused on Network Intrusion Detection Systems, business analytics applications impose different requirements on regular expression processing efficiency. We present an analytical model of accelerators for regular expression processing, which includes memory bus-, I/O bus-, and network-attached accelerators with a focus on business analytics applications. Based on this model, we advocate the use of vector-style processing for regular expressions in business analytics applications, leveraging the SIMD hardware available in many modern processors. In addition, we show how\u00a0\u2026", "num_citations": "26\n", "authors": ["1948"]}
{"title": "Runahead execution vs. conventional data prefetching in the IBM POWER6 microprocessor\n", "abstract": " After many years of prefetching research, most commercially available systems support only two types of prefetching: software-directed prefetching and hardware-based prefetchers using simple sequential or stride-based prefetching algorithms. More sophisticated prefetching proposals, despite promises of improved performance, have not been adopted by industry. In this paper, we explore the efficacy of both hardware and software prefetching in the context of an IBM POWER6 commercial server. Using a variety of applications that have been compiled with an aggressively optimizing compiler to use software prefetching when appropriate, we perform the first study of a new runahead prefetching feature adopted by the POWER6 design, evaluating it in isolation and in conjunction with a conventional hardware-based sequential stream prefetcher and compiler-inserted software prefetching. We find that the POWER6\u00a0\u2026", "num_citations": "24\n", "authors": ["1948"]}
{"title": "The data-centricity of web 2.0 workloads and its impact on server performance\n", "abstract": " Advances in network performance and browser technologies, coupled with the ubiquity of internet access and proliferation of users, have lead to the emergence of a new class of Web applications, called Web 2.0. Web 2.0 technologies enable easy collaboration and sharing by allowing users to contribute, modify, and aggregate content using applications like Wikis, Blogs, Social Networking communities, and Mashups. Web 2.0 applications also make heavy use of Ajax, which allows asynchronous communication between client and server, to provide a richer user experience. In this paper, we analyze the effect of these new features on the infrastructure that hosts these workloads. In particular, we focus on the data-centricity, inherent in many Web 2.0 applications, and study its impact on the persistence layer in an application server context. Our experimental results reveal some important performance characteristics\u00a0\u2026", "num_citations": "24\n", "authors": ["1948"]}
{"title": "Language and virtual machine support for efficient fine-grained futures in java\n", "abstract": " In this work, we investigate the implementation of futures in Java J2SE v 5.0. Java 5.0 provides an interface-based implementation of futures that enables users to encapsulate potentially asynchronous computation and to define their own execution engines for futures. Although this methodology decouples thread scheduling from application logic, for applications with fine-grained parallelism, this model imposes an undue burden on the average users and introduces significant performance overhead. To address these issues, we investigate the use of lazy futures and offer an alternative implementation to the Java 5.0 approach. In particular, we present a directive-based programming model for using futures in Java that uses annotations in Java 5.0 (as opposed to interfaces) and a lazy future implementation to significantly simplify programmer effort. Our directive-based future system employs novel compilation and\u00a0\u2026", "num_citations": "24\n", "authors": ["1948"]}
{"title": "Visualization and analysis of phased behavior in Java programs\n", "abstract": " To enable analysis and visualization of phased behavior in Java programs and to facilitate optimization development, we have implemented a freely-available, phase analysis framework within JikesRVM. The framework couples existing techniques into a unifying set of tools for data collection, processing, and analysis of dynamic phased behavior in Java programs. The framework enables optimization developers to significantly reduce analysis time and target optimization (by-hand or automatic) to parts of the code that will recur with sufficient regularity. We use the framework to evaluate phased behavior in the SpecJVM benchmark suite.", "num_citations": "23\n", "authors": ["1948"]}
{"title": "Opvis: extensible, cross-platform operational visibility and analytics for cloud\n", "abstract": " Operational visibility is an important administrative capability and a critical factor in deciding the success or failure of a cloud service. It is becoming increasingly complex due to the need to (1) track both persistent and volatile system state across heterogeneous endpoints and (2) consider a broader range of data sources fueled by demand for sophisticated analytics. In this paper we present OpVis, a monitoring and analytics framework to provide operational visibility without the limitations of traditional fragmented monitoring solutions. We highlight OpVis' extensible data model, enabling custom data collection and analytics based on the cloud user's requirements, describe its monitoring and analytics capabilities, present performance measurements, and discuss our experiences while supporting operational visibility in our cloud.", "num_citations": "12\n", "authors": ["1948"]}
{"title": "Phase-based visualization and analysis of java programs\n", "abstract": " Extant Java Virtual Machines (JVMs) apply dynamic compiler optimizations adaptively, based on the partial execution of the program, with the goal of improving performance. Understanding and characterizing program behavior is of vital importance to such systems. Recent research, primarily in the area of computer architecture, has identified potential optimization opportunities in the repeating patterns in the time-varying behavior of programs. In view of this, we believe that by considering time-varying, i.e., phase, behavior in Java programs, adaptive JVMs can enable performance that exceeds current levels.To enable analysis and visualization of phase behavior in Java programs and to facilitate optimization development, we have implemented a freely available, offline, phase analysis framework within the IBM Jikes Research Virtual Machine (JikesRVM) for Java. The framework couples existing techniques into a\u00a0\u2026", "num_citations": "8\n", "authors": ["1948"]}
{"title": "A cloud-native monitoring and analytics framework\n", "abstract": " Operational visibility is an important administrative capability and is one of the critical factor in deciding the success or failure of a cloud service. Today, it is increasingly becoming more complex along many dimensions which include being able to track both persistent and volatile system state, as well as provide higher level services such as log analytics, software discovery, behavioral anomaly detection, drift analysis to name a few. In addition, the target endpoints to monitor are becoming increasingly varied in terms of their heterogeneity, cardinality, and lifecycles, while being hosted across different software stacks. In this paper, we present our unified monitoring and analytics pipeline to provide operational visibility, that overcomes the limitations of traditional monitoring solutions, as well as provides a uniform platform as opposed to configuring, installing and maintaining multiple siloed solutions. Our OpVis framework has been running in our production cloud for over two years, while providing a multitude of such operational visibility and analytics functionality uniformly across heterogeneous endpoints. To be able to adapt to the ever-changing cloud landscape, we highlight it\u2019s extensibility model that enables custom data collection and analytics based on the cloud user\u2019s requirements. We describe its monitoring and analytics capabilities, present performance measures, and discuss our experiences while supporting operational visibility for our cloud deployment.", "num_citations": "5\n", "authors": ["1948"]}
{"title": "Dualities in programming languages\n", "abstract": " A duality can be thought of as a pair of concepts and a mapping between their terminology, such that substituting the concept-specific terminology turns a statement about one concept into a statement about the other. For example, in 1979, Lauer and Needham pointed out the duality between message passing= shared-memory concurrency [6]. The similarities in a duality enable cross-domain idea reuse. But equally important are the imperfections of dualities, which often trigger original research. We claim that thinking about dualities inspires innovation in programming languages. It is also a convenient excuse to play with fancy LATEX multicolumn formatting.", "num_citations": "2\n", "authors": ["1948"]}
{"title": "Analysis, detection, and exploitation of phase behavior in Java programs\n", "abstract": " The Java programming language offers developers many productivity enhancing features, including high-level abstractions, extensive libraries, architecture-independent execution, and type safety. These features are enabled by an intelligent execution environment that, incrementally and dynamically, compiles and executes compact representations of Java programs encoded for a virtual machine. While this necessarily adds overhead, the ability to compile (and recompile) code at runtime also enables the execution environment to perform dynamic, performance-enhancing optimizations based on the runtime behavior of the executing program. There are three primary steps in developing effective adaptive optimizations for these systems:(1) Development of a thorough analysis, understanding, and characterization of the performance of Java programs;(2) Extracting accurate data from programs efficiently at runtime\u00a0\u2026", "num_citations": "2\n", "authors": ["1948"]}
{"title": "Runtime estimation for machine learning tasks\n", "abstract": " Techniques for estimating runtimes of one or more machine learning tasks are provided. For example, one or more embodiments described herein can regard a system that can comprise a memory that stores computer executable components. The system can also comprise a processor, operably coupled to the memory, and that can execute the computer executable components stored in the memory. The computer executable components can comprise an extraction component that can extract a parameter from a machine learning task. The parameter can define a performance characteristic of the machine learning task. Also, the computer executable components can comprise a model component that can generate a model based on the parameter. Further, the computer executable components can comprise an estimation component that can generate an estimated runtime of the machine learning task based on\u00a0\u2026", "num_citations": "1\n", "authors": ["1948"]}
{"title": "Actively controlled performance clothing\n", "abstract": " A method includes embedding clothing with at least one sensor and at least one control unit; a power unit powering on the at least one sensor and the at least one control unit; the at least one sensor monitoring a sensed condition; the at least one control unit conducting a heat prediction based on the sensed condition; and the at least one control unit controlling threads within the clothing based on the heat prediction to actively adjust properties of the clothing.", "num_citations": "1\n", "authors": ["1948"]}