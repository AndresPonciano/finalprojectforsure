{"title": "DNA computing on surfaces\n", "abstract": " DNA computing was proposed 1 as a means of solving a class of intractable computational problems in which the computing time can grow exponentially with problem size (the \u2018NP-complete\u2019or non-deterministic polynomial time complete problems). The principle of the technique has been demonstrated experimentally for a simple example of the hamiltonian path problem 2 (in this case, finding an airline flight path between several cities, such that each city is visited only once 3). DNA computational approaches to the solution of other problems have also been investigated 4, 5, 6, 7, 8, 9. One technique 10, 11, 12, 13 involves the immobilization and manipulation of combinatorial mixtures of DNA on a support. A set of DNA molecules encoding all candidate solutions to the computational problem of interest is synthesized and attached to the surface. Successive cycles of hybridization operations and exonuclease\u00a0\u2026", "num_citations": "733\n", "authors": ["1790"]}
{"title": "The complexity of stochastic games\n", "abstract": " We consider the complexity of stochastic games\u2014simple games of chance played by two players. We show that the problem of deciding which player has the greatest chance of winning the game is in the class NP \u2322 co-NP.", "num_citations": "604\n", "authors": ["1790"]}
{"title": "Algorithms for graph partitioning on the planted partition model\n", "abstract": " The NP\u2010hard graph bisection problem is to partition the nodes of an undirected graph into two equal\u2010sized groups so as to minimize the number of edges that cross the partition. The more general graph l\u2010partition problem is to partition the nodes of an undirected graph into l equal\u2010sized groups so as to minimize the total number of edges that cross between groups. We present a simple, linear\u2010time algorithm for the graph l\u2010partition problem and we analyze it on a random \u201cplanted l\u2010partition\u201d model. In this model, the n nodes of a graph are partitioned into l groups, each of size n/l; two nodes in the same group are connected by an edge with some probability p, and two nodes in different groups are connected by an edge with some probability r<p. We show that if p\u2212r\u2265n\u22121/2+\u03f5 for some constant \u03f5, then the algorithm finds the optimal partition with probability 1\u2212 exp(\u2212n\u0398(\u03b5)).\u2003\u00a9 2001 John Wiley & Sons, Inc.\u2003Random\u00a0\u2026", "num_citations": "489\n", "authors": ["1790"]}
{"title": "Demonstration of a word design strategy for DNA computing on surfaces\n", "abstract": " A strategy for DNA computing on surfaces using linked sets of \u2018DNA words\u2019 that are short oligonucleotides (16mers) is proposed. The 16mer words have the format 5\u2032-FFFFvvvvvvvvFFFF-3\u2032 in which 4\u20138 bits of data are stored in 8 variable (\u2018v\u2019) base locations, and the remaining fixed (\u2018F\u2019) base locations are used as a word label. Using a template and map strategy, a set of 108 8mers each of which possesses at least a 4 base mismatch with the complements to all the other members of the set (4bm complements) are identified for use as a variable base sequence set. In addition, sets of 4 and 12 word labels of the form ABCD....DCBA that are respectively 8bm and 6bm complements with each other are identified. The 16mers are chosen to have a G/C content of 50% in order to make the thermodynamic stability of the perfectly matched hybridized DNA duplexes similar; a simple pairwise additive method is used\u00a0\u2026", "num_citations": "352\n", "authors": ["1790"]}
{"title": "On the undecidability of probabilistic planning and infinite-horizon partially observable Markov decision problems\n", "abstract": " We investigate the computability of problems in probabilistic planning and partially observable infinite-horizon Markov decision processes. The undecidability of the string-existence problem for probabilistic finite automata is adapted to show that the following problem of plan existence in probabilistic planning is undecidable: given a probabilistic planning problem, determine whether there exists a plan with success probability exceeding a desirable threshold. Analogous policy-existence problems for partially observable infinite-horizon Markov decision processes under discounted and undiscounted total reward models, average-reward models, and state-avoidance models are all shown to be undecidable. The results apply to corresponding approximation problems as well.", "num_citations": "310\n", "authors": ["1790"]}
{"title": "RNA STRAND: the RNA secondary structure and statistical analysis database\n", "abstract": " The ability to access, search and analyse secondary structures of a large set of known RNA molecules is very important for deriving improved RNA energy models, for evaluating computational predictions of RNA secondary structures and for a better understanding of RNA folding. Currently there is no database that can easily provide these capabilities for almost all RNA molecules with known secondary structures. In this paper we describe RNA STRAND \u2013 the RNA secondary STRucture and statistical ANalysis Database, a curated database containing known secondary structures of any type and organism. Our new database provides a wide collection of known RNA secondary structures drawn from public databases, searchable and downloadable in a common format. Comprehensive statistical information on the secondary structures in our database is provided using the RNA Secondary Structure Analyser, a new\u00a0\u2026", "num_citations": "309\n", "authors": ["1790"]}
{"title": "On combinatorial DNA word design\n", "abstract": " We consider the problem of designing DNA codes, namely sets of equi-length words over the alphabet {A, C, G, T} that satisfy certain combinatorial constraints. This problem          is motivated by the task of reliably storing and retrieving information in synthetic DNA strands for use in DNA computing or as molecular bar codes in chemical libraries. The primary constraints that we          consider, defined with respect to a parameter d, are as follows: for every pair of words w, x in a code, there are at least d mismatches between w and x if w \u2260          x and also between the reverse of w and the Watson-Crick complement of x. Extending classical results from coding theory, we present several upper and lower bounds on the maximum size          of such DNA codes and give methods for constructing such codes. An additional constraint that is relevant to the design of DNA codes is that the free energies and enthalpies of the\u00a0\u2026", "num_citations": "302\n", "authors": ["1790"]}
{"title": "On the undecidability of probabilistic planning and related stochastic optimization problems\n", "abstract": " Automated planning, the problem of how an agent achieves a goal given a repertoire of actions, is one of the foundational and most widely studied problems in the AI literature. The original formulation of the problem makes strong assumptions regarding the agent's knowledge and control over the world, namely that its information is complete and correct, and that the results of its actions are deterministic and known. Recent research in planning under uncertainty has endeavored to relax these assumptions, providing formal and computation models wherein the agent has incomplete or noisy information about the world and has noisy sensors and effectors. This research has mainly taken one of two approaches: extend the classical planning paradigm to a semantics that admits uncertainty, or adopt another framework for approaching the problem, most commonly the Markov Decision Process (MDP) model. This\u00a0\u2026", "num_citations": "280\n", "authors": ["1790"]}
{"title": "HotKnots: heuristic prediction of RNA secondary structures including pseudoknots\n", "abstract": " We present HotKnots, a new heuristic algorithm for the prediction of RNA secondary structures including pseudoknots. Based on the simple idea of iteratively forming stable stems, our algorithm explores many alternative secondary structures, using a free energy minimization algorithm for pseudoknot free secondary structures to identify promising candidate stems. In an empirical evaluation of the algorithm with 43 sequences taken from the Pseudobase database and from the literature on pseudoknotted structures, we found that overall, in terms of the sensitivity and specificity of predictions, HotKnots outperforms the well-known Pseudoknots algorithm of Rivas and Eddy and the NUPACK algorithm of Dirks and Pierce, both based on dynamic programming approaches for limited classes of pseudoknotted structures. It also outperforms the heuristic Iterated Loop Matching algorithm of Ruan and colleagues, and in\u00a0\u2026", "num_citations": "277\n", "authors": ["1790"]}
{"title": "On Algorithms for Simple Stochastic Games.\n", "abstract": " We survey a number of algorithms for the simple stochastic game problem, which is to determine the winning probability of a type of stochastic process, where the transitions are partially controlled by two players. We show that four natural approaches to solving the problem are incorrect, and present two new algorithms for the problem. The first reduces the problem to that of finding a locally optimal solution to a (nonconvex) quadratic program with linear constraints. The second extends a technique of Shapley called the successive approximation technique, by using linear programming to maximize the improvement at each approximation step. Finally, we analyze a randomized variant of the Hoffman-Karp strategy improvement algorithm.", "num_citations": "223\n", "authors": ["1790"]}
{"title": "Secondary structure prediction of interacting RNA molecules\n", "abstract": " Computational tools for prediction of the secondary structure of two or more interacting nucleic acid molecules are useful for understanding mechanisms for ribozyme function, determining the affinity of an oligonucleotide primer to its target, and designing good antisense oligonucleotides, novel ribozymes, DNA code words, or nanostructures. Here, we introduce new algorithms for prediction of the minimum free energy pseudoknot-free secondary structure of two or more nucleic acid molecules, and for prediction of alternative low-energy (sub-optimal) secondary structures for two nucleic acid molecules. We provide a comprehensive analysis of our predictions against secondary structures of interacting RNA molecules drawn from the literature. Analysis of our tools on 17 sequences of up to 200 nucleotides that do not form pseudoknots shows that they have 79% accuracy, on average, for the minimum free energy\u00a0\u2026", "num_citations": "210\n", "authors": ["1790"]}
{"title": "Interpretable dimensionality reduction of single cell transcriptome data with deep generative models\n", "abstract": " Single-cell RNA-sequencing has great potential to discover cell types, identify cell states, trace development lineages, and reconstruct the spatial organization of cells. However, dimension reduction to interpret structure in single-cell sequencing data remains a challenge. Existing algorithms are either not able to uncover the clustering structures in the data or lose global information such as groups of clusters that are close to each other. We present a robust statistical model, scvis, to capture and visualize the low-dimensional structures in single-cell gene expression data. Simulation results demonstrate that low-dimensional representations learned by scvis preserve both the local and global neighbor structures in the data. In addition, scvis is robust to the number of data points and learns a probabilistic parametric mapping function to add new data points to an existing embedding. We then use scvis to analyze four\u00a0\u2026", "num_citations": "189\n", "authors": ["1790"]}
{"title": "Efficient parameter estimation for RNA secondary structure prediction\n", "abstract": " Motivation: Accurate prediction of RNA secondary structure from the base sequence is an unsolved computational challenge. The accuracy of predictions made by free energy minimization is limited by the quality of the energy parameters in the underlying free energy model. The most widely used model, the Turner99 model, has hundreds of parameters, and so a robust parameter estimation scheme should efficiently handle large data sets with thousands of structures. Moreover, the estimation scheme should also be trained using available experimental free energy data in addition to structural data.                    Results: In this work, we present constraint generation (CG), the first computational approach to RNA free energy parameter estimation that can be efficiently trained on large sets of structural as well as thermodynamic data. Our CG approach employs a novel iterative scheme, whereby the energy\u00a0\u2026", "num_citations": "182\n", "authors": ["1790"]}
{"title": "A new algorithm for RNA secondary structure design\n", "abstract": " The function of many RNAs depends crucially on their structure. Therefore, the design of RNA molecules with specific structural properties has many potential applications, e.g. in the context of investigating the function of biological RNAs, of creating new ribozymes, or of designing artificial RNA nanostructures. Here, we present a new algorithm for solving the following RNA secondary structure design problem: given a secondary structure, find an RNA sequence (if any) that is predicted to fold to that structure. Unlike the (pseudoknot-free) secondary structure prediction problem, this problem appears to be hard computationally. Our new algorithm, \u201cRNA Secondary Structure Designer (RNA-SSD)\u201d, is based on stochastic local search, a prominent general approach for solving hard combinatorial problems. A thorough empirical evaluation on computationally predicted structures of biological sequences and artificially\u00a0\u2026", "num_citations": "176\n", "authors": ["1790"]}
{"title": "RNAsoft: a suite of RNA secondary structure prediction and design software tools\n", "abstract": " DNA and RNA strands are employed in novel ways in the construction of nanostructures, as molecular tags in libraries of polymers and in therapeutics. New software tools for prediction and design of molecular structure will be needed in these applications. The RNAsoft suite of programs provides tools for predicting the secondary structure of a pair of DNA or RNA molecules, testing that combinatorial tag sets of DNA and RNA molecules have no unwanted secondary structure and designing RNA strands that fold to a given input secondary structure. The tools are based on standard thermodynamic models of RNA secondary structure formation. RNAsoft can be found online at http://www.RNAsoft.ca.", "num_citations": "163\n", "authors": ["1790"]}
{"title": "Designed DNA molecules: principles and applications of molecular nanotechnology\n", "abstract": " Long admired for its informational role in the cell, DNA is now emerging as an ideal molecule for molecular nanotechnology. Biologists and biochemists have discovered DNA sequences and structures with new functional properties, which are able to prevent the expression of harmful genes or detect macromolecules at low concentrations. Physical and computational scientists can design rigid DNA structures that serve as scaffolds for the organization of matter at the molecular scale, and can build simple DNA-computing devices, diagnostic machines and DNA motors. The integration of biological and engineering advances offers great potential for therapeutic and diagnostic applications, and for nanoscale electronic engineering.", "num_citations": "154\n", "authors": ["1790"]}
{"title": "Feature based classifiers for somatic mutation detection in tumour-normal paired sequencing data\n", "abstract": " Motivation: The study of cancer genomes now routinely involves using next-generation sequencing technology (NGS) to profile tumours for single nucleotide variant (SNV) somatic mutations. However, surprisingly few published bioinformatics methods exist for the specific purpose of identifying somatic mutations from NGS data and existing tools are often inaccurate, yielding intolerably high false prediction rates. As such, the computational problem of accurately inferring somatic mutations from paired tumour/normal NGS data remains an unsolved challenge.                    Results: We present the comparison of four standard supervised machine learning algorithms for the purpose of somatic SNV prediction in tumour/normal NGS experiments. To evaluate these approaches (random forest, Bayesian additive regression tree, support vector machine and logistic regression), we constructed 106 features\u00a0\u2026", "num_citations": "153\n", "authors": ["1790"]}
{"title": "DNA models and algorithms for NP-complete problems\n", "abstract": " A goal of research on DNA computing is to solve problems that are beyond the capabilities of the fastest silicon-based supercomputers. Adleman and Lipton present exhaustive search algorithms for 3Sat and 3-coloring, which can only be run on small instances and, hence, are not practical. In this paper, we show how improved algorithms can be developed for the 3-coloring and independent set problems. Our algorithms use only the DNA operations proposed by Adleman and Lipton, but combine them in more powerful ways and use polynomial preprocessing on a standard computer to tailor them to the specific instance to be solved. The main contribution of this paper is a more general model of DNA algorithms than that proposed by Lipton. We show that DNA computation for NP-complete problems can do more than just exhaustive search. Further research in this direction will help determine whether or not DNA\u00a0\u2026", "num_citations": "151\n", "authors": ["1790"]}
{"title": "Strand design for biomolecular computation\n", "abstract": " The design of DNA or RNA strands for DNA computations poses many new questions in algorithms and coding theory. DNA strand design also arises in use of molecular bar codes to manipulate and identify individual molecules in complex chemical libraries, and to attach molecules to DNA chips. We survey several formulations of the DNA strand design problem, along with results and open questions in this area.", "num_citations": "145\n", "authors": ["1790"]}
{"title": "On the complexity of space bounded interactive proofs\n", "abstract": " We prove two results on interactive proof systems with 2-way probabilistic finite state verifiers. The first is a lower bound on the power of such proof systems, if they are not required to halt with high probability on rejected inputs: we show that they can accept any recursively enumerable language. The second is an upper bound on the power of interactive proof systems that halt with high probability on all inputs: any language they accept is in ATIME (22 O (n)). Our results generalize to other space bounds. The proof techniques we develop have other interesting applications. The proof method for the lower bound also shows that the emptiness problem for 1-way probabilistic finite state machines is undecidable. In proving the upper bound, we obtain some results of independent interest on the rate of convergence of time-varying Markov chains and of non-Markov chains, called feedback chains, to their halting states.", "num_citations": "128\n", "authors": ["1790"]}
{"title": "Computational approaches for RNA energy parameter estimation\n", "abstract": " Methods for efficient and accurate prediction of RNA structure are increasingly valuable, given the current rapid advances in understanding the diverse functions of RNA molecules in the cell. To enhance the accuracy of secondary structure predictions, we developed and refined optimization techniques for the estimation of energy parameters. We build on two previous approaches to RNA free-energy parameter estimation: (1) the Constraint Generation (CG) method, which iteratively generates constraints that enforce known structures to have energies lower than other structures for the same molecule; and (2) the Boltzmann Likelihood (BL) method, which infers a set of RNA free-energy parameters that maximize the conditional likelihood of a set of reference RNA structures. Here, we extend these approaches in two main ways: We propose (1) a max-margin extension of CG, and (2) a novel linear Gaussian Bayesian\u00a0\u2026", "num_citations": "125\n", "authors": ["1790"]}
{"title": "Classifying RNA pseudoknotted structures\n", "abstract": " Computational prediction of the minimum free energy (mfe) secondary structure of an RNA molecule from its base sequence is valuable in understanding the structure and function of the molecule. Since the general problem of predicting pseudoknotted secondary structures is NP-hard, several algorithms have been proposed that find the mfe secondary structure from a restricted class of secondary structures. In this work, we order the algorithms by generality of the structure classes that they handle. We provide simple characterizations of the classes of structures handled by four algorithms, as well as linear time methods to test whether a given secondary structure is in three of these classes. We report on the percentage of biological structures from the PseudoBase and Gutell databases that are handled by these three algorithms.", "num_citations": "122\n", "authors": ["1790"]}
{"title": "Stochastic local search algorithms for DNA word design\n", "abstract": " We present results on the performance of a stochastic local search algorithm for the design of DNA codes, namely sets of equallength words over the nucleotides alphabet A,C,G, T that satisfy certain combinatorial constraints. Using empirical analysis of the algorithm, we gain insight on goodd esign principles. We report several cases in which our algorithm finds word sets that match or exceed the best previously known constructions.1", "num_citations": "119\n", "authors": ["1790"]}
{"title": "A surface-based approach to DNA computation\n", "abstract": " A scalable approach to DNA-based computations is described. Complex combinatorial mixtures of DNA molecules encoding all possible answers to a computational problem are synthesized and attached to the surface of a solid support. This set of molecules is queried in successive MARK (hybridization) and DESTROY (enzymatic digestion) operations. Determination of the sequence of the DNA molecules remaining on the surface after completion of these operations yields the answer to the computational problem. Experimental demonstrations of aspects of the strategy are presented.", "num_citations": "110\n", "authors": ["1790"]}
{"title": "Computational models of games.\n", "abstract": " Degree: Ph. D.DegreeYear: 1987Institute: University of WashingtonBecause games and game-like phenomena occur naturally in a computational setting, it is natural to formulate many problems in Computer Science in terms of games. In order to understand their complexity, various models of computation have been developed which reflect the game-like properties of such problems. These models include the alternating Turing machines of Chandra, Kozen, and Stockmeyer (CKS81), the games against nature of Papadimitriou (PAP83), the Arthur-Merlin games of Babai (BAB85), and the interactive proof systems of Goldwasser, Micali, and Rackoff (GMR85).", "num_citations": "108\n", "authors": ["1790"]}
{"title": "Parallel implementation of Bouvka's minimum spanning tree algorithm\n", "abstract": " We study parallel algorithms for the minimum spanning tree problem, based on the sequential algorithm of O. Boruvka (1926). The target architectures for our algorithm are asynchronous, distributed-memory machines. Analysis of our parallel algorithm on a simple model that is reminiscent of the LogP model, shows that in principle a speedup proportional to the number of processors can be achieved, but that communication costs can be significant. To reduce these costs, we develop a new randomized linear work pointer jumping scheme that performs better than previous linear work algorithms. We also consider empirically the effects of data imbalance on the running time. For the graphs used in our experiments, load balancing schemes result in little improvement in running times. Our implementations on sparse graphs with 64,000 vertices on Thinking Machine's CM-5 achieve a speedup factor of about 4 on 16\u00a0\u2026", "num_citations": "107\n", "authors": ["1790"]}
{"title": "Specifying and verifying a broadcast and a multicast snooping cache coherence protocol\n", "abstract": " We develop a specification methodology that documents and specifies a cache coherence protocol in eight tables: the states, events, actions, and transitions of the cache and memory controllers. We then use this methodology to specify a detailed, modern three-state broadcast snooping protocol with an unordered data network and an ordered address network that allows arbitrary skew. We also present a detailed specification of a new protocol called multicast snooping (Bilir et al., 1999) and, in doing so, we better illustrate the utility of the table-based specification methodology. Finally, we demonstrate a technique for verification of the multicast snooping protocol, through the sketch of a manual proof that the specification satisfies a sequentially consistent memory model.", "num_citations": "98\n", "authors": ["1790"]}
{"title": "Probabilistically checkable debate systems and approximation algorithms for PSPACE-hard functions\n", "abstract": " We initiate an investigation of probabilistically checkable debate systems(PCDS\u2019S), a natural generalization of the probabilistically checkable proof systems studied in [1, 2, 3, 8]. A PCDS for a language L consists of a probabilistic polynomial-time verifier V and a debate between player 1, who claims that the input z is in L, and player O, who claims that the input x is not in L. We show that there is a PCDS for L in which V flips O (log n) random coins and reads O (1) bits of the debate if and only if L is in PSPACE. This characterization of PSPACE is used to show that certain PSPACE-hard functions are as hard to approximate as they are to compute exactly. t University of Wisconsin, Computer Sciences Department, 1210 West Dayton Street, Madison, WI 57306 USA, condon@ cs. wise. edu. Supported in part by NSF grants CCR-9100886 and CCR-9257241. tAT&T Ben Laboratories, Room 2C473, 600 Mowt~ n Avenue\u00a0\u2026", "num_citations": "93\n", "authors": ["1790"]}
{"title": "Improved free energy parameters for RNA pseudoknotted secondary structure prediction\n", "abstract": " Accurate prediction of RNA pseudoknotted secondary structures from the base sequence is a challenging computational problem. Since prediction algorithms rely on thermodynamic energy models to identify low-energy structures, prediction accuracy relies in large part on the quality of free energy change parameters. In this work, we use our earlier constraint generation and Boltzmann likelihood parameter estimation methods to obtain new energy parameters for two energy models for secondary structures with pseudoknots, namely, the Dirks\u2013Pierce (DP) and the Cao\u2013Chen (CC) models. To train our parameters, and also to test their accuracy, we create a large data set of both pseudoknotted and pseudoknot-free secondary structures. In addition to structural data our training data set also includes thermodynamic data, for which experimentally determined free energy changes are available for sequences and their\u00a0\u2026", "num_citations": "90\n", "authors": ["1790"]}
{"title": "Lamport clocks: verifying a directory cache-coherence protocol\n", "abstract": " Modern shared-memory multiprocessors use complex memory system implementations that include a variety of non-trivial and interacting optimizations. More time is spent in verl $ ving the correctness of such implementations than in designing the system. In particular; large-scale Distributed Shared Memory (DSM) systems usually rely on a directory cache-coherence protocol to provide the illusion of a sequentially consistent shared address space. Verifying that such a distributed protocol satisfies sequential consistency is a dificult task. Current formal protocol verification techniques [18] complement simulation, but are somewhat nonintuitive to system designers and verl $ ers, and they do not scale well to practical systems.In this papes we examine a new reasoning technique that is precise and (we find) intuitive. Our technique is based on Lamport\u2019s logical clocks, which were originally used in distributed systems\u00a0\u2026", "num_citations": "89\n", "authors": ["1790"]}
{"title": "Systematic analysis of somatic mutations impacting gene expression in 12 tumour types\n", "abstract": " We present a novel hierarchical Bayes statistical model, xseq, to systematically quantify the impact of somatic mutations on expression profiles. We establish the theoretical framework and robust inference characteristics of the method using computational benchmarking. We then use xseq to analyse thousands of tumour data sets available through The Cancer Genome Atlas, to systematically quantify somatic mutations impacting expression profiles. We identify 30 novel cis-effect tumour suppressor gene candidates, enriched in loss-of-function mutations and biallelic inactivation. Analysis of trans-effects of mutations and copy number alterations with xseq identifies mutations in 150 genes impacting expression networks, with 89 novel predictions. We reveal two important novel characteristics of mutation impact on expression:(1) patients harbouring known driver mutations exhibit different downstream gene expression\u00a0\u2026", "num_citations": "83\n", "authors": ["1790"]}
{"title": "Random debaters and the hardness of approximating stochastic functions\n", "abstract": " A probabilistically checkable debate system (PCDS) for a language L consists of a probabilistic polynomial-time verifier V and a debate between Player 1, who claims that the input x is in L, and Player 0, who claims that the input x is not in L. It is known that there is a PCDS for L in which V flips O(log n) coins and reads O(1) bits of the debate if and only if L is in PSPACE [A. Condon, J. Feigenbaum, C. Lund, and P. Shor, Chicago J. Theoret. Comput. Sci., 1995, No. 4]. In this paper, we restrict attention to RPCDSs, which are PCDSs in which Player 0 follows a very simple strategy: On each turn, Player 0 chooses uniformly at random from the set of legal moves. We prove the following result.Theorem.  L has an RPCDS in which the verifier flips O(log n) coins and reads O(1) bits of the debate if and only if L is in PSPACE.This new characterization of PSPACE is used to show that certain stochastic PSPACE-hard functions\u00a0\u2026", "num_citations": "81\n", "authors": ["1790"]}
{"title": "Experiments with parallel graph coloring heuristics and applications of graph coloring\n", "abstract": " We introduce a new hybrid graph coloring algorithm, which combines a parallel version of Morgenstern'5 S-Impasse algorithm [26], with exhaustive search. Our goal is progress towards a coloring heuristic that works well without extensive tuning of algorithm parameters. We also contribute new test data arising in five different application domains, including register allocation and course scheduling. Hybrid was implemented on aConnection Machine CM-5, and tested on the application data as well as several types of randomly generated graphs. The results are compared with results of two simple sequential heuristics, the Saturation algorithm of Brelaz [5] and the Recursive Largest First (RLF) algorithm of Leighton [24]. as well as with previous work reported by Morgenstern [26] and Johnson et al.[17].", "num_citations": "81\n", "authors": ["1790"]}
{"title": "Thermodynamically based DNA strand design\n", "abstract": " We describe a new algorithm for design of strand sets, for use in DNA computations or universal microarrays. Our algorithm can design sets that satisfy any of several thermodynamic and combinatorial constraints, which aim to maximize desired hybridizations between strands and their complements, while minimizing undesired cross-hybridizations. To heuristically search for good strand sets, our algorithm uses a conflict-driven stochastic local search approach, which is known to be effective in solving comparable search problems. The PairFold program of Andronescu              et al             . [M. Andronescu, Z. C. Zhang and A. Condon (2005)              J. Mol. Biol             ., 345, 987\u20131001; M. Andronescu, R. Aguirre-Hernandez, A. Condon, and H. Hoos (2003)              Nucleic Acids Res             ., 31, 3416\u20133422.] is used to calculate the minimum free energy of hybridization between two mismatched strands. We\u00a0\u2026", "num_citations": "74\n", "authors": ["1790"]}
{"title": "Computational RNA secondary structure design: empirical complexity and improved methods\n", "abstract": " We investigate the empirical complexity of the RNA secondary structure design problem, that is, the scaling of the typical difficulty of the design task for various classes of RNA structures as the size of the target structure is increased. The purpose of this work is to understand better the factors that make RNA structures hard to design for existing, high-performance algorithms. Such understanding provides the basis for improving the performance of one of the best algorithms for this problem, RNA-SSD, and for characterising its limitations. To gain insights into the practical complexity of the problem, we present a scaling analysis on random and biologically motivated structures using an improved version of the RNA-SSD algorithm, and also the RNAinverse algorithm from the Vienna package. Since primary structure constraints are relevant for designing RNA structures, we also investigate the correlation between the number and the location of the primary structure constraints when designing structures and the performance of the RNA-SSD algorithm. The scaling analysis on random and biologically motivated structures supports the hypothesis that the running time of both algorithms scales polynomially with the size of the structure. We also found that the algorithms are in general faster when constraints are placed only on paired bases in the structure. Furthermore, we prove that, according to the standard thermodynamic model, for some structures that the RNA-SSD algorithm was unable to design, there exists no sequence whose minimum free energy structure is the target structure. Our analysis helps to better understand the strengths and limitations\u00a0\u2026", "num_citations": "65\n", "authors": ["1790"]}
{"title": "Algorithms for graph partitioning on the planted partition model\n", "abstract": " The NP-hard graph bisection problem is to partition the nodes of an undirected graph into two equal-sized groups so as to minimize the number of edges that cross the partition. The more general graph\u00a0l-partition problem is to partition the nodes of an undirected graph into\u00a0l equal-sized groups so as to minimize the total number of edges that cross between groups.               We present a simple, linear-time algorithm for the graph\u00a0l-partition problem and analyze it on a random \u201cplanted\u00a0l-partition\u201d model. In this model, the\u00a0n nodes of a graph are partitioned into\u00a0l groups, each of size n/l; two nodes in the same group are connected by an edge with some probability\u00a0p, and two nodes in different groups are connected by an edge with some probability r < p. We show that if p \u2013 r > n                         \u2009\u2212\u2009\u2212\u20091/2\u2009+\u2009\u03b5 for some constant \u03b5, then the algorithm finds the optimal partition with probability .", "num_citations": "63\n", "authors": ["1790"]}
{"title": "DNA word design strategy for creating sets of non-interacting oligonucleotides for DNA microarrays\n", "abstract": " A template\u2212map design strategy for generating sets of non-interacting DNA oligonucleotides for applications in DNA arrays and biosensors is demonstrated. This strategy is used to create a set of oligonucleotides of size s with length l that possess at least n base mismatches with the complements of all the other members in the set. These \u201cDNA word\u201d sets are denoted as nbm l-mers or l:n sets. To regularize the thermodynamic stability of the perfectly matched hybridized DNA duplexes, the l-mers chosen for all the sets are required to have an approximately 50% G/C content. To achieve good discrimination between each DNA word in each set generated using the template\u2212map strategy, it is required that n should be approximately equal to l/2 or higher. The template\u2212map strategy can be used in a straightforward manner to create DNA word sets for cases when l = 4k and n = 2k, where k is an integer. Specific\u00a0\u2026", "num_citations": "62\n", "authors": ["1790"]}
{"title": "A surface-based approach to DNA computation\n", "abstract": " A new model of DNA-based computation is presented. The main difference between this model and that of Adleman is in manipulation of DNA strands that are first immobilized on a surface. This approach greatly reduces losses of DNA molecules during purification steps. A simple. surface-based model of computation is described and it is shown how to implement an exhaustive search algorithm for the SAT problem on this model. Partial experimental progress in solving a 5-variable SAT instance is described. and possible extensions of our model that allow general computations are discussed.1. lntroductionAdleman [1] and subsequently Lipton [6] described how genetic engineering tools can be used to solve instances of NP-complete combinatorial problems. Their work has led to hopes of a DNA computer that can outperform the fastest realizable super computers at such problems. Other suggested applications include massive associative memory [3] and problems in combinatorial chemistry, such as drug design [2],", "num_citations": "62\n", "authors": ["1790"]}
{"title": "Two-sided matching with partial information\n", "abstract": " The traditional model of two-sided matching assumes that all agents fully know their own preferences. As markets grow large, however, it becomes impractical for agents to precisely assess their rankings over all agents on the other side of the market. We propose a novel model of two-sided matching in which agents are endowed with known partially ordered preferences and unknown true preferences drawn from known distributions consistent with the partial order. The true preferences are learned through interviews, revealing the pairwise rankings among all interviewed agents, performed according to a centralized interview policy, ie, an algorithm that adaptively schedules interviews. Our goal is for the policy to guarantee both stability and optimality for a given side of the market, with respect to the underlying true preferences of the agents. As interviews are costly, we seek a policy that minimizes the number of\u00a0\u2026", "num_citations": "61\n", "authors": ["1790"]}
{"title": "PSPACE is provable by two provers in one round\n", "abstract": " We describe a general methodology for parallelizing unbounded round interactive proof systems to obtain 1-round, 2-prover interactive proof systems. We show that this methodology yields a 1-round, 2-prover interactive proof system for any language in PSPACE. Our interactive proof systems have exponentially small error probability.", "num_citations": "60\n", "authors": ["1790"]}
{"title": "On the complexity of the policy improvement algorithm for Markov decision processes\n", "abstract": " We consider the complexity of the policy improvement algorithm for Markov decision processes. We show that four variants of the algorithm require exponential time in the worst case. INFORMS Journal on Computing, ISSN 1091-9856, was published as ORSA Journal on Computing from 1989 to 1995 under ISSN 0899-1499.", "num_citations": "55\n", "authors": ["1790"]}
{"title": "Multiple word DNA computing on surfaces\n", "abstract": " The enzymatic manipulation of DNA molecules immobilized on a surface that each contain linked, multiple \u201cDNA words\u201d is demonstrated, with applications to DNA computing. A new DESTROY operation to selectively remove unmarked DNA strands from surfaces, consisting of polymerase extension followed by restriction enzyme cleavage, has been developed for multiple-word DNA computing. DNA polymerase is used to extend DNA primers hybridized to DNA strands that are covalently attached to a chemically modified gold thin film. The efficiency of this surface polymerase extension reaction is >90%, as determined by removal of the extended DNA molecules from the surface followed by gel electrophoretic analysis. Complete extension of the DNA strands creates a Dpn II restriction enzyme site in the duplex DNA; these molecules may then be cleaved from the surface by addition of Dpn II, with an efficiency\u00a0\u2026", "num_citations": "50\n", "authors": ["1790"]}
{"title": "The determination of RNA folding nearest neighbor parameters\n", "abstract": " The stability of RNA secondary structure can be predicted using a set of nearest neighbor parameters. These parameters are widely used by algorithms that predict secondary structure. This contribution introduces the UV optical melting experiments that are used to determine the folding stability of short RNA strands. It explains how the nearest neighbor parameters are chosen and how the values are fit to the data. A sample nearest neighbor calculation is provided. The contribution concludes with new methods that use the database of sequences with known structures to determine parameter values.", "num_citations": "48\n", "authors": ["1790"]}
{"title": "Using lamport clocks to reason about relaxed memory models\n", "abstract": " Cache coherence protocols of current shared-memory multiprocessors are difficult to verify. Our previous work proposed an extension of Lamport's logical clocks for showing that multiprocessors can implement sequential consistency (SC) with an SGI Origin 2000-like directory protocol and a Sun Gigaplane-like split-transaction bus protocol. Many commercial multiprocessors, however, implement more relaxed models, such as SPARC Total Store Order (TSO), a variant of processor consistency, and Compaq (DEC) Alpha, a variant of weak consistency. This paper applies Lamport clocks to both a TSO and an Alpha implementation. Both implementations are based on the same Sun Gigaplane-like split-transaction bus protocol we previously used, but the TSO implementation places a first-in-first-out write buffer between a processor and its cache, while the Alpha implementation uses a coalescing write buffer. Both\u00a0\u2026", "num_citations": "48\n", "authors": ["1790"]}
{"title": "The complexity of the max word problem and the power of one-way interactive proof systems\n", "abstract": " We study the complexity of the max word problem for matrices, a variation of the well-known word problem for matrices. We show that the problem is NP-complete, and cannot be approximated within any constant factor, unless P=NP. We describe applications of this result to probabilistic finite state automata, rational series andk-regular sequences. Our proof is novel in that it employs the theory of interactive proof systems, rather than a standard reduction argument. As another consequence of our results, we characterize NP exactly in terms ofone-way interactive proof systems.", "num_citations": "47\n", "authors": ["1790"]}
{"title": "An O (n 5) algorithm for MFE prediction of kissing hairpins and 4-chains in nucleic acids\n", "abstract": " Efficient methods for prediction of minimum free energy (MFE) nucleic secondary structures are widely used, both to better understand structure and function of biological RNAs and to design novel nano-structures. Here, we present a new algorithm for MFE secondary structure prediction, which significantly expands the class of structures that can be handled in O(n5) time. Our algorithm can handle H-type pseudoknotted structures, kissing hairpins, and chains of four overlapping stems, as well as nested substructures of these types.", "num_citations": "46\n", "authors": ["1790"]}
{"title": "A thermodynamic approach to designing structure-free combinatorial DNA word sets\n", "abstract": " An algorithm is presented for the generation of sets of non-interacting DNA sequences, employing existing thermodynamic models for the prediction of duplex stabilities and secondary structures. A DNA \u2018word\u2019 structure is employed in which individual DNA \u2018words\u2019 of a given length (e.g. 12mer and 16mer) may be concatenated into longer sequences (e.g. four tandem words and six tandem words). This approach, where multiple word variants are used at each tandem word position, allows very large sets of non-interacting DNA strands to be assembled from combinations of the individual words. Word sets were generated and their figures of merit are compared to sets as described previously in the literature (e.g. 4, 8, 12, 15 and 16mer). The predicted hybridization behavior was experimentally verified on selected members of the sets using standard UV hyperchromism measurements of duplex melting\u00a0\u2026", "num_citations": "46\n", "authors": ["1790"]}
{"title": "Automatable verification of sequential consistency\n", "abstract": " Sequential consistency is a multiprocessor memory model of both practical and theoretical importance. Designing and implementing a memory system that efficiently provides a given memory model is a challenging and error-prone task, so automated verification support would be invaluable. Unfortunately, the general problem of deciding whether a finite-state protocol implements sequential consistency is undecidable.  In this paper we identify a restricted class of protocols for which verifying sequential consistency is decidable. The class includes all real sequentially consistent protocols that are known to us, and we argue why the class is likely to include all real sequentially consistent protocols. In principle, our method can be applied in a completely automated fashion for verification of all implemented protocols.", "num_citations": "46\n", "authors": ["1790"]}
{"title": "From RNA secondary structure to coding theory: A combinatorial approach\n", "abstract": " We use combinatorial analysis to transform a special case of the computational problem of designing RNA base sequences with a given minimal free energy secondary structure into a coding theory question. The function of RNA molecules is largely determined by their molecular form,wh ich in turn is significantly related to the base pairings of the secondary structure. Hence,thi s is crucial initial work in the design of RNA molecules with desired three-dimensional structures and specific functional properties. The biological importance of RNA only continues to grow with the discoveries of many different RNA molecules having vital functions other than mediating the production of proteins from DNA. Furthermore,RNA has the same potential as DNA in terms of nanotechnology and biomolecular computing.", "num_citations": "44\n", "authors": ["1790"]}
{"title": "The Complexity of Space Boundes Interactive Proof Systems.\n", "abstract": " An early motivation for the study of interactive proof systems was to extend the notion of NP as the class of problems with efficient \u201cproofs of membership\u201d. Informally, a prover can convince a verifier in polynomial time that a string is in an NP language, by presenting a witness of that fact to the verifier. Suppose that the power of the verifier is extended so that it can flip coins and can interact with the prover during the course of a proof. In this way, a verifier can gather statistical evidence that an input is in a language.As we will see, the interactive proof system model precisely captures this interaction between a prover P and a verifier V. In the model, the computation of V is probabilistic, but is typically restricted in time or space. A language is accepted by the interactive proof system if, for all inputs in the language, V accepts with high probability, based on the communication with the \u201chonest\u201d prover P. However, on inputs not in the language, V rejects with high probability, even when communicating with a \u201cdishonest\u201d prover. In the general model, V can keep its coin flips secret from the prover. An important restriction is obtained by requiring that the verifier communicate all its coin flips to the prover as it flips them. Such interactive proof systems were first studied by", "num_citations": "43\n", "authors": ["1790"]}
{"title": "Initial association of NR2E1 with bipolar disorder and identification of candidate mutations in bipolar disorder, schizophrenia, and aggression through resequencing\n", "abstract": " Nuclear receptor 2E1 gene (NR2E1) resides within a 6q21\u201022 locus for bipolar disorder and schizophrenia. Mice deleted for Nr2e1 show altered neurogenesis, cortical and limbic abnormalities, aggression, hyperexcitability, and cognitive impairment. NR2E1 is therefore a positional and functional candidate for involvement in mental illness. We performed association analyses in 394 patients with bipolar disorder, 396 with schizophrenia, and 479 controls using six common markers and haplotypes. We also performed a comprehensive mutation screen of NR2E1, resequencing its entire coding region, complete 5\u2032 and 3\u2032 untranslated regions, consensus splice\u2010sites, and evolutionarily conserved regions in 126 humans with bipolar disorder, schizophrenia, or aggressive disorders. NR2E1 was associated with bipolar disorder I and II [odds ratio (OR\u2009=\u20090.77, P\u2009=\u20090.013), bipolar disorder I (OR\u2009=\u20090.77, P\u2009=\u20090\u00a0\u2026", "num_citations": "42\n", "authors": ["1790"]}
{"title": "Revenue monotonicity in combinatorial auctions\n", "abstract": " In recent work [Rastegari et al. 2007a; 2007b] we study revenue properties of combinatorial auctions. Consider a well-known drawback of the famous VCG mechanism: a seller\u2019s revenue can go down when bidders are added to an auction, contrary to the intuition that having more bidders should increase competition. Following an example due to Ausubel and Milgrom [2006], consider an auction with three bidders and two goods for sale. Suppose that bidder 2 wants both goods for the price of $2 billion whereas bidder 1 and bidder 3 are willing to pay $2 billion for the first and the second good respectively (see Figure 1). The VCG mechanism awards the goods to bidders 1 and 3 for the price of zero, yielding the seller zero revenue. However, in the absence of either bidder 1 or bidder 3, the revenue of the auction would be $2 billion.We say that an auction mechanism is revenue monotonic if the seller\u2019s revenue is\u00a0\u2026", "num_citations": "42\n", "authors": ["1790"]}
{"title": "Multiple word DNA computing on surfaces\n", "abstract": " The present invention relates to a molecular computer used to perform mathematical calculations and logical operations. In particular, the molecular computer disclosed herein simulates circuit-SAT mathematical models, and is thus a generalized computer. The present invention further relates to compositions and methods for performing biochemical reactions on a solid support.", "num_citations": "42\n", "authors": ["1790"]}
{"title": "Probabilistic game automata\n", "abstract": " We define a probabilistic game automaton, a general model of a two-person game. We show how this model includes as special cases the games against nature of Papadimitriou [13], the Arthur-Merlin games of Babai [1], and the interactive proof systems of Goldwasser, Micali, and Rackoff [7]. We prove a number of results about another special case, games against unknown nature, which is a generalization of games against nature. In our notation, we let UP, (UC) denote the class of two-person games with unbounded two-sided error where one player plays randomly, with partial information (complete information). Hence, the designation UC refers to games against known nature and UP refers to games against unknown nature. We show that UC-TIME(t(n))\u2286 UP-TIME(t(n))\u2286 UC-TIME(t2(n)), ASPACE(s(n))=UC-SPACE(s(n)) if s(n) =\u03a9(log n), UC-SPACE(s(n))\u2286UP-SPACE(log(s(n))) if s(n) =\u03a9(n), where ASPACE(s\u00a0\u2026", "num_citations": "42\n", "authors": ["1790"]}
{"title": "Analysis of energy-based algorithms for RNA secondary structure prediction\n", "abstract": " RNA molecules play critical roles in the cells of organisms, including roles in gene regulation, catalysis, and synthesis of proteins. Since RNA function depends in large part on its folded structures, much effort has been invested in developing accurate methods for prediction of RNA secondary structure from the base sequence. Minimum free energy (MFE) predictions are widely used, based on nearest neighbor thermodynamic parameters of Mathews, Turner et al. or those of Andronescu et al. Some recently proposed alternatives that leverage partition function calculations find the structure with maximum expected accuracy (MEA) or pseudo-expected accuracy (pseudo-MEA) methods. Advances in prediction methods are typically benchmarked using sensitivity, positive predictive value and their harmonic mean, namely F-measure, on datasets of known reference structures. Since such benchmarks document progress in improving accuracy of computational prediction methods, it is important to understand how measures of accuracy vary as a function of the reference datasets and whether advances in algorithms or thermodynamic parameters yield statistically significant improvements. Our work advances such understanding for the MFE and (pseudo-)MEA-based methods, with respect to the latest datasets and energy parameters. We present three main findings. First, using the bootstrap percentile method, we show that the average F-measure accuracy of the MFE and (pseudo-)MEA-based algorithms, as measured on our largest datasets with over 2000 RNAs from diverse families, is a reliable estimate (within a 2% range with high confidence) of\u00a0\u2026", "num_citations": "41\n", "authors": ["1790"]}
{"title": "On bounded round multiprover interactive proof systems\n", "abstract": " Bounded round multiprover interactive proof systems (MIPs) are compared with unbounded round interactive proof systems (IPSs). It is shown that for any constant epsilon , any language accepted by an unbounded round IPS has a bounded round, two-prover MIP that has error probability epsilon , resolving an open problem of L. Fortnow et al. (1988). To obtain this result, it is shown that a certain one-round MIP that simulates the computation of an unbounded round IPS can be executed many times in parallel to significantly reduce its probability of error.< >", "num_citations": "40\n", "authors": ["1790"]}
{"title": "Space and energy efficient computation with DNA strand displacement systems\n", "abstract": " Chemical reaction networks (CRN\u2019s) are important models of molecular programming that can be realized by logically reversible, and thus energy efficient, DNA strand displacement systems (DSD\u2019s). Qian\u00a0et al. [12] showed that energy efficient DSD\u2019s are Turing-universal; however their simulation of a computation requires space (or volume) proportional to the number of steps of the computation. Here we show that polynomially space bounded computations can be simulated in both a space and energy efficient manner using logically reversible CRN\u2019s and DSD\u2019s. A consequence of our proofs is that determining whether a particular molecular species can be produced from an initial pool of molecules of a CRN or DSD is PSPACE-hard, and thus also verifying the correctness of CRN\u2019s and DSD\u2019s is PSPACE-hard.", "num_citations": "38\n", "authors": ["1790"]}
{"title": "Surface-based DNA computing operations: DESTROY and READOUT\n", "abstract": " DNA computing on surfaces is where complex combinatorial mixtures of DNA molecules are immobilized on a substrate and subsets are tagged and enzymatically modified (DESTROY) in repeated cycles of the DNA computation. A restriction enzyme has been chosen for the surface DESTROY operation. For the READOUT operation, both cycle sequencing and PCR amplification followed by addressed array hybridization were studied to determine the DNA sequences after the computations.", "num_citations": "35\n", "authors": ["1790"]}
{"title": "The power of surface-based DNA computation\n", "abstract": " A new model of DNA computation that is based on surface chemistry is studied. Such computations involve the manipulation of DNA strands that are immobilized on a surface, rather than in solution as in the work of Adleman. Surface-based chemistry has been a critical technology in many recent advances in biochemistry and offers several advantages over solution-based chemistry, including simplified handling of samples and elimination of loss of strands, which reduce error in the computation.The main contribution of this paper is in showing that in principle, surface-based DNA chemistry can efficiently support general circuit computation on many inputs in parallel. To do this, an abstract model of computation that allows parallel manipulation of binary inputs is described. It is then shown that this model can be implemented by encoding inputs as DNA strands and repeatedly modifying the strands in parallel on a\u00a0\u2026", "num_citations": "34\n", "authors": ["1790"]}
{"title": "On the power of finite automata with both nondeterministic and probabilistic states\n", "abstract": " We study finite automata with both nondeterministic and random states (npfa's). We restrict our attention to those npfa's that accept their languages with a small probability of error and run in polynomial expected time. Equivalently, we study Arthur--Merlin games where Arthur is limited to polynomial time and constant space.Dwork and Stockmeyer [SIAM J. Comput., 19 (1990), pp. 1011--1023] asked whether these npfa's accept only the regular languages (this was known if the automaton has only randomness or only nondeterminism). We show that the answer is yes in the case of npfa's with a 1-way input head. We also show that if L is a nonregular language, then either L or  is not accepted by any npfa with a 2-way input head.Toward this end, we define a new measure of the complexity of a language L, called its 1-tiling complexity. For each n, this is the number of tiles needed to cover the 1's in the \"characteristic matrix\" of L\u00a0\u2026", "num_citations": "33\n", "authors": ["1790"]}
{"title": "Space-bounded probabilistic game automata\n", "abstract": " New results on the power of space-bounded probabdlmc game automata are presented. Space-bounded analogues of Arthur-Merlin games and mtemctive proof systems, which are denoted by BC and BP respectively, for Bounded random game automata with Complete and Partial mformatlon, are considered. The main results are that", "num_citations": "33\n", "authors": ["1790"]}
{"title": "Algorithmic bioprocesses\n", "abstract": " A fundamental understanding of algorithmic bioprocesses is key to learning how information processing occurs in nature at the cell level. The field is concerned with the interactions between computer science on the one hand and biology, chemistry, and DNA-oriented nanoscience on the other. In particular, this book offers a comprehensive overview of research into algorithmic self-assembly, RNA folding, the algorithmic foundations for biochemical reactions, and the algorithmic nature of developmental processes. The editors of the book invited 36 chapters, written by the leading researchers in this area, and their contributions include detailed tutorials on the main topics, surveys of the state of the art in research, experimental results, and discussions of specific research goals. The main subjects addressed are sequence discovery, generation, and analysis; nanoconstructions and self-assembly; membrane computing; formal models and analysis; process calculi and automata; biochemical reactions; and other topics from natural computing, including molecular evolution, regulation of gene expression, light-based computing, cellular automata, realistic modelling of biological systems, and evolutionary computing. This subject is inherently interdisciplinary, and this book will be of value to researchers in computer science and biology who study the impact of the exciting mutual interaction between our understanding of bioprocesses and our understanding of computation.", "num_citations": "32\n", "authors": ["1790"]}
{"title": "Revenue monotonicity in deterministic, dominant-strategy combinatorial auctions\n", "abstract": " In combinatorial auctions using VCG, a seller can sometimes increase revenue by dropping bidders. In this paper we investigate the extent to which this counterintuitive phenomenon can also occur under other deterministic, dominant-strategy combinatorial auction mechanisms. Our main result is that such failures of \u201crevenue monotonicity\u201d can occur under any such mechanism that is weakly maximal\u2014meaning roughly that it chooses allocations that cannot be augmented to cause a losing bidder to win without hurting winning bidders\u2014and that allows bidders to express arbitrary known single-minded preferences. We also give a set of other impossibility results as corollaries, concerning revenue when the set of goods changes, false-name-proofness, and the core.1", "num_citations": "31\n", "authors": ["1790"]}
{"title": "Novel and efficient RNA secondary structure prediction using hierarchical folding\n", "abstract": " Algorithms for prediction of RNA secondary structure\u2014the set of base pairs that form when an RNA molecule folds\u2014are valuable to biologists who aim to understand RNA structure and function. Improving the accuracy and efficiency of prediction methods is an ongoing challenge, particularly for pseudoknotted secondary structures, in which base pairs overlap. This challenge is biologically important, since pseudoknotted structures play essential roles in functions of many RNA molecules, such as splicing and ribosomal frameshifting. State-of-the-art methods, which are based on free energy minimization, have high run-time complexity (typically \u0398(n5) or worse), and can handle (minimize over) only limited types of pseudoknotted structures. We propose a new approach for prediction of pseudoknotted structures, motivated by the hypothesis that RNA structures fold hierarchically, with pseudoknot-free (non-overlapping\u00a0\u2026", "num_citations": "29\n", "authors": ["1790"]}
{"title": "Flow algorithms for two pipelined filter ordering problems\n", "abstract": " Pipelined filter ordering is a central problem in database query optimization, and has received renewed attention recently in the context of environments such as the web, continuous high-speed data streams and sensor networks. We present algorithms for two natural extensions of the classical pipelined filter ordering problem:(1) a distributional type problem where the filters run in parallel and the goal is to maximize throughput, and (2) an adversarial type problem where the goal is to minimize the expected value of multiplicative regret. We show that both problems can be solved using similar flow algorithms, which find an optimal ordering scheme in time O (n 2), where n is the number of filters. Our algorithm for (1) improves on an earlier O (n 3 log n) algorithm of Kodialam.", "num_citations": "29\n", "authors": ["1790"]}
{"title": "Linear time algorithm for parsing RNA secondary structure\n", "abstract": " Accurate prediction of pseudoknotted RNA secondary structure is an important computational challenge. Typical prediction algorithms aim to find a structure with minimum free energy according to some thermodynamic (\u201csum of loop energies\u201d) model that is implicit in the recurrences of the algorithm. However, a clear definition of what exactly are the loops and stems in pseudoknotted structures, and their associated energies, has been lacking.                 We present a comprehensive classification of loops in pseudoknotted RNA secondary structures. Building on an algorithm of Bader et al. [2] we obtain a linear time algorithm for parsing a secondary structures into its component loops.                 We also give a linear time algorithm to calculate the free energy of a pseudoknotted secondary structure. This is useful for heuristic prediction algorithms which are widely used since (pseudoknotted) RNA secondary\u00a0\u2026", "num_citations": "29\n", "authors": ["1790"]}
{"title": "Problems on RNA secondary structure prediction and design\n", "abstract": " We describe several computational problems on prediction and design of RNA molecules.", "num_citations": "29\n", "authors": ["1790"]}
{"title": "Progress toward demonstration of a surface based DNA computation: a one word approach to solve a model satisfiability problem\n", "abstract": " A multi-base encoding strategy is used in a one word approach to surface-based DNA computation. In this designed DNA model system, a set of 16 oligonucleotides, each a 16mer, is used with the format 5\u2032-FFFFvvvvvvvvFFFF-3\u2032 in which 4\u20138 bits of data are stored in eight central variable (\u2018v\u2019) base locations, and the remaining fixed (\u2018F\u2019) base locations are used as a word label. The detailed implementations are reported here. In order to achieve perfect discrimination between each oligonucleotide, the efficiency and specificity of hybridization discrimination of the set of 16 oligonucleotides were examined by carrying out the hybridization of each individual fluorescently tagged complement to an array of 16 addressed immobilized oligonucleotides. A series of preliminary hybridization experiments are presented and further studies about hybridization, enzymatic destruction, read out and demonstrations of a SAT\u00a0\u2026", "num_citations": "29\n", "authors": ["1790"]}
{"title": "densityCut: an efficient and versatile topological approach for automatic clustering of biological data\n", "abstract": " Motivation             : Many biological data processing problems can be formalized as clustering problems to partition data points into sensible and biologically interpretable groups.                               Results             : This article introduces densityCut, a novel density-based clustering algorithm, which is both time- and space-efficient and proceeds as follows: densityCut first roughly estimates the densities of data points from a              K             -nearest neighbour graph and then refines the densities via a random walk. A cluster consists of points falling into the basin of attraction of an estimated mode of the underlining density function. A post-processing step merges clusters and generates a hierarchical cluster tree. The number of clusters is selected from the most stable clustering in the hierarchical cluster tree. Experimental results on ten synthetic benchmark datasets and two microarray gene expression\u00a0\u2026", "num_citations": "28\n", "authors": ["1790"]}
{"title": "NP-completeness of the energy barrier problem without pseudoknots and temporary arcs\n", "abstract": " Knowledge of energy barriers between pairs of secondary structures for a given DNA or RNA molecule is useful, both in understanding RNA function in biological settings and in design of programmed molecular systems. Current heuristics are not guaranteed to find the exact energy barrier, raising the question whether the energy barrier can be calculated efficiently. In this paper, we study the computational complexity of a simple formulation of the energy barrier problem, in which each base pair contributes an energy of \u22121 and only base pairs in the initial and final structures may be used on a folding pathway from initial to final structure. We show that this problem is NP-complete.", "num_citations": "28\n", "authors": ["1790"]}
{"title": "Algorithms for testing that sets of DNA words concatenate without secondary structure\n", "abstract": " We present an efficient algorithm for determining whether all moleculesin a combinatorial set of DNA or RNA strandsare structure free, and thus availablefor bonding to their Watson-Crick complements.This work is motivated by the goalof testing whether strands used in DNAcomputations or as molecular bar-codesare structure free, where the strands areconcatenations of short words. We alsopresent an algorithm for determining whetherall words in S*, for some finite setS of equi-length words, are structure free.", "num_citations": "28\n", "authors": ["1790"]}
{"title": "On combinatorial DNA word design\n", "abstract": " CiNii \u8ad6\u6587 - On combinatorial DNA word design CiNii \u56fd\u7acb\u60c5\u5831\u5b66\u7814\u7a76\u6240 \u5b66\u8853\u60c5\u5831\u30ca\u30d3\u30b2\u30fc\u30bf[\u30b5\u30a4\u30cb\u30a3 ] \u65e5\u672c\u306e\u8ad6\u6587\u3092\u3055\u304c\u3059 \u5927\u5b66\u56f3\u66f8\u9928\u306e\u672c\u3092\u3055\u304c\u3059 \u65e5\u672c\u306e\u535a\u58eb\u8ad6\u6587\u3092\u3055\u304c\u3059 \u65b0\u898f\u767b\u9332 \u30ed\u30b0\u30a4\u30f3 English \u691c\u7d22 \u3059\u3079\u3066 \u672c\u6587\u3042\u308a \u3059\u3079\u3066 \u672c\u6587\u3042\u308a \u9589\u3058\u308b \u30bf\u30a4\u30c8\u30eb \u8457\u8005\u540d \u8457\u8005ID \u8457\u8005\u6240\u5c5e \u520a\u884c\u7269\u540d ISSN \u5dfb\u53f7 \u30da\u30fc\u30b8 \u51fa\u7248\u8005 \u53c2\u8003\u6587\u732e \u51fa\u7248\u5e74 \u5e74\u304b\u3089 \u5e74\u307e\u3067 \u691c\u7d22 \u691c\u7d22 \u691c\u7d22 CiNii\u7a93\u53e3\u696d\u52d9\u306e\u518d\u958b\u306b\u3064\u3044\u3066 On combinatorial DNA word design CONDON A. \u88ab\u5f15\u7528\u6587\u732e: 1\u4ef6 \u8457\u8005 CONDON A. \u53ce\u9332\u520a\u884c\u7269 J. Comput. Biol. J. Comput. Biol. 8, 201-220, 2001 \u88ab\u5f15\u7528\u6587\u732e: 1\u4ef6\u4e2d 1-1\u4ef6\u3092 \u8868\u793a 1 Analysis and Re-engineering of Whiplash PCR: Simulations of Fidelity and Efficiency, and an Improved Architecture Based on Targeted Strand Displacement (\u5c0f\u7279\u96c6 DNA\u30b3\u30f3\u30d4\u30e5\u30fc\u30c6\u30a3\u30f3\u30b0\u306e \u5fdc\u7528\u3068\u30b7\u30df\u30e5\u30ec\u30fc\u30b7\u30e7\u30f3) Rose John A. \u30b7\u30df\u30e5\u30ec\u30fc\u30b7\u30e7\u30f3 = JOURNAL OF THE JAPAN SOCIETY FOR SIMULATION TECHNOLOGY 24(4), 289-299, 2005-12-15 \u53c2\u8003\u6587\u732e25\u4ef6 \u5927\u5b66\u9662\u8aac\u660e\u2026", "num_citations": "28\n", "authors": ["1790"]}
{"title": "A fast and robust iterative algorithm for prediction of RNA pseudoknotted secondary structures\n", "abstract": " Improving accuracy and efficiency of computational methods that predict pseudoknotted RNA secondary structures is an ongoing challenge. Existing methods based on free energy minimization tend to be very slow and are limited in the types of pseudoknots that they can predict. Incorporating known structural information can improve prediction accuracy; however, there are not many methods for prediction of pseudoknotted structures that can incorporate structural information as input. There is even less understanding of the relative robustness of these methods with respect to partial information. We present a new method, Iterative HFold, for pseudoknotted RNA secondary structure prediction. Iterative HFold takes as input a pseudoknot-free structure, and produces a possibly pseudoknotted structure whose energy is at least as low as that of any (density-2) pseudoknotted structure containing the input structure. Iterative HFold leverages strengths of earlier methods, namely the fast running time of HFold, a method that is based on the hierarchical folding hypothesis, and the energy parameters of HotKnots V2.0. Our experimental evaluation on a large data set shows that Iterative HFold is robust with respect to partial information, with average accuracy on pseudoknotted structures steadily increasing from roughly 54% to 79% as the user provides up to 40% of the input structure. Iterative HFold is much faster than HotKnots V2.0, while having comparable accuracy. Iterative HFold also has significantly better accuracy than IPknot on our HK-PK and IP-pk168 data sets. Iterative HFold is a robust method for prediction of pseudoknotted RNA secondary\u00a0\u2026", "num_citations": "27\n", "authors": ["1790"]}
{"title": "Playing games of incomplete information\n", "abstract": " We study two-person games of cooperation and multi-prover interactive proof systems. We first consider a two person game G, which we call a free game, defined as follows. A Boolean function\u00a2 a is given. Player I and II each pick a random number i and j in private, where I< i, j< s, and then each chooses a private number f (i) and g (j), 1< f (i), g (j)< _ s. If ea (i, J, f (i), g (J))= 1, then both players win, otherwise they lose. The objective of both players is to win collectively. We ask whether, if such a game is played n times in parallel, the probability of winning all the games decays exponentially in n. This question was posed in a more general context by Fortnow [4], which we discuss soon.Formally we define the nth product game G n as the following two person game. Player I and II each pick a vector of independent random numbers~=(il,..., i,~) and~=(jl,..., j~) in private, 1< _ ik, jk _< s, and then each chooses a private\u00a0\u2026", "num_citations": "26\n", "authors": ["1790"]}
{"title": "An algorithm for the energy barrier problem without pseudoknots and temporary arcs\n", "abstract": " We make two new contributions to the problem of calculating pseudoknot-free folding pathways with minimum energy barrier between pairs (, ) of RNA secondary structures. Our first contribution pertains to a problem posed by Morgan and Higgs: find a min-barrier direct folding pathway for a simple energy model in which each base pair contributes -1. In a direct folding pathway, intermediate structures contain only base pairs in  and  and are of length  (the size of the symmetric difference of the two structures). We show how to solve this problem exactly, using techniques for deconstructing bipartite graphs. The problem is NP-hard and so our algorithm requires exponential time in the worst case but performs quite well empirically on pairs of structures that are hundreds of nucleotides long. Our second contribution shows that for the simple energy model, repeatedly adding or removing a base pair from\u00a0\u2026", "num_citations": "25\n", "authors": ["1790"]}
{"title": "Less haste, less waste: on recycling and its limits in strand displacement systems\n", "abstract": " We study the potential for molecule recycling in chemical reaction systems and their DNA strand displacement realizations. Recycling happens when a product of one reaction is a reactant in a later reaction. Recycling has the benefits of reducing consumption, or waste, of molecules and of avoiding fuel depletion. We present a binary counter that recycles molecules efficiently while incurring just a moderate slowdown compared with alternative counters that do not recycle strands. This counter is an n-bit binary reflecting Gray code counter that advances through 2n states. In the strand displacement realization of this counter, the waste\u2014total number of nucleotides of the DNA strands consumed\u2014is polynomial in n, the number of bits of the counter, while the waste of alternative counters grows exponentially in n. We also show that our n-bit counter fails to work correctly when many (\u0398(n)) copies of the species that\u00a0\u2026", "num_citations": "24\n", "authors": ["1790"]}
{"title": "Parsing nucleic acid pseudoknotted secondary structure: algorithm and applications\n", "abstract": " Accurate prediction of pseudoknotted nucleic acid secondary structure is an important computational challenge. Prediction algorithms based on dynamic programming aim to find a structure with minimum free energy according to some thermodynamic (\"sum of loop energies\") model that is implicit in the recurrences of the algorithm. However, a clear definition of what exactly are the loops in pseudoknotted structures, and their associated energies, has been lacking. In this work, we present a complete classification of loops in pseudoknotted nucleic secondary structures, and describe the Rivas and Eddy and other energy models as sum-of-loops energy models. We give a linear time algorithm for parsing a pseudoknotted secondary structure into its component loops. We give two applications of our parsing algorithm. The first is a linear time algorithm to calculate the free energy of a pseudoknotted secondary\u00a0\u2026", "num_citations": "24\n", "authors": ["1790"]}
{"title": "Asynchronous analysis of parallel dynamic programming algorithms\n", "abstract": " We examine a very simple asynchronous model of parallel computation that assumes the time to compute a task is random, following some probability distribution. The goal of this model is to capture the effects of unpredictable delays on processors, due to communication delays or cache misses, for example. Using techniques from queueing theory and occupancy problems, we use this model to analyze two parallel dynamic programming algorithms. We show that this model is simple to analyze and correctly predicts which algorithm will perform better in practice. The algorithms we consider are a pipeline algorithm, where each processor i computes in order the entries of rows i, i+p, and so on, where p is the number of processors; and a diagonal algorithm, where entries along each diagonal extending from the left to the top of the table are computed in turn. It is likely that the techniques used here can be useful in\u00a0\u2026", "num_citations": "23\n", "authors": ["1790"]}
{"title": "Algorithms for distributional and adversarial pipelined filter ordering problems\n", "abstract": " Pipelined filter ordering is a central problem in database query optimization. The problem is to determine the optimal order in which to apply a given set of commutative filters (predicates) to a set of elements (the tuples of a relation), so as to find, as efficiently as possible, the tuples that satisfy all of the filters. Optimization of pipelined filter ordering has recently received renewed attention in the context of environments such as the Web, continuous high-speed data streams, and sensor networks. Pipelined filter ordering problems are also studied in areas such as fault detection and machine learning under names such as learning with attribute costs, minimum-sum set cover, and satisficing search. We present algorithms for two natural extensions of the classical pipelined filter ordering problem: (1) a distributional-type problem where the filters run in parallel and the goal is to maximize throughput, and (2) an adversarial\u00a0\u2026", "num_citations": "21\n", "authors": ["1790"]}
{"title": "Reasoning about optimal stable matchings under partial information\n", "abstract": " We study two-sided matching markets in which participants are initially endowed with partial preference orderings, lacking precise information about their true, strictly ordered list of preferences. We wish to reason about matchings that are stable with respect to agents' true preferences, and which are furthermore optimal for one given side of the market. We present three main results. First, one can decide in polynomial time whether there exists a matching that is stable and optimal under all strict preference orders that refine the given partial orders, and can construct this matching in polynomial time if it does exist. We show, however, that deciding whether a given pair of agents are matched in all or no such optimal stable matchings is co-NP-complete, even under quite severe restrictions on preferences. Finally, we describe a polynomial-time algorithm that decides, given a matching that is stable under the partial\u00a0\u2026", "num_citations": "20\n", "authors": ["1790"]}
{"title": "HFold: RNA pseudoknotted secondary structure prediction using hierarchical folding\n", "abstract": " Improving the accuracy and efficiency of computational RNA secondary structure prediction is an important challenge, particularly for pseudoknotted secondary structures. We propose a new approach for prediction of pseudoknotted structures, motivated by the hypothesis that RNA structures fold hierarchically, with pseudoknot free pairs forming initially, and pseudoknots forming later so as to minimize energy relative to the initial pseudoknot free structure. Our HFold (Hierarchical Fold) algorithm has O(n               3) running time, and can handle a wide range of biological structures, including nested kissing hairpins, which have previously required \u0398(n               6) time using traditional minimum free energy approaches. We also report on an experimental evaluation of HFold.", "num_citations": "18\n", "authors": ["1790"]}
{"title": "Interactive proof systems with polynomially bounded strategies\n", "abstract": " Interactive proof systems in which the Prover is restricted to have a polynomial size strategy are investigated. The restriction of polynomial size computation tree, visible to the Prover, or logarithmically bounded number of coin flips by the Verifier guarantee a polynomial size strategy. The additional restriction of logarithmic space is also investigated. A main result of the paper is that interactive proof systems in which the Prover is restricted to a polynomial size strategy are equivalent to MA, Merlin-Arthur games, defined by Babai and Moran. Polynomial tree size is also equivalent to MA, but when logarithmic space is added as a restriction, the power of polynomial tree size reduces to NP. Logarithmically bounded number of coin flips are equivalent to MP, and when logarithmic space is added as a restriction, the power is not diminished. The proof that NP \u2286 of or equal to IP (log-space, log-random-bits) illustrates an\u00a0\u2026", "num_citations": "18\n", "authors": ["1790"]}
{"title": "NP-completeness of the direct energy barrier problem without pseudoknots\n", "abstract": " Knowledge of energy barriers between pairs of secondary structures for a given DNA or RNA molecule is useful, both in understanding RNA function in biological settings and in design of programmed molecular systems. Current heuristics are not guaranteed to find the exact energy barrier, raising the question whether the energy barrier can be calculated efficiently. In this paper, we study the computational complexity of a simple formulation of the energy barrier problem, in which each base pair contributes an energy of \u2212\u20091 and only base pairs in the initial and final structures may be used on a folding pathway from initial to final structure. We show that this problem is NP-complete.", "num_citations": "17\n", "authors": ["1790"]}
{"title": "A theory of strict P-completeness\n", "abstract": " A serious limitation of the theory of P-completeness is that it fails to distinguish between those P-complete problems that do have polynomial speedup on parallel machines from those that don't. We introduce the notion of strict P-completeness and develop tools to prove precise limits on the possible speedups obtainable for a number of P-complete problems.", "num_citations": "17\n", "authors": ["1790"]}
{"title": "On games of incomplete information\n", "abstract": " We study two-person games of cooperation and multi-prover interactive proof systems. We first consider a two-person game G, which we call a free game, defined as follows. A Boolean function C& is given. Players I and II each pick a random number i and j in private, where 1 d i, j< s, and then each chooses a private numberf (i) and g (j), 1< f (i), g (j)< s. If & (i, j, f (i), g (j))= 1, then both players win; otherwise, they lose. The objective of both players is to win collectively. We ask whether, if such a game is played n times in parallel, the probability of winning all the games decays exponentially in n. This question was posed in a more general context by Fortnow [lo], which we will discuss soon.Formally, we define the nth product game G\u201d as the following two-person game. Players I and II each pick a vector of independent random numbers i=(iI,..., i,) and j=(j l,..., jn) in private, 1< ik, jk< s, and then each chooses a private sequence of numbers fi (g,.... f.(fl and gl (j),..., g&3. The goal for both players is to ensure Ai= 1 & (&, j&.(i), g. Jj))= 1. We define th e winning probability of the game G to be maxS,, Pr [& (i, j, f (i), g (j))= 11, where the probability is taken over all randomly and uniformly chosen i, j in the range 1,.... s, and we denote it by w (G). The game G is called nontrivial if its winning probability is neither 0 nor 1. We shall consider only", "num_citations": "17\n", "authors": ["1790"]}
{"title": "Lamort Clocks: Reasoning About Shared Memory Correctness\n", "abstract": " Modern shared memory implementations use many complex, interacting optimizations, forcing industrial product groups to spend much more effort in verification than in design. Current formal verification techniques are somewhat non-intuitive to system designers and verifiers, and these formal methods do not scale well to practical systems. This paper seeks to give verifiers and designers a reasoning technique that is precise (unlike informal reasoning) and intuitive (unlike some formal models). To prove that a system obeys the desired consistency model, we would like a tool that allows us to create a total order of events. We modestly extend Lamport's logical clock work from distributed systems and apply it to shared memory systems. We use these so-called Lamport clocks to timestamp events and thereby create a total order: This total order can then be examined to see if it satisfies the desired consistency model\u00a0\u2026", "num_citations": "16\n", "authors": ["1790"]}
{"title": "Will biologists become computer scientists? A truly interdisciplinary effort by computer scientists and biologists to understand how cells process information may yield new\u00a0\u2026\n", "abstract": " The idea that living systems could be understood and described as information-processing systems has been around even before the first computers were built. From Alan Turing\u2019s considerable paper in 1936 to Erwin Schr\u00f6dinger\u2019s work in 1944 and John von Neumann\u2019s work in 1948 [1], many scientists pondered about information storage and the possible existence of a logical processor within living cells. The discovery of the double-helical structure of DNA in 1953 provided the material basis for these intuitions as it finally revealed how cells store inheritable information in a \u201cdigital\u201d format. The recent success of genome transplantation experiments into recipient host cells [2]\u2014akin to transferring software to another computer\u2014further strengthened the hypothesis that living cells can be regarded as Turing Machines, as was suggested by Sydney Brenner [3](see Sidebar 1 for a glossary and Sidebar 2 for further\u00a0\u2026", "num_citations": "15\n", "authors": ["1790"]}
{"title": "The complexity of string partitioning\n", "abstract": " Given a string w over a finite alphabet \u03a3 and an integer K, can w be partitioned into strings of length at most K, such that there are no collisions? We refer to this question as the string partition problem and show it is NP-complete for various definitions of collision and for a number of interesting restrictions including| \u03a3|= 2. This establishes the hardness of an important problem in contemporary synthetic biology, namely, oligo design for gene synthesis.", "num_citations": "14\n", "authors": ["1790"]}
{"title": "Toward a decidable notion of sequential consistency\n", "abstract": " A memory model specifies a correctness requirement for a distributed shared memory protocol. Sequential consistency (SC) is the most widely researched model; previous work citealur1996 has shown that, in general, the SC verification problem is undecidable. We identify two aspects of the formulation found in citealur1996 that we consider to be highly unnatural; we call these non-prefix-closedness and prophetic inheritance. We conjecture that preclusion of such behavior yields a decidable version of SC, which we call decisive sequential consistency (DSC). We also introduce a structure called a phview window (VW), which retains information about a protocol's history, and we define the notion of a phVW-bound, which essentially bounds the size of the VWs needed to maintain DSC. We prove that the class of DSC protocols with VW-bound k is decidable; left conjectured is the hypothesis that all DSC protocols\u00a0\u2026", "num_citations": "14\n", "authors": ["1790"]}
{"title": "On the power of finite automata with both nondeterministic and probabilistic states (preliminary version)\n", "abstract": " We study finite automata with both nondeterministic and random states (npfa\u2019s). We restrict our attention to those npfa\u2019s that accept their languages with a small probability of error and run in polynomial expected time. Equivalently, we study Arthur-Merlin games where the players are limited to polynomial time and constant space. Dwork and Stockmeyer asked whether the above class of npfa\u2019s accept only the regular languages(this was known if the automaton has only randomness or only nondeterminism). We show that the answer is yes in the case of npfa\u2019s with a l-way input head. We also show that if L is a nonregular language, then either L or~ is not accepted by any npfa with a 2-way input head.Toward this end, we define a new measure of the complexity of a language L, called its l-tiling complexity. For each n, this is the number of tiles needed to cover the 1\u2018s in the \u201ccharacteristic matrix\u201d of L, namely the binary\u00a0\u2026", "num_citations": "14\n", "authors": ["1790"]}
{"title": "A theory of strict P-completeness\n", "abstract": " A serious limitation of the theory of P-completeness is that it fails to distinguish between those P-complete problems that do have polynomial speedup on parallel machines from those that don't. We introduce the notion of strict P-completeness and develop tools to prove precise limits on the possible speedup obtainable for a number of P-complete problems.", "num_citations": "14\n", "authors": ["1790"]}
{"title": "Probabilistic game automata\n", "abstract": " We define a probabilistic game automaton, a general model of a two-person game. We show how this model includes as special cases the games against nature of Papadimitriou [9], the Arthur-Merlin games of Babai [1] andthe interactive proof systems of Goldwasser, Micali and Rackoff [5]. We prove a number of results about another special case, games against unknown nature, which is a generalization of games against nature. In our notation, we let UP(UC, resp.) denote the class of two-person games with unbounded two-sided error where one player plays randomly with partial information (complete information, resp.) and the otherplayer plays existentially. Hence, the designation UC refers to games against known nature andUP refers to games against unknown nature. We show that  $$\\begin{gathered}ATIME(t(n)) = UC - TIME(t(n)) \\subseteq UP - TIME(t(n)) \\subseteq UC - TIME(t^2 (n)) \\hfill \\\\ASPACE\u00a0\u2026", "num_citations": "14\n", "authors": ["1790"]}
{"title": "Computational prediction of nucleic acid secondary structure: Methods, applications, and challenges\n", "abstract": " RNA molecules are crucial in different levels of cellular function, ranging from translation and regulating genes to coding for proteins. Additionally, nucleic acids (RNA and DNA molecules) are designed for novel applications in biotechnology. Understanding the structure of a molecule is important in inferring its function, and computational methods for structure prediction have captured the interest of many researchers.Some functions of RNA molecules in cells, such as gene regulation, result from the binding of one RNA molecule to another, so-called target RNA molecule. This has led to recent interest in prediction of the secondary structure formed from interacting molecules. In this paper, we provide a brief overview of methods, applications, and challenges in computational prediction of nucleic acid secondary structure, both for single strands and for interacting strands.", "num_citations": "12\n", "authors": ["1790"]}
{"title": "Stepwise randomized combinatorial auctions achieve revenue monotonicity\n", "abstract": " In combinatorial auctions that use VCG, a seller can sometimes increase revenue by dropping bidders (see e.g. [5]). In our previous work [26], we showed that such failures of \u201crevenue monotonicity\u201d occur under an extremely broad range of deterministic strategyproof combinatorial auction mechanisms, even when bidders have \u201cknown single-minded\u201d valuations. In this work we consider the question of whether revenue monotonic, strategyproof mechanisms for such bidders can be found in the broader class of randomized mechanisms. We demonstrate that\u2014surprisingly\u2014such mechanisms do exist, show how they can be constructed, and consider algorithmic techniques for implementing them in polynomial time. More formally, we characterize a class of randomized mechanisms defined for known single-minded bidders that are strategyproof and revenue monotonic, and furthermore satisfy some other desirable\u00a0\u2026", "num_citations": "12\n", "authors": ["1790"]}
{"title": "Complexity of a collision-aware string partition problem and its relation to oligo design for gene synthesis\n", "abstract": " Artificial synthesis of long genes and entire genomes is achieved by self-assembly of DNA oligo fragments - fragments which are short enough to be generated using a DNA synthesizer. Given a description of the duplex to be synthesized, a computational challenge is to select the short oligos so that, once synthesized, they will self-assemble without error. In this paper, we show that a natural abstraction of this problem, the collision-aware string partition problem, is NP-complete.", "num_citations": "12\n", "authors": ["1790"]}
{"title": "Automata make antisense\n", "abstract": " Figure 1 Automaton in abstract. Benenson et al. 2 devised a molecular automaton that theoretically tests for certain diagnostic conditions (high or low concentrations of particular indicator molecules) in cells. After each transition, the state of the diagnosis is either positive (\u2018yes\u2019), indicating that all conditions tested to date are true, or negative (\u2018no\u2019), signifying that at least one of the conditions tested so far is false. Should all four conditions be satisfied, indicating a positive diagnosis overall, a drug would be released.", "num_citations": "12\n", "authors": ["1790"]}
{"title": "Proving sequential consistency by model checking\n", "abstract": " Sequential consistency is a multiprocessor memory model of both practical and theoretical importance. Unfortunately, the general problem of verifying that a finite-state protocol implements sequential consistency is undecidable, and in practice, validating that a real-world, finite-state protocol implements sequential consistency is very time-consuming and costly. In this work, we show that for memory protocols that occur in practice, a small amount of manual effort can reduce the problem of verifying sequential consistency into a verification task that can be discharged automatically via model checking. Furthermore, we present experimental results on a substantial, directory-based cache coherence protocol, which demonstrate the practicality of our approach.", "num_citations": "12\n", "authors": ["1790"]}
{"title": "A system-level Specification Framework for I/O Architectures\n", "abstract": " A computer system is useless unless it can interact with the outside world through input/output (I/O) devices. II0 systems are complex, including aspects such as memory-mapped operations, interrupts, and bus bridges. Often, IJO behavior is described for isolated devices without a formal description of how the complete II0 sys-~ tern behaves. The lack of an end-to-end Jrstem description makes the tasks of system programmers and hardware implementors more dificult to do correctly.This paper proposes a framework for formally describing I/O architectures called Wisconsin II0 (WIO). WI0 extends work on memory consistency models (that formally specify the behavior of normal memory) to handle considerations such as memorymapped operations, device operations, interrupts, and operations with side effects. Specifically, WI0 asks each processor or device that can issue k operation types to speci\u2019ordering\u00a0\u2026", "num_citations": "12\n", "authors": ["1790"]}
{"title": "Reducing errors in DNA computing by appropriate word design\n", "abstract": " In a recent paper,[1] we have proposed to perform logical manipulations of large sets of data chemically by using the hybridization and enzymatic manipulation of DNA molecules attached to surfaces. In these experiments, combinatorial mixtures of DNA molecules are attached to a surface, and subsets of this mixture are identified by the hybridization adsorption of complementary DNA molecules. Enzymes are then used to destroy all unhybridized DNA, and the process is repeated until only a few DNA molecules representing the\" solutions\" to a mathematical problem remain on the surface. In order to store information in the attached DNA molecules, we have proposed to break up the data into\" words\" of 5 or 8 bits that are stored in short oligonucleotides (either 15mers or 16mers respectively). By linking sets of these words together, we can eventually form the very large combinatorial sets required in the calculations while perfecting the chemistry on a much smaller length scale. In this paper we address the problem of finding the best sequences for storing the data in these oligonucleotides.In our first set of test experiments, we have used 15mers to store 5 bits of information. The sequence of the 15mers has the form 3'-FFFFFFvvvvvFFFF-5', where F is a fixed base (G, C, T or A) that is the same for every 15mer, and v is a variable base that can vary between either (G, C) or (A, T). In this manner, one bit of information can be stored at each variable base position. Since there are 5 variable base positions, there are a total of 2^ 5 or 32 possible molecules in the entire combinatorial set. The template for the sequence used in our first set of experiments is 3\u00a0\u2026", "num_citations": "12\n", "authors": ["1790"]}
{"title": "On the Complexity of the Policy Interation Algorithm for Stochastic Games\n", "abstract": " We consider a natural class of algorithms for simple stochastic games. It has been proved that the problem of deciding which player has the greatest chance of winning the game is in the class NP r co-NP. It is not known whether the problem is in P. We examine a number of local search algorithms, called policy iteration algorithms, which solve this problem, and prove that these algorithms require exponential time in the worst", "num_citations": "12\n", "authors": ["1790"]}
{"title": "Approximate majority analyses using tri-molecular chemical reaction networks\n", "abstract": " Approximate Majority is a well-studied problem in the context of chemical reaction networks\u00a0(CRNs) and their close relatives, population protocols: Given a mixture of two types of species with an initial gap between their counts, a CRN computation must reach consensus on the majority species. Angluin, Aspnes, and Eisenstat proposed a simple population protocol for Approximate Majority and proved correctness and  time efficiency with high probability, given an initial gap of size  when the total molecular count in the mixture is n. Motivated by their intriguing but complex proof, we provide a new analysis of several CRNs for Approximate Majority, starting with a very simple tri-molecular protocol with just two reactions and two species. We obtain simple analyses of three bi-molecular protocols, including that of Angluin et al., by showing how they emulate the tri-molecular protocol. Our results improve on\u00a0\u2026", "num_citations": "11\n", "authors": ["1790"]}
{"title": "Efficient codon optimization with motif engineering\n", "abstract": " It is now common to add synthetic protein coding genes into cloning vectors for expression within non-native host organisms. Codon optimization is the task of choosing a sequence of codons that specify a protein so that the chosen codons are those used with the highest possible frequency in the host genome, subject to certain constraints, such as ensuring that occurrences of pre-specified \u201cforbidden\u201d motifs are minimized. Codon optimization supports translational efficiency of the desired protein product, by exchanging codons which are rarely found in the host organism with more frequently observed codons. Motif engineering, such as removal of restriction enzyme recognition sites or addition of immuno-stimulatory elements, is also often necessary. We present an algorithm for optimizing codon bias of a gene with respect to a well motivated measure of bias, while simultaneously performing motif engineering. The\u00a0\u2026", "num_citations": "11\n", "authors": ["1790"]}
{"title": "On approximation algorithms for hierarchical MAX-SAT\n", "abstract": " We prove upper and lower bounds on performance guarantees of approximation algorithms for the hierarchical MAX-SAT (H-MAX-SAT) problem. This problem is representative of a broad class of PSPACE-hard problems involving graphs, Boolean formulas, and other structures that are defined succinctly.Our first result is that, for some constant \u03b5\u00a0<\u00a01, it is PSPACE-hard to approximate the function H-MAX-SAT to within ratio \u03b5. We obtain our result using a reduction from the language recognition problem for a model of PSPACE called the probabilistically checkable debate system. As an immediate application, we obtain nonapproximability results for functions on hierarchical graphs by combining our result with previously known approximation-preserving reductions to other problems. For example, it is PSPACE-hard to approximate H-MAX-CUT and H-MAX-INDEPENDENT-SET to within some constant factor.Our\u00a0\u2026", "num_citations": "11\n", "authors": ["1790"]}
{"title": "Random walks on colored graphs\n", "abstract": " We initiate a study of random walks on undirected graphs with colored edges. In our model, a sequence of colors is specified before the walk begins, and it dictates the color of edge to be followed at each step. We give tight upper and lower bounds on the expected cover time of a random walk on an undirected graph with colored edges. We show that, in general, graphs with two colors have exponential expected cover time, and graphs with three or more colors have doubly\u2010exponential expected cover time. We also give polynomial bounds on the expected cover time in a number of interesting special cases. We described applications of our results to understanding the dominant eigenvectors of products and weighted averages of stochastic matrices, and to problems on time\u2010inhomogeneous Markov chains. \u00a9 1994 John Wiley & Sons, Inc.", "num_citations": "11\n", "authors": ["1790"]}
{"title": "Strategic directions in research in theory of computing\n", "abstract": " Theory of computing is the scientific study of the fundamental nature of computation. The goal is to determine what can be computed efficiently: for specific computational problems, researchers endeavor to devise efficient algorithms or to prove that no efficient algorithm exists. Theoretical research yields concepts and principles that provide the scientific basis for the design and construction of computer software and hardware, just as linear system theory provides the basis for the design of an aircraft\u2019s control systems. This report focuses on two core areas of theoretical computer science, discrete algorithms and computational complexity theory. Other reports from the Strategic Directions Workshop address theoretical research in computational geometry, concurrency, programming language semantics, and formal methods. Research in theory of computing began in the 1930s, when investigations by logicians\u00a0\u2026", "num_citations": "10\n", "authors": ["1790"]}
{"title": "Complexity of sub-bus mesh computations\n", "abstract": " The time complexity of several fundamental problems on the sub-bus mesh parallel computer with p processors is investigated. The problems include computing the PARITY and MAJORITY of p bits, the SUM of p numbers of length , and the MINIMUM of p numbers. It is shown that in one dimension the time to compute any of these problems is . In two dimensions the time to compute any of PARITY, MAJORITY, and SUM is . It was previously shown that the time to compute MINIMUM in two dimensions is  [R. Miller et al., IEEE Trans. Comput., 42 (1993), pp. 678\u2013692; L. Valiant, SIAM J. Comput., 4 (1975), pp. 348\u2013355]", "num_citations": "10\n", "authors": ["1790"]}
{"title": "Reachability bounds for chemical reaction networks and strand displacement systems\n", "abstract": " Chemical reaction networks (CRNs) and DNA strand displacement systems (DSDs) are widely-studied and useful models of molecular programming. However, in order for some DSDs in the literature to behave in an expected manner, the initial number of copies of some reagents is required to be fixed. In this paper we show that, when multiple copies of all initial molecules are present, general types of CRNs and DSDs fail to work correctly if the length of the shortest sequence of reactions needed to produce any given molecule exceeds a threshold that grows polynomially with attributes of the system.", "num_citations": "9\n", "authors": ["1790"]}
{"title": "Bounded error probabilistic finite state automata\n", "abstract": " What power does randomness confer to computing devices? In this article, we focus on this question in what is perhaps its simplest form, namely when the computing device is a finite state automaton. Some of the oldest studies of probabilistic computations, dating as far back as the 40's, implicitly concern probabilistic finite state devices. A beautiful theory of probabilistic finite state automata was developed starting in the early 60's [Rabin, 1963, Paz, 1971]. This work primarily concerned automata with 1-way heads on the input tape, where an input w is considered to be accepted if the probability of reaching the accept state from the initial con guration is greater than some threshold, say 1/2. The class of languages thus accepted is known as the stochastic languages. A pfa for a stochastic language may err by rejecting inputs in the language with probability that approaches 1/2 as the input size increases. It is natural to cons...", "num_citations": "9\n", "authors": ["1790"]}
{"title": "On the computability of infinite-horizon partially observable Markov decision processes\n", "abstract": " We investigate the computability of infinite-horizon partially observable Markov decision processes under discounted and undiscounted optimality criteria. The undecidability of the emptiness problem for probabilistic finite automata is used to show that a few technical problems, such as the isolation of a threshold, and closely related undiscounted problems such as probabilistic planning are undecidable. The decidability of corresponding problems under the discounted criterion remains largely open, but we provide evidence for decidabilility of several, while we also give evidence of hardness as there may be no closed-forms for describing optimal sequences of actions. The research sheds light on some interesting structural properties of these problems.We investigate the computability of infinite-horizon partially observable Markov decision processes (POMDPs). These problems form the basic model for closely related problems in the area of probabilistic planning. Their computability had been questioned or conjectured before (see for example [PT87] and [Lit96]). To simplify and focus on important properties of the problems, we will concentrate on unobservable MDPs, or UMDPs. Of course, any hardness result shown applies to the more general class of POMDPs as well. In Section 1, we give a brief introduction to the models, several infinite-horizon discounted and undiscounted optimality criteria, notions of optimal policies, values and action sequences, and the computational problems of interest.", "num_citations": "9\n", "authors": ["1790"]}
{"title": "DNA and the brain\n", "abstract": " TV series Pinky and the Brain. The Acme researchers used their technology to enhance the intelligence of the eponymous mice\u2014Brain became a fiendish genius bent on world domination, although Pinky\u2019s transformation into a dimwit was arguably less impressive. Such experiments are clearly fantasy, but a related and compelling bioengineering challenge in the real world is to demonstrate how tiny biological molecules could support limited forms of intelligent behaviour, as must have happened before brains evolved. On page 368 of this issue, Qian et al. 1 report a leap forward in this area: a network of interacting DNA strands that can act as artificial neurons, and that supports simple memory functions. Brains are large networks of neurons. Within these networks, individual cells produce electrochemical signals whose strength depends in a complex way on the strengths of input signals received from other\u00a0\u2026", "num_citations": "8\n", "authors": ["1790"]}
{"title": "A limit theorem for sets of stochastic matrices\n", "abstract": " The following fact about (row) stochastic matrices is an easy consequence of well known results: for each positive integer n\u2a7e 1 there is a positive integer q= q (n) with the property that if A is any n\u00d7 n stochastic matrix then the sequence of matrices A q, A 2q, A 3q,\u2026 converges. We prove a generalization of this for sets of stochastic matrices under the Hausdorff metric. Let d be any metric inducing the standard topology on the set of n\u00d7 n real matrices. For a matrix A and set of matrices B define d (A, B) to be the infimum of d (A, B) over all B\u2208 B. For two sets of matrices A and B, define d+(A, B) to be the supremum of d (A, B) over all A\u2208 A, and define d (A, B) to be the maximum of d+(A, B) and d+(B, A). This is the Hausdorff metric on the set of subsets of n\u00d7 n stochastic matrices. If A is a set of stochastic matrices and k is a positive integer, define A (k) to be the set of all matrices expressible as a product of a sequence of k\u00a0\u2026", "num_citations": "8\n", "authors": ["1790"]}
{"title": "Approximate solutions to problems in PSPACE\n", "abstract": " This issue's complexity theory column is a wonderful guest column by Anne Condon; enjoy! By coincidence, the center door of Anne's article-ending cartoon provides a commercial for the topic of a forthcoming guest column: Richard Lipton writing on molecular computing. Also in the works is a column about oracles and (gasp!) death. I wish you a wonderful, theorem-filled (and indeed a wonderful-theorem-filled) summer!", "num_citations": "8\n", "authors": ["1790"]}
{"title": "Output-oblivious stochastic chemical reaction networks\n", "abstract": " We classify the functions  which are stably computable by output-oblivious Stochastic Chemical Reaction Networks (CRNs), i.e., systems of reactions in which output species are never reactants. While it is known that precisely the semilinear functions are stably computable by CRNs, such CRNs sometimes rely on initially producing too many output species and then consuming the excess in order to reach a correct stable state. These CRNs may be difficult to integrate into larger systems: if the output of a CRN  becomes the input to a downstream CRN , then  could inadvertently consume too many outputs before  stabilizes. If, on the other hand,  is output-oblivious then  may consume 's output as soon as it is available. In this work we prove that a semilinear function  is stably computable by an output-oblivious CRN with a leader if and only if it is both increasing and either grid-affine (intuitively, its domains are congruence classes), or the minimum of a finite set of fissure functions (intuitively, functions behaving like the min function).", "num_citations": "7\n", "authors": ["1790"]}
{"title": "Simplifying analyses of chemical reaction networks for approximate majority\n", "abstract": " Approximate Majority is a well-studied problem in the context of chemical reaction networks\u00a0(CRNs) and their close relatives, population protocols: Given a mixture of two types of species with an initial gap between their counts, a CRN computation must reach consensus on the majority species. Angluin, Aspnes, and Eisenstat proposed a simple population protocol for Approximate Majority and proved correctness and  time efficiency with high probability, given an initial gap of size  when the total molecular count in the mixture is n. Motivated by their intriguing but complex proof, we provide simpler, and more intuitive proofs of correctness and efficiency for two bi-molecular CRNs for Approximate Majority, including that of Angluin et al. Key to our approach is to show how the bi-molecular CRNs essentially emulate a tri-molecular CRN with just two reactions and two species. Our results improve on\u00a0\u2026", "num_citations": "7\n", "authors": ["1790"]}
{"title": "RNA molecules: glimpses through an algorithmic lens\n", "abstract": " Dubbed the \u201carchitects of eukaryotic complexity\u201d [8], RNA molecules are increasingly in the spotlight, in recognition of the important catalytic and regulatory roles they play in our cells and their promise in therapeutics. Our goal is to describe the ways in which algorithms can help shape our understanding of RNA structure and function.", "num_citations": "6\n", "authors": ["1790"]}
{"title": "A new model for approximating RNA folding trajectories and population kinetics\n", "abstract": " RNA participates both in functional aspects of the cell and in gene regulation. The interactions of these molecules are mediated by their secondary structure which can be viewed as a planar circle graph with arcs for all the chemical bonds between pairs of bases in the RNA sequence. The problem of predicting RNA secondary structure, specifically the chemically most probable structure, has many useful and efficient algorithms. This leaves RNA folding, the problem of predicting the dynamic behavior of RNA structure over time, as the main open problem. RNA folding is important for functional understanding because some RNA molecules change secondary structure in response to interactions with the environment. The full RNA folding model on at most O (3 n) secondary structures is the gold standard. We present a new subset approximation model for the full model, give methods to analyze its accuracy and\u00a0\u2026", "num_citations": "5\n", "authors": ["1790"]}
{"title": "On the design of oligos for gene synthesis\n", "abstract": " Methods for reliable synthesis of long genes offer great promise for protein synthesis via expression of synthetic genes, with applications to improved analysis of protein structure and function, as well as engineering of novel proteins. Current technologies for gene synthesis use computational methods for design of short oligos, which can then be reliably synthesized and assembled into the desired target gene. For collision-oblivious oligo design -when mishybridizations between oligos are ignored -we give a simple and efficient dynamic programming algorithm. We conjecture that the collision-aware oligo design problem is NP-hard and provide evidence that mishybridizations between oligos occur infrequently in the designs from the collision-oblivious algorithm. We extend our dynamic programming algorithm to achieve collision-aware oligo design, when the target gene can be partitioned into independently\u00a0\u2026", "num_citations": "5\n", "authors": ["1790"]}
{"title": "Inferring parameters for an elementary step model of DNA structure kinetics with locally context-dependent Arrhenius rates\n", "abstract": " Models of nucleic acid thermal stability are calibrated to a wide range of experimental observations, and typically predict equilibrium probabilities of nucleic acid secondary structures with reasonable accuracy. By comparison, a similar calibration and evaluation of nucleic acid kinetic models to a broad range of measurements has not been attempted so far. We introduce an Arrhenius model of interacting nucleic acid kinetics that relates the activation energy of a state transition with the immediate local environment of the affected base pair. Our model can be used in stochastic simulations to estimate kinetic properties and is consistent with existing thermodynamic models. We infer parameters for our model using an ensemble Markov chain Monte Carlo (MCMC) approach on a training dataset with 320 kinetic measurements of hairpin closing and opening, helix association and dissociation, bubble closing and toehold\u00a0\u2026", "num_citations": "4\n", "authors": ["1790"]}
{"title": "Upper and lower bounds for selection on the mesh\n", "abstract": " A distance-optimal algorithm for selection on the mesh has proved to be elusive, although distance-optimal algorithms for the related problems of routing and sorting have recently been discovered. In this paper, we explain, using the notion of adaptiveness, why techniques used in the currently best selection algorithms cannot lead to a distance-optimal algorithm. We also present the first algorithm for selection that has distance-optimal performance on average. For worst-case inputs, we apply new techniques to improve the previous best upper bound of 1.22n of Kaklanaanis et al. to 1.15n. This improvement is obtained in part by increasing the adaptiveness of previous algorithms.< >", "num_citations": "4\n", "authors": ["1790"]}
{"title": "Realistic analysis of parallel dynamic programming algorithms\n", "abstract": " We examine a very simple asynchronous model of parallel computation that assumes the time to compute a task is random, following some probability distribution. The goal of this model is to capture the effects of unexpected delays on processors. Using techniques from queueing theory and occupancy problems, we use this model to analyze two parallel dynamic programming algorithms. We show that this model is both simple to analyze and realistic in the sense that the analysis corresponds to experimental results on a shared memory parallel machine.The algorithms we consider are a pipeline algorithm, where each processor 2'computes in order the entries of rows 2', i+ p and so on, where p is the number of processors; and a diagonal algorithm, where entries along each diagonal extending from the left to the top of the table are computed in turn.", "num_citations": "4\n", "authors": ["1790"]}
{"title": "On low energy barrier folding pathways for nucleic acid sequences\n", "abstract": " Secondary structure folding pathways correspond to the execution of DNA programs such as DNA strand displacement systems. It is helpful to understand the full diversity of features that such pathways can have, when designing novel folding pathways. In this work, we show that properties of folding pathways over a 2-base strand (a strand with either A and T, or C and G, but not all four bases) may be quite different than those over a 4-base alphabet. Our main result is that, for a simple energy model in which each base pair contributes , 2-base sequences of length n always have a folding pathway of length  with energy barrier at most 2. We provide an efficient algorithm for constructing such a pathway. In contrast, it is unknown whether minimum energy barrier pathways for 4-base sequences can be found efficiently, and such pathways can have barrier . We also present several results that\u00a0\u2026", "num_citations": "3\n", "authors": ["1790"]}
{"title": "Less haste, less waste: on recycling and its limits in strand displacement systems\n", "abstract": " We study the potential for molecule recycling in chemical reaction systems and their DNA strand displacement realizations. Recycling happens when a product of one reaction is a reactant in a later reaction. Recycling has the benefits of reducing consumption, or waste, of molecules and of avoiding fuel depletion. We present a binary counter that recycles molecules efficiently while incurring just a moderate slowdown compared to alternative counters that do not recycle strands. This counter is an n-bit binary reflecting Gray code counter that advances through 2                   n                  states. In the strand displacement realization of this counter, the waste\u2014total number of nucleotides of the DNA strands consumed\u2014is O(n                 3), while alternative counters have \u03a9(2                   n                 ) waste. We also show that our n-bit counter fails to work correctly when \u0398(n) copies of the species that represent the state (bits\u00a0\u2026", "num_citations": "3\n", "authors": ["1790"]}
{"title": "Perspectives: Canadian women in computer science\n", "abstract": " Statistics. In Canada, females participate in Computer Science and Information Technology in lower numbers than their male counterparts both at school and in the work force. Girls, particularly those from lower socio-economic groups, have less home access to computers and the Internet than do boys. Female students are enrolled in fewer Computer Science courses and are awarded fewer degrees in Computer Science at all levels, from high school Information Technology courses to PhD degrees (see tables 1-4). Fewer women than men teach Computer Science, with women holding 7% of all Full Professorships in Computer Science. In industry, women represent about 25% of computer professionals across Canada.", "num_citations": "3\n", "authors": ["1790"]}
{"title": "On the complexity of the policy iteration algorithm\n", "abstract": " We consider a natural class of algorithms for simple stochastic games. It has been proved that the problem of deciding which player has the greatest chance of winning the game is in the class NP n co-NP. It is not known whether the problem is in P. We examine a number of local search algorithms, called policy iteration algorithms, which solve this problem, and prove that these algorithms require exponential time in the worst case.", "num_citations": "3\n", "authors": ["1790"]}
{"title": "Composable Computation in Leaderless, Discrete Chemical Reaction Networks\n", "abstract": " We classify the functions f: \u2115^ d\u2192 \u2115 that are stably computable by leaderless, output-oblivious discrete (stochastic) Chemical Reaction Networks (CRNs). CRNs that compute such functions are systems of reactions over species that include d designated input species, whose initial counts represent an input x\u2208 \u2115^ d, and one output species whose eventual count represents f (x). Chen et al. showed that the class of functions computable by CRNs is precisely the semilinear functions. In output-oblivious CRNs, the output species is never a reactant. Output-oblivious CRNs are easily composable since a downstream CRN can consume the output of an upstream CRN without affecting its correctness. Severson et al. showed that output-oblivious CRNs compute exactly the subclass of semilinear functions that are eventually the minimum of quilt-affine functions, ie, affine functions with different intercepts in each of finitely many congruence classes. They call such functions the output-oblivious functions. A leaderless CRN can compute only superadditive functions, and so a leaderless output-oblivious CRN can compute only superadditive, output-oblivious functions. In this work we show that a function f: \u2115^ d\u2192 \u2115 is stably computable by a leaderless, output-oblivious CRN if and only if it is superadditive and output-oblivious.", "num_citations": "2\n", "authors": ["1790"]}
{"title": "Error-free stable computation with polymer-supplemented chemical reaction networks\n", "abstract": " When disallowing error, traditional chemical reaction networks (CRNs) are very limited in computational power: Angluin et al. and Chen et al. showed that only semilinear predicates and functions are stably computable by CRNs. Qian et al. and others have shown that polymer-supplemented CRNs (psCRNs) are capable of Turing-universal computation. However, their model requires that inputs are pre-loaded on the polymers, in contrast with the traditional convention that inputs are represented by counts of molecules in solution. Here, we show that psCRNs can stably simulate Turing-universal computations even with solution-based inputs. However, such simulations use a unique \u201cleader\u201d polymer per input type and thus involve many slow bottleneck reactions. We further refine the polymer-supplemented CRN model to allow for anonymous polymers, that is, multiple functionally-identical copies of a\u00a0\u2026", "num_citations": "2\n", "authors": ["1790"]}
{"title": "Efficient Parameter Estimation for DNA Kinetics Modeled as Continuous-Time Markov Chains\n", "abstract": " Nucleic acid kinetic simulators aim to predict the kinetics of interacting nucleic acid strands. Many simulators model the kinetics of interacting nucleic acid strands as continuous-time Markov chains (CTMCs). States of the CTMCs represent a collection of secondary structures, and transitions between the states correspond to the forming or breaking of base pairs and are determined by a nucleic acid kinetic model. The number of states these CTMCs can form may be exponentially large in the length of the strands, making two important tasks challenging, namely, mean first passage time (MFPT) estimation and parameter estimation for kinetic models based on MFPTs. Gillespie\u2019s stochastic simulation algorithm (SSA) is widely used to analyze nucleic acid folding kinetics, but could be computationally expensive for reactions whose CTMC has a large state space or for slow reactions. It could also be expensive for\u00a0\u2026", "num_citations": "2\n", "authors": ["1790"]}
{"title": "Towards space-and energy-efficient computations\n", "abstract": " We sta t ith a ie it odu tio to lo i al ee si ilit i the o te to ti e-ou ded o putatio as ell as ea lok o spa e-ou ded, lo i all ee si le o putatio s. We the des ieapo essio o ideas o ho the a st ato ept o lo i al ee si ilit i ht ei ple e ted he i all, ad ho the ee effi ie o he i al i ple e tatio sae easu ed.", "num_citations": "2\n", "authors": ["1790"]}
{"title": "Finding MFE Structures Formed by Nucleic Acid Strands in a Combinatorial Set\n", "abstract": " 5 Conclusions               We presented here an algorithm that, given a combinatorial set and parameter k, predicts the k secondary structures with lowest minimum free energies in the combinatorial set. When the number of words in each set of the overall input-set is considered to be a constant, our algorithm runs in O(skn3) time. In our algorithms, given a combination C, we look at the minimum free energy structure only. Extensions of these problems would be to find suboptimal structures (i.e. whose free energy is greater than the MFE), or to consider pseudoknots. Another problem for future work would be to find an algorithm with better running time, for example O(n3 + k).", "num_citations": "2\n", "authors": ["1790"]}
{"title": "Understanding RNA Pseudoknotted Structures\n", "abstract": " Computational prediction of the minimum free energy (mfe) secondary structure of an RNA molecule from its base sequence is valuable in understanding the structure and function of the molecule. Since the general problem of predicting pseudoknotted secondary structures is NP-hard, several algorithms have been proposed that find the mfe secondary structure from a restricted class of secondary structures. In this work, we order the classes by generality of the structure classes that they handle. We provide simple characterizations of the classes of structures handled by three algorithms, as well as linear time methods to test whether a given secondary structure is in each class. We report on the percentage of biological structures from the PseudoBase and Gutell databases that are handled by these three algorithms. Finally, we provide a linear time method for parsing a pseudoknotted structure into its elementary\u00a0\u2026", "num_citations": "2\n", "authors": ["1790"]}
{"title": "DNA Computing: 6th International Workshop on DNA-Based Computers, DNA 2000, Leiden, The Netherlands, June 13-17, 2000. Revised Papers\n", "abstract": " The papers in this volume were presented at the 6th International Meeting on DNA Based Computers, organized by the Leiden Center for Natural Computing and held from June 13 to June 17, 2000 at The Lorentz Center, University of Leiden, Leiden, The Netherlands. DNA Computing is a novel and fascinating development at the interface of computer science and molecular biology. It has emerged in recent years, not simply as an exciting technology for information processing, but also as a catalyst for knowledge transfer between information processing, nanotechnology, and biology. This area of research has the potential to change our understanding of the theory and practice of computing. The call for papers and poster presentations sought contributions of original research and technical expositions in all areas of bio-computation. A total of 33 abstracts were submitted of which 16 were accepted for presentation and included in the proceedings. The papers were selected by the program committee based on originality and quality of research and on relevance to the bio-computing eld. Invited talks were given by Masami Hagiya (Tokyo University), Laura La-weber (Princeton University), John Reif (Duke University), Thomas Schmidt (Leiden University), and Lloyd M. Smith (University of Wisconsin). Invited-pers based on the talks by Hagiya and Reif are included in this volume, along with the contributed papers. Additional tutorials were held on the rst and last days of the conference.", "num_citations": "2\n", "authors": ["1790"]}
{"title": "Challenges for theory of computing\n", "abstract": " This report is the culmination of a two-day workshop, funded by the National Science Foundation (NSF), that took place March 11\u201312, 1999 in Chicago. Fourteen of the authors and the Program Director of the Theory of Computing, Zeke Zalcstein, attended this workshop. All of the authors participated in extensive discussions by email. The purpose of this effort was to develop and offer a current perspective on research in theoretical computer science.This is an especially opportune time to carry out this exercise. The President\u2019s Information Technology Advisory Committee (PITAC) Report calls for an increase in support of information technology research of roughly a billion dollars over the next five years, and the Administration\u2019s proposed Federal budget for FY 2000 demonstrates a commitment to sustained growth in information technology research through its initiative, Information Technology for the Twenty-First Century (IT 2). Since NSF will be the lead agency of IT 2 and NSF is essentially the sole agency funding research in theory of computing, it is certainly appropriate to inquire into the impact of theoretical research on computer science and to attempt to measure the importance of theoretical research for solving strategic long-range problems as called for by the PITAC Report.", "num_citations": "2\n", "authors": ["1790"]}
{"title": "Upper and lower bounds for selection on the mesh\n", "abstract": " A distance-optimal algorithm for selection on the mesh has proved to be elusive, although distance-optimal algorithms for the related problems of routing and sorting have recently been discovered. In this paper we explain, using the notion of adaptiveness, why techniques used in the currently best selection algorithms cannot lead to a distance-optimal algorithm.                For worst-case inputs we apply new techniques to improve the previous best upper bound of 1.22n  of Kaklamanis et al. [7] to 1.15n . This improvement is obtained in part by increasing the adaptiveness of previous algorithms.", "num_citations": "2\n", "authors": ["1790"]}
{"title": "Asynchronous analysis of parallel dynamic programming\n", "abstract": " We examine a very simple asynchronous model of parallel computation that assumes the time to compute a task is random, following some probability distribution. The goal of this model is to capture the effects of unexpected delays on processors.", "num_citations": "2\n", "authors": ["1790"]}
{"title": "Upper Bounds on the Complexity of Space Bounded Interactive Proofs\n", "abstract": " We show that the class IP(2pfa) of languages accepted by interactive proof systems with finite state verifiers is contained in ATIME(2 2o(n)). We also show that 2-prover interactive proof systems with finite state verifiers accept exactly the recursive languages.  Our results generalize to other space bounds.  We also obtain some results of independent interest on the rate of convergence of time-varying Markov chains and of non-Markov chains, called feedback chains, to their halting states.", "num_citations": "2\n", "authors": ["1790"]}
{"title": "RNA STRAND\n", "abstract": " RNA SSTRAND Page 1 RNA SSTRAND A new database for RNA secondary structure data and statistical analysis of RNA structural motifs Mirela Andronescu, Vera Bereg, Holger H. Hoos and Anne Condon Department of Computer Science University of British Columbia Page 2 Motivation and Goals to interactively analyse a diverse collection of over 9000 RNA molecules to offer comprehensive information on structural features within and across functional classes of molecules to help improve methods for computational prediction of RNA secondary structure to permit comparison across different classes of molecules to allow submission of new molecules, so as to maintain the vast broadness of the database Page 3 Analyser in the heart of the RNA SSTRAND database lies Analyser it is a tool capable of taking in a bpseq representation of a secondary structure of RNA molecule and outputting statistical data that \u2026", "num_citations": "2\n", "authors": ["1790"]}
{"title": "Design of nucleic acid strands with long low-barrier folding pathways\n", "abstract": " A major goal of natural computing is to design biomolecules, such as nucleic acid sequences, that can be used to perform computations. We design sequences of nucleic acids that are \u201cguaranteed\u201d to have long folding pathways relative to their length. This particular sequences with high probability follow low-barrier folding pathways that visit a large number of distinct structures. Long folding pathways are interesting, because they demonstrate that natural computing can potentially support long and complex computations. Formally, we provide the first scalable designs of molecules whose low-barrier folding pathways, with respect to a simple, stacked pair energy model, grow superlinearly with the molecule length, but for which all significantly shorter alternative folding pathways have an energy barrier that is  times that of the low-barrier pathway for any  and a sufficiently long sequence.", "num_citations": "1\n", "authors": ["1790"]}
{"title": "Improving the Working Climate in the Faculty of Science at UBC\n", "abstract": " In 2005, an advisory committee was struck to assess the working climate for Science faculty at the University of British Columbia (UBC), with an initial focus on concerns raised by women faculty. This study carefully analyzed both institutional and survey data. It was supported by the Faculty of Science, the Provost and the Vice President, Research, and led by UBC mathematics professor Rachel Kuske. The study found that, while faculty overall reported a general sense of fair treatment and collegiality, several concerns were raised by female faculty about the lack of professional support, issues of workplace equity, and career development needs. In areas where clear policies were applied, such as salaries, there were limited differences by gender. In contrast, significant gender differences were observed, where the data suggested a lack of transparent and equitable procedures and policies. These included differences in time to promotion, in amounts of retention funding, and in awards.The Dean's Office of the Faculty of Science (FoS) has already acted on several recommendations, but there is much work ahead. Key components of the plan for change will include: new recruiting practices to increase faculty diversity, with oversight by the Dean's office; better support for partner accommodation; policy development and documentation including policies on research support during maternity/parental leave and teaching reductions; better support for mentoring and career feedback; and mechanisms to increase equity in retention, awards and support of leadership.", "num_citations": "1\n", "authors": ["1790"]}
{"title": "A New SLS Algorithm for RNA Secondary Structure Design\n", "abstract": " Ribonucleic acids (RNAs) are amongst the most important molecular components of all biological organisms. Similar to proteins, their function often depends crucially on their structure. Hence, computational methods for design of RNA molecules with specific structural properties are of considerable interest for biological and biomedical research. In this paper, we propose a new algorithm for the RNA Secondary Structure Design Problem: Given any RNA secondary structure, ie, a specification of base pairing interactions within an RNA strand, find an RNA strand that folds into this structure. This problem can be seen as a complex constraint satisfaction problem with interesting general properties. Our new stochastic local search (SLS) algorithm is based on a combination of problem-specific insights and state-of-the-art techniques for solving CSPs and other hard combinatorial problems. A thorough empirical\u00a0\u2026", "num_citations": "1\n", "authors": ["1790"]}
{"title": "Upper and lower bounds for selection on the mesh\n", "abstract": " A distance-optimal algorithm for selection on the mesh has proved to be elusive, although distance-optimal algorithms for the related problems of routing and sorting have recently been discovered. In this paper, we explain, using the notion of adaptiveness, why techniques used in the currently best selection algorithms cannot lead to a distance-optimal algorithm. For worst-case inputs, we apply new techniques to improve the previous best upper bound of 1: 22n of Kaklamanis et al. 7] to 1: 15n. This improvement is obtained in part by increasing the adaptiveness of previous algorithms.", "num_citations": "1\n", "authors": ["1790"]}