{"title": "Model-based early and rapid estimation of COSMIC functional size\u2013An experimental evaluation\n", "abstract": " ContextFunctional size measurement methods are widely used but have two major shortcomings: they require a complete and detailed knowledge of user requirements, and they involve relatively expensive and lengthy processes.ObjectiveUML is routinely used in the software industry to effectively describe software requirements in an incremental way, so UML models grow in detail and completeness through the requirements analysis phase. Here, we aim at defining the characteristics of increasingly more refined UML requirements models that support increasingly more sophisticated \u2013 hence presumably more accurate \u2013 size estimation processes.MethodWe consider the COSMIC method and three alternative processes (two of which are proposed in this paper) to estimate COSMIC size measures that can be applied to UML diagrams at progressive stages of the requirements definition phase. Then, we check the\u00a0\u2026", "num_citations": "22\n", "authors": ["2008"]}
{"title": "A survey of schema matching research using database schemas and instances\n", "abstract": " Schema matching is considered as one of the essential phases of data integration in database systems. The main aim of the schema matching process is to identify the correlation between schema which helps later in the data integration process. The main issue concern of schema matching is how to support the merging decision by providing the correspondence between attributes through syntactic and semantic heterogeneous in data sources. There have been a lot of attempts in the literature toward utilizing database instances to detect the correspondence between attributes during schema matching process. Many approaches based on instances have been proposed aiming at improving the accuracy of the matching process. This paper set out a classification of schema matching research in database system exploiting database schema and instances. We survey and analyze the schema matching techniques applied in the literature by highlighting the strengths and the weaknesses of each technique. A deliberate discussion has been reported highlights on challenges and the current research trends of schema matching in database. We conclude this paper with some future work directions that help researchers to explore and investigate current issues and challenges related to schema matching in contemporary databases.", "num_citations": "19\n", "authors": ["2008"]}
{"title": "Disaster recovery with minimum replica plan for reliability checking in multi-cloud\n", "abstract": " The primary uses for cloud computing are to store data and share resources. The cloud has become a dominant and preferred method to store large amounts of data and enable the sharing of that data among several users. It also enables the use of pay-as-you-go pricing models. Today\u2019s cloud computing environment has required data centers to increase the amount of available storage. There are two main concerns with cloud storage: data reliability and cost of storage. This paper discusses the issue of data recovery in case of a disaster in a Multi-Cloud environment. We propose a preventive approach for data backup and recovery aiming at minimizing the number of replicas and ensure high reliability for data before the disaster. The approach named Preventive Disaster Recovery Plan with Minimum Replica (PDRPMR) which is a cost-effective mechanism to reduce the number of replications in the cloud to be 1\u00a0\u2026", "num_citations": "14\n", "authors": ["2008"]}
{"title": "Improved handover decision algorithm using multiple criteria\n", "abstract": " The transfer of massive data between varied network positions links of network relies on data rate, as well as the traffic capacity of the network. Conventionally, a device that is mobile can be used to attain vertical handover functional by weighing in only an aspect, which refers to Received Signal Strength (RSS). The application of this particular criterion could lead to interruption in services, ineffective vertical handover, and a network load that is not balanced. Hence, this paper proposes an improvised vertical handover decision algorithm by integrating multi-criteria within a wireless network that is heterogeneous. The proposed algorithm comprised of three vertical handover decision algorithms, namely: mobile weight, network weight, and equal weight. Additionally, three technology interfaces were embedded in this study including Worldwide interoperability for Microwave Access (WiMAX), Wireless Local Area\u00a0\u2026", "num_citations": "13\n", "authors": ["2008"]}
{"title": "Digital transformation in higher education: a framework for maturity assessment\n", "abstract": " Literature in digital transformation maturity is scarce. Digital transformation in higher education, especially after COVID-19 is seen as inevitable. This research explores digital transformation maturity and challenges within Higher Education. The significance of this study stems from the role digital transformation plays in today\u2019s knowledge economy. This study proposes a new framework based on Deloitte\u2019s 2019 digital transformation assessment framework with Petkovic 2014 mega and major higher education process mapping. The study triangulates the findings of multiple research instruments, including survey, interviews, case study, and direct observation. The research findings show a significant variance between the respondents\u2019 perception of digital transformations maturity levels, and the core requirements of digital transformation maturity. The findings also show the lack of holistic vision, digital transformation competency, and data structure and processing as the leading challenges of digital transformation.", "num_citations": "11\n", "authors": ["2008"]}
{"title": "IFPUG Function Points to COSMIC Function Points convertibility: A fine-grained statistical approach\n", "abstract": " BackgroundFunctional size measurement is widely used in software organizations because it supports the estimation of software development effort. Function Point Analysis was the first functional size measurement method and became quite popular. The COSMIC method is considered a second-generation method, due to its novel design, and has also gained wide acceptance. Since the proposal of the COSMIC method, the measure convertibility issue arose. Many studies have investigated this issue: several conversion techniques have been proposed and their accuracy has been evaluated through empirical studies.ObjectiveThe goal of the paper is to explore statistic conversion criteria that leverage the similarity between the Base Functional Components of the considered functional measurement methods, especially concerning elementary processes and functional processes.MethodStatistical models of the\u00a0\u2026", "num_citations": "9\n", "authors": ["2008"]}
{"title": "Integrating Elman Recurrent Neural Network with Particle Swarm Optimization Algorithms for an Improved Hybrid Training of Multidisciplinary Datasets\n", "abstract": " There are several types of neural networks (NNs) that are widely used for data classification tasks. The supervised learning NN is an advanced network with a training algorithm for setting the weights and biases of the network in its training phase. However, traditional training algorithms such as backpropagation have some drawbacks, such as slow convergence speed and falling into local minima, which reduces the performance of the classifier. Therefore, different nature-inspired metaheuristic algorithms are integrated with the NN training algorithms to provide derivative-free solutions for complex classification problems. Consequently, this paper proposes the integration of a particle swarm optimization (PSO) algorithm with an improved Elman recurrent neural network (ERNN) to form a PSO-ERNN metaheuristic model. The key contribution of this study is the development of a new dimensional equation for ERNN\u00a0\u2026", "num_citations": "6\n", "authors": ["2008"]}
{"title": "Model-based Simplified Functional Size Measurement-an Experimental Evaluation with COSMIC Function Points.\n", "abstract": " Functional Size Measurement methods\u2013like the COSMIC method\u2013are widely used but have two major shortcomings: they require a complete and detailed knowledge of user requirements and they are carried out via relatively expensive and lengthy processes. To tackle these issues, simplified measurement processes have been proposed that can be applied to requirements specifications even if they are incomplete or not very detailed. Since software requirements can be effectively modeled using languages like UML and the models increase their level of detail and completeness through the development lifecycle, our goal is to define the characteristics of progressively refined requirements models that support progressively more sophisticated and accurate measurement processes for functional software size. We consider the COSMIC method and three simplified measurement processes, and we show how they can be carried out, based on UML diagrams. Then, the accuracy of the measurement supported by each type of UML model is empirically tested, by analyzing the results obtained on a set of projects. Our analysis shows that it is possible to write progressively more detailed and complete user requirements UML models that provide the data required by simplified methods, which provide progressively more accurate values for functional size measures of the modeled software. Conclusions. Developers that use UML for requirements model can obtain an estimation of the application\u2019s functional size early on in the development process, when only a very simple UML model has been built for the application, and can get increasingly more\u00a0\u2026", "num_citations": "6\n", "authors": ["2008"]}
{"title": "A COMPARATIVE STUDY ON THE SOFTWARE ARCHITECTURE OF WRF AND OTHER NUMERICAL WEATHER PREDICTION MODELS\n", "abstract": " Software modularity architecture facilitates software development and software reusability. Software reusability enhances the maintenance of software, facilitates building larger component out of subcomponents. Numerical weather prediction uses complex mathematical models and run them on powerful computers to forecast weather conditions. Numerical weather prediction models have proliferated and can be classified into regional and global models. The Weather Research Forecast model is considered the nextgeneration mesoscale regional model and widely used. The Weather Research Forecasting model consists of several modules interacting with each other. This research aims to study the WRF\u2019s software architecture, software modules, and the forecasting accuracy of WRF in respect to other well-known Numerical Prediction Models. The study outcomes show that WRF\u2019s software architecture characterized with high degree of flexibility, loosely coupled modules which plays a very important role to obtain accurate forecasting results through the application of independent modules, and consequently it provides a high reliable and accurate forecasting results.", "num_citations": "5\n", "authors": ["2008"]}
{"title": "Skyline queries computation on crowdsourced-enabled incomplete database\n", "abstract": " Data incompleteness becomes a frequent phenomenon in a large number of contemporary database applications such as web autonomous databases, big data, and crowd-sourced databases. Processing skyline queries over incomplete databases impose a number of challenges that negatively influence processing the skyline queries. Most importantly, the skylines derived from incomplete databases are also incomplete in which some values are missing. Retrieving skylines with missing values is undesirable, particularly, for recommendation and decision-making systems. Furthermore, running skyline queries on a database with incomplete data raises a number of issues influence processing skyline queries such as losing the transitivity property of the skyline technique and cyclic dominance between the tuples. The issue of estimating the missing values of skylines has been discussed and examined in the\u00a0\u2026", "num_citations": "3\n", "authors": ["2008"]}
{"title": "A model for computing skyline data items in cloud incomplete databases\n", "abstract": " Skyline queries intend to retrieve the most superior data items in the database that best fit with the user\u2019s given preference. However, processing skyline queries are expensive and uneasy when applying on large distributed databases such as cloud databases. Moreover, it would be further sophisticated to process skyline queries if these distributed databases have missing values in certain dimensions. The effect of data incompleteness on skyline process is extremely severe because missing values result in un-hold the transitivity property of skyline technique and leads to the problem of cyclic dominance. This paper proposes an efficient model for computing skyline data items in cloud incomplete databases. The model focuses on processing skyline queries in cloud incomplete databases aiming at reducing the domination tests between data items, the processing time, and the amount of data transfer among the\u00a0\u2026", "num_citations": "2\n", "authors": ["2008"]}
{"title": "An Empirical Comparative Study of Instance-based Schema Matching\n", "abstract": " The main issue concern of schema matching is how to support the merging decision by providing matching between attributes of different schemas. There have been many works in the literature toward utilizing database instances to detect the correspondence between attributes. Most of these previous works aim at improving the match accuracy. We observed that no technique managed to provide an accurate matching for different types of data. In other words, some of the techniques treat numeric values as strings. Similarly, other techniques process textual instance, as numeric, and this negatively influences the process of discovering the match and compromising the matching result. Thus, a practical comparative study between syntactic and semantic techniques is needed. The study emphasizes on analyzing these techniques to determine the strengths and weaknesses of each technique. This paper aims at comparing two different instance-based matching techniques, namely:(i) regular expression and (ii) Google similarity to identify the match between attributes. Several analyses have been conducted on real and synthetic data sets to evaluate the performance of these techniques with respect to Precision (P), Recall (R) and F-Measure.", "num_citations": "2\n", "authors": ["2008"]}
{"title": "Data Backup and Recovery With a Minimum Replica Plan in a Multi-Cloud Environment\n", "abstract": " Cloud computing has become a desirable choice to store and share large amounts of data among several users. The two main concerns with cloud storage are data recovery and cost of storage. This article discusses the issue of data recovery in case of a disaster in a multi-cloud environment. This research proposes a preventive approach for data backup and recovery aiming at minimizing the number of replicas and ensuring high data reliability during disasters. This approach named Preventive Disaster Recovery Plan with Minimum Replica (PDRPMR) aims at reducing the number of replications in the cloud without compromising the data reliability. PDRPMR means preventive action checking of the availability of replicas and monitoring of denial of service attacks to maintain data reliability. Several experiments were conducted to evaluate the effectiveness of PDRPMR and the results demonstrated that the\u00a0\u2026", "num_citations": "1\n", "authors": ["2008"]}
{"title": "Algorithm for enhancing the QoS of video traffic over wireless mesh networks\n", "abstract": " One of the major issues in a wireless mesh networks (WMNs) which needs to be solved is the lack of a viable protocol for medium access control (MAC). In fact, the main concern is to expand the application of limited wireless resources while simultaneously retaining the quality of service (QoS) of all types of traffic. In particular, the video service for real-time variable bit rate (rt-VBR). As such, this study attempts to enhance QoS with regard to packet loss, average delay, and throughput by controlling the transmitted video packets. The packet loss and average delay of QoS for video traffic can be controlled. Results of simulation show that Optimum Dynamic Reservation-Time Division Multiplexing Access (ODR-TDMA) has achieved excellent utilization of resource that improvised the QoS meant for video packets. This study has also proven the adequacy of the proposed algorithm to minimize packet delay and packet loss, in addition to enhancing throughput in comparison to those reported in previous studies.", "num_citations": "1\n", "authors": ["2008"]}
{"title": "Disaster Recovery in Cloud Computing Systems: An Overview\n", "abstract": " With the rapid growth of internet technologies, large-scale online services, such as data backup and data recovery are increasingly available. Since these large-scale online services require substantial networking, processing, and storage capacities, it has become a considerable challenge to design equally large-scale computing infrastructures that support these services costeffectively. In response to this rising demand, cloud computing has been refined during the past decade and turned into a lucrative business for organizations that own large datacenters and offer their computing resources. Undoubtedly cloud computing provides tremendous benefits for data storage backup and data accessibility at a reasonable cost. This paper aims at surveying and analyzing the previous works proposed for disaster recovery in cloud computing. The discussion concentrates on investigating the positive aspects and the limitations of each proposal. Also examined are discussed the current challenges in handling data recovery in the cloud context and the impact of data backup plan on maintaining the data in the event of natural disasters. A summary of the leading research work is provided outlining their weaknesses and limitations in the area of disaster recovery in the cloud computing environment. An in-depth discussion of the current and future trends research in the area of disaster recovery in cloud computing is also offered. Several work research directions that ought to be explored are pointed out as well, which may help researchers to discover and further investigate those problems related to disaster recovery in the cloud environment that have\u00a0\u2026", "num_citations": "1\n", "authors": ["2008"]}